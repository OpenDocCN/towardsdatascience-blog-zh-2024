- en: 'K Nearest Neighbor Regressor, Explained: A Visual Guide with Code Examples'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kæœ€è¿‘é‚»å›å½’å™¨ï¼Œè§£é‡Šï¼šå¸¦ä»£ç ç¤ºä¾‹çš„è§†è§‰æŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889?source=collection_archive---------1-----------------------#2024-10-07](https://towardsdatascience.com/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889?source=collection_archive---------1-----------------------#2024-10-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889?source=collection_archive---------1-----------------------#2024-10-07](https://towardsdatascience.com/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889?source=collection_archive---------1-----------------------#2024-10-07)
- en: REGRESSION ALGORITHM
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å›å½’ç®—æ³•
- en: Finding the neighbors FAST with KD Trees and Ball Trees
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨KDæ ‘å’ŒBallæ ‘å¿«é€Ÿå¯»æ‰¾é‚»å±…
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)
    Â·11 min readÂ·Oct 7, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)
    Â·é˜…è¯»æ—¶é—´11åˆ†é’ŸÂ·2024å¹´10æœˆ7æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=post_page-----df5052c8c889--------------------------------)
    [## K Nearest Neighbor Classifier, Explained: A Visual Guide with Code Examples
    for Beginners'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=post_page-----df5052c8c889--------------------------------)
    [## Kè¿‘é‚»åˆ†ç±»å™¨ï¼Œè§£é‡Šï¼šå¸¦ä»£ç ç¤ºä¾‹çš„åˆå­¦è€…è§†è§‰æŒ‡å—'
- en: The friendly neighbor approach to machine learning
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ä¸­çš„å‹å¥½é‚»å±…æ–¹æ³•
- en: towardsdatascience.com](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=post_page-----df5052c8c889--------------------------------)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=post_page-----df5052c8c889--------------------------------)'
- en: Building on our exploration of the [Nearest Neighbor Classifier](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1),
    letâ€™s turn to its sibling in the regression world. The Nearest Neighbor Regressor
    applies the same intuitive concept to predicting continuous values. But as our
    datasets get bigger, finding these neighbors efficiently becomes a real pain.
    Thatâ€™s where KD Trees and Ball Trees come in.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬æ¢è®¨äº†[æœ€è¿‘é‚»åˆ†ç±»å™¨](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)åï¼Œè®©æˆ‘ä»¬è½¬å‘å›å½’é¢†åŸŸä¸­çš„â€œå…„å¼Ÿâ€â€”â€”æœ€è¿‘é‚»å›å½’å™¨ã€‚æœ€è¿‘é‚»å›å½’å™¨å°†ç›¸åŒçš„ç›´è§‚æ¦‚å¿µåº”ç”¨äºé¢„æµ‹è¿ç»­å€¼ã€‚ä½†æ˜¯ï¼Œéšç€æ•°æ®é›†çš„å¢å¤§ï¼Œå¦‚ä½•é«˜æ•ˆåœ°æ‰¾åˆ°è¿™äº›é‚»å±…å˜å¾—éå¸¸éº»çƒ¦ã€‚è¿™å°±æ˜¯KDæ ‘å’ŒBallæ ‘æ´¾ä¸Šç”¨åœºçš„åœ°æ–¹ã€‚
- en: Itâ€™s super frustrating that thereâ€™s no clear guide out there that really explains
    whatâ€™s going on with these algorithms. Sure, there are some 2D visualizations,
    but they often donâ€™t make it clear how the trees work in multidimensional setting.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¤äººæ²®ä¸§çš„æ˜¯ï¼Œç›®å‰æ²¡æœ‰æ˜ç¡®çš„æŒ‡å—èƒ½å¤ŸçœŸæ­£è§£é‡Šè¿™äº›ç®—æ³•çš„è¿ä½œåŸç†ã€‚å½“ç„¶ï¼Œæœ‰ä¸€äº›äºŒç»´å¯è§†åŒ–å›¾åƒï¼Œä½†å®ƒä»¬é€šå¸¸æ— æ³•æ¸…æ¥šåœ°å±•ç¤ºæ ‘åœ¨å¤šç»´ç¯å¢ƒä¸­çš„å·¥ä½œæ–¹å¼ã€‚
- en: Here, we will explain whatâ€™s **actually** going on in these algorithms without
    using the oversimplified 2D representation. Weâ€™ll be focusing on the construction
    of the trees itself and see which computation (and numbers) actually matters.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è§£é‡Šè¿™äº›ç®—æ³•**å®é™…**æ˜¯å¦‚ä½•è¿ä½œçš„ï¼Œè€Œä¸ä½¿ç”¨è¿‡äºç®€åŒ–çš„äºŒç»´è¡¨ç¤ºã€‚æˆ‘ä»¬å°†ä¸“æ³¨äºæ ‘çš„æ„å»ºè¿‡ç¨‹ï¼Œå¹¶çœ‹çœ‹å“ªäº›è®¡ç®—ï¼ˆå’Œæ•°å­—ï¼‰å®é™…ä¸Šæ˜¯é‡è¦çš„ã€‚
- en: '![](../Images/00c7b6d82e926d5ce08ebc77977eab63.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00c7b6d82e926d5ce08ebc77977eab63.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å¯è§†åŒ–ï¼šä½œè€…ä½¿ç”¨Canva Proåˆ›å»ºï¼Œé’ˆå¯¹ç§»åŠ¨è®¾å¤‡è¿›è¡Œäº†ä¼˜åŒ–ï¼›åœ¨æ¡Œé¢ä¸Šå¯èƒ½æ˜¾ç¤ºè¿‡å¤§ã€‚
- en: Definition
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®šä¹‰
- en: The Nearest Neighbor Regressor is a straightforward predictive model that estimates
    values by averaging the outcomes of nearby data points. This method builds on
    the idea that similar inputs likely yield similar outputs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘é‚»å›å½’å™¨æ˜¯ä¸€ä¸ªç›´æ¥çš„é¢„æµ‹æ¨¡å‹ï¼Œé€šè¿‡å¹³å‡é™„è¿‘æ•°æ®ç‚¹çš„ç»“æœæ¥ä¼°ç®—å€¼ã€‚è¯¥æ–¹æ³•åŸºäºç›¸ä¼¼è¾“å…¥å¯èƒ½äº§ç”Ÿç›¸ä¼¼è¾“å‡ºçš„ç†å¿µã€‚
- en: '![](../Images/aba12c7b4e3b510a0d187544f9510e12.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aba12c7b4e3b510a0d187544f9510e12.png)'
- en: Nearest Neighbor approaches are among the most basic yet powerful techniques
    in the machine learning toolkit. Their simplicity belies their effectiveness in
    many real-world scenarios.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘é‚»æ–¹æ³•æ˜¯æœºå™¨å­¦ä¹ å·¥å…·åŒ…ä¸­æœ€åŸºç¡€ä¸”å¼ºå¤§çš„æŠ€æœ¯ä¹‹ä¸€ã€‚å®ƒä»¬çš„ç®€å•æ€§æ©ç›–äº†å®ƒä»¬åœ¨è®¸å¤šå®é™…åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚
- en: ğŸ“Š Dataset Used
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- en: To illustrate our concepts, weâ€™ll use [our usual dataset](/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629).
    This dataset helps predict the number of golfers visiting on any given day. It
    includes factors such as weather outlook, temperature, humidity, and wind conditions.
    Our goal is to estimate the daily golfer turnout based on these variables.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯´æ˜æˆ‘ä»¬çš„æ¦‚å¿µï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[æˆ‘ä»¬é€šå¸¸çš„æ•°æ®é›†](/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629)ã€‚è¿™ä¸ªæ•°æ®é›†æœ‰åŠ©äºé¢„æµ‹æ¯å¤©çš„é«˜å°”å¤«çƒæ‰‹æ•°é‡ã€‚å®ƒåŒ…æ‹¬å¤©æ°”çŠ¶å†µã€æ¸©åº¦ã€æ¹¿åº¦å’Œé£é€Ÿç­‰å› ç´ ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åŸºäºè¿™äº›å˜é‡ä¼°ç®—æ¯æ—¥é«˜å°”å¤«çƒæ‰‹çš„åˆ°åœºäººæ•°ã€‚
- en: '![](../Images/8f70777fcdcfbe631c352c17a649d816.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f70777fcdcfbe631c352c17a649d816.png)'
- en: 'Columns: â€˜Outlookâ€™, â€˜Temperatureâ€™ (in Fahrenheit), â€˜Humidityâ€™ (in %), â€˜Windâ€™
    (Yes/No) and â€˜Number of Playersâ€™ (numerical, target feature)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—ï¼šâ€˜Outlookâ€™ï¼ˆå¤©æ°”çŠ¶å†µï¼‰ï¼Œâ€˜Temperatureâ€™ï¼ˆæ¸©åº¦ï¼Œå•ä½åæ°åº¦ï¼‰ï¼Œâ€˜Humidityâ€™ï¼ˆæ¹¿åº¦ï¼Œå•ä½%ï¼‰ï¼Œâ€˜Windâ€™ï¼ˆé£é€Ÿï¼Œæ˜¯å¦æœ‰é£ï¼‰ï¼Œä»¥åŠâ€˜Number
    of Playersâ€™ï¼ˆç©å®¶æ•°é‡ï¼Œæ•°å€¼å‹ï¼Œç›®æ ‡ç‰¹å¾ï¼‰
- en: To use Nearest Neighbor Regression effectively, we need to preprocess our data.
    This involves [converting categorical variables into numerical format](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    and [scaling numerical features](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æœ‰æ•ˆåœ°ä½¿ç”¨æœ€è¿‘é‚»å›å½’ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚è¿™åŒ…æ‹¬[å°†åˆ†ç±»å˜é‡è½¬æ¢ä¸ºæ•°å€¼æ ¼å¼](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)å’Œ[ç¼©æ”¾æ•°å€¼ç‰¹å¾](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)ã€‚
- en: '![](../Images/856bb5024939a0acbe57928f62346faa.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/856bb5024939a0acbe57928f62346faa.png)'
- en: Standard scaling is applied to â€˜Temperatureâ€™ and â€˜Humidityâ€™ while the one-hot
    encoding is applied to â€˜Outlookâ€™ and â€˜Windâ€™
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹â€˜Temperatureâ€™ï¼ˆæ¸©åº¦ï¼‰å’Œâ€˜Humidityâ€™ï¼ˆæ¹¿åº¦ï¼‰åº”ç”¨æ ‡å‡†ç¼©æ”¾ï¼Œè€Œå¯¹â€˜Outlookâ€™ï¼ˆå¤©æ°”çŠ¶å†µï¼‰å’Œâ€˜Windâ€™ï¼ˆé£é€Ÿï¼‰åº”ç”¨ç‹¬çƒ­ç¼–ç ã€‚
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Main Mechanism
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸»è¦æœºåˆ¶
- en: 'The Nearest Neighbor Regressor works similarly to its classifier counterpart,
    but instead of voting on a class, it averages the target values. Hereâ€™s the basic
    process:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘é‚»å›å½’å™¨çš„å·¥ä½œåŸç†ç±»ä¼¼äºå…¶åˆ†ç±»å™¨å¯¹ç­‰ç‰©ï¼Œä½†å®ƒä¸æ˜¯å¯¹ç±»åˆ«è¿›è¡ŒæŠ•ç¥¨ï¼Œè€Œæ˜¯å¯¹ç›®æ ‡å€¼è¿›è¡Œå¹³å‡ã€‚åŸºæœ¬è¿‡ç¨‹å¦‚ä¸‹ï¼š
- en: Calculate the distance between the new data point and all points in the training
    set.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ–°æ•°æ®ç‚¹ä¸è®­ç»ƒé›†ä¸­æ‰€æœ‰ç‚¹ä¹‹é—´çš„è·ç¦»ã€‚
- en: Select the K nearest neighbors based on these distances.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®è¿™äº›è·ç¦»é€‰æ‹©Kä¸ªæœ€è¿‘é‚»å±…ã€‚
- en: Calculate the average of the target values of these K neighbors.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—è¿™äº›Kä¸ªé‚»å±…çš„ç›®æ ‡å€¼çš„å¹³å‡å€¼ã€‚
- en: Assign this average as the predicted value for the new data point.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†è¿™ä¸ªå¹³å‡å€¼ä½œä¸ºæ–°æ•°æ®ç‚¹çš„é¢„æµ‹å€¼ã€‚
- en: '![](../Images/250524333fd9efd70666c9f0c773da69.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/250524333fd9efd70666c9f0c773da69.png)'
- en: The approach above, using all data points to find neighbors, is known as the
    **Brute Force** method. Itâ€™s straightforward but can be slow for large datasets.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°æ–¹æ³•ï¼Œå³ä½¿ç”¨æ‰€æœ‰æ•°æ®ç‚¹æ¥å¯»æ‰¾é‚»å±…ï¼Œç§°ä¸º**æš´åŠ›æœç´¢**æ–¹æ³•ã€‚å®ƒç®€å•ç›´æ¥ï¼Œä½†å¯¹äºå¤§è§„æ¨¡æ•°æ®é›†æ¥è¯´å¯èƒ½æ¯”è¾ƒæ…¢ã€‚
- en: 'Here, weâ€™ll explore two more efficient algorithms for finding nearest neighbors:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸¤ç§æ›´é«˜æ•ˆçš„å¯»æ‰¾æœ€è¿‘é‚»å±…çš„ç®—æ³•ï¼š
- en: '**KD Tree for KNN Regression**'
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**KNNå›å½’çš„KDæ ‘**'
- en: KD Tree (K-Dimensional Tree) is a binary tree structure used for organizing
    points in a *k*-dimensional space. Itâ€™s particularly useful for tasks like nearest
    neighbor searches and range searches in multidimensional data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: KDæ ‘ï¼ˆKç»´æ ‘ï¼‰æ˜¯ä¸€ç§äºŒå‰æ ‘ç»“æ„ï¼Œç”¨äºåœ¨*k*ç»´ç©ºé—´ä¸­ç»„ç»‡ç‚¹ã€‚å®ƒç‰¹åˆ«é€‚ç”¨äºè¯¸å¦‚æœ€è¿‘é‚»æœç´¢å’Œå¤šç»´æ•°æ®èŒƒå›´æœç´¢ç­‰ä»»åŠ¡ã€‚
- en: '**Training Steps:**'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒæ­¥éª¤ï¼š**'
- en: '1\. Build the KD Tree:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 1. æ„å»ºKDæ ‘ï¼š
- en: a. Start with a root node that contains all the points.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: a. ä»åŒ…å«æ‰€æœ‰ç‚¹çš„æ ¹èŠ‚ç‚¹å¼€å§‹ã€‚
- en: '![](../Images/f9eb3bb6d235cd561bf67f214fa3586f.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9eb3bb6d235cd561bf67f214fa3586f.png)'
- en: b. Choose a feature to split on. Any random feature should be ok actually, but
    another good way to choose this is by looking which feature has median value closest
    to the midpoint between max and min value.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: b. é€‰æ‹©ä¸€ä¸ªç‰¹å¾è¿›è¡Œåˆ’åˆ†ã€‚å®é™…ä¸Šï¼Œé€‰æ‹©ä»»ä½•ä¸€ä¸ªéšæœºç‰¹å¾éƒ½å¯ä»¥ï¼Œä½†å¦ä¸€ç§è¾ƒå¥½çš„é€‰æ‹©æ–¹å¼æ˜¯æŸ¥çœ‹å“ªä¸ªç‰¹å¾çš„ä¸­ä½æ•°å€¼æœ€æ¥è¿‘æœ€å¤§å€¼ä¸æœ€å°å€¼ä¹‹é—´çš„ä¸­ç‚¹ã€‚
- en: '![](../Images/79a398331b63176a9e9084603cb200e9.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79a398331b63176a9e9084603cb200e9.png)'
- en: Temperature has the midpoint line closest to the median line. We can start splitting
    from that dimension.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ¸©åº¦å…·æœ‰æœ€æ¥è¿‘ä¸­ä½çº¿çš„ä¸­ç‚¹çº¿ã€‚æˆ‘ä»¬å¯ä»¥ä»è¯¥ç»´åº¦å¼€å§‹è¿›è¡Œæ‹†åˆ†ã€‚
- en: c. Split the tree in the chosen feature and midpoint.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: c. åœ¨é€‰å®šçš„ç‰¹å¾å’Œä¸­ç‚¹å¤„åˆ†å‰²æ ‘ã€‚
- en: '![](../Images/c1a195c9003c18519a00a688f662db95.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1a195c9003c18519a00a688f662db95.png)'
- en: d. Recursively, do step a-c until the stopping criterion, usually minimal leaf
    size (see [â€œmin samples leafâ€ here](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e/))
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: d. é€’å½’åœ°æ‰§è¡Œæ­¥éª¤a-cï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢æ ‡å‡†ï¼Œé€šå¸¸æ˜¯æœ€å°å¶å­èŠ‚ç‚¹å¤§å°ï¼ˆè§[è¿™é‡Œçš„â€œæœ€å°æ ·æœ¬å¶å­â€](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e/)ï¼‰
- en: '![](../Images/cfad5e8688c34aba173a931f66dbd614.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfad5e8688c34aba173a931f66dbd614.png)'
- en: '2\. Store the target values:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. å­˜å‚¨ç›®æ ‡å€¼ï¼š
- en: Along with each point in the KD Tree, store its corresponding target value.
    The minimum and maximum value for each node are also stored.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨KDæ ‘ä¸­çš„æ¯ä¸ªç‚¹æ—è¾¹å­˜å‚¨å…¶å¯¹åº”çš„ç›®æ ‡å€¼ã€‚æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ä¹Ÿè¢«å­˜å‚¨ã€‚
- en: '![](../Images/3cf4c4165760cabc63946fa1328de2c8.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cf4c4165760cabc63946fa1328de2c8.png)'
- en: '**Regression/Prediction Steps:**'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å›å½’/é¢„æµ‹æ­¥éª¤ï¼š**'
- en: '1\. Traverse the KD Tree:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. éå†KDæ ‘ï¼š
- en: a. Start at the root node.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: a. ä»æ ¹èŠ‚ç‚¹å¼€å§‹ã€‚
- en: b. Compare the query point (test point) with the splitting dimension and value
    at each node.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: b. æ¯”è¾ƒæŸ¥è¯¢ç‚¹ï¼ˆæµ‹è¯•ç‚¹ï¼‰ä¸æ¯ä¸ªèŠ‚ç‚¹å¤„çš„åˆ†å‰²ç»´åº¦å’Œå€¼ã€‚
- en: c. Recursively traverse left or right based on this comparison.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: c. æ ¹æ®æ¯”è¾ƒç»“æœé€’å½’åœ°å‘å·¦æˆ–å‘å³éå†ã€‚
- en: d. When reaching a leaf node, add its points to the candidate set.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: d. å½“åˆ°è¾¾å¶å­èŠ‚ç‚¹æ—¶ï¼Œå°†å…¶ç‚¹æ·»åŠ åˆ°å€™é€‰é›†ã€‚
- en: '![](../Images/b6ac7ebb18046966c3e7886af47a307e.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6ac7ebb18046966c3e7886af47a307e.png)'
- en: '2\. Refine the search:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. ç²¾ç»†åŒ–æœç´¢ï¼š
- en: a. Backtrack through the tree, checking if there could be closer points in other
    branches.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: a. å›æº¯æ ‘ç»“æ„ï¼Œæ£€æŸ¥å…¶ä»–åˆ†æ”¯æ˜¯å¦æœ‰æ›´æ¥è¿‘çš„ç‚¹ã€‚
- en: b. Use distance calculations to the maximum and minimum of the unexplored branches
    to determine if exploring is necessary.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: b. ä½¿ç”¨æœªæ¢ç´¢åˆ†æ”¯çš„æœ€å¤§å€¼å’Œæœ€å°å€¼è¿›è¡Œè·ç¦»è®¡ç®—ï¼Œä»¥ç¡®å®šæ˜¯å¦éœ€è¦ç»§ç»­æ¢ç´¢ã€‚
- en: '![](../Images/d7b70deaeed99a10b64698e7be1c231e.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7b70deaeed99a10b64698e7be1c231e.png)'
- en: We backtrack to the branches that has not been visited and check the distance
    to the minimum and maximum of those node.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å›æº¯åˆ°æœªè®¿é—®çš„åˆ†æ”¯ï¼Œå¹¶æ£€æŸ¥é‚£äº›èŠ‚ç‚¹çš„æœ€å°å€¼å’Œæœ€å¤§å€¼çš„è·ç¦»ã€‚
- en: '![](../Images/dfb1b7b1b636bee05aa2c2ce53805785.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dfb1b7b1b636bee05aa2c2ce53805785.png)'
- en: As both the minimum and maximum of those nodes are further than kth distance,
    no need to check the distance to the data points in those nodes.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè¿™äº›èŠ‚ç‚¹çš„æœ€å°å€¼å’Œæœ€å¤§å€¼éƒ½æ¯”ç¬¬kä¸ªè·ç¦»è¿œï¼Œå› æ­¤æ— éœ€æ£€æŸ¥è¿™äº›èŠ‚ç‚¹ä¸­æ•°æ®ç‚¹çš„è·ç¦»ã€‚
- en: '3\. Find K nearest neighbors:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. æŸ¥æ‰¾Kä¸ªæœ€è¿‘é‚»ï¼š
- en: a. Among the candidate points found, select the K points closest to the query
    point.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: a. åœ¨æ‰¾åˆ°çš„å€™é€‰ç‚¹ä¸­ï¼Œé€‰æ‹©ä¸æŸ¥è¯¢ç‚¹æœ€æ¥è¿‘çš„Kä¸ªç‚¹ã€‚
- en: '4\. Perform regression:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. æ‰§è¡Œå›å½’ï¼š
- en: a. Calculate the average of the target values of the K nearest neighbors.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: a. è®¡ç®—Kä¸ªæœ€è¿‘é‚»çš„ç›®æ ‡å€¼çš„å¹³å‡å€¼ã€‚
- en: b. This average is the predicted value for the query point.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: b. è¿™ä¸ªå¹³å‡å€¼å³ä¸ºæŸ¥è¯¢ç‚¹çš„é¢„æµ‹å€¼ã€‚
- en: '![](../Images/73271b1d2aa3434168ed7b3c7b85b162.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73271b1d2aa3434168ed7b3c7b85b162.png)'
- en: By using a KD Tree, the average time complexity for finding nearest neighbors
    can be reduced from *O*(*n*) in the brute force method to *O*(log *n*) in many
    cases, where *n* is the number of points in the dataset. This makes KNN Regression
    much more efficient for large datasets.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä½¿ç”¨KDæ ‘ï¼Œæ‰¾åˆ°æœ€è¿‘é‚»çš„å¹³å‡æ—¶é—´å¤æ‚åº¦å¯ä»¥ä»æš´åŠ›æœç´¢æ³•ä¸­çš„*O*(*n*)å‡å°‘åˆ°åœ¨è®¸å¤šæƒ…å†µä¸‹çš„*O*(log *n*)ï¼Œå…¶ä¸­*n*æ˜¯æ•°æ®é›†ä¸­çš„ç‚¹æ•°ã€‚è¿™ä½¿å¾—KNNå›å½’åœ¨å¤§æ•°æ®é›†ä¸­çš„æ•ˆç‡å¤§å¤§æé«˜ã€‚
- en: '**Ball Tree for KNN Regression**'
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**KNNå›å½’ä¸­çš„çƒæ ‘**'
- en: Ball Tree is another space-partitioning data structure that organizes points
    in a series of nested hyperspheres. Itâ€™s particularly effective for high-dimensional
    data where KD Trees may become less efficient.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: çƒæ ‘æ˜¯å¦ä¸€ç§ç©ºé—´åˆ’åˆ†æ•°æ®ç»“æ„ï¼Œå®ƒé€šè¿‡ä¸€ç³»åˆ—åµŒå¥—çš„è¶…çƒé¢ç»„ç»‡ç‚¹ã€‚åœ¨é«˜ç»´æ•°æ®ä¸­ï¼ŒKDæ ‘å¯èƒ½å˜å¾—ä½æ•ˆï¼Œè€Œçƒæ ‘åœ¨è¿™ç§æƒ…å†µä¸‹å°¤ä¸ºæœ‰æ•ˆã€‚
- en: '**Training Steps:**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒæ­¥éª¤ï¼š**'
- en: '1\. Build the Ball Tree:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. æ„å»ºçƒæ ‘ï¼š
- en: a. Calculate the centroid of all points in the node (the mean). This becomes
    the **pivot point**.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: a. è®¡ç®—èŠ‚ç‚¹ä¸­æ‰€æœ‰ç‚¹çš„é‡å¿ƒï¼ˆå‡å€¼ï¼‰ã€‚è¿™å°†æˆä¸º**æ¢çº½ç‚¹**ã€‚
- en: '![](../Images/f4e68143b7ec7469a2c23cc8f59c3d50.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4e68143b7ec7469a2c23cc8f59c3d50.png)'
- en: 'b. Make the first branch:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: b. æ„å»ºç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼š
- en: '- **Finding the first center:** Choose the furthest point from the pivot point
    as the first center with its distance as the **radius**.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '- **æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸­å¿ƒï¼š** é€‰æ‹©è·ç¦»æ¢çº½ç‚¹æœ€è¿œçš„ç‚¹ä½œä¸ºç¬¬ä¸€ä¸ªä¸­å¿ƒï¼Œå¹¶å°†å…¶è·ç¦»ä½œä¸º**åŠå¾„**ã€‚'
- en: '- **Finding the second center:** From the first center, select the furthest
    point as the second center.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '- **å¯»æ‰¾ç¬¬äºŒä¸ªä¸­å¿ƒï¼š** ä»ç¬¬ä¸€ä¸ªä¸­å¿ƒå‡ºå‘ï¼Œé€‰æ‹©æœ€è¿œçš„ç‚¹ä½œä¸ºç¬¬äºŒä¸ªä¸­å¿ƒã€‚'
- en: '- **Partitioning:** Divide the remaining points into two child nodes based
    on which center they are closer to.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '- **åˆ†åŒºï¼š** æ ¹æ®ç‚¹æ›´æ¥è¿‘å“ªä¸ªä¸­å¿ƒå°†å‰©ä½™çš„ç‚¹åˆ†æˆä¸¤ä¸ªå­èŠ‚ç‚¹ã€‚'
- en: '![](../Images/3f318c1ad3e5909f1299034607cbb9d7.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f318c1ad3e5909f1299034607cbb9d7.png)'
- en: d. Recursively apply steps a-b to each child node until a stopping criterion
    is met, usually minimal leaf size (see [â€œmin samples leafâ€ here](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e/)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: é€’å½’åœ°å¯¹æ¯ä¸ªå­èŠ‚ç‚¹åº”ç”¨æ­¥éª¤a-bï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ ‡å‡†ï¼Œé€šå¸¸æ˜¯æœ€å°å¶å­èŠ‚ç‚¹å¤§å°ï¼ˆè¯·å‚è§[â€œæœ€å°æ ·æœ¬å¶å­â€](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e/)ï¼‰ã€‚
- en: '![](../Images/7a2c7c38531c763643bd4d7f179f03e4.png)![](../Images/466452b8a11ac4c4308f57d663d4c728.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a2c7c38531c763643bd4d7f179f03e4.png)![](../Images/466452b8a11ac4c4308f57d663d4c728.png)'
- en: '2\. Store the target values:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. å­˜å‚¨ç›®æ ‡å€¼ï¼š
- en: Along with each point in the Ball Tree, store its corresponding target value.
    The radius and centroid for each node are also stored.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æ¯ä¸ªBall Treeä¸­çš„ç‚¹ï¼Œå­˜å‚¨å…¶å¯¹åº”çš„ç›®æ ‡å€¼ã€‚æ¯ä¸ªèŠ‚ç‚¹çš„åŠå¾„å’Œè´¨å¿ƒä¹Ÿä¼šè¢«å­˜å‚¨ã€‚
- en: '![](../Images/9883a4e7158dce6fa0413c88d60c6432.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9883a4e7158dce6fa0413c88d60c6432.png)'
- en: '**Regression/Prediction Steps:**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›å½’/é¢„æµ‹æ­¥éª¤ï¼š**'
- en: '1\. Traverse the Ball Tree:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. éå†Ball Treeï¼š
- en: a. Start at the root node.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: a. ä»æ ¹èŠ‚ç‚¹å¼€å§‹ã€‚
- en: b. At each node, calculate the distance between the unseen data and the center
    of each child hypersphere.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: b. åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šï¼Œè®¡ç®—æœªè§æ•°æ®ä¸æ¯ä¸ªå­è¶…çƒä¸­å¿ƒä¹‹é—´çš„è·ç¦»ã€‚
- en: c. Traverse into the closest hypersphere first.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: c. é¦–å…ˆéå†åˆ°æœ€æ¥è¿‘çš„è¶…çƒã€‚
- en: d. When reaching a leaf node, add its points to the candidate set.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: d. å½“åˆ°è¾¾å¶èŠ‚ç‚¹æ—¶ï¼Œå°†å…¶ç‚¹æ·»åŠ åˆ°å€™é€‰é›†ã€‚
- en: '![](../Images/85e4feaae0d4811c3cc6f20839783835.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85e4feaae0d4811c3cc6f20839783835.png)'
- en: '2\. Refine the search:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. ç²¾ç»†åŒ–æœç´¢ï¼š
- en: a. Determine if other branches need to be explored.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: a. ç¡®å®šæ˜¯å¦éœ€è¦æ¢ç´¢å…¶ä»–åˆ†æ”¯ã€‚
- en: b. If the distance to a hypersphere plus its radius is greater than the current
    Kth nearest distance, that branch can be safely ignored.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: b. å¦‚æœåˆ°è¶…çƒçš„è·ç¦»åŠ ä¸Šå…¶åŠå¾„å¤§äºå½“å‰ç¬¬Kä¸ªæœ€è¿‘è·ç¦»ï¼Œåˆ™å¯ä»¥å®‰å…¨å¿½ç•¥è¯¥åˆ†æ”¯ã€‚
- en: '![](../Images/a55da95adf34346e7d47fb4f5f316f47.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a55da95adf34346e7d47fb4f5f316f47.png)'
- en: For those branches that we considered before, add the radius to the distance.
    If it is greater than the kth distance, no need to explore those balls.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¹‹å‰è€ƒè™‘è¿‡çš„åˆ†æ”¯ï¼Œå°†åŠå¾„åŠ åˆ°è·ç¦»ä¸Šã€‚å¦‚æœè¯¥è·ç¦»å¤§äºå½“å‰çš„ç¬¬Kä¸ªè·ç¦»ï¼Œåˆ™æ— éœ€æ¢ç´¢è¿™äº›çƒã€‚
- en: '![](../Images/0b1dfe1b420ff207edb0a413d4f3f131.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b1dfe1b420ff207edb0a413d4f3f131.png)'
- en: '3\. Find K nearest neighbors:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. æŸ¥æ‰¾Kä¸ªæœ€è¿‘é‚»ï¼š
- en: a. Among the candidate points found, select the K points closest to the query
    point.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: a. ä»æ‰¾åˆ°çš„å€™é€‰ç‚¹ä¸­ï¼Œé€‰æ‹©ä¸æŸ¥è¯¢ç‚¹æœ€æ¥è¿‘çš„Kä¸ªç‚¹ã€‚
- en: '4\. Perform regression:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. æ‰§è¡Œå›å½’ï¼š
- en: a. Calculate the average of the target values of the K nearest neighbors.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: a. è®¡ç®—Kä¸ªæœ€è¿‘é‚»çš„ç›®æ ‡å€¼å¹³å‡å€¼ã€‚
- en: b. This average is the predicted value for the query point.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: b. è¿™ä¸ªå¹³å‡å€¼å°±æ˜¯æŸ¥è¯¢ç‚¹çš„é¢„æµ‹å€¼ã€‚
- en: '![](../Images/e2b2f49da2d913d67e259e3e5fa857fb.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2b2f49da2d913d67e259e3e5fa857fb.png)'
- en: Ball Trees can be more efficient than KD Trees for high-dimensional data or
    when the dimensionality is greater than the log of the number of samples. They
    maintain good performance even when the number of dimensions increases, making
    them suitable for a wide range of datasets.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Ball Treeå¯¹äºé«˜ç»´æ•°æ®æˆ–ç»´åº¦å¤§äºæ ·æœ¬æ•°é‡å¯¹æ•°çš„æƒ…å†µæ¯”KD Treeæ›´é«˜æ•ˆã€‚å³ä½¿ç»´åº¦å¢åŠ ï¼Œå®ƒä»¬ä¹Ÿèƒ½ä¿æŒè‰¯å¥½çš„æ€§èƒ½ï¼Œé€‚ç”¨äºå¹¿æ³›çš„æ•°æ®é›†ã€‚
- en: The time complexity for querying in a Ball Tree is O(log *n*) on average, similar
    to KD Trees, but Ball Trees often perform better in higher dimensions where KD
    Trees may degrade to linear time complexity.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Ball Treeä¸­æŸ¥è¯¢çš„æ—¶é—´å¤æ‚åº¦é€šå¸¸æ˜¯O(log *n*)ï¼Œä¸KD Treeç›¸ä¼¼ï¼Œä½†åœ¨é«˜ç»´åº¦ä¸‹ï¼ŒBall Treeé€šå¸¸è¡¨ç°å¾—æ›´å¥½ï¼Œè€ŒKD Treeå¯èƒ½é€€åŒ–ä¸ºçº¿æ€§æ—¶é—´å¤æ‚åº¦ã€‚
- en: Evaluation Step (Brute Force, KD Tree, Ball Tree)
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¯„ä¼°æ­¥éª¤ï¼ˆæš´åŠ›æ³•ã€KDæ ‘ã€Ballæ ‘ï¼‰
- en: 'Regardless of the algorithm we choose, all of them give the same following
    result:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºæˆ‘ä»¬é€‰æ‹©å“ªç§ç®—æ³•ï¼Œå®ƒä»¬éƒ½ä¼šç»™å‡ºç›¸åŒçš„ç»“æœï¼š
- en: '![](../Images/ac80599b3efec37df8746639217d7aea.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac80599b3efec37df8746639217d7aea.png)'
- en: Compared to [the result of the dummy regressor,](https://medium.com/towards-data-science/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629)
    there is a major improvement for the value of RMSE.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸[è™šæ‹Ÿå›å½’å™¨çš„ç»“æœ](https://medium.com/towards-data-science/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629)ç›¸æ¯”ï¼ŒRMSEå€¼æœ‰äº†æ˜¾è‘—æ”¹å–„ã€‚
- en: Which Algorithm to Choose?
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é€‰æ‹©å“ªç§ç®—æ³•ï¼Ÿ
- en: 'You can follow this simple rule for choosing the best one:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥éµå¾ªè¿™ä¸ªç®€å•çš„è§„åˆ™æ¥é€‰æ‹©æœ€ä¼˜çš„ç®—æ³•ï¼š
- en: '- For small datasets (< 1000 samples), â€˜bruteâ€™ might be fast enough and guarantees
    finding the exact nearest neighbors.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '- å¯¹äºå°å‹æ•°æ®é›†ï¼ˆ< 1000æ ·æœ¬ï¼‰ï¼Œâ€˜bruteâ€™å¯èƒ½è¶³å¤Ÿå¿«ï¼Œå¹¶ä¿è¯æ‰¾åˆ°ç²¾ç¡®çš„æœ€è¿‘é‚»ã€‚'
- en: '- For larger datasets with few features (< 20), â€˜kd_treeâ€™ is usually the fastest.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '- å¯¹äºç‰¹å¾è¾ƒå°‘çš„å¤§å‹æ•°æ®é›†ï¼ˆ< 20ï¼‰ï¼Œâ€˜kd_treeâ€™é€šå¸¸æ˜¯æœ€å¿«çš„ã€‚'
- en: '- For larger datasets with many features, â€˜ball_treeâ€™ often performs best.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '- å¯¹äºå…·æœ‰è®¸å¤šç‰¹å¾çš„å¤§å‹æ•°æ®é›†ï¼Œâ€˜ball_treeâ€™é€šå¸¸è¡¨ç°æœ€ä½³ã€‚'
- en: 'The â€˜autoâ€™ option in scikit-learn typically follow the following chart:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learnä¸­çš„â€˜autoâ€™é€‰é¡¹é€šå¸¸éµå¾ªä»¥ä¸‹å›¾è¡¨ï¼š
- en: '![](../Images/cdea807e4c32673c58a2daa66594870a.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cdea807e4c32673c58a2daa66594870a.png)'
- en: Key Parameters
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…³é”®å‚æ•°
- en: While KNN regression has many other parameter, other than the algorithm we just
    discussed (brute force, kd tree, ball tree), you mainly need to consider
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶KNNå›å½’æœ‰è®¸å¤šå…¶ä»–å‚æ•°ï¼Œé™¤äº†æˆ‘ä»¬åˆšåˆšè®¨è®ºçš„ç®—æ³•ï¼ˆæš´åŠ›æ³•ã€kdæ ‘ã€ballæ ‘ï¼‰ï¼Œä½†ä½ ä¸»è¦éœ€è¦è€ƒè™‘çš„æ˜¯
- en: '**Number of Neighbors (K).**'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é‚»å±…æ•°ï¼ˆKï¼‰**'
- en: '- Smaller K: More sensitive to local patterns, but may lead to overfitting.'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- è¾ƒå°çš„Kï¼šå¯¹å±€éƒ¨æ¨¡å¼æ›´æ•æ„Ÿï¼Œä½†å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚'
- en: '- Larger K: Smoother predictions, but might miss important local variations.'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- è¾ƒå¤§çš„Kï¼šå¹³æ»‘çš„é¢„æµ‹ï¼Œä½†å¯èƒ½é”™è¿‡é‡è¦çš„å±€éƒ¨å˜åŒ–ã€‚'
- en: Unlike classification, **even numbers are fine** in regression as weâ€™re averaging
    values.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸åˆ†ç±»ä¸åŒï¼Œ**å›å½’ä¸­å¶æ•°ä¹Ÿå¯ä»¥**ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯åœ¨å¯¹å€¼è¿›è¡Œå¹³å‡ã€‚
- en: '**Leaf Size**'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¶èŠ‚ç‚¹å¤§å°**'
- en: This is the stopping condition for building kd tree or ball tree. Generally,
    It affects the speed of construction and query, as well as the memory required
    to store the tree.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ„å»ºkdæ ‘æˆ–ballæ ‘çš„åœæ­¢æ¡ä»¶ã€‚é€šå¸¸ï¼Œå®ƒä¼šå½±å“æ„å»ºå’ŒæŸ¥è¯¢çš„é€Ÿåº¦ï¼Œä»¥åŠå­˜å‚¨æ ‘æ‰€éœ€çš„å†…å­˜ã€‚
- en: Pros & Cons
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¼˜ç¼ºç‚¹
- en: 'Pros:'
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ï¼š
- en: '**Simplicity and Versatility**: Easy to understand and implement; can be used
    for both classification and regression tasks.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç®€æ´æ€§å’Œå¤šåŠŸèƒ½æ€§**ï¼šæ˜“äºç†è§£å’Œå®ç°ï¼›å¯ä»¥ç”¨äºåˆ†ç±»å’Œå›å½’ä»»åŠ¡ã€‚'
- en: '**No Assumptions**: Doesnâ€™t assume anything about the data distribution, making
    it suitable for complex datasets.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ— å‡è®¾**ï¼šä¸å¯¹æ•°æ®åˆ†å¸ƒåšä»»ä½•å‡è®¾ï¼Œä½¿å…¶é€‚ç”¨äºå¤æ‚æ•°æ®é›†ã€‚'
- en: '**No Training Phase**: Can quickly incorporate new data without retraining.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ— è®­ç»ƒé˜¶æ®µ**ï¼šå¯ä»¥å¿«é€Ÿçº³å…¥æ–°æ•°æ®ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚'
- en: '**Interpretability**: Predictions can be explained by examining nearest neighbors.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¯è§£é‡Šæ€§**ï¼šé€šè¿‡æ£€æŸ¥æœ€è¿‘é‚»ï¼Œå¯ä»¥è§£é‡Šé¢„æµ‹ç»“æœã€‚'
- en: '**Cons:**'
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¼ºç‚¹ï¼š**'
- en: '**Computational Complexity**: Prediction time can be slow, especially with
    large datasets, though optimized algorithms (KD-Tree, Ball Tree) can help for
    lower dimensions.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®¡ç®—å¤æ‚åº¦**ï¼šé¢„æµ‹æ—¶é—´å¯èƒ½è¾ƒæ…¢ï¼Œå°¤å…¶æ˜¯å¯¹äºå¤§æ•°æ®é›†ï¼Œå°½ç®¡ä¼˜åŒ–ç®—æ³•ï¼ˆKD-Treeã€Ball Treeï¼‰åœ¨ä½ç»´æƒ…å†µä¸‹èƒ½æœ‰æ‰€å¸®åŠ©ã€‚'
- en: '**Curse of Dimensionality**: Performance degrades in high-dimensional spaces,
    affecting both accuracy and efficiency.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç»´åº¦ç¾éš¾**ï¼šåœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæ€§èƒ½ä¼šä¸‹é™ï¼Œå½±å“å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚'
- en: '**Memory Intensive**: Requires storing all training data.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å†…å­˜å¯†é›†å‹**ï¼šéœ€è¦å­˜å‚¨æ‰€æœ‰è®­ç»ƒæ•°æ®ã€‚'
- en: '**Sensitive to Feature Scaling and Irrelevant Features**: Can be biased by
    features on larger scales or those unimportant to the prediction.'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¯¹ç‰¹å¾ç¼©æ”¾å’Œæ— å…³ç‰¹å¾æ•æ„Ÿ**ï¼šå¯èƒ½ä¼šå—åˆ°è¾ƒå¤§å°ºåº¦ç‰¹å¾æˆ–å¯¹é¢„æµ‹æ— å…³ç‰¹å¾çš„åå€šã€‚'
- en: Final Remarks
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ€ç»ˆå¤‡æ³¨
- en: The K-Nearest Neighbors (KNN) regressor is a basic yet powerful tool in machine
    learning. Its straightforward approach makes it great for beginners, and its flexibility
    ensures itâ€™s useful for experts too.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Kæœ€è¿‘é‚»ï¼ˆKNNï¼‰å›å½’å™¨æ˜¯æœºå™¨å­¦ä¹ ä¸­ä¸€ä¸ªåŸºæœ¬è€Œå¼ºå¤§çš„å·¥å…·ã€‚å®ƒç®€å•ç›´è§‚ï¼Œéå¸¸é€‚åˆåˆå­¦è€…ï¼Œè€Œä¸”å…¶çµæ´»æ€§ç¡®ä¿å®ƒå¯¹ä¸“å®¶åŒæ ·æœ‰ç”¨ã€‚
- en: As you learn more about data analysis, use KNN to understand the basics of regression
    before exploring more advanced methods. By mastering KNN and how to compute the
    nearest neighbors, youâ€™ll build a strong foundation for tackling more complex
    challenges in data analysis.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ä½ å¯¹æ•°æ®åˆ†æçš„äº†è§£é€æ¸æ·±å…¥ï¼Œå¯ä»¥ä½¿ç”¨KNNæ¥ç†è§£å›å½’çš„åŸºç¡€çŸ¥è¯†ï¼Œç„¶åå†æ¢ç´¢æ›´é«˜çº§çš„æ–¹æ³•ã€‚é€šè¿‡æŒæ¡KNNå’Œå¦‚ä½•è®¡ç®—æœ€è¿‘é‚»ï¼Œä½ å°†ä¸ºå¤„ç†æ›´å¤æ‚çš„æ•°æ®åˆ†ææŒ‘æˆ˜æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚
- en: ğŸŒŸ k Nearest Neighbor Regressor Code Summarized
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŒŸ Kæœ€è¿‘é‚»å›å½’å™¨ä»£ç æ¦‚è¿°
- en: '[PRE1]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Further Reading
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥é˜…è¯»
- en: For a detailed explanation of the [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html),
    [KDTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html),
    [BallTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html),
    and its implementation in scikit-learn, readers can refer to their official documentation.
    It provides comprehensive information on their usage and parameters.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³[KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)ã€[KDTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html)ã€[BallTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html)åŠå…¶åœ¨scikit-learnä¸­çš„å®ç°çš„è¯¦ç»†è¯´æ˜ï¼Œè¯»è€…å¯ä»¥å‚è€ƒå…¶å®˜æ–¹æ–‡æ¡£ã€‚å®ƒæä¾›äº†å…³äºè¿™äº›å·¥å…·çš„ä½¿ç”¨åŠå‚æ•°çš„å…¨é¢ä¿¡æ¯ã€‚
- en: Technical Environment
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æŠ€æœ¯ç¯å¢ƒ
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä½¿ç”¨çš„æ˜¯Python 3.7å’Œscikit-learn 1.5ç‰ˆæœ¬ã€‚è™½ç„¶è®¨è®ºçš„æ¦‚å¿µæ™®éé€‚ç”¨ï¼Œä½†ä¸åŒç‰ˆæœ¬ä¹‹é—´çš„å…·ä½“ä»£ç å®ç°å¯èƒ½ä¼šç•¥æœ‰ä¸åŒã€‚
- en: About the Illustrations
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºæ’å›¾
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…åˆ›å»ºï¼Œå¹¶èåˆäº†æ¥è‡ªCanva Proçš„æˆæƒè®¾è®¡å…ƒç´ ã€‚
- en: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ™ğ™šğ™œğ™§ğ™šğ™¨ğ™¨ğ™ğ™¤ğ™£ ğ˜¼ğ™¡ğ™œğ™¤ğ™§ğ™ğ™©ğ™ğ™¢ğ™¨ ğ™ğ™šğ™§ğ™š:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ™ğ™šğ™œğ™§ğ™šğ™¨ğ™¨ğ™ğ™¤ğ™£ ğ˜¼ğ™¡ğ™œğ™¤ğ™§ğ™ğ™©ğ™ğ™¢ğ™¨ ğ™ğ™šğ™§ğ™š:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----df5052c8c889--------------------------------)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----df5052c8c889--------------------------------)'
- en: Regression Algorithms
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å›å½’ç®—æ³•
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----df5052c8c889--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This â€œdummyâ€ doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----df5052c8c889--------------------------------)5ç¯‡æ•…äº‹![ä¸€åªæ‰ç€è¾«å­æˆ´ç€ç²‰çº¢è‰²å¸½å­çš„å¡é€šå¨ƒå¨ƒã€‚è¿™ä¸ªâ€œå‡äººâ€å¨ƒå¨ƒï¼Œå‡­å€Ÿå…¶åŸºæœ¬è®¾è®¡å’Œå¿ƒå½¢è£…é¥°çš„è¡¬è¡«ï¼Œå½¢è±¡åœ°å±•ç¤ºäº†æœºå™¨å­¦ä¹ ä¸­çš„å‡å›å½’å™¨æ¦‚å¿µã€‚å°±åƒè¿™ä¸ªç©å…·èˆ¬çš„å½¢è±¡æ˜¯ä¸€ä¸ªç®€åŒ–çš„ã€é™æ€çš„äººç‰©è¡¨è¾¾ä¸€æ ·ï¼Œå‡å›å½’å™¨ä¹Ÿæ˜¯ä¸€ä¸ªåŸºæœ¬æ¨¡å‹ï¼Œç”¨ä½œæ›´å¤æ‚åˆ†æçš„åŸºå‡†ã€‚](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
- en: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----df5052c8c889--------------------------------)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----df5052c8c889--------------------------------)'
- en: Classification Algorithms
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ†ç±»ç®—æ³•
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----df5052c8c889--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----df5052c8c889--------------------------------)8ç¯‡æ•…äº‹![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
