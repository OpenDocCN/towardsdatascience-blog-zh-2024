<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Explaining OpenAI Sora’s Spacetime Patches: The Key Ingredient</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Explaining OpenAI Sora’s Spacetime Patches: The Key Ingredient</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b?source=collection_archive---------0-----------------------#2024-02-16">https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b?source=collection_archive---------0-----------------------#2024-02-16</a></blockquote><div><div class="em ff fg fh fi fj"/><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><div/><div><h2 id="83be" class="pw-subtitle-paragraph go fq fr bf b gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd cq dx">Under The Hood Of The Generative AI For Video By OpenAI</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vincentkoc?source=post_page---byline--e14e0703ec5b--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Vincent Koc" class="l ep by dd de cx" src="../Images/6cbe2dab3c452384057fbdb7a16506be.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*oJyChdfazLrlPdWjbg0GUQ.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e14e0703ec5b--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@vincentkoc?source=post_page---byline--e14e0703ec5b--------------------------------" rel="noopener follow">Vincent Koc</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e14e0703ec5b--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 16, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk ld le ab q ee lf lg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lb lc">5</span></p></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lh k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al li an ao ap ie lj lk ll" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lm cn"><div class="l ae"><div class="ab cb"><div class="ln lo lp lq lr ls ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml mm"><img src="../Images/696e47de6e132862f8813fed2c0d613c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OJUmmet0I_Y6VMCGNRQiqw.png"/></div></div></figure><p id="d84c" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">How can AI transform a static image into a dynamic, realistic video? OpenAI’s Sora introduces an answer through the innovative use of spacetime patches.</p><p id="1523" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">In the rapidly evolving landscape of generative models, <a class="af nu" href="https://openai.com/sora" rel="noopener ugc nofollow" target="_blank">OpenAI’s Sora</a> stands out as a significant milestone, promising to reshape our understanding and capabilities in video generation. We unpack the <a class="af nu" href="https://openai.com/research/video-generation-models-as-world-simulators" rel="noopener ugc nofollow" target="_blank">technology behind Sora</a> and its potential to inspire a new generation of models in image, video, and 3D content creation.</p><figure class="mn mo mp mq mr ms"><div class="nv ip l ed"><div class="nw nx l"/></div><figcaption class="ny nz oa mk ml ob oc bf b bg z dx">OpenAI Sosa Demo — Cat on Bed. Credit: OpenAI</figcaption></figure><p id="a1f7" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">The demo above was generated by OpenAI using the prompt: <em class="od">A cat waking up its sleeping owner demanding breakfast. The owner tries to ignore the cat, but the cat tries new tactics and finally the owner pulls out a secret stash of treats from under the pillow to hold the cat off a little longer. — </em>With Sora we verge onto near indistinguishable realism with video content generation. The full model is yet to be fully released to the public as its undergoing testing.</p></div></div></div><div class="ab cb oe of og oh" role="separator"><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="de4c" class="om on fr bf oo op oq gr or os ot gu ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk">How Sora’s Unique Approach Transforms Video Generation</h1><p id="91ba" class="pw-post-body-paragraph my mz fr na b gp pi nc nd gs pj nf ng nh pk nj nk nl pl nn no np pm nr ns nt fk bk">In the world of generative models we have seen a number of approaches from GAN’s to auto-regressive, and diffusion models, all with their own strengths and limitations. Sora now introduces a paradigm shift with a new modelling techniques and flexibility to handle a broad range of duration's, aspect ratios, and resolutions.</p><p id="0e86" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">Sora combines both diffusion and transformer architectures together to create a diffusion transformer model and is able to provide features such as:</p><ul class=""><li id="e285" class="my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt pn po pp bk"><strong class="na fs">Text-to-video</strong>: <em class="od">As we have seen</em></li><li id="2a84" class="my mz fr na b gp pq nc nd gs pr nf ng nh ps nj nk nl pt nn no np pu nr ns nt pn po pp bk"><strong class="na fs">Image-to-video: </strong>Bringing life to still images</li><li id="5584" class="my mz fr na b gp pq nc nd gs pr nf ng nh ps nj nk nl pt nn no np pu nr ns nt pn po pp bk"><strong class="na fs">Video-to-video: </strong>Changing the style of video to something else</li><li id="8d7a" class="my mz fr na b gp pq nc nd gs pr nf ng nh ps nj nk nl pt nn no np pu nr ns nt pn po pp bk"><strong class="na fs">Extending video in time:</strong> Forwards and backwards</li><li id="2a7d" class="my mz fr na b gp pq nc nd gs pr nf ng nh ps nj nk nl pt nn no np pu nr ns nt pn po pp bk"><strong class="na fs">Create seamless loops: </strong>Tiled videos that seem like they never end</li><li id="5fa8" class="my mz fr na b gp pq nc nd gs pr nf ng nh ps nj nk nl pt nn no np pu nr ns nt pn po pp bk"><strong class="na fs">Image generation: </strong>Still image is a movie of one frame (<em class="od">up to 2048 x 2048</em>)</li><li id="80d8" class="my mz fr na b gp pq nc nd gs pr nf ng nh ps nj nk nl pt nn no np pu nr ns nt pn po pp bk"><strong class="na fs">Generate video in any format: </strong>From 1920 x 1080 to 1080 x 1920 and everything in between</li><li id="507f" class="my mz fr na b gp pq nc nd gs pr nf ng nh ps nj nk nl pt nn no np pu nr ns nt pn po pp bk"><strong class="na fs">Simulate virtual worlds:</strong> Like Minecraft and other video games</li><li id="c982" class="my mz fr na b gp pq nc nd gs pr nf ng nh ps nj nk nl pt nn no np pu nr ns nt pn po pp bk"><strong class="na fs">Create a video: </strong>Up to 1 minute in length with multiple shorts</li></ul><p id="03fc" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">Imagine for one moment you’re in a kitchen. The traditional video generation models like those from <a class="af nu" href="https://pika.art/home" rel="noopener ugc nofollow" target="_blank">Pika</a> and <a class="af nu" href="https://runwayml.com/ai-tools/gen-2/" rel="noopener ugc nofollow" target="_blank">RunwayML</a> a like the cooks that follow recipes to the letter. They can produce excellent dishes (<em class="od">videos</em>) but are limited by the recipes (<em class="od">algorithms</em>) they know. The cooks might specialize in baking cakes (<em class="od">short clips</em>) or cooking pasta (<em class="od">specific types of videos</em>), using specific ingredients (<em class="od">data formats</em>) and techniques (<em class="od">model architectures</em>).</p><p id="0a08" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">Sora, on the other hand, is a new kind of chef who understand the fundamentals of flavor. This chef doesn’t just follow recipes; they invent new ones. The flexibility of Sora’s ingredients (<em class="od">data</em>) and techniques (<em class="od">model architecture</em>) is what allow Sora to produce a wide range of high-quality videos, akin to a master chef’s versatile culinary creations.</p></div></div></div><div class="ab cb oe of og oh" role="separator"><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="b6a5" class="om on fr bf oo op oq gr or os ot gu ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk">The Core of Sora’s Secret Ingredient: Exploring the Spacetime Patches</h1><p id="6160" class="pw-post-body-paragraph my mz fr na b gp pi nc nd gs pj nf ng nh pk nj nk nl pl nn no np pm nr ns nt fk bk">Spacetime patches are at the heart of Sora’s innovation, built on the earlier research from <a class="af nu" href="https://arxiv.org/abs/2307.06304" rel="noopener ugc nofollow" target="_blank">Google DeepMind on NaViT</a> and ViT (<em class="od">Vision Transformers</em>) based on the 2021 paper <a class="af nu" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank">An Image is Worth 16x16 Words</a>.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pv"><img src="../Images/86a56bfe41bcfd43b7545eb7a2c02f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FVJYaaIR7YyXoWl1GtCmDw.png"/></div></div><figcaption class="ny nz oa mk ml ob oc bf b bg z dx"><em class="pw">“Vanilla”</em> Vision Transformer Architecture — Credit <a class="af nu" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank">Dosovitskiy et al., 2021</a></figcaption></figure><p id="5d8e" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">Traditionally with Vision Transformers we use a sequence of images “patches” to train a transformer model for image recognition instead of words for language transformers. The patches allow us to move away from convolutional neural networks for image processing.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml px"><img src="../Images/908472615a28faa5775319f399da1d0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9KnKr--AxBIgV52Omnq_2w.png"/></div></div><figcaption class="ny nz oa mk ml ob oc bf b bg z dx">How frames/images are “patch-ified” — Credit <a class="af nu" href="https://arxiv.org/abs/2307.06304" rel="noopener ugc nofollow" target="_blank">Dehghani et al., 2023</a></figcaption></figure><p id="8b4d" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">However with vision transformers were constraint on image training data that was fixed in size and aspect ratio which limited the quality and required vast amounts of preprocessing of images.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml py"><img src="../Images/23af45258db5008a735e3d941c624e9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*P5-Gm0KaYA9Moia7MzlnLg.gif"/></div></div><figcaption class="ny nz oa mk ml ob oc bf b bg z dx">Visualization of Slicing Video Temporal Data — Source: <a class="af nu" href="https://twitter.com/kitasenjudesign/status/1489260985135157258" rel="noopener ugc nofollow" target="_blank">kitasenjudesign</a></figcaption></figure><p id="4cd4" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">By treating videos as sequences of patches, Sora maintains the original aspect ratios and resolutions, similar to NaViT’s handling of images. <strong class="na fs">This preservation is crucial for capturing the true essence of the visual data, enabling the model to learn from a more accurate representation of the world and thus giving Sora its near magical accuracy.</strong></p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pz"><img src="../Images/d6dcaefaeaae1752d3da13a123191004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QJ4eCG920fpYQoL3w_B7xA.png"/></div></div><figcaption class="ny nz oa mk ml ob oc bf b bg z dx">Visualization of Spacetime Patching (Processing) — Credit: OpenAI (Sora)</figcaption></figure><p id="5ecd" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">The method allows Sora to efficiently process a diverse array of visual data without the need for pre-processing steps like resizing or padding. This flexibility ensures that every piece of data contributes to the model’s understanding, much like how a chef uses a variety of ingredients to enhance a dish’s flavor profile.</p><p id="78ae" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">The detailed and flexible handling of video data through spacetime patches lays the groundwork for sophisticated features such as accurate physics simulation and 3D consistency. These capabilities are essential for creating videos that not only look realistic but also adhere to the physical rules of the world, offering a glimpse into the potential for AI to create complex, dynamic visual content.</p></div></div></div><div class="ab cb oe of og oh" role="separator"><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="fc71" class="om on fr bf oo op oq gr or os ot gu ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk">Feeding Sora: The Role of Diverse Data in Training</h1><p id="35ca" class="pw-post-body-paragraph my mz fr na b gp pi nc nd gs pj nf ng nh pk nj nk nl pl nn no np pm nr ns nt fk bk">The quality and diversity of training data are crucial for the performance of generative models. Existing video models were traditionally trained on a more restrictive set of data, shorter lengths and narrow target.</p><p id="7928" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">Sora leverages a vast and varied dataset, including videos and images of different durations, resolutions, and aspect ratios. <a class="af nu" href="https://techcrunch.com/2024/02/15/openais-sora-video-generating-model-can-render-video-games-too/" rel="noopener ugc nofollow" target="_blank">It’s ability to re-create digital worlds like Minecraft</a>, its likely also included gameplay and simulated world footage from systems such as Unreal or Unity in its training set in order to capture all the angles and various styles of video content. This brings Sora to a “generalist” model just like GPT-4 for text.</p><p id="cb14" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">This extensive training enables Sora to understand complex dynamics and generate content that is both diverse and high in quality. The approach mimics the way large language models are trained on diverse text data, applying a similar philosophy to visual content to achieve generalist capabilities.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qa"><img src="../Images/e151e5585f1180958834629a5986a95f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U1DMalQ43Nd42N11gjOviA.png"/></div></div><figcaption class="ny nz oa mk ml ob oc bf b bg z dx">Variable “Patches” NaVit vs. Traditional Vision Transformers — Credit <a class="af nu" href="https://arxiv.org/abs/2307.06304" rel="noopener ugc nofollow" target="_blank">Dehghani et al., 2023</a></figcaption></figure><p id="983f" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">Just as the NaViT model demonstrates significant training efficiency and performance gains by packing multiple patches from different images into single sequences, Sora leverages spacetime patches to achieve similar efficiencies in video generation. This approach allows for more effective learning from a vast dataset, improving the model’s ability to generate high-fidelity videos yet lowering the compute required versus existing modeling architectures.</p><h1 id="ce70" class="om on fr bf oo op qb gr or os qc gu ou ov qd ox oy oz qe pb pc pd qf pf pg ph bk">Bringing the Physical World to Life: Sora’s Mastery over 3D and Continuity</h1><p id="f62b" class="pw-post-body-paragraph my mz fr na b gp pi nc nd gs pj nf ng nh pk nj nk nl pl nn no np pm nr ns nt fk bk">3D space and object permanence is one of the key standouts in the demo’s by Sora. Through its training on a wide range of video data without adapting or preprocessing the videos, Sora learns to model the physical world with impressive accuracy as its able to consume the training data in its original form.</p><p id="ba64" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">It can generate digital worlds and videos where objects and characters move and interact in three-dimensional space convincingly, maintaining coherence even when they are occluded or leave the frame.</p></div></div></div><div class="ab cb oe of og oh" role="separator"><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="b846" class="om on fr bf oo op oq gr or os ot gu ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk"><strong class="al">Looking Ahead: The Future Implications of Sora</strong></h1><p id="727f" class="pw-post-body-paragraph my mz fr na b gp pi nc nd gs pj nf ng nh pk nj nk nl pl nn no np pm nr ns nt fk bk">Sora sets a new standard for what’s possible in generative models. This approach, much is likely to inspire the open-source community to experiment with and advance the capabilities in visual modalities, fueling a new generation of generative models that push the boundaries of creativity and realism.</p><blockquote class="qg qh qi"><p id="6db8" class="my mz od na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">The journey of Sora is just beginning, and as OpenAI put’s it “scaling video generation models is a promising path towards building general purpose simulators of the physical world”</p></blockquote><p id="276e" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk">Sora’s approach, blending the latest in AI research with practical applications, signals a bright future for generative models. As these technologies continue to evolve, they promise to redefine our interactions with digital content, making the creation of high-fidelity, dynamic videos more accessible and versatile.</p></div></div></div><div class="ab cb oe of og oh" role="separator"><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok ol"/><span class="oi by bm oj ok"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h2 id="2199" class="qj on fr bf oo qk ql qm or qn qo qp ou nh qq qr qs nl qt qu qv np qw qx qy qz bk">Enjoyed This Story?</h2><p id="0c3c" class="pw-post-body-paragraph my mz fr na b gp pi nc nd gs pj nf ng nh pk nj nk nl pl nn no np pm nr ns nt fk bk">Vincent Koc is a highly accomplished, commercially-focused technologist and futurist with a wealth of experience focused in data-driven and digital disciplines.</p><p id="1da3" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk"><a class="af nu" href="https://medium.com/subscribe/@vkoc" rel="noopener">Subscribe for free</a> to get notified when Vincent publishes a new story. Or follow him on <a class="af nu" href="https://www.linkedin.com/in/koconder/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> and <a class="af nu" href="https://twitter.com/koconder" rel="noopener ugc nofollow" target="_blank">X</a>.</p><div class="ra rb rc rd re rf"><a href="https://medium.com/subscribe/@vkoc?source=post_page-----e14e0703ec5b--------------------------------" rel="noopener follow" target="_blank"><div class="rg ab ih"><div class="rh ab co cb ri rj"><h2 class="bf fs hx z ip rk ir is rl iu iw fq bk">Get an email whenever Vincent Koc publishes.</h2><div class="rm l"><h3 class="bf b hx z ip rk ir is rl iu iw dx">Get an email whenever Vincent Koc publishes. By signing up, you will create a Medium account if you don't already have…</h3></div><div class="rn l"><p class="bf b dy z ip rk ir is rl iu iw dx">medium.com</p></div></div><div class="ro l"><div class="rp l rq rr rs ro rt ls rf"/></div></div></a></div><p id="51e8" class="pw-post-body-paragraph my mz fr na b gp nb nc nd gs ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fk bk"><em class="od">Unless otherwise noted, all images are by the author</em></p></div></div></div></div>    
</body>
</html>