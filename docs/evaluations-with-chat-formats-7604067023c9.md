# ä½¿ç”¨èŠå¤©æ ¼å¼çš„è¯„ä¼°

> åŸæ–‡ï¼š[`towardsdatascience.com/evaluations-with-chat-formats-7604067023c9?source=collection_archive---------6-----------------------#2024-02-21`](https://towardsdatascience.com/evaluations-with-chat-formats-7604067023c9?source=collection_archive---------6-----------------------#2024-02-21)

## å°†èŠå¤©æ¨¡æ¿åº”ç”¨äºç”Ÿæˆå¼è¯­è¨€æ¨¡å‹çš„è¯„ä¼°æµ‹è¯•

[](https://medium.com/@daniel_furman?source=post_page---byline--7604067023c9--------------------------------)![Daniel Furman](https://medium.com/@daniel_furman?source=post_page---byline--7604067023c9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7604067023c9--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7604067023c9--------------------------------) [Daniel Furman](https://medium.com/@daniel_furman?source=post_page---byline--7604067023c9--------------------------------)

Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7604067023c9--------------------------------) Â·7 åˆ†é’Ÿé˜…è¯»Â·2024 å¹´ 2 æœˆ 21 æ—¥

--

![](img/a8e714bc5984165c0816edc5f138bd2f.png)

å›¾ç‰‡ç”± [Google DeepMind](https://unsplash.com/@googledeepmind) æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/photos/a-close-up-of-a-metal-structure-made-of-wood-and-metal-pyET8SQTc0A)

> â€œ**æ„å»ºæ‰å®çš„è¯„ä¼°åº”è¯¥æ˜¯ä»»ä½•åŸºäº LLM çš„ç³»ç»Ÿæˆ–äº§å“çš„èµ·ç‚¹**ï¼ˆä»¥åŠä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼‰ã€‚â€ â€” Eugene Yan, [é“¾æ¥](https://eugeneyan.com/writing/llm-patterns/#how-to-apply-evals)

# **ç®€è¦æ€»ç»“**

èŠå¤©æ¨¡å‹é€šå¸¸åœ¨ä½¿ç”¨æç¤ºæ¨¡æ¿æ ¼å¼çš„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒã€‚è¿™äº›èŠå¤©æ¨¡æ¿æ˜¯ç¼–ç¨‹å¥½çš„â€œé£Ÿè°±â€ï¼Œèƒ½å¤Ÿå°†ä¸€æ¬¡èŠå¤©å¯¹è¯è½¬åŒ–ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²ã€‚åœ¨é¢„æµ‹æ—¶ï¼Œé€šå¸¸éœ€è¦åŒ¹é…å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœŸæœ›çš„èŠå¤©æ ¼å¼â€”â€”å¦‚æœä¸è¿™ä¹ˆåšï¼Œé€šå¸¸ä¼šè¢«æŒ‡å‡ºä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ [1]ã€‚ä½†æ˜¯ï¼Œå®é™…ä¸Šæˆ‘ä»¬æ˜¯å¦åœ¨è¯„ä¼°åŸºå‡†ä¸Šçœ‹åˆ°äº†è¿™äº›æ€§èƒ½ä¸‹é™ï¼Ÿ

**æ³¨æ„**ï¼šæœ¬åšå®¢é€‚åˆå…·æœ‰ Python ç¼–ç¨‹å’Œç¥ç»è¯­è¨€å»ºæ¨¡åŸºç¡€çŸ¥è¯†çš„è¯»è€…ã€‚

# ä»‹ç»

å¦‚æœä½ å·²ç»åœ¨ OpenAI çš„èŠå¤© API ä¸Šæ„å»ºè¿‡åº”ç”¨ï¼Œä¸‹é¢çš„ä»£ç å°†æ˜¯ä½ ç†Ÿæ‚‰çš„ã€‚åº•å±‚ï¼Œè¿™äº›è¾“å…¥ä¼šé€šè¿‡ [ChatML](https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/ai-services/openai/includes/chat-markup-language.md#working-with-chat-markup-language-chatml) æ ¼å¼è½¬æ¢æˆä¸€ä¸ªå¯åˆ†è¯çš„å­—ç¬¦ä¸²ï¼š

```py
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Who won the world series in 2020?"},
    {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
    {"role": "user", "content": "Where was it played?"}
  ]
)
```

```py
"<|im_start|>system
You are a helpful assistant.
<|im_start|>user
Who won the world series in 2020?<|im_end|>
<|im_start|>assistant
The Los Angeles Dodgers won the World Series in 2020.<|im_end|>
<|im_start|>user
Where was it played?<|im_end|>
<|im_start|>assistant"
```

äº‹å®è¯æ˜ï¼ŒLLM ç ”ç©¶ç¤¾åŒºä¸­æœ‰å„ç§å„æ ·çš„èŠå¤©æ¨¡æ¿ã€‚ä»¥å¼€æºæ¨¡å‹ `Mixtral-8x7B-Instruct-v0.1`*.* ä¸ºä¾‹ï¼Œå®ƒçš„æ ¼å¼ä¸ä¸Šé¢æåˆ°çš„ `gpt-3.5-turbo` çœ‹èµ·æ¥æˆªç„¶ä¸åŒï¼š

```py
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mixtral-8x7B-Instruct-v0.1")
chat = [
  {"role": "user", "content": "Hello, how are you?"},
  {"role": "assistant", "content": "I'm doing great. How can I help you today?"},
  {"role": "user", "content": "Write me a haiku about coding."},
]
tokenizer.apply_chat_template(chat, tokenize=False)
```

```py
"<s>[INST] Hello, how are you? [/INST]I'm doing great. How can I help you today?</s> [INST] Write me a haiku about coding. [/INST]"
```

ä¸ºä»€ä¹ˆè¦ä½¿ç”¨èŠå¤©æ¨¡æ¿å‘¢ï¼Ÿå…¶å®ï¼Œå¼ºçƒˆå»ºè®®åœ¨é¢„æµ‹æ—¶åŒ¹é…æœŸæœ›çš„èŠå¤©æ¨¡æ¿ï¼ˆä¾‹å¦‚ï¼Œå‚è§[ä»“åº“](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)ä¸­çš„â€œæŒ‡ä»¤æ ¼å¼â€ä¿¡æ¯ï¼Œé’ˆå¯¹`Mixtral-8x7B-Instruct-v0.1`ï¼‰ã€‚è€Œä¸”ï¼Œå¯¹äºåƒ`gpt-3.5-turbo`è¿™æ ·çš„ä¸“æœ‰èŠå¤©æ¨¡å‹ï¼ŒèŠå¤©æ¨¡æ¿é€šå¸¸åœ¨ç«¯ç‚¹èƒŒåè‡ªåŠ¨åº”ç”¨ï¼Œæ— è®ºä½ æ˜¯å¦å–œæ¬¢ï¼

ä½†æ˜¯æˆ‘ä»¬æ€ä¹ˆçŸ¥é“èŠå¤©æ ¼å¼æ˜¯å¦çœŸçš„åœ¨æé«˜æˆ‘ä»¬çš„æ€§èƒ½å‘¢ï¼Ÿè¿™å°±æ˜¯è¯­è¨€æ¨¡å‹è¯„ä¼°çš„ä½œç”¨ã€‚

# è¯­è¨€æ¨¡å‹è¯„ä¼°

è¯„ä¼°ç”¨äºè¡¡é‡ AI/ML æ¨¡å‹çš„æ€§èƒ½ï¼Œå®ƒä»¬å¯ä»¥æœ‰è®¸å¤šä¸åŒçš„å½¢å¼å’Œå¤§å°ã€‚è¯„ä¼°åŒ…æ‹¬ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šé’ˆå¯¹ç‰¹å®šä»»åŠ¡ç­–åˆ’çš„æ•°æ®é›†å’Œä¸ä¹‹ç›¸å…³çš„è¡¡é‡æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ã€‚

ç”Ÿæˆæ€§è¯­è¨€æ¨¡å‹è¯„ä¼°åŒ…å«ä¸€äº›é¢å¤–çš„ç»†èŠ‚ã€‚ä¾‹å¦‚ï¼Œä¸åŒçš„æ¡†æ¶ä»¥ä¸åŒæ–¹å¼è¡¡é‡æ–‡æœ¬ç”Ÿæˆæ€§èƒ½â€”â€”å³ä½¿æ˜¯ç›¸åŒçš„è¯„ä¼°ä¹Ÿä¼šæœ‰æ‰€ä¸åŒï¼ˆ[å‚è€ƒ](https://huggingface.co/blog/evaluating-mmlu-leaderboard)ï¼‰ã€‚å› æ­¤ï¼Œåœ¨è·¨ç ”ç©¶æ¯”è¾ƒåˆ†æ•°æ—¶ï¼Œéå¸¸é‡è¦çš„ä¸€ç‚¹æ˜¯è¦ç¡®è®¤ç»“æœæ˜¯ä½¿ç”¨ç›¸åŒçš„ä»£ç å’Œé…ç½®è®¡ç®—çš„ï¼Œä»¥é¿å…é”™è¯¯åˆ†æã€‚

è¶…çº§çš„æŒ‡ä»¤éµå¾ªè¯„ä¼°ï¼ˆ[IFEval](https://arxiv.org/abs/2311.07911)ï¼‰[2]åœ¨è¿™é‡Œç”¨äºæˆ‘ä»¬çš„æµ‹è¯•ã€‚è¯¥è¯„ä¼°åŒ…æ‹¬ 541 ä¸ªæç¤ºï¼Œç”¨æ¥è¡¡é‡è¯­è¨€æ¨¡å‹éµå¾ªå¯éªŒè¯è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„èƒ½åŠ›ã€‚è¿™äº›å¯éªŒè¯æŒ‡ä»¤çš„ç¤ºä¾‹åŒ…æ‹¬ï¼š

> â€œå†™ 450 åˆ° 500 å­—â€ï¼Œâ€œä½ çš„æ‰€æœ‰è¾“å‡ºåº”è¯¥æ˜¯ JSON æ ¼å¼â€ï¼Œâ€œåŒ…æ‹¬ä¸€ä¸ªæ ‡é¢˜ï¼Œå¹¶å°†å…¶æ”¾å…¥ä¸¤ä¸ªæ–¹æ‹¬å·ä¸­ï¼Œä¾‹å¦‚[[ title ]]â€

å¯¹äºç»™å®šçš„å“åº”å’Œå¯éªŒè¯æŒ‡ä»¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å››ä¸ªæŒ‡æ ‡æ¥æ£€æŸ¥è¯¥æŒ‡ä»¤æ˜¯å¦å·²è¢«éµå¾ªï¼š

> 1\. **æç¤ºçº§ä¸¥æ ¼å‡†ç¡®åº¦**ï¼šæ¯ä¸ªæç¤ºä¸­æ‰€æœ‰å¯éªŒè¯æŒ‡ä»¤éƒ½è¢«éµå¾ªçš„ç™¾åˆ†æ¯”ã€‚
> 
> 2\. **æŒ‡ä»¤çº§ä¸¥æ ¼å‡†ç¡®åº¦**ï¼šå¯éªŒè¯çš„æŒ‡ä»¤ä¸­è¢«éµå¾ªçš„ç™¾åˆ†æ¯”ã€‚
> 
> 3\. **æç¤ºçº§å®½æ¾å‡†ç¡®åº¦**ï¼šä½¿ç”¨å®½æ¾æ ‡å‡†è®¡ç®—çš„æç¤ºçº§å‡†ç¡®åº¦ã€‚
> 
> 4\. **æŒ‡ä»¤çº§å®½æ¾å‡†ç¡®åº¦**ï¼šä½¿ç”¨å®½æ¾æ ‡å‡†è®¡ç®—çš„æŒ‡ä»¤çº§å‡†ç¡®åº¦ã€‚

è¿™å››ä¸ªæŒ‡æ ‡çš„å¹³å‡å€¼åœ¨æ­¤è®¡ç®—ï¼ˆè¡¨æ ¼ 1ï¼‰ï¼Œä¸»è¦ç›®çš„æ˜¯ä½¿ç”¨ä¸€ä¸ªæ•æ‰æœ€å¹¿æ³›ä¿¡å·çš„å•ä¸€æŒ‡æ ‡ã€‚

IFEval æ˜¯æ¢ç´¢èŠå¤©æ¨¡æ¿å½±å“çš„ç†æƒ³æµ‹è¯•ï¼Œå› ä¸ºè¯¥æµ‹è¯•ä¸“é—¨è®¾è®¡ç”¨æ¥è¡¡é‡åœ¨èŠå¤©æ•°æ®ä¸Šçš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚å¦ä¸€ä¸ªæœ‰è¶£çš„é—®é¢˜æ˜¯ï¼ŒèŠå¤©æ¨¡æ¿æ˜¯å¦å¯¹é‚£äº›ä¸å¤ªé€‚åˆèŠå¤©æ•°æ®çš„è¯„ä¼°äº§ç”Ÿç§¯æå½±å“â€”â€”è¿™æ˜¯ä¸€ä¸ªç•™å¾…æœªæ¥ç ”ç©¶çš„è¯é¢˜ã€‚

# IFEval çš„èŠå¤©æ¨¡æ¿

Eleuther.AI çš„[lm-eval](https://github.com/EleutherAI/lm-evaluation-harness)æ˜¯äº‹å®ä¸Šçš„å¼€æºè¯­è¨€æ¨¡å‹è¯„ä¼°å·¥å…·åŒ…ã€‚ç”±äºæ›´å¤šæ¨¡å‹çš„èŠå¤©æ¨¡æ¿åŠŸèƒ½æ˜¯ç”¨æˆ·å¸¸è¯·æ±‚çš„æ–°å¢åŠŸèƒ½ï¼Œå› æ­¤æˆ‘ä»¬å¾ˆå®¹æ˜“ä¸å…¶ä»–å¼€å‘è€…åä½œï¼Œä¸“æ³¨äºåœ¨ğŸ¤—æ¨¡å‹ç±»ä¸­å®ç°è¿™ä¸€åŠŸèƒ½ã€‚ç›®å‰ï¼Œå¼€å‘å·¥ä½œæ­£åœ¨`add-chat-templating`åˆ†æ”¯ä¸­è¿›è¡Œï¼ˆ[é“¾æ¥](https://github.com/EleutherAI/lm-evaluation-harness/tree/add-chat-templating)ï¼‰ï¼Œç”±é—®é¢˜#1098ï¼ˆ[é“¾æ¥](https://github.com/EleutherAI/lm-evaluation-harness/issues/1098#issuecomment-1947116099)ï¼‰å’Œ#1209ï¼ˆ[é“¾æ¥](https://github.com/EleutherAI/lm-evaluation-harness/issues/1209#issuecomment-1879966071)ï¼‰æ¨åŠ¨ã€‚å½“ä½¿ç”¨æ­¤åˆ†æ”¯æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼å°†èŠå¤©æ ¼å¼åº”ç”¨äºè¯„ä¼°ï¼š

```py
!lm_eval --model hf \
    --model_args=pretrained=meta-llama/Llama-2-70b-chat-hf,dtype="bfloat16",parallelize=True,device_map="auto",use_chat_template=True,system_prompt="You are a helpful assistant." \
    --tasks ifeval \
    --batch_size 16 \
    --output_path output/Llama-2-70b-chat-hf \
    --log_samples \
    --num_fewshot 0
```

æ–°å¼•å…¥çš„è§¦å‘å™¨`use_chat_template`å’Œ`system_prompt`å‡ºç°åœ¨`model_args`çš„å³ä¾§ï¼Œç”¨äºæ§åˆ¶èŠå¤©æ¨¡æ¿çš„åº”ç”¨æ–¹å¼ã€‚åœ¨å½“å‰åˆ†æ”¯çš„å®éªŒæ€§ç‰ˆæœ¬ä¸­ï¼Œä»£ç åœ¨åº”ç”¨èŠå¤©æ¨¡æ¿å‰åæ‰“å°ç¬¬ä¸€ä¸ªæç¤ºã€‚è¿™æ˜¯ä¸Šè¿°ä»£ç å—çš„æ•ˆæœï¼š

```py
# First element before prompt formatting...
('Write a 300+ word summary of the wikipedia page "https://en.wikipedia.org/wiki/Raymond_III,_Count_of_Tripoli". Do not use any commas and highlight at least 3 sections that has titles in markdown format, for example *highlighted section part 1*, *highlighted section part 2*, *highlighted section part 3*.', {'until': [], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 1280})

# First element after prompt formatting...
('<s>[INST] <<SYS>>\nYou are a helpful assistant.\n<</SYS>>\n\nWrite a 300+ word summary of the wikipedia page "https://en.wikipedia.org/wiki/Raymond_III,_Count_of_Tripoli". Do not use any commas and highlight at least 3 sections that has titles in markdown format, for example *highlighted section part 1*, *highlighted section part 2*, *highlighted section part 3*. [/INST]', {'until': [], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 1280})
```

è¾“å‡ºå·²é‡‡ç”¨æ‰€éœ€çš„èŠå¤©æ¨¡æ¿ï¼

æˆ‘ä»¬ç°åœ¨å‡†å¤‡è¿›è¡Œ A/B æµ‹è¯•ï¼Œè¯„ä¼°èŠå¤©æ¨¡æ¿å¯¹ IFEval çš„å½±å“ã€‚æˆ‘ä»¬ä¸ºå®éªŒé€‰æ‹©äº†ä¸€äº›æµè¡Œçš„ LLMï¼Œæ¯ä¸ªæ¨¡å‹éƒ½æœ‰è‡ªå·±ç‹¬ç‰¹çš„èŠå¤©æ¨¡æ¿ã€‚åœ¨è¾ƒå¤§çš„æ¨¡å‹æ–¹é¢ï¼Œæˆ‘ä»¬é€‰æ‹©äº† 70B å‚æ•°çš„`Llama-2â€“70b-chat`ï¼Œä¸¤ç§ 47B å‚æ•°æ¨¡å‹çš„å˜ä½“ï¼Œ`Mixtral-8x7B-Instruct-v0.1`å’Œ`Nous-Hermes-2-Mixtral-8x7B-DPO`ï¼Œä»¥åŠ 34B å‚æ•°çš„`Nous-Hermes-2-Yi-34B`ã€‚åœ¨è¾ƒå°çš„æ¨¡å‹æ–¹é¢ï¼Œæˆ‘ä»¬æœ‰ä¸‰ä¸ª 7B å‚æ•°çš„æ¨¡å‹ï¼š`Mistral-Instruct-7B-v0.2`ã€`Zephyr-7b-beta`å’Œ`Starling-LM-7B-alpha`ã€‚è‡³äºç³»ç»Ÿæç¤ºï¼Œå…¼å®¹æ¨¡å‹ä½¿ç”¨äº†ç®€å•çš„æç¤ºâ€œä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚â€æ›´å¤šå…³äºè¿™ä¸ƒä¸ªæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯è¯·å‚è§ä¸‹æ–‡[3]ã€‚

ç°åœ¨ï¼Œæ¯«ä¸æ‹–å»¶ï¼Œæˆ‘ä»¬çš„ç»“æœï¼š

![](img/89bcb4f71233c0c5252237b46374b882.png)

**è¡¨ 1**ï¼šæ¥è‡ª IFEval çš„ A/B æµ‹è¯•ç»“æœï¼ŒæŒ‰æ¨¡å‹å¤§å°é™åºæ’åˆ—ï¼ˆ[é“¾æ¥](https://docs.google.com/spreadsheets/d/1Tawz9IHH2B-_XWj-JjeVGmu-og60lgSSpMywrGxcj6Q/edit?usp=sharing)ï¼‰ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ä¸‹é¢çš„â€œé™„åŠ è¯´æ˜â€éƒ¨åˆ†ï¼Œä¾‹å¦‚è¿è¡Œæ—¥å¿—çš„é“¾æ¥ã€‚ä¸ºäº†ä¿è¯å¯é‡å¤æ€§ï¼Œå®éªŒåœ¨åŠç²¾åº¦ bfloat16 æ¨¡å‹ä¸Šæ‰§è¡Œï¼Œå·¥ä½œç«™é…ç½®äº† 2 ä¸ª H100 80GB SXM5 èŠ¯ç‰‡ï¼Œå¹¶ä½¿ç”¨äº†`lm-eval`åŒ…çš„åˆ†æ”¯ï¼Œå“ˆå¸Œå€¼ä¸º[0c0c314c0df4c10f35bf7c17dc80f745f8027e9b](https://github.com/EleutherAI/lm-evaluation-harness/tree/0c0c314c0df4c10f35bf7c17dc80f745f8027e9b)ã€‚

ğŸ”¥ èŠå¤©æ¨¡æ¿å¯¹ IFEval è¯„åˆ†äº§ç”Ÿäº†é‡å¤§å½±å“ï¼`Nous-Hermes-2-Mixtral-8x7B-DPO` ä½œä¸ºæµ‹è¯•ä¸­è¡¨ç°æœ€å¥½çš„æ¨¡å‹ï¼Œå¹³å‡å¾—åˆ†çº¦ä¸º 63%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ`Zephyr-7b-beta` æ˜¯è¡¨ç°æœ€å·®çš„æ¨¡å‹ï¼Œä½†å´ä»èŠå¤©æ¨¡æ¿ä¸­è·å¾—äº†æœ€å¤§çš„æå‡â€”â€”æƒŠäººçš„ +39%ï¼ä½œä¸ºå‚è€ƒï¼ŒIFEval è®ºæ–‡ä¸­æŠ¥å‘Šçš„ `gpt-4`ï¼ˆ2023 å¹´ 11 æœˆï¼‰å¹³å‡å¾—åˆ†çº¦ä¸º 81%ï¼Œ`PaLM 2S`ï¼ˆ2023 å¹´ 8 æœˆï¼‰ä¸ºçº¦ 51% [2]ã€‚

æ€»ç»“æ¥è¯´ï¼Œè¿™äº›ç»“æœæ­ç¤ºäº†å‡ ä¸ªå…³é”®çš„æ´å¯Ÿï¼š

1.  èŠå¤©æ¨¡æ¿å¯¹å¼€æº LLM çš„æŒ‡ä»¤è·Ÿéšæœ‰ç§¯æå½±å“ï¼Œå…¶å½±å“ç¨‹åº¦å› æ¨¡å‹è€Œå¼‚ã€‚

1.  å¼€æº LLM åœ¨éµå¾ªè‡ªç„¶è¯­è¨€æŒ‡ä»¤æ–¹é¢ä¸å¦‚ SOA ä¸“æœ‰æ¨¡å‹ï¼Œå¦‚ `gpt-4`ã€‚

# ç»“è®º

èŠå¤©æ¨¡æ¿åœ¨æˆ‘ä»¬çš„å®éªŒä¸­æ˜¾è‘—æå‡äº† IFEval çš„è¯„åˆ†ï¼Œè¿™åœ¨å„ç§æ ¼å¼å’Œæ¨¡å‹ä¸­éƒ½å¾—åˆ°äº†è¯æ˜ã€‚ç„¶è€Œï¼Œæˆ‘å¹¶ä¸ä¸€å®šæœŸå¾…è¿™äº›æ•ˆæœèƒ½æ™®éé€‚ç”¨äºæ‰€æœ‰ LM è¯„ä¼°ã€‚ä¸ºäº†è¿›ä¸€æ­¥æ¢è®¨èŠå¤©æ¨¡æ¿å¯¹åŸºå‡†çš„å½±å“ï¼Œä¸‹ä¸€æ­¥åŒ…æ‹¬è¿›è¡Œä»¥ä¸‹å®éªŒï¼š

+   æ›´å¤šç±»ä¼¼ IFEval çš„æŒ‡ä»¤è·Ÿéšè¯„ä¼°

+   ä¸€èˆ¬ç”¨é€”è¯„ä¼°ï¼Œä¾‹å¦‚ ğŸ¤— çš„[å¼€æ”¾ LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

+   ä¸Šä¸‹æ–‡æ£€ç´¢è¯„ä¼°ï¼Œä¾‹å¦‚â€œ[Needle in a Haystack](https://github.com/Arize-ai/LLMTest_NeedleInAHaystack2)â€

+   è¿˜æœ‰æ›´å¤šï¼Œæ›´å¤šå†…å®¹ï¼

ä»ä¸‰ä¸‡è‹±å°ºçš„é«˜åº¦æ¥çœ‹ï¼Œç°åœ¨æ˜¯è¿›è¡Œ LM è¯„ä¼°ç ”ç©¶çš„å¥½æ—¶æœºâ€”â€”é¦–å…ˆï¼Œå› ä¸ºæ›´å¼ºå¤§çš„ LLM éœ€è¦æ–°ä¸€ä»£æµ‹è¯•æ¥æœ‰æ•ˆè¯„ä¼°å®ƒä»¬ã€‚æ— è®ºæ˜¯åˆ›å»ºè‡ªå·±çš„è¯„ä¼°æ–¹æ³•ï¼Œè¿˜æ˜¯åœ¨ç°æœ‰æ–¹æ³•çš„åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ï¼Œç ”ç©¶è¯„ä¼°æ˜¯ä¸ºå¼€æ”¾ç§‘å­¦ç¤¾åŒºåšå‡ºè´¡çŒ®çš„ä¸€ç§é‡è¦æ–¹å¼ã€‚

# å¼•ç”¨

[1] Matthew Carriganï¼ˆ2023ï¼‰ï¼Œ[èŠå¤©æ¨¡æ¿ï¼šç»ˆç»“æ²‰é»˜çš„æ€§èƒ½æ€æ‰‹](https://huggingface.co/blog/chat-templates)ï¼ŒHugging Faceã€‚

[2] Zhou ç­‰äººï¼ˆ2023ï¼‰ï¼Œ[å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤è·Ÿéšè¯„ä¼°](https://arxiv.org/pdf/2311.07911.pdf)ï¼ŒarXivã€‚

+   **æ•°æ®é›†è®¸å¯**ï¼šæ­¤å¤„ä½¿ç”¨çš„ IFEval æ•°æ®é›†å¯¹æ‰€æœ‰äººå…¬å¼€ï¼Œæ— é™åˆ¶ä½¿ç”¨ï¼ˆ[Apache-2.0 è®¸å¯è¯](https://github.com/google-research/google-research/tree/master#Apache-2.0-1-ov-file)ï¼‰ã€‚

[3] æ­¤å¤„ä½¿ç”¨çš„æ¨¡å‹ï¼ŒæŒ‰å¤§å°æ’åˆ—ï¼ˆæ‰€æœ‰æ¨¡å‹å‡å·²è·å¾—ç ”ç©¶ä½¿ç”¨çš„å®½æ¾è®¸å¯ï¼‰ã€‚

+   `Llama-2â€“70b-chat`ï¼ˆ[é“¾æ¥](http://meta-llama/Llama-2-70b-chat-hf)ï¼‰â€” Meta

+   `Mixtral-8x7B-Instruct-v0.1`ï¼ˆ[é“¾æ¥](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)ï¼‰â€” Mistral.AI

+   `Nous-Hermes-2-Mixtral-8x7B-DPO`ï¼ˆ[é“¾æ¥](https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO)ï¼‰â€” Nous-Research

+   `Nous-Hermes-2-Yi-34B`ï¼ˆ[é“¾æ¥](http://NousResearch/Nous-Hermes-2-Yi-34B)ï¼‰â€” Nous-Research

+   `Starling-LM-7B-alpha`ï¼ˆ[é“¾æ¥](https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha)ï¼‰â€” Berkeley NEST

+   `Zephyr-7B-beta`ï¼ˆ[é“¾æ¥](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)ï¼‰â€” Hugging Face

+   `Mistral-7B-Instruct-v0.2` ([é“¾æ¥](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)) â€” Mistral.AI

# å…¶ä»–æ³¨æ„äº‹é¡¹

+   æŸ¥çœ‹ç”¨äºè¿è¡Œå®éªŒçš„ä»£ç ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/daniel-furman/evals-with-chat-formats)æ‰¾åˆ°ã€‚

+   è¦å®¡è®¡ç»“æœï¼Œè¯·æŸ¥çœ‹æ¯æ¬¡è¿è¡Œçš„è¾“å‡ºï¼Œ[è¿™é‡Œ](https://github.com/daniel-furman/evals-with-chat-formats/tree/main/assets/IFEval_results)ï¼Œä»¥åŠ Zeno æ—¥å¿—ï¼Œ[è¿™é‡Œ](https://hub.zenoml.com/project/79b4684d-0f4e-48f4-b739-ba4e0bd63ee8/IFEval-chat-templating-experiments-run-1)å’Œ[è¿™é‡Œ](https://hub.zenoml.com/project/548fcb7a-52cf-4c60-aaf7-13d6b03343fd/IFEval-chat-templating-experiments-run-2)ï¼ˆæ¨¡å‹åœ¨ 2 ä¸ªæ‰¹æ¬¡ä¸­è¿è¡Œï¼‰ã€‚è¯·æ³¨æ„ï¼ŒZeno æ—¥å¿—å°šæœªæ•æ‰åˆ°èŠå¤©æ¨¡æ¿åº”ç”¨äºæç¤ºçš„è¿‡ç¨‹â€”â€”è¿™æ˜¯å¼€å‘å¾…åŠäº‹é¡¹ä¸­çš„ä¸€é¡¹å†…å®¹ã€‚

+   åœ¨è®¡ç®—æ–¹é¢ï¼Œä½¿ç”¨äº† RunPod ([é“¾æ¥](https://www.runpod.io/)) è®¿é—®å¸¦æœ‰ Nvidia GPU èŠ¯ç‰‡çš„å·¥ä½œç«™â€”â€”ç‰¹åˆ«æ˜¯ä¸€ä¸ªæ‹¥æœ‰ 2 ä¸ª H100 80 GB SXM5 èŠ¯ç‰‡çš„é›†ç¾¤ã€‚æ€»çš„æ¥è¯´ï¼Œå®éªŒåŒ…æ‹¬äº† 14 æ¬¡ IFEval çš„è¿è¡Œï¼Œæ€»å…±ç§¯ç´¯äº†çº¦ 6 å°æ—¶çš„é›†ç¾¤è¿è¡Œæ—¶é—´ã€‚

+   é€šè¿‡ç½®ä¿¡åŒºé—´ä¼°è®¡æˆ‘ä»¬çš„ç»“æœä¸­çš„ç»Ÿè®¡ä¸ç¡®å®šæ€§ï¼ˆä½¿ç”¨äº†è‡ªåŠ©æ³•é‡æŠ½æ ·æ–¹æ³•ï¼‰ã€‚è¿™äº› 95%çš„ç½®ä¿¡åŒºé—´å¤§çº¦åœ¨+/- 2.75%åˆ° 4.25%ä¹‹é—´â€”â€”ç›¸å¯¹äºèŠå¤©æ¨¡æ¿åº”ç”¨çš„æµ‹é‡æ•ˆæœæ¥è¯´ï¼Œè¿™ä¸ªèŒƒå›´è¾ƒå°ã€‚
