- en: Constructive Heuristics in Discrete Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/constructive-heuristics-in-discrete-optimization-f6a41bf26d01?source=collection_archive---------5-----------------------#2024-05-30](https://towardsdatascience.com/constructive-heuristics-in-discrete-optimization-f6a41bf26d01?source=collection_archive---------5-----------------------#2024-05-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Obtain initial solutions for combinatorial optimization problems with Python
    examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@bruscalia12?source=post_page---byline--f6a41bf26d01--------------------------------)[![Bruno
    Scalia C. F. Leite](../Images/1042cd04be047c0811fef79ecd04e69c.png)](https://medium.com/@bruscalia12?source=post_page---byline--f6a41bf26d01--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f6a41bf26d01--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f6a41bf26d01--------------------------------)
    [Bruno Scalia C. F. Leite](https://medium.com/@bruscalia12?source=post_page---byline--f6a41bf26d01--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f6a41bf26d01--------------------------------)
    ·11 min read·May 30, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a97a50e5ff6012c41ccf3d6b3143c9d5.png)'
  prefs: []
  type: TYPE_IMG
- en: Representation of a constructive heuristic selecting elements from a ground
    set. (Image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: Discrete or Combinatorial Optimization is a relevant study area in Operations
    Research (OR) and Computer Science, dedicated to identifying the best (or a suitable)
    solution from a finite set of possibilities. With applications including vehicle
    routing, operations scheduling, and network design, often the problems cannot
    be tackled by exact approaches in tractable runtimes. Therefore, heuristics can
    be an interesting alternative to provide fast and good quality solutions guiding
    operations in reasonable computing time.
  prefs: []
  type: TYPE_NORMAL
- en: Not only as stand-alone techniques, constructive heuristics can be coupled with
    other algorithms to improve their runtimes, cost functions, or other performance
    aspects. For instance, providing an initial solution to a Mixed-Integer Programming
    (MIP) solver can establish a dual bound that helps to prune the search space.
    Additionally, this initial solution can enable the solver to incorporate local
    search heuristics more effectively, potentially leading to faster convergence
    and better overall solution quality.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, you will find basic definitions of discrete optimization with
    an introduction to constructive heuristics. Python examples will be used to illustrate
    the topics with applications to the *Knapsack* and *Maximum Independent Set* problems.
    Random choices and greedy selection of elements will be analyzed as we create
    our solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The complete code for these problems, besides several other optimization examples,
    is available in my [GitHub repository](https://github.com/bruscalia/optimization-demo-files).
  prefs: []
  type: TYPE_NORMAL
- en: Discrete Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a broad sense, a numerical optimization problem aims to find the best value
    of an objective *f* which is a function of decision variables ***x*** and might
    be subject to some equality and inequality constraints, functions of ***x*** as
    well. The objective can be defined in either a *minimization* or a *maximization*
    sense.
  prefs: []
  type: TYPE_NORMAL
- en: Discrete optimization refers to a category of optimization problems in which
    decision variables can assume only discrete values. Therefore one faces a finite
    (although it might be large) set *S* of possible solutions from which it must
    be selected a feasible one leading to the best objective.
  prefs: []
  type: TYPE_NORMAL
- en: Solution Construction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many algorithms for combinatorial optimization problems build a solution incrementally
    from scratch, where at each step, a single ground set element is added to the
    partial solution under construction. A ground set element to be added at each
    step cannot be such that its combination with one or more previously added elements
    leads to an infeasibility *(Resende & Ribeiro, 2016)*.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Suppose we have a ground set *E* of elements that might be used to compose a
    solution *S*. Suppose *F* is a subset of elements from *E* that included into
    a partial solution *S* would not lead to infeasibility and would improve the overall
    results. A pseudocode for a constructive heuristic can be described as the following.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The choice of the next element to include in the solution can vary according
    to the problem and strategy adopted. In some situations, choosing one element
    that leads to the best immediate effect in the partial solution can be an interesting
    alternative, in other situations random effects might be desirable. We will compare
    both approaches in two different problems in the remainder of this article.
  prefs: []
  type: TYPE_NORMAL
- en: In some problems, there are exact constructive algorithms in polynomial time
    even when adopting a greedy incremental approach as will be presented in this
    article. An interesting example is the Minimum Spanning Tree (MST) problem. However,
    this is not the case for the problems that will be presented here.
  prefs: []
  type: TYPE_NORMAL
- en: The knapsack problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the knapsack problem, from a set of items with individual attributes of weight
    and value, one must select the most valuable ones to include in a knapsack of
    pre-defined capacity in such a way that the total weight of items selected does
    not exceed it. In this problem, we can think of the items available as our *ground
    set*.
  prefs: []
  type: TYPE_NORMAL
- en: So let us create a Python class to represent each of our items available.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We also create attributes `density` with the corresponding “value per weight”
    ratio of the given item, `index` with its corresponding identifier, and `selected`
    to indicate if that item is part of our final solution. The *classmethod* `from_dict`
    is useful for initializing a new item from a Python `dict` with keys *index*,
    *weight*, and *value*.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us think of an abstraction of a constructive heuristic for the knapsack
    problem. It takes as initialization arguments the knapsack capacity and a list
    of items (as dictionaries). Both should be available as attributes of our class
    to be used in the solution procedure.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: A naive solution procedure can iterate over our set of items and include the
    next item in the solution if its corresponding weight is lesser than or equal
    to the remaining capacity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: However, this method can lead to poor-quality solutions. Suppose at the beginning
    of our list there was a heavy item with a small value. It would be included in
    the solution occupying available space that more valuable alternatives could use.
  prefs: []
  type: TYPE_NORMAL
- en: A better choice could have been to first sort items by their *density* and then
    run the previous procedure of including the next from the input if it fits in
    the remaining space. That leads us to the *Greedy* selection.
  prefs: []
  type: TYPE_NORMAL
- en: Greedy selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A greedy approximation algorithm is an iterative algorithm which produces a
    partial solution incrementally. Each iteration makes a locally optimal or suboptimal
    augmentation to the current partial solution, so that a globally suboptimal solution
    is reached at the end of the algorithm *(Wan, 2013)*.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the context of the knapsack problem, we could choose the next element using
    a priority of *density* as previously suggested. In this case, a greedy approach
    does not guarantee the optimality of the solution, but it can be an interesting
    alternative for fast and good-quality results. In our Python code, we can achieve
    that just by sorting our items in place previously to applying the solution procedure.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In my [GitHub repository](https://github.com/bruscalia/optimization-demo-files/tree/main/mip/knapsack/heuristics),
    you might find an instance with 10 items to which I applied both methods. While
    the choice based on the original input sequence produced a solution with a total
    value of 68, the choice based on density resulted in a total value of 91\. I would
    go with the greedy approach for good-quality and fast solutions on this one.
  prefs: []
  type: TYPE_NORMAL
- en: The maximum independent set problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next example is a classical problem on subset partitioning in which our
    goal is to find a subset of elements from an undirected graph *G*(*V*, *E*) with
    the maximum number of elements such that there are no edges connecting any pair
    from the given subset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us start by creating classes to work with the graph elements of this problem.
    The class `Node` will be used to represent a vertice (or node) from our undirected
    graph. It will have as attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`neighbors`: A list of neighbor vertices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`index`: Its identifier'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`selected`: A boolean to indicate when it was included in the solution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whenever a `Node` instance is deleted from our feasible subset of elements,
    we must remove it from its neighbors’ list of neighbors, so we create a method
    `delete` to make it easier.
  prefs: []
  type: TYPE_NORMAL
- en: The property `degree` computes the number of neighbors from a given node and
    will be used as our criterion for choosing the next element in the *greedy* approach.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now, let us create our `Graph` class. It should be instantiated from a list
    of edges and an optional list of nodes. It should have an attribute `N` which
    is a dictionary of existing nodes (or vertices).
  prefs: []
  type: TYPE_NORMAL
- en: The property `queue` should return a list of nodes not yet selected for us to
    consider including in the solution at each step of our constructive heuristic.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever a new `Node` instance is selected, the method `select` should be called,
    which changes its `selected` attribute and calls its `delete` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now, let us create an abstraction for our constructive heuristic. It should
    be instantiated, as its corresponding `Graph`, from a list of edges and an optional
    list of nodes. When instantiated, its attribute `graph` is defined from the original
    graph of the problem instance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `solve` method will be at the core of our solution procedure. It should
    return a subgraph of *G*(*V*, *E*) with a candidate solution. When using an instance
    of the solution procedure as a callable, it should overwrite its nodes’ `selected`
    attributes based on the result returned by the `solve` method.
  prefs: []
  type: TYPE_NORMAL
- en: Notice the `choice` method here is an abstraction yet to be overwritten by child
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Let us first create an algorithm that randomly chooses the next node to include
    into our solution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: It can already be used in our solution procedure and creates feasible solutions
    that are *maximal independent sets* (not *maximum*). However, its performance
    varies according to the random sequence and we might be vulnerable to poor results.
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive greedy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Alternatively, at each step, we could have chosen the next node that has the
    smallest impact on the “pool” of feasible elements from the ground set. It would
    mean choosing the next element that in the subgraph has the smallest number of
    neighbors. In other words, with the smallest `degree` attribute. This is the same
    approach adopted by Feo et al. (1994).
  prefs: []
  type: TYPE_NORMAL
- en: Notice the `degree` of our nodes might vary as the partial solution changes
    and elements are removed from the subgraph. It can be therefore defined as an
    *adaptive greedy* procedure.
  prefs: []
  type: TYPE_NORMAL
- en: There are other situations where the cost of the contribution of an element
    is affected by the previous choices of elements made by the algorithm. We shall
    call these adaptive greedy algorithms *(Resende & Ribeiro, 2016)*.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let us then implement an algorithm that chooses as the next element the one
    from the subgraph with the smallest `degree`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Although it does not provide proof of optimality, the adaptive greedy approach
    can also be an interesting strategy for providing fast and good-quality results
    to this problem. But try running the random approach multiple times… In some instances,
    it might outperform the greedy strategy (at least in one or a few runs). Why not
    implement a multi-start framework then?
  prefs: []
  type: TYPE_NORMAL
- en: Multistarts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this approach, multiple independent runs are performed, and a registry of
    the best solution is kept. In the end, the best solution is returned.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In my [GitHub repository](https://github.com/bruscalia/optimization-demo-files/blob/5546625793917492f4abe1aca0a571527e256e32/graph-coloring/max_independent_set.ipynb),
    you will find an example of a 32-node graph in which the *adaptive greedy* found
    a subset of 5 vertices, but a random framework with multi-start found a solution
    with 6\. The solution procedure is represented below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/abb86a60627ac000096137ee77138ed8.png)'
  prefs: []
  type: TYPE_IMG
- en: Solution procedure of constructive heuristic applied to a maximum independent
    set problem. (Animation by the author).
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the beginning of this text, I suggested constructive heuristics can be coupled
    with local search techniques. One fantastic meta-heuristic that explores it is
    called *Greedy Randomized Adaptive Search Procedure* (GRASP).
  prefs: []
  type: TYPE_NORMAL
- en: The idea of GRASP is to use a multi-start framework in which a random element
    will lead the constructive phase to produce different initial solutions to which
    local search should be applied. This way, the solution procedure escapes local
    optima. For those interested in exploring heuristics and meta-heuristics in more
    detail, it is worth checking the [website of Prof Mauricio Resende](https://mauricio.resende.info/),
    one of the authors who originally proposed GRASP. There, he lists several of his
    works and contributions to the academic community on operations research.
  prefs: []
  type: TYPE_NORMAL
- en: Those interested in coding examples of GRASP might also check my [GitHub repository](https://github.com/bruscalia/jobshop)
    with an application for the Job-Shop Scheduling Problem.
  prefs: []
  type: TYPE_NORMAL
- en: To those interested in exploring more optimization problems and solution techniques,
    I have several other stories available on Medium which I have aggregated on a
    comprehensive list.
  prefs: []
  type: TYPE_NORMAL
- en: '![Bruno Scalia C. F. Leite](../Images/0c7396e41d4b598be2349eaea982c984.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Bruno Scalia C. F. Leite](https://medium.com/@bruscalia12?source=post_page-----f6a41bf26d01--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Tales of the Optimization Age
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@bruscalia12/list/tales-of-the-optimization-age-c15faf64a6ca?source=post_page-----f6a41bf26d01--------------------------------)15
    stories![](../Images/848ca03a7d7366b8a040f720f5d51f5c.png)![](../Images/b79fd62ce301f6295199d983f7633588.png)![](../Images/a6e8cbe0e088f4e7b1edcf27c524b072.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this article, constructive heuristics in the context of discrete
    optimization were introduced and applied to the *knapsack* and the *maximum independent
    set* problems. Intuitions on how to choose ground elements to build a solution
    were presented exemplifying a greedy choice, random factors, and multi-starts.
    The complete code is available in my [GitHub repository](https://github.com/bruscalia/optimization-demo-files).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feo, T. A., Resende, M. G., & Smith, S. H., 1994\. A greedy randomized adaptive
    search procedure for maximum independent set. *Operations Research*, *42*(5),
    860–878.
  prefs: []
  type: TYPE_NORMAL
- en: Resende, M. G., & Ribeiro, C. C., 2016\. *Optimization by GRASP*. Springer Science+
    Business Media New York.
  prefs: []
  type: TYPE_NORMAL
- en: 'Wan, PJ., 2013\. Greedy Approximation Algorithms. In: Pardalos, P., Du, DZ.,
    Graham, R. (eds) Handbook of Combinatorial Optimization. Springer, New York, NY.'
  prefs: []
  type: TYPE_NORMAL
