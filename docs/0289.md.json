["```py\nimport boto3\n\nregion = 'us-east-1'\njob_id = 'my-experiment' # replace with unique id\nnum_instances = 1\nimage_id = 'ami-0240b7264c1c9e6a9' # replace with image of choice\ninstance_type = 'g5.xlarge' # replace with instance of choice\n\nec2 = boto3.resource('ec2', region_name=region)\n\ninstances = ec2.create_instances(\n    MaxCount=num_instances,\n    MinCount=num_instances,\n    ImageId=image_id,\n    InstanceType=instance_type,\n)\n```", "```py\nimport boto3\n\nregion = 'us-east-1'\njob_id = 'my-experiment' # replace with unique id\nnum_instances = 1\nimage_id = 'ami-0240b7264c1c9e6a9' # replace with image of choice\ninstance_type = 'g5.xlarge' # replace with instance of choice\ninstance_profile_arn = 'instance-profile-arn' # replace with profile arn\n\nec2 = boto3.resource('ec2', region_name=region)\n\nscript = \"\"\"#!/bin/bash\n         # environment setup\n         export PATH=/opt/conda/envs/pytorch/bin/python:$PATH\n\n         # download and unpack code\n         aws s3 cp s3://my-s3-path/my-code.tar .\n         tar -xvf my-code.tar\n\n         # install dependencies\n         python3 -m pip install -r requirements.txt\n\n         # run training workload\n         python3 train.py\n\n         # sync output artifacts\n         aws s3 sync artifacts s3://my-s3-path/artifacts\n         \"\"\"\n\ninstances = ec2.create_instances(\n    MaxCount=num_instances,\n    MinCount=num_instances,\n    ImageId=image_id,\n    InstanceType=instance_type,\n    IamInstanceProfile={'Arn':instance_profile_arn},\n    UserData=script\n )\n```", "```py\nscript = \"\"\"#!/bin/bash\n         # environment setup\n         TOKEN=$(curl -s -X PUT \"http://169.254.169.254/latest/api/token\" -H \\\n                              \"X-aws-ec2-metadata-token-ttl-seconds: 21600\")\n         INST_MD=http://169.254.169.254/latest/meta-data\n         CURL_FLAGS=\"-H \\\"X-aws-ec2-metadata-token: ${TOKEN}\\\" -s\"\n         INSTANCE_ID=$(curl $CURL_FLAGS $INST_MD/instance-id)\n         REGION=$(curl $CURL_FLAGS $INST_MD/placement/region)\n         export PATH=/opt/conda/envs/pytorch/bin/python:$PATH\n\n         # download and unpack code\n         aws s3 cp s3://my-s3-path/my-code.tar .\n         tar -xvf my-code.tar\n\n         # install dependencies\n         python3 -m pip install -r requirements.txt\n\n         # run training workload\n         python3 train.py\n\n         # sync output artifacts\n         aws s3 sync artifacts s3://my-s3-path/artifacts\n\n         # self-destruct\n         aws ec2 terminate-instances --instance-ids $INSTANCE_ID \\\n                                     --region $REGION\n         \"\"\"\n```", "```py\nimport boto3\n\nregion = 'us-east-1'\njob_id = 'my-experiment' # replace with unique id\nnum_instances = 1\nimage_id = 'ami-0240b7264c1c9e6a9' # replace with image of choice\ninstance_type = 'g5.xlarge' # replace with instance of choice\ninstance_profile_arn = 'instance-profile-arn' # replace with profile arn\n\nec2 = boto3.resource('ec2', region_name=region)\n\nscript = \"\"\"#!/bin/bash\n         # environment setup\n         TOKEN=$(curl -s -X PUT \"http://169.254.169.254/latest/api/token\" -H \\\n                              \"X-aws-ec2-metadata-token-ttl-seconds: 21600\")\n         INST_MD=http://169.254.169.254/latest/meta-data\n         CURL_FLAGS=\"-H \\\"X-aws-ec2-metadata-token: ${TOKEN}\\\" -s\"\n         INSTANCE_ID=$(curl $CURL_FLAGS $INST_MD/instance-id)\n         REGION=$(curl $CURL_FLAGS $INST_MD/placement/region)\n         JOB_ID=$(curl $CURL_FLAGS $INST_MD/tags/instance/JOB_ID)\n         export PATH=/opt/conda/envs/pytorch/bin/python:$PATH\n\n         # download and unpack code\n         aws s3 cp s3://my-s3-path/$JOB_ID/my-code.tar .\n         tar -xvf my-code.tar\n\n         # install dependencies\n         python3 -m pip install -r requirements.txt\n\n         # run training workload\n         python3 train.py\n\n         # sync output artifacts\n         aws s3 sync artifacts s3://my-s3-path/$JOB_ID/artifacts\n\n         # self-destruct\n         aws ec2 terminate-instances --instance-ids $INSTANCE_ID \\\n                                     --region $REGION\n         \"\"\"\n\ninstances = ec2.create_instances(\n    MaxCount=num_instances,\n    MinCount=num_instances,\n    ImageId=image_id,\n    InstanceType=instance_type,\n    IamInstanceProfile={'Arn':instance_profile_arn},\n    UserData=script,\n    MetadataOptions={\"InstanceMetadataTags\":\"enabled\"},\n    TagSpecifications=[{\n        'ResourceType': 'instance',\n        'Tags': [\n            {'Key': 'NAME', 'Value': 'test-vm'},\n            {'Key': 'JOB_ID', 'Value': f'{job_id}'}\n        ]\n    }],\n)\n```", "```py\n{\n    \"logs\": {\n        \"logs_collected\": {\n            \"files\": {\n                \"collect_list\": [\n                    {\n                        \"file_path\": \"/output.log\",\n                        \"log_group_name\": \"/aws/ec2/training-jobs\",\n                        \"log_stream_name\": \"job-id\"\n                    }\n                ]\n            }\n        }\n    }\n}\n```", "```py\nscript = \"\"\"#!/bin/bash\n         # environment setup\n         TOKEN=$(curl -s -X PUT \"http://169.254.169.254/latest/api/token\" -H \\\n                              \"X-aws-ec2-metadata-token-ttl-seconds: 21600\")\n         INST_MD=http://169.254.169.254/latest/meta-data\n         CURL_FLAGS=\"-H \\\"X-aws-ec2-metadata-token: ${TOKEN}\\\" -s\"\n         INSTANCE_ID=$(curl $CURL_FLAGS $INST_MD/instance-id)\n         REGION=$(curl $CURL_FLAGS $INST_MD/placement/region)\n         JOB_ID=$(curl $CURL_FLAGS $INST_MD/tags/instance/JOB_ID)\n         export PATH=/opt/conda/envs/pytorch/bin/python:$PATH\n\n         # download and unpack code\n         aws s3 cp s3://my-s3-path/$JOB_ID/my-code.tar .\n         tar -xvf my-code.tar\n\n         # configure cloudwatch\n         sed -i \"s/job-id/${JOB_ID}/g\" cw_config.json\n         /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \\\n                  -a fetch-config -m ec2 -c file:cw_config.json -s\n\n         # install dependencies\n         python3 -m pip install -r requirements.txt 2>&1 | tee -a output.log\n\n         # run training workload\n         python3 train.py 2>&1 | tee -a output.log\n\n         # sync output artifacts\n         aws s3 sync artifacts s3://my-s3-path/$JOB_ID/artifacts\n\n         # self-destruct\n         aws ec2 terminate-instances --instance-ids $INSTANCE_ID \\\n                                     --region $REGION\n         \"\"\"\n```", "```py\naws ec2 create-placement-group --group-name cluster-placement-group \\\n    --strategy cluster\n```", "```py\nimport os, ast, socket\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef mp_fn(local_rank, *args):\n    # discover topology settings\n    num_nodes = int(os.environ.get('NUM_NODES',1))\n    node_rank = int(os.environ.get('NODE_RANK',0))\n    gpus_per_node = torch.cuda.device_count()\n    world_size = num_nodes * gpus_per_node\n    node_rank = nodes.index(socket.gethostname())\n    global_rank = (node_rank * gpus_per_node) + local_rank\n    print(f'local rank {local_rank} '\n          f'global rank {global_rank} '\n          f'world size {world_size}')\n    # init_process_group assumes the existence of MASTER_ADDR\n    # and MASTER_PORT environment variables\n    dist.init_process_group(backend='nccl',\n                            rank=global_rank, \n                            world_size=world_size)\n    torch.cuda.set_device(local_rank)\n    # Add training logic\n\nif __name__ == '__main__':\n    mp.spawn(mp_fn,\n             args=(),\n             nprocs=torch.cuda.device_count())\n```", "```py\nimport boto3\n\nregion = 'us-east-1'\njob_id = 'my-multinode-experiment' # replace with unique id\nnum_instances = 4\nimage_id = 'ami-0240b7264c1c9e6a9' # replace with image of choice\ninstance_type = 'g5.xlarge' # replace with instance of choice\ninstance_profile_arn = 'instance-profile-arn' # replace with profile arn\nplacement_group = 'cluster-placement-group' # replace with placement group\n\nec2 = boto3.resource('ec2', region_name=region)\n\nscript = \"\"\"#!/bin/bash\n         # environment setup\n         TOKEN=$(curl -s -X PUT \"http://169.254.169.254/latest/api/token\" -H \\\n                              \"X-aws-ec2-metadata-token-ttl-seconds: 21600\")\n         INST_MD=http://169.254.169.254/latest/meta-data\n         CURL_FLAGS=\"-H \\\"X-aws-ec2-metadata-token: ${TOKEN}\\\" -s\"\n         INSTANCE_ID=$(curl $CURL_FLAGS $INST_MD/instance-id)\n         REGION=$(curl $CURL_FLAGS $INST_MD/placement/region)\n         JOB_ID=$(curl $CURL_FLAGS $INST_MD/tags/instance/JOB_ID)\n         export NODE_RANK=$(curl $CURL_FLAGS $INST_MD/ami-launch-index)\n         export NUM_NODES=$(curl $CURL_FLAGS $INST_MD/NUM_NODES)\n         export MASTER_PORT=$(curl $CURL_FLAGS $INST_MD/tags/instance/MASTER_PORT)\n         export PATH=/opt/conda/envs/pytorch/bin/python:$PATH         \n\n         # download and unpack code\n         aws s3 cp s3://my-s3-path/$JOB_ID/my-code.tar .\n         tar -xvf my-code.tar\n\n         # configure cloudwatch\n         sed -i \"s/job-id/${JOB_ID}_${NODE_RANK}/g\" cw_config.json\n         /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \\\n                  -a fetch-config -m ec2 -c file:cw_config.json -s\n\n         # install dependencies\n         python3 -m pip install -r requirements.txt 2>&1 | tee -a output.log\n\n         # retrieve master address\n         # should be available but just in case tag application is delayed...\n         while true; do\n           export MASTER_ADDR=$(curl $CURL_FLAGS $INST_MD/tags/instance/MASTER_ADDR)\n           if [[ $MASTER_ADDR == \"<?xml\"* ]]; then\n             echo 'tags missing, sleep for 5 seconds' 2>&1 | tee -a output.log\n             sleep 5\n           else\n             break\n           fi\n         done\n\n         # run training workload\n         python3 train.py 2>&1 | tee -a output.log\n\n         # sync output artifacts\n         aws s3 sync artifacts s3://my-s3-path/$JOB_ID/artifacts\n\n         # self-destruct\n         aws ec2 terminate-instances --instance-ids $INSTANCE_ID \\\n                                     --region $REGION\n         \"\"\"\n\ninstances = ec2.create_instances(\n    MaxCount=num_instances,\n    MinCount=num_instances,\n    ImageId=image_id,\n    InstanceType=instance_type,\n    IamInstanceProfile={'Arn':instance_profile_arn},\n    UserData=script,\n    MetadataOptions={\"InstanceMetadataTags\":\"enabled\"},\n    TagSpecifications=[{\n        'ResourceType': 'instance',\n        'Tags': [\n            {'Key': 'NAME', 'Value': 'test-vm'},\n            {'Key': 'JOB_ID', 'Value': f'{job_id}'},\n            {'Key': 'MASTER_PORT', 'Value': '7777'},\n            {'Key': 'NUM_NODES', 'Value': f'{num_instances}'}\n        ]\n    }],\n    Placement={'GroupName': placement_group}\n)\n\nif num_instances > 1:\n\n    # find master_addr\n    for inst in instances:\n        if inst.ami_launch_index == 0:\n            master_addr = inst.network_interfaces_attribute[0]['PrivateIpAddress']\n            break\n\n    # update ec2 tags\n    for inst in instances:\n        res = ec2.create_tags(\n            Resources=[inst.id],\n            Tags=[\n                {'Key': 'NAME', 'Value': f'test-vm-{inst.ami_launch_index}'},\n                {'Key': 'MASTER_ADDR', 'Value': f'{master_addr}'}]\n        )\n```", "```py\nimport boto3\n\nregion = 'us-east-1'\njob_id = 'my-spot-experiment' # replace with unique id\nnum_instances = 1\nimage_id = 'ami-0240b7264c1c9e6a9' # replace with image of choice\ninstance_type = 'g5.xlarge' # replace with instance of choice\ninstance_profile_arn = 'instance-profile-arn' # replace with profile arn\nplacement_group = 'cluster-placement-group' # replace with placement group\n\ninstances = ec2.create_instances(\n    MaxCount=num_instances,\n    MinCount=num_instances,\n    ImageId=image_id,\n    InstanceType=instance_type,\n    IamInstanceProfile={'Arn':instance_profile_arn},\n    UserData=script,\n    MetadataOptions={\"InstanceMetadataTags\":\"enabled\"},\n    TagSpecifications=[{\n        'ResourceType': 'instance',\n        'Tags': [\n            {'Key': 'NAME', 'Value': 'test-vm'},\n            {'Key': 'JOB_ID', 'Value': f'{job_id}'},\n        ]\n    }],\n    InstanceMarketOptions = {\n        'MarketType': 'spot',\n        'SpotOptions': {\n            \"SpotInstanceType\": \"one-time\",\n            \"InstanceInterruptionBehavior\": \"terminate\"\n        }\n    }\n)\n```"]