- en: 'Building LLM Apps: A Clear Step-By-Step Guide'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建 LLM 应用：清晰的逐步指南
- en: 原文：[https://towardsdatascience.com/building-llm-apps-a-clear-step-by-step-guide-1fe1e6ef60fd?source=collection_archive---------0-----------------------#2024-06-10](https://towardsdatascience.com/building-llm-apps-a-clear-step-by-step-guide-1fe1e6ef60fd?source=collection_archive---------0-----------------------#2024-06-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-llm-apps-a-clear-step-by-step-guide-1fe1e6ef60fd?source=collection_archive---------0-----------------------#2024-06-10](https://towardsdatascience.com/building-llm-apps-a-clear-step-by-step-guide-1fe1e6ef60fd?source=collection_archive---------0-----------------------#2024-06-10)
- en: 'Comprehensive Steps for Building LLM-Native Apps: From Initial Idea to Experimentation,
    Evaluation, and Productization'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建 LLM 原生应用的全面步骤：从最初的构想到实验、评估和产品化
- en: '[](https://medium.com/@almogbaku?source=post_page---byline--1fe1e6ef60fd--------------------------------)[![Almog
    Baku](../Images/3ac36986f6ca0ba56c8edced6ec7dd07.png)](https://medium.com/@almogbaku?source=post_page---byline--1fe1e6ef60fd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1fe1e6ef60fd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1fe1e6ef60fd--------------------------------)
    [Almog Baku](https://medium.com/@almogbaku?source=post_page---byline--1fe1e6ef60fd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@almogbaku?source=post_page---byline--1fe1e6ef60fd--------------------------------)[![Almog
    Baku](../Images/3ac36986f6ca0ba56c8edced6ec7dd07.png)](https://medium.com/@almogbaku?source=post_page---byline--1fe1e6ef60fd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1fe1e6ef60fd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1fe1e6ef60fd--------------------------------)
    [Almog Baku](https://medium.com/@almogbaku?source=post_page---byline--1fe1e6ef60fd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1fe1e6ef60fd--------------------------------)
    ·12 min read·Jun 10, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1fe1e6ef60fd--------------------------------)
    ·12分钟阅读·2024年6月10日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Large Language Models (LLMs) are swiftly becoming a cornerstone of modern AI.
    Yet, there are **no established best practices**, and often, pioneers are left
    with **no clear roadmap**, needing to reinvent the wheel or getting stuck.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）正迅速成为现代人工智能的基石。然而，目前并**没有成熟的最佳实践**，而且许多先驱者常常面临**没有清晰路线图**的困境，不得不重新发明轮子，或者陷入困境。
- en: Over the past two years, I’ve helped organizations leverage LLMs to build innovative
    applications. Through this experience, I developed a ***battle-tested method***
    for creating innovative solutions (shaped by insights from the [LLM.org.il](https://llm.org.il)
    community), which I’ll share in this article.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的两年里，我帮助组织利用 LLM 构建创新应用。通过这些经验，我开发了一种***经受考验的方法***，用于创建创新解决方案（这些方法受到[LLM.org.il](https://llm.org.il)社区的见解影响），我将在本文中分享这些方法。
- en: This guide provides a *clear roadmap* for navigating the complex landscape of
    LLM-native development. You’ll learn how to move from ideation to experimentation,
    evaluation, and productization, unlocking your potential to create groundbreaking
    applications.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南提供了一个*清晰的路线图*，帮助你在 LLM 原生开发的复杂领域中找到前进的方向。你将学习如何从构思到实验、评估和产品化，释放你的潜力，创造开创性的应用。
- en: '![](../Images/36d91b22a5b41e77c6e555b9655839f9.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36d91b22a5b41e77c6e555b9655839f9.png)'
- en: (Created with Dall-E3)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: （由 Dall-E3 创建）
- en: Why a Standardized Process is Essential
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么标准化流程至关重要
- en: The LLM space is so dynamic that sometimes, we hear about new groundbreaking
    innovations day after day. This is quite exhilarating but also very chaotic —
    you may find yourself lost in the process, wondering what to do or how to bring
    your novel idea to life.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 领域变化如此之快，有时我们每天都会听到新的突破性创新。这虽然令人振奋，但也充满混乱——你可能会发现自己迷失在过程当中，不知道该做什么，或者如何将你的新创意付诸实践。
- en: Long story short, if you are an **AI Innovator** (a manager or a practitioner)
    who wants to build LLM-native apps effectively, **this is for you**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 长话短说，如果你是一个**AI 创新者**（无论是管理者还是从业者），想要有效地构建 LLM 原生应用，**这篇文章适合你**。
- en: 'Implementing a standardized process helps kick off new projects and offers
    several key benefits:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 实施标准化流程有助于启动新项目，并带来几个关键的好处：
- en: '**Standardize the process —** A standardized process helps align the team members
    and ensures a smooth new member onboarding process (especially in this chaos).'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**标准化流程 ——** 标准化流程有助于协调团队成员，确保顺利的新人入职过程（特别是在这种混乱中）。'
- en: '**Defines clear milestones** — A straightforward way to track your work, measure
    it, and make sure you''re on the right path'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义清晰的里程碑** —— 一种简单的方法来跟踪你的工作、衡量它并确保你走在正确的道路上。'
- en: '**Identify decision points** — LLM-native development is full of unknowns and
    "small experimentation" [see below]. Clear decision points make it easy to mitigate
    our risk and always stay lean with our development effort.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**确定决策点** —— LLM原生开发充满了未知和“小规模实验”[见下文]。明确的决策点使我们能够降低风险，并始终保持精益开发。'
- en: The Essential Skills of an LLM Engineer
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM工程师的必备技能
- en: 'Unlike any other established role in Software R&D, LLM-native development absolutely
    requires a new role: the **LLM Engineer** or the **AI Engineer.**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与软件研发中的任何其他既定角色不同，LLM原生开发绝对需要一个新的角色：**LLM工程师** 或 **AI工程师**。
- en: 'The LLM Engineer is a unique hybrid creature that involves skills from different
    (established) roles:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: LLM工程师是一个独特的混合型角色，涉及不同（既定）角色的技能：
- en: '**Software Engineering skills—**Like most SWEs, most of the work involves putting
    the Lego pieces together and gluing everything together.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软件工程技能——** 就像大多数软件工程师一样，大部分工作是将乐高积木拼凑在一起，并将所有东西粘合在一起。'
- en: '**Research skills** —Properly understanding the LLM-native experimental nature
    is ***essential.*** While building "cool demo apps" is pretty accessible, the
    distance between a "cool demo" and a practical solution requires experimentation
    and agility.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究技能** —— 正确理解LLM原生实验的性质是***至关重要的。*** 尽管构建“酷炫的演示应用”相对容易，但“酷炫演示”和实际解决方案之间的距离需要实验和敏捷性。'
- en: '**Deep business/product understanding —** Due to the fragility of the models,
    it''s essential to understand the business goals and procedures rather than sticking
    to the architecture we defined. The ability to model a manual process is a golden
    skill for LLM Engineers.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深入理解业务/产品——** 由于模型的脆弱性，理解业务目标和流程至关重要，而不是坚持我们定义的架构。能够建模手动流程是LLM工程师的金牌技能。'
- en: While writing this, LLM Engineering is still brand new, and **hiring can be
    very challenging**. It can be a good idea to look for candidates with a background
    in backend/data engineering or data science.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在写这篇文章时，LLM工程学仍然是全新的领域，**招聘可能非常具有挑战性**。寻找有后端/数据工程或数据科学背景的候选人可能是一个不错的主意。
- en: '*Software Engineers* might expect a *smoother transition*, as the experimentation
    process is much more "engineer-y" and not that "scientific" (compared to traditional
    data science work). That being said, I''ve seen many *Data Scientists* do this
    transition as well. As long as you''re okay with the fact that you''ll have to
    embrace new soft skills, you''re on the right path!'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*软件工程师* 可能会期望一个 *更平滑的过渡*，因为实验过程更加“工程化”，而不像传统的数据科学工作那样“科学”。话虽如此，我也见过许多*数据科学家*成功完成这个过渡。只要你能接受你必须拥抱新的软技能这一事实，你就走在了正确的道路上！'
- en: The Key Elements of LLM-Native Development
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM原生开发的关键要素
- en: Unlike classical backend apps (such as CRUD), there are no step-by-step recipes
    here. Like everything else in "AI," LLM-native apps require a **research and experimentation
    *mindset*.**
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的后端应用（如CRUD）不同，这里没有一步步的操作指南。像“AI”中的其他所有事物一样，LLM原生应用需要一个**研究和实验的*思维方式*。**
- en: To tame the beast, you must divide and conquer by splitting your work into smaller
    experiments, trying some of them, and selecting the most promising experiment.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要驯服这只野兽，你必须通过将工作拆分成更小的实验来实现分而治之，尝试其中一些实验，并选择最有前景的实验。
- en: I can't emphasize enough the importance of the *research mindset*.That means
    you might invest the time to explore a research vector and find out that it's
    "not possible," "not good enough," or "not worth it." That's totally okay — it
    means you're on the right track.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我无法强调*研究心态*的重要性。 这意味着你可能会投入时间去探索一个研究方向，结果发现它“不可行”、“不够好”或“不值得”。完全没关系——这意味着你在正确的轨道上。
- en: '![](../Images/d80576c3df986e4e82ba49558a9d3111.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d80576c3df986e4e82ba49558a9d3111.png)'
- en: Experimenting with LLMs is the only way to build LLM-native apps (and avoid
    the snakes in the way) (Created with Dall-E3)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 实验LLM是构建LLM原生应用的唯一途径（并且避免途中出现障碍）（由Dall-E3创建）
- en: 'Embracing Experimentation: The Heart of the Process'
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拥抱实验：过程的核心
- en: Sometimes, your "experiment" will fail, then you slightly pivot your work, and
    this other experiment succeeded much better.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你的“实验”会失败，然后你会稍微调整工作，结果另一个实验会成功得多。
- en: That's precisely why, *before* designing our endgame solution, we must start
    simple and hedge our risks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是为什么，在设计我们的终极解决方案之前，我们必须从简单开始并对我们的风险进行对冲。
- en: '**Define a "budget" or timeframe.** Let''s see what we can do in X weeks and
    then decide how or if to continue. Usually, 2–4 weeks to understand basic PoC
    will be sufficient. If it looks promising — continue investing resources to improve
    it.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义“预算”或时间框架。**我们看看在X周内能做些什么，然后决定是否继续。通常，2到4周的时间来理解基本的PoC就足够了。如果看起来有希望——继续投入资源以改善它。'
- en: '**Experiment—**Whether you choose a bottom-up or top-down approach for your
    experimentation phase, your goal is to maximize the result succession rate. By
    the end of the first experimentation iteration, you should have some PoC (that
    stakeholders can play with) and a baseline you achieved.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实验—**无论你在实验阶段选择自下而上还是自上而下的方法，你的目标是最大化结果成功率。在第一次实验迭代结束时，你应该拥有一些PoC（供利益相关者使用）以及你所取得的基准。'
- en: '**Retrospective —** By the end of our research phase, we can understand the
    feasibility, limitations, and cost of building such an app. This helps us decide
    whether to productionize it and how to design the final product and its UX.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**回顾—**在我们的研究阶段结束时，我们可以了解构建此类应用的可行性、局限性和成本。这有助于我们决定是否将其投入生产，并设计最终的产品及其用户体验。'
- en: '**Productization —** Develop a production-ready version of your project and
    integrate it with the rest of your solution by following standard SWE best practices
    and implementing a feedback and data collection mechanism.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**产品化—**开发项目的生产就绪版本，并通过遵循标准的软件工程最佳实践，将其与其他解决方案整合，实施反馈和数据收集机制。'
- en: '![](../Images/3584722390c58fe3144fc2d6496b099d.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3584722390c58fe3144fc2d6496b099d.png)'
- en: LLM-Native app development lifecycle (Image by author)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LLM原生应用开发生命周期（图示来自作者）
- en: 'To implement the experiment-oriented process well, we must make an informed
    decision on approaching and constructing these experiments:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地实现面向实验的过程，我们必须做出有根据的决定来接近并构建这些实验：
- en: 'Starting Lean: The Bottom-Up Approach'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精简起步：自下而上的方法
- en: While many early adopters quickly jump into" *State-Of-The-Art"* multichain
    agentic systems with full-fledged Langchain or something similar, I found "**The
    Bottom-Up approach**" often yields better results.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多早期采用者很快就跳入了*最先进的*多链条代理系统，像是完整的Langchain或类似的框架，但我发现**自下而上的方法**往往能取得更好的效果。
- en: Start lean, **very lean**, embracing the *“one prompt to rule them all”* philosophy.
    Although this strategy might seem unconventional and will likely produce bad results
    at first, it establishes a *baseline* for your system.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从精简开始，**非常精简**，拥抱*“一个提示统治一切”*的哲学。尽管这种策略看起来不太传统，并且一开始可能会产生不好的结果，但它为你的系统建立了一个*基准*。
- en: From there, continuously iterate and refine your prompts, employing prompt engineering
    techniques to optimize outcomes. As you identify weaknesses in your lean solution,
    split the process by adding branches to address those shortcomings.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里开始，持续迭代和优化你的提示，运用提示工程技术来优化结果。当你发现精简方案中的弱点时，通过添加分支来拆分过程，解决这些不足。
- en: While designing each "leaf" of my LLM workflow graph, or LLM-native architecture,
    I follow the[*LLM Triangle Principles*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)³
    to determine where and when to cut the branches, split them, or thicken the roots
    (by using prompt engineering techniques) and squeeze more of the lemon.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计我的LLM工作流图的每个“叶子”或LLM原生架构时，我遵循[*LLM三角原理*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)³来决定在哪些时候、以何种方式剪枝、分支或加粗根部（通过使用提示工程技术），并挤出更多的“柠檬汁”。
- en: '![](../Images/5201b05f41b5d4fed69473f9d53293e3.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5201b05f41b5d4fed69473f9d53293e3.png)'
- en: An illustration for the Bottom-Up approach (Image by author)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 自下而上的方法插图（图示来自作者）
- en: For example, to implement "Native language SQL querying" with the bottom-up
    approach, we'll start by naively sending the schemas to the LLM and ask it to
    generate a query.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要使用自下而上的方法实现“本地语言SQL查询”，我们将从直接向LLM发送模式并要求它生成查询开始。
- en: '![](../Images/1cc8092436c0a284cf6ca8b5914b78ad.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cc8092436c0a284cf6ca8b5914b78ad.png)'
- en: A Bottom-Up approach example (Image by author)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个自下而上的方法示例（图示来自作者）
- en: Usually, this does not contradict the "top-down approach" but serves as another
    step before it. This allows us to show quick wins and attract more project investment.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这并不与“自上而下的方法”相矛盾，而是作为它的另一个步骤。这使我们能够展示快速的胜利，并吸引更多项目投资。
- en: 'The Big Picture Upfront: The Top-Down Strategy'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全局视角：自上而下的策略
- en: “We know that LLM workflow is not easy, and to achieve our goal, we'll probably
    end up with some workflow or LLM-native architecture.”
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们知道 LLM 工作流并不容易，为了实现我们的目标，我们可能最终会采用某种工作流或 LLM 本地架构。”
- en: The Top-Down approach recognizes it and starts by designing the LLM-native architecture
    from day one and implementing its different steps/chains from the beginning.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 自上而下方法认识到这一点，并从第一天开始就设计 LLM 本地架构，并从一开始就实施其不同的步骤/链条。
- en: This way, you can test your workflow architecture as a whole and squeeze the
    whole lemon instead of refining each leaf separately.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，你可以测试整个工作流架构，而不是单独优化每一片叶子，真正做到榨干整个柠檬。
- en: '![](../Images/c45de8272f121dbc6dc5740d4459892f.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c45de8272f121dbc6dc5740d4459892f.png)'
- en: 'Top-down approach process: design your architecture once, implement, test &
    measure (Image by author)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 自上而下方法流程：一次性设计架构，实施、测试并衡量效果（图片由作者提供）
- en: 'For example, to implement "Native language SQL querying" with the top-down
    approach, we''ll start designing the architecture before even starting to code
    and then jump to the full implementation:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要实现“本地语言 SQL 查询”并采用自上而下的方法，我们会在开始编码之前先设计架构，然后再跳到完整实现：
- en: '![](../Images/59ca9496b40b497469678b254636bbcc.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59ca9496b40b497469678b254636bbcc.png)'
- en: An example of the Top-Down approach (Image by author)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 自上而下方法的一个例子（图片由作者提供）
- en: Finding the Right Balance
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 找到正确的平衡
- en: When you start experimenting with LLMs, you'll probably start at one of the
    extremes (overcomplicated top-down or super simple one-shot). In reality, there's
    no such a winner.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始尝试实验 LLM（大型语言模型）时，你可能会从两个极端中的一个开始（过于复杂的自上而下方法或超级简单的一次性方法）。实际上，并没有绝对的“赢家”。
- en: Ideally — you'll define a good SoP¹ and model an expert before coding and experimenting
    with the model. In reality, modeling is very hard; sometimes, you may not have
    access to such an expert.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下——你会在编码和实验模型之前，先定义好一个好的 SoP¹，并建模一个专家。但在现实中，建模非常困难，有时你可能没有接触到这样的专家。
- en: I found it challenging to land on a good architecture/SoP¹ at the first shot,
    so it's worth experimenting lightly before jumping to the big guns. However, it
    doesn't mean that *everything* has to be *too lean.* If you already have a *prior
    understanding* that something *MUST* be broken into smaller pieces — do that.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现要在第一次尝试时找到一个好的架构/SoP¹非常具有挑战性，因此在跳到更复杂的方案之前，轻微实验是值得的。然而，这并不意味着*一切*都必须*过于精简*。如果你已经有*先验理解*，知道某些东西*必须*被拆解成更小的部分——就去做。
- en: You should leverage the [*LLM Triangle Principles*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)³
    and correctly model the manual process while designing your solution.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该利用 [*LLM 三角原理*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)³，正确地建模手动过程，同时设计你的解决方案。
- en: 'Optimizing Your Solution: Squeezing the Lemon'
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化你的解决方案：榨干柠檬
- en: 'During the experimentation phase, we continuously squeeze the lemon and add
    more "layers of complexity":'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验阶段，我们不断地榨干柠檬并增加更多的“复杂性层次”：
- en: '[**Prompt engineering techniques**](https://www.promptingguide.ai/) — Like
    Few Shots, Role assignment, or even Dynamic few-shot'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**提示工程技术**](https://www.promptingguide.ai/)——如少量样本、角色分配，甚至是动态少量样本'
- en: '**Expanding the Context Window** from simple variable information to complex
    RAG flows can help improve the results.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展上下文窗口**，从简单的变量信息到复杂的 RAG 流程，可以帮助提高结果。'
- en: '**Experimenting with different models** — Different models perform differently
    on different tasks. Also, the large LLMs are often not very cost-effective, and
    it''s worth trying more task-specific models.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尝试不同的模型**——不同的模型在不同的任务上表现不同。此外，大型 LLM 往往不具备成本效益，因此值得尝试更多针对特定任务的模型。'
- en: '**Prompt dieting —** I learned that putting the SOP¹ (specifically, the prompt
    and the requested output) through a "diet" usually improves latency.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示精简**——我发现将 SOP¹（具体来说是提示和请求的输出）进行“精简”通常可以提高延迟。'
- en: By reducing the prompt size and the steps the model needs to go through, we
    can reduce both the input and output the model needs to generate. You'll be surprised,
    but prompt dieting can sometimes even improve the quality!
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过减少提示大小和模型需要经过的步骤，我们可以减少模型需要生成的输入和输出。你会感到惊讶，但有时候，提示精简甚至能提高质量！
- en: Be aware that the diet might also cause quality degradation, so it's important
    to set up a sanity test before doing so.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，饮食可能也会导致质量下降，因此在进行之前设置一个合理性测试非常重要。
- en: '**Splitting the process** into smaller steps can also be very beneficial and
    make optimizing a subprocess of your SOP¹ easier and feasible.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将过程分解**成更小的步骤也非常有利，并能使得优化 SOP¹ 中的子过程变得更容易且可行。'
- en: Be aware that this might increase the solution's complexity or damage the performance
    (e.g., increase the number of tokens processed). To mitigate this, aim for concise
    prompts and smaller models.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，这可能会增加解决方案的复杂性或影响性能（例如，增加处理的令牌数）。为了缓解这一点，尽量使用简洁的提示和更小的模型。
- en: As a rule of thumb, it's usually a good idea to split when a dramatic change
    of the System Prompt yields much better results for this part of the SOP¹ flow.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一般来说，当系统提示的剧烈变化能为 SOP¹ 流程的这一部分带来更好的结果时，分割是个不错的选择。
- en: '![](../Images/0ccb287ce6adee9c671ffc63e24be4ae.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ccb287ce6adee9c671ffc63e24be4ae.png)'
- en: Squeezing the AI Lemon (Created with Dall-E3)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 挤压 AI 柠檬（由 Dall-E3 创建）
- en: The Anatomy of an LLM Experiment
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 实验的解剖学
- en: 'Personally, I prefer to start *lean* with a simple Jupyter Notebook using Python,
    Pydantic, and Jinja2:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 就个人而言，我更倾向于使用一个简单的 Jupyter Notebook，结合 Python、Pydantic 和 Jinja2，*以轻量的方式*开始：
- en: '**Use Pydantic** to define my outputs'' schema from the model.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用 Pydantic** 定义模型输出的架构。'
- en: Write the **prompt template** with **Jinja2**.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 **Jinja2** 编写 **提示模板**。
- en: '**Define a structured output** format (in **YAML**²). This will ensure the
    model follows the "thinking steps" and is guided by my SOP.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义一个结构化输出**格式（使用 **YAML**²）。这将确保模型遵循“思考步骤”并遵循我的 SOP。'
- en: '**Ensure this output** with your Pydantic validations; if needed — retry.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**通过**你的 Pydantic 验证确保此输出；如果需要——请重试。'
- en: '**Stabilize your work** — structure your code into functional units with Python
    files and packages.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**稳定你的工作**——将代码结构化为功能单元，使用 Python 文件和包。'
- en: In a broader scope, you can use different tools such as [openai-streaming](https://github.com/AlmogBaku/openai-streaming)
    to easily **utilize streaming (and tools)**, [LiteLLM](https://docs.litellm.ai/docs/)
    to have a **standardized LLM SDK** across different providers, or [vLLM](https://docs.vllm.ai/)
    to **serve open-source LLMs.**
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 从更广泛的角度来看，你可以使用不同的工具，比如 [openai-streaming](https://github.com/AlmogBaku/openai-streaming)
    来轻松 **利用流式处理（和工具）**，[LiteLLM](https://docs.litellm.ai/docs/) 来拥有一个 **标准化的 LLM
    SDK**，适用于不同的提供商，或者 [vLLM](https://docs.vllm.ai/) 来 **提供开源 LLM 服务**。
- en: Ensuring Quality with Sanity Tests and Evaluations
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过健全性测试和评估确保质量
- en: A sanity test evaluates the quality of your project and ensures that you're
    not degrading a certain success rate baseline you defined.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一项健全性测试评估你的项目质量，并确保你没有降低已经定义的某个成功率基准。
- en: Think of your solution/prompts as a short blanket — if you stretch it too much,
    it might suddenly not cover some use cases it used to cover.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 把你的解决方案/提示想象成一条短毛毯——如果你把它拉得太长，它可能突然无法覆盖以前能够覆盖的某些用例。
- en: To do that, define a set of cases you have already covered successfully and
    ensure you keep it that way (or at least it's worth it). Thinking of it like a
    [table-driven test](https://lorenzopeppoloni.com/tabledriventestspy/) might help.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，定义一组你已经成功覆盖的案例，并确保它保持这样（或者至少值得这样做）。把它当作 [表驱动测试](https://lorenzopeppoloni.com/tabledriventestspy/)
    可能会有帮助。
- en: Evaluating the success of a "generative" solution(e.g., writing text) is much
    more complex than using LLMs for other tasks (such as categorization, entity extraction,
    etc.). For these kinds of tasks, you might want to involve a smarter model (such
    as GPT4, Claude Opus, or LLAMA3–70B) to act as a "judge."
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 评估“生成性”解决方案（例如，写文本）的成功比使用 LLM 处理其他任务（如分类、实体提取等）要复杂得多。对于这些任务，你可能需要引入更智能的模型（如
    GPT4、Claude Opus 或 LLAMA3–70B）作为“裁判”。
- en: 'It might also be a good idea to try and make the output include "deterministic
    parts" before the "generative" output, as these kinds of output are easier to
    test:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，尝试让输出先包含“确定性部分”，再输出“生成部分”可能是一个好主意，因为这类输出更容易进行测试：
- en: '[PRE0]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'There are a few cutting-edge,🤩🤩 promising solutions worth investigating. I
    found them especially relevant when evaluating RAG-based solutions: take a look
    at [DeepChecks](https://deepchecks.com/), [Ragas](https://github.com/explodinggradients/ragas),
    or [ArizeAI](https://arize.com/).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些前沿的、🤩🤩 有前景的解决方案值得探索。我发现它们在评估基于 RAG 的解决方案时尤其相关：可以看看 [DeepChecks](https://deepchecks.com/)、[Ragas](https://github.com/explodinggradients/ragas)
    或 [ArizeAI](https://arize.com/)。
- en: 'Making Informed Decisions: The Importance of Retrospectives'
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做出明智的决策：回顾的意义
- en: After each major/time-framed experiment or milestone, we should stop and make
    **an informed decision** on how and if to proceed with this approach.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次主要/定期实验或里程碑后，我们应该停下来并做出**明智的决策**，决定是否继续采用这种方法。
- en: At this point, your experiment will have a clear success rate baseline, and
    you'll have an idea of what needs to be improved.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您的实验将有一个明确的成功率基准，您也会了解需要改进的地方。
- en: 'This is also a good point to start discussing the productization implications
    of this solution and start with the "product work":'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的时机来开始讨论这个解决方案的产品化影响，并开始进行“产品工作”：
- en: What will this look like within the product?
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这在产品中会是什么样子？
- en: What are the limitations/challenges? How would you mitigate them?
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有哪些限制/挑战？您将如何应对？
- en: What’s your current latency? Is it good enough?
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目前的延迟是多少？够好吗？
- en: What should the UX be? Which UI hacks can you use? Can [streaming](https://github.com/AlmogBaku/openai-streaming)
    help?
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户体验应如何设计？可以使用哪些UI技巧？[流媒体](https://github.com/AlmogBaku/openai-streaming)能否有所帮助？
- en: What's the estimated spending on tokens? Can we use smaller models to reduce
    spending?
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预计的代币消耗是多少？我们能否使用更小的模型来减少消耗？
- en: What are priorities? Is any of the challenges a showstopper?
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优先级是什么？有哪些挑战是不可妥协的？
- en: Suppose the *baseline* we achieved is “good enough,” and we believe we can mitigate
    the problems we raised. In that case, we will continue investing in and improving
    the project while *ensuring it never degrades* and using the sanity tests.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们达成的*基准*“足够好”，并且我们相信可以解决提出的问题。在这种情况下，我们将继续投资并改善项目，同时*确保它永远不会退化*，并使用理智测试。
- en: '![](../Images/bacac79b87978cd360d070bb0f44464a.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bacac79b87978cd360d070bb0f44464a.png)'
- en: (Created with Dall-E3)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: （由Dall-E3创建）
- en: 'From Experiment to Product: Bringing Your Solution to Life'
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从实验到产品：让您的解决方案落地
- en: Last but not least, we have to productize our work. Like any other production-grade
    solution, we must implement production engineering concepts like logging, monitoring,
    dependency management, containerization, caching, etc.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我们必须将我们的工作产品化。像任何其他生产级解决方案一样，我们必须实现生产工程概念，如日志记录、监控、依赖管理、容器化、缓存等。
- en: This is a huge world, but luckily, we can borrow many mechanisms from classical
    production engineering and even adopt many of the existing tools.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个庞大的世界，但幸运的是，我们可以借用许多来自传统生产工程的机制，甚至采用许多现有的工具。
- en: 'That being said, it''s important to take extra care of the nuances involving
    LLM-native apps:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，在处理涉及LLM原生应用的细节时要特别小心：
- en: '**Feedback loop** — How do we measure success? Is it simply a "thumb up/down"
    mechanism or something more sophisticated that considers the adoption of our solution?'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈循环**—我们如何衡量成功？是仅仅一个“点赞/点踩”机制，还是更复杂的机制，考虑到我们解决方案的采用情况？'
- en: It is also important to collect this data; down the road, this can help us redefine
    our sanity "baseline" or fine-tune our results with [dynamic-few shots](https://arxiv.org/abs/1804.09458)
    or fine-tune the model.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 收集这些数据也很重要；在未来，这将帮助我们重新定义我们的理智“基准”或通过[动态少量样本](https://arxiv.org/abs/1804.09458)来微调结果，或微调模型。
- en: '**Caching** — Unlike traditional SWE, caching can be very challenging when
    we involve a generative aspect in our solution. To mitigate it, explore the option
    to cache similar results(e.g., using RAG) and/or reduce the generative output
    (by having a strict output schema)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓存**—与传统的软件工程不同，当我们在解决方案中引入生成性特征时，缓存可能会变得非常具有挑战性。为缓解这一问题，可以探索缓存相似结果（例如，使用RAG）和/或减少生成性输出（通过严格的输出架构）。'
- en: '**Cost tracking** — Many companies find it very tempting to start with a "strong
    model" (such as GPT-4 or Opus) however - in production, the costs can quickly
    rise. Avoid being surprised on the final bill, and make sure to measure the input/output
    tokens and keep track of your workflow impact (without these practices — good
    luck profiling it later on)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本跟踪**—许多公司发现，启动时使用“强大模型”（如GPT-4或Opus）非常有吸引力，然而——在生产中，成本可能迅速上升。避免在最终账单上感到惊讶，并确保衡量输入/输出代币并跟踪工作流的影响（如果没有这些做法——稍后再进行分析可能就会非常困难）'
- en: '**Debuggability and tracing** — Ensure you have set up the right tools to track
    a "buggy" input and track it throughout the process. This usually involves retaining
    the user input for later investigation and setting up [a tracing system](https://github.com/traceloop/openllmetry?tab=readme-ov-file).
    Remember: "Unlike traditional software, AI fails silently!"'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可调试性和追踪**——确保你已经设置好正确的工具，以追踪“有问题”的输入并贯穿整个过程。这通常涉及保存用户输入以供后续调查，并设置一个[追踪系统](https://github.com/traceloop/openllmetry?tab=readme-ov-file)。记住：“与传统软件不同，AI的失败是悄无声息的！”'
- en: 'Closing Remarks: Your Role in Advancing LLM-Native Technology'
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束语：你在推动LLM原生技术发展中的角色
- en: This might be the end of the article, but certainly not the end of our work.
    LLM-native development is an iterative process that covers more use cases, challenges,
    and features and continuously improves our LLM-native product.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是文章的结束，但肯定不是我们工作的终结。LLM原生开发是一个迭代过程，涉及更多的使用案例、挑战和功能，并不断改进我们的LLM原生产品。
- en: As you continue your AI development journey, stay agile, experiment fearlessly,
    and keep the end-user in mind. Share your experiences and insights with the community,
    and together, we can push the boundaries of what's possible with LLM-native apps.
    Keep exploring, learning, and building — the possibilities are endless.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在你继续进行AI开发之旅时，保持灵活，勇敢地进行实验，并始终关注最终用户。与社区分享你的经验和见解，让我们一起推动LLM原生应用的可能性边界。继续探索、学习和构建——无限的可能等待着你。
- en: I hope this guide has been a valuable companion on your LLM-native development
    journey! I'd love to hear your story — share your triumphs and challenges in the
    comments below. 💬
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这本指南在你进行LLM原生开发的过程中成为了一个有价值的伴侣！我很想听听你的故事——在下面的评论中分享你的成功与挑战吧。💬
- en: If you find this article helpful, please give it a few **claps** 👏 on Medium
    and **share** it with your fellow AI enthusiasts. Your support means the world
    to me! 🌍
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得这篇文章对你有帮助，请在Medium上给它点几个**掌声** 👏并**分享**给你的AI爱好者朋友们。你的支持对我意义重大！🌍
- en: Let's keep the conversation going — feel free to reach out via [email](mailto:almog.baku@gmail.com)
    or [connect on LinkedIn](https://www.linkedin.com/in/almogbaku/) 🤝
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续对话——随时通过[电子邮件](mailto:almog.baku@gmail.com)或[LinkedIn联系](https://www.linkedin.com/in/almogbaku/)
    🤝
- en: Special thanks to [Yonatan V. Levin](https://medium.com/u/8735065c2497?source=post_page---user_mention--1fe1e6ef60fd--------------------------------),
    [Gal Peretz](https://medium.com/u/532f8dc01db8?source=post_page---user_mention--1fe1e6ef60fd--------------------------------),
    [Philip Tannor](https://medium.com/u/5c5d2a69bcdb?source=post_page---user_mention--1fe1e6ef60fd--------------------------------),
    [Ori Cohen](https://medium.com/u/4dde5994e6c1?source=post_page---user_mention--1fe1e6ef60fd--------------------------------),
    [Nadav](https://medium.com/u/ed1905bd6262?source=post_page---user_mention--1fe1e6ef60fd--------------------------------),
    [Ben Huberman](https://medium.com/u/e6ad8abedec9?source=post_page---user_mention--1fe1e6ef60fd--------------------------------),
    [Carmel Barniv](https://medium.com/u/6374acbf3a05?source=post_page---user_mention--1fe1e6ef60fd--------------------------------),
    [Omri Allouche](https://medium.com/u/bf14cec4d697?source=post_page---user_mention--1fe1e6ef60fd--------------------------------),
    and [Liron Izhaki Allerhand](https://medium.com/u/251cd1007ce8?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)
    for insights, feedback, and editing notes.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢[Yonatan V. Levin](https://medium.com/u/8735065c2497?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)、[Gal
    Peretz](https://medium.com/u/532f8dc01db8?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)、[Philip
    Tannor](https://medium.com/u/5c5d2a69bcdb?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)、[Ori
    Cohen](https://medium.com/u/4dde5994e6c1?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)、[Nadav](https://medium.com/u/ed1905bd6262?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)、[Ben
    Huberman](https://medium.com/u/e6ad8abedec9?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)、[Carmel
    Barniv](https://medium.com/u/6374acbf3a05?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)、[Omri
    Allouche](https://medium.com/u/bf14cec4d697?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)
    和 [Liron Izhaki Allerhand](https://medium.com/u/251cd1007ce8?source=post_page---user_mention--1fe1e6ef60fd--------------------------------)提供的见解、反馈和编辑意见。
- en: '**¹SoP**- Standard operating procedure, a concept borrowed from [The *LLM Triangle
    Principles*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)³'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**¹SoP**——标准操作程序，这一概念来自于[《LLM三角原则》](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)³'
- en: '**²YAML**- I found that using YAML to structure your output works much better
    with LLMs. Why? My theory is that it reduces the non-relevant tokens and behaves
    much like the native language. This article dives deep into this subject.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**²YAML** - 我发现使用YAML来结构化输出对于LLM来说效果更好。为什么？我的理论是，它减少了不相关的标记，行为更像是原生语言。本文深入探讨了这个话题。'
- en: '**³**[**The LLM Triangle Principles**](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)-
    Software design principles for designing and building LLM-native apps; Update-
    the whitepaper recently published, [you can read it here](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**³**[**LLM三角原理**](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)
    - 用于设计和构建LLM原生应用的软设计原则；更新 - 最近发布的白皮书，[你可以在这里阅读](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)。'
