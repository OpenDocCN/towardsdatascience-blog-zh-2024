["```py\n# importing modules\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\ndef create_data(N, w):\n  \"\"\"\n  Creates a dataset with noise having a linear relationship with the target values.\n  N: number of samples\n  w: target values\n  \"\"\"\n  # Feature matrix with random data\n  X = np.random.rand(N, 1) * 10\n  # target values with noise normally distributed\n  y = w[0] * X + w[1] + np.random.randn(N, 1)\n  return X, y\n\n# Visualize the data\nX, y = create_data(200, [2, 1])\n\nplt.figure(figsize=(10, 6))\nplt.title('Simulated Linear Data')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.scatter(X, y)\nplt.show()\n```", "```py\ndef create_time_series(N, w):\n  \"\"\"\n  Creates a time series data with a linear trend and a seasonal component.\n  N: number of samples\n  w: target values\n  \"\"\"\n  # time values\n  time = np.arange(0,N)\n  # linear trend\n  trend = time * w[0]\n  # seasonal component\n  seasonal = np.sin(time * w[1])\n  # noise\n  noise = np.random.randn(N)\n  # target values\n  y = trend + seasonal + noise\n  return time, y\n\n# Visualize the data\ntime, y = create_time_series(100, [0.25, 0.2])\n\nplt.figure(figsize=(10, 6))\nplt.title('Simulated Time Series Data')\nplt.xlabel('Time')\nplt.ylabel('y')\n\nplt.plot(time, y)\nplt.show()\n```", "```py\n# create simulated data for analysis\nnp.random.seed(42)\n# Generate a low-dimensional signal\nlow_dim_data = np.random.randn(100, 3)\n\n# Create a random projection matrix to project into higher dimensions\nprojection_matrix = np.random.randn(3, 6)\n\n# Project the low-dimensional data to higher dimensions\nhigh_dim_data = np.dot(low_dim_data, projection_matrix)\n\n# Add some noise to the high-dimensional data\nnoise = np.random.normal(loc=0, scale=0.5, size=(100, 6))\ndata_with_noise = high_dim_data + noise\n\nX = data_with_noise\n```", "```py\nX, y = make_classification(n_samples=1000, n_features=5, n_classes=2)\n\n#Visualize the first rows of the synthetic dataset\nimport pandas as pd\ndf = pd.DataFrame(X, columns=['feature1', 'feature2', 'feature3', 'feature4', 'feature5'])\ndf['target'] = y\ndf.head()\n```", "```py\nfrom sklearn.datasets import make_regression\n\nX,y, coef = make_regression(n_samples=100, # number of observations\n                            n_features=1,  # number of features\n                            bias=10, # bias term\n                            noise=50, # noise level\n                            n_targets=1, # number of target values\n                            random_state=0, # random seed\n                            coef=True # return coefficients\n                            )\n```", "```py\nfrom sklearn.datasets import make_blobs\n\nX,y = make_blobs(n_samples=300, # number of observations\n                n_features=2, # number of features\n                centers=3, # number of clusters\n                cluster_std=0.5, # standard deviation of the clusters\n                random_state=0)\n```", "```py\nfrom scipy.stats import norm, binom, expon\n```", "```py\n# Normal Distribution\nnorm_data = norm.rvs(size=1000)\n```", "```py\n# Binomial distribution\nbinom_data = binom.rvs(n=50, p=0.8, size=1000)\n```", "```py\n# Exponential distribution\nexp_data = expon.rvs(scale=.2, size=10000)\n```", "```py\nfrom faker import Faker\n\ndef create_fake_data(N):\n  \"\"\"\n  Creates a dataset with fake data.\n  N: number of samples\n  \"\"\"\n  fake = Faker()\n  names = [fake.name() for _ in range(N)]\n  addresses = [fake.address() for _ in range(N)]\n  emails = [fake.email() for _ in range(N)]\n  phone_numbers = [fake.phone_number() for _ in range(N)]\n  fake_df = pd.DataFrame({'Name': names, 'Address': addresses, 'Email': emails, 'Phone Number': phone_numbers})\n  return fake_df\n\nfake_users = create_fake_data(100)\nfake_users.head()\n```", "```py\nfrom sdv.datasets.demo import download_demo\n\n# Load the 'adult' dataset\nadult_data, metadata = download_demo(dataset_name='adult', modality='single_table')\nadult_data.head()\n```", "```py\nfrom sdv.single_table import GaussianCopulaSynthesizer\n# Use GaussianCopulaSynthesizer to train on the data\nmodel = GaussianCopulaSynthesizer(metadata)\nmodel.fit(adult_data)\n\n# Generate Synthetic data\nsimulated_data = model.sample(100)\nsimulated_data.head()\n```"]