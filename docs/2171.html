<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Implement Graph RAG Using Knowledge Graphs and Vector Databases</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Implement Graph RAG Using Knowledge Graphs and Vector Databases</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759?source=collection_archive---------0-----------------------#2024-09-06">https://towardsdatascience.com/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759?source=collection_archive---------0-----------------------#2024-09-06</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="fr fs ft fu fv fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/bb57df531853e6ba435c6662113afbce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hrwv6zmmgogVNpQQlOIwIA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><div/><div><h2 id="6526" class="pw-subtitle-paragraph hh gj gk bf b hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw cq dx">A Step-by-Step Tutorial on Implementing Retrieval-Augmented Generation (RAG), Semantic Search, and Recommendations</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hx hy hz ia ib ab"><div><div class="ab ic"><div><div class="bm" aria-hidden="false"><a href="https://stevehedden.medium.com/?source=post_page---byline--60bb69a22759--------------------------------" rel="noopener follow"><div class="l id ie by if ig"><div class="l ed"><img alt="Steve Hedden" class="l ep by dd de cx" src="../Images/af7bec4a191ab857eccd885dd89e88b4.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*O80NSnmxNIhFhPEm9Kd0cA.png"/><div class="ih by l dd de em n ii eo"/></div></div></a></div></div><div class="ij ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--60bb69a22759--------------------------------" rel="noopener follow"><div class="l ik il by if im"><div class="l ed"><img alt="Towards Data Science" class="l ep by br in cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ih by l br in em n ii eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="io ab q"><div class="ab q ip"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b iq ir bk"><a class="af ag ah ai aj ak al am an ao ap aq ar is" data-testid="authorName" href="https://stevehedden.medium.com/?source=post_page---byline--60bb69a22759--------------------------------" rel="noopener follow">Steve Hedden</a></p></div></div></div><span class="it iu" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b iq ir dx"><button class="iv iw ah ai aj ak al am an ao ap aq ar ix iy iz" disabled="">Follow</button></p></div></div></span></div></div><div class="l ja"><span class="bf b bg z dx"><div class="ab cn jb jc jd"><div class="je jf ab"><div class="bf b bg z dx ab jg"><span class="jh l ja">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar is ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--60bb69a22759--------------------------------" rel="noopener follow"><p class="bf b bg z ji jj jk jl jm jn jo jp bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="it iu" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">39 min read</span><div class="jq jr l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 6, 2024</span></div></span></div></span></div></div></div><div class="ab cp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="h k w ea eb q"><div class="kx l"><div class="ab q ky kz"><div class="pw-multi-vote-icon ed jh la lb lc"><div class=""><div class="ld le lf lg lh li lj am lk ll lm lc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ln lo lp lq lr ls lt"><p class="bf b dy z dx"><span class="le">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ld lw lx ab q ee ly lz" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lv"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lu lv">18</span></p></button></div></div></div><div class="ab q ki kj kk kl km kn ko kp kq kr ks kt ku kv kw"><div class="ma k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al mb an ao ap ix mc md me" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep mf cn"><div class="l ae"><div class="ab cb"><div class="mg mh mi mj mk gb ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al mb an ao ap ix ml mm lz mn mo mp mq mr s ms mt mu mv mw mx my u mz na nb"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al mb an ao ap ix ml mm lz mn mo mp mq mr s ms mt mu mv mw mx my u mz na nb"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al mb an ao ap ix ml mm lz mn mo mp mq mr s ms mt mu mv mw mx my u mz na nb"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="f357" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">The accompanying code for this tutorial is </em><a class="af nz" href="https://github.com/SteveHedden/kg_llm" rel="noopener ugc nofollow" target="_blank"><em class="ny">here.</em></a></p><p id="dee8" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">My <a class="af nz" href="https://medium.com/towards-data-science/how-to-implement-knowledge-graphs-and-large-language-models-llms-together-at-the-enterprise-level-cf2835475c47" rel="noopener">last blog post</a> was about how to implement knowledge graphs (KGs) and Large Language Models (LLMs) together at the enterprise level. In that post, I went through the two ways KGs and LLMs are interacting right now: LLMs as tools to build KGs; and KGs as inputs into LLM or GenAI applications. The diagram below shows the two sides of integrations and the different ways people are using them together.</p><figure class="ob oc od oe of fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp oa"><img src="../Images/a8660e076ec5e3ba690aac08a47eceac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YU59GFNMi4Q0aOskrpx0Hw.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><p id="96a9" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this post, I will focus on one popular way KGs and LLMs are being used together: RAG using a knowledge graph, sometimes called <a class="af nz" href="https://www.ontotext.com/knowledgehub/fundamentals/what-is-graph-rag/" rel="noopener ugc nofollow" target="_blank">Graph RAG</a>, <a class="af nz" href="https://microsoft.github.io/graphrag/" rel="noopener ugc nofollow" target="_blank">GraphRAG</a>, <a class="af nz" href="https://arxiv.org/abs/2405.16506" rel="noopener ugc nofollow" target="_blank">GRAG</a>, or <a class="af nz" href="https://www.poolparty.biz/semantic-retrieval-augmented-generation" rel="noopener ugc nofollow" target="_blank">Semantic RAG</a>. Retrieval-Augmented Generation (RAG) is about <strong class="ne gl">retrieving</strong> relevant information to <strong class="ne gl">augment</strong> a prompt that is sent to an LLM, which <strong class="ne gl">generates</strong> a response. The idea is that, rather than sending your prompt directly to an LLM, which was not trained on your data, you can supplement your prompt with the relevant information needed for the LLM to answer your prompt accurately. The example I used in my previous post is copying a job description and my resume into ChatGPT to write a cover letter. The LLM is able to provide a much more relevant response to my prompt, ‘write me a cover letter,’ if I give it my resume and the description of the job I am applying for. Since knowledge graphs are built to store knowledge, they are a perfect way to store internal data and supplement LLM prompts with additional context, improving the accuracy and contextual understanding of the responses.</p><p id="eeb1" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">What is important, and I think often misunderstood, is that RAG and RAG using a KG (Graph RAG) are methodologies for combining technologies, not a product or technology themselves. No one invented, owns, or has a monopoly on Graph RAG. Most people can see the potential that these two technologies have when combined, however, and there are <a class="af nz" href="https://arxiv.org/pdf/2311.07509" rel="noopener ugc nofollow" target="_blank">more</a> and <a class="af nz" href="https://arxiv.org/pdf/2405.11706" rel="noopener ugc nofollow" target="_blank">more</a> studies proving the benefits of combining them.</p><p id="71f1" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Generally, there are three ways of using a KG for the retrieval part of RAG:</p><ol class=""><li id="9cfa" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx og oh oi bk"><strong class="ne gl">Vector-based retrieval:</strong> Vectorize your KG and store it in a vector database. If you then vectorize your natural language prompt, you can find vectors in the vector database that are most similar to your prompt. Since these vectors correspond to entities in your graph, you can return the most ‘relevant’ entities in the graph given a natural language prompt. <em class="ny">Note that you can do vector-based retrieval without a graph. That is actually the original way RAG was implemented, sometimes called Baseline RAG. You’d vectorize your SQL database or content and retrieve it at query time.</em></li><li id="35fd" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx og oh oi bk"><strong class="ne gl">Prompt-to-query retrieval:</strong> Use an LLM to write a SPARQL or Cypher query for you, use the query against your KG, and then use the returned results to augment your prompt.</li><li id="6627" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx og oh oi bk"><strong class="ne gl">Hybrid (vector + SPARQL): </strong>You can combine these two approaches in all kinds of interesting ways. In this tutorial, I will demonstrate some of the ways you can combine these methods. I will primarily focus on using vectorization for the initial retrieval and then SPARQL queries to refine the results.</li></ol><p id="f679" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There are, however, many ways of combining vector databases and KGs for search, similarity, and RAG. This is just an illustrative example to highlight the pros and cons of each individually and the benefits of using them together. The way I am using them together here — vectorization for initial retrieval and then SPARQL for filtering — is not unique. I have seen this implemented elsewhere. A good example I have heard anecdotally was from someone at a large furniture manufacturer. He said the vector database might recommend a lint brush to people buying couches, but the knowledge graph would understand materials, properties, and relationships and would ensure that the lint brush is not recommended to people buying leather couches.</p><p id="9294" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this tutorial I will:</p><ul class=""><li id="f92c" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk">Vectorize a dataset into a vector database to test semantic search, similarity search, and RAG <em class="ny">(vector-based retrieval)</em></li><li id="435a" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">Turn the data into a KG to test semantic search, similarity search, and RAG <em class="ny">(prompt-to-query retrieval, though really more like query retrieval since I’m just using SPARQL directly rather than having an LLM turn my natural language prompt into a SPARQL query)</em></li><li id="1741" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">Vectorize dataset with tags and URIs from the knowledge graph into a vector database (what I’ll refer to as a “vectorized knowledge graph”) and test semantic search, similarity, and RAG <em class="ny">(hybrid)</em></li></ul><p id="a98b" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The goal is to illustrate the differences between KGs and vector databases for these capabilities and to show some of the ways they can work together. Below is a high-level overview of how, together, vector databases and knowledge graphs can execute advanced queries.</p><figure class="ob oc od oe of fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/bb57df531853e6ba435c6662113afbce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hrwv6zmmgogVNpQQlOIwIA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><p id="5016" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If you don’t feel like reading any further, here is the TL;DR:</p><ul class=""><li id="adcf" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk">Vector databases can run semantic searches, similarity calculations and some basic forms of RAG pretty well with a few caveats. The first caveat is that the data I am using contains abstracts of journal articles, i.e. it has a good amount of unstructured text associated with it. Vectorization models are trained primarily on unstructured data and so perform well when given chunks of text associated with entities.</li><li id="a492" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">That being said, there is very little overhead in getting your data into a vector database and ready to be queried. If you have a dataset with some unstructured data in it, you can vectorize and start searching in 15 minutes.</li><li id="0ec3" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">Not surprisingly, one of the biggest drawbacks of using a vector database alone is the lack of explainability. The response might have three good results and one that doesn’t make much sense, and there is no way to know why that fourth result is there.</li><li id="52f4" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">The chance of unrelated content being returned by a vector database is a nuisance for search and similarity, but a huge problem for RAG. If you’re augmenting your prompt with four articles and one of them is about a completely unrelated topic, the response from the LLM is going to be misleading. This is often referred to as ‘context poisoning’.</li><li id="b85c" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">What is especially dangerous about context poisoning is that the response isn’t necessarily factually inaccurate, and it isn’t based on an inaccurate piece of data, it’s just using the wrong data to answer your question. The example I found in this tutorial is for the prompt, “therapies for mouth neoplasms.” One of the retrieved articles was about a study conducted on therapies for rectal cancer, which was sent to the LLM for summarization. I’m no doctor but I’m pretty sure the rectum’s not part of the mouth. The LLM accurately summarized the study and the effects of different therapy options on both mouth and rectal cancer, but didn’t always mention type of cancer. The user would therefore be unknowingly reading an LLM describe different treatment options for rectal cancer, after having asked the LLM to describe treatments for mouth cancer.</li><li id="bfba" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">The degree to which KGs can do semantic search and similarity search well is a function of the quality of your metadata and the controlled vocabularies the metadata connects to. In the example dataset in this tutorial, the journal articles have all been tagged already with topical terms. These terms are part of a rich controlled vocabulary, the <a class="af nz" href="https://www.ncbi.nlm.nih.gov/mesh/" rel="noopener ugc nofollow" target="_blank">Medical Subject Headings</a> (MeSH) from the National Institutes of Health. Because of that, we can do semantic search and similarity relatively easily out of the box.</li><li id="1c0e" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">There is likely some benefit of vectorizing a KG directly into a vector database to use as your knowledge base for RAG, but I didn’t do that for this tutorial. I just vectorized the data in tabular format but added a column for a URI for each article so I could connect the vectors back to the KG.</li><li id="1053" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">One of the biggest strengths of using a KG for semantic search, similarity, and RAG is in explainability. You can always explain why certain results were returned: they were tagged with certain concepts or had certain metadata properties.</li><li id="7557" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">Another benefit of the KG that I did not foresee is something sometimes called, “enhanced data enrichment” or “<a class="af nz" href="https://www.ontotext.com/knowledgehub/fundamentals/what-is-graph-rag/" rel="noopener ugc nofollow" target="_blank">graph as an expert</a>” — you can use the KG to expand or refine your search terms. For example, you can find similar terms, narrower terms, or terms related to your search term in specific ways, to expand or refine your query. For example, I might start with searching for “mouth cancer,” but based on my KG terms and relationships, refine my search to “gingival neoplasms and palatal neoplasms.”</li><li id="f8aa" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">One of the biggest obstacles to getting started with using a KG is that you need to build a KG. That being said, there are many ways to use LLMs to speed up the construction of a KG (figure 1 above).</li><li id="6443" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">One downside of using a KG alone is that you’ll need to write SPARQL queries to do everything. Hence the popularity of prompt-to-query retrieval described above.</li><li id="349c" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">The results from using Jaccard similarity on terms to find similar articles in the knowledge graph were poor. Without specification, the KG returned articles that had overlapping tags such as, “Aged”, “Male”, and “Humans”, that are probably not nearly as relevant as “Treatment Options” or “Mouth Neoplasms”.</li><li id="d5c6" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">Another issue I faced was that Jaccard similarity took forever (like 30 minutes) to run. I don’t know if there is a better way to do this (open to suggestions) but I am guessing that it is just very computationally intensive to find overlapping tags between an article and 9,999 other articles.</li><li id="1d07" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">Since the example prompts I used in this tutorial were something simple like ‘summarize these articles’ — the accuracy of the response from the LLM (for both the vector-based and KG-based retrieval methods) was much more dependent on the retrieval than the generation. What I mean is that as long as you give the LLM the relevant context, it is very unlikely that the LLM is going to mess up a simple prompt like ‘summarize’. This would be very different if our prompts were more complicated questions of course.</li><li id="f01e" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">Using the vector database for the initial search and then the KG for filtering provided the best results. This is somewhat obvious —you wouldn’t filter to get worse results. But that’s the point: it’s not that the KG necessarily improves results by itself, it’s that the KG provides you the ability to control the output to optimize your results.</li><li id="acba" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">Filtering results using the KG can improve the accuracy and relevancy based on the prompt, but it can also be used to customize results based on the person writing the prompt. For example, we may want to use similarity search to find similar articles to recommend to a user, but we’d only want to recommend articles that that person has access to. The KG allows for query-time access control.</li><li id="79e8" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">KGs can also help reduce the likelihood of context poisoning. In the RAG example above, we can search for ‘therapies for mouth neoplasms,’ in the vector database, but then filter for only articles that are tagged with mouth neoplasms (or related concepts).</li><li id="dd4f" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk">I only focused on a simple implementation in this tutorial where we sent the prompt directly to the vector database and then filter the results using the graph. There are far better ways of doing this. For example, you could extract entities from the prompt that align with your controlled vocabulary and enrich them (with synonyms and narrower terms) using the graph; you could parse the prompt into semantic chunks and send them separately to the vector database; you could turn the RDF data into text before vectorizing so the language model understands it better, etc. Those are topics for future blog posts.</li></ul><h1 id="35e6" class="op oq gk bf or os ot hk ou ov ow hn ox oy oz pa pb pc pd pe pf pg ph pi pj pk bk">Step 1: Vector-based retrieval</h1><p id="567e" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">The diagram below shows the plan at a high level. We want to vectorize the abstracts and titles from journal articles into a vector database to run different queries: semantic search, similarity search, and a simple version of RAG. For semantic search, we will test a term like ‘mouth neoplasms’ — the vector database should return articles relevant to this topic. For similarity search, we will use the ID of a given article to find its nearest neighbors in the vector space i.e. the articles most similar to this article. Finally, vector databases allow for a form of RAG where we can supplement a prompt like, “please explain this like you would to someone without a medical degree,” with an article.</p><figure class="ob oc od oe of fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pq"><img src="../Images/e466e1c2961bfa2db76099214cf93fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A5BGgck3oOUqtxyg8qwYeg.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><p id="e29b" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">I’ve decided to use <a class="af nz" href="https://www.kaggle.com/datasets/owaiskhan9654/pubmed-multilabel-text-classification" rel="noopener ugc nofollow" target="_blank">this</a> dataset of 50,000 research articles from the PubMed repository (License <a class="af nz" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank">CC0: Public Domain</a>). This dataset contains the title of the articles, their abstracts, as well as a field for metadata tags. These tags are from the Medical Subject Headings (MeSH) controlled vocabulary thesaurus. For the purposes of this part of the tutorial, we are only going to use the abstracts and the titles. This is because we are trying to compare a vector database with a knowledge graph and the strength of the vector database is in its ability to ‘understand’ unstructured data without rich metadata. I only used the top 10,000 rows of the data, just to make the calculations run faster.</p><p id="3a27" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><a class="af nz" href="https://weaviate.io/developers/weaviate/quickstart" rel="noopener ugc nofollow" target="_blank">Here</a> is Weaviate’s official quickstart tutorial. I also found <a class="af nz" rel="noopener" target="_blank" href="/getting-started-with-weaviate-a-beginners-guide-to-search-with-vector-databases-14bbb9285839">this</a> article helpful in getting started.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="1cda" class="pv oq gk ps b bg pw px l py pz">from weaviate.util import generate_uuid5<br/>import weaviate<br/>import json<br/>import pandas as pd<br/><br/>#Read in the pubmed data<br/>df = pd.read_csv("PubMed Multi Label Text Classification Dataset Processed.csv")</span></pre><p id="345d" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then we can establish a connection to our Weaviate cluster:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="317f" class="pv oq gk ps b bg pw px l py pz">client = weaviate.Client(<br/>    url = "XXX",  # Replace with your Weaviate endpoint<br/>    auth_client_secret=weaviate.auth.AuthApiKey(api_key="XXX"),  # Replace with your Weaviate instance API key<br/>    additional_headers = {<br/>        "X-OpenAI-Api-Key": "XXX"  # Replace with your inference API key<br/>    }<br/>)</span></pre><p id="8dee" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Before we vectorize the data into the vector database, we must define the schema. Here is where we define which columns from the csv we want to vectorize. As mentioned, for the purposes of this tutorial, to start, I only want to vectorize the title and abstract columns.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="2cf3" class="pv oq gk ps b bg pw px l py pz">class_obj = {<br/>    # Class definition<br/>    "class": "articles",<br/><br/>    # Property definitions<br/>    "properties": [<br/>        {<br/>            "name": "title",<br/>            "dataType": ["text"],<br/>        },<br/>        {<br/>            "name": "abstractText",<br/>            "dataType": ["text"],<br/>        },<br/>    ],<br/><br/>    # Specify a vectorizer<br/>    "vectorizer": "text2vec-openai",<br/><br/>    # Module settings<br/>    "moduleConfig": {<br/>        "text2vec-openai": {<br/>            "vectorizeClassName": True,<br/>            "model": "ada",<br/>            "modelVersion": "002",<br/>            "type": "text"<br/>        },<br/>        "qna-openai": {<br/>          "model": "gpt-3.5-turbo-instruct"<br/>        },<br/>        "generative-openai": {<br/>          "model": "gpt-3.5-turbo"<br/>        }<br/>    },<br/>}</span></pre><p id="a230" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then we push this schema to our Weaviate cluster:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="ef78" class="pv oq gk ps b bg pw px l py pz">client.schema.create_class(class_obj)</span></pre><p id="b0ec" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can check that this worked by looking directly in your Weaviate cluster.</p><p id="281e" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now that we have established the schema, we can write all of our data into the vector database.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="0246" class="pv oq gk ps b bg pw px l py pz">import logging<br/>import numpy as np<br/><br/># Configure logging<br/>logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')<br/><br/># Replace infinity values with NaN and then fill NaN values<br/>df.replace([np.inf, -np.inf], np.nan, inplace=True)<br/>df.fillna('', inplace=True)<br/><br/># Convert columns to string type<br/>df['Title'] = df['Title'].astype(str)<br/>df['abstractText'] = df['abstractText'].astype(str)<br/><br/># Log the data types<br/>logging.info(f"Title column type: {df['Title'].dtype}")<br/>logging.info(f"abstractText column type: {df['abstractText'].dtype}")<br/><br/>with client.batch(<br/>    batch_size=10,  # Specify batch size<br/>    num_workers=2,   # Parallelize the process<br/>) as batch:<br/>    for index, row in df.iterrows():<br/>        try:<br/>            question_object = {<br/>                "title": row.Title,<br/>                "abstractText": row.abstractText,<br/>            }<br/>            batch.add_data_object(<br/>                question_object,<br/>                class_name="articles",<br/>                uuid=generate_uuid5(question_object)<br/>            )<br/>        except Exception as e:<br/>            logging.error(f"Error processing row {index}: {e}")</span></pre><p id="ede2" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To check that the data went into the cluster, you can run this:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="225c" class="pv oq gk ps b bg pw px l py pz">client.query.aggregate("articles").with_meta_count().do()</span></pre><p id="c41c" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For some reason, only 9997 of my rows were vectorized. ¯\_(ツ)_/¯</p><h2 id="c62b" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">Semantic search using vector database</h2><p id="a542" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">When we talk about semantics in the vector database, we mean that the terms are vectorized into the vector space using the LLM API which has been trained on lots of unstructured content. This means that the vector takes the context of the terms into consideration. For example, if the term Mark Twain is mentioned many times near the term Samuel Clemens in the training data, the vectors for these two terms should be close to each other in the vector space. Likewise, if the term Mouth Cancer appears together with Mouth Neoplasms many times in the training data, we would expect the vector for an article about Mouth Cancer to be near an article about Mouth Neoplasms in the vector space.</p><p id="ae5b" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can check that it worked by running a simple query:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="3a6a" class="pv oq gk ps b bg pw px l py pz">response = (<br/>    client.query<br/>    .get("articles", ["title","abstractText"])<br/>    .with_additional(["id"])<br/>    .with_near_text({"concepts": ["Mouth Neoplasms"]})<br/>    .with_limit(10)<br/>    .do()<br/>)<br/><br/>print(json.dumps(response, indent=4))</span></pre><p id="6d07" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here are the results:</p><ul class=""><li id="1e0c" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 1:</strong> <em class="ny">“Gingival metastasis as first sign of multiorgan dissemination of epithelioid malignant mesothelioma.” </em>This article is about a study conducted on people who had malignant mesothelioma (a form of lung cancer) that spread to their gums. The study was to test the effects of different treatments (chemotherapy, decortication, and radiotherapy) on the cancer. This seems like an appropriate article to return — it is about gingival neoplasms, a subset of mouth neoplasms.</li><li id="17c2" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 2:</strong> <em class="ny">“Myoepithelioma of minor salivary gland origin. Light and electron microscopical study.” </em>This article is about a tumor that was removed from a 14-year-old boy’s gum, had spread to part of the upper jaw, and was composed of cells which originated in the salivary gland. This also seems like an appropriate article to return — it is about a neoplasm that was removed from a boy’s mouth.</li><li id="e6ae" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 3:</strong> <em class="ny">“Metastatic neuroblastoma in the mandible. Report of a case.” </em>This article is a case study of a 5-year-old boy who had cancer in his lower jaw. This is about cancer, but technically not mouth cancer — mandibular neoplasms (neoplasms in the lower jaw) are not a subset of mouth neoplasms.</li></ul><p id="a27b" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This is what we mean by semantic search — none of these articles have the word ‘mouth’ anywhere in their titles or abstracts. The first article is about gingival (gums) neoplasms, a subset of mouth neoplasms. The second article is about a gingival neoplasms that originated in the subject’s salivary gland, both subsets of mouth neoplasms. The third article is about mandibular neoplasms — which is, technically, according to the MeSH vocabulary <strong class="ne gl">not</strong> a subset of mouth neoplasms. Still, the vector database knew that a mandible is close to a mouth.</p><h2 id="3f7c" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">Similarity search using vector database</h2><p id="5d9b" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">We can also use the vector database to find similar articles. I chose an article that was returned using the mouth neoplasms query above titled,<em class="ny"> “Gingival metastasis as first sign of multiorgan dissemination of epithelioid malignant mesothelioma.” </em>Using the ID for that article, I can query the vector database for all similar entities:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="8567" class="pv oq gk ps b bg pw px l py pz">response = (<br/>    client.query<br/>    .get("articles", ["title", "abstractText"])<br/>    .with_near_object({<br/>        "id": "a7690f03-66b9-5d17-b765-8c6eb21f99c8" #id for a given article<br/>    })<br/>    .with_limit(10)<br/>    .with_additional(["distance"])<br/>    .do()<br/>)<br/><br/>print(json.dumps(response, indent=2))</span></pre><p id="01d5" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The results are ranked in order of similarity. Similarity is calculated as distance in the vector space. As you can see, the top result is the Gingival article — this article is the most similar article to itself.</p><p id="12c3" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The other articles are:</p><ul class=""><li id="797e" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 4</strong><em class="ny">: “Feasability study of screening for malignant lesions in the oral cavity targeting tobacco users.”</em> This is about mouth cancer, but about how to get tobacco smokers to sign up for screenings rather than on the ways they were treated.</li><li id="8a3d" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 5:</strong><em class="ny"> "Extended Pleurectomy and Decortication for Malignant Pleural Mesothelioma Is an Effective and Safe Cytoreductive Surgery in the Elderly." </em>This article is about a study on treating pleural mesothelioma (cancer in the lungs) with pleurectomy and decortication (surgery to remove cancer from the lungs) in the elderly. So this is similar in that it is about treatments for mesothelioma, but not about gingival neoplasms.</li><li id="f33c" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 3 (from above):</strong><em class="ny"> “Metastatic neuroblastoma in the mandible. Report of a case.” </em>Again, this is the article about the 5-year-old boy who had cancer in his lower jaw. This is about cancer, but technically not mouth cancer, and this is not really about treatment outcomes like the gingival article.</li></ul><p id="ad37" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">All of these articles, one could argue, are similar to our original gingival article. It is difficult to assess how similar they are and to therefore assess how well the similarity search performed because that is largely a matter of what the user means by similar. Were you interested in other articles about treatments for mesothelioma and the fact that the first article is about how it spread to the gums is irrelevant? In that case, <strong class="ne gl">Article 5 </strong>is the most similar. Or are you interested in reducing any type of mouth cancer, whether through treatment or prevention? In that case, <strong class="ne gl">Article 4 </strong>is the most similar. One drawback of the vector database, is that it is a black box — we have no idea why these articles were returned.</p><h2 id="5ff3" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">Retrieval-Augmented Generation (RAG) using a vector database</h2><p id="d5f4" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">Here is how you can use the vector database to retrieve results which are then sent to an LLM for summarization — an example of RAG.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="d90b" class="pv oq gk ps b bg pw px l py pz">response = (<br/>    client.query<br/>    .get("articles", ["title", "abstractText"])<br/>    .with_near_text({"concepts": ["Gingival metastasis as first sign of multiorgan dissemination of epithelioid malignant mesothelioma"]})<br/>    .with_generate(single_prompt="Please explain this article {title} like you would to someone without a medical degree.")<br/>    .with_limit(1)<br/>    .do()<br/>)<br/><br/>print(json.dumps(response, indent=4))</span></pre><p id="3f7b" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can see the response below:</p><blockquote class="qr qs qt"><p id="37e9" class="nc nd ny ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">"Sure! This article is talking about a case where a person had a type of cancer called epithelioid malignant mesothelioma. This cancer usually starts in the lining of the lungs or abdomen. However, in this case, the first sign of the cancer spreading to other parts of the body was seen in the gums (gingiva). This is called gingival metastasis.\n\nMetastasis means that cancer cells have spread from the original tumor to other parts of the body. In this case, the cancer had spread to the gums before spreading to other organs. This is important because it shows that the cancer was already advanced and had spread to multiple organs before it was even detected.\n\nOverall, this article highlights the importance of early detection and monitoring of cancer, as well as the potential for cancer to spread to unexpected parts of the body."</p></blockquote><p id="fab4" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">I am actually disappointed by this response. The abstract clearly explains that this is a study that follows 13 patients with metastatic malignant mesothelioma that underwent different treatments and the outcomes. The RAG output describes the article as about ‘a person’ and doesn’t mention the study at all.</p><p id="2a08" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Rather than just summarize one article, let’s try to summarize several. In this next example, we use the same search term as above (Mouth Neoplasms) and then send the top three articles along with a prompt, ‘Summarize the key information here in bullet points. Make it understandable to someone without a medical degree,’ to an LLM.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="e5c9" class="pv oq gk ps b bg pw px l py pz"><br/>response = (<br/>    client.query<br/>    .get(collection_name, ["title", "abstractText"])<br/>    .with_near_text({"concepts": ["Mouth Neoplasms"]})<br/>    .with_limit(3)<br/>    .with_generate(grouped_task="Summarize the key information here in bullet points. Make it understandable to someone without a medical degree.")<br/>    .do()<br/>)<br/><br/>print(response["data"]["Get"]["Articles"][0]["_additional"]["generate"]["groupedResult"])</span></pre><p id="63eb" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here are the results:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="6ee6" class="pv oq gk ps b bg pw px l py pz">- Metastatic malignant mesothelioma to the oral cavity is rare, with more cases in jaw bones than soft tissue<br/>- Average survival rate for this type of cancer is 9-12 months<br/>- Study of 13 patients who underwent neoadjuvant chemotherapy and surgery showed a median survival of 11 months<br/>- One patient had a gingival mass as the first sign of multiorgan recurrence of mesothelioma<br/>- Biopsy of new growing lesions, even in uncommon sites, is important for patients with a history of mesothelioma<br/>- Myoepithelioma of minor salivary gland origin can show features indicative of malignant potential<br/>- Metastatic neuroblastoma in the mandible is very rare and can present with osteolytic jaw defects and looseness of deciduous molars in children</span></pre><p id="8067" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This looks better to me than the previous response — it mentions the study conducted in <strong class="ne gl">Article 1</strong>, the treatments, and the outcomes. The second to last bullet is about the <em class="ny">“Myoepithelioma of minor salivary gland origin. Light and electron microscopical study,”</em> article and seems to be an accurate one line description. The final bullet is about <strong class="ne gl">Article 3 </strong>referenced above, and, again, seems to be an accurate one line description.</p><h1 id="2f7c" class="op oq gk bf or os ot hk ou ov ow hn ox oy oz pa pb pc pd pe pf pg ph pi pj pk bk">Step 2: use a knowledge graph for data retrieval</h1><p id="ca21" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">Here is a high-level overview of how we use a knowledge graph for semantic search, similarity search, and RAG:</p><figure class="ob oc od oe of fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qu"><img src="../Images/7625e519cdfa5e2d9290ba765ec43526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QXX1I1mB7B9VvtbML8eYjg.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><p id="4f54" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The first step of using a knowledge graph to retrieve your data is to turn your data into RDF format. The code below creates classes and properties for all of the data types, and then populates it with instances of articles and MeSH terms. I have also created properties for date published and access level and populated them with random values just as a demonstration.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="8c11" class="pv oq gk ps b bg pw px l py pz">from rdflib import Graph, RDF, RDFS, Namespace, URIRef, Literal<br/>from rdflib.namespace import SKOS, XSD<br/>import pandas as pd<br/>import urllib.parse<br/>import random<br/>from datetime import datetime, timedelta<br/><br/># Create a new RDF graph<br/>g = Graph()<br/><br/># Define namespaces<br/>schema = Namespace('http://schema.org/')<br/>ex = Namespace('http://example.org/')<br/>prefixes = {<br/>    'schema': schema,<br/>    'ex': ex,<br/>    'skos': SKOS,<br/>    'xsd': XSD<br/>}<br/>for p, ns in prefixes.items():<br/>    g.bind(p, ns)<br/><br/># Define classes and properties<br/>Article = URIRef(ex.Article)<br/>MeSHTerm = URIRef(ex.MeSHTerm)<br/>g.add((Article, RDF.type, RDFS.Class))<br/>g.add((MeSHTerm, RDF.type, RDFS.Class))<br/><br/>title = URIRef(schema.name)<br/>abstract = URIRef(schema.description)<br/>date_published = URIRef(schema.datePublished)<br/>access = URIRef(ex.access)<br/><br/>g.add((title, RDF.type, RDF.Property))<br/>g.add((abstract, RDF.type, RDF.Property))<br/>g.add((date_published, RDF.type, RDF.Property))<br/>g.add((access, RDF.type, RDF.Property))<br/><br/># Function to clean and parse MeSH terms<br/>def parse_mesh_terms(mesh_list):<br/>    if pd.isna(mesh_list):<br/>        return []<br/>    return [term.strip().replace(' ', '_') for term in mesh_list.strip("[]'").split(',')]<br/><br/># Function to create a valid URI<br/>def create_valid_uri(base_uri, text):<br/>    if pd.isna(text):<br/>        return None<br/>    sanitized_text = urllib.parse.quote(text.strip().replace(' ', '_').replace('"', '').replace('&lt;', '').replace('&gt;', '').replace("'", "_"))<br/>    return URIRef(f"{base_uri}/{sanitized_text}")<br/><br/># Function to generate a random date within the last 5 years<br/>def generate_random_date():<br/>    start_date = datetime.now() - timedelta(days=5*365)<br/>    random_days = random.randint(0, 5*365)<br/>    return start_date + timedelta(days=random_days)<br/><br/># Function to generate a random access value between 1 and 10<br/>def generate_random_access():<br/>    return random.randint(1, 10)<br/><br/># Load your DataFrame here<br/># df = pd.read_csv('your_data.csv')<br/><br/># Loop through each row in the DataFrame and create RDF triples<br/>for index, row in df.iterrows():<br/>    article_uri = create_valid_uri("http://example.org/article", row['Title'])<br/>    if article_uri is None:<br/>        continue<br/>    <br/>    # Add Article instance<br/>    g.add((article_uri, RDF.type, Article))<br/>    g.add((article_uri, title, Literal(row['Title'], datatype=XSD.string)))<br/>    g.add((article_uri, abstract, Literal(row['abstractText'], datatype=XSD.string)))<br/>    <br/>    # Add random datePublished and access<br/>    random_date = generate_random_date()<br/>    random_access = generate_random_access()<br/>    g.add((article_uri, date_published, Literal(random_date.date(), datatype=XSD.date)))<br/>    g.add((article_uri, access, Literal(random_access, datatype=XSD.integer)))<br/>    <br/>    # Add MeSH Terms<br/>    mesh_terms = parse_mesh_terms(row['meshMajor'])<br/>    for term in mesh_terms:<br/>        term_uri = create_valid_uri("http://example.org/mesh", term)<br/>        if term_uri is None:<br/>            continue<br/>        <br/>        # Add MeSH Term instance<br/>        g.add((term_uri, RDF.type, MeSHTerm))<br/>        g.add((term_uri, RDFS.label, Literal(term.replace('_', ' '), datatype=XSD.string)))<br/>        <br/>        # Link Article to MeSH Term<br/>        g.add((article_uri, schema.about, term_uri))<br/><br/># Serialize the graph to a file (optional)<br/>g.serialize(destination='ontology.ttl', format='turtle')</span></pre><h2 id="384f" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">Semantic search using a knowledge graph</h2><p id="524f" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">Now we can test semantic search. The word semantic is slightly different in the context of knowledge graphs, however. In the knowledge graph, we are relying on the tags associated with the documents and their relationships in the MeSH taxonomy for the semantics. For example, an article might be about Salivary Neoplasms (cancer in the salivary glands) but still be tagged with the term Mouth Neoplasms.</p><p id="d417" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Rather than query all articles tagged with Mouth Neoplasms, we will also look for any concept narrower than Mouth Neoplasms. The MeSH vocabulary contains definitions of terms but it also contains relationships like broader and narrower.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="8340" class="pv oq gk ps b bg pw px l py pz">from SPARQLWrapper import SPARQLWrapper, JSON<br/><br/>def get_concept_triples_for_term(term):<br/>    sparql = SPARQLWrapper("https://id.nlm.nih.gov/mesh/sparql")<br/>    query = f"""<br/>    PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;<br/>    PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;<br/>    PREFIX meshv: &lt;http://id.nlm.nih.gov/mesh/vocab#&gt;<br/>    PREFIX mesh: &lt;http://id.nlm.nih.gov/mesh/&gt;<br/><br/>    SELECT ?subject ?p ?pLabel ?o ?oLabel<br/>    FROM &lt;http://id.nlm.nih.gov/mesh&gt;<br/>    WHERE {{<br/>        ?subject rdfs:label "{term}"@en .<br/>        ?subject ?p ?o .<br/>        FILTER(CONTAINS(STR(?p), "concept"))<br/>        OPTIONAL {{ ?p rdfs:label ?pLabel . }}<br/>        OPTIONAL {{ ?o rdfs:label ?oLabel . }}<br/>    }}<br/>    """<br/>    <br/>    sparql.setQuery(query)<br/>    sparql.setReturnFormat(JSON)<br/>    results = sparql.query().convert()<br/>    <br/>    triples = set()  # Using a set to avoid duplicate entries<br/>    for result in results["results"]["bindings"]:<br/>        obj_label = result.get("oLabel", {}).get("value", "No label")<br/>        triples.add(obj_label)<br/>    <br/>    # Add the term itself to the list<br/>    triples.add(term)<br/>    <br/>    return list(triples)  # Convert back to a list for easier handling<br/><br/>def get_narrower_concepts_for_term(term):<br/>    sparql = SPARQLWrapper("https://id.nlm.nih.gov/mesh/sparql")<br/>    query = f"""<br/>    PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;<br/>    PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;<br/>    PREFIX meshv: &lt;http://id.nlm.nih.gov/mesh/vocab#&gt;<br/>    PREFIX mesh: &lt;http://id.nlm.nih.gov/mesh/&gt;<br/><br/>    SELECT ?narrowerConcept ?narrowerConceptLabel<br/>    WHERE {{<br/>        ?broaderConcept rdfs:label "{term}"@en .<br/>        ?narrowerConcept meshv:broaderDescriptor ?broaderConcept .<br/>        ?narrowerConcept rdfs:label ?narrowerConceptLabel .<br/>    }}<br/>    """<br/>    <br/>    sparql.setQuery(query)<br/>    sparql.setReturnFormat(JSON)<br/>    results = sparql.query().convert()<br/>    <br/>    concepts = set()  # Using a set to avoid duplicate entries<br/>    for result in results["results"]["bindings"]:<br/>        subject_label = result.get("narrowerConceptLabel", {}).get("value", "No label")<br/>        concepts.add(subject_label)<br/>    <br/>    return list(concepts)  # Convert back to a list for easier handling<br/><br/>def get_all_narrower_concepts(term, depth=2, current_depth=1):<br/>    # Create a dictionary to store the terms and their narrower concepts<br/>    all_concepts = {}<br/><br/>    # Initial fetch for the primary term<br/>    narrower_concepts = get_narrower_concepts_for_term(term)<br/>    all_concepts[term] = narrower_concepts<br/>    <br/>    # If the current depth is less than the desired depth, fetch narrower concepts recursively<br/>    if current_depth &lt; depth:<br/>        for concept in narrower_concepts:<br/>            # Recursive call to fetch narrower concepts for the current concept<br/>            child_concepts = get_all_narrower_concepts(concept, depth, current_depth + 1)<br/>            all_concepts.update(child_concepts)<br/>    <br/>    return all_concepts<br/><br/># Fetch alternative names and narrower concepts<br/>term = "Mouth Neoplasms"<br/>alternative_names = get_concept_triples_for_term(term)<br/>all_concepts = get_all_narrower_concepts(term, depth=2)  # Adjust depth as needed<br/><br/># Output alternative names<br/>print("Alternative names:", alternative_names)<br/>print()<br/><br/># Output narrower concepts<br/>for broader, narrower in all_concepts.items():<br/>    print(f"Broader concept: {broader}")<br/>    print(f"Narrower concepts: {narrower}")<br/>    print("---")</span></pre><p id="6aa5" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Below are all of the alternative names and narrower concepts for Mouth Neoplasms.</p><figure class="ob oc od oe of fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qv"><img src="../Images/1c30892d8e9629891ef3cf1da34f904c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DHKPKSShI9K6AFOX6COARA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><p id="ce13" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We turn this into a flat list of terms:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="fe94" class="pv oq gk ps b bg pw px l py pz">def flatten_concepts(concepts_dict):<br/>    flat_list = []<br/><br/>    def recurse_terms(term_dict):<br/>        for term, narrower_terms in term_dict.items():<br/>            flat_list.append(term)<br/>            if narrower_terms:<br/>                recurse_terms(dict.fromkeys(narrower_terms, []))  # Use an empty dict to recurse<br/>    <br/>    recurse_terms(concepts_dict)<br/>    return flat_list<br/><br/># Flatten the concepts dictionary<br/>flat_list = flatten_concepts(all_concepts)</span></pre><p id="c033" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then we turn the terms into MeSH URIs so we can incorporate them into our SPARQL query:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="1b6f" class="pv oq gk ps b bg pw px l py pz">#Convert the MeSH terms to URI<br/>def convert_to_mesh_uri(term):<br/>    formatted_term = term.replace(" ", "_").replace(",", "_").replace("-", "_")<br/>    return URIRef(f"http://example.org/mesh/_{formatted_term}_")<br/><br/><br/># Convert terms to URIs<br/>mesh_terms = [convert_to_mesh_uri(term) for term in flat_list]</span></pre><p id="fb2f" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then we write a SPARQL query to find all articles that are tagged with ‘Mouth Neoplasms’, its alternative name, ‘Cancer of Mouth,’ or any of the narrower terms:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="9687" class="pv oq gk ps b bg pw px l py pz">from rdflib import URIRef<br/><br/>query = """<br/>PREFIX schema: &lt;http://schema.org/&gt;<br/>PREFIX ex: &lt;http://example.org/&gt;<br/><br/>SELECT ?article ?title ?abstract ?datePublished ?access ?meshTerm<br/>WHERE {<br/>  ?article a ex:Article ;<br/>           schema:name ?title ;<br/>           schema:description ?abstract ;<br/>           schema:datePublished ?datePublished ;<br/>           ex:access ?access ;<br/>           schema:about ?meshTerm .<br/><br/>  ?meshTerm a ex:MeSHTerm .<br/>}<br/>"""<br/><br/># Dictionary to store articles and their associated MeSH terms<br/>article_data = {}<br/><br/># Run the query for each MeSH term<br/>for mesh_term in mesh_terms:<br/>    results = g.query(query, initBindings={'meshTerm': mesh_term})<br/><br/>    # Process results<br/>    for row in results:<br/>        article_uri = row['article']<br/><br/>        if article_uri not in article_data:<br/>            article_data[article_uri] = {<br/>                'title': row['title'],<br/>                'abstract': row['abstract'],<br/>                'datePublished': row['datePublished'],<br/>                'access': row['access'],<br/>                'meshTerms': set()<br/>            }<br/><br/>        # Add the MeSH term to the set for this article<br/>        article_data[article_uri]['meshTerms'].add(str(row['meshTerm']))<br/><br/># Rank articles by the number of matching MeSH terms<br/>ranked_articles = sorted(<br/>    article_data.items(),<br/>    key=lambda item: len(item[1]['meshTerms']),<br/>    reverse=True<br/>)<br/><br/># Get the top 3 articles<br/>top_3_articles = ranked_articles[:3]<br/><br/># Output results<br/>for article_uri, data in top_3_articles:<br/>    print(f"Title: {data['title']}")<br/>    print("MeSH Terms:")<br/>    for mesh_term in data['meshTerms']:<br/>        print(f"  - {mesh_term}")<br/>    print()</span></pre><p id="f1a2" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The articles returned are:</p><ul class=""><li id="ab1a" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 2 (from above):</strong> <em class="ny">“Myoepithelioma of minor salivary gland origin. Light and electron microscopical study.”</em></li><li id="b63f" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 4 (from above):</strong> “Feasability study of screening for malignant lesions in the oral cavity targeting tobacco users.”</li><li id="ff63" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 6:</strong> <em class="ny">“Association between expression of embryonic lethal abnormal vision-like protein HuR and cyclooxygenase-2 in oral squamous cell carcinoma.”</em> This article is about a study to determine whether the presence of a protein called HuR is linked to a higher level of cyclooxygenase-2, which plays a role in cancer development and the spread of cancer cells. Specifically, the study was focused on oral squamous cell carcinoma, a type of mouth cancer.</li></ul><p id="f3c7" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">These results are not dissimilar to what we got from the vector database. Each of these articles is about mouth neoplasms. What is nice about the knowledge graph approach is that we do get explainability — we know exactly why these articles were chosen. Article 2 is tagged with “Gingival Neoplasms”, and “Salivary Gland Neoplasms.” Articles 4 and 6 are both tagged with “Mouth Neoplasms.” Since Article 2 is tagged with 2 matching terms from our search terms, it is ranked highest.</p><h2 id="340d" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">Similarity search using a knowledge graph</h2><p id="9ae2" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">Rather than using a vector space to find similar articles, we can rely on the tags associated with articles. There are different ways of doing similarity using tags, but for this example, I will use a common method: Jaccard Similarity. We will use the gingival article again for comparison across methods.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="25cf" class="pv oq gk ps b bg pw px l py pz">from rdflib import Graph, URIRef<br/>from rdflib.namespace import RDF, RDFS, Namespace, SKOS<br/>import urllib.parse<br/><br/># Define namespaces<br/>schema = Namespace('http://schema.org/')<br/>ex = Namespace('http://example.org/')<br/>rdfs = Namespace('http://www.w3.org/2000/01/rdf-schema#')<br/><br/># Function to calculate Jaccard similarity and return overlapping terms<br/>def jaccard_similarity(set1, set2):<br/>    intersection = set1.intersection(set2)<br/>    union = set1.union(set2)<br/>    similarity = len(intersection) / len(union) if len(union) != 0 else 0<br/>    return similarity, intersection<br/><br/># Load the RDF graph<br/>g = Graph()<br/>g.parse('ontology.ttl', format='turtle')<br/><br/>def get_article_uri(title):<br/>    # Convert the title to a URI-safe string<br/>    safe_title = urllib.parse.quote(title.replace(" ", "_"))<br/>    return URIRef(f"http://example.org/article/{safe_title}")<br/><br/>def get_mesh_terms(article_uri):<br/>    query = """<br/>    PREFIX schema: &lt;http://schema.org/&gt;<br/>    PREFIX ex: &lt;http://example.org/&gt;<br/>    PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;<br/><br/>    SELECT ?meshTerm<br/>    WHERE {<br/>      ?article schema:about ?meshTerm .<br/>      ?meshTerm a ex:MeSHTerm .<br/>      FILTER (?article = &lt;""" + str(article_uri) + """&gt;)<br/>    }<br/>    """<br/>    results = g.query(query)<br/>    mesh_terms = {str(row['meshTerm']) for row in results}<br/>    return mesh_terms<br/><br/>def find_similar_articles(title):<br/>    article_uri = get_article_uri(title)<br/>    mesh_terms_given_article = get_mesh_terms(article_uri)<br/><br/>    # Query all articles and their MeSH terms<br/>    query = """<br/>    PREFIX schema: &lt;http://schema.org/&gt;<br/>    PREFIX ex: &lt;http://example.org/&gt;<br/>    PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;<br/><br/>    SELECT ?article ?meshTerm<br/>    WHERE {<br/>      ?article a ex:Article ;<br/>               schema:about ?meshTerm .<br/>      ?meshTerm a ex:MeSHTerm .<br/>    }<br/>    """<br/>    results = g.query(query)<br/><br/>    mesh_terms_other_articles = {}<br/>    for row in results:<br/>        article = str(row['article'])<br/>        mesh_term = str(row['meshTerm'])<br/>        if article not in mesh_terms_other_articles:<br/>            mesh_terms_other_articles[article] = set()<br/>        mesh_terms_other_articles[article].add(mesh_term)<br/><br/>    # Calculate Jaccard similarity<br/>    similarities = {}<br/>    overlapping_terms = {}<br/>    for article, mesh_terms in mesh_terms_other_articles.items():<br/>        if article != str(article_uri):<br/>            similarity, overlap = jaccard_similarity(mesh_terms_given_article, mesh_terms)<br/>            similarities[article] = similarity<br/>            overlapping_terms[article] = overlap<br/><br/>    # Sort by similarity and get top 5<br/>    top_similar_articles = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:15]<br/>    <br/>    # Print results<br/>    print(f"Top 15 articles similar to '{title}':")<br/>    for article, similarity in top_similar_articles:<br/>        print(f"Article URI: {article}")<br/>        print(f"Jaccard Similarity: {similarity:.4f}")<br/>        print(f"Overlapping MeSH Terms: {overlapping_terms[article]}")<br/>        print()<br/><br/># Example usage<br/>article_title = "Gingival metastasis as first sign of multiorgan dissemination of epithelioid malignant mesothelioma."<br/>find_similar_articles(article_title)</span></pre><p id="cf55" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The results are below. Since we are searching on the Gingival article again, that is the most similar article, which is what we would expect. The other results are:</p><ul class=""><li id="139a" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 7:</strong> <em class="ny">“Calcific tendinitis of the vastus lateralis muscle. A report of three cases.” </em>This article is about calcific tendinitis (calcium deposits forming in tendons) in the vastus lateralis muscle (a muscle in the thigh). This has nothing to do with mouth neoplasms.</li><li id="7605" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Overlapping terms:</strong> Tomography, Aged, Male, Humans, X-Ray computed</li><li id="1b7a" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 8:</strong> <em class="ny">“What is the optimal duration of androgen deprivation therapy in prostate cancer patients presenting with prostate specific antigen levels.” </em>This article is about how long prostate cancer patients should receive a specific treatment (androgen deprivataion therapy). This is about a treatment for cancer (radiotherapy), but not mouth cancer.</li><li id="32f3" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Overlapping terms:</strong> Radiotherapy, Aged, Male, Humans, Adjuvant</li><li id="9bd6" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 9:</strong> <em class="ny">CT scan cerebral hemisphere asymmetries: predictors of recovery from aphasia. </em>This article is about how differences between the left and right sides of the brain (cerebral hemisphere assymetries) might predict how well someone recovers from aphasia after a stroke.</li><li id="36a8" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Overlapping terms:</strong> Tomography, Aged, Male, Humans, X-Ray Computed</li></ul><p id="9587" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The best part of this method is that, because of the way we are calculating similarity here, we can see WHY the other articles are similar — we see exactly which terms are overlapping i.e. which terms are common on the Gingival article and each of the comparisons.</p><p id="f1ee" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The downside of explainability is that we can see that these do not seem like the most similar articles, given the previous results. They all have three terms in common (Aged, Male, and Humans) that are probably not nearly as relevant as Treatment Options or Mouth Neoplasms. You could re-calculate using some weight based on the prevalence of the term across the corpus — Term Frequency-Inverse Document Frequency (TF-IDF) — which would probably improve the results. You could also select the tagged terms that are most relevant for you when conducting similarity for more control over the results.</p><p id="3249" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The biggest downside of using Jaccard similarity on terms in a knowledge graph for calculating similarity is the computational efforts — it took like 30 minutes to run this one calculation.</p><h2 id="a792" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">RAG using a knowledge graph</h2><p id="b609" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">We can also do RAG using just the knowledge graph for the retrieval part. We already have a list of articles about mouth neoplasms saved as results from the semantic search above. To implement RAG, we just want to send these articles to an LLM and ask it to summarize the results.</p><p id="0e3f" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First we combine the titles and abstracts for each of the articles into one big chunk of text called combined_text:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="d871" class="pv oq gk ps b bg pw px l py pz"># Function to combine titles and abstracts<br/>def combine_abstracts(top_3_articles):<br/>    combined_text = "".join(<br/>        [f"Title: {data['title']} Abstract: {data['abstract']}" for article_uri, data in top_3_articles]<br/>    )<br/>    return combined_text<br/><br/># Combine abstracts from the top 3 articles<br/>combined_text = combine_abstracts(top_3_articles)<br/>print(combined_text)</span></pre><p id="5f01" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We then set up a client so that we can send this text directly to an LLM:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="478e" class="pv oq gk ps b bg pw px l py pz">import openai<br/><br/># Set up your OpenAI API key<br/>api_key = "YOUR API KEY"<br/>openai.api_key = api_key</span></pre><p id="e579" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then we give the context and the prompt to the LLM:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="2f47" class="pv oq gk ps b bg pw px l py pz">def generate_summary(combined_text):<br/>    response = openai.Completion.create(<br/>        model="gpt-3.5-turbo-instruct",<br/>        prompt=f"Summarize the key information here in bullet points. Make it understandable to someone without a medical degree:\n\n{combined_text}",<br/>        max_tokens=1000,<br/>        temperature=0.3<br/>    )<br/>    <br/>    # Get the raw text output<br/>    raw_summary = response.choices[0].text.strip()<br/>    <br/>    # Split the text into lines and clean up whitespace<br/>    lines = raw_summary.split('\n')<br/>    lines = [line.strip() for line in lines if line.strip()]<br/>    <br/>    # Join the lines back together with actual line breaks<br/>    formatted_summary = '\n'.join(lines)<br/>    <br/>    return formatted_summary<br/><br/># Generate and print the summary<br/>summary = generate_summary(combined_text)<br/>print(summary)</span></pre><p id="cba9" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The results look as follows:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="b6fb" class="pv oq gk ps b bg pw px l py pz">- A 14-year-old boy had a gingival tumor in his anterior maxilla that was removed and studied by light and electron microscopy<br/>- The tumor was made up of myoepithelial cells and appeared to be malignant<br/>- Electron microscopy showed that the tumor originated from a salivary gland<br/>- This is the only confirmed case of a myoepithelioma with features of malignancy<br/>- A feasibility study was conducted to improve early detection of oral cancer and premalignant lesions in a high incidence region<br/>- Tobacco vendors were involved in distributing flyers to invite smokers for free examinations by general practitioners<br/>- 93 patients were included in the study and 27% were referred to a specialist<br/>- 63.6% of those referred actually saw a specialist and 15.3% were confirmed to have a premalignant lesion<br/>- A study found a correlation between increased expression of the protein HuR and the enzyme COX-2 in oral squamous cell carcinoma (OSCC)<br/>- Cytoplasmic HuR expression was associated with COX-2 expression and lymph node and distant metastasis in OSCCs<br/>- Inhibition of HuR expression led to a decrease in COX-2 expression in oral cancer cells.</span></pre><p id="f591" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The results look good i.e. it is a good summary of the three articles that were returned from the semantic search. The quality of the response from a RAG application using a KG alone is a function of the ability of your KG to retrieve relevant documents. As seen in this example, if your prompt is simple enough, like, “summarize the key information here,” then the hard part is the retrieval (giving the LLM the correct articles as context), not in generating the response.</p><h1 id="4166" class="op oq gk bf or os ot hk ou ov ow hn ox oy oz pa pb pc pd pe pf pg ph pi pj pk bk">Step 3: use a vectorized knowledge graph to test data retrieval</h1><p id="bb06" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">Now we want to combine forces. We will add a URIs to each article in the database and then create a new collection in Weaviate where we vectorize the article name, abstract, the MeSH terms associated with it, as well as the URI. The URI is a unique identifier for the article and a way for us to connect back to the knowledge graph.</p><p id="8c36" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First we add a new column in the data for the URI:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="2647" class="pv oq gk ps b bg pw px l py pz"># Function to create a valid URI<br/>def create_valid_uri(base_uri, text):<br/>    if pd.isna(text):<br/>        return None<br/>    # Encode text to be used in URI<br/>    sanitized_text = urllib.parse.quote(text.strip().replace(' ', '_').replace('"', '').replace('&lt;', '').replace('&gt;', '').replace("'", "_"))<br/>    return URIRef(f"{base_uri}/{sanitized_text}")<br/><br/># Add a new column to the DataFrame for the article URIs<br/>df['Article_URI'] = df['Title'].apply(lambda title: create_valid_uri("http://example.org/article", title))<br/></span></pre><p id="d393" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now we create a new schema for the new collection with the additional fields:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="4371" class="pv oq gk ps b bg pw px l py pz">class_obj = {<br/>    # Class definition<br/>    "class": "articles_with_abstracts_and_URIs",<br/><br/>    # Property definitions<br/>    "properties": [<br/>        {<br/>            "name": "title",<br/>            "dataType": ["text"],<br/>        },<br/>        {<br/>            "name": "abstractText",<br/>            "dataType": ["text"],<br/>        },<br/>        {<br/>            "name": "meshMajor",<br/>            "dataType": ["text"],<br/>        },<br/>        {<br/>            "name": "Article_URI",<br/>            "dataType": ["text"],<br/>        },<br/>    ],<br/><br/>    # Specify a vectorizer<br/>    "vectorizer": "text2vec-openai",<br/><br/>    # Module settings<br/>    "moduleConfig": {<br/>        "text2vec-openai": {<br/>            "vectorizeClassName": True,<br/>            "model": "ada",<br/>            "modelVersion": "002",<br/>            "type": "text"<br/>        },<br/>        "qna-openai": {<br/>          "model": "gpt-3.5-turbo-instruct"<br/>        },<br/>        "generative-openai": {<br/>          "model": "gpt-3.5-turbo"<br/>        }<br/>    },<br/>}</span></pre><p id="324c" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Push that schema to the vector database:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="e99a" class="pv oq gk ps b bg pw px l py pz">client.schema.create_class(class_obj)</span></pre><p id="ab0f" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now we vectorize the data into the new collection:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="e75f" class="pv oq gk ps b bg pw px l py pz">import logging<br/>import numpy as np<br/><br/># Configure logging<br/>logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')<br/><br/># Replace infinity values with NaN and then fill NaN values<br/>df.replace([np.inf, -np.inf], np.nan, inplace=True)<br/>df.fillna('', inplace=True)<br/><br/># Convert columns to string type<br/>df['Title'] = df['Title'].astype(str)<br/>df['abstractText'] = df['abstractText'].astype(str)<br/>df['meshMajor'] = df['meshMajor'].astype(str)<br/>df['Article_URI'] = df['Article_URI'].astype(str)<br/><br/><br/># Log the data types<br/>logging.info(f"Title column type: {df['Title'].dtype}")<br/>logging.info(f"abstractText column type: {df['abstractText'].dtype}")<br/>logging.info(f"meshMajor column type: {df['meshMajor'].dtype}")<br/>logging.info(f"Article_URI column type: {df['Article_URI'].dtype}")<br/><br/><br/>with client.batch(<br/>    batch_size=10,  # Specify batch size<br/>    num_workers=2,   # Parallelize the process<br/>) as batch:<br/>    for index, row in df.iterrows():<br/>        try:<br/>            question_object = {<br/>                "title": row.Title,<br/>                "abstractText": row.abstractText,<br/>                "meshMajor": row.meshMajor,<br/>                "article_URI": row.Article_URI,<br/>            }<br/>            batch.add_data_object(<br/>                question_object,<br/>                class_name="articles_with_abstracts_and_URIs",<br/>                uuid=generate_uuid5(question_object)<br/>            )<br/>        except Exception as e:<br/>            logging.error(f"Error processing row {index}: {e}")</span></pre><h2 id="b630" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">Semantic search with a vectorized knowledge graph</h2><p id="a06c" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">Now we can do semantic search over the vector database, just like before, but with more explainability and control over the results.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="a0ec" class="pv oq gk ps b bg pw px l py pz">response = (<br/>    client.query<br/>    .get("articles_with_abstracts_and_URIs", ["title","abstractText","meshMajor","article_URI"])<br/>    .with_additional(["id"])<br/>    .with_near_text({"concepts": ["mouth neoplasms"]})<br/>    .with_limit(10)<br/>    .do()<br/>)<br/><br/>print(json.dumps(response, indent=4))</span></pre><p id="a0ab" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The results are:</p><ul class=""><li id="2592" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 1: </strong>"Gingival metastasis as first sign of multiorgan dissemination of epithelioid malignant mesothelioma."</li><li id="2df9" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 10:</strong> <em class="ny">"Angiocentric Centrofacial Lymphoma as a Challenging Diagnosis in an Elderly Man." </em>This article is about how it was challenging to diagnose a man with nasal cancer.</li><li id="468c" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 11:</strong> <em class="ny">"Mandibular pseudocarcinomatous hyperplasia."</em> This is a very hard article for me to decipher but I believe it is about how pseudocarcinomatous hyperplasia can look like cancer (hence the pseuo in the name), but that is non-cancerous. While it does seem to be about mandibles, it is tagged with the MeSH term “Mouth Neoplasms”.</li></ul><p id="402d" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It is hard to say whether these results are better or worse than the KG or the vector database alone. In theory, the results should be better because the MeSH terms associated with each article are now vectorized alongside the articles. We are not really vectorizing the knowledge graph, however. The relationships between the MeSH terms, for example, are not in the vector database.</p><p id="6faa" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">What is nice about having the MeSH terms vectorized is that there is some explainability right away — Article 11 is also tagged with Mouth Neoplasms, for example. But what is really cool about having the vector database connected to the knowledge graph is that we can apply any filters we want from the knowledge graph. Remember how we added in date published as a field in the data earlier? We can now filter on that. Suppose we want to find articles about mouth neoplasms published after May 1st, 2020:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="52ab" class="pv oq gk ps b bg pw px l py pz">from rdflib import Graph, Namespace, URIRef, Literal<br/>from rdflib.namespace import RDF, RDFS, XSD<br/><br/># Define namespaces<br/>schema = Namespace('http://schema.org/')<br/>ex = Namespace('http://example.org/')<br/>rdfs = Namespace('http://www.w3.org/2000/01/rdf-schema#')<br/>xsd = Namespace('http://www.w3.org/2001/XMLSchema#')<br/><br/>def get_articles_after_date(graph, article_uris, date_cutoff):<br/>    # Create a dictionary to store results for each URI<br/>    results_dict = {}<br/><br/>    # Define the SPARQL query using a list of article URIs and a date filter<br/>    uris_str = " ".join(f"&lt;{uri}&gt;" for uri in article_uris)<br/>    query = f"""<br/>    PREFIX schema: &lt;http://schema.org/&gt;<br/>    PREFIX ex: &lt;http://example.org/&gt;<br/>    PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;<br/>    PREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;<br/><br/>    SELECT ?article ?title ?datePublished<br/>    WHERE {{<br/>      VALUES ?article {{ {uris_str} }}<br/>      <br/>      ?article a ex:Article ;<br/>               schema:name ?title ;<br/>               schema:datePublished ?datePublished .<br/>      <br/>      FILTER (?datePublished &gt; "{date_cutoff}"^^xsd:date)<br/>    }}<br/>    """<br/>    <br/>    # Execute the query<br/>    results = graph.query(query)<br/>    <br/>    # Extract the details for each article<br/>    for row in results:<br/>        article_uri = str(row['article'])<br/>        results_dict[article_uri] = {<br/>            'title': str(row['title']),<br/>            'date_published': str(row['datePublished'])<br/>        }<br/>    <br/>    return results_dict<br/><br/>date_cutoff = "2023-01-01"<br/>articles_after_date = get_articles_after_date(g, article_uris, date_cutoff)<br/><br/># Output the results<br/>for uri, details in articles_after_date.items():<br/>    print(f"Article URI: {uri}")<br/>    print(f"Title: {details['title']}")<br/>    print(f"Date Published: {details['date_published']}")<br/>    print()</span></pre><p id="8a2a" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The originally query returned ten results (we gave it a max of ten) but only six of these were published after Jan 1st, 2023. See the results below:</p><figure class="ob oc od oe of fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qw"><img src="../Images/ada8d32d499aa914c3251e746b68c4c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0_GMd93pNKwb7mqCx5Jhcw.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><h2 id="fbb0" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">Similarity search using a vectorized knowledge graph</h2><p id="6101" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">We can run a similarity search on this new collection just like we did before on our gingival article (Article 1):</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="2cb0" class="pv oq gk ps b bg pw px l py pz">response = (<br/>    client.query<br/>    .get("articles_with_abstracts_and_URIs", ["title","abstractText","meshMajor","article_URI"])<br/>    .with_near_object({<br/>        "id": "37b695c4-5b80-5f44-a710-e84abb46bc22"<br/>    })<br/>    .with_limit(50)<br/>    .with_additional(["distance"])<br/>    .do()<br/>)<br/><br/>print(json.dumps(response, indent=2))</span></pre><p id="f4ce" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The results are below:</p><ul class=""><li id="8d37" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 3:</strong> <em class="ny">"Metastatic neuroblastoma in the mandible. Report of a case."</em></li><li id="3744" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 4:</strong> <em class="ny">“Feasability study of screening for malignant lesions in the oral cavity targeting tobacco users.”</em></li><li id="be9e" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 12:</strong> <em class="ny">“Diffuse intrapulmonary malignant mesothelioma masquerading as interstitial lung disease: a distinctive variant of mesothelioma.</em>” This article is about five male patients with a form of mesothelioma that looks a lot like another lung disease: interstitial lung disease.</li></ul><p id="b828" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Since we have the MeSH tagged vectorized, we can see the tags associated with each article. Some of them, while perhaps similar in some respects, are not about mouth neoplasms. Suppose we want to find articles similar to our gingival article, but specifically about mouth neoplasms. We can now combine the SPARQL filtering we did with the knowledge graph earlier on these results.</p><p id="4a3c" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The MeSH URIs for the synonyms and narrower concepts of Mouth Neoplasms is already saved, but do need the URIs for the 50 articles returned by the vector search:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="7c4c" class="pv oq gk ps b bg pw px l py pz"># Assuming response is the data structure with your articles<br/>article_uris = [URIRef(article["article_URI"]) for article in response["data"]["Get"]["Articles_with_abstracts_and_URIs"]]</span></pre><p id="cc82" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now we can rank the results based on the tags, just like we did before for semantic search using a knowledge graph.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="0a58" class="pv oq gk ps b bg pw px l py pz">from rdflib import URIRef<br/><br/># Constructing the SPARQL query with a FILTER for the article URIs<br/>query = """<br/>PREFIX schema: &lt;http://schema.org/&gt;<br/>PREFIX ex: &lt;http://example.org/&gt;<br/><br/>SELECT ?article ?title ?abstract ?datePublished ?access ?meshTerm<br/>WHERE {<br/>  ?article a ex:Article ;<br/>           schema:name ?title ;<br/>           schema:description ?abstract ;<br/>           schema:datePublished ?datePublished ;<br/>           ex:access ?access ;<br/>           schema:about ?meshTerm .<br/><br/>  ?meshTerm a ex:MeSHTerm .<br/><br/>  # Filter to include only articles from the list of URIs<br/>  FILTER (?article IN (%s))<br/>}<br/>"""<br/><br/><br/># Convert the list of URIRefs into a string suitable for SPARQL<br/>article_uris_string = ", ".join([f"&lt;{str(uri)}&gt;" for uri in article_uris])<br/><br/># Insert the article URIs into the query<br/>query = query % article_uris_string<br/><br/># Dictionary to store articles and their associated MeSH terms<br/>article_data = {}<br/><br/># Run the query for each MeSH term<br/>for mesh_term in mesh_terms:<br/>    results = g.query(query, initBindings={'meshTerm': mesh_term})<br/><br/>    # Process results<br/>    for row in results:<br/>        article_uri = row['article']<br/><br/>        if article_uri not in article_data:<br/>            article_data[article_uri] = {<br/>                'title': row['title'],<br/>                'abstract': row['abstract'],<br/>                'datePublished': row['datePublished'],<br/>                'access': row['access'],<br/>                'meshTerms': set()<br/>            }<br/><br/>        # Add the MeSH term to the set for this article<br/>        article_data[article_uri]['meshTerms'].add(str(row['meshTerm']))<br/><br/># Rank articles by the number of matching MeSH terms<br/>ranked_articles = sorted(<br/>    article_data.items(),<br/>    key=lambda item: len(item[1]['meshTerms']),<br/>    reverse=True<br/>)<br/><br/><br/># Output results<br/>for article_uri, data in ranked_articles:<br/>    print(f"Title: {data['title']}")<br/>    print(f"Abstract: {data['abstract']}")<br/>    print("MeSH Terms:")<br/>    for mesh_term in data['meshTerms']:<br/>        print(f"  - {mesh_term}")<br/>    print()</span></pre><p id="9c88" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Of the 50 articles originally returned by the vector database, only five of them are tagged with Mouth Neoplasms or a related concept.</p><ul class=""><li id="5e46" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 2:</strong> <em class="ny">“Myoepithelioma of minor salivary gland origin. Light and electron microscopical study.” </em>Tagged with: Gingival Neoplasms, Salivary Gland Neoplasms</li><li id="87e7" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 4:</strong> <em class="ny">“Feasability study of screening for malignant lesions in the oral cavity targeting tobacco users.” </em>Tagged with: Mouth Neoplasms</li><li id="512b" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 13:</strong> <em class="ny">“Epidermoid carcinoma originating from the gingival sulcus.”</em> This article describes a case of gum cancer (gingival neoplasms). Tagged with: Gingival Neoplasms</li><li id="a6ac" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 1: <em class="ny">“</em></strong><em class="ny">Gingival metastasis as first sign of multiorgan dissemination of epithelioid malignant mesothelioma.” </em>Tagged with: Gingival Neoplasms</li><li id="7507" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 14:</strong> <em class="ny">“Metastases to the parotid nodes: CT and MR imaging findings.” </em>This article is about neoplasms in the parotid glands, major salivary glands. Tagged with: Parotid Neoplasms</li></ul><p id="53d3" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Finally, suppose we want to serve these similar articles to a user as a recommendation, but we only want to recommend the articles that that user has access to. Suppose we know that this user can only access articles tagged with access levels 3, 5, and 7. We can apply a filter in our knowledge graph using a similar SPARQL query:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="8731" class="pv oq gk ps b bg pw px l py pz">from rdflib import Graph, Namespace, URIRef, Literal<br/>from rdflib.namespace import RDF, RDFS, XSD, SKOS<br/><br/># Assuming your RDF graph (g) is already loaded<br/><br/># Define namespaces<br/>schema = Namespace('http://schema.org/')<br/>ex = Namespace('http://example.org/')<br/>rdfs = Namespace('http://www.w3.org/2000/01/rdf-schema#')<br/><br/>def filter_articles_by_access(graph, article_uris, access_values):<br/>    # Construct the SPARQL query with a dynamic VALUES clause<br/>    uris_str = " ".join(f"&lt;{uri}&gt;" for uri in article_uris)<br/>    query = f"""<br/>    PREFIX schema: &lt;http://schema.org/&gt;<br/>    PREFIX ex: &lt;http://example.org/&gt;<br/>    PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;<br/><br/>    SELECT ?article ?title ?abstract ?datePublished ?access ?meshTermLabel<br/>    WHERE {{<br/>      VALUES ?article {{ {uris_str} }}<br/>      <br/>      ?article a ex:Article ;<br/>               schema:name ?title ;<br/>               schema:description ?abstract ;<br/>               schema:datePublished ?datePublished ;<br/>               ex:access ?access ;<br/>               schema:about ?meshTerm .<br/>      ?meshTerm rdfs:label ?meshTermLabel .<br/>      <br/>      FILTER (?access IN ({", ".join(map(str, access_values))}))<br/>    }}<br/>    """<br/>    <br/>    # Execute the query<br/>    results = graph.query(query)<br/>    <br/>    # Extract the details for each article<br/>    results_dict = {}<br/>    for row in results:<br/>        article_uri = str(row['article'])<br/>        if article_uri not in results_dict:<br/>            results_dict[article_uri] = {<br/>                'title': str(row['title']),<br/>                'abstract': str(row['abstract']),<br/>                'date_published': str(row['datePublished']),<br/>                'access': str(row['access']),<br/>                'mesh_terms': []<br/>            }<br/>        results_dict[article_uri]['mesh_terms'].append(str(row['meshTermLabel']))<br/>    <br/>    return results_dict<br/><br/>access_values = [3,5,7]<br/>filtered_articles = filter_articles_by_access(g, ranked_article_uris, access_values)<br/><br/># Output the results<br/>for uri, details in filtered_articles.items():<br/>    print(f"Article URI: {uri}")<br/>    print(f"Title: {details['title']}")<br/>    print(f"Abstract: {details['abstract']}")<br/>    print(f"Date Published: {details['date_published']}")<br/>    print(f"Access: {details['access']}")<br/>    print()</span></pre><p id="6c86" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There was one article that the user did not have access to. The four remaining articles are:</p><ul class=""><li id="da31" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 2:</strong> <em class="ny">“Myoepithelioma of minor salivary gland origin. Light and electron microscopical study.” </em>Tagged with: Gingival Neoplasms, Salivary Gland Neoplasms. Access level: 5</li><li id="0781" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 4:</strong> <em class="ny">“Feasability study of screening for malignant lesions in the oral cavity targeting tobacco users.” </em>Tagged with: Mouth Neoplasms. Access level: 7</li><li id="b292" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 1: <em class="ny">“</em></strong><em class="ny">Gingival metastasis as first sign of multiorgan dissemination of epithelioid malignant mesothelioma.” </em>Tagged with: Gingival Neoplasms. Access level: 3</li><li id="03c6" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 14:</strong> <em class="ny">“Metastases to the parotid nodes: CT and MR imaging findings.” </em>This article is about neoplasms in the parotid glands, major salivary glands. Tagged with: Parotid Neoplasms. Access level: 3</li></ul><h2 id="5384" class="qa oq gk bf or qb qc qd ou qe qf qg ox nl qh qi qj np qk ql qm nt qn qo qp qq bk">RAG with a vectorized knowledge graph</h2><p id="dc69" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">Finally, let’s see how RAG works once we combine a vector database with a knowledge graph. As a reminder, you can run RAG directly against the vector database and send it to an LLM to get a generated response:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="e054" class="pv oq gk ps b bg pw px l py pz">response = (<br/>    client.query<br/>    .get("Articles_with_abstracts_and_URIs", ["title", "abstractText",'article_URI','meshMajor'])<br/>    .with_near_text({"concepts": ["therapies for mouth neoplasms"]})<br/>    .with_limit(3)<br/>    .with_generate(grouped_task="Summarize the key information here in bullet points. Make it understandable to someone without a medical degree.")<br/>    .do()<br/>)<br/><br/>print(response["data"]["Get"]["Articles_with_abstracts_and_URIs"][0]["_additional"]["generate"]["groupedResult"])</span></pre><p id="9e1c" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this example, I am using the search term, ‘therapies for mouth neoplasms,’ with the same prompt, ‘Summarize the key information here in bullet points. Make it understandable to someone without a medical degree.’ We are only returning the top three articles to generate this response. Here are the results:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="577c" class="pv oq gk ps b bg pw px l py pz">- Metastatic malignant mesothelioma to the oral cavity is rare, with an average survival rate of 9-12 months.<br/>- Neoadjuvant chemotherapy and radical pleurectomy decortication followed by radiotherapy were used in 13 patients from August 2012 to September 2013.<br/>- In January 2014, 11 patients were still alive with a median survival of 11 months, while 8 patients had a recurrence and 2 patients died at 8 and 9 months after surgery.<br/>- A 68-year-old man had a gingival mass that turned out to be a metastatic deposit of malignant mesothelioma, leading to multiorgan recurrence.<br/>- Biopsy is important for new growing lesions, even in uncommon sites, when there is a history of mesothelioma.<br/><br/>- Neoadjuvant radiochemotherapy for locally advanced rectal carcinoma can be effective, but some patients may not respond well.<br/>- Genetic alterations may be associated with sensitivity or resistance to neoadjuvant therapy in rectal cancer.<br/>- Losses of chromosomes 1p, 8p, 17p, and 18q, and gains of 1q and 13q were found in rectal cancer tumors.<br/>- Alterations in specific chromosomal regions were associated with the response to neoadjuvant therapy.<br/>- The cytogenetic profile of tumor cells may influence the response to radiochemotherapy in rectal cancer.<br/><br/>- Intensity-modulated radiation therapy for nasopharyngeal carcinoma achieved good long-term outcomes in terms of local control and overall survival.<br/>- Acute toxicities included mucositis, dermatitis, and xerostomia, with most patients experiencing Grade 0-2 toxicities.<br/>- Late toxicity mainly included xerostomia, which improved over time.<br/>- Distant metastasis remained the main cause of treatment failure, highlighting the need for more effective systemic therapy.</span></pre><p id="78a5" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As a test, we can see exactly which three articles were chosen:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="4c56" class="pv oq gk ps b bg pw px l py pz"># Extract article URIs<br/>article_uris = [article["article_URI"] for article in response["data"]["Get"]["Articles_with_abstracts_and_URIs"]]<br/><br/># Function to filter the response for only the given URIs<br/>def filter_articles_by_uri(response, article_uris):<br/>    filtered_articles = []<br/>    <br/>    articles = response['data']['Get']['Articles_with_abstracts_and_URIs']<br/>    for article in articles:<br/>        if article['article_URI'] in article_uris:<br/>            filtered_articles.append(article)<br/>    <br/>    return filtered_articles<br/><br/># Filter the response<br/>filtered_articles = filter_articles_by_uri(response, article_uris)<br/><br/># Output the filtered articles<br/>print("Filtered articles:")<br/>for article in filtered_articles:<br/>    print(f"Title: {article['title']}")<br/>    print(f"URI: {article['article_URI']}")<br/>    print(f"Abstract: {article['abstractText']}")<br/>    print(f"MeshMajor: {article['meshMajor']}")<br/>    print("---")</span></pre><p id="6dec" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Interestingly, the first article is about gingival neoplasms, which is a subset of mouth neoplasms, but the second article is about rectal cancer, and the third is about nasopharyngeal cancer. They are about therapies for cancers, just not the kind of cancer I searched for. What is concerning is that the prompt was, “therapies for mouth neoplasms” and the results contain information about therapies for other kinds of cancer. This is what is sometimes called ‘context poisoning’ — irrelevant or misleading information is getting injected into the prompt which leads to misleading responses from the LLM.</p><p id="1b0b" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can use the KG to address the context poisoning. Here is a diagram of how the vector database and the KG can work together for a better RAG implementation:</p><figure class="ob oc od oe of fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qx"><img src="../Images/0d64f10c44a2ffa30daa4a207c094e12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vsHgGlGo8GJeq8SH8iUa0w.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><p id="a3d3" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First, we run a semantic search on the vector database using the same prompt: therapies for mouth cancer. I’ve upped the limit to 20 articles this time since we are going to filter some out.</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="c0c4" class="pv oq gk ps b bg pw px l py pz">response = (<br/>    client.query<br/>    .get("articles_with_abstracts_and_URIs", ["title", "abstractText", "meshMajor", "article_URI"])<br/>    .with_additional(["id"])<br/>    .with_near_text({"concepts": ["therapies for mouth neoplasms"]})<br/>    .with_limit(20)<br/>    .do()<br/>)<br/><br/># Extract article URIs<br/>article_uris = [article["article_URI"] for article in response["data"]["Get"]["Articles_with_abstracts_and_URIs"]]<br/><br/># Print the extracted article URIs<br/>print("Extracted article URIs:")<br/>for uri in article_uris:<br/>    print(uri)</span></pre><p id="6f0c" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next we use the same sorting technique as before, using the Mouth Neoplasms related concepts:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="e358" class="pv oq gk ps b bg pw px l py pz">from rdflib import URIRef<br/><br/># Constructing the SPARQL query with a FILTER for the article URIs<br/>query = """<br/>PREFIX schema: &lt;http://schema.org/&gt;<br/>PREFIX ex: &lt;http://example.org/&gt;<br/><br/>SELECT ?article ?title ?abstract ?datePublished ?access ?meshTerm<br/>WHERE {<br/>  ?article a ex:Article ;<br/>           schema:name ?title ;<br/>           schema:description ?abstract ;<br/>           schema:datePublished ?datePublished ;<br/>           ex:access ?access ;<br/>           schema:about ?meshTerm .<br/><br/>  ?meshTerm a ex:MeSHTerm .<br/><br/>  # Filter to include only articles from the list of URIs<br/>  FILTER (?article IN (%s))<br/>}<br/>"""<br/><br/><br/># Convert the list of URIRefs into a string suitable for SPARQL<br/>article_uris_string = ", ".join([f"&lt;{str(uri)}&gt;" for uri in article_uris])<br/><br/># Insert the article URIs into the query<br/>query = query % article_uris_string<br/><br/># Dictionary to store articles and their associated MeSH terms<br/>article_data = {}<br/><br/># Run the query for each MeSH term<br/>for mesh_term in mesh_terms:<br/>    results = g.query(query, initBindings={'meshTerm': mesh_term})<br/><br/>    # Process results<br/>    for row in results:<br/>        article_uri = row['article']<br/><br/>        if article_uri not in article_data:<br/>            article_data[article_uri] = {<br/>                'title': row['title'],<br/>                'abstract': row['abstract'],<br/>                'datePublished': row['datePublished'],<br/>                'access': row['access'],<br/>                'meshTerms': set()<br/>            }<br/><br/>        # Add the MeSH term to the set for this article<br/>        article_data[article_uri]['meshTerms'].add(str(row['meshTerm']))<br/><br/># Rank articles by the number of matching MeSH terms<br/>ranked_articles = sorted(<br/>    article_data.items(),<br/>    key=lambda item: len(item[1]['meshTerms']),<br/>    reverse=True<br/>)<br/><br/><br/># Output results<br/>for article_uri, data in ranked_articles:<br/>    print(f"Title: {data['title']}")<br/>    print(f"Abstract: {data['abstract']}")<br/>    print("MeSH Terms:")<br/>    for mesh_term in data['meshTerms']:<br/>        print(f"  - {mesh_term}")<br/>    print()</span></pre><p id="3b98" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There are only three articles that are tagged with one of the Mouth Neoplasms terms:</p><ul class=""><li id="bafe" class="nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oo oh oi bk"><strong class="ne gl">Article 4:</strong> <em class="ny">“Feasability study of screening for malignant lesions in the oral cavity targeting tobacco users.” </em>Tagged with: Mouth Neoplasms.</li><li id="a90c" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 15:</strong> <em class="ny">“Photofrin-mediated photodynamic therapy of chemically-induced premalignant lesions and squamous cell carcinoma of the palatal mucosa in rats.” </em>This article is about an experimental cancer therapy (photodynamic therapy) for palatal cancer tested on rats. Tagged with: Palatal Neoplasms.</li><li id="e018" class="nc nd gk ne b hi oj ng nh hl ok nj nk nl ol nn no np om nr ns nt on nv nw nx oo oh oi bk"><strong class="ne gl">Article 1:</strong> <em class="ny">“Gingival metastasis as first sign of multiorgan dissemination of epithelioid malignant mesothelioma.” </em>Tagged with: Gingival Neoplasms.</li></ul><p id="c70b" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s send these to the LLM to see if the results improve:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="a537" class="pv oq gk ps b bg pw px l py pz"># Filter the response<br/>filtered_articles = filter_articles_by_uri(response, matching_articles)<br/><br/># Function to combine titles and abstracts into one chunk of text<br/>def combine_abstracts(filtered_articles):<br/>    combined_text = "\n\n".join(<br/>        [f"Title: {article['title']}\nAbstract: {article['abstractText']}" for article in filtered_articles]<br/>    )<br/>    return combined_text<br/><br/># Combine abstracts from the filtered articles<br/>combined_text = combine_abstracts(filtered_articles)<br/><br/># Generate and print the summary<br/>summary = generate_summary(combined_text)<br/>print(summary)</span></pre><p id="1d0e" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here are the results:</p><pre class="ob oc od oe of pr ps pt bp pu bb bk"><span id="c335" class="pv oq gk ps b bg pw px l py pz">- Oral cavity cancer is common and often not detected until it is advanced<br/>- A feasibility study was conducted to improve early detection of oral cancer and premalignant lesions in a high-risk region<br/>- Tobacco vendors were involved in distributing flyers to smokers for free examinations by general practitioners<br/>- 93 patients were included in the study, with 27% being referred to a specialist<br/>- 63.6% of referred patients actually saw a specialist, with 15.3% being diagnosed with a premalignant lesion<br/>- Photodynamic therapy (PDT) was studied as an experimental cancer therapy in rats with chemically-induced premalignant lesions and squamous cell carcinoma of the palatal mucosa<br/>- PDT was performed using Photofrin and two different activation wavelengths, with better results seen in the 514.5 nm group<br/>- Gingival metastasis from malignant mesothelioma is extremely rare, with a low survival rate<br/>- A case study showed a patient with a gingival mass as the first sign of multiorgan recurrence of malignant mesothelioma, highlighting the importance of biopsy for all new lesions, even in uncommon anatomical sites.</span></pre><p id="5f28" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can definitely see an improvement — these results are not about rectal cancer or nasopharyngeal neoplasms. This looks like a relatively accurate summary of the three articles selected, which are about therapies for mouth neoplasms</p><h1 id="2ed5" class="op oq gk bf or os ot hk ou ov ow hn ox oy oz pa pb pc pd pe pf pg ph pi pj pk bk">Conclusions</h1><p id="2726" class="pw-post-body-paragraph nc nd gk ne b hi pl ng nh hl pm nj nk nl pn nn no np po nr ns nt pp nv nw nx fj bk">Overall, vector databases are great at getting search, similarity (recommendation), and RAG applications up and running quickly. There is little overhead required. If you have unstructured data associated with your structured data, like in this example of journal articles, it can work well. This would not work nearly as well if we didn’t have article abstracts as part of the dataset, for example.</p><p id="ac4d" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">KGs are great for accuracy and control. If you want to be sure that the data going into your search application is ‘right,’ and by ‘right’ I mean whatever you decide based on your needs, then a KG is going to be needed. KGs can work well for search and similarity, but the degree to which they will meet your needs will depend on the richness of your metadata, and the quality of the tagging. Quality of tagging might also mean different things depending on your use case — the way you build and apply a taxonomy to content might look different if you’re building a recommendation engine rather than a search engine.</p><p id="5327" class="pw-post-body-paragraph nc nd gk ne b hi nf ng nh hl ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Using a KG to filter results from a vector database leads to the best results. This is not surprising — I am using the KG to filter out irrelevant or misleading results <strong class="ne gl">as determined by me</strong>, so of course the results are better, according to me. But that’s the point: it’s not that the KG necessarily improves results by itself, it’s that the KG provides you the ability to control the output to optimize your results.</p></div></div></div></div>    
</body>
</html>