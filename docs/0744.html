<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Build a (recipe) recommender chatbot using RAG and hybrid search (Part I)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Build a (recipe) recommender chatbot using RAG and hybrid search (Part I)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-a-recipe-recommender-chatbot-using-rag-and-hybrid-search-part-i-c4aa07d14dcf?source=collection_archive---------2-----------------------#2024-03-20">https://towardsdatascience.com/build-a-recipe-recommender-chatbot-using-rag-and-hybrid-search-part-i-c4aa07d14dcf?source=collection_archive---------2-----------------------#2024-03-20</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="6852" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">This tutorial will teach you how to create sparse and dense embeddings and build a recommender system using hybrid search</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@sebastianbahr?source=post_page---byline--c4aa07d14dcf--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Sebastian Bahr" class="l ep by dd de cx" src="../Images/082ca57697e35575127e71308a613b54.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*KsIhIDrj5gatLp0TYapuoQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--c4aa07d14dcf--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@sebastianbahr?source=post_page---byline--c4aa07d14dcf--------------------------------" rel="noopener follow">Sebastian Bahr</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--c4aa07d14dcf--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 20, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">3</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/6619ea46b5aacdb61382fdadae8d715d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E1aogTVov80wGrV4SdL7rg.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@kate5oh3?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" rel="noopener ugc nofollow" target="_blank">Katie Smith</a> on <a class="af nc" href="https://unsplash.com/photos/avocado-tomatoes-eggs-mushrooms-spring-onions-and-leaves-uQs1802D0CQ?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="35eb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This tutorial provides a step-by-step guide with code on how to create a chatbot-style recommender system. By the end, you will have built a recommender that uses the user’s open-text input to find matching items through a hybrid search on sparse and dense vectors. The dataset used in this tutorial contains recipes. However, you can easily replace the dataset with one that suits your needs with minimal adjustments. The first part of this task will focus on building the recommender system, which involves data cleaning, creating sparse and dense embeddings, uploading them to a vector database, and performing dense vector search and hybrid search. In the second part, you will create a chatbot that generates responses based on user input and recommendations, and a UI using a Plotly dashboard.</p><p id="9af6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To follow this tutorial, you will need to set up accounts for paid services such as Vertex AI, OpenAI API, and Pinecone. Fortunately, most services offer free credits, and the costs associated with this tutorial should not exceed $5. Additionally, you can reduce costs further by using the files and datasets provided on my GitHub <a class="af nc" href="https://github.com/sebastianbahr/RecipeRecommender" rel="noopener ugc nofollow" target="_blank">repository</a>.</p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="e451" class="oh oi fq bf oj ok ol gq om on oo gt op oq or os ot ou ov ow ox oy oz pa pb pc bk">Data preparation</h1><p id="e083" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">For this project, we will use recipes from <a class="af nc" href="https://publicdomainrecipes.com/" rel="noopener ugc nofollow" target="_blank">Public Domain Recipes</a>. All recipes are stored as markdown files in this GitHub <a class="af nc" href="https://github.com/ronaldlong46/public-domain-recipes" rel="noopener ugc nofollow" target="_blank">repository.</a> For this tutorial, I already did some data cleaning and created features from the raw text input. If you are keen on doing the data cleaning part yourself, the code is available on my GitHub <a class="af nc" href="https://github.com/sebastianbahr/RecipeRecommender" rel="noopener ugc nofollow" target="_blank">repository</a>.</p><p id="b36a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The dataset consists of the following columns:</p><ul class=""><li id="8c44" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pi pj pk bk"><em class="pl">title: </em>the title of the recipe</li><li id="b1ec" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk"><em class="pl">date:</em> the date the recipe was added</li><li id="4206" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk"><em class="pl">tags:</em> a list of tags that describe the meal</li><li id="8fde" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk"><em class="pl">introduction:</em> an introduction to the recipe, the content varies strongly between records</li><li id="8475" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk"><em class="pl">ingredients:</em> all needed ingredients. Note that I removed the quantity as it is not needed for creating embeddings and contrary may lead to undesirable recommendations.</li><li id="ace5" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk"><em class="pl">direction:</em> all required steps you need to perform to cook the meal</li><li id="48ce" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk"><em class="pl">recipe_type: </em>indicator if the recipe is vegan, vegetarian, or regular</li><li id="fe30" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk"><em class="pl">output:</em> contains the <em class="pl">title</em>, <em class="pl">ingredients,</em> and <em class="pl">direction</em> of the recipe and will be later provided to the chat model as input.</li></ul><p id="d33c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s have a look at the distribution of the <em class="pl">recipe_type</em> feature. We see that the majority (60%) of the recipes include fish or meat and aren’t vegetarian-friendly. Approximately 35% are vegetarian-friendly and only 5% are vegan-friendly. This feature will be used as a hard filter for retrieving matching recipes from the vector database.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="7e11" class="pv oi fq ps b bg pw px l py pz">import re<br/>import json<br/>import spacy<br/>import torch<br/>import openai<br/>import vertexai<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from tqdm.auto import tqdm<br/>from transformers import AutoModelForMaskedLM, AutoTokenizer<br/>from pinecone import Pinecone, ServerlessSpec<br/>from vertexai.language_models import TextEmbeddingModel<br/>from utils_google import authenticate<br/>credentials, PROJECT_ID, service_account, pinecone_API_KEY = authenticate() <br/>from utils_openai import authenticate<br/>OPENAI_API_KEY = authenticate() <br/><br/>openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)<br/><br/>REGION = "us-central1"<br/>vertexai.init(project = PROJECT_ID,<br/>              location = REGION,<br/>              credentials = credentials)<br/><br/>pc = Pinecone(api_key=pinecone_API_KEY)<br/><br/># download spacy model<br/>#!python -m spacy download en_core_web_sm</span></pre><pre class="qa pr ps pt bp pu bb bk"><span id="5517" class="pv oi fq ps b bg pw px l py pz">recipes = pd.read_json("recipes_v2.json")<br/>recipes.head()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qb"><img src="../Images/7fe0a3fb021229bc428ebc654abad1a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFR0TUyG4q44iyYzMZ4G5g.png"/></div></div></figure><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="0a8d" class="pv oi fq ps b bg pw px l py pz">plt.bar(recipes.recipe_type.unique(), recipes.recipe_type.value_counts(normalize=True).values)<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qc"><img src="../Images/493e0101786f39c0ad909cc73d765734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9dMi5wyvNU-a_3rOUPPAw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of recipe types</figcaption></figure><p id="545d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Hybrid search uses a combination of sparse and dense vectors and a weighting factor <em class="pl">alpha,</em> which allows adjusting the importance of the dense vector in the retrieval process. In the following, we will create dense vectors based on the <em class="pl">title</em>, <em class="pl">tags</em>, and <em class="pl">introduction</em> and sparse vectors on the <em class="pl">ingredients</em>. By adjusting <em class="pl">alpha</em> we can therefore later on determine how much “attention” should be paid to ingredients the user mentioned in its query.</p><p id="b53b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Before creating the embeddings a new feature needs to be created that contains the combined information of the <em class="pl">title</em>, the <em class="pl">tags</em>, and the <em class="pl">introduction</em>.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="a01b" class="pv oi fq ps b bg pw px l py pz">recipes["dense_feature"] = recipes.title + "; " + recipes.tags.apply(lambda x: str(x).strip("[]").replace("'", "")) + "; " + recipes.introduction<br/>recipes["dense_feature"].head()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qd"><img src="../Images/7c5589bf23680055144fc3a93bd8e990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Jq19KpHGt2CYuIl6MeraA.png"/></div></div></figure><p id="bd34" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Finally, before diving deeper into the generation of the embeddings we’ll have a look at the output column. The second part of the tutorial will be all about creating a chatbot using OpenAI that is able to answer user questions using knowledge from our recipe database. Therefore, after finding the recipes that match best the user query the chat model needs some information it builds its answer on. That’s where the <em class="pl">output</em> is used, as it contains all the needed information for an adequate answer</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="06a7" class="pv oi fq ps b bg pw px l py pz"># example output<br/>{'title': 'Creamy Mashed Potatoes',<br/> 'ingredients': 'The quantities here are for about four adult portions. If you are planning on eating this as a side dish, it might be more like 6-8 portions. * 1kg potatoes * 200ml milk* * 200ml mayonnaise* * ~100g cheese * Garlic powder * 12-16 strips of bacon * Butter * 3-4 green onions * Black pepper * Salt  *You can play with the proportions depending on how creamy or dry you want the mashed potatoes to be.',<br/> 'direction': '1. Peel and cut the potatoes into medium sized pieces. 2. Put the potatoes in a pot with some water so that it covers the potatoes and   boil them for about 20-30 minutes, or until the potatoes are soft. 3. About ten minutes before removing the potatoes from the boiling water, cut   the bacon into little pieces and fry it. 4. Warm up the milk and mayonnaise. 5. Shred the cheese. 6. When the potatoes are done, remove all water from the pot, add the warm milk   and mayonnaise mix, add some butter, and mash with a potato masher or a   blender. 7. Add some salt, black pepper and garlic powder to taste and continue mashing   the mix. 8. Once the mix is somewhat homogeneous and the potatoes are properly mashed,   add the shredded cheese and fried bacon and mix a little. 9. Serve and top with chopped green onions.'}</span></pre><p id="cb78" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Further, a unique identifier needs to be added to each recipe, which allows retrieving the records of the recommended candidate recipes and their <em class="pl">output</em>.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="4fe4" class="pv oi fq ps b bg pw px l py pz">recipes["ID"] = range(len(recipes))</span></pre><h2 id="0af3" class="qe oi fq bf oj qf qg qh om qi qj qk op nm ql qm qn nq qo qp qq nu qr qs qt qu bk">Generate sparse embeddings</h2><p id="1a99" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">The next step involves creating sparse embeddings for all 360 observations. To calculate these embeddings, a more sophisticated method than the frequently used TF-IDF or BM25 approach is used. Instead, the SPLADE <strong class="nf fr">Sp</strong>arse <strong class="nf fr">L</strong>exical <strong class="nf fr">a</strong>n<strong class="nf fr">d</strong> <strong class="nf fr">E</strong>xpansion model is applied. A detailed explanation of SPLADE can be found <a class="af nc" href="https://www.pinecone.io/learn/splade/" rel="noopener ugc nofollow" target="_blank">here</a>. Dense embeddings have the same shape for each text input, regardless of the number of tokens in the input. In contrast, sparse embeddings contain a weight for each unique token in the input. The dictionary below represents a sparse vector, where the token ID is the key and the assigned weight is the value.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="44bb" class="pv oi fq ps b bg pw px l py pz">model_id = "naver/splade-cocondenser-ensembledistil"<br/><br/>tokenizer = AutoTokenizer.from_pretrained(model_id)<br/>model = AutoModelForMaskedLM.from_pretrained(model_id)<br/><br/>def to_sparse_vector(text, tokenizer, model):<br/>    tokens = tokenizer(text, return_tensors='pt')<br/>    output = model(**tokens)<br/>    vec = torch.max(<br/>        torch.log(1 + torch.relu(output.logits)) * tokens.attention_mask.unsqueeze(-1), dim=1<br/>    )[0].squeeze()<br/><br/>    cols = vec.nonzero().squeeze().cpu().tolist()<br/>    weights = vec[cols].cpu().tolist()<br/>    sparse_dict = dict(zip(cols, weights))<br/>    return sparse_dict<br/>    <br/>sparse_vectors = []<br/><br/>for i in tqdm(range(len(recipes))):<br/>    sparse_vectors.append(to_sparse_vector(recipes.iloc[i]["ingredients"], tokenizer, model))<br/><br/>recipes["sparse_vectors"] = sparse_vectors</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qv"><img src="../Images/69a25dad27f8097f9e1d64df625d39e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*6BgW4_BSJo-3twbP3Jp9ng.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">sparse embeddings of the first recipe</figcaption></figure><h2 id="e7be" class="qe oi fq bf oj qf qg qh om qi qj qk op nm ql qm qn nq qo qp qq nu qr qs qt qu bk">Generating dense embeddings</h2><p id="2bcf" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">At this point of the tutorial, some costs will arise if you use a text embedding model from VertexAI (Google) or OpenAI. However, if you use the same dataset, the costs will be at most $5. The cost may vary if you use a dataset with more records or longer texts, as you are charged by tokens. If you do not wish to incur any costs but still want to follow the tutorial, particularly the second part, you can download the pandas DataFrame <em class="pl">recipes_with_vectors.pkl</em> with pre-generated embedding data from my GitHub <a class="af nc" href="https://github.com/sebastianbahr/RecipeRecommender" rel="noopener ugc nofollow" target="_blank">repository.</a></p><p id="e6d8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">You can choose to use either VertexAI or OpenAI to create the embeddings. OpenAI has the advantage of being easy to set up with an API key, while VertexAI requires logging into Google Console, creating a project, and adding the VertexAI API to your project. Additionally, the OpenAI model allows you to specify the number of dimensions for the dense vector. Nevertheless, both of them create state-of-the-art dense embeddings.</p><p id="19f2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Using VertexAI API</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="0225" class="pv oi fq ps b bg pw px l py pz"># running this code will create costs !!!<br/>model = TextEmbeddingModel.from_pretrained("textembedding-gecko@003")<br/><br/>def to_dense_vector(text, model):<br/>    dense_vectors = model.get_embeddings([text])<br/>    return [dense_vector.values for dense_vector in dense_vectors][0]<br/><br/>dense_vectors = []<br/><br/>for i in tqdm(range(len(recipes))):<br/>    dense_vectors.append(to_dense_vector(recipes.iloc[i]["dense_feature"], model))<br/><br/>recipes["dense_vectors"] = dense_vectors</span></pre><p id="43b0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Using OpenAI API</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="05f4" class="pv oi fq ps b bg pw px l py pz"># running this code will create costs !!!<br/><br/># Create dense embeddings using OpenAIs text embedding model with 768 dimensions<br/>model = "text-embedding-3-small"<br/><br/>def to_dense_vector_openAI(text, client, model, dimensions):<br/>    dense_vectors = client.embeddings.create(model=model, dimensions=dimensions, input=[text])<br/>    return [dense_vector.values for dense_vector in dense_vectors][0]<br/><br/>dense_vectors = []<br/><br/>for i in tqdm(range(len(recipes))):<br/>    dense_vectors.append(to_dense_vector_openAI(recipes.iloc[i]["dense_feature"], openai_client, model, 768))<br/><br/>recipes["dense_vectors"] = dense_vectors</span></pre><h2 id="35bf" class="qe oi fq bf oj qf qg qh om qi qj qk op nm ql qm qn nq qo qp qq nu qr qs qt qu bk">Upload data to vector database</h2><p id="355b" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">After generating the sparse and dense embeddings, we have all the necessary data to upload them to a vector database. In this tutorial, Pinecone will be used as they allow performing a hybrid search using sparse and dense vectors and offer a serverless pricing schema with $100 free credits. To perform a hybrid search later on, the similarity metric needs to be set to dot product. If we would only perform a dense instead of a hybrid search we would be able to select one of these similarity metrics: dot product, cosine, and Euclidean distance. More information about similarity metrics and how they calculate the similarity between two vectors can be found <a class="af nc" href="https://www.pinecone.io/learn/vector-similarity/" rel="noopener ugc nofollow" target="_blank">here</a>.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="f0aa" class="pv oi fq ps b bg pw px l py pz"># load pandas DataFrame with pre-generated embeddings if you<br/># didn't generate them in the last step<br/>recipes = pd.read_pickle("recipes_with_vectors.pkl")<br/><br/># if you need to delte an existing index<br/>pc.delete_index("index-name")<br/><br/># create a new index <br/>pc.create_index(<br/>    name="recipe-project",<br/>    dimension=768, # adjust if needed<br/>    metric="dotproduct",<br/>    spec=ServerlessSpec(<br/>        cloud="aws",<br/>        region="us-west-2"<br/>    )<br/>)<br/><br/>pc.describe_index("recipe-project")</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/164af1e806cbfad149d54caeb0a5d067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xe2f2Fs15rbMX1KZuSyl_Q.png"/></div></div></figure><p id="7e8c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Congratulations on creating your first Pinecone index! Now, it’s time to upload the embedded data to the vector database. If the embedding model you used creates vectors with a different number of dimensions, make sure to adjust the <em class="pl">dimension</em> argument.</p><p id="864b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now it’s time to upload the data to the newly created Pinecone index.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="d2df" class="pv oi fq ps b bg pw px l py pz"># upsert to pinecone in batches<br/>def sparse_to_dict(data):<br/>    dict_ = {"indices": list(data.keys()),<br/>             "values": list(data.values())}<br/>    return dict_<br/><br/>batch_size = 100<br/>index = pc.Index("recipe-project")<br/><br/>for i in tqdm(range(0, len(recipes), batch_size)):<br/>    i_end = min(i + batch_size, len(recipes))<br/>    meta_batch = recipes.iloc[i: i_end][["ID", "recipe_type"]]<br/>    meta_dict = meta_batch.to_dict(orient="records")<br/><br/>    sparse_batch = recipes.iloc[i: i_end]["sparse_vectors"].apply(lambda x: sparse_to_dict(x))<br/>    dense_batch = recipes.iloc[i: i_end]["dense_vectors"]<br/><br/>    upserts = []<br/><br/>    ids = [str(x) for x in range(i, i_end)]<br/>    for id_, meta, sparse_, dense_ in zip(ids, meta_dict, sparse_batch, dense_batch):<br/>        upserts.append({<br/>            "id": id_,<br/>            "sparse_values": sparse_,<br/>            "values": dense_,<br/>            "metadata": meta<br/>        })<br/><br/>    index.upsert(upserts)<br/><br/>index.describe_index_stats()</span></pre><p id="8e6b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If you are curious about what the uploaded data looks like, log in to Pinecone, select the newly created index, and have a look at its items. For now, we don’t need to pay attention to the score, as it is generated by default and indicates the match with a vector randomly generated by Pinecone. However, later we will calculate the similarity of the embedded user query with all items in the vector database and retrieve the <em class="pl">k</em> most similar items. Further, each item contains an item ID generated by Pinecone, and the metadata, which consists of the recipe <em class="pl">ID</em> and its <em class="pl">recipe_type</em>. The dense embeddings are stored in <em class="pl">Values</em> and the sparse embeddings in <em class="pl">Sparse Values.</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qx"><img src="../Images/62c6420c8583f925846f22822a799b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A4BdyilMQ_qfA2K17KwMvQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">The first three items of the index (<em class="qy">Image by author</em>)</figcaption></figure><p id="dc2a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We can fetch the information from above using the Pinecone Python SDK. Let’s have a look at the stored information of the first item with the index item ID 50.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="fc29" class="pv oi fq ps b bg pw px l py pz">index.fetch(ids=["50"])</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qz"><img src="../Images/67424101a92329f08d02ba4bac2b2dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LO7f-yTosoLi_D3B2JoA-g.png"/></div></div></figure><p id="ebdc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As in the Pinecone dashboard, we get the item ID of the element, its metadata, the sparse values, and the dense values, which are stored in the list at the bottom of the truncated output.</p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="ba4f" class="oh oi fq bf oj ok ol gq om on oo gt op oq or os ot ou ov ow ox oy oz pa pb pc bk">Search</h1><p id="51e7" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">In this section, we will solely use dense vectors to find the best-matching entries in our database (<em class="pl">dense search</em>). In the second step, we will utilize the information stored in both the sparse and dense vectors to perform a hybrid search.</p><h2 id="8551" class="qe oi fq bf oj qf qg qh om qi qj qk op nm ql qm qn nq qo qp qq nu qr qs qt qu bk">Regular search using dense vectors</h2><p id="be4e" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">To test the functionality of our recommender system, we will attempt to obtain recommendations for a vegetarian Italian dish. It is important to note that the same model must be used to generate the dense embeddings as the one used to embed the recipes.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="3b92" class="pv oi fq ps b bg pw px l py pz">user_query = "I want to cook some Italian dish with rice"<br/>recipe_type = "vegetarian"</span></pre><pre class="qa pr ps pt bp pu bb bk"><span id="d65c" class="pv oi fq ps b bg pw px l py pz"># running this code will create costs !!!<br/><br/># If you used VertexAI and gecko003 to create dense embeddings<br/>model = TextEmbeddingModel.from_pretrained("textembedding-gecko@003")<br/><br/>def to_dense_vector(text, model):<br/>    dense_vectors = model.get_embeddings([text])<br/>    return [dense_vector.values for dense_vector in dense_vectors][0]<br/><br/>text_dense_vector = to_dense_vector(user_query, model)</span></pre><p id="b749" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Using OpenAI API</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="a6ee" class="pv oi fq ps b bg pw px l py pz"># running this code will create costs !!!<br/><br/># If you used OpenAI to create dense embeddings<br/>model = "text-embedding-3-small"<br/><br/>def to_dense_vector_openAI(text, client, model, dimensions):<br/>    dense_vectors = client.embeddings.create(model=model, dimensions=dimensions, input=[text])<br/>    return [dense_vector.values for dense_vector in dense_vectors][0]<br/><br/>text_dense_vector = to_dense_vector_openAI(user_query, openai_client, model, 768)</span></pre><p id="5761" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After embedding the user text, we can query the vector database for the recipes that resemble the user query the most. As previously defined Pinecone uses the dot product to calculate the similarity score. Further, we specify that Piencone should return the metadata of the recommended items, as we need the <em class="pl">ID</em> of the recipe to filter the recipes database and get the output of the corresponding items. The parameter <em class="pl">top_k</em> allows us to specify the number of matches that should be returned and lastly, we specify with a hard filter to only recommend coffee blends that cost equal to or less than the indicated price (10.0). More information on how the filtering of metadata works in Pinecone can be found <a class="af nc" href="https://docs.pinecone.io/docs/metadata-filtering" rel="noopener ugc nofollow" target="_blank">here</a>.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="dcff" class="pv oi fq ps b bg pw px l py pz">index = pc.Index("recipe-project")<br/><br/>retrieved_items = index.query(vector=text_dense_vector,<br/>                              include_values=False,<br/>                              include_metadata=True,<br/>                              top_k=3,<br/>                              filter={"recipe_type": {"$eq": recipe_type}})<br/><br/>retrieved_ids = [item.get("metadata").get("ID") for item in retrieved_items.get("matches")]<br/><br/>retrieved_items</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ra"><img src="../Images/c10907a654af67b069ab69bcc05a33b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SIf3XrHQJFWfn37qWo6ySw.png"/></div></div></figure><p id="152c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After obtaining the IDs of the recommended recipes we can easily query the <em class="pl">recipes</em> dataset for them and have a look at their <em class="pl">output</em>. The <em class="pl">output</em> contains all the needed information as the <em class="pl">title</em>, the <em class="pl">ingredients</em>, and the <em class="pl">directions</em>. A look at the first recommendations reveals that they are all vegetarian, this is not surprising as we applied a “hard” filter, but they are all Italian dishes as requested by the user.</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="1548" class="pv oi fq ps b bg pw px l py pz">recipes[recipes.ID.isin(retrieved_ids)].output.values</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rb"><img src="../Images/d13ce43cfeefe2b52d9d511f9ee2b074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pW6UOQSFDAol2m_QtpyZcg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">recipes with the highest similarity scores</figcaption></figure><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="5f9a" class="pv oi fq ps b bg pw px l py pz">recipes[recipes.ID.isin(retrieved_ids)].output.values[0]</span></pre><pre class="qa pr ps pt bp pu bb bk"><span id="54eb" class="pv oi fq ps b bg pw px l py pz">{'title': 'Pasta Arrabbiata',<br/> 'ingredients': '- Pasta - Olive oil - Chilli flakes or diced chilli peppers - Crushed garlic cloves - Crushed tomatoes (about 800 gramms for 500 gramms of pasta) - Chopped parsley - Grated Pecorino Romano or Parmigiano Reggiano (optional, but highly recommended)',<br/> 'direction': '1. Start heating up water for the pasta. 2. Heat up a few tablespoons of olive oil over low heat. 3. Crush several cloves of garlic into the olive oil, add the chilli flakes or chilli peppers and fry them for a short time, while being careful not to burn the garlic. 4. Add your crushed tomatoes, together with some salt and pepper, increase the heat to medium and let simmer for 10-15 minutes or until it looks nicely thickened. 5. When the water starts boiling, put a handful of salt into it and then your pasta of choice. Ideally leave the pasta slightly undercooked, because it will go in the hot sauce and finish cooking there. 6. When the sauce is almost ready, add most of your chopped parsley and stir it around. Save some to top the dish later. 8. When the pasta is ready (ideally at the same time as the sauce or slightly later), strain it and add it to the sauce, which should be off the heat. If the sauce looks a bit too thick, add some of the pasta water. Mix well. 9. Add some of the grated cheese of your choice and stir it in. 10. Serve with some more grated cheese and chopped parsley on top.'}</span></pre><h2 id="b400" class="qe oi fq bf oj qf qg qh om qi qj qk op nm ql qm qn nq qo qp qq nu qr qs qt qu bk">Hybrid Search</h2><p id="9401" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">Now it’s time to implement hybrid search. The concept sounds fancier than it is and you will realize it when we implement it in just two lines of code. Hybrid search weights the values of the dense vector by a factor <em class="pl">alpha</em> and the values of the sparse vector by <em class="pl">1-alpha.</em> In other words, <em class="pl">alpha</em> determines how much “attention” should be paid to the dense respectively the sparse embeddings of the input text. If <em class="pl">alpha=1</em> we perform a pure dense vector search, <em class="pl">alpha=0.5</em> is a pure hybrid search, and <em class="pl">alpha=0</em> is a pure sparse vector search.<br/>As you remember the sparse and dense vectors were created using different information. Whereas the sparse vector contains information about the ingredients, the dense vector incorporates the title, tags, and introduction. Therefore, by changing <em class="pl">alpha</em> we can tell the query engine to prioritize some features of the recipes more than others. Let’s use an alpha of 1 first and run a pure dense search on the user query:</p><blockquote class="rc rd re"><p id="21a5" class="nd ne pl nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">What can I cook with potatos, mushrooms, and beef?</p></blockquote><p id="94be" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Unfortunately, besides beef, the recommended recipe doesn’t contain any of the other mentioned ingredients.</p><p id="c4f4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Generate sparse embeddings</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="19f1" class="pv oi fq ps b bg pw px l py pz">model_id = "naver/splade-cocondenser-ensembledistil"<br/>tokenizer = AutoTokenizer.from_pretrained(model_id)<br/>model = AutoModelForMaskedLM.from_pretrained(model_id)<br/><br/>def to_sparse_vector(text, tokenizer, model):<br/>    tokens = tokenizer(text, return_tensors='pt')<br/>    output = model(**tokens)<br/>    vec = torch.max(<br/>        torch.log(1 + torch.relu(output.logits)) * tokens.attention_mask.unsqueeze(-1), dim=1<br/>    )[0].squeeze()<br/><br/>    cols = vec.nonzero().squeeze().cpu().tolist()<br/>    weights = vec[cols].cpu().tolist()<br/>    sparse_dict = dict(zip(cols, weights))<br/>    return sparse_dict<br/><br/>text_sparse_vector = to_sparse_vector(user_query, tokenizer, model)</span></pre><p id="050e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Generate dense embeddings</p><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="5984" class="pv oi fq ps b bg pw px l py pz"># running this code will create costs !!!<br/><br/># If you used VertexAI and gecko003 to create dense embeddings<br/>model = TextEmbeddingModel.from_pretrained("textembedding-gecko@003")<br/><br/>text_dense_vector = to_dense_vector(user_query, model)</span></pre><pre class="qa pr ps pt bp pu bb bk"><span id="61c0" class="pv oi fq ps b bg pw px l py pz">def hybride_search(sparse_dict, dense_vectors, alpha):<br/><br/>    # check alpha value is in range<br/>    if alpha &lt; 0 or alpha &gt; 1:<br/>        raise ValueError("Alpha must be between 0 and 1")<br/>    # scale sparse and dense vectors to create hybrid search vecs<br/>    hsparse = {<br/>        "indices": list(sparse_dict.keys()),<br/>        "values": [v * (1 - alpha) for v in list(sparse_dict.values())]<br/>    }<br/>    hdense = [v * alpha for v in dense_vectors]<br/>    return hdense, hsparse<br/><br/><br/><br/>user_query = "What can I cook with potatos, mushrooms, and beef?"<br/>recipe_type = ["regular", "vegetarian", "vegan"] # allows for all recipe types<br/><br/><br/>dense_vector, sparse_dict = hybride_search(text_sparse_vector, text_dense_vector, 1.0)<br/><br/>retrieved_items = index.query(vector=dense_vector,<br/>                              sparse_vector=sparse_dict,<br/>                              include_values=False,<br/>                              include_metadata=True,<br/>                              top_k=1,<br/>                              filter={"recipe_type": {"$in": recipe_type}})<br/><br/>retrieved_ids = [item.get("metadata").get("ID") for item in retrieved_items.get("matches")]<br/><br/>[x.get("ingredients") for x in recipes[recipes.ID.isin(retrieved_ids)].output.values]</span></pre><pre class="qa pr ps pt bp pu bb bk"><span id="3f85" class="pv oi fq ps b bg pw px l py pz"># retrived output with alpha=1.0<br/>['- 1 beef kidney - 60g butter - 2 onions - 2 shallots - 1 sprig of fresh parsley - 3 bay leaves - 400g croutons or toasted bread in pieces']</span></pre><p id="4172" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s set alpha to 0.5 and have a look at the ingredients of the recommended recipe. This alpha score leads to a much better result and the recommended recipe contains all three asked ingredients:</p><ul class=""><li id="7726" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pi pj pk bk">500g beef</li><li id="f8ee" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk">300–400g potatoes</li><li id="8bca" class="nd ne fq nf b go pm nh ni gr pn nk nl nm po no np nq pp ns nt nu pq nw nx ny pi pj pk bk">2–3 champignon mushrooms</li></ul><pre class="mm mn mo mp mq pr ps pt bp pu bb bk"><span id="da0f" class="pv oi fq ps b bg pw px l py pz">dense_vector, sparse_dict = hybride_search(text_sparse_vector, text_dense_vector, 0.5)<br/><br/>retrieved_items = index.query(vector=dense_vector,<br/>                              sparse_vector=sparse_dict,<br/>                              include_values=False,<br/>                              include_metadata=True,<br/>                              top_k=1,<br/>                              filter={"recipe_type": {"$in": recipe_type}})<br/><br/>retrieved_ids = [item.get("metadata").get("ID") for item in retrieved_items.get("matches")]<br/><br/>[x.get("ingredients") for x in recipes[recipes.ID.isin(retrieved_ids)].output.values]</span></pre><pre class="qa pr ps pt bp pu bb bk"><span id="e575" class="pv oi fq ps b bg pw px l py pz"># retrived output with alpha=0.5<br/>['* 500g beef * 300-400g potatoes * 1 carrot * 1 medium onion * 12 tablespoons tomato paste * 500ml water * 3-4 garlic cloves * 3-4 bay leaves * Curcuma * Paprika * Oregano * Parsley * Caraway * Basil (optional) * Cilantro (optional) * 2-3 champignon mushrooms (optional)']Using a serverless index has the advantage that you do not need to pay for a server instance that runs 24/7. Instead, you are billed by queries or read and write units, as they are called by Pinecone. Sparse and dense vector searches work well with a serverless index. However, please keep in mind the following limitation.</span></pre><p id="dbee" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Congratulations, you made it to the end of this tutorial!</p><h2 id="16bf" class="qe oi fq bf oj qf qg qh om qi qj qk op nm ql qm qn nq qo qp qq nu qr qs qt qu bk">Final remarks</h2><blockquote class="rc rd re"><p id="31ef" class="nd ne pl nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The implementation of hybrid search is meaningfully different between pod-based and serverless indexes. If you switch from one to the other, you may experience a regression in accuracy or performance.</p><p id="4996" class="nd ne pl nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When you query a serverless index, the dense value of the query is used to retrieve the initial candidate records, and then the sparse value is considered when returning the final results.</p></blockquote></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="91ba" class="oh oi fq bf oj ok ol gq om on oo gt op oq or os ot ou ov ow ox oy oz pa pb pc bk">Conclusion</h1><p id="ed20" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">In this tutorial, you have learned how to embed a dataset using sparse and dense embeddings and use dense and hybrid search to find the closest matching entries in a vector database.</p><p id="b9b8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In the second part, you will build a chatbot using a GPT 3.5-turbo model with function calling and generate a UI using Plotly Dash. Have a look at it if you’re curious and enjoyed the first part.</p><h2 id="c6bf" class="qe oi fq bf oj qf qg qh om qi qj qk op nm ql qm qn nq qo qp qq nu qr qs qt qu bk">Please support my work!</h2><p id="44ff" class="pw-post-body-paragraph nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fj bk">If you liked this blog post, please leave a clap or comment. To stay tuned follow me on <a class="af nc" href="https://medium.com/@sebastianbahr" rel="noopener">Medium</a> and <a class="af nc" href="https://www.linkedin.com/in/sebastian-bahr-61b58b197/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>.</p></div></div></div></div>    
</body>
</html>