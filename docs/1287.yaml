- en: 'Reinforcement Learning: Deep Q-Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/reinforcement-learning-from-scratch-deep-q-networks-0a8d33ce165b?source=collection_archive---------1-----------------------#2024-05-23](https://towardsdatascience.com/reinforcement-learning-from-scratch-deep-q-networks-0a8d33ce165b?source=collection_archive---------1-----------------------#2024-05-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Teaching a shuttle to land on the moon using Deep Q-Networks in Python: A mathematical
    deep dive into Reinforcement Learning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@cristianleo120?source=post_page---byline--0a8d33ce165b--------------------------------)[![Cristian
    Leo](../Images/99074292e7dfda50cf50a790b8deda79.png)](https://medium.com/@cristianleo120?source=post_page---byline--0a8d33ce165b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0a8d33ce165b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0a8d33ce165b--------------------------------)
    [Cristian Leo](https://medium.com/@cristianleo120?source=post_page---byline--0a8d33ce165b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0a8d33ce165b--------------------------------)
    ·28 min read·May 23, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38970589a005da7933deef0ef58bbb32.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by DALL-E
  prefs: []
  type: TYPE_NORMAL
- en: In reinforcement learning (RL), Q-learning is a foundational algorithm that
    helps an agent navigate its environment by learning a policy to maximize cumulative
    rewards. It does this by updating an action-value function, which estimates the
    expected utility of taking a specific action in a given state, based on received
    rewards and future estimations (this doesn’t sound familiar? Don’t worry as we
    will go over it later together).
  prefs: []
  type: TYPE_NORMAL
- en: However, traditional Q-learning has its challenges. It struggles with scalability
    as the state space grows and is less effective in environments with continuous
    state and action spaces. This is where Deep Q Networks (DQNs) come in. DQNs use
    neural networks to approximate the Q-values, enabling agents to handle larger
    and more complex environments effectively.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll dive into Deep Q Networks. We’ll explore how DQNs overcome
    the limitations of traditional Q-learning and discuss the key components that
    make up a DQN. We’ll also walk through implementing a DQN from scratch and applying
    it to a more complex environment. By the end of this article, you’ll have a solid
    understanding of…
  prefs: []
  type: TYPE_NORMAL
