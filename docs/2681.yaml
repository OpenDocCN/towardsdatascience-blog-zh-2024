- en: What Did I Learn from Building LLM Applications in 2024? — Part 1
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我从2024年构建LLM应用中学到了什么？——第1部分
- en: 原文：[https://towardsdatascience.com/what-did-i-learn-from-building-llm-applications-in-2024-part-1-d299b638773b?source=collection_archive---------1-----------------------#2024-11-04](https://towardsdatascience.com/what-did-i-learn-from-building-llm-applications-in-2024-part-1-d299b638773b?source=collection_archive---------1-----------------------#2024-11-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-did-i-learn-from-building-llm-applications-in-2024-part-1-d299b638773b?source=collection_archive---------1-----------------------#2024-11-04](https://towardsdatascience.com/what-did-i-learn-from-building-llm-applications-in-2024-part-1-d299b638773b?source=collection_archive---------1-----------------------#2024-11-04)
- en: An engineer’s journey to building LLM-native applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一位工程师构建LLM原生应用的历程
- en: '[](https://medium.com/@cleancoder?source=post_page---byline--d299b638773b--------------------------------)[![Satwiki
    De](../Images/a0c45e202a3d3d3dcfea65cb9cad2719.png)](https://medium.com/@cleancoder?source=post_page---byline--d299b638773b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d299b638773b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d299b638773b--------------------------------)
    [Satwiki De](https://medium.com/@cleancoder?source=post_page---byline--d299b638773b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@cleancoder?source=post_page---byline--d299b638773b--------------------------------)[![Satwiki
    De](../Images/a0c45e202a3d3d3dcfea65cb9cad2719.png)](https://medium.com/@cleancoder?source=post_page---byline--d299b638773b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d299b638773b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d299b638773b--------------------------------)
    [Satwiki De](https://medium.com/@cleancoder?source=post_page---byline--d299b638773b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d299b638773b--------------------------------)
    ·7 min read·Nov 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d299b638773b--------------------------------)
    ·阅读时间：7分钟·2024年11月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1bb90ed9e4c569bffe308a1f00a9a2fc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1bb90ed9e4c569bffe308a1f00a9a2fc.png)'
- en: Large Language Models (LLMs) are poised to transform the way we approach AI
    and it is already being quite noticeable with innovative designs of integrating
    LLMs with web applications. Since late 2022, multiple frameworks, SDKs and tools
    have been introduced to demonstrate the integration of LLMs with web applications
    or business tools in format of simple prototypes. With significant investments
    flowing into creating Generative AI-based applications and tools for business
    use, it is becoming essential to bring these prototypes to production stage and
    derive business value. If you’ve set out to spend your time and money in building
    an LLM-native tool, how do you make sure that the investment will pay off in long-term?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）正在迅速改变我们对人工智能的理解，并且通过将LLM与Web应用结合的创新设计，已经显现出显著的变化。自2022年底以来，多个框架、SDK和工具相继推出，展示了将LLM与Web应用或商业工具集成的简单原型。随着大量投资流入基于生成性AI的商业应用和工具，逐渐将这些原型推向生产阶段并创造商业价值变得至关重要。如果你打算投入时间和金钱来构建一个LLM原生工具，如何确保这笔投资能够在长期内获得回报？
- en: In order to achieve this, it is crucial to establish a set of best practices
    for developing LLM applications. My journey in developing LLM applications in
    the past year has been incredibly exciting and full of learning. With nearly a
    decade of experience in designing and building web and cloud-native applications,
    I’ve realized that traditional product development norms often fall short for
    LLM-native applications. Instead, a continuous cycle of research, experimentation,
    and evaluation proves to be far more effective in creating superior AI-driven
    products.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一目标，必须建立一套开发LLM应用的最佳实践。我在过去一年中开发LLM应用的经历非常激动人心，充满了学习的机会。凭借近十年的Web和云原生应用设计与构建经验，我意识到传统的产品开发规范往往无法满足LLM原生应用的需求。相反，持续的研究、实验和评估循环在创建优秀的AI驱动产品方面更为有效。
- en: In order to help you navigate the challenges of LLM applications development,
    I will talk about best practices in the following key focus areas — *use case
    selection, team mindset, development approach, responsible AI and cost management*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助你应对LLM应用开发中的挑战，我将在以下关键领域讨论最佳实践——*使用案例选择、团队心态、开发方法、负责任的AI和成本管理*。
- en: 'Ideation: Choosing the right use case'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创意生成：选择合适的使用案例
- en: Does every problem require AI for solution? The answer is a hard ‘no’. Rather
    ask yourself that which business scenario can benefit most from leveraging LLMs?
    The businesses need to ask these questions before setting out to build an app.
    Sometimes, the right use case is right in front of us, other times talking to
    your co-workers or researching within your organization can point you to the right
    direction. Here are few aspects that might help you to decide.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 每个问题都需要AI来解决吗？答案是否定的。相反，你应该问自己，哪个业务场景最能从利用LLM中受益？企业在开始构建应用程序之前需要问这些问题。有时候，合适的用例就在我们面前，其他时候，与同事交谈或在组织内进行研究可能会引导你找到正确的方向。以下是一些可能帮助你做出决定的方面。
- en: '**Does the proposed solution has a market need?** Conduct a market research
    for the proposed use case to understand the current landscape. Identify any existing
    solution with or without AI integration, their pros and cons, and any flaws that
    your proposed LLM application could fill. This involves analyzing competitors,
    industry trends, and customer feedback.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提议的解决方案有市场需求吗？** 对提议的用例进行市场调研，了解当前的市场情况。识别任何现有的解决方案，无论是否集成了AI，分析它们的优缺点，以及你的LLM应用可以填补的空白。这涉及对竞争对手、行业趋势和客户反馈的分析。'
- en: '**Does it help the users?** If your proposed solution aims to serve users within
    your organization, a common measure of user expectations is to check if the solution
    can enhance their productivity by saving time. A common example is IT or HR support
    chatbot to help employees with day-to-day queries about their organization. Additionally,
    conducting a short survey with potential users can also help to understand the
    pain points that can be addressed with AI.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**它是否帮助了用户？** 如果你提议的解决方案旨在服务于组织内部的用户，一种常见的衡量用户期望的方式是检查该解决方案是否能够通过节省时间提高他们的生产力。一个常见的例子是IT或HR支持的聊天机器人，帮助员工解决关于组织日常问题的查询。此外，进行一项简短的调查，了解潜在用户的痛点，也有助于理解可以通过AI来解决的问题。'
- en: '**Does it accelerate business processes?** Another type of use cases might
    be addressing business process improvement, indirectly impacting users. Examples
    include sentiment analysis of call center transcripts, generating personalized
    recommendations, summarizing legal and financial documents etc. For this type
    of use cases, implementing automation can become a key factor to integrate LLM
    in a regular business process.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**它是否加速了业务流程？** 另一类用例可能是解决业务流程改进，间接影响用户。例如包括对呼叫中心转录的情感分析、生成个性化推荐、总结法律和金融文档等。对于这种类型的用例，实现自动化可以成为将大语言模型（LLM）融入常规业务流程的关键因素。'
- en: '**Do we have the data available?** Most LLM-native applications use RAG(Retrieval
    Augmented Generation) principle to generate contextual and grounded answer from
    specific knowledge documents. The root of any RAG based solution is the availability,
    type and quality of the data. If you do not have adequate knowledge base, or good
    quality data, the end result from your solution might not be up to the mark. Accessibility
    of the data is also important, as confidential or sensitive data might not always
    be available at your hand.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**我们有可用的数据吗？** 大多数基于LLM的应用程序使用RAG（检索增强生成）原则，从特定的知识文档中生成有上下文且有根据的答案。任何基于RAG的解决方案的核心在于数据的可用性、类型和质量。如果你没有足够的知识库或高质量的数据，你的解决方案的最终结果可能无法达到预期。数据的可访问性也很重要，因为机密或敏感数据可能并不总是触手可得。'
- en: '**Is the proposed solution feasible?** Determining whether to implement the
    AI solution depends not only on the technical feasibility, but also on the ethical,
    legal and financial aspects. If sensitive data is involved, then privacy and regulatory
    compliance should also be taken into consideration before finalizing the use case.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提议的解决方案可行吗？** 是否实施AI解决方案不仅取决于技术可行性，还涉及伦理、法律和财务等方面。如果涉及敏感数据，则在最终确定用例之前，还应考虑隐私和法规遵从性。'
- en: '**Does the solution meet your business requirements?** Think about the short-term
    and long-term business goals that your AI solution can serve. Managing expectations
    is also crucial here, since being too ambitious with short-term goals might not
    help with value realization. Reaping the benefits from AI applications is usually
    a long-term process.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**解决方案符合你的业务需求吗？** 思考你的AI解决方案可以服务的短期和长期业务目标。管理期望值也是至关重要的，因为过于雄心勃勃的短期目标可能不会有助于实现价值。从AI应用中获取收益通常是一个长期过程。'
- en: Setting right expectations
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置正确的期望值
- en: Along with choosing the use case, the product owner should also think about
    setting the right expectations and short, attainable milestones for the team.
    Each milestones should have clear goals and timeline defined and agreed upon by
    the team, so that stakeholders can review the outcome in a periodic manner. This
    is also crucial to make informed decision on how to move forward with the proposed
    LLM-based solution, productionizing strategy, onboarding users etc.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择用例的同时，产品负责人还应考虑设定正确的期望值以及为团队设定短期且可达成的里程碑。每个里程碑应有明确的目标和时间表，并且得到团队的定义和一致同意，这样利益相关者才能定期审查结果。这对于做出有关如何推进所提议的基于LLM的解决方案、生产化策略、用户引导等方面的明智决策至关重要。
- en: 'Experimentation: Adopting the right ‘mindset’'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验：采用正确的‘心态’
- en: Research and experiments are at the heart of any exercise that involves AI.
    Building LLM applications is no different. Unlike traditional web apps that follow
    a pre-decided design that has little to no variation, AI-based designs rely heavily
    on the experiments and can change depending on early outcomes. The success factor
    is experimenting on clearly defined expectations in iterations, followed by continuously
    evaluating each iteration. In LLM-native development, the success criteria is
    usually the quality of the output, which means that the focus is on producing
    accurate and highly relevant results. This can be either a response from chatbot,
    text summary, image generation or even an action (Agentic approach) defined by
    LLM. Generating quality results consistently requires a deep understanding of
    the underlying language models, constant fine-tuning of the prompts, and rigorous
    evaluation to ensure that the application meets the desired standards.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 研究和实验是任何涉及AI的工作核心。构建LLM应用程序也不例外。与传统的Web应用程序不同，后者遵循一个预先决定的设计，变化极少或没有变化，而基于AI的设计则高度依赖实验，并且可能根据早期的结果发生变化。成功的关键在于在明确预期的基础上进行迭代实验，之后不断评估每次迭代的结果。在LLM原生开发中，成功标准通常是输出的质量，这意味着重点在于生成准确且高度相关的结果。这些结果可以是聊天机器人的回复、文本摘要、图像生成，甚至是LLM定义的一个动作（Agentic方法）。要始终如一地生成高质量的结果，需要对底层语言模型有深入的理解，不断微调提示词，并进行严格的评估，以确保应用程序符合期望标准。
- en: What kind of tech skill set do you need in the team?
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 团队需要什么样的技术技能组合？
- en: You might assume that a team with only a handful of data scientists is sufficient
    to build you an LLM application. But in reality, engineering skills are equally
    or more important to actually ‘deliver’ the target product, as LLM applications
    do not follow the classical ML approach. For both data scientists and software
    engineers, some mindset shifts are required to get familiar with the development
    approach. I have seen both roles making this journey, such as data scientists
    getting familiar with cloud infrastructure and application deployment and on the
    other hand, engineers familiarizing themselves with the intricacies of model usage
    and evaluation of LLM outputs. Ultimately, you need *AI practitioners* in team
    who are not there just to ‘code’, rather research, collaborate and improve on
    the AI applicability.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为只有少数数据科学家的团队就足以为你构建一个LLM应用程序。但实际上，工程技能同样重要，甚至更为关键，因为LLM应用程序并不遵循传统的机器学习方法。无论是数据科学家还是软件工程师，都需要改变一些心态，以熟悉开发方法。我见过这两个角色都经历了这样的过程，例如，数据科学家开始熟悉云基础设施和应用程序部署，而工程师则开始了解模型使用的复杂性以及评估LLM输出的方式。最终，你需要团队中有*AI从业者*，他们不仅仅是来‘编程’的，而是来研究、协作并改进AI的适用性。
- en: Do I really need to ‘experiment’ since we are going to use pre-trained language
    models?
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 既然我们要使用预训练的语言模型，真的需要‘实验’吗？
- en: Popular LLMs like GPT-4o are already trained on large set of data and capable
    of recognizing and generating texts, images etc., hence you do not need to ‘train’
    these types of model. Very few scenarios might require to fine-tune the model
    but that is also achievable easily without needing classical ML approach. However,
    let’s not confuse the term ‘experiment’ with ‘model training’ methodology used
    in predictive ML. As I’ve mentioned above that quality of the application output
    matters. setting up iterations of experiments can help us to reach the target
    quality of result. For example — if you’re building a chatbot and you want to
    control how the bot output should look like to end user, an iterative and experimental
    approach on prompt improvement and fine-tuning hyper parameters will help you
    find the right way to generate most accurate and consistent output.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 像GPT-4o这样流行的LLM已经在大量数据集上进行了训练，能够识别和生成文本、图像等，因此你无需“训练”这些类型的模型。很少有场景需要微调模型，但这也可以轻松实现，无需传统的机器学习方法。然而，我们不要将“实验”一词与用于预测性机器学习中的“模型训练”方法混淆。正如我在上面提到的，应用程序输出的质量很重要。设置实验迭代可以帮助我们达到目标质量。例如——如果你正在构建一个聊天机器人，并且你希望控制机器人的输出如何呈现给最终用户，那么通过在提示改进和超参数微调上的迭代和实验性方法，将帮助你找到生成最准确、一致输出的正确方法。
- en: Build a prototype early in your journey
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在项目初期尽早构建原型。
- en: Build a prototype (also referred to as MVP — minimum viable product) with only
    the core functionalities as early as possible, ideally within 2–4 weeks. If you’re
    using a knowledge base for RAG approach, use a subset of data to avoid extensive
    data pre-processing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽早构建一个只包含核心功能的原型（也称为最小可行产品MVP），理想情况下是在2-4周内。如果你正在使用知识库进行RAG方法，使用数据子集来避免过多的数据预处理。
- en: Gaining quick feedback from a subset of target users helps you to understand
    whether the solution is meeting their expectations.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从目标用户子集获取快速反馈，帮助你了解解决方案是否满足他们的期望。
- en: Review with stakeholders to not only show the good results, also discuss the
    limitations and constraints your team found out during prototype building. This
    is crucial to mitigate risks early, and also to make informed decision regarding
    delivery.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与利益相关者进行审查，不仅要展示好的结果，还要讨论团队在原型构建过程中发现的局限性和约束条件。这对于尽早减轻风险至关重要，也有助于在交付决策时做出知情判断。
- en: The team can finalize the tech stack, security and scalability requirements
    to move the prototype to fully functional product and delivery timeline.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队可以最终确定技术栈、安全性和可扩展性要求，以便将原型转化为完全功能的产品并确定交付时间表。
- en: Determine if your prototype is ready for building into the ‘product’
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定你的原型是否已经准备好转变为“产品”。
- en: 'Availability of multiple AI-focused samples have made it super easy to create
    a prototype, and initial testing of such prototypes usually delivers promising
    results. By the time the prototype is ready, the team might have more understanding
    on success criteria, market research, target user base, platform requirements
    etc. At this point, considering following questions can help to decide the direction
    to which the product can move:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 多个以AI为重点的样本的可用性使得创建原型变得非常容易，且这些原型的初步测试通常会提供有前景的结果。当原型准备好时，团队可能会对成功标准、市场调研、目标用户群体、平台需求等有更深入的了解。在这一点上，考虑以下问题可以帮助决定产品发展的方向：
- en: Does the functionalities developed in the prototype serve the primary need of
    the end users or business process?
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 原型中开发的功能是否满足最终用户或业务流程的主要需求？
- en: What are the challenges that team faced during prototype development that might
    come up in production journey? Are there any methods to mitigate these risks?
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 团队在原型开发过程中遇到了哪些挑战，这些挑战在生产过程中可能会再次出现？是否有方法可以减轻这些风险？
- en: Does the prototype pose any risk with regards to responsible AI principles?
    If so, then what guardrails can be implemented to avoid these risks? (*We’ll discuss
    more on this point in part 2*)
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 原型是否存在违反负责任AI原则的风险？如果是，那么可以实施哪些保护措施来避免这些风险？ (*我们将在第二部分进一步讨论此点*)
- en: If the solution is to be integrated into an existing product, what might be
    a show-stopper for that?
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果解决方案需要集成到现有产品中，可能会遇到哪些阻碍？
- en: If the solution handles sensitive data, are effective measures been taken to
    handle the data privacy and security?
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果解决方案涉及敏感数据，是否已经采取了有效的措施来处理数据隐私和安全问题？
- en: Do you need to define any performance requirement for the product? Is the prototype
    results promising in this aspect or can be improved further?
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你是否需要为产品定义任何性能要求？原型结果在这一方面是否有前景，或者还能进一步改进？
- en: What are the security requirements does your product need?
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的产品需要哪些安全要求？
- en: Does your product need any UI? (A common LLM-based use case is chatbot, hence
    UI requirements are necessary to be defined as early as possible)
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的产品需要任何UI吗？（一个常见的基于LLM的用例是聊天机器人，因此UI需求需要尽早定义）
- en: Do you have a cost estimate for the LLM usage from your MVP? How does it look
    like considering the estimated scale of usage in production and your budget?
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你是否有关于MVP中LLM使用的成本估算？考虑到生产环境中的预计使用规模和你的预算，它看起来如何？
- en: If you can gain satisfactory answers to most of the questions after initial
    review, coupled with good results from your prototype, then you can move forward
    with the product development.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在初步审查后，你能对大多数问题得到令人满意的回答，并且你的原型有良好的结果，那么你可以继续进行产品开发。
- en: Stay tuned for part 2 where I will talk about ***what should be your approach
    to product development, how you can implement responsible AI early into the product
    and cost management techniques.***
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 敬请期待第二部分，我将在其中讨论***你应该采取什么样的产品开发方法，如何在产品中早期实现负责任的人工智能以及成本管理技巧。***
- en: '*Please follow me if you want to read more such content about new and exciting
    technology. If you have any feedback, please leave a comment. Thanks :)*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你想阅读更多关于新兴和令人兴奋的技术的内容，请关注我。如果你有任何反馈，请留下评论。谢谢 :)*'
