- en: 'One Year of Consistent Kaggling: What Did It Teach Me?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一年的持续Kaggle实践：它教会了我什么？
- en: 原文：[https://towardsdatascience.com/1-year-of-continuous-kaggling-what-did-it-taught-me-d267c222cfa3?source=collection_archive---------1-----------------------#2024-05-11](https://towardsdatascience.com/1-year-of-continuous-kaggling-what-did-it-taught-me-d267c222cfa3?source=collection_archive---------1-----------------------#2024-05-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/1-year-of-continuous-kaggling-what-did-it-taught-me-d267c222cfa3?source=collection_archive---------1-----------------------#2024-05-11](https://towardsdatascience.com/1-year-of-continuous-kaggling-what-did-it-taught-me-d267c222cfa3?source=collection_archive---------1-----------------------#2024-05-11)
- en: Competitions are more valuable than other components
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 竞赛比其他组件更有价值
- en: '[](https://medium.com/@geremieyeo?source=post_page---byline--d267c222cfa3--------------------------------)[![Geremie
    Yeo](../Images/d218b1be15725937f7e70b6db49cb184.png)](https://medium.com/@geremieyeo?source=post_page---byline--d267c222cfa3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d267c222cfa3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d267c222cfa3--------------------------------)
    [Geremie Yeo](https://medium.com/@geremieyeo?source=post_page---byline--d267c222cfa3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@geremieyeo?source=post_page---byline--d267c222cfa3--------------------------------)[![Geremie
    Yeo](../Images/d218b1be15725937f7e70b6db49cb184.png)](https://medium.com/@geremieyeo?source=post_page---byline--d267c222cfa3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d267c222cfa3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d267c222cfa3--------------------------------)
    [Geremie Yeo](https://medium.com/@geremieyeo?source=post_page---byline--d267c222cfa3--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d267c222cfa3--------------------------------)
    ·5 min read·May 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d267c222cfa3--------------------------------)
    ·阅读时长5分钟·2024年5月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[Kaggle](https://www.kaggle.com/) is a platform for users to gain hands-on
    experience on practical data science and machine learning. It has 4 different
    progression components, namely Competitions, Datasets, Notebooks and Discussions.
    No prior experience in data science is necessary to get yourself started in using
    this platform and learn'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kaggle](https://www.kaggle.com/)是一个让用户在实践数据科学和机器学习方面获得动手经验的平台。它有四个不同的进阶组件，分别是竞赛、数据集、笔记本和讨论。使用这个平台并开始学习不需要数据科学方面的先前经验。'
- en: 'My background: I did my first project on Kaggle as part of a Machine Learning
    course in my Bachelor’s curriculum (Math + Comp Sci) in early 2023\. Since then
    I have been hooked to this platform as a **favorite pastime**. I have taken part
    in 20 competitions to date. I had no work/internship experience as a data scientist
    prior to starting Kaggle.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我的背景：我在2023年初在我的本科学位（数学与计算机科学）课程中完成了第一个Kaggle项目，这个项目是机器学习课程的一部分。从那时起，我就迷上了这个平台，将其作为**最喜欢的消遣**。到目前为止，我参加了20场竞赛。开始使用Kaggle之前，我没有作为数据科学家的工作或实习经验。
- en: In one year, I have made (I believe) significant progress in my Kaggle journey,
    including winning 2 gold competition medals, one of which I won 1st place and
    rising to the top 116 in the Competitions category, while barely missing a day
    of activity.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在一年时间里，我在Kaggle旅程中取得了（我认为）显著的进展，包括赢得了2枚金奖竞赛奖牌，其中一项我获得了第一名，并且在竞赛类别中跻身前116名，同时几乎没有错过任何一天的活动。
- en: '[My Kaggle Profile](https://www.kaggle.com/yeoyunsianggeremie)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[我的Kaggle个人主页](https://www.kaggle.com/yeoyunsianggeremie)'
- en: '![](../Images/e919c5318c1a0d336047ed28f21b0232.png)![](../Images/6d05e765021b51e73713d913d93bc87c.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e919c5318c1a0d336047ed28f21b0232.png)![](../Images/6d05e765021b51e73713d913d93bc87c.png)'
- en: Now, let’s dive into 3 key learnings from my Kaggle journey to date.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入探讨我在Kaggle旅程中至今得到的三大关键学习。
- en: '**Your team cannot solely rely on public notebooks to succeed in Competitions**'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**你的团队不能仅仅依赖公开的笔记本在竞赛中获得成功**'
- en: A standard Kaggle competition only awards Gold medals to the **top 10 + floor(NumTeams
    / 500) teams**! For example, in a competition with 2500 teams, only 15 teams win
    gold. This is **mandatory** for one to progress to the **Master** tier in competitions,
    and you need **five (including one solo)** to progress to the **Grandmaster**
    tier**.**
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的Kaggle竞赛只会颁发金奖给**前10名+ floor(NumTeams / 500)支队伍**！例如，在一个有2500支队伍的竞赛中，只有15支队伍能够获得金奖。要想晋升到竞赛中的**Master**等级，这**是强制性**要求，你需要**五枚金奖（其中至少一枚为个人赛金奖）**才能晋升到**Grandmaster**等级。
- en: It is very unlikely that your team could just briefly modify public work (such
    as ensembling public notebooks) and earn a spot in the gold zone. Your team will
    be competing against top-notch data scientists and grandmasters who have lots
    of creative ideas to approach the problem.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你的团队不太可能通过简单地修改公共工作（如集成公共笔记本）而获得金奖名次。你的团队将与顶尖的数据科学家和大师们竞争，他们有很多创造性的想法来解决问题。
- en: Briefly modifying public work is something even beginners to ML can do and it
    is unlikely your team’s solution stands out using this. Most likely, a small enhancement
    of a public notebook gets a bronze medal, or if lucky, a silver medal.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 简单修改公共工作是即使是机器学习初学者也能做到的事情，并且使用这种方法不太可能让你的团队的解决方案脱颖而出。很可能，稍微改进一个公共笔记本会获得铜奖，或者如果运气好，获得银奖。
- en: 'In the 2 competitions which my team won gold:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们团队赢得金奖的两场比赛中：
- en: '1/2048 (Champion) [PII Detection](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/overview):
    We used a wide variety of Deberta architectures and postprocessing strategies,
    most of which are not shared in the public forums. No public models were used
    in our final ensemble'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1/2048（冠军）[PII检测](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/overview)：我们使用了多种Deberta架构和后处理策略，其中大多数没有在公共论坛中分享。我们的最终集成模型中没有使用公共模型。
- en: '14/4436 [Optiver — Trading At The Close](https://www.kaggle.com/competitions/optiver-trading-at-the-close/overview):
    We used online training to make sure the model is fitted with the latest data
    before making the prediction. It was not easy to write an online training pipeline
    that worked on the private LB, and such an idea was not shared in the public forums,
    as far as I know. We did not use the [popular public training approach](https://www.kaggle.com/code/verracodeguacas/fold-cv)
    as we felt it was overfitting to the train data, despite its great public LB score'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 14/4436 [Optiver — 临近收盘交易](https://www.kaggle.com/competitions/optiver-trading-at-the-close/overview)：我们使用了在线训练，以确保模型在做出预测之前已经适配了最新的数据。编写在私有排行榜上有效的在线训练管道并不容易，据我所知，这个想法没有在公共论坛中分享。我们没有使用[流行的公共训练方法](https://www.kaggle.com/code/verracodeguacas/fold-cv)，因为我们认为它会对训练数据过拟合，尽管它的公共排行榜成绩非常好。
- en: 'In contrast, here is a competition in which my team won bronze:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，这是我们团队获得铜奖的一个比赛：
- en: '185/2664 [LLM Science Exam](https://www.kaggle.com/competitions/kaggle-llm-science-exam):
    We briefly modified a [public training pipeline](https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1)
    and a [public inference pipeline](https://www.kaggle.com/code/mbanaei/86-2-with-only-270k-articles),
    such as changing the embedding model, hyperparameters and ensembling. There was
    no creative ideas in our final solution'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 185/2664 [LLM科学考试](https://www.kaggle.com/competitions/kaggle-llm-science-exam)：我们简单修改了一个[公共训练管道](https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1)和一个[公共推理管道](https://www.kaggle.com/code/mbanaei/86-2-with-only-270k-articles)，例如更改了嵌入模型、超参数和集成方法。我们的最终方案中没有创意。
- en: 'Summary: In my opinion, it is better to spend more time analyzing the baseline,
    and research to think of enhancements. It may be a good idea to start with a small
    model (deberta-v3-xsmall for example) to evaluate ideas quickly. Aim to establish
    a robust cross-validation strategy from the very beginning.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 总结：在我看来，花更多时间分析基准，并进行研究以思考如何改进是更好的做法。可能从一个小模型（例如deberta-v3-xsmall）开始，以快速评估想法是一个不错的选择。目标是从一开始就建立一个稳健的交叉验证策略。
- en: 2\. **You learn much more from the Competitions category compared to Datasets/Notebooks/Discussions**
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **相比数据集/笔记本/讨论，你从比赛类别中学到的更多。**
- en: Some of the **real-world** skills I learnt
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我所学到的一些**真实世界**技能。
- en: I was the team leader for most of the competitions I participated in, including
    both of them which my team won the gold medal. It has drastically improved my
    communication and leadership skills.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是大部分比赛的队长，其中包括我们团队赢得金奖的两场比赛。这大大提升了我的沟通和领导能力。
- en: Collaborating with other data scientists/engineers from different countries
    and timezones, and learning good practices from them
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与来自不同国家和时区的其他数据科学家/工程师合作，并向他们学习最佳实践。
- en: Using [Wandb](https://wandb.ai/site) to track and log experiments
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[Wandb](https://wandb.ai/site)跟踪和记录实验。
- en: Customizing architectures of transformer models
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定制化变换器模型的架构
- en: Generating use-case specific synthetic datasets using LLMs
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLM生成特定用例的合成数据集。
- en: How to model a real-world use case in a data science perspective
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据科学角度建模真实世界的用例。
- en: Writing clean code that is easily understandable
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写简洁、易于理解的代码。
- en: How to utilize multi-GPU training
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何利用多GPU训练
- en: Better time management
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更好的时间管理
- en: Evaluating and mitigating model mistakes
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估并减轻模型错误
- en: In contrast, it is much easier to progress in datasets/notebooks/discussions
    without learning much about data science. In discussions, a user can earn gold
    discussion medals by posting his/her accomplishments on the Kaggle forum. I doubt
    I would learn most of the skills above without doing competitions. In my opinion,
    progress on datasets/notebooks/discussions does not necessarily tell that one
    is passionate about data science.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，在数据集/笔记本/讨论中进展要容易得多，而无需深入学习数据科学。在讨论中，用户可以通过在Kaggle论坛发布自己的成就来获得金奖讨论奖牌。我怀疑如果没有参与竞赛，我大多数技能是无法学到的。在我看来，在数据集/笔记本/讨论中的进展不一定说明一个人对数据科学充满热情。
- en: 3\. **Playground Competitions is a great way to start for beginners**
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. **游乐场竞赛是初学者入门的好方式**
- en: The playground series simulate the featured competitions, except that it is
    more beginner-friendly and do not award medals/prizes. In playgrounds, you make
    predictions on a tabular dataset, which allows you to learn the basics of coding
    an ML pipeline. Plenty of notebooks are shared in playgrounds, both tabular and
    NN (neural network) approaches, so if you are stuck, those public notebooks are
    a good reference.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 游乐场系列模拟了特色竞赛，只不过它更加适合初学者，并且不颁发奖牌/奖品。在游乐场中，你需要在表格数据集上做预测，这让你能够学习如何编写机器学习管道的基础。游乐场中有很多共享的笔记本，既有表格数据方法也有神经网络（NN）方法，所以如果你卡住了，那些公共笔记本是一个很好的参考。
- en: Each playground series competition is about 1 month long.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 每个游乐场系列的竞赛大约持续1个月。
- en: 'Based on my experience, the playground competitions taught me:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，游乐场竞赛教会了我：
- en: How to build a robust cross-validation strategy and not overfit the public LB
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何建立一个稳健的交叉验证策略，避免在公共排行榜上过拟合
- en: How to select submissions for evaluation
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何选择提交内容进行评估
- en: How to perform feature engineering and feature selection
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何进行特征工程和特征选择
- en: How to style a Jupyter Notebook
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何设计Jupyter笔记本的样式
- en: (More on the data engineering side of things) How to use [Polars](https://pola.rs/).
    This is a much faster dataframe library than Pandas and is better suited for big
    data use cases
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （更多关于数据工程方面的内容）如何使用[Polars](https://pola.rs/)。这是一种比Pandas更快的DataFrame库，更适用于大数据场景
- en: In conclusion, I feel the most rewarding part from doing Kaggle is the hands-on
    experience in competitions and the opportunity to collaborate with data professionals
    from around the globe. I get to solve a wide variety of problems ranging from
    tabular to more advanced NLP tasks. Looking forward to more as I continue to improve
    myself in the field of data science!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我觉得做Kaggle最有收获的部分是竞赛中的实战经验，以及与全球数据专业人士合作的机会。我得以解决各种问题，从表格数据到更高级的自然语言处理任务。期待在数据科学领域继续提高自己！
