<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Creating an Assistant with OpenAI Assistant API and Streamlit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Creating an Assistant with OpenAI Assistant API and Streamlit</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-an-assistant-with-openai-assistant-api-and-streamlit-282d9be9f03e?source=collection_archive---------4-----------------------#2024-06-18">https://towardsdatascience.com/creating-an-assistant-with-openai-assistant-api-and-streamlit-282d9be9f03e?source=collection_archive---------4-----------------------#2024-06-18</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="4db3" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A step-by-step guide</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vanillaxiangshuyang?source=post_page---byline--282d9be9f03e--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Shuyang Xiang" class="l ep by dd de cx" src="../Images/36a5fd18fd9b7b88cb41094f09b83882.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*Q-6F64L3h4jxYNYPiqHVaQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--282d9be9f03e--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@vanillaxiangshuyang?source=post_page---byline--282d9be9f03e--------------------------------" rel="noopener follow">Shuyang Xiang</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--282d9be9f03e--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 18, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ml"><img src="../Images/c668f6173825f0585d7ec25aca505ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*bX5eqE7EUmnwxWuqjZDzIQ.gif"/></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by author: assistant done with assistant api and streamlit</figcaption></figure><h1 id="e239" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">OpenAI Assistant API</h1><p id="7433" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">OpenAI has recently introduced new features that showcase an agent-like architecture, such as the Assistant API. According to OpenAI:</p><blockquote class="oq or os"><p id="85d0" class="nu nv ot nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">The Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and files to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, File Search, and Function calling.</p></blockquote><p id="57d7" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">While these advancements are promising, they still lag behind LangChain. LangChain enables the creation of agent-like systems powered by LLMs with greater flexibility in processing natural language input and executing context-based actions.</p><p id="2942" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">However, this is only the beginning.</p><p id="e491" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">At a high level, interaction with the Assistant API can be envisioned as a loop:</p><ul class=""><li id="2d76" class="nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op oz pa pb bk">Given a user input, an LLM is called to determine whether to provide a response or take specific actions.</li><li id="3394" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op oz pa pb bk">If the LLM’s decision suffices to answer the query, the loop ends.</li><li id="ea68" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op oz pa pb bk">If an action leads to a new observation, this observation is included in the prompt, and the LLM is called again.</li><li id="71c6" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op oz pa pb bk">The loop then restarts.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="pi pj ed pk bh pl"><div class="mj mk ph"><img src="../Images/070f496f4c9531b9c9a982299f110bdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9tUzk7PdL-vvXJzBMEILog.png"/></div></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by author: LLM agent loop</figcaption></figure><p id="0bb6" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">Unfortunately, despite the announced advantages, I found the documentation for the API to be poorly done, especially regarding interactions with custom function calls and building apps using frameworks like Streamlit.</p><p id="ae6a" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">In this blog post, I will guide you through building an AI assistant using the OpenAI Assistant API with custom function calls, paired with a Streamlit interface, to help those interested in effectively using the Assistant API.</p><h1 id="c880" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Use case: Tax Computation Assistant</h1><p id="0c87" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">In this blog post, I will demonstrate a simple example: an AI assistant capable of calculating tax based on a given revenue. Langchain users can easily come into mind implementing this by creating an <a class="af pm" href="https://python.langchain.com/v0.1/docs/modules/agents/" rel="noopener ugc nofollow" target="_blank">agent</a> with a “tax computation” tool.</p><p id="ff1e" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">This tool would include the necessary computation steps and a well-designed prompt to ensure the LLM knows when to call the tool whenever a question involves revenue or tax.</p><p id="006b" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">However, this process is not exactly the same with the OpenAI Assistant API. While the code interpreter and file search tools can be used directly in a straightforward manner according to <a class="af pm" href="https://platform.openai.com/docs/assistants/how-it-works/creating-assistants" rel="noopener ugc nofollow" target="_blank">OpenAI’s documentation</a>, custom tools require a slightly different approach.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="2b3a" class="pr mz fq po b bg ps pt l pu pv">assistant = client.beta.assistants.create(<br/>  name="Data visualizer",<br/>  description="You are great at creating beautiful data visualizations. You analyze data present in .csv files, understand trends, and come up with data visualizations relevant to those trends. You also share a brief text summary of the trends observed.",<br/>  model="gpt-4o",<br/>  tools=[{"type": "code_interpreter"}],<br/>)</span></pre><p id="1e71" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">Let’s break it down step by step. We aim to:</p><ol class=""><li id="076e" class="nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op pw pa pb bk">Define a function that computes tax based on given revenue.</li><li id="1d29" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op pw pa pb bk">Develop a tool using this function.</li><li id="c5a2" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op pw pa pb bk">Create an assistant that can access this tool and call it whenever tax computation is needed.</li></ol><h1 id="fece" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Tax Computation Function for Assistant Integration</h1><p id="dae8" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Please note that the tax computation tool described in the following paragraph is designed as a toy example to demonstrate how to use the API discussed in the post. It should not be used for actual tax calculations.</p><p id="c855" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">Consider the following piecewise function, which returns the tax value for a given revenue. Note that the input is set as a string for simpler parsing:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="03e5" class="pr mz fq po b bg ps pt l pu pv">def calculate_tax(revenue: str):<br/>    try:<br/>        revenue = float(revenue)<br/>    except ValueError:<br/>        raise ValueError("The revenue should be a string representation of a number.")<br/><br/>    if revenue &lt;= 10000:<br/>        tax = 0<br/>    elif revenue &lt;= 30000:<br/>        tax = 0.10 * (revenue - 10000)<br/>    elif revenue &lt;= 70000:<br/>        tax = 2000 + 0.20 * (revenue - 30000)<br/>    elif revenue &lt;= 150000:<br/>        tax = 10000 + 0.30 * (revenue - 70000)<br/>    else:<br/>        tax = 34000 + 0.40 * (revenue - 150000)<br/><br/>    return tax</span></pre><p id="9408" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">Next, we define the assistant:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="d1ea" class="pr mz fq po b bg ps pt l pu pv">function_tools = [<br/>    {<br/>        "type": "function",<br/>        "function": {<br/>            "name": "calculate_tax",<br/>            "description": "Get the tax for given revenue in euro",<br/>            "parameters": {<br/>                "type": "object",<br/>                "properties": {<br/>                    "revenue": {<br/>                        "type": "string",<br/>                        "description": "Annual revenue in euro"<br/>                    }<br/>                },<br/>                "required": ["revenue"]<br/>            }<br/>        }<br/>    }<br/>]<br/># Define the assistant<br/>assistant = client.beta.assistants.create(<br/>    name="Assistant",<br/>    instructions="",<br/>    tools=function_tools,<br/>    model="gpt-4o",<br/>)</span></pre><p id="88cc" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">Now, the essential point:</p><p id="cfd0" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">How does the assistant use the function when “calculate_tax” is called? This part is poorly documented in the OpenAI assistant, and many users might get confused the first time using it. To handle this, we need to define an <code class="cx px py pz po b">EventHandler</code> to manage different events in the response stream, specifically how to handle the event when the "calculate_tax" tool is called.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="0181" class="pr mz fq po b bg ps pt l pu pv">    def handle_requires_action(self, data, run_id):<br/>        tool_outputs = []<br/><br/>        for tool in data.required_action.submit_tool_outputs.tool_calls:<br/>            if tool.function.name == "calculate_tax":<br/>                try:<br/>                    # Extract revenue from tool parameters<br/>                    revenue = ast.literal_eval(tool.function.arguments)["revenue"]<br/>                    # Call your calculate_tax function to get the tax<br/>                    tax_result = calculate_tax(revenue)<br/>                    # Append tool output in the required format<br/>                    tool_outputs.append({"tool_call_id": tool.id, "output": f"{tax_result}"})<br/>                except ValueError as e:<br/>                    # Handle any errors when calculating tax<br/>                    tool_outputs.append({"tool_call_id": tool.id, "error": str(e)})<br/>        # Submit all tool_outputs at the same time<br/>        self.submit_tool_outputs(tool_outputs)</span></pre><p id="6967" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">The code above works as follows: For each tool call that requires action:</p><ul class=""><li id="cfee" class="nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op oz pa pb bk">Check if the function name is “calculate_tax”.</li><li id="06b0" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op oz pa pb bk">Extract the revenue value from the tool parameters.</li><li id="1eaf" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op oz pa pb bk">Call the <code class="cx px py pz po b">calculate_tax</code> function with the revenue to compute the tax. (This is where the real interaction happens.)</li><li id="cc3e" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op oz pa pb bk">After processing all tool calls, submit the collected results.</li></ul><h1 id="eb43" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Talking to the assistant</h1><p id="7cf9" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">You can now interact with the assistant following these standard steps documented by OpenAI (for that reason, I will not provide many details in this section):</p><ol class=""><li id="5a9c" class="nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op pw pa pb bk"><strong class="nw fr">Create a thread:</strong> This represents a conversation between a user and the assistant.</li><li id="e5a6" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op pw pa pb bk"><strong class="nw fr">Add user messages:</strong> These can include both text and files, which are added to the thread.</li><li id="eb3b" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op pw pa pb bk"><strong class="nw fr">Create a run:</strong> Utilize the model and tools associated with the assistant to generate a response. This response is then added back to the thread.</li></ol><p id="c904" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">The code snippet below demonstrates how to run the assistant in my specific use case: The code sets up a streaming interaction with an assistant using specific parameters, including a thread ID and an assistant ID. An <code class="cx px py pz po b">EventHandler</code> instance manages events during the stream. The <code class="cx px py pz po b">stream.until_done()</code> method keeps the stream active until all interactions are complete. The <code class="cx px py pz po b">with</code> statement ensures that the stream is properly closed afterward.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="03fc" class="pr mz fq po b bg ps pt l pu pv">  with client.beta.threads.runs.stream(thread_id=st.session_state.thread_id,<br/>                                         assistant_id=assistant.id,<br/>                                         event_handler=EventHandler(),<br/>                                         temperature=0) as stream:<br/>        stream.until_done()</span></pre><h1 id="2969" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Streamlit interface</h1><p id="0b26" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">While my post could end here, I’ve noticed numerous inquiries on the Streamlit forum (<a class="af pm" href="https://discuss.streamlit.io/t/openai-assistants-api-streaming/64690/3" rel="noopener ugc nofollow" target="_blank">like this one</a>) where users struggle to get streaming to work on the interface, even though it functions perfectly in the terminal. This prompted me to delve deeper.</p><p id="1289" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">To successfully integrate streaming into your app, you’ll need to extend the functionality of the EventHandler class mentioned earlier, specifically focusing on handling text creation, text deltas, and text completion. Here are the three key steps required to display text in the Streamlit interface while managing chat history:</p><ol class=""><li id="f364" class="nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op pw pa pb bk"><strong class="nw fr">Handling Text Creation (</strong><code class="cx px py pz po b"><strong class="nw fr">on_text_created</strong></code><strong class="nw fr">):</strong> Initiates and displays a new text box for each response from the assistant, updating the UI to reflect the status of preceding actions.</li><li id="c7b0" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op pw pa pb bk"><strong class="nw fr">Handling Text Delta (</strong><code class="cx px py pz po b"><strong class="nw fr">on_text_delta</strong></code><strong class="nw fr">):</strong> Dynamically updates the current text box as the assistant generates text, enabling incremental changes without refreshing the entire UI.</li><li id="a29b" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op pw pa pb bk"><strong class="nw fr">Handling Text Completion (</strong><code class="cx px py pz po b"><strong class="nw fr">on_text_done</strong></code><strong class="nw fr">):</strong> Finalizes each interaction segment by adding a new empty text box, preparing for the next interaction. Additionally, it records completed conversation segments in <code class="cx px py pz po b">chat_history</code>.</li></ol><p id="d049" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">For instance, consider the following code snippet for managing text deltas:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="8c73" class="pr mz fq po b bg ps pt l pu pv">def on_text_delta(self, delta: TextDelta, snapshot: Text):<br/>    """<br/>    Handler for when a text delta is created<br/>    """<br/>    # Clear the latest text box<br/>    st.session_state.text_boxes[-1].empty()<br/>    <br/>    # If there is new text, append it to the latest element in the assistant text list<br/>    if delta.value:<br/>        st.session_state.assistant_text[-1] += delta.value<br/>    <br/>    # Re-display the updated assistant text in the latest text box<br/>    st.session_state.text_boxes[-1].info("".join(st.session_state["assistant_text"][-1]))</span></pre><p id="54fe" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">This code accomplishes three main tasks:</p><ul class=""><li id="2d0b" class="nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op oz pa pb bk"><strong class="nw fr">Clearing the Latest Text Box:</strong> Empties the content of the most recent text box (<code class="cx px py pz po b">st.session_state.text_boxes[-1]</code>) to prepare it for new input.</li><li id="6fa3" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op oz pa pb bk"><strong class="nw fr">Appending Delta Value to Assistant Text:</strong> If new text (<code class="cx px py pz po b">delta.value</code>) is present, it appends this to the ongoing assistant text stored in <code class="cx px py pz po b">st.session_state.assistant_text[-1]</code>.</li><li id="85cb" class="nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op oz pa pb bk"><strong class="nw fr">Re-displaying Updated Assistant Text:</strong> Updates the content of the latest text box to reflect the combined content of all assistant text accumulated so far (<code class="cx px py pz po b">st.session_state["assistant_text"][-1]</code>).</li></ul><figure class="mm mn mo mp mq mr"><div class="qa io l ed"><div class="qb qc l"/></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Video by author: the assistant done in this post</figcaption></figure><h1 id="7526" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Conclusion</h1><p id="17b4" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">This blog post demonstrated how to use the OpenAI Assistant API and Streamlit to build an AI assistant capable of calculating tax.</p><p id="2141" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">I did this simple project to highlight the capabilities of the Assistant API, despite its less-than-clear documentation. My goal was to clarify ambiguities and provide some guidance for those interested in using the Assistant API. I hope this post has been helpful and encourages you to explore further possibilities with this powerful tool.</p><p id="8c4e" class="pw-post-body-paragraph nu nv fq nw b go ou ny nz gr ov ob oc od ow of og oh ox oj ok ol oy on oo op fj bk">Due to space constraints, I have tried to avoid including unnecessary code snippets. However, if needed, please visit my <a class="af pm" href="https://github.com/ShuyangenFrance/openai_assistant" rel="noopener ugc nofollow" target="_blank">Github repository</a> to view the complete implementation.</p></div></div></div></div>    
</body>
</html>