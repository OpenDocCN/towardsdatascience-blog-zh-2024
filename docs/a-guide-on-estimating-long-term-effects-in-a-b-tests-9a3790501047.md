# A/B 测试中估算长期效应的指南

> 原文：[https://towardsdatascience.com/a-guide-on-estimating-long-term-effects-in-a-b-tests-9a3790501047?source=collection_archive---------9-----------------------#2024-02-24](https://towardsdatascience.com/a-guide-on-estimating-long-term-effects-in-a-b-tests-9a3790501047?source=collection_archive---------9-----------------------#2024-02-24)

## 解决在在线实验中识别和衡量长期效应的复杂性

[](https://medium.com/@kseniia.baidina?source=post_page---byline--9a3790501047--------------------------------)[![Kseniia Baidina](../Images/a6ee80021fb9b319d463006ce5952634.png)](https://medium.com/@kseniia.baidina?source=post_page---byline--9a3790501047--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9a3790501047--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9a3790501047--------------------------------) [Kseniia Baidina](https://medium.com/@kseniia.baidina?source=post_page---byline--9a3790501047--------------------------------)

·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9a3790501047--------------------------------) ·阅读时间 9 分钟 ·2024年2月24日

--

![](../Images/57e1dbb6b650f6237f9d43bad54dec94.png)

图片由[Isaac Smith](https://unsplash.com/@isaacmsmith?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)提供，来源于[Unsplash](https://unsplash.com/photos/pen-on-paper-6EnTPvPPL6I?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)

想象一下，你是一个在线商店的分析师。你和你的团队的目标是了解提供免费送货如何影响平台上的订单数量，于是你决定进行 A/B 测试。测试组享受免费送货，而对照组则坚持正常的运费。在实验的初期，你会看到更多人在将商品加入购物车后完成订单。但真正的影响是长期的——测试组的用户更有可能再次回到平台购物，因为他们知道你提供免费送货。

本例的核心结论是什么？免费送货对订单的影响往往是逐渐增加的。仅在短期内进行测试可能意味着你错过了整个故事，而这是我们在本文中旨在解决的挑战。

# 理解为什么长期效应和短期效应可能不同

总体而言，实验的短期效应与长期效应可能存在差异的原因有很多[1]：

*异质性处理效应*

+   实验的影响可能因产品的常用用户和偶尔使用者而有所不同。在短期内，常用用户可能会对实验结果产生不成比例的影响，从而引入对平均处理效应的偏差。

*用户学习*

+   新颖效应 —— 想象一下：你向产品中引入了新的游戏化机制。最初，用户会感到好奇，但这一效应通常会随着时间的推移而减少。

+   初始效应 —— 想象一下，当Facebook将排名算法从按时间顺序显示改为推荐时。最初，用户可能会因为无法找到预期内容而导致信息流中的时间减少，产生挫败感。然而，随着时间的推移，随着用户逐渐适应新算法并发现有趣的帖子，互动可能会恢复。用户最初可能反应消极，但最终会适应，从而导致互动增加。

在本文中，我们的重点将放在回答两个问题：

> 如何识别和测试实验的长期影响是否与短期有所不同？
> 
> 当实验不能进行足够长的时间时，如何估计长期效应？

# 识别长期效应趋势的方法

## 可视化

初始步骤是观察测试组与控制组之间的差异如何随时间变化。如果你注意到类似的模式，就需要深入细节，理解长期效应。

![](../Images/ebe54510b9c4c097b8e52642dc962476.png)

[我](https://arxiv.org/pdf/2102.12893.pdf)来自Sadeghi等人（2021）的插图[2]

你可能也会觉得有诱惑去绘制实验效果，不仅基于实验的日期，还基于自第一次接触以来的天数。

![](../Images/fab48d1bbf252e97184834534a975f8c.png)

[我](https://arxiv.org/pdf/2102.12893.pdf)来自Sadeghi等人（2021）的插图[2]

然而，当你查看自第一次接触以来的天数时，有几个陷阱需要注意：

+   *参与用户偏差*：图表的右侧可能显示更多的活跃用户。观察到的模式可能并非由于用户学习，而是因为不同的处理效应。对高度活跃用户的影响可能与对偶尔用户的影响不同。

+   *选择性抽样问题*：我们可以决定仅关注高度活跃的用户，观察他们的效应如何随时间演变。然而，这一子集可能无法准确代表整个用户群体。

+   *用户数量下降*：从第一次接触开始已经有较长时间的用户可能很少（图表的右侧部分）。这会扩大置信区间，使得得出可靠结论变得更加困难。

在实验中识别长期效应的可视化方法非常直观，通常观察效果随时间的变化是一个很好的起点。然而，这种方法缺乏严谨性；你也可以考虑正式测试长期效应的存在。我们将在下一部分深入探讨这一点。

## 阶梯实验任务[2]

这种方法背后的概念如下：在开始实验之前，我们将用户分为*k*个队列，并逐步将他们引入实验。例如，如果我们将用户分为4个队列，*k_1*为对照组，*k_2*从第1周开始接受处理，*k_3*从第2周开始接受处理，*k_4*从第3周开始接受处理。

![](../Images/b23011c3e7a8b1121eb5cfdae3603e4a.png)

[我](https://arxiv.org/pdf/2102.12893.pdf)摘自Sadeghi等人（2021年）²

用户学习率可以通过比较不同时间段的处理效果来估计。

![](../Images/5496aab0b7ccdaedc93a2e7a05aa0cd8.png)

[我](https://arxiv.org/pdf/2102.12893.pdf)摘自Sadeghi等人（2021年）[2]

例如，如果你想估计第4周的用户学习情况，你可以比较值*T4_5*和*T4_2*。

这种方法的挑战非常明显。首先，它为实验设计引入了额外的操作复杂性。其次，需要大量用户才能有效地将其分成不同的队列，并获得合理的统计显著性水平。第三，应该提前预期到不同的长期效应，并准备在这种复杂环境中进行实验。

## 差分中的差分 [2]

这种方法是前一种方法的简化版。我们将实验分成两个（或更一般的，分成*k*）时间段，并比较第一个时间段和第*k*个时间段的处理效果。

![](../Images/7317a638c2acd81df3f46586f503d599.png)

[我](https://arxiv.org/pdf/2102.12893.pdf)摘自Sadeghi等人（2021年）[2]

在这种方法中，一个关键问题是如何估计估计值的方差，以便得出关于统计显著性的结论。作者建议使用以下公式（详细信息请参阅文章）：

![](../Images/8009f071299337c4fc666708239b8859.png)

[我](https://arxiv.org/pdf/2102.12893.pdf)摘自Sadeghi等人（2021年）[2]

*σ2* — 每个实验单元在每个时间窗口内的方差

*ρ* — 每个实验单元在两个时间窗口中的度量相关性

## 随机与恒定处理分配 [3]

这是阶梯实验分配的另一种扩展方法。在这种方法中，用户池被分为三组：*C* — 对照组，*E* — 在整个实验中都接受处理的组，*E1* — 每天以概率*p*将用户分配到处理组的组。因此，*E1*组中的每个用户只会在几天内接受处理，从而防止了用户的学习。那么，如何估计用户的学习情况呢？我们引入*E1_d* — *E1*组中在第*d*天接受处理的用户比例。然后，用户学习率由*E*组和*E1_d*组之间的差异来确定。

## 用户“遗忘”[3]

这种方法使我们能够评估用户学习的存在性以及这种学习的持续时间。这个概念相当优雅：它假设用户的学习速率与他们“遗忘”的速率相同。其思路如下：关闭实验并观察测试组和对照组随着时间的推移如何趋同。由于两组在实验结束后将接受相同的处理，任何行为的变化都将是因为实验期间不同的处理方式。

这种方法帮助我们衡量用户“遗忘”实验所需的时间，我们假设这个遗忘期将等同于用户在功能推出期间所需的学习时间。

这种方法有两个显著的缺点：首先，它需要大量时间来分析用户学习。最初，你需要运行一个长期的实验以让用户“学习”，然后你必须停用实验并等待他们“遗忘”。这个过程可能非常耗时。其次，你需要停用实验功能，这可能会让企业犹豫不决。

# 评估长期效果的方法 [4]

你已经成功确认了实验中用户学习的存在性，并且很明显，长期结果可能与短期观察的结果不同。那么，现在的问题是如何在不进行数周甚至数月实验的情况下预测这些长期结果。

一种方法是尝试使用短期数据预测长期结果 *Y*。最简单的方法是使用 *Y* 的滞后值，这被称为“自动替代”模型。假设你想预测实验结果在两个月后的表现，但目前只有两周的数据。在这种情况下，你可以训练一个线性回归（或其他）模型：

![](../Images/dad84ab54798e76c9f05f7e1b0b618aa.png)

[我](https://arxiv.org/pdf/2102.12893.pdf)来自张等人（2023）的插图 [5]

*m* 是用户 *i* 在两个月期间的平均每日结果

*Yi_t* 是用户 *i* 在第 *t* 天的度量值（在我们的例子中，*T* 范围是从 1 到 14）

在这种情况下，长期治疗效果是通过使用替代模型，测试组和对照组的度量预测值之间的差异来决定的。

![](../Images/b7241935cba06b8faac86270b181f439.png)

[我](https://arxiv.org/pdf/2102.12893.pdf)来自张等人（2023）的插图 [5]

其中，*N_a* 表示实验组的用户数量，*N_0* 表示对照组的用户数量。

这里似乎有些不一致：我们目标是预测***μ***（实验的长期效果），但训练模型时却需要这个***μ***。那么，我们该如何获得模型呢？有两种方法：

+   *使用实验前数据：* 我们可以使用同一用户的两个月实验前数据来训练一个模型。

+   *类似实验：* 我们可以从相同产品领域选择一个持续了两个月的“黄金标准”实验，并用它来训练模型。

在他们的文章中，Netflix 使用 200 次实验验证了这种方法，并得出结论：在 95% 的实验中，代理指数模型与长期测量结果一致[5]。

# 结论

我们学到了很多，现在让我们来总结一下。短期实验结果通常与长期结果不同，原因可能包括异质性处理效应或用户学习等因素。有几种方法可以检测这种差异，其中最直接的方法是：

+   *视觉方法：* 简单地观察测试组和对照组随时间的差异。然而，这种方法缺乏严谨性。

+   *差异中的差异：* 比较实验开始时和一段时间后测试组与对照组之间的差异。

如果你怀疑实验中存在用户学习的现象，理想的方法是延长实验直到处理效应稳定。然而，由于技术（例如短效 cookie）或商业限制，这可能并不总是可行。在这种情况下，你可以使用自动代理模型来预测长期效果，通过*Y*的滞后值来预测实验的长期结果。

> 感谢您花时间阅读这篇文章。我很想听听您的想法，请随时分享任何评论或问题。

# 参考文献

1.  N. Larsen, J. Stallrich, S. Sengupta, A. Deng, R. Kohavi, N. T. Stevens, *在线控制实验中的统计挑战：A/B 测试方法综述*（2023），[https://arxiv.org/pdf/2212.11366.pdf](https://arxiv.org/pdf/2212.11366.pdf)

1.  S. Sadeghi, S. Gupta, S. Gramatovici, J. Lu, H. Ai, R. Zhang, *新颖性与首因效应：一种长期在线实验估算方法*（2021），[https://arxiv.org/pdf/2102.12893.pdf](https://arxiv.org/pdf/2102.12893.pdf)

1.  H. Hohnhold, D. O’Brien, D. Tang, *聚焦长期：这对用户和商业都有好处*（2015），[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43887.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43887.pdf)

1.  S. Athey, R. Chetty, G. W. Imbens, H. Kang, *代理指数：结合短期代理快速而精确地估算长期处理效应*（2019），[https://www.nber.org/system/files/working_papers/w26463/w26463.pdf](https://www.nber.org/system/files/working_papers/w26463/w26463.pdf)

1.  V. Zhang, M. Zhao, A. Le, M. Dimakopoulou, N. Kallus, *使用 Netflix 上的 200 次 A/B 测试评估代理指数作为决策工具*（2023），[https://arxiv.org/pdf/2311.11922.pdf](https://arxiv.org/pdf/2311.11922.pdf)
