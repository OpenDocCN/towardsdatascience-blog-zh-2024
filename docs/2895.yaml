- en: 'Multimodal Embeddings: An Introduction'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f?source=collection_archive---------4-----------------------#2024-11-29](https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f?source=collection_archive---------4-----------------------#2024-11-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Mapping text and images into a common space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shawhin.medium.com/?source=post_page---byline--5dc36975966f--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page---byline--5dc36975966f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5dc36975966f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5dc36975966f--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page---byline--5dc36975966f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5dc36975966f--------------------------------)
    ·8 min read·Nov 29, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: This is the 2nd article in a [larger series](https://shawhin.medium.com/list/multimodal-ai-fe9521d0e77a)
    on multimodal AI. In the [previous post](/multimodal-models-llms-that-can-see-and-hear-5c6737c981d3),
    we saw how to augment [large language models (LLMs)](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c)
    to understand new data modalities (e.g., images, audio, video). One such approach
    relied on encoders that generate vector representations (i.e. embeddings) of non-text
    data. In this article, I will discuss *multimodal* embeddings and share what they
    can do via two practical use cases.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8c2812bed48f472f72cfe64d7de7b9a9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from Canva.
  prefs: []
  type: TYPE_NORMAL
- en: 'AI research is traditionally split into distinct fields: NLP, computer vision
    (CV), robotics, human-computer interface (HCI), etc. However, countless practical
    tasks require the **integration of these different research areas** e.g. autonomous
    vehicles (CV + robotics), AI agents (NLP + CV + HCI), personalized learning (NLP
    + HCI), etc.'
  prefs: []
  type: TYPE_NORMAL
- en: Although these fields aim to solve different problems and work with different
    data types, they all share a fundamental process. Namely, **generating useful
    numerical representations of real-world phenomena**.
  prefs: []
  type: TYPE_NORMAL
