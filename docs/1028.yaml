- en: 'Speak, Don’t Type: Exploring Voice Interaction with LLMs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 说话，不要打字：探索与大型语言模型（LLMs）的语音交互
- en: 原文：[https://towardsdatascience.com/speak-dont-type-exploring-voice-interaction-with-llms-part-1-732257710e9d?source=collection_archive---------4-----------------------#2024-04-23](https://towardsdatascience.com/speak-dont-type-exploring-voice-interaction-with-llms-part-1-732257710e9d?source=collection_archive---------4-----------------------#2024-04-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/speak-dont-type-exploring-voice-interaction-with-llms-part-1-732257710e9d?source=collection_archive---------4-----------------------#2024-04-23](https://towardsdatascience.com/speak-dont-type-exploring-voice-interaction-with-llms-part-1-732257710e9d?source=collection_archive---------4-----------------------#2024-04-23)
- en: Augmenting LLM Apps with a Voice Modality
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为LLM应用增添语音模式
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--732257710e9d--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--732257710e9d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--732257710e9d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--732257710e9d--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--732257710e9d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@CVxTz?source=post_page---byline--732257710e9d--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--732257710e9d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--732257710e9d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--732257710e9d--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--732257710e9d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--732257710e9d--------------------------------)
    ·6 min read·Apr 23, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--732257710e9d--------------------------------)
    ·阅读时间6分钟·2024年4月23日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b1a5f00dff88978127a9214c8aa3c074.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1a5f00dff88978127a9214c8aa3c074.png)'
- en: Photo by [Quino Al](https://unsplash.com/@quinoal?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/top-view-photo-of-purple-daisy--3KfR1GVKXY?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Quino Al](https://unsplash.com/@quinoal?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)拍摄，来源于[Unsplash](https://unsplash.com/photos/top-view-photo-of-purple-daisy--3KfR1GVKXY?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: Many LLMs, particularly those that are open-source, have typically been limited
    to processing text or, occasionally, text with images (Large Multimodal Models
    or LMMs). But what if you want to communicate with your LLM using your voice?
    Thanks to the advancement of powerful speech-to-text open-source technologies
    in recent years, this becomes achievable.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 许多LLMs，特别是开源的LLMs，通常仅限于处理文本，或偶尔处理带有图像的文本（大型多模态模型，LMMs）。但如果你想用声音与LLM进行沟通怎么办？得益于近年来强大的语音转文本开源技术的发展，这一目标变得可实现。
- en: We will go into the integration of Llama 3 with a speech-to-text model, all
    within a user-friendly interface. This fusion enables (near) real-time communication
    with an LLM through speech. Our exploration involves selecting Llama 3 8B as the
    LLM, using the Whisper speech-to-text model, and the capabilities of NiceGUI —
    a framework that uses FastAPI on the backend and Vue3 on the frontend, interconnected
    with socket.io.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨Llama 3与语音转文本模型的集成，所有操作都将在一个用户友好的界面中完成。这一融合使得通过语音与LLM进行（接近）实时的交流成为可能。我们的探索涉及选择Llama
    3 8B作为LLM，使用Whisper语音转文本模型，并利用NiceGUI的功能——这是一个在后端使用FastAPI，前端使用Vue3，并通过socket.io互联的框架。
- en: After reading this post, you will be able to augment an LLM with a new audio
    modality. This will allow you to build a full end-to-end workflow and UI that
    enables you to use your voice to command and prompt an LLM instead of typing.
    This feature can prove especially beneficial for mobile applications, where typing
    on a keyboard may not be as user-friendly as on desktops. Additionally, integrating
    this functionality can enhance the accessibility of your LLM app…
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本文后，你将能够为LLM增添一种新的音频模式。这将允许你构建一个完整的端到端工作流和用户界面，使用语音来命令和提示LLM，而不是打字。这一功能对于移动应用特别有用，因为在手机上打字可能不像在桌面上那么方便。此外，集成这一功能还可以增强你LLM应用的可访问性……
