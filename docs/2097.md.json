["```py\n#clone repository from github\ngit clone https://github.com/prsdm/mlops-project.git\n```", "```py\n.\n├── .github                         # DVC metadata and configuration\n│   └── workflows                   # GitHub Actions workflows for CI/CD\n│       └── docs.yml                \n├── data                            # Directory for storing data files\n│   ├── train.csv                   \n│   └── test.csv                                  \n├── docs                            # Project documentation.\n│   └── index.md                    \n├── models                          # Store trained models \n├── mlruns                          # Directory for MLflow run logs and artifacts\n├── steps                           # Source code for data processing and model training\n│   ├── __init__.py                \n│   ├── ingest.py                   \n│   ├── clean.py                    \n│   ├── train.py                    \n│   └── predict.py                  \n├── tests                           # Directory to store tests\n│   ├── __init__.py                 \n│   ├── test_ingest.py              \n│   └── test_clean.py              \n├── .gitignore                      # To ignore files that can't commit to Git\n├── app.py                          # FastAPI app file\n├── config.yml                      # Configuration file\n├── data.dvc                        # For tracking data files and their versions\n├── dataset.py                      # Script to download or generate data\n├── dockerfile                      # Dockerfile for containerizing FastAPI\n├── LICENSE                         # License for project\n├── main.py                         # To automate model training\n├── Makefile                        # To store useful commands to make train or make test \n├── mkdocs.yml                      # Configuration file for MkDocs\n├── README.md                       # Project description\n├── requirements.txt                # Requirements file for reproducing the environment.\n├── samples.json                    # Sample data for testing\n\n'''Extra files for monitoring'''\n├── data                           \n│   └──production.csv               # data for Monitoring\n├── monitor.ipynb                   # Model Monitoring notebook \n├── test_data.html                  # monitoring results for test data  \n└── production_data.html            # monitoring results for production data\n```", "```py\n#create venv\npython3 -m venv venv\n```", "```py\n#activate\nsource venv/bin/activate\n```", "```py\n#create venv\npython -m venv venv\n```", "```py\n#activate\n.\\venv\\Scripts\\activate\n```", "```py\n#install all the dependancies\npip install -r requirements.txt\n```", "```py\n#to get data from source\npython3 dataset.py\n```", "```py\n#model training part from project structure\n\n├── steps/                     \n│   ├── ingest.py              \n│   ├── clean.py \n│   ├── train.py            \n│   └── predict.py\n├── main.py                    \n├── models/model.pkl\n```", "```py\n#to train the model\npython3 main.py\n```", "```py\nimport logging\nfrom steps.ingest import Ingestion\nfrom steps.clean import Cleaner\nfrom steps.train import Trainer\nfrom steps.predict import Predictor\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO,format='%(asctime)s:%(levelname)s:%(message)s')\n\ndef main():\n    # Load data\n    ingestion = Ingestion()\n    train, test = ingestion.load_data()\n    logging.info(\"Data ingestion completed successfully\")\n\n    # Clean data\n    cleaner = Cleaner()\n    train_data = cleaner.clean_data(train)\n    test_data = cleaner.clean_data(test)\n    logging.info(\"Data cleaning completed successfully\")\n\n    # Prepare and train model\n    trainer = Trainer()\n    X_train, y_train = trainer.feature_target_separator(train_data)\n    trainer.train_model(X_train, y_train)\n    trainer.save_model()\n    logging.info(\"Model training completed successfully\")\n\n    # Evaluate model\n    predictor = Predictor()\n    X_test, y_test = predictor.feature_target_separator(test_data)\n    accuracy, class_report, roc_auc_score = predictor.evaluate_model(X_test, y_test)\n    logging.info(\"Model evaluation completed successfully\")\n\n    # Print evaluation results\n    print(\"\\n============= Model Evaluation Results ==============\")\n    print(f\"Model: {trainer.model_name}\")\n    print(f\"Accuracy Score: {accuracy:.4f}, ROC AUC Score: {roc_auc_score:.4f}\")\n    print(f\"\\n{class_report}\")\n    print(\"=====================================================\\n\")\n\nif __name__ == \"__main__\":\n    main()\n```", "```py\n#install DVC via pip\npip install dvc\n```", "```py\n#initialize a DVC\ndvc init\n```", "```py\n#add data\ndvc add data\n```", "```py\n#add remote storage configuration\ndvc remote add -d <remote_name> <remote_storage_path>\n```", "```py\n#commit the DVC configuration changes to Git\ngit commit .dvc/config -m 'config dvc store'\n```", "```py\n#upload data to the configured remote storage\ndvc push\n```", "```py\n#push all committed changes to the Git repository\ngit push origin main\n```", "```py\n#pull the latest version of the data\ndvc pull\n```", "```py\n#install mlfow\npip install mlflow\n```", "```py\nimport logging\nimport yaml\nimport mlflow\nimport mlflow.sklearn\nfrom steps.ingest import Ingestion\nfrom steps.clean import Cleaner\nfrom steps.train import Trainer\nfrom steps.predict import Predictor\nfrom sklearn.metrics import classification_report\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO,format='%(asctime)s:%(levelname)s:%(message)s')\n\ndef main():\n\n    with open('config.yml', 'r') as file:\n        config = yaml.safe_load(file)\n\n    mlflow.set_experiment(\"Model Training Experiment\")\n\n    with mlflow.start_run() as run:\n        # Load data\n        ingestion = Ingestion()\n        train, test = ingestion.load_data()\n        logging.info(\"Data ingestion completed successfully\")\n\n        # Clean data\n        cleaner = Cleaner()\n        train_data = cleaner.clean_data(train)\n        test_data = cleaner.clean_data(test)\n        logging.info(\"Data cleaning completed successfully\")\n\n        # Prepare and train model\n        trainer = Trainer()\n        X_train, y_train = trainer.feature_target_separator(train_data)\n        trainer.train_model(X_train, y_train)\n        trainer.save_model()\n        logging.info(\"Model training completed successfully\")\n\n        # Evaluate model\n        predictor = Predictor()\n        X_test, y_test = predictor.feature_target_separator(test_data)\n        accuracy, class_report, roc_auc_score = predictor.evaluate_model(X_test, y_test)\n        report = classification_report(y_test, trainer.pipeline.predict(X_test), output_dict=True)\n        logging.info(\"Model evaluation completed successfully\")\n\n        # Tags \n        mlflow.set_tag('Model developer', 'prsdm')\n        mlflow.set_tag('preprocessing', 'OneHotEncoder, Standard Scaler, and MinMax Scaler')\n\n        # Log metrics\n        model_params = config['model']['params']\n        mlflow.log_params(model_params)\n        mlflow.log_metric(\"accuracy\", accuracy)\n        mlflow.log_metric(\"roc\", roc_auc_score)\n        mlflow.log_metric('precision', report['weighted avg']['precision'])\n        mlflow.log_metric('recall', report['weighted avg']['recall'])\n        mlflow.sklearn.log_model(trainer.pipeline, \"model\")\n\n        # Register the model\n        model_name = \"insurance_model\" \n        model_uri = f\"runs:/{run.info.run_id}/model\"\n        mlflow.register_model(model_uri, model_name)\n\n        logging.info(\"MLflow tracking completed successfully\")\n\n        # Print evaluation results\n        print(\"\\n============= Model Evaluation Results ==============\")\n        print(f\"Model: {trainer.model_name}\")\n        print(f\"Accuracy Score: {accuracy:.4f}, ROC AUC Score: {roc_auc_score:.4f}\")\n        print(f\"\\n{class_report}\")\n        print(\"=====================================================\\n\")\n\nif __name__ == \"__main__\":\n    main()\n```", "```py\n#to launch MLflow UI\nmlflow ui\n```", "```py\npython = venv/bin/python\npip = venv/bin/pip\n\nsetup:\n python3 -m venv venv\n $(python) -m pip install --upgrade pip\n $(pip) install -r requirements.txt\n\nrun:\n $(python) main.py\n\nmlflow:\n venv/bin/mlflow ui\n\ntest:\n $(python) -m pytest\n\nclean:\n rm -rf steps/__pycache__\n rm -rf __pycache__\n rm -rf .pytest_cache\n rm -rf tests/__pycache__\n\nremove:\n rm -rf venv\n```", "```py\npython = venv/Scripts/python\npip = venv/Scripts/pip\n\nsetup:\n python -m venv venv\n $(python) -m pip install --upgrade pip\n $(pip) install -r requirements.txt\n\nrun:\n $(python) main.py\n\nmlflow:\n venv/Scripts/mlflow ui\n\ntest:\n $(python) -m pytest\n\nclean:\n @if exist steps\\__pycache__ (rmdir /s /q steps\\__pycache__)\n @if exist __pycache__ (rmdir /s /q __pycache__)\n @if exist .pytest_cache (rmdir /s /q .pytest_cache)\n @if exist tests\\__pycache__ (rmdir /s /q tests\\__pycache__)\n\nremove:\n @if exist venv (rmdir /s /q venv)\n```", "```py\n# For example, to set up the environment\nmake setup\n\n# OR To run the main script\nmake run\n\n# OR To run the tests\nmake test\n\n# so on...\n```", "```py\ndata: \n  train_path: data/train.csv\n  test_path: data/test.csv\n\ntrain:\n  test_size: 0.2\n  random_state: 42\n  shuffle: true\n\nmodel:\n  name: DecisionTreeClassifier\n  params:\n    criterion: entropy\n    max_depth: null\n  store_path: models/\n\n  # name: GradientBoostingClassifier\n  # params:\n  #   max_depth: null\n  #   n_estimators: 10\n  # store_path: models/\n\n  # name: RandomForestClassifier\n  # params:\n  #   n_estimators: 50\n  #   max_depth: 10\n  #   random_state: 42\n  # store_path: models/\n```", "```py\n#install fastapi and uvicorn\npip install fastapi uvicorn\n```", "```py\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nimport pandas as pd\nimport joblib\n\napp = FastAPI()\n\nclass InputData(BaseModel):\n    Gender: str\n    Age: int\n    HasDrivingLicense: int\n    RegionID: float\n    Switch: int\n    PastAccident: str\n    AnnualPremium: float\n\nmodel = joblib.load('models/model.pkl')\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"health_check\": \"OK\", \"model_version\": 1}\n\n@app.post(\"/predict\")\nasync def predict(input_data: InputData):\n\n        df = pd.DataFrame([input_data.model_dump().values()], \n                          columns=input_data.model_dump().keys())\n        pred = model.predict(df)\n        return {\"predicted_class\": int(pred[0])}\n```", "```py\n#run the FastAPI app\nuvicorn app:app --reload\n```", "```py\n#official Python 3.10 image\nFROM python:3.10\n\n#set the working directory \nWORKDIR /app\n\n#add app.py and models directory\nCOPY app.py .\nCOPY models/ ./models/\n\n# add requirements file\nCOPY requirements.txt .\n\n# install python libraries\nRUN pip install --no-cache-dir -r requirements.txt\n\n# specify default commands\nCMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n```", "```py\n# To build docker image\ndocker build -t <image_name> <path_to_dockerfile>\n```", "```py\n# To run docker container\ndocker run -d -p 80:80 <image_name>\n```", "```py\n# To show running containers\ndocker ps\n```", "```py\n# To stop the container\ndocker stop <container_id_or_name>\n```", "```py\n# List images by name and tag.\ndocker image ls\n```", "```py\n# Tag the image\ndocker tag <image_name> <dockerhub_username>/<docker-repo-name>\n```", "```py\n# Push the Docker image \ndocker push <dockerhub_username>/<docker-repo-name>:latest\n```", "```py\n#to install\npip install evidently\n\n#or\npip install evidently @ git+https://github.com/evidentlyai/evidently.git\n```", "```py\n# If this .py file doesn't work, then use a notebook to run it.\nimport joblib\nimport pandas as pd\nfrom steps.clean import Cleaner\nfrom evidently.report import Report\nfrom evidently.metric_preset import DataDriftPreset, DataQualityPreset, TargetDriftPreset\nfrom evidently import ColumnMapping\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# # import mlflow model version 1\n# import mlflow\n# logged_model = 'runs:/47b6b506fd2849429ee13576aef4a852/model'\n# model = mlflow.pyfunc.load_model(logged_model)\n\n# # OR import from models/\nmodel = joblib.load('models/model.pkl')\n\n# Loading data\nreference = pd.read_csv(\"data/train.csv\")\ncurrent = pd.read_csv(\"data/test.csv\")\nproduction = pd.read_csv(\"data/production.csv\")\n\n# Clean data\ncleaner = Cleaner()\nreference = cleaner.clean_data(reference)\nreference['prediction'] = model.predict(reference.iloc[:, :-1])\n\ncurrent = cleaner.clean_data(current)\ncurrent['prediction'] = model.predict(current.iloc[:, :-1])\n\nproduction = cleaner.clean_data(production)\nproduction['prediction'] = model.predict(production.iloc[:, :-1])\n\n# Apply column mapping\ntarget = 'Result'\nprediction = 'prediction'\nnumerical_features = ['Age', 'AnnualPremium', 'HasDrivingLicense', 'RegionID', 'Switch']\ncategorical_features = ['Gender','PastAccident']\ncolumn_mapping = ColumnMapping()\n\ncolumn_mapping.target = target\ncolumn_mapping.prediction = prediction\ncolumn_mapping.numerical_features = numerical_features\ncolumn_mapping.categorical_features = categorical_features\n\n# Data drift detaction part\ndata_drift_report = Report(metrics=[\n    DataDriftPreset(),\n    DataQualityPreset(),\n    TargetDriftPreset()\n])\ndata_drift_report.run(reference_data=reference, current_data=current, column_mapping=column_mapping)\ndata_drift_report\n# data_drift_report.json()\ndata_drift_report.save_html(\"test_drift.html\")\n```"]