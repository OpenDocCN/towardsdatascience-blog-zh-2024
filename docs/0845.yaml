- en: Fabric Madness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/fabric-madness-96b84dc5f241?source=collection_archive---------6-----------------------#2024-04-01](https://towardsdatascience.com/fabric-madness-96b84dc5f241?source=collection_archive---------6-----------------------#2024-04-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Predicting basketball games with Microsoft Fabric
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@roger_noble?source=post_page---byline--96b84dc5f241--------------------------------)[![Roger
    Noble](../Images/869b5b0f237f24b119ca6c41c2e31162.png)](https://medium.com/@roger_noble?source=post_page---byline--96b84dc5f241--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--96b84dc5f241--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--96b84dc5f241--------------------------------)
    [Roger Noble](https://medium.com/@roger_noble?source=post_page---byline--96b84dc5f241--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--96b84dc5f241--------------------------------)
    ¬∑10 min read¬∑Apr 1, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8c8b9740fc1e7fac643483f34944ee5a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author and ChatGPT. ‚ÄúDesign an illustration, focusing on a basketball
    player in action, the design integrates sports and data analytics themes in a
    graphic novel style‚Äù prompt. ChatGPT, 4, OpenAI, 28 March. 2024\. [https://chat.openai.com.](https://chat.openai.com./)
  prefs: []
  type: TYPE_NORMAL
- en: '*A Huge thanks to* [*Martim Chaves*](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
    *who co-authored this post and developed the example scripts.*'
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, it‚Äôs basketball season in the United States, and there
    is a lot of excitement around the men‚Äôs and women‚Äôs college basketball tournaments.
    The format is single elimination, so over the course of several rounds, teams
    are eliminated, till eventually we get a champion. This tournament is not only
    a showcase of upcoming basketball talent, but, more importantly, a fertile ground
    for data enthusiasts like us to analyse trends and predict outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: One of the great things about sports is that there is lots of data available,
    and we at [Noble Dynamic](https://nobledynamic.com/) wanted to take a crack at
    it ü§ì.
  prefs: []
  type: TYPE_NORMAL
- en: In this series of posts titled *Fabric Madness*, we‚Äôre going to be diving deep
    into some of the most interesting features of [Microsoft Fabric](https://www.microsoft.com/en-us/microsoft-fabric),
    for an end-to-end demonstration of how to train and use a machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this first blog post, we‚Äôll be going over:'
  prefs: []
  type: TYPE_NORMAL
- en: A first look at the data using [Data Wrangler](https://learn.microsoft.com/en-us/fabric/data-science/data-wrangler).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploratory Data Analysis (EDA) and Feature Engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking the performance of different Machine Learning (ML) Models using Experiments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting the best performing model using the ML Model functionality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data used was obtained from the on-going Kaggle competition, the details
    of which can be found [here](https://www.kaggle.com/competitions/march-machine-learning-mania-2024/overview),
    which is licensed under [CC BY 4.0](http://creativecommons.org/licenses/by/4.0/)
    [1]
  prefs: []
  type: TYPE_NORMAL
- en: Among all of the interesting data available, our focus for this case study was
    on the match-by-match statistics. This data was available for both the regular
    seasons and the tournaments, going all the way back to 2003\. For each match,
    besides the date, the teams that were playing, and their scores, other relevant
    features were made available, such as field goals made and personal fouls by each
    team.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step was creating a Fabric **Workspace**. Workspaces in Fabric are
    one of the fundamental building blocks of the platform, and are used for grouping
    together related items and for collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: After downloading all of the CSV files available, a **Lakehouse** was created.
    A Lakehouse, in simple terms, is a mix between a *Database* of Tables (structured)
    and a *Data Lake* of Files (unstructured). The big benefit of a Lakehouse is that
    data is available for every tool in the workspace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Uploading the files was done using the UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d3b6b5fa058b68609673e75ea3526db.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 1 ‚Äî Uploading Files. Image by [Martim Chaves](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a Lakehouse with the CSV files, it was time to dig in, and
    get a first look at the data. To do that, we created a Notebook, using the UI,
    and attached the previously created Lakehouse.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f93f56518fd10171dbe0c20ff82564b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 2 ‚Äî Adding Lakehouse to Notebook. Image by [Martim Chaves](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: First Look
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After a quick data wrangling, it was found that, as expected with data from
    Kaggle, the quality was great. With no duplicates or missing values.
  prefs: []
  type: TYPE_NORMAL
- en: For this task we used [Data Wrangler](https://learn.microsoft.com/en-us/fabric/data-science/data-wrangler),
    a tool built into Microsoft Fabric notebooks. Once an initial DataFrame has been
    created (Spark or Pandas supported), Data Wrangler becomes available to use and
    can attach to any DataFrame in the Notebook. What‚Äôs great is that it allows for
    easy analysis of loaded DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: In a Notebook, after reading the files into PySpark DataFrames, in the ‚ÄúData‚Äù
    section, the ‚ÄúTransform DataFrame in Data Wrangler‚Äù was selected, and from there
    the several DataFrames were explored. Specific DataFrames can be chosen, carrying
    out a careful inspection.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ae7bc9853f50fa142857c6345255b181.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 3 ‚Äî Opening Data Wrangler. Image by [Martim Chaves](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c89f0f109d2fd114c56c931e36e23861.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 4 ‚Äî Analysing the DataFrame with Data Wrangler. Image by [Martim Chaves](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In the centre, we have access to all of the rows of the loaded DataFrame. On
    the right, a **Summary** tab, showing that indeed there are no duplicates or missing
    values. Clicking in a certain column, summary statistics of that column will be
    shown.
  prefs: []
  type: TYPE_NORMAL
- en: On the left, in the **Operations** tab, there are several pre-built operations
    that can be applied to the DataFrame. The operations feature many of the most
    common data wrangling tasks, such as filtering, sorting, and grouping, and is
    a quick way to generate boilerplate code for these tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, the data was already in good shape, so we moved on to the EDA stage.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory Data Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A short Exploratory Data Analysis (EDA) followed, with the goal of getting a
    general idea of the data. Charts were plotted to get a sense of the distribution
    of the data and if there were any statistics that could be problematic due to,
    for example, very long tails.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6d8f47db68ff58f8e5820bb4d9136cd0.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 5 ‚Äî Histogram of field goals made. Image by [Martim Chaves](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: At a quick glance, it was found that the data available from the regular season
    had normal distributions, suitable to use in the creation of features. Knowing
    the importance that good features have in creating solid predictive systems, the
    next sensible step was to carry out feature engineering to extract relevant information
    from the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal was to create a dataset where each sample‚Äôs input would be a set of
    features for a game, containing information of both teams. For example, both teams
    average field goals made for the regular season. The target for each sample, the
    desired output, would be 1 if Team 1 won the game, or 0 if Team 2 won the game
    (which was done by subtracting the scores). Here‚Äôs a representation of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Feature Engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first feature that we decided to explore was win rate. Not only would it
    be an interesting feature to explore, but it would also provide a baseline score.
    This initial approach employed a simple rule: the team with the higher win rate
    would be predicted as the winner. This method provides a fundamental baseline
    against which the performance of more sophisticated predictive systems can be
    compared to.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To evaluate the accuracy of our predictions across different models, we adopted
    the Brier score. The Brier score is the mean of the square of the difference between
    the predicted probability (p) and the actual outcome (o) for each sample, and
    can be described by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4555570882e57072bf20b4054088e29f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: The predicted probability will vary between 0 and 1, and the actual outcome
    will either be 0 or 1\. Thus, the Brier score will always be between 0 and 1\.
    As we want the predicted probability to be as close to the actual outcome as possible,
    the lower the Brier score, the better, with 0 being the perfect score, and 1 the
    worst.
  prefs: []
  type: TYPE_NORMAL
- en: For the baseline, the previously mentioned dataset structure was followed. Each
    sample of the dataset was a match, containing the win rates for the regular season
    for Team 1 and Team 2\. The actual outcome was considered 1 if Team 1 won, or
    0 if Team 2 won. To simulate a probability, the prediction was a normalised difference
    between T1‚Äôs win rate and T2‚Äôs win rate. For the maximum value of the difference
    between the win rates, the prediction would be 1\. For the minimum value, the
    prediction would be 0.
  prefs: []
  type: TYPE_NORMAL
- en: After calculating the win rate, and then using it to predict the outcomes, we
    got a Brier score of **0.23**. Considering that guessing at random leads to a
    Brier score of **0.25**, it‚Äôs clear that this feature alone is not very good üò¨.
  prefs: []
  type: TYPE_NORMAL
- en: By starting with a simple baseline, it clearly highlighted that more complex
    patterns were at play. We went ahead to developed another 42 features, in preparation
    for utilising more complex algorithms, machine learning models, that might have
    a better chance.
  prefs: []
  type: TYPE_NORMAL
- en: It was then time to create machine learning models!
  prefs: []
  type: TYPE_NORMAL
- en: Models & Machine Learning Experiments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the models, we opted for simple Neural Networks (NN). To determine which
    level of complexity would be best, we created three different NNs, with an increasing
    number of layers and hyper-parameters. Here‚Äôs an example of a small NN, one that
    was used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e1e5cdf6b3a9f592f8b1e64c630c99da.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 6 ‚Äî Diagram of a Neural Network. Image by [Martim Chaves](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
    using [draw.io](https://app.diagrams.net/)
  prefs: []
  type: TYPE_NORMAL
- en: If you‚Äôre familiar with NNs, feel free to skip to the [Experiments](https://nobledynamic.com/posts/fabric-madness-1/#what-is-an-experiment)!
    If you‚Äôre unfamiliar with NNs think of them as a set of layers, where each layer
    acts as a filter for relevant information. Data passes through successive layers,
    in a step-by-step fashion, where each layer has inputs and outputs. Data moves
    through the network in one direction, from the first layer (the model‚Äôs input)
    to the last layer (the model‚Äôs output), without looping back, hence the **Sequential**
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Each layer is made up of several neurons, that can be described as nodes. The
    model‚Äôs input, the first layer, will contain as many neurons as there are features
    available, and each neuron will hold the value of a feature. The model‚Äôs output,
    the last layer, in binary problems such as the one we‚Äôre tackling, will only have
    1 neuron. The value held by this neuron should be 1 if the model is processing
    a match where Team 1 won, or 0 if Team 2 won. The intermediate layers have an
    *ad hoc* number of neurons. In the example in the code snippet, 64 neurons were
    chosen.
  prefs: []
  type: TYPE_NORMAL
- en: In a **Dense** layer, as is the case here, each neuron in the layer is connected
    to every neuron in the preceding layer. Fundamentally, each neuron **processes**
    the information provided by the neurons from the previous layer.
  prefs: []
  type: TYPE_NORMAL
- en: The processing of the previous layer‚Äôs information requires an **activation
    function**. There are many types of activation functions ‚Äî **ReLU**, standing
    for Rectified Linear Unit, is one of them. It allows only positive values to pass
    and sets negative values to zero, making it effective for many types of data.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the final activation function is a **sigmoid** function ‚Äî this converts
    the output to a number between 0 and 1\. This is crucial for binary classification
    tasks, where you need the model to express its output as a probability.
  prefs: []
  type: TYPE_NORMAL
- en: Besides these small models, medium and large models were created, with an increasing
    number of layers and parameters. The size of a model affects its ability to capture
    complex patterns in the data, with larger models generally being more capable
    in this regard. However, larger models also require more data to learn effectively
    ‚Äî if there‚Äôs not enough data, issues may occur. Finding the right size is sometimes
    only possible through experimentation, by training different models and comparing
    their performance to identify the most effective configuration.
  prefs: []
  type: TYPE_NORMAL
- en: The next step was running the experiments ‚öóÔ∏è!
  prefs: []
  type: TYPE_NORMAL
- en: What is an Experiment?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Fabric, an Experiment can be seen as a group of related runs, where a run
    is an execution of a code snippet. In this context, a run is a training of a model.
    For each run, a model will be trained with a different set of hyper-parameters.
    The set of hyper-parameters, along with the final model score, is logged, and
    this information is available for each run. Once enough runs have been completed,
    the final model scores can be compared, so that the best version of each model
    can be selected.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Experiment in Fabric can be done via the UI or directly from a Notebook.
    The Experiment is essentially a wrapper for [MLFlow Experiments](https://mlflow.org/).
    One of the great things about using Experiments in Fabric is that the results
    can be shared with others. This makes it possible to collaborate and allow others
    to participate in experiments, either writing code to run experiments, or analysing
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the UI to create an Experiment simply select Experiment from the **+ New**
    button, and choose a name.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/16babe28e7df7b00cf239df62d51f397.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 7 ‚Äî Creating an Experiment using the UI. Image by [Martim Chaves](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: When training each of the models, the hyper-parameters are logged with the experiment,
    as well as the final score. Once completed we can see the results in the UI, and
    compare the different runs to see which model performed best.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/05d17570644c450b37baa0c3a2019637.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 8 ‚Äî Comparing different runs. Image by [Martim Chaves](https://medium.com/u/1c5c115c8045?source=post_page---user_mention--96b84dc5f241--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: After that we can select the best model and use it to make the final prediction.
    When comparing the three models, the best Brier score was **0.20**, a slight improvement
    üéâ!
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After loading and analysing data from this year‚Äôs US major college basketball
    tournament, and creating a dataset with relevant features, we were able to predict
    the outcome of the games using a simple Neural Network. Experiments were used
    to compare the performance of different models. Finally, the best performing model
    was selected to carry out the final prediction.
  prefs: []
  type: TYPE_NORMAL
- en: In the next post we will go into detail on how we created the features using
    pyspark. Stay tuned for more! üëã
  prefs: []
  type: TYPE_NORMAL
- en: '**The full source code for this post can be found** [**here**](https://dev.azure.com/nobledynamic/_git/FabricMadness)**.**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Originally published at* [*https://nobledynamic.com*](https://nobledynamic.com/posts/fabric-madness-1/)
    *on April 1, 2024.*'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Jeff Sonas, Ryan Holbrook, Addison Howard, Anju Kandru. (2024). March Machine
    Learning Mania 2024\. Kaggle. [https://kaggle.com/competitions/march-machine-learning-mania-2024](https://kaggle.com/competitions/march-machine-learning-mania-2024)'
  prefs: []
  type: TYPE_NORMAL
