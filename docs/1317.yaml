- en: Physics-Informed Neural Network with Forcing Function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/physics-informed-neural-network-with-forcing-function-81f59aa24c39?source=collection_archive---------1-----------------------#2024-05-27](https://towardsdatascience.com/physics-informed-neural-network-with-forcing-function-81f59aa24c39?source=collection_archive---------1-----------------------#2024-05-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Solving differential equations directly with neural networks *(with code)***'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@john_morrow?source=post_page---byline--81f59aa24c39--------------------------------)[![John
    Morrow](../Images/4a8ce62a0b4e1eb1cf77ecaba6b7ddcc.png)](https://medium.com/@john_morrow?source=post_page---byline--81f59aa24c39--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--81f59aa24c39--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--81f59aa24c39--------------------------------)
    [John Morrow](https://medium.com/@john_morrow?source=post_page---byline--81f59aa24c39--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--81f59aa24c39--------------------------------)
    ·7 min read·May 27, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/606da5e15190e1076896e6f2b0203807.png)'
  prefs: []
  type: TYPE_IMG
- en: image by agsandrew on iStock
  prefs: []
  type: TYPE_NORMAL
- en: In physics, mathematics, economics, engineering, and many other fields, differential
    equations describe a function in terms of the derivatives of the variables. Put
    simply, when the rate of change of a variable in terms of other variables is involved,
    you will likely find a differential equation. Many [examples](https://en.wikipedia.org/wiki/List_of_named_differential_equations)
    describe these relationships. A differential equation’s solution is typically
    derived through analytical or numerical methods.
  prefs: []
  type: TYPE_NORMAL
- en: While deriving the analytic solution can be a tedious or, in some cases, an
    impossible task, a physics-informed neural network (PINN) produces the solution
    directly from the differential equation, bypassing the analytic process. This
    innovative approach to solving differential equations is an important development
    in the field.
  prefs: []
  type: TYPE_NORMAL
- en: A [previous article](https://medium.com/towards-data-science/inverse-physics-informed-neural-net-3b636efeb37e)
    by the author used a PINN to find the solution to a differential equation describing
    a simple electronic circuit. This article explores the more challenging task of
    finding a solution when driving the circuit with a forcing function. Consider
    the following series-connected electronic circuit that comprises a resistor *R*,
    capacitor *C*, inductor *L*, and a sinusoidal voltage source *V sin(ωt)*. The
    behavior of the current flow, *i(t)*, in this circuit is described by Equation
    1, a 2nd-order non-homogeneous differential equation with forcing function, *Vω/L
    cos(ωt)*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db0fbad3f8570d544e8cd6e091cc7384.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: **RLC circuit with sinusoidal voltage source**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b214ed62114f959ed2d5f400852f2ac1.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 1**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Analytic solution**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The analytic solution to Equation 1 requires solving the equation for three
    cases depending upon the relationship between *λ* and *ω₀*. As seen below, each
    results in a complicated and unique formula for *i(t)*. In tests presented later
    in **Results**, these solutions will be compared against results produced by a
    PINN. The PINN will produce the solution directly from the differential equation
    without consideration of these cases.
  prefs: []
  type: TYPE_NORMAL
- en: (A detailed analytic solution by the author using Laplace transform techniques
    is available [here](https://github.com/jmorrow1000/PINN-with-forcing-function).)
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 1: Under-damped (***λ/2 < ω₀*)'
  prefs: []
  type: TYPE_NORMAL
- en: Damping refers to how fast the circuit transitions from its starting transit
    to equilibrium. An under-damped response attempts to transition quickly but typically
    cycles through overshooting and undershooting before reaching equilibrium.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c338c1f20f47e542a90500e04b389766.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 2**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 2: Over-damped (***λ/2 >ω₀*)'
  prefs: []
  type: TYPE_NORMAL
- en: An over-damped response slowly transitions from starting transit to equilibrium
    without undergoing cycles of overshooting and undershooting.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fc2cb05714bb5c7684e505a7173cea54.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 3**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 3: Critically-damped (***λ/2 = ω₀*)'
  prefs: []
  type: TYPE_NORMAL
- en: A critically-damped response falls between under-damped and over-damped, delivering
    the fastest response from starting transit to equilibrium.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bdd758e22d8b82a78a8828fa598e6fcb.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 4**'
  prefs: []
  type: TYPE_NORMAL
- en: '**PINN solution**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PyTorch code is available [here](https://github.com/jmorrow1000/PINN-with-forcing-function).
  prefs: []
  type: TYPE_NORMAL
- en: A neural network is typically trained with pairs of inputs and desired outputs.
    The inputs are applied to the neural network, and back-propagation adjusts the
    network’s weights and biases to minimize an objective function. The objective
    function represents the error in the neural network’s output compared to the desired
    output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objective function of a PINN, in contrast, requires three components: a
    residual component (*obj* *ᵣₑₛ*) and two initial condition components (*obj ᵢₙᵢₜ₁*
    and *obj* *ᵢₙᵢₜ*₂). These are combined to produce the objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/19c6a8727252c5abf6ea24df3a4a16c7.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 5**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fff0ab3129a246ee2670d6d090921c40.png)'
  prefs: []
  type: TYPE_IMG
- en: '**PINN objective function**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Residual**'
  prefs: []
  type: TYPE_NORMAL
- en: The residual component is where *physics-informed* comes into play. This component,
    incorporating derivatives of the output, constrains the network to conform to
    the defining differential equation. The residual, Equation 6, is formed by rearranging
    Equation 1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df65ffa7c3d425398f069611eb792afb.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 6**'
  prefs: []
  type: TYPE_NORMAL
- en: 'During training, values of *t* are presented to the neural network’s input,
    resulting in a residual. Backpropagation then reduces the residual component of
    the objective to a minimum value close to *0* over all the training points. The
    residual component is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2d90cb6e39531082d56833d1673b0bb.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 7**'
  prefs: []
  type: TYPE_NORMAL
- en: The first and second derivatives, *di/dt* and *d²i/dt²*, required by Equation
    6 are provided by the automatic differentiation function in the PyTorch and TensorFlow
    neural network platforms.
  prefs: []
  type: TYPE_NORMAL
- en: '**Initial condition 1**'
  prefs: []
  type: TYPE_NORMAL
- en: In this circuit example, the first initial condition requires that the PINN’s
    output, *i(t) = 0* when input *t = 0*. This is due to the sinusoidal source *V
    sin(t) = 0* at *t = 0*, resulting in no current flowing in the circuit. The objective
    component for initial condition 1 is given by Equation 8\. During training, backpropagation
    will reduce this component to a value near *0*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/915dca72ab9b43afd54a753c473d2a35.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 8**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initial condition 2**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second initial condition requires that *L di/dt = 0* when input *t = 0*.
    It is derived from [Kirchhoff’s voltage law](https://en.wikipedia.org/wiki/Kirchhoff%27s_circuit_laws)
    (i.e., the sum of voltage drops around a closed loop is zero). Specifically, at
    *t = 0* the following conditions exist in the circuit:'
  prefs: []
  type: TYPE_NORMAL
- en: voltage source *V sin(ωt) = 0*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: capacitor *C* has an initial charge of *Q = 0* , yielding a capacitor voltage
    of *V_cap = Q/C = 0*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: voltage across the resistor *R* is *V_res = iR = 0*, since *i(t) = 0* (initial
    condition 1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: voltage across the inductor *L* is *V_ind = L di/dt*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: given the above conditions, the sum of the voltage drops around the circuit
    reduces to *L di/dt = 0*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The objective component for initial condition 2 is given by Equation 9\. Backpropagation
    will reduce this component to a value near 0.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c670e274daa775038f59303a0f9ebca.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Equation 9**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Objective plot**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the reduction in the value of the objective during
    training:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/073cb167d96415af82c2757de2813a30.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Objective plot**'
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following test cases compare the response of the trained PINN to the appropriate
    analytic solution for each case. The circuit component values were chosen to produce
    the conditions of under-damped, overdamped, and critically-damped responses, as
    discussed above. All three cases are driven with a sinusoidal voltage source of
    *V = 10 volts* and *ω = 1.8 radians/second*. For each case, the capacitor and
    inductor values are *C = 0.3 farads* and *L = 1.51 henries*, respectively. The
    value of the resistor *R* is noted below for each case.
  prefs: []
  type: TYPE_NORMAL
- en: '**Under-damped** (*R = 1.2 ohms*)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bebbbf47fa38540073e17b1920b45faa.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Underdamped test case**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Over-damped** (*R = 6.0 ohms*)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c951ac3a6978e890f3fd2e6443e3e9c0.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Over-damped test case**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Critically-damped** (*R = 4.487 ohms*)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be7a71c2f40b4bd4d3523ea3ffdadfc4.png)'
  prefs: []
  type: TYPE_IMG
- en: '**critically-damped test case**'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this article, a neural network with a custom objective function was used
    to successfully solve a differential equation describing an electronic circuit
    driven by a sinusoidal source. Typically, the solution to a differential equation
    is derived through a tedious analytic process or numerically. The example presented
    here demonstrates that a neural network can accurately solve these equations in
    a straightforward and efficient manner. As shown in the three test cases, the
    neural network response is identical to the analytic solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Appendix: PINN training notes'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'PINN structure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '- input layer, 1 input'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- hidden layer, 128 neurons with GELU activation'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- hidden layer, 128 neurons with GELU activation'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- output layer, 1 neuron with linear activation'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The PINN is trained with 220 points in the time domain of 0 to 20 seconds. The
    number of points is controlled by the duration of the domain and a hyperparameter
    for the number of points per second, which is set to 11 points/sec for the test
    cases. This value gives a sufficient number of training points for each period
    of a sinusoidal driving source with *ω = 1.8*. For higher values of *ω*, more
    points per second are required, e.g., *ω = 4.0* requires 25 points/sec.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The PINN is trained in batches of 32 points sampled from the set of all training
    points. The training points are randomly shuffled at every epoch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The learning rate starts at a value of 0.01 at the beginning of training and
    decreases by factor of 0.75 every 2000 epochs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The objective plot is an important indicator of successful training. As training
    progresses, the objective should decrease by several orders of magnitude and bottom
    out at a small value near 0\. If training fails to produce this result, the hyperparameters
    will require adjustment. It is recommended to first try increasing the number
    of epochs and then increasing the number of training points per second.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A pdf of this article is available** [**here**](https://github.com/jmorrow1000/PINN-with-forcing-function)**.**'
  prefs: []
  type: TYPE_NORMAL
- en: '*All images, unless otherwise noted, are by the author.*'
  prefs: []
  type: TYPE_NORMAL
