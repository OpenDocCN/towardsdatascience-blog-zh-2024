- en: 'LLMs for Everyone: Running the LLaMA-13B model and LangChain in Google Colab'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/llms-for-everyone-running-the-llama-13b-model-and-langchain-in-google-colab-68d88021cf0b?source=collection_archive---------4-----------------------#2024-01-05](https://towardsdatascience.com/llms-for-everyone-running-the-llama-13b-model-and-langchain-in-google-colab-68d88021cf0b?source=collection_archive---------4-----------------------#2024-01-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Experimenting with Large Language Models for free (Part 2)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://dmitryelj.medium.com/?source=post_page---byline--68d88021cf0b--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--68d88021cf0b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--68d88021cf0b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--68d88021cf0b--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--68d88021cf0b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--68d88021cf0b--------------------------------)
    ·14 min read·Jan 5, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a3ad498b55784156229ddc0304847682.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by Glib Albovsky, [Unsplash](https://unsplash.com/@albovsky)
  prefs: []
  type: TYPE_NORMAL
- en: In the [first part](/llms-for-everyone-running-langchain-and-a-mistralai-7b-model-in-google-colab-246ca94d7c4d)
    of the story, we used a free Google Colab instance to run a Mistral-7B model and
    extract information using the FAISS (Facebook AI Similarity Search) database.
    In this part, we will go further, and I will show how to run a LLaMA 2 13B model;
    we will also test some extra LangChain functionality like making chat-based applications
    and using agents. In the same way, as in the first part, all used components are
    based on open-source projects and will work completely for free.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get into it!
  prefs: []
  type: TYPE_NORMAL
- en: LLaMA.cpp
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A [LLaMA.CPP](https://github.com/ggerganov/llama.cpp) is a very interesting
    open-source project, originally designed to run an LLaMA model on Macbooks, but
    its functionality grew far beyond that. First, it is written in plain C/C++ without
    external dependencies and can run on any hardware (CUDA, OpenCL, and Apple silicon
    are supported; it can even work on a Raspberry Pi). Second, LLaMA.CPP can be connected
    with [LangChain](https://github.com/langchain-ai/langchain), which allows us to
    test a lot of its functionality for free without having an OpenAI key. Last but
    not least, because LLaMA.CPP works everywhere, it's a good candidate to run in
    a free Google Colab instance. As a reminder, Google provides free…
  prefs: []
  type: TYPE_NORMAL
