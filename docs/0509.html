<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>OpenAI vs Open-Source Multilingual Embedding Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>OpenAI vs Open-Source Multilingual Embedding Models</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/openai-vs-open-source-multilingual-embedding-models-e5ccb7c90f05?source=collection_archive---------0-----------------------#2024-02-24">https://towardsdatascience.com/openai-vs-open-source-multilingual-embedding-models-e5ccb7c90f05?source=collection_archive---------0-----------------------#2024-02-24</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="4105" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Choosing the model that works best for your data</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://ya-lb.medium.com/?source=post_page---byline--e5ccb7c90f05--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Yann-Aël Le Borgne" class="l ep by dd de cx" src="../Images/acc1c8b32373d7f345064b89b51869fd.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*I1DOXVG7-91vkO5iX_qjyg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e5ccb7c90f05--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://ya-lb.medium.com/?source=post_page---byline--e5ccb7c90f05--------------------------------" rel="noopener follow">Yann-Aël Le Borgne</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e5ccb7c90f05--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 24, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">15</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/d4106437a23e5edaba980ce8486937d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTVKNzDy1dnUCfcszIePXA.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">We’ll use the EU AI act as the data corpus for our embedding model comparison. Image by Dall-E 3.</figcaption></figure><p id="d89f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">OpenAI recently released their new generation of embedding models, called <em class="ny">embedding v3</em>, which they <a class="af nz" href="https://openai.com/blog/new-embedding-models-and-api-updates" rel="noopener ugc nofollow" target="_blank">describe</a> as their most performant embedding models, with higher multilingual performances. The models come in two classes: a smaller one called <code class="cx oa ob oc od b">text-embedding-3-small</code>, and a larger and more powerful one called <code class="cx oa ob oc od b">text-embedding-3-large</code>.</p><p id="0b57" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Very little information was disclosed concerning the way these models were designed and trained. As their previous embedding model release (December 2022 with the ada-002 model class), OpenAI again chooses a closed-source approach where the models may only be accessed through a paid API.</p><p id="8a23" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">But are the performances so good that they make it worth paying?</p><p id="fe7c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">The motivation for this post is to empirically compare the performances of these new models with their open-source counterparts</strong>. We’ll rely on a data retrieval workflow, where the most relevant documents in a corpus have to be found given a user query.</p><p id="425a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Our corpus will be the <a class="af nz" href="https://artificialintelligenceact.eu/" rel="noopener ugc nofollow" target="_blank">European AI Act</a>, which is currently in its final stages of validation. An interesting characteristic of this corpus, besides being the first-ever legal framework on AI worldwide, is its availability in 24 languages. This makes it possible to compare the accuracy of data retrieval <strong class="ne fr">across different families of languages</strong>.</p><p id="007e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The post will go through the two main following steps:</p><ul class=""><li id="3d08" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oe of og bk">Generate a custom synthetic question/answer dataset from a multilingual text corpus</li><li id="cf4d" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk">Compare the accuracy of OpenAI and state-of-the-art open-source embedding models on this custom dataset.</li></ul><p id="e879" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The code and data to reproduce the results presented in this post are made available in <a class="af nz" href="https://github.com/Yannael/multilingual-embeddings" rel="noopener ugc nofollow" target="_blank">this Github repository</a>. Note that the EU AI Act is used as an example, and the methodology followed in this post can be adapted to other data corpus.</p><h1 id="e04f" class="om on fq bf oo op oq gq or os ot gt ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk">Generate a custom Q/A dataset</h1><p id="3e81" class="pw-post-body-paragraph nc nd fq ne b go pi ng nh gr pj nj nk nl pk nn no np pl nr ns nt pm nv nw nx fj bk">Let us first start by generating a dataset of questions and answers (Q/A) on custom data, which will be used to assess the performance of different embedding models. The benefits of generating a custom Q/A dataset are twofold. First, it avoids biases by ensuring that the dataset has not been part of the training of an embedding model, which may happen on reference benchmarks such as <a class="af nz" href="https://huggingface.co/spaces/mteb/leaderboard" rel="noopener ugc nofollow" target="_blank">MTEB</a>. Second, it allows to tailor the assessment to a specific corpus of data, which can be relevant in the case of retrieval augmented applications (RAG) for example.</p><p id="2c9e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We will follow the simple process suggested by <a class="af nz" href="https://blog.llamaindex.ai/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971" rel="noopener ugc nofollow" target="_blank">Llama Index in their documentation</a>. The corpus is first split into a set of chunks. Then, for each chunk, a set of synthetic questions are generated by means of a large language model (LLM), such that the answer lies in the corresponding chunk. The process is illustrated below:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pn"><img src="../Images/debcd01ca6179cf42bb71ec7c684627d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*20cjDXK7k5BQrxl0He3Sdg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Generating a question/answer dataset for your data, methodology from <a class="af nz" href="https://blog.llamaindex.ai/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971" rel="noopener ugc nofollow" target="_blank">Llama Index</a></figcaption></figure><p id="82f5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Implementing this strategy is straightforward with a data framework for LLM such as Llama Index. The loading of the corpus and splitting of text can be conveniently carried out using high-level functions, as illustrated with the following code.</p><pre class="mm mn mo mp mq po od pp bp pq bb bk"><span id="3451" class="pr on fq od b bg ps pt l pu pv">from llama_index.readers.web import SimpleWebPageReader<br/>from llama_index.core.node_parser import SentenceSplitter<br/><br/>language = "EN"<br/>url_doc = "https://eur-lex.europa.eu/legal-content/"+language+"/TXT/HTML/?uri=CELEX:52021PC0206"<br/><br/>documents = SimpleWebPageReader(html_to_text=True).load_data([url_doc])<br/><br/>parser = SentenceSplitter(chunk_size=1000)<br/>nodes = parser.get_nodes_from_documents(documents, show_progress=True)</span></pre><p id="6de5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this example, the corpus is the EU AI Act in English, taken directly from the Web using this <a class="af nz" href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206" rel="noopener ugc nofollow" target="_blank">official URL</a>. We use the draft version from April 2021, as the final version is not yet available for all European languages. In this version, English language can be replaced in the URL by any of the 23 other EU official languages to retrieve the text in a different language (BG for Bulgarian, ES for Spanish, CS for Czech, and so forth).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pw"><img src="../Images/b228519bd3b36c7cec689ffd01b3226c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u38JuOdo4Q37CLztFJHFtw.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Download links to the EU AI Act for the 24 official EU languages (from <a class="af nz" href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206" rel="noopener ugc nofollow" target="_blank">EU official website</a>)</figcaption></figure><p id="4ed8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We use the SentenceSplitter object to split the document in chunks of 1000 tokens. For English, this results in about 100 chunks.</p><p id="5de8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Each chunk is then provided as context to the following prompt (<a class="af nz" href="https://github.com/run-llama/llama_index/blob/c058f2531ea86ee74822cb1421ceaeee7098a99f/llama_index/finetuning/embeddings/common.py#L51" rel="noopener ugc nofollow" target="_blank">the default prompt suggested in the Llama Index library</a>):</p><pre class="mm mn mo mp mq po od pp bp pq bb bk"><span id="3779" class="pr on fq od b bg ps pt l pu pv">prompts={}<br/>prompts["EN"] = """\<br/>Context information is below.<br/><br/>---------------------<br/>{context_str}<br/>---------------------<br/><br/>Given the context information and not prior knowledge, generate only questions based on the below query.<br/><br/>You are a Teacher/ Professor. Your task is to setup {num_questions_per_chunk} questions for an upcoming quiz/examination.<br/>The questions should be diverse in nature across the document. Restrict the questions to the context information provided."<br/>"""</span></pre><p id="9442" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The prompt aims at generating questions about the document chunk, as if a teacher were preparing an upcoming quiz. The number of questions to generate for each chunk is passed as the parameter ‘num_questions_per_chunk’, which we set to two. Questions can then be generated by calling the generate_qa_embedding_pairs from the Llama Index library:</p><pre class="mm mn mo mp mq po od pp bp pq bb bk"><span id="bf98" class="pr on fq od b bg ps pt l pu pv">from llama_index.llms import OpenAI<br/>from llama_index.legacy.finetuning import generate_qa_embedding_pairs<br/><br/>qa_dataset = generate_qa_embedding_pairs(<br/>    llm=OpenAI(model="gpt-3.5-turbo-0125",additional_kwargs={'seed':42}),<br/>    nodes=nodes,<br/>    qa_generate_prompt_tmpl = prompts[language],<br/>    num_questions_per_chunk=2<br/>)</span></pre><p id="55e1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We rely for this task on the GPT-3.5-turbo-0125 mode from OpenAI, which is according to OpenAI the flagship model of this family, supporting a 16K context window and optimized for dialog (<a class="af nz" href="https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fmodels%2Fgpt-3-5-turbo" rel="noopener ugc nofollow" target="_blank">https://platform.openai.com/docs/models/gpt-3-5-turbo</a>).</p><p id="530f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The resulting objet ‘qa_dataset’ contains the questions and answers (chunks) pairs. As an example of generated questions, here is the result for the first two questions (for which the ‘answer’ is the first chunk of text):</p><blockquote class="px py pz"><p id="e888" class="nc nd ny ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">1) What are the main objectives of the proposal for a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) according to the explanatory memorandum?<br/>2) How does the proposal for a Regulation on artificial intelligence aim to address the risks associated with the use of AI while promoting the uptake of AI in the European Union, as outlined in the context information?</p></blockquote><p id="e957" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The number of chunks and questions depends on the language, ranging from around 100 chunks and 200 questions for English, to 200 chunks and 400 questions for Hungarian.</p><h1 id="592e" class="om on fq bf oo op oq gq or os ot gt ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk">Evaluation of OpenAI embedding models</h1><p id="8a30" class="pw-post-body-paragraph nc nd fq ne b go pi ng nh gr pj nj nk nl pk nn no np pl nr ns nt pm nv nw nx fj bk">Our evaluation function follows the <a class="af nz" href="https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding.html" rel="noopener ugc nofollow" target="_blank">Llama Index documentation</a> and consists in two main steps. First, the embeddings for all answers (document chunks) are stored in a VectorStoreIndex for efficient retrieval. Then, the evaluation function loops over all queries, retrieves the top k most similar documents, and the accuracy of the retrieval in assessed in terms of MRR (<a class="af nz" href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank" rel="noopener ugc nofollow" target="_blank">Mean Reciprocal Rank</a>).</p><pre class="mm mn mo mp mq po od pp bp pq bb bk"><span id="65ea" class="pr on fq od b bg ps pt l pu pv">def evaluate(dataset, embed_model, insert_batch_size=1000, top_k=5):<br/>    # Get corpus, queries, and relevant documents from the qa_dataset object<br/>    corpus = dataset.corpus<br/>    queries = dataset.queries<br/>    relevant_docs = dataset.relevant_docs<br/><br/>    # Create TextNode objects for each document in the corpus and create a VectorStoreIndex to efficiently store and retrieve embeddings<br/>    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]<br/>    index = VectorStoreIndex(<br/>        nodes, embed_model=embed_model, insert_batch_size=insert_batch_size<br/>    )<br/>    retriever = index.as_retriever(similarity_top_k=top_k)<br/><br/>    # Prepare to collect evaluation results<br/>    eval_results = []<br/><br/>    # Iterate over each query in the dataset to evaluate retrieval performance<br/>    for query_id, query in tqdm(queries.items()):<br/>        # Retrieve the top_k most similar documents for the current query and extract the IDs of the retrieved documents<br/>        retrieved_nodes = retriever.retrieve(query)<br/>        retrieved_ids = [node.node.node_id for node in retrieved_nodes]<br/><br/>        # Check if the expected document was among the retrieved documents<br/>        expected_id = relevant_docs[query_id][0]<br/>        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc per query<br/><br/>        # Calculate the Mean Reciprocal Rank (MRR) and append to results<br/>        if is_hit:<br/>            rank = retrieved_ids.index(expected_id) + 1<br/>            mrr = 1 / rank<br/>        else:<br/>            mrr = 0<br/>        eval_results.append(mrr)<br/><br/>    # Return the average MRR across all queries as the final evaluation metric<br/>    return np.average(eval_results)</span></pre><p id="300a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The embedding model is passed to the evaluation function by means of the `embed_model` argument, which for OpenAI models is an OpenAIEmbedding object initialised with the name of the model, and the model dimension.</p><pre class="mm mn mo mp mq po od pp bp pq bb bk"><span id="cdc0" class="pr on fq od b bg ps pt l pu pv">from llama_index.embeddings.openai import OpenAIEmbedding<br/><br/>embed_model = OpenAIEmbedding(model=model_spec['model_name'],<br/>                              dimensions=model_spec['dimensions'])</span></pre><p id="237f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The <code class="cx oa ob oc od b">dimensions</code> API parameter can shorten embeddings (i.e. remove some numbers from the end of the sequence) without the embedding losing its concept-representing properties. OpenAI for example suggests <a class="af nz" href="https://openai.com/blog/new-embedding-models-and-api-updates" rel="noopener ugc nofollow" target="_blank">in their annoucement</a> that on the MTEB benchmark, an embedding can be shortened to a size of 256 while still outperforming an unshortened <code class="cx oa ob oc od b">text-embedding-ada-002</code> embedding with a size of 1536.</p><p id="12e2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We ran the evaluation function on four different OpenAI embedding models:</p><ul class=""><li id="b77e" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oe of og bk">two versions of <code class="cx oa ob oc od b">text-embedding-3-large</code> : one with the lowest possible dimension (256), and the other one with the highest possible dimension (3072). These are called ‘OAI-large-256’ and ‘OAI-large-3072’.</li><li id="9ead" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk">OAI-small: The <code class="cx oa ob oc od b">text-embedding-3-small</code> embedding model, with a dimension of 1536.</li><li id="3bca" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk">OAI-ada-002: The legacy <code class="cx oa ob oc od b">text-embedding-ada-002</code> model, with a dimension of 1536.</li></ul><p id="97df" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Each model was evaluated on four different languages: English (EN), French (FR), Czech (CS) and Hungarian (HU), covering examples of Germanic, Romance, Slavic and Uralic language, respectively.</p><pre class="mm mn mo mp mq po od pp bp pq bb bk"><span id="f654" class="pr on fq od b bg ps pt l pu pv">embeddings_model_spec = {<br/>}<br/><br/>embeddings_model_spec['OAI-Large-256']={'model_name':'text-embedding-3-large','dimensions':256}<br/>embeddings_model_spec['OAI-Large-3072']={'model_name':'text-embedding-3-large','dimensions':3072}<br/>embeddings_model_spec['OAI-Small']={'model_name':'text-embedding-3-small','dimensions':1536}<br/>embeddings_model_spec['OAI-ada-002']={'model_name':'text-embedding-ada-002','dimensions':None}<br/><br/>results = []<br/><br/>languages = ["EN", "FR", "CS", "HU"]<br/><br/># Loop through all languages<br/>for language in languages:<br/><br/>    # Load dataset<br/>    file_name=language+"_dataset.json"<br/>    qa_dataset = EmbeddingQAFinetuneDataset.from_json(file_name)<br/><br/>    # Loop through all models<br/>    for model_name, model_spec in embeddings_model_spec.items():<br/><br/>        # Get model<br/>        embed_model = OpenAIEmbedding(model=model_spec['model_name'],<br/>                                      dimensions=model_spec['dimensions'])<br/><br/>        # Assess embedding score (in terms of MRR)<br/>        score = evaluate(qa_dataset, embed_model)<br/><br/>        results.append([language, model_name, score])<br/><br/>df_results = pd.DataFrame(results, columns = ["Language" ,"Embedding model", "MRR"])</span></pre><p id="d622" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The resulting accuracy in terms of MRR is reported below:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qa"><img src="../Images/e85932db410223b301977602a81afcd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VllucQQDw_ECognmNaBxqw.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Summary of performances for the OpenAI models</figcaption></figure><p id="e0d6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As expected, for the large model, better performances are observed with the larger embedding size of 3072. Compared with the small and legacy Ada models, the large model is however smaller than we would have expected. For comparison, we also report below the performances obtained by the OpenAI models on the MTEB benchmark.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qb"><img src="../Images/d7f95f6dd6fc1fa806136b1f0a8236bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kz_nRojbAoR58ehSNIvevQ.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Performances of OpenAI embedding models, as reported in their <a class="af nz" href="https://openai.com/blog/new-embedding-models-and-api-updates" rel="noopener ugc nofollow" target="_blank">official announcement</a></figcaption></figure><p id="c376" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It is interesting to note that the differences in performances between the large, small and Ada models are much less pronounced in our assessment than in the MTEB benchmark, reflecting the fact that the average performances observed in large benchmarks do not necessarily reflect those obtained on custom datasets.</p><h1 id="a9a9" class="om on fq bf oo op oq gq or os ot gt ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk">Evaluation of open-source embedding models</h1><p id="e6d2" class="pw-post-body-paragraph nc nd fq ne b go pi ng nh gr pj nj nk nl pk nn no np pl nr ns nt pm nv nw nx fj bk">The open-source research around embeddings is quite active, and new models are regularly published. A good place to keep updated about the latest published models is the <a class="af nz" href="https://huggingface.co/spaces/mteb/leaderboard" rel="noopener ugc nofollow" target="_blank">Hugging Face 😊 MTEB leaderboard</a>.</p><p id="697b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For the comparison in this article, we selected a set of four embedding models recently published (2024). The criteria for selection were their average score on the MTEB leaderboard and their ability to deal with multilingual data. A summary of the main characteristics of the selected models are reported below.</p><figure class="mm mn mo mp mq mr"><div class="qc io l ed"><div class="qd qe l"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Selected open-source embedding models</figcaption></figure><ul class=""><li id="8b62" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oe of og bk"><a class="af nz" href="https://huggingface.co/intfloat/e5-mistral-7b-instruct" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr"><em class="ny">E5-Mistral-7B-instruct</em></strong></a><strong class="ne fr"><em class="ny"> </em></strong>(E5-mistral-7b): This E5 embedding model by Microsoft is initialized from <a class="af nz" href="https://huggingface.co/mistralai/Mistral-7B-v0.1" rel="noopener ugc nofollow" target="_blank">Mistral-7B-v0.1</a> and fine-tuned on a mixture of multilingual datasets. The model performs best on the MTEB leaderboard, but is also by far the biggest one (14GB).</li><li id="cdb3" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" href="https://huggingface.co/intfloat/multilingual-e5-large-instruct" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr"><em class="ny">multilingual-e5-large-instruct</em></strong></a><strong class="ne fr"><em class="ny"> </em></strong>(ML-E5-large): Another E5 model from Microsoft, meant to better handle multilingual data. It is initialized from <a class="af nz" href="https://huggingface.co/xlm-roberta-large" rel="noopener ugc nofollow" target="_blank">xlm-roberta-large</a> and trained on a mixture of multilingual datasets. It is much smaller (10 times) than E5-Mistral, but also has a much lower context size (514).</li><li id="fe06" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" href="https://huggingface.co/BAAI/bge-m3" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr"><em class="ny">BGE-M3</em></strong></a>: The model was designed by the Beijing Academy of Artificial Intelligence, and is their state-of-the-art embedding model for multilingual data, supporting more than 100 working languages. It was not yet benchmarked on the MTEB leaderboard as of 22/02/2024.</li><li id="3689" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" href="https://huggingface.co/nomic-ai/nomic-embed-text-v1" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr"><em class="ny">nomic-embed-text-v1</em></strong></a><strong class="ne fr"><em class="ny"> </em></strong>(Nomic-Embed): The model was designed by <a class="af nz" href="https://home.nomic.ai/" rel="noopener ugc nofollow" target="_blank">Nomic</a>, and claims better performances than OpenAI Ada-002 and text-embedding-3-small while being only 0.55GB in size. Interestingly, the model is the first to be fully reproducible and auditable (open data and open-source training code).</li></ul><p id="e805" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The code for evaluating these open-source models is similar to the code used for OpenAI models. The main change lies in the model specifications, where additional details such as maximum context length and pooling types have to be specified. We then evaluate each model for each of the four languages:</p><pre class="mm mn mo mp mq po od pp bp pq bb bk"><span id="10fe" class="pr on fq od b bg ps pt l pu pv">embeddings_model_spec = {<br/>}<br/><br/>embeddings_model_spec['E5-mistral-7b']={'model_name':'intfloat/e5-mistral-7b-instruct','max_length':32768, 'pooling_type':'last_token', <br/>                                        'normalize': True, 'batch_size':1, 'kwargs': {'load_in_4bit':True, 'bnb_4bit_compute_dtype':torch.float16}}<br/>embeddings_model_spec['ML-E5-large']={'model_name':'intfloat/multilingual-e5-large','max_length':512, 'pooling_type':'mean', <br/>                                      'normalize': True, 'batch_size':1, 'kwargs': {'device_map': 'cuda', 'torch_dtype':torch.float16}}<br/>embeddings_model_spec['BGE-M3']={'model_name':'BAAI/bge-m3','max_length':8192, 'pooling_type':'cls', <br/>                                 'normalize': True, 'batch_size':1, 'kwargs': {'device_map': 'cuda', 'torch_dtype':torch.float16}}<br/>embeddings_model_spec['Nomic-Embed']={'model_name':'nomic-ai/nomic-embed-text-v1','max_length':8192, 'pooling_type':'mean', <br/>                                      'normalize': True, 'batch_size':1, 'kwargs': {'device_map': 'cuda', 'trust_remote_code' : True}}<br/><br/>results = []<br/><br/>languages = ["EN", "FR", "CS", "HU"]<br/><br/># Loop through all models<br/>for model_name, model_spec in embeddings_model_spec.items():<br/><br/>    print("Processing model : "+str(model_spec))<br/><br/>    # Get model<br/>    tokenizer = AutoTokenizer.from_pretrained(model_spec['model_name'])<br/>    embed_model = AutoModel.from_pretrained(model_spec['model_name'], **model_spec['kwargs'])<br/>        <br/>    if model_name=="Nomic-Embed":<br/>        embed_model.to('cuda')<br/><br/>    # Loop through all languages<br/>    for language in languages:<br/><br/>        # Load dataset<br/>        file_name=language+"_dataset.json"<br/>        qa_dataset = EmbeddingQAFinetuneDataset.from_json(file_name)<br/><br/>        start_time_assessment=time.time()<br/><br/>        # Assess embedding score (in terms of hit rate at k=5)<br/>        score = evaluate(qa_dataset, tokenizer, embed_model, model_spec['normalize'], model_spec['max_length'], model_spec['pooling_type'])<br/><br/>        # Get duration of score assessment<br/>        duration_assessment = time.time()-start_time_assessment<br/><br/>        results.append([language, model_name, score, duration_assessment])<br/><br/>df_results = pd.DataFrame(results, columns = ["Language" ,"Embedding model", "MRR", "Duration"])</span></pre><p id="4a87" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The resulting accuracies in terms of MRR are reported below.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qf"><img src="../Images/f77ab24c4d15f7334aa730420a285de6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cVV7rPMK-EVyaHrBVBohKw.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Summary of performances for the open-source models</figcaption></figure><p id="26ee" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">BGE-M3 turns out to provide the best performances, followed on average by ML-E5-Large, E5-mistral-7b and Nomic-Embed. BGE-M3 model is not yet benchmarked on the MTEB leaderboard, and our results indicate that it could rank higher than other models. It is also interesting to note that while BGE-M3 is optimized for multilingual data, it also performs better for English than the other models.</p><p id="5bb6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We additionally report the processing times for each embedding model below.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qg"><img src="../Images/026e18ce209b4a9150cc60b529e46e89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k3iKkgdpR4ilLCYEDkcxcw.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Processing times in seconds for going throught the English Q/A dataset</figcaption></figure><p id="818d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The E5-mistral-7b, which is more than 10 times larger than the other models, is without surprise by far the slowest model.</p><h1 id="adca" class="om on fq bf oo op oq gq or os ot gt ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk">Conclusion</h1><p id="b7e8" class="pw-post-body-paragraph nc nd fq ne b go pi ng nh gr pj nj nk nl pk nn no np pl nr ns nt pm nv nw nx fj bk">Let us put side-by-side of the performance of the eight tested models in a single figure.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qh"><img src="../Images/2098db260ef495cac46c32a79518bcc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x_IbdvfVCSm1OLaP3Ev72w.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Summary of performances for the eight tested models</figcaption></figure><p id="05ef" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The key observations from these results are:</p><ul class=""><li id="8377" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oe of og bk"><strong class="ne fr">Best performances were obtained by open-source models</strong>. The <a class="af nz" href="https://huggingface.co/BAAI/bge-m3" rel="noopener ugc nofollow" target="_blank">BGE-M3</a> model, developed by the Beijing Academy of Artificial Intelligence, emerged as the top performer. The model has the same context length as OpenAI models (8K), for a size of 2.2GB.</li><li id="1d15" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><strong class="ne fr">Consistency Across OpenAI’s Range</strong>. The performances of the large (3072), small and legacy OpenAI models were very similar. Reducing the embedding size of the large model (256) however led to a degradation of performances.</li><li id="bdd2" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><strong class="ne fr">Language Sensitivity. </strong>Almost all models (except ML-E5-large) performed best on English. Significant variations in performances were observed in languages like Czech and Hungarian.</li></ul><p id="d911" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Should you therefore go for a paid OpenAI subscription, or for hosting an open-source embedding model?</p><p id="363e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">OpenAI’s <a class="af nz" href="https://openai.com/pricing" rel="noopener ugc nofollow" target="_blank">recent price revision</a> has made access to their API significantly more affordable, with the cost now standing at $0.13 per million tokens. Dealing with one million queries per month (and assuming that each query involves around 1K token) would therefore cost on the order of $130. Depending on your use case, it may therefore not be cost-effective to rent and maintain your own embedding server.</p><p id="17a1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Cost-effectiveness is however not the sole consideration. Other factors such as latency, privacy, and control over data processing workflows may also need to be considered. Open-source models offer the advantage of complete data control, enhancing privacy and customization. On the other hand, latency issues have been observed with OpenAI’s API, sometimes resulting in extended response times.</p><p id="0b55" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In conclusion, the choice between open-source models and proprietary solutions like OpenAI’s does not lend itself to a straightforward answer. Open-source embeddings present a compelling option, combining performance with greater control over data. Conversely, OpenAI’s offerings may still appeal to those prioritizing convenience, especially if privacy concerns are secondary.</p><h1 id="1fa6" class="om on fq bf oo op oq gq or os ot gt ou ov ow ox oy oz pa pb pc pd pe pf pg ph bk">Useful links</h1><ul class=""><li id="4a57" class="nc nd fq ne b go pi ng nh gr pj nj nk nl pk nn no np pl nr ns nt pm nv nw nx oe of og bk">Companion Github repository: <a class="af nz" href="https://github.com/Yannael/multilingual-embeddings" rel="noopener ugc nofollow" target="_blank">https://github.com/Yannael/multilingual-embeddings</a></li><li id="5ae8" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" href="https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/" rel="noopener ugc nofollow" target="_blank">Everything you wanted to know about sentence embeddings (and maybe a bit more)</a></li><li id="dd4e" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" href="https://openai.com/blog/new-embedding-models-and-api-updates" rel="noopener ugc nofollow" target="_blank">OpenAI blog announcement: New embedding models and API updates</a></li><li id="5a48" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" href="https://platform.openai.com/docs/guides/embeddings/embedding-models" rel="noopener ugc nofollow" target="_blank">Embeddings: OpenAI guide</a></li><li id="6473" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" href="https://arxiv.org/abs/2210.07316" rel="noopener ugc nofollow" target="_blank">MTEB: Massive Text Embedding Benchmark</a> and <a class="af nz" href="https://huggingface.co/spaces/mteb/leaderboard" rel="noopener ugc nofollow" target="_blank">Hugging Face MTEB leaderboard</a></li><li id="abb8" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" rel="noopener" target="_blank" href="/text-embeddings-comprehensive-guide-afd97fce8fb5">Text Embeddings: Comprehensive Guide</a></li><li id="2274" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" href="https://cameronrwolfe.substack.com/p/a-practitioners-guide-to-retrieval" rel="noopener ugc nofollow" target="_blank">A Practitioners Guide to Retrieval Augmented Generation (RAG)</a></li><li id="7298" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk"><a class="af nz" rel="noopener" target="_blank" href="/how-to-find-the-best-multilingual-embedding-model-for-your-rag-40325c308ebb">How to Find the Best Multilingual Embedding Model for Your RAG</a></li></ul><p id="079f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Notes:</p><ul class=""><li id="b3a2" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oe of og bk">Unless otherwise noted, all images are by the author</li><li id="349b" class="nc nd fq ne b go oh ng nh gr oi nj nk nl oj nn no np ok nr ns nt ol nv nw nx oe of og bk">The EU AI act draft is published under the <a class="af nz" href="https://eur-lex.europa.eu/content/legal-notice/legal-notice.html" rel="noopener ugc nofollow" target="_blank">Commission’s document reuse policy</a> based on <a class="af nz" href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32011D0833" rel="noopener ugc nofollow" target="_blank">Decision 2011/833/EU</a>, and can be re-used for commercial or non-commercial purposes.</li></ul></div></div></div><div class="ab cb qi qj qk ql" role="separator"><span class="qm by bm qn qo qp"/><span class="qm by bm qn qo qp"/><span class="qm by bm qn qo"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="433a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">Enjoyed this post? Share your thoughts, give it claps, or </em><a class="af nz" href="https://www.linkedin.com/in/yannaelb/" rel="noopener ugc nofollow" target="_blank"><em class="ny">connect with me on LinkedIn</em></a><em class="ny">.</em></p></div></div></div></div>    
</body>
</html>