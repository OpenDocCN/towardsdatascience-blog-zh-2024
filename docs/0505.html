<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Spurious Correlations: The Comedy and Drama of Statistics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Spurious Correlations: The Comedy and Drama of Statistics</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spurious-correlations-the-comedy-and-drama-of-statistics-b63bf99169d8?source=collection_archive---------0-----------------------#2024-02-23">https://towardsdatascience.com/spurious-correlations-the-comedy-and-drama-of-statistics-b63bf99169d8?source=collection_archive---------0-----------------------#2024-02-23</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="d856" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">What not to do with statistics</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@celiabanks?source=post_page---byline--b63bf99169d8--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Celia Banks, Ph.D." class="l ep by dd de cx" src="../Images/40ac2c6abdf6e29dfad8b4cee65219ba.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*0T3fimDIaOw3l9Vy"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--b63bf99169d8--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@celiabanks?source=post_page---byline--b63bf99169d8--------------------------------" rel="noopener follow">Celia Banks, Ph.D.</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--b63bf99169d8--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">17 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 23, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">3</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="12f2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><em class="nf">By Celia Banks, PhD and Paul Boothroyd III</em></p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div class="ng nh ni"><img src="../Images/0cef47eaebc1542573870c5334f983f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*88zVz1hdLds5g9kpthBGNg.png"/></div><figcaption class="nq nr ns ng nh nt nu bf b bg z dx">By</figcaption></figure><figure class="nj nk nl nm nn no ng nh paragraph-image"><div class="ng nh nv"><img src="../Images/7276687644c06e47d05d1df48b7226ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*OV5Qx8JLKAG9h3NZGRVKDg.png"/></div></figure><h1 id="84cb" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">Introduction</h1><p id="f6ef" class="pw-post-body-paragraph mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne fj bk">Since <em class="nf">Tyler Vigen</em> coined the term ‘spurious correlations’ for “any random correlations dredged up from silly data” (Vigen, 2014) see: <a class="af ox" href="https://www.tylervigen.com/" rel="noopener ugc nofollow" target="_blank">Tyler Vigen’s personal website</a>, there have been many articles that pay tribute to the perils and pitfalls of this whimsical tendency to manipulate statistics to make correlation equal causation. See: HBR (2015), Medium (2016), FiveThirtyEight (2016). As data scientists, we are tasked with providing statistical analyses that either accept or reject null hypotheses. We are taught to be ethical in how we source data, extract it, preprocess it, and make statistical assumptions about it. And this is no small matter — global companies rely on the validity and accuracy of our analyses. It is just as important that our work be reproducible. Yet, in spite of all of the ‘good’ that we are taught to practice, there may be that ​one occasion (or more) where a boss or client will insist that you work the data until it supports the hypothesis and, above all, show how variable y causes variable x when correlated. This is the basis of p-hacking where you enter into a territory that is far from supported by ‘good’ practice. In this report, we learn how to conduct fallacious research using spurious correlations. We get to delve into ‘bad’ with the objective of learning what not to do when you are faced with that inevitable moment to deliver what the boss or client whispers in your ear.</p><blockquote class="oy"><p id="cb25" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">The objective of this project is to teach you</p><p id="9495" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">what not to do with statistics</p></blockquote><p id="9029" class="pw-post-body-paragraph mj mk fq ml b go pi mn mo gr pj mq mr ms pk mu mv mw pl my mz na pm nc nd ne fj bk">​We’ll demonstrate the spurious correlation of two unrelated variables. Datasets from two different sources were preprocessed and merged together in order to produce visuals of relationships. Spurious correlations occur when two variables are misleadingly correlated, and it is further assumed that one variable directly affects the other variable so as to cause a certain outcome. ​The reason we chose this project idea is because we were interested in ways that manage a client’s expectations of what a data analysis project should produce. For team member Banks, sometimes she has had clients demonstrate displeasure with analysis results and actually on one occasion she was asked to go back and look at other data sources and opportunities to “help” arrive at the answers they were seeking. Yes, this is p-hacking — in this case, where the client insisted that causal relationships existed because they believe the correlations existed to cause an outcome.</p><blockquote class="oy"><p id="84f2" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">Examples of Spurious Correlations</p></blockquote></div></div><div class="no"><div class="ab cb"><div class="lm pn ln po lo pp cf pq cg pr ci bh"><figure class="pt pu pv pw px no py pz paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh ps"><img src="../Images/2476b96a968c0806c6c83cf14b752b09.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*6PJkoYEijDR1La8zPG9Gxw.png"/></div></div><figcaption class="nq nr ns ng nh nt nu bf b bg z dx">Excerpts of Tyler Vigen’s Spurious Correlations. Retrieved February 1, 2024, from <a class="af ox" href="https://www.tylervigen.com/spurious-correlations" rel="noopener ugc nofollow" target="_blank">Spurious Correlations (tylervigen.com)</a> Reprinted with permission from the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="c8ce" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">Research Questions Pertinent to this Study</h1><blockquote class="oy"><p id="6450" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">What are the research questions?</p><p id="8bf6" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">Why the heck do we need them?</p><p id="c32a" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">We’re doing a “bad” analysis, right?</p></blockquote><p id="278a" class="pw-post-body-paragraph mj mk fq ml b go pi mn mo gr pj mq mr ms pk mu mv mw pl my mz na pm nc nd ne fj bk">Research questions are the foundation of the research study. They guide the research process by focusing on specific topics that the researcher will investigate. Reasons why they are essential include but are not limited to: for focus and clarity; as guidance for methodology; establish the relevance of the study; help to structure the report; help the researcher evaluate results and interpret findings. ​In learning how a ‘bad’ analysis is conducted, we addressed the following questions:</p><p id="c5b4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(1) Are the data sources valid (not made up)?</p><p id="e740" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(2) How were missing values handled?</p><p id="9a97" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(3) How were you able to merge dissimilar datasets?</p><p id="199c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(4) What are the response and predictor variables?</p><p id="a857" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(5) Is the relationship between the response and predictor variables linear?</p><p id="af88" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(6) Is there a correlation between the response and predictor variables?</p><p id="e7ef" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(7) Can we say that there is a causal relationship between the variables?</p><p id="1a25" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(8) What explanation would you provide a client interested in the relationship between these two variables?</p><p id="6b27" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(9) Did you find spurious correlations in the chosen datasets?</p><p id="a694" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(10) What learning was your takeaway in conducting this project?</p><h1 id="47c8" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">Methodology</h1><blockquote class="oy"><p id="3981" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">How did we conduct a study about</p><p id="d3b1" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">Spurious Correlations?​</p></blockquote><p id="feb5" class="pw-post-body-paragraph mj mk fq ml b go pi mn mo gr pj mq mr ms pk mu mv mw pl my mz na pm nc nd ne fj bk">To investigate the presence of spurious correlations between variables, a comprehensive analysis was conducted. The datasets spanned different domains of economic and environmental factors that were collected and affirmed as being from public sources. The datasets contained variables with no apparent causal relationship but exhibited statistical correlation. The chosen datasets were of the Apple stock data, the primary, and daily high temperatures in New York City, the secondary. The datasets spanned the time period of January, 2017 through December, 2022.</p><p id="d4cb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">​Rigorous statistical techniques were used to analyze the data. A Pearson correlation coefficients was calculated to quantify the strength and direction of linear relationships between pairs of the variables. To complete this analysis, scatter plots of the 5-year daily high temperatures in New York City, candlestick charting of the 5-year Apple stock trend, and a dual-axis charting of the daily high temperatures versus sock trend were utilized to visualize the relationship between variables and to identify patterns or trends. Areas this methodology followed were:</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qe"><img src="../Images/03b7343e1128b679fd75a327cbb81c9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ww-faj7IayqQOosIfoUw5g.png"/></div></div></figure><h1 id="ab5c" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk"><strong class="al"><em class="qf">The Data: Source/Extract/Process</em></strong></h1><p id="c05a" class="pw-post-body-paragraph mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne fj bk"><strong class="ml fr">Primary dataset</strong>: <a class="af ox" href="https://markets.financialcontent.com/stocks/quote/historical?Symbol=537%3A908440&amp;Year=2019&amp;Month=1&amp;Range=12" rel="noopener ugc nofollow" target="_blank">Apple Stock Price History | Historical AAPL Company Stock Prices | FinancialContent Business Page</a></p><p id="024b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Secondary dataset</strong>: New York City daily high temperatures from Jan 2017 to Dec 2022: <a class="af ox" href="https://www.extremeweatherwatch.com/cities/new-york/year-{year}" rel="noopener ugc nofollow" target="_blank">https://www.extremeweatherwatch.com/cities/new-york/year-{year}</a></p><p id="44a4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The data was affirmed as publicly sourced and available for reproducibility. Capturing the data over a time period of five years gave a meaningful view of patterns, trends, and linearity. Temperature readings saw seasonal trends. For temperature and stock, there were troughs and peaks in data points. Note temperature was in Fahrenheit, a meteorological setting. We used astronomical setting to further manipulate our data to pose stronger spuriousness. While the data could be downloaded as csv or xls files, for this assignment, Python’s Beautiful soup web scraping API was used.</p><p id="bc0a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Next, the data was checked for missing values and how many records each contained. Weather data contained date, daily high, daily low temperature, and Apple stock data contained date, opening price, closing price, volume, stock price, stock name. To merge the datasets, the date columns needed to be in datetime format. An inner join matched records and discarded non-matching. For Apple stock, date and daily closing price represented the columns of interest. For the weather, date and daily high temperature represented the columns of interest.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qg"><img src="../Images/d97cbfa1f8c8f7a0898c790e3f99c3f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oVN599uEndeiBjxtEsqnig.png"/></div></div></figure><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qh"><img src="../Images/2a9267e484e40582e285ab4363d56e10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6vwtWlydXGOpkLAq8v5TUw.png"/></div></div></figure><h1 id="ddf3" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">The Data: Manipulation</h1><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qi"><img src="../Images/e2b1a47efe76ee5bc51927ebeda70ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5wj2x_xLuxVyJremOXVsjw.png"/></div></div><figcaption class="nq nr ns ng nh nt nu bf b bg z dx">From Duarte® Slide Deck</figcaption></figure><blockquote class="oy"><p id="ea4b" class="oz pa fq bf pb pc qj qk ql qm qn ne dx">To do ‘bad’ the right way, you have to</p><p id="6860" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">massage the data until you find the</p><p id="11a2" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">relationship that you’re looking for…​</p></blockquote><p id="4a46" class="pw-post-body-paragraph mj mk fq ml b go pi mn mo gr pj mq mr ms pk mu mv mw pl my mz na pm nc nd ne fj bk">Our earlier approach did not quite yield the intended results. So, instead of using the summer season of 2018 temperatures in five U.S. cities, we pulled five years of daily high temperatures for New York City and Apple Stock performance from January, 2017 through December, 2022. In conducting exploratory analysis, we saw weak correlations across the seasons and years. So, our next step was to convert the temperature. Instead of meteorological, we chose astronomical. This gave us ​‘meaningful’ correlations across seasons.</p><p id="28c5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">​With the new approach in place, we noticed that merging the datasets was problematic. The date fields were different where for weather, the date was month and day. For stock, the date was in year-month-day format. We addressed this by converting each dataset’s date column to datetime. Also, each date column was sorted either in chronological or reverse chronological order. This was resolved by sorting both date columns in ascending order.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qo"><img src="../Images/22958908fff78293f87d2acbdb02a3cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*graj_uHepvhp4D_btQmIqg.png"/></div></div></figure><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qp"><img src="../Images/e8bf0fbf8ce4fca700bea52acf82a7af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Ya8qFdP6n_H9cQZKiJeXw.png"/></div></div></figure><h1 id="e57f" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">Analysis I: Do We Have Spurious Correlation? Can We Prove It?</h1><blockquote class="oy"><p id="b622" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">The spurious nature of the correlations</p><p id="4127" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">here is shown by shifting from</p><p id="9f76" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">meteorological seasons (Spring: Mar-May,</p><p id="3d79" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">Summer: Jun-Aug, Fall: Sep-Nov, Winter:</p><p id="3e56" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">Dec-Feb) which are based on weather</p><p id="868b" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">patterns in the northern hemisphere, to</p><p id="83bd" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">astronomical seasons (Spring: Apr-Jun,</p><p id="3934" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">Summer: Jul-Sep, Fall: Oct-Dec, Winter:</p><p id="cbbd" class="oz pa fq bf pb pc pd pe pf pg ph ne dx">Jan-Mar) which are based on Earth’s tilt.</p></blockquote><p id="4a9f" class="pw-post-body-paragraph mj mk fq ml b go pi mn mo gr pj mq mr ms pk mu mv mw pl my mz na pm nc nd ne fj bk">​Once we accomplished the exploration, a key point in our analysis of spurious correlation was to determine if the variables of interest correlate. We eyeballed that Spring 2020 had a correlation of 0.81. We then determined if there was statistical significance — yes, and at p-value ≈ 0.000000000000001066818316115281, I’d say we have significance!</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div class="ng nh qq"><img src="../Images/041a0587d114d9f9ac602a834ba34aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*LE7YgPiWQM_iMCIZzHFhLA.png"/></div><figcaption class="nq nr ns ng nh nt nu bf b bg z dx">Spring 2020 temperatures correlate with Apple stock</figcaption></figure><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qr"><img src="../Images/6f3bd291a761c61b64fcfec5ea36103c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kBBqp6NMg5zI4_zyDLLMDQ.png"/></div></div></figure><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qs"><img src="../Images/7853dd21c3584db37688fca3272ef4b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qwn2SgS-5G2zqr-V8FYb3w.png"/></div></div></figure><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qr"><img src="../Images/98fcd4a88fbc2da92eb951d40d1e7b3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i52k2ebs1oC_jJpOfdA29A.png"/></div></div></figure><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="qa qb ed qc bh qd"><div class="ng nh qt"><img src="../Images/96ec72bf2c05293e26cc67f71e608f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xG5-u5UknUDDQQysV7HXHw.png"/></div></div></figure><h1 id="2aba" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">Analysis II: Additional Statistics to Test the Nature of Spuriousness</h1><blockquote class="oy"><p id="d96c" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">If there is truly spurious correlation, we may want to</em></p><p id="1968" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">consider if the correlation equates to causation — that</em></p><p id="86db" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">is, does a change in astronomical temperature cause</em></p><p id="4fce" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">Apple stock to fluctuate? We employed further</em></p><p id="eac0" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">statistical testing to prove or reject the hypothesis</em></p><p id="e76f" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">that one variable causes the other variable.</em></p></blockquote><p id="65df" class="pw-post-body-paragraph mj mk fq ml b go pi mn mo gr pj mq mr ms pk mu mv mw pl my mz na pm nc nd ne fj bk">There are numerous statistical tools that test for causality. Tools such as Instrumental Variable (IV) Analysis, Panel Data Analysis, Structural Equation Modelling (SEM), Vector Autoregression Models, Cointegration Analysis, and Granger Causality. IV analysis considers omitted variables in regression analysis; Panel Data studies fixed-effects and random effects models; SEM analyzes structural relationships; Vector Autoregression considers dynamic multivariate time series interactions; and Cointegration Analysis determines whether variables move together in a stochastic trend. We wanted a tool that could finely distinguish between genuine causality and coincidental association. To achieve this, our choice was Granger Causality.</p><p id="cafe" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Granger Causality</strong></p><p id="42fe" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A Granger test checks whether past values can predict future ones. In our case, we tested whether past daily high temperatures in New York City could predict future values of Apple stock prices.</p><p id="52ce" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">​<em class="nf">Ho: Daily high temperatures in New York City do not Granger cause Apple stock price fluctuation.</em></p><p id="e7ae" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">​To conduct the test, we ran through 100 lags to see if there was a standout p-value. We encountered near 1.0 p-values, and this suggested that we could not reject the null hypothesis, and we concluded that there was no evidence of a causal relationship between the variables of interest.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div class="ng nh qu"><img src="../Images/6392f882fc12ff50bb6659d9a61ed1e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*KMtBlvLCOVxuqZ7t1C8k4g.png"/></div><figcaption class="nq nr ns ng nh nt nu bf b bg z dx">Granger Causality Test at lags=100</figcaption></figure><h1 id="97e6" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">Analysis III: Statistics to Validate Not Rejecting the Null Ho</h1><blockquote class="oy"><p id="6fdd" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">Granger causality proved the p-value</em></p><p id="2dcd" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">insignificant in rejecting the null</em></p><p id="3704" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">hypothesis. But, is that enough?</em></p><p id="4021" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">Let’s validate our analysis.</em></p></blockquote><p id="0562" class="pw-post-body-paragraph mj mk fq ml b go pi mn mo gr pj mq mr ms pk mu mv mw pl my mz na pm nc nd ne fj bk">To help in mitigating the risk of misinterpreting spuriousness as genuine causal effects, performing a Cross-Correlation analysis in conjunction with a Granger causality test will confirm its finding. Using this approach, if spurious correlation exists, we will observe significance in cross-correlation at some lags without consistent causal direction or without Granger causality being present.</p><p id="afa6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Cross-Correlation Analysis</strong></p><p id="9236" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This method is accomplished by the following steps:</p><ul class=""><li id="807b" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qv qw qx bk">Examine temporal patterns of correlations between variables;</li><li id="c0d5" class="mj mk fq ml b go qy mn mo gr qz mq mr ms ra mu mv mw rb my mz na rc nc nd ne qv qw qx bk">•If variable A Granger causes variable B, significant cross-correlation will occur between variable A and variable B at positive lags;</li><li id="e5ad" class="mj mk fq ml b go qy mn mo gr qz mq mr ms ra mu mv mw rb my mz na rc nc nd ne qv qw qx bk">Significant peaks in cross-correlation at specific lags infers the time delay between changes in the causal variable.</li></ul><figure class="nj nk nl nm nn no ng nh paragraph-image"><div class="ng nh rd"><img src="../Images/b1d62d212c5265a3297f2c241787218c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*vnXQ0F7ndH2OQrf8EEXyIg.png"/></div></figure><p id="05d3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><em class="nf">Interpretation:</em></p><p id="f740" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The ccf and lag values show significance in positive correlation at certain lags. This confirms that spurious correlation exists. However, like the Granger causality, the cross-correlation analysis cannot support the claim that causality exists in the relationship between the two variables.</p><h1 id="8181" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">Wrapup: Key Learnings</h1><ul class=""><li id="e65f" class="mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne qv qw qx bk">Spurious correlations are a form of p-hacking. Correlation does not imply causation.</li><li id="ac92" class="mj mk fq ml b go qy mn mo gr qz mq mr ms ra mu mv mw rb my mz na rc nc nd ne qv qw qx bk">Even with ‘bad’ data tactics, statistical testing will root out the lack of significance. While there was statistical evidence of spuriousness in the variables, causality testing could not support the claim that causality existed in the relationship of the variables.</li><li id="d362" class="mj mk fq ml b go qy mn mo gr qz mq mr ms ra mu mv mw rb my mz na rc nc nd ne qv qw qx bk">A study cannot rest on the sole premise that variables displaying linearity can be correlated to exhibit causality. Instead, other factors that contribute to each variable must be considered.</li><li id="3f92" class="mj mk fq ml b go qy mn mo gr qz mq mr ms ra mu mv mw rb my mz na rc nc nd ne qv qw qx bk">A non-statistical test of whether daily high temperatures in New York City cause Apple stock to fluctuate can be to just consider: If you owned an Apple stock certificate and you placed it in the freezer, would the value of the certificate be impacted by the cold? Similarly, if you placed the certificate outside on a sunny, hot day, would the sun impact the value of the certificate?</li></ul><h1 id="a55d" class="nw nx fq bf ny nz oa gq ob oc od gt oe of og oh oi oj ok ol om on oo op oq or bk">Ethical Considerations: P-Hacking is Not a Valid Analysis</h1><figure class="nj nk nl nm nn no ng nh paragraph-image"><div class="ng nh re"><img src="../Images/2fcbc421f09326839fdf6fd3626d1aeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*xhvzKPUnXyb1YptpI6HORA.png"/></div><figcaption class="nq nr ns ng nh nt nu bf b bg z dx"><a class="af ox" href="https://www.freepik.com/free-vector/business-people-saying-no-concept-illustration_38687005.htm#query=refuse%20work&amp;position=20&amp;from_view=keyword&amp;track=ais&amp;uuid=e5cd742b-f902-40f7-b7c4-812b147fe1df" rel="noopener ugc nofollow" target="_blank">https://www.freepik.com/free-vector/business-people-saying-no-concept-illustration_38687005.htm#query=refuse%20work&amp;position=20&amp;from_view=keyword&amp;track=ais&amp;uuid=e5cd742b-f902-40f7-b7c4-812b147fe1df</a> Image by storyset on Freepik</figcaption></figure><blockquote class="oy"><p id="e313" class="oz pa fq bf pb pc qj qk ql qm qn ne dx"><em class="qf">Spurious correlations are not causality.</em></p><p id="257b" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">P-hacking may impact your credibility as a</em></p><p id="2bf5" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">data scientist. Be the adult in the room and</em></p><p id="7cd3" class="oz pa fq bf pb pc pd pe pf pg ph ne dx"><em class="qf">refuse to participate in bad statistics.</em>​</p></blockquote><p id="fb14" class="pw-post-body-paragraph mj mk fq ml b go pi mn mo gr pj mq mr ms pk mu mv mw pl my mz na pm nc nd ne fj bk">This study portrayed analysis that involved ‘bad’ statistics. It demonstrated how a data scientist could source, extract and manipulate data in such a way as to statistically show correlation. In the end, statistical testing withstood the challenge and demonstrated that correlation does not equal causality.</p><p id="c801" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">​Conducting a spurious correlation brings ethical questions of using statistics to derive causation in two unrelated variables. It is an example of p-hacking, which exploits statistics in order to achieve a desired outcome. This study was done as academic research to show the absurdity in misusing statistics.</p><p id="2221" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">​Another area of ethical consideration is the practice of web scraping. Many website owners warn against pulling data from their sites to use in nefarious ways or ways unintended by them. For this reason, sites like Yahoo Finance make stock data downloadable to csv files. This is also true for most weather sites where you can request time datasets of temperature readings. Again, this study is for academic research and to demonstrate one’s ability to extract data in a nonconventional way.</p><p id="4bf1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">​When faced with a boss or client that compels you to p-hack and offer something like a spurious correlation as proof of causality, explain the implications of their ask and respectfully refuse the project. Whatever your decision, it will have a lasting impact on your credibility as a data scientist.</p><blockquote class="rf rg rh"><p id="b48e" class="mj mk nf ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Dr. Banks is CEO of <a class="af ox" href="https://www.spice-chip.com" rel="noopener ugc nofollow" target="_blank">I-Meta</a>, maker of the patented Spice Chip Technology that provides Big Data analytics for various industries. Mr. Boothroyd, III is a retired Military Analyst. Both are veterans having honorably served in the United States military and both enjoy discussing spurious correlations. They are cohorts of the University of Michigan, School of Information MADS program…Go Blue!</p></blockquote></div></div></div><div class="ab cb ri rj rk rl" role="separator"><span class="rm by bm rn ro rp"/><span class="rm by bm rn ro rp"/><span class="rm by bm rn ro"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="b77a" class="nw nx fq bf ny nz rq gq ob oc rr gt oe of rs oh oi oj rt ol om on ru op oq or bk">References</h1><p id="775f" class="pw-post-body-paragraph mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne fj bk">Aschwanden, Christie. January 2016. <em class="nf">You Can’t Trust What You Read About Nutrition</em>. FiveThirtyEight. Retrieved January 24, 2024 from <a class="af ox" href="https://fivethirtyeight.com/features/you-cant-trust-what-you-read-about-nutrition/" rel="noopener ugc nofollow" target="_blank">https://fivethirtyeight.com/features/you-cant-trust-what-you-read-about-nutrition/</a></p><p id="349c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Business Management: From the Magazine. June 2015. <em class="nf">Beware Spurious Correlations</em>. Harvard Business Review. Retrieved January 24, 2024 from <a class="af ox" href="https://hbr.org/2015/06/beware-spurious-correlations" rel="noopener ugc nofollow" target="_blank">https://hbr.org/2015/06/beware-spurious-correlations</a></p><p id="c1a7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Extreme Weather Watch. 2017–2023. Retrieved January 24, 2024 from <a class="af ox" href="https://www.extremeweatherwatch.com/cities/new-york/year-2017" rel="noopener ugc nofollow" target="_blank">https://www.extremeweatherwatch.com/cities/new-york/year-2017</a></p><p id="e26d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Financial Content Services, Inc. <em class="nf">Apple Stock Price History | Historical AAPL Company Stock Prices | Financial Content Business Page</em>. Retrieved January 24, 2024 from</p><p id="017c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><a class="af ox" href="https://markets.financialcontent.com/stocks/quote/historical?Symbol=537%3A908440&amp;Year=2019&amp;Month=1&amp;Range=12" rel="noopener ugc nofollow" target="_blank">https://markets.financialcontent.com/stocks/quote/historical?Symbol=537%3A908440&amp;Year=2019&amp;Month=1&amp;Range=12</a></p><p id="91f4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Plotlygraphs.July 2016. <em class="nf">Spurious-Correlations</em>. Medium. Retrieved January 24, 2024 from <a class="af ox" href="https://plotlygraphs.medium.com/spurious-correlations-56752fcffb69" rel="noopener">https://plotlygraphs.medium.com/spurious-correlations-56752fcffb69</a></p><p id="f8da" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Vigen, Tyler. <em class="nf">Spurious Correlations</em>. Retrieved February 1, 2024 from <a class="af ox" href="https://www.tylervigen.com/spurious-correlations" rel="noopener ugc nofollow" target="_blank">https://www.tylervigen.com/spurious-correlations</a></p><p id="8bbe" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Mr. Vigen’s graphs were reprinted with permission from the author received on January 31, 2024.</p><p id="42ea" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Images were licensed from their respective owners.</p></div></div></div><div class="ab cb ri rj rk rl" role="separator"><span class="rm by bm rn ro rp"/><span class="rm by bm rn ro rp"/><span class="rm by bm rn ro"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="5e36" class="nw nx fq bf ny nz rq gq ob oc rr gt oe of rs oh oi oj rt ol om on ru op oq or bk">Code Section</h1><pre class="nj nk nl nm nn rv rw rx bp ry bb bk"><span id="6b34" class="rz nx fq rw b bg sa sb l sc sd">##########################<br/># IMPORT LIBRARIES SECTION<br/>##########################<br/># Import web scraping tool<br/>import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd<br/>import numpy as np<br/><br/># Import visualization appropriate libraries<br/>import plotly.graph_objects as go<br/>from plotly.subplots import make_subplots<br/>import seaborn as sns # New York temperature plotting<br/>import plotly.graph_objects as go # Apple stock charting<br/>from pandas.plotting import scatter_matrix # scatterplot matrix<br/><br/># Import appropriate libraries for New York temperature plotting<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from datetime import datetime, timedelta<br/>import re<br/><br/># Convert day to datetime library<br/>import calendar<br/><br/># Cross-correlation analysis library<br/>from statsmodels.tsa.stattools import ccf<br/><br/># Stats library<br/>import scipy.stats as stats<br/><br/># Granger causality library<br/>from statsmodels.tsa.stattools import grangercausalitytests</span></pre><pre class="se rv rw rx bp ry bb bk"><span id="be79" class="rz nx fq rw b bg sa sb l sc sd">##################################################################################<br/># EXAMINE THE NEW YORK CITY WEATHER AND APPLE STOCK DATA IN READYING FOR MERGE ...<br/>##################################################################################<br/><br/># Extract New York City weather data for the years 2017 to 2022 for all 12 months<br/># 5-YEAR NEW YORK CITY TEMPERATURE DATA<br/><br/># Function to convert 'Day' column to a consistent date format for merging<br/>def convert_nyc_date(day, month_name, year):<br/>    month_num = datetime.strptime(month_name, '%B').month<br/><br/>    # Extract numeric day using regular expression<br/>    day_match = re.search(r'\d+', day)<br/>    day_value = int(day_match.group()) if day_match else 1<br/><br/>    date_str = f"{month_num:02d}-{day_value:02d}-{year}"<br/><br/>    try:<br/>        return pd.to_datetime(date_str, format='%m-%d-%Y')<br/>    except ValueError:<br/>        return pd.to_datetime(date_str, errors='coerce')<br/><br/># Set variables<br/>years = range(2017, 2023)<br/>all_data = [] # Initialize an empty list to store data for all years<br/><br/># Enter for loop<br/>for year in years:<br/>    url = f'https://www.extremeweatherwatch.com/cities/new-york/year-{year}'<br/>    response = requests.get(url)<br/>    soup = BeautifulSoup(response.text, 'html.parser')<br/><br/>    div_container = soup.find('div', {'class': 'page city-year-page'})<br/><br/>    if div_container:<br/>        select_month = div_container.find('select', {'class': 'form-control url-selector'})<br/><br/>        if select_month:<br/>            monthly_data = []<br/>            for option in select_month.find_all('option'):<br/>                month_name = option.text.strip().lower()<br/><br/>                h5_tag = soup.find('a', {'name': option['value'][1:]}).find_next('h5', {'class': 'mt-4'})<br/><br/>                if h5_tag:<br/>                    responsive_div = h5_tag.find_next('div', {'class': 'responsive'})<br/>                    table = responsive_div.find('table', {'class': 'bordered-table daily-table'})<br/><br/>                    if table:<br/>                        data = []<br/>                        for row in table.find_all('tr')[1:]:<br/>                            cols = row.find_all('td')<br/>                            day = cols[0].text.strip()<br/>                            high_temp = float(cols[1].text.strip())<br/>                            data.append([convert_nyc_date(day, month_name, year), high_temp])<br/><br/>                        monthly_df = pd.DataFrame(data, columns=['Date', 'High (°F)'])<br/>                        monthly_data.append(monthly_df)<br/>                    else:<br/>                        print(f"Table not found for {month_name.capitalize()} {year}")<br/>                else:<br/>                    print(f"h5 tag not found for {month_name.capitalize()} {year}")<br/><br/>            # Concatenate monthly data to form the complete dataframe for the year<br/>            yearly_nyc_df = pd.concat(monthly_data, ignore_index=True)<br/>           <br/>            # Extract month name from the 'Date' column<br/>            yearly_nyc_df['Month'] = yearly_nyc_df['Date'].dt.strftime('%B')<br/><br/>            # Capitalize the month names<br/>            yearly_nyc_df['Month'] = yearly_nyc_df['Month'].str.capitalize()<br/><br/>            all_data.append(yearly_nyc_df)<br/><br/>            <br/>######################################################################################################<br/># Generate a time series plot of the 5-year New York City daily high temperatures<br/>######################################################################################################<br/><br/># Concatenate the data for all years<br/>if all_data:<br/>    combined_df = pd.concat(all_data, ignore_index=True)<br/><br/>    # Create a line plot for each year<br/>    plt.figure(figsize=(12, 6))<br/>    sns.lineplot(data=combined_df, x='Date', y='High (°F)', hue=combined_df['Date'].dt.year)<br/>    plt.title('New York City Daily High Temperature Time Series (2017-2022) - 5-Year Trend', fontsize=18)<br/>    plt.xlabel('Date', fontsize=16)  # Set x-axis label<br/>    plt.ylabel('High Temperature (°F)', fontsize=16)  # Set y-axis label<br/>    plt.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=14)  # Display legend outside the plot<br/>    plt.tick_params(axis='both', which='major', labelsize=14)  # Set font size for both axes' ticks<br/>    plt.show()</span></pre><pre class="se rv rw rx bp ry bb bk"><span id="d785" class="rz nx fq rw b bg sa sb l sc sd"># APPLE STOCK CODE<br/><br/># Set variables<br/>years = range(2017, 2023)<br/>data = []  # Initialize an empty list to store data for all years<br/><br/># Extract Apple's historical data for the years 2017 to 2022<br/>for year in years:<br/>    url = f'https://markets.financialcontent.com/stocks/quote/historical?Symbol=537%3A908440&amp;Year={year}&amp;Month=12&amp;Range=12'<br/>    response = requests.get(url)<br/>    soup = BeautifulSoup(response.text, 'html.parser')<br/>    table = soup.find('table', {'class': 'quote_detailed_price_table'})<br/><br/>    if table:<br/>        for row in table.find_all('tr')[1:]:<br/>            cols = row.find_all('td')<br/>            date = cols[0].text<br/><br/>            # Check if the year is within the desired range<br/>            if str(year) in date:<br/>                open_price = cols[1].text<br/>                high = cols[2].text<br/>                low = cols[3].text<br/>                close = cols[4].text<br/>                volume = cols[5].text<br/>                change_percent = cols[6].text<br/>                data.append([date, open_price, high, low, close, volume, change_percent])<br/><br/># Create a DataFrame from the extracted data<br/>apple_df = pd.DataFrame(data, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Change(%)'])<br/><br/># Verify that DataFrame contains 5-years<br/># apple_df.head(50)<br/><br/>#################################################################<br/># Generate a Candlestick charting of the 5-year stock performance<br/>#################################################################<br/><br/>new_apple_df = apple_df.copy()<br/><br/># Convert Apple 'Date' column to a consistent date format<br/>new_apple_df['Date'] = pd.to_datetime(new_apple_df['Date'], format='%b %d, %Y')<br/><br/># Sort the datasets by 'Date' in ascending order<br/>new_apple_df = new_apple_df.sort_values('Date')<br/><br/># Convert numerical columns to float, handling empty strings<br/>numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change(%)']<br/>for col in numeric_cols:<br/>    new_apple_df[col] = pd.to_numeric(new_apple_df[col], errors='coerce')<br/><br/># Create a candlestick chart<br/>fig = go.Figure(data=[go.Candlestick(x=new_apple_df['Date'],<br/>                open=new_apple_df['Open'],<br/>                high=new_apple_df['High'],<br/>                low=new_apple_df['Low'],<br/>                close=new_apple_df['Close'])])<br/><br/># Set the layout<br/>fig.update_layout(title='Apple Stock Candlestick Chart',<br/>                  xaxis_title='Date',<br/>                  yaxis_title='Stock Price',<br/>                  xaxis_rangeslider_visible=False,<br/>                  font=dict(<br/>                      family="Arial",<br/>                      size=16,<br/>                      color="Black"<br/>                  ),<br/>                  title_font=dict(<br/>                      family="Arial",<br/>                      size=20,<br/>                      color="Black"<br/>                  ),<br/>                  xaxis=dict(<br/>                      title=dict(<br/>                          text="Date",<br/>                          font=dict(<br/>                              family="Arial",<br/>                              size=18,<br/>                              color="Black"<br/>                          )<br/>                      ),<br/>                      tickfont=dict(<br/>                          family="Arial",<br/>                          size=16,<br/>                          color="Black"<br/>                      )<br/>                  ),<br/>                  yaxis=dict(<br/>                      title=dict(<br/>                          text="Stock Price",<br/>                          font=dict(<br/>                              family="Arial",<br/>                              size=18,<br/>                              color="Black"<br/>                          )<br/>                      ),<br/>                      tickfont=dict(<br/>                          family="Arial",<br/>                          size=16,<br/>                          color="Black"<br/>                      )<br/>                  )<br/>)<br/><br/># Show the chart<br/>fig.show()</span></pre><pre class="se rv rw rx bp ry bb bk"><span id="30bd" class="rz nx fq rw b bg sa sb l sc sd">##########################################<br/># MERGE THE NEW_NYC_DF WITH NEW_APPLE_DF<br/>##########################################<br/># Convert the 'Day' column in New York City combined_df to a consistent date format ...<br/><br/>new_nyc_df = combined_df.copy()<br/><br/># Add missing weekends to NYC temperature data<br/>start_date = new_nyc_df['Date'].min()<br/>end_date = new_nyc_df['Date'].max()<br/>weekend_dates = pd.date_range(start_date, end_date, freq='B')  # B: business day frequency (excludes weekends)<br/>missing_weekends = weekend_dates[~weekend_dates.isin(new_nyc_df['Date'])]<br/>missing_data = pd.DataFrame({'Date': missing_weekends, 'High (°F)': None})<br/>new_nyc_df = pd.concat([new_nyc_df, missing_data]).sort_values('Date').reset_index(drop=True)  # Resetting index<br/>new_apple_df = apple_df.copy()<br/><br/># Convert Apple 'Date' column to a consistent date format<br/>new_apple_df['Date'] = pd.to_datetime(new_apple_df['Date'], format='%b %d, %Y')<br/><br/># Sort the datasets by 'Date' in ascending order<br/>new_nyc_df = combined_df.sort_values('Date')<br/>new_apple_df = new_apple_df.sort_values('Date')<br/><br/># Merge the datasets on the 'Date' column<br/>merged_df = pd.merge(new_apple_df, new_nyc_df, on='Date', how='inner')<br/><br/># Verify the correct merge -- should merge only NYC temp records that match with Apple stock records by Date<br/>merged_df</span></pre><pre class="se rv rw rx bp ry bb bk"><span id="e2ca" class="rz nx fq rw b bg sa sb l sc sd"># Ensure the columns of interest are numeric <br/>merged_df['High (°F)'] = pd.to_numeric(merged_df['High (°F)'], errors='coerce')<br/>merged_df['Close'] = pd.to_numeric(merged_df['Close'], errors='coerce')<br/><br/># UPDATED CODE BY PAUL USES ASTRONOMICAL TEMPERATURES <br/><br/># CORRELATION HEATMAP OF YEAR-OVER-YEAR <br/># DAILY HIGH NYC TEMPERATURES VS.<br/># APPLE STOCK 2017-2023<br/><br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/><br/># Convert 'Date' to datetime<br/>merged_df['Date'] = pd.to_datetime(merged_df['Date'])<br/><br/># Define a function to map months to seasons<br/>def map_season(month):<br/>    if month in [4, 5, 6]:<br/>        return 'Spring'<br/>    elif month in [7, 8, 9]:<br/>        return 'Summer'<br/>    elif month in [10, 11, 12]:<br/>        return 'Fall'<br/>    else:<br/>        return 'Winter'<br/><br/># Extract month from the Date column and map it to seasons<br/>merged_df['Season'] = merged_df['Date'].dt.month.map(map_season)<br/><br/># Extract the years present in the data<br/>years = merged_df['Date'].dt.year.unique()<br/><br/># Create subplots for each combination of year and season<br/>seasons = ['Spring', 'Summer', 'Fall', 'Winter']<br/><br/># Convert 'Close' column to numeric<br/>merged_df['Close'] = pd.to_numeric(merged_df['Close'], errors='coerce')<br/><br/># Create an empty DataFrame to store correlation matrix<br/>corr_matrix = pd.DataFrame(index=years, columns=seasons)<br/><br/># Calculate correlation matrix for each combination of year and season<br/>for year in years:<br/>    year_data = merged_df[merged_df['Date'].dt.year == year]<br/>    for season in seasons:<br/>        data = year_data[year_data['Season'] == season]<br/>        corr = data['High (°F)'].corr(data['Close'])<br/>        corr_matrix.loc[year, season] = corr<br/><br/># Plot correlation matrix<br/>plt.figure(figsize=(10, 6))<br/>sns.heatmap(corr_matrix.astype(float), annot=True, cmap='coolwarm', fmt=".2f")<br/>plt.title('Temperature-Stock Correlation', fontsize=18)  # Set main title font size<br/>plt.xlabel('Season', fontsize=16)  # Set x-axis label font size<br/>plt.ylabel('Year', fontsize=16)  # Set y-axis label font size<br/>plt.tick_params(axis='both', which='major', labelsize=14)  # Set annotation font size<br/>plt.tight_layout()<br/>plt.show()</span></pre><pre class="se rv rw rx bp ry bb bk"><span id="d1b1" class="rz nx fq rw b bg sa sb l sc sd">#######################<br/># STAT ANALYSIS SECTION<br/>#######################<br/>#############################################################<br/># GRANGER CAUSALITY TEST<br/># test whether past values of temperature (or stock prices) <br/># can predict future values of stock prices (or temperature).<br/># perform the Granger causality test between 'High (°F)' and <br/># 'Close' columns in merged_df up to a maximum lag of 255<br/>#############################################################<br/><br/># Perform Granger causality test<br/>max_lag = 1  # Choose the maximum lag of 100 - Jupyter times out at higher lags<br/>test_results = grangercausalitytests(merged_df[['High (°F)', 'Close']], max_lag)<br/><br/># Interpretation:<br/><br/># looks like none of the lag give a significant p-value<br/># at alpha .05, we cannot reject the null hypothesis, that is,<br/># we cannot conclude that Granger causality exists between daily high<br/># temperatures in NYC and Apple stock<br/><br/>#################################################################<br/># CROSS-CORRELATION ANALYSIS<br/># calculate the cross-correlation between 'High (°F)' and 'Close' <br/># columns in merged_df, and ccf_values will contain the <br/># cross-correlation coefficients, while lag_values will <br/># contain the corresponding lag values<br/>#################################################################<br/><br/># Calculate cross-correlation<br/>ccf_values = ccf(merged_df['High (°F)'], merged_df['Close'])<br/>lag_values = np.arange(-len(merged_df)+1, len(merged_df))<br/><br/>ccf_values, lag_values<br/><br/># Interpretation:<br/># Looks like there is strong positive correlation in the variables<br/># in latter years and positive correlation in their respective<br/># lags. This confirms what our plotting shows us<br/><br/>########################################################<br/># LOOK AT THE BEST CORRELATION COEFFICIENT - 2020? LET'S<br/># EXPLORE FURTHER AND CALCULATE THE p-VALUE AND<br/># CONFIDENCE INTERVAL<br/>########################################################<br/><br/># Get dataframes for specific periods of spurious correlation<br/><br/>merged_df['year'] = merged_df['Date'].dt.year<br/>best_season_data = merged_df.loc[(merged_df['year'] == 2020) &amp; (merged_df['Season'] == 'Spring')]<br/><br/># Calculate correlation coefficient and p-value<br/>corr_coeff, p_value = stats.pearsonr(best_season_data['High (°F)'], best_season_data['Close'])<br/>corr_coeff, p_value<br/><br/># Perform bootstrapping to obtain confidence interval<br/>def bootstrap_corr(data, n_bootstrap=1000):<br/>    corr_values = []<br/>    for _ in range(n_bootstrap):<br/>        sample = data.sample(n=len(data), replace=True)<br/>        corr_coeff, _ = stats.pearsonr(sample['High (°F)'], sample['Close'])<br/>        corr_values.append(corr_coeff)<br/>    return np.percentile(corr_values, [2.5, 97.5])  # 95% confidence interval<br/><br/>confidence_interval = bootstrap_corr(best_season_data)<br/>confidence_interval</span></pre><pre class="se rv rw rx bp ry bb bk"><span id="a5a2" class="rz nx fq rw b bg sa sb l sc sd">#####################################################################<br/># VISUALIZE RELATIONSHIP BETWEEN APPLE STOCK AND NYC DAILY HIGH TEMPS<br/>#####################################################################<br/><br/># Dual y-axis plotting using twinx() function from matplotlib<br/>date = merged_df['Date']<br/>temperature = merged_df['High (°F)']<br/>stock_close = merged_df['Close']<br/><br/># Create a figure and axis<br/>fig, ax1 = plt.subplots(figsize=(10, 6))<br/><br/># Plotting temperature on the left y-axis (ax1)<br/>color = 'tab:red'<br/>ax1.set_xlabel('Date', fontsize=16)<br/>ax1.set_ylabel('Temperature (°F)', color=color, fontsize=16)<br/>ax1.plot(date, temperature, color=color)<br/>ax1.tick_params(axis='y', labelcolor=color)<br/><br/># Create a secondary y-axis for the stock close prices<br/>ax2 = ax1.twinx()<br/>color = 'tab:blue'<br/>ax2.set_ylabel('Stock Close Price', color=color, fontsize=16)<br/>ax2.plot(date, stock_close, color=color)<br/>ax2.tick_params(axis='y', labelcolor=color)<br/><br/># Title and show the plot<br/>plt.title('Apple Stock correlates with New York City Temperature', fontsize=18)<br/>plt.show()</span></pre></div></div></div></div>    
</body>
</html>