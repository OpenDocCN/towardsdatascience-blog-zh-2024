<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Productionizing a RAG App with Prefect, Weave, and RAGAS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Productionizing a RAG App with Prefect, Weave, and RAGAS</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/productionizing-a-rag-app-04c857e0966e?source=collection_archive---------7-----------------------#2024-08-03">https://towardsdatascience.com/productionizing-a-rag-app-04c857e0966e?source=collection_archive---------7-----------------------#2024-08-03</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="0591" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Adding evaluation, automated data pulling, and other improvements.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@ed.izaguirre?source=post_page---byline--04c857e0966e--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ed Izaguirre" class="l ep by dd de cx" src="../Images/c9eded1f06c47571baa662107428483f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*X9RggnIeuLK8p0PvTB4jNw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--04c857e0966e--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@ed.izaguirre?source=post_page---byline--04c857e0966e--------------------------------" rel="noopener follow">Ed Izaguirre</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--04c857e0966e--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 3, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/105f6f4816994872796a36639b99148d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KO_UZKZEyuDTK2b91x9YuQ.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">From Film Search to Rosebud 🌹. Image from Unsplash.</figcaption></figure><p id="20e1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Table of Contents</strong></p><ol class=""><li id="110c" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><a class="af ob" href="#d4f8" rel="noopener ugc nofollow">Introduction</a></li><li id="7cca" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx ny nz oa bk"><a class="af ob" href="#fdde" rel="noopener ugc nofollow">Offline Evaluation</a></li><li id="3a3a" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx ny nz oa bk"><a class="af ob" href="#9988" rel="noopener ugc nofollow">Online Evaluation</a></li><li id="bf0c" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx ny nz oa bk"><a class="af ob" href="#690c" rel="noopener ugc nofollow">Automated Data Pulling with Prefect</a></li><li id="7f7e" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx ny nz oa bk"><a class="af ob" href="#0875" rel="noopener ugc nofollow">Summary</a></li></ol><p id="5105" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Relevant Links</strong></p><ul class=""><li id="c675" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk"><a class="af ob" href="https://github.com/EdIzaguirre/Rosebud" rel="noopener ugc nofollow" target="_blank">GitHub repo</a></li><li id="307d" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><a class="af ob" href="https://medium.com/towards-data-science/how-to-build-a-rag-system-with-a-self-querying-retriever-in-langchain-16b4fa23e9ad" rel="noopener">Link to earlier article discussing Film Search, a dev version of this project</a></li><li id="a00d" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><a class="af ob" href="https://filmsearch.azurewebsites.net/" rel="noopener ugc nofollow" target="_blank">Try out the app</a> (now 100% free! 🤑)</li></ul><h1 id="d4f8" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Introduction</h1><p id="f832" class="pw-post-body-paragraph nc nd fq ne b go pe ng nh gr pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">A few months ago, I released the <em class="pj">Film Search</em> app, a Retrieval-Augmented Generation (RAG) application designed to recommend films based on user queries. For example, a user may ask: <em class="pj">“Find me drama movies in English that are less than 2 hours long and feature dogs.” </em>and receive a recommendation like:</p><blockquote class="pk pl pm"><p id="b636" class="nc nd pj ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Title of Film: Hachi: A Dog’s Tale</p><p id="8c06" class="nc nd pj ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Runtime: 93 minutes<br/>Release Year: 2009<br/>Streaming: Not available for streaming<br/>This film tells the poignant true story of Hachiko, an Akita dog known for his remarkable loyalty to his owner. The emotional depth and the themes of friendship and loyalty resonate strongly, making it a touching drama that showcases the profound bond between humans and dogs. It’s perfect for anyone looking for a heartfelt story that highlights the importance of companionship.</p><p id="b2b5" class="nc nd pj ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">…</p></blockquote><p id="0608" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This was not just a simple RAG app, however. It included what is known as <strong class="ne fr">self-querying retrieval</strong>. This means that the bot takes the user’s query and transforms it by adding metadata filters. This ensures any documents pulled into the chat model’s context respects the constraints set by the user’s query. For more information, I recommend checking out my earlier article linked above.</p><p id="ec8b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Unfortunately, there were some issues with the app:</p><ul class=""><li id="a6e9" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk">There was no offline evaluation done, besides passing the ‘eye test’. This test is necessary, but not sufficient.</li><li id="fb29" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Observability was non-existent. If a query went poorly, you had to manually pull up the project and run some ad-hoc scripts in an attempt to see what went wrong.</li><li id="7459" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">The Pinecone vector database had to be pulled manually. This meant the documents would quickly be out of date if, say, a film got pulled from a streaming service.</li></ul><p id="64bd" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this article, I will briefly cover some of the improvements made to the Film Search app. This will cover:</p><ul class=""><li id="7676" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk"><strong class="ne fr">Offline Evaluation using RAGAS and Weave</strong></li><li id="0fa5" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><strong class="ne fr">Online Evaluation and Observability</strong></li><li id="d9ea" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><strong class="ne fr">Automated Data Pulling using Prefect</strong></li></ul><p id="416a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">One thing before we jump in: I found the name <em class="pj">Film Search</em> to be a bit generic, so I rebranded the app as <em class="pj">Rosebud </em>🌹<em class="pj">, </em>hence the image shown above. Real film geeks will <a class="af ob" href="https://www.youtube.com/watch?v=O4mQqVqRB7I" rel="noopener ugc nofollow" target="_blank">understand the reference</a>.</p><h1 id="fdde" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Offline Evaluation</h1><p id="b66a" class="pw-post-body-paragraph nc nd fq ne b go pe ng nh gr pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">It is important to be able to judge if a change made to your LLM application improves or degrades its performance. Unfortunately, evaluation of LLM apps is a difficult and novel space. There is simply not much agreement on what constitutes a good evaluation.</p><p id="ac16" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For Rosebud<em class="pj"> </em>🌹, I decided to tackle what is known as the <a class="af ob" href="https://www.trulens.org/trulens_eval/getting_started/core_concepts/rag_triad/" rel="noopener ugc nofollow" target="_blank">RAG triad</a>. This approach is promoted by TruLens, a platform to evaluate and track LLM applications.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pn"><img src="../Images/d536e3e20215d54bdf6e350f4f06a994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TG76IaJwb2Uor_Qw_sbZig.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">The RAG Triad. Image by author.</figcaption></figure><p id="f63f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The triad covers three aspects of a RAG app:</p><ul class=""><li id="c571" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk"><strong class="ne fr">Context Relevancy</strong>: When a query is made by the user, documents fill the context of the chat model. Is the retrieved context actually useful? If not, you may need to tweak things like document embedding, chunking, or metadata filtering.</li><li id="f983" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><strong class="ne fr">Faithfulness: </strong>Is the model’s response actually grounded in the retrieved documents? You don’t want the model making up facts; the whole point of RAG is to help reduce hallucinations by using retrieved documents.</li><li id="38ca" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><strong class="ne fr">Answer Relevancy: </strong>Does the model’s response actually answer the user’s query? If the user asks for “<em class="pj">Comedy films made in the 1990s?</em>”, the model’s answer better contain only comedy films made in the 1990s.</li></ul><p id="c0dc" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There are a few ways to attempt to assess these three functions of a RAG app. One way would be to use human expert evaluators. Unfortunately, this would be expensive and wouldn’t scale. For Rosebud<em class="pj"> </em>🌹 I decided to use <strong class="ne fr">LLMs-as-a-judges</strong>. This means using a chat model to look at each of the three criteria above and assigning a score of 0 to 1 for each. This method has the advantage of being cheap and scaling well. To accomplish this, I used <a class="af ob" href="https://github.com/explodinggradients/ragas" rel="noopener ugc nofollow" target="_blank">RAGAS</a>, a popular framework that helps you evaluate your RAG applications. The RAGAS framework includes the three metrics mentioned above and makes it fairly easy to use them to evaluate your apps. Below is a code snippet demonstrating how I conducted this offline evaluation:</p><pre class="mm mn mo mp mq po pp pq bp pr bb bk"><span id="28ca" class="ps oj fq pp b bg pt pu l pv pw">from ragas import evaluate<br/>from ragas.metrics import AnswerRelevancy, ContextRelevancy, Faithfulness<br/>import weave<br/><br/>@weave.op()<br/>def evaluate_with_ragas(query, model_output):<br/>    # Put data into a Dataset object<br/>    data = {<br/>        "question": [query],<br/>        "contexts": [[model_output['context']]],<br/>        "answer": [model_output['answer']]<br/>    }<br/>    dataset = Dataset.from_dict(data)<br/><br/>    # Define metrics to judge<br/>    metrics = [<br/>        AnswerRelevancy(),<br/>        ContextRelevancy(),<br/>        Faithfulness(),<br/>    ]<br/><br/>    judge_model = ChatOpenAI(model=config['JUDGE_MODEL_NAME'])<br/>    embeddings_model = OpenAIEmbeddings(model=config['EMBEDDING_MODEL_NAME'])<br/><br/>    evaluation = evaluate(dataset=dataset, metrics=metrics, llm=judge_model, embeddings=embeddings_model)<br/><br/>    return {<br/>        "answer_relevancy": float(evaluation['answer_relevancy']),<br/>        "context_relevancy": float(evaluation['context_relevancy']),<br/>        "faithfulness": float(evaluation['faithfulness']),<br/>    }<br/><br/><br/>def run_evaluation():<br/>    # Initialize chat model<br/>    model = rosebud_chat_model()<br/><br/>    # Define evaluation questions<br/>    questions = [<br/>        {"query": "Suggest a good movie based on a book."},  # Adaptations<br/>        {"query": "Suggest a film for a cozy night in."},  # Mood-Based<br/>        {"query": "What are some must-watch horror movies?"},  # Genre-Specific<br/>        ...<br/>        # Total of 20 questions<br/>    ]<br/><br/>    # Create Weave Evaluation object<br/>    evaluation = weave.Evaluation(dataset=questions, scorers=[evaluate_with_ragas])<br/><br/>    # Run the evaluation<br/>    asyncio.run(evaluation.evaluate(model))<br/><br/><br/>if __name__ == "__main__":<br/>    weave.init('film-search')<br/>    run_evaluation()</span></pre><p id="035f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A few notes:</p><ul class=""><li id="60a9" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk">With twenty questions and three criteria to judge across, you’re looking at sixty LLM calls for a single evaluation! It gets even worse though; with the <code class="cx px py pz pp b">rosebud_chat_model</code> , there are two calls for every query: one to construct the metadata filter and another to provide the answer, so really this is 120 calls for a single eval! All models used in this evaluation are the new<code class="cx px py pz pp b"> gpt-4o-mini</code>, which I strongly recommend. In my experience the calls cost $0.05 per evaluation.</li><li id="75d4" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Note that we are using <code class="cx px py pz pp b">asyncio.run</code> to run the evals. It is ideal to use asynchronous calls because you don’t want to evaluate each question sequentially one after the other. Instead, with <code class="cx px py pz pp b">asyncio</code> we can begin evaluating other questions as we wait for previous I/O operations to finish.</li><li id="485c" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">There are a total of twenty questions for a single evaluation. These span a variety of typical film queries a user may ask. I mostly came up with these myself, but in practice it would be better to use queries actually asked by users in production.</li><li id="f449" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Notice the <code class="cx px py pz pp b">weave.init</code> and the <code class="cx px py pz pp b">@weave.op</code> decorator that are being used. These are part of the new <a class="af ob" href="https://wandb.ai/site/weave/" rel="noopener ugc nofollow" target="_blank">Weave library</a> from Weights &amp; Biases (W&amp;B). Weave is a complement to the traditional W&amp;B library, with a focus on LLM applications. It allows you to capture inputs and outputs of LLMs by using a the simple <code class="cx px py pz pp b">@weave.op</code> decorator. It also allows you to capture the results of evaluations using <code class="cx px py pz pp b">weave.Evaluation(…)</code> . By integrating RAGAS to perform evaluations and Weave to capture and log them, we get a powerful duo that helps GenAI developers iteratively improve their applications. You also get to log the model latency, cost, and more.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qa"><img src="../Images/ec7f61849ae276bbcc97508920e22e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GNxJaYxraPtN3PYl7JcLJw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of Weave + RAGAS integration. Image by author.</figcaption></figure><p id="9f3c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In theory, one can now tweak a hyperparameter (e.g. temperature), re-run the evaluation, and see if the adjustment has a positive or negative impact. Unfortunately, in practice I found the LLM judging to be finicky, and I am <a class="af ob" href="https://x.com/aparnadhinak/status/1748368364395721128" rel="noopener ugc nofollow" target="_blank">not the only one</a>. LLM judges seem to be fairly bad at using a floating point value to assess these metrics. Instead, it appears they seem to do better at classification e.g. a thumbs up/thumbs down. RAGAS doesn’t yet support LLM judges performing classification. Writing it by hand doesn’t seem too difficult, and perhaps in a future update I may attempt this myself.</p><h1 id="9988" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk"><strong class="al">Online Evaluation</strong></h1><p id="b265" class="pw-post-body-paragraph nc nd fq ne b go pe ng nh gr pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Offline evaluation is good for seeing how tweaking hyperparameters affects performance, but in my opinion online evaluation is far more useful. In Rosebud<em class="pj"> </em>🌹 I have now incorporated the use of 👍/👎 buttons at the bottom of every response to provide feedback.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qb"><img src="../Images/c9351c7a2914be0e13e6295426c304fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xfLH6Q0spdYLdJZz6Z6j5w.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of online feedback. Image by author.</figcaption></figure><p id="9129" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">When a user clicks on either button they are told that their feedback was logged. Below is a snippet of how this was accomplished in the Streamlit interface:</p><pre class="mm mn mo mp mq po pp pq bp pr bb bk"><span id="7729" class="ps oj fq pp b bg pt pu l pv pw">def start_log_feedback(feedback):<br/>    print("Logging feedback.")<br/>    st.session_state.feedback_given = True<br/>    st.session_state.sentiment = feedback<br/>    thread = threading.Thread(target=log_feedback, args=(st.session_state.sentiment,<br/>                                                         st.session_state.query,<br/>                                                         st.session_state.query_constructor,<br/>                                                         st.session_state.context,<br/>                                                         st.session_state.response))<br/>    thread.start()<br/><br/><br/>def log_feedback(sentiment, query, query_constructor, context, response):<br/>    ct = datetime.datetime.now()<br/>    wandb.init(project="film-search",<br/>               name=f"query: {ct}")<br/>    table = wandb.Table(columns=["sentiment", "query", "query_constructor", "context", "response"])<br/>    table.add_data(sentiment,<br/>                   query,<br/>                   query_constructor,<br/>                   context,<br/>                   response<br/>                   )<br/>    wandb.log({"Query Log": table})<br/>    wandb.finish()</span></pre><p id="51ed" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Note that the process of sending the feedback to W&amp;B runs on a separate thread rather than on the main thread. This is to prevent the user from getting stuck for a few seconds waiting for the logging to complete.</p><p id="17e9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A W&amp;B table is used to store the feedback. Five quantities are logged in the table:</p><ul class=""><li id="cdd8" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk"><strong class="ne fr">Sentiment:</strong> Whether the user clicked thumbs up or thumbs down</li><li id="43ce" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><strong class="ne fr">Query:</strong> The user’s query, e.g. <em class="pj">Find me drama movies in English that are less than 2 hours long and feature dogs.</em></li><li id="082c" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><strong class="ne fr">Query_Constructor:</strong> The results of the query constructor, which rewrites the user’s query and includes metadata filtering if necessary, e.g.</li></ul><pre class="mm mn mo mp mq po pp pq bp pr bb bk"><span id="649c" class="ps oj fq pp b bg pt pu l pv pw">{<br/>    "query": "drama English dogs", <br/>    "filter": {<br/>        "operator": "and", <br/>        "arguments": [<br/>            {<br/>                "comparator": "eq", "attribute": "Genre", "value": "Drama"<br/>            }, <br/>            {<br/>                "comparator": "eq", "attribute": "Language", "value": "English"<br/>            }, <br/>                <br/>            {<br/>                "comparator": "lt", "attribute": "Runtime (minutes)", "value": 120<br/>            }<br/>        ]<br/>    },<br/>}</span></pre><ul class=""><li id="b940" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk"><strong class="ne fr">Context: </strong>The retrieved context based on the reconstructed query, e.g. <em class="pj">Title: Hachi: A Dog’s Tale. Overview: A drama based on the true story of a college professor’s…</em></li><li id="1021" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk"><strong class="ne fr">Response: </strong>The model’s response</li></ul><p id="fd39" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">All of this is logged conveniently in the same project as the Weave evaluations shown earlier. Now, when a query goes south it is as simple as hitting the thumbs down button to see exactly what happened. This will allow much faster iteration and improvement of the Rosebud<em class="pj"> </em>🌹 recommendation application.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qc"><img src="../Images/f1ec5605b853d379a932d40b1012a4c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-sLFVd5JtXZle1lhmjpR2Q.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image showing observability of the model’s response. Note on the left-hand side how it is seamless to transition between W&amp;B and Weave. Image by author.</figcaption></figure><h1 id="690c" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk"><strong class="al">Automated Data Pulling using Prefect</strong></h1><p id="e566" class="pw-post-body-paragraph nc nd fq ne b go pe ng nh gr pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">To ensure recommendations from Rosebud<em class="pj"> </em>🌹 continue to stay accurate it was important to automate the process of pulling data and uploading them to Pinecone. For this task, I chose <a class="af ob" href="https://www.prefect.io/" rel="noopener ugc nofollow" target="_blank">Prefect</a>. Prefect is a popular workflow orchestration tool. I was looking for something lightweight, easy to learn, and Pythonic. I found all of this in Prefect.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qd"><img src="../Images/74bf21e667d7580aa0f0a410a2ac3d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ng2TQ3W-4q6OSojIJdPw9Q.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Automated flow for pulling and updating Pinecone vector store provided by Prefect. Image by author.</figcaption></figure><p id="1724" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Prefect offers a variety of ways to schedule your workflows. I decided to use the <a class="af ob" href="https://docs.prefect.io/latest/tutorial/work-pools/#push-work-pools-with-automatic-infrastructure-provisioning" rel="noopener ugc nofollow" target="_blank">push work pools with automatic infrastructure provisioning</a>. I found that this setup balances simplicity with configurability. It allows the user to task Prefect with automatically provisioning all of the infrastructure needed to run your flow in your cloud provider of choice. I chose to deploy on Azure, but deploying on GCP or AWS only requires changing a few lines of code. Refer to the <code class="cx px py pz pp b">pinecone_flow.py</code> file for more details. A simplified flow is provided below:</p><pre class="mm mn mo mp mq po pp pq bp pr bb bk"><span id="9cc5" class="ps oj fq pp b bg pt pu l pv pw">@task<br/>def start():<br/>    """<br/>    Start-up: check everything works or fail fast!<br/>    """<br/><br/>    # Print out some debug info<br/>    print("Starting flow!")<br/><br/>    # Ensure user has set the appropriate env variables<br/>    assert os.environ['LANGCHAIN_API_KEY']<br/>    assert os.environ['OPENAI_API_KEY']<br/>    ...<br/><br/><br/>@task(retries=3, retry_delay_seconds=[1, 10, 100])<br/>def pull_data_to_csv(config):<br/>    TMBD_API_KEY = os.getenv('TMBD_API_KEY')<br/>    YEARS = range(config["years"][0], config["years"][-1] + 1)<br/>    CSV_HEADER = ['Title', 'Runtime (minutes)', 'Language', 'Overview', ...]<br/><br/>    for year in YEARS:<br/>        # Grab list of ids for all films made in {YEAR}<br/>        movie_list = list(set(get_id_list(TMBD_API_KEY, year)))<br/><br/>        FILE_NAME = f'./data/{year}_movie_collection_data.csv'<br/><br/>        # Creating file<br/>        with open(FILE_NAME, 'w') as f:<br/>            writer = csv.writer(f)<br/>            writer.writerow(CSV_HEADER)<br/><br/>        ...<br/><br/>    print("Successfully pulled data from TMDB and created csv files in data/")<br/><br/><br/>@task<br/>def convert_csv_to_docs():<br/>    # Loading in data from all csv files<br/>    loader = DirectoryLoader(<br/>        ...<br/>        show_progress=True)<br/><br/>    docs = loader.load()<br/><br/>    metadata_field_info = [<br/>        AttributeInfo(name="Title",<br/>                      description="The title of the movie", type="string"),<br/>        AttributeInfo(name="Runtime (minutes)",<br/>                      description="The runtime of the movie in minutes", type="integer"),<br/>        ...<br/>    ]<br/><br/>    def convert_to_list(doc, field):<br/>        if field in doc.metadata and doc.metadata[field] is not None:<br/>            doc.metadata[field] = [item.strip()<br/>                                   for item in doc.metadata[field].split(',')]<br/><br/>    ...<br/><br/>    fields_to_convert_list = ['Genre', 'Actors', 'Directors',<br/>                              'Production Companies', 'Stream', 'Buy', 'Rent']<br/>    ...<br/><br/>    # Set 'overview' and 'keywords' as 'page_content' and other fields as 'metadata'<br/>    for doc in docs:<br/>        # Parse the page_content string into a dictionary<br/>        page_content_dict = dict(line.split(": ", 1)<br/>                                 for line in doc.page_content.split("\n") if ": " in line)<br/><br/>        doc.page_content = (<br/>            'Title: ' + page_content_dict.get('Title') +<br/>            '. Overview: ' + page_content_dict.get('Overview') +<br/>            ...<br/>        )<br/><br/>        ...<br/><br/>    print("Successfully took csv files and created docs")<br/><br/>    return docs<br/><br/><br/>@task<br/>def upload_docs_to_pinecone(docs, config):<br/>    # Create empty index<br/>    PINECONE_KEY, PINECONE_INDEX_NAME = os.getenv(<br/>        'PINECONE_API_KEY'), os.getenv('PINECONE_INDEX_NAME')<br/><br/>    pc = Pinecone(api_key=PINECONE_KEY)<br/><br/>    # Target index and check status<br/>    pc_index = pc.Index(PINECONE_INDEX_NAME)<br/>    print(pc_index.describe_index_stats())<br/><br/>    embeddings = OpenAIEmbeddings(model=config['EMBEDDING_MODEL_NAME'])<br/>    namespace = "film_search_prod"<br/><br/>    PineconeVectorStore.from_documents(<br/>        docs,<br/>        ...<br/>    )<br/><br/>    print("Successfully uploaded docs to Pinecone vector store")<br/><br/><br/>@task<br/>def publish_dataset_to_weave(docs):<br/>    # Initialize Weave<br/>    weave.init('film-search')<br/><br/>    rows = []<br/>    for doc in docs:<br/>        row = {<br/>            'Title': doc.metadata.get('Title'),<br/>            'Runtime (minutes)': doc.metadata.get('Runtime (minutes)'),<br/>             ...<br/>        }<br/>        rows.append(row)<br/><br/>    dataset = Dataset(name='Movie Collection', rows=rows)<br/>    weave.publish(dataset)<br/>    print("Successfully published dataset to Weave")<br/><br/>@flow(log_prints=True)<br/>def pinecone_flow():<br/>    with open('./config.json') as f:<br/>        config = json.load(f)<br/><br/>    start()<br/>    pull_data_to_csv(config)<br/>    docs = convert_csv_to_docs()<br/>    upload_docs_to_pinecone(docs, config)<br/>    publish_dataset_to_weave(docs)<br/><br/><br/>if __name__ == "__main__":<br/>    pinecone_flow.deploy(<br/>        name="pinecone-flow-deployment",<br/>        work_pool_name="my-aci-pool",<br/>        cron="0 0 * * 0",<br/>        image=DeploymentImage(<br/>            name="prefect-flows:latest",<br/>            platform="linux/amd64",<br/>        )<br/>    )</span></pre><p id="2144" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Notice how simple it is to turn Python functions into a Prefect flow. All you need are some sub-functions styled with <code class="cx px py pz pp b">@task</code> decorators and a <code class="cx px py pz pp b">@flow</code> decorator on the main function. Also note that after uploading the documents to Pinecone, the last step of our flow publishes the dataset to Weave. This is important for reproducibility purposes. To learn the basics of Prefect I recommend going through the tutorials <a class="af ob" href="https://docs.prefect.io/latest/tutorial/" rel="noopener ugc nofollow" target="_blank">on their website</a>.</p><p id="f05e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">At the bottom of the script we see how deployment is done in Prefect.</p><ul class=""><li id="bb0e" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk">We need to provide a <code class="cx px py pz pp b">name</code> for the deployment. This is arbitrary.</li><li id="9203" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">We also need to specify a <code class="cx px py pz pp b">work_pool_name</code> . Push work pools in Prefect automatically send tasks to serverless computers without needing a middleman. This name needs to match the name used to create the pool, which we’ll see below.</li><li id="41e7" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">You also need to specify a <code class="cx px py pz pp b">cron</code> , which is short for chronograph. This allows you to specify how often to repeat a workflow. The value <code class="cx px py pz pp b">“0 0 * * 0”</code> means repeat this workflow every week. Check out <a class="af ob" href="https://cloud.google.com/scheduler/docs/configuring/cron-job-schedules" rel="noopener ugc nofollow" target="_blank">this website</a> for details on how the <code class="cx px py pz pp b">cron</code> syntax works.</li><li id="c0a0" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Finally, you need to specify a <code class="cx px py pz pp b">DeploymentImage</code> . Here you specify both a <code class="cx px py pz pp b">name</code> and a <code class="cx px py pz pp b">platform</code> . The name is arbitrary, but the platform is not. Since I want to deploy to Azure compute instances, and these instances run Linux, it’s important I specify that in the <code class="cx px py pz pp b">DeploymentImage</code> .</li></ul><p id="d46a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To deploy this flow on Azure using the CLI, run the following commands:</p><pre class="mm mn mo mp mq po pp pq bp pr bb bk"><span id="5a30" class="ps oj fq pp b bg pt pu l pv pw">prefect work-pool create --type azure-container-instance:push --provision-infra my-aci-pool<br/>prefect deployment run 'get_repo_info/my-deployment'</span></pre><p id="ca07" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">These commands will automatically provision all of the necessary infrastructure on Azure. This includes an Azure Container Registry (ACR) that will hold a Docker image containing all files in your directory as well as any necessary libraries listed in a <code class="cx px py pz pp b">requirements.txt</code> . It will also include an Azure Container Instance (ACI) Identity that will have permissions necessary to deploy a container with the aforementioned Docker image. Finally, the <code class="cx px py pz pp b">deployment run</code> command will schedule the code to be run every week. You can check the Prefect dashboard to see your flow get run:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qe"><img src="../Images/fd1b54cdc71bbf012184a5f21cddd770.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wc2FFMhe61LWEWuRb5--1g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image of a flow in Prefect being successfully run. Image by author.</figcaption></figure><p id="742c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By updating my Pinecone vector store weekly, I can ensure that the recommendations from Rosebud 🌹 remain accurate.</p><h1 id="0875" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Summary</h1><p id="4816" class="pw-post-body-paragraph nc nd fq ne b go pe ng nh gr pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">In this article, I discussed my experience improving the Rosebud 🌹 app. This included the process of incorporating offline and online evaluation, as well as automating the update of my Pinecone vector store.</p><p id="544e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Some other improvements not mentioned in this article:</p><ul class=""><li id="59f4" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oh nz oa bk">Including ratings from <a class="af ob" href="https://www.themoviedb.org/?language=en-US" rel="noopener ugc nofollow" target="_blank">The Movie Database</a> in the film data. You can now ask for “<em class="pj">highly rated films</em>” and the chat model will filter for films above a 7/10.</li><li id="2813" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Upgraded chat models. Now the query and summary models are using <code class="cx px py pz pp b">gpt-4o-mini</code> . Recall that the LLM judge model is also using <code class="cx px py pz pp b">gpt-4o-mini</code> .</li><li id="579b" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Embedding model upgraded to <code class="cx px py pz pp b">text-embedding-3-small</code> from <code class="cx px py pz pp b">text-embedding-ada-002</code> .</li><li id="811e" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Years now span 1950–2023, instead of starting at 1920. Film data from 1920–1950 was not high quality, and only messed up recommendations.</li><li id="4be7" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">UI is cleaner, with all details regarding the project relegated to a sidebar.</li><li id="4e92" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Vastly improved documentation on GitHub.</li><li id="86d9" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx oh nz oa bk">Bug fixes.</li></ul><p id="851a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As mentioned at the top of the article, the app is now 100% free to use! I will foot the bill for queries for the foreseeable future (hence the choice of <code class="cx px py pz pp b">gpt-4o-mini</code> instead of the more expensive <code class="cx px py pz pp b">gpt-4o</code>). I really want to get the experience of running an app in production, and having my readers test out Rosebud<em class="pj"> </em>🌹 is a great way to do this. In the unlikely event that the app really blows up, I will have to come up with some other model of funding. But that would a great problem to have.</p><p id="2555" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Enjoy discovering awesome films! 🎥</p></div></div></div></div>    
</body>
</html>