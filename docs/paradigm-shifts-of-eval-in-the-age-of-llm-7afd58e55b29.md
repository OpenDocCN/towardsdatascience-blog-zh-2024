# 大语言模型时代评估的范式转变

> 原文：[https://towardsdatascience.com/paradigm-shifts-of-eval-in-the-age-of-llm-7afd58e55b29?source=collection_archive---------2-----------------------#2024-12-31](https://towardsdatascience.com/paradigm-shifts-of-eval-in-the-age-of-llm-7afd58e55b29?source=collection_archive---------2-----------------------#2024-12-31)

## 大语言模型在评估方法上需要一些微妙、概念上简单但却非常重要的变化。

[](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)[![Lili Jiang](../Images/ca3c10589bf964a7c29e70f6cdd12244.png)](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------) [Lili Jiang](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------) ·阅读时长7分钟·5天前

--

在我的职业生涯中，我一直在为机器学习系统构建评估。在Quora担任数据科学主管时，我们为信息流排序、广告、内容审核等构建了评估系统。我的Waymo团队为自动驾驶汽车构建了评估系统。最近，在我们的金融科技创业公司 [Coverbase](http://coverbase.io) 中，我们使用大语言模型来缓解第三方风险管理的困难。通过这些经验，我逐渐意识到，大语言模型在评估方法上需要一些微妙、概念上简单但却非常重要的变化。

本文的目标不是为您的大语言模型应用提供具体的评估技术，而是提出这三种范式转变：

1.  评估是蛋糕，而不再是糖霜。

1.  基准评估差异。

1.  将人工分拣作为评估的重要组成部分。

我需要说明的是，我的讨论主要集中在大语言模型的应用上，而非基础模型的开发。此外，尽管标题如此，我在这里讨论的内容也适用于其他生成系统（受到我在自动驾驶领域经验的启发），不仅仅是大语言模型应用。

## **1\. 评估是蛋糕，而不再是糖霜。**

评估在机器学习（ML）发展中一直很重要，不论是否涉及大语言模型（LLM）。但我认为，评估在大语言模型的发展中尤为重要，原因有二：

a) **评估的重要性**上升，因为在构建LLM应用时，调整的自由度较低，导致非评估工作的时间减少。在LLM开发中，基于基础模型（例如OpenAI的GPT或Anthropic的Claude模型）进行开发时，应用层可以调整的参数更少。而这些参数的调整速度也要快得多（警告：调整速度快，并不代表能更快达到正确的结果）。例如，修改提示语（prompt）显然比为一个梯度提升决策树编写一个新的手工特征要快速得多。因此，非评估工作的时间减少，导致评估所占时间比例增加。

![](../Images/ff691a2259916d0656e6baa7c4384077.png)

作者提供的图片

b) **评估的绝对重要性**上升，因为生成性人工智能的输出自由度更高，使得评估任务变得更加复杂。与分类或排序任务相比，生成性人工智能任务（例如：写一篇关于X的文章、制作Y的图像、为自动驾驶车辆生成轨迹）可以有无数种可接受的输出。因此，评估是将高维空间投射到低维空间的过程。例如，对于一个LLM任务，可以衡量：“输出文本是否真实？”，“输出是否包含有害内容？”，“语言是否简洁？”，“是否经常以‘当然！’开头？”等。如果二元分类任务中的精确度和召回率是对这些二元输出的无损测量（衡量你所看到的内容），那么我之前列出的LLM任务的示例指标就是对输出文本的有损测量（衡量你所看到内容的低维表示）。这要正确执行要困难得多。

这种范式转变对团队规模和招聘在大语言模型（LLM）应用项目中的实践意义重大。

## **2. 基准对比差异。**

这是理想的场景：我们设定一个目标指标并不断在其上进行改进。

![](../Images/3a3d72ce940c7167b69e889fc2d9f889.png)

作者提供的图片

现实情况呢？

你几乎无法在图表中绘制超过2个连续的点！

这些可能对你来说很熟悉：

在第一次发布后，我们获得了一个更大的数据集，因此新的度量值与旧的度量值不再是苹果对苹果的比较。我们也无法在新数据集上重新运行旧模型——也许系统的其他部分已经升级，我们无法查看旧的提交以重现旧模型；也许评估指标是一个LLM作为评判者，而数据集非常庞大，因此每次评估运行的成本非常高，等等。

在第二次发布后，我们决定更改输出模式。例如，之前我们指示模型输出“是/否”答案；现在我们指示模型输出“是/否/也许/我不知道”。因此，之前精心策划的真实标签集不再有效。

在第三次发布后，我们决定将单一的LLM调用分解为两个调用的组合，并且需要评估这些子组件。我们需要为子组件评估准备新的数据集。

….

关键是，在LLM时代，开发周期往往太快，以至于无法对同一度量进行纵向跟踪。

那么解决方案是什么？

测量增量。

换句话说，接受图表上只有两个连续数据点的事实。关键是确保每个模型版本比前一个版本更好（在当时你所知道的情况下），即使很难知道其表现的绝对水平。

假设我有一个基于LLM的语言辅导器，它首先将输入分类为英语或西班牙语，然后提供语法提示。一个简单的度量可以是“英语/西班牙语”标签的准确率。现在，假设我对提示做了一些修改，想知道新提示是否提高了准确率。与其手动标记一个大型数据集并计算其准确率，另一种方法是只关注旧提示和新提示产生不同标签的数据点。我不能通过这种方式知道任何模型的绝对准确率，但我会知道哪个模型的准确率更高。

![](../Images/d9d96c3cb0456a62f5a6a56c806bbe1f.png)

作者提供的图片

我需要澄清的是，我并不是说基准测试绝对值没有价值。我只是说我们应该意识到这样做的成本，而基准测试增量——尽管不能完全替代——可以是一种更加具有成本效益的方式，来得到一个方向性的结论。这种范式转变的一个更根本的原因是，如果你从零开始构建你的机器学习模型，你通常必须整理一个大的训练集，因此评估数据集通常是这个过程的副产品。而这在零-shot和少-shot学习中（例如，LLM）并非如此。

作为第二个例子，假设我有一个基于LLM的度量：我们使用一个独立的LLM来判断我在LLM语言辅导器中生成的解释是否足够清晰。有人可能会问：“既然评估现在是自动化的，基准测试增量仍然比基准测试绝对值便宜吗？”是的。因为度量现在更复杂了，你可以不断改进度量本身（例如，进行基于LLM的度量的提示工程）。首先，我们仍然需要评估评估；基准测试增量可以告诉你新版本的度量是否更好。其次，随着基于LLM的度量的发展，如果我们只专注于比较LLM语言辅导器模型的两个相邻版本，就不必费心去填补所有旧版本的基准结果，用新的基于LLM的度量版本来重新评估。

基准测试增量可以成为一种有效的内部循环、快速迭代机制，同时节省外部循环、低频率迭代中基准测试绝对值或纵向跟踪的高成本。

## **3\. 将人工筛选作为评估的一个组成部分。**

如上所述，精心筛选一个黄金数据集，一劳永逸地将其作为永恒基准使用的梦想可能无法实现。筛选将成为开发过程中的一个不可或缺的、持续的部分，无论是直接筛选LLM输出，还是筛选LLM作为判断者或其他更复杂的指标。我们应继续使评估尽可能可扩展；关键是，尽管如此，我们不应指望能够消除人工筛选。我们越早接受这一点，就能越早在工具投资上做出正确决策。

因此，无论我们使用何种评估工具，无论是内部工具还是外部工具，都应该有一个便捷的人工筛选界面。一个简单的界面可以像下面这样。结合前面提到的差异基准，界面可以呈现并排面板，用户可以轻松浏览结果。它还应允许你轻松记录筛选的笔记，以便将其作为黄金标签用于未来的基准测试（从而减少未来的筛选负担）。

![](../Images/5ce8ee267c785af203979bc27966b731.png)

图像来自作者

更高级的版本理想情况下应该是盲测，即筛选者不知道哪个版本是哪个。我们通过数据反复验证了，当不进行盲测时，开发人员即便是出于最佳意图，也会有潜在的偏见，偏向自己开发的版本。

一旦发现这三种范式转变，适应起来其实相当直接。挑战不在于解决方案的复杂性，而在于在激动人心的快速开发节奏中，提前识别这些转变。我希望分享这些思考能帮助其他在自己工作中面临类似挑战的人。
