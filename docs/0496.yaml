- en: QLoRA — How to Fine-Tune an LLM on a Single GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32?source=collection_archive---------1-----------------------#2024-02-22](https://towardsdatascience.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32?source=collection_archive---------1-----------------------#2024-02-22)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An introduction with Python example code (ft. Mistral-7b)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shawhin.medium.com/?source=post_page---byline--4e44d6b5be32--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page---byline--4e44d6b5be32--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4e44d6b5be32--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4e44d6b5be32--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page---byline--4e44d6b5be32--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4e44d6b5be32--------------------------------)
    ·16 min read·Feb 22, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: This article is part of a [larger series](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c)
    on using large language models (LLMs) in practice. In the [previous post](/how-to-build-an-ai-assistant-with-openai-python-8b3b5a636f69),
    we saw how to fine-tune an LLM using OpenAI. The main limitation to this approach,
    however, is that OpenAI’s models are concealed behind their API, which limits
    what and how we can build with them. Here, I’ll discuss an alternative way to
    fine-tune an LLM using open-source models and QLoRA.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68d9cb7567d5ae053a881cfeea25ba43.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Dell](https://unsplash.com/@dell?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**Fine-tuning** is when we **take an existing model and tweak it for a particular
    use case**. This has been a critical part of the recent explosion of AI innovations,
    giving rise to ChatGPT and the like.'
  prefs: []
  type: TYPE_NORMAL
- en: Although fine-tuning is a simple (and powerful) idea, applying it to LLMs isn’t
    always straightforward. The key challenge is that **LLMs are (very) computationally
    expensive** (i.e. they aren’t something that can be trained on a typical laptop).
  prefs: []
  type: TYPE_NORMAL
- en: For example, standard fine-tuning of a 70B parameter model requires over 1TB
    of memory [1]. For context, an A100 GPU comes with up to 80GB of memory, so you’d
    (at best) need over a dozen of these $20,000 cards!
  prefs: []
  type: TYPE_NORMAL
- en: While this may deflate your dreams of building a custom AI, don’t give up just
    yet. The open-source community has been working hard…
  prefs: []
  type: TYPE_NORMAL
