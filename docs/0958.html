<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Feature Engineering with Microsoft Fabric and Dataflow Gen2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Feature Engineering with Microsoft Fabric and Dataflow Gen2</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-engineering-with-microsoft-fabric-and-dataflow-gen2-1471d22014b9?source=collection_archive---------11-----------------------#2024-04-15">https://towardsdatascience.com/feature-engineering-with-microsoft-fabric-and-dataflow-gen2-1471d22014b9?source=collection_archive---------11-----------------------#2024-04-15</a></blockquote><div><div class="em ff fg fh fi fj"/><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><div/><div><h2 id="f642" class="pw-subtitle-paragraph go fq fr bf b gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd cq dx">Fabric Madness part 3</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@roger_noble?source=post_page---byline--1471d22014b9--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Roger Noble" class="l ep by dd de cx" src="../Images/869b5b0f237f24b119ca6c41c2e31162.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*DSDhBVvFKAUKXJfpbO5beg.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--1471d22014b9--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@roger_noble?source=post_page---byline--1471d22014b9--------------------------------" rel="noopener follow">Roger Noble</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--1471d22014b9--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk lb lc ab q ee ld le" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lf"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap ie li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/6a72c6bcc90ff02e9f300c48d9df2afc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VTgEZWdOf9f5DUjuWAFx6g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by author and ChatGPT. “Design an illustration, featuring a Paralympic basketball player in action, this time the theme is on data pipelines” prompt. ChatGPT, 4, OpenAI, 15April. 2024. <a class="af nc" href="https://chat.openai.com./" rel="noopener ugc nofollow" target="_blank">https://chat.openai.com.</a></figcaption></figure><p id="59a0" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">In the <a class="af nc" href="https://medium.com/towards-data-science/feature-engineering-with-microsoft-fabric-and-pyspark-16d458018744" rel="noopener">previous post</a>, we discussed how to use Notebooks with PySpark for feature engineering. While spark offers a lot of flexibility and power, it can be quite complex and requires a lot of code to get started. Not everyone is comfortable with writing code or has the time to learn a new programming language, which is where Dataflow Gen2 comes in.</p><h1 id="59b7" class="nz oa fr bf ob oc od gr oe of og gu oh oi oj ok ol om on oo op oq or os ot ou bk">What is Dataflow Gen2?</h1><p id="fe80" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">Dataflow Gen2 is a low-code data transformation and integration engine that allows you to create data pipelines for loading data from a wide variety of sources into Microsoft Fabric. It’s based on Power Query, which is integrated into many Microsoft products, such as Excel, Power BI, and Azure Data Factory. Dataflow Gen2 is a great tool for creating data pipelines without code via a visual interface, making it easy to create data pipelines quickly. If you are already familiar with Power Query or are not afraid of writing code, you can also use the underlying M (“Mashup”) language to create more complex transformations.</p><p id="b995" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">In this post, we will walk through how to use Dataflow Gen2 to create the same features needed to train our machine learning model. We will use the same dataset as in the previous post, which contains data about college basketball games.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pa"><img src="../Images/9612ef75cfbd3ebf67434d7e9b667e29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v2F5aKJvR-z775doJ2U4Cw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 1 — The final result. Image by author.</figcaption></figure><h1 id="2f4b" class="nz oa fr bf ob oc od gr oe of og gu oh oi oj ok ol om on oo op oq or os ot ou bk">The Challenge</h1><p id="913d" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">There are two datasets that we will be using to create our features: the regular season games and the tournament games. These two datasets are also split into the Men’s and Women’s tournaments, which will need to be combined into a single dataset. In total there are four csv files, that need to be combined and transformed into two separate tables in the Lakehouse.</p><p id="452e" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Using Dataflows there are multiple ways to solve this problem, and in this post I want to show three different approaches: a no code approach, a low code approach and finally a more advanced all code approach.</p><h1 id="34d9" class="nz oa fr bf ob oc od gr oe of og gu oh oi oj ok ol om on oo op oq or os ot ou bk">The no code approach</h1><p id="19ec" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">The first and simplest approach is to use the Dataflow Gen2 visual interface to load the data and create the features.</p><h2 id="329a" class="pb oa fr bf ob pc pd pe oe pf pg ph oh nm pi pj pk nq pl pm pn nu po pp pq pr bk">The Data</h2><p id="5e68" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">The data we are looking at is from the 2024 US college basketball tournaments, which was obtained from the on-going March Machine Learning Mania 2024 Kaggle competition, the details of which can be found <a class="af nc" href="https://www.kaggle.com/competitions/march-machine-learning-mania-2024/overview" rel="noopener ugc nofollow" target="_blank">here</a>, and is licensed under CC BY 4.0</p><h2 id="e5ec" class="pb oa fr bf ob pc pd pe oe pf pg ph oh nm pi pj pk nq pl pm pn nu po pp pq pr bk">Loading the data</h2><p id="631b" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">The first step is to get the data from the Lakehouse, which can be done by selecting the “Get Data” button in the Home ribbon and then selecting <strong class="nf fs">More…</strong> from the list of data sources.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ps"><img src="../Images/09e6830ca797495bd419893e0cb18b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*QRdRxmgdOs5pNgkjMa_Aog.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 2 — Choosing a data source. Image by author.</figcaption></figure><p id="b62d" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">From the list, select <strong class="nf fs">OneLake data hub</strong> to find the Lakehouse and then once selected, find the csv file in the Files folder.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pt"><img src="../Images/79af66f24ffb07087bd9b233f519caa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nqnkb0ncQm_VKMQ7TSbfMw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 3 — Select the csv file. Image by author.</figcaption></figure><p id="79e3" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">This will create a new query with four steps, which are:</p><ul class=""><li id="b005" class="nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pu pv pw bk">Source: A function that queries the Lakehouse for all the contents.</li><li id="c948" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny pu pv pw bk">Navigation 1: Converts the contents of the Lakehouse into a table.</li><li id="3b17" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny pu pv pw bk">Navigation 2: Filters the table to retrieve the selected csv file by name.</li><li id="7f3a" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny pu pv pw bk">Imported CSV: Converts the binary file into a table.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qc"><img src="../Images/b2fd1a2b8f2b1f429cc45716b45bb3a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KDTHbIGuh2glBnhWWLTHfQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 4 — Initial load. Image by author.</figcaption></figure><p id="575d" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Now that the data is loaded we can start with some basic data preparation to get it into a format that we can use to create our features. The first thing we need to do is set the column names to be based on the first row of the dataset. This can be done by selecting the “Use first row as headers” option in either the Transform group on the Home ribbon or in the Transform menu item.</p><p id="ccb2" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">The next step is to rename the column “WLoc” to “location” by either selecting the column in the table view, or by right clicking on the column and selecting “Rename”.</p><p id="5322" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">The location column contains the location of the game, which is either “H” for home, “A” for away, or “N” for neutral. For our purposes, we want to convert this to a numerical value, where “H” is 1, “A” is -1, and “N” is 0, as this will make it easier to use in our model. This can be done by selecting the column and then using the <strong class="nf fs">Replace values…</strong> transform in the Transform menu item.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qd"><img src="../Images/3026952f8952ad4f14af39db338e6cc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*4ravBzBF0_r-HEOyrjGu5A.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 5 — Replace Values. Image by author.</figcaption></figure><p id="63d9" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">This will need to be done for the other two location values as well.</p><p id="8cce" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Finally, we need to change the data type of the location column to be a Whole number instead of Text. This can be done by selecting the column and then selecting the data type from the drop down list in the Transform group on the Home ribbon.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qe"><img src="../Images/6a798ea01fb3197b4ffcacc135a69f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-m7E-8BEoLLWT6ca8f0BJA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 6 — Final data load. Image by author.</figcaption></figure><p id="69d5" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Instead of repeating the rename step for each of the location types, a little bit of M code can be used to replace the values in the location column. This can be done by selecting the previous transform in the query (Renamed columns) and then selecting the Insert step button in the formula bar. This will add a new step, and you can enter the following code to replace the values in the location column.</p><pre class="mm mn mo mp mq qf qg qh bp qi bb bk"><span id="2999" class="qj oa fr qg b bg qk ql l qm qn">Table.ReplaceValue(#"Renamed columns", each [location], each if Text.Contains([location], "H") then "1" else if Text.Contains([location], "A") then "-1" else "0", Replacer.ReplaceText, {"location"})</span></pre><h2 id="cd21" class="pb oa fr bf ob pc pd pe oe pf pg ph oh nm pi pj pk nq pl pm pn nu po pp pq pr bk">Adding features</h2><p id="4cda" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">We’ve got the data loaded, but it’s still not right for our model. Each row in the dataset represents a game between two teams, and includes the scores and statistics for both the winning and losing team in a single wide table. We need to create features that represent the performance of each team in the game and to have a row per team per game.</p><p id="c559" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">To do this we need to split the data into two tables, one for the winning team and one for the losing team. The simplest way to do this is to create a new query for each team and then merge them back together at the end. There are a few ways that this could be done, however to keep things simple and understandable (especially if we ever need to come back to this later), we will create two references to the source query and then append them together again, after doing some light transformations.</p><p id="412c" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Referencing a column can be done either from the Queries panel on the left, or by selecting the context menu of the query if using Diagram view. This will create a new query that references the original query, and any changes made to the original query will be reflected in the new query. I did this twice, once for the winning team and once for the losing team and then renamed the columns by prefixing them with “T1_” and “T2_” respectively.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qo"><img src="../Images/eaa71856383445c2c54e32569ebd31f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*75BMfcNjf6O9hapOxhN08A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 7 — Split the dataset. Image by author.</figcaption></figure><p id="f636" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Once the column values are set, we can then combine the two queries back together by using Append Queries and then create our first feature, which is the point difference between the two teams. This can be done by selecting the T1_Score and T2_Score columns and then selecting “Subtract” from the “Standard” group on the Add column ribbon.</p><p id="ad59" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Now that’s done, we can then load the data into the Lakehouse as a new table. The final result should look something like this:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qp"><img src="../Images/b1e0440221e77afad699b89e8a1ee67d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-OTQaIsKkInA2FOxYRtzw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 8 — All joined up. Image by author.</figcaption></figure><p id="124b" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">There are a few limitations with the no code approach, the main one is that it’s not easy to reuse queries or transformations. In the above example we would need to repeat the same steps another three times to load each of the individual csv files. This is where copy / paste comes in handy, but it’s not ideal. Let’s look at a low code approach next.</p><h1 id="0485" class="nz oa fr bf ob oc od gr oe of og gu oh oi oj ok ol om on oo op oq or os ot ou bk">The low code approach</h1><p id="b05f" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">In the low code approach we will use a combination of the visual interface and the M language to load and transform the data. This approach is more flexible than the no code approach, but still doesn’t require a lot of code to be written.</p><h2 id="6264" class="pb oa fr bf ob pc pd pe oe pf pg ph oh nm pi pj pk nq pl pm pn nu po pp pq pr bk">Loading the data</h2><p id="68e3" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">The goal of the low code approach is to reduce the number of repeated queries that are needed and to make it easier to reuse transformations. To do this we will take advantage of the fact that Power Query is a functional language and that we can create functions to encapsulate the transformations that we want to apply to the data. When we first loaded the data from the Lakehouse there were four steps that were created, the second step was to convert the contents of the Lakehouse into a table, with each row containing a reference to a binary csv file. We can use this as the input into a function, which will load the csv into a new table, using the Invoke custom function transformation for each row of the table.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qq"><img src="../Images/38cb149e20c76260a93ed2ba7fc2ddf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*zaqBEKc2vpFfa5me0c9J2A.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 9 — Lakehouse query with the binary csv files in a column called Content. Image by author.</figcaption></figure><p id="5d4c" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">To create the function, select “Blank query” from the Get data menu, or right click the Queries panel and select “New query” &gt; “Blank query”. In the new query window, enter the following code:</p><pre class="mm mn mo mp mq qf qg qh bp qi bb bk"><span id="6f52" class="qj oa fr qg b bg qk ql l qm qn">(TableContents as binary) =&gt;let<br/>  Source = Csv.Document(TableContents, [Delimiter = ",", Columns = 34, QuoteStyle = QuoteStyle.None]),<br/>  PromoteHeaders = Table.PromoteHeaders(Source, [PromoteAllScalars = true])<br/>in<br/>  PromoteHeaders</span></pre><p id="6ea1" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">The code of this function has been copied from our initial no code approach, but instead of loading the csv file directly, it takes a parameter called <strong class="nf fs">TableContents</strong>, reads it as a csv file <code class="cx qr qs qt qg b">Csv.Document</code> and then sets the first row of the data to be the column headers <code class="cx qr qs qt qg b">Table.PromoteHeaders</code>.</p><p id="f5f8" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">We can then use the Invoke custom function transformation to apply this function to each row of the Lakehouse query. This can be done by selecting the “Invoke custom function” transformation from the Add column ribbon and then selecting the function that we just created.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qd"><img src="../Images/93db46a8fd3ec467e7c6ccb9c13d3605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*s7ne9MJwFTJSrzz_BPBfZQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 10 — Invoke custom function. Image by author.</figcaption></figure><p id="2a3a" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">This will create a new column in the Lakehouse query, with the entire contents of the csv file loaded into a table, which is represented as <code class="cx qr qs qt qg b">[Table]</code> in the table view. We can then use the expand function on the column heading to expand the table into individual columns.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qu"><img src="../Images/a2f6d83805e7ca0cf3ab9814c6746ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gu3QwZBefS0BUD7pZYTGvA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 11 — Expand columns. Image by author.</figcaption></figure><p id="7895" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">The result effectively combines the two csv files into a single table, which we can then continue to create our features from as before.</p><p id="7f03" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">There are still some limitations with this approach, while we’ve reduced the number of repeated queries, we still need to duplicate everything for both the regular season and tournament games datasets. This is where the all code approach comes in.</p><h1 id="15ea" class="nz oa fr bf ob oc od gr oe of og gu oh oi oj ok ol om on oo op oq or os ot ou bk">The all code approach</h1><p id="857b" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">The all code approach is the most flexible and powerful approach, but also requires the most amount of code to be written. This approach is best suited for those who are comfortable with writing code and want to have full control over the transformations that are applied to the data.</p><p id="6e90" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Essentially what we’ll do is grab all the M code that was generated in each of the queries and combine them into a single query. This will allow us to load all the csv files in a single query and then apply the transformations to each of them in a single step. To get all the M code, we can select each query and then click on the Advanced Editor from the Home ribbon, which displays all the M code that was generated for that query. We can then copy and paste this code into a new query and then combine them all together.</p><p id="8432" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">To do this, we need to create a new blank query and then enter the following code:</p><pre class="mm mn mo mp mq qf qg qh bp qi bb bk"><span id="4417" class="qj oa fr qg b bg qk ql l qm qn">(TourneyType as text) =&gt; let<br/>  Source = Lakehouse.Contents(null){[workspaceId = "..."]}[Data]{[lakehouseId = "..."]}[Data],<br/>  #"Navigation 1" = Source{[Id = "Files", ItemKind = "Folder"]}[Data],<br/>  #"Filtered rows" = Table.SelectRows(#"Navigation 1", each Text.Contains([Name], TourneyType)),<br/>  #"Invoked custom function" = Table.AddColumn(#"Filtered rows", "Invoked custom function", each LoadCSV([Content])),<br/>  #"Removed columns" = Table.RemoveColumns(#"Invoked custom function", {"Content", "Name", "Extension", "Date accessed", "Date modified", "Date created", "Attributes", "Folder Path", "ItemKind", "IsLeaf"}),<br/>  #"Expanded Invoked custom function" = Table.ExpandTableColumn(#"Removed columns", "Invoked custom function", {"Season", "DayNum", "WTeamID", "WScore", "LTeamID", "LScore", "WLoc", "NumOT", "WFGM", "WFGA", "WFGM3", "WFGA3", "WFTM", "WFTA", "WOR", "WDR", "WAst", "WTO", "WStl", "WBlk", "WPF", "LFGM", "LFGA", "LFGM3", "LFGA3", "LFTM", "LFTA", "LOR", "LDR", "LAst", "LTO", "LStl", "LBlk", "LPF"}, {"Season", "DayNum", "WTeamID", "WScore", "LTeamID", "LScore", "WLoc", "NumOT", "WFGM", "WFGA", "WFGM3", "WFGA3", "WFTM", "WFTA", "WOR", "WDR", "WAst", "WTO", "WStl", "WBlk", "WPF", "LFGM", "LFGA", "LFGM3", "LFGA3", "LFTM", "LFTA", "LOR", "LDR", "LAst", "LTO", "LStl", "LBlk", "LPF"}),<br/>  #"Renamed columns" = Table.RenameColumns(#"Expanded Invoked custom function", {{"WLoc", "location"}}),<br/>  Custom = Table.ReplaceValue(#"Renamed columns", each [location], each if Text.Contains([location], "H") then "1" else if Text.Contains([location], "A") then "-1" else "0", Replacer.ReplaceText, {"location"}),<br/>  #"Change Types" = Table.TransformColumnTypes(Custom, {{"Season", Int64.Type}, {"DayNum", Int64.Type}, {"WTeamID", Int64.Type}, {"WScore", Int64.Type}, {"LTeamID", Int64.Type}, {"LScore", Int64.Type}, {"location", Int64.Type}, {"NumOT", Int64.Type}, {"WFGM", Int64.Type}, {"WFGA", Int64.Type}, {"WFGM3", Int64.Type}, {"WFGA3", Int64.Type}, {"WFTM", Int64.Type}, {"WFTA", Int64.Type}, {"WOR", Int64.Type}, {"WDR", Int64.Type}, {"WAst", Int64.Type}, {"WTO", Int64.Type}, {"WStl", Int64.Type}, {"WBlk", Int64.Type}, {"WPF", Int64.Type}, {"LFGM", Int64.Type}, {"LFGA", Int64.Type}, {"LFGM3", Int64.Type}, {"LFGA3", Int64.Type}, {"LFTM", Int64.Type}, {"LFTA", Int64.Type}, {"LOR", Int64.Type}, {"LDR", Int64.Type}, {"LAst", Int64.Type}, {"LTO", Int64.Type}, {"LStl", Int64.Type}, {"LBlk", Int64.Type}, {"LPF", Int64.Type}}),<br/>  Winners = Table.TransformColumnNames(#"Change Types", each if Text.StartsWith(_, "W") then Text.Replace(_, "W", "T1_") else Text.Replace(_, "L", "T2_")),<br/>  #"Rename L" = Table.TransformColumnNames(#"Change Types", each if Text.StartsWith(_, "W") then Text.Replace(_, "W", "T2_") else Text.Replace(_, "L", "T1_")),<br/>  #"Replaced Value L" = Table.ReplaceValue(#"Rename L", each [location], each if [location] = 1 then -1 else if Text.Contains([location], -1) then 1 else [location], Replacer.ReplaceValue, {"location"}),<br/>  Losers = Table.TransformColumnTypes(#"Replaced Value L", {{"location", Int64.Type}}),<br/>  Combined = Table.Combine({Winners, Losers}),<br/>  PointDiff = Table.AddColumn(Combined, "PointDiff", each [T1_Score] - [T2_Score], Int64.Type)<br/>in<br/>  PointDiff</span></pre><p id="bf45" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk"><em class="qv">Note: the Lakehouse connection values have been removed</em></p><p id="3531" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">What’s happening here is that we’re:</p><ol class=""><li id="874c" class="nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qw pv pw bk">Loading the data from the Lakehouse;</li><li id="0f4b" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny qw pv pw bk">Filtering the rows to only include the csv files that match the TourneyType parameter;</li><li id="66e5" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny qw pv pw bk">Loading the csv files into tables;</li><li id="9f6d" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny qw pv pw bk">Expanding the tables into columns;</li><li id="a69a" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny qw pv pw bk">Renaming the columns;</li><li id="7fea" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny qw pv pw bk">Changing the data types;</li><li id="7c26" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny qw pv pw bk">Combining the two tables back together;</li><li id="da81" class="nd ne fr nf b gp px nh ni gs py nk nl nm pz no np nq qa ns nt nu qb nw nx ny qw pv pw bk">Calculating the point difference between the two teams.</li></ol><p id="1a66" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Using the query is then as simple as selecting it, and then invoking the function with the TourneyType parameter.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qx"><img src="../Images/6fb312c0bced0e91a3e7141022d951e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*-rBPvtUfcm5jnVW5BxtP5Q.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 12 — Invoke function. Image by author.</figcaption></figure><p id="02a8" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">This will create a new query with the function as it’s source, and the data loaded and transformed. It’s then just a case of loading the data into the Lakehouse as a new table.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qy"><img src="../Images/91ea5a15eb7ff19de63185d8fee0d1a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*up1wBqG8twNDbzbY6j8Iag.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Fig. 13 — Function load. Image by author.</figcaption></figure><p id="cb13" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">As you can see, the LoadTournamentData function is invoked with the parameter “RegularSeasonDetailedResults” which will load both the Men’s and Women’s regular season games into a single table.</p><h1 id="fb1d" class="nz oa fr bf ob oc od gr oe of og gu oh oi oj ok ol om on oo op oq or os ot ou bk">Conclusion</h1><p id="1752" class="pw-post-body-paragraph nd ne fr nf b gp ov nh ni gs ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fk bk">And that’s it!</p><p id="1614" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Hopefully this post has given you a good overview of how to use Dataflow Gen2 to prepare data and create features for your machine learning model. Its low code approach makes it easy to create data pipelines quickly, and it contains a lot of powerful features that can be used to create complex transformations. It’s a great first port of call for anyone who needs to transform data, but more importantly, has the benefit of not needing to write complex code that is prone to errors, is hard to test, and is difficult to maintain.</p><p id="c64f" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">At the time of writing, Dataflows Gen2 are unsupported with the Git integration, and so it’s not possible to version control or share the dataflows. This feature is expected to be <a class="af nc" href="https://learn.microsoft.com/en-us/fabric/release-plan/data-factory#git-df" rel="noopener ugc nofollow" target="_blank">released in Q4 2024</a>.</p></div></div></div><div class="ab cb qz ra rb rc" role="separator"><span class="rd by bm re rf rg"/><span class="rd by bm re rf rg"/><span class="rd by bm re rf"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="d271" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk"><em class="qv">Originally published at </em><a class="af nc" href="https://nobledynamic.com/posts/fabric-madness-3/" rel="noopener ugc nofollow" target="_blank"><em class="qv">https://nobledynamic.com</em></a><em class="qv"> on April 15, 2024.</em></p></div></div></div></div>    
</body>
</html>