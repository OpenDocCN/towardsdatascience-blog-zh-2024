- en: 'Logistic Regression, Explained: A Visual Guide with Code Examples for Beginners'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505?source=collection_archive---------0-----------------------#2024-09-10](https://towardsdatascience.com/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505?source=collection_archive---------0-----------------------#2024-09-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: CLASSIFICATION ALGORITHM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finding the perfect weights to fit the data in
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--81baf5871505--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--81baf5871505--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--81baf5871505--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--81baf5871505--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--81baf5871505--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--81baf5871505--------------------------------)
    ¬∑10 min read¬∑Sep 10, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/08286a411c63fdbe68e056f07d6540a2.png)'
  prefs: []
  type: TYPE_IMG
- en: '`‚õ≥Ô∏è More [CLASSIFICATION ALGORITHM](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c),
    explained: ¬∑ [Dummy Classifier](/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    ¬∑ [K Nearest Neighbor Classifier](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    ¬∑ [Bernoulli Naive Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)
    ¬∑ [Gaussian Naive Bayes](/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c)
    ¬∑ [Decision Tree Classifier](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    ‚ñ∂ [Logistic Regression](/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505)
    ¬∑ [Support Vector Classifier](/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9)
    ¬∑ [Multilayer Perceptron](/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c)`'
  prefs: []
  type: TYPE_NORMAL
- en: While some probabilistic-based machine learning models (like [Naive Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6))
    make bold assumptions about feature independence, logistic regression takes a
    more measured approach. Think of it as drawing a line (or plane) that separates
    two outcomes, allowing us to predict probabilities with a bit more flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/add544fe281d9cac3d807605d793740a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  prefs: []
  type: TYPE_NORMAL
- en: Definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression is a statistical method used for predicting binary outcomes.
    Despite its name, it‚Äôs used for classification rather than regression. It estimates
    the probability that an instance belongs to a particular class. If the estimated
    probability is greater than 50%, the model predicts that the instance belongs
    to that class (or vice versa).
  prefs: []
  type: TYPE_NORMAL
- en: üìä Dataset Used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this article, we‚Äôll use this artificial golf dataset (inspired by
    [1]) as an example. This dataset predicts whether a person will play golf based
    on weather conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '[Just like in KNN](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1),
    logistic regression requires the data to be scaled first. [Convert categorical
    columns](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    into 0 & 1 and also [scale the numerical features](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    so that no single feature dominates the distance metric.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be47d8fc7fb892e46cc3ac4f26cdf8f5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Columns: ‚ÄòOutlook‚Äô, ‚ÄòTemperature‚Äô, ‚ÄòHumidity‚Äô, ‚ÄòWind‚Äô and ‚ÄòPlay‚Äô (target feature).
    The categorical columns (Outlook & Windy) are encoded using one-hot encoding while
    the numerical columns are scaled using standard scaling (z-normalization).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Main Mechanism
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logistic regression works by applying the logistic function to a linear combination
    of the input features. Here‚Äôs how it operates:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate a weighted sum of the input features (similar to linear regression).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the logistic function (also called sigmoid function) to this sum, which
    maps any real number to a value between 0 and 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Interpret this value as the probability of belonging to the positive class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a threshold (typically 0.5) to make the final classification decision.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/a7075b4e966c4487e4ddf0397a705947.png)'
  prefs: []
  type: TYPE_IMG
- en: For our golf dataset, logistic regression might combine the weather factors
    into a single score, then transform this score into a probability of playing golf.
  prefs: []
  type: TYPE_NORMAL
- en: Training Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The training process for logistic regression involves finding the best weights
    for the input features. Here‚Äôs the general outline:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the weights (often to small random values).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/3b3d36e76e221058bfb5bdef6dbcb540.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '2\. For each training example:'
  prefs: []
  type: TYPE_NORMAL
- en: a. Calculate the predicted probability using the current weights.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ad914e2c81f2ef22d3423c61b065128.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: b. Compare this probability to the actual class label by calculating its log
    loss.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d03bec8cdef352fdd52c9e1cf0a8985b.png)'
  prefs: []
  type: TYPE_IMG
- en: 3\. Update the weights to minimize the loss (usually using some optimization
    algorithm, like gradient descent. This include repeatedly do Step 2 until log
    loss cannot get smaller).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7970c48934b6717e83f2f94d7f770846.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Classification Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the model is trained:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. For a new instance, calculate the probability with the final weights (also
    called coefficients), just like during the training step.
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Interpret the output by seeing the probability: if *p* ‚â• 0.5, predict class
    1; otherwise, predict class 0'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/99a363cd8b98d3754e27643122b7c9c7.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Evaluation Step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/c7574523a49fa326eb623dcf5cf0d23c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Key Parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logistic regression has several important parameters that control its behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1.Penalty**: The type of regularization to use (‚Äòl1‚Äô, ‚Äòl2‚Äô, ‚Äòelasticnet‚Äô,
    or ‚Äònone‚Äô). Regularization in logistic regression prevents overfitting by adding
    a penalty term to the model‚Äôs loss function, that encourages simpler models.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d6388db7b9a3516fa793253062783429.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**2\. Regularization Strength (C)**: Controls the trade-off between fitting
    the training data and keeping the model simple. A smaller C means stronger regularization.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b456b69f56e095c9ced88959e77bab79.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**3\. Solver:** The algorithm to use for optimization (‚Äòliblinear‚Äô, ‚Äònewton-cg‚Äô,
    ‚Äòlbfgs‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô). Some regularization might require a particular algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Max Iterations**: The maximum number of iterations for the solver to
    converge.'
  prefs: []
  type: TYPE_NORMAL
- en: For our golf dataset, we might start with ‚Äòl2‚Äô penalty, ‚Äòliblinear‚Äô solver,
    and C=1.0 as a baseline.
  prefs: []
  type: TYPE_NORMAL
- en: Pros & Cons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like any algorithm in machine learning, logistic regression has its strengths
    and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pros:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Simplicity**: Easy to implement and understand.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Interpretability**: The weights directly show the importance of each feature.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Efficiency**: Doesn‚Äôt require too much computational power.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Probabilistic Output**: Provides probabilities rather than just classifications.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Cons:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Linearity Assumption**: Assumes a linear relationship between features and
    log-odds of the outcome.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Feature Independence**: Assumes features are not highly correlated.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Limited Complexity**: May underfit in cases where the decision boundary is
    highly non-linear.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Requires More Data**: Needs a relatively large sample size for stable results.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In our golf example, logistic regression might provide a clear, interpretable
    model of how each weather factor influences the decision to play golf. However,
    it might struggle if the decision involves complex interactions between weather
    conditions that can‚Äôt be captured by a linear model.
  prefs: []
  type: TYPE_NORMAL
- en: Final Remark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression shines as a powerful yet straightforward classification
    tool. It stands out for its ability to handle complex data while remaining easy
    to interpret. Unlike [some other basic models](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e),
    it provides smooth probability estimates and works well with many features. In
    the real world, from predicting customer behavior to medical diagnoses, logistic
    regression often performs surprisingly well. It‚Äôs not just a stepping stone ‚Äî
    it‚Äôs a reliable model that can match more complex models in many situations.
  prefs: []
  type: TYPE_NORMAL
- en: üåü Logistic Regression Code Summarized
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a detailed explanation of the [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
    and its implementation in scikit-learn, readers can refer to the official documentation
    [2], which provides comprehensive information on its usage and parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Technical Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  prefs: []
  type: TYPE_NORMAL
- en: About the Illustrations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3954bb576147e89326d88edd83f57b51.png)'
  prefs: []
  type: TYPE_IMG
- en: For a concise visual summary, check out [the companion Instagram post](https://www.instagram.com/p/C_viu8bSXJ8/).
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] T. M. Mitchell, [Machine Learning](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)
    (1997), McGraw-Hill Science/Engineering/Math, pp. 59'
  prefs: []
  type: TYPE_NORMAL
- en: 'ùôéùôöùôö ùô¢ùô§ùôßùôö ùòæùô°ùôñùô®ùô®ùôûùôõùôûùôòùôñùô©ùôûùô§ùô£ ùòºùô°ùôúùô§ùôßùôûùô©ùôùùô¢ùô® ùôùùôöùôßùôö:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----81baf5871505--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Classification Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----81baf5871505--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'ùôîùô§ùô™ ùô¢ùôûùôúùôùùô© ùôñùô°ùô®ùô§ ùô°ùôûùô†ùôö:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----81baf5871505--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Regression Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----81baf5871505--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This ‚Äúdummy‚Äù doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----81baf5871505--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----81baf5871505--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  prefs: []
  type: TYPE_NORMAL
