- en: 'Logistic Regression, Explained: A Visual Guide with Code Examples for Beginners'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505?source=collection_archive---------0-----------------------#2024-09-10](https://towardsdatascience.com/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505?source=collection_archive---------0-----------------------#2024-09-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: CLASSIFICATION ALGORITHM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finding the perfect weights to fit the data in
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--81baf5871505--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--81baf5871505--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--81baf5871505--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--81baf5871505--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--81baf5871505--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--81baf5871505--------------------------------)
    Â·10 min readÂ·Sep 10, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/08286a411c63fdbe68e056f07d6540a2.png)'
  prefs: []
  type: TYPE_IMG
- en: '`â›³ï¸ More [CLASSIFICATION ALGORITHM](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c),
    explained: Â· [Dummy Classifier](/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    Â· [K Nearest Neighbor Classifier](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    Â· [Bernoulli Naive Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)
    Â· [Gaussian Naive Bayes](/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c)
    Â· [Decision Tree Classifier](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    â–¶ [Logistic Regression](/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505)
    Â· [Support Vector Classifier](/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9)
    Â· [Multilayer Perceptron](/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c)`'
  prefs: []
  type: TYPE_NORMAL
- en: While some probabilistic-based machine learning models (like [Naive Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6))
    make bold assumptions about feature independence, logistic regression takes a
    more measured approach. Think of it as drawing a line (or plane) that separates
    two outcomes, allowing us to predict probabilities with a bit more flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/add544fe281d9cac3d807605d793740a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  prefs: []
  type: TYPE_NORMAL
- en: Definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression is a statistical method used for predicting binary outcomes.
    Despite its name, itâ€™s used for classification rather than regression. It estimates
    the probability that an instance belongs to a particular class. If the estimated
    probability is greater than 50%, the model predicts that the instance belongs
    to that class (or vice versa).
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ“Š Dataset Used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this article, weâ€™ll use this artificial golf dataset (inspired by
    [1]) as an example. This dataset predicts whether a person will play golf based
    on weather conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '[Just like in KNN](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1),
    logistic regression requires the data to be scaled first. [Convert categorical
    columns](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    into 0 & 1 and also [scale the numerical features](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    so that no single feature dominates the distance metric.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be47d8fc7fb892e46cc3ac4f26cdf8f5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Columns: â€˜Outlookâ€™, â€˜Temperatureâ€™, â€˜Humidityâ€™, â€˜Windâ€™ and â€˜Playâ€™ (target feature).
    The categorical columns (Outlook & Windy) are encoded using one-hot encoding while
    the numerical columns are scaled using standard scaling (z-normalization).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Main Mechanism
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logistic regression works by applying the logistic function to a linear combination
    of the input features. Hereâ€™s how it operates:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate a weighted sum of the input features (similar to linear regression).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the logistic function (also called sigmoid function) to this sum, which
    maps any real number to a value between 0 and 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Interpret this value as the probability of belonging to the positive class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a threshold (typically 0.5) to make the final classification decision.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/a7075b4e966c4487e4ddf0397a705947.png)'
  prefs: []
  type: TYPE_IMG
- en: For our golf dataset, logistic regression might combine the weather factors
    into a single score, then transform this score into a probability of playing golf.
  prefs: []
  type: TYPE_NORMAL
- en: Training Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The training process for logistic regression involves finding the best weights
    for the input features. Hereâ€™s the general outline:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the weights (often to small random values).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/3b3d36e76e221058bfb5bdef6dbcb540.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '2\. For each training example:'
  prefs: []
  type: TYPE_NORMAL
- en: a. Calculate the predicted probability using the current weights.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ad914e2c81f2ef22d3423c61b065128.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: b. Compare this probability to the actual class label by calculating its log
    loss.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d03bec8cdef352fdd52c9e1cf0a8985b.png)'
  prefs: []
  type: TYPE_IMG
- en: 3\. Update the weights to minimize the loss (usually using some optimization
    algorithm, like gradient descent. This include repeatedly do Step 2 until log
    loss cannot get smaller).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7970c48934b6717e83f2f94d7f770846.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Classification Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the model is trained:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. For a new instance, calculate the probability with the final weights (also
    called coefficients), just like during the training step.
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Interpret the output by seeing the probability: if *p* â‰¥ 0.5, predict class
    1; otherwise, predict class 0'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/99a363cd8b98d3754e27643122b7c9c7.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Evaluation Step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/c7574523a49fa326eb623dcf5cf0d23c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Key Parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logistic regression has several important parameters that control its behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1.Penalty**: The type of regularization to use (â€˜l1â€™, â€˜l2â€™, â€˜elasticnetâ€™,
    or â€˜noneâ€™). Regularization in logistic regression prevents overfitting by adding
    a penalty term to the modelâ€™s loss function, that encourages simpler models.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d6388db7b9a3516fa793253062783429.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**2\. Regularization Strength (C)**: Controls the trade-off between fitting
    the training data and keeping the model simple. A smaller C means stronger regularization.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b456b69f56e095c9ced88959e77bab79.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**3\. Solver:** The algorithm to use for optimization (â€˜liblinearâ€™, â€˜newton-cgâ€™,
    â€˜lbfgsâ€™, â€˜sagâ€™, â€˜sagaâ€™). Some regularization might require a particular algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Max Iterations**: The maximum number of iterations for the solver to
    converge.'
  prefs: []
  type: TYPE_NORMAL
- en: For our golf dataset, we might start with â€˜l2â€™ penalty, â€˜liblinearâ€™ solver,
    and C=1.0 as a baseline.
  prefs: []
  type: TYPE_NORMAL
- en: Pros & Cons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like any algorithm in machine learning, logistic regression has its strengths
    and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pros:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Simplicity**: Easy to implement and understand.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Interpretability**: The weights directly show the importance of each feature.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Efficiency**: Doesnâ€™t require too much computational power.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Probabilistic Output**: Provides probabilities rather than just classifications.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Cons:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Linearity Assumption**: Assumes a linear relationship between features and
    log-odds of the outcome.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Feature Independence**: Assumes features are not highly correlated.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Limited Complexity**: May underfit in cases where the decision boundary is
    highly non-linear.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Requires More Data**: Needs a relatively large sample size for stable results.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In our golf example, logistic regression might provide a clear, interpretable
    model of how each weather factor influences the decision to play golf. However,
    it might struggle if the decision involves complex interactions between weather
    conditions that canâ€™t be captured by a linear model.
  prefs: []
  type: TYPE_NORMAL
- en: Final Remark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression shines as a powerful yet straightforward classification
    tool. It stands out for its ability to handle complex data while remaining easy
    to interpret. Unlike [some other basic models](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e),
    it provides smooth probability estimates and works well with many features. In
    the real world, from predicting customer behavior to medical diagnoses, logistic
    regression often performs surprisingly well. Itâ€™s not just a stepping stone â€”
    itâ€™s a reliable model that can match more complex models in many situations.
  prefs: []
  type: TYPE_NORMAL
- en: ğŸŒŸ Logistic Regression Code Summarized
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a detailed explanation of the [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
    and its implementation in scikit-learn, readers can refer to the official documentation
    [2], which provides comprehensive information on its usage and parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Technical Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  prefs: []
  type: TYPE_NORMAL
- en: About the Illustrations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3954bb576147e89326d88edd83f57b51.png)'
  prefs: []
  type: TYPE_IMG
- en: For a concise visual summary, check out [the companion Instagram post](https://www.instagram.com/p/C_viu8bSXJ8/).
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] T. M. Mitchell, [Machine Learning](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)
    (1997), McGraw-Hill Science/Engineering/Math, pp. 59'
  prefs: []
  type: TYPE_NORMAL
- en: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ˜¾ğ™¡ğ™–ğ™¨ğ™¨ğ™ğ™›ğ™ğ™˜ğ™–ğ™©ğ™ğ™¤ğ™£ ğ˜¼ğ™¡ğ™œğ™¤ğ™§ğ™ğ™©ğ™ğ™¢ğ™¨ ğ™ğ™šğ™§ğ™š:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----81baf5871505--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Classification Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----81baf5871505--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----81baf5871505--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Regression Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----81baf5871505--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This â€œdummyâ€ doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----81baf5871505--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----81baf5871505--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  prefs: []
  type: TYPE_NORMAL
