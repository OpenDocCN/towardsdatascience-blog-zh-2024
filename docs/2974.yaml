- en: 'Synthetic Data in Practice: A Shopify Case Study'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '实践中的合成数据：Shopify案例研究  '
- en: 原文：[https://towardsdatascience.com/synthetic-data-in-practice-a-shopify-case-study-79b0af024880?source=collection_archive---------6-----------------------#2024-12-10](https://towardsdatascience.com/synthetic-data-in-practice-a-shopify-case-study-79b0af024880?source=collection_archive---------6-----------------------#2024-12-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/synthetic-data-in-practice-a-shopify-case-study-79b0af024880?source=collection_archive---------6-----------------------#2024-12-10](https://towardsdatascience.com/synthetic-data-in-practice-a-shopify-case-study-79b0af024880?source=collection_archive---------6-----------------------#2024-12-10)
- en: Testing new Snowflake functionality with a 30k records dataset
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '使用30k条记录数据集测试新的Snowflake功能  '
- en: '[](https://medium.com/@piotr.gruszecki_22364?source=post_page---byline--79b0af024880--------------------------------)[![Piotr
    Gruszecki](../Images/0d8b89957a88b258e87887cf7e1de093.png)](https://medium.com/@piotr.gruszecki_22364?source=post_page---byline--79b0af024880--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--79b0af024880--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--79b0af024880--------------------------------)
    [Piotr Gruszecki](https://medium.com/@piotr.gruszecki_22364?source=post_page---byline--79b0af024880--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@piotr.gruszecki_22364?source=post_page---byline--79b0af024880--------------------------------)[![Piotr
    Gruszecki](../Images/0d8b89957a88b258e87887cf7e1de093.png)](https://medium.com/@piotr.gruszecki_22364?source=post_page---byline--79b0af024880--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--79b0af024880--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--79b0af024880--------------------------------)
    [Piotr Gruszecki](https://medium.com/@piotr.gruszecki_22364?source=post_page---byline--79b0af024880--------------------------------)  '
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--79b0af024880--------------------------------)
    ·13 min read·Dec 10, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--79b0af024880--------------------------------)
    ·13分钟阅读·2024年12月10日  '
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '--  '
- en: '![](../Images/86f740f9908c2f0378251c2b79b24a67.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86f740f9908c2f0378251c2b79b24a67.png)  '
- en: Image created with DALL·E, based on author’s prompt
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '由DALL·E根据作者的提示生成的图像  '
- en: 'Working with data, I keep running into the same problem more and more often.
    On one hand, we have growing requirements for data privacy and confidentiality;
    on the other — the need to make quick, data-driven decisions. Add to this the
    modern business reality: freelancers, consultants, short-term projects.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '在处理数据时，我越来越频繁地遇到同样的问题。一方面，我们对数据隐私和保密性的要求日益增加；另一方面——我们需要快速做出数据驱动的决策。再加上现代商业的现实：自由职业者、顾问和短期项目。  '
- en: 'As a decision maker, I face a dilemma: I need analysis right now, the internal
    team is overloaded, and I can’t just hand over confidential data to every external
    analyst.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '作为决策者，我面临一个两难：我现在需要分析，内部团队已经超负荷工作，而且我不能随便把机密数据交给每一个外部分析师。  '
- en: And this is where synthetic data comes in.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '这就是合成数据的作用所在。  '
- en: 'But wait — I don’t want to write another theoretical article about what synthetic
    data is. There are enough of those online already. Instead, I’ll show you a specific
    comparison: 30 thousand real Shopify transactions versus their synthetic counterpart.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '等等——我不想再写一篇关于合成数据是什么的理论文章了，网上已经有足够多了。相反，我将向你展示一个具体的对比：30,000笔真实的Shopify交易与它们的合成数据对比。  '
- en: What exactly did I check?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '我到底检查了什么？  '
- en: How faithfully does synthetic data reflect real trends?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '合成数据能多忠实地反映真实趋势？  '
- en: Where are the biggest discrepancies?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '最大的差异在哪里？  '
- en: When can we trust synthetic data, and when should we be cautious?
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '我们什么时候可以信任合成数据？又在什么情况下应该谨慎？  '
- en: This won’t be another “how to generate synthetic data” guide (though I’ll show
    the code too). I’m focusing on what really matters — whether this data is actually
    useful and what its limitations are.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '这不会是另一篇“如何生成合成数据”的指南（虽然我也会展示代码）。我关注的是真正重要的——这些数据是否真正有用，它的局限性是什么。  '
- en: I’m a practitioner — less theory, more specifics. Let’s begin.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '我是一个实战派——少说理论，更多具体细节。让我们开始吧。  '
- en: Data Overview
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '数据概览  '
- en: 'When testing synthetic data, you need a solid reference point. In our case,
    we’re working with real transaction data from a growing e-commerce business:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '在测试合成数据时，你需要一个坚实的参考点。在我们的案例中，我们使用的是来自一家成长中的电子商务企业的真实交易数据：  '
- en: 30,000 transactions spanning 6 years
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '30,000笔交易，跨越6年  '
- en: Clear growth trend year over year
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '年年增长趋势明显  '
- en: Mix of high and low-volume sales months
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '销售月份的高低波动混合  '
- en: Diverse geographical spread, with one dominant market
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '多样化的地理分布，其中一个市场占主导地位  '
- en: '![](../Images/31ef72599e5edf82fdb5519351e97c5c.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31ef72599e5edf82fdb5519351e97c5c.png)'
- en: All charts created by author, using his own R code
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所有图表由作者创建，使用他自己的R代码
- en: For practical testing, I focused on transaction-level data such as order values,
    dates, and basic geographic information. Most assessments require only essential
    business information, without personal or product specifics.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实际测试，我专注于交易级数据，如订单金额、日期和基本地理信息。大多数评估只需要基本的业务信息，不涉及个人或产品的详细信息。
- en: 'The procedure was simple: export raw Shopify data, analyze it to maintain only
    the most important information, produce synthetic data in Snowflake, then compare
    the two datasets side by side. One can think of it as generating a “digital twin”
    of your business data, with comparable trends but entirely anonymized.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程很简单：导出原始Shopify数据，分析后仅保留最重要的信息，在Snowflake中生成合成数据，然后将这两个数据集并排比较。可以将其视为生成“数字双胞胎”业务数据，具有可比的趋势，但完全匿名化。
- en: '*[Technical note: If you’re interested in the detailed data preparation process,
    including R code and Snowflake setup, check the appendix at the end of this article.]*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*[技术说明：如果你对详细的数据准备过程感兴趣，包括R代码和Snowflake设置，请查看本文末尾的附录。]*'
- en: Monthly Revenue Analysis
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 月度收入分析
- en: The first test for any synthetic dataset is how well it captures core business
    metrics. Let’s start with monthly revenue — arguably the most important metric
    for any business (for sure in top 3).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 任何合成数据集的首要测试是它能多好地捕捉核心业务指标。让我们从月度收入开始——这无疑是任何业务中最重要的指标之一（肯定排在前三名）。
- en: 'Looking at the raw trends (Figure 1), both datasets follow a similar pattern:
    steady growth over the years with seasonal fluctuations. The synthetic data captures
    the general trend well, including the business’s growth trajectory. However, when
    we dig deeper into the differences, some interesting patterns emerge.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从原始趋势（图1）来看，两个数据集都遵循类似的模式：多年持续增长，并伴有季节性波动。合成数据很好地捕捉了总体趋势，包括业务的增长轨迹。然而，当我们深入探讨差异时，一些有趣的模式浮现出来。
- en: 'To quantify these differences, I calculated a monthly delta:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了量化这些差异，我计算了一个月度变化值：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/b90f2b2c5623a7444841831b96c2d95f.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b90f2b2c5623a7444841831b96c2d95f.png)'
- en: We see from the plot, that monthly revenue delta varies — sometimes original
    is bigger, and sometimes synthetic. But the bars seem to be symmetrical and also
    the differences are getting smaller with time. I added number of records (transactions)
    per month, maybe it has some impact? Let’s dig a bit deeper.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以看到，月度收入变化值是有波动的——有时原始数据更大，有时是合成数据更大。但这些柱状图看起来是对称的，而且随着时间的推移，差异变得越来越小。我增加了每月记录数（交易量），也许它有一些影响？让我们深入探讨一下。
- en: The deltas are indeed quite well balanced, and if we look at the cumulative
    revenue lines, they are very well aligned, without large variations. I am skipping
    this chart.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变化值确实相当平衡，如果我们看累计收入曲线，它们非常吻合，没有大的波动。我跳过这个图表。
- en: Sample Size Impact
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 样本量的影响
- en: The deltas are getting smaller, and we intuitively feel it is because of larger
    number of records. Let us check it — next plot shows absolute values of revenue
    deltas as a function of records per month. While the number of records does grow
    with time, the X axis is not exactly time — it’s the records.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 变化值变小了，我们直觉上觉得是由于记录数的增加。让我们检查一下——下一个图表显示了月度收入变化值的绝对值与每月记录数的关系。虽然记录数随着时间的推移在增长，但X轴实际上并非时间——而是记录数。
- en: '![](../Images/cfe8da970d0b893877a5aa979e66f96a.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfe8da970d0b893877a5aa979e66f96a.png)'
- en: The deltas (absolute values) do decrease, as the number of records per month
    is higher — as we expected. But there is one more thing, quite intriguing, and
    not that obvious, at least at first glance. Above around 500 records per month,
    the deltas do not fall further, they stay at (in average) more or less same level.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变化值（绝对值）确实在减少，因为每月记录数增多——正如我们预期的那样。但还有一件事，相当有趣，而且不那么显而易见，至少在初次看来。每月记录数超过约500条后，变化值不再进一步下降，它们保持在（平均值）大致相同的水平。
- en: 'While this specific number is derived from our dataset and might vary for different
    business types or data structures, the pattern itself is important: there exists
    a threshold where synthetic data stability improves significantly. Below this
    threshold, we see high variance; above it, the differences stabilize but don’t
    disappear entirely — synthetic data maintains some variation by design, which
    actually helps with privacy protection.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个具体数字来源于我们的数据集，并可能因不同的商业类型或数据结构而有所变化，但模式本身是重要的：存在一个阈值，在这个阈值下，合成数据的稳定性显著提高。在这个阈值以下，我们看到较大的方差；而超过阈值后，差异稳定下来，但并未完全消失——合成数据根据设计保持一定的变化，这实际上有助于隐私保护。
- en: There is a noise, which makes monthly values randomized, also with larger samples.
    All, while preserves consistency on higher aggregates (yearly, or cumulative).
    And while reproducing overall trend very well.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 存在噪声，这使得每月的数值变得随机化，尤其在样本较大时。所有这些都同时在较高的汇总（年度或累计）数据上保持一致性，并且能够很好地再现总体趋势。
- en: It would be quite interesting to see similar chart for other metrics and datasets.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果能看到其他指标和数据集的类似图表，将会非常有趣。
- en: We already know revenue delta depends on number of records, but is it just that
    more records in a given month, the higher the revenue of synthetic data? Let us
    find out …
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道收入增量依赖于记录数，但这仅仅是因为某个月份的记录数越多，合成数据的收入就越高吗？让我们来探讨一下…
- en: So we want to check how revenue delta depends on number of records delta. And
    we mean by delta Synthetic-Shopify, whether it is monthly revenue or monthly number
    of records.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们希望检查收入增量如何依赖于记录数增量。我们所说的增量是指Synthetic-Shopify之间的差异，无论是月收入还是月记录数。
- en: The chart below shows exactly this relationship. There is some (light) correlation
    - if number of records per month differ substantially between Synthetic and Shopify,
    or vice-versa (high delta values), the revenue delta follows. But it is far from
    simple linear relationship - there is extra noise there as well.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了这种关系。存在一定的（轻微的）相关性——如果每月记录数在Synthetic和Shopify之间差异显著，或反之（高的增量值），收入的增量也会随之变化。但这远不是简单的线性关系——其中也存在额外的噪声。
- en: '![](../Images/765bdbe50a11b668f852fffec32616f3.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/765bdbe50a11b668f852fffec32616f3.png)'
- en: Dimensional Analysis
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 维度分析
- en: When generating synthetic data, we often need to preserve not just overall metrics,
    but also their distribution across different dimensions like geography. I kept
    country and state columns in our test dataset to see how synthetic data handles
    dimensional analysis.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成合成数据时，我们通常不仅需要保持整体指标，还需要保持它们在不同维度上的分布，比如地理分布。我在我们的测试数据集中保留了国家和州列，以便查看合成数据如何处理维度分析。
- en: 'The results reveal two important aspects:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 结果揭示了两个重要方面：
- en: The reliability of synthetic data strongly depends on the sample size within
    each dimension
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合成数据的可靠性在很大程度上依赖于每个维度内的样本量
- en: Dependencies between dimensions are not preserved
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 维度之间的依赖关系未被保留
- en: 'Looking at revenue by country:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 查看按国家划分的收入：
- en: '![](../Images/3ae2bbb8dc5959e1b5593f23ea6ee3d2.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ae2bbb8dc5959e1b5593f23ea6ee3d2.png)'
- en: For the dominant market with thousands of transactions, the synthetic data provides
    a reliable representation — revenue totals are comparable between real and synthetic
    datasets. However, for countries with fewer transactions, the differences become
    significant.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有成千上万交易的主导市场，合成数据提供了可靠的表示——实际和合成数据集之间的收入总额是可以比较的。然而，对于交易较少的国家，差异变得显著。
- en: 'A critical observation about dimensional relationships: in the original dataset,
    state information appears only for US transactions, with empty values for other
    countries. However, in the synthetic data, this relationship is lost — we see
    randomly generated values in both country and state columns, including states
    assigned to other countries, not US. This highlights an important limitation:
    synthetic data generation does not maintain logical relationships between dimensions.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 关于维度关系的一个关键观察：在原始数据集中，州信息仅出现在美国交易中，其他国家的州信息为空。然而，在合成数据中，这种关系丧失——我们看到在国家和州列中随机生成的值，包括分配给其他国家的州，而非美国。这突显了一个重要的限制：合成数据生成并未保持维度之间的逻辑关系。
- en: There is, however, a practical way to overcome this country-state dependency
    issue. Before generating synthetic data, we could preprocess our input by concatenating
    country and state into a single dimension (e.g., ‘US-California’, ‘US-New York’,
    while keeping just ‘Germany’ or ‘France’ for non-US transactions). This simple
    preprocessing step would preserve the business logic of states being US-specific
    and prevent the generation of invalid country-state combinations in the synthetic
    data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，确实有一种实用的方法可以克服这个国家-州依赖性问题。在生成合成数据之前，我们可以通过将国家和州合并为一个维度来预处理输入（例如，“US-California”，“US-New
    York”，而对于非美国交易，只保留“Germany”或“France”）。这一简单的预处理步骤将保留州是美国特有的业务逻辑，并防止在合成数据中生成无效的国家-州组合。
- en: 'This has important practical implications:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这有重要的实践意义：
- en: Synthetic data works well for high-volume segments
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据在高流量细分市场中效果良好
- en: Be cautious when analyzing smaller segments
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分析较小细分市场时要小心
- en: Always check sample sizes before drawing conclusions
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在得出结论之前，务必检查样本量
- en: Be aware that logical relationships between dimensions may be lost, consider
    pre-aggregation of some columns
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要注意，维度之间的逻辑关系可能会丢失，可以考虑对某些列进行预聚合处理
- en: Consider additional data validation if dimensional integrity is crucial
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果维度完整性至关重要，考虑进行额外的数据验证
- en: Transaction value distribution
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交易价值分布
- en: One of the most interesting findings in this analysis comes from examining transaction
    value distributions. Looking at these distributions year by year reveals both
    the strengths and limitations of synthetic data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这项分析中最有趣的发现之一来自于检查交易价值分布。逐年查看这些分布揭示了合成数据的优点和局限性。
- en: '![](../Images/81ea005b766e189066459f614c5fe583.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81ea005b766e189066459f614c5fe583.png)'
- en: 'The original Shopify data shows what you’d typically expect in e-commerce:
    highly asymmetric distribution with a long tail towards higher values, and distinct
    peaks corresponding to popular single-product transactions, showing clear bestseller
    patterns.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的Shopify数据展示了你在电子商务中通常会遇到的情况：高度不对称的分布，向更高值的长尾，并且有与畅销单品交易相对应的显著峰值，展现了明显的畅销产品模式。
- en: 'The synthetic data tells an interesting story: it maintains very well the overall
    shape of the distribution, but the distinct peaks from bestseller products are
    smoothed out. The distribution becomes more “theoretical”, losing some real-world
    specifics.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据讲述了一个有趣的故事：它很好地保持了分布的整体形状，但来自畅销产品的显著峰值被平滑化了。分布变得更“理论化”，失去了一些现实世界的特征。
- en: 'This smoothing effect isn’t necessarily a bad thing. In fact, it might be preferable
    in some cases:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这种平滑效应不一定是坏事。事实上，在某些情况下，它可能是更可取的：
- en: For general business modeling and forecasting
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一般的商业建模和预测
- en: When you want to avoid overfitting to specific product patterns
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你想避免过拟合于特定的产品模式时
- en: If you’re looking for underlying trends rather than specific product effects
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你关注的是潜在的趋势，而不是具体的产品效果
- en: However, if you’re specifically interested in bestseller analysis or single-product
    transaction patterns, you’ll need to factor in this limitation of synthetic data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你特别关注畅销产品分析或单一产品交易模式，你需要考虑到合成数据的这个局限性。
- en: Knowing, the goal is product analysis, we’d prepare original dataset differently.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 知道我们的目标是产品分析，我们将会以不同的方式准备原始数据集。
- en: To quantify how well the synthetic data matches the real distribution, we’ll
    look at statistical validation in the next section.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了量化合成数据与真实分布的匹配程度，我们将在下一节中讨论统计验证。
- en: Statistical Validation (K-S Test)
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计验证（K-S检验）
- en: Let’s validate our observations with the Kolmogorov-Smirnov test — a standard
    statistical method for comparing two distributions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过科尔莫戈罗夫-斯米尔诺夫检验来验证我们的观察结果——这是一种用于比较两个分布的标准统计方法。
- en: '![](../Images/f4eb956f09eb0fd83d377d84b726b859.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4eb956f09eb0fd83d377d84b726b859.png)'
- en: 'The findings are positive, but what do these figures mean in practice? The
    Kolmogorov-Smirnov test compares two distributions and returns two essential metrics:
    D = 0.012201 (smaller is better, with 0 indicating identical distributions), and
    p-value = 0.0283 (below the normal 0.05 level, indicating statistically significant
    differences).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些发现是积极的，但这些数字在实践中意味着什么呢？科尔莫戈罗夫-斯米尔诺夫检验比较了两个分布并返回了两个重要的指标：D = 0.012201（越小越好，0表示分布完全相同），p值
    = 0.0283（低于通常的0.05水平，表示统计上有显著差异）。
- en: 'While the p-value indicates some variations between distributions, the very
    low D statistic (nearly to 0) verifies the plot’s findings: a near-perfect match
    in the middle, with just slight differences at the extremities. The synthetic
    data captures crucial patterns while keeping enough variance to ensure anonymity,
    making it suitable for commercial analytics.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然p值显示分布之间存在一定的变化，但非常低的D统计量（接近0）验证了图表的发现：中间部分几乎完美匹配，只有在极端值处有轻微差异。合成数据捕捉了关键的模式，同时保持足够的方差以确保匿名性，使其适用于商业分析。
- en: 'In practical terms, this means:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，这意味着：
- en: The synthetic data provides an excellent match in the most important mid-range
    of transaction values
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据在交易值的最重要中间范围内提供了非常匹配的结果
- en: The match is particularly strong where we have the most data points
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该匹配在我们拥有最多数据点的地方特别强
- en: Differences appear mainly in edge cases, which is expected and even desirable
    from a privacy perspective
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 差异主要出现在边缘案例中，这是预期的，甚至从隐私角度来看是可取的
- en: The statistical validation confirms our visual observations from the distribution
    plots
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计验证确认了我们从分布图中获得的视觉观察结果
- en: This kind of statistical validation is crucial before deciding to use synthetic
    data for any specific analysis. In our case, the results suggest that the synthetic
    dataset is reliable for most business analytics purposes, especially when focusing
    on typical transaction patterns rather than extreme values.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这种统计验证在决定是否使用合成数据进行任何特定分析之前至关重要。在我们的案例中，结果表明合成数据集对于大多数商业分析用途是可靠的，尤其是在关注典型交易模式而非极端值时。
- en: Conclusions
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Let’s summarize our journey from real Shopify transactions to their synthetic
    counterpart.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下从真实的Shopify交易到其合成对等物的过程。
- en: Overall business trends and patterns are maintained, including transactions
    value distributions. Spikes are ironed out, resulting in more theoretical distributions,
    while maintaining key characteristics.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 整体业务趋势和模式得以保持，包括交易价值分布。尖峰已被平滑，结果呈现出更加理论化的分布，同时保持关键特征。
- en: Sample size matters, by design. Going too granular we will get noise, preserving
    confidentiality (in addition to removing all PII of course).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 样本大小很重要，这是有意设计的。过于细化会产生噪音，同时确保保密性（当然还会移除所有个人身份信息）。
- en: Dependencies between columns are not preserved (country-state), but there is
    an easy walk around, so I think it is not a real issue.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 列之间的依赖关系未被保留（如国家-州），但有一个简单的解决办法，因此我认为这不是一个真正的问题。
- en: It is important to understand how the generated dataset will be used — what
    kind of analysis we expect, so that we can take it into account while reshaping
    the original dataset.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 了解生成的数据集将如何使用非常重要——我们预期进行什么样的分析，以便在重塑原始数据集时考虑到这一点。
- en: The synthetic dataset will work perfectly for applications testing, but we should
    manually check edge cases, as these might be missed during generation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据集将非常适用于应用程序测试，但我们应该手动检查边缘案例，因为这些在生成过程中可能被遗漏。
- en: In our Shopify case, the synthetic data proved reliable enough for most business
    analytics scenarios, especially when working with larger samples and focusing
    on general patterns rather than specific product-level analysis.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的Shopify案例中，合成数据在大多数商业分析场景中证明是足够可靠的，尤其是在处理较大的样本并专注于一般模式时，而不是特定的产品级别分析。
- en: Future Work
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来工作
- en: This analysis focused on transactions, as one of key metrics and an easy case
    to start with.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本次分析专注于交易，作为一个关键指标和一个易于入手的案例。
- en: We can proceed with products analysis and also explore multi-table scenarios.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续进行产品分析，也可以探索多表场景。
- en: It is also worth to develop internal guidelines how to use synthetic data, including
    check and limitations.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，值得制定内部指南，说明如何使用合成数据，包括检查和限制。
- en: 'Appendix: Data Preparation and Methodology'
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录：数据准备和方法论
- en: You can scroll through this section, as it is quite technical on how to prepare
    data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以浏览这一部分，因为它非常技术性，涉及如何准备数据。
- en: Raw Data Export
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原始数据导出
- en: Instead of relying on pre-aggregated Shopify reports, I went straight for the
    raw transaction data. At Alta Media, this is our standard approach — we prefer
    working with raw data to maintain full control over the analysis process.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有依赖预先汇总的Shopify报告，而是直接使用了原始交易数据。在Alta Media，我们采用的是这种标准方法——我们更倾向于使用原始数据，以保持对分析过程的完全控制。
- en: 'The export process from Shopify is straightforward but not immediate:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 从Shopify导出的过程是直接的，但并非即时的：
- en: Request raw transaction data export from the admin panel
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从管理面板请求导出原始交易数据
- en: Wait for email with download links
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待包含下载链接的电子邮件
- en: Download multiple ZIP files containing CSV data
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载多个包含 CSV 数据的 ZIP 文件
- en: Data Reshaping
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据重塑
- en: I used R for exploratory data analysis, processing, and visualization. The code
    snippets are in R, copied from my working scripts, but of course one can use other
    languages to achieve the same final data frame.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用 R 进行探索性数据分析、处理和可视化。代码片段是 R 语言的，来自我的工作脚本，但当然也可以使用其他语言来实现相同的最终数据框。
- en: The initial dataset had dozens of columns, so the first step was to select only
    the relevant ones for our synthetic data experiment.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 初始数据集有几十列，所以第一步是选择与我们合成数据实验相关的列。
- en: '*Code formatting is adjusted, so that we don’t have horizontal scroll.*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '*代码格式已调整，以便我们避免出现水平滚动条。*'
- en: '[PRE1]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We need one data frame, so we need to combine three files. Since we use data.table
    package, the syntax is very simple. And we pipe combined dataset to trim columns,
    keeping only selected ones.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个数据框，所以我们需要将三个文件合并。由于我们使用的是 `data.table` 包，语法非常简单。然后我们将合并后的数据集通过管道传递，去除不需要的列，仅保留选定的列。
- en: '[PRE2]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s also change column names to single string, replacing spaces with underscore
    “_” — we don’t need to deal with extra quotations in SQL.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将列名更改为单个字符串，用下划线“_”替换空格——这样我们就不需要在 SQL 中处理额外的引号。
- en: '[PRE3]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: I also change transaction id from character “#1234”, to numeric “1234”. I create
    a new column, so we can easily compare if transformation went as expected.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我还将交易 ID 从字符型“#1234”改为数值型“1234”。我创建了一个新列，这样我们就可以轻松比较转换是否按预期进行。
- en: '[PRE4]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Of course you can also overwrite.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你也可以覆盖它。
- en: Extra experimentation
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的实验
- en: Since this was an experiment with Snowflake’s synthetic data generation, I made
    some additional preparations. The Shopify export contains actual customer emails,
    which would be masked in Snowflake while generating synthetic data, but I hashed
    them anyway.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个关于 Snowflake 合成数据生成的实验，我进行了额外的准备工作。Shopify 导出包含了实际客户的电子邮件，而这些电子邮件在 Snowflake
    中生成合成数据时会被屏蔽，但我还是对它们进行了哈希处理。
- en: So I hashed these emails using MD5 and created an additional column with numerical
    hashes. This was purely experimental — I wanted to see how Snowflake handles different
    types of unique identifiers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我使用 MD5 对这些电子邮件进行了哈希处理，并创建了一个包含数字哈希值的额外列。这纯粹是实验性的——我想看看 Snowflake 如何处理不同类型的唯一标识符。
- en: By default, Snowflake masks text-based unique identifiers as it considers them
    personally identifiable information. For a real application, we’d want to remove
    any data that could potentially identify customers.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Snowflake 会将基于文本的唯一标识符进行屏蔽，因为它将其视为个人可识别信息。对于实际应用，我们希望删除任何可能识别客户的数据。
- en: '[PRE5]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: I was also curious how logical column will be handled, so I changed type of
    a binary column, which has “yes/no” values.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我也很好奇逻辑列会如何处理，所以我更改了一个二进制列的类型，该列具有“yes/no”值。
- en: '[PRE6]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Filter transactions
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过滤交易记录
- en: The dataset contains records per each item, while for this particular analysis
    we need only transactions.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含每个项目的记录，而对于这项特定分析，我们只需要交易记录。
- en: '[PRE7]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/505e4fd5854a0a53d702c5419b4b126a.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/505e4fd5854a0a53d702c5419b4b126a.png)'
- en: Final subset of columns and filtering records with total amount paid.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的列子集并过滤支付总额的记录
- en: '[PRE8]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Export dataset
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出数据集
- en: Once we have a dataset, we nee to export it as a csv file. I export full dataset,
    and I also produce a 5% sample, which I use for initial test run in Snowflake.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了数据集，我们需要将其导出为 csv 文件。我导出了完整数据集，并且还生成了一个 5% 的样本，用于在 Snowflake 中的初步测试。
- en: '[PRE9]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: And also saving in Rds format, so I don’t need to repeat all the preparatory
    steps (which are scripted, so they are executed in seconds anyway).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 还将其保存在 Rds 格式中，这样我就不需要重复所有准备步骤（这些步骤是脚本化的，因此无论如何都会在几秒钟内执行）。
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Appendix: Data generation in Snowflake'
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录：在 Snowflake 中生成数据
- en: Once we have our dataset, prepared according to our needs, generation of it’s
    synthetic “sibling” is straightforward. One needs to upload the data, run generation,
    and export results. For details follow Snowflake guidelines. Anyway, I will add
    here short summary, for complteness of this article.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们根据需求准备好数据集，生成其合成的“兄弟”数据集就变得简单了。需要上传数据、运行生成过程并导出结果。有关详细信息，请参考 Snowflake 指南。无论如何，我会在这里简要总结，以完整本文。
- en: First, we need to make some preparations — role, database and warehouse.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要做一些准备工作——角色、数据库和仓库。
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Create schema and stage, if not defined yet.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尚未定义，则创建模式和阶段。
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Upload csv files(s) to stage, and then import them to table(s).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 上传 csv 文件到阶段，然后将它们导入到表中。
- en: Then, run generation of synthetic data. I like having a small “pilot”, somethiong
    like 5% records to make initial check if it goes through. It is a time saver (and
    costs too), in case of more complicated cases, where we might need some SQL adjustment.
    In this case it is rather pro-forma.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，生成合成数据。我喜欢先做一个小的“试点”，比如5%的记录，用来初步检查是否可以通过。这是一个节省时间的办法（也节省成本），尤其是在更复杂的情况下，我们可能需要进行一些SQL调整。在这种情况下，它更多的是形式化操作。  '
- en: '[PRE13]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: It is good to inspect what we have as a result — checking tables directly in
    Snowflake.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '检查我们得到的结果是很有必要的——直接在Snowflake中检查表格。  '
- en: And then run a full dataset.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '然后运行完整的数据集。  '
- en: '[PRE14]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The execution time is non-linear, for the full dataset it is way, way faster
    than what data volume would suggest.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '执行时间是非线性的，对于完整的数据集，它比数据量所暗示的速度要快得多。  '
- en: Now we export files.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们导出文件。  '
- en: 'Some preparations:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '一些准备工作：  '
- en: '[PRE15]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And export (small and full dataset):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '并且导出（小数据集和完整数据集）：  '
- en: '[PRE16]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: So now we have both original Shopify dataset and Synthetic. Time to analyze,
    compare, and make some plots.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在我们有了原始的Shopify数据集和合成数据集。是时候进行分析、比较并绘制一些图表了。
- en: 'Appendix: Data comparison & charting'
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '附录：数据比较与图表  '
- en: 'For this analysis, I used R for both data processing and visualization. The
    choice of tools, however, is secondary — the key is having a systematic approach
    to data preparation and validation. Whether you use R, Python, or other tools,
    the important steps remain the same:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '对于这项分析，我使用了R进行数据处理和可视化。然而，工具的选择并不是最重要的——关键是有一个系统化的数据准备和验证方法。无论你使用R、Python还是其他工具，重要的步骤始终是相同的：  '
- en: Clean and standardize the input data
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '清理并标准化输入数据  '
- en: Validate the transformations
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '验证转化结果  '
- en: Create reproducible analysis
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '创建可重复的分析  '
- en: Document key decisions
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '记录关键决策  '
- en: The detailed code and visualization techniques could indeed be a topic for another
    article.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '详细的代码和可视化技巧实际上可以作为另一篇文章的主题。  '
- en: If you’re interested in specific aspects of the implementation, feel free to
    reach out.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你对实现的特定方面感兴趣，随时可以联系我。  '
