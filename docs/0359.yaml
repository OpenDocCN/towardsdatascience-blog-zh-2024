- en: How AI Can Remove Imperceptible Watermarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-ai-can-remove-imperceptible-watermarks-6b4560ea867a?source=collection_archive---------8-----------------------#2024-02-06](https://towardsdatascience.com/how-ai-can-remove-imperceptible-watermarks-6b4560ea867a?source=collection_archive---------8-----------------------#2024-02-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploring the Vulnerabilities in Detecting AI-Generated Media
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@maxhilsdorf?source=post_page---byline--6b4560ea867a--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page---byline--6b4560ea867a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6b4560ea867a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6b4560ea867a--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page---byline--6b4560ea867a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6b4560ea867a--------------------------------)
    ·8 min read·Feb 6, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df762585aafadbb58ae869e19736266e.png)'
  prefs: []
  type: TYPE_IMG
- en: High-level illustration of how invisible watermarking works. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we Need Watermarks?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Watermarks are all over the internet — and for obvious reasons. How else could
    you protect your art or photography from ending up in someone's PowerPoint presentation
    without crediting the creator? The simplest way of addressing this problem is
    to create visible watermarks like the one below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b1c16dba56bef08ad535cc1002d4871a.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of a visible watermark. Image by author based on DALL-E 3.
  prefs: []
  type: TYPE_NORMAL
- en: The primary downside of this method is that it can compromise the art itself.
    No one would purchase and use the cat image like this. Therefore, while mitigating
    unauthorized copies, perceptible watermarks can also discourage the target audience
    from using the art.
  prefs: []
  type: TYPE_NORMAL
- en: In the music domain, perceptible watermarks are also common in free Hip-Hop
    beats. Beat producers often insert a voice sample with their brand name right
    before the first verse starts. This can serve either as a safeguard against illegal
    downloads or as a marketing tool when the beat is free-to-use.
  prefs: []
  type: TYPE_NORMAL
- en: An example of a Hip-Hop beat with an audible watermark at ~10 seconds. “Solitude”
    by Direct Beats.
  prefs: []
  type: TYPE_NORMAL
- en: For stock photos and Hip-Hop beats alike, a common practice is to place watermarks
    on the online previews and send the original product to clients after payment.
    However, this is also prone to misuse. As soon as the watermark-free product is
    purchased, it can be copied and reuploaded to the internet.
  prefs: []
  type: TYPE_NORMAL
- en: The Case for Imperceptible Watermarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Protection of Intellectual Property
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Imperceptible watermarks come with a distinct advantage: You can prove ownership
    over any digital copy of your product without negatively affecting product quality.
    It’s like a piece of paper with invisible ink on it. The paper is fully functional,
    but it carries a secret message that can be revealed at any time.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0610bdf41567fd854d03cbc4af657f89.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of an imperceptible watermark. Lemon juice can be used as invisible
    ink. It can be made visible through heat. Watch [this video](https://www.youtube.com/watch?v=poCnU_crpjQ)
    for a demonstration. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: With this technology, creators can encode any kind of message within their works.
    More importantly, as they have access to the decoder, they can always assert ownership
    over any digital copy of their original work. Another emerging opportunity for
    rights-holders is to use web crawlers to search the web and report any detected
    misuse.
  prefs: []
  type: TYPE_NORMAL
- en: Detection of AI-Generated Content
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another valuable application for imperceptible watermarks is for detecting AI-generated
    content. The advent of ChatGPT and similar AI tools has raised concerns about
    the potential overflow of dangerous AI-generated content on the internet. Tech
    companies like [Meta](https://about.fb.com/news/2023/12/meta-ai-updates/) or [Google](https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/)
    are bringing forward imperceptible watermarking systems as technological breakthroughs
    to mitigate this problem. Their tools can add watermarks to images or music without
    any noticeable change in quality.
  prefs: []
  type: TYPE_NORMAL
- en: In principle, this is a noteworthy development. With imperceptible watermarks,
    only the owner of the technology can decode and detect the presence of such watermarks.
    Using our example from above, Meta & Google own both the invisible ink and the
    means to reveal it. This allows them to accurately detect and filter content generated
    with their own tools on their platforms (e.g. Instagram, YouTube). Through collaborations,
    even independent platforms like X (former Twitter) could use this tech to limit
    AI-generated misinformation or other harmful content.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef1a586948bbeb3a223889f5becce969.png)'
  prefs: []
  type: TYPE_IMG
- en: AI providers like Meta or Google are building their own watermarking systems
    to detect their own generated content — or sell others the ability to do so. Image
    by author.
  prefs: []
  type: TYPE_NORMAL
- en: How can AI Remove Imperceptible Watermarks?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although imperceptible watermarks sound promising and are being promoted by
    big tech companies, they are far from perfect. In fact, many of these watermarks
    can be reliably removed using smart AI algorithms. But how can AI remove something
    that is imperceptible?
  prefs: []
  type: TYPE_NORMAL
- en: Removing Perceptible Watermarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start by understanding how perceptible watermarks can be removed with
    AI. Let me propose a simple approach: Start by collecting hundreds of thousands
    of images from the web. Then, automatically add artificial watermarks to these
    images. Make sure they resemble real watermarks and cover a wide variety of fonts,
    sizes, and styles. Then, train an AI to remove watermarks by repeatedly showing
    it pairs of the same image — once with and once without the watermark.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are certainly more sophisticated approaches, this illustrates the
    ease with which watermarks can be removed if the AI is trained to recognize their
    appearance or sound. There are numerous tools online that allow me to easily remove
    the watermark from my cat image above:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/585aa311107ff553c3cf7f491b66a5d3.png)'
  prefs: []
  type: TYPE_IMG
- en: Watermark removed using [watermarkremover.io](https://www.watermarkremover.io/).
    In this example, both the image and the watermark are artificial. Please don’t
    use such tools to undermine the intellectual property of others.
  prefs: []
  type: TYPE_NORMAL
- en: Removing Imperceptible Watermarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To employ this simple approach from above, you need to provide the AI with the
    “before and after” examples. However, if the watermarks are imperceptible, how
    can find these examples? Even worse, we can’t even tell if a watermark is present
    or not just by looking at an image or listening to a song.
  prefs: []
  type: TYPE_NORMAL
- en: To solve this problem, researchers had to get creative. Zhao et al., 2023 came
    up with a two-stage procedure.
  prefs: []
  type: TYPE_NORMAL
- en: Destroy the watermark by adding random noise to the image
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reconstruct the real image by using a denoising algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/9909ff42ff21c00a905f97962ce10856.png)'
  prefs: []
  type: TYPE_IMG
- en: Two-stage procedure for removing imperceptible watermarks on images. Adapted
    from Zhao et al., 2023.
  prefs: []
  type: TYPE_NORMAL
- en: This is brilliant, because it challenges the intuition that, in order to remove
    a watermark, you must be able to detect it. This approach can’t locate the watermark.
    However, if the only goal is to remove the watermark, simply destroying it by
    adding enough white noise to the image is quick and effective.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, after adding noise, you might have broken the watermark, but you
    end up with a noisy picture. The most fascinating part is how the authors then
    reconstructed the original image from the noise. For that, they used AI diffusion
    models, such as the ones used in DALL-E 3 or Midjourney. These models generate
    images by iteratively turning random noise into realistic pictures.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bfeeda368bb662cbb1aeaa33915cf22b.png)'
  prefs: []
  type: TYPE_IMG
- en: How diffusion models generate images from noise. Taken from [David Briand](https://www.photoroom.com/inside-photoroom/stable-diffusion-25-percent-faster-and-save-seconds).
  prefs: []
  type: TYPE_NORMAL
- en: As a side effect, diffusion models are also incredibly effective denoising systems,
    both for images and for [audio](https://google-research.github.io/noise2music/).
    By leveraging this technology, anyone can remove imperceptible watermarks using
    this exact two-step procedure.
  prefs: []
  type: TYPE_NORMAL
- en: Does this Mean Imperceptible Watermarks are Useless?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/fc0cecec2d310e531cd896d7df308ee6.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Anthony Tori](https://unsplash.com/@anthonytori?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Yes and no. On the one hand, it seems likely that any imperceptible watermarking
    system invented so far can be broken by bad actors through one method or the other.
    When I posted about this problem on Linkedin for the first time, one person commented:
    “It’s the adblocker blocker blocker game all over again”, and I couldn’t agree
    more.'
  prefs: []
  type: TYPE_NORMAL
- en: The obvious defence against the attack approach proposed by Zhao et al. (2023)
    is to develop an invisible watermarking system that is robust to it. For instance,
    we could train our watermarking system in a way that current SOTA diffusion models
    cannot reconstruct the image well after removing the watermark with random noise.
    Or we could try to build a watermark that is robust to random noise attacks. In
    either case, new vulnerabilities would quickly be found and exploited.
  prefs: []
  type: TYPE_NORMAL
- en: So are imperceptible watermarks simply useless? In a [recent article](https://venturebeat.com/ai/invisible-ai-watermarks-wont-stop-bad-actors-but-they-are-a-really-big-deal-for-good-ones/),
    Sharon Goldman argues that while watermarks might not stop bad actors, they could
    still be beneficial for good actors. They are a bit like metadata, but encoded
    directly into the object of interest. Unlike MP3 metadata, which may be lost when
    the audio is converted to a different format, imperceptible watermarks would always
    be traceable, as they are embedded directly in the music itself.
  prefs: []
  type: TYPE_NORMAL
- en: However, if I am honest with myself, I was hopeful that imperceptible watermarks
    could be a viable solution to flagging and detecting AI-generated content. Apparently,
    I was wrong. These watermarks will not prevent bad actors from flooding the internet
    with harmful AI-generated content, by and large.
  prefs: []
  type: TYPE_NORMAL
- en: How Else Can We Prove Ownership in the AI Era?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/aaf55576dcd8e072ac6799d55652d8a7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the author using DALL-E 3.
  prefs: []
  type: TYPE_NORMAL
- en: Development of Countermeasures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As highlighted above, developing countermeasures to known attack algorithms
    is always an option. In many cases, however, it is easier for the attackers to
    iterate on their attack algorithms than for the defenders to develop safeguards.
    Still, we can’t neglect the possibility that we might discover a new approach
    to watermarking that isn’t as easily breakable. It is therefore definitely worth
    investing time and resources into further research on this topic.
  prefs: []
  type: TYPE_NORMAL
- en: Legal Consequences Against Watermark Attackers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While generating images with AI and uploading them to a social media platform
    is generally not considered illegal, purposefully removing watermarks from AI-generated
    images could very well be. Having no legal expertise myself, I can only argue
    that it would make sense to threaten legal consequences against such malicious
    actions.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the normal users resharing images they found online should be excluded
    from this. However, purposefully removing watermarks to spread misinformation
    is clearly immoral. And even if legal pressure will not eradicate misuse (it never
    has), it can be one mitigating factor.
  prefs: []
  type: TYPE_NORMAL
- en: Rethinking Proofs of Ownership
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many approaches exist around how blockchain technology and/or smart contracts
    could help prove ownership in the digital age. A blockchain, in simple terms,
    is a information storage that tracks interactions between members of a network.
    Each transaction can be uniquely identified and can’t be manipulated at any later
    point in time. Adding smart contracts to this network allows us to connect transactions
    to binding responsibilities that are automatically fulfilled once the transaction
    is done.
  prefs: []
  type: TYPE_NORMAL
- en: In less abstract terms, blockchains and smart contracts could be used in the
    future to automate ownership checks or royalty payments for intellectual property
    in any shape or form. So far, no such system has found widespread adoption. Still,
    we might be only a few technical breakthroughs away from these technologies becoming
    invaluable assets in our economies.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Digital watermarks have been used since the the early days of the internet to
    prevent misuse of intellectual property such as images or music. Recently, it
    has been discussed as a method for flagging and detecting AI generated content.
    However, it turns out that AI is not only great at generating fake images. It
    is just as good at removing any kind of watermark on these images, rendering most
    detection systems useless.
  prefs: []
  type: TYPE_NORMAL
- en: It is clear that we can’t let this discourage us in searching for alternative
    ways of proving ownership in the age of AI. By developing concrete technical and
    legal countermeasures and, at the same time, exploring how blockchains and/or
    smart contracts could be leveraged in the future, we might just figure out how
    to solve this important problem.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Zhao et al., 2023\. Invisible Image Watermarks Are Provably Removable Using
    Generative AI. [https://arxiv.org/pdf/2306.01953.pdf](https://arxiv.org/pdf/2306.01953.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: About Me
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I’m a musicologist and a data scientist, sharing my thoughts on current topics
    in AI & music. Here is some of my previous work related to this article:'
  prefs: []
  type: TYPE_NORMAL
- en: '**3 Music AI Breakthroughs to Expect in 2024:** [https://towardsdatascience.com/3-music-ai-breakthroughs-to-expect-in-2024-2d945ae6b5fd](/3-music-ai-breakthroughs-to-expect-in-2024-2d945ae6b5fd)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How Meta’s AI Generates Music Based on a Reference Melody**: [https://medium.com/towards-data-science/how-metas-ai-generates-music-based-on-a-reference-melody-de34acd783](https://medium.com/towards-data-science/how-metas-ai-generates-music-based-on-a-reference-melody-de34acd783)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AI Music Source Separation: How it Works and Why it is so Hard**: [https://medium.com/towards-data-science/ai-music-source-separation-how-it-works-and-why-it-is-so-hard-187852e54752](https://medium.com/towards-data-science/ai-music-source-separation-how-it-works-and-why-it-is-so-hard-187852e54752)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find me on [Medium](https://medium.com/@maxhilsdorf) and [Linkedin](https://www.linkedin.com/in/max-hilsdorf/)!
  prefs: []
  type: TYPE_NORMAL
