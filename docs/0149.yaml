- en: Supervised Fine-Tuning (SFT) with Large Language Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/supervised-fine-tuning-sft-with-large-language-models-0c7d66a26788?source=collection_archive---------5-----------------------#2024-01-16](https://towardsdatascience.com/supervised-fine-tuning-sft-with-large-language-models-0c7d66a26788?source=collection_archive---------5-----------------------#2024-01-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Understanding how SFT works from idea to a working implementation…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page---byline--0c7d66a26788--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page---byline--0c7d66a26788--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0c7d66a26788--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0c7d66a26788--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page---byline--0c7d66a26788--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0c7d66a26788--------------------------------)
    ·15 min read·Jan 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a8b71e93af85d8dfd9d788819ccea379.png)'
  prefs: []
  type: TYPE_IMG
- en: (Photo by [Chris Ried](https://unsplash.com/@cdr6934?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/a-computer-screen-with-a-bunch-of-code-on-it-ieic5Tq8YMk?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash))
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) are typically trained in several stages, including
    pretraining and several fine-tuning stages; see below. Although [pretraining is
    expensive](https://www.mosaicml.com/blog/gpt-3-quality-for-500k) (i.e., several
    hundred thousand dollars in compute), fine-tuning an LLM (or performing in-context
    learning) is cheap in comparison (i.e., several hundred dollars, or less). Given
    that high-quality, pretrained LLMs (e.g., MPT, Falcon, or LLAMA-2) are widely
    available and free to use (even commercially), we can build a variety of powerful
    applications by fine-tuning LLMs on relevant tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/664dbe43ffcc4d04191d6328b399634c.png)'
  prefs: []
  type: TYPE_IMG
- en: Different stages of training an LLM (created by author)
  prefs: []
  type: TYPE_NORMAL
- en: One of the most widely-used forms of fine-tuning for LLMs within recent AI research
    is supervised fine-tuning (SFT). This approach curates a dataset of high-quality
    LLM outputs over which the model is directly fine-tuned using a standard language
    modeling objective. SFT is simple/cheap to use and a useful tool for aligning
    language models, which has made is popular within the open-source LLM research
    community and beyond. Within this overview, we will outline the idea behind SFT,
    look at relevant…
  prefs: []
  type: TYPE_NORMAL
