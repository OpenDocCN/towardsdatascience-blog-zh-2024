- en: 'Interpreting R²: a Narrative Guide for the Perplexed'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解读 R²：迷惑者的叙述指南
- en: 原文：[https://towardsdatascience.com/interpreting-r%C2%B2-a-narrative-guide-for-the-perplexed-086a9a69c1ec?source=collection_archive---------3-----------------------#2024-02-19](https://towardsdatascience.com/interpreting-r%C2%B2-a-narrative-guide-for-the-perplexed-086a9a69c1ec?source=collection_archive---------3-----------------------#2024-02-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/interpreting-r%C2%B2-a-narrative-guide-for-the-perplexed-086a9a69c1ec?source=collection_archive---------3-----------------------#2024-02-19](https://towardsdatascience.com/interpreting-r%C2%B2-a-narrative-guide-for-the-perplexed-086a9a69c1ec?source=collection_archive---------3-----------------------#2024-02-19)
- en: An accessible walkthrough of fundamental properties of this popular, yet often
    misunderstood metric from a predictive modeling perspective
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从预测性建模的角度出发，对这一流行但常被误解的指标的基本性质进行易于理解的讲解
- en: '[](https://medium.com/@rbrrcc?source=post_page---byline--086a9a69c1ec--------------------------------)[![Roberta
    Rocca](../Images/dca9384fdc5d7c8aa9c01ee2aeccb787.png)](https://medium.com/@rbrrcc?source=post_page---byline--086a9a69c1ec--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--086a9a69c1ec--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--086a9a69c1ec--------------------------------)
    [Roberta Rocca](https://medium.com/@rbrrcc?source=post_page---byline--086a9a69c1ec--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@rbrrcc?source=post_page---byline--086a9a69c1ec--------------------------------)[![Roberta
    Rocca](../Images/dca9384fdc5d7c8aa9c01ee2aeccb787.png)](https://medium.com/@rbrrcc?source=post_page---byline--086a9a69c1ec--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--086a9a69c1ec--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--086a9a69c1ec--------------------------------)
    [Roberta Rocca](https://medium.com/@rbrrcc?source=post_page---byline--086a9a69c1ec--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--086a9a69c1ec--------------------------------)
    ·15 min read·Feb 19, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--086a9a69c1ec--------------------------------)
    ·阅读时长：15分钟·2024年2月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/bf7c9d2b9af55c745a8b08153db33da0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf7c9d2b9af55c745a8b08153db33da0.png)'
- en: Photo by [Josh Rakower](https://unsplash.com/@joshrako?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Josh Rakower](https://unsplash.com/@joshrako?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: R² (R-squared), also known as the *coefficient of determination*, is widely
    used as a metric to evaluate the performance of regression models. It is commonly
    used to quantify *goodness of fit* in statistical modeling, and it is a default
    scoring metric for regression models both in popular statistical modeling and
    machine learning frameworks, from *statsmodels* to *scikit-learn*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: R²（R平方），也称为*决定系数*，广泛用于作为回归模型性能的评估指标。它通常用于量化统计建模中的*拟合优度*，并且是回归模型在流行的统计建模和机器学习框架中的默认评分指标，从*statsmodels*到*scikit-learn*。
- en: Despite its omnipresence, there is a surprising amount of confusion on what
    R² truly means, and it is not uncommon to encounter conflicting information (for
    example, concerning the upper or lower bounds of this metric, and its interpretation).
    At the root of this confusion is a “culture clash” between the explanatory and
    predictive modeling tradition. In fact, in predictive modeling — where evaluation
    is conducted out-of-sample and any modeling approach that increases performance
    is desirable — many properties of R² that do apply in the narrow context of explanation-oriented
    linear modeling no longer hold.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 R² 无处不在，但关于它究竟意味着什么，仍然存在相当多的混淆，遇到相互矛盾的信息并不罕见（例如，关于该指标的上限或下限，以及它的解释）。这种混淆的根源在于解释性建模和预测性建模传统之间的“文化冲突”。实际上，在预测性建模中——即评估是在样本外进行的，任何能提高性能的建模方法都是可取的——许多
    R² 的性质，在狭义的解释导向的线性建模上下文中适用，但在此情境下已不再成立。
- en: To help navigate this confusing landscape, this post provides an accessible
    narrative primer to some basic properties of R² from a predictive modeling perspective,
    highlighting and dispelling common confusions and misconceptions about this metric.
    With this, I hope to help the reader to converge on a unified intuition of what
    R² truly captures as a measure of fit in predictive modeling and machine learning,
    and to highlight some of this metric’s strengths and limitations. Aiming for a
    broad audience which includes Stats 101 students and predictive modellers alike,
    I will keep the language simple and ground my arguments into concrete visualizations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助理解这一混乱的情况，本文提供了一份易于理解的 R² 基本属性介绍，从预测建模的角度出发，重点揭示并澄清了关于这个指标的常见困惑和误解。通过这篇文章，我希望能帮助读者形成关于
    R² 作为预测建模和机器学习中拟合度衡量指标的统一直觉，并强调该指标的一些优缺点。本文面向广泛的读者群体，包括统计学入门学生和预测建模专家，我将保持语言简单，并通过具体的可视化图示来支撑我的论点。
- en: Ready? Let’s get started!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好了吗？我们开始吧！
- en: What is R²?
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 R²？
- en: 'Let’s start from a working verbal definition of R². To keep things simple,
    let’s take the first high-level definition given by [Wikipedia](https://en.wikipedia.org/wiki/Coefficient_of_determination),
    which is a good reflection of definitions found in many pedagogical resources
    on statistics, including authoritative textbooks:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的口头定义开始。为了简化问题，我们采用 [Wikipedia](https://en.wikipedia.org/wiki/Coefficient_of_determination)
    给出的第一个高层次定义，它很好地反映了许多统计学教学资源中所找到的定义，包括权威的教科书：
- en: the proportion of the variation in the dependent variable that is predictable
    from the independent variable(s)
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从自变量预测因变量变化的比例
- en: Anecdotally, this is also what the vast majority of students trained in using
    statistics for inferential purposes would probably say, if you asked them to define
    R². But, as we will see in a moment, this common way of defining R² is the source
    of many of the misconceptions and confusions related to R². Let’s dive deeper
    into it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 据经验，如果你问大多数受过统计推断训练的学生如何定义 R²，他们可能会这么回答。但正如我们接下来会看到的，这种常见的定义方式是导致许多与 R² 相关的误解和困惑的根源。让我们深入探讨一下。
- en: 'Calling R² a *proportion* implies that R² will be a number between 0 and 1,
    where 1 corresponds to a model that explains *all the variation* in the outcome
    variable, and 0 corresponds to a model that explains *no variation* in the outcome
    variable. Note: your model might also include no predictors (e.g., an intercept-only
    model is still a model), that’s why I am focusing on variation predicted by a
    model rather than by independent variables.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 叫 R² 为*比例*意味着 R² 将是一个介于 0 和 1 之间的数字，其中 1 对应于一个解释了*因变量所有变化*的模型，而 0 对应于一个解释了*因变量没有变化*的模型。注意：你的模型也可能不包含任何预测变量（例如，仅包含截距的模型仍然是一个模型），这就是为什么我将重点放在模型所预测的变化上，而不是独立变量所预测的变化上。
- en: 'Let’s verify if this intuition on the range of possible values is correct.
    To do so, let’s recall the mathematical definition of R²:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证一下关于可能值范围的直觉是否正确。为此，让我们回顾一下 R² 的数学定义：
- en: '![](../Images/9af1218a8d2199939b3793b5be762441.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9af1218a8d2199939b3793b5be762441.png)'
- en: 'Here, RSS is the residual sum of squares, which is defined as:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，RSS 是残差平方和，其定义为：
- en: '![](../Images/7667e41ecf0e08350840411951cc42c4.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7667e41ecf0e08350840411951cc42c4.png)'
- en: This is simply the **sum of squared errors of the model**, that is the sum of
    squared differences between true values *y* and corresponding model predictions
    *ŷ*.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是**模型的平方误差和**，即真实值 *y* 和相应模型预测值 *ŷ* 之间平方差的总和。
- en: 'On the other hand, TSS, the total sum of squares, is defined as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，TSS，即总平方和，定义如下：
- en: '![](../Images/416903b5803d98b4196af1ef52f2e22d.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/416903b5803d98b4196af1ef52f2e22d.png)'
- en: 'As you might notice, this term has a similar “form” than the residual sum of
    squares, but this time, we are looking at the squared differences between the
    true values of the outcome variables *y* and *the mean of the outcome variable*
    ȳ. This is technically the *variance* of the outcome variable. But a more intuitive
    way to look at this in a predictive modeling context is the following: this term
    is the residual sum of squares of a model that always predicts the mean of the
    outcome variable. Hence, **the ratio of RSS and TSS is a ratio between the sum
    of squared errors of your model, and the sum of squared errors of a “reference”
    model predicting the mean of the outcome variable**.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能注意到的，这个项与残差平方和的“形式”类似，但这次我们关注的是结果变量*y*与结果变量的均值ȳ之间的平方差。这在技术上是结果变量的*方差*。但是，在预测建模的背景下，更直观的理解方式是：这个项是一个模型的残差平方和，该模型总是预测结果变量的均值。因此，**残差平方和与总平方和的比率是你的模型的平方误差之和与一个“参考”模型预测结果变量均值的平方误差之和之间的比率**。
- en: With this in mind, let’s go on to analyse what the range of possible values
    for this metric is, and to verify our intuition that these should, indeed, range
    between 0 and 1.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个思考，我们继续分析这个指标的可能值范围，并验证我们的直觉，认为这些值应该确实在0到1之间。
- en: What is the best possible R²?
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最好的R²值是多少？
- en: As we have seen so far, R² is computed by subtracting the ratio of RSS and TSS
    from 1\. Can this ever be higher than 1? Or, in other words, is it true that 1
    is the largest possible value of R²? Let’s think this through by looking back
    at the formula.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，R²是通过从1中减去RSS与TSS的比率来计算的。那么，R²能否大于1？换句话说，1是否是R²的最大可能值？让我们通过回顾公式来思考这个问题。
- en: The only scenario in which1 minus *something* can be higher than 1 is if that
    *something* is a *negative* number. But here, RSS and TSS are both sums of squared
    values, that is, sums of positive values. The ratio of RSS and TSS will thus *always*
    be positive. The largest possible R² must therefore be 1.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一一种情况下，1减去*某个值*能大于1，那就是这个*某个值*是一个*负数*。但是在这里，RSS和TSS都是平方和，即正值的和。因此，RSS和TSS的比率*总是*正数。因此，最大可能的R²必须是1。
- en: Now that we have established that R² cannot be higher than 1, let’s try to visualize
    what needs to happen for our model to have the maximum possible R². For R² to
    be 1, RSS / TSS must be zero. This can happen if RSS = 0, that is, if the model
    predicts all data points *perfectly.*
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了R²不能大于1，让我们试着可视化一下，模型需要怎样才能达到最大可能的R²。为了使R²为1，RSS / TSS必须为零。这可能发生在RSS
    = 0时，也就是说，如果模型*完美地*预测了所有数据点。
- en: '![](../Images/38ec206d4b5fc43ebe9200e04346a8a8.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38ec206d4b5fc43ebe9200e04346a8a8.png)'
- en: Examples illustrating hypothetical models with R² ≈ 1 using simulated data.
    In all cases, the true underlying model is y = 2x + 3\. The first two models fit
    the data perfectly, in the first case because the data has no noise and a linear
    model can retrieve perfectly the relation between x and y (left) and in the second
    because the model is very *flexible and overfits the data (center). These are
    extreme cases which are hardly found in reality. In fact, the largest possible*
    R² will often be defined by the amount of noise if the data*. This is illustrated
    by the third plot, where due to the presence of random noise, even the true model
    can only achieve* R² = 0.458.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模拟数据，举例说明了R² ≈ 1的假设模型。在所有案例中，真实的底层模型是y = 2x + 3。前两个模型完美拟合数据，第一种情况是因为数据没有噪声，线性模型能够完美地恢复x与y之间的关系（左），第二种情况是因为模型非常*灵活且过拟合数据*（中）。这些是极端的案例，在现实中很难找到。事实上，最大可能的*R²通常由数据中的噪声量来定义*。第三个图展示了这一点，由于存在随机噪声，即使是真实模型也只能达到*R²
    = 0.458*。
- en: In practice, this will never happen, unless you are *wildly* overfitting your
    data with an overly complex model, or you are computing R² on a ridiculously low
    number of data points that your model can fit perfectly. All datasets will have
    *some* amount of noise that *cannot* be accounted for by the data. In practice,
    the largest possible R² will be defined by the amount of unexplainable noise in
    your outcome variable.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，除非你*极度*过拟合你的数据，使用过于复杂的模型，或者你正在对一个数据点极少的、你的模型能够完美拟合的数据集计算R²，否则这种情况永远不会发生。所有数据集都会有*一些*无法通过数据解释的噪声。在实际应用中，最大可能的R²将由结果变量中无法解释的噪声量来定义。
- en: What is the worst possible R²?
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最差的R²值是多少？
- en: So far so good. If the largest possible value of R² is 1, we can still think
    of R² as the proportion of variation in the outcome variable explained by the
    model. But let’s now move on to looking at the lowest possible value. If we buy
    into the definition of R² we presented above, then we must assume that the lowest
    possible R² is 0.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切都很好。如果R²的最大可能值为1，我们仍然可以将R²视为模型解释的结果变量变异的比例。但现在让我们来看看R²的最小可能值。如果我们接受上面我们提出的R²定义，那么我们必须假设R²的最小可能值是0。
- en: When is R² = 0? For R² to be null, RSS/TSS must be equal to 1\. This is the
    case if RSS = TSS, that is, if the sum of squared errors of our model is equal
    to the sum of squared errors of a model predicting the mean. If you are better
    off just predicting the mean, then your model is really not doing a terribly good
    job. There are infinitely many reasons why this can happen, one of these being
    an issue with your choice of model — if, for example, if you are trying to model
    really non-linear data with a linear model. Or it can be a consequence of your
    data. If your outcome variable is very noisy, then a model predicting the mean
    might be the best you can do.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: R²何时为0？要使R²为零，RSS/TSS必须等于1。这种情况发生在RSS = TSS时，也就是说，如果我们模型的平方误差之和等于预测均值模型的平方误差之和。如果你仅仅预测均值会更好，那么你的模型确实没有做得非常好。造成这种情况的原因有无数种，其中之一可能是你选择的模型存在问题——例如，如果你试图用线性模型拟合真正的非线性数据。或者这可能是数据本身的结果。如果你的结果变量非常嘈杂，那么预测均值的模型可能是你能做的最好的模型。
- en: '![](../Images/2e8e0bdb87e615aa2723926b1987aba4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e8e0bdb87e615aa2723926b1987aba4.png)'
- en: 'Two cases where the mean model might be the best *possible* (linear) models
    because: a) data is pure Gaussian noise (left); b) the data is highly non-linear,
    as it is *generated using a periodic function (right).*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 两种情况，其中均值模型可能是最佳的*（线性）*模型，因为：a) 数据是纯高斯噪声（左）；b) 数据是高度非线性的，因为它是*由周期函数生成的（右）。*
- en: But is R² = 0 truly the lowest possible R²? Or, in other words, can R² ever
    be negative? Let’s look back at the formula. R² < 0 is only possible if RSS/TSS
    > 1, that is, if RSS > TSS. Can this ever be the case?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，R² = 0真的是可能的最小R²吗？换句话说，R²是否有可能为负值？让我们回过头来看一下公式。R² < 0只有在RSS/TSS > 1时才有可能，即，如果RSS
    > TSS。这种情况可能发生吗？
- en: This is where things start getting interesting, as the answer to this question
    depends very much on contextual information that we have notyet specified, namely
    which type of models we are considering, and which datawe are computing R² on.
    As we will see, whether our interpretation of R² as the proportion of variance
    explained holds depends on our answer to these questions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这时事情开始变得有趣，因为这个问题的答案在很大程度上取决于我们尚未指定的背景信息，即我们正在考虑哪种类型的模型，以及我们在哪些数据上计算R²。正如我们将看到的，我们对R²作为方差解释比例的理解是否成立，取决于我们对这些问题的回答。
- en: The bottomless pit of negative R²
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负R²的无底洞
- en: Let’s looks at a concrete case. Let’s generate some data using the following
    model *y = 3 + 2x*, and added Gaussian noise.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个具体的例子。我们使用以下模型*y = 3 + 2x*生成一些数据，并添加了高斯噪声。
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The figure below displays three models that make predictions for *y* based on
    values of *x* for different, randomly sampled subsets of this data. These models
    are not made-up models, as we will see in a moment, but let’s ignore this right
    now. Let’s focus simply on the sign of their R².
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图显示了三个模型，这些模型基于不同随机抽样的数据子集，预测*y*的值。这些模型不是虚构的模型，正如我们稍后将看到的那样，但现在让我们忽略这一点。我们仅仅关注它们的R²的符号。
- en: '![](../Images/2482ed6e603f62a8d97c8d4bec1c8f70.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2482ed6e603f62a8d97c8d4bec1c8f70.png)'
- en: 'Three examples of models for data generated using the function: y = 3 + 2x,
    with added Gaussian noise.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用函数y = 3 + 2x（并加入高斯噪声）生成的数据的三个模型示例。
- en: 'Let’s start from the first model, a simple model that predicts a constant,
    which in this case is lower than the mean of the outcome variable. Here, our RSS
    will be the sum of squared distances between each of the dots and the orange line,
    while TSS will be the sum of squared distances between each of the dots and the
    blue line (the meanmodel). It is easy to see that for most of the data points,
    the distance between the dots and the orange line will be higher than the distance
    between the dots and the blue line. Hence, our RSS will be higher than our TSS.
    If this is the case, we will have RSS/TSS > 1, and, therefore: 1 — RSS/TSS < 0,
    that is, R²<0.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一个模型开始，这是一个简单的常数预测模型，在这个例子中该常数低于结果变量的均值。在这里，我们的RSS将是每个数据点与橙色线之间的平方距离之和，而TSS将是每个数据点与蓝色线（均值模型）之间的平方距离之和。很容易看出，对于大多数数据点，数据点与橙色线之间的距离将大于数据点与蓝色线之间的距离。因此，我们的RSS将大于我们的TSS。如果是这种情况，我们将得到RSS/TSS
    > 1，因此：1 — RSS/TSS < 0，也就是说，R² < 0。
- en: 'In fact, if we compute R² for this model on this data, we obtain R² = -2.263\.
    If you want to check that it is in fact realistic, you can run the code below
    (due to randomness, you will likely get a similarly negative value, but not exactly
    the same value):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果我们计算这个模型在此数据上的R²，我们得到R² = -2.263。如果你想验证它是否真实，你可以运行下面的代码（由于随机性，你可能会得到一个类似的负值，但不会完全相同）：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s now move on to the second model. Here, too, it is easy to see that distances
    between the data points and the red line (our target model) will be larger than
    distances between data points and the blue line (the mean model). In fact, here:
    R²= -3.341\. Note that our target model is different from the *true* model (the
    orange line) because we have fitted it on a subset of the data that also includes
    noise. We will return to this in the next paragraph.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续讨论第二个模型。在这里，同样容易看出数据点与红线（我们的目标模型）之间的距离将大于数据点与蓝线（均值模型）之间的距离。事实上，在这里：R²
    = -3.341。注意，我们的目标模型与*真实*模型（橙色线）不同，因为我们在包括噪音的子集数据上进行了拟合。我们将在下一段中进一步讨论这一点。
- en: Finally, let’s look at the last model. Here, we fit a 5-degree polynomial model
    to a subset of the data generated above. The distance between data points and
    the fitted function, here, is *dramatically* higher than the distance between
    the data points and the mean model. In fact, our fitted model yields R² = -1540919.225.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看最后一个模型。在这里，我们对上述生成的数据子集拟合了一个5次多项式模型。此时，数据点与拟合函数之间的距离比数据点与均值模型之间的距离*显著*更大。事实上，我们拟合的模型得出
    R² = -1540919.225。
- en: 'Clearly, as this example shows, models *can* have a negative R². In fact, there
    is no limit to how low R² can be. Make the model bad enough, and your R² can approach
    minus infinity. This can also happen with a simple linear model: further increase
    the value of the slope of the linear model in the second example, and your R²
    will keep going down. So, where does this leave us with respect to our initial
    question, namely whether R² is in fact that proportion of variance in the outcome
    variable that can be accounted for by the model?'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，正如这个例子所展示的，模型*确实*可以有负的R²。事实上，R²的值没有下限。将模型做得足够糟糕，R²可以接近负无穷大。这在简单线性模型中也可能发生：进一步增加第二个例子中线性模型斜率的值，R²将继续下降。那么，这对于我们最初的问题——即R²是否真的表示模型能够解释的结果变量方差的比例——意味着什么呢？
- en: Well, we don’t tend to think of proportions as arbitrarily large negative values.
    If are really attached to the original definition, we could, with a creative leap
    of imagination, extend this definition to covering scenarios where arbitrarily
    bad models can *add* varianceto your outcome variable. The inverse proportion
    of variance *added* by your model (e.g., as a consequence of poor model choices,
    or overfitting to different data) is what is reflected in arbitrarily low negative
    values.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我们通常不会将比例看作是任意大的负值。如果我们真的对原始定义有所依赖，我们可以通过富有创意的想象力将这个定义扩展到涵盖那些模型表现极差、能*增加*结果变量方差的情境。模型*增加*的方差反比（例如，作为糟糕模型选择或过拟合不同数据的结果）在极低负值中有所体现。
- en: But this is more of a metaphor than a definition. Literary thinking aside, the
    most literal and most productive way of thinking about R² is as a comparativemetric,
    which says something about how much better (on a scale from 0 to 1) or worse(on
    a scale from 0 to infinity) your model is at predicting the data *compared to
    a model which always predicts the mean of the outcome variable*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 但这更多的是一种比喻，而非定义。抛开文学思维不谈，最字面且最具生产力的思考方式是将 R² 视为一种比较度量，它说明了你的模型在预测数据时有多好（从 0
    到 1 的范围内）或多差（从 0 到无穷大），*相较于一个总是预测结果变量均值的模型*。
- en: Importantly, what this suggests, is that while R² can be a tempting way to evaluate
    your model in a scale-independent fashion, and while it might makes sense to use
    it as a comparative metric, it is a far from transparent metric. The value of
    R² will not provide explicit information of how wrong your model is in absolute
    terms; the best possible value will always be dependent on the amount of noise
    present in the data; and good or bad R² can come about from a wide variety of
    reasons that can be hard to disambiguate without the aid of additional metrics.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，这表明，虽然 R² 可能是一个诱人的方式来以独立于尺度的方式评估模型，并且作为比较度量使用它可能是有意义的，但它远不是一个透明的度量标准。R²
    的值不会提供关于你的模型在绝对意义上有多错的明确指示；最佳值始终会依赖于数据中噪声的大小；而良好或差的 R² 可能来自多种原因，而没有额外的度量工具，很难分辨清楚。
- en: Alright, R² can be negative. But does this ever happen, in practice?
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 好的，R² 可以是负数。但在实践中，这种情况会发生吗？
- en: A very legitimate objection, here, is whether any of the scenarios displayed
    above is actually plausible. I mean, which modeller in their right mind would
    actually fit such *poor* models to such simple data? These might just look like
    *ad hoc* models, made up for the purpose of this example and not actually fit
    to any data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常合理的反对意见是，上述展示的场景是否实际可行。我是说，哪个理智的建模者会对如此简单的数据拟合出这样*差劲*的模型呢？这些看起来可能只是为了这个例子而人为构建的*特设*模型，并没有真正拟合任何数据。
- en: This is an excellent point, and one that brings us to another crucial point
    related to R² and its interpretation. As we highlighted above, all these models
    *have*, in fact, been fit to data which are generated from the same true underlying
    function as the data in the figures. This corresponds to the practice, foundational
    to predictive modeling, of splitting data intro a *training set* and a *test set*,
    where the former is used to estimate the model, and the latter for evaluation
    on unseen data — which is a “fairer” proxy for how well the model generally performs
    in its prediction task.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常好的观点，它引出了另一个与 R² 及其解释相关的关键问题。正如我们上面所强调的，所有这些模型*实际上*都是拟合于从与图中数据相同的真实基础函数生成的数据。这对应了预测建模中一个基础性的做法，即将数据分为*训练集*和*测试集*，前者用于估计模型，后者用于在未见数据上进行评估——这是评估模型在预测任务中表现的一个“更公正”的代理。
- en: In fact, if we display the models introduced in the previous section against
    the data used to estimate them, we see that they are not *unreasonable* models
    in relation to their training data. In fact, R² values for the training set are,
    at least, non-negative (and, in the case of the linear model, very close to the
    R² of the true model on the test data).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果我们将前一节中介绍的模型与用于估计它们的数据进行对比，会发现它们对于其训练数据来说并不是*不合理*的模型。事实上，训练集的 R² 值至少是非负的（在线性模型的情况下，其
    R² 值非常接近真实模型在测试数据上的 R²）。
- en: '![](../Images/129d5a1dd5d05a54ad94720c75a90e82.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/129d5a1dd5d05a54ad94720c75a90e82.png)'
- en: Same functions displayed in the previous figure, this time displayed against
    the data they were fit on, which were generated with the same true function y
    = 3 + 2x. For the first model, which predicts a constant, model “fitting” simply
    consists of calculating the mean of the training set.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 与前图中展示的相同函数，这次是将其与拟合数据进行对比，这些数据是通过相同的真实函数 y = 3 + 2x 生成的。对于第一个模型，它预测的是一个常数，模型的“拟合”仅仅是计算训练集的均值。
- en: Why, then, is there such a big difference between the previous data and this
    data? What we are observing are cases of *overfitting*. The model is mistaking
    sample-specific noise in the training data for signal and modeling that — which
    is not at all an uncommon scenario. As a result, models’ predictions on new data
    samples will be poor.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么之前的数据和现在的数据差距如此之大呢？我们观察到的是*过拟合*的情况。模型错误地将训练数据中的样本特有噪声当作信号进行建模——这并不是一个罕见的场景。因此，模型在新数据样本上的预测会很差。
- en: Avoiding overfitting is perhaps the biggest challenge in predictive modeling.
    Thus, it is not at all uncommon to observe negative R² values when (as one should
    always do to ensure that the model is generalizable and robust ) R² is computed
    *out-of-sample*, that is, on data that differ “randomly” from those on which the
    model was estimated.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 避免过拟合可能是预测建模中最大的挑战。因此，当（为了确保模型具有泛化能力和鲁棒性，我们应该始终这样做）R²值是*在样本外*计算时，也就是说，在与模型估计时的数据“随机”不同的数据上计算时，观察到负的R²值并不罕见。
- en: 'Thus, the answer to the question posed in the title of this section is, in
    fact, a resounding *yes*: negative R² do happen in common modeling scenarios,
    even when models have been properly estimated. In fact, they happen all the time.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本节标题中提出的问题的答案实际上是一个响亮的*肯定*回答：负的R²确实会出现在常见的建模场景中，即使模型已正确估计。事实上，它们一直都会发生。
- en: So, is everyone just wrong?
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么，大家都是错的吗？
- en: If R² is *not* a proportion, and its interpretation as variance explained clashes
    with some basic facts about its behavior, do we have to conclude that our initial
    definition is wrong? Are Wikipedia and all those textbooks presenting a similar
    definition wrong? Was my Stats 101 teacher wrong? Well. Yes, and no. It depends
    hugelyon the context in which R² is presented, and on the modeling tradition we
    are embracing.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果R²*不是*一个比例，并且它作为解释方差的解释与关于其行为的一些基本事实冲突，那么我们是否必须得出结论，认为我们最初的定义是错误的？维基百科和那些教科书中呈现的相似定义是否错误？我的统计学101老师是否错了？好吧。是的，也不是。它很大程度上取决于R²所呈现的上下文，以及我们所采纳的建模传统。
- en: If we simply analyse the definition of R² and try to describe its general behavior,
    *regardless* of which type of model we are using to make predictions, and assuming
    we will want to compute this metrics out-of-sample, then yes, they are all wrong.
    Interpreting R² as the proportion of variance explained is misleading, and it
    conflicts with basic facts on the behavior of this metric.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仅仅分析R²的定义并尝试描述其一般行为，*无论*我们使用哪种类型的模型进行预测，并假设我们希望计算这个指标时是在样本外，那么是的，它们都是错的。将R²解释为方差解释的比例是误导性的，它与这个指标的基本行为事实相冲突。
- en: 'Yet, the answer changes slightly if we constrain ourselves to a narrower set
    of scenarios, namely *linear models*, and especially linear models *estimated
    with least squares methods*. Here, R² *will* behave as a proportion. In fact,
    it can be shown that, due to properties of least squares estimation, a linear
    model can *never* do worse than a model predicting the mean of the outcome variable.
    Which means, that a linear model can never have a negative R² — or at least, it
    cannot have a negative R² on the same data on which it was estimated (a debatable
    practice if you are interested in a generalizable model). For a *linear regression*
    scenario with in-sample evaluation, the definition discussed can therefore be
    considered correct. Additional fun fact: this is also the only scenario where
    R² is equivalent to the squared correlation between model predictions and the
    true outcomes.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们将自己限制在一个狭窄的场景中，即*线性模型*，特别是使用最小二乘法估计的线性模型，那么答案会略有变化。在这里，R²*会*表现为一个比例。实际上，可以证明，由于最小二乘估计的性质，线性模型*永远*不可能比预测结果变量均值的模型表现更差。这意味着，线性模型永远不会有负的R²——或者至少，它不会在与其估计时相同的数据上有负的R²（如果你对泛化模型感兴趣的话，这是一种值得争议的做法）。因此，对于*线性回归*情境下的样本内评估，所讨论的定义可以视为正确的。额外有趣的事实：这是R²等同于模型预测与真实结果之间的平方相关性的唯一场景。
- en: The reason why many misconceptions about R² arise is that this metric is often
    first introduced in the context of linear regression and with a focus on *inference*
    rather than prediction. But in predictive modeling, where *in-sample* evaluation
    is a no-go and linear models are just one of many possible models, interpreting
    R² as the proportion of variation explained by the model is at best unproductive,
    and at worst deeply misleading.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 许多关于R²的误解产生的原因是，这个指标通常首先在线性回归的背景下引入，并且侧重于*推断*而非预测。但在预测建模中，在这里*在样本内*评估是不可行的，线性模型只是许多可能模型中的一种，将R²解释为模型所解释的变异的比例，充其量是无益的，最坏的情况下是极具误导性的。
- en: Should I still use R²?
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我还应该使用R²吗？
- en: 'We have touched upon quite a few points, so let’s sum them up. We have observed
    that:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涉及了不少内容，那么让我们总结一下。我们观察到：
- en: R² cannot be interpreted as a proportion, as its values can range from -∞ to
    1
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R²不能被解释为一个比例，因为它的值可以从-∞到1。
- en: Its interpretation as “variance explained” is also misleading (you can imagine
    models that *add* variance to your data, or that combined explained existing variance
    and variance “hallucinated” by a model)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其作为“解释方差”进行的解释也是误导性的（你可以想象出那些*增加*数据方差的模型，或者那些将已有方差与模型“幻想”出的方差结合的模型）。
- en: In general, R² is a “relative” metric, which compares the errors of your model
    with those of a simple model always predicting the mean
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一般来说，R²是一个“相对”指标，它将你的模型误差与一个总是预测均值的简单模型的误差进行比较。
- en: It is, however, accurate to describe R² as the proportion of variance explained
    *in the context of linear modeling with least squares estimation* and *when the
    R² of a least-squares linear model is computed in-sample*.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，将R²描述为*在线性建模和最小二乘估计的背景下*以及*当计算最小二乘线性模型的R²时，使用样本内数据*是准确的。
- en: Given all these caveats, should we still use R²? Or should we give up?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些注意事项，我们是否仍然应该使用R²？还是应该放弃它？
- en: Here, we enter the territory of more subjective observations. In general, if
    you are doing predictive modeling and you want to get a concrete sense for *how
    wrong* your predictions are in absolute terms, R² is *not* a useful metric. Metrics
    like MAE or RMSE will definitely do a better job in providing information on the
    magnitude of errors your model makes. This is useful in absolute terms but also
    in a model comparison context, where you might want to know by how much, concretely,
    the precision of your predictions differs across models. If knowing something
    about precision matters (it hardly ever does not), you might at least want to
    complement R² with metrics that says something meaningful about how wrong each
    of your individual predictions is likely to be.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们进入了更多主观观察的领域。一般来说，如果你在进行预测建模，并且想要对预测结果在绝对意义上的*错误程度*有一个具体的了解，那么R²*不是*一个有用的指标。像MAE或RMSE这样的指标在提供模型误差大小的信息方面肯定会做得更好。这对于绝对意义上的理解是有用的，也适用于模型比较的场景，在这种场景下，你可能想要知道不同模型之间，具体而言，预测精度有多大差异。如果了解某些关于精度的信息很重要（几乎总是重要），你至少可能想要将R²与能够提供关于每个单独预测可能有多错误的有意义的指标结合使用。
- en: More generally, as we have highlighted, there are a number of caveats to keep
    in mind if you decide to use R². Some of these concern the “practical” upper bounds
    for R² (your noise ceiling), and its literal interpretation as a *relative*, rather
    than absolute measure of fit compared to the mean model. Furthermore, good or
    bad R² values, as we have observed, can be driven by many factors, from overfitting
    to the amount of noise in your data.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般来说，正如我们所强调的，如果你决定使用R²，有一些注意事项需要牢记。其中一些涉及到R²的“实际”上限（你的噪声上限），以及它作为*相对*指标的字面解释，而不是与均值模型相比的绝对拟合度。此外，正如我们所观察到的，好的或坏的R²值可能受到多种因素的影响，从过拟合到数据中的噪声量。
- en: On the other hand, while there are very few predictive modeling contexts where
    I have found R² particularly informative in isolation, having a measure of fit
    relative to a “dummy” model (the meanmodel) can be a productive way to think critically
    about your model. Unrealistically high R² on your training set, or a negative
    R² on your test set might, respectively, help you entertain the possibility that
    you might be going for an overly complex model or for an inappropriate modeling
    approach (e.g., a linear model for non-linear data), or that your outcome variable
    might contain, mostly, noise. This is, again, more of a “pragmatic” personal take
    here, but while I would resist fully discarding R² (there aren’t many good global
    and scale-independent measures of fit), in a predictive modeling context I would
    consider it most useful as a complement to scale-dependent metrics such as RMSE/MAE,
    or as a “diagnostic” tool, rather than a target itself.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，虽然我发现很少有预测建模场景中，单独使用R²特别有用，但拥有相对于“虚拟”模型（均值模型）的拟合度度量，可以是一个富有成效的方式，帮助你批判性地思考你的模型。在训练集上，R²值不现实地高，或者在测试集上R²值为负，可能分别帮助你考虑到你可能在追求一个过于复杂的模型，或者一个不适当的建模方法（例如，使用线性模型处理非线性数据），或者你的结果变量大部分可能仅包含噪声。这再次是一个更“务实”的个人看法，但虽然我不完全排除R²（没有很多好的全球性和规模独立的拟合度量），在预测建模的上下文中，我会将它视为对RMSE/MAE等规模相关指标的补充，或者作为一种“诊断”工具，而不是作为一个目标。
- en: Concluding remarks
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论性 remarks
- en: R² is everywhere. Yet, especially in fields that are biased towards explanatory,
    rather than predictive modelling traditions, many misconceptions about its interpretation
    as a model evaluation tool flourish and persist.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: R²无处不在。然而，尤其是在偏向解释性建模而非预测性建模传统的领域中，许多人对其作为模型评估工具的解释存在误解，并且这些误解仍然广泛存在。
- en: In this post, I have tried to provide a narrative primer to some basic properties
    of R² in order to dispel common misconceptions, and help the reader get a grasp
    of what R² generally measures beyond the narrow context of in-sample evaluation
    of linear models.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我尝试为读者提供关于R²的一些基本属性的叙述性介绍，以消除常见的误解，并帮助读者理解R²通常衡量的内容，超越仅仅是线性模型样本内评估的狭窄范围。
- en: Far from being a complete and definitive guide, I hope this can be a pragmatic
    and agile resource to clarify some very justified confusion. Cheers!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章远非一个完整和权威的指南，我希望它能成为一个务实且灵活的资源，帮助澄清一些非常合理的困惑。干杯！
- en: '*Unless otherwise states in the caption, images in this article are by the
    author*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非标题中另有说明，本文中的图片均由作者提供*'
