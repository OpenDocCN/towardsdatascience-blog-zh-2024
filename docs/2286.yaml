- en: A Visual Exploration of Semantic Text Chunking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-visual-exploration-of-semantic-text-chunking-6bb46f728e30?source=collection_archive---------1-----------------------#2024-09-19](https://towardsdatascience.com/a-visual-exploration-of-semantic-text-chunking-6bb46f728e30?source=collection_archive---------1-----------------------#2024-09-19)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/f3920b86cf68505cb2d81e429fb627c7.png)'
  prefs: []
  type: TYPE_IMG
- en: Dalle3’s interpretation of “Semantic Chunking”. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Use embeddings and visualization tools to split text into meaningful chunks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@rmartinshort?source=post_page---byline--6bb46f728e30--------------------------------)[![Robert
    Martin-Short](../Images/e3910071b72a914255b185b850579a5a.png)](https://medium.com/@rmartinshort?source=post_page---byline--6bb46f728e30--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6bb46f728e30--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6bb46f728e30--------------------------------)
    [Robert Martin-Short](https://medium.com/@rmartinshort?source=post_page---byline--6bb46f728e30--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6bb46f728e30--------------------------------)
    ·18 min read·Sep 19, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '***This article offers an explanation of semantic text chunking, a technique
    designed to automatically group similar pieces of text that can be employed as
    part of the pre-processing stage of a pipeline for Retrieval Augmented Generation
    (RAG) or a similar applications. We use visualizations to understand what the
    chunking is doing, and we explore some extensions that involve clustering and
    LLM-powered labeling. Check out the full code*** [***here***](https://github.com/rmartinshort/text_chunking)***.***'
  prefs: []
  type: TYPE_NORMAL
- en: Automatic information retrieval and summarization of large volumes of text has
    many useful applications. One of the most well developed is Retrieval Augmented
    Generation (RAG), which involves extraction of relevant chunks of text from a
    large corpus — typically via semantic search or some other filtering step — in
    response to a user question. Then, the chunks are interpreted or summarized by
    an LLM with the aim of providing a high quality, accurate answer. In order for
    the extracted chunks to be as relevant as possible to the question its very helpful
    for them to be semantically coherent, meaning that each chunk is “about” a specific
    concept and contains a useful packet of information in it’s own right.
  prefs: []
  type: TYPE_NORMAL
- en: Chunking has applications beyond RAG too. Imagine we have a complex document
    like a book or journal article and want to quickly understand what key concepts
    it contains. If the text can be clustered into semantically coherent groups and
    then each cluster summarized in some way, this can really help speed up time to
    insights. The excellent package [BertTopic](https://maartengr.github.io/BERTopic/index.html)
    (see [this article](/topics-per-class-using-bertopic-252314f2640) for a nice overview)
    can help here.
  prefs: []
  type: TYPE_NORMAL
- en: Visualization of the chunks can also be insightful, both as a final product
    and during development. Humans are visual learners in that our brains are much
    faster at gleaning information from graphs and images rather than streams of text.
    In my experience, it’s quite difficult to understand what a chunking algorithm
    has done to the text — and what the optimal parameters might be — without visualizing
    the chunks in some way or reading them all, which is impractical in the case of
    large documents.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’re going to explore a method to split text into semantically
    meaningful chunks with an emphasis on using graphs and plots to understand what’s
    going on. In doing so, we’ll touch on dimensionality reduction and hierarchical
    clustering of embedding vectors, in addition to the use of LLMs to summarize the
    chunks so that we can quickly see what information is present. My hope is that
    this might spark further ideas for anyone researching semantic chunking as a potential
    tool in their application. I’ll be using Python 3.9, LangChain and Seaborn here,
    with full details in the [repo](https://github.com/rmartinshort/text_chunking).
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. What is semantic chunking?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a few standard types of chunking and to learn more about them I recommend
    [this excellent tutorial](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb),
    which also provided inspiration for this article. Assuming we are dealing with
    English text, the simplest form of chunking is character based, where we choose
    a fixed window of characters and simply break up the text into chunks of that
    length. Optionally we can add an overlap between the chunks to preserve some indication
    of the sequential relationship between them. This is computationally straightforward
    but there is no guarantee that the chunks will be semantically meaningful or even
    complete sentences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recursive chunking is typically more useful and is seen as the go-to first
    algorithm for many applications. The process takes in hierarchical list of separators
    (the default in LangChain is `[“\n\n”, “\n”, “ ”, “”]` ) and a target length.
    It then splits up the text using the separators in a recursive way, advancing
    down the list until each chunk is less than or equal to the target length. This
    is much better at preserving full paragraphs and sentences, which is good because
    it makes the chunks much more likely to be coherent. However it does not consider
    semantics: If one sentence follows on from the last and happens to be at the end
    of the chunk window, the sentences will be separated.'
  prefs: []
  type: TYPE_NORMAL
- en: In semantic chunking, which has implementations in both [LangChain](https://python.langchain.com/v0.2/docs/how_to/semantic-chunker/)
    and [LlamaIndex](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/semantic_splitter/#llama_index.core.node_parser.SemanticSplitterNodeParser),
    the splits are made based on the cosine distance between embeddings of sequential
    chunks. So we start by dividing the text into small but coherent groups, perhaps
    using a recursive chunker.
  prefs: []
  type: TYPE_NORMAL
- en: Next we take vectorize each chunk using a model that has been trained to generate
    meaningful embeddings. Typically this takes the form of a transformer-based bi-encoder
    (see the [SentenceTransformers](https://sbert.net/) library for details and examples),
    or an [endpoint such as OpenAI’s](https://platform.openai.com/docs/guides/embeddings)
    `[text-embeddings-3-small](https://platform.openai.com/docs/guides/embeddings)`
    , which is what we use here. Finally, we look at the cosine distances between
    the embeddings of subsequent chunks and choose breakpoints where the distances
    are large. Ideally, this helps to create groups of text that are both coherent
    and semantically distinct.
  prefs: []
  type: TYPE_NORMAL
- en: A recent extension of this called [semantic double chunk merging](https://docs.llamaindex.ai/en/stable/examples/node_parsers/semantic_double_merging_chunking/)
    (see [this article](https://bitpeak.pl/chunking-methods-in-rag-methods-comparison/)
    for details) attempts to extend this by doing a second pass and using some re-grouping
    logic. So for example if the first pass has put a break between chunks 1 and 2,
    but chunks 1 and 3 are very similar, it will make a new group that includes chunks
    1, 2 and 3\. This proves useful if chunk 2 was, for example, a mathematical formula
    or a code block.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, when it comes to any type of semantic chunking some key questions
    remain: How large can the distance between chunk embeddings get before we make
    a breakpoint, and what do these chunks actually represent? Do we care about that?
    Answers to these questions depend on the application and the text in question.'
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Exploring the breakpoints**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s use an example to illustrate the generation of breakpoints using semantic
    chunking. We will implement our own version of this algorithm, though out of the
    box implementations are also available as described above. Our demo text is [here](https://github.com/rmartinshort/text_chunking/blob/main/text_chunking/datasets/test_text_dataset.py)
    and it consists of three short, factual essays written by GPT-4o and appended
    together. The first is about the general importance of preserving trees, the second
    is about the history of Namibia and the third is a deeper exploration of the importance
    of protecting trees for medical purposes. The topic choice doesn’t really matter,
    but the corpus represents an interesting test because the first and third essays
    are somewhat similar, yet separated by the second which is very different. Each
    essay is also broken into sections focussing on different things.
  prefs: []
  type: TYPE_NORMAL
- en: We can use a basic `RecursiveCharacterTextSplitter` to make the initial chunks.
    The most important parameters here are the chunk size and separators list, and
    we typically don’t know what they should be without some subject knowledge of
    the text. Here I chose a relatively small chunk size because I want the initial
    chunks to be at most a few sentences long. I also chose the separators such that
    we avoid splitting sentences.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Next we can split the text. The `min_chunk_len` parameter comes into play if
    any of the chunks generated by the splitter are smaller than this value. If that
    happens, that chunk just gets appended to the end of the previous one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now we can embed the splits using the embeddings model. You’ll see in the class
    for `[SemanticClusterVisualizer](https://github.com/rmartinshort/text_chunking/blob/main/text_chunking/SemanticClusterVisualizer.py)`
    that by default we’re using `text-embeddings-3-small` . This will create a list
    of 53 vectors, each of length 1536\. Intuitively, this means that the semantic
    meaning of each chunk is represented in a 1536 dimensional space. Not great for
    visualization, which is why we’ll turn to dimensionality reduction later.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Running the semantic chunker generates a graph like this. We can think of it
    like a time series, where the x-axis represents distance through the entire text
    in terms of characters. The y axis represents the cosine distance between the
    embeddings of subsequent chunks. The break points occur at distances values above
    the 95th percentile.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e940488f2fe8a7b5a4510091e7ffd230.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph showing the cosine distance between subsequent chunks of text generated
    by the RecursiveCharacterTextSplitter. We can use these distances to establish
    breakpoints for semantic chunking. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The pattern makes sense given what we know about the text — there are three
    big subjects, each of which has a few different sections. Aside from the two large
    spikes though, it’s not clear where the other breakpoints should be.
  prefs: []
  type: TYPE_NORMAL
- en: This is where the subjectivity and iteration comes in — depending on our application,
    we may want larger or smaller chunks and it’s important to use the graph to help
    guide our eye towards which chunks to actually read.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few ways we could break the text into more granular chunks. The
    first is just to decrease the percentile threshold to make a breakpoint.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9cd03a729e49f3b62d411890e66325a5.png)'
  prefs: []
  type: TYPE_IMG
- en: Breakpoints generated by choosing a lower percentile threshold on the cosine
    distances array. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: This creates 4 really small chunks and 8 larger ones. If we look at the first
    4 chunks, for example, the splits seem semantically reasonable although I would
    argue that the 4th chunk is a bit too long, given that it contains most of the
    “economic importance”, “social importance” and “conclusions” sections of the first
    essay.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c8f630c99b29e79fa59ddc8b45793df.png)'
  prefs: []
  type: TYPE_IMG
- en: The first four semantic chunks generated by setting percentile threshold at
    0.8\. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of just changing the percentile threshold, an alternative idea is to
    apply the same threshold recursively. We start by creating breakpoints on the
    whole text. Then for each newly created chunk, if the chunk is above some length
    threshold, we create breakpoints just within that chunk. This happens until all
    the chunks are below the length threshold. Although somewhat subjective, I think
    this more closely mirrors what a human would do in that they would first identify
    very different groups of text and then iteratively reduce the size of each one.
  prefs: []
  type: TYPE_NORMAL
- en: It can be implemented with a stack, as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Our choice of `length_threshold` is also subjective and can be informed by the
    plot. In this case, a threshold of 1000 appears to work well. It divides the essays
    quite nicely into short and meaningfully different chunks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8763d5ba09fe12415629a54ce769f603.png)'
  prefs: []
  type: TYPE_IMG
- en: Breakpoints generated by running a recursive semantic splitter on the cosine
    distance timeseries from the original chunk embeddings. Image generated by the
    author.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the chunks corresponding to the first essay, we see that they are
    closely aligned with the different sections that GPT4-o created when it wrote
    the essay. Obviously in the case of this particular essay we could have just split
    on `"\n\n"` and been done here, but we want a more general approach.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83ac1c17b0fd7cdb3753d47489b91938.png)'
  prefs: []
  type: TYPE_IMG
- en: The first six semantic chunks generated by the recursive breakpoint generation
    approach described above. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Clustering the semantic splits**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have made some candidate semantic chunks, it might be useful to
    see how similar they are to one another. This will help us get a sense for what
    information they contain. We will proceed by embedding the semantic chunks, and
    then use UMAP to reduce the dimensionality of the resulting embeddings to 2D so
    that we can plot them.
  prefs: []
  type: TYPE_NORMAL
- en: UMAP stands for Uniform Manifold Approximation and Projection, and is a powerful,
    general dimensionality reduction technique that can capture non-linear relationships.
    A full explanation of how it works can be found [here](https://umap-learn.readthedocs.io/en/latest/how_umap_works.html).
    The purpose of using it here is to capture something of the relationships that
    exist between the embedded chunks in 1536-D space in a 2-D plot
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: UMAP is quite sensitive to the `n_neighbors` parameter. Generally the smaller
    the value of `n_neighbors`, the more the algorithm focuses on the use of local
    structure to learn how to project the data into lower dimensions. Setting this
    value too small can lead to projections that don’t do a great job of capturing
    the large scale structure of the data, and it should generally increase as the
    number of datapoints grows.
  prefs: []
  type: TYPE_NORMAL
- en: 'A projection of our data is shown below and its quite informative: Clearly
    we have three clusters of similar meaning, with the 1st and 3rd being more similar
    to each other than either is to the 2nd. The `idx` color bar in the plot above
    shows the chunk number, while the red line gives us an indication of the sequence
    of the chunks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6690eb5aad72ac6f82942ee770779a9d.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot of UMAP projection of the embeddings of the semantic splits generated in
    the previous section. idx refers to the index of the chunk in the order that they
    are generated by looping through the text. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: What about automatic clustering? This would be helpful if we wanted to group
    the chunks into larger segments or topics, which could serve as useful metadata
    to filter on in a RAG application with hybrid search, for example. We also might
    be able to group chunks that are far apart in the text (and therefore would not
    have been grouped by the standard semantic chunking in section 1) but have similar
    meanings.
  prefs: []
  type: TYPE_NORMAL
- en: There are many clustering approaches that could be used here. HDBSCAN is a possibility,
    and is the default method recommended by the [BERTopic](https://maartengr.github.io/BERTopic/getting_started/clustering/clustering.html)
    package. However, in this case hierarchical clustering seems more useful since
    it can give us a sense of the relative importance of whatever groups emerge. To
    run hierarchical clustering, we first use UMAP to reduce the dimensionality of
    the dataset to a smaller number of components. So long as UMAP is working well
    here, the exact number of components shouldn’t significantly affect the clusters
    that get generated. Then we use the [hierarchy module from scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html)
    to perform the clustering and plot the result using seaborn
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The result is also quite informative. Here `n_components_reduced` was 4, so
    we reduced the dimensionality of the embeddings to 4D, therefore making a matrix
    with 4 features where each row represents one of the semantic chunks. Hierarchical
    clustering has identified the two major groups (i.e. trees and Namibia), two large
    subgroup within trees (i.e. medical uses vs. other) and an number of other groups
    that might be worth exploring.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fee5033190b5b9077467ad2d0ed75e7d.png)'
  prefs: []
  type: TYPE_IMG
- en: Hierarchical clustering of the UMAP projections of the embeddings of the semantic
    clunks generated. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Note that [BERTopic uses a similar technique for topic visualization](https://maartengr.github.io/BERTopic/getting_started/hierarchicaltopics/hierarchicaltopics.html),
    which could be seen as an extension of what’s being presented here.
  prefs: []
  type: TYPE_NORMAL
- en: How is this useful in our exploration of semantic chunking? Depending on the
    results, we may choose to group some of the chunks together. This is again quite
    subjective and it might be important to try out a few different types of grouping.
    Let’s say we looked at the dendrogram and decided we wanted 8 distinct groups.
    We could then cut the hierarchy accordingly, return the cluster labels associated
    with each group and plot them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting plot is shown below. We have 8 clusters, and their distribution
    in the 2D space looks reasonable. This again demonstrates the importance of visualization:
    Depending on the text, application and stakeholders, the right number and distribution
    of groups will likely be different and the only way to check what the algorithm
    is doing is by plotting graphs like this.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dc1a6edcaacd42723c107f27e11b02d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Cluster ids of the semantic chunks used to color the UMAP-projected embeddings
    of the semantic chunks. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Labeling the clusters**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assume after a few iterations of the steps above, we’ve settled on semantic
    splits and clusters that we’re happy with. It then makes sense to ask what these
    clusters actually represent? Obviously we could read the text and find out, but
    for a large corpus this is impractical. Instead, let’s use an LLM to help. Specifically,
    we will feed the text associated with each cluster to GPT-4o-mini and ask it to
    generate a summary. This is a relatively simple task with LangChain, and the core
    aspects of the code are shown below
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Running this on our 8 clusters and plotting the result with [datamapplot](https://datamapplot.readthedocs.io/en/latest/)
    gives the following
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d03ea790b2958ab89a786710fcccbec6.png)'
  prefs: []
  type: TYPE_IMG
- en: Labels generated by running GPT-4o-mini for the semantic clusters. Image generated
    by the author.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative way of visualizing these groups is similar to the graphs shown
    in section 2, where we plot cumulative character number on the x axis and show
    the boundaries between the groups. Recall that we had 18 semantic chunks and have
    now grouped them further into 8 clusters. Plotting them like this shows how the
    semantic content of the text changes from beginning to end, highlights the fact
    that similar content is not always adjacent and gives a visual indication of the
    relative size of the chunks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/af3cec1f961f5b5a507553dc5cf843e1.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph showing the text segmented by semantic cluster and the names of the clusters.
    Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The code used to produce these figures can be found [here](https://github.com/rmartinshort/text_chunking/blob/main/text_chunking/utils/SemanticGroupUtils.py).
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Testing on a larger corpus**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far we’ve tested this workflow on a relatively small amount of text for demo
    purposes. Ideally it would also be useful on a larger corpus without significant
    modification. To test this, let’s try it out on a book downloaded from [Project
    Gutenberg](https://www.gutenberg.org/), and I’ve chosen the Wizard of Oz here.
    This is a much more difficult task because novels are typically not arranged in
    clear semantically distinct sections like factual essays. Although they are commonly
    arranged in chapters, the story line may “arch” in a continuous fashion, or skip
    around between different subjects. It would be very interesting to see if semantic
    chunk analysis could be used to learn something about the style of different authors
    from their work.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Embed and generate breakpoints**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This generates 77 semantic chunks of varying size. Doing some spot checks here
    led me to feel confident that it was working relatively well and many of the chunks
    end up being divided on or close to chapter boundaries, which makes a lot of sense.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a81a54829db8050a2620be382d653dc6.png)'
  prefs: []
  type: TYPE_IMG
- en: Semantic splits from the Wizard of Oz. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2 : Cluster and generate labels'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On looking at the hierarchical clustering dendrogram, I decided to experiment
    with reduction to 35 clusters. The result reveals an outlier in the top left of
    the plot below (cluster id 34), which turns out to be a group of chunks at the
    very end of the text that contain a lengthy description of the terms under which
    the book is distributed.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c2b807ca8401d2438bc1a26d2cd9c16e.png)'
  prefs: []
  type: TYPE_IMG
- en: 2D plot of UMAP projections of semantic chunks from the Wizard of Oz, and their
    cluster labels. Image generated by the author
  prefs: []
  type: TYPE_NORMAL
- en: The descriptions given to each of the clusters are shown below and, with the
    exception of the first one, they provide a nice overview of the main events of
    the novel. A quick check on the actual texts associated with each one confirms
    that they are reasonably accurate summaries, although again, a determination of
    where the boundaries of the clusters should be is very subjective.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/76695daf7c6e6e49b67108db231e91fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Names automatically chosen for each of the 40 semantic clusters from the Wizard
    of Oz. This list provides a quick overview of the storyline. Image generated by
    the author.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4o-mini labeled the outlier cluster “Project Gutenberg allows free distribution
    of unprotected works”. The text associated with this label is not particularly
    interesting to us, so let’s remove it and re-plot the result. This will make the
    structure in the novel easier to see.
  prefs: []
  type: TYPE_NORMAL
- en: What if we are interested in larger clusters? If we were to focus on high level
    structure, the dendrogram suggests approximately six clusters of semantic chunks,
    which are plotted below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dbc6c75ea91fc60aec528016e258f437.png)'
  prefs: []
  type: TYPE_IMG
- en: Searching for high level structure — if we choose to make 6 clusters from the
    semantic chunks of the Wizard of Oz, this is the pattern we get. Image generated
    by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s a lot of jumping back and forth between points that are somewhat distant
    in this semantic space, suggesting frequent sudden changes in subject. It’s also
    interesting to consider the connectivity between the various clusters: 4 and 5
    have no links between them for example, while there’s a lot of back and forth
    between 0 and 1.'
  prefs: []
  type: TYPE_NORMAL
- en: Can we summarize these larger clusters? It turns out that our prompt doesn’t
    seem well suited for chunks of this size, producing descriptions that seem either
    too specific to one part of the cluster (i.e. clusters 0 and 4) or too vague to
    be very helpful. Improved prompt engineering — possibly involving multiple summarization
    steps — would probably improve the results here.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c38aff26c65af18a4f901652af0cde32.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph showing the text segmented by semantic cluster id and the names of the
    six clusters identified above. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the unhelpful names, this plot of the text segments colored by cluster
    is still informative as a guide to selective reading of the text. We see that
    the book starts and ends on the same cluster, which likely is about descriptions
    of Dorothy, Toto and their home — and aligns with the story arch of the Wizard
    of Oz as a journey and subsequent return. Cluster 1 is mainly about meeting new
    characters, which happens mainly near the beginning but also periodically throughout
    the book. Clusters 2 and 3 are concerned with Emerald City and the Wizard, while
    clusters 4 and 5 are broadly about journeying and fighting respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '**5\. Concluding thoughts**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for making it to the end! Here we took a deep dive into the idea of semantic
    chunking, and how it can be complimented by dimensionality reduction, clustering
    and visualization. The major takeaway is the importance of systematically exploring
    the effects of different chunking techniques and a parameters on your text before
    deciding on the most suitable approach. My hope is that this article will spark
    new ideas about how we can use AI and visualization tools to advance semantic
    chunking and quickly extract insights from large bodies of text. Please feel free
    to explore the full codebase here [https://github.com/rmartinshort/text_chunking](https://github.com/rmartinshort/text_chunking).
  prefs: []
  type: TYPE_NORMAL
