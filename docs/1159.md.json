["```py\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n```", "```py\nbrew --version\n```", "```py\necho ‘eval “$(/opt/homebrew/bin/brew shellenv)”’ >> /Users/rindhujajohnson/.bash_profile\n\neval “$(/opt/homebrew/bin/brew shellenv)”\n```", "```py\nbrew install hadoop\n```", "```py\ncd /opt/homebrew/Cellar/hadoop/3.3.6/libexec/etc/hadoop\n```", "```py\n/usr/libexec/java_home\n```", "```py\n<configuration>\n <property>\n  <name>fs.defaultFS</name>\n  <value>hdfs://localhost:9000</value>\n </property>\n</configuration>\n```", "```py\n<configuration>\n  <property>\n    <name>dfs.replication</name>\n    <value>1</value>\n  </property>\n</configuration>\n```", "```py\n<configuration>\n    <property>\n       <name>mapreduce.framework.name</name>\n       <value>yarn</value>\n    </property>\n    <property>\n    <name>mapreduce.application.classpath</name>   \n  <value>\n$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*\n  </value>\n    </property>\n</configuration>\n```", "```py\n<configuration>\n  <property>\n    <name>yarn.nodemanager.aux-services</name>\n    <value>mapreduce_shuffle</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.env-whitelist</name>  \n   <value>\nJAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME\n  </value>\n  </property>\n</configuration>\n```", "```py\nhadoop namenode -format \n```", "```py\n# starts the Hadoop environment\n% start-all.sh \n\n# Gathers all the nodes functioning to ensure that the installation was successful\n% jps \n```", "```py\nGET store.steampowered.com/appreviews/<appid>?json=1\n```", "```py\nhadoop fs -mkdir /user\nhadoop fs -mkdir /user/steam_analysis\n```", "```py\nhadoop fs -put /Users/rindhujajohnson/local_file_path/steam_reviews.csv /user/steam_analysis\n```", "```py\n# By default, the Hadoop version considered will be 3 here.\nPYSPARK_HADOOP_VERSION=3 pip install pyspark\n```", "```py\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n\n# Initializing the Spark Session\nspark = SparkSession.builder.appName(\"SteamReviewAnalysis\").master(\"yarn\").getOrCreate()\n\n# Providing the url for accessing the HDFS\ndata = \"hdfs://localhost:9000/user/steam_analysis/steam_reviews.csv\"\n\n# Extracting the CSV data in the form of a Schema\ndata_csv = spark.read.csv(data, inferSchema = True, header = True)\n\n# Visualize the structure of the Schema\ndata_csv.printSchema()\n\n# Counting the number of rows in the dataset\ndata_csv.count() # 40,848,659\n```", "```py\n# Dropping the review column and saving the data into a new variable\ndata = data_csv.drop(\"review\")\n\n# Displaying the data\ndata.show() \n```", "```py\n# Drops all the records with NULL values\ndata = data.na.drop(how = \"any\")\n\n# Count the number of records in the remaining dataset\ndata.count() # 16,876,852\n```", "```py\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import from_unixtime\n\n# Changing the data type of each columns into appropriate types\ndata = data.withColumn(\"app_id\",data[\"app_id\"].cast(IntegerType())).\\\n            withColumn(\"author_steamid\", data[\"author_steamid\"].cast(LongType())).\\\n            withColumn(\"recommended\", data[\"recommended\"].cast(BooleanType())).\\\n            withColumn(\"steam_purchase\", data[\"steam_purchase\"].cast(BooleanType())).\\\n            withColumn(\"author_num_games_owned\", data[\"author_num_games_owned\"].cast(IntegerType())).\\\n            withColumn(\"author_num_reviews\", data[\"author_num_reviews\"].cast(IntegerType())).\\\n            withColumn(\"author_playtime_forever\", data[\"author_playtime_forever\"].cast(FloatType())).\\\n            withColumn(\"author_playtime_at_review\", data[\"author_playtime_at_review\"].cast(FloatType()))\n\n# Converting the time columns into timestamp data type\ndata = data.withColumn(\"timestamp_created\", from_unixtime(\"timestamp_created\").cast(\"timestamp\")).\\\n            withColumn(\"author_last_played\", from_unixtime(data[\"author_last_played\"]).cast(TimestampType())).\\\n            withColumn(\"timestamp_updated\", from_unixtime(data[\"timestamp_updated\"]).cast(TimestampType()))\n```", "```py\n# Grouping the columns for each analysis\ncol_demo = [\"app_id\", \"app_name\", \"review_id\", \"language\", \"author_steamid\", \"timestamp_created\" ,\"author_playtime_forever\",\"recommended\"]\ncol_author = [\"steam_purchase\", 'author_steamid', \"author_num_games_owned\", \"author_num_reviews\", \"author_playtime_forever\", \"author_playtime_at_review\", \"author_last_played\",\"recommended\"]\ncol_time = [ \"app_id\", \"app_name\", \"timestamp_created\", \"timestamp_updated\", 'author_playtime_at_review', \"recommended\"]\ncol_rev = [ \"app_id\", \"app_name\", \"language\", \"recommended\"]\ncol_rec = [\"app_id\", \"app_name\", \"recommended\"]\n\n# Creating new pyspark data frames using the grouped columns\ndata_demo = data.select(*col_demo)\ndata_author = data.select(*col_author)\ndata_time = data.select(*col_time)\ndata_rev = data.select(*col_rev)\ndata_rec = data.select(*col_rec) \n```", "```py\n# the data frame is grouped by the game and the number of occurrences are counted\napp_names = data_rec.groupBy(\"app_name\").count()\n\n# the data frame is ordered depending on the count for the highest 20 games\napp_names_count = app_names.orderBy(app_names[\"count\"].desc()).limit(20)\n\n# a pandas data frame is created for plotting\napp_counts = app_names_count.toPandas()\n\n# A pie chart is created\nfig = plt.figure(figsize = (10,5))\ncolors = sns.color_palette(\"muted\")\nexplode = (0.1,0.075,0.05,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)\nplt.pie(x = app_counts[\"count\"], labels = app_counts[\"app_name\"], colors = colors,  explode = explode, shadow = True)\nplt.title(\"The Most Popular Games\")\nplt.show()\n```", "```py\n# Pick the 20 highest recommended games and convert it in to pandas data frame\ntrue_counts = data_rec.filter(data_rec[\"recommended\"] == \"true\").groupBy(\"app_name\").count()\nrecommended = true_counts.orderBy(true_counts[\"count\"].desc()).limit(20)\nrecommended_apps = recommended.toPandas()\n\n# Pick the games such that both they are in both the popular and highly recommended list\ntrue_apps = list(recommended_apps[\"app_name\"])\ntrue_app_counts = data_rec.filter(data_rec[\"app_name\"].isin(true_apps)).groupBy(\"app_name\").count()\ntrue_app_counts = true_app_counts.orderBy(true_app_counts[\"count\"].desc())\ntrue_app_counts = true_app_counts.toPandas()\n\n# Evaluate the percent of true recommendations for the top games and sort them\ntrue_perc = []\nfor i in range(0,20,1):\n    percent = (true_app_counts[\"count\"][i]-recommended_apps[\"count\"][i])/true_app_counts[\"count\"][i]*100\n    true_perc.append(percent)\nrecommended_apps[\"recommend_perc\"] = true_perc\nrecommended_apps = recommended_apps.sort_values(by = \"recommend_perc\", ascending = False)\n\n# Built a pie chart to visualize\nfig = plt.figure(figsize = (10,5))\ncolors = sns.color_palette(\"muted\")\nexplode = (0.1,0.075,0.05,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)\nplt.pie(x = recommended_apps[\"recommend_perc\"], labels = recommended_apps[\"app_name\"], colors = colors,  explode = explode, shadow = True)\nplt.title(\"The Most Recommended Games\")\nplt.show()\n```", "```py\n# We standardize the language names in the language column, then group them,\n# Count by the groups and convert into pandas df after sorting them the count\nauthor_lang = data_demo.select(lower(\"language\").alias(\"language\"))\n    \\.groupBy(\"language\").count().orderBy(col(\"count\").desc()).\n    \\limit(20).toPandas()\n\n# Plotting a bar graph\nfig = plt.figure(figsize = (10,5))\nplt.bar(author_lang[\"language\"], author_lang[\"count\"])\nplt.xticks(rotation = 90)\nplt.xlabel(\"Popular Languages\")\nplt.ylabel(\"Number of Reviews (in Millions)\")\nplt.show()\n```", "```py\n# We group the data frame based on the game and language and count each occurrence\ndata_demo_new = data_demo.select(lower(\"language\").\n  \\alias(\"language\"), \"app_name\")\ngames_lang = data_demo_new.groupBy(\"app_name\",\"language\").count().orderBy(col(\"count\").desc()).limit(100).toPandas()\n\n# Plot a stacked bar graph to visualize\ngrouped_games_lang = games_lang_df.pivot(index='app_name', columns='language', values='count')\ngrouped_games_lang.plot(kind='bar', stacked=True, figsize=(12, 6))\nplt.title('Count of Different App Names and Languages')\nplt.xlabel('App Name')\nplt.ylabel('Count')\nplt.show()\n```", "```py\nnew_pair_games = data_demo.filter(col(\"author_playtime_forever\")>=5*mean_playtime)\nnew_pair_games = new_pair_games.filter(new_pair_games[\"author_steamid\"]>=76560000000000000).select(\"author_steamid\",\"app_id\", \"app_name\",\"recommended\")\n\n# Convert author_steamid and app_id to indices, and use the recommended column for rating\nauthor_indexer = StringIndexer(inputCol=\"author_steamid\", outputCol=\"author_index\").fit(new_pair_games)\napp_indexer = StringIndexer(inputCol=\"app_name\", outputCol=\"app_index\").fit(new_pair_games)\nnew_pair_games = new_pair_games.withColumn(\"Rating\", when(col(\"recommended\") == True, 5).otherwise(1))\n\n# We apply the indexing to the data frame by invoking the reduce phase function transform()\nnew_pair = author_indexer.transform(app_indexer.transform(new_pair_games))\nnew_pair.show()\n```", "```py\n# The reference chart for games\ngames = new_pair.select(\"app_index\",\"app_name\").distinct().orderBy(\"app_index\")\n```", "```py\n# Create an ALS (Alternating Least Squares) model\nals = ALS(maxIter=10, regParam=0.01, userCol=\"app_index\", itemCol=\"author_index\", ratingCol=\"Rating\", coldStartStrategy=\"drop\")\n\n# Fit the model to the data\nmodel = als.fit(new_pair)\n\n# Generate recommendations for all items\napp_recommendations = model.recommendForAllItems(5)  # Number of recommendations per item\n\n# Display the recommendations\napp_recommendations.show(truncate=False)\n```"]