# æˆ‘å¦‚ä½•ä½¿ç”¨ LlamaIndex å·¥ä½œæµç®€åŒ–æˆ‘çš„ç ”ç©¶å’Œæ¼”ç¤ºè¿‡ç¨‹

> åŸæ–‡ï¼š[`towardsdatascience.com/how-i-streamline-my-research-and-presentation-with-llamaindex-workflows-3d75a9a10564?source=collection_archive---------3-----------------------#2024-09-10`](https://towardsdatascience.com/how-i-streamline-my-research-and-presentation-with-llamaindex-workflows-3d75a9a10564?source=collection_archive---------3-----------------------#2024-09-10)

## ä¸€ä¸ªé€šè¿‡ AI å·¥ä½œæµå®ç°å¯é æ€§ã€çµæ´»æ€§å’Œå¯æ§æ€§çš„ç¤ºä¾‹

[](https://medium.com/@lzchen.cs?source=post_page---byline--3d75a9a10564--------------------------------)![Lingzhen Chen](https://medium.com/@lzchen.cs?source=post_page---byline--3d75a9a10564--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3d75a9a10564--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3d75a9a10564--------------------------------) [Lingzhen Chen](https://medium.com/@lzchen.cs?source=post_page---byline--3d75a9a10564--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3d75a9a10564--------------------------------) Â·16 åˆ†é’Ÿé˜…è¯»Â·2024 å¹´ 9 æœˆ 10 æ—¥

--

LlamaIndex æœ€è¿‘æ¨å‡ºäº†ä¸€é¡¹æ–°åŠŸèƒ½ï¼šå·¥ä½œæµã€‚å¯¹äºé‚£äº›å¸Œæœ›åˆ›å»ºæ—¢å¯é åˆçµæ´»çš„ AI è§£å†³æ–¹æ¡ˆçš„äººæ¥è¯´ï¼Œè¿™éå¸¸æœ‰ç”¨ã€‚ä¸ºä»€ä¹ˆå‘¢ï¼Ÿå› ä¸ºå®ƒå…è®¸ä½ å®šä¹‰å…·æœ‰æ§åˆ¶æµçš„è‡ªå®šä¹‰æ­¥éª¤ã€‚å®ƒæ”¯æŒå¾ªç¯ã€åé¦ˆå’Œé”™è¯¯å¤„ç†ã€‚å®ƒå°±åƒä¸€ä¸ª AI é©±åŠ¨çš„ç®¡é“ã€‚ä½†ä¸é€šå¸¸å®ç°ä¸ºæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰çš„å…¸å‹ç®¡é“ä¸åŒï¼Œå·¥ä½œæµè¿˜æ”¯æŒå¾ªç¯æ‰§è¡Œï¼Œä½¿å…¶æˆä¸ºå®ç°ä»£ç†å¼å’Œå…¶ä»–æ›´å¤æ‚è¿‡ç¨‹çš„è‰¯å¥½å€™é€‰ã€‚

[](https://www.llamaindex.ai/blog/introducing-workflows-beta-a-new-way-to-create-complex-ai-applications-with-llamaindex?source=post_page-----3d75a9a10564--------------------------------) [## Introducing workflows beta: a new way to create complex AI applications with LlamaIndex â€¦

### LlamaIndex æ˜¯ä¸€ä¸ªç®€å•çµæ´»çš„æ•°æ®æ¡†æ¶ï¼Œç”¨äºå°†è‡ªå®šä¹‰æ•°æ®æºè¿æ¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚

www.llamaindex.ai](https://www.llamaindex.ai/blog/introducing-workflows-beta-a-new-way-to-create-complex-ai-applications-with-llamaindex?source=post_page-----3d75a9a10564--------------------------------)

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LlamaIndex å·¥ä½œæµç®€åŒ–æˆ‘çš„ç ”ç©¶è¿‡ç¨‹ï¼Œå¸®åŠ©æˆ‘ç ”ç©¶æŸä¸ªä¸»é¢˜çš„æœ€æ–°è¿›å±•ï¼Œç„¶åå°†è¿™äº›ç ”ç©¶æˆæœè½¬åŒ–ä¸º PowerPoint æ¼”ç¤ºæ–‡ç¨¿ã€‚

å½“æ¶‰åŠåˆ°æŸ¥æ‰¾æ–°çš„ç ”ç©¶å‡ºç‰ˆç‰©æˆ–è®ºæ–‡æ—¶ï¼Œ[ArXiv.org](http://ArXiv.org)æ˜¯æˆ‘ä¸»è¦çš„æ¥æºã€‚ç„¶è€Œï¼Œç½‘ç«™ä¸Šçš„è®ºæ–‡éå¸¸å¤šã€‚æˆªè‡³ 2024 å¹´ 9 æœˆï¼ŒArXiv ä¸Šå¤§çº¦æœ‰ 250 ä¸‡ç¯‡è®ºæ–‡ï¼Œå…¶ä¸­ 17,000 ç¯‡æ˜¯ä»…åœ¨ 8 æœˆä»½æäº¤çš„ï¼ˆç»Ÿè®¡æ•°æ®[åœ¨è¿™é‡Œ](https://arxiv.org/stats/monthly_submissions)ï¼‰ã€‚å³ä½¿é™åˆ¶åœ¨ä¸€ä¸ªç‰¹å®šä¸»é¢˜ä¸‹ï¼Œè¦é˜…è¯»çš„å†…å®¹ä¾ç„¶éå¸¸åºå¤§ã€‚ä½†è¿™å¹¶ä¸æ˜¯ä¸€ä¸ªæ–°é—®é¢˜ã€‚é•¿æœŸä»¥æ¥ï¼Œå­¦æœ¯ç ”ç©¶äººå‘˜å¿…é¡»æµè§ˆå¤§é‡çš„æ–‡çŒ®ä»¥è¿›è¡Œè‡ªå·±çš„ç ”ç©¶ã€‚è¿‡å»ä¸¤å¹´å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å…´èµ·ä¸ºæˆ‘ä»¬æä¾›äº†è¯¸å¦‚[ResearchGPT](https://www.researchgpt.com/)ã€[papersGPT](https://jessezhang.org/llmdemo?via=topaitools)å’Œè®¸å¤šåœ¨[OpenAI](https://chatgpt.com/gpts)å¹³å°ä¸Šä¸ºç‰¹å®šç ”ç©¶ç›®çš„æ„å»ºçš„å®šåˆ¶ GPT å·¥å…·ï¼Œè¿™äº›å·¥å…·æœ‰åŠ©äºæ–‡çŒ®æœç´¢ã€æ‘˜è¦æå–å’Œå±•ç¤ºã€‚

å°½ç®¡è¿™äº›å·¥å…·å¾ˆæœ‰ç”¨ï¼Œä½†æˆ‘é€‰æ‹©ä½¿ç”¨ LlamaIndex å·¥ä½œæµæ¥æ„å»ºè‡ªå·±çš„å·¥ä½œæµï¼ŒåŸå› æœ‰å‡ ä¸ªå…³é”®ç‚¹ï¼š

+   æˆ‘å·²ç»æœ‰ä¸€ä¸ªç‰¹å®šçš„ç ”ç©¶è¿‡ç¨‹ï¼Œå¹¶å¸Œæœ›ä¿æŒå®ƒï¼Œä½†æé«˜æ•ˆç‡ã€‚

+   æˆ‘æƒ³åˆ©ç”¨ LLM å’Œä»£ç†è¡Œä¸ºï¼Œå¹¶ä¿æŒå¯¹å¤§å¤šæ•°æ­¥éª¤çš„æ§åˆ¶ã€‚

+   æˆ‘çš„ç›®æ ‡ä¸ä»…ä»…æ˜¯è·å¾—æœ€ç»ˆçš„ PowerPoint æ¼”ç¤ºæ–‡ç¨¿ï¼›æˆ‘è¿˜å¸Œæœ›èƒ½è®¿é—®ä¸­é—´ç»“æœï¼Œä»¥ä¾¿åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­è§‚å¯Ÿã€è°ƒæ•´å’Œæ’é™¤æ•…éšœã€‚

+   æˆ‘éœ€è¦ä¸€ä¸ªä¸€ä½“åŒ–çš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿç«¯åˆ°ç«¯å¤„ç†æ‰€æœ‰ä»»åŠ¡ï¼Œè€Œæ— éœ€åœ¨ä¸åŒçš„å·¥å…·ä¹‹é—´åˆ‡æ¢æ¥è¿›è¡Œæ‘˜è¦æˆ–åˆ›å»ºå¹»ç¯ç‰‡ç­‰ä»»åŠ¡ã€‚

+   å¦‚æœæˆ‘çš„éœ€æ±‚å‘ç”Ÿå˜åŒ–ï¼Œæˆ‘å¯ä»¥è½»æ¾åœ°æ‰©å±•æˆ–ä¿®æ”¹å·¥ä½œæµã€‚

æˆ‘å°†è®¾ç½®ä¸€ä¸ªå·¥ä½œæµï¼Œç”¨æˆ·æä¾›ä¸€ä¸ªç ”ç©¶ä¸»é¢˜ï¼ˆä¾‹å¦‚ï¼šâ€œ*ä½¿ç”¨ GenAI åˆ¶ä½œ PowerPoint å¹»ç¯ç‰‡*â€ï¼‰ï¼Œç„¶åä» arxiv.org ç½‘ç«™æ‹‰å–å‡ ç¯‡è®ºæ–‡ï¼Œå¹¶ä½¿ç”¨ LLM å¯¹æ¯ç¯‡è®ºæ–‡è¿›è¡Œæ€»ç»“ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘å¸Œæœ›æ€»ç»“çš„ä¸€äº›å…³é”®ä¿¡æ¯åŒ…æ‹¬ï¼šæ–¹æ³•ç±»å‹ã€æ¨¡å‹çš„ç»„ä»¶ã€é¢„è®­ç»ƒæˆ–å¾®è°ƒæ–¹æ³•ã€æ•°æ®é›†ã€è¯„ä¼°æ–¹æ³•æŒ‡æ ‡å’Œç»“è®ºã€‚æ‰€æœ‰è¿™äº›çš„è¾“å‡ºå°†æ˜¯ä¸€ä¸ª PowerPoint æ¼”ç¤ºæ–‡ç¨¿ï¼Œæ¯ç¯‡è®ºæ–‡ä¸€å¼ å¹»ç¯ç‰‡ï¼ŒåŒ…å«æ¥è‡ªæ€»ç»“çš„å…³é”®æ´è§ã€‚

åœ¨æˆ‘è§£é‡Šå¦‚ä½•å®ç°è¿™ä¸ªå·¥ä½œæµä¹‹å‰ï¼Œç†è§£ LlamaIndex å·¥ä½œæµä¸­çš„ä¸¤ä¸ªå…³é”®æ¦‚å¿µéå¸¸é‡è¦ï¼š`äº‹ä»¶`å’Œ`æ­¥éª¤`ã€‚

+   `æ­¥éª¤`ï¼šæ­¥éª¤æ˜¯å·¥ä½œæµçš„æ„å»ºå—ã€‚å®ƒä»¬æ˜¯ä»£è¡¨å·¥ä½œæµå„ä¸ªç»„ä»¶çš„ Python å‡½æ•°ã€‚æ¯ä¸ªæ­¥éª¤æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œå¦‚å‘é€ç½‘é¡µæŸ¥è¯¢ã€è·å– LLM å“åº”æˆ–å¤„ç†æ•°æ®ã€‚æ­¥éª¤å¯ä»¥é€šè¿‡æ¥æ”¶å’Œå‘å‡ºäº‹ä»¶ä¸å…¶ä»–æ­¥éª¤è¿›è¡Œäº¤äº’ã€‚æ­¥éª¤è¿˜å¯ä»¥è®¿é—®å…±äº«çš„ä¸Šä¸‹æ–‡ï¼Œä»è€Œå®ç°è·¨ä¸åŒæ­¥éª¤çš„çŠ¶æ€ç®¡ç†ã€‚

+   `Event`ï¼šäº‹ä»¶ä½œä¸ºæ•°æ®æ‰¿è½½ä½“å’Œå·¥ä½œæµçš„æµç¨‹æ§åˆ¶å™¨ï¼Œä»¥ Pydantic å¯¹è±¡çš„å½¢å¼å®ç°ã€‚å®ƒä»¬æ§åˆ¶å·¥ä½œæµçš„æ‰§è¡Œè·¯å¾„ï¼Œä½¿å·¥ä½œæµå…·æœ‰åŠ¨æ€æ€§å’Œçµæ´»æ€§ã€‚ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰äº‹ä»¶çš„å±æ€§ã€‚ä¸¤ä¸ªé¢„å®šä¹‰çš„ç‰¹æ®Šäº‹ä»¶ç±»å‹`StartEvent`å’Œ`StopEvent`æ§åˆ¶å·¥ä½œæµçš„å¼€å§‹å’Œç»“æŸç‚¹ã€‚

LlamaIndex æä¾›äº†[å‡ ä¸ªç¬”è®°æœ¬ç¤ºä¾‹](https://docs.llamaindex.ai/en/stable/understanding/workflows/)å’Œ[è§†é¢‘ç³»åˆ—](https://www.youtube.com/@LlamaIndex/videos)ï¼Œè¯¦ç»†ä»‹ç»äº†è¿™äº›æ¦‚å¿µã€‚

é™¤äº†åŸºæœ¬ç»„ä»¶å¤–ï¼Œæˆ‘çš„å·¥ä½œæµè¿˜ä½¿ç”¨äº†ï¼š

+   **å¼‚æ­¥å’Œå¹¶è¡Œæ‰§è¡Œ**ï¼šä¸ºäº†æé«˜æ•ˆç‡ï¼Œèƒ½å¤Ÿå¹¶å‘åœ°å®Œæˆå¤šä¸ªä»»åŠ¡ã€‚

+   **åµŒå¥—å·¥ä½œæµ**ï¼šå·¥ä½œæµä¸­æ›´å¤æ‚çš„å±‚çº§ç»“æ„ã€‚

+   **LLM çš„ç»“æ„åŒ–è¾“å‡º**ï¼šä¸ºäº†ç¡®ä¿æ•°æ®åœ¨æ­¥éª¤ä¹‹é—´ä¼ é€’æ—¶æ˜¯ç»“æ„åŒ–çš„ã€‚

+   **ä¸åŒçš„ LLM æ¨¡å‹**ï¼šä¸ºäº†åœ¨æ­¥éª¤ä¹‹é—´ä½¿ç”¨å…·æœ‰ä¸åŒèƒ½åŠ›å’Œæ¨ç†é€Ÿåº¦çš„æ¨¡å‹ï¼ˆ`gpt-4o`å’Œ`gpt-4o-mini`ï¼‰ã€‚

+   **ä»£ç æ‰§è¡Œçš„åŠ¨æ€ä¼šè¯**ï¼šä¸ºäº†å…è®¸åœ¨éš”ç¦»ç¯å¢ƒä¸­æ‰§è¡Œä»£ç ã€‚

+   **ä¸åŒæ­¥éª¤çš„ç‹¬ç«‹ä»£ç†**ï¼šåœ¨è¿‡ç¨‹ä¸­ä½¿ç”¨ç‰¹å®šçš„ä»£ç†æ¥å¤„ç†ç‰¹å®šä»»åŠ¡ã€‚

ä½ å¯ä»¥åœ¨[Github](https://github.com/lz-chen/research-agent)ä¸Šæ‰¾åˆ°è¿™ä¸ªå·¥ä½œæµçš„å®Œæ•´ä»£ç ã€‚è¦è¿è¡Œå®ƒï¼Œä½ éœ€è¦ Tavily æœç´¢ã€Semantic Scholar å’Œ Azure OpenAI çš„ API å¯†é’¥ï¼ˆç”±äºè¿™ä¸ªå®ç°ä½¿ç”¨äº† Azure èµ„æºï¼Œä½†ä½ å¯ä»¥å¾ˆå®¹æ˜“åœ°å°†å…¶åˆ‡æ¢ä¸º OpenAI æˆ–å…¶ä»–æ¨¡å‹ï¼Œä½¿ç”¨ LlamaIndexï¼‰ã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œæˆ‘å°†ä»‹ç»ä¸€äº›æ„å»ºè¿™ä¸ªå·¥ä½œæµçš„å…³é”®ç»†èŠ‚å’Œæ­¥éª¤ã€‚

# ä¸»å·¥ä½œæµ

ä¸»å·¥ä½œæµç”±ä¸¤ä¸ªåµŒå¥—çš„å­å·¥ä½œæµç»„æˆï¼š

+   `summary_gen`ï¼šè¿™ä¸ªå­å·¥ä½œæµä¼šæŸ¥æ‰¾ç»™å®šä¸»é¢˜çš„ç ”ç©¶è®ºæ–‡å¹¶ç”Ÿæˆæ‘˜è¦ã€‚å®ƒé€šè¿‡ç½‘é¡µæŸ¥è¯¢è¿›è¡Œæ–‡çŒ®æ£€ç´¢ï¼Œå¹¶åˆ©ç”¨ LLM æ ¹æ®æŒ‡ç¤ºè·å–è§è§£å’Œæ‘˜è¦ã€‚

+   `slide_gen`ï¼šè¿™ä¸ªå­å·¥ä½œæµè´Ÿè´£ä½¿ç”¨å‰ä¸€æ­¥çš„æ‘˜è¦ç”Ÿæˆ PowerPoint å¹»ç¯ç‰‡ã€‚å®ƒä½¿ç”¨æä¾›çš„ PowerPoint æ¨¡æ¿æ ¼å¼åŒ–å¹»ç¯ç‰‡ï¼Œå¹¶é€šè¿‡åˆ›å»ºå’Œæ‰§è¡Œ Python ä»£ç ï¼ˆä½¿ç”¨`python-pptx`åº“ï¼‰ç”Ÿæˆå¹»ç¯ç‰‡ã€‚

![](img/96f12d1104e4621f16076bdf2db26ea8.png)

ä¸»å·¥ä½œæµæ¦‚è¿°ï¼ˆä½œè€…æä¾›çš„å›¾åƒï¼‰

# æ‘˜è¦ç”Ÿæˆå­å·¥ä½œæµ

è®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹è¿™äº›å­å·¥ä½œæµã€‚é¦–å…ˆæ˜¯`summary_gen`å·¥ä½œæµï¼Œå®ƒç›¸å½“ç®€å•ã€‚å®ƒéµå¾ªä¸€ä¸ªç®€å•çš„çº¿æ€§è¿‡ç¨‹ã€‚å®ƒåŸºæœ¬ä¸Šä½œä¸ºä¸€ä¸ªâ€œæ•°æ®å¤„ç†â€å·¥ä½œæµï¼ŒæŸäº›æ­¥éª¤ä¼šå‘ LLM å‘é€è¯·æ±‚ã€‚

![](img/6b509b343f1fef98f8c97632785d934f.png)

æ‘˜è¦ç”Ÿæˆå·¥ä½œæµï¼ˆä½œè€…æä¾›çš„å›¾åƒï¼‰

å·¥ä½œæµé¦–å…ˆé€šè¿‡è·å–ç”¨æˆ·è¾“å…¥ï¼ˆä¸€ä¸ªç ”ç©¶ä¸»é¢˜ï¼‰å¼€å§‹ï¼Œå¹¶ç»è¿‡ä»¥ä¸‹æ­¥éª¤ï¼š

+   `tavily_query`ï¼šä½¿ç”¨ Tavily API æŸ¥è¯¢ä¸ä¸»é¢˜ç›¸å…³çš„å­¦æœ¯è®ºæ–‡ï¼Œå¹¶è¿”å›ç»“æ„åŒ–çš„å“åº”ã€‚

+   `get_paper_with_citations`ï¼šå¯¹äºä» Tavily æŸ¥è¯¢è¿”å›çš„æ¯ç¯‡è®ºæ–‡ï¼Œæ­¤æ­¥éª¤ä½¿ç”¨ SemanticScholar API è·å–è®ºæ–‡å…ƒæ•°æ®ä»¥åŠè¢«å¼•ç”¨è®ºæ–‡çš„å…ƒæ•°æ®ã€‚

+   `filter_papers`ï¼šç”±äºå¹¶éæ‰€æœ‰æ£€ç´¢åˆ°çš„å¼•ç”¨éƒ½ä¸åŸå§‹ä¸»é¢˜ç›´æ¥ç›¸å…³ï¼Œå› æ­¤æ­¤æ­¥éª¤å¯¹ç»“æœè¿›è¡Œç²¾ç‚¼ã€‚æ¯ç¯‡è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ä¼šè¢«å‘é€åˆ° LLMï¼Œä»¥è¯„ä¼°å®ƒä»¬çš„ç›¸å…³æ€§ã€‚æ­¤æ­¥éª¤å®šä¹‰å¦‚ä¸‹ï¼š

```py
@step(num_workers=4)
async def filter_papers(self, ev: PaperEvent) -> FilteredPaperEvent:
    llm = new_gpt4o_mini(temperature=0.0)
    response = await process_citation(ev.paper, llm)
    return FilteredPaperEvent(paper=ev.paper, is_relevant=response)
```

åœ¨`process_citation()`å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨[LlamaIndex çš„ FunctionCallingProgram](https://docs.llamaindex.ai/en/stable/examples/output_parsing/function_program/)æ¥è·å–ç»“æ„åŒ–çš„å“åº”ï¼š

```py
IS_CITATION_RELEVANT_PMT = """
You help a researcher decide whether a paper is relevant to their current research topic: {topic}
You are given the title and abstract of a paper.
title: {title}
abstract: {abstract}

Give a score indicating the relevancy to the research topic, where:
Score 0: Not relevant
Score 1: Somewhat relevant
Score 2: Very relevant

Answer with integer score 0, 1 or 2 and your reason.
"""

class IsCitationRelevant(BaseModel):
    score: int
    reason: str

async def process_citation(citation, llm):
    program = FunctionCallingProgram.from_defaults(
        llm=llm,
        output_cls=IsCitationRelevant,
        prompt_template_str=IS_CITATION_RELEVANT_PMT,
        verbose=True,
    )
    response = await program.acall(
        title=citation.title,
        abstract=citation.summary,
        topic=citation.topic,
        description="Data model for whether the paper is relevant to the research topic.",
    )
    return response
```

+   `download_papers`ï¼šæ­¤æ­¥éª¤æ”¶é›†æ‰€æœ‰ç­›é€‰åçš„è®ºæ–‡ï¼Œæ ¹æ®ç›¸å…³æ€§å¾—åˆ†å’Œåœ¨ ArXiv ä¸Šçš„å¯ç”¨æ€§å¯¹å®ƒä»¬è¿›è¡Œä¼˜å…ˆçº§æ’åºï¼Œå¹¶ä¸‹è½½æœ€ç›¸å…³çš„è®ºæ–‡ã€‚

+   `paper2summary_dispatcher`ï¼šæ¯ç¯‡ä¸‹è½½çš„è®ºæ–‡éƒ½ä¼šä¸ºç”Ÿæˆæ‘˜è¦è¿›è¡Œå‡†å¤‡ï¼Œé€šè¿‡è®¾ç½®å­˜å‚¨å›¾åƒå’Œæ‘˜è¦çš„è·¯å¾„ã€‚æ­¤æ­¥éª¤ä½¿ç”¨`self.send_event()`æ¥å¯ç”¨æ¯ç¯‡è®ºæ–‡çš„`paper2summary`æ­¥éª¤å¹¶è¡Œæ‰§è¡Œã€‚å®ƒè¿˜é€šè¿‡å˜é‡`ctx.data[â€œn_pdfsâ€]`è®¾ç½®å·¥ä½œæµä¸Šä¸‹æ–‡ä¸­çš„è®ºæ–‡æ•°é‡ï¼Œä»¥ä¾¿åç»­æ­¥éª¤çŸ¥é“éœ€è¦å¤„ç†çš„è®ºæ–‡æ€»æ•°ã€‚

```py
@step(pass_context=True)
async def paper2summary_dispatcher(
    self, ctx: Context, ev: Paper2SummaryDispatcherEvent
) -> Paper2SummaryEvent:
    ctx.data["n_pdfs"] = 0
    for pdf_name in Path(ev.papers_path).glob("*.pdf"):
        img_output_dir = self.papers_images_path / pdf_name.stem
        img_output_dir.mkdir(exist_ok=True, parents=True)
        summary_fpath = self.paper_summary_path / f"{pdf_name.stem}.md"
        ctx.data["n_pdfs"] += 1
        self.send_event(
            Paper2SummaryEvent(
                pdf_path=pdf_name,
                image_output_dir=img_output_dir,
                summary_path=summary_fpath,
            )
        )
```

+   `paper2summary`ï¼šå¯¹äºæ¯ç¯‡è®ºæ–‡ï¼Œå®ƒå°† PDF è½¬æ¢ä¸ºå›¾åƒï¼Œç„¶åå°†å›¾åƒå‘é€åˆ° LLM è¿›è¡Œæ‘˜è¦ç”Ÿæˆã€‚ä¸€æ—¦ç”Ÿæˆæ‘˜è¦ï¼Œå®ƒä¼šä¿å­˜åœ¨ä¸€ä¸ª Markdown æ–‡ä»¶ä¸­ï¼Œä»¥ä¾›å°†æ¥å‚è€ƒã€‚ç‰¹åˆ«åœ°ï¼Œè¿™é‡Œç”Ÿæˆçš„æ‘˜è¦éå¸¸è¯¦ç»†ï¼Œåƒä¸€ç¯‡å°æ–‡ç« ï¼Œå› æ­¤è¿˜ä¸å¤ªé€‚åˆç›´æ¥æ”¾å…¥æ¼”ç¤ºæ–‡ç¨¿ä¸­ã€‚ä½†å®ƒä¼šè¢«ä¿ç•™ä¸‹æ¥ï¼Œä»¥ä¾¿ç”¨æˆ·æŸ¥çœ‹è¿™äº›ä¸­é—´ç»“æœã€‚åœ¨åç»­çš„æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿è¿™äº›ä¿¡æ¯æ›´å…·å¯å±•ç¤ºæ€§ã€‚æä¾›ç»™ LLM çš„æç¤ºåŒ…å«å…³é”®æŒ‡ä»¤ï¼Œä»¥ç¡®ä¿ç”Ÿæˆå‡†ç¡®ä¸”ç®€æ˜çš„æ‘˜è¦ï¼š

```py
SUMMARIZE_PAPER_PMT = """
You are an AI specialized in summarizing scientific papers.
 Your goal is to create concise and informative summaries, with each section preferably around 100 words and 
 limited to a maximum of 200 words, focusing on the core approach, methodology, datasets,
 evaluation details, and conclusions presented in the paper. After you summarize the paper,
 save the summary as a markdown file.

Instructions:
- Key Approach: Summarize the main approach or model proposed by the authors.
 Focus on the core idea behind their method, including any novel techniques, algorithms, or frameworks introduced.
- Key Components/Steps: Identify and describe the key components or steps in the model or approach.
 Break down the architecture, modules, or stages involved, and explain how each contributes to the overall method.
- Model Training/Finetuning: Explain how the authors trained or finetuned their model.
 Include details on the training process, loss functions, optimization techniques, 
 and any specific strategies used to improve the modelâ€™s performance.
- Dataset Details: Provide an overview of the datasets used in the study.
 Include information on the size, type and source. Mention whether the dataset is publicly available
 and if there are any benchmarks associated with it.
- Evaluation Methods and Metrics: Detail the evaluation process used to assess the model's performance.
 Include the methods, benchmarks, and metrics employed.
- Conclusion: Summarize the conclusions drawn by the authors. Include the significance of the findings, 
any potential applications, limitations acknowledged by the authors, and suggested future work.

Ensure that the summary is clear and concise, avoiding unnecessary jargon or overly technical language.
 Aim to be understandable to someone with a general background in the field.
 Ensure that all details are accurate and faithfully represent the content of the original paper. 
 Avoid introducing any bias or interpretation beyond what is presented by the authors. Do not add any
 information that is not explicitly stated in the paper. Stick to the content presented by the authors.

"""
```

+   `finish`ï¼šæ­¤å·¥ä½œæµæ”¶é›†æ‰€æœ‰ç”Ÿæˆçš„æ‘˜è¦ï¼ŒéªŒè¯å®ƒä»¬æ˜¯å¦æ­£ç¡®å­˜å‚¨ï¼Œå¹¶è®°å½•æµç¨‹çš„å®Œæˆæƒ…å†µï¼Œå¹¶è¿”å›`StopEvent`ä½œä¸ºæœ€ç»ˆç»“æœã€‚

å¦‚æœæ­¤å·¥ä½œæµç‹¬ç«‹è¿è¡Œï¼Œæ‰§è¡Œå°†åœ¨æ­¤å¤„ç»“æŸã€‚ç„¶è€Œï¼Œç”±äºè¿™æ˜¯ä¸»æµç¨‹çš„ä¸€ä¸ªå­å·¥ä½œæµï¼Œå®Œæˆåå°†è§¦å‘ä¸‹ä¸€ä¸ªå­å·¥ä½œæµâ€”â€”`slide_gen`ã€‚

# å¹»ç¯ç‰‡ç”Ÿæˆå­å·¥ä½œæµ

æ­¤å·¥ä½œæµåŸºäºå‰ä¸€æ­¥éª¤ä¸­åˆ›å»ºçš„æ‘˜è¦ç”Ÿæˆå¹»ç¯ç‰‡ã€‚ä»¥ä¸‹æ˜¯`slide_gen`å·¥ä½œæµçš„æ¦‚è¿°ï¼š

![](img/573a6a77435fb934c9b90afff1c6acce.png)

å¹»ç¯ç‰‡ç”Ÿæˆå·¥ä½œæµï¼ˆå›¾ç‰‡æ¥è‡ªä½œè€…ï¼‰

å½“å‰ä¸€ä¸ªå­å·¥ä½œæµå®Œæˆä¸”æ‘˜è¦ Markdown æ–‡ä»¶å‡†å¤‡å¥½æ—¶ï¼Œå¯åŠ¨ä»¥ä¸‹å·¥ä½œæµï¼š

+   `get_summaries`ï¼šæ­¤æ­¥éª¤è¯»å–æ‘˜è¦æ–‡ä»¶çš„å†…å®¹ï¼Œé’ˆå¯¹æ¯ä¸ªæ–‡ä»¶è§¦å‘`SummaryEvent`ï¼Œå†æ¬¡ä½¿ç”¨`self.send_event()`ä»¥ä¾¿å¯ç”¨å¹¶è¡Œæ‰§è¡Œï¼Œä¿ƒè¿›æ›´å¿«é€Ÿçš„å¤„ç†ã€‚

+   `summary2outline`ï¼šæ­¤æ­¥éª¤é€šè¿‡ä½¿ç”¨ LLM å°†æ‘˜è¦è½¬åŒ–ä¸ºå¹»ç¯ç‰‡å¤§çº²æ–‡æœ¬ã€‚å®ƒå°†æ‘˜è¦ç¼©çŸ­ä¸ºå¥å­æˆ–é¡¹ç›®ç¬¦å·ï¼Œä»¥ä¾¿æ”¾å…¥æ¼”ç¤ºæ–‡ç¨¿ä¸­ã€‚

+   `gather_feedback_outline`ï¼šåœ¨æ­¤æ­¥éª¤ä¸­ï¼Œå®ƒå°†æè®®çš„å¹»ç¯ç‰‡å¤§çº²ä¸è®ºæ–‡æ‘˜è¦ä¸€èµ·å‘ˆç°ç»™ç”¨æˆ·ä»¥ä¾›ä»–ä»¬å®¡é˜…ã€‚ç”¨æˆ·æä¾›åé¦ˆï¼Œå¦‚æœéœ€è¦ä¿®æ”¹ï¼Œå¯èƒ½ä¼šè§¦å‘`OutlineFeedbackEvent`ã€‚è¿™ä¸ªåé¦ˆå¾ªç¯ä¼šç»§ç»­è¿›è¡Œï¼Œç›´åˆ°ç”¨æˆ·æ‰¹å‡†æœ€ç»ˆå¤§çº²ä¸ºæ­¢ï¼Œå±Šæ—¶ä¼šè§¦å‘`OutlineOkEvent`ã€‚  

```py
@step(pass_context=True)
async def gather_feedback_outline(
    self, ctx: Context, ev: OutlineEvent
) -> OutlineFeedbackEvent | OutlineOkEvent:
    """Present user the original paper summary and the outlines generated, gather feedback from user"""
    print(f"the original summary is: {ev.summary}")
    print(f"the outline is: {ev.outline}")
    print("Do you want to proceed with this outline? (yes/no):")
    feedback = input()
    if feedback.lower().strip() in ["yes", "y"]:
        return OutlineOkEvent(summary=ev.summary, outline=ev.outline)
    else:
        print("Please provide feedback on the outline:")
        feedback = input()
        return OutlineFeedbackEvent(
            summary=ev.summary, outline=ev.outline, feedback=feedback
        )
```

+   `outlines_with_layout`ï¼šå®ƒé€šè¿‡åŒ…æ‹¬æ¥è‡ªç»™å®š PowerPoint æ¨¡æ¿çš„é¡µé¢å¸ƒå±€ç»†èŠ‚ï¼Œä½¿ç”¨ LLM å¢å¼ºæ¯ä¸ªå¹»ç¯ç‰‡å¤§çº²ã€‚åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæ‰€æœ‰å¹»ç¯ç‰‡é¡µé¢çš„å†…å®¹å’Œè®¾è®¡éƒ½ä¼šä¿å­˜åœ¨ä¸€ä¸ª JSON æ–‡ä»¶ä¸­ã€‚  

+   `slide_gen`ï¼šå®ƒä½¿ç”¨**ReAct ä»£ç†**æ ¹æ®ç»™å®šçš„å¤§çº²å’Œå¸ƒå±€ç»†èŠ‚åˆ¶ä½œå¹»ç¯ç‰‡æ–‡æ¡£ã€‚è¿™ä¸ªä»£ç†å…·æœ‰ä¸€ä¸ª[ä»£ç è§£é‡Šå™¨å·¥å…·](https://llamahub.ai/l/tools/llama-index-tools-azure-code-interpreter?from=all)ï¼Œå¯ä»¥åœ¨éš”ç¦»ç¯å¢ƒä¸­è¿è¡Œå’Œä¿®æ­£ä»£ç ï¼Œè¿˜å…·æœ‰ä¸€ä¸ªå¸ƒå±€æ£€æŸ¥å·¥å…·ï¼Œç”¨æ¥æŸ¥çœ‹ç»™å®šçš„ PowerPoint æ¨¡æ¿ä¿¡æ¯ã€‚è¯¥ä»£ç†ä¼šä½¿ç”¨`python-pptx`æ¥åˆ›å»ºå¹»ç¯ç‰‡ï¼Œå¹¶èƒ½è§‚å¯Ÿå¹¶ä¿®æ­£é”™è¯¯ã€‚  

```py
 @step(pass_context=True)
async def slide_gen(
    self, ctx: Context, ev: OutlinesWithLayoutEvent
) -> SlideGeneratedEvent:
    agent = ReActAgent.from_tools(
        tools=self.azure_code_interpreter.to_tool_list() + [self.all_layout_tool],
        llm=new_gpt4o(0.1),
        verbose=True,
        max_iterations=50,
    )

    prompt = (
        SLIDE_GEN_PMT.format(
            json_file_path=ev.outlines_fpath.as_posix(),
            template_fpath=self.slide_template_path,
            final_slide_fname=self.final_slide_fname,
        )
        + REACT_PROMPT_SUFFIX
    )
    agent.update_prompts({"agent_worker:system_prompt": PromptTemplate(prompt)})

    res = self.azure_code_interpreter.upload_file(
        local_file_path=self.slide_template_path
    )
    logging.info(f"Uploaded file to Azure: {res}")

    response = agent.chat(
        f"An example of outline item in json is {ev.outline_example.json()},"
        f" generate a slide deck"
    )
    local_files = self.download_all_files_from_session()
    return SlideGeneratedEvent(
        pptx_fpath=f"{self.workflow_artifacts_path}/{self.final_slide_fname}"
    )
```

+   `validate_slides`ï¼šæ£€æŸ¥å¹»ç¯ç‰‡æ–‡æ¡£ï¼Œç¡®ä¿å®ƒç¬¦åˆç»™å®šçš„æ ‡å‡†ã€‚è¿™ä¸ªæ­¥éª¤åŒ…æ‹¬å°†å¹»ç¯ç‰‡è½¬åŒ–ä¸ºå›¾åƒï¼Œå¹¶è®© LLM æ ¹æ®æŒ‡å—å¯¹å…¶è¿›è¡Œè§†è§‰æ£€æŸ¥ï¼Œä»¥ç¡®ä¿å†…å®¹æ­£ç¡®ä¸”é£æ ¼ä¸€è‡´ã€‚æ ¹æ® LLM çš„å‘ç°ï¼Œå¦‚æœæœ‰é—®é¢˜ï¼Œå®ƒä¼šå‘é€`SlideValidationEvent`ï¼Œå¦‚æœä¸€åˆ‡çœ‹èµ·æ¥è‰¯å¥½ï¼Œåˆ™ä¼šå‘é€`StopEvent`ã€‚  

```py
@step(pass_context=True)
async def validate_slides(
    self, ctx: Context, ev: SlideGeneratedEvent
) -> StopEvent | SlideValidationEvent:
    """Validate the generated slide deck"""
    ctx.data["n_retry"] += 1
    ctx.data["latest_pptx_file"] = Path(ev.pptx_fpath).name
    img_dir = pptx2images(Path(ev.pptx_fpath))
    image_documents = SimpleDirectoryReader(img_dir).load_data()
    llm = mm_gpt4o
    program = MultiModalLLMCompletionProgram.from_defaults(
        output_parser=PydanticOutputParser(SlideValidationResult),
        image_documents=image_documents,
        prompt_template_str=SLIDE_VALIDATION_PMT,
        multi_modal_llm=llm,
        verbose=True,
    )
    response = program()
    if response.is_valid:
        return StopEvent(
            self.workflow_artifacts_path.joinpath(self.final_slide_fname)
        )
    else:
        if ctx.data["n_retry"] < self.max_validation_retries:
            return SlideValidationEvent(result=response)
        else:
            return StopEvent(
                f"The slides are not fixed after {self.max_validation_retries} retries!"
            )
```

ç”¨äºéªŒè¯çš„æ ‡å‡†æ˜¯ï¼š  

```py
SLIDE_VALIDATION_PMT = """
You are an AI that validates the slide deck generated according to following rules:
- The slide need to have a front page 
- The slide need to have a final page (e.g. a 'thank you' or 'questions' page)
- The slide texts are clearly readable, not cut off, not overflowing the textbox
 and not overlapping with other elements

If any of the above rules are violated, you need to provide the index of the slide that violates the rule,
 as well as suggestion on how to fix it. 

"""
```

+   `modify_slides`ï¼šå¦‚æœå¹»ç¯ç‰‡æœªé€šè¿‡éªŒè¯æ£€æŸ¥ï¼Œä¸Šä¸€é˜¶æ®µä¼šå‘é€`SlideValidationEvent`äº‹ä»¶ã€‚åœ¨è¿™é‡Œï¼Œå¦ä¸€ä¸ª**ReAct ä»£ç†**ä¼šæ ¹æ®éªŒè¯åé¦ˆæ›´æ–°å¹»ç¯ç‰‡ï¼Œæ›´æ–°åçš„å¹»ç¯ç‰‡å°†è¢«ä¿å­˜å¹¶è¿”å›è¿›è¡Œå†æ¬¡éªŒè¯ã€‚æ ¹æ®`SlideGenWorkflow`ç±»çš„`max_validation_retries`å˜é‡å±æ€§ï¼Œè¿™ä¸ªéªŒè¯å¾ªç¯å¯èƒ½ä¼šå¤šæ¬¡å‘ç”Ÿã€‚  

ä¸ºäº†è¿è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯å·¥ä½œæµï¼Œæˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ­¥éª¤å¯åŠ¨è¿‡ç¨‹ï¼š  

```py
class SummaryAndSlideGenerationWorkflow(Workflow):
    @step
    async def summary_gen(
        self, ctx: Context, ev: StartEvent, summary_gen_wf: SummaryGenerationWorkflow
    ) -> SummaryWfReadyEvent:
        print("Need to run reflection")
        res = await summary_gen_wf.run(user_query=ev.user_query)
        return SummaryWfReadyEvent(summary_dir=res)

    @step
    async def slide_gen(
        self, ctx: Context, ev: SummaryWfReadyEvent, slide_gen_wf: SlideGenerationWorkflow
    ) -> StopEvent:
        res = await slide_gen_wf.run(file_dir=ev.summary_dir)
        return StopEvent()

async def run_workflow(user_query: str):
    wf = SummaryAndSlideGenerationWorkflow(timeout=2000, verbose=True)
    wf.add_workflows(
        summary_gen_wf=SummaryGenerationWorkflow(timeout=800, verbose=True)
    )
    wf.add_workflows(slide_gen_wf=SlideGenerationWorkflow(timeout=1200, verbose=True))
    result = await wf.run(
        user_query=user_query,
    )
    print(result)

@click.command()
@click.option(
    "--user-query",
    "-q",
    required=False,
    help="The user query",
    default="powerpoint slides automation",
)
def main(user_query: str):
    asyncio.run(run_workflow(user_query))

if __name__ == "__main__":
    draw_all_possible_flows(
        SummaryAndSlideGenerationWorkflow, filename="summary_slide_gen_flows.html"
    )
    main()
```

# ç»“æœ  

ç°åœ¨è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹ä¸ºè®ºæ–‡[*LayoutGPT: åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç»„åˆè§†è§‰è§„åˆ’ä¸ç”Ÿæˆ*](https://arxiv.org/abs/2305.15393)ç”Ÿæˆçš„ä¸€ä¸ªä¸­é—´æ€»ç»“ç¤ºä¾‹ï¼š  

```py
 # Summary of "LayoutGPT: Compositional Visual Planning and Generation with Large Language Models"

## Key Approach
The paper introduces LayoutGPT, a framework leveraging large language models (LLMs) for compositional visual planning and generation. The core idea is to utilize LLMs to generate 2D and 3D scene layouts from textual descriptions, integrating numerical and spatial reasoning. LayoutGPT employs a novel prompt construction method and in-context learning to enhance the model's ability to understand and generate complex visual scenes.

## Key Components/Steps
1\. **Prompt Construction**: LayoutGPT uses detailed task instructions and CSS-like structures to guide the LLMs in generating layouts.
2\. **In-Context Learning**: Demonstrative exemplars are provided to the LLMs to improve their understanding and generation capabilities.
3\. **Numerical and Spatial Reasoning**: The model incorporates reasoning capabilities to handle numerical and spatial relationships in scene generation.
4\. **Scene Synthesis**: LayoutGPT generates 2D keypoint layouts and 3D scene layouts, ensuring spatial coherence and object placement accuracy.

## Model Training/Finetuning
LayoutGPT is built on GPT-3.5 and GPT-4 models, utilizing in-context learning rather than traditional finetuning. The training process involves providing the model with structured prompts and examples to guide its generation process. Loss functions and optimization techniques are not explicitly detailed, as the focus is on leveraging pre-trained LLMs with minimal additional training.

## Dataset Details
The study uses several datasets:
- **NSR-1K**: A new benchmark for numerical and spatial reasoning, created from MSCOCO annotations.
- **3D-FRONT**: Used for 3D scene synthesis, containing diverse indoor scenes.
- **HRS-Bench**: For evaluating color binding accuracy in generated scenes.
These datasets are publicly available and serve as benchmarks for evaluating the model's performance.

## Evaluation Methods and Metrics
The evaluation involves:
- **Quantitative Metrics**: Precision, recall, and F1 scores for layout accuracy, numerical reasoning, and spatial reasoning.
- **Qualitative Analysis**: Visual inspection of generated scenes to assess spatial coherence and object placement.
- **Comparative Analysis**: Benchmarking against existing methods like GLIGEN and ATISS to demonstrate improvements in layout generation.

## Conclusion
The authors conclude that LayoutGPT effectively integrates LLMs for visual planning and scene generation, achieving state-of-the-art performance in 2D and 3D layout tasks. The framework's ability to handle numerical and spatial reasoning is highlighted as a significant advancement. Limitations include the focus on specific scene types and the need for further exploration of additional visual reasoning tasks. Future work suggests expanding the model's capabilities to more diverse and complex visual scenarios.
```

æ¯‹åº¸ç½®ç–‘ï¼Œæ€»ç»“å¯¹äº LLM æ¥è¯´å¹¶ä¸æ˜¯ä¸€ä¸ªç‰¹åˆ«å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚åªéœ€æä¾›è®ºæ–‡çš„å›¾åƒï¼ŒLLM ä¾¿èƒ½æœ‰æ•ˆåœ°æ•æ‰åˆ°æç¤ºä¸­æ¦‚è¿°çš„æ‰€æœ‰å…³é”®å†…å®¹ï¼Œå¹¶ä¸”ç›¸å½“å¥½åœ°éµå¾ªäº†æ ·å¼è¦æ±‚ã€‚  

è‡³äºæœ€ç»ˆç»“æœï¼Œä»¥ä¸‹æ˜¯ç”Ÿæˆçš„å‡ å¼ æ¼”ç¤ºæ–‡ç¨¿å¹»ç¯ç‰‡ç¤ºä¾‹ï¼š  

![](img/2fb32b9b194336ba795dc312262a1d0b.png)  

ç”Ÿæˆçš„å¹»ç¯ç‰‡ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰  

![](img/1ca329172991fe913dde582b525f045c.png)  

ç”Ÿæˆçš„å¹»ç¯ç‰‡ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

åœ¨å¡«å†™æ‘˜è¦å†…å®¹æ—¶ï¼ŒæŒ‰ç…§æ¨¡æ¿çš„å¸ƒå±€ä¿æŒæ–‡æœ¬é£æ ¼ï¼Œå°†æ€»ç»“è¦ç‚¹ä»¥é¡¹ç›®ç¬¦å·æ ¼å¼å‘ˆç°ï¼Œå¹¶åŒ…å«å¹»ç¯ç‰‡ä¸­æ‰€éœ€çš„æ‰€æœ‰ç›¸å…³è®ºæ–‡æ—¶ï¼Œå·¥ä½œæµç¨‹è¿è¡Œå¾—å¾ˆå¥½ã€‚å”¯ä¸€çš„é—®é¢˜æ˜¯ï¼Œæœ‰æ—¶ä¸»å†…å®¹å ä½ç¬¦ä¸­çš„æ–‡æœ¬æ²¡æœ‰è°ƒæ•´å¤§å°ä»¥é€‚åº”æ–‡æœ¬æ¡†ï¼Œæ–‡æœ¬æº¢å‡ºå¹»ç¯ç‰‡è¾¹ç•Œã€‚è¿™ç±»é”™è¯¯å¯èƒ½é€šè¿‡ä½¿ç”¨æ›´æœ‰é’ˆå¯¹æ€§çš„å¹»ç¯ç‰‡éªŒè¯æç¤ºæ¥ä¿®å¤ã€‚

# æœ€åçš„æƒ³æ³•

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ LlamaIndex å·¥ä½œæµç¨‹æ¥ç®€åŒ–æˆ‘çš„ç ”ç©¶å’Œå±•ç¤ºè¿‡ç¨‹ï¼Œä»æŸ¥è¯¢å­¦æœ¯è®ºæ–‡åˆ°ç”Ÿæˆæœ€ç»ˆçš„ PowerPoint å¹»ç¯ç‰‡ã€‚ä»¥ä¸‹æ˜¯æˆ‘åœ¨å®æ–½è¯¥å·¥ä½œæµç¨‹æ—¶çš„ä¸€äº›æƒ³æ³•å’Œè§‚å¯Ÿï¼Œä»¥åŠæˆ‘è®¤ä¸ºå¯èƒ½æ”¹è¿›çš„æ–¹é¢ã€‚

`**gpt-4o**` **æ¨¡å‹ä¸** `**gpt-4o-mini**` **æ¨¡å‹**ï¼šè™½ç„¶å£°ç§°`gpt-4o-mini`çš„æ€§èƒ½ä¸`gpt-4o`ç›¸å½“ï¼Œä½†æˆ‘å‘ç°`gpt-4o-mini`åœ¨å®Œæˆå¤æ‚ä»»åŠ¡æ—¶æ˜æ˜¾å­˜åœ¨é—®é¢˜ï¼Œå¦‚åœ¨å·¥ä½œæµç¨‹ä¸­ä½œä¸º ReAct ä»£ç†è¿›è¡Œè§„åˆ’å’Œä¿®æ­£é”™è¯¯ã€‚ç„¶è€Œï¼Œå®ƒåœ¨ç®€å•ä»»åŠ¡ï¼ˆå¦‚å†…å®¹æ‘˜è¦ï¼‰ä¸­è¡¨ç°å¾—è¶³å¤Ÿå¥½ã€‚

**åˆ›å»ºä¸­é—´æ–‡ä»¶**ï¼šç”Ÿæˆä¸­é—´æ–‡ä»¶ï¼ˆæ‘˜è¦çš„ Markdown æ–‡ä»¶å’Œæ‘˜è¦å¸ƒå±€çš„ JSON æ–‡ä»¶ï¼‰æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ–¹æ³•ï¼Œå®ƒå‡è½»äº†ä»£ç†å¿…é¡»è·Ÿè¸ªå†…å®¹å’Œå¹»ç¯ç‰‡æ ·å¼çš„è´Ÿæ‹…ï¼ŒåŒæ—¶ç”Ÿæˆå¹»ç¯ç‰‡çš„ä»£ç ã€‚

**å¤„ç†è¾¹ç¼˜æ¡ˆä¾‹**ï¼šä»å¤´åˆ°å°¾è¿è¡Œå·¥ä½œæµç¨‹æ­ç¤ºäº†è®¸å¤šè¾¹ç¼˜æ¡ˆä¾‹ï¼Œç‰¹åˆ«æ˜¯åœ¨éªŒè¯å¹»ç¯ç‰‡æ ·å¼æ—¶ã€‚ç›®å‰ï¼Œé€šè¿‡è¿­ä»£ä¿®æ”¹ç›¸å…³æç¤ºæ¥å¤„ç†è¿™äº›é—®é¢˜ã€‚ä½†æˆ‘è®¤ä¸ºï¼Œä¿ƒè¿›æŸç§ç±»å‹çš„åä½œå’Œäººç±»å‚ä¸æœºåˆ¶å°†å¤§å¤§æœ‰åŠ©äºæ­¤ï¼ŒåŒæ—¶ä¹Ÿèƒ½æä¾›æ›´é«˜çš„å‡†ç¡®æ€§ã€‚

**python-pptx çš„å±€é™æ€§**ã€‚å·¥ä½œæµç¨‹å—é™äº python-pptx åœ¨ PowerPoint å¹»ç¯ç‰‡ä¸­èƒ½å¤Ÿå®é™…æ¸²æŸ“å’Œæ“ä½œçš„å†…å®¹ã€‚å› æ­¤ï¼Œå€¼å¾—è¿›ä¸€æ­¥è€ƒè™‘å…¶ä»–é«˜æ•ˆçš„å¹»ç¯ç‰‡ç”Ÿæˆæ–¹å¼ï¼Œä¾‹å¦‚ä½¿ç”¨ VBAã€‚

**ç”¨äºæ‘˜è¦ç”Ÿæˆçš„ä»£ç†å’Œå·¥å…·**ï¼šä¸ä¸¥æ ¼çš„é€æ­¥æ‘˜è¦ç”Ÿæˆè¿‡ç¨‹ä¸åŒï¼Œä½¿ç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå…·æœ‰å·¥å…·è®¿é—®æƒé™çš„ä»£ç†ï¼ˆç›®å‰æ˜¯æ­¥éª¤å‡½æ•°ï¼‰å¯ä»¥ä½¿å·¥ä½œæµç¨‹æ›´çµæ´»ï¼Œæ›´é€‚åº”æœªæ¥çš„å˜åŒ–ã€‚

**å¢å¼ºäººç±»å‚ä¸çš„äº’åŠ¨**ã€‚ç›®å‰çš„å®ç°ä¸å…è®¸å¤ªå¤šç”¨æˆ·äº¤äº’ã€‚è®©æœ€ç»ˆç”¨æˆ·æ›´å¤šåœ°å‚ä¸å·¥ä½œæµç¨‹ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠç”¨æˆ·åˆ¤æ–­çš„ä»»åŠ¡ä¸­ï¼Œå¦‚å†…å®¹éªŒè¯å’Œç²¾ç‚¼ï¼Œè¿™éå¸¸æœ‰ç›Šã€‚ä¸€ä¸ªæ–¹æ³•æ˜¯å¢åŠ æ›´å¤šæ­¥éª¤ï¼Œå·¥ä½œæµç¨‹å¯ä»¥å‘ç”¨æˆ·è¯·æ±‚éªŒè¯ï¼Œå¹¶è€ƒè™‘ç”¨æˆ·çš„åé¦ˆã€‚äººç±»çš„å‚ä¸å¯¹äºå®æ—¶ä¿®å¤é”™è¯¯å’Œè¿›è¡Œæ›´æ”¹æ˜¯æ— ä»·çš„ã€‚

**è®ºæ–‡æŸ¥è¯¢å¼•æ“**ã€‚è¿˜å¯ä»¥ä¸ºæ¯ç¯‡è®ºæ–‡æ„å»º[æŸ¥è¯¢å¼•æ“](https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/)ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæå‡ºé—®é¢˜å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹æ‘˜è¦ã€‚è¿™æœ‰åŠ©äºå·¥ä½œæµç»“æœçš„ä¸ªæ€§åŒ–ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼ŒLlamaIndex å·¥ä½œæµæ˜¯ä¸€ä¸ªéå¸¸çµæ´»ä¸”å¯å®šåˆ¶çš„å·¥å…·ï¼Œç”¨äºæ„å»ºå¤æ‚ä¸”é‡èº«å®šåˆ¶çš„ AI è§£å†³æ–¹æ¡ˆã€‚å®ƒè®©æˆ‘å¯ä»¥è‡ªç”±å®šä¹‰æˆ‘çš„æµç¨‹ï¼ŒåŒæ—¶å…·å¤‡å¯æ§æ€§å’Œçµæ´»æ€§ï¼Œå¹¶èƒ½å¤Ÿåˆ©ç”¨åº“ä¸­çš„è®¸å¤šå†…ç½®å·¥å…·ã€‚

# ä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆï¼Ÿ

å¦‚å‰æ‰€è¿°ï¼Œä¸»è¦çš„æ”¹è¿›å°†æ˜¯**å®ç°æ›´å¤šäººæœºåä½œï¼ˆhuman-in-the-loopï¼‰**ç±»å‹çš„åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œå…è®¸è®¾ç½®æ›´å¤šçš„äº¤äº’å¼æ£€æŸ¥ç‚¹ï¼Œç”¨æˆ·å¯ä»¥åœ¨éœ€è¦æ—¶è¦†ç›–æ­¥éª¤æ‰§è¡Œï¼Œå°†äº¤äº’æ­¥éª¤é›†æˆåˆ°å·¥ä½œæµä¸­ï¼Œå¹¶æä¾›ç”¨æˆ·åœ¨ä»»ä½•é˜¶æ®µæ£€æŸ¥å·¥ä½œæµæ˜¯å¦äº§ç”Ÿæ»¡æ„è¾“å‡ºçš„æœºä¼šã€‚ä¸æä¾›æ›´å¥½ç”¨æˆ·ä½“éªŒçš„ç›®æ ‡ä¸€è‡´ï¼Œæ„å»º**Streamlit å‰ç«¯**ä¹Ÿæ˜¯ä¸€ä¸ªä¸é”™çš„è¡¥å……ï¼Œå¯ä»¥æä¾›æ›´å¤šå…³äºå·¥ä½œæµæ‰§è¡Œçš„æ·±å…¥ä¿¡æ¯ã€‚æ‹¥æœ‰å‰ç«¯å°†ä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿå®æ—¶ç›‘æ§å·¥ä½œæµçš„è¿›å±•ï¼Œå¹¶æ ¹æ®éœ€è¦æ›´å¿«é€Ÿåœ°è°ƒæ•´è½¨è¿¹ã€‚æ­¤å¤–ï¼Œè·å–ç”¨æˆ·åé¦ˆå’ŒéªŒè¯ã€å¯è§†åŒ–ä¸­é—´ç»“æœå’Œæœ€ç»ˆè¾“å‡ºå°†ä¸ºå·¥ä½œæµå¢åŠ é€æ˜åº¦ã€‚æ‰€ä»¥è¯·å…³æ³¨ä¸‹ä¸€ç¯‡æ–‡ç« ï¼Œäº†è§£è¿™äº›å˜åŒ–ï¼ğŸ˜ƒ

æ„Ÿè°¢é˜…è¯»ï¼æŸ¥çœ‹æˆ‘çš„[GitHub](https://github.com/lz-chen/research-agent)ä»¥è·å–å®Œæ•´å®ç°ã€‚æˆ‘æœŸå¾…å¬åˆ°ä½ çš„æƒ³æ³•ã€æ„è§å’Œåé¦ˆã€‚æˆ‘ç›®å‰åœ¨[Inmeta](https://inmeta.no/)æ‹…ä»»æ•°æ®ç§‘å­¦é¡¾é—®ï¼ŒInmeta æ˜¯[Crayon Group](https://www.crayon.com/no/)çš„ä¸€éƒ¨åˆ†ã€‚æ¬¢è¿åœ¨[LinkedIn](https://www.linkedin.com/in/lingzhen-chen-76720680/)ä¸æˆ‘å»ºç«‹è”ç³»ã€‚ğŸ˜Š
