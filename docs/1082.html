<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>An Undeservedly Forgotten Correlation Coefficient</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>An Undeservedly Forgotten Correlation Coefficient</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-undeservedly-forgotten-correlation-coefficient-86245ccb774c?source=collection_archive---------2-----------------------#2024-04-30">https://towardsdatascience.com/an-undeservedly-forgotten-correlation-coefficient-86245ccb774c?source=collection_archive---------2-----------------------#2024-04-30</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="29cb" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A nonlinear correlation measure for your everyday tasks</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vadim.arzamasov?source=post_page---byline--86245ccb774c--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Vadim Arzamasov" class="l ep by dd de cx" src="../Images/70ced2eafa6fc926052979875a0a4265.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*sLla8xXL0qQuaiNDqAnTiw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--86245ccb774c--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@vadim.arzamasov?source=post_page---byline--86245ccb774c--------------------------------" rel="noopener follow">Vadim Arzamasov</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--86245ccb774c--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 30, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">6</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/1d1768870561985b726ed04a98c04904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cRTk-by3DW6XWHnoXFegGQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author with recraft.ai</figcaption></figure><p id="7a61" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Traditional correlation coefficients such as Pearson <em class="ny">ρ</em>, Spearman, or Kendall’s <em class="ny">τ</em> are limited to finding linear or monotonic relationships and struggle to identify more complex association structures. The <a class="af nz" href="https://medium.com/towards-data-science/a-new-coefficient-of-correlation-64ae4f260310" rel="noopener">recent article on TDS</a> [1] about a new correlation coefficient <em class="ny">ξ</em> that aims to overcome these limitations has received a lot of attention and has been discussed intensively. One of the questions raised in the comments was what particular advantages <em class="ny">ξ</em> brings over a nonlinear correlation measure based on mutual information. An experiment may be worth a thousand words in such debates. So in this story, I experimentally compare <em class="ny">ξ</em> to the mutual information-based coefficient <em class="ny">R</em> along a variety of properties one would like a nonlinear correlation measure to satisfy. Based on the results, I would strongly recommend <em class="ny">R</em> over <em class="ny">ξ</em> for the majority of routines that require finding nonlinear associations.</p><h2 id="0b24" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Requirements</h2><p id="e130" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Let me first summarize and convince you about the desired properties of a coefficient we are looking for. We want an association measure <em class="ny">A(x,y) </em>that</p><ul class=""><li id="02cb" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pa pb pc bk">is <strong class="ne fr">nonlinear</strong>. That is, it takes the value zero when <em class="ny">x</em> and <em class="ny">y</em> are independent; it has a value of one for the modulus of the measure when there is an exact nonlinear relationship between the variables, such as <em class="ny">x = h(t), y=f(t), </em>where<em class="ny"> t </em>is a parameter<em class="ny">;</em></li><li id="8b4a" class="nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx pa pb pc bk">is <strong class="ne fr">symmetric</strong>. That is, <em class="ny">A(x,y)=A(y,x). </em>The opposite would be confusing;</li><li id="c785" class="nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx pa pb pc bk">is <strong class="ne fr">consistent</strong>. That is, it is equal to the linear correlation coefficient <em class="ny">ρ</em> when <em class="ny">x, y</em> have a bivariate normal distribution, i.e. is a generalization of <em class="ny">ρ</em> to other distributions. This is because <em class="ny">ρ</em> is widely used in practice, and many of us have developed a sense of how its values relate to the strength of the relationship. In addition, <em class="ny">ρ</em> has a clear meaning for a standard normal distribution, since it completely defines it;</li><li id="43c8" class="nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx pa pb pc bk">is <strong class="ne fr">scalable</strong> — one can compute correlations even for datasets with many observations in a reasonable time;</li><li id="ccb2" class="nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx pa pb pc bk">is <strong class="ne fr">precise</strong>, i.e., has a low variance estimator.</li></ul><p id="1025" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The table below summarizes the results of my experiments, where green indicates that the measure has the property tested, red indicates the opposite, and orange is slightly better than red. Let me now walk you through the experiments; you can find their code in this <a class="af nz" href="https://github.com/Arzik1987/medium/tree/main/nonlinear_correlation" rel="noopener ugc nofollow" target="_blank">Github repo</a> [2] in the <strong class="ne fr">R</strong> programming language.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pi"><img src="../Images/1a43b98dfd9d8fba5a8c637943b133cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*6ByT_684ih3ZTglgzYUU7Q.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author</figcaption></figure><h2 id="0769" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk"><strong class="al">Coefficients of correlation</strong></h2><p id="c3fa" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">I use the following coefficient implementations and their configurations</p><ul class=""><li id="4dc5" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pa pb pc bk">For the linear correlation coefficient <em class="ny">ρ</em>, I use the standard function <code class="cx pj pk pl pm b">cor()</code> from the ‘stats’ package;</li><li id="fc9a" class="nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx pa pb pc bk">for <em class="ny">ξ</em>, I use the <code class="cx pj pk pl pm b">xicor()</code>function from the <a class="af nz" href="https://cran.r-project.org/web/packages/XICOR/index.html" rel="noopener ugc nofollow" target="_blank">‘XICOR’ package</a> [3];</li><li id="8905" class="nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx pa pb pc bk">mutual information (MI) takes values in the range [0,∞) and there are several ways to estimate it. Therefore, for R one has to choose (a) the MI estimator to use and (b) the transformation to bring MI into the range [0,1].</li></ul><p id="59d0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There are histogram-based and nearest neighbor-based MI estimators. Although many still use histogram-based estimators, I believe that Kraskov’s nearest neighbor estimator [4] is one of the best. I will use its implementation <code class="cx pj pk pl pm b">mutinfo()</code> from the <a class="af nz" href="https://cran.r-project.org/web/packages/FNN/index.html" rel="noopener ugc nofollow" target="_blank">‘FNN’ package</a> [5] with the parameter <em class="ny">k=2</em> as suggested in the paper.</p><blockquote class="pn po pp"><p id="7f3d" class="nc nd ny ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Write in the comments if you want to know more about this particular MI estimator</p></blockquote><p id="3f68" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There are also several ways to normalize the MI to the interval [0,1]. I will use the one below because it has been shown to have a consistency property, and I will demonstrate it in the experiments.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pq"><img src="../Images/cfa6e398c2c11549289e5ed81d7de107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WMeO27mqk3PymuCnew4tug.png"/></div></div></figure><blockquote class="pn po pp"><p id="b0a1" class="nc nd ny ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This measure R is called the <strong class="ne fr">Mutual</strong> Information Coefficient [6]. However, I have noticed a tendency to confuse it with the more recent <strong class="ne fr">Maximal</strong> Information Coefficient (MIC) [7]. The latter has been shown to be worse than some alternatives [8], and to lack some of the properties it is supposed to have [9].</p></blockquote><h2 id="0e21" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Nonlinearity</h2><p id="ef8b" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">In the figure below, I have calculated all three correlation coefficients for a donut data of 10K points with different donut thickness. As expected, the linear correlation coefficient <em class="ny">ρ</em> does not capture the existence of a relationship in any of the plots. In contrast, <em class="ny">R</em> correctly determines that <em class="ny">x</em> and <em class="ny">y</em> are related and takes the value of 1 for the data in the right plot which corresponds to a noiseless relationship between <em class="ny">x</em> and <em class="ny">y</em>: <em class="ny">x = cos(t)</em> and <em class="ny">y = sin(t)</em>. However, the coefficient <em class="ny">ξ</em> is only 0.24 in the latter case. More importantly, in the left plot,<em class="ny"> ξ</em> is close to zero, even though <em class="ny">x</em> and <em class="ny">y</em> are not independent.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pr"><img src="../Images/617eddceef4ec977046f47c6680344e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aA5KQbozUTktbcppuqooTg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author</figcaption></figure><h2 id="7448" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Symmetry</h2><p id="b4e1" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">In the figure below, I calculated these quantities for data sets generated from a different distribution. I obtained <em class="ny">ρ(x,y)=ρ(y,x)</em> and <em class="ny">R(x,y)=R(y,x)</em>, so I report only a single value for these measures. However, <em class="ny">ξ(x,y)</em> and <em class="ny">ξ(y,x)</em> are very different. This is probably due to the fact that <em class="ny">y=f(x)</em>, but <em class="ny">x</em> is not a function of <em class="ny">y</em>. This behavior may not be desirable in reality, since it is not easy to interpret a non-symmetric correlation matrix.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pr"><img src="../Images/5581926845a4dd77c216c85036c7875c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zVfurijj5Kkc2EA9eNqdQQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author</figcaption></figure><h2 id="e8db" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Consistency</h2><p id="25be" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">In this experiment, I computed all coefficients for data sets resulting from a bivariate standard normal distribution with a given correlation coefficient of 0.4, 0.7, or 1. Both <em class="ny">ρ</em> and <em class="ny">R</em> are close to the true correlation, while <em class="ny">ξ </em>is not, i.e. it does not have the consistency property defined above.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pr"><img src="../Images/7399a137d4e74b6087c503cf6cdf17f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5RcwdaOy6UwSEqwNq6AuRA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author</figcaption></figure><h2 id="cf40" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Scalability</h2><p id="af15" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">To check the performance of the estimators, I generated data sets of different sizes consisting of two independent and uniformly distributed variables. The figure below shows the time in milliseconds required to compute each coefficient. When the dataset consists of 50K points, <em class="ny">R</em> is about 1000 times slower than <em class="ny">ξ </em>and about 10000 times slower than <em class="ny">ρ</em>. However, it still takes ~10 seconds to compute, which is reasonable when computing a moderate number of correlations. Given the advantages of <em class="ny">R</em> discussed above, I’d suggest using it even for computing large numbers of correlations — just subsample your data randomly to ~10K points, where computing <em class="ny">R</em> takes less than a second.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pr"><img src="../Images/c16f10389e59b0999dc654b60d9b5a69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P7rLRLTnxotWR_bxNRNtTg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author</figcaption></figure><h2 id="9da8" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk"><strong class="al">Precision</strong></h2><p id="c885" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">For different samples from the same distribution, there will be different estimates of the correlation coefficient. If there is an association between <em class="ny">x </em>and <em class="ny">y</em>, we want the variance of these estimates to be small compared to the mean of the correlation. For a measure <em class="ny">A(x,y)</em> one can compute <em class="ny">precision=sd(A)/mean(A)</em>, where <em class="ny">sd</em> is a standard deviation. Lower values of this quantity are better. The following table contains <em class="ny">precision</em> values calculated from a bivariate normal distribution on data sets of different sizes with different values of the correlation between dimensions. <em class="ny">ξ</em> is the least precise, while <em class="ny">ρ</em> is the most precise.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ps"><img src="../Images/3f65054e0ebdd098a98507d66df51600.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*egzovJDGbPddbusIY9JIpQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author</figcaption></figure><h2 id="6fcc" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">References</h2><p id="c46a" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">[1] <a class="af nz" href="https://medium.com/towards-data-science/a-new-coefficient-of-correlation-64ae4f260310" rel="noopener">A New Coefficient of Correlation</a></p><p id="fae8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[2] <a class="af nz" href="https://github.com/Arzik1987/medium/tree/main/nonlinear_correlation" rel="noopener ugc nofollow" target="_blank">My experiments on Github</a></p><p id="fd85" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[3] <a class="af nz" href="https://cran.r-project.org/web/packages/XICOR/index.html" rel="noopener ugc nofollow" target="_blank">XICOR package for R</a></p><p id="6ade" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[4] Kraskov, A., Stögbauer, H., &amp; Grassberger, P. (2004). Estimating mutual information. <em class="ny">Physical review E</em>, <em class="ny">69</em>(6), 066138.</p><p id="1b55" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[5] <a class="af nz" href="https://cran.r-project.org/web/packages/FNN/index.html" rel="noopener ugc nofollow" target="_blank">FNN package for R</a></p><p id="76b1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[6] Granger, C., &amp; Lin, J. L. (1994). Using the mutual information coefficient to identify lags in nonlinear models. <em class="ny">Journal of time series analysis</em>, <em class="ny">15</em>(4), 371–384.</p><p id="40f6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[7] Reshef, D. N., Reshef, Y. A., Finucane, H. K., Grossman, S. R., McVean, G., Turnbaugh, P. J., … &amp; Sabeti, P. C. (2011). Detecting novel associations in large data sets. <em class="ny">science</em>, <em class="ny">334</em>(6062), 1518–1524.</p><p id="91ed" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[8] Simon, N., &amp; Tibshirani, R. (2014). Comment on” Detecting Novel Associations In Large Data Sets” by Reshef Et Al, Science Dec 16, 2011. <em class="ny">arXiv preprint arXiv:1401.7645</em>.</p><p id="6755" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[9] Kinney, J. B., &amp; Atwal, G. S. (2014). Equitability, mutual information, and the maximal information coefficient. <em class="ny">Proceedings of the National Academy of Sciences</em>, <em class="ny">111</em>(9), 3354–3359.</p></div></div></div></div>    
</body>
</html>