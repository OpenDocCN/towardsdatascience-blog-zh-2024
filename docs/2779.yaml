- en: Field Boundary Detection in Satellite Imagery Using the SAM2 Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ SAM2 æ¨¡å‹åœ¨å«æ˜Ÿå›¾åƒä¸­è¿›è¡Œç”°åœ°è¾¹ç•Œæ£€æµ‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/field-boundary-detection-in-satellite-imagery-using-the-sam2-model-b556aa97bf7a?source=collection_archive---------4-----------------------#2024-11-15](https://towardsdatascience.com/field-boundary-detection-in-satellite-imagery-using-the-sam2-model-b556aa97bf7a?source=collection_archive---------4-----------------------#2024-11-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/field-boundary-detection-in-satellite-imagery-using-the-sam2-model-b556aa97bf7a?source=collection_archive---------4-----------------------#2024-11-15](https://towardsdatascience.com/field-boundary-detection-in-satellite-imagery-using-the-sam2-model-b556aa97bf7a?source=collection_archive---------4-----------------------#2024-11-15)
- en: Step-by-Step Tutorial on Applying Segment Anything Model Version 2 to Satellite
    Imagery for Detecting and Exporting Field Boundaries in Agricultural Areas
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Segment Anything æ¨¡å‹ç‰ˆæœ¬ 2 å¯¹å«æ˜Ÿå›¾åƒè¿›è¡Œç”°åœ°è¾¹ç•Œæ£€æµ‹å’Œå¯¼å‡ºçš„åˆ†æ­¥æ•™ç¨‹
- en: '[](https://medium.com/@mahyar.aboutalebi?source=post_page---byline--b556aa97bf7a--------------------------------)[![Mahyar
    Aboutalebi, Ph.D. ğŸ“](../Images/83d62352800f8a2932db8a07997c8059.png)](https://medium.com/@mahyar.aboutalebi?source=post_page---byline--b556aa97bf7a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b556aa97bf7a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b556aa97bf7a--------------------------------)
    [Mahyar Aboutalebi, Ph.D. ğŸ“](https://medium.com/@mahyar.aboutalebi?source=post_page---byline--b556aa97bf7a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mahyar.aboutalebi?source=post_page---byline--b556aa97bf7a--------------------------------)[![Mahyar
    Aboutalebi, Ph.D. ğŸ“](../Images/83d62352800f8a2932db8a07997c8059.png)](https://medium.com/@mahyar.aboutalebi?source=post_page---byline--b556aa97bf7a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b556aa97bf7a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b556aa97bf7a--------------------------------)
    [Mahyar Aboutalebi, Ph.D. ğŸ“](https://medium.com/@mahyar.aboutalebi?source=post_page---byline--b556aa97bf7a--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b556aa97bf7a--------------------------------)
    Â·13 min readÂ·Nov 15, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b556aa97bf7a--------------------------------)
    Â·é˜…è¯»æ—¶é—´ 13 åˆ†é’Ÿ Â·2024å¹´11æœˆ15æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/35bfa284528a9c88bd5c94bc2b127162.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35bfa284528a9c88bd5c94bc2b127162.png)'
- en: Table of Contents
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç›®å½•
- en: '**ğŸŒŸ Introduction**'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ğŸŒŸ ä»‹ç»**'
- en: '**ğŸ·ï¸ Segment Anything Model**'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ğŸ·ï¸ Segment Anything æ¨¡å‹**'
- en: ğŸš€ **Setup Google Colab**
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ğŸš€ **è®¾ç½® Google Colab**
- en: ğŸ›°ï¸ L**oad Clear Sentinel-2 Images**
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ğŸ›°ï¸ **åŠ è½½æ¸…æ™°çš„ Sentinel-2 å›¾åƒ**
- en: ğŸŒ **Apply SAM2 on Sentinel-2 Images**
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ğŸŒ **åœ¨ Sentinel-2 å›¾åƒä¸Šåº”ç”¨ SAM2**
- en: '**ğŸ“„ Conclusion**'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ğŸ“„ ç»“è®º**'
- en: '**ğŸ“š References**'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ğŸ“š å‚è€ƒæ–‡çŒ®**'
- en: '**ğŸŒŸ Introduction**'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ğŸŒŸ ä»‹ç»**'
- en: Manually drawing field boundaries is one of the most time-consuming tasks, and
    its accuracy depends on the performance of the person doing it. However, accurate
    boundary detection has applications in many areas. For example, letâ€™s assume you
    want to train a machine learning algorithm to analyze the relationship between
    vegetation indices from satellite images and crop yields on a farm. The first
    input youâ€™ll need is a shapefile of the farm, which typically has to be drawn
    manually. Drawing one shapefile may only take a few minutes, but what if you need
    to draw boundaries for 1,000 farms? Thatâ€™s when the process becomes very time
    consumingâ€¦
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰‹åŠ¨ç»˜åˆ¶ç”°åœ°è¾¹ç•Œæ˜¯æœ€è€—æ—¶çš„ä»»åŠ¡ä¹‹ä¸€ï¼Œå…¶å‡†ç¡®æ€§å–å†³äºæ‰§è¡Œè¯¥ä»»åŠ¡çš„äººçš„è¡¨ç°ã€‚ç„¶è€Œï¼Œç²¾ç¡®çš„è¾¹ç•Œæ£€æµ‹åœ¨è®¸å¤šé¢†åŸŸä¸­éƒ½æœ‰åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä½ æƒ³è®­ç»ƒä¸€ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•æ¥åˆ†æå«æ˜Ÿå›¾åƒä¸­çš„æ¤è¢«æŒ‡æ•°ä¸å†œåœºä½œç‰©äº§é‡ä¹‹é—´çš„å…³ç³»ã€‚ä½ éœ€è¦çš„ç¬¬ä¸€ä¸ªè¾“å…¥æ˜¯å†œåœºçš„å½¢çŠ¶æ–‡ä»¶ï¼Œé€šå¸¸éœ€è¦æ‰‹åŠ¨ç»˜åˆ¶ã€‚ç»˜åˆ¶ä¸€ä¸ªå½¢çŠ¶æ–‡ä»¶å¯èƒ½åªéœ€è¦å‡ åˆ†é’Ÿï¼Œä½†å¦‚æœä½ éœ€è¦ä¸º1,000ä¸ªå†œåœºç»˜åˆ¶è¾¹ç•Œæ€ä¹ˆåŠï¼Ÿè¿™æ—¶å€™ï¼Œè¿‡ç¨‹å°±å˜å¾—éå¸¸è€—æ—¶â€¦â€¦
