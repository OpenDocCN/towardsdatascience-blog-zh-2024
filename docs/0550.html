<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Tune the Perfect Smoother</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Tune the Perfect Smoother</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-tune-the-perfect-smoother-bcc5a67660b1?source=collection_archive---------6-----------------------#2024-02-28">https://towardsdatascience.com/how-to-tune-the-perfect-smoother-bcc5a67660b1?source=collection_archive---------6-----------------------#2024-02-28</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="70a5" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Get the most out of your data with Whittaker-Eilers smoothing and leave-one-out cross validation</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@anbowell?source=post_page---byline--bcc5a67660b1--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Andrew Bowell" class="l ep by dd de cx" src="../Images/a23bade2986dd9ce01f9056d0a9b108f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*fkOmpCsjasixp_L8yDcamw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--bcc5a67660b1--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@anbowell?source=post_page---byline--bcc5a67660b1--------------------------------" rel="noopener follow">Andrew Bowell</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--bcc5a67660b1--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 28, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="3851" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In a previous article I introduced the Whittaker-Eilers smoother¹ as <a class="af ne" rel="noopener" target="_blank" href="/the-perfect-way-to-smooth-your-noisy-data-4f3fe6b44440">The Perfect Way to Smooth Your Noisy Data</a>. In a few lines of code, the method provides quick and reliable smoothing with inbuilt interpolation that can handle large stretches of missing data. Furthermore, just a single parameter, λ (lambda), controls how smooth your data becomes. You’ll find that any smoother will have such parameters and tuning them can be tremendously tedious. So, let me show you just how painless it can be with the right method.</p><h2 id="3911" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk">Whittaker-Eilers Smoothing</h2><p id="5efe" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">When smoothing data, it’s likely there’s no ground truth you’re aiming towards; just some noise in your measurements that hamper attempts to analyse it. Using the Whittaker smoother, we can vary λ to alter the level of noise removed from our data.</p><figure class="oi oj ok ol om on of og paragraph-image"><div role="button" tabindex="0" class="oo op ed oq bh or"><div class="of og oh"><img src="../Images/880cdb8fb79fc97e30aff2e4312bd11e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yrPbSRNFdWXSJKemJzotQQ.png"/></div></div><figcaption class="ot ou ov of og ow ox bf b bg z dx">Figure 1) <a class="af ne" href="https://dr10.sdss.org/spectrumDetail?plateid=1939&amp;mjd=53389&amp;fiber=138" rel="noopener ugc nofollow" target="_blank">Optical output of a galaxy</a> smoothed for three different λs using the Whittaker-Eilers smoother².</figcaption></figure><p id="e445" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">With λ ranging from 10 to 10,000,000 in Figure 1, how do we know what value would be most suitable for our data?</p><h2 id="2b58" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk">Leave-one-out cross validation</h2><p id="b00f" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">To get an idea of how effective the smoothing is at any given λ, we need a metric we can calculate from each smoothed series. As we’re unable to rely on having a ground truth, we’re going to estimate the standard <em class="oy">predictive squared error</em> (PSE) using <em class="oy">leave-one-out cross validation </em>(LOOCV). It’s a special case of k-fold cross validation where the number of folds, <em class="oy">k</em>, is equal to the length of your dataset, <em class="oy">n</em>.</p><p id="7524" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The calculation is straightforward; we remove a measurement, smooth the series, and calculate the squared residual between our smoothed curve and the removed measurement. Repeat this for every measurement in the data, take an average and voila<em class="oy">, </em>we’ve calculated the <em class="oy">leave-one-out cross validation error </em>(CVE) — our estimation of the predictive squared error.</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og oz"><img src="../Images/3d98dcaf31d97b30924b4f13fec9bf12.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*RUWw4npxFpbegqw_LsJQiA.jpeg"/></div></figure><blockquote class="pa pb pc"><p id="51fb" class="mi mj oy mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In the equation above, our function <em class="fq">f </em>is the smoother and the<em class="fq"> -i </em>notation denotes that we’ve smoothed our data leaving out the <em class="fq">ith </em>measurement. From here on, I’ll also utilise the root cross validation error (RCVE) which is just the square root of our cross validation error.</p></blockquote><p id="dc9a" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">We can now smooth the optical spectra again, calculating the cross validation error for a variety of λs. Then we can select the λ that produces the lowest cross validation error.</p><figure class="oi oj ok ol om on of og paragraph-image"><div role="button" tabindex="0" class="oo op ed oq bh or"><div class="of og pd"><img src="../Images/d7c56a3f4055a3c354661d70f67368d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zjv8Fy9dikF3CucUkRRwjQ.png"/></div></div><figcaption class="ot ou ov of og ow ox bf b bg z dx">Figure 2) <a class="af ne" href="https://dr10.sdss.org/spectrumDetail?plateid=1939&amp;mjd=53389&amp;fiber=138" rel="noopener ugc nofollow" target="_blank">Optical spectra</a> smoothed with the optimal λ as chosen by the minimum cross validation error².</figcaption></figure><p id="4c8f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In Figure 2 you can see the root cross validation error plotted against λ. For this specific data series a λ of ~10³ results in the optimal configuration.</p><p id="c2cc" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Within the whittaker-eilers <a class="af ne" href="https://pypi.org/project/whittaker-eilers/" rel="noopener ugc nofollow" target="_blank">Python</a> and <a class="af ne" href="https://crates.io/crates/whittaker-eilers" rel="noopener ugc nofollow" target="_blank">Rust</a> packages I’ve implemented this as a single function which performs a search of λ and returns the optimally smoothed series alongside all of the λs and cross validation errors.</p><p id="6baf" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr"><em class="oy">Python</em></strong><em class="oy">: </em><a class="af ne" href="https://pypi.org/project/whittaker-eilers/" rel="noopener ugc nofollow" target="_blank"><em class="oy">pip install whittaker-eilers</em></a></p><pre class="oi oj ok ol om pe pf pg bp ph bb bk"><span id="457c" class="pi ng fq pf b bg pj pk l pl pm">from whittaker_eilers import WhittakerSmoother<br/><br/><br/>data_to_smooth = [6.7, 8.0, 2.1, 8.4, 7.6, 3.4]<br/><br/>smoother = WhittakerSmoother(lmbda=1, order=2, data_length=len(data_to_smooth))<br/><br/>results = smoother.smooth_optimal(data_to_smooth, break_serial_correlation=False)<br/><br/>optimally_smoothed_series = results.get_optimal().get_smoothed()<br/>optimal_lambda = results.get_optimal().get_lambda()</span></pre><p id="2e0d" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr"><em class="oy">Rust</em></strong><em class="oy">: </em><a class="af ne" href="https://crates.io/crates/whittaker-eilers" rel="noopener ugc nofollow" target="_blank"><em class="oy">cargo add whittaker-eilers</em></a></p><pre class="oi oj ok ol om pe pf pg bp ph bb bk"><span id="6c0c" class="pi ng fq pf b bg pj pk l pl pm">use whittaker_eilers::WhittakerSmoother;<br/><br/>let data_to_smooth = vec![6.7, 8.0, 2.1, 8.4, 7.6, 3.4];<br/><br/>let mut smoother = <br/>            WhittakerSmoother::new(1.0, 2, data_to_smooth.len(), None, None)<br/>            .unwrap();<br/><br/>let results = smoother.smooth_optimal(&amp;data_to_smooth,  false).unwrap();<br/><br/>println!("Optimal result: {:?}", results.get_optimal());</span></pre><h2 id="2e17" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk">Has cross validation produced a good result?</h2><p id="3ed8" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">With a little domain knowledge, we can double check our smoothed result from cross validation. On the left of Figure 2, at a wavelength of around 4000 Ångströms, there’s two dips which align with the absorption lines for Potassium and Hydrogen, alongside a Hydrogen emission line.</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og pn"><img src="../Images/013ff087a77f41bcd59f1c246b90c38a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*QZbSViy9YySTYYp6RU7yNg.png"/></div><figcaption class="ot ou ov of og ow ox bf b bg z dx">Figure 3) Close up of the optical spectra with the emission and absorption lines overlaid from the <a class="af ne" href="https://dr10.sdss.org/spectrumDetail?plateid=1939&amp;mjd=53389&amp;fiber=138" rel="noopener ugc nofollow" target="_blank">SDSS website</a>².</figcaption></figure><p id="39b8" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Over-smoothing results in these dips being merged and under-smoothing leaves the dips separate but very noisy. Leave-one-out cross validation has done an excellent job of selecting a λ which removes the vast majority of the noise while preserving the underlying signal.</p><h2 id="4cce" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk">More examples</h2><p id="4fe8" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">Let’s take a look at more data smoothed with the optimal λ as selected by leave-one-out cross validation.</p><figure class="oi oj ok ol om on of og paragraph-image"><div role="button" tabindex="0" class="oo op ed oq bh or"><div class="of og po"><img src="../Images/a6339a9a5cc9d36549c9afcd136c6f1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8EpCU62vCZey0PlO0kLrxA.png"/></div></div><figcaption class="ot ou ov of og ow ox bf b bg z dx">Figure 4) Optimally smoothed <a class="af ne" href="https://hastie.su.domains/ElemStatLearn/" rel="noopener ugc nofollow" target="_blank">change in mineral bone density</a> and root cross validation error for the λs tested³. This is an example of how the Whittaker can be used to smooth a scatter plot.</figcaption></figure><figure class="oi oj ok ol om on of og paragraph-image"><div role="button" tabindex="0" class="oo op ed oq bh or"><div class="of og pp"><img src="../Images/173d3a3dd3d2436a181bc9a11120dcb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PneGmlgSbWnVyaWMExeZuw.png"/></div></div><figcaption class="ot ou ov of og ow ox bf b bg z dx">Figure 5) Optimally smoothed <a class="af ne" href="https://archive.ics.uci.edu/dataset/360/air+quality" rel="noopener ugc nofollow" target="_blank">absolute humidity for an Italian town</a> and root cross validation error for the λs tested⁴.</figcaption></figure><p id="5b7e" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The first of the two datasets is rather noisy and therefore small values of λ have generated the largest cross validation errors. Conversely, the second dataset isn’t very noisy at all and has resulted in larger λs being penalised much more than smaller λs.</p><blockquote class="pa pb pc"><p id="45a8" class="mi mj oy mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">It’s worth noting that λ can vary across datasets not only due to noise, but also due to the sampling rate of the measurements.</p></blockquote><h2 id="911a" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk"><strong class="al">The Achilles heel of cross validation</strong></h2><p id="812b" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">Serially correlated data — when data is correlated with the lagged version of itself — causes a significant problem when using leave-one-out cross validation. Cross validation requires measurement error to be independent (like most statistical techniques) but, in serially correlated data measurement errors are likely dependent on the previous one. In practicality this leads to data barely being smoothed as only at that scale are the errors independent.</p><p id="f153" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Eilers presents a quick solution to this whereby you sample the data series at every 5th (or 10th or 20th) point effectively removing the serial correlation from your data¹. In the previous code snippets you can see I’ve implemented this by exposing a Boolean option named <em class="oy">“break_serial_correlation”. </em>This was left off to smooth the optical spectra in Figure 3 as no serial correlation is present but turned on for smoothing the humidity data Figure 5. It makes for a good solution, but not a perfect one.</p><h2 id="d1c1" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk">As good as a ground truth?</h2><p id="0a04" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">Generally when you want to assess how well a model fits your data, you’ll use a metric such as <em class="oy">root mean squared error </em>(RMSE)<em class="oy"> </em>to calculate the difference in your model’s estimations against a ground truth. So let’s generate a few data series with varying levels of noise and compare how the RMSE reacts in comparison to our leave-one-out cross validation error.</p><figure class="oi oj ok ol om on of og paragraph-image"><div role="button" tabindex="0" class="oo op ed oq bh or"><div class="of og pq"><img src="../Images/213407d0c8cdf6009cca8ac18e2673fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DPd_NVt7b-yEHaU7oYIM7Q.png"/></div></div><figcaption class="ot ou ov of og ow ox bf b bg z dx">Figure 6) Cosine function between 0 and 2<strong class="bf nh">π</strong> with varying levels of Gaussian noise added and then smoothed using the optimally tuned Whittaker.</figcaption></figure><figure class="oi oj ok ol om on of og paragraph-image"><div role="button" tabindex="0" class="oo op ed oq bh or"><div class="of og pr"><img src="../Images/df30f83983e9242458d89babae9a2a9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sq5CI88DOJEplf0vHlxuWA.png"/></div></div><figcaption class="ot ou ov of og ow ox bf b bg z dx">Figure 7) The root cross validation error (RCVE) and the root mean squared error (RMSE) plotted against λ on the same graph with separately scaled axes.</figcaption></figure><p id="34bf" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">As is expected, when the error added to the measurements gets larger the optimal λ selected is larger too, inducing more smoothing on the series. An approximately linear relationship between the RCVE and RMSE can be seen with the two offset by some constant. This aligns with what is expected from the literature⁵ as CVE is our estimate of <em class="oy">predictive squared error </em>(PSE) which is related to mean squared error by,</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og ps"><img src="../Images/da4e0a2775e7c8798aead8ad089509e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*-BAN0MPKbrivsR47KgMDGg.jpeg"/></div></figure><p id="7945" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">where σ is the standard deviation of the residuals. What we’ve proved here is that in the case of actually random<em class="oy">, </em>independent errors, leave-one-out cross validation offers a good estimation of the predictive squared error and in turn, the overall quality of the smoothed fit.</p><h2 id="f840" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk">Cross validation is slow. Let’s speed it up</h2><p id="cf3e" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">Earlier in this article, I provided the formula to compute cross validation error. Following it exactly would require you to smooth a data series of <em class="oy">n-1 </em>length <em class="oy">n </em>times which, even with a quick method, is not ideal. Luckily for us the Whittaker is a <em class="oy">constant preserving linear smoother </em>which enables us to derive an amazing relationship between the ordinary residuals and the leave-one-out cross validation residuals⁵. The result of this relationship? <strong class="mk fr">Only having to smooth the data once to compute the cross validation error. </strong>Let’s dive right in.</p><p id="09a1" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><a class="af ne" href="https://medium.com/towards-data-science/the-perfect-way-to-smooth-your-noisy-data-4f3fe6b44440#:~:text=of%20pre%2Dprocessing!-,The%20Mathematics,-Now%20we%E2%80%99ve%20covered" rel="noopener">I’ve previously demonstrated the linear algebra behind the Whittaker smoother</a> and how; by calculating the ordinary residuals between your smoothed series <strong class="mk fr">z </strong>and your original series <strong class="mk fr">y,</strong></p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og pt"><img src="../Images/ce682b350b10e89e8cc03365c8036fe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*Q732gx4JCAhJfxuXT5sVbw.jpeg"/></div></figure><p id="4cb4" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">and then balancing them with a measure of smoothness — the sum of squared differences between adjacent points in the smoothed series,</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og pu"><img src="../Images/08f3d2018814c3e3c2fe63844c58b77d.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*oFatqU9VoT-cNdfA0WHf1g.jpeg"/></div></figure><p id="327a" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">you end up with equation 3, where <strong class="mk fr">λ</strong> is a used to scale the scale the smoothness of your data.</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og pv"><img src="../Images/035ce655ca1104315ce733750db31758.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*y_Vd7TdDLgUkUsNth-Yoow.jpeg"/></div></figure><p id="c1e7" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Minimising <strong class="mk fr">Q</strong> then results in the optimally smoothed series for any given <strong class="mk fr">λ</strong>, which can be boiled down to a least squares problem resulting in the following linear equation,</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og pw"><img src="../Images/9a26dc37854174e779cecdde83fbb192.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/format:webp/1*UDCocMbcdbgsgcBLSogJWA.jpeg"/></div></figure><p id="8792" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">where<strong class="mk fr"> y </strong>is a vector of raw points, <strong class="mk fr">z </strong>a vector of smoothed points, and <strong class="mk fr">A </strong>a matrix containing some information about your smoothing constant <strong class="mk fr">λ. </strong>We can shuffle this about,</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og px"><img src="../Images/77a02a4a506e737664e1a5de64de03a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*26oG2FApyTZzvl9Gi6EouA.jpeg"/></div></figure><p id="2668" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">and arrive at a generic equation that describes a<em class="oy"> linear smoother</em>. <strong class="mk fr">H </strong>throughout regression and smoothing literature is called the<em class="oy"> smoother matrix</em> or <em class="oy">hat matrix — </em>which makes a lot of sense as multiplying our series <strong class="mk fr">y </strong>by <strong class="mk fr">H</strong> results in a smoothed series<strong class="mk fr"> z (</strong>and in some notations <strong class="mk fr">ŷ </strong>instead, hence hat matrix)¹. The smoother matrix is important as it forms the basis of the relationship between our ordinary residuals and the leave-one-out cross validation residuals.</p><p id="cda5" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Let’s revisit the statement I made at the start of the section. The Whittaker smoother is <em class="oy">constant preserving</em>; meaning that the smoother isn’t adding a bias to the underlying signal. Due to this, we can assume each row in the smoother matrix sums to 1. If it didn’t, when you multiplied it with your raw points, it would shift the smoothed series away from the underlying signal in the data. Relating this back to how we calculate the cross validated smoothed series gives us a starting point for the derivation. When we remove a point from our series, we have to remove a column from <strong class="mk fr">H. </strong>A row therefore contains one fewer element and needs to be re-normalised to sum to 1. We can formalise this as</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og py"><img src="../Images/f96ebb8c5412d315942c1ca2b2b122bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*maBAhcAhspx5KzTwfeqgcw.jpeg"/></div></figure><p id="28d3" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">where <strong class="mk fr">h</strong> is an element of our smoother matrix <strong class="mk fr">H</strong>, and we’re really just describing a matrix multiplication which skips a column⁵. The <em class="oy">-i </em>notation here is the same as in the CVE equation from earlier — it’s the predicted value for <em class="oy">ith </em>element where<em class="oy"> y</em>ᵢ hasn’t been used to calculate the fit.</p><p id="a504" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">We now want to try and find a relationship between the ordinary residuals (computed between the smoothed series and raw series) and the leave-one-out cross validation residuals (computed between the smoothed series produced with an input point missing and the raw series). Let’s first expand and rearrange to get rid of the ugly notation in the summation.</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og pz"><img src="../Images/925015a6c58193ee951551ab45b8fdf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*-Lc8DWiVfbHwBEMAtQJzwQ.jpeg"/></div></figure><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qa"><img src="../Images/518b8db938b48f5f34a8eb9cfe5963e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*Xs_juNXM6StoYW2xcdgXEw.jpeg"/></div></figure><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qb"><img src="../Images/7889d68a89fcf7c57bb35d1dc6aa1ad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*_CTIPBBCj6raYCVaQboaFA.jpeg"/></div></figure><p id="0477" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The summation is now taking into account all elements and becomes the equation that produces our standard smoothed value<strong class="mk fr"> z</strong>,</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qc"><img src="../Images/ffb1b8bf039306bd456688d243b2a3f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*e581r3OGltsgi9h610C1Kw.jpeg"/></div></figure><p id="d86f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">which can then be substituted in,</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qd"><img src="../Images/322dd392de1380822f5b242ea9166987.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*ocogCP-K4i8QLCoSgunflw.jpeg"/></div></figure><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qe"><img src="../Images/661011418518fbbb172e1a95a4f2c685.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*7X1wdCbmKYKaQ6055eAUUg.jpeg"/></div></figure><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qf"><img src="../Images/ba41782c2eb9f1c5e40003e03b601b98.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*yigmJbRZH0aV1AxLgoo9aA.jpeg"/></div></figure><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qg"><img src="../Images/e66e4835b09003db3483a9008165daa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*Qtv8unSi27tvD5ncyVhe9A.jpeg"/></div></figure><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qh"><img src="../Images/0e6711bd2125da2a8d96d444756f1249.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*VxiCX6rNNllMPW0OywIGIA.jpeg"/></div></figure><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qi"><img src="../Images/eb665e7045e28e1d8d161d70daad9774.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*fVeZQOHToF0dDeVhmhltxA.jpeg"/></div></figure><p id="d551" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">eventually resulting in a direct relationship between the leave-one-out cross validation residuals and the ordinary residuals via the diagonal of the smoother matrix. Pretty neat. We can now take our original equation for CVE and plug in our new relationship,</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qj"><img src="../Images/6a9b84f8a607543c721f5743a727f868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*PHIL5J1runHnKf9OhsyoGg.jpeg"/></div></figure><p id="f0be" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">and as you can see, we now don’t need to smooth the series each time! We just access an element of our smoother matrix diagonal⁵. This leads neatly onto the equation for <em class="oy">generalised cross validation</em> where, instead of dividing by each diagonal element of <strong class="mk fr">H</strong>,<strong class="mk fr"> </strong>we calculate the mean of the diagonal and divide by that instead³.</p><figure class="oi oj ok ol om on of og paragraph-image"><div class="of og qk"><img src="../Images/fb4ec457ddd82f0c46164b520a1bbc8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*mtSUDMTMfMIpNWXVnKEt8A.jpeg"/></div></figure><h2 id="eae5" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk"><strong class="al">Why this is still too slow</strong></h2><p id="8226" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">In calculating the smoother matrix we need to invert a sparse matrix — which unfortunately results in a dense matrix. As our data length grows, the dense smoother matrix will grow by <em class="oy">n². </em>While calculating this is still quicker than smoothing our series <em class="oy">n</em> times, it’s not as fast as it could be.<em class="oy"> </em>Eilers observes that the diagonal of <strong class="mk fr">H</strong> plots a similar shape for a series of any length, it just needs to be scaled accordingly by the ratio of the lengths¹. What we’re essentially doing is creating a sample from <strong class="mk fr">H </strong>we’ll use to get our average of the full <strong class="mk fr">H</strong>’s diagonal. Implementing this for a sample size of 100 enables us to have consistently quick way of calculating the cross validation error.</p><figure class="oi oj ok ol om on of og paragraph-image"><div role="button" tabindex="0" class="oo op ed oq bh or"><div class="of og ql"><img src="../Images/28b52efb81d448e8d8ea3a23215f77a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RJXiQti6GrssxBytFGCQPA.png"/></div></div><figcaption class="ot ou ov of og ow ox bf b bg z dx">Figure 8) The time taken to smooth a series of<strong class="bf nh"> <em class="qm">n </em></strong><em class="qm">length using the optimised smoother matrix method and by simply smoothing the data series of </em><strong class="bf nh"><em class="qm">n-1 </em></strong><em class="qm">length</em><strong class="bf nh"><em class="qm"> n </em></strong><em class="qm">times</em><strong class="bf nh"><em class="qm">.</em></strong></figcaption></figure><p id="dc91" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In Figure 8 we can see that if we were to use the original equation for CVE, smoothing our data series <em class="oy">n</em> times, the time complexity increases with <em class="oy">n² —</em> as does when we’re calculating the the smoother matrix up to a length of 100. Kicking sampling in after <em class="oy">n=100 </em>enables us to increase the length of the series for little additional cost. This sampling is likely responsible for the small differences between RCVE and the RMSE in Figure 7.</p><h2 id="9add" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk">Concluding thoughts and further reading</h2><p id="d48a" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">The Whittaker-Eilers method is an amazing tool for both smoothing and interpolating noisy data. Implementing it with sparse matrices results in an incredibly quick and memory efficient method allowing for fast cross validation which, in the absence of a ground truth, is an effective measure of the smoother’s performance.</p><p id="46f3" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In the case of serially correlated data, cross validation can still be a good method when slightly tweaked. Ultimately, more complex methods such as L- and V-curve optimisation are better suited to parameter selection on this sort of data. Maybe some time soon I’ll get round to implementing them in the whittaker-eilers package.</p><p id="6e37" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">All of the code which has been used to generate these results is available within the <a class="af ne" href="https://github.com/AnBowell/whittaker-eilers" rel="noopener ugc nofollow" target="_blank">whittaker-eilers</a> GitHub repository where both the Python and Rust packages reside. I’ve also included Eilers original MATLAB scripts used to implement the Whittaker and cross validation¹.</p><p id="8769" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Thanks again for reading! Be sure to check out my <a class="af ne" href="https://www.anbowell.com/" rel="noopener ugc nofollow" target="_blank">personal site</a> and medium for more.</p></div></div></div><div class="ab cb qn qo qp qq" role="separator"><span class="qr by bm qs qt qu"/><span class="qr by bm qs qt qu"/><span class="qr by bm qs qt"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="22db" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><em class="oy">All images within this article have been produced by the author with data referenced accordingly.</em></p><h2 id="84b6" class="nf ng fq bf nh ni nj nk nl nm nn no np mr nq nr ns mv nt nu nv mz nw nx ny nz bk">References</h2><p id="c43f" class="pw-post-body-paragraph mi mj fq mk b go oa mm mn gr ob mp mq mr oc mt mu mv od mx my mz oe nb nc nd fj bk">[1] Eilers, Paul H. C., <em class="oy">A Perfect Smoother</em>, Analytical Chemistry <strong class="mk fr">2003</strong> <em class="oy">75</em> (14), 3631–3636, DOI: <a class="af ne" href="https://doi.org/10.1021/ac034173t" rel="noopener ugc nofollow" target="_blank">10.1021/ac034173t</a></p><p id="4efd" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">[2] Kollmeier et al, <em class="oy">SDSS-V Pioneering Panoptic Spectroscopy, </em>Bulletin of the American Astronomical Society, <strong class="mk fr">2019 </strong>51 (7), 274, Bibcode: <a class="af ne" href="https://ui.adsabs.harvard.edu/abs/2019BAAS...51g.274K/abstract" rel="noopener ugc nofollow" target="_blank">2019BAAS…51g.274K</a></p><p id="d1e5" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">[3] Hastie T, Tibshirani T, Friedman J, <em class="oy">The Elements of Statistical Learning, </em>Springer, <strong class="mk fr">2009, </strong>URL: <a class="af ne" href="https://hastie.su.domains/ElemStatLearn/" rel="noopener ugc nofollow" target="_blank">https://hastie.su.domains/ElemStatLearn/</a></p><p id="ad31" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">[4] Vito, Saverio, <em class="oy">Air Quality, </em>UCI Machine Learning Repository, <strong class="mk fr">2016, </strong>DOI: <a class="af ne" href="https://doi.org/10.24432/C59K5F" rel="noopener ugc nofollow" target="_blank">10.24432/C59K5F</a> Licence: <em class="oy">Creative Commons Attribution 4.0 International</em></p><p id="0a43" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">[5] Geyer, Charles J., <em class="oy">5601 Notes: Smoothing</em>, University Of Minnesota, <strong class="mk fr">2013, </strong>URL<strong class="mk fr">: </strong><a class="af ne" href="https://www.stat.umn.edu/geyer/5601/notes/smoo.pdf" rel="noopener ugc nofollow" target="_blank">https://www.stat.umn.edu/geyer/5601/notes/smoo.pdf</a></p></div></div></div><div class="ab cb qn qo qp qq" role="separator"><span class="qr by bm qs qt qu"/><span class="qr by bm qs qt qu"/><span class="qr by bm qs qt"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="a525" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Data acknowledgement for SDSS optical spectra data</strong></p><p id="f61d" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><em class="oy">Funding for the Sloan Digital Sky Survey V has been provided by the Alfred P. Sloan Foundation, the Heising-Simons Foundation, the National Science Foundation, and the Participating Institutions. SDSS acknowledges support and resources from the Center for High-Performance Computing at the University of Utah. SDSS telescopes are located at Apache Point Observatory, funded by the Astrophysical Research Consortium and operated by New Mexico State University, and at Las Campanas Observatory, operated by the Carnegie Institution for Science. The SDSS web site is </em><a class="af ne" href="https://www.sdss.org/" rel="noopener ugc nofollow" target="_blank"><em class="oy">www.sdss.org</em></a><em class="oy">.</em></p><p id="a63d" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><em class="oy">SDSS is managed by the Astrophysical Research Consortium for the Participating Institutions of the SDSS Collaboration, including Caltech, the Carnegie Institution for Science, Chilean National Time Allocation Committee (CNTAC) ratified researchers, The Flatiron Institute, the Gotham Participation Group, Harvard University, Heidelberg University, The Johns Hopkins University, L’Ecole polytechnique fédérale de Lausanne (EPFL), Leibniz-Institut für Astrophysik Potsdam (AIP), Max-Planck-Institut für Astronomie (MPIA Heidelberg), Max-Planck-Institut für Extraterrestrische Physik (MPE), Nanjing University, National Astronomical Observatories of China (NAOC), New Mexico State University, The Ohio State University, Pennsylvania State University, Smithsonian Astrophysical Observatory, Space Telescope Science Institute (STScI), the Stellar Astrophysics Participation Group, Universidad Nacional Autónoma de México, University of Arizona, University of Colorado Boulder, University of Illinois at Urbana-Champaign, University of Toronto, University of Utah, University of Virginia, Yale University, and Yunnan University.</em></p></div></div></div></div>    
</body>
</html>