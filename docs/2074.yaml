- en: Introducing Markov Decision Processes, Setting up Gymnasium Environments and
    Solving them via Dynamic Programming Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/introducing-markov-decision-processes-setting-up-gymnasium-environments-and-solving-them-via-e806c36dc04f?source=collection_archive---------4-----------------------#2024-08-26](https://towardsdatascience.com/introducing-markov-decision-processes-setting-up-gymnasium-environments-and-solving-them-via-e806c36dc04f?source=collection_archive---------4-----------------------#2024-08-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dissecting “Reinforcement Learning” by Richard S. Sutton with custom Python
    implementations, Episode II
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@hrmnmichaels?source=post_page---byline--e806c36dc04f--------------------------------)[![Oliver
    S](../Images/b5ee0fa2d5fb115f62e2e9dfcb92afdd.png)](https://medium.com/@hrmnmichaels?source=post_page---byline--e806c36dc04f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e806c36dc04f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e806c36dc04f--------------------------------)
    [Oliver S](https://medium.com/@hrmnmichaels?source=post_page---byline--e806c36dc04f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e806c36dc04f--------------------------------)
    ·12 min read·Aug 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: In a [previous post](https://medium.com/towards-data-science/introduction-to-reinforcement-learning-and-solving-the-multi-armed-bandit-problem-e4ae74904e77)
    we started our series about Reinforcement Learning (RL) following Sutton’s great
    book [1]. In that post we introduced RL in general, and discussed Multi-armed
    Bandits as a *nonassociative* toy problem.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will build on this — but go significantly beyond. In particular, we
    will introduce our first *associative* problem, which might feel much more like
    “real” RL to many readers — and introduce a simple but general solution technique.
    Furthermore, we will introduce Gymnasium [2], a powerful library providing a multitude
    of environments (e.g. Atari or MuJoCo games) and allowing us to quickly experiment
    with solving them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ea806371c177ee506c0b0a5ecfb843b.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Adarsh Kummur](https://unsplash.com/@akummur?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/wilted-tree-during-daytime-zThTy8rPPsY?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: 'The previously mentioned associative setting is the “standard” in RL: as opposed
    to the previously introduced nonassociative setting where there is only a single
    state, and we only have to decide on what action to take, here we have multiple
    states — and for every state we might decide for a different best action.'
  prefs: []
  type: TYPE_NORMAL
