<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Can Large Language Models (LLMs) Be Used to Label Data?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Can Large Language Models (LLMs) Be Used to Label Data?</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-large-language-models-llms-label-data-2a8334e70fb8?source=collection_archive---------5-----------------------#2024-04-02">https://towardsdatascience.com/can-large-language-models-llms-label-data-2a8334e70fb8?source=collection_archive---------5-----------------------#2024-04-02</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="b831" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A brief overview</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@majapavlo?source=post_page---byline--2a8334e70fb8--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Maja Pavlovic" class="l ep by dd de cx" src="../Images/a3b8a94c236519bc86c5c6319db5bc66.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*ab-q_ef4aJmf2hJxu8hUzA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--2a8334e70fb8--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@majapavlo?source=post_page---byline--2a8334e70fb8--------------------------------" rel="noopener follow">Maja Pavlovic</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--2a8334e70fb8--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 2, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">4</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="1301" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This article is meant to provide a simple approachable summary of studies that explored labelling data with LLMs<a class="af nf" href="#9b7e" rel="noopener ugc nofollow"><strong class="ml fr">¹</strong></a><strong class="ml fr">.</strong> We will cover current views on annotating textual data with LLMs and also things to consider for your own projects.</p><p id="c634" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Overview:</strong></p><ul class=""><li id="494a" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne ng nh ni bk"><a class="af nf" href="#1525" rel="noopener ugc nofollow">Why even use LLMs?</a></li><li id="c7ee" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk"><a class="af nf" href="#7740" rel="noopener ugc nofollow">Current Views</a></li><li id="c156" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk"><a class="af nf" href="#13fd" rel="noopener ugc nofollow">Things to Consider when using LLMs as Annotators</a></li><li id="c66b" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk"><a class="af nf" href="#4a23" rel="noopener ugc nofollow">Summary |<strong class="ml fr"> <em class="no">TL;DR</em></strong></a></li></ul><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq nr"><img src="../Images/eb85d873b755934ed4cb4b9ae8915e2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IFyroGyHwXnoX8RKkzD_wg.png"/></div></div><figcaption class="od oe of np nq og oh bf b bg z dx">Source: Pexels</figcaption></figure><h1 id="1525" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Why even use an LLM for labelling?</h1><p id="949e" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">High quality labelled data creates the foundation for training and evaluating machine learning models across diverse tasks. The most common approach to annotating datasets right now is to hire crowd-workers <em class="no">(e.g. Amazon Mechanical Turk)</em> or domain experts if specialised knowledge is required.</p><p id="03d7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">These approaches can be rather expensive<strong class="ml fr"> </strong>and time-consuming, which is why a lot of people are now wondering if LLMs can handle data labelling well enough. Businesses with limited budgets could benefit from this by building specialised models that address their particular needs. In more sensitive domains like medicine, there’s potential to speed up the labelling process by having experts review and correct LLM labels rather than starting from scratch.</p><p id="5557" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Additionally, researchers at Carnegie Mellon &amp; Google find that people are motivated by the possibility of protecting human annotators from psychological harm caused during the labelling process <em class="no">(e.g hate-speech) </em>as well as the diversification of opinions in the data<em class="no">.</em></p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="7740" class="oi oj fq bf ok ol pr gq on oo ps gt oq or pt ot ou ov pu ox oy oz pv pb pc pd bk">Current views across different studies</h1><p id="4ca9" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">Opinions are somewhat split amongst studies regarding the potential of LLMs as annotators. While some studies are optimistic about their capabilities, others remain sceptical. Table 1 provides an overview of the approach and results from twelve studies. You can find the source of these studies in the References <em class="no">(see end of this article)</em>.</p><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq pw"><img src="../Images/79bc9b2ff8ff92d0ee358b024f25a71f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XZu7CPV72ocid8hMqYVUIg.png"/></div></div><figcaption class="od oe of np nq og oh bf b bg z dx"><strong class="bf ok">Table 1 </strong>— z: zero-shot, f: few-shot, z&amp;f: zero&amp;few-shot; en+: predominantly English | image by author</figcaption></figure><h2 id="91e3" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Model<a class="af nf" href="#a37b" rel="noopener ugc nofollow">²</a></h2><p id="44b9" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">The <strong class="ml fr">Number of Model Families</strong> highlights that most of the studies only test one model family and when we look at which model they used, we can see that almost all except for 2 studies <strong class="ml fr">used GPT</strong>. Study [7] is the only one which solely focuses on the exploration of open-source LLMs (Table 2).</p><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq qo"><img src="../Images/3fff610c6de85ad358c8b378fca9f6ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*frIjsRmb0hkpts_0fj4KtQ.png"/></div></div><figcaption class="od oe of np nq og oh bf b bg z dx"><strong class="bf ok">Table 2</strong> | image by author</figcaption></figure><h2 id="508f" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Datasets</h2><p id="2b27" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">The third column of <a class="af nf" href="#4ca9" rel="noopener ugc nofollow">Table 1</a> contains the <strong class="ml fr">Number of Datasets</strong> that were used for labelling purposes. The different studies explore different tasks and thereby also a variety of datasets. Most explore the performance on more than one dataset. Study [3] stands out by testing LLM classification performance across 20 different datasets. More details on which datasets were used are shown in Table 3 below, and could help you<em class="no"> </em>spot the studies most relevant to you.</p><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq qp"><img src="../Images/03cdf5b34f7dda8b4d5fe27aa3809e46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qG7SAt8Cemi09RGtJJfFLQ.png"/></div></div><figcaption class="od oe of np nq og oh bf b bg z dx"><strong class="bf ok">Table 3 </strong>| image by author</figcaption></figure><blockquote class="qq qr qs"><p id="cc71" class="mj mk no ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">If you’re starting out with no labelled data at hand: </strong>Have a look at existing <strong class="ml fr">labelled</strong> datasets for tasks that are similar to your own use case and label the data with an LLM. Compare the LLM generated labels with the human labels by investigating the errors and potential issues in detail. This should give you an indication of how well the LLM will perform on your task and whether the time &amp; cost savinngs can be justified.</p></blockquote><h2 id="5c56" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Perspectivist Approach</h2><p id="312b" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">A <strong class="ml fr">Perspectivist Approach </strong>simply means recognising that there is no one “right” way to understand a dataset or solve a problem. Different perspectives can reveal different insights or solutions. Whereas traditionally, most datasets are labelled using a majority voting approach, meaning that the most commonly chosen label is viewed as the ground truth:</p><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq qt"><img src="../Images/134e765061c32993d940b03ea01b0776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cg-GfkW5fEYLtRUuDqfSiQ.png"/></div></div><figcaption class="od oe of np nq og oh bf b bg z dx">Majority Voting Vs. Perspectivist Approach | image by author</figcaption></figure><p id="1d0a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In <a class="af nf" href="#4ca9" rel="noopener ugc nofollow">Table 1</a>, the labelling approach is categorised based on whether the study uses a majority voting or perspectivist mindset. We can see that most of the studies take a majority voting approach towards their labelling efforts.</p><h2 id="159d" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">LLM as Annotator?</h2><p id="5809" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">The last column summarises each study’s findings, with a check-mark indicating a tendency towards believing that LLMs can be helpful in the annotation process. While some are quite optimistic about their potential and suggest the replacement of human annotators, others see them more as a support tool rather than a substitute for humans. Regardless, even amongst these studies with a positive outlook, there are <em class="no">some tasks</em> on which LLMs don’t perform well enough.</p><p id="43f9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Additionally, three studies, two of which follow the perspectivist approach, conclude that they are not suited for labelling data. Another study <em class="no">(not included in the table) </em>takes a different approach and shows that the current method of aligning LLMs via a single reward function doesn’t capture the diversity of preferences among different human subgroups, especially minority views.</p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="13fd" class="oi oj fq bf ok ol pr gq on oo ps gt oq or pt ot ou ov pu ox oy oz pv pb pc pd bk">Things to Consider when Using LLMs as Annotators</h1><h2 id="ac6a" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Prompting: Zero vs. Few-shot</h2><p id="236e" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">Obtaining meaningful responses from LLMs can be a bit of a challenge. How do you then best prompt an LLM to label your data? As we can see from <a class="af nf" href="#4ca9" rel="noopener ugc nofollow">Table 1</a>, the above studies explored either zero-shot or few-shot prompting, or both. <strong class="ml fr">Zero-shot </strong>prompting expects an answer from the LLM without having seen any examples in the prompt. Whereas <strong class="ml fr">few-shot </strong>prompting includes multiple examples in the prompt itself so that the LLM knows what a desired response looks like:</p><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq qu"><img src="../Images/37392df9567b3466d7f3ec16c74c5dea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zFSuMwbglwe51U_eyCetcw.png"/></div></div><figcaption class="od oe of np nq og oh bf b bg z dx">Zero Vs Few-Shot Prompting | <a class="af nf" href="https://github.com/amitsangani/Llama-2/blob/main/Building_Using_Llama.ipynb" rel="noopener ugc nofollow" target="_blank">source of example (amitsangani)</a> | image by author</figcaption></figure><p id="2c3b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The studies differ in their views on which approach returns better results. Some resort to few-shot prompting on their tasks, others to zero-shot prompting. So you might want to explore what works best for your particular use case and model.</p><blockquote class="qq qr qs"><p id="f8e2" class="mj mk no ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If you are wondering how to even start with good prompting <span class="ia"><span class="ia" aria-hidden="false"><a class="qv ib qw" href="https://medium.com/u/94d7839def70?source=post_page---user_mention--2a8334e70fb8--------------------------------" rel="noopener" target="_blank">Sander Schulhoff</a></span></span> &amp; <span class="ia"><span class="ia" aria-hidden="false"><a class="qv ib qw" href="https://medium.com/u/e3a305374f9a?source=post_page---user_mention--2a8334e70fb8--------------------------------" rel="noopener" target="_blank">Shyamal H Anadkat</a></span></span> have created <a class="af nf" href="https://learn-prompting.webflow.io/testimonials" rel="noopener ugc nofollow" target="_blank"><strong class="ml fr">LearnPrompting</strong></a> which can help you with basics and also more advanced techniques.</p></blockquote><h2 id="3223" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Prompting: Sensitivity</h2><p id="1ab9" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">LLMs are sensitive to minor modifications in the prompt. Changing one word of your prompt can affect the response. If you want to account for that variability to some degree you could approach it as in study [3]. First, they let a task expert provide the initial prompt. Then, using GPT, they generate 4 more with similar meaning and average the results over all 5 prompts. Or you could also explore moving away from hand-written prompts and try replacing them with <a class="af nf" rel="noopener" target="_blank" href="/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9#7029">signatures</a> leaving it to <a class="af nf" rel="noopener" target="_blank" href="/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9">DSPy</a> to optimise the prompt for you as shown in <span class="ia"><span class="ia" aria-hidden="false"><a class="qv ib qw" href="https://medium.com/u/3a38da70d8dc?source=post_page---user_mention--2a8334e70fb8--------------------------------" rel="noopener" target="_blank">Leonie Monigatti</a></span></span>’s blog post.</p><h2 id="285e" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Model Choice</h2><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq qx"><img src="../Images/47c78f3eb88071c5102e84d4fb571100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0vkaFoaqrfw9UfBHsBbmHQ.png"/></div></div></figure><p id="115b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Which model should you choose for labelling your dataset? There are a few factors to consider. Let’s briefly touch on some key considerations:</p><ul class=""><li id="fb80" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne ng nh ni bk"><strong class="ml fr">Open Source vs. Closed Source: </strong>Do you go for the latest best performing model? Or is open-source customisation more important to you? You’ll need to think about things such as your budget, performance requirements, customization and ownership preferences, security needs, and community support requirements.</li><li id="7094" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk"><strong class="ml fr">Guardrails:</strong> LLMs have guardrails in place to prevent them from responding with undesirable or harmful content. If your task involves sensitive content, models might refuse to label your data. Also, LLMs vary in the strength of their safeguards, so you should explore and compare them to find the most suitable one for your task.</li><li id="13c0" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk"><strong class="ml fr">Model Size:</strong> LLMs come in different sizes and bigger models might perform better but they also require more compute resources. If you prefer to use open-source LLMs and have limited compute, you could consider<a class="af nf" rel="noopener" target="_blank" href="/democratizing-llms-4-bit-quantization-for-optimal-llm-inference-be30cf4e0e34"> quantisation</a>. In the case of closed-source models, the larger models currently have higher costs per prompt associated with them. But is bigger always better?</li></ul><h2 id="d50e" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Model Bias</h2><p id="8916" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">According to study [3] larger, instruction-tuned<a class="af nf" href="#30fc" rel="noopener ugc nofollow"><strong class="ml fr">³</strong></a> models show superior labelling performance. However, the study doesn’t evaluate bias in their results. Another research effort shows that bias tends to increase with both scale and ambiguous contexts. Several studies also warn about left-leaning tendencies and the limited capability to accurately represent the opinions of minority groups (e.g. older individuals or underrepresented religions). All in all, current LLMs show considerable cultural biases and respond with stereotyped views of minority individuals. Depending on your task and its aims, these are things to consider across every timeline in your project.</p><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq qy"><img src="../Images/73ffb7e66f0c8310862a2da6c31096c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zy2yqB5LaEr0DeEOSRDMCg.png"/></div></div></figure><blockquote class="qq qr qs"><p id="a38e" class="mj mk no ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">“By default, LLM responses tend to be more similar to the opinions of certain populations, such as those from the USA, and some European and South American countries” <em class="fq">— quote from study [2]</em></p></blockquote><h2 id="8fee" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Model Parameter: Temperature</h2><p id="f9c1" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">A commonly mentioned parameter across most studies in <a class="af nf" href="#4ca9" rel="noopener ugc nofollow">Table 1</a> is the temperature parameter, which adjusts the <em class="no">“creativity”</em> of the LLMs outputs. Studies [5] and [6] experiment with both higher and lower temperatures, and find that LLMs have higher consistency in responses with lower temperatures without sacrificing accuracy; therefore they recommend <strong class="ml fr"><em class="no">lower values for annotation tasks</em></strong>.</p><h2 id="e106" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Language Limitations</h2><p id="af23" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">As we can see in <a class="af nf" href="#4ca9" rel="noopener ugc nofollow">Table 1</a>, most of the studies measure the LLMs labelling performance on English datasets. Study [7] explores French, Dutch and English tasks and sees a considerable decline in performance with the non-English languages. Currently, <strong class="ml fr">LLMs perform better in English</strong>, but alternatives are underway to extend their benefits to non-English users. Two such initiatives include: YugoGPT <em class="no">(for Serbian, Croatian, Bosnian, Montenegrin)</em> by <span class="ia"><span class="ia" aria-hidden="false"><a class="qv ib qw" href="https://medium.com/u/37f02ae83e8c?source=post_page---user_mention--2a8334e70fb8--------------------------------" rel="noopener" target="_blank">Aleksa Gordić</a></span></span> &amp; Aya (101 different languages) by <a class="af nf" href="https://cohere.com/research/aya" rel="noopener ugc nofollow" target="_blank"><em class="no">Cohere for AI</em></a><em class="no">.</em></p><h2 id="8497" class="px oj fq bf ok py pz qa on qb qc qd oq ms qe qf qg mw qh qi qj na qk ql qm qn bk">Human Reasoning &amp; Behaviour (Natural Language Explanations)</h2><p id="bb65" class="pw-post-body-paragraph mj mk fq ml b go pe mn mo gr pf mq mr ms pg mu mv mw ph my mz na pi nc nd ne fj bk">Apart from simply requesting a label from the LLM, we can also ask it to provide an explanation for the chosen label. One of the studies [10] finds that GPT returns explanations that are comparable, if not more clear than those produced by humans. However, we also have researchers from Carnegie Mellon &amp; Google highlighting that LLMs are not yet capable of <a class="af nf" href="https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86#9e13" rel="noopener">simulating human decision making</a> and don’t show <a class="af nf" href="https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86#fb0c" rel="noopener">human-like behavior</a> in their choices. They find that instruction-tuned models show even less human-like behaviour and say that LLMs should not be used to substitute humans in the annotation pipeline. I would also caution the use of natural language explanations at this stage in time.</p><blockquote class="qq qr qs"><p id="83b2" class="mj mk no ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">“Substitution undermines three values: the representation of participants’ interests; participants’ inclusion and empowerment in the development process” <em class="fq">— quote from Agnew (2023)</em></p></blockquote></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="4a23" class="oi oj fq bf ok ol pr gq on oo ps gt oq or pt ot ou ov pu ox oy oz pv pb pc pd bk">Summary | TL;DR</h1><figure class="ns nt nu nv nw nx np nq paragraph-image"><div role="button" tabindex="0" class="ny nz ed oa bh ob"><div class="np nq qz"><img src="../Images/484758ee333481ef8e1fb3568793d07c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aKkEvhTX0KnpJEyqTGVidQ.png"/></div></div><figcaption class="od oe of np nq og oh bf b bg z dx">Benefits &amp; Drawbacks | image by author</figcaption></figure><ul class=""><li id="1b2d" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne ng nh ni bk">LLMs can be an option for those with limited budgets<em class="no"> </em>and relatively objective tasks, where you care about the most likely label. Be careful with subjective tasks where opinions about the correct label might differ considerably!</li><li id="197e" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk">Avoid using LLMs to simulate human reasoning and behaviour.</li><li id="4671" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk">For more critical tasks <em class="no">(e.g. healthcare)</em> you could use LLMs to speed up the labelling process by having humans correct the labelled data; but don’t remove humans from the labelling process entirely!</li><li id="6d63" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk">Evaluate your results critically for biases &amp; other problems and consider if the cost of the errors are worth the trouble they might cause.</li></ul></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><blockquote class="ra"><p id="f586" class="rb rc fq bf rd re rf rg rh ri rj ne dx">This review is by no means an exhaustive comparison. If you have <a class="af nf" href="https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86" rel="noopener">other sources</a> that can contribute to the discussion or personal experience with LLM data labelling, please do share in the comments.</p></blockquote></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="edbf" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">References</strong></p><ul class=""><li id="f8b5" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne ng nh ni bk">If you want to look at the studies and other resources individually here is a list of all the papers used to create this blog post: <a class="af nf" href="https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86" rel="noopener"><strong class="ml fr">Blog References</strong></a><strong class="ml fr">.</strong></li><li id="b93f" class="mj mk fq ml b go nj mn mo gr nk mq mr ms nl mu mv mw nm my mz na nn nc nd ne ng nh ni bk">If you want more insights on <em class="no">Table 1 and the studies</em>, here is the <a class="af nf" href="https://aclanthology.org/2024.nlperspectives-1.11.pdf" rel="noopener ugc nofollow" target="_blank"><em class="no">link to NLPerspectives workshop paper</em></a> from LREC-COLING</li></ul></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="3912" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><em class="no">Footnotes</em></p><p id="9b7e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">¹</strong><em class="no">This is not a comprehensive review on all the literature out there but covers only papers I found whilst doing reading on this topic. Additionally, my focus was mostly on classification tasks.</em></p><p id="a37b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">²</strong><em class="no">Given the pace of development in LLMs, there are now a lot more powerful models available compared to the ones tested in these studies.</em></p><p id="30fc" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">³</strong><em class="no">Instruction-tuned models are trained with a focus on understanding and generating accurate and coherent responses based on given instructions/prompts.</em></p></div></div></div></div>    
</body>
</html>