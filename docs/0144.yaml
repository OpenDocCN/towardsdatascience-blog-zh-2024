- en: The Math Behind Stochastic Gradient Descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/stochastic-gradient-descent-math-and-python-code-35b5e66d6f79?source=collection_archive---------0-----------------------#2024-01-16](https://towardsdatascience.com/stochastic-gradient-descent-math-and-python-code-35b5e66d6f79?source=collection_archive---------0-----------------------#2024-01-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Deep Dive on Stochastic Gradient Descent. Algorithm, assumptions, benefits,
    formula, and practical implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)[![Cristian
    Leo](../Images/99074292e7dfda50cf50a790b8deda79.png)](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)
    [Cristian Leo](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)
    ·18 min read·Jan 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/188abc5dbac543899ab3d77a9e4711ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [DALL-E-2](https://openai.com/dall-e-2)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The image above is not just an appealing visual that drew you to this article
    (despite its length), but it also represents a potential journey of the SGD algorithm
    in search of a global minimum. In this journey, it navigates rocky paths where
    the height symbolizes the loss. If this doesn’t sound clear now, don’t worry,
    it will be by the end of this article.
  prefs: []
  type: TYPE_NORMAL
- en: '**Index:**'
  prefs: []
  type: TYPE_NORMAL
- en: '· [1: Understanding the Basics](#6a59)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [1.1: What is Gradient Descent](#2d34)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [1.2: The ‘Stochastic’ in Stochastic Gradient Descent](#5b93)'
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**2: The Mechanics of SGD**](#d6f5)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [2.1: The Algorithm Explained](#7563)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [2.2: Understanding Learning Rate](#f1f1)'
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**3: SGD in Practice**](#c500)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [3.1: Implementing SGD in Machine Learning Models](#c4db)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [3.2: SGD in Sci-kit Learn and Tensorflow](#451b)'
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**4: Advantages and Challenges**](#0e3d)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [4.1: Why Choose SGD?](#de7c)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [4.2: Overcoming Challenges in SGD](#c053)'
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**5: Beyond Basic SGD**](#5a3f)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [5.1: Variants of SGD](#19d7)'
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [5.2: Future of SGD](#b6e0)'
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**Conclusion**](#6db6)'
  prefs: []
  type: TYPE_NORMAL
