- en: Classify Jira Tickets with GenAI On Amazon Bedrock
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用生成式AI在Amazon Bedrock上分类Jira票务
- en: 原文：[https://towardsdatascience.com/classify-jira-tickets-with-genai-on-amazon-bedrock-69450d4d8b21?source=collection_archive---------4-----------------------#2024-11-04](https://towardsdatascience.com/classify-jira-tickets-with-genai-on-amazon-bedrock-69450d4d8b21?source=collection_archive---------4-----------------------#2024-11-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/classify-jira-tickets-with-genai-on-amazon-bedrock-69450d4d8b21?source=collection_archive---------4-----------------------#2024-11-04](https://towardsdatascience.com/classify-jira-tickets-with-genai-on-amazon-bedrock-69450d4d8b21?source=collection_archive---------4-----------------------#2024-11-04)
- en: Replace traditional NLP approaches with prompt engineering and Large Language
    Models (LLMS) for Jira ticket text classification. A code sample walkthrough
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示工程和大语言模型（LLM）替代传统的NLP方法来进行Jira票务文本分类。这是一个代码示例的详细讲解。
- en: '[](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)[![Tanner
    McRae](../Images/bb80770681d29438860fe83aba8a22fb.png)](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)
    [Tanner McRae](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)[![Tanner
    McRae](../Images/bb80770681d29438860fe83aba8a22fb.png)](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)
    [Tanner McRae](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)
    ·8 min read·Nov 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学前沿](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)
    ·阅读时长8分钟·2024年11月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e829c8a66e2c4fbdce6ee9ed37ea3f46.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e829c8a66e2c4fbdce6ee9ed37ea3f46.png)'
- en: Photo by [Annie Spratt](https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Annie Spratt](https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Remember the days when classifying text meant embarking on a machine learning
    journey? If you’ve been in the ML space long enough, you’ve probably witnessed
    at least one team disappear down the rabbit hole of building the “perfect” text
    classification system. The story usually goes something like this:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得以前将文本分类意味着开始一段机器学习之旅吗？如果你在机器学习领域待得够久，你可能已经亲眼见证过至少一个团队陷入了构建“完美”文本分类系统的无底洞。这个故事通常是这样的：
- en: '**Month 1**: “We’ll just quickly train a NLP model!”'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第1个月：“我们就快速训练一个NLP模型！”**'
- en: '**Month 2:** “We need more training data…”'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第2个月：“我们需要更多的训练数据……”**'
- en: '**Month 3: “**This is good enough”'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第3个月：“**这个已经足够好了”'
- en: For years, text classification has fallen into the realm of classic ML. Early
    in my career, I remember training a support vector machine (SVM) for email classification.
    Lots of preprocessing, iteration, data collection, and labeling.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，文本分类一直是经典机器学习领域的一个部分。早在我的职业生涯初期，我就记得为电子邮件分类训练支持向量机（SVM）。那时需要大量的预处理、迭代、数据收集和标注。
- en: 'But here’s the twist: it’s 2024, and generative AI models can **“generally”**
    classify text out of the box! You can build a robust ticket classification system
    without, collecting thousands of labeled training examples, managing ML training
    pipelines, or maintaining custom models.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里有个转折：现在是2024年，生成式AI模型已经能够**“通常”**开箱即用进行文本分类！你可以构建一个强大的票务分类系统，无需收集成千上万的标注训练数据，也不需要管理机器学习训练管道，或者维护定制的模型。
- en: In this post, we’ll go over how to setup a Jira ticket classification system
    using large language models on Amazon Bedrock and other AWS services.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将讨论如何使用Amazon Bedrock上的大语言模型和其他AWS服务，搭建一个Jira票务分类系统。
- en: '**DISCLAIMER**: I am a GenAI Architect at AWS and my opinions are my own.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**免责声明**：我在AWS担任生成式AI架构师，以下观点仅代表我个人意见。'
- en: Why Classify Jira Tickets?
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要分类Jira票务？
- en: A common ask from companies is to understand how teams spend their time. Jira
    has tagging features, but it can sometimes fall short through human error or lack
    of granularity. By doing this exercise, organizations can get better insights
    into their team activities, enabling data-driven decisions about resource allocation,
    project investment, and deprecation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 企业常见的需求之一是了解团队如何分配时间。Jira 有标签功能，但有时由于人为错误或缺乏粒度，可能会有所不足。通过进行这项工作，组织可以更好地洞察团队活动，从而做出基于数据的资源分配、项目投资和淘汰决策。
- en: Why Not Use Other NLP Approaches?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么不使用其他 NLP 方法？
- en: Traditional ML models and smaller transformers like BERT need hundreds (or thousands)
    of labeled examples, while LLMs can classify text out of the box. In our Jira
    ticket classification tests, a prompt-engineering approach matched or beat traditional
    ML models, processing 10k+ annual tickets for ~$10/year using Claude Haiku (excluding
    other AWS Service costs). Also, prompts are easier to update than retraining models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的 ML 模型和像 BERT 这样的较小的变换器需要数百（或数千）个标注示例，而 LLM 可以开箱即用地进行文本分类。在我们的 Jira 票据分类测试中，提示工程方法的效果与传统的
    ML 模型相当，甚至超越了它们，使用 Claude Haiku 处理 10k+ 年度票据，费用约为每年 ~$10（不包括其他 AWS 服务费用）。此外，提示比重新训练模型更容易更新。
- en: Code Sample
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码示例
- en: This [github repo](https://github.com/aws-samples/jira-ticket-classification)
    contains a sample application that connects to Jira Cloud, classifies tickets,
    and outputs them in a format that can be consumed by your favorite dashboarding
    tool (Tableu, Quicksight, or any other tool that supports CSVs).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 [github 仓库](https://github.com/aws-samples/jira-ticket-classification)包含了一个示例应用程序，它连接到
    Jira Cloud，分类票据，并以你最喜欢的仪表盘工具（如 Tableu、Quicksight 或任何支持 CSV 的工具）可以使用的格式输出它们。
- en: 'Important Notice: This project deploys resources in your AWS environment using
    Terraform. You will incur costs for the AWS resources used. Please be aware of
    the pricing for services like Lambda, Bedrock, Glue, and S3 in your AWS region.'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 重要通知：该项目使用 Terraform 在你的 AWS 环境中部署资源。你将为使用的 AWS 资源产生费用。请留意你所在 AWS 区域内 Lambda、Bedrock、Glue
    和 S3 等服务的定价。
- en: '**Pre Requisites**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**前提条件**'
- en: You’ll need to have terraform installed and the AWS CLI installed in the environment
    you want to deploy this code from
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在你希望部署此代码的环境中安装 terraform 和 AWS CLI
- en: '[Install Terraform using tfenv](https://github.com/tfutils/tfenv)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 tfenv 安装 Terraform](https://github.com/tfutils/tfenv)'
- en: '[Install AWS CLI & configure](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[安装 AWS CLI 并配置](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)'
- en: Architecture
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构
- en: The architecture is pretty straight forward. You can find details below.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 架构非常简单。你可以在下面找到详细信息。
- en: '![](../Images/7a1dc84efb3bbf496059d6045ca74266.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a1dc84efb3bbf496059d6045ca74266.png)'
- en: Image by the author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '**Step 1:** An AWS Lambda function is triggered on a cron job to fetch jira
    tickets based on a time window. Those tickets are then formatted and pushed to
    an S3 bucket under the **/unprocessed** prefix.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：** 触发一个 AWS Lambda 函数，通过定时任务获取基于时间窗口的 Jira 票据。然后，这些票据会被格式化并推送到 S3 存储桶中的
    **/unprocessed** 前缀。'
- en: '**Step 2:** A Glue job is triggered off **/unprocessed** object puts. This
    runs a PySpark deduplication task to ensure no duplicate tickets make their way
    to the dashboard. The deduplicated tickets are then put to the **/staged** prefix.
    This is useful for cases where you manually upload tickets as well as rely on
    the automatic fetch. **If you can ensure no duplicates, you can remove this step.**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：** 触发一个 Glue 任务，基于 **/unprocessed** 对象上传来运行 PySpark 去重任务，确保没有重复票据进入仪表盘。去重后的票据会被推送到
    **/staged** 前缀。这对于手动上传票据以及依赖自动获取的情况很有用。**如果你可以确保没有重复，你可以移除此步骤。**'
- en: '**Step 3:** A classification task is kicked off on the new tickets by calling
    Amazon Bedrock to classify the tickets based on a prompt to a large language model
    (LLM). After classification, the finished results are pushed to the **/processed**
    prefix. From here, you can pick up the processed CSV using any dashboarding tool
    you’d like that can consume a CSV.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3：** 通过调用 Amazon Bedrock 来启动新票据的分类任务，根据大语言模型（LLM）的提示对票据进行分类。分类后，完成的结果会推送到
    **/processed** 前缀。从这里，你可以使用任何支持 CSV 的仪表盘工具提取处理过的 CSV 文件。'
- en: Getting Started
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: To get started, clone the github repo above and move to the /terraform directory
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请克隆上述 GitHub 仓库并转到 /terraform 目录
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Run terraform init, plan, & apply. Make sure you have terraform installed on
    your computer and the AWS CLI configured.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`terraform init`、`plan`和`apply`。确保你的计算机上已安装Terraform并配置了AWS CLI。
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once the infrastructure is deployed into your account, you can navigate to AWS
    Secrets Manager and update the secret with your Jira Cloud credentials. You’ll
    need an API key, base url, and email to enable the automatic pull
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦基础设施部署到你的账户中，你可以导航到AWS Secrets Manager并更新密钥，使用你的Jira Cloud凭证。你需要一个API密钥、基本网址和电子邮件来启用自动拉取功能。
- en: '![](../Images/74f14dbab21c582550d50baf14a9b905.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74f14dbab21c582550d50baf14a9b905.png)'
- en: Image by the author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: And that’s it!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！
- en: You can (1) wait for the Cron to kick off an automatic fetch, (2) export the
    tickets to CSV and upload them to the /unprocessed S3 bucket prefix, or (3) manually
    trigger the Lambda function using a test.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择（1）等待Cron触发自动拉取，（2）将票据导出为CSV并上传到`/unprocessed` S3前缀，或者（3）通过测试手动触发Lambda函数。
- en: How Does It Work?
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: 'Jira Fetch:'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Jira拉取：
- en: 'Jira fetch uses a Lambda function with a Cloudwatch cron event to trigger it.
    The Lambda pulls in the AWS Secret and uses a get request in a while loop to retrieve
    paginated results until the JQL query completes:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Jira拉取使用Lambda函数和CloudWatch cron事件来触发。Lambda函数获取AWS Secrets，并使用while循环中的get请求，直到JQL查询完成，来检索分页结果：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It then creates a string representation of a CSV and uploads it into S3:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 它会创建CSV的字符串表示，并将其上传到S3：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Glue Job
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Glue作业
- en: An S3 event on the /unprocessed prefix kicks off a second lambda that starts
    an AWS Glue job. This is useful when there’s multiple entry points that Jira tickets
    can enter the system through. For example, if you want to do a backfill.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`/unprocessed`前缀上的S3事件触发了第二个Lambda函数，启动了AWS Glue作业。当Jira票据有多个入口点进入系统时，这非常有用。例如，如果你想进行回填操作。'
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The Glue job itself is written in PySpark and can be found in the code repo
    [here](https://github.com/aws-samples/jira-ticket-classification/blob/main/src/glue/etl_script.py).
    The important take away is that it does a [leftanti](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-join.html#anti-join)
    join using the issue Ids on the items in the new CSV against all the Ids in the
    /staged CSVs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Glue作业本身是用PySpark编写的，可以在代码仓库[这里](https://github.com/aws-samples/jira-ticket-classification/blob/main/src/glue/etl_script.py)找到。重要的要点是，它使用[左反连接](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-join.html#anti-join)将新CSV中的项与`/staged`
    CSV中的所有ID进行连接。
- en: The results are then pushed to the **/staged** prefix.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 结果随后被推送到**/staged**前缀。
- en: 'Classify Jira Tickets:'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类Jira票据：
- en: This is where it it gets interesting. As it turns out, using prompt engineering
    can perform on par, if not better, than a text classification model using a couple
    techniques.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是有趣的地方。事实证明，使用提示工程可以与文本分类模型的表现相媲美，甚至在某些技术上表现更好。
- en: You can define the classifications and their descriptions in a prompt,
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在提示中定义分类及其描述，
- en: Ask the model to think step-by-step [(Chain of Thought)](https://www.promptingguide.ai/techniques/cot).
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让模型按步骤思考[(链式思维)](https://www.promptingguide.ai/techniques/cot)。
- en: 'And then output the classification without having to train a single model.
    See the prompt below:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后输出分类结果，而无需训练单个模型。请参见以下提示：
- en: '**Note:** It’s important to validate your prompt using a human curated subset
    of classified / labelled tickets. You should run this prompt through the validation
    dataset to make sure it aligns with how you expect the tickets to be classified'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 使用人工策划的分类/标签票据子集来验证你的提示非常重要。你应该将此提示通过验证数据集运行，确保它与预期的票据分类一致。'
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We’ve added a helper class that threads the calls to Bedrock to speed things
    up:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了一个帮助类，将调用Bedrock的操作串联起来，以加快速度：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Lastly, the classified tickets are converted to a CSV and uploaded to S3
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，分类的票据被转换为CSV并上传到S3。
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Dashboarding
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仪表板
- en: The project is dashboard agnostic. Any popular tool/service will work as long
    as it can consume a CSV. Amazon Quicksight, Tableu or anything in between will
    do.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目对仪表板工具没有依赖。任何流行的工具/服务都可以，只要它能够处理CSV。Amazon Quicksight、Tableau或任何介于两者之间的工具都可以使用。
- en: Conclusion
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this blog we discussed using Bedrock to automatically classify Jira tickets.
    These enriched tickets can then be used to create dashboards using various AWS
    Services or 3P tools. The takeaway, is that classifying text has become much simpler
    since the adoption of LLMs and what would have taken weeks can now be done in
    days.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们讨论了使用 Bedrock 来自动分类 Jira 工单。这些增强后的工单可以用来通过各种 AWS 服务或第三方工具创建仪表盘。要点是，自从采用了大型语言模型（LLM）后，文本分类变得更加简单，以前需要几周的工作，现在可以在几天内完成。
- en: '*If you enjoyed this article feel free to connect with me on* [*LinkedIn*](https://www.linkedin.com/in/tanner-mcrae-aa728358/)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢这篇文章，欢迎通过* [*LinkedIn*](https://www.linkedin.com/in/tanner-mcrae-aa728358/)
    *与我联系*'
