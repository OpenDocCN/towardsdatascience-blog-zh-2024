- en: Classify Jira Tickets with GenAI On Amazon Bedrock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/classify-jira-tickets-with-genai-on-amazon-bedrock-69450d4d8b21?source=collection_archive---------4-----------------------#2024-11-04](https://towardsdatascience.com/classify-jira-tickets-with-genai-on-amazon-bedrock-69450d4d8b21?source=collection_archive---------4-----------------------#2024-11-04)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Replace traditional NLP approaches with prompt engineering and Large Language
    Models (LLMS) for Jira ticket text classification. A code sample walkthrough
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)[![Tanner
    McRae](../Images/bb80770681d29438860fe83aba8a22fb.png)](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)
    [Tanner McRae](https://medium.com/@tannermcrae?source=post_page---byline--69450d4d8b21--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--69450d4d8b21--------------------------------)
    ·8 min read·Nov 4, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e829c8a66e2c4fbdce6ee9ed37ea3f46.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Annie Spratt](https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember the days when classifying text meant embarking on a machine learning
    journey? If you’ve been in the ML space long enough, you’ve probably witnessed
    at least one team disappear down the rabbit hole of building the “perfect” text
    classification system. The story usually goes something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Month 1**: “We’ll just quickly train a NLP model!”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Month 2:** “We need more training data…”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Month 3: “**This is good enough”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For years, text classification has fallen into the realm of classic ML. Early
    in my career, I remember training a support vector machine (SVM) for email classification.
    Lots of preprocessing, iteration, data collection, and labeling.
  prefs: []
  type: TYPE_NORMAL
- en: 'But here’s the twist: it’s 2024, and generative AI models can **“generally”**
    classify text out of the box! You can build a robust ticket classification system
    without, collecting thousands of labeled training examples, managing ML training
    pipelines, or maintaining custom models.'
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we’ll go over how to setup a Jira ticket classification system
    using large language models on Amazon Bedrock and other AWS services.
  prefs: []
  type: TYPE_NORMAL
- en: '**DISCLAIMER**: I am a GenAI Architect at AWS and my opinions are my own.'
  prefs: []
  type: TYPE_NORMAL
- en: Why Classify Jira Tickets?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common ask from companies is to understand how teams spend their time. Jira
    has tagging features, but it can sometimes fall short through human error or lack
    of granularity. By doing this exercise, organizations can get better insights
    into their team activities, enabling data-driven decisions about resource allocation,
    project investment, and deprecation.
  prefs: []
  type: TYPE_NORMAL
- en: Why Not Use Other NLP Approaches?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Traditional ML models and smaller transformers like BERT need hundreds (or thousands)
    of labeled examples, while LLMs can classify text out of the box. In our Jira
    ticket classification tests, a prompt-engineering approach matched or beat traditional
    ML models, processing 10k+ annual tickets for ~$10/year using Claude Haiku (excluding
    other AWS Service costs). Also, prompts are easier to update than retraining models.
  prefs: []
  type: TYPE_NORMAL
- en: Code Sample
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This [github repo](https://github.com/aws-samples/jira-ticket-classification)
    contains a sample application that connects to Jira Cloud, classifies tickets,
    and outputs them in a format that can be consumed by your favorite dashboarding
    tool (Tableu, Quicksight, or any other tool that supports CSVs).
  prefs: []
  type: TYPE_NORMAL
- en: 'Important Notice: This project deploys resources in your AWS environment using
    Terraform. You will incur costs for the AWS resources used. Please be aware of
    the pricing for services like Lambda, Bedrock, Glue, and S3 in your AWS region.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Pre Requisites**'
  prefs: []
  type: TYPE_NORMAL
- en: You’ll need to have terraform installed and the AWS CLI installed in the environment
    you want to deploy this code from
  prefs: []
  type: TYPE_NORMAL
- en: '[Install Terraform using tfenv](https://github.com/tfutils/tfenv)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Install AWS CLI & configure](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The architecture is pretty straight forward. You can find details below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a1dc84efb3bbf496059d6045ca74266.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1:** An AWS Lambda function is triggered on a cron job to fetch jira
    tickets based on a time window. Those tickets are then formatted and pushed to
    an S3 bucket under the **/unprocessed** prefix.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2:** A Glue job is triggered off **/unprocessed** object puts. This
    runs a PySpark deduplication task to ensure no duplicate tickets make their way
    to the dashboard. The deduplicated tickets are then put to the **/staged** prefix.
    This is useful for cases where you manually upload tickets as well as rely on
    the automatic fetch. **If you can ensure no duplicates, you can remove this step.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3:** A classification task is kicked off on the new tickets by calling
    Amazon Bedrock to classify the tickets based on a prompt to a large language model
    (LLM). After classification, the finished results are pushed to the **/processed**
    prefix. From here, you can pick up the processed CSV using any dashboarding tool
    you’d like that can consume a CSV.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started, clone the github repo above and move to the /terraform directory
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Run terraform init, plan, & apply. Make sure you have terraform installed on
    your computer and the AWS CLI configured.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Once the infrastructure is deployed into your account, you can navigate to AWS
    Secrets Manager and update the secret with your Jira Cloud credentials. You’ll
    need an API key, base url, and email to enable the automatic pull
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/74f14dbab21c582550d50baf14a9b905.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: And that’s it!
  prefs: []
  type: TYPE_NORMAL
- en: You can (1) wait for the Cron to kick off an automatic fetch, (2) export the
    tickets to CSV and upload them to the /unprocessed S3 bucket prefix, or (3) manually
    trigger the Lambda function using a test.
  prefs: []
  type: TYPE_NORMAL
- en: How Does It Work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Jira Fetch:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Jira fetch uses a Lambda function with a Cloudwatch cron event to trigger it.
    The Lambda pulls in the AWS Secret and uses a get request in a while loop to retrieve
    paginated results until the JQL query completes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'It then creates a string representation of a CSV and uploads it into S3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Glue Job
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An S3 event on the /unprocessed prefix kicks off a second lambda that starts
    an AWS Glue job. This is useful when there’s multiple entry points that Jira tickets
    can enter the system through. For example, if you want to do a backfill.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The Glue job itself is written in PySpark and can be found in the code repo
    [here](https://github.com/aws-samples/jira-ticket-classification/blob/main/src/glue/etl_script.py).
    The important take away is that it does a [leftanti](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-join.html#anti-join)
    join using the issue Ids on the items in the new CSV against all the Ids in the
    /staged CSVs.
  prefs: []
  type: TYPE_NORMAL
- en: The results are then pushed to the **/staged** prefix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Classify Jira Tickets:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is where it it gets interesting. As it turns out, using prompt engineering
    can perform on par, if not better, than a text classification model using a couple
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: You can define the classifications and their descriptions in a prompt,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask the model to think step-by-step [(Chain of Thought)](https://www.promptingguide.ai/techniques/cot).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And then output the classification without having to train a single model.
    See the prompt below:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note:** It’s important to validate your prompt using a human curated subset
    of classified / labelled tickets. You should run this prompt through the validation
    dataset to make sure it aligns with how you expect the tickets to be classified'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ve added a helper class that threads the calls to Bedrock to speed things
    up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, the classified tickets are converted to a CSV and uploaded to S3
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Dashboarding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The project is dashboard agnostic. Any popular tool/service will work as long
    as it can consume a CSV. Amazon Quicksight, Tableu or anything in between will
    do.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog we discussed using Bedrock to automatically classify Jira tickets.
    These enriched tickets can then be used to create dashboards using various AWS
    Services or 3P tools. The takeaway, is that classifying text has become much simpler
    since the adoption of LLMs and what would have taken weeks can now be done in
    days.
  prefs: []
  type: TYPE_NORMAL
- en: '*If you enjoyed this article feel free to connect with me on* [*LinkedIn*](https://www.linkedin.com/in/tanner-mcrae-aa728358/)'
  prefs: []
  type: TYPE_NORMAL
