- en: Prompt Engineering for Cognitive Flexibility
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认知灵活性的提示工程
- en: 原文：[https://towardsdatascience.com/prompt-engineering-for-cognitive-flexibility-44e490e3473d?source=collection_archive---------4-----------------------#2024-07-11](https://towardsdatascience.com/prompt-engineering-for-cognitive-flexibility-44e490e3473d?source=collection_archive---------4-----------------------#2024-07-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/prompt-engineering-for-cognitive-flexibility-44e490e3473d?source=collection_archive---------4-----------------------#2024-07-11](https://towardsdatascience.com/prompt-engineering-for-cognitive-flexibility-44e490e3473d?source=collection_archive---------4-----------------------#2024-07-11)
- en: Practical insights and analysis from experiments with MMLU-Pro
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 来自MMLU-Pro实验的实践见解与分析
- en: '[](https://medium.com/@hominum_universalis?source=post_page---byline--44e490e3473d--------------------------------)[![Giuseppe
    Scalamogna](../Images/ff7b3bec7c26e5684fba26211b6f027a.png)](https://medium.com/@hominum_universalis?source=post_page---byline--44e490e3473d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--44e490e3473d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--44e490e3473d--------------------------------)
    [Giuseppe Scalamogna](https://medium.com/@hominum_universalis?source=post_page---byline--44e490e3473d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@hominum_universalis?source=post_page---byline--44e490e3473d--------------------------------)[![朱塞佩·斯卡拉莫尼亚](../Images/ff7b3bec7c26e5684fba26211b6f027a.png)](https://medium.com/@hominum_universalis?source=post_page---byline--44e490e3473d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--44e490e3473d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--44e490e3473d--------------------------------)
    [朱塞佩·斯卡拉莫尼亚](https://medium.com/@hominum_universalis?source=post_page---byline--44e490e3473d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--44e490e3473d--------------------------------)
    ·9 min read·Jul 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--44e490e3473d--------------------------------)
    ·9分钟阅读·2024年7月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/436b39e193a137a79ca30655f218133f.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/436b39e193a137a79ca30655f218133f.png)'
- en: 'Source: Image by Author and generated with MidJourney'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：图片由作者提供，并使用MidJourney生成
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: 'Developing AI agents that can, among other things, think, plan and decide with
    human-like proficiency is a prominent area of current research and discussion.
    For now, LLMs have taken the lead as the foundational building block for these
    agents. As we pursue ever increasingly complex capabilities, regardless of the
    LLM(s) being utilized, we inevitably encounter the same types of questions over
    and over, including:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 开发能够执行思考、规划和决策等任务的AI代理，并且具有人类水平的熟练度，是当前研究和讨论的一个重要领域。目前，LLM（大语言模型）已经成为这些代理的基础构建块。随着我们追求越来越复杂的能力，无论使用的是哪种LLM，我们不可避免地会反复遇到相同类型的问题，包括：
- en: Does the model have the necessary knowledge to complete a task accurately and
    efficiently?
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型是否具备完成任务所需的必要知识，并能够高效、准确地执行任务？
- en: If the appropriate knowledge is available, how do we reliably activate it?
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果有合适的知识，如何可靠地激活它？
- en: Is the model capable of imitating complex cognitive behavior such as reasoning,
    planning and decision making to an acceptable level of proficiency?
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型是否能够模仿复杂的认知行为，如推理、规划和决策，达到一个可以接受的熟练度？
- en: This article explores these questions through the lens of a recent mini-experiment
    I conducted that leverages the latest [MMLU-Pro](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro)
    benchmark. The findings lead to some interesting insights around cognitive flexibility
    and how we might apply this concept from cognitive science to our AI agent and
    prompt engineering efforts.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文通过我最近进行的一项小型实验来探讨这些问题，该实验利用了最新的[MMLU-Pro](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro)基准。实验结果带来了一些关于认知灵活性的重要见解，以及我们如何将这一概念从认知科学应用到我们的AI代理和提示工程工作中。
- en: '**Background**'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**背景**'
- en: '**MMLU-Pro — A multiple choice gauntlet**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**MMLU-Pro — 一项多项选择挑战**'
- en: The recently released MMLU-Pro (Massive Multitask Language Understanding) benchmark
    tests the capability boundaries of AI models by presenting a more robust and challenging
    set of tasks compared to its predecessor, MMLU [1]. The goal was to create a comprehensive
    evaluation covering a diverse array of subjects, requiring models to possess a
    broad base of knowledge and demonstrate the ability to apply it in varied contexts.
    To this end, MMLU-Pro tests models against very challenging, reasoning-oriented
    multiple-choice questions spread across 14 different knowledge domains.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近发布的MMLU-Pro（大规模多任务语言理解）基准测试通过提出比前身MMLU[1]更强大、更具挑战性的任务，测试AI模型的能力边界。目标是创建一个全面的评估，涵盖多个学科，要求模型具有广泛的知识基础，并展示在不同情境中应用这些知识的能力。为此，MMLU-Pro通过14个不同知识领域中的非常具有挑战性的推理导向选择题来测试模型。
- en: We are all quite familiar with multiple-choice exams from our own academic journeys.
    The strategies we use on these types of tests often involve a combination of reasoning,
    problem solving, recall, elimination, inference, and educated guessing. Our ability
    to switch seamlessly between these strategies in underpinned by cognitive flexibility,
    which we employ to adapt our approach to the demands of each specific question.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都非常熟悉来自自己学术经历的选择题考试。我们在这些类型的考试中使用的策略通常包括推理、解决问题、回忆、排除、推断和有根据的猜测。我们能够在这些策略之间无缝切换，这一能力由认知灵活性支撑，使我们能够根据每个具体问题的要求调整我们的解题方式。
- en: 'Cognitive flexibility encompasses mental capabilities such as switching between
    different concepts and thinking about multiple concepts simultaneously. It enables
    us to adapt our thinking in response to the situation at hand. Is this concept
    potentially useful in our AI agent and prompt engineering efforts? Before we explore
    that, let’s examine a sample question from MMLU-Pro in the “business” category:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 认知灵活性包含了诸如在不同概念之间切换以及同时思考多个概念等心理能力。它使我们能够根据当前的情境调整我们的思维方式。这个概念在我们的AI代理和提示工程工作中可能会有用吗？在我们探讨之前，让我们来看一个来自MMLU-Pro“商业”类别的样题：
- en: 'Question 205: If the annual earnings per share has mean $8.6 and standard deviation
    $3.4, what is the chance that an observed EPS less than $5.5?'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 问题205：如果每股年盈余的均值为$8.6，标准差为$3.4，那么观察到的每股盈余小于$5.5的概率是多少？
- en: 'Answers: A: 0.3571, B: 0.0625, C: 0.2345, D: 0.5000, E: 0.4112, F: 0.1814,
    G: 0.3035, H: 0.0923, I: 0.2756, J: 0.1587'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '答案：A: 0.3571, B: 0.0625, C: 0.2345, D: 0.5000, E: 0.4112, F: 0.1814, G: 0.3035,
    H: 0.0923, I: 0.2756, J: 0.1587'
- en: 'Although categorically labelled as ‘business’, this question requires knowledge
    of statistics. We need to standardize the value and calculate how many standard
    deviations it is away from the mean to get a probability estimate. This is done
    by calculating the Z-score as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管被归类为“商业”问题，这道题实际上需要统计学知识。我们需要标准化该值，并计算它离均值有多少个标准差，以获取概率估算。这是通过计算Z分数来完成的，计算方式如下：
- en: '![](../Images/4861a4ae9b88f0ec3883ab3eb13c8381.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4861a4ae9b88f0ec3883ab3eb13c8381.png)'
- en: 'Where:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: X is the value in question ($5.50 in this case)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: X是待求值（在本例中为$5.50）
- en: μ​ is the mean (given as $8.6).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: μ是均值（给定为$8.6）。
- en: σ is the standard deviation (given as $3.4)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: σ是标准差（给定为$3.4）
- en: If we substitute those values into the formula we get -0.09118\. We then consult
    the standard normal distribution table and find that the probability of Z being
    less than -0.9118 is approximately 18.14% which correspond to answer “F” from
    our choices.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将这些值代入公式，我们得到-0.09118。然后，我们查阅标准正态分布表，发现Z小于-0.9118的概率约为18.14%，这对应我们选择中的答案“F”。
- en: I think it is safe to say that this is a non-trivial problem for an LLM to solve.
    The correct answer cannot be memorized and needs to be calculated. Would an LLM
    have the knowledge and cognitive flexibility required to solve this type of problem?
    What prompt engineering strategies might we employ?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为可以肯定地说，这对一个LLM来说是一个非平凡的问题。正确答案不能仅凭记忆，需要通过计算得出。一个LLM是否具备解决此类问题所需的知识和认知灵活性？我们可以采用哪些提示工程策略？
- en: '**Prompt Engineering to the Rescue**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示工程来拯救**'
- en: 'In approaching the above problem with an LLM, we might consider: does our chosen
    model have the knowledge of statistics needed? Assuming it does, how do we reliably
    activate the knowledge around standard normal distributions? And finally, can
    the model imitate the mathematical reasoning steps to arrive at the correct answer?'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在用 LLM 解决上述问题时，我们可能会考虑：我们选择的模型是否具备所需的统计学知识？假设它具备这些知识，如何可靠地激活与标准正态分布相关的知识？最后，模型能否模仿数学推理步骤来得出正确答案？
- en: The widely known “Chain-of-Thought” (CoT) prompt engineering strategy seems
    like a natural fit. The strategy relies on prompting the model to generate intermediate
    reasoning steps before arriving at the final answer. There are two basic approaches.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 广为人知的“思维链”（CoT）提示工程策略似乎非常合适。该策略依赖于提示模型在得出最终答案之前生成中间推理步骤。基本上有两种方法。
- en: '**Chain-of-Thought (CoT)**: Involves few-shot prompting, where examples of
    the reasoning process are provided to guide the model [2].'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**思维链（CoT）**：涉及少量示例提示，在此过程中提供推理过程的示例来指导模型 [2]。'
- en: '**Zero-Shot Chain-of-Thought (Zero-Shot CoT)**: Involves prompting the model
    to generate reasoning steps without prior examples, often using phrases like “Let’s
    think step by step” [3].'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**零-shot 思维链（Zero-Shot CoT）**：涉及提示模型生成推理步骤而不使用先前的示例，通常使用诸如“让我们一步步思考”之类的短语 [3]。'
- en: There are numerous other strategies, generally relying on a combination of pre-generation
    feature activation, i.e. focusing on activating knowledge in the initial prompt,
    and intra-generation feature activation, i.e. focusing on the LLM dynamically
    activating knowledge as it generates its output token by token.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他策略，通常依赖于预生成特征激活的结合，即在初始提示中聚焦于激活知识，以及生成内在特征激活，即在模型生成输出时动态激活知识，每次生成一个令牌。
- en: '**Mini-Experiment**'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**小型实验**'
- en: '**Experiment Design**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**实验设计**'
- en: 'In designing the mini-experiment, I utilized ChatGPT-4o and randomly sampled
    10 questions from each of the 14 knowledge domains in the MMLU-Pro data set. The
    experiment aimed to evaluate two main aspects:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计小型实验时，我使用了 ChatGPT-4o 并随机从 MMLU-Pro 数据集中每个14个知识领域中抽取了10个问题。实验的目标是评估两个主要方面：
- en: '**Effectiveness of different prompt engineering techniques:** Specifically,
    the impact of using different techniques for activating the necessary knowledge
    and desired behavior in the model. The techniques were selected to align with
    varying degrees of cognitive flexibility and were all zero-shot based.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不同提示工程技术的有效性：** 具体来说，使用不同技术来激活模型中所需知识和期望行为的影响。这些技术的选择旨在与不同程度的认知灵活性相匹配，且均为零-shot
    技术。'
- en: '**The impact from deliberately limiting reasoning and cognitive flexibility:**
    Specifically, how limiting the model’s ability to reason openly (and by consequence
    severely limiting cognitive flexibility) affects accuracy.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**故意限制推理和认知灵活性带来的影响：** 具体来说，限制模型自由推理的能力（因此严重限制认知灵活性）如何影响准确性。'
- en: 'The different prompt techniques tested relied on the following templates:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 测试的不同提示技巧依赖于以下模板：
- en: '**Direct Question** — {Question}. Select the correct answer from the following
    answer choices: {Answers}. Respond with the letter and answer selected.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**直接提问** — {问题}。从以下选项中选择正确答案：{答案}。请用字母和选定的答案回答。'
- en: '**CoT** — {Question}. Let’s think step by step and select the correct answer
    from the following answer choices: {Answers}. Respond with the letter and answer
    selected.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**思维链（CoT）** — {问题}。让我们一步步思考，从以下选项中选择正确答案：{答案}。请用字母和选定的答案回答。'
- en: '**Knowledge Domain Activation** — {Question}. Let’s think about the knowledge
    and concepts needed and select the correct answer from the following answer choices:
    {Answers}. Respond with the letter and answer selected.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识领域激活** — {问题}。让我们考虑所需的知识和概念，并从以下选项中选择正确答案：{答案}。请用字母和选定的答案回答。'
- en: '**Contextual Scaffolds** — {Question}. My expectations are that you will answer
    the question correctly. Create an operational context for yourself to maximize
    fulfillment of my expectations and select the correct answer from the following
    answer choices: {Answers}. Respond with the letter and answer selected. [4]'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**情境框架** — {问题}。我的期望是你能正确回答这个问题。为自己创建一个操作性情境，以最大化实现我的期望，并从以下选项中选择正确答案：{答案}。请用字母和选定的答案回答。
    [4]'
- en: The Direct Question approach served as the baseline, likely enabling the highest
    degree of cognitive flexibility from the model. CoT would likely lead to the least
    amount of cognitive flexibility as the model is instructed to proceed step-by-step.
    Knowledge Domain Activation and Contextual Scaffolds fall somewhere between Direct
    Question and CoT.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 直接提问方法作为基准，可能让模型发挥出最高程度的认知灵活性。链式推理（CoT）可能导致最少的认知灵活性，因为模型被指示逐步进行。知识领域激活和情境支架的表现介于直接提问和链式推理之间。
- en: Deliberately constraining reasoning was accomplished by taking the last line
    of the above prompt templates, i.e. “Respond with the letter and answer selected.”
    and specifying instead “Respond *only* with the letter and answer selected *and
    nothing else*.”
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有意限制推理是通过采纳上述提示模板的最后一行来实现的，即“仅回复所选字母和答案”，并进一步明确为“*仅*回复所选字母和答案，*且不包含其他内容*。”
- en: If you are interested in the code I used to run the experiment and results,
    they can be found in this GitHub repo linked [here](https://github.com/gfranco78/cognitive-flex-exp).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对我用于运行实验的代码和结果感兴趣，可以在这个[GitHub仓库](https://github.com/gfranco78/cognitive-flex-exp)找到。
- en: '**Results**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**结果**'
- en: 'Here are the results for the different prompt techniques and their reasoning
    constrained variants:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是不同提示方法及其推理受限变体的结果：
- en: '![](../Images/c292a17494973e36fe9755fcc37c890c.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c292a17494973e36fe9755fcc37c890c.png)'
- en: All unconstrained reasoning prompts performed comparably, with the Direct Question
    approach performing slightly better than the others. This was a bit of a surprise
    since the MMLU-Pro paper [1] reports significant underperformance in direct question
    and strong performance gains with few-shot CoT. I won’t dwell on the discrepancy
    here since the purpose of the mini-experiment was not to replicate their setup.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 所有未限制推理的提示方法表现相似，直接提问方法的表现略优于其他方法。这有些出乎意料，因为MMLU-Pro论文[1]报告称，直接提问表现较差，而少量示例的链式推理（CoT）表现显著提高。我不会在这里详细讨论这一差异，因为这项小型实验的目的是不是为了复制他们的实验设置。
- en: More importantly for this mini-experiment, when reasoning was deliberately constrained,
    all techniques showed a comparable decline in accuracy, dropping from an average
    of 66% to 51%. This result is along the lines of what we expected. The more pertinent
    observation is that none of the techniques were successful in enhancing pre-generation
    knowledge activation beyond what would occur with Direct Question where pre-generation
    feature activation primarily occurs from the model being exposed to the text in
    the question and answer choices.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这项小型实验来说，更重要的是，当推理被故意限制时，所有技术的准确率都有所下降，从平均66%下降到51%。这一结果符合我们的预期。更相关的观察是，所有技术在生成前知识激活方面都没有成功超越直接提问方法，在直接提问中，生成前的特征激活主要来自模型接触问题和答案选项中的文本。
- en: 'The overall conclusion from these high-level results suggests that an optimal
    combination for prompt engineering effectiveness may very well involve:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些高层次结果的总体结论表明，提升提示工程有效性的最佳组合可能涉及以下内容：
- en: Allowing the model to exercise some degree of cognitive flexibility as exemplified
    best in the Direct Question approach.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 允许模型在一定程度上发挥认知灵活性，最佳示例是直接提问方法。
- en: Allowing the model to reason openly such that the reasoning traces are an active
    part of the generation.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 允许模型自由推理，使推理过程成为生成的一部分。
- en: '**The Compute Cost Dimension**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算成本维度**'
- en: Although not often discussed, token efficiency is becoming more and more important
    as LLMs find their way into varied industry use cases. The graph below shows the
    accuracy of each unconstrained prompt technique versus the average tokens generated
    in the answer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不常讨论，但随着大语言模型（LLMs）在不同行业应用场景中的应用，令牌效率变得越来越重要。下图展示了每种未限制提示方法的准确性与回答中生成的平均令牌数之间的关系。
- en: '![](../Images/e2a62bbd03388c9ceb1c42210c2f8f4b.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2a62bbd03388c9ceb1c42210c2f8f4b.png)'
- en: 'While the accuracy differential is not the primary focus, the efficiency of
    the Direct Question approach, generating an average of 180 tokens per answer,
    is notable compared to CoT, which produced approximately 339 tokens per answer
    (i.e. 88% more). Since accuracy was comparable, it leads us to speculate that
    CoT is on average less efficient compared to the other strategies when it comes
    to intra-generation knowledge activation, producing excessively verbose results.
    But what drove the excessive verbosity? To try and answer this it was helpful
    to examine the unconstrained reasoning prompts and number of times the model chose
    to answer with just the answer and no reasoning trace, even if not explicitly
    instructed to do so. The results were as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管准确性的差异并不是主要关注点，但“直接问题”方法的效率值得注意，每个答案平均生成 180 个标记，而 CoT 方法每个答案大约生成 339 个标记（即多出
    88%）。由于准确性相当，这让我们推测，当涉及到生成内在知识激活时，CoT 相较于其他策略平均效率较低，产生了过多冗长的结果。但是什么导致了这种过度冗长呢？为了解答这一问题，分析不受约束的推理提示以及模型选择仅用答案而没有推理痕迹回答的次数是很有帮助的，哪怕并没有明确指示这么做。结果如下：
- en: '![](../Images/73ed58b64d7088592a93ed2d09a568e7.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73ed58b64d7088592a93ed2d09a568e7.png)'
- en: '% of instances where only the answer was generated even if not strictly specified
    to do so'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 仅生成答案的实例百分比，即使没有严格要求这么做
- en: 'What was even more interesting was accuracy when the model chose to answer
    directly without any reasoning trace which is shown in the following table:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 更有趣的是，当模型选择直接回答而没有任何推理痕迹时，准确性表现如何，这在下表中有所展示：
- en: '![](../Images/51f7f765a6f040e10218fa1ad8c19735.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51f7f765a6f040e10218fa1ad8c19735.png)'
- en: The accuracy ranged from 64% to 70% without any reasoning traces being generated.
    Even with MMLU-Pro questions that are purposely designed to require reasoning
    and problem solving, when not over-constrained by the prompt, the model appears
    to demonstrate somethin akin to selecting different strategies based on the specific
    question at hand.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是设计上特别需要推理和解决问题的 MMLU-Pro 问题，在没有被提示过度约束时，模型似乎表现出类似于根据特定问题选择不同策略的能力，准确率从 64%
    到 70% 不等，并且没有生成任何推理痕迹。
- en: '**Practical Implications**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**实际意义**'
- en: The practical takeaway from these results is that straightforward prompt strategies
    can often be just as effective as overly structured ones. While CoT aims to simulate
    reasoning by inducing specific feature activations that are reasoning oriented,
    it may not always be necessary or optimal especially if excess token generation
    is a concern. Striving instead to allow the model to exercise cognitive flexibility
    can be a potentially more suitable approach.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些结果中得到的实际启示是，直接的提示策略往往和过于结构化的策略一样有效。尽管 CoT 旨在通过激发特定的特征激活来模拟推理，但它并不总是必要或最优，特别是当过多生成标记成为问题时。相反，鼓励模型发挥其认知灵活性可能是一个更合适的策略。
- en: '**Conclusion: Paving the Way for Cognitive Flexibility in AI Agents**'
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论：为 AI 代理铺平认知灵活性的道路**'
- en: The findings from this mini-experiment offer compelling insights into the importance
    of cognitive flexibility in LLMs and AI Agents. In human cognition, cognitive
    flexibility refers to the ability to adapt thinking and behavior in response to
    changing tasks or demands. It involves switching between different concepts, maintaining
    multiple concepts simultaneously, and shifting attention as needed. In the context
    of LLMs, it can be understood as the model’s ability to dynamically adjust its
    internal activations in response to textual stimuli.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这项小型实验的发现提供了关于大语言模型（LLMs）和 AI 代理认知灵活性重要性的有力见解。在人类认知中，认知灵活性指的是在面对任务或需求变化时，能够调整思维和行为的能力。它包括在不同概念之间切换，同时维持多个概念，并根据需要转移注意力。在
    LLM 的语境下，可以理解为模型能够根据文本刺激动态调整其内部激活。
- en: 'Continued focus on developing technologies and techniques in this area could
    result in significant enhancements to AI agent proficiency in a variety of complex
    task settings. For example, exploring the idea alongside other insights such as
    those surfaced by Anthropic in their recent paper “[Scaling Monosemanticity: Extracting
    Interpretable Features from Claude 3 Sonnet](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html),”
    could yield techniques that unlock the ability to dynamically observe and tailor
    the level of cognitive flexibility employed based on the task’s complexity and
    domain.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '继续关注该领域技术和技巧的开发，可能会在各种复杂任务环境中显著提升人工智能代理的能力。例如，与Anthropic在其近期论文“[Scaling Monosemanticity:
    Extracting Interpretable Features from Claude 3 Sonnet](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html)”中提出的其他见解一起探索这一思想，可能会产生技术，使我们能够根据任务的复杂性和领域动态观察并调整使用的认知灵活性水平。'
- en: As we push the boundaries of AI, cognitive flexibility will likely be key to
    creating models that not only perform reliably but also understand and adapt to
    the complexities of the real world.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们推动人工智能的边界，认知灵活性可能是创建不仅能可靠执行任务，还能理解并适应现实世界复杂性的模型的关键。
- en: Thanks for reading and follow me for insights that result from future explorations
    connected to this work. If you would like to discuss do not hesitate to connect
    with me on [LinkedIn](https://www.linkedin.com/in/giuseppe-scalamogna-8b389145/).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读，并关注我以获取未来与这项工作相关的探索成果。如果你希望讨论，请随时在[LinkedIn](https://www.linkedin.com/in/giuseppe-scalamogna-8b389145/)与我联系。
- en: Unless otherwise noted, all images in this article are by the author.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有注明，本文中的所有图片均由作者提供。
- en: '**References:**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献：**'
- en: '[1] Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang
    Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai
    Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, Wenhu Chen: MMLU-Pro: A More Robust
    and Challenging Multi-Task Language Understanding Benchmark. [*arXiv:2406.01574*](https://arxiv.org/abs/2406.01574)*,
    2024*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang
    Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai
    Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, Wenhu Chen: MMLU-Pro: 更强大且具有挑战性的多任务语言理解基准。[*arXiv:2406.01574*](https://arxiv.org/abs/2406.01574)，*2024*'
- en: '[2] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei
    Xia, Ed Chi, Quoc Le, Denny Zhou: Chain-of-Thought Prompting Elicits Reasoning
    in Large Language Models. [*arXiv:2201.11903v6*](https://arxiv.org/abs/2201.11903v6)
    *, 2023*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei
    Xia, Ed Chi, Quoc Le, Denny Zhou: 连锁推理提示在大型语言模型中引发推理。[*arXiv:2201.11903v6*](https://arxiv.org/abs/2201.11903v6)，*2023*'
- en: '[3] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa:
    Large Language Models are Zero-Shot Reasoners. [*arXiv:2205.11916v4*](https://arxiv.org/abs/2205.11916v4),
    *2023*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa:
    大型语言模型是零-shot推理者。[*arXiv:2205.11916v4*](https://arxiv.org/abs/2205.11916v4)，*2023*'
- en: '[4] Giuseppe Scalamogna, A Universal Roadmap for Prompt Engineering: The Contextual
    Scaffolds Framework (CSF), [*https://medium.com/towards-data-science/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a*](https://medium.com/towards-data-science/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a)*,
    2023*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Giuseppe Scalamogna, 通用提示工程路线图：情境支架框架（CSF），[*https://medium.com/towards-data-science/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a*](https://medium.com/towards-data-science/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a)，*2023*'
