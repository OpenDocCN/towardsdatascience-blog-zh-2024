- en: How to Build a Semantic Search Engine for Emojis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建一个语义搜索引擎来搜索表情符号
- en: 原文：[https://towardsdatascience.com/how-to-build-a-semantic-search-engine-for-emojis-ef4c75e3f7be?source=collection_archive---------8-----------------------#2024-01-10](https://towardsdatascience.com/how-to-build-a-semantic-search-engine-for-emojis-ef4c75e3f7be?source=collection_archive---------8-----------------------#2024-01-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-build-a-semantic-search-engine-for-emojis-ef4c75e3f7be?source=collection_archive---------8-----------------------#2024-01-10](https://towardsdatascience.com/how-to-build-a-semantic-search-engine-for-emojis-ef4c75e3f7be?source=collection_archive---------8-----------------------#2024-01-10)
- en: Find The Sentiment You’re Looking For 🔍🤔😀🚀
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找你想要的情感 🔍🤔😀🚀
- en: '[](https://medium.com/@jacob_marks?source=post_page---byline--ef4c75e3f7be--------------------------------)[![Jacob
    Marks, Ph.D.](../Images/94d9832b8706d1044e3195386613bfab.png)](https://medium.com/@jacob_marks?source=post_page---byline--ef4c75e3f7be--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ef4c75e3f7be--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ef4c75e3f7be--------------------------------)
    [Jacob Marks, Ph.D.](https://medium.com/@jacob_marks?source=post_page---byline--ef4c75e3f7be--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jacob_marks?source=post_page---byline--ef4c75e3f7be--------------------------------)[![Jacob
    Marks, Ph.D.](../Images/94d9832b8706d1044e3195386613bfab.png)](https://medium.com/@jacob_marks?source=post_page---byline--ef4c75e3f7be--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ef4c75e3f7be--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ef4c75e3f7be--------------------------------)
    [Jacob Marks, Ph.D.](https://medium.com/@jacob_marks?source=post_page---byline--ef4c75e3f7be--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ef4c75e3f7be--------------------------------)
    ·15 min read·Jan 10, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ef4c75e3f7be--------------------------------)
    ·阅读时间15分钟·2024年1月10日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/38c4d89af0b8bd1549b7af17e735042e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38c4d89af0b8bd1549b7af17e735042e.png)'
- en: Semantic search over emojis for “halloween” using a custom emoji search engine.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自定义表情符号搜索引擎进行“halloween”的语义搜索。
- en: 'If you’ve ever used Google Docs, or Slack, you may have noticed that when you
    type a “:” immediately followed by another character, a list of emojis pops up:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经使用过Google Docs或Slack，你可能注意到，当你输入一个“:”紧接着另一个字符时，会弹出一个表情符号列表：
- en: '![](../Images/22de006beada9fd015206018637aeaf2.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22de006beada9fd015206018637aeaf2.png)'
- en: Since I discovered this, I’ve been making *major* use out of the feature. I
    add emojis into way more of my messages, blog posts, and other written works than
    I ever imagined I would. I actually got so accustomed to this means of adding
    emojis that I installed [Rocket](https://matthewpalmer.net/rocket/) — a free app
    that brings the same emoji searchability to all text boxes and text editors on
    the computer. It’s a game changer.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自从我发现这个功能以来，我就一直在*大量*使用它。我在我的消息、博客文章和其他书面作品中添加了比我曾经想象的更多的表情符号。事实上，我已经习惯了这种添加表情符号的方式，以至于我安装了[Rocket](https://matthewpalmer.net/rocket/)——一款免费应用程序，它将相同的表情符号搜索功能带入到电脑上的所有文本框和文本编辑器中。这真是一个改变游戏规则的工具。
- en: 'But as I’ve used these emoji search engines more and more, I’ve noticed a frustrating
    limitation: all of the searches are based on the *exact* text in your query and
    in the name and description of the emoji. Essentially, you need to search for
    something incredibly precisely for any results to show up.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，随着我使用这些表情符号搜索引擎的次数越来越多，我注意到一个令人沮丧的限制：所有搜索都基于你查询中的*精确*文本，以及表情符号的名称和描述。实际上，你需要非常精确地搜索某个词，才能显示出任何结果。
- en: 'Here’s an example: if we search for “audio”, not a single result shows up:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子：如果我们搜索“audio”，一个结果都不会显示出来：
- en: '![](../Images/8a07cd9f11d0ee6dbaebc12f5c01ab83.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a07cd9f11d0ee6dbaebc12f5c01ab83.png)'
- en: This isn’t because the set of emojis is lacking in the audio category. If we
    were to type in “music” or “speaker”, we would get a long list of results. Instead,
    it has to do with the fact that the specific string of text “audio” does not show
    up in the name or textual description associated with any of the emojis.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是因为表情符号集合中缺少音频类的表情符号。如果我们输入“music”或“speaker”，我们会得到一长串结果。实际上，这与“audio”这个特定文本串的名称或描述中并没有出现任何表情符号相关的事实有关。
- en: '![](../Images/4df2c1363dab033580d0ac83ffbf4870.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4df2c1363dab033580d0ac83ffbf4870.png)'
- en: 'This relatively minor inconvenience bothered me so much that I decided to build
    this:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个相对较小的不便让我感到如此困扰，以至于我决定构建这个：
- en: By “this”, I mean an open-source semantic emoji search engine, with both UI-centric
    and CLI versions. The Python CLI library can be found [here](https://github.com/jacobmarks/emoji_search),
    and the UI-centric version can be found [here](https://github.com/jacobmarks/emoji-search-plugin).
    You can also play around with a hosted (also free) version of the UI emoji search
    engine online [here](https://try.fiftyone.ai/datasets/emojis/samples).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: “这个”指的是一个开源的语义表情符号搜索引擎，具有基于UI和CLI两个版本。Python CLI库可以在[这里](https://github.com/jacobmarks/emoji_search)找到，基于UI的版本可以在[这里](https://github.com/jacobmarks/emoji-search-plugin)找到。你还可以在线尝试一个托管的（也是免费的）UI表情符号搜索引擎，点击[这里](https://try.fiftyone.ai/datasets/emojis/samples)。
- en: '![](../Images/2bb7629d1dedcae260e9e34cf7d77451.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2bb7629d1dedcae260e9e34cf7d77451.png)'
- en: '*Command line version of the Semantic Emoji Search Engine*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*语义表情符号搜索引擎的命令行版本*'
- en: Building this was not as simple or straightforward as I initially hoped. It
    took a lot of experimentation, and a lot of ideas I thought were quite clever
    fell essentially flat. But in the end, I was able to create an emoji search engine
    that works fairly well.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 构建这个过程并不像我最初希望的那样简单或直接。这花了很多实验，很多我认为相当聪明的想法最终都失败了。但最终，我成功地创建了一个相当好用的表情符号搜索引擎。
- en: Here’s how I built it, what worked, and what didn’t, and the lessons learned
    along the way.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我如何构建它、哪些方面有效、哪些方面无效，以及在过程中学到的经验教训。
- en: '[What is an Emoji](#ae15)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是表情符号](#ae15)'
- en: '[The Data](#a881)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据](#a881)'
- en: '[Emojis versus Images and Text](#2396)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[表情符号与图片和文本](#2396)'
- en: '[Bridging the Modality Gap](#89d6)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[弥合模态差距](#89d6)'
- en: '[Using the Emoji Search Engine](#733f)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用表情符号搜索引擎](#733f)'
- en: What is an Emoji
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是表情符号
- en: Before building a semantic search engine for emojis, it’s worth briefly explaining
    what exactly an emoji is. The term *emoji* derives from the Japanese kanji 絵 (eh)
    meaning *picture*, and 文字 (mōji) meaning letter or character. Essentially, this
    means that an emoji is etymologically a pictogram, and while it is connected to
    the English word *emotion,* it is not an “emotion icon” — that is an [emoticon](https://en.wikipedia.org/wiki/Emoticon).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建一个表情符号语义搜索引擎之前，值得简要解释一下什么是表情符号。*emoji* 这个词源自日语汉字絵（eh），意思是*图片*，以及文字（mōji），意思是字母或字符。从词源学的角度来看，emoji本质上是一种象形文字，虽然它与英语单词*emotion*（情感）有关，但它并不是“情感图标”——这才是[表情符号](https://en.wikipedia.org/wiki/Emoticon)。
- en: Along with [alphanumeric characters](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Latin_script),
    [African click sounds](https://en.wikipedia.org/wiki/Latin_Extended-B#African_letters_for_clicks),
    [mathematical](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Mathematical_symbols)
    and [geometric symbols](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Geometric_Shapes),
    [dingbats](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Dingbats),
    and [computer control sequences](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Control_codes),
    emojis can be represented as Unicode characters, making them computer-readable.
    Unlike alphanumeric characters and other symbols, however, emojis are *maintained*
    by the [Unicode Consortium](https://home.unicode.org/)*.* The consortium solicits
    proposals for new emojis, and regularly selects which emojis will be added to
    the standard.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与[字母数字字符](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Latin_script)、[非洲点击音](https://en.wikipedia.org/wiki/Latin_Extended-B#African_letters_for_clicks)、[数学符号](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Mathematical_symbols)和[几何符号](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Geometric_Shapes)、[装饰符号](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Dingbats)以及[计算机控制序列](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Control_codes)一起，表情符号可以作为Unicode字符表示，从而使它们可以被计算机读取。然而，与字母数字字符和其他符号不同，表情符号由[Unicode联盟](https://home.unicode.org/)进行*维护*。该联盟会征集新表情符号的提案，并定期选择哪些表情符号将被加入到标准中。
- en: At the time of writing, in November 2023, there are [more than 3,600 recognized
    emojis](https://home.unicode.org/emoji/about-emoji/), symbolizing a wide range
    of ideas and sentiments. Some emojis are represented by a single unicode character,
    or *code-point*. For example, the “grinning face” emoji, 😀, is represented in
    unicode as U+1F600.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 截至写作时，2023年11月，已经有[超过3600个被认可的表情符号](https://home.unicode.org/emoji/about-emoji/)，它们象征着各种各样的思想和情感。有些表情符号由单一的Unicode字符或*编码点*表示。例如，“露齿而笑的脸”表情符号，😀，在Unicode中表示为U+1F600。
- en: 'Others are represented with sequences of code-points. These sequences, which
    combine single code-point emojis with the zero-width-joiner unicode character,
    are known as ZWJ sequences, and allow for the combining of concepts, in much the
    same way as [Chinese radicals](https://en.wikipedia.org/wiki/Kangxi_radical) can
    be combined to create a character that tells a story. As an example, the emoji
    👨‍👩‍👧is a zero-width joining of the emojis for *man* 👨(U+1F468), *woman* 👩(​​U+1F469),
    and *girl* 👧(U+1F467), connected by the ZWJ code-point U+200D:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其他的则通过代码点序列表示。这些序列将单个代码点表情符号与零宽度连接符unicode字符结合，称为ZWJ序列，允许将概念组合在一起，就像[汉字部首](https://en.wikipedia.org/wiki/Kangxi_radical)可以组合成一个讲述故事的字符一样。例如，表情符号👨‍👩‍👧就是通过ZWJ代码点U+200D连接的*男人*👨（U+1F468）、*女人*👩（U+1F469）和*女孩*👧（U+1F467）表情符号：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'According to the Unicode Consortium, 92% of the world’s online population uses
    emojis in their communications, and the ten most-used emojis in 2021 were: 😂 ❤️
    🤣 👍 😭 🙏 😘 🥰 😍 😊.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Unicode联盟的统计，全球92%的在线用户在通信中使用表情符号，2021年使用频率最高的十个表情符号是：😂 ❤️ 🤣 👍 😭 🙏 😘 🥰 😍 😊。
- en: Starting with the Data
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据开始
- en: Given that emojis are pictographs of sorts, I wanted to utilize both textual
    and visual information in the search process. My initial hypothesis was that for
    many emojis, the name — the text string used to invoke the emoji — conveys but
    a fraction of its meaning. This can be due to many reasons, from the limitations
    of natural language, to the additional meanings imbued by cultures and visual
    similarities. In order to truly bring the full essence of the emoji to bear, I
    needed to make use of visual information.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于表情符号在某种程度上是象形文字，我希望在搜索过程中同时利用文本信息和视觉信息。我的初步假设是，对于许多表情符号来说，名称——用于调出表情符号的文本字符串——只传达了其含义的一部分。这可能是由于多种原因，包括自然语言的局限性，以及文化和视觉相似性所赋予的附加含义。为了真正展现表情符号的完整本质，我需要利用视觉信息。
- en: 'I found this [Kaggle Emojis dataset](https://www.kaggle.com/datasets/subinium/emojiimage-dataset)
    from 2021, which has data about 1816 emojis, including the emoji representation,
    the text associated with it, the unicode code (or codes), and a [base64](https://en.wikipedia.org/wiki/Base64)
    encoded image. Here’s what the first few rows of the dataset look like, loaded
    as a pandas DataFrame:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我找到了一份2021年的[Kaggle Emojis数据集](https://www.kaggle.com/datasets/subinium/emojiimage-dataset)，其中包含1816个表情符号的数据，包括表情符号的表示、与之相关的文本、unicode编码（或编码）和一个[base64](https://en.wikipedia.org/wiki/Base64)编码的图像。以下是该数据集的前几行，加载为pandas
    DataFrame后呈现的样子：
- en: '![](../Images/ac2785f516f75b2549052b5388d10910.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac2785f516f75b2549052b5388d10910.png)'
- en: 'There are separate columns with names `Apple`, `Google`, `Facebook`, etc. because
    the emoji renders differently depending on the computer, website, or application.
    I decoded the images from base64 and converted them into [Pillow](https://pypi.org/project/Pillow/)
    images. Here is the first image from the Kaggle dataset (grinning face):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于表情符号的渲染方式取决于计算机、网站或应用程序，因此存在名为`Apple`、`Google`、`Facebook`等的单独列。我从base64解码这些图像并将其转换为[Pillow](https://pypi.org/project/Pillow/)图像。以下是Kaggle数据集中的第一张图像（露齿笑脸）：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/d2948f4c8927c66d864a400e50897b2f.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2948f4c8927c66d864a400e50897b2f.png)'
- en: Upon conversion, however, it became clear that the images were very low resolution.
    This one, for instance, is only 72x72 pixels. To improve the quality of the images
    that I was going to pass into downstream models, and to improve the quality of
    the experience in the eventual UI-based application, I passed all of these low-resolution
    images into [Real-ESRGAN](https://replicate.com/nightmareai/real-esrgan) to 10x
    the resolution.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在转换后很明显，这些图像的分辨率非常低。例如，这张图像仅为72x72像素。为了提高将要传递给下游模型的图像质量，并且为了改善最终基于UI的应用程序中的体验，我将所有这些低分辨率图像传递到[Real-ESRGAN](https://replicate.com/nightmareai/real-esrgan)，将分辨率提高了10倍。
- en: 'This is what the resulting images looked like:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图像看起来是这样的：
- en: '![](../Images/4d6b93d5b04f05729c9f7dc4e48f6164.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d6b93d5b04f05729c9f7dc4e48f6164.png)'
- en: Not all of the emojis had images for all of the image columns in the pandas
    DataFrame, so I used the first viable base64 encoding for each row.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 由于并非所有表情符号在pandas DataFrame中的所有图像列都有图像，因此我为每一行使用了第一个有效的base64编码。
- en: Emojis Versus Images and Text
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 表情符号与图像和文本
- en: 'Before diving any deeper, I want to emphasize one crucial element of emojis
    that makes them so special, and deserving of their own semantic search engine:
    in a sense, they are *both* images and text. From the human perspective, we can
    represent each emoji as a unicode character, on the same playing field as text
    characters, and we can represent it as a standalone image, both of which we saw
    in the previous section. Said another way, if we squint with one eye, we can see
    a pictogram as a picture, and if we squint with the other eye, we can see the
    same pictogram as text.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨之前，我想强调表情符号的一个关键元素，它使得表情符号如此特别，并且值得拥有自己的语义搜索引擎：从某种意义上说，它们*既*是图像也是文本。从人类的角度来看，我们可以将每个表情符号表示为一个
    Unicode 字符，与文本字符处于同一层面，同时也可以将其表示为一个独立的图像，这两者在前一节中都已经看到。换句话说，如果我们用一只眼睛眯起，我们可以把象形符号看作是一张图片，而如果我们用另一只眼睛眯起，我们可以将同一个象形符号看作是文本。
- en: Computers, however, are not known for their ability to squint. While a computer
    may be able to display a unicode code-point as an emoji, a machine learning model
    may not have a good way of interpreting the emoji as text or images.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，计算机并不以其眯眼能力而闻名。尽管计算机可以将一个 Unicode 码点显示为表情符号，但机器学习模型可能没有很好的方法将该表情符号解释为文本或图像。
- en: Whenever I’m working on semantic search applications that connect images and
    text, I start with a family of models known as [contrastive language image pre-training](https://github.com/openai/CLIP)
    (CLIP). These models are trained on image-text pairs to generate similar vector
    representations or [*embeddings*](/neural-network-embeddings-explained-4d028e6f0526)
    for images and their captions, and dissimilar vectors when images are paired with
    other text strings. There are multiple CLIP-style models, including [OpenCLIP](https://github.com/mlfoundations/open_clip)
    and [MetaCLIP](https://github.com/facebookresearch/metaclip), but for simplicity
    we’ll focus on the original CLIP model from OpenAI. No model is perfect, and at
    a fundamental level there is no *right* way to compare images and text, but CLIP
    certainly provides a good starting point.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我在进行连接图像和文本的语义搜索应用时，我都会从一个被称为 [对比语言图像预训练](https://github.com/openai/CLIP)（CLIP）的一组模型开始。这些模型通过对图像-文本对进行训练，生成图像及其标题的相似向量表示或
    [*嵌入*](/neural-network-embeddings-explained-4d028e6f0526)，当图像与其他文本字符串配对时，生成不相似的向量。有多种
    CLIP 风格的模型，包括 [OpenCLIP](https://github.com/mlfoundations/open_clip) 和 [MetaCLIP](https://github.com/facebookresearch/metaclip)，但为了简便起见，我们将重点关注
    OpenAI 的原始 CLIP 模型。没有任何模型是完美的，在根本层面上，也没有*正确*的方式来比较图像和文本，但 CLIP 无疑提供了一个很好的起点。
- en: Interpreting Emojis as Text
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将表情符号解释为文本
- en: At a high level, language models process input text by converting it into an
    ordered sequence of *tokens*, and then *encoding* the tokens and positional information
    in a dense numerical vector. Each language model has its own *vocabulary* of tokens
    to decompose a text string into, spanning from individual letters to complete
    words. Some tokens are easily interpretable by a human, while others are not,
    and in the case of CLIP, the vocabulary has 49,408 entries.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，语言模型通过将输入文本转换为一个有序的*标记*序列，然后*编码*这些标记和位置信息为一个密集的数值向量。每个语言模型都有自己的*词汇表*，用于将文本字符串分解为标记，涵盖了从单个字母到完整单词的范围。一些标记对于人类来说很容易理解，而另一些则不容易理解，在
    CLIP 的情况下，词汇表包含了 49,408 个条目。
- en: 'Let’s see an explicit example. Assuming the CLIP library is installed, we can
    *tokenize* a text string “a dog” with:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个明确的例子。假设已安装 CLIP 库，我们可以使用以下方式对文本字符串“a dog”进行*分词*处理：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output tensor contains four nonzero entries: 49406, 320, 1929, and 49407\.
    To make sense of these, we can map these values back to keys in the [CLIP vocabulary
    dictionary](https://huggingface.co/openai/clip-vit-base-patch32/resolve/main/vocab.json).
    The first number, 49406, corresponds to the key “<|startoftext|>”, and the last
    number, 49407 corresponds to the key “<|endoftext|>”. These are special tokens
    denoting the beginning and end of the text string to be encoded. The second number,
    320, maps back to “a</w>”, which signifies the character “a” followed by a new
    word. Finally, 1929 is the value for key “dog</w>”.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 输出张量包含四个非零条目：49406、320、1929 和 49407。为了理解这些条目的含义，我们可以将这些值映射回 [CLIP 词汇字典](https://huggingface.co/openai/clip-vit-base-patch32/resolve/main/vocab.json)中的键。第一个数字
    49406 对应于键“<|startoftext|>”，最后一个数字 49407 对应于键“<|endoftext|>”。这些是表示要编码的文本字符串开始和结束的特殊标记。第二个数字
    320 映射回“a</w>”，表示字符“a”后跟一个新单词。最后，1929 是键“dog</w>”的值。
- en: 'If we try to tokenize a string containing an emoji, however, we quickly run
    into a hitch: emojis don’t get tokenized in the same way as other characters do.
    Let’s start with the dog emoji 🐶:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们尝试标记化包含表情符号的字符串，我们会很快遇到问题：表情符号不像其他字符那样被标记化。让我们从狗表情符号🐶开始：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Doing a reverse lookup for the key associated with 10,631, we get the token
    “ðŁĲ¶</w>”. But if we pass this string into the tokenizer, we get a completely
    different set of token IDs:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对与10,631相关的键进行反向查找时，我们得到标记“ðŁĲ¶</w>”。但是如果我们将这个字符串传入分词器，我们会得到一组完全不同的标记ID：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'An even more curious case concerns the flag emojis. If we take the emoji for
    the flag of Cameroon, for instance, we get:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更为有趣的案例是关于国旗表情符号的。如果我们以喀麦隆国旗的表情符号为例，我们得到：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The two non-start/end tokens here correspond to “ðŁĩ¨ðŁĩ” and “²</w>”. If we
    plug the first of these back into the tokenizer, we get another completely different
    set of token IDs, but the second maps back to itself.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的两个非开始/结束标记对应于“ðŁĩ¨ðŁĩ”和“²</w>”。如果我们将第一个标记重新输入分词器，我们会得到一组完全不同的标记ID，但第二个标记会映射回其自身。
- en: Things get even more precarious when we start comparing embeddings of text strings
    with embeddings of emojis, parsed as text strings via this tokenizer. After all,
    we want to find the most relevant emojis given a *text query*. We can use the
    [cosine distance](https://medium.com/@milana.shxanukova15/cosine-distance-and-cosine-similarity-a5da0e4d9ded)
    as a way to measure how similar or different two vectors are — and by proxy the
    inputs that generated those embedding vectors are. A distance of 0 means that
    two vectors are completely aligned, and a distance of 1 implies that two vectors
    are orthogonal. If we wanted to treat emojis as text, we would want the name for
    an emoji to be relatively close to the tokenized emoji in the embedding space,
    but this is not always the case!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始比较文本字符串的嵌入与通过这个分词器解析为文本字符串的表情符号嵌入时，情况变得更加复杂。毕竟，我们希望根据*文本查询*找到最相关的表情符号。我们可以使用[余弦距离](https://medium.com/@milana.shxanukova15/cosine-distance-and-cosine-similarity-a5da0e4d9ded)来衡量两个向量的相似性或差异性——间接地，衡量生成这些嵌入向量的输入之间的差异。0的距离意味着两个向量完全对齐，而1的距离则意味着两个向量正交。如果我们想把表情符号当作文本处理，我们希望表情符号的名称与嵌入空间中的标记化表情符号相对接近，但这并不总是如此！
- en: 'The utility below will compare an emoji and a list of text prompts:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下工具将比较一个表情符号和一系列文本提示：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here’s an example, where according to CLIP, the encoding for the “birthday”
    emoji 🎂is closer to “man” than “birthday”, closer to “dog” than “birthday present”,
    and closer to “car” than “candle”, “date”, or “holiday”:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例，根据CLIP的结果，"生日"表情符号🎂的编码更接近“男人”而非“生日”，更接近“狗”而非“生日礼物”，更接近“车”而非“蜡烛”、“约会”或“假期”：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Sometimes, the emoji and its name (and similar concepts) are close together
    in the embedding space, but sometimes they are most certainly not.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，表情符号及其名称（以及类似的概念）在嵌入空间中彼此接近，但有时它们显然并非如此。
- en: 'We can also go the other way and retrieve the emojis whose embeddings most
    closely match the embedding of an input text prompt. For instance, for the input
    “love”, we get the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以反过来，检索出与输入文本提示的嵌入最匹配的表情符号。例如，对于输入“爱”，我们得到以下结果：
- en: '![](../Images/9df5407cefbb3a9eb346f00af77ca861.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9df5407cefbb3a9eb346f00af77ca861.png)'
- en: Of course, we can do way better than this!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可以做得比这更好！
- en: Interpreting Emojis as Images
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将表情符号解释为图像
- en: 'The high-resolution images of emojis that we generated using Real-ESRGAN provide
    an alternative pathway to searching through our emojis: treating emojis as *images*.
    We can use CLIP’s vision encoder to embed the images into the same vector space,
    and then query these image embeddings with our input text prompt.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Real-ESRGAN生成的高分辨率表情符号图像提供了一条替代的表情符号搜索路径：将表情符号视为*图像*。我们可以使用CLIP的视觉编码器将这些图像嵌入到相同的向量空间中，然后通过输入文本提示查询这些图像嵌入。
- en: For applications like cross-modal retrieval (or semantically searching images
    with text), CLIP typically works best when the image embeddings are compared to
    a text prompt that is the user’s query wrapped in the phrase “A photo of <query>”.
    As an example, the image embedding for a photo of a dog will be closer (in terms
    of the angle between the vectors) to the embedding of “A photo of a dog” than
    the embedding of the raw query “dog”.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于跨模态检索（或通过文本搜索图像）等应用，CLIP通常在将图像嵌入与包含用户查询的文本提示“一个关于<query>的照片”进行比较时表现最佳。例如，一张狗的照片的图像嵌入与“一个关于狗的照片”的嵌入之间的距离会比与原始查询“狗”的嵌入之间的距离更近（从向量之间的角度来看）。
- en: 'However, when I used this template, the results were underwhelming. For instance,
    here are the 25 top results for the query “A photo of a dog”:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我使用这个模板时，结果并不理想。例如，以下是查询“狗的照片”时的前25个结果：
- en: '![](../Images/d281ba379d7de5eb874e930f9e631113.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d281ba379d7de5eb874e930f9e631113.png)'
- en: 'Because emojis aren’t exactly *photos*, I decided to dig a little deeper into
    this and try out a few templating, or wrapping strategies. To cover my bases,
    I test five formats for text prompts:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因为表情符号并不完全是*照片*，所以我决定深入挖掘这一点，并尝试几种模板或包装策略。为了全面测试，我测试了五种文本提示格式：
- en: <emoji_name>
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <emoji_name>
- en: A photo of a <emoji_name>
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一张<emoji_name>表情符号的照片
- en: An emoji of <emoji_name>
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个<emoji_name>的表情符号
- en: A photo of a <emoji_name> emoji
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一张<emoji_name>表情符号的照片
- en: A <emoji_name> emoji
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个<emoji_name>表情符号
- en: I generated embeddings for all 1816 emojis with each of these methods, and computed
    the CLIPScore (cosine similarity multiplied by 100) of these vectors with the
    corresponding image embedding vectors.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我用这些方法为所有1816个表情符号生成了嵌入，并计算了这些向量与相应图像嵌入向量的CLIPScore（余弦相似度乘以100）。
- en: 'Here were the aggregate results:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是综合结果：
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: From these statistics, I thought that the “An emoji of” descriptors were the
    best fit of the bunch, as they had the highest mean and max. But when I tried
    to use this, the results were again less than ideal. They seemed to preference
    faces (e.g. 😄😢🙃👦👧), to the detriment of other emojis like symbols, animals, and
    flags. When it came to semantic emoji searches, I found that entering the raw
    text tended to work best. In other words, the CLIP embedding of “dog” worked better
    than “A photo of a dog”, or “An emoji of a dog”.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些统计数据，我认为“An emoji of”描述最适合，因为它们具有最高的均值和最大值。但当我尝试使用这个时，结果依然不理想。它们似乎偏好面部表情（例如😄😢🙃👦👧），忽视了其他表情符号，如符号、动物和旗帜。在语义表情符号搜索时，我发现直接输入原始文本通常效果最好。换句话说，“dog”这个词的CLIP嵌入效果比“A
    photo of a dog”或“An emoji of a dog”要好。
- en: 'There were a few takeaways from this:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几点收获：
- en: Overall image-text “alignment” isn’t necessarily important for semantic search
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像-文本的“对齐”整体上对语义搜索不一定重要
- en: The images of the emojis encode (to some degree) the fact that they are not
    photos
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表情符号的图像在某种程度上编码了它们不是照片的事实
- en: The word “emoji” biases CLIP toward faces
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “emoji”这个词使CLIP偏向面部
- en: Bridging the Modality Gap
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弥合模态差距
- en: By this point, I had come to the conclusion that treating emojis as just images
    or just text leaves a lot of rich information on the table. To build a robust
    semantic emoji search engine, I wanted to incorporate both textual and image information,
    and bridge the gap between these two modalities.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我已经得出结论，将表情符号仅视为图像或仅视为文本会遗漏很多丰富的信息。为了构建一个强大的语义表情符号搜索引擎，我希望结合文本和图像信息，弥合这两种模态之间的差距。
- en: I tried generating descriptions of the emoji images using Adept’s multimodal
    [Fuyu-8b](https://www.adept.ai/blog/fuyu-8b) model, but these descriptions proved
    far too detailed; I tried using other CLIP-style models like [MetaCLIP](https://github.com/facebookresearch/metaclip),
    but saw the same behavior as in CLIP; I even tried using [GPT-4V](https://openai.com/research/gpt-4v-system-card)
    to generate captions for the emoji images, but was cut off by OpenAI because the
    rate limit for the model is 100 queries per day.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我尝试使用Adept的多模态模型[Fuyu-8b](https://www.adept.ai/blog/fuyu-8b)生成表情符号图像的描述，但这些描述过于详细；我尝试使用其他类似CLIP的模型，如[MetaCLIP](https://github.com/facebookresearch/metaclip)，但表现与CLIP相同；我甚至尝试使用[GPT-4V](https://openai.com/research/gpt-4v-system-card)生成表情符号图像的标题，但由于模型的查询频率限制为每天100次，我被OpenAI中断了。
- en: 'In the end, I was able to pass the emoji unicode characters into the base GPT-4
    API with the prompt:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我能够将表情符号的Unicode字符传递到基础的GPT-4 API中，提示为：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: After post-processing these captions, I removed the “A photo of” prefix and
    used these descriptions in the semantic search pipeline.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在对这些标题进行后处理后，我删除了“A photo of”前缀，并将这些描述用于语义搜索管道中。
- en: 'The emoji search engine works as follows, taking in an input *query*:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 表情符号搜索引擎的工作原理如下，输入*query*：
- en: Generate a set of 100 candidate emojis (out of 1816) with an image similarity
    search that compares the image embeddings to the query embedding. Save this ordering,
    *clip_image_ordering.*
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成100个候选表情符号（从1816个中选择），使用图像相似度搜索将图像嵌入与查询嵌入进行比较。保存此排序，*clip_image_ordering*。
- en: Order these candidate emojis by the similarity of the CLIP embeddings of the
    emoji names to the query’s embedding (*clip_name_ordering*).
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照表情符号名称的CLIP嵌入与查询嵌入的相似度对这些候选表情符号进行排序（*clip_name_ordering*）。
- en: Using a [cross-encoder](https://ai.plainenglish.io/decoding-sentence-representations-a-comprehensive-guide-to-cross-encoders-and-bi-encoders-67c4ac16e35f),
    order the emojis based on the similarity of their name (*cross_encoder_name_ordering*)
    and their description generated by GPT-4 (*cross_encoder_description_ordering*)
    to the query.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 [cross-encoder](https://ai.plainenglish.io/decoding-sentence-representations-a-comprehensive-guide-to-cross-encoders-and-bi-encoders-67c4ac16e35f)，根据表情符号名称的相似性（*cross_encoder_name_ordering*）和由
    GPT-4 生成的描述（*cross_encoder_description_ordering*）对表情符号进行排序。
- en: Combine all four orderings using [reciprocal rank fusion](https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html),
    and return the top results!
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 [互惠排名融合](https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html)
    将四种排序结合起来，并返回排名靠前的结果！
- en: The resulting search engine isn’t perfect, but it does a decent job at incorporating
    textual and visual information. Because using a cross-encoder is more computationally
    expensive (and higher latency), this is reserved for the pared-down set of candidates.
    I use the `distilroberta-base` checkpoint with the `CrossEncoder` class from the
    [Sentence Transformers](https://www.sbert.net/index.html) library.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 结果搜索引擎虽然不完美，但在结合文本和视觉信息方面做得不错。由于使用 cross-encoder 计算开销较大（且延迟较高），因此它仅用于简化后的候选集。我使用的是
    `distilroberta-base` 检查点，并配合 [Sentence Transformers](https://www.sbert.net/index.html)
    库中的 `CrossEncoder` 类。
- en: 'When all of these steps are combined, this is the result:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有这些步骤结合在一起时，结果如下：
- en: '![](../Images/2ddaf850b6a4265b791b6faf02d0df4f.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ddaf850b6a4265b791b6faf02d0df4f.png)'
- en: Again, it isn’t perfect. But it’s not bad!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，它不是完美的，但它还不错！
- en: Using the Emoji Search Engine
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用表情符号搜索引擎
- en: 'There are three ways to use this emoji search engine: hosted (free), locally
    via UI (open source), or locally via command line (also open source). All three
    options are quite easy!'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种方式可以使用这个表情符号搜索引擎：托管版（免费）、通过用户界面在本地使用（开源）或者通过命令行在本地使用（同样是开源的）。这三种方式都非常简单！
- en: Online
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线版
- en: Head over to [try.fiftyone.ai/datasets/emojis](https://try.fiftyone.ai/datasets/emojis/samples),
    sign in (it’s free), and click on the emoji button in the menu above the grid
    of images. That’s it!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 [try.fiftyone.ai/datasets/emojis](https://try.fiftyone.ai/datasets/emojis/samples)，登录（免费），然后点击网格上方菜单中的表情符号按钮。就是这样！
- en: Locally via the UI
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过用户界面本地使用
- en: If you want to perform emoji searches locally with the same visual interface,
    you can do so with the [Emoji Search plugin](https://github.com/jacobmarks/emoji-search-plugin)
    for [FiftyOne](https://github.com/voxel51/fiftyone).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在本地使用相同的视觉界面进行表情符号搜索，可以使用 [Emoji Search 插件](https://github.com/jacobmarks/emoji-search-plugin)
    进行 [FiftyOne](https://github.com/voxel51/fiftyone) 搜索。
- en: 'First, install FiftyOne:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，安装 FiftyOne：
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then download the Emoji Search plugin and install its requirements:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然后下载 Emoji Search 插件并安装其依赖：
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Launch the FiftyOne App:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 启动 FiftyOne 应用：
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Click on the “browse operations” text, search for “emoji”, and click on the
    entry “Create Emoji Dataset”. This will download the high-resolution images of
    the emojis, along with embeddings and all other relevant data. At the top left
    of the app, click in the “Select dataset” box and select “Emojis”. Now you should
    see the same UI as in the hosted version.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“浏览操作”文本，搜索“emoji”，然后点击“创建 Emoji 数据集”条目。这将下载表情符号的高清图像、嵌入以及所有相关数据。在应用的左上角，点击“选择数据集”框，选择“Emojis”。现在，你应该看到与托管版本相同的用户界面。
- en: Locally via the CLI
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 CLI 本地使用
- en: 'Finally, you can search via the command line using the [Emoji Search](https://github.com/jacobmarks/emoji_search)
    Python CLI library. Install the package from GitHub repository with:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以通过命令行使用 [Emoji Search](https://github.com/jacobmarks/emoji_search) Python
    CLI 库进行搜索。可以通过以下命令从 GitHub 仓库安装该软件包：
- en: '[PRE15]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Then you can start searching using the `emoji-search` command, followed by the
    text query (with or without quotation marks).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以使用 `emoji-search` 命令进行搜索，后面跟上文本查询（带不带引号均可）。
- en: '[PRE16]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first search you perform will download embeddings to your device if necessary.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次执行搜索时，如果需要，会将嵌入下载到你的设备上。
- en: All three versions support copying an emoji to clipboard with [pyperclip](https://pypi.org/project/pyperclip/).
    In the UI, click on the image for an emoji, and you’ll see a copy button appear
    in the menu. In the CLI, pass the `-c` argument to copy the top result to clipboard.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 所有三个版本都支持通过 [pyperclip](https://pypi.org/project/pyperclip/) 复制表情符号到剪贴板。在用户界面中，点击表情符号的图像，你会看到菜单中出现一个复制按钮。在命令行界面中，使用
    `-c` 参数将顶部结果复制到剪贴板。
- en: Conclusion
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'Emojis might seem like a silly subject to obsess over. And in practice, the
    utility of a semantic emoji search engine over lexical emoji search may be somewhat
    limited. The real value in this endeavor is in understanding the boundaries and
    overlaps between two modalities we traditionally think of as distinct: images
    and text. Emojis sit squarely in this intersection and as such, they allow us
    to probe the strengths and weaknesses — the capabilities and limitations of today’s
    multimodal models.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 表情符号可能看起来是一个无聊的主题，让人感到过度关注。但实际上，语义表情符号搜索引擎相比于词汇表情符号搜索，其实用性可能有限。这个工作的真正价值在于理解我们传统上认为是独立的两种模式——图像和文本——之间的边界和重叠。表情符号恰好位于这个交汇点，因此，它们让我们能够探究今天多模态模型的优缺点——它们的能力与局限。
- en: 'The Semantic Emoji Search Engine I ended up building is far from perfect. Frankly,
    emojis have subjectivity, connoting different things for different people, that
    is impossible to precisely bottle up. But going back to the motivating example,
    when I type in “an audio player”, I get some solid results:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我最终构建的语义表情符号搜索引擎远非完美。坦率来说，表情符号具有主观性，代表不同的人可能有不同的含义，这一点是无法精确地封装的。但回到激发这个想法的例子，当我输入“一个音频播放器”时，我得到了几个不错的结果：
- en: '![](../Images/1861d91728d8781810ec0c2072406e80.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1861d91728d8781810ec0c2072406e80.png)'
- en: 'I’ll end with a quote from [Nancy Gibbs](https://en.wikipedia.org/wiki/Nancy_Gibbs),
    a Professor at the Harvard Kennedy School and former managing editor for *TIME*
    magazine:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我将以哈佛大学甘尼迪学院教授、前《时代》杂志执行编辑[南希·吉布斯](https://en.wikipedia.org/wiki/Nancy_Gibbs)的一句话作为结尾：
- en: '*What makes emojis special is the fact that [they have] helped millions express
    themselves better than even the wide array of words in the Oxford dictionary [could].*'
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*表情符号之所以特别，是因为[它们]帮助了数百万人比牛津词典中广泛的词汇还要更好地表达自己。*'
- en: ''
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Nancy Gibbs
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 南希·吉布斯
- en: '*Note: All images in article created by the author unless otherwise noted*'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：文章中的所有图像由作者创作，除非另有说明*'
