- en: 3 Essential Questions to Address When Building an API-Involved Incremental Data
    Loading Script
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„å»ºæ¶‰åŠ API çš„å¢é‡æ•°æ®åŠ è½½è„šæœ¬æ—¶éœ€è¦è§£å†³çš„ 3 ä¸ªå…³é”®é—®é¢˜
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/3-essential-questions-to-address-when-building-an-api-involved-incremental-data-loading-script-03723cad3411?source=collection_archive---------3-----------------------#2024-06-30](https://towardsdatascience.com/3-essential-questions-to-address-when-building-an-api-involved-incremental-data-loading-script-03723cad3411?source=collection_archive---------3-----------------------#2024-06-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/3-essential-questions-to-address-when-building-an-api-involved-incremental-data-loading-script-03723cad3411?source=collection_archive---------3-----------------------#2024-06-30](https://towardsdatascience.com/3-essential-questions-to-address-when-building-an-api-involved-incremental-data-loading-script-03723cad3411?source=collection_archive---------3-----------------------#2024-06-30)
- en: '[](https://medium.com/@khoadaniel?source=post_page---byline--03723cad3411--------------------------------)[![Daniel
    Khoa Le](../Images/5c01c760dc1e92b3048cfae005838ef1.png)](https://medium.com/@khoadaniel?source=post_page---byline--03723cad3411--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--03723cad3411--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--03723cad3411--------------------------------)
    [Daniel Khoa Le](https://medium.com/@khoadaniel?source=post_page---byline--03723cad3411--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@khoadaniel?source=post_page---byline--03723cad3411--------------------------------)[![Daniel
    Khoa Le](../Images/5c01c760dc1e92b3048cfae005838ef1.png)](https://medium.com/@khoadaniel?source=post_page---byline--03723cad3411--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--03723cad3411--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--03723cad3411--------------------------------)
    [Daniel Khoa Le](https://medium.com/@khoadaniel?source=post_page---byline--03723cad3411--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--03723cad3411--------------------------------)
    Â·8 min readÂ·Jun 30, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--03723cad3411--------------------------------)
    Â·é˜…è¯»æ—¶é•¿ 8 åˆ†é’ŸÂ·2024å¹´6æœˆ30æ—¥
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '**TLDR**'
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ç®€çŸ­è¯´æ˜**'
- en: This article explains both the conceptual framework and practical code implementation
    for syncing data from API endpoints to your database using dlt (a Python library).
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æœ¬æ–‡è§£é‡Šäº†ä½¿ç”¨ dltï¼ˆä¸€ä¸ª Python åº“ï¼‰ä» API ç«¯ç‚¹åˆ°æ•°æ®åº“åŒæ­¥æ•°æ®çš„æ¦‚å¿µæ¡†æ¶å’Œå®é™…ä»£ç å®ç°ã€‚
- en: At the end of this tutorial, you will understand (and know how to implement)
    the sync behavior in the following illustration where we extract data **incrementally**
    and write to the destination table with the merge (dedup) strategy.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ç»“æŸæ—¶ï¼Œä½ å°†ç†è§£ï¼ˆå¹¶çŸ¥é“å¦‚ä½•å®ç°ï¼‰ä»¥ä¸‹ç¤ºæ„å›¾ä¸­çš„åŒæ­¥è¡Œä¸ºï¼Œåœ¨æ­¤ç¤ºæ„å›¾ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¢é‡æ–¹å¼æå–æ•°æ®ï¼Œå¹¶ä½¿ç”¨åˆå¹¶ï¼ˆå»é‡ï¼‰ç­–ç•¥å°†æ•°æ®å†™å…¥ç›®æ ‡è¡¨ã€‚
- en: '![](../Images/e80987236bba43864b69abbfaef3cadd.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e80987236bba43864b69abbfaef3cadd.png)'
- en: Image by Author
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…å›¾ç‰‡
- en: The context
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: èƒŒæ™¯
- en: You want to sync data from an application (e.g., ads performance, sales figures,
    etc.) to your database.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ å¸Œæœ›å°†æ•°æ®ä»ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼ˆä¾‹å¦‚ï¼Œå¹¿å‘Šæ•ˆæœã€é”€å”®æ•°æ®ç­‰ï¼‰åŒæ­¥åˆ°ä½ çš„æ•°æ®åº“ã€‚
- en: Your application provides API endpoints to retrieve its data.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ çš„åº”ç”¨ç¨‹åºæä¾› API ç«¯ç‚¹æ¥æ£€ç´¢å…¶æ•°æ®ã€‚
- en: The data needs to be synced daily to your database.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•°æ®éœ€è¦æ¯å¤©åŒæ­¥åˆ°ä½ çš„æ•°æ®åº“ã€‚
- en: You want to load only the â—***â€œnewâ€ data (or the changes)***â— into your database.
    You do not want to load the entire set of data all over again every time you sync.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ å¸Œæœ›ä»…å°† â—***â€œæ–°â€æ•°æ®ï¼ˆæˆ–æ›´æ”¹éƒ¨åˆ†ï¼‰***â— åŠ è½½åˆ°æ•°æ®åº“ä¸­ã€‚ä½ ä¸å¸Œæœ›æ¯æ¬¡åŒæ­¥æ—¶éƒ½é‡æ–°åŠ è½½æ•´ä¸ªæ•°æ®é›†ã€‚
- en: How would you do it in Python?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¦‚ä½•åœ¨ Python ä¸­å®ç°è¿™ä¸€ç‚¹ï¼Ÿ
- en: I will walk you through the solution by addressing the following 3 questions.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘å°†é€šè¿‡å›ç­”ä»¥ä¸‹ä¸‰ä¸ªé—®é¢˜ï¼Œå¸¦ä½ äº†è§£è§£å†³æ–¹æ¡ˆã€‚
- en: 'ğŸ’¥ Question 1: What do I need from an API to sync data incrementally?'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¥ é—®é¢˜ 1ï¼šæˆ‘éœ€è¦ä» API è·å–å“ªäº›ä¿¡æ¯ä»¥è¿›è¡Œå¢é‡æ•°æ®åŒæ­¥ï¼Ÿ
- en: Before developing an incremental loading script, we need to understand the behavior
    of the API endpoints we are working with.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å‘å¢é‡åŠ è½½è„šæœ¬ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨çš„ API ç«¯ç‚¹çš„è¡Œä¸ºã€‚
- en: â—Not all APIs can facilitate incremental loading.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: â—å¹¶ä¸æ˜¯æ‰€æœ‰çš„ API éƒ½æ”¯æŒå¢é‡åŠ è½½ã€‚
- en: 'ğŸ‘‰ Answer: Query params that support incremental loading'
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ‘‰ ç­”æ¡ˆï¼šæ”¯æŒå¢é‡åŠ è½½çš„æŸ¥è¯¢å‚æ•°
- en: Letâ€™s look at an example of an application (or â€œsourceâ€ application) that tracks
    your sales performance. In this application, each record represents a product
    along with its sales volume. The fields `created_at` and `updated_at` indicate
    when the record was created and updated.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªåº”ç”¨ç¨‹åºçš„ç¤ºä¾‹ï¼ˆæˆ–ç§°ä¸ºâ€œæºâ€åº”ç”¨ç¨‹åºï¼‰ï¼Œå®ƒè·Ÿè¸ªä½ çš„é”€å”®ä¸šç»©ã€‚åœ¨è¿™ä¸ªåº”ç”¨ç¨‹åºä¸­ï¼Œæ¯æ¡è®°å½•ä»£è¡¨ä¸€ä¸ªäº§å“åŠå…¶é”€å”®é‡ã€‚å­—æ®µ `created_at`
    å’Œ `updated_at` è¡¨ç¤ºè®°å½•çš„åˆ›å»ºå’Œæ›´æ–°æ—¶é—´ã€‚
- en: 'Changes in the sales data typically occur in two main ways:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: é”€å”®æ•°æ®çš„å˜åŒ–é€šå¸¸æœ‰ä¸¤ç§ä¸»è¦æ–¹å¼ï¼š
- en: New products are added to the list.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ–°äº§å“å·²è¢«æ·»åŠ åˆ°åˆ—è¡¨ä¸­ã€‚
- en: Updates are made to the sales figures of existing records, **which results in
    a new value for** `**updated_at**`. This helps us to track the new changes; without
    it, we cannot know which records have been modified.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ›´æ–°ä¼šåº”ç”¨åˆ°ç°æœ‰è®°å½•çš„é”€å”®æ•°æ®ï¼Œ**è¿™ä¼šå¯¼è‡´** `**updated_at**` çš„æ–°å€¼ã€‚è¿™æ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¿½è¸ªæ–°çš„å˜åŒ–ï¼›å¦‚æœæ²¡æœ‰å®ƒï¼Œæˆ‘ä»¬å°±æ— æ³•çŸ¥é“å“ªäº›è®°å½•å·²è¢«ä¿®æ”¹ã€‚
- en: ğŸ‘ï¸ğŸ‘ï¸ Below is the example sales table in the source applicationâ€™s database.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘ï¸ğŸ‘ï¸ ä¸‹é¢æ˜¯æºåº”ç”¨æ•°æ®åº“ä¸­çš„ç¤ºä¾‹é”€å”®è¡¨ã€‚
- en: 'â†ªï¸ **Yesterday''s data: 2 records**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: â†ªï¸ **æ˜¨å¤©çš„æ•°æ®ï¼š2æ¡è®°å½•**
- en: '![](../Images/fcf8c37fb8ec51718382ef2cb9d09a8b.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fcf8c37fb8ec51718382ef2cb9d09a8b.png)'
- en: Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'â†ªï¸ **Today''s data: a new record added and a change made to an existing record**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: â†ªï¸ **ä»Šå¤©çš„æ•°æ®ï¼šæ–°å¢äº†ä¸€æ¡è®°å½•ï¼Œå¹¶ä¸”ä¿®æ”¹äº†ç°æœ‰è®°å½•**
- en: '![](../Images/a7b45d06827f32925d53d8bf2cf1043d.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7b45d06827f32925d53d8bf2cf1043d.png)'
- en: Image by Author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: ğŸŸ¢ **Takeaways:** If the API endpoint allows queries based on the`updated_at`
    parameter, you can implement incremental loading by making requests to retrieve
    only records that have an `updated_at` value later than the most recent `updated_at`
    value saved from the previous sync. In this context, `updated_at` is referred
    to as the incremental cursor, and its value, which persists through to the next
    sync, is known as the state.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŸ¢ **è¦ç‚¹ï¼š** å¦‚æœAPIç«¯ç‚¹å…è®¸åŸºäº `updated_at` å‚æ•°è¿›è¡ŒæŸ¥è¯¢ï¼Œä½ å¯ä»¥é€šè¿‡å‘èµ·è¯·æ±‚æ¥åªæ£€ç´¢é‚£äº› `updated_at` å€¼æ™šäºä¸Šæ¬¡åŒæ­¥ä¿å­˜çš„
    `updated_at` çš„è®°å½•ï¼Œä»è€Œå®ç°å¢é‡åŠ è½½ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`updated_at` è¢«ç§°ä¸ºå¢é‡æ¸¸æ ‡ï¼Œå…¶å€¼ä¼šæŒç»­åˆ°ä¸‹æ¬¡åŒæ­¥ï¼Œè¿™ä¸ªå€¼ç§°ä¸ºçŠ¶æ€ã€‚
- en: The `updated_at` field is a common choice for an incremental cursor. Other query
    params, such as **id** or **sales,** cannot help us to request data incrementally
    as they cannot tell us which records have been added or updated since the last
    sync.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`updated_at` å­—æ®µæ˜¯å¢é‡æ¸¸æ ‡çš„å¸¸è§é€‰æ‹©ã€‚å…¶ä»–æŸ¥è¯¢å‚æ•°ï¼Œå¦‚ **id** æˆ– **sales**ï¼Œæ— æ³•å¸®åŠ©æˆ‘ä»¬å¢é‡è¯·æ±‚æ•°æ®ï¼Œå› ä¸ºå®ƒä»¬æ— æ³•å‘Šè¯‰æˆ‘ä»¬è‡ªä¸Šæ¬¡åŒæ­¥ä»¥æ¥ï¼Œå“ªäº›è®°å½•å·²è¢«æ·»åŠ æˆ–æ›´æ–°ã€‚'
- en: '**Which query param do you need to load data incrementally?**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½ éœ€è¦å“ªä¸ªæŸ¥è¯¢å‚æ•°æ¥å¢é‡åŠ è½½æ•°æ®ï¼Ÿ**'
- en: '![](../Images/7301b30bfbf0c3f33879ec2791bd4802.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7301b30bfbf0c3f33879ec2791bd4802.png)'
- en: Image by Author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'Since weâ€™re developing a data loading script that works with API, Iâ€™ll introduce
    two other important aspects of APIs for the code implementation: **pagination
    and path parameters**. They have nothing to do with incremental loading though.'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ­£åœ¨å¼€å‘ä¸€ä¸ªä¸APIé…åˆä½¿ç”¨çš„æ•°æ®åŠ è½½è„šæœ¬ï¼Œæˆ‘å°†ä»‹ç»ä¸¤ä¸ªAPIçš„å…¶ä»–é‡è¦æ–¹é¢ï¼Œä»¥ä¾¿ä»£ç å®ç°ï¼š**åˆ†é¡µå’Œè·¯å¾„å‚æ•°**ã€‚ä¸è¿‡ï¼Œå®ƒä»¬ä¸å¢é‡åŠ è½½æ— å…³ã€‚
- en: ğŸ¤· Pagination mechanism
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ¤· åˆ†é¡µæœºåˆ¶
- en: APIs often return results in small chunks to enhance performance. For instance,
    instead of returning 10,000 records at once, an API might limit the response to
    a maximum of 100 records per request, requiring you to iterate through subsequent
    batches.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: APIé€šå¸¸ä¼šåˆ†æ‰¹è¿”å›ç»“æœï¼Œä»¥æé«˜æ€§èƒ½ã€‚ä¾‹å¦‚ï¼ŒAPIå¯èƒ½ä¸ä¼šä¸€æ¬¡æ€§è¿”å›10,000æ¡è®°å½•ï¼Œè€Œæ˜¯å°†å“åº”é™åˆ¶ä¸ºæ¯æ¬¡æœ€å¤š100æ¡è®°å½•ï¼Œè¦æ±‚ä½ è¿­ä»£å¤„ç†åç»­æ‰¹æ¬¡ã€‚
- en: 'To manage this, you typically (not always) need to use two query parameters:
    `limit` and `skip` (or offset).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®¡ç†è¿™ä¸ªï¼Œä½ é€šå¸¸ï¼ˆä½†å¹¶éæ€»æ˜¯ï¼‰éœ€è¦ä½¿ç”¨ä¸¤ä¸ªæŸ¥è¯¢å‚æ•°ï¼š`limit` å’Œ `skip`ï¼ˆæˆ– `offset`ï¼‰ã€‚
- en: 'Hereâ€™s a simple example to illustrate:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥è¯´æ˜ï¼š
- en: 'For the first request:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¬¬ä¸€ä¸ªè¯·æ±‚ï¼š
- en: '`limit`=100'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`limit`=100'
- en: '`skip`=0'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip`=0'
- en: 'For the second request, to skip the first 100 records weâ€™ve already synced:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¬¬äºŒä¸ªè¯·æ±‚ï¼Œè¦è·³è¿‡æˆ‘ä»¬å·²ç»åŒæ­¥çš„å‰100æ¡è®°å½•ï¼š
- en: '`limit`=100'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`limit`=100'
- en: '`skip`=100'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip`=100'
- en: This pattern continues, incrementing the `skip` value by the `limit` after each
    batch until all records are retrieved.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€æ¨¡å¼å°†æŒç»­è¿›è¡Œï¼Œæ¯æ‰¹æ¬¡åï¼Œ`skip` å€¼ä¼šæŒ‰ `limit` å¢åŠ ï¼Œç›´åˆ°æ‰€æœ‰è®°å½•éƒ½è¢«æ£€ç´¢ã€‚
- en: ğŸŸ¢ **Takeaways:** You need to understand how APIs return responses so that you
    wonâ€™t miss any records while extracting. There are many approaches an API can
    use to manage pagination, beyond the commonly used methods of skip and offset.
    But thatâ€™s a story for another day.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŸ¢ **è¦ç‚¹ï¼š** ä½ éœ€è¦ç†è§£APIå¦‚ä½•è¿”å›å“åº”ï¼Œä»¥å…åœ¨æå–æ•°æ®æ—¶æ¼æ‰ä»»ä½•è®°å½•ã€‚APIæœ‰å¾ˆå¤šç®¡ç†åˆ†é¡µçš„æ–¹æ³•ï¼Œè¶…å‡ºäº†å¸¸ç”¨çš„ `skip` å’Œ `offset`
    æ–¹æ³•ã€‚è¿™æ˜¯å¦ä¸€ä¸ªè¯é¢˜ï¼Œç•™å¾…ä»¥åå†è¯´ã€‚
- en: ğŸ¤· Path param
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ¤· è·¯å¾„å‚æ•°
- en: Path parameters are included directly in the URL of an API and are typically
    used to distinguish between different segments (partitions) of data. For example,
    they might specify different campaigns within your marketing account or different
    sub-accounts managed in the source application.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è·¯å¾„å‚æ•°ç›´æ¥åŒ…å«åœ¨APIçš„URLä¸­ï¼Œé€šå¸¸ç”¨äºåŒºåˆ†æ•°æ®çš„ä¸åŒéƒ¨åˆ†ï¼ˆåˆ†åŒºï¼‰ã€‚ä¾‹å¦‚ï¼Œå®ƒä»¬å¯èƒ½æŒ‡å®šä½ è¥é”€è´¦æˆ·ä¸­çš„ä¸åŒæ´»åŠ¨æˆ–æºåº”ç”¨ä¸­ç®¡ç†çš„ä¸åŒå­è´¦æˆ·ã€‚
- en: 'In the example below: the path params are `applicationId` and `campaignId`.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼šè·¯å¾„å‚æ•°æ˜¯ `applicationId` å’Œ `campaignId`ã€‚
- en: '`[https://yourbaseurl.myapp/v1/applications/{applicationId}/campaigns/{campaignId}/](https://yourbaseurl.talon.one/v1/applications/%7BapplicationId%7D/campaigns/%7BcampaignId%7D/coupons/no_total)sales`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`[https://yourbaseurl.myapp/v1/applications/{applicationId}/campaigns/{campaignId}/](https://yourbaseurl.talon.one/v1/applications/%7BapplicationId%7D/campaigns/%7BcampaignId%7D/coupons/no_total)sales`'
- en: ğŸŸ¢ **Takeaways:** You need to decide whether you will sync data from the same
    API but with different path params to a single table or different tables (sales_campaign_1,
    sales_campaign_2, etc.).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŸ¢ **æ€»ç»“ï¼š**ä½ éœ€è¦å†³å®šæ˜¯å°†æ¥è‡ªåŒä¸€APIä½†å…·æœ‰ä¸åŒè·¯å¾„å‚æ•°çš„æ•°æ®åŒæ­¥åˆ°åŒä¸€å¼ è¡¨ï¼Œè¿˜æ˜¯åŒæ­¥åˆ°ä¸åŒçš„è¡¨ï¼ˆå¦‚ sales_campaign_1, sales_campaign_2
    ç­‰ï¼‰ã€‚
- en: 'ğŸ’¥ Question 2: How do I want to write the extracted records to the destination
    table?'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¥ é—®é¢˜ 2ï¼šæˆ‘å¦‚ä½•å°†æå–çš„è®°å½•å†™å…¥ç›®æ ‡è¡¨ï¼Ÿ
- en: Now letâ€™s say you already extracted a bunch of records by making API requests
    with the above-mentioned params, itâ€™s time for you to decide how you want to write
    them to the destination table.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå‡è®¾ä½ å·²ç»é€šè¿‡ä¸Šè¿°å‚æ•°æå–äº†ä¸€æ‰¹è®°å½•ï¼Œæ˜¯æ—¶å€™å†³å®šå¦‚ä½•å°†è¿™äº›è®°å½•å†™å…¥ç›®æ ‡è¡¨äº†ã€‚
- en: 'ğŸ‘‰ Answer: Merge/Dedup mode (recommended)'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ‘‰ ç­”æ¡ˆï¼šåˆå¹¶/å»é‡æ¨¡å¼ï¼ˆæ¨èï¼‰
- en: This question concerns the choice of **Write disposition** or **Sync mode**.
    The immediate answer is that, given you are looking to load your data incrementally,
    you will likely opt to write your extracted data in either append mode or merge
    mode (also known as deduplication mode).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé—®é¢˜æ¶‰åŠåˆ°**å†™å…¥æ–¹å¼ï¼ˆWrite dispositionï¼‰**æˆ–**åŒæ­¥æ¨¡å¼ï¼ˆSync modeï¼‰**çš„é€‰æ‹©ã€‚ç›´æ¥çš„ç­”æ¡ˆæ˜¯ï¼Œå¦‚æœä½ å¸Œæœ›å¢é‡åŠ è½½æ•°æ®ï¼Œä½ å¯èƒ½ä¼šé€‰æ‹©ä»¥è¿½åŠ æ¨¡å¼æˆ–åˆå¹¶æ¨¡å¼ï¼ˆä¹Ÿå«å»é‡æ¨¡å¼ï¼‰å°†æå–çš„æ•°æ®å†™å…¥ã€‚
- en: However, letâ€™s step back to examine our options more closely and determine which
    method is best suited for incremental loading.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè®©æˆ‘ä»¬é€€åä¸€æ­¥ï¼Œæ›´ä»”ç»†åœ°å®¡è§†æˆ‘ä»¬çš„é€‰æ‹©ï¼Œå¹¶ç¡®å®šå“ªç§æ–¹æ³•æœ€é€‚åˆå¢é‡åŠ è½½ã€‚
- en: Here are the popular write dispositions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¸¸è§çš„å†™å…¥æ–¹å¼ã€‚
- en: ğŸŸª **overwrite/replace:** drop all existing records in the destination tables
    and then insert the extracted records.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸŸª **è¦†ç›–/æ›¿æ¢ï¼ˆoverwrite/replaceï¼‰**ï¼šåˆ é™¤ç›®æ ‡è¡¨ä¸­æ‰€æœ‰ç°æœ‰è®°å½•ï¼Œç„¶åæ’å…¥æå–çš„è®°å½•ã€‚
- en: ğŸŸª **append:** simply append extracted records to the destination tables.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸŸª **è¿½åŠ ï¼ˆappendï¼‰**ï¼šç®€å•åœ°å°†æå–çš„è®°å½•è¿½åŠ åˆ°ç›®æ ‡è¡¨ä¸­ã€‚
- en: ğŸŸª **merge / dedup:** insert new(*) records and update(**) existing records.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸŸª **åˆå¹¶ / å»é‡ï¼ˆmerge / dedupï¼‰**ï¼šæ’å…¥æ–°(*)è®°å½•å¹¶æ›´æ–°(**)ç°æœ‰è®°å½•ã€‚
- en: '(*) How do we know which records are new?: Usually, we will use a primary key
    to determine that. If you use dlt, their merging strategy can be more sophisticated
    than that, including the distinction between `merge_key` and `primary_key` *(one
    is used for merging and one is used for dedupication before merging)* or `dedup_sort`
    *(which records are to be deleted with the same key in the dedup process)*. I
    will leave that part for another tutorial.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: (*) æˆ‘ä»¬æ€ä¹ˆçŸ¥é“å“ªäº›è®°å½•æ˜¯æ–°çš„ï¼Ÿï¼šé€šå¸¸ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä¸»é”®æ¥ç¡®å®šã€‚å¦‚æœä½¿ç”¨ dltï¼Œå®ƒçš„åˆå¹¶ç­–ç•¥å¯ä»¥æ¯”è¿™æ›´å¤æ‚ï¼ŒåŒ…æ‹¬åŒºåˆ†`merge_key`å’Œ`primary_key`
    *(ä¸€ä¸ªç”¨äºåˆå¹¶ï¼Œä¸€ä¸ªç”¨äºå»é‡åå†åˆå¹¶)*ï¼Œæˆ–è€…`dedup_sort` *(åœ¨å»é‡è¿‡ç¨‹ä¸­ï¼Œå“ªäº›è®°å½•ä¼šè¢«åˆ é™¤)*ã€‚è¿™ä¸€éƒ¨åˆ†æˆ‘å°†ç•™åˆ°å¦ä¸€ä¸ªæ•™ç¨‹è®²è§£ã€‚
- en: (**) This is a simple explanation, if you want to find out more about how dlt
    handles this merging strategy, read more [here](https://dlthub.com/docs/general-usage/incremental-loading#merge-incremental-loading).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: (**) è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è§£é‡Šï¼Œå¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äº dlt å¦‚ä½•å¤„ç†è¿™ç§åˆå¹¶ç­–ç•¥çš„ä¿¡æ¯ï¼Œå¯ä»¥[ç‚¹å‡»è¿™é‡Œ](https://dlthub.com/docs/general-usage/incremental-loading#merge-incremental-loading)é˜…è¯»æ›´å¤šã€‚
- en: ğŸ‘ï¸ğŸ‘ï¸ Here is an example to help us understand the results of different write
    dispositions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘ï¸ğŸ‘ï¸ è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­å¸®åŠ©æˆ‘ä»¬ç†è§£ä¸åŒå†™å…¥æ–¹å¼çš„ç»“æœã€‚
- en: 'â†ªï¸ **On 2024.06.19: We make the first sync.**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: â†ªï¸ **2024å¹´6æœˆ19æ—¥ï¼šæˆ‘ä»¬è¿›è¡Œäº†ç¬¬ä¸€æ¬¡åŒæ­¥ã€‚**
- en: ğŸ…°ï¸ **Data in** `**source application**`ï¸ï¸
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ…°ï¸ **æ•°æ®åœ¨** `**æºåº”ç”¨ç¨‹åº**`ï¸ï¸
- en: '![](../Images/74b8a8cbec32ac881ce296f257ab9913.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74b8a8cbec32ac881ce296f257ab9913.png)'
- en: Image by Author
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: ğŸ…±ï¸ ï¸**Data loaded to our** `**destination database**`
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ…±ï¸ **æ•°æ®å·²åŠ è½½åˆ°æˆ‘ä»¬çš„** `**ç›®æ ‡æ•°æ®åº“**`
- en: No matter what sync strategy you choose, the table at the destination is **literally
    a copy** of the source table.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºé€‰æ‹©å“ªç§åŒæ­¥ç­–ç•¥ï¼Œç›®æ ‡è¡¨ä¸­çš„æ•°æ®**ä¸¥æ ¼æ¥è¯´æ˜¯æºè¡¨çš„å‰¯æœ¬**ã€‚
- en: '![](../Images/74b8a8cbec32ac881ce296f257ab9913.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74b8a8cbec32ac881ce296f257ab9913.png)'
- en: Image by Author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Saved state of `updated_at`= 2024â€“06â€“03, which is the latest `updated_at` mong
    the 2 records we synced.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å·²ä¿å­˜çš„ `updated_at` çŠ¶æ€ = 2024-06-03ï¼Œè¿™æ˜¯æˆ‘ä»¬åŒæ­¥çš„ä¸¤æ¡è®°å½•ä¸­æœ€æ–°çš„ `updated_at`ã€‚
- en: 'â†ªï¸ **On 2024.06.2: We make the second sync.**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: â†ªï¸ **2024å¹´6æœˆ2æ—¥ï¼šæˆ‘ä»¬è¿›è¡Œäº†ç¬¬äºŒæ¬¡åŒæ­¥ã€‚**
- en: '**ğŸ…°ï¸ ï¸ï¸ï¸ï¸ï¸ï¸ï¸Data in** `**source application**`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**ğŸ…°ï¸ ï¸ï¸ï¸ï¸ï¸ï¸ï¸æ•°æ®åœ¨** `**æºåº”ç”¨ç¨‹åº**`'
- en: '![](../Images/43dd22288ef2069f3129fa81154bed22.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43dd22288ef2069f3129fa81154bed22.png)'
- en: Image by Author
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'âœï¸ Changes in the source table:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: âœï¸ æºè¡¨ä¸­çš„æ›´æ”¹ï¼š
- en: Record id=1 was updated (sales figure).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®°å½• ID=1 å·²æ›´æ–°ï¼ˆé”€å”®æ•°æ®ï¼‰ã€‚
- en: Record id=2 was dropped.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®°å½• ID=2 å·²åˆ é™¤ã€‚
- en: Record id=3 was inserted.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®°å½• ID=3 å·²æ’å…¥ã€‚
- en: At this sync, we ONLY extract records with the `updated_at`> 2024â€“06â€“03 (state
    saved from last sync). Therefore, we will extracted only record id=1 and id=3\.
    Since record id=2 was removed from the source data, there is no way for us to
    recognize this change.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™æ¬¡åŒæ­¥ä¸­ï¼Œæˆ‘ä»¬ä»…æå– `updated_at` > 2024â€“06â€“03ï¼ˆä¸Šæ¬¡åŒæ­¥æ—¶ä¿å­˜çš„çŠ¶æ€ï¼‰ä¹‹åçš„è®°å½•ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åªä¼šæå–è®°å½• id=1 å’Œ id=3ã€‚ç”±äºè®°å½•
    id=2 å·²ä»æºæ•°æ®ä¸­åˆ é™¤ï¼Œæˆ‘ä»¬æ— æ³•è¯†åˆ«æ­¤å˜åŠ¨ã€‚
- en: With the second sync, you now will see the difference among the write strategies.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬äºŒæ¬¡åŒæ­¥åï¼Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°ä¸åŒçš„å†™å…¥ç­–ç•¥ä¹‹é—´çš„å·®å¼‚ã€‚
- en: ğŸ…±ï¸ **Data loaded to our** `**destination database**`
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ…±ï¸ **æ•°æ®å·²åŠ è½½åˆ°æˆ‘ä»¬çš„** `**ç›®æ ‡æ•°æ®åº“**`
- en: 'â— **Scenario 1: Overwrite**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: â— **åœºæ™¯ 1ï¼šè¦†ç›–**
- en: '![](../Images/19496a1ddb57a9f1e1107c691ddf441d.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19496a1ddb57a9f1e1107c691ddf441d.png)'
- en: Image by Author
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: The destination table will be overwritten by the 2 records extracted this time.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡è¡¨å°†è¢«è¿™æ¬¡æå–çš„ä¸¤æ¡è®°å½•è¦†ç›–ã€‚
- en: 'â— **Scenario 2: Append**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: â— **åœºæ™¯ 2ï¼šè¿½åŠ **
- en: '![](../Images/c30e26065a3f3bf15be9590181267768.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c30e26065a3f3bf15be9590181267768.png)'
- en: Image by Author
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: The 2 extracted records will be appended to the destination table, the existing
    records are not affected.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤æ¡æå–çš„è®°å½•å°†è¢«è¿½åŠ åˆ°ç›®æ ‡è¡¨ä¸­ï¼Œç°æœ‰çš„è®°å½•ä¸ä¼šå—åˆ°å½±å“ã€‚
- en: 'â— **Scenario 3: Merge or dedup**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: â— **åœºæ™¯ 3ï¼šåˆå¹¶æˆ–å»é‡**
- en: '![](../Images/380959de013398c27bd89d42b83d8da6.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/380959de013398c27bd89d42b83d8da6.png)'
- en: Image by Author
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: The 2 extracted records with id=1 and 3 will replace the existing records at
    destination. This processing is so called merging or deduplicating. Record id=2
    in the destination table remains intact.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æå–çš„ä¸¤æ¡è®°å½•ï¼Œid=1 å’Œ id=3ï¼Œå°†æ›¿æ¢ç›®æ ‡ä¸­çš„ç°æœ‰è®°å½•ã€‚è¿™ä¸€å¤„ç†è¿‡ç¨‹è¢«ç§°ä¸ºåˆå¹¶æˆ–å»é‡ã€‚ç›®æ ‡è¡¨ä¸­çš„è®°å½• id=2 å°†ä¿æŒä¸å˜ã€‚
- en: ğŸŸ¢ **Takeaways:** The merge (dedup) strategy can be effective in the incremental
    data loading pipeline, but if your table is very large, this dedup process might
    take a considerable amount of time.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŸ¢ **æ€»ç»“ï¼š** åˆå¹¶ï¼ˆå»é‡ï¼‰ç­–ç•¥åœ¨å¢é‡æ•°æ®åŠ è½½ç®¡é“ä¸­å¯èƒ½éå¸¸æœ‰æ•ˆï¼Œä½†å¦‚æœä½ çš„è¡¨éå¸¸å¤§ï¼Œå»é‡è¿‡ç¨‹å¯èƒ½éœ€è¦ç›¸å½“é•¿çš„æ—¶é—´ã€‚
- en: 'ğŸ’¥ Question 3: How do I implement it in code?'
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¥ é—®é¢˜ 3ï¼šæˆ‘å¦‚ä½•åœ¨ä»£ç ä¸­å®ç°å®ƒï¼Ÿ
- en: 'ğŸ‘‰ Answer: dlt â€” as it is lightweight, well-documented, and has an active community
    for support.'
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ‘‰ ç­”æ¡ˆï¼šdlt â€”â€” å› ä¸ºå®ƒè½»é‡ã€æ–‡æ¡£é½å…¨ï¼Œå¹¶ä¸”æœ‰æ´»è·ƒçš„ç¤¾åŒºæ”¯æŒã€‚
- en: '[dlt](https://dlthub.com/) is an excellent choice because it provides you with
    the right level of abstraction. In fact, you can choose how much abstraction you
    want. As you can see in my example code below, I have taken the liberty of writing
    my own request loop, but dlt offers helper functions that can do this for you
    with much fewer lines of code. This flexibility makes dlt stand out compared to
    other solutions.'
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[dlt](https://dlthub.com/) æ˜¯ä¸€ä¸ªéå¸¸ä¸é”™çš„é€‰æ‹©ï¼Œå› ä¸ºå®ƒæä¾›äº†é€‚å½“çš„æŠ½è±¡å±‚æ¬¡ã€‚äº‹å®ä¸Šï¼Œä½ å¯ä»¥é€‰æ‹©ä½ éœ€è¦çš„æŠ½è±¡ç¨‹åº¦ã€‚å¦‚ä½ åœ¨æˆ‘ä¸‹é¢çš„ç¤ºä¾‹ä»£ç ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä¸»åŠ¨ç¼–å†™äº†è‡ªå·±çš„è¯·æ±‚å¾ªç¯ï¼Œä½†
    dlt æä¾›äº†å¯ä»¥ç”¨æ›´å°‘ä»£ç è¡Œå®Œæˆçš„è¾…åŠ©å‡½æ•°ã€‚è¿™ç§çµæ´»æ€§ä½¿å¾— dlt ç›¸è¾ƒäºå…¶ä»–è§£å†³æ–¹æ¡ˆè„±é¢–è€Œå‡ºã€‚'
- en: You can refer to the diagram for a high-level view and then drill down to the
    code with detailed remarks below.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å‚è€ƒè¿™ä¸ªå›¾è¡¨æ¥è·å¾—é«˜å±‚æ¬¡çš„è§†å›¾ï¼Œç„¶åå†æ·±å…¥åˆ°å¸¦æœ‰è¯¦ç»†å¤‡æ³¨çš„ä»£ç ä¸­ã€‚
- en: 'Quick note: dlt uses the terms **source** and **resources** in its structuring.
    A resource typically corresponds to an API endpoint and writes data to a table
    in the destination database. A source is a collection of resources.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å°æç¤ºï¼šdlt åœ¨å…¶ç»“æ„ä¸­ä½¿ç”¨äº† **æº** å’Œ **èµ„æº** è¿™ä¸¤ä¸ªæœ¯è¯­ã€‚èµ„æºé€šå¸¸å¯¹åº”ä¸€ä¸ª API ç«¯ç‚¹ï¼Œå¹¶å°†æ•°æ®å†™å…¥ç›®æ ‡æ•°æ®åº“ä¸­çš„è¡¨ã€‚æºæ˜¯èµ„æºçš„é›†åˆã€‚
- en: 'In the illustration below, you can see the answers to the two questions we
    discussed:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹é¢çš„æ’å›¾ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬è®¨è®ºçš„ä¸¤ä¸ªé—®é¢˜çš„ç­”æ¡ˆï¼š
- en: 'Answer to Question 1: Make requests to an API endpoint using a date cursor
    to get data incrementally (and persist the cursor value, also known as state,
    for subsequent runs).'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é—®é¢˜ 1 çš„ç­”æ¡ˆï¼šä½¿ç”¨æ—¥æœŸæ¸¸æ ‡å‘ API ç«¯ç‚¹å‘é€è¯·æ±‚ï¼Œé€æ­¥è·å–æ•°æ®ï¼ˆå¹¶æŒä¹…åŒ–æ¸¸æ ‡å€¼ï¼Œä¹Ÿå°±æ˜¯çŠ¶æ€ï¼Œä»¥ä¾¿åç»­æ‰§è¡Œï¼‰ã€‚
- en: 'Answer to Question 2: Write data to the destination table using the merge strategy.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é—®é¢˜ 2 çš„ç­”æ¡ˆï¼šä½¿ç”¨åˆå¹¶ç­–ç•¥å°†æ•°æ®å†™å…¥ç›®æ ‡è¡¨ã€‚
- en: '![](../Images/0d48e7a8399a7ac757f7be442cb17cd2.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d48e7a8399a7ac757f7be442cb17cd2.png)'
- en: Now, you might wonder how to run this Python script? I suggest you to go to
    [this repository](https://github.com/khoadaniel/incremental-data-loading-guide)
    and try out yourself. This repository also provides you with a mock API that you
    can deploy locally for testing purposes. Check out the README for the detailed
    execution guide.
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä½ å¯èƒ½æƒ³çŸ¥é“å¦‚ä½•è¿è¡Œè¿™ä¸ª Python è„šæœ¬ï¼Ÿæˆ‘å»ºè®®ä½ è®¿é—®[è¿™ä¸ªä»£ç åº“](https://github.com/khoadaniel/incremental-data-loading-guide)ï¼Œå¹¶äº²è‡ªå°è¯•ä¸€ä¸‹ã€‚è¿™ä¸ªä»£ç åº“è¿˜ä¸ºä½ æä¾›äº†ä¸€ä¸ªæ¨¡æ‹Ÿ
    APIï¼Œä½ å¯ä»¥åœ¨æœ¬åœ°éƒ¨ç½²è¿›è¡Œæµ‹è¯•ã€‚æŸ¥çœ‹ README è·å–è¯¦ç»†çš„æ‰§è¡ŒæŒ‡å—ã€‚
- en: ğŸ’¥ Here is a snippet of the dlt implementation with my remarks ğŸ’¥
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¥ è¿™é‡Œæ˜¯æˆ‘é™„å¸¦å¤‡æ³¨çš„ dlt å®ç°ç‰‡æ®µ ğŸ’¥
- en: ğŸŸ£ï¸ **Full code can be seen at the repository** [**here**](https://github.com/khoadaniel/incremental-data-loading-guide)ğŸŸ£
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŸ£ï¸ **å®Œæ•´ä»£ç å¯ä»¥åœ¨ä»“åº“ä¸­æŸ¥çœ‹** [**ç‚¹å‡»è¿™é‡Œ**](https://github.com/khoadaniel/incremental-data-loading-guide)ğŸŸ£
- en: âœ… This concludes the tutorial. I hope you have learned about the different components
    that make up an incremental loading script, as well as the code implementation.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: âœ… æœ¬æ•™ç¨‹åˆ°æ­¤ç»“æŸã€‚å¸Œæœ›æ‚¨å·²ç»äº†è§£äº†æ„æˆå¢é‡åŠ è½½è„šæœ¬çš„ä¸åŒç»„ä»¶ï¼Œä»¥åŠä»£ç çš„å®ç°æ–¹æ³•ã€‚
- en: If youâ€™re interested in finding out more about how to build an incremental loading
    script with dlt, check out their documentation [here](https://dlthub.com/docs/general-usage/incremental-loading).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£å¦‚ä½•ä½¿ç”¨dltæ„å»ºå¢é‡åŠ è½½è„šæœ¬ï¼Œè¯·æŸ¥çœ‹ä»–ä»¬çš„æ–‡æ¡£[ç‚¹å‡»è¿™é‡Œ](https://dlthub.com/docs/general-usage/incremental-loading)ã€‚
- en: About me
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…³äºæˆ‘
- en: I am Daniel Le, based in Berlin. I currently work in the fields of Data Engineering
    and Machine Learning.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯Daniel Leï¼Œå±…ä½åœ¨æŸæ—ï¼Œç›®å‰ä»äº‹æ•°æ®å·¥ç¨‹å’Œæœºå™¨å­¦ä¹ é¢†åŸŸçš„å·¥ä½œã€‚
- en: I am interested in new technologies and how they can be implemented to solve
    real-world problems.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯¹æ–°æŠ€æœ¯å……æ»¡å…´è¶£ï¼Œå°¤å…¶æ˜¯å®ƒä»¬å¦‚ä½•åº”ç”¨äºè§£å†³ç°å®ä¸–ç•Œä¸­çš„é—®é¢˜ã€‚
- en: Should you have any inquiries or wish to discuss these interests further, please
    do not hesitate to connect with me on [LinkedIn](https://www.linkedin.com/in/khoadaniel/).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰ä»»ä½•ç–‘é—®æˆ–å¸Œæœ›è¿›ä¸€æ­¥è®¨è®ºè¿™äº›å…´è¶£ï¼Œæ¬¢è¿é€šè¿‡[LinkedIn](https://www.linkedin.com/in/khoadaniel/)ä¸æˆ‘è”ç³»ã€‚
- en: Reference
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[https://dlthub.com/docs/general-usage/incremental-loading](https://dlthub.com/docs/general-usage/incremental-loading)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://dlthub.com/docs/general-usage/incremental-loading](https://dlthub.com/docs/general-usage/incremental-loading)'
