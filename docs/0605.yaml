- en: Self-Instruct Framework, Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/self-instruct-framework-explained-16bce90f4683?source=collection_archive---------10-----------------------#2024-03-05](https://towardsdatascience.com/self-instruct-framework-explained-16bce90f4683?source=collection_archive---------10-----------------------#2024-03-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Or how to “eliminate” human annotators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@dmitry.tsyuzhentsin?source=post_page---byline--16bce90f4683--------------------------------)[![Tsiu-zhen-tsin
    Dmitrii](../Images/e210c94ae2a6415cba7189c59f7eafa5.png)](https://medium.com/@dmitry.tsyuzhentsin?source=post_page---byline--16bce90f4683--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--16bce90f4683--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--16bce90f4683--------------------------------)
    [Tsiu-zhen-tsin Dmitrii](https://medium.com/@dmitry.tsyuzhentsin?source=post_page---byline--16bce90f4683--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16bce90f4683--------------------------------)
    ·10 min read·Mar 5, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a2032623dfbb4f53b21fa2fade0a02d4.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by DALL·E
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/846718fbfb023aecc4441a424b81e209.png)'
  prefs: []
  type: TYPE_IMG
- en: 'High-level overview of InstructGPT with human annotated outputs and ranking
    for supervised learning and reward model training | Source: [Training language
    models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155).'
  prefs: []
  type: TYPE_NORMAL
- en: 'As Large Language Models (LLMs) revolutionize our life, the growth of instruction-tuned
    LLMs faces significant challenges: the critical need for vast, varied, and high-quality
    datasets. Traditional methods, such as employing human annotators to generate
    datasets — a strategy used in InstructGPT (image above)— face high costs, limited
    diversity, creativity, and allignment challenges. To address these limitations,
    the Self-Instruct framework² was introduced. Its core idea is simple and powerful:
    let language models (LM) generate training data, leading to more cost-effective,
    diverse and creative datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, in this article, I would like to lead you through the framework step-by-step,
    demonstrating all the details so that after reading it, you will be able to reproduce
    the results yourself :)
  prefs: []
  type: TYPE_NORMAL
- en: ❗ This article provides all steps from code perspective, so please feel free
    to visit the original [GitHub repository](https://github.com/yizhongw/self-instruct#)
    .❗
  prefs: []
  type: TYPE_NORMAL
- en: Self-Instruct Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/c52708b5f5a0ce82c6b7da94255ad7e1.png)'
  prefs: []
  type: TYPE_IMG
- en: A high-level overview of the Self-Instruct framework
  prefs: []
  type: TYPE_NORMAL
- en: 'The recipe is relatively straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 0** — Define Instruction Data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: — Add a seed of high-quality and diverse human-written tasks in different domains
    as tuples (instruction, instances) to the task pool;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Step 1 —** Instruction Generation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: — Sample 8 (6 human-written and 2 model-generated) instructions from the task
    pool;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: — Insert bootstrapped instructions into the prompt in a few-shot way and ask
    an LM to come up with more instructions;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: — Filter generated instructions out based on ROUGE-metric (a method to evaluate
    the similarity between text outputs and reference texts) and some heuristics (I
    will cover this later);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: — Repeat Step 1 until reaching some amount of instructions;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Step 2 —** Classification Task Identification:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: — For every generated instruction in the task pool, we need to identify its
    type (classification or non-classification) via a few-shot manner;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Step 3 —** Instance Generation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: — Given the instructions and task types, generate instances (inputs and outputs)
    and filter them out based on heuristics;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Step 4** — Finetuning the LM to Follow Instructions:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: — Utilize generated tasks to finetune a pre-trained model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Voila, that’s how the Self-Instruct works, but the devil is in the details,
    so let’s dive into every step!
  prefs: []
  type: TYPE_NORMAL
- en: Step 0 — Define Instruction Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/c1ad6c077176a803126a54ade25f05bf.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 0
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by understanding what is inside the initial “Seed of tasks”: it
    consists of 175 seed tasks (25 classification and 150 non-classifications) with
    **one** **instruction** and **one** **instance** per task in different domains.
    Each task has an id, name, instruction, instances (**input and output**), and
    is_classification binary flag, identifying whether the task has a limited output
    label space.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some examples of classification and non-classification tasks with
    empty and non-empty input fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/445da55a377333a447a8e31681447d2c.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of classification task with non-empty input
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/45fde17cc82f3f58851167a597992e3f.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of non-classification task with empty input
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we can see in the first example how the input field clarifies and
    provides context to the more general instruction, while in the second example,
    we don’t need an input field as long as the instruction is already self-contained.
    Also, the first example is the classification task — we can answer it by assigning
    some labels from limited space, while we can’t do the same with the second example.
  prefs: []
  type: TYPE_NORMAL
- en: This step is **crucial** as long as we encourage task diversity via data formats
    in the dataset and demonstrate correct ways of solving various tasks.
  prefs: []
  type: TYPE_NORMAL
- en: As long as we define the instruction format, we add them to the task pool to
    store our final dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 — Instruction Generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/3ddb5fb00f8753b2ce69ee59bfec769e.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 1
  prefs: []
  type: TYPE_NORMAL
- en: '**Sampling and prompting**'
  prefs: []
  type: TYPE_NORMAL
- en: 'By adding a human-written seed set of tasks to the task pool, we can start
    with instructions generation. To do so, we need to sample 8 instructions from
    the task pool (6 human-written and 2 machine-generated) and encode them into the
    following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3fe0f35250659fbce7e3c14511796cd6.png)'
  prefs: []
  type: TYPE_IMG
- en: Prompt to generate new instructions
  prefs: []
  type: TYPE_NORMAL
- en: However, in the beginning, we do not have any machine-generated instructions.
    Therefore, we just replaced them with empty strings in the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'After generation, we extract instructions from the LM’s response (via regular
    expressions), filter them out, and add filtered instructions to the task pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/56ae357136a1310a25a128bc1cf65cc2.png)'
  prefs: []
  type: TYPE_IMG
- en: Pseudo-code of instruction generation step
  prefs: []
  type: TYPE_NORMAL
- en: We repeat the instruction generation step until we reach some number of machine-generated
    instructions (specified at the beginning of the step).
  prefs: []
  type: TYPE_NORMAL
- en: '**Filtering**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To obtain a diverse dataset, we need to define somehow which instructions will
    be added or not to the task pool, and the easiest way is a heuristically chosen
    set of rules, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Filter out instructions that are too short or too long;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filter based on keywords unsuitable for language models (image, graph, file,
    plot, …);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filter those starting with punctuation;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filter those starting with non-English characters;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filter those when their ROUGE-L similarity with any existing instruction is
    higher than 0.7;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 2— Classification Task Identification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/c6ffd4aca9d8e7ec419a64b2f5c7b11e.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 2
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors of Self-Instruct noticed that depending on an instruction, the
    language models can be biased towards one label, especially for classification
    tasks. Therefore, to eliminate such such, we need to classify every instruction
    via few-shot prompting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/af86a11dae91aa778edbb0a0b6f0bb1a.png)'
  prefs: []
  type: TYPE_IMG
- en: Prompt used to classify whether a task instruction is a classification or non-classification
    task (12 classification and 19 non-classification instructions are used in this
    template)
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 — Instance Generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/c1f43525948bb2d7bb6ef780a01d3f63.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 3
  prefs: []
  type: TYPE_NORMAL
- en: After identifying the instruction type, we can finally generate input and output,
    considering that we have two types of instructions (classification or non-classification).
    How? **Few-shot prompting!**
  prefs: []
  type: TYPE_NORMAL
- en: For non-classification instructions, we ask the model to generate input and
    only then output (**Input-First Approach**), but for classification tasks, we
    ask the model to generate output (class label) first and then condition input
    generation based on output (**Output-First Approach**). Compared to Step 0, we
    don’t restrict the number of generated instances per every instruction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/936041e4deb8138940508512b2d2fc22.png)'
  prefs: []
  type: TYPE_IMG
- en: Prompt used for the Input-First Approach of instance generation
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/81ce9945254ce624197510383efa8904.png)'
  prefs: []
  type: TYPE_IMG
- en: Prompt used for the Output-First Approach of instance generation
  prefs: []
  type: TYPE_NORMAL
- en: 'After generation, we extract instances and format them (regular expressions);
    after formatting, we filter them out using some rules, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: If input and output are the same,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If instances are already in the task pool,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the output is empty,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are usually incomplete generations if the input or output ends with a
    colon;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And some other heuristics. In the end, we have the following example of a generated
    task with 1 instruction and 1 instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e66b61fa15e4b849411a66a67414099d.png)'
  prefs: []
  type: TYPE_IMG
- en: Instance generation example
  prefs: []
  type: TYPE_NORMAL
- en: That’s the main idea behind Self-Intsruct!
  prefs: []
  type: TYPE_NORMAL
- en: Step 4— Finetuning the LM to Follow Instructions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After completing all previous steps, we can take a pre-trained LM and instruction-tune
    it on the generated dataset to achieve better metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Overcoming challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the beginning of the article, I covered some challenges that “instruction-tuned”
    LLMs face; let’s see how Self-Instruct enables overcoming them.
  prefs: []
  type: TYPE_NORMAL
- en: Quantity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the help of only 175 initial human-written tasks, 52K instructions and
    82K instances were generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7c26e7706615a94f7c70e392cccd8c52.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Self-Instruct: Aligning Language Models with Self-Generated Instructions](https://arxiv.org/pdf/2212.10560)'
  prefs: []
  type: TYPE_NORMAL
- en: Diversity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To investigate how diverse the generated dataset is, authors of Self-Instruct
    used Berkley Neural Parser to parse instructions and then extract the closest
    verb to the root and its first direct noun object. 26K out of 52K instructions
    have a verb-noun format, but the other 26K instructions have more complex structure
    (e.g., “Classify whether this tweet contains political content or not.”) or are
    framed as questions (e.g., “Which of these statements are true?”).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3321770df0415c9c20e8478a05891469.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The top 20 most common root verbs (inner circle) and their top 4 direct noun
    objects (outer circle) in the generated instructions | Source: [Self-Instruct:
    Aligning Language Models with Self-Generated Instructions](https://arxiv.org/pdf/2212.10560)'
  prefs: []
  type: TYPE_NORMAL
- en: Quality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To prove that Self-Instruct can generate high-quality tasks, it was randomly
    selected 200 generated instructions and sampled 1 instance per instruction, and
    then the author of the framework assessed them, obtaining the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/75c61fdf98529ce8b391c552b4fe9f56.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Self-Instruct: Aligning Language Models with Self-Generated Instructions](https://arxiv.org/pdf/2212.10560)'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, 92% of all tasks describe a valid task, and 54% — have all valid
    fields (given that we generated 52K tasks, at least 26K will represent high-quality
    data, which is fantastic!)
  prefs: []
  type: TYPE_NORMAL
- en: '**Costs**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Self-Instruct framework also introduces significant cost advantages as well.
    The initial phases of task generation (Steps 1-3 ) amount to a mere $600, while
    the last step of fine-tuning using the GPT-3 model incurs a cost of $338\. It’s
    vital to keep in mind when we look at results!
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'How Self-Instruct can enhance the ROUGE-L metric on the SuperNI (**Super-Natural
    Instructions**) dataset? For that, we can compare the results of 1) off-the-shelf
    pre-trained LMs without any instruction fine-tuning (Vanilla LMs), 2) Instruction-tuned
    models (Instruction-tuned w/o SuperNI), and 3) Instruction-tuned models trained
    on SuperNI (Instruction-tuned w/ SuperNI):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/998b6798d954b2297b79ba9b0c2aa56c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Evaluation results on ***unseen***tasks from SuperNI | Source: [Self-Instruct:
    Aligning Language Models with Self-Generated Instructions](https://arxiv.org/pdf/2212.10560)'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, using Self-Instruct demonstrates a 33% absolute improvement over
    the original model on the dataset (1); simultaneously, it shows that using the
    framework can also slightly improve metrics after fine-tuning the SuperNI dataset
    (3).
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, if we create a new (=unseen) dataset of 252 instructions and 1 instance
    per instruction and evaluate a selection of instruction-tuned variants, we can
    see the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8a00ab05695c5026ef4cc894e16e4a93.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Performance of GPT3 model and its instruction-tuned variants, evaluated by
    human experts on our 252 user-oriented instructions | Source: [Self-Instruct:
    Aligning Language Models with Self-Generated Instructions](https://arxiv.org/pdf/2212.10560)'
  prefs: []
  type: TYPE_NORMAL
- en: GPT3 + Self-Instruct shows impressive results compared to other instruction-tuned
    variants, but there is still a place for improvement compared to InstructGPT (previously
    available LLMs by OpenAI) variants.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The idea behind Self-Instruct is straightforward, but at the same time, it is
    compelling, so let’s look at how we can use it in different cases.
  prefs: []
  type: TYPE_NORMAL
- en: Stanford Alpaca³
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In 2023, Alpaca LLM from Stanford gained colossal interest due to affordability,
    accessibility, and the fact that it was developed for less than $600, and at the
    same time, it combined LLaMA and Self-Instruct ideas.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b4d952b864fe39083fd674bcca9c7f51.png)'
  prefs: []
  type: TYPE_IMG
- en: 'High-level overview of Alpaca | Source: [Alpaca: A Strong, Replicable Instruction-Following
    Model](https://crfm.stanford.edu/2023/03/13/alpaca.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Alpaca’s version of Self-Instruct were slightly modified:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1 (instruction generation): more aggressive batch decoding was applied,
    i.e., generating 20 instructions at once'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 2 (classification task): this step was wholly excluded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 3 (instance generation): only one instance is generated per instruction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the end, researchers from Stanford could achieve significant improvements
    in comparison to the initial set-up in Self-Instruct and based on performed a
    blind pairwise comparison between text-davinci-003 (InstructGPT-003) and Alpaca
    7B: Alpaca wins 90 versus 89 comparisons against text-davinci-003.'
  prefs: []
  type: TYPE_NORMAL
- en: Self-Rewarding Language Models⁴
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0219851ef32d6d7ffd7ab7fa267ece14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Self-Rewarding Language Models](https://arxiv.org/pdf/2401.10020)'
  prefs: []
  type: TYPE_NORMAL
- en: In 2024, Self-Instruct is a practical framework used in more complex set-ups
    like in Self-Rewarding Language Models by Meta. As in Self-Instruct, initially,
    we have a seed set of human-written tasks; we then generate new instructions {xᵢ}
    and prompt model Mₜ to generate outputs {yᵢ¹, …, yᵢᵏ} and later generate rewards
    {rᵢ¹, …, rᵢᵏ } — that’s how we could ““eliminate”” human-annotators in InstructGPT
    by self-instruction process. The last block of Self-Rewarding models is instruction
    following training — on this step, we compose preference pairs and via DPO train
    Mₜ₊₁ — next iteration model. Therefore, we can repeat this procedure repeatedly
    to enrich the dataset and improve the initial pre-trained model.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although Self-Instruct offers an innovative approach to autonomous dataset generation,
    its reliance on large pre-trained models introduces potential limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Data quality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Despite the impressive capability to generate synthetic data, the quality —
    marked by a 54% validity in the Overcoming Challenges section — remains a concern.
    It underscores a critical issue: the biases inherent in pre-trained models could
    replicate, or even amplify, within the generated datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: Tail phenomena
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Instructions vary in frequency: some instructions are frequently requested,
    while others are rare. Nonetheless, it’s crucial to effectively manage these infrequent
    requests, as they highlight the brittleness of LLMs in processing uncommon and
    creative tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, the Self-Instruct framework represents an advancement in developing
    instruction-tuned LMs, offering an innovative solution to the challenges of dataset
    generation. Enabling LLMs to autonomously produce diverse and high-quality data
    significantly reduces dependency on human annotators, therefore driving down costs.
  prefs: []
  type: TYPE_NORMAL
- en: Unless otherwise noted, all images are by the author, inspired by [Self-Instruct](https://arxiv.org/pdf/2212.10560)
    :)
  prefs: []
  type: TYPE_NORMAL
- en: '**References:**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Ouyang, Long, et al. “[Training language models to follow instructions
    with human feedback](https://arxiv.org/pdf/2203.02155).” *Advances in Neural Information
    Processing Systems* 35 (2022): 27730–27744'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N.A., Khashabi, D. and
    Hajishirzi, H., 2022\. [Self-instruct: Aligning language model with self generated
    instructions](https://arxiv.org/pdf/2212.10560). *arXiv preprint arXiv:2212.10560*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C.,
    Liang, P. and Hashimoto, T.B., 2023\. [Stanford alpaca: An instruction-following
    llama model](https://crfm.stanford.edu/2023/03/13/alpaca.html).'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Yuan, W., Pang, R.Y., Cho, K., Sukhbaatar, S., Xu, J. and Weston, J., 2024\.
    [Self-rewarding language models](https://arxiv.org/pdf/2401.10020). *arXiv preprint
    arXiv:2401.10020*.'
  prefs: []
  type: TYPE_NORMAL
