# ä½¿ç”¨ Gemini ä¸ºä»»ä½•ç±»å‹çš„ PDF æ„å»ºæ–‡æ¡£ AI æµæ°´çº¿

> åŸæ–‡ï¼š[https://towardsdatascience.com/build-a-document-ai-pipeline-for-any-type-of-pdf-with-gemini-9221c8e143db?source=collection_archive---------0-----------------------#2024-12-15](https://towardsdatascience.com/build-a-document-ai-pipeline-for-any-type-of-pdf-with-gemini-9221c8e143db?source=collection_archive---------0-----------------------#2024-12-15)

## è¡¨æ ¼ã€å›¾ç‰‡ã€å›¾è¡¨æˆ–å…¬å¼å·²ç»ä¸å†æ˜¯é—®é¢˜ï¼æä¾›å®Œæ•´ä»£ç ã€‚

[](https://medium.com/@CVxTz?source=post_page---byline--9221c8e143db--------------------------------)[![Youness Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--9221c8e143db--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9221c8e143db--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9221c8e143db--------------------------------) [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--9221c8e143db--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9221c8e143db--------------------------------) Â·é˜…è¯»æ—¶é—´ 10 åˆ†é’ŸÂ·2024å¹´12æœˆ15æ—¥

--

![](../Images/04f5f0506207581622a222ae56c38208.png)

å›¾ç‰‡æ¥æºï¼š[Matt Noble](https://unsplash.com/@mcnoble?utm_source=medium&utm_medium=referral) via [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

è‡ªåŠ¨åŒ–æ–‡æ¡£å¤„ç†æ˜¯ ChatGPT é©å‘½ä¸­çš„æœ€å¤§èµ¢å®¶ä¹‹ä¸€ï¼Œå› ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èƒ½å¤Ÿåœ¨é›¶æ ·æœ¬ç¯å¢ƒä¸‹å¤„ç†å„ç§ä¸»é¢˜å’Œä»»åŠ¡ï¼Œè¿™æ„å‘³ç€å®ƒä»¬ä¸éœ€è¦é¢†åŸŸå†…çš„æ ‡æ³¨è®­ç»ƒæ•°æ®ã€‚è¿™ä½¿å¾—æ„å»ºåŸºäº AI çš„åº”ç”¨ç¨‹åºæ¥å¤„ç†ã€è§£æå’Œè‡ªåŠ¨ç†è§£ä»»æ„æ–‡æ¡£å˜å¾—æ›´åŠ å®¹æ˜“ã€‚å°½ç®¡ä½¿ç”¨ LLM çš„ç®€å•æ–¹æ³•ä»ç„¶å—åˆ°éæ–‡æœ¬ä¸Šä¸‹æ–‡çš„åˆ¶çº¦ï¼Œå¦‚å›¾è¡¨ã€å›¾ç‰‡å’Œè¡¨æ ¼ï¼Œä½†è¿™æ­£æ˜¯æˆ‘ä»¬å°†åœ¨æœ¬åšå®¢ä¸­å°è¯•è§£å†³çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å…³æ³¨ PDF æ–‡ä»¶ã€‚

ä»åŸºç¡€å±‚é¢æ¥è¯´ï¼ŒPDF æ–‡ä»¶ä»…ä»…æ˜¯ç”±å­—ç¬¦ã€å›¾ç‰‡å’Œçº¿æ¡ä»¥åŠå®ƒä»¬çš„ç²¾ç¡®åæ ‡ç»„æˆã€‚å®ƒä»¬æ²¡æœ‰å†…åœ¨çš„â€œæ–‡æœ¬â€ç»“æ„ï¼Œå¹¶ä¸”å¹¶éä¸ºäº†ä½œä¸ºæ–‡æœ¬è¿›è¡Œå¤„ç†è€Œæ„å»ºï¼Œè€Œåªæ˜¯ä¸ºäº†æŸ¥çœ‹è€Œå­˜åœ¨ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä¸å®ƒä»¬æ‰“äº¤é“ä¼šå¾ˆå›°éš¾ï¼Œå› ä¸ºä»…é™æ–‡æœ¬çš„æ–¹æ³•æ— æ³•æ•æ‰åˆ°è¿™äº›æ–‡æ¡£ä¸­çš„æ‰€æœ‰å¸ƒå±€å’Œè§†è§‰å…ƒç´ ï¼Œå¯¼è‡´å¤§é‡çš„ä¸Šä¸‹æ–‡å’Œä¿¡æ¯ä¸¢å¤±ã€‚

ç»•è¿‡è¿™ä¸€â€œä»…é™æ–‡æœ¬â€çš„é™åˆ¶çš„ä¸€ç§æ–¹æ³•æ˜¯ï¼Œé€šè¿‡åœ¨å°†æ–‡æ¡£è¾“å…¥åˆ° LLM ä¹‹å‰ï¼Œè¿›è¡Œå¤§é‡çš„é¢„å¤„ç†å·¥ä½œï¼Œæ£€æµ‹è¡¨æ ¼ã€å›¾ç‰‡å’Œå¸ƒå±€ã€‚è¡¨æ ¼å¯ä»¥è§£æä¸º Markdown æˆ– JSONï¼Œå›¾ç‰‡å’Œå›¾è¡¨å¯ä»¥é€šè¿‡å®ƒä»¬çš„æ ‡é¢˜æ¥è¡¨ç¤ºï¼Œæ–‡æœ¬åˆ™å¯ä»¥æŒ‰åŸæ ·è¾“å…¥ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•éœ€è¦è‡ªå®šä¹‰æ¨¡å‹ï¼Œå¹¶ä¸”ä»ç„¶ä¼šå¯¼è‡´ä¸€äº›ä¿¡æ¯ä¸¢å¤±ï¼Œé‚£ä¹ˆæˆ‘ä»¬èƒ½åšå¾—æ›´å¥½å—ï¼Ÿ

# å¤šæ¨¡æ€ LLMs

æœ€è¿‘çš„å¤§å‹æ¨¡å‹å¤§å¤šæ˜¯å¤šæ¨¡æ€çš„ï¼Œæ„å‘³ç€å®ƒä»¬èƒ½å¤Ÿå¤„ç†æ–‡æœ¬ã€ä»£ç å’Œå›¾åƒç­‰å¤šç§æ¨¡æ€ã€‚è¿™ä¸ºæˆ‘ä»¬çš„é—®é¢˜æä¾›äº†æ›´ç®€å•çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥è®©ä¸€ä¸ªæ¨¡å‹ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å†…å®¹ã€‚å› æ­¤ï¼Œä»£æ›¿ä¸ºå›¾åƒåŠ ä¸Šæ ‡é¢˜å’Œè§£æè¡¨æ ¼ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å°†é¡µé¢ä½œä¸ºå›¾åƒè¾“å…¥ï¼Œå¹¶æŒ‰åŸæ ·å¤„ç†ã€‚æˆ‘ä»¬çš„ç®¡é“å°†èƒ½å¤ŸåŠ è½½PDFï¼Œæå–æ¯ä¸€é¡µä½œä¸ºå›¾åƒï¼Œä½¿ç”¨LLMå°†å…¶æ‹†åˆ†ä¸ºå¤šä¸ªåˆ†å—ï¼Œå¹¶ä¸ºæ¯ä¸ªåˆ†å—åˆ›å»ºç´¢å¼•ã€‚å¦‚æœæŸä¸ªåˆ†å—è¢«æ£€ç´¢åˆ°ï¼Œå®Œæ•´çš„é¡µé¢å°†è¢«åŒ…å«åœ¨LLMçš„ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œä»»åŠ¡å¤„ç†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨å®è·µä¸­å®ç°è¿™ä¸€ç‚¹ã€‚

# ç®¡é“

æˆ‘ä»¬å®ç°çš„ç®¡é“æ˜¯ä¸€ä¸ªä¸¤æ­¥è¿‡ç¨‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ¯ä¸€é¡µåˆ†å‰²æˆé‡è¦çš„åˆ†å—å¹¶å¯¹æ¯ä¸ªåˆ†å—è¿›è¡Œæ‘˜è¦ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åœ¨æ¯æ¬¡è·å–è¯·æ±‚æ—¶æ£€ç´¢è¿™äº›åˆ†å—å¹¶å°†å®Œæ•´ä¸Šä¸‹æ–‡ä¸æ¯ä¸ªæ£€ç´¢åˆ°çš„åˆ†å—ä¸€åŒåŒ…å«åœ¨LLMä¸Šä¸‹æ–‡ä¸­ã€‚

## æ­¥éª¤ 1ï¼šé¡µé¢åˆ†å‰²ä¸æ‘˜è¦

æˆ‘ä»¬å°†é¡µé¢æå–ä¸ºå›¾åƒï¼Œå¹¶å°†æ¯ä¸ªå›¾åƒä¼ é€’ç»™å¤šæ¨¡æ€LLMè¿›è¡Œåˆ†å‰²ã€‚åƒGeminiè¿™æ ·çš„æ¨¡å‹å¯ä»¥è½»æ¾ç†è§£å¹¶å¤„ç†é¡µé¢å¸ƒå±€ï¼š

+   **è¡¨æ ¼**è¢«è§†ä¸ºä¸€ä¸ªåˆ†å—ã€‚

+   **å›¾å½¢**æ„æˆå¦ä¸€ä¸ªåˆ†å—ã€‚

+   **æ–‡æœ¬å—**è¢«åˆ†å‰²æˆç‹¬ç«‹çš„åˆ†å—ã€‚

+   â€¦

å¯¹äºæ¯ä¸ªå…ƒç´ ï¼ŒLLMä¼šç”Ÿæˆä¸€ä¸ªæ‘˜è¦ï¼Œå¯ä»¥åµŒå…¥å¹¶ç´¢å¼•åˆ°å‘é‡æ•°æ®åº“ä¸­ã€‚

## æ­¥éª¤ 2ï¼šåµŒå…¥ä¸ä¸Šä¸‹æ–‡æ£€ç´¢

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä»…ä½¿ç”¨æ–‡æœ¬åµŒå…¥ä»¥ç®€åŒ–æ“ä½œï¼Œä½†ä¸€ç§æ”¹è¿›æ–¹æ³•æ˜¯ç›´æ¥ä½¿ç”¨è§†è§‰åµŒå…¥ã€‚

æ•°æ®åº“ä¸­çš„æ¯ä¸€æ¡è®°å½•åŒ…æ‹¬ï¼š

+   åˆ†å—çš„æ‘˜è¦ã€‚

+   æ‰¾åˆ°è¯¥é¡¹çš„é¡µé¢ç¼–å·ã€‚

+   æä¾›å®Œæ•´é¡µé¢å›¾åƒçš„é“¾æ¥ä»¥å¢åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

è¯¥æ¶æ„å…è®¸**å±€éƒ¨çº§åˆ«æœç´¢**ï¼ˆæŒ‰åˆ†å—çº§åˆ«ï¼‰ï¼ŒåŒæ—¶ä¿æŒ**ä¸Šä¸‹æ–‡è·Ÿè¸ª**ï¼ˆé€šè¿‡é“¾æ¥å›å®Œæ•´é¡µé¢ï¼‰ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæœç´¢æŸ¥è¯¢æ£€ç´¢åˆ°æŸä¸ªé¡¹ï¼Œä»£ç†å¯ä»¥å°†æ•´ä¸ªé¡µé¢å›¾åƒåŒ…å«è¿›æ¥ï¼Œä»¥ä¾¿å‘LLMæä¾›å®Œæ•´çš„å¸ƒå±€å’Œé¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæœ€å¤§åŒ–å“åº”è´¨é‡ã€‚

é€šè¿‡æä¾›å®Œæ•´å›¾åƒï¼Œæ‰€æœ‰çš„è§†è§‰æç¤ºå’Œé‡è¦çš„å¸ƒå±€ä¿¡æ¯ï¼ˆå¦‚å›¾åƒã€æ ‡é¢˜ã€é¡¹ç›®ç¬¦å·â€¦ï¼‰ä»¥åŠé‚»è¿‘çš„é¡¹ï¼ˆè¡¨æ ¼ã€æ®µè½ç­‰ï¼‰éƒ½å¯ä»¥åœ¨ç”Ÿæˆå“åº”æ—¶æä¾›ç»™LLMã€‚

# ä»£ç†

æˆ‘ä»¬å°†æ¯ä¸ªæ­¥éª¤å®ç°ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ã€å¯é‡ç”¨çš„ä»£ç†ï¼š

ç¬¬ä¸€ä¸ªä»£ç†ç”¨äºè§£æã€åˆ†å—å’Œæ‘˜è¦ã€‚è¿™æ¶‰åŠåˆ°å°†æ–‡æ¡£åˆ†å‰²æˆé‡è¦çš„åˆ†å—ï¼Œå¹¶ä¸ºæ¯ä¸ªåˆ†å—ç”Ÿæˆæ‘˜è¦ã€‚è¿™ä¸ªä»£ç†æ¯ä¸ªPDFåªéœ€è¦è¿è¡Œä¸€æ¬¡ï¼Œç”¨äºé¢„å¤„ç†æ–‡æ¡£ã€‚

ç¬¬äºŒä¸ªä»£ç†è´Ÿè´£ç®¡ç†ç´¢å¼•ã€æœç´¢å’Œæ£€ç´¢ã€‚è¿™åŒ…æ‹¬å°†åˆ†å—çš„åµŒå…¥æ’å…¥åˆ°å‘é‡æ•°æ®åº“ä¸­ï¼Œä»¥ä¾¿é«˜æ•ˆæœç´¢ã€‚ç´¢å¼•åœ¨æ¯ä¸ªæ–‡æ¡£ä¸­åªæ‰§è¡Œä¸€æ¬¡ï¼Œè€Œæœç´¢å¯ä»¥æ ¹æ®ä¸åŒçš„æŸ¥è¯¢é‡å¤è¿›è¡Œã€‚

å¯¹äºä¸¤ä¸ªä»£ç†ï¼Œæˆ‘ä»¬ä½¿ç”¨**Gemini**ï¼Œä¸€ä¸ªå…·æœ‰å¼ºå¤§è§†è§‰ç†è§£èƒ½åŠ›çš„å¤šæ¨¡æ€LLMã€‚

## è§£æä¸åˆ†å—ä»£ç†

ç¬¬ä¸€ä¸ªä»£ç†è´Ÿè´£å°†æ¯ä¸€é¡µåˆ†å‰²æˆæœ‰æ„ä¹‰çš„ç‰‡æ®µï¼Œå¹¶å¯¹æ¯ä¸ªç‰‡æ®µè¿›è¡Œæ€»ç»“ï¼ŒæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

**æ­¥éª¤ 1ï¼šå°†PDFé¡µé¢æå–ä¸ºå›¾åƒ**

æˆ‘ä»¬ä½¿ç”¨`pdf2image`åº“ã€‚ç„¶åå°†å›¾åƒç¼–ç ä¸ºBase64æ ¼å¼ï¼Œä»¥ç®€åŒ–å°†å…¶æ·»åŠ åˆ°LLMè¯·æ±‚ä¸­ã€‚

ä¸‹é¢æ˜¯å®ç°è¿‡ç¨‹ï¼š

```py
from document_ai_agents.document_utils import extract_images_from_pdf
from document_ai_agents.image_utils import pil_image_to_base64_jpeg
from pathlib import Path

class DocumentParsingAgent:
    @classmethod
    def get_images(cls, state):
        """
        Extract pages of a PDF as Base64-encoded JPEG images.
        """
        assert Path(state.document_path).is_file(), "File does not exist"
        # Extract images from PDF
        images = extract_images_from_pdf(state.document_path)
        assert images, "No images extracted"
        # Convert images to Base64-encoded JPEG
        pages_as_base64_jpeg_images = [pil_image_to_base64_jpeg(x) for x in images]
        return {"pages_as_base64_jpeg_images": pages_as_base64_jpeg_images}
```

`extract_images_from_pdf`ï¼šå°†PDFçš„æ¯ä¸€é¡µæå–ä¸ºPILå›¾åƒã€‚

`pil_image_to_base64_jpeg`ï¼šå°†å›¾åƒè½¬æ¢ä¸ºBase64ç¼–ç çš„JPEGæ ¼å¼ã€‚

**æ­¥éª¤ 2ï¼šåˆ†æ®µå’Œæ€»ç»“**

æ¯ä¸ªå›¾åƒå°†è¢«å‘é€åˆ°LLMè¿›è¡Œåˆ†å‰²å’Œæ€»ç»“ã€‚æˆ‘ä»¬ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºä»¥ç¡®ä¿è·å¾—æˆ‘ä»¬æœŸæœ›çš„æ ¼å¼çš„é¢„æµ‹ï¼š

```py
from pydantic import BaseModel, Field
from typing import Literal
import json
import google.generativeai as genai
from langchain_core.documents import Document

class DetectedLayoutItem(BaseModel):
    """
    Schema for each detected layout element on a page.
    """
    element_type: Literal["Table", "Figure", "Image", "Text-block"] = Field(
        ..., 
        description="Type of detected item. Examples: Table, Figure, Image, Text-block."
    )
    summary: str = Field(..., description="A detailed description of the layout item.")

class LayoutElements(BaseModel):
    """
    Schema for the list of layout elements on a page.
    """
    layout_items: list[DetectedLayoutItem] = []

class FindLayoutItemsInput(BaseModel):
    """
    Input schema for processing a single page.
    """
    document_path: str
    base64_jpeg: str
    page_number: int

class DocumentParsingAgent:
    def __init__(self, model_name="gemini-1.5-flash-002"):
        """
        Initialize the LLM with the appropriate schema.
        """
        layout_elements_schema = prepare_schema_for_gemini(LayoutElements)
        self.model_name = model_name
        self.model = genai.GenerativeModel(
            self.model_name,
            generation_config={
                "response_mime_type": "application/json",
                "response_schema": layout_elements_schema,
            },
        )
    def find_layout_items(self, state: FindLayoutItemsInput):
        """
        Send a page image to the LLM for segmentation and summarization.
        """
        messages = [
            f"Find and summarize all the relevant layout elements in this PDF page in the following format: "
            f"{LayoutElements.schema_json()}. "
            f"Tables should have at least two columns and at least two rows. "
            f"The coordinates should overlap with each layout item.",
            {"mime_type": "image/jpeg", "data": state.base64_jpeg},
        ]
        # Send the prompt to the LLM
        result = self.model.generate_content(messages)
        data = json.loads(result.text)

        # Convert the JSON output into documents
        documents = [
            Document(
                page_content=item["summary"],
                metadata={
                    "page_number": state.page_number,
                    "element_type": item["element_type"],
                    "document_path": state.document_path,
                },
            )
            for item in data["layout_items"]
        ]
        return {"documents": documents}
```

`LayoutElements`æ¨¡å¼å®šä¹‰äº†è¾“å‡ºçš„ç»“æ„ï¼Œå…¶ä¸­åŒ…æ‹¬æ¯ç§å¸ƒå±€é¡¹ç±»å‹ï¼ˆè¡¨æ ¼ã€å›¾å½¢ç­‰ï¼‰åŠå…¶æ€»ç»“ã€‚

**æ­¥éª¤ 3ï¼šé¡µé¢çš„å¹¶è¡Œå¤„ç†**

é¡µé¢å¹¶è¡Œå¤„ç†ä»¥æé«˜é€Ÿåº¦ã€‚ä»¥ä¸‹æ–¹æ³•åˆ›å»ºä¸€ä¸ªä»»åŠ¡åˆ—è¡¨ï¼Œä»¥ä¾¿åŒæ—¶å¤„ç†æ‰€æœ‰é¡µé¢å›¾åƒï¼Œå› ä¸ºå¤„ç†æ˜¯IOç»‘å®šçš„ï¼š

```py
from langgraph.types import Send

class DocumentParsingAgent:
    @classmethod
    def continue_to_find_layout_items(cls, state):
        """
        Generate tasks to process each page in parallel.
        """
        return [
            Send(
                "find_layout_items",
                FindLayoutItemsInput(
                    base64_jpeg=base64_jpeg,
                    page_number=i,
                    document_path=state.document_path,
                ),
            )
            for i, base64_jpeg in enumerate(state.pages_as_base64_jpeg_images)
        ]
```

æ¯ä¸€é¡µå°†ä½œä¸ºç‹¬ç«‹ä»»åŠ¡å‘é€åˆ°`find_layout_items`å‡½æ•°ã€‚

**å®Œæ•´å·¥ä½œæµç¨‹**

è¯¥ä»£ç†çš„å·¥ä½œæµç¨‹ä½¿ç”¨`StateGraph`æ„å»ºï¼Œå°†å›¾åƒæå–å’Œå¸ƒå±€æ£€æµ‹æ­¥éª¤é“¾æ¥æˆä¸€ä¸ªç»Ÿä¸€çš„ç®¡é“ ->

```py
from langgraph.graph import StateGraph, START, END

class DocumentParsingAgent:
    def build_agent(self):
        """
        Build the agent workflow using a state graph.
        """
        builder = StateGraph(DocumentLayoutParsingState)

        # Add nodes for image extraction and layout item detection
        builder.add_node("get_images", self.get_images)
        builder.add_node("find_layout_items", self.find_layout_items)
        # Define the flow of the graph
        builder.add_edge(START, "get_images")
        builder.add_conditional_edges("get_images", self.continue_to_find_layout_items)
        builder.add_edge("find_layout_items", END)

        self.graph = builder.compile()
```

è¦åœ¨ä¸€ä¸ªæ ·æœ¬PDFä¸Šè¿è¡Œä»£ç†ï¼Œæˆ‘ä»¬éœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```py
if __name__ == "__main__":
    _state = DocumentLayoutParsingState(
        document_path="path/to/document.pdf"
    )
    agent = DocumentParsingAgent()

    # Step 1: Extract images from PDF
    result_images = agent.get_images(_state)
    _state.pages_as_base64_jpeg_images = result_images["pages_as_base64_jpeg_images"]

    # Step 2: Process the first page (as an example)
    result_layout = agent.find_layout_items(
        FindLayoutItemsInput(
            base64_jpeg=_state.pages_as_base64_jpeg_images[0],
            page_number=0,
            document_path=_state.document_path,
        )
    )
    # Display the results
    for item in result_layout["documents"]:
        print(item.page_content)
        print(item.metadata["element_type"]) 
```

è¿™å°†ç”Ÿæˆä¸€ä¸ªè§£æã€åˆ†æ®µå’Œæ€»ç»“åçš„PDFè¡¨ç¤ºï¼Œå®ƒæ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥è¦æ„å»ºçš„ç¬¬äºŒä¸ªä»£ç†çš„è¾“å…¥ã€‚

## RAGä»£ç†

è¿™ä¸ªç¬¬äºŒä¸ªä»£ç†è´Ÿè´£ç´¢å¼•å’Œæ£€ç´¢éƒ¨åˆ†ã€‚å®ƒå°†å‰ä¸€ä¸ªä»£ç†çš„æ–‡æ¡£ä¿å­˜åˆ°å‘é‡æ•°æ®åº“ä¸­ï¼Œå¹¶ä½¿ç”¨ç»“æœè¿›è¡Œæ£€ç´¢ã€‚è¿™å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„æ­¥éª¤ï¼Œç´¢å¼•å’Œæ£€ç´¢ã€‚

**æ­¥éª¤ 1ï¼šç´¢å¼•æ‹†åˆ†æ–‡æ¡£**

ä½¿ç”¨ç”Ÿæˆçš„æ€»ç»“ï¼Œæˆ‘ä»¬å°†å®ƒä»¬å‘é‡åŒ–å¹¶ä¿å­˜åˆ°ChromaDBæ•°æ®åº“ä¸­ï¼š

```py
class DocumentRAGAgent:
    def index_documents(self, state: DocumentRAGState):
        """
        Index the parsed documents into the vector store.
        """
        assert state.documents, "Documents should have at least one element"
        # Check if the document is already indexed
        if self.vector_store.get(where={"document_path": state.document_path})["ids"]:
            logger.info(
                "Documents for this file are already indexed, exiting this node"
            )
            return  # Skip indexing if already done
        # Add parsed documents to the vector store
        self.vector_store.add_documents(state.documents)
        logger.info(f"Indexed {len(state.documents)} documents for {state.document_path}")
```

`index_documents`æ–¹æ³•å°†ç‰‡æ®µæ€»ç»“åµŒå…¥åˆ°å‘é‡å­˜å‚¨ä¸­ã€‚æˆ‘ä»¬ä¿ç•™æ–‡æ¡£è·¯å¾„å’Œé¡µé¢ç¼–å·ç­‰å…ƒæ•°æ®ï¼Œä»¥å¤‡åç»­ä½¿ç”¨ã€‚

**æ­¥éª¤ 2ï¼šå¤„ç†é—®é¢˜**

å½“ç”¨æˆ·æå‡ºé—®é¢˜æ—¶ï¼Œä»£ç†ä¼šåœ¨å‘é‡å­˜å‚¨ä¸­æœç´¢æœ€ç›¸å…³çš„ç‰‡æ®µã€‚å®ƒæ£€ç´¢æ€»ç»“å’Œç›¸åº”çš„é¡µé¢å›¾åƒä»¥ä¾¿ç†è§£ä¸Šä¸‹æ–‡ã€‚

```py
class DocumentRAGAgent:
    def answer_question(self, state: DocumentRAGState):
        """
        Retrieve relevant chunks and generate a response to the user's question.
        """
        # Retrieve the top-k relevant documents based on the query
        relevant_documents: list[Document] = self.retriever.invoke(state.question)

        # Retrieve corresponding page images (avoid duplicates)
        images = list(
            set(
                [
                    state.pages_as_base64_jpeg_images[doc.metadata["page_number"]]
                    for doc in relevant_documents
                ]
            )
        )
        logger.info(f"Responding to question: {state.question}")
        # Construct the prompt: Combine images, relevant summaries, and the question
        messages = (
            [{"mime_type": "image/jpeg", "data": base64_jpeg} for base64_jpeg in images]
            + [doc.page_content for doc in relevant_documents]
            + [
                f"Answer this question using the context images and text elements only: {state.question}",
            ]
        )
        # Generate the response using the LLM
        response = self.model.generate_content(messages)
        return {"response": response.text, "relevant_documents": relevant_documents}
```

æ£€ç´¢å™¨æŸ¥è¯¢å‘é‡å­˜å‚¨ä»¥æŸ¥æ‰¾ä¸ç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„ç‰‡æ®µã€‚ç„¶åæˆ‘ä»¬ä¸ºLLMï¼ˆGeminiï¼‰æ„å»ºä¸Šä¸‹æ–‡ï¼Œç»“åˆæ–‡æœ¬ç‰‡æ®µå’Œå›¾åƒä»¥ç”Ÿæˆå›åº”ã€‚

**å®Œæ•´ä»£ç†å·¥ä½œæµç¨‹**

ä»£ç†çš„å·¥ä½œæµç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼Œä¸€ä¸ªæ˜¯ç´¢å¼•é˜¶æ®µï¼Œå¦ä¸€ä¸ªæ˜¯é—®ç­”é˜¶æ®µï¼š

```py
class DocumentRAGAgent:
    def build_agent(self):
        """
        Build the RAG agent workflow.
        """
        builder = StateGraph(DocumentRAGState)
        # Add nodes for indexing and answering questions
        builder.add_node("index_documents", self.index_documents)
        builder.add_node("answer_question", self.answer_question)
        # Define the workflow
        builder.add_edge(START, "index_documents")
        builder.add_edge("index_documents", "answer_question")
        builder.add_edge("answer_question", END)
        self.graph = builder.compile()
```

**ç¤ºä¾‹è¿è¡Œ**

```py
if __name__ == "__main__":
    from pathlib import Path

  # Import the first agent to parse the document
    from document_ai_agents.document_parsing_agent import (
        DocumentLayoutParsingState,
        DocumentParsingAgent,
    )
    # Step 1: Parse the document using the first agent
    state1 = DocumentLayoutParsingState(
        document_path=str(Path(__file__).parents[1] / "data" / "docs.pdf")
    )
    agent1 = DocumentParsingAgent()
    result1 = agent1.graph.invoke(state1)
    # Step 2: Set up the second agent for retrieval and answering
    state2 = DocumentRAGState(
        question="Who was acknowledged in this paper?",
        document_path=str(Path(__file__).parents[1] / "data" / "docs.pdf"),
        pages_as_base64_jpeg_images=result1["pages_as_base64_jpeg_images"],
        documents=result1["documents"],
    )
    agent2 = DocumentRAGAgent()
    # Index the documents
    agent2.graph.invoke(state2)
    # Answer the first question
    result2 = agent2.graph.invoke(state2)
    print(result2["response"])
    # Answer a second question
    state3 = DocumentRAGState(
        question="What is the macro average when fine-tuning on PubLayNet using M-RCNN?",
        document_path=str(Path(__file__).parents[1] / "data" / "docs.pdf"),
        pages_as_base64_jpeg_images=result1["pages_as_base64_jpeg_images"],
        documents=result1["documents"],
    )
    result3 = agent2.graph.invoke(state3)
    print(result3["response"])
```

é€šè¿‡æ­¤å®ç°ï¼Œç®¡é“å®Œæˆäº†æ–‡æ¡£å¤„ç†ã€æ£€ç´¢å’Œé—®ç­”åŠŸèƒ½ã€‚

# ç¤ºä¾‹ï¼šä½¿ç”¨æ–‡æ¡£AIç®¡é“

è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå®é™…ç¤ºä¾‹æ¥æ“ä½œï¼Œä½¿ç”¨æ–‡æ¡£[LLM & Adaptation.pdf](https://github.com/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Slides/Chapter_05_Natural_Language_Processing/04-LLM%26Adaptation/LLM%20%26%20Adaptation.pdf)ï¼Œå®ƒåŒ…å«39é¡µå¹»ç¯ç‰‡ï¼ŒåŒ…å«æ–‡æœ¬ã€å…¬å¼å’Œå›¾å½¢ï¼ˆCC BY 4.0ï¼‰ã€‚

## ç¬¬1æ­¥ï¼šè§£æå’Œæ€»ç»“æ–‡æ¡£ï¼ˆä»£ç†1ï¼‰

+   **æ‰§è¡Œæ—¶é—´**ï¼šè§£æ39é¡µæ–‡æ¡£èŠ±è´¹äº†**29ç§’**ã€‚

+   **ç»“æœ**ï¼šä»£ç†1ç”Ÿæˆäº†ä¸€ä¸ªç´¢å¼•æ–‡æ¡£ï¼Œå…¶ä¸­åŒ…å«æ¯é¡µçš„æ‘˜è¦å’ŒBase64ç¼–ç çš„JPEGå›¾ç‰‡ã€‚

## ç¬¬2æ­¥ï¼šè´¨ç–‘æ–‡æ¡£ï¼ˆä»£ç†2ï¼‰

æˆ‘ä»¬æå‡ºäº†ä»¥ä¸‹é—®é¢˜ï¼š

**â€œ**è§£é‡ŠLoRAï¼Œç»™å‡ºç›¸å…³çš„å…¬å¼**â€**

## ç»“æœï¼š

æ£€ç´¢çš„é¡µé¢ï¼š

![](../Images/a96c96db2579443f470a142aa9c9d1a7.png)

æ¥æºï¼š[LLM & Adaptation.pdf](https://github.com/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Slides/Chapter_05_Natural_Language_Processing/04-LLM%26Adaptation/LLM%20%26%20Adaptation.pdf) è®¸å¯è¯ CC-BY

## æ¥è‡ªLLMçš„å›åº”

![](../Images/4af2dc191f5a778641c7a0e0c0b2fcb8.png)

å›¾ç‰‡æ¥æºï¼šä½œè€…ã€‚

LLMèƒ½å¤Ÿé€šè¿‡åˆ©ç”¨ç”Ÿæˆè¿è´¯ä¸”æ­£ç¡®å›åº”çš„è§†è§‰ä¸Šä¸‹æ–‡ï¼Œå°†å…¬å¼å’Œå›¾å½¢çº³å…¥å…¶å›åº”ä¸­ã€‚

# ç»“è®º

åœ¨è¿™ä¸ªç®€çŸ­çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•é€šè¿‡åˆ©ç”¨è¿‘æœŸLLMsçš„å¤šæ¨¡æ€æ€§ï¼Œè¿›ä¸€æ­¥æ¨è¿›ä½ çš„æ–‡æ¡£AIå¤„ç†æµç¨‹ï¼Œå¹¶åˆ©ç”¨æ¯ä¸ªæ–‡æ¡£ä¸­çš„å®Œæ•´è§†è§‰ä¸Šä¸‹æ–‡ï¼Œæ¥æå‡ä½ ä»ä¿¡æ¯æå–æˆ–RAGæµç¨‹ä¸­è·å¾—çš„è¾“å‡ºè´¨é‡ã€‚

æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ›´å¼ºå¤§çš„æ–‡æ¡£åˆ†å‰²æ­¥éª¤ï¼Œèƒ½å¤Ÿæ£€æµ‹åˆ°é‡è¦çš„é¡¹ç›®ï¼Œå¦‚æ®µè½ã€è¡¨æ ¼å’Œå›¾å½¢ï¼Œå¹¶å¯¹å…¶è¿›è¡Œæ€»ç»“ï¼Œéšåä½¿ç”¨è¿™ä¸€ç¬¬ä¸€æ­¥çš„ç»“æœæ¥æŸ¥è¯¢é¡¹ç›®å’Œé¡µé¢é›†åˆï¼Œåˆ©ç”¨Geminiç»™å‡ºç›¸å…³ä¸”ç²¾å‡†çš„ç­”æ¡ˆã€‚ä½œä¸ºä¸‹ä¸€æ­¥ï¼Œä½ å¯ä»¥åœ¨ä½ çš„ä½¿ç”¨æ¡ˆä¾‹å’Œæ–‡æ¡£ä¸Šå°è¯•ï¼Œè¯•ç€ä½¿ç”¨ä¸€ä¸ªå¯æ‰©å±•çš„å‘é‡æ•°æ®åº“ï¼Œå¹¶å°†è¿™äº›ä»£ç†éƒ¨ç½²ä¸ºä½ AIåº”ç”¨çš„ä¸€éƒ¨åˆ†ã€‚

å®Œæ•´ä»£ç å’Œç¤ºä¾‹è¯·å‚è§ï¼š[https://github.com/CVxTz/document_ai_agents](https://github.com/CVxTz/document_ai_agents)

æ„Ÿè°¢é˜…è¯»ï¼ğŸ˜ƒ
