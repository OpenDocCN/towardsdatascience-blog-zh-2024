- en: Exploring the Latest Advances in Foundation Time-Series Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/exploring-the-latest-advances-in-foundation-time-series-models-3fc8431ab7bd?source=collection_archive---------1-----------------------#2024-07-17](https://towardsdatascience.com/exploring-the-latest-advances-in-foundation-time-series-models-3fc8431ab7bd?source=collection_archive---------1-----------------------#2024-07-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fast and accurate forecasting of new data — without training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)[![Nikos
    Kafritsas](../Images/de965cfcd8fbd8e1baf849017d365cbb.png)](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)
    [Nikos Kafritsas](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)
    ·8 min read·Jul 17, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5e26a78575698dd1a34f917967ce67c7.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Join* [*AI Horizon Forecast*](https://aihorizonforecast.substack.com/subscribe)*,
    a blog making complex AI topics as clear as daylight.*'
  prefs: []
  type: TYPE_NORMAL
- en: Recent advances in foundation time-series models are groundbreaking.
  prefs: []
  type: TYPE_NORMAL
- en: TimeGPT was the first native foundation model. It was released this past August
    and shook the forecasting community.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since then, numerous other foundation models have been released, including:'
  prefs: []
  type: TYPE_NORMAL
- en: TimesFM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MOIRAI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tiny Time Mixers (TTM)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MOMENT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ve covered these models in previous articles, but they’ve had many updates
    since their initial release.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll explore these updates — which include new benchmarks
    and improved model variants.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: TimesFM — Google’s Foundation model [1]
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**New updates:** The model weights were recently released on Hugging Face!
    You can find a project tutorial for TimesFM on the [***AI Projects folder***](https://aihorizonforecast.substack.com/p/ai-projects)***!***'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Google entered the race of foundation models with *TimesFM*, a 200 million parameter
    model.
  prefs: []
  type: TYPE_NORMAL
