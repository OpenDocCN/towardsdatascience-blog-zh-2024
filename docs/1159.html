<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Apache Hadoop and Apache Spark for Big Data Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Apache Hadoop and Apache Spark for Big Data Analysis</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-hadoop-and-apache-spark-for-big-data-analysis-daaf659fd0ee?source=collection_archive---------5-----------------------#2024-05-08">https://towardsdatascience.com/apache-hadoop-and-apache-spark-for-big-data-analysis-daaf659fd0ee?source=collection_archive---------5-----------------------#2024-05-08</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="11e0" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A complete guide to big data analysis using Apache Hadoop (HDFS) and PySpark library in Python on game reviews on the Steam gaming platform.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@rindhuj1?source=post_page---byline--daaf659fd0ee--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Rindhuja Treesa Johnson" class="l ep by dd de cx" src="../Images/15d2bfb802395968ea23faff62cc623a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*ghRJwyYZIQ7N8bjGhJ8CHg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--daaf659fd0ee--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@rindhuj1?source=post_page---byline--daaf659fd0ee--------------------------------" rel="noopener follow">Rindhuja Treesa Johnson</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--daaf659fd0ee--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 8, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="8162" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk nf"><span class="l ng nh ni bo nj nk nl nm nn ed">W</span>ith over 100 zettabytes (= 10¹²GB) of <a class="af no" href="https://www.statista.com/statistics/871513/worldwide-data-created/" rel="noopener ugc nofollow" target="_blank">data produced every year</a> around the world, the significance of handling big data is one of the most required skills today. Data Analysis, itself, could be defined as the ability to handle big data and derive insights from the never-ending and exponentially growing data. Apache Hadoop and Apache Spark are two of the basic tools that help us untangle the limitless possibilities hidden in large datasets. <a class="af no" href="https://hadoop.apache.org/" rel="noopener ugc nofollow" target="_blank">Apache Hadoop</a> enables us to streamline data storage and distributed computing with its Distributed File System (HDFS) and the MapReduce-based parallel processing of data. <a class="af no" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">Apache Spark</a> is a big data analytics engine capable of EDA, SQL analytics, Streaming, Machine Learning, and Graph processing compatible with the major programming languages through its APIs. Both when combined form an exceptional environment for dealing with big data with the available computational resources — just a personal computer in most cases!</p><p id="c122" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let us unfold the power of <a class="af no" href="https://medium.com/@roshmitadey/a-beginners-guide-to-big-data-and-hadoop-distributed-file-system-hdfs-b5c324d3c722" rel="noopener">Big Data and Apache Hadoop</a> with a simple analysis project implemented using Apache Spark in Python.</p><p id="54bb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To begin with, let’s dive into the installation of Hadoop Distributed File System and Apache Spark on a MacOS. I am using a MacBook Air with macOS Sonoma with an M1 chip.</p><p id="d91c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Jump to the section —</strong></p><ol class=""><li id="0e92" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne np nq nr bk"><a class="af no" href="#b292" rel="noopener ugc nofollow">Installing Hadoop Distributed File System</a></li><li id="7117" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne np nq nr bk"><a class="af no" href="#2773" rel="noopener ugc nofollow">Installing Apache Spark</a></li><li id="c34d" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne np nq nr bk"><a class="af no" href="#32ea" rel="noopener ugc nofollow">Steam Review Analysis using PySpark</a></li><li id="9c6b" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne np nq nr bk"><a class="af no" href="#2580" rel="noopener ugc nofollow">What next?</a></li></ol><h2 id="b292" class="nx ny fq bf nz oa ob oc od oe of og oh ms oi oj ok mw ol om on na oo op oq or bk">1. Installing Hadoop Distributed File System</h2><p id="ea80" class="pw-post-body-paragraph mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne fj bk">Thanks to <span class="ia"><span class="ia" aria-hidden="false"><a class="ox ib oy" href="https://medium.com/u/bdd6bb8fb77f?source=post_page---user_mention--daaf659fd0ee--------------------------------" rel="noopener" target="_blank">Code With Arjun</a></span></span> for the amazing article that helped me with the <a class="af no" href="https://codewitharjun.medium.com/install-hadoop-on-macos-efe7c860c3ed" rel="noopener">installation of Hadoop on my Mac</a>. I seamlessly installed and ran Hadoop following his steps which I will show you here as well.</p><ol class=""><li id="6ad3" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne np nq nr bk"><strong class="ml fr">a. Installing HomeBrew</strong></li></ol><p id="101c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">I use <a class="af no" href="https://brew.sh/" rel="noopener ugc nofollow" target="_blank">Homebrew</a> for installing applications on my Mac for ease. It can be directly installed on the system with the below code —</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="80aa" class="pi ny fq pf b bg pj pk l pl pm">/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"</span></pre><p id="5cc5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Once it is installed, you can run the simple code below to verify the installation.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="a941" class="pi ny fq pf b bg pj pk l pl pm">brew --version</span></pre><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po pp"><img src="../Images/c0f0f02df5fc0a74936bb9fba42d896e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FjfL-ZrdYH6MDnvKRBpeIg.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 1: Image by Author</figcaption></figure><p id="497a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">However, you will likely encounter an error saying, <code class="cx qb qc qd pf b">command not found</code>, this is because the homebrew will be installed in a different location (Figure 2) and it is not executable from the current directory. For it to function, we add a path environment variable for the brew, i.e., adding homebrew to the .bash_profile.</p><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po pp"><img src="../Images/594e71aa1c71a70fe1615dba45a9b210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LigK8ZgNLAvLf9_CuMPh1Q.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 2: Image by Author</figcaption></figure><blockquote class="qe qf qg"><p id="0e66" class="mj mk qh ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">You can avoid this step by using the full path to Homebrew in your commands, however, it might become a hustle at later stages, so not recommended!</p></blockquote><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="ca50" class="pi ny fq pf b bg pj pk l pl pm">echo ‘eval “$(/opt/homebrew/bin/brew shellenv)”’ &gt;&gt; /Users/rindhujajohnson/.bash_profile<br/><br/>eval “$(/opt/homebrew/bin/brew shellenv)”</span></pre><p id="c185" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now, when you try, <code class="cx qb qc qd pf b">brew --version</code>, it should show the Homebrew version correctly.</p><ol class=""><li id="80c7" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne np nq nr bk"><strong class="ml fr">b. Installing Hadoop</strong></li></ol><blockquote class="qe qf qg"><p id="f4aa" class="mj mk qh ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Disclaimer! Hadoop is a Java-based application and is supported by a Java Development Kit (JDK) version older than 11, preferably 8 or 11. Install JDK before continuing.</p></blockquote><p id="981f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Thanks to <span class="ia"><span class="ia" aria-hidden="false"><a class="ox ib oy" href="https://medium.com/u/bdd6bb8fb77f?source=post_page---user_mention--daaf659fd0ee--------------------------------" rel="noopener" target="_blank">Code With Arjun</a></span></span> again for this video on JDK installation on MacBook M1.</p><figure class="oz pa pb pc pd pq"><div class="qi io l ed"><div class="qj qk l"/></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Guide to Installing JDK</figcaption></figure><p id="32d3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now, we install the Hadoop on our system using the brew command.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="d937" class="pi ny fq pf b bg pj pk l pl pm">brew install hadoop</span></pre><p id="9d01" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This command should install Hadoop seamlessly. Similar to the steps followed while installing HomeBrew, we should edit the path environment variable for Java in the Hadoop folder. The environment variable settings for the installed version of Hadoop can be found in the Hadoop folder within HomeBrew. You can use <code class="cx qb qc qd pf b">which hadoop</code> command to find the location of the Hadoop installation folder. Once you locate the folder, you can find the variable settings at the below location. The below command takes you to the required folder for editing the variable settings (Check the Hadoop version you installed to avoid errors).</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="a25b" class="pi ny fq pf b bg pj pk l pl pm">cd /opt/homebrew/Cellar/hadoop/3.3.6/libexec/etc/hadoop</span></pre><p id="3ef2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">You can view the files in this folder using the <code class="cx qb qc qd pf b">ls</code> command. We will edit the <code class="cx qb qc qd pf b">hadoop-env.sh</code> to enable the proper running of Hadoop on the system.</p><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po ql"><img src="../Images/c9433c954e59f2cbaaf96c35b2a1fcac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hkxWGrBuLWcJ9P07_UAkA.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 3: Image by Author</figcaption></figure><p id="3a03" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now, we have to find the path variable for Java to edit the <code class="cx qb qc qd pf b">hadoop-ev.sh</code> file using the following command.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="c921" class="pi ny fq pf b bg pj pk l pl pm">/usr/libexec/java_home</span></pre><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po qm"><img src="../Images/e3082e79171b59a742c2462151b8efa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2rrmrNuUMw1yumyMVXtj4Q.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 4: Image by Author</figcaption></figure><p id="4923" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We can open the <code class="cx qb qc qd pf b">hadoop-env.sh</code> file in any text editor. I used VI editor, you can use any editor for the purpose. We can copy and paste the path — <code class="cx qb qc qd pf b">Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home</code> at the <code class="cx qb qc qd pf b">export JAVA_HOME = </code>position.</p><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po qn"><img src="../Images/bbeff2e0db5eba54d035987932f6209a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RgVd6L0hM2Ho0eRnhkHstw.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 5: hadoop-env.sh file opened in VI Text Editor</figcaption></figure><p id="a54d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Next, we edit the four XML files in the Hadoop folder.</p><p id="a8b9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><code class="cx qb qc qd pf b">core-site.xml</code></p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="d51e" class="pi ny fq pf b bg pj pk l pl pm">&lt;configuration&gt;<br/> &lt;property&gt;<br/>  &lt;name&gt;fs.defaultFS&lt;/name&gt;<br/>  &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;<br/> &lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><p id="2ce1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><code class="cx qb qc qd pf b">hdfs-site.xml</code></p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="bb7a" class="pi ny fq pf b bg pj pk l pl pm">&lt;configuration&gt;<br/>  &lt;property&gt;<br/>    &lt;name&gt;dfs.replication&lt;/name&gt;<br/>    &lt;value&gt;1&lt;/value&gt;<br/>  &lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><p id="b792" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><code class="cx qb qc qd pf b">mapred-site.xml</code></p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="3404" class="pi ny fq pf b bg pj pk l pl pm">&lt;configuration&gt;<br/>    &lt;property&gt;<br/>       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br/>       &lt;value&gt;yarn&lt;/value&gt;<br/>    &lt;/property&gt;<br/>    &lt;property&gt;<br/>    &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;   <br/>  &lt;value&gt;<br/>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<br/>  &lt;/value&gt;<br/>    &lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><p id="3199" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><code class="cx qb qc qd pf b">yarn-site.xml</code></p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="9e8a" class="pi ny fq pf b bg pj pk l pl pm">&lt;configuration&gt;<br/>  &lt;property&gt;<br/>    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br/>    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br/>  &lt;/property&gt;<br/>  &lt;property&gt;<br/>    &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;  <br/>   &lt;value&gt;<br/>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<br/>  &lt;/value&gt;<br/>  &lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><p id="6ee4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">With this, we have successfully completed the installation and configuration of HDFS on the local. To make the data on Hadoop accessible with Remote login, we can go to Sharing in the General settings and enable <code class="cx qb qc qd pf b">Remote Login</code>. You can edit the user access by clicking on the info icon.</p><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po qo"><img src="../Images/b09bae4523e0679b1275c841247e5aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ufkqaHD_olfKCkkD9aSoFg.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 6: Enable Remote Access. Image by Author</figcaption></figure><p id="28fb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let’s run Hadoop!</p><p id="5ad1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Execute the following commands</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="4bad" class="pi ny fq pf b bg pj pk l pl pm">hadoop namenode -format </span></pre><pre class="qp pe pf pg bp ph bb bk"><span id="c20f" class="pi ny fq pf b bg pj pk l pl pm"># starts the Hadoop environment<br/>% start-all.sh <br/><br/># Gathers all the nodes functioning to ensure that the installation was successful<br/>% jps </span></pre><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po qq"><img src="../Images/fb2fa78c2639a628f5ee27da07acfa27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pBp4NAeNVOhP24uVLmY7MQ.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 7: Initiating Hadoop and viewing the nodes and resources running. Image by Author</figcaption></figure><p id="43ab" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We are all set! Now let’s create a directory in HDFS and add the data will be working on. Let’s quickly take a look at our data source and details.</p><p id="0903" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Data</strong></p><p id="b1e1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The <a class="af no" href="https://www.kaggle.com/datasets/najzeko/steam-reviews-2021" rel="noopener ugc nofollow" target="_blank">Steam Reviews Dataset 2021</a> <strong class="ml fr"><em class="qh">(</em></strong><a class="af no" href="https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html" rel="noopener ugc nofollow" target="_blank"><strong class="ml fr"><em class="qh">License: GPL 2</em></strong></a><strong class="ml fr"><em class="qh">)</em></strong> is a collection of reviews from about 21 million gamers covering over 300 different games in the year 2021. the data is extracted using Steam’s API — <a class="af no" href="https://partner.steamgames.com/doc/store/getreviews" rel="noopener ugc nofollow" target="_blank">Steamworks </a>— using the Get List function.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="b253" class="pi ny fq pf b bg pj pk l pl pm">GET store.steampowered.com/appreviews/&lt;appid&gt;?json=1</span></pre><p id="c12a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The dataset consists of 23 columns and 21.7 million rows with a size of 8.17 GB (that is big!). The data consists of reviews in different languages and a boolean column that tells if the player recommends the game to other players. We will be focusing on how to handle this big data locally using HDFS and analyze it using Apache Spark in Python using the PySpark library.</p><ol class=""><li id="5f49" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne np nq nr bk"><strong class="ml fr">c. Uploading Data into HDFS</strong></li></ol><p id="128c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Firstly, we create a directory in the HDFS using the <code class="cx qb qc qd pf b">mkdir</code> command. <em class="qh">It will throw an error if we try to add a file directly to a non-existing folder.</em></p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="2fbc" class="pi ny fq pf b bg pj pk l pl pm">hadoop fs -mkdir /user<br/>hadoop fs -mkdir /user/steam_analysis</span></pre><p id="542a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now, we will add the data file to the folder <code class="cx qb qc qd pf b">steam_analysis</code> using the <code class="cx qb qc qd pf b">put</code> command.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="96ca" class="pi ny fq pf b bg pj pk l pl pm">hadoop fs -put /Users/rindhujajohnson/local_file_path/steam_reviews.csv /user/steam_analysis</span></pre><p id="9718" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Apache Hadoop also uses a user interface available at <a class="af no" href="http://localhost:9870/" rel="noopener ugc nofollow" target="_blank">http://localhost:9870/</a>.</p><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po qr"><img src="../Images/a158c45d8a4f833962c62d1c16d19215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I7LZIT_hzg1qRqQx"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 8: HDFS User Interface at localhost:9870. Image by Author</figcaption></figure><p id="0eca" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We can see the uploaded files as shown below.</p><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po qr"><img src="../Images/b57932add5847d2cf0d9f63a7bfad1cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7mm7QT2VbU1GJwuK"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 10: Navigating files in HDFS. Image by Author</figcaption></figure><p id="a59e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Once the data interaction is over, we can use <code class="cx qb qc qd pf b">stop-all.sh</code> command to stop all the Apache Hadoop daemons.</p><p id="0167" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let us move to the next step — Installing Apache Spark</p><h2 id="2773" class="nx ny fq bf nz oa ob oc od oe of og oh ms oi oj ok mw ol om on na oo op oq or bk">2. Installing Apache Spark</h2><p id="5d72" class="pw-post-body-paragraph mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne fj bk">Apache Hadoop takes care of data storage (HDFS) and parallel processing (MapReduce) of the data for faster execution. <a class="af no" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">Apache Spark</a> is a multi-language compatible analytical engine designed to deal with big data analysis. We will run the Apache Spark on Python in Jupyter IDE.</p><p id="cfa6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">After installing and running HDFS, the installation of Apache Spark for Python is a piece of cake. PySpark is the Python API for Apache Spark that can be installed using the <code class="cx qb qc qd pf b">pip</code> method in the Jupyter Notebook. PySpark is the Spark Core API with its four components — Spark SQL, Spark ML Library, Spark Streaming, and GraphX. Moreover, we can access the Hadoop files through PySpark by initializing the installation with the required Hadoop version.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="97d0" class="pi ny fq pf b bg pj pk l pl pm"># By default, the Hadoop version considered will be 3 here.<br/>PYSPARK_HADOOP_VERSION=3 pip install pyspark</span></pre><p id="b91b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let’s get started with the Big Data Analytics!</p><h2 id="32ea" class="nx ny fq bf nz oa ob oc od oe of og oh ms oi oj ok mw ol om on na oo op oq or bk">3. Steam Review Analysis using PySpark</h2><p id="34c1" class="pw-post-body-paragraph mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne fj bk"><a class="af no" href="https://store.steampowered.com/about/" rel="noopener ugc nofollow" target="_blank">Steam</a> is an online gaming platform that hosts over 30,000 games streaming across the world with over 100 million players. Besides gaming, the platform allows the players to provide reviews for the games they play, a great resource for the platform to improve customer experience and for the gaming companies to work on to keep the players on edge. We used this review data provided by the platform publicly available on <a class="af no" href="https://www.kaggle.com/datasets/najzeko/steam-reviews-2021" rel="noopener ugc nofollow" target="_blank">Kaggle</a>.</p><p id="b456" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">3. a. Data Extraction from HDFS</strong></p><p id="7e98" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We will use the PySpark library to access, clean, and analyze the data. To start, we connect the PySpark session to Hadoop using the local host address.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="a1f2" class="pi ny fq pf b bg pj pk l pl pm">from pyspark.sql import SparkSession<br/>from pyspark.sql.functions import *<br/><br/># Initializing the Spark Session<br/>spark = SparkSession.builder.appName("SteamReviewAnalysis").master("yarn").getOrCreate()<br/><br/># Providing the url for accessing the HDFS<br/>data = "hdfs://localhost:9000/user/steam_analysis/steam_reviews.csv"<br/><br/># Extracting the CSV data in the form of a Schema<br/>data_csv = spark.read.csv(data, inferSchema = True, header = True)<br/><br/># Visualize the structure of the Schema<br/>data_csv.printSchema()<br/><br/># Counting the number of rows in the dataset<br/>data_csv.count() # 40,848,659</span></pre><p id="045b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">3. b. Data Cleaning and Pre-Processing</strong></p><p id="f189" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We can start by taking a look at the dataset. Similar to the pandas.head() function in Pandas, PySpark has the SparkSession.show() function that gives a glimpse of the dataset.</p><p id="1f71" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Before that, we will remove the reviews column in the dataset as we do not plan on performing any NLP on the dataset. Also, the reviews are in different languages making any sentiment analysis based on the review difficult.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="53af" class="pi ny fq pf b bg pj pk l pl pm"># Dropping the review column and saving the data into a new variable<br/>data = data_csv.drop("review")<br/><br/># Displaying the data<br/>data.show() </span></pre><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po qs"><img src="../Images/52636915bc9dc3c68b59c2d3238eeb54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1gWbobi0q9jhYvYZb7xzSA.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 11: The Structure of the Schema</figcaption></figure><p id="c712" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We have a huge dataset with us with 23 attributes with NULL values for different attributes which does not make sense to consider any imputation. Therefore, I have removed the records with NULL values. However, this is not a recommended approach. You can evaluate the importance of the available attributes and remove the irrelevant ones, then try imputing data points to the NULL values.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="eff2" class="pi ny fq pf b bg pj pk l pl pm"># Drops all the records with NULL values<br/>data = data.na.drop(how = "any")<br/><br/># Count the number of records in the remaining dataset<br/>data.count() # 16,876,852</span></pre><p id="588c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We still have almost 17 million records in the dataset!</p><p id="615f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now, we focus on the variable names of the dataset as in Figure 11. We can see that the attributes have a few characters like dot(.) that are unacceptable as Python identifiers. Also, we change the data type of the date and time attributes. So we change these using the following code —</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="b1a3" class="pi ny fq pf b bg pj pk l pl pm">from pyspark.sql.types import *<br/>from pyspark.sql.functions import from_unixtime<br/><br/># Changing the data type of each columns into appropriate types<br/>data = data.withColumn("app_id",data["app_id"].cast(IntegerType())).\<br/>            withColumn("author_steamid", data["author_steamid"].cast(LongType())).\<br/>            withColumn("recommended", data["recommended"].cast(BooleanType())).\<br/>            withColumn("steam_purchase", data["steam_purchase"].cast(BooleanType())).\<br/>            withColumn("author_num_games_owned", data["author_num_games_owned"].cast(IntegerType())).\<br/>            withColumn("author_num_reviews", data["author_num_reviews"].cast(IntegerType())).\<br/>            withColumn("author_playtime_forever", data["author_playtime_forever"].cast(FloatType())).\<br/>            withColumn("author_playtime_at_review", data["author_playtime_at_review"].cast(FloatType()))<br/><br/># Converting the time columns into timestamp data type<br/>data = data.withColumn("timestamp_created", from_unixtime("timestamp_created").cast("timestamp")).\<br/>            withColumn("author_last_played", from_unixtime(data["author_last_played"]).cast(TimestampType())).\<br/>            withColumn("timestamp_updated", from_unixtime(data["timestamp_updated"]).cast(TimestampType()))</span></pre><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po qt"><img src="../Images/a42764009ddbe5123c2a75a7f5cf4e0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0IdNbwBKxO6K_u4Qc621WQ.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 12: A glimpse of the Steam review Analysis dataset. Image by Author</figcaption></figure><p id="e696" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The dataset is clean and ready for analysis!</p><p id="8cac" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">3. c. Exploratory Data Analysis</strong></p><p id="b09f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The dataset is rich in information with over 20 variables. We can analyze the data from different perspectives. Therefore, we will be splitting the data into different PySpark data frames and caching them to run the analysis faster.</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="4ed2" class="pi ny fq pf b bg pj pk l pl pm"># Grouping the columns for each analysis<br/>col_demo = ["app_id", "app_name", "review_id", "language", "author_steamid", "timestamp_created" ,"author_playtime_forever","recommended"]<br/>col_author = ["steam_purchase", 'author_steamid', "author_num_games_owned", "author_num_reviews", "author_playtime_forever", "author_playtime_at_review", "author_last_played","recommended"]<br/>col_time = [ "app_id", "app_name", "timestamp_created", "timestamp_updated", 'author_playtime_at_review', "recommended"]<br/>col_rev = [ "app_id", "app_name", "language", "recommended"]<br/>col_rec = ["app_id", "app_name", "recommended"]<br/><br/># Creating new pyspark data frames using the grouped columns<br/>data_demo = data.select(*col_demo)<br/>data_author = data.select(*col_author)<br/>data_time = data.select(*col_time)<br/>data_rev = data.select(*col_rev)<br/>data_rec = data.select(*col_rec)<br/></span></pre><p id="468d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr"><em class="qh">i. Games Analysis</em></strong></p><p id="b8ce" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this section, we will try to understand the review and recommendation patterns for different games. We will consider the <em class="qh">number of reviews</em> analogous to the popularity of the game and the <em class="qh">number of </em><strong class="ml fr"><em class="qh">True</em></strong><em class="qh"> recommendations</em> analogous to the gamer’s preference for the game.</p><ul class=""><li id="bd59" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qu nq nr bk">Finding the Most Popular Games</li></ul><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="d7ff" class="pi ny fq pf b bg pj pk l pl pm"># the data frame is grouped by the game and the number of occurrences are counted<br/>app_names = data_rec.groupBy("app_name").count()<br/><br/># the data frame is ordered depending on the count for the highest 20 games<br/>app_names_count = app_names.orderBy(app_names["count"].desc()).limit(20)<br/><br/># a pandas data frame is created for plotting<br/>app_counts = app_names_count.toPandas()<br/><br/># A pie chart is created<br/>fig = plt.figure(figsize = (10,5))<br/>colors = sns.color_palette("muted")<br/>explode = (0.1,0.075,0.05,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)<br/>plt.pie(x = app_counts["count"], labels = app_counts["app_name"], colors = colors,  explode = explode, shadow = True)<br/>plt.title("The Most Popular Games")<br/>plt.show()</span></pre><ul class=""><li id="06e7" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qu nq nr bk">Finding the Most Recommended Games</li></ul><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="b269" class="pi ny fq pf b bg pj pk l pl pm"># Pick the 20 highest recommended games and convert it in to pandas data frame<br/>true_counts = data_rec.filter(data_rec["recommended"] == "true").groupBy("app_name").count()<br/>recommended = true_counts.orderBy(true_counts["count"].desc()).limit(20)<br/>recommended_apps = recommended.toPandas()<br/><br/># Pick the games such that both they are in both the popular and highly recommended list<br/>true_apps = list(recommended_apps["app_name"])<br/>true_app_counts = data_rec.filter(data_rec["app_name"].isin(true_apps)).groupBy("app_name").count()<br/>true_app_counts = true_app_counts.orderBy(true_app_counts["count"].desc())<br/>true_app_counts = true_app_counts.toPandas()<br/><br/># Evaluate the percent of true recommendations for the top games and sort them<br/>true_perc = []<br/>for i in range(0,20,1):<br/>    percent = (true_app_counts["count"][i]-recommended_apps["count"][i])/true_app_counts["count"][i]*100<br/>    true_perc.append(percent)<br/>recommended_apps["recommend_perc"] = true_perc<br/>recommended_apps = recommended_apps.sort_values(by = "recommend_perc", ascending = False)<br/><br/># Built a pie chart to visualize<br/>fig = plt.figure(figsize = (10,5))<br/>colors = sns.color_palette("muted")<br/>explode = (0.1,0.075,0.05,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)<br/>plt.pie(x = recommended_apps["recommend_perc"], labels = recommended_apps["app_name"], colors = colors,  explode = explode, shadow = True)<br/>plt.title("The Most Recommended Games")<br/>plt.show()</span></pre></div></div><div class="pq"><div class="ab cb"><div class="lm qv ln qw lo qx cf qy cg qz ci bh"><div class="oz pa pb pc pd ab ke"><figure class="lb pq ra rb rc rd re paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><img src="../Images/b62fe5c6d97a4793d51ff4f7c653c876.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*bCHiglLUX0Viccv6SMuDVw.png"/></div></figure><figure class="lb pq rf rb rc rd re paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><img src="../Images/405b141436af05e056a8c5953a809287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*WpkuIpuTQmiUGvxqTLBj4g.png"/></div><figcaption class="pw px py pn po pz qa bf b bg z dx rg ed rh ri">Figure 13: Shows the pie charts for popular and recommended games. Images by Author</figcaption></figure></div></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="e2ee" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr"><em class="qh">Insights</em></strong></p><ul class=""><li id="7ec9" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qu nq nr bk">Player Unknown’s Battlegrounds (PUBG) is the most popular and most recommended game of 2021.</li><li id="88cf" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">However, the second positions for the two categories are held by Grand Theft Auto V (GTA V) and Stardew Valley respectively. This shows that being popular does not mean all the players recommend the game to another player.</li><li id="e5dc" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">The same pattern is observed with other games also. However, the number of reviews for a game significantly affects this trend.</li></ul><p id="3026" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr"><em class="qh">ii. Demographic Analysis</em></strong></p><p id="0db3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We will find the demography, especially, the locality of the gamers using the <code class="cx qb qc qd pf b">data_demo</code> data frame. This analysis will help us understand the popular languages used for review and languages used by reviewers of popular games. We can use this trend to determine the demographic influence and sentiments of the players to be used for recommending new games in the future.</p><ul class=""><li id="20dc" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qu nq nr bk">Finding Popular Review Languages</li></ul><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="f69a" class="pi ny fq pf b bg pj pk l pl pm"># We standardize the language names in the language column, then group them,<br/># Count by the groups and convert into pandas df after sorting them the count<br/>author_lang = data_demo.select(lower("language").alias("language"))<br/>    \.groupBy("language").count().orderBy(col("count").desc()).<br/>    \limit(20).toPandas()<br/><br/># Plotting a bar graph<br/>fig = plt.figure(figsize = (10,5))<br/>plt.bar(author_lang["language"], author_lang["count"])<br/>plt.xticks(rotation = 90)<br/>plt.xlabel("Popular Languages")<br/>plt.ylabel("Number of Reviews (in Millions)")<br/>plt.show()</span></pre><ul class=""><li id="bfde" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qu nq nr bk">Finding Review Languages of Popular Games</li></ul><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="60ff" class="pi ny fq pf b bg pj pk l pl pm"># We group the data frame based on the game and language and count each occurrence<br/>data_demo_new = data_demo.select(lower("language").<br/>  \alias("language"), "app_name")<br/>games_lang = data_demo_new.groupBy("app_name","language").count().orderBy(col("count").desc()).limit(100).toPandas()<br/><br/># Plot a stacked bar graph to visualize<br/>grouped_games_lang = games_lang_df.pivot(index='app_name', columns='language', values='count')<br/>grouped_games_lang.plot(kind='bar', stacked=True, figsize=(12, 6))<br/>plt.title('Count of Different App Names and Languages')<br/>plt.xlabel('App Name')<br/>plt.ylabel('Count')<br/>plt.show()</span></pre></div></div><div class="pq"><div class="ab cb"><div class="lm qv ln qw lo qx cf qy cg qz ci bh"><div class="oz pa pb pc pd ab ke"><figure class="lb pq rj rb rc rd re paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><img src="../Images/45704b3736bfb990e3200b620c4af498.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*ts-BwecMNpZmYpdHqR6cUg.png"/></div></figure><figure class="lb pq rk rb rc rd re paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><img src="../Images/da796a9979022ac0928317fb693f394f.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*ARm_v9taRuNGBj-lUP7Gkw.png"/></div><figcaption class="pw px py pn po pz qa bf b bg z dx rl ed rm ri">Figure 14: Language Popularity; Language Popularity among Popular games. Images by Author</figcaption></figure></div></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="be36" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr"><em class="qh">Insights</em></strong></p><ul class=""><li id="fde4" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qu nq nr bk">English is the most popular language used by reviewers followed by Schinese and Russian</li><li id="ac3e" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Schinese is the most widely used language for the most popular game (PUBG), whereas, English is widely used for the second most popular game (GTA V) and almost all others!</li><li id="4809" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">The popularity of a game seems to have roots in the area of origin. <a class="af no" href="https://letsuncoverhistory.blogspot.com/2023/06/History-and-The-Future-of-PubG.html" rel="noopener ugc nofollow" target="_blank">PUBG</a> is a product of a South Korean gaming company and we observe that it has the Korean language among one of the highly used.</li></ul><p id="b085" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Time, author, and review analyses are also performed on this data, however, do not give any actionable insights. Feel free to visit the <a class="af no" href="https://github.com/Rindhujatreesa/Big_Data_Processing_Projects/tree/main/Steam_Review_Analysis_with_HDFS_%26_PySpark" rel="noopener ugc nofollow" target="_blank">GitHub repository for the full project</a> documentation.</p><p id="0bc5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">3. d. Game Recommendation using Spark ML Library</strong></p><p id="8fcb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We have reached the last stage of this project, where we will implement the <a class="af no" href="https://spark.apache.org/docs/latest/ml-collaborative-filtering.html" rel="noopener ugc nofollow" target="_blank">Alternating Least Squares (ALS)</a> machine-learning algorithm from the Spark ML Library. This model utilizes the collaborative filtering technique to recommend games based on player’s behavior, i.e., the games they played before. This algorithm identifies the game selection pattern for players who play each available game on the Steam App.</p><p id="1ec5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For the algorithm to work,</p><ul class=""><li id="c6f4" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qu nq nr bk">We require three variables — the independent variable, target variable(s) — depending on the number of recommendations, here 5, and a rating variable.</li><li id="01d3" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">We encode the games and the authors to make the computation easier. We also convert the <code class="cx qb qc qd pf b">boolean</code>recommended column into a rating column with <strong class="ml fr"><em class="qh">True = 5, and False = 1.</em></strong></li><li id="5453" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Also, we will be recommending 5 new games for each played game and therefore we consider the data of the players who have played more than five for modeling the algorithm.</li></ul><p id="3085" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let’s jump to the modeling and recommending part!</p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="d09d" class="pi ny fq pf b bg pj pk l pl pm">new_pair_games = data_demo.filter(col("author_playtime_forever")&gt;=5*mean_playtime)<br/>new_pair_games = new_pair_games.filter(new_pair_games["author_steamid"]&gt;=76560000000000000).select("author_steamid","app_id", "app_name","recommended")<br/><br/># Convert author_steamid and app_id to indices, and use the recommended column for rating<br/>author_indexer = StringIndexer(inputCol="author_steamid", outputCol="author_index").fit(new_pair_games)<br/>app_indexer = StringIndexer(inputCol="app_name", outputCol="app_index").fit(new_pair_games)<br/>new_pair_games = new_pair_games.withColumn("Rating", when(col("recommended") == True, 5).otherwise(1))<br/><br/># We apply the indexing to the data frame by invoking the reduce phase function transform()<br/>new_pair = author_indexer.transform(app_indexer.transform(new_pair_games))<br/>new_pair.show()</span></pre><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po rn"><img src="../Images/84c72ca4d73022d09883d5a231ebc3bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VNp_Zd7pAqV6jBRb-ySzdw.png"/></div></div></figure><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="20f6" class="pi ny fq pf b bg pj pk l pl pm"># The reference chart for games<br/>games = new_pair.select("app_index","app_name").distinct().orderBy("app_index")</span></pre><figure class="oz pa pb pc pd pq pn po paragraph-image"><div class="pn po ro"><img src="../Images/c613673f7ba9009d76ebd17d9d48ec25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*4CKp0JU32uUBuYRJj-moww.png"/></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 16: The game list with the corresponding index for reference. Image by Author</figcaption></figure><p id="2a28" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr"><em class="qh">Implementing ALS Algorithm</em></strong></p><pre class="oz pa pb pc pd pe pf pg bp ph bb bk"><span id="1e79" class="pi ny fq pf b bg pj pk l pl pm"># Create an ALS (Alternating Least Squares) model<br/>als = ALS(maxIter=10, regParam=0.01, userCol="app_index", itemCol="author_index", ratingCol="Rating", coldStartStrategy="drop")<br/><br/># Fit the model to the data<br/>model = als.fit(new_pair)<br/><br/># Generate recommendations for all items<br/>app_recommendations = model.recommendForAllItems(5)  # Number of recommendations per item<br/><br/># Display the recommendations<br/>app_recommendations.show(truncate=False)</span></pre><figure class="oz pa pb pc pd pq pn po paragraph-image"><div role="button" tabindex="0" class="pr ps ed pt bh pu"><div class="pn po rp"><img src="../Images/3362790f58d8e6be83a3fdd37556267f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A6lU8TzXhhltXlJdmSbrww.png"/></div></div><figcaption class="pw px py pn po pz qa bf b bg z dx">Figure 17: The recommendation and rating generated for each author based on their gaming history. Image by Author</figcaption></figure><p id="54bc" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We can cross-match the indices from Figure 16 to find the games recommended for each player. Thus, we implemented a basic recommendation system using the Spark Core ML Library.</p><p id="0dca" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">3. e. Conclusion</strong></p><p id="9438" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this project, we could successfully implement the following —</p><ul class=""><li id="c537" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qu nq nr bk">Download and install the Hadoop ecosystem — HDFS and MapReduce — to store, access, and extract big data efficiently, and implement big data analytics much faster using a personal computer.</li><li id="6d7c" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Install the Apache Spark API for Python (PySpark) and integrate it with the Hadoop ecosystem, enabling us to carry out big data analytics and some machine-learning operations.</li><li id="72bf" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">The games and demographic analysis gave us some insights that can be used to improve the gaming experience and control the player churn. Keeping the players updated and informed about the trends in their peers should be a priority for the Steam platform. Suggestions like “most played”, “most played in your region”, “most recommended”, and “don’t miss out on these new games” can keep the players active.</li><li id="c7f0" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">The Steam Application can use the ALS recommendation system to recommend new games to existing players based on their profile and keep them engaged and afresh.</li></ul><h2 id="2580" class="nx ny fq bf nz oa ob oc od oe of og oh ms oi oj ok mw ol om on na oo op oq or bk">4. What Next?</h2><ul class=""><li id="0b0c" class="mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne qu nq nr bk">Implement Natural Language Processing techniques in the review column, for different languages to extract the essence of the reviews and improve the gaming experience.</li><li id="5778" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Steam can report bugs in the games based on the reviews. Developing an AI algorithm that captures the review content, categorizes it, and sends it to appropriate personnel could do wonders for the platform.</li><li id="648e" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Comment what you think can be done more!</li></ul><h2 id="41f8" class="nx ny fq bf nz oa ob oc od oe of og oh ms oi oj ok mw ol om on na oo op oq or bk">5. References</h2><ul class=""><li id="caf7" class="mj mk fq ml b go os mn mo gr ot mq mr ms ou mu mv mw ov my mz na ow nc nd ne qu nq nr bk">Apache Hadoop. <a class="af no" href="https://hadoop.apache.org/" rel="noopener ugc nofollow" target="_blank">Apache Hadoop</a><em class="qh">. Apache Hadoop</em></li><li id="b310" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Statista. (2021). <a class="af no" href="https://www.statista.com/statistics/871513/worldwide-data-created/" rel="noopener ugc nofollow" target="_blank">Volume of data/information created, captured, copied, and consumed worldwide from 2010 to 2020, with forecasts from 2021 to 2025</a> <em class="qh">statista</em></li><li id="3f1e" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Dey, R. (2023). <a class="af no" href="https://medium.com/@roshmitadey/a-beginners-guide-to-big-data-and-hadoop-distributed-file-system-hdfs-b5c324d3c722" rel="noopener">A Beginner’s Guide to Big Data and Hadoop Distributed File System (HDFS)</a>. <em class="qh">Medium</em></li><li id="0a85" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Code with Arjun (2021). <a class="af no" href="https://codewitharjun.medium.com/install-hadoop-on-macos-efe7c860c3ed" rel="noopener">Install Hadoop on Mac OS (MacBook M1)</a>. <em class="qh">Medium</em></li><li id="ba38" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Apache Spark. <a class="af no" href="https://spark.apache.org/docs/latest/api/python/getting_started/install.html" rel="noopener ugc nofollow" target="_blank">PySpark Installation</a>. <em class="qh">Apache Spark</em></li><li id="16f5" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Apache Spark. <a class="af no" href="https://spark.apache.org/docs/latest/ml-collaborative-filtering.html" rel="noopener ugc nofollow" target="_blank">Collaborative Filtering with ALS)</a>. <em class="qh">Apache Spark</em></li><li id="d9a5" class="mj mk fq ml b go ns mn mo gr nt mq mr ms nu mu mv mw nv my mz na nw nc nd ne qu nq nr bk">Let’s Uncover it. (2023). <a class="af no" href="https://letsuncoverhistory.blogspot.com/2023/06/History-and-The-Future-of-PubG.html" rel="noopener ugc nofollow" target="_blank">PUBG</a>. <em class="qh">Let’s Uncover It</em></li></ul><blockquote class="rq"><p id="d96d" class="rr rs fq bf rt ru rv rw rx ry rz ne dx">You can find the complete big data analysis project in my <a class="af no" href="https://github.com/Rindhujatreesa/Big_Data_Processing_Projects/tree/main/Steam_Review_Analysis_with_HDFS_%26_PySpark" rel="noopener ugc nofollow" target="_blank">GitHub repository</a>.</p><p id="ffef" class="rr rs fq bf rt ru sa sb sc sd se ne dx">Let’s connect on <a class="af no" href="https://www.linkedin.com/in/rindhuja-johnson/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> and discuss more!</p><p id="216a" class="rr rs fq bf rt ru sa sb sc sd se ne dx">If you found this article useful, clap, share, and comment!</p></blockquote></div></div></div></div>    
</body>
</html>