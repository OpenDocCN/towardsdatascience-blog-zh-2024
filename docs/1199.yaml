- en: The (lesser known) rising application of LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM的（较少为人知的）崛起应用
- en: 原文：[https://towardsdatascience.com/the-lesser-known-rising-application-of-llms-775834116477?source=collection_archive---------3-----------------------#2024-05-13](https://towardsdatascience.com/the-lesser-known-rising-application-of-llms-775834116477?source=collection_archive---------3-----------------------#2024-05-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-lesser-known-rising-application-of-llms-775834116477?source=collection_archive---------3-----------------------#2024-05-13](https://towardsdatascience.com/the-lesser-known-rising-application-of-llms-775834116477?source=collection_archive---------3-----------------------#2024-05-13)
- en: '[](https://medium.com/@vianney.mixtur_39698?source=post_page---byline--775834116477--------------------------------)[![Vianney
    Mixtur](../Images/a97e69c63123e450910f6887b7c0813d.png)](https://medium.com/@vianney.mixtur_39698?source=post_page---byline--775834116477--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--775834116477--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--775834116477--------------------------------)
    [Vianney Mixtur](https://medium.com/@vianney.mixtur_39698?source=post_page---byline--775834116477--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vianney.mixtur_39698?source=post_page---byline--775834116477--------------------------------)[![Vianney
    Mixtur](../Images/a97e69c63123e450910f6887b7c0813d.png)](https://medium.com/@vianney.mixtur_39698?source=post_page---byline--775834116477--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--775834116477--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--775834116477--------------------------------)
    [Vianney Mixtur](https://medium.com/@vianney.mixtur_39698?source=post_page---byline--775834116477--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--775834116477--------------------------------)
    ·8 min read·May 13, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--775834116477--------------------------------)
    ·8分钟阅读·2024年5月13日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Overview
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: '**Large Language Models** (LLMs) are often described as **Generative Artificial
    Intelligence** (GenAI) as they indeed have the ability to generate text. The first
    popular application of LLMs were chatbots with ChatGPT leading the way. Then we
    extended their horizon to other tasks such as [**semantic search**](https://vianmixt.notion.site/Practical-Semantic-Search-with-MongoDB-and-OpenAI-451692801b41465fae1bea5f70238279)
    and **retrieval augmented generation**(RAG). Today, I want to talk about a rising
    application for LLM which is **structuring unstructed data** for which I am going
    to show you an example by structuring raw texts into JSON data.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**大语言模型**（LLMs）通常被称为**生成型人工智能**（GenAI），因为它们确实具有生成文本的能力。LLM的第一个流行应用是聊天机器人，其中ChatGPT走在前列。随后，我们将其应用范围扩展到其他任务，如[**语义搜索**](https://vianmixt.notion.site/Practical-Semantic-Search-with-MongoDB-and-OpenAI-451692801b41465fae1bea5f70238279)和**检索增强生成**（RAG）。今天，我想谈谈LLM的一个崛起应用，即**结构化无结构数据**，我将通过将原始文本结构化为JSON数据来展示一个例子。'
- en: 'Using LLMs for **data structuration and extraction** is a very promising application
    with a lot of potential. Here’s why:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM（大语言模型）进行**数据结构化和提取**是一个非常有前景的应用，具有很大的潜力。以下是原因：
- en: '**Improved accuracy :** LLMs understand the nuances of human language. This
    allows them to identify key information within messy, unstructured text with greater
    accuracy than traditional rule-based systems'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提高准确性：** LLM能够理解人类语言的细微差别。这使得它们能够比传统的基于规则的系统更准确地从杂乱、无结构的文本中识别关键信息。'
- en: '**Automation potential** : Extracting information from unstructured data can
    be a time-consuming and laborious task. LLMs can automate this process, freeing
    up human resources for other tasks and allowing for faster analysis of larger
    datasets.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化潜力：** 从无结构数据中提取信息可能是一项耗时且劳动密集的任务。LLM可以自动化这个过程，从而释放人力资源用于其他任务，并加速对更大数据集的分析。'
- en: '**Adaptability and learning capabilities**: LLMs, on the other hand, can be
    continuously fine-tuned and adapted to handle new data sources and information
    types. As they are exposed to more unstructured data, they can learn and improve
    their ability to identify patterns and extract relevant information.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适应性和学习能力：** LLM则可以持续进行微调，并适应处理新的数据源和信息类型。随着它们接触到更多的无结构数据，它们能够学习并提高识别模式和提取相关信息的能力。'
- en: '**Business outcome :** A vast amount of valuable information resides within
    unstructured textual data sources like emails, customer reviews, social media
    conversations, and internal documents. However, this data is often difficult to
    analyze. LLMs can unlock this hidden potential by transforming unstructured data
    into a structured format. This allows businesses to leverage powerful analytics
    tools to identify trends, and gain insights. Essentially, by structuring unstructured
    data with LLMs, businesses can transform a liability (unusable data) into an asset
    (valuable insights) that drives better decision-making and improves overall business
    outcomes.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**业务成果：** 大量宝贵信息存在于诸如电子邮件、客户评论、社交媒体对话和内部文档等非结构化文本数据源中。然而，这些数据通常难以分析。大语言模型（LLM）可以通过将非结构化数据转换为结构化格式，解锁这些隐藏的潜力。这使得企业能够利用强大的分析工具来识别趋势并获取洞察。实质上，通过使用LLM将非结构化数据进行结构化，企业可以将一种负担（不可用的数据）转变为一种资产（有价值的洞察），从而推动更好的决策并提升整体业务成果。'
- en: An example
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个例子
- en: Recently, I was searching for an open-source recipes dataset for a personal
    project but I could not find any except for [this github repository](https://github.com/ronaldlong46/public-domain-recipes)
    containing the recipes displayed on [publicdomainrecipes.com](https://publicdomainrecipes.com/).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我在为个人项目寻找开源食谱数据集时，除了[这个GitHub仓库](https://github.com/ronaldlong46/public-domain-recipes)外，什么也没找到，该仓库包含了在[publicdomainrecipes.com](https://publicdomainrecipes.com/)上显示的食谱。
- en: '![](../Images/04ad1e467b2d1359d7502b35c19f079e.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04ad1e467b2d1359d7502b35c19f079e.png)'
- en: Photo by [Jeff Sheldon](https://unsplash.com/@ugmonk?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Jeff Sheldon](https://unsplash.com/@ugmonk?utm_source=medium&utm_medium=referral)拍摄，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Unfortunately, I needed a dataset that was more exploitable, i.e something closer
    to **tabular data** or to a **NoSQL document**. That’s how I thought about finding
    a way to transform the raw data into something more suitable to my needs, without
    spending hours, days and weeks doing it manually.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我需要一个更具可操作性的数据集，即更接近**表格数据**或**NoSQL文档**的东西。这就是我开始考虑找到一种方法，将原始数据转换成更适合我需求的东西，而不需要花费数小时、数天甚至数周手动完成的原因。
- en: Let me show you how I used the power of Large Language Models to automate the
    process of converting the raw text into structured documents.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我展示一下我如何利用大语言模型的强大能力来自动化将原始文本转换为结构化文档的过程。
- en: Dataset
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: The original dataset is a collection of markdown files. Each file representing
    a recipe.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集是一个markdown文件的集合，每个文件代表一个食谱。
- en: An example of markdown file describing a recipe to make french crêpes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一个描述如何制作法式可丽饼的食谱的markdown文件示例。
- en: 'As you can see, this is not completely unstructured, there are nice tabular
    metadata on top of the file, then there are 4 distincts sections:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这并非完全无结构，文件顶部有一些漂亮的表格元数据，接下来有4个不同的部分：
- en: An introduction,
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个介绍，
- en: The list of ingredients
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 食材列表
- en: Directions
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步骤
- en: Some tips.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些提示。
- en: Based on this observation, [Sebastian Bahr](https://www.linkedin.com/in/sebastianbahr/),
    developed a parser to transform the markdown files into JSON [here](https://github.com/sebastianbahr/RecipeRecommender).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这个观察，[Sebastian Bahr](https://www.linkedin.com/in/sebastianbahr/)开发了一个解析器，将markdown文件转换为JSON格式，[在这里](https://github.com/sebastianbahr/RecipeRecommender)。
- en: The output of the parser is already more exploitable, besides Sebastian used
    it to [build a recipe recommender chatbot](/build-a-recipe-recommender-chatbot-using-rag-and-hybrid-search-part-i-c4aa07d14dcf).
    However, there are still some drawbacks. The ingredients and directions keys contain
    raw texts that could be better structured.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器的输出已经变得更具可操作性，此外，Sebastian利用它[构建了一个食谱推荐聊天机器人](/build-a-recipe-recommender-chatbot-using-rag-and-hybrid-search-part-i-c4aa07d14dcf)。然而，仍然存在一些缺点。食材和步骤的键包含了原始文本，这些文本可以做得更有结构。
- en: As-is, some useful information is hidden.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 按原样，某些有用的信息被隐藏了。
- en: For example, the quantities for the ingredients, the preparation or cooking
    time for each step.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，食材的数量，每个步骤的准备或烹饪时间。
- en: Code
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: In the remainder of this article, I’ll show the steps that I undertook to get
    to JSON documents that look like the one below.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的剩余部分，我将展示我采取的步骤，以便得到像下面这样的JSON文档。
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The code to reproduce the tutorial is on GitHub [here](https://github.com/VianneyMI/baker).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 复现教程的代码在GitHub[这里](https://github.com/VianneyMI/baker)。
- en: I relied on two powerful libraries `[langchain](https://www.langchain.com/)`
    for communicating with LLM providers and `[pydantic](https://docs.pydantic.dev/latest/)`
    to format the output of the LLMs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我依赖了两个强大的库——用于与LLM提供商通信的`[langchain](https://www.langchain.com/)`，以及用于格式化LLM输出的`[pydantic](https://docs.pydantic.dev/latest/)`。
- en: First, I defined the two main components of a recipe with the `Ingredient`and
    `Step`classes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我定义了食谱的两个主要组成部分——`Ingredient`类和`Step`类。
- en: In each class, I defined the relevant attributes and provided a description
    of the field and examples. Those are then fed to the LLMs by `langchain` leading
    to better results.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个类中，我定义了相关的属性，并提供了字段描述和示例。然后这些内容通过`langchain`传递给LLM，从而获得更好的结果。
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Technical Details**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**技术细节**'
- en: It is important to not have a model which is too strict here otherwise, the
    pydantic validation of the JSON outputted by the LLM will fail. A good way to
    give some flexibility is too provide default values like `None` or empty lists
    `[]` depending on the targeted output type.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这里需要注意不要使用过于严格的模型，否则LLM输出的JSON会失败Pydantic验证。一个好的方法是提供一些灵活性，比如根据目标输出类型，提供默认值如`None`或空列表`[]`。
- en: Note the `field_validator`on the `quantity`attribute of the `Ingredient` , is
    there to help the engine parse quantities. It was not initially there but by doing
    some trials, I found out that the LLM was often providing quantities as strings
    such as `1/3`or `1/2` .
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意`Ingredient`类中`quantity`属性上的`field_validator`，它帮助引擎解析数量。最初没有这个，但通过一些实验，我发现LLM经常将数量作为字符串提供，例如`1/3`或`1/2`。
- en: The `used_ingredients`allow to formally link the ingredients to the relevant
    steps of the recipes.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`used_ingredients`用于正式地将食材与食谱的相关步骤联系起来。'
- en: The model of the output being defined the rest of the process is pretty smooth.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出模型一旦定义，后续过程就相对顺利。
- en: In a `prompt.py`file, I defined a `create_prompt`function to easily generate
    prompts. A “new” prompt is generated for every recipe. All prompts have the same
    basis but the recipe itself is passed as a variable to the base prompt to create
    a new one.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在`prompt.py`文件中，我定义了一个`create_prompt`函数，用于轻松生成提示语。每个食谱都会生成一个“新”的提示语。所有提示语有相同的基础，但食谱本身作为变量传递给基础提示语，以创建一个新的提示。
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The communication with the LLM logic was defined in the`run`function of the`core.py`file,
    that I won’t show here for brevity.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与LLM逻辑的通信是在`core.py`文件的`run`函数中定义的，我这里为了简洁没有展示。
- en: Finally, I combined all those components in my`demo.ipynb`notebook whose content
    is shown below.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我将所有这些组件结合在我的`demo.ipynb`笔记本中，以下是其内容。
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: I used [MistralAI](https://mistral.ai/) as a LLM provider, with their `open-mixtral-8x7b`model
    which is a very good open-source alternative to [OpenAI](https://openai.com/).
    `langchain`allows you to easily switch provider given you have created an account
    on the provider’s platform.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了[MistralAI](https://mistral.ai/)作为LLM提供商，采用他们的`open-mixtral-8x7b`模型，这是一个非常好的开源替代方案，相较于[OpenAI](https://openai.com/)。`langchain`让你可以轻松切换提供商，只要你在提供商平台上创建了账户。
- en: 'If you are trying to reproduce the results:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你试图复现这些结果：
- en: (#1) — Make sure you have a `MISTRAL_API_KEY`in a .env file or in your OS environment.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (#1) — 确保你在`.env`文件中或在操作系统环境中有`MISTRAL_API_KEY`。
- en: (#2) — Be careful to the path to the data. If you clone my repo, this won’t
    be an issue.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (#2) — 请小心数据的路径。如果你克隆了我的仓库，这将不是问题。
- en: Running the code on the entire dataset cost less than 2€.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个数据集上运行代码的费用不到2€。
- en: The structured dataset resulting from this code can be found [here](https://github.com/VianneyMI/baker/blob/main/data/output/parsed_recipes_all_8x7b.json)
    in my repository.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过此代码生成的结构化数据集可以在我的仓库中[这里](https://github.com/VianneyMI/baker/blob/main/data/output/parsed_recipes_all_8x7b.json)找到。
- en: I am happy with the results but I could still try to iterate on the prompt,
    my field descriptions or the model used to improve them. I might try MistralAI
    newer model, the `open-mixtral-8x22b` or try another LLM provider by simply changing
    2 or 3 lines of code thanks to `langchain` .
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我对结果很满意，但仍然可以尝试对提示语、字段描述或所使用的模型进行迭代，以进一步改进它们。我可能会尝试MistralAI的最新模型`open-mixtral-8x22b`，或者通过简单地修改2到3行代码，借助`langchain`尝试另一个LLM提供商。
- en: When I am ready, I can get back to my original project. Stay tuned if you want
    to know what it was. In the meantime, let me know in the comments what would you
    do with the final dataset ?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当我准备好时，我可以回到我的原始项目。如果你想知道它是什么，敬请关注。同时，如果你有任何想法，欢迎在评论中告诉我，你会如何利用最终的数据集？
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Large Language Models (LLMs) offer a powerful tool for structuring unstructured
    data. Their ability to understand and interpret human language nuances, automate
    laborious tasks, and adapt to evolving data make them an invaluable resource in
    data analysis. By unlocking the hidden potential within unstructured textual data,
    businesses can transform this data into valuable insights, driving better decision-making
    and business outcomes. The example provided, of transforming raw recipes data
    into a structured format, is just one of the countless possibilities that LLMs
    offer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）为结构化非结构化数据提供了强大的工具。它们理解和解释人类语言细微差别的能力、自动化繁琐任务的能力，以及适应不断变化的数据的能力，使它们成为数据分析中无价的资源。通过发掘非结构化文本数据中的潜在价值，企业可以将这些数据转化为有价值的洞察，推动更好的决策和商业成果。提供的例子——将原始食谱数据转化为结构化格式——只是LLMs所能提供的无数可能性中的一个。
- en: As we continue to explore and develop these models, we can expect to see many
    more innovative applications in the future. The journey of harnessing the full
    potential of LLMs is just beginning, and the road ahead promises to be an exciting
    one.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续探索和开发这些模型，未来我们可以预见到更多创新应用的出现。充分发挥LLMs潜力的旅程才刚刚开始，未来的道路充满了激动人心的前景。
