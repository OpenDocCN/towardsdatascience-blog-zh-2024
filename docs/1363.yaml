- en: Deep Dive into Anthropic’s Sparse Autoencoders by Hand ✍️
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨Anthropic的稀疏自编码器 ✍️
- en: 原文：[https://towardsdatascience.com/deep-dive-into-anthropics-sparse-autoencoders-by-hand-%EF%B8%8F-eebe0ef59709?source=collection_archive---------1-----------------------#2024-05-31](https://towardsdatascience.com/deep-dive-into-anthropics-sparse-autoencoders-by-hand-%EF%B8%8F-eebe0ef59709?source=collection_archive---------1-----------------------#2024-05-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deep-dive-into-anthropics-sparse-autoencoders-by-hand-%EF%B8%8F-eebe0ef59709?source=collection_archive---------1-----------------------#2024-05-31](https://towardsdatascience.com/deep-dive-into-anthropics-sparse-autoencoders-by-hand-%EF%B8%8F-eebe0ef59709?source=collection_archive---------1-----------------------#2024-05-31)
- en: Explore the concepts behind the interpretability quest for LLMs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索大语言模型（LLMs）可解释性追求背后的概念
- en: '[](https://medium.com/@srijanie.dey?source=post_page---byline--eebe0ef59709--------------------------------)[![Srijanie
    Dey, PhD](../Images/2b3292a3b22d712d91d0bfc14df64446.png)](https://medium.com/@srijanie.dey?source=post_page---byline--eebe0ef59709--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--eebe0ef59709--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--eebe0ef59709--------------------------------)
    [Srijanie Dey, PhD](https://medium.com/@srijanie.dey?source=post_page---byline--eebe0ef59709--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@srijanie.dey?source=post_page---byline--eebe0ef59709--------------------------------)[![Srijanie
    Dey, PhD](../Images/2b3292a3b22d712d91d0bfc14df64446.png)](https://medium.com/@srijanie.dey?source=post_page---byline--eebe0ef59709--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--eebe0ef59709--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--eebe0ef59709--------------------------------)
    [Srijanie Dey, PhD](https://medium.com/@srijanie.dey?source=post_page---byline--eebe0ef59709--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--eebe0ef59709--------------------------------)
    ·11 min read·May 31, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--eebe0ef59709--------------------------------)
    ·阅读时长：11分钟·2024年5月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/81130790966487c80fb82406f9fe2482.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81130790966487c80fb82406f9fe2482.png)'
- en: Image by author (Zephyra, the protector of Lumaria by my 4-year old)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者（Zephyra，卢玛利亚的守护者，由我的4岁孩子绘制）
- en: '*“In the mystical lands of Lumaria, where ancient magic filled the air, lived
    Zephyra, the Ethereal Griffin. With the body of a lion and the wings of an eagle,
    Zephyra was the revered protector of the Codex of Truths, an ancient script holding
    the universe’s secrets.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*“在神秘的卢玛利亚大地上，古老的魔法弥漫在空气中，生活着Zephyra，这只以狮身鹰翼为特征的空灵狮鹫。Zephyra是《真理法典》的崇高守护者，这本古老的文献蕴藏着宇宙的秘密。*'
- en: '*Nestled in a sacred cave, the Codex was safeguarded by Zephyra’s viridescent
    eyes, which could see through deception to unveil pure truths. One day, a dark
    sorcerer descended on the lands of Lumaria and sought to shroud the world in ignorance
    by concealing the Codex. The villagers called upon Zephyra, who soared through
    the skies, as a beacon of hope. With a majestic sweep of the wings, Zephyra created
    a protective barrier of light around the grove, repelling the sorcerer and exposing
    the truths.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*“在一座神圣的洞窟中，法典由Zephyra那双绿色的眼睛守护，她能看破虚伪，揭示纯粹的真理。一天，一位黑暗巫师降临卢玛利亚大地，试图通过隐藏《法典》将世界笼罩在无知之中。村民们呼唤Zephyra，她如希望的灯塔在空中翱翔。随着一阵雄伟的翅膀挥动，Zephyra在树林周围创造了一个保护光障，击退了巫师，揭示了真理。”*'
- en: '*After a long duel, it was concluded that the dark sorcerer was no match to
    Zephyra’s light. Through her courage and vigilance, the true light kept shining
    over Lumaria. And as time went by, Lumaria was guided to prosperity under Zephyra’s
    protection and its path stayed illuminated by the truths Zephyra safeguarded.
    And this is how Zephyra’s legend lived on!”*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*“经过一场长久的决斗，最终结论是黑暗巫师无法与Zephyra的光芒抗衡。通过她的勇气和警觉，真正的光明继续照耀着卢玛利亚。随着时间流逝，卢玛利亚在Zephyra的守护下走向繁荣，而她所守护的真理也始终照亮着这片土地。这就是Zephyra传奇延续下去的方式！”*'
- en: Anthropic’s journey ‘towards extracting interpretable features’
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Anthropic的“提取可解释特征之旅”
- en: Following the story of Zephyra, Anthropic AI delved into the expedition of extracting
    meaningful features in a model. The idea behind this investigation lies in understanding
    how different components in a neural network interact with one another and what
    role each component plays.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 追随Zephyra的故事，Anthropic AI深入探讨了从模型中提取有意义特征的探索过程。这项研究的核心思想在于理解神经网络中不同组件如何相互作用，以及每个组件所扮演的角色。
- en: 'According to the paper **“**[**Towards Monosemanticity: Decomposing Language
    Models With Dictionary Learning**](https://transformer-circuits.pub/2023/monosemantic-features/index.html)**”**
    a Sparse Autoencoder is able to successfully extract meaningful features from
    a model. In other words, Sparse Autoencoders help break down the problem of ‘polysemanticity’
    — neural activations that correspond to several meanings/interpretations at once
    by focusing on sparsely activating features that hold a single interpretation
    — in other words, are more one-directional.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 根据论文**“**[**迈向单一语义性：通过字典学习分解语言模型**](https://transformer-circuits.pub/2023/monosemantic-features/index.html)**”**，稀疏自动编码器能够成功地从模型中提取有意义的特征。换句话说，稀疏自动编码器帮助解决‘多义性’问题——神经激活同时对应多个意义/解释，通过专注于稀疏激活那些只包含单一解释的特征——换句话说，它们更具单向性。
- en: To understand how all of it is done, we have these beautiful handiworks on [Autoencoders](https://lnkd.in/g2rM9iV2)
    and [Sparse Autoencoders](https://www.linkedin.com/posts/tom-yeh_claude-autoencoder-aibyhand-activity-7199774212759183362-msKU/?)
    by Prof. [Tom Yeh](https://www.linkedin.com/in/tom-yeh/) that explain the behind-the-scenes
    workings of these phenomenal mechanisms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一切是如何完成的，我们可以参考[自动编码器](https://lnkd.in/g2rM9iV2)和[稀疏自动编码器](https://www.linkedin.com/posts/tom-yeh_claude-autoencoder-aibyhand-activity-7199774212759183362-msKU/?)的精彩作品，这些作品由[Tom
    Yeh教授](https://www.linkedin.com/in/tom-yeh/)创作，解释了这些神奇机制的幕后工作原理。
- en: (All the images below, unless otherwise noted, are by Prof. Tom Yeh from the
    above-mentioned LinkedIn posts, which I have edited with his permission. )
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: （以下所有图片，除非另有说明，均来自Tom Yeh教授上面提到的LinkedIn帖子，已获他的许可进行编辑。）
- en: To begin, let us first let us first explore what an Autoencoder is and how it
    works.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们首先探讨一下什么是自动编码器，它是如何工作的。
- en: What is an Autoencoder?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是自动编码器？
- en: Imagine a writer has his desk strewn with different papers — some are his notes
    for the story he is writing, some are copies of final drafts, some are again illustrations
    for his action-packed story. Now amidst this chaos, it is hard to find the important
    parts — more so when the writer is in a hurry and the publisher is on the phone
    demanding a book in two days. Thankfully, the writer has a very efficient assistant
    — this assistant makes sure the cluttered desk is cleaned regularly, grouping
    similar items, organizing and putting things into their right place. And as and
    when needed, the assistant would retrieve the correct items for the writer, helping
    him meet the deadlines set by his publisher.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个作家，他的桌子上散乱着各种纸张——有的是他写故事的笔记，有的是最终稿的副本，还有的是为他的动作故事绘制的插图。在这种混乱中，很难找到重要的部分——尤其是当作家很匆忙，出版社在电话中催促他两天内交书时。幸运的是，作家有一个非常高效的助手——这个助手确保杂乱的桌面被定期清理，类似的物品被分组整理，并把东西放到合适的位置。而且，当作家需要时，助手会帮助他快速找到正确的物品，帮助他按时完成出版社设定的截止日期。
- en: Well, the name of this assistant is Autoencoder. It mainly has two functions
    — encoding and decoding. Encoding refers to condensing input data and extracting
    the essential features (organization). Decoding is the process of reconstructing
    original data from encoded representation while aiming to minimize information
    loss (retrieval).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这个助手的名字叫做自动编码器。它主要有两个功能——编码和解码。编码是指压缩输入数据并提取出关键特征（组织）。解码则是从编码表示中重建原始数据的过程，目标是尽量减少信息丢失（恢复）。
- en: Now let’s look at how this assistant works.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看这个助手是如何工作的。
- en: How does an Autoencoder Work?
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动编码器是如何工作的？
- en: 'Given : Four training examples **X1, X2, X3, X4.**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 给定：四个训练样本 **X1, X2, X3, X4.**
- en: '[1] Auto'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[1] 编码器'
- en: The first step is to copy the training examples to targets **Y’**. The Autoencoder’s
    work is to reconstruct these training examples. Since the targets are the training
    examples themselves, the word ***‘Auto’*** is used which is Greek for ***‘self’***.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将训练样本复制到目标 **Y’**。自动编码器的工作是重建这些训练样本。由于目标就是训练样本本身，所以使用了词***‘Auto’***，它是希腊语的***‘自我’***意思。
- en: '[2] Encoder : Layer 1 +ReLU'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[2] 编码器：第一层 +ReLU'
- en: As we have seen in all our previous models, a simple weight and bias matrix
    coupled with ReLU is powerful and is able to do wonders. Thus, by using the first
    Encoding layer we reduce the size of the original feature set from 4x4 to 3x4.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在之前的所有模型中所看到的，简单的权重和偏置矩阵结合ReLU非常强大，能够做出惊人的效果。因此，通过使用第一个编码层，我们将原始特征集的大小从4x4减少到3x4。
- en: '![](../Images/c2c2896b0761620ef71f79dd24b7de1a.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2c2896b0761620ef71f79dd24b7de1a.png)'
- en: 'A quick recap:'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 简要回顾：
- en: ''
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Linear transformation** : The input embedding vector is multiplied by the
    weight matrix W and then added with the bias vector **b**,'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**线性变换**：输入嵌入向量与权重矩阵W相乘，然后与偏置向量**b**相加，'
- en: ''
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: z = **W**x+**b**, where **W** is the weight matrix, x is our word embedding
    and **b** is the bias vector.
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: z = **W**x + **b**，其中**W**是权重矩阵，x是我们的词嵌入，**b**是偏置向量。
- en: ''
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**ReLU activation function** : Next, we apply the ReLU to this intermediate
    z.'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ReLU激活函数**：接下来，我们将ReLU应用于这个中间的z。'
- en: ''
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ReLU returns the element-wise maximum of the input and zero. Mathematically,
    **h** = max{0,z}.
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ReLU返回输入和零之间的逐元素最大值。数学上，**h** = max{0, z}。
- en: '[3] Encoder : Layer 2 + ReLU'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[3] 编码器：第二层 + ReLU'
- en: The output of the previous layer is processed by the second Encoder layer which
    reduces the input size further to 2x3\. This is where the extraction of relevant
    features occurs. This layer is also called the ‘bottleneck’ since the outputs
    in this layer have much lower features than the input features.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 上一层的输出由第二个编码器层处理，该层进一步将输入大小减小到2x3。这时，相关特征的提取发生在此层。这个层也叫做“瓶颈”，因为该层的输出特征远小于输入特征。
- en: '![](../Images/486e9e67fbbfac831061f662d28f156c.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/486e9e67fbbfac831061f662d28f156c.png)'
- en: '[4] Decoder : Layer 1 + ReLU'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[4] 解码器：第一层 + ReLU'
- en: Once the encoding process is complete, the next step is to decode the relevant
    features to build ‘back’ the final output. To do so, we multiply the features
    from the last step with corresponding weights and biases and apply the ReLU layer.
    The result is a 3x4 matrix.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦编码过程完成，下一步是解码相关特征，以构建最终输出。为此，我们将上一步的特征与相应的权重和偏置相乘，并应用ReLU层。结果是一个3x4的矩阵。
- en: '![](../Images/9f9ffd4521b3c28b6eba26be3b1c2100.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f9ffd4521b3c28b6eba26be3b1c2100.png)'
- en: '[5] Decoder : Layer 2 + ReLU'
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[5] 解码器：第二层 + ReLU'
- en: A second Decoder layer (weight, biases + ReLU) applies on the previous output
    to give the final result which is the reconstructed 4x4 matrix. We do so to get
    back to original dimension in order to compare the results with our original target.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个解码器层（权重、偏置 + ReLU）应用于之前的输出，给出最终结果，即重建的4x4矩阵。我们这样做是为了恢复原始维度，以便将结果与我们的原始目标进行比较。
- en: '![](../Images/47b3bd18b0209d34df20b5cb9f242b97.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47b3bd18b0209d34df20b5cb9f242b97.png)'
- en: '[6] Loss Gradients & BackPropagation'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[6] 损失梯度和反向传播'
- en: Once the output from the decoder layer is obtained, we calculate the gradients
    of the Mean Square Error (MSE) between the **outputs (Y)** and the **targets (Y’)**.
    To do so, we find **2*(Y-Y’)** , which gives us the final gradients that activate
    the backpropagation process and updates the weights and biases accordingly.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获得解码器层的输出，我们计算**输出（Y）**和**目标（Y’）**之间的均方误差（MSE）的梯度。为此，我们求解**2*(Y-Y’)**，这给出了最终的梯度，激活反向传播过程，并相应地更新权重和偏置。
- en: '![](../Images/286ca27d2139e0c693ec2fdcee1050b0.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/286ca27d2139e0c693ec2fdcee1050b0.png)'
- en: Now that we understand how the Autoencoder works, it’s time to explore how its
    **sparse variation** is able to achieve interpretability for large language models
    (LLMs).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了自编码器的工作原理，接下来就该探讨它的**稀疏变体**如何实现大语言模型（LLMs）的可解释性。
- en: Sparse Autoencoder — How does it work?
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稀疏自编码器——它是如何工作的？
- en: 'To start with, suppose we are given:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，假设我们给定了：
- en: The output of a transformer after the feed-forward layer has processed it, i.e.
    let us assume we have the model activations for five tokens (X). They are good
    but they do not shed light on how the model arrives at its decision or makes the
    predictions.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在经过前馈层处理后的变换器输出，即假设我们有五个标记（X）的模型激活值。它们很好，但并不能揭示模型如何得出决策或进行预测。
- en: '![](../Images/5c01141ce07bd9ff3330b673178216f6.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c01141ce07bd9ff3330b673178216f6.png)'
- en: 'The prime question here is:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的主要问题是：
- en: Is it possible to map each activation (3D) to a higher-dimension space (6D)
    that will help with the understanding?
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 是否有可能将每个激活（3D）映射到一个更高维度空间（6D），以帮助理解？
- en: '[1] Encoder : Linear Layer'
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[1] 编码器：线性层'
- en: The first step in the Encoder layer is to multiply the input **X** with encoder
    weights and add biases (as done in the first step of an Autoencoder).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器层的第一步是将输入**X**与编码器权重相乘，并添加偏置（如在自编码器的第一步中所做）。
- en: '![](../Images/312068c487f5a71ba089baf15668d291.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/312068c487f5a71ba089baf15668d291.png)'
- en: '[2] Encoder : ReLU'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[2] 编码器：ReLU'
- en: The next sub-step is to apply the ReLU activation function to add non-linearity
    and suppress negative activations. This suppression leads to many features being
    set to 0 which enables the concept of sparsity — outputting sparse and interpretable
    features ***f.***
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下一子步骤是应用ReLU激活函数，加入非线性并抑制负激活。这种抑制导致许多特征被设为0，从而实现稀疏性概念——输出稀疏且可解释的特征***f.***
- en: Interpretability happens when we have only one or two positive features. If
    we examine ***f6***, we can see **X2** and **X3** are positive, and may say that
    both have ‘Mountain’ in common.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们只有一个或两个正特征时，就会发生可解释性。如果我们检查***f6***，我们可以看到**X2**和**X3**是正的，并可以说它们两个有‘山’这一共同点。
- en: '![](../Images/7b8b7f37cd47ccde17cf92263a8a113b.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b8b7f37cd47ccde17cf92263a8a113b.png)'
- en: '[3] Decoder : Reconstruction'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[3] 解码器 : 重建'
- en: Once we are done with the encoder, we proceed to the decoder step. We multiply
    ***f***with decoder weights and add biases. This outputs **X’**, which is the
    reconstruction of **X** from interpretable features.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成编码器步骤，我们就进入解码器步骤。我们将***f***与解码器的权重相乘并添加偏置。这样输出的**X’**就是从可解释特征重建的**X**。
- en: '![](../Images/0ef0969dd32ed6d5a1a46041619c2efe.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ef0969dd32ed6d5a1a46041619c2efe.png)'
- en: As done in an Autoencoder, we want **X’** to be as close to **X** as possible.
    To ensure that, further training is essential.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如同在自编码器中所做的那样，我们希望**X’**尽可能接近**X**。为了确保这一点，进一步的训练是必不可少的。
- en: '[4] Decoder : Weights'
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[4] 解码器 : 权重'
- en: As an intermediary step, we compute the L2 norm for each of the weights in this
    step. We keep them aside to be used later.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个中间步骤，我们计算每个权重的L2范数，并将它们保留下来以便稍后使用。
- en: '![](../Images/9208c5b6e536090638fa96455a2dc40b.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9208c5b6e536090638fa96455a2dc40b.png)'
- en: '**L2-norm**'
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**L2-范数**'
- en: ''
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Also known as Euclidean norm, L2-norm calculates the magnitude of a vector
    using the formula: ||x||₂ = √(Σᵢ xᵢ²).'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 也称为欧几里得范数，L2范数使用以下公式计算向量的大小：||x||₂ = √(Σᵢ xᵢ²)。
- en: ''
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, it sums the squares of each component and then takes the square
    root over the result. This norm provides a straightforward way to quantify the
    length or distance of a vector in Euclidean space.
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 换句话说，它对每个分量的平方进行求和，然后对结果取平方根。这个范数提供了一种直接的方式来量化向量在欧几里得空间中的长度或距离。
- en: Training
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: 'As mentioned earlier, a Sparse Autoencoder instils extensive training to get
    the reconstructed **X’** closer to **X**. To illustrate that, we proceed to the
    next steps below:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，稀疏自编码器通过广泛的训练使得重建的**X’**尽可能接近**X**。为此，我们接下来执行以下步骤：
- en: '[5] Sparsity : L1 Loss'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[5] 稀疏性 : L1损失'
- en: The goal here is to obtain as many values close to zero / zero as possible.
    We do so by invoking **L1 sparsity** to penalize the absolute values of the weights
    — the core idea being that we want to make the sum as small as possible.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是尽可能获得接近零/零的值。我们通过调用**L1稀疏性**来惩罚权重的绝对值——核心思想是我们希望使得和尽可能小。
- en: '![](../Images/f8aa5583bdaebc8564e7bd8b44ddd399.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8aa5583bdaebc8564e7bd8b44ddd399.png)'
- en: '**L1-loss**'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**L1-损失**'
- en: ''
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The L1-loss is calculated as the sum of the absolute values of the weights:
    L1 = λΣ|w|, where λ is a regularization parameter.'
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: L1-损失是权重绝对值之和：L1 = λΣ|w|，其中λ是正则化参数。
- en: ''
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This encourages many weights to become zero, simplifying the model and thus
    enhancing **interpretability**.
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这促使许多权重变为零，从而简化了模型，并增强了**可解释性**。
- en: ''
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, L1 helps build the focus on the most relevant features while
    also preventing overfitting, improving model generalization, and reducing computational
    complexity.
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 换句话说，L1有助于将注意力集中在最相关的特征上，同时防止过拟合，改善模型的泛化能力，并减少计算复杂性。
- en: '[6] Sparsity : Gradient'
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[6] 稀疏性 : 梯度'
- en: The next step is to calculate **L1**’s gradients which -1 for positive values.
    Thus, for all values of ***f >0*** , the result will be set to -1.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是计算**L1**的梯度，对于正值为-1。因此，对于所有值为***f >0***的情况，结果将被设定为-1。
- en: '![](../Images/5e85338940e15e3475ce8be719ff40e3.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e85338940e15e3475ce8be719ff40e3.png)'
- en: '**How does L1 penalty push weights towards zero?**'
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**L1惩罚如何将权重推向零？**'
- en: ''
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The gradient of the L1 penalty pushes weights towards zero through a process
    that applies a constant force, regardless of the weight’s current value. Here’s
    how it works (all images in this sub-section are by author):'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: L1惩罚的梯度通过一个过程将权重推向零，这个过程施加一个恒定的力，无论权重的当前值如何。下面是它的工作原理（本小节中的所有图片均为作者提供）：
- en: ''
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The L1 penalty is expressed as:'
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: L1惩罚表示为：
- en: '![](../Images/04df48be6e16080c94467c08c9f248ef.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04df48be6e16080c94467c08c9f248ef.png)'
- en: 'The gradient of this penalty with respect to a weight ***w*** is:'
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个惩罚相对于权重***w***的梯度是：
- en: '![](../Images/52a15cda96d611eb04f7e52d79a4a817.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52a15cda96d611eb04f7e52d79a4a817.png)'
- en: 'where ***sign(w)*** is:'
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其中***sign(w)***是：
- en: '![](../Images/5d0377f88ae46308b533ea7284c90ab7.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d0377f88ae46308b533ea7284c90ab7.png)'
- en: 'During gradient descent, the update rule for weights is:'
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在梯度下降过程中，权重的更新规则是：
- en: '![](../Images/c4cf2e8036e3f8abe10def8af14ab467.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4cf2e8036e3f8abe10def8af14ab467.png)'
- en: where 𝞰 is the learning rate.
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其中𝞰是学习率。
- en: ''
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The **constant subtraction (or addition)** of **λ** from the weight value (depending
    on its sign) decreases the absolute value of the weight. If the weight is small
    enough, this process can drive it to exactly zero.
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**常量减法（或加法）**操作中的**λ**（根据其符号）会减小权重值的绝对值。如果权重足够小，这个过程可以将其完全驱动为零。'
- en: '[7] Sparsity : Zero'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[7] 稀疏性：零'
- en: For all other values that are already zero, we keep them unchanged since they
    have already been zeroed out.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有已经是零的其他值，我们保持它们不变，因为它们已经被归零。
- en: '![](../Images/35dcfe7c72319bdffd087a7baa4fe776.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35dcfe7c72319bdffd087a7baa4fe776.png)'
- en: '[8] Sparsity : Weight'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[8] 稀疏性：权重'
- en: We multiple each row of the gradient matrix obtained in Step 6 by the corresponding
    decoder weights obtained in Step 4\. This step is crucial as it prevents the model
    from learning large weights which would add incorrect information while reconstructing
    the results.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将第6步中获得的梯度矩阵的每一行与第4步中获得的相应解码器权重相乘。这个步骤至关重要，因为它防止模型学习到较大的权重，避免在重建结果时加入错误的信息。
- en: '![](../Images/306a1ce823111e9d815e4b7f1fd15802.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/306a1ce823111e9d815e4b7f1fd15802.png)'
- en: '[9] Reconstruction : MSE Loss'
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[9] 重建：均方误差损失'
- en: We use the Mean Square Error or the **L2** loss function to calculate the difference
    between **X’** and **X**. The goal as seen previously is to minimize the error
    to the lowest value.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用均方误差或**L2**损失函数来计算**X’**和**X**之间的差异。如前所述，目标是将误差最小化到最低值。
- en: '![](../Images/f4383312900f938f95dc354d99c296fe.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4383312900f938f95dc354d99c296fe.png)'
- en: '[10] Reconstruction : Gradient'
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[10] 重建：梯度'
- en: The gradient of **L2** loss is **2*(X’-X)**.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**L2**损失的梯度是**2*(X’-X)**。'
- en: And hence as seen for the original Autoencoders, we run backpropagation to update
    the weights and the biases. The catch here is finding a good balance between sparsity
    and reconstruction.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，正如原始自编码器所示，我们运行反向传播来更新权重和偏差。这里的关键是找到稀疏性和重建之间的良好平衡。
- en: '![](../Images/8b70731a04ecd7810360275f13324e41.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b70731a04ecd7810360275f13324e41.png)'
- en: And with this, we come to the end of this very clever and intuitive way of learning
    how a model understands an idea and the direction it takes to generate a response.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就结束了这一非常巧妙且直观的学习方法，帮助我们理解模型是如何理解一个概念，并在生成响应时采取的方向。
- en: 'To summarize:'
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结：
- en: 'An **Autoencoder** overall consists of two parts : **Encoder** and **Decoder**.
    The **Encoder** uses weights and biases coupled with the ReLU activation function
    to compress the initial input features into a lower dimension, trying to capture
    only the relevant parts. The **Decoder** on the other hand takes the output of
    the Encoder and works to reconstruct the input features back to their original
    state. Since the targets in an Autoencoder are the initial features themselves,
    hence the use of the word ‘auto’. The aim, as is for standard neural networks,
    is to achieve the lowest error (difference) between the target and the input features
    — and it is achieved by propagating the gradient of the error through the network
    while updating the weights and biases.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个**自编码器**整体由两个部分组成：**编码器**和**解码器**。**编码器**利用权重和偏差以及ReLU激活函数将初始输入特征压缩到一个较低的维度，力图仅捕捉相关的部分。另一方面，**解码器**则接收编码器的输出，并努力将输入特征重建回其原始状态。由于自编码器的目标就是初始特征本身，因此才称之为“自”。目标和标准神经网络一样，是通过传播误差的梯度并更新权重和偏差来实现目标特征和输入特征之间的最小误差（差异）。
- en: 'A **Sparse Autoencoder** consists of all the components as a standard Autoencoder
    along with a few more additions. The key here is the different approach in the
    training step. Since the aim here is to retrieve the interpretable features, we
    want to zero out those values which hold relatively less meaning. Once the encoder
    uses ReLU to suppress the negative values, we go a step further and use L1-Loss
    on the result to encourage sparsity by penalizing the absolute values of the weights.
    This is achieved by adding a penalty term to the loss function, which is the sum
    of the absolute values of the weights: λΣ|w|. The weights that remain non-zero
    are those that are crucial for the model’s performance.'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**稀疏自编码器**由与标准自编码器相同的所有组件以及一些额外的组成部分构成。这里的关键是训练步骤中的不同方法。由于目标是提取可解释的特征，我们希望将那些相对意义较小的值置为零。一旦编码器使用ReLU抑制负值，我们进一步使用L1损失对结果进行处理，通过惩罚权重的绝对值来促进稀疏性。这是通过向损失函数中添加一个惩罚项来实现的，该惩罚项是权重绝对值之和：λΣ|w|。那些保持非零的权重是对模型性能至关重要的。'
- en: Extracting Interpretable features using Sparsity
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用稀疏性提取可解释特征
- en: As humans, our brains activate only a small subset of neurons in response to
    specific stimuli. Likewise, Sparse Autoencoders learn a sparse representation
    of the input by leveraging sparsity constraints like **L1** regularization. By
    doing so, a Sparse Autoencoder is able to extract interpretable features from
    complex data thus enhancing the simplicity and interpretability of the learned
    features. This selective activation mirroring biological neural processes helps
    focus on the most relevant aspects of the input data making the models more robust
    and efficient.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 作为人类，我们的大脑仅对特定刺激激活一小部分神经元。同样，稀疏自编码器通过利用稀疏性约束，如**L1**正则化，学习输入的稀疏表示。通过这样做，稀疏自编码器能够从复杂数据中提取可解释的特征，从而增强所学习特征的简洁性和可解释性。这种类似生物神经过程的选择性激活有助于聚焦于输入数据中最相关的部分，使模型更加鲁棒和高效。
- en: With Anthropic’s endeavor to understand interpretability in AI models, their
    initiative highlights the need for transparent and understandable AI systems,
    especially as they become more integrated into critical decision-making processes.
    By focusing on creating models that are both powerful and interpretable, Anthropic
    contributes to the development of AI that can be trusted and effectively utilized
    in real-world applications.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Anthropic致力于理解AI模型中的可解释性，其倡议强调了透明和易理解的AI系统的必要性，尤其是在AI系统越来越多地融入关键决策过程时。通过专注于创建既强大又可解释的模型，Anthropic为开发可信赖且能有效应用于现实世界的AI做出了贡献。
- en: In conclusion, **Sparse Autoencoders** are vital for extracting interpretable
    features, enhancing model robustness, and ensuring efficiency. The ongoing work
    on understanding these powerful models and how they make inferences underscore
    the growing importance of interpretability in AI, paving the way for more transparent
    AI systems. It remains to see how these concepts evolve and driving us towards
    a future that entails a safe integration of AI in our lives!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，**稀疏自编码器**对于提取可解释的特征、增强模型的鲁棒性并确保效率至关重要。对这些强大模型的理解工作以及它们如何进行推理，突显了AI可解释性日益重要的趋势，为更加透明的AI系统铺平了道路。未来如何发展这些概念，并推动我们迈向一个将AI安全地融入我们生活的未来，值得期待！
- en: '*P.S. If you would like to work through this exercise on your own, here is
    a link to a blank template for your use.*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*附言：如果你想自己完成这个练习，下面有一个空白模板的链接供你使用。*'
- en: '[Blank Template for hand-exercise](https://drive.google.com/file/d/1xiAjdlWCAzhj-I-YOb7wSMeroUOQzdlE/view?usp=sharing)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[空白模板用于手工练习](https://drive.google.com/file/d/1xiAjdlWCAzhj-I-YOb7wSMeroUOQzdlE/view?usp=sharing)'
- en: Now go have fun and help Zephyr keep the Codex of Truth safe!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在去玩吧，帮助Zephyr保持《真理法典》的安全！
- en: '![](../Images/eb16ec0901108e38f05e6bac5825305e.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb16ec0901108e38f05e6bac5825305e.png)'
- en: '*Once again special thanks to* [*Prof. Tom Yeh*](https://www.linkedin.com/in/tom-yeh/)
    *for supporting this work!*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*再次特别感谢* [*Tom Yeh教授*](https://www.linkedin.com/in/tom-yeh/) *对本项工作的支持！*'
- en: 'References:'
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[1] Towards Monosemanticity: Decomposing Language Models With Dictionary Learning,
    Bricken et al. Oct 2023 [https://transformer-circuits.pub/2023/monosemantic-features/index.html](https://transformer-circuits.pub/2023/monosemantic-features/index.html)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 朝着单义性：通过字典学习分解语言模型，Bricken等人，2023年10月 [https://transformer-circuits.pub/2023/monosemantic-features/index.html](https://transformer-circuits.pub/2023/monosemantic-features/index.html)'
- en: '[2] Scaling Monosemanticity: Extracting Interpretable Features from Claude
    3 Sonnet, Templeton et al. May 2024 [https://transformer-circuits.pub/2024/scaling-monosemanticity/](https://transformer-circuits.pub/2024/scaling-monosemanticity/)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] 扩展单义性：从Claude 3 Sonnet中提取可解释特征，Templeton等人，2024年5月 [https://transformer-circuits.pub/2024/scaling-monosemanticity/](https://transformer-circuits.pub/2024/scaling-monosemanticity/)'
