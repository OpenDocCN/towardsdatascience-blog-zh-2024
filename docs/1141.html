<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Do Machine Learning Models Store Protected Content?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Do Machine Learning Models Store Protected Content?</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/do-machine-learning-models-store-protected-content-abec357c6b70?source=collection_archive---------6-----------------------#2024-05-06">https://towardsdatascience.com/do-machine-learning-models-store-protected-content-abec357c6b70?source=collection_archive---------6-----------------------#2024-05-06</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="ce96" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">~A proof of concept~</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@nathanReitinger?source=post_page---byline--abec357c6b70--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Nathan Reitinger" class="l ep by dd de cx" src="../Images/a4f92fd800035099e00b92ea9006181d.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*YE0-ZAewZoATK7PL5Y9aKQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--abec357c6b70--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@nathanReitinger?source=post_page---byline--abec357c6b70--------------------------------" rel="noopener follow">Nathan Reitinger</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--abec357c6b70--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">5 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 6, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mj bh"><figure class="mk ml mm mn mo mj bh paragraph-image"><img src="../Images/aa8bacd956c21071a77783c79542970b.png" data-original-src="https://miro.medium.com/v2/resize:fit:3840/format:webp/1*XuSsX2z8-pI7tuKXYLFQiQ.gif"/></figure></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="ed10" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">From chatGPT to Stable Diffusion, Artificial Intelligence (AI) is having a summer the likes of which rival only the AI heydays of the <a class="af nm" href="https://clivethompson.medium.com/the-risk-of-a-new-ai-winter-332ffb4767f0" rel="noopener">1970s</a>. This jubilation, however, has not been met without resistance. From <a class="af nm" href="https://www.newscientist.com/article/2402251-hollywood-strike-ends-but-actors-battle-against-ai-may-not-be-over/#:~:text=The%20use%20of%20AI%20to,companies%20use%20performers'%20digital%20twins." rel="noopener ugc nofollow" target="_blank">Hollywood</a> to the <a class="af nm" href="https://nftevening.com/claire-silver-brings-artificial-intelligence-nft-art-to-the-louvre/" rel="noopener ugc nofollow" target="_blank">Louvre</a>, AI seems to have awoken a sleeping giant — a giant keen to protect a world that once seemed exclusively human: creativity.</p><p id="143e" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">For those desiring to protect creativity, AI appears to have an Achilles heel: training data. Indeed, all of the <a class="af nm" href="https://arxiv.org/pdf/2310.19909" rel="noopener ugc nofollow" target="_blank">best models today</a> necessitate a high-quality, world-encompassing data diet — but what does that mean?</p><p id="191a" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk"><em class="nn">First</em>, high-quality means human created. Although <a class="af nm" href="https://law.stanford.edu/wp-content/uploads/2019/01/Bellovin_20190129.pdf" rel="noopener ugc nofollow" target="_blank">not-human-created</a> data has made many strides since the idea of a computer playing itself was popularized by <a class="af nm" href="https://www.youtube.com/watch?v=YIh41wZEd5c" rel="noopener ugc nofollow" target="_blank">War Games</a>, computer science literature has shown that model quality degrades over time if humanness is completely taken out of the loop (i.e., model rot or <a class="af nm" href="https://ui.adsabs.harvard.edu/link_gateway/2024arXiv240207712D/doi:10.48550/arXiv.2402.07712" rel="noopener ugc nofollow" target="_blank">model collapse</a>). In simple terms: human data is the lifeblood of these models.</p><p id="2f1a" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk"><em class="nn">Second</em>, world-encompassing means world-encompassing. If you put it online, you should assume the model has used it in training: that Myspace post you were hoping only you and Tom remembered (ingested), that <a class="af nm" href="https://www.cnn.com/2022/05/24/tech/cher-scarlett-facial-recognition-trauma/index.html" rel="noopener ugc nofollow" target="_blank">picture-encased-memory</a> you gladly forgot about until PimEyes forced you to remember it (ingested), and those late-night Reddit tirades you hoped were just a dream (ingested).</p><p id="e856" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">Models like LLaMa, BERT, Stable Diffusion, Claude, and chatGPT were all trained on massive amounts of human-created data. And what’s unique about some, many, or most human-created expressions — especially those that happen to be fixed in a tangible medium a computer can access and learn from — is that they qualify for copyright protection.</p><figure class="mk ml mm mn mo mj no np paragraph-image"><div role="button" tabindex="0" class="nr ns ed nt bh nu"><div class="no np nq"><img src="../Images/4d7d5938bdf54b319faf9fd7ff8b4290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWZYUKM887nIyZTRgeXLug.gif"/></div></div><figcaption class="nv nw nx no np ny nz bf b bg z dx">Anderson v. Stability AI; Concord Music Group, Inc. v. Anthropic PBC; Doe v. GitHub, Inc.; Getty Images v. Stability AI; {Tremblay, Silverman, Chabon} v. OpenAI; New York Times v. Microsoft</figcaption></figure><p id="789a" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">Fortuitous as it may be, the data these models cannot survive without is the same data most protected by copyright. And this gives rise to the titanic copyright battles we are seeing today.</p><p id="cc4f" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">Of the many questions arising in these lawsuits, one of the most pressing is whether models themselves store protected content. This question seems rather obvious, because how can we say that models — merely collections of numbers (i.e., weights) with an architecture — “store” anything? As Professor Murray states:</p><blockquote class="oa ob oc"><p id="7ea5" class="mq mr nn ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">Many of the participants in the current debate on visual generative AI systems have latched onto the idea that generative AI systems have been trained on datasets and foundation models that contained actual copyrighted image files, .jpgs, .gifs, .png files and the like, scraped from the internet, that somehow the dataset or foundation model must have made and stored copies of these works, and somehow the generative AI system further selected and copied individual images out of that dataset, and somehow the system copied and incorporated significant copyrightable parts of individual images into the final generated images that are offered to the end-user. This is magical thinking.</p><p id="b39a" class="mq mr nn ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">Michael D. Murray, 26 SMU Science and Technology Law Review 259, 281 (2023)</p></blockquote><p id="2fce" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">And yet, models themselves do seem, in some circumstances, <a class="af nm" href="https://arxiv.org/pdf/2301.13188" rel="noopener ugc nofollow" target="_blank">to memorize training data</a>.</p><p id="b0fe" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">The following toy example is from a <a class="af nm" href="https://huggingface.co/spaces/nathanReitinger/modelProblems" rel="noopener ugc nofollow" target="_blank">Gradio Space on HuggingFace</a> which allows users to pick a model, see an output, and check — from that model’s training data — how similar the generated image is to any image in its training data. MNIST digits were used to generate because they are easy for the machine to parse, easy for humans to interpret in terms of similarity, and have the nice property of being easily classified — allowing a hunt of similarity to only consider images that are of the same number (efficiency gains).</p><blockquote class="oa ob oc"><p id="0572" class="mq mr nn ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">Let’s see how it works!</p></blockquote><p id="7739" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">The following image has a similarity score of .00039. RMSE stands for Root Mean Squared Error and is a way of assessing the similarity between two images. True enough, many other methods for similarity assessment exist, but RMSE gives you a pretty good idea of whether an image is a duplicate or not (i.e., we are not hunting for a legal definition of similarity here). As an example, an RMSE of &lt;.006 gets you into the nearly “copy” range, and an RMSE of &lt;.0009 is entering perfect copy territory (indistinguishable to the naked eye).</p><figure class="mk ml mm mn mo mj no np paragraph-image"><div role="button" tabindex="0" class="nr ns ed nt bh nu"><div class="no np nq"><img src="../Images/826e5055d8ed033dbdf5653fa61840b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eg-SUL91mdtSCFd1xEMwPQ.gif"/></div></div><figcaption class="nv nw nx no np ny nz bf b bg z dx"><a class="af nm" href="https://huggingface.co/spaces/nathanReitinger/modelProblems" rel="noopener ugc nofollow" target="_blank">🤗</a> A model that generates a nearly exact copy of training data (RMSE at .0003) <a class="af nm" href="https://huggingface.co/spaces/nathanReitinger/modelProblems" rel="noopener ugc nofollow" target="_blank">🤗</a></figcaption></figure><p id="8075" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">To use the <a class="af nm" href="https://huggingface.co/spaces/nathanReitinger/modelProblems" rel="noopener ugc nofollow" target="_blank">Gradio space</a>, follow these three steps (optionally build the space if it’s sleeping):</p><ul class=""><li id="148d" class="mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl od oe of bk"><strong class="ms fr">STEP 1</strong>: Select the type of pre-trained model to use</li><li id="00e2" class="mq mr fq ms b go og mu mv gr oh mx my mz oi nb nc nd oj nf ng nh ok nj nk nl od oe of bk"><strong class="ms fr">STEP 2</strong>: Hit “submit” and the model will generate an image for you (a 28x28 grayscale image)</li><li id="5d00" class="mq mr fq ms b go og mu mv gr oh mx my mz oi nb nc nd oj nf ng nh ok nj nk nl od oe of bk"><strong class="ms fr">STEP 3</strong>: The Gradio app searches through that model’s training data to identify the most similar image to the generated image (out of 60K examples)</li></ul><p id="39a1" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">As is plain to see, the image generated on the left (AI creation) is nearly an exact copy of the training data on the right when the “FASHION-diffusion-oneImage” model is used. And this makes sense. This model was trained on <em class="nn">only</em> a single image from the <a class="af nm" href="https://www.tensorflow.org/datasets/catalog/fashion_mnist" rel="noopener ugc nofollow" target="_blank">FASHION dataset</a>. The same is true for the “MNIST-diffusion-oneImage” model.</p><p id="2015" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">That said, even models trained on more images (e.g., 300, 3K, or 60K images) can produce eerily similar output. This example comes from a Generative Adversarial Network (GAN) trained on the full 60K image dataset (training only) of <a class="af nm" href="https://etzold.medium.com/mnist-dataset-of-handwritten-digits-f8cf28edafe" rel="noopener">MNIST hand-drawn digits</a>. As background, GANs are known to produce <a class="af nm" href="https://arxiv.org/abs/2301.13188" rel="noopener ugc nofollow" target="_blank">less-memorized generations</a> than diffusion models:</p><figure class="mk ml mm mn mo mj no np paragraph-image"><div role="button" tabindex="0" class="nr ns ed nt bh nu"><div class="no np ol"><img src="../Images/d11c66b90b7f39f29515de89eaa6a1b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T5-KTKF3m93ZLjB7KSvVsQ.png"/></div></div><figcaption class="nv nw nx no np ny nz bf b bg z dx">RMSE at .008</figcaption></figure><p id="aa60" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">Here’s another with a<strong class="ms fr"> </strong><em class="nn">diffusion model</em> trained on the 60K MNIST dataset (i.e., the type of model powering Stable Diffusion):</p><figure class="mk ml mm mn mo mj no np paragraph-image"><div role="button" tabindex="0" class="nr ns ed nt bh nu"><div class="no np om"><img src="../Images/f05a6c47cea9b8483157508ec39a87d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*suDFLIZAmNcMr8L85LXqAA.png"/></div></div><figcaption class="nv nw nx no np ny nz bf b bg z dx">RMSE at .004</figcaption></figure><p id="9b9b" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">Feel free to play around with the <a class="af nm" href="https://huggingface.co/spaces/nathanReitinger/modelProblems" rel="noopener ugc nofollow" target="_blank">Gradio space yourself</a>, investigate the models, or reach out to me with questions!</p><p id="2749" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk"><strong class="ms fr">Summary: </strong>The point of this small, toy example is that there is nothing mystical or absolute-copyright-nullifying about machine-learning models. Machine learning models can and do produce images that are copies of their training data — in other words, models can and do <em class="nn">store</em> protected content, and may therefore run into copyright problems. True enough, there are many counterarguments to be made here (my work in progress!); this demo should only be taken as anecdotal evidence of storage, and possibly a canary for developers working in this space.</p><p id="ef61" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk">What goes into a model is just as important as what comes out, and this is especially true for certain models performing certain tasks. We need to be careful and mindful of our “back boxes” because this analogy often turns out not to be true. That you cannot interpret for yourself the set of weights held by a model does not mean you escape all forms of liability or scrutiny.</p><p id="dd48" class="pw-post-body-paragraph mq mr fq ms b go mt mu mv gr mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl fj bk"><em class="nn">— </em><a class="af nm" href="https://nathanreitinger.umiacs.io" rel="noopener ugc nofollow" target="_blank"><em class="nn">@nathanReitinge</em></a><em class="nn">r stay tuned for further work in this space!</em></p></div></div></div><div class="ab cb on oo op oq" role="separator"><span class="or by bm os ot ou"/><span class="or by bm os ot ou"/><span class="or by bm os ot"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><pre class="mk ml mm mn mo ov ow ox bp oy bb bk"><span id="f4d4" class="oz pa fq ow b bg pb pc l pd pe">Unless otherwise noted, all images are by the author</span></pre></div></div></div></div>    
</body>
</html>