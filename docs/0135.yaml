- en: Evaluating Large Language Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/evaluating-large-language-models-a145b801dce0?source=collection_archive---------1-----------------------#2024-01-14](https://towardsdatascience.com/evaluating-large-language-models-a145b801dce0?source=collection_archive---------1-----------------------#2024-01-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Generative AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do you know how good your LLM is? A complete guide.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)
    ·19 min read·Jan 14, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e5f31c4eb999520c1f49d4d0f136d2d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Having gone mainstream over a year ago with the releases of Stable Diffusion
    and ChatGPT, generative AI is developing incredibly fast. New models claiming
    to beat the state-of-the-art are announced almost every week. But how do we know
    if they are actually any good? How do we compare and rank generative models in
    the absence of ground truth, the “correct” solutions? Finally, if the LLM is using
    external data through a Retrieval-Augmented Generation or RAG system, how do we
    judge whether it makes correct use of these data?
  prefs: []
  type: TYPE_NORMAL
- en: In a two-part series, we will explore evaluation protocols for generative AI.
    This post focuses on text generation and Large Language Models. Keep an eye out
    for a follow-up in which we will discuss evaluation methods for image generators.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating generated content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s start by noting the distinction between generative and discriminative
    models. Generative models generate new data samples, be it text, images, audio,
    video, latent representations, or even tabular data, that are similar to the model’s
    training data. Discriminative models, on the other hand, learn decision boundaries
    through the training data, allowing us to solve…
  prefs: []
  type: TYPE_NORMAL
