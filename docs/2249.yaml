- en: 'Bayesian Linear Regression: A Complete Beginner’s guide'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/bayesian-linear-regression-a-complete-beginners-guide-3a49bb252fdc?source=collection_archive---------1-----------------------#2024-09-14](https://towardsdatascience.com/bayesian-linear-regression-a-complete-beginners-guide-3a49bb252fdc?source=collection_archive---------1-----------------------#2024-09-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A workflow and code walkthrough for building a Bayesian regression model in
    **STAN**
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samvardhanvishnoi2026?source=post_page---byline--3a49bb252fdc--------------------------------)[![Samvardhan
    Vishnoi](../Images/a99d8db797d6ff346aed66cc84f0f32e.png)](https://medium.com/@samvardhanvishnoi2026?source=post_page---byline--3a49bb252fdc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3a49bb252fdc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3a49bb252fdc--------------------------------)
    [Samvardhan Vishnoi](https://medium.com/@samvardhanvishnoi2026?source=post_page---byline--3a49bb252fdc--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3a49bb252fdc--------------------------------)
    ·9 min read·Sep 14, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Check out my previous [article](https://medium.com/towards-data-science/a-practical-guide-to-becoming-a-bayesian-data-scientist-i-c4f7a1844825)
    for a practical discussion on why Bayesian modeling may be the right choice for
    your task.'
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial will focus on a workflow + code walkthrough for building a Bayesian
    regression model in **STAN**, a probabilistic programming language. STAN is widely
    adopted and interfaces with your language of choice (R, Python, shell, MATLAB,
    Julia, Stata). See the [installation](https://mc-stan.org/users/interfaces/) guide
    and [documentation](https://mc-stan.org/users/documentation/).
  prefs: []
  type: TYPE_NORMAL
- en: I will use [Pystan](https://pystan.readthedocs.io/en/latest/) for this tutorial,
    simply because I code in Python. Even if you use another language, the general
    Bayesian practices and STAN language syntax I will discuss here doesn’t vary much.
  prefs: []
  type: TYPE_NORMAL
- en: For the more hands-on reader, here is a link to the [notebook](https://github.com/samvardhan/stan_workshop/blob/main/stan_workshop.ipynb)
    for this tutorial, part of my Bayesian modeling workshop at Northwestern University
    (April, 2024).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive in!
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Linear Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lets learn how to build a simple linear regression model, the bread and butter
    of any statistician, the Bayesian way. Assuming a dependent variable **Y** and
    covariate **X**, I propose the following simple model-
  prefs: []
  type: TYPE_NORMAL
- en: '**Y** = α + β * **X** + ϵ'
  prefs: []
  type: TYPE_NORMAL
- en: Where ⍺ is the intercept, β is the slope, and ϵ is some random error. Assuming
    that,
  prefs: []
  type: TYPE_NORMAL
- en: ϵ ~ Normal(0, σ)
  prefs: []
  type: TYPE_NORMAL
- en: we can show that
  prefs: []
  type: TYPE_NORMAL
- en: '**Y** ~ Normal(α + β * **X,** σ)'
  prefs: []
  type: TYPE_NORMAL
- en: We will learn how to code this model form in STAN.
  prefs: []
  type: TYPE_NORMAL
- en: '**Generate Data**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s generate some fake data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6164a06655df22cfc765b4dc8df23e5e.png)'
  prefs: []
  type: TYPE_IMG
- en: Generated data for Linear Regression (Image from code by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Model String
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have some data to model, let’s dive into how to structure it and
    pass it to STAN along with modeling instructions. This is done via the *model*
    string, which typically contains 4 (occasionally more) blocks- *data*, *parameters*,
    *model*, and *generated* *quantities*. Let’s discuss each of these blocks in detail.
  prefs: []
  type: TYPE_NORMAL
- en: '**DATA block**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The *data* block is perhaps the simplest, it tells STAN internally what data
    it should expect, and in what format. For instance, here we pass-
  prefs: []
  type: TYPE_NORMAL
- en: '**N**: the size of our dataset as type *int*. The *<lower=0>* part declares
    that N≥0\. (Even though it is obvious here that data length cannot be negative,
    stating these bounds is good standard practice that can make STAN’s job easier.)'
  prefs: []
  type: TYPE_NORMAL
- en: '**x**: the covariate as a vector of length N.'
  prefs: []
  type: TYPE_NORMAL
- en: '**y**: the dependent as a vector of length N.'
  prefs: []
  type: TYPE_NORMAL
- en: See [docs here](https://mc-stan.org/docs/reference-manual/types.html#:~:text=Stan%20provides%20three%20real%2Dvalued,vectors%2C%20and%20matrix%20for%20matrices.)
    for a full range of supported data types. STAN offers support for a wide range
    of types like arrays, vectors, matrices etc. As we saw above, STAN also has support
    for encoding **limits** on variables. Encoding limits is recommended! It leads
    to better specified models and simplifies the probabilistic sampling processes
    operating under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: Model Block
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next is the *model* block, where we tell STAN the structure of our model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The model block also contains an important, and often confusing, element: *prior*
    specification. Priors are a **quintessential** part of Bayesian modeling, and
    must be specified suitably for the sampling task.'
  prefs: []
  type: TYPE_NORMAL
- en: See my previous [article](https://medium.com/towards-data-science/a-practical-guide-to-becoming-a-bayesian-data-scientist-i-c4f7a1844825)
    for a primer on the role and intuition behind priors. To summarize, the *prior*
    is a presupposed functional form for the distribution of parameter values — often
    referred to, simply, as *prior belief*. Even though priors **don’t** have to exactly
    **match** the final solution, they must allow us to **sample** from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, we use Normal priors of mean 0 with different variances, depending
    on how sure we are of the supplied mean value: 10 for alpha (very unsure), 1 for
    beta (somewhat sure). Here, I supplied the general *belief* that while alpha can
    take a wide range of different values, the slope is generally more contrained
    and won’t have a large magnitude.'
  prefs: []
  type: TYPE_NORMAL
- en: Hence, in the example above, the prior for alpha is ‘weaker’ than beta.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As models get more complicated, the sampling solution space expands, and supplying
    beliefs gains importance. Otherwise, if there is no strong intuition, it is good
    practice to just supply less belief into the model i.e. use a **weakly informative**
    prior, and remain flexible to incoming data.
  prefs: []
  type: TYPE_NORMAL
- en: The form for y, which you might have recognized already, is the standard linear
    regression equation.
  prefs: []
  type: TYPE_NORMAL
- en: Generated Quantities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lastly, we have our block for *generated quantities*. Here we tell STAN what
    quantities we want to calculate and receive as output.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Note: STAN supports vectors to be passed either directly into equations, or
    as iterations 1:N for each element n. In practice, I’ve found this support to
    change with different versions of STAN, so it is good to try the iterative declaration
    if the vectorized version fails to compile.'
  prefs: []
  type: TYPE_NORMAL
- en: In the above example-
  prefs: []
  type: TYPE_NORMAL
- en: '**yhat:** generates samples for y from the fitted parameter values.'
  prefs: []
  type: TYPE_NORMAL
- en: '**log_lik:** generates probability of data given the model and fitted parameter
    value.'
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of these values will be clearer when we talk about model evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Altogether, we have now fully specified our first simple Bayesian regression
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: All that remains is to compile the model and run the sampling.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: STAN takes input data in the form of a dictionary. It is important that this
    dict contains all the variables that we told STAN to expect in the model-data
    block, otherwise the model won’t compile.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**num_chains:** is the number of times we repeat the sampling process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**num_samples:** is the number of samples to be drawn in each chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**warmup:** is the number of initial samples that we discard (as it takes some
    time to reach the general vicinity of the solution space).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Knowing the right values for these parameters depends on both the complexity
    of our model and the resources available.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Higher sampling sizes are of course ideal, yet for an ill-specified model they
    will prove to be just waste of time and computation. Anecdotally, I’ve had large
    data models I’ve had to wait a week to finish running, only to find that the model
    didn’t converge. Is is important to start slowly and sanity check your model before
    running a full-fledged sampling.
  prefs: []
  type: TYPE_NORMAL
- en: Model Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The generated quantities are used for
  prefs: []
  type: TYPE_NORMAL
- en: evaluating the goodness of fit i.e. convergence,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: model comparison
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Convergence**'
  prefs: []
  type: TYPE_NORMAL
- en: The first step for evaluating the model, in the Bayesian framework, is visual.
    We observe the sampling draws of the [Hamiltonian Monte Carlo](https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo)
    (HMC) sampling process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b5a5120fa7102b295945615ecfe1bbc2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Model Convergence: visually evaluating the overlap of independent sampling
    chains (Image from code by Author)'
  prefs: []
  type: TYPE_NORMAL
- en: In simplistic terms, STAN iteratively draws samples for our parameter values
    and evaluates them (HMC does *way* more, but that’s beyond our current scope).
    For a good fit, the sample draws must **converge** to some common general area
    which would, ideally, be the global **optima**.
  prefs: []
  type: TYPE_NORMAL
- en: The figure above shows the sampling draws for our model across 2 independent
    chains (red and blue).
  prefs: []
  type: TYPE_NORMAL
- en: On the left, we plot the overall distribution of the fitted parameter value
    i.e. the **posteriors**. We expect a **normal** distribution if the model, and
    its parameters, are **well specified**. (*Why* is that? Well, a normal distribution
    just implies that there exist a certain range of best fit values for the parameter,
    which speaks in support of our chosen model form). Furthermore, we should expect
    a considerable **overlap** across chains **IF** the model is converging to an
    optima.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the right, we plot the actual samples drawn in each iteration (just to be
    *extra* sure). Here, again, we wish to see not only a **narrow** range but also
    a lot of **overlap** between the draws.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not all evaluation metrics are visual. Gelman et al. [1] also propose the **Rhat**
    diagnostic which essentially is a mathematical measure of the sample similarity
    across chains. Using Rhat, one can define a cutoff point beyond which the two
    chains are judged too dissimilar to be converging. The cutoff, however, is hard
    to define due to the iterative nature of the process, and the variable warmup
    periods.
  prefs: []
  type: TYPE_NORMAL
- en: Visual comparison is hence a crucial component, regardless of diagnostic tests
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A frequentist thought you may have here is that, “well, if all we have is chains
    and distributions, what is the actual parameter value?” This is exactly the point.
    The Bayesian formulation only deals in **distributions**, NOT **point** estimates
    with their hard-to-interpret test statistics.
  prefs: []
  type: TYPE_NORMAL
- en: That said, the posterior can still be summarized using **credible** intervals
    like the **High Density Interval (HDI**), which includes all the x% highest probability
    density points.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/59d883677a32fba505646b0a126d59da.png)'
  prefs: []
  type: TYPE_IMG
- en: 95% HDI for beta (Image from code by Author)
  prefs: []
  type: TYPE_NORMAL
- en: It is important to contrast Bayesian **credible** intervals with frequentist
    **confidence** intervals.
  prefs: []
  type: TYPE_NORMAL
- en: The credible interval gives a **probability** distribution on the **possible
    values** for the **parameter** i.e. the probability of the parameter assuming
    each value in some interval, given the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The confidence interval regards the **parameter** value as **fixed**, and estimates
    instead the confidence that **repeated** random **samplings** of the data would
    **match**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hence the
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian approach lets the parameter values be fluid and takes the data at face
    value, while the frequentist approach demands that there exists the one true parameter
    value… if only we had access to all the data ever
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Phew. Let that sink in, read it again until it does.
  prefs: []
  type: TYPE_NORMAL
- en: Another important implication of using credible intervals, or in other words,
    allowing the parameter to be **variable**, is that the predictions we make capture
    this **uncertainty** with **transparency**, with a certain HDI % informing the
    best fit line.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1dffd2b876d486a412c8f23896cfd326.png)'
  prefs: []
  type: TYPE_IMG
- en: 95% HDI line of best fit (Image from code by Author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Model comparison**'
  prefs: []
  type: TYPE_NORMAL
- en: In the Bayesian framework, the Watanabe-Akaike Information Metric (**WAIC**)
    score is the widely accepted choice for model comparison. A simple explanation
    of the WAIC score is that it estimates the model **likelihood** while **regularizing**
    for the number of model parameters. In simple words, it can account for overfitting.
    This is also major draw of the Bayesian framework — one does **not** necessarily
    **need** to hold-out a model **validation** dataset. Hence,
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian modeling offers a crucial advantage when data is scarce.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The WAIC score is a **comparative** measure i.e. it only holds meaning when
    compared across different models that attempt to explain the same underlying data.
    Thus in practice, one can keep adding more complexity to the model as long as
    the WAIC increases. If at some point in this process of adding maniacal complexity,
    the WAIC starts dropping, one can call it a day — any more complexity will not
    offer an informational advantage in describing the underlying data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To summarize, the STAN model block is simply a string. It explains to STAN what
    you are going to give to it (model), what is to be found (parameters), what you
    think is going on (model), and what it should give you back (generated quantities).
  prefs: []
  type: TYPE_NORMAL
- en: When turned on, STAN simple turns the crank and gives its output.
  prefs: []
  type: TYPE_NORMAL
- en: The real challenge lies in defining a proper model (refer priors), structuring
    the data appropriately, asking STAN exactly what you need from it, and evaluating
    the sanity of its output.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Once we have this part down, we can delve into the real power of STAN, where
    specifying increasingly complicated models becomes just a simple syntactical task.
    In fact, in our next tutorial we will do exactly this. We will build upon this
    simple regression example to explore Bayesian **Hierarchical** models: an industry
    standard, state-of-the-art, defacto… you name it. We will see how to add group-level
    radom or fixed effects into our models, and marvel at the ease of adding complexity
    while maintaining comparability in the Bayesian framework.'
  prefs: []
  type: TYPE_NORMAL
- en: Subscribe if this article helped, and to stay-tuned for more!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari
    and Donald B. Rubin (2013). *Bayesian Data Analysis, Third Edition*. Chapman and
    Hall/CRC.'
  prefs: []
  type: TYPE_NORMAL
