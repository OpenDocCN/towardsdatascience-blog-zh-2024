- en: Can Transformers Solve Everything?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/can-transformers-solve-everything-0421ebaf9f8e?source=collection_archive---------1-----------------------#2024-10-01](https://towardsdatascience.com/can-transformers-solve-everything-0421ebaf9f8e?source=collection_archive---------1-----------------------#2024-10-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Looking into the math and the data reveals that transformers are both overused
    and underused.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@crackalamoo?source=post_page---byline--0421ebaf9f8e--------------------------------)[![Harys
    Dalvi](../Images/cf7fa3865063408efd1fd4c0b4b603db.png)](https://medium.com/@crackalamoo?source=post_page---byline--0421ebaf9f8e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0421ebaf9f8e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0421ebaf9f8e--------------------------------)
    [Harys Dalvi](https://medium.com/@crackalamoo?source=post_page---byline--0421ebaf9f8e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0421ebaf9f8e--------------------------------)
    ·13 min read·Oct 1, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Transformers are best known for their applications in natural language processing.
    They were originally designed for translating between languages,[[1](https://arxiv.org/pdf/1706.03762)]
    and are now most famous for their use in large language models like ChatGPT (generative
    pretrained *transformer*).
  prefs: []
  type: TYPE_NORMAL
- en: But since their introduction, transformers have been applied to ever more tasks,
    with great results. These include image recognition,[[2](https://arxiv.org/abs/2010.11929)]
    reinforcement learning,[[3](https://arxiv.org/abs/2106.01345)] and even weather
    prediction.[[4](https://arxiv.org/abs/2312.03876)]
  prefs: []
  type: TYPE_NORMAL
- en: Even the seemingly specific task of language generation with transformers has
    a number of surprises, as we’ve already seen. Large language models have emergent
    properties that feel more intelligent than just predicting the next word. For
    example, they may know various facts about the world, or replicate nuances of
    a person’s style of speech.
  prefs: []
  type: TYPE_NORMAL
- en: The success of transformers has made some people ask the question of whether
    transformers can do everything. If transformers generalize to so many tasks, is
    there any reason *not* to use a transformer?
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, there is still a case for other machine learning models and, as is
    often forgotten these days, non-machine learning models and human intellect. But
    transformers do have a number of unique properties, and have shown incredible
    results so far. There is also a considerable mathematical and empirical basis…
  prefs: []
  type: TYPE_NORMAL
