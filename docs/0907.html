<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Generate “Verified” Python Code Using AutoGen Conversable Agents</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Generate “Verified” Python Code Using AutoGen Conversable Agents</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generate-verified-python-code-using-autogen-conversable-agents-2102b4f706ba?source=collection_archive---------9-----------------------#2024-04-09">https://towardsdatascience.com/generate-verified-python-code-using-autogen-conversable-agents-2102b4f706ba?source=collection_archive---------9-----------------------#2024-04-09</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="39f7" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Leverage multi-agentic workflows for code testing and debugging</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@shahzebnaveed?source=post_page---byline--2102b4f706ba--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Shahzeb Naveed" class="l ep by dd de cx" src="../Images/cdf5a3f205eac63306d1f8384fa634ab.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*lwSIlrPsjTtSJzCs8lEHpw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--2102b4f706ba--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@shahzebnaveed?source=post_page---byline--2102b4f706ba--------------------------------" rel="noopener follow">Shahzeb Naveed</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--2102b4f706ba--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 9, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mj bh"><figure class="mk ml mm mn mo mj bh paragraph-image"><img src="../Images/743dc56e1a6501a8f27b1ed2ffcf407f.png" data-original-src="https://miro.medium.com/v2/resize:fit:4608/format:webp/1*IDG5NM3Qtyj2ILUS7DsVSA.png"/><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">“Two AI bots solving an Error” —Source: Adobe Firefly (Image generated by author)</figcaption></figure></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="276e" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk nt"><span class="l nu nv nw bo nx ny nz oa ob ed">I</span>t’s April 2024 and it’s been about 17 months since we’ve been using LLMs like ChatGPT to aid us in code generation and debugging tasks. While it has added a great level of productivity, there are indeed times when the code generated is full of bugs and makes us take the good ole StackOverflow route.</p><p id="b732" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In this article, I’ll give a quick demonstration on how we can address this lack of “verification” using Conversable Agents offered by AutoGen.</p><p id="f484" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Full AutoGen Course: <a class="af oc" href="https://www.youtube.com/playlist?list=PLlHeJrpDA0jXy_zgfzt2aUvQu3_VS5Yx_" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/playlist?list=PLlHeJrpDA0jXy_zgfzt2aUvQu3_VS5Yx_</a></p><p id="39a4" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><strong class="mz fr">What is AutoGen?</strong></p><blockquote class="od oe of"><p id="2172" class="mx my og mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">“AutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks.”</p></blockquote><p id="92e8" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><strong class="mz fr">Presenting LeetCode Problem Solver:</strong></p><p id="c4a4" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Start with quietly installing autogen:</p><pre class="mk ml mm mn mo oh oi oj bp ok bb bk"><span id="906a" class="ol om fq oi b bg on oo l op oq">!pip install pyautogen -q --progress-bar off</span></pre><p id="484f" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">I’m using Google Colab so I entered by OPENAI_API_KEY in the Secrets tab, and securely loaded it along with other modules:</p><pre class="mk ml mm mn mo oh oi oj bp ok bb bk"><span id="53d8" class="ol om fq oi b bg on oo l op oq">import os<br/>import csv<br/>import autogen<br/>from autogen import Cache<br/>from google.colab import userdata<br/>userdata.get('OPENAI_API_KEY')</span></pre><p id="5e55" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">I’m using <code class="cx or os ot oi b">gpt-3.5-turbo</code> only because it’s cheaper than <code class="cx or os ot oi b">gpt4</code>. If you can afford more expensive experimentation and/or you’re doing things more “seriously”, you should obviously use a stronger model.</p><pre class="mk ml mm mn mo oh oi oj bp ok bb bk"><span id="fa9d" class="ol om fq oi b bg on oo l op oq">llm_config = {<br/>    "config_list": [{"model": "gpt-3.5-turbo", "api_key": userdata.get('OPENAI_API_KEY')}],<br/>    "cache_seed": 0,  # seed for reproducibility<br/>    "temperature": 0,  # temperature to control randomness<br/>}</span></pre><p id="a34c" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Now, I’ll copy the problem statement from my favourite LeetCode problem <a class="af oc" href="https://leetcode.com/problems/two-sum/description/" rel="noopener ugc nofollow" target="_blank"><em class="og">Two Sum</em></a><em class="og">. </em>It’s one of the most commonly asked questions in leetcode-style interviews and covers basic concepts like caching using hashmaps and basic equation manipulation.</p><pre class="mk ml mm mn mo oh oi oj bp ok bb bk"><span id="e63f" class="ol om fq oi b bg on oo l op oq">LEETCODE_QUESTION = """<br/>Title: Two Sum<br/><br/>Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target. You may assume that each input would have exactly one solution, and you may not use the same element twice. You can return the answer in any order.<br/><br/>Example 1:<br/>Input: nums = [2,7,11,15], target = 9<br/>Output: [0,1]<br/>Explanation: Because nums[0] + nums[1] == 9, we return [0, 1].<br/><br/>Example 2:<br/>Input: nums = [3,2,4], target = 6<br/>Output: [1,2]<br/><br/>Example 3:<br/>Input: nums = [3,3], target = 6<br/>Output: [0,1]<br/><br/>Constraints:<br/><br/>2 &lt;= nums.length &lt;= 104<br/>-109 &lt;= nums[i] &lt;= 109<br/>-109 &lt;= target &lt;= 109<br/>Only one valid answer exists.<br/><br/>Follow-up: Can you come up with an algorithm that is less than O(n2) time complexity?<br/>"""</span></pre><p id="fab3" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">We can now define both of our agents. One agent acts as the “assistant” agent that suggests the solution and the other serves as a proxy to us, the user and is also responsible for executing the suggested Python code.</p><pre class="mk ml mm mn mo oh oi oj bp ok bb bk"><span id="23cb" class="ol om fq oi b bg on oo l op oq"># create an AssistantAgent named "assistant"<br/><br/>SYSTEM_MESSAGE = """You are a helpful AI assistant.<br/>Solve tasks using your coding and language skills.<br/>In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.<br/>1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.<br/>2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.<br/>Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.<br/>When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.<br/>If you want the user to save the code in a file before executing it, put # filename: &lt;filename&gt; inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.<br/>If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.<br/>When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.<br/><br/>Additional requirements:<br/>1. Within the code, add functionality to measure the total run-time of the algorithm in python function using "time" library.<br/>2. Only when the user proxy agent confirms that the Python script ran successfully and the total run-time (printed on stdout console) is less than 50 ms, only then return a concluding message with the word "TERMINATE". Otherwise, repeat the above process with a more optimal solution if it exists.<br/>"""<br/><br/>assistant = autogen.AssistantAgent(<br/>    name="assistant",<br/>    llm_config=llm_config,<br/>    system_message=SYSTEM_MESSAGE<br/>)<br/><br/># create a UserProxyAgent instance named "user_proxy"<br/>user_proxy = autogen.UserProxyAgent(<br/>    name="user_proxy",<br/>    human_input_mode="NEVER",<br/>    max_consecutive_auto_reply=4,<br/>    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),<br/>    code_execution_config={<br/>        "work_dir": "coding",<br/>        "use_docker": False,<br/>    },<br/>)</span></pre><p id="4af5" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">I set the <code class="cx or os ot oi b">human_input_mode</code> to “NEVER” because I’m not planning to give any inputs myself and <code class="cx or os ot oi b">max_consecutive_auto_reply</code> to 4 to limit the back-and-forth turns in the conversation. The Assistant agent has been instructed to respond with the word “TERMINATE” that tells the UserProxyAgent when to conclude the conversation.</p><p id="f154" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Now, the fun time! We’ll initiate the conversation by sending a message from our UserProxyAgent to our Assistant.</p><p id="477d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">One added benefit of using AutoGen (even for non-agentic workflows) is that it provides explicit caching capability to help you save API costs during development. Here, I’m caching responses on the disk but you can also integrate redis for this purpose.</p><pre class="mk ml mm mn mo oh oi oj bp ok bb bk"><span id="28b8" class="ol om fq oi b bg on oo l op oq"># Use DiskCache as cache<br/>with Cache.disk(cache_seed=7) as cache:<br/>  # the assistant receives a message from the user_proxy, which contains the task description<br/>  chat_res = user_proxy.initiate_chat(<br/>      assistant,<br/>      message="""Solve the following leetcode problem and also comment on it's time and space complexity:\n\n""" + LEETCODE_QUESTION<br/>)</span></pre><p id="a75a" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><strong class="mz fr">Output:</strong></p><pre class="mk ml mm mn mo oh oi oj bp ok bb bk"><span id="4608" class="ol om fq oi b bg on oo l op oq">user_proxy (to assistant):<br/><br/>Solve the following leetcode problem and also comment on it's time and space complexity:<br/><br/><br/>Title: Two Sum<br/><br/>...<br/><br/>Follow-up: Can you come up with an algorithm that is less than O(n2) time complexity?<br/><br/><br/>--------------------------------------------------------------------------------<br/>assistant (to user_proxy):<br/><br/>To solve this problem efficiently, we can use a dictionary to store the elements we have seen so far along with their indices. While iterating through the array, we can check if the complement of the current element (target - current element) is already in the dictionary. If it is, we have found the pair that sums up to the target.<br/><br/>Here's the Python code to solve the Two Sum problem with a time complexity less than O(n^2):<br/><br/>```python<br/># filename: two_sum.py<br/>def two_sum(nums, target):<br/>    num_dict = {}<br/>    for i, num in enumerate(nums):<br/>        complement = target - num<br/>        if complement in num_dict:<br/>            return [num_dict[complement], i]<br/>        num_dict[num] = i<br/><br/># Test the function with the given examples<br/>nums1 = [2, 7, 11, 15]<br/>target1 = 9<br/>print(two_sum(nums1, target1))  # Output: [0, 1]<br/><br/>nums2 = [3, 2, 4]<br/>target2 = 6<br/>print(two_sum(nums2, target2))  # Output: [1, 2]<br/><br/>nums3 = [3, 3]<br/>target3 = 6<br/>print(two_sum(nums3, target3))  # Output: [0, 1]<br/>```<br/><br/>The time complexity of this solution is O(n) because we iterate through the list of numbers only once. The space complexity is also O(n) because we store elements in a dictionary.<br/><br/>You can run this code and check if it provides the correct output. Let me know the total run-time, and if it's less than 50 ms, you can reply with "TERMINATE". If it's not, I can suggest a more optimal solution.<br/><br/>--------------------------------------------------------------------------------<br/><br/>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; EXECUTING CODE BLOCK 0 (inferred language is python)...<br/>user_proxy (to assistant):<br/><br/>exitcode: 0 (execution succeeded)<br/>Code output: <br/>[0, 1]<br/>[1, 2]<br/>[0, 1]<br/><br/><br/>--------------------------------------------------------------------------------<br/>assistant (to user_proxy):<br/><br/>The Python script ran successfully and provided the correct output for the given examples. Since the total run-time is not provided, I will suggest measuring the total run-time of the algorithm using the "time" library to determine if it's less than 50 ms. <br/><br/>You can add the functionality to measure the total run-time by importing the "time" library and using it to calculate the elapsed time before and after calling the `two_sum` function. Here's how you can modify the code:<br/><br/>```python<br/># filename: two_sum.py<br/>import time<br/><br/>def two_sum(nums, target):<br/>    num_dict = {}<br/>    for i, num in enumerate(nums):<br/>        complement = target - num<br/>        if complement in num_dict:<br/>            return [num_dict[complement], i]<br/>        num_dict[num] = i<br/><br/># Test the function with the given examples and measure the total run-time<br/>nums1 = [2, 7, 11, 15]<br/>target1 = 9<br/>start_time = time.time()<br/>print(two_sum(nums1, target1))  # Output: [0, 1]<br/>end_time = time.time()<br/>print("Total run-time:", (end_time - start_time) * 1000, "ms")<br/><br/>nums2 = [3, 2, 4]<br/>target2 = 6<br/>start_time = time.time()<br/>print(two_sum(nums2, target2))  # Output: [1, 2]<br/>end_time = time.time()<br/>print("Total run-time:", (end_time - start_time) * 1000, "ms")<br/><br/>nums3 = [3, 3]<br/>target3 = 6<br/>start_time = time.time()<br/>print(two_sum(nums3, target3))  # Output: [0, 1]<br/>end_time = time.time()<br/>print("Total run-time:", (end_time - start_time) * 1000, "ms")<br/>```<br/><br/>Please run this modified code and provide the total run-time for each example. If the total run-time is less than 50 ms for all examples, you can reply with "TERMINATE".<br/><br/>--------------------------------------------------------------------------------<br/><br/>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; EXECUTING CODE BLOCK 0 (inferred language is python)...<br/>user_proxy (to assistant):<br/><br/>exitcode: 0 (execution succeeded)<br/>Code output: <br/>[0, 1]<br/>Total run-time: 0.01239776611328125 ms<br/>[1, 2]<br/>Total run-time: 0.00286102294921875 ms<br/>[0, 1]<br/>Total run-time: 0.0016689300537109375 ms<br/><br/><br/>--------------------------------------------------------------------------------<br/>assistant (to user_proxy):<br/><br/>The Python script ran successfully, and the total run-time for each example is significantly less than 50 ms. Therefore, you can reply with "TERMINATE". The algorithm provided an efficient solution with a time complexity of O(n) and a space complexity of O(n).<br/><br/>--------------------------------------------------------------------------------</span></pre><p id="89f9" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This is what’s happening here:</p><ol class=""><li id="9940" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns ou ov ow bk">The UserProxyAgent asks the Assistant to solve the problem based on the task description.</li><li id="416d" class="mx my fq mz b go ox nb nc gr oy ne nf ng oz ni nj nk pa nm nn no pb nq nr ns ou ov ow bk">The Assistant suggests a solution with a Python block</li><li id="a1d5" class="mx my fq mz b go ox nb nc gr oy ne nf ng oz ni nj nk pa nm nn no pb nq nr ns ou ov ow bk">The UserProxyAgent executes the python code.</li><li id="43b1" class="mx my fq mz b go ox nb nc gr oy ne nf ng oz ni nj nk pa nm nn no pb nq nr ns ou ov ow bk">The Assistant reads the console output and responds back with a modified solution (with time measurement functionality. Honestly, I would’ve expected this modified solution right away but this behavior can be tuned through prompt engineering or by employing a stronger LLM).</li></ol><p id="7f96" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">With AutoGen, you can also display the cost of the agentic workflow.</p><pre class="mk ml mm mn mo oh oi oj bp ok bb bk"><span id="9404" class="ol om fq oi b bg on oo l op oq">chat_res.cost</span></pre><pre class="pc oh oi oj bp ok bb bk"><span id="2a43" class="ol om fq oi b bg on oo l op oq"><br/>({'total_cost': 0,<br/>  'gpt-3.5-turbo-0125': {'cost': 0,<br/>   'prompt_tokens': 14578,<br/>   'completion_tokens': 3460,<br/>   'total_tokens': 18038}}</span></pre><p id="1746" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><strong class="mz fr">Concluding Remarks:</strong></p><p id="9d57" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Thus, by using AutoGen’s conversable agents:</p><ol class=""><li id="3fc2" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns ou ov ow bk">We automatically verified that the Python code suggested by the LLM actually works.</li><li id="4cd5" class="mx my fq mz b go ox nb nc gr oy ne nf ng oz ni nj nk pa nm nn no pb nq nr ns ou ov ow bk">And created a framework by which the LLM can further respond to syntax or logical errors by reading the output in the console.</li></ol><p id="0d48" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><em class="og">Thanks for reading! Please follow me and subscribe to be the first when I post a new article! :)</em></p><p id="f2ac" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><em class="og">Check out my other articles:</em></p><ol class=""><li id="4d52" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns ou ov ow bk"><a class="af oc" href="https://medium.com/thedeephub/a-deep-dive-into-evaluation-in-azure-prompt-flow-dd898ebb158c" rel="noopener"><em class="og">A Deep Dive into Evaluation in Azure Prompt Flow</em></a></li><li id="65f8" class="mx my fq mz b go ox nb nc gr oy ne nf ng oz ni nj nk pa nm nn no pb nq nr ns ou ov ow bk"><a class="af oc" href="https://medium.com/thedeephub/develop-a-ui-for-azure-prompt-flow-with-streamlit-f425342029ce" rel="noopener"><em class="og">Develop a UI for Azure Prompt Flow with Streamlit</em></a></li><li id="097d" class="mx my fq mz b go ox nb nc gr oy ne nf ng oz ni nj nk pa nm nn no pb nq nr ns ou ov ow bk"><a class="af oc" href="https://medium.com/thedeephub/build-a-custom-chatbot-using-hugging-face-chat-ui-and-cosmos-db-on-azure-kubernetes-service-0e391c00cd78" rel="noopener"><em class="og">Build a custom Chatbot using Hugging Face Chat UI and Cosmos DB on Azure Kubernetes Service</em></a></li><li id="e051" class="mx my fq mz b go ox nb nc gr oy ne nf ng oz ni nj nk pa nm nn no pb nq nr ns ou ov ow bk"><a class="af oc" href="https://medium.com/thedeephub/deploy-hugging-face-text-generation-inference-on-azure-container-instance-3709eb3d3187" rel="noopener"><em class="og">Deploy Hugging Face Text Generation Inference on Azure Container Instance</em></a></li></ol></div></div></div></div>    
</body>
</html>