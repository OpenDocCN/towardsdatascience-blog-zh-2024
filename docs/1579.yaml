- en: Improving RAG Performance Using Rerankers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/improving-rag-performance-using-rerankers-6adda61b966d?source=collection_archive---------9-----------------------#2024-06-25](https://towardsdatascience.com/improving-rag-performance-using-rerankers-6adda61b966d?source=collection_archive---------9-----------------------#2024-06-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A tutorial on using rerankers to improve your RAG pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@het.trivedi05?source=post_page---byline--6adda61b966d--------------------------------)[![Het
    Trivedi](../Images/f6f11a66f60cacc6b553c7d1682b2fc6.png)](https://medium.com/@het.trivedi05?source=post_page---byline--6adda61b966d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6adda61b966d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6adda61b966d--------------------------------)
    [Het Trivedi](https://medium.com/@het.trivedi05?source=post_page---byline--6adda61b966d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6adda61b966d--------------------------------)
    ·10 min read·Jun 25, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/768d657abb899c5596fa24028e1a7b70.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by author using Stable Diffusion XL
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RAG is one of the first tools an engineer will try out when building an LLM
    application. It’s easy enough to understand and simple to use. The primary motive
    when using vector search is to gather enough relevant context so that the output
    of the LLM is of higher quality.
  prefs: []
  type: TYPE_NORMAL
- en: Although vector search can perform quite well out of the box, there are still
    many cases where the results don’t hit the mark. For example, with vector embedding
    the `top k` results might not contain all the relevant information. To compensate
    for this, `top k` can be set to a larger value. However, this comes with a new
    set of problems.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a86a8eea58ba77bf1ab019498c6156ce.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of documents exceeds the size of the LLM context window
  prefs: []
  type: TYPE_NORMAL
- en: Even though LLMs support larger context windows, there is only so much information
    you can fit. The higher the `top k` value, the more difficult it becomes to fit
    everything into the context. Although the embeddings are sorted by cosine similarity,
    this doesn’t guarantee that the most pertinent content will be at the top. This
    is partly because vector search typically relies on pre-computed embeddings, which
    may not…
  prefs: []
  type: TYPE_NORMAL
