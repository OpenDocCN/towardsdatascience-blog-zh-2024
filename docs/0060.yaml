- en: 'Ablation Testing Neural Networks: The Compensatory Masquerade'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ablation-testing-neural-networks-the-compensatory-masquerade-ba27d0037a88?source=collection_archive---------5-----------------------#2024-01-07](https://towardsdatascience.com/ablation-testing-neural-networks-the-compensatory-masquerade-ba27d0037a88?source=collection_archive---------5-----------------------#2024-01-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Disruptively testing parts of neural networks and other ML architectures to
    make them more robust
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://squoraishee.medium.com/?source=post_page---byline--ba27d0037a88--------------------------------)[![Shafik
    Quoraishee](../Images/439d3502b98af4d994a8fab33b8bb428.png)](https://squoraishee.medium.com/?source=post_page---byline--ba27d0037a88--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ba27d0037a88--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ba27d0037a88--------------------------------)
    [Shafik Quoraishee](https://squoraishee.medium.com/?source=post_page---byline--ba27d0037a88--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ba27d0037a88--------------------------------)
    ·8 min read·Jan 7, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17facce6e4c4b29da7fcbbde246cf1b7.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image generated by author using DALL-E). Interesting what AI thinks of it’s
    own brain.
  prefs: []
  type: TYPE_NORMAL
- en: In a similar fashion to how a person’s intellect can be stress tested, Artificial
    Neural Networks can be subjected to a gamut of tests to evaluate how robust they
    are to different kinds of disruption, by running what’s called controlled Ablation
    Testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get into [ablation testing](https://en.wikipedia.org/wiki/Ablation_(artificial_intelligence)),
    lets talk about a familiar technique in “destructive evolution” that many people
    who study machine learning and artificial intelligence applications might be familiar
    with: [Regularization](https://en.wikipedia.org/wiki/Regularization_(mathematics))'
  prefs: []
  type: TYPE_NORMAL
- en: '**Regularization**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regulariztion is a very well known example of ablating, or selectively destroying/deactivating
    parts of a neural network and re-training it to make it an even more powerful
    classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Through a process called [Dropout](https://en.wikipedia.org/wiki/Dilution_(neural_networks)),
    neurons can be deactivated in a controlled way, which allow the work of the neural
    network that was previously handled by the now defunct neurons, to be taken up
    by nearby active neurons.
  prefs: []
  type: TYPE_NORMAL
- en: In nature, the brain actually can undergo similar phenomenon due to the concept
    of neuro-plasticity. If a person suffers brain damage, in some cases nearby neurons
    and brain structures can reorganize to help take up some of the functionality
    of the dead brain tissue.
  prefs: []
  type: TYPE_NORMAL
- en: Or how if someone loses one of their senses, like vision, oftentimes their other
    senses become stronger to make up for their missing capability.
  prefs: []
  type: TYPE_NORMAL
- en: This is also known as the [Compensatory Masquerade](https://www.britannica.com/science/compensatory-masquerade).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38cb217c01889fc9be7aaf32bad46223.png)'
  prefs: []
  type: TYPE_IMG
- en: A fully connected Neural Network to the left, and randomized dropout version
    on the right. In many cases, these networks may actually perform comparatively
    well (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Ablation Testing**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While regularization is a technique used in neural networks and other A.I. architectures
    to aide in training a neural network better through artificial “[neuroplasticity](https://en.wikipedia.org/wiki/Neuroplasticity)”,
    sometimes we want to just do a similar procedure on a neural network to see how
    it will behave in the presence of deactivations in terms of accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We might do this for several other reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identifying Critical Parts of a Neural Network:** Some parts of a neural
    network may do more important work than other parts of a neural network. In order
    to optimize the resource usage and the training time of the network, we can selectively
    ablate “weaker learners”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reducing Complexity of the Neural Network:** Sometimes neural networks can
    get quite large, especially in the case of Deep MLPs ([multi layer perceptrons](https://en.wikipedia.org/wiki/Multilayer_perceptron)).
    This can make it difficult to map their behavior from input to output. By selectively
    shutting of parts of the network, we can potentially identify regions of excessive
    complexity and remove redundancy — simplifying our architecture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault Tolerance:** In a realtime system, parts of a system can fail. The
    same applies for parts of a neural network, and thus the systems that depend on their output as we.
    We can turn to ablation studies to determine if destroying certain parts of the
    neural network, will cause the predictive or generative power of the system to
    suffer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Types of Ablation Tests**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are actually many different kinds of ablation tests, and here we are
    going to talk about 3 specific kinds:'
  prefs: []
  type: TYPE_NORMAL
- en: Neuronal Ablation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functional Ablation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Input Ablation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quick note that ablation tests will have different effects depending on the
    network you are testing against and the data itself. An ablation test might demonstrate
    weakness in 1 part of the network for a specific data set, and may demonstrate
    weakness in another part of the neural network for a different ablation test.
    That is why that in a truly robust ablation testing system, you will need a wide
    variety of tests to get an accurate picture of the ANN’s ([Artificial Neural Network](https://en.wikipedia.org/wiki/Artificial_neural_network))
    weak points.
  prefs: []
  type: TYPE_NORMAL
- en: '**Neuronal Ablation**'
  prefs: []
  type: TYPE_NORMAL
- en: This is the first kind of ablation test we are going to run, and it’s the simplest
    to see the effects of and extend. We will simply remove varying percentages of
    neurons from our neural network
  prefs: []
  type: TYPE_NORMAL
- en: For our experiment we have a simple ANN set up to test the accuracy of random
    character prediction agains using our old friend the [MNIST data set](https://en.wikipedia.org/wiki/MNIST_database).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/193196488e4f29b9aee031723542889b.png)'
  prefs: []
  type: TYPE_IMG
- en: A snapshot of digit data from the MNIST data set (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code I wrote as a simple ANN test harness to test digit classification
    accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: So if we run the above code we see the following result of deactivating increasing
    percentages of our 128 node MLP.
  prefs: []
  type: TYPE_NORMAL
- en: The results are fairly interesting in this simple example, where as you can
    see dropping 80% of the neurons barely effects the accuracy, which means that
    removing excess neurons is certainly an optimization we could consider in building
    this network.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8804627f95e4e423a2bdd894aef0979b.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph generated for dropout ablation test (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Functional Ablation**'
  prefs: []
  type: TYPE_NORMAL
- en: For functional ablation, we change the activation functions of the neurons to
    different curves, with different amounts of non-linearity. The last function we
    use is a straight line, completely destroying the non-linear characteristic of
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because non-linear models are by definition more complex than linear models,
    and the purpose of activation functions is to induce nonlinear effects on the
    classification, a line of reasoning one could make is that:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“If we can get away with using linear functions instead of non-linear functions,
    and still have a good classification, then maybe we can simply our architecture
    and lower its cost”*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** You’ll notice in addition to regularization, certain kinds of ablation
    testing, like functional ablation has similarities to [hyperparameter tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization).
    They are similar, but ablation testing refers more to changing parts of the neural
    network architecture (e.g. neurons, layers, etc), where as hyperparameter tuning
    refers to changing structural parameters of the model. Both have the goal of optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: When we run the above code we get the following accuracies vs activation function.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a428a18957cb11484ff2823a55c3a840.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph generated for functional ablation test (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: So it indeed it looks like non-linearity of some kind is important to the classification,
    with “[ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))” and [hyperbolic
    tangent](https://en.wikipedia.org/wiki/Hyperbolic_functions) non-linearity being
    the most effective. This makes sense, because it’s well known that digit classification
    is best framed as a non-linear task.
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature Ablation**'
  prefs: []
  type: TYPE_NORMAL
- en: We can also remove features from the classification and see how that effects
    the accuracy of our predictor.
  prefs: []
  type: TYPE_NORMAL
- en: Normally *prior* to doing a machine learning or data science project, we typically
    do exploratory data analysis (EDA) and feature selection to determine what features
    could be important to our classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: But sometimes interesting effects can be observed, especially with the ever
    mysterious neural networks, by removing features as part of an ablation study
    and seeing the effect on classification. Using the following code, we can remove
    columns of pixels from our letters in groups of 4 columns.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, there are several ways to ablate the features, by distorting the
    characters in different ways besides in columns. But we can start with this simple
    example and observe the effects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'After we run the above feature ablation code, we see:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07a74f18d9fe0131f2c7bfc8f29ebea7.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph generated for 4-column input feature ablation test (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, there’s a slight dip in accuracy when we remove columns 8 to
    to 12, and a rise again after that. That suggests that on average, the more “sensitive”
    character geometry lies in those center columns, but the other columns especially
    close to the beginning and end could potentially be removed for an optimization
    effect.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s the same test against removing 7 columns at a time, along with the columns.
    Visualizing the actual distorted character data allows us to make a lot more sense
    of the result, as we see that the reason that removing the first few columns makes
    a smaller different is because they are mostly just padding!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5fe4ea84cf30abc94770488eff6c5111.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph generated for result of 4 column pixel removal (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting example of an ablation study would be testing against different
    sorts of noise profiles. Here below is code I wrote to progressively noise an
    image using the above ANN model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We’ve created an ablation study for the robustness of the network in the presence
    of an increasing strength [Gaussian Noise](https://en.wikipedia.org/wiki/Gaussian_noise#:~:text=In%20signal%20processing%20theory%2C%20Gaussian,can%20take%20are%20Gaussian%2Ddistributed.).
    Notice the expected and marked decreasing prediction accuracy as the noise level
    increases.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f3ccd17fd6e9b8bc4ad14b5df6b461d.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph generated for result of progressive noising (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Situations like this let us know that we may have to increase the power and
    complexity of our neural network to compensate. Also remember that ablation studies
    can be done in combination which each other, in the presence of different types
    of noise combined with different types of distortion.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusions**'
  prefs: []
  type: TYPE_NORMAL
- en: Ablation studies can be very important to optimizing and testing a neural network.
    We demonstrated a small example here in this post, but there are an innumerable
    number of ways to run these studies on different and more complex network architectures.
    If you have any thoughts, would love some feedback and also perhaps even put them
    in your own article. Thank you for reading!
  prefs: []
  type: TYPE_NORMAL
