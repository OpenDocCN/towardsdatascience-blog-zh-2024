["```py\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{instruction}\n\n### Input:\n{input}\n\n### Response:\n```", "```py\nimport json\nimport random\nrandom.seed(42)\n\ndef read_jsonl_file(file_path):\n    \"\"\"\n    Parses a JSONL (JSON Lines) file and returns a list of dictionaries.\n\n    Args:\n        file_path (str): The path to the JSONL file to be read.\n\n    Returns:\n        list of dict: A list where each element is a dictionary representing\n            a JSON object from the file.\n    \"\"\"\n    jsonl_lines = []\n    with open(file_path, 'r', encoding=\"utf-8\") as file:\n        for line in file:\n            json_object = json.loads(line)\n            jsonl_lines.append(json_object)\n\n    return jsonl_lines\n\ndef write_jsonl_file(dict_list, file_path):\n    \"\"\"\n    Write a list of dictionaries to a JSON Lines file.\n\n    Args:\n    - dict_list (list): A list of dictionaries to write to the file.\n    - file_path (str): The path to the file where the data will be written.\n    \"\"\"\n    with open(file_path, 'w') as file:\n        for dictionary in dict_list:\n            # Convert the dictionary to a JSON string and write it to the file.\n            json_line = json.dumps(dictionary)\n            file.write(json_line + '\\n')\n\n# read the contents of the train and test set\ntrain_set = read_jsonl_file(\"data_clean/questions/US/4_options/phrases_no_exclude_train.jsonl\")\ntest_set = read_jsonl_file(\"data_clean/questions/US/4_options/phrases_no_exclude_test.jsonl\")\n\n# subsample test set samples and few-shot samples\ntest_set_subsampled = random.sample(test_set, 300)\nfew_shot_examples = random.sample(test_set, 3)\n\n# dump the sampled questions and few-shot samples as jsonl files\nwrite_jsonl_file(test_set_subsampled, \"USMLE_test_samples_300.jsonl\")\nwrite_jsonl_file(few_shot_examples, \"USMLE_few_shot_samples.jsonl\")\n```", "```py\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom tqdm import tqdm\n\nquestions = read_jsonl_file(\"USMLE_test_samples_300.jsonl\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\nmodel = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",  torch_dtype=torch.bfloat16).cuda()\nmodel.eval()\n```", "```py\nPROMPT = \"\"\"You will be provided with a medical or clinical question, along with multiple possible answer choices. Pick the right answer from the choices. \nYour response should be in the format \"The answer is <correct_choice>\". Do not add any other unnecessary content in your response\"\"\"\n```", "```py\n<s>[INST] <<SYS>>\nYou will be provided with a medical or clinical question, along with multiple possible answer choices. Pick the right answer from the choices. \nYour response should be in the format \"The answer is <correct_choice>\". Do not add any other unnecessary content in your response\n<</SYS>>\n\nA 21-year-old male presents to his primary care provider for fatigue. He reports that he graduated from college last month and returned 3 days ago from a 2 week vacation to Vietnam and Cambodia. For the past 2 days, he has developed a worsening headache, malaise, and pain in his hands and wrists. The patient has a past medical history of asthma managed with albuterol as needed. He is sexually active with both men and women, and he uses condoms “most of the time.” On physical exam, the patient’s temperature is 102.5°F (39.2°C), blood pressure is 112/66 mmHg, pulse is 105/min, respirations are 12/min, and oxygen saturation is 98% on room air. He has tenderness to palpation over his bilateral metacarpophalangeal joints and a maculopapular rash on his trunk and upper thighs. Tourniquet test is negative. Laboratory results are as follows:\n\nHemoglobin: 14 g/dL\nHematocrit: 44%\nLeukocyte count: 3,200/mm^3\nPlatelet count: 112,000/mm^3\n\nSerum:\nNa+: 142 mEq/L\nCl-: 104 mEq/L\nK+: 4.6 mEq/L\nHCO3-: 24 mEq/L\nBUN: 18 mg/dL\nGlucose: 87 mg/dL\nCreatinine: 0.9 mg/dL\nAST: 106 U/L\nALT: 112 U/L\nBilirubin (total): 0.8 mg/dL\nBilirubin (conjugated): 0.3 mg/dL\n\nWhich of the following is the most likely diagnosis in this patient?\nOptions:\nA. Chikungunya\nB. Dengue fever\nC. Epstein-Barr virus\nD. Hepatitis A [/INST]\n```", "```py\ndef create_query(item):\n    \"\"\"\n    Creates the input for the model using the question and the multiple choice options.\n\n    Args:\n        item (dict): A dictionary containing the question and options.\n            Expected keys are \"question\" and \"options\", where \"options\" is another\n            dictionary with keys \"A\", \"B\", \"C\", and \"D\".\n\n    Returns:\n        str: A formatted query combining the question and options, ready for use.\n    \"\"\"\n    query = item[\"question\"] + \"\\nOptions:\\n\" + \\\n            \"A. \" + item[\"options\"][\"A\"] + \"\\n\" + \\\n            \"B. \" + item[\"options\"][\"B\"] + \"\\n\" + \\\n            \"C. \" + item[\"options\"][\"C\"] + \"\\n\" + \\\n            \"D. \" + item[\"options\"][\"D\"]\n    return query\n\ndef build_zero_shot_prompt(system_prompt, question):\n    \"\"\"\n    Builds the zero-shot prompt.\n\n    Args:\n        system_prompt (str): Task Instruction\n        content (dict): The content for which to create a query, formatted as\n            required by `create_query`.\n\n    Returns:\n        list of dict: A list of messages, including a system message defining\n            the task and a user message with the input question.\n    \"\"\"\n    messages = [{\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": create_query(question)}]\n    return messages\n```", "```py\npattern = re.compile(r\"([A-Z])\\.\\s*(.*)\")\n\ndef parse_answer(response):\n    \"\"\"\n    Extracts the answer option from the predicted string.\n\n    Args:\n    - response (str): The string to search for the pattern.\n\n    Returns:\n    - str: The matched answer option if found or an empty string otherwise.\n    \"\"\"\n    match = re.search(pattern, response)\n    if match:\n        letter = match.group(1)\n    else:\n        letter = \"\"\n\n    return letter\n\ndef calculate_accuracy(ground_truth, predictions):\n    \"\"\"\n    Calculates the accuracy of predictions compared to ground truth labels.\n\n    Args:\n    - ground_truth (list): A list of true labels.\n    - predictions (list): A list of predicted labels.\n\n    Returns:\n    - float: The accuracy of predictions as a fraction of correct predictions over total predictions.\n    \"\"\"\n    return sum([1 if x==y else 0 for x,y in zip(ground_truth, predictions)]) / len(ground_truth)\n```", "```py\nground_truth = []\n\nfor item in questions:\n    ans_options = item[\"options\"]\n    correct_ans_option = \"\"\n    for key,value in ans_options.items():\n        if value == item[\"answer\"]:\n            correct_ans_option = key\n            break\n\n    ground_truth.append(correct_ans_option)\n```", "```py\nzero_shot_llama_answers = []\nfor item in tqdm(questions):\n    zero_shot_prompt_messages = build_zero_shot_prompt(PROMPT, item)\n    input_ids = tokenizer.apply_chat_template(zero_shot_prompt_messages, tokenize=True, return_tensors=\"pt\").cuda()  #modified on 09/03/2024   \n    # prompt = tokenizer.apply_chat_template(zero_shot_prompt_messages, tokenize=False)\n    # input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()    \n    outputs = model.generate(input_ids=input_ids, max_new_tokens=10, do_sample=False)\n    # https://github.com/huggingface/transformers/issues/17117#issuecomment-1124497554\n    gen_text = tokenizer.batch_decode(outputs.detach().cpu().numpy()[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n    zero_shot_llama_answers.append(gen_text.strip())\n\nzero_shot_llama_predictions = [parse_answer(x) for x in zero_shot_llama_answers]\nprint(calculate_accuracy(ground_truth, zero_shot_llama_predictions))\n```", "```py\ndef build_few_shot_prompt(system_prompt, content, few_shot_examples):\n    \"\"\"\n    Builds the few-shot prompt using provided examples.\n\n    Args:\n        system_prompt (str): Task description for the LLM\n        content (dict): The content for which to create a query, similar to the\n            structure required by `create_query`.\n        few_shot_examples (list of dict): Examples to simulate a hypothetical\n            conversation. Each dict must have \"options\" and an \"answer\".\n\n    Returns:\n        list of dict: A list of messages, simulating a conversation with\n            few-shot examples, followed by the current user query.\n    \"\"\"\n    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n    for item in few_shot_examples:\n        ans_options = item[\"options\"]\n        correct_ans_option = \"\"\n        for key, value in ans_options.items():\n            if value == item[\"answer\"]:\n                correct_ans_option = key\n                break\n        messages.append({\"role\": \"user\", \"content\": create_query(item)})\n        messages.append({\"role\": \"assistant\", \"content\": \"The answer is \" + correct_ans_option + \".\"})\n    messages.append({\"role\": \"user\", \"content\": create_query(content)})\n    return messages\n\nfew_shot_prompts = read_jsonl_file(\"USMLE_few_shot_samples.jsonl\")\n```", "```py\n<s>[INST] <<SYS>>\nYou will be provided with a medical or clinical question, along with multiple possible answer choices. Pick the right answer from the choices. \nYour response should be in the format \"The answer is <correct_choice>\". Do not add any other unnecessary content in your response\n<</SYS>>\n\nA 30-year-old woman presents to the clinic because of fever, joint pain, and a rash on her lower extremities. She admits to intravenous drug use. Physical examination reveals palpable petechiae and purpura on her lower extremities. Laboratory results reveal a negative antinuclear antibody, positive rheumatoid factor, and positive serum cryoglobulins. Which of the following underlying conditions in this patient is responsible for these findings?\nOptions:\nA. Hepatitis B infection\nB. Hepatitis C infection\nC. HIV infection\nD. Systemic lupus erythematosus (SLE) [/INST] The answer is B. </s><s>[INST] A 10-year-old child presents to your office with a chronic cough. His mother states that he has had a cough for the past two weeks that is non-productive along with low fevers of 100.5 F as measured by an oral thermometer. The mother denies any other medical history and states that he has been around one other friend who also has had this cough for many weeks. The patient's vitals are within normal limits with the exception of his temperature of 100.7 F. His chest radiograph demonstrated diffuse interstitial infiltrates. Which organism is most likely causing his pneumonia?\nOptions:\nA. Mycoplasma pneumoniae\nB. Staphylococcus aureus\nC. Streptococcus pneumoniae\nD. Streptococcus agalactiae [/INST] The answer is A. </s><s>[INST] A 44-year-old with a past medical history significant for human immunodeficiency virus infection presents to the emergency department after he was found to be experiencing worsening confusion. The patient was noted to be disoriented by residents and staff at the homeless shelter where he resides. On presentation he reports headache and muscle aches but is unable to provide more information. His temperature is 102.2°F (39°C), blood pressure is 112/71 mmHg, pulse is 115/min, and respirations are 24/min. Knee extension with hips flexed produces significant resistance and pain. A lumbar puncture is performed with the following results:\n\nOpening pressure: Normal\nFluid color: Clear\nCell count: Increased lymphocytes\nProtein: Slightly elevated\n\nWhich of the following is the most likely cause of this patient's symptoms?\nOptions:\nA. Cryptococcus\nB. Group B streptococcus\nC. Herpes simplex virus\nD. Neisseria meningitidis [/INST] The answer is C. </s><s>[INST] A 21-year-old male presents to his primary care provider for fatigue. He reports that he graduated from college last month and returned 3 days ago from a 2 week vacation to Vietnam and Cambodia. For the past 2 days, he has developed a worsening headache, malaise, and pain in his hands and wrists. The patient has a past medical history of asthma managed with albuterol as needed. He is sexually active with both men and women, and he uses condoms “most of the time.” On physical exam, the patient’s temperature is 102.5°F (39.2°C), blood pressure is 112/66 mmHg, pulse is 105/min, respirations are 12/min, and oxygen saturation is 98% on room air. He has tenderness to palpation over his bilateral metacarpophalangeal joints and a maculopapular rash on his trunk and upper thighs. Tourniquet test is negative. Laboratory results are as follows:\n\nHemoglobin: 14 g/dL\nHematocrit: 44%\nLeukocyte count: 3,200/mm^3\nPlatelet count: 112,000/mm^3\n\nSerum:\nNa+: 142 mEq/L\nCl-: 104 mEq/L\nK+: 4.6 mEq/L\nHCO3-: 24 mEq/L\nBUN: 18 mg/dL\nGlucose: 87 mg/dL\nCreatinine: 0.9 mg/dL\nAST: 106 U/L\nALT: 112 U/L\nBilirubin (total): 0.8 mg/dL\nBilirubin (conjugated): 0.3 mg/dL\n\nWhich of the following is the most likely diagnosis in this patient?\nOptions:\nA. Chikungunya\nB. Dengue fever\nC. Epstein-Barr virus\nD. Hepatitis A [/INST]\n```", "```py\nfew_shot_llama_answers = []\nfor item in tqdm(questions):\n    few_shot_prompt_messages = build_few_shot_prompt(PROMPT, item, few_shot_prompts)\n    input_ids = tokenizer.apply_chat_template(few_shot_prompt_messages, tokenize=True, return_tensors=\"pt\").cuda() #modified on 09/03/2024\n    # prompt = tokenizer.apply_chat_template(few_shot_prompt_messages, tokenize=False)\n    # input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n    outputs = model.generate(input_ids=input_ids, max_new_tokens=10, do_sample=False)\n    gen_text = tokenizer.batch_decode(outputs.detach().cpu().numpy()[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n    few_shot_llama_answers.append(gen_text.strip())\n\nfew_shot_llama_predictions = [parse_answer(x) for x in few_shot_llama_answers]\nprint(calculate_accuracy(ground_truth, few_shot_llama_predictions))\n```", "```py\ndef build_few_shot_prompt_wo_chat_template(system_prompt, content, few_shot_examples):\n    \"\"\"\n    Builds the few-shot prompt using provided examples, bypassing the chat-template\n    for Llama-2.\n\n    Args:\n        system_prompt (str): Task description for the LLM\n        content (dict): The content for which to create a query, similar to the\n            structure required by `create_query`.\n        few_shot_examples (list of dict): Examples to simulate a hypothetical\n            conversation. Each dict must have \"options\" and an \"answer\".\n\n    Returns:\n        str: few-shot prompt in non-chat format\n    \"\"\"\n    few_shot_prompt = \"\"\n    few_shot_prompt += \"Task: \" + system_prompt + \"\\n\"\n    for item in few_shot_examples:\n        ans_options = item[\"options\"]\n        correct_ans_option = \"\"\n        for key, value in ans_options.items():\n            if value == item[\"answer\"]:\n                correct_ans_option = key\n                break\n        few_shot_prompt += create_query(item) + \"\\n\" + \"The answer is \" + correct_ans_option + \".\" + \"\\n\"\n\n    few_shot_prompt += create_query(content) + \"\\n\"\n    return few_shot_prompt\n```", "```py\nTask: You will be provided with a medical or clinical question, along with multiple possible answer choices. Pick the right answer from the choices. \nYour response should be in the format \"The answer is <correct_choice>\". Do not add any other unnecessary content in your response\nA 30-year-old woman presents to the clinic because of fever, joint pain, and a rash on her lower extremities. She admits to intravenous drug use. Physical examination reveals palpable petechiae and purpura on her lower extremities. Laboratory results reveal a negative antinuclear antibody, positive rheumatoid factor, and positive serum cryoglobulins. Which of the following underlying conditions in this patient is responsible for these findings?\nOptions:\nA. Hepatitis B infection\nB. Hepatitis C infection\nC. HIV infection\nD. Systemic lupus erythematosus (SLE)\nThe answer is B.\nA 10-year-old child presents to your office with a chronic cough. His mother states that he has had a cough for the past two weeks that is non-productive along with low fevers of 100.5 F as measured by an oral thermometer. The mother denies any other medical history and states that he has been around one other friend who also has had this cough for many weeks. The patient's vitals are within normal limits with the exception of his temperature of 100.7 F. His chest radiograph demonstrated diffuse interstitial infiltrates. Which organism is most likely causing his pneumonia?\nOptions:\nA. Mycoplasma pneumoniae\nB. Staphylococcus aureus\nC. Streptococcus pneumoniae\nD. Streptococcus agalactiae\nThe answer is A.\nA 44-year-old with a past medical history significant for human immunodeficiency virus infection presents to the emergency department after he was found to be experiencing worsening confusion. The patient was noted to be disoriented by residents and staff at the homeless shelter where he resides. On presentation he reports headache and muscle aches but is unable to provide more information. His temperature is 102.2°F (39°C), blood pressure is 112/71 mmHg, pulse is 115/min, and respirations are 24/min. Knee extension with hips flexed produces significant resistance and pain. A lumbar puncture is performed with the following results:\n\nOpening pressure: Normal\nFluid color: Clear\nCell count: Increased lymphocytes\nProtein: Slightly elevated\n\nWhich of the following is the most likely cause of this patient's symptoms?\nOptions:\nA. Cryptococcus\nB. Group B streptococcus\nC. Herpes simplex virus\nD. Neisseria meningitidis\nThe answer is C.\nA 21-year-old male presents to his primary care provider for fatigue. He reports that he graduated from college last month and returned 3 days ago from a 2 week vacation to Vietnam and Cambodia. For the past 2 days, he has developed a worsening headache, malaise, and pain in his hands and wrists. The patient has a past medical history of asthma managed with albuterol as needed. He is sexually active with both men and women, and he uses condoms “most of the time.” On physical exam, the patient’s temperature is 102.5°F (39.2°C), blood pressure is 112/66 mmHg, pulse is 105/min, respirations are 12/min, and oxygen saturation is 98% on room air. He has tenderness to palpation over his bilateral metacarpophalangeal joints and a maculopapular rash on his trunk and upper thighs. Tourniquet test is negative. Laboratory results are as follows:\n\nHemoglobin: 14 g/dL\nHematocrit: 44%\nLeukocyte count: 3,200/mm^3\nPlatelet count: 112,000/mm^3\n\nSerum:\nNa+: 142 mEq/L\nCl-: 104 mEq/L\nK+: 4.6 mEq/L\nHCO3-: 24 mEq/L\nBUN: 18 mg/dL\nGlucose: 87 mg/dL\nCreatinine: 0.9 mg/dL\nAST: 106 U/L\nALT: 112 U/L\nBilirubin (total): 0.8 mg/dL\nBilirubin (conjugated): 0.3 mg/dL\n\nWhich of the following is the most likely diagnosis in this patient?\nOptions:\nA. Chikungunya\nB. Dengue fever\nC. Epstein-Barr virus\nD. Hepatitis A\n```", "```py\nfew_shot_llama_answers_wo_chat_template = []\nfor item in tqdm(questions):\n    prompt = build_few_shot_prompt_wo_chat_template(PROMPT, item, few_shot_prompts)\n    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n    outputs = model.generate(input_ids=input_ids, max_new_tokens=10, do_sample=False)\n    gen_text = tokenizer.batch_decode(outputs.detach().cpu().numpy()[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n    few_shot_llama_answers_wo_chat_template.append(gen_text.strip())\n\nfew_shot_llama_predictions_wo_chat_template = [parse_answer(x) for x in few_shot_llama_answers_wo_chat_template]\nprint(calculate_accuracy(ground_truth, few_shot_llama_predictions_wo_chat_template))\n```", "```py\ndef create_query_cot(item):\n    \"\"\"\n    Creates the input for the model using the question and the multiple choice options in the CoT format.\n\n    Args:\n        item (dict): A dictionary containing the question and options.\n            Expected keys are \"question\" and \"options\", where \"options\" is another\n            dictionary with keys \"A\", \"B\", \"C\", and \"D\".\n\n    Returns:\n        str: A formatted query combining the question and options, ready for use.\n    \"\"\"\n    query = \"Question: \" + item[\"question\"] + \"\\n\" + \\\n            \"(A) \" + item[\"options\"][\"A\"] + \" \" +  \\\n            \"(B) \" + item[\"options\"][\"B\"] + \" \" +  \\\n            \"(C) \" + item[\"options\"][\"C\"] + \" \" +  \\\n            \"(D) \" + item[\"options\"][\"D\"]\n    return query\n\ndef build_cot_prompt(instruction, input_question, cot_examples):\n    \"\"\"\n    Builds the few-shot prompt for the GPT API using provided examples.\n\n    Args:\n        content (dict): The content for which to create a query, similar to the\n            structure required by `create_query`.\n        few_shot_examples (list of dict): Examples to simulate a hypothetical\n            conversation. Each dict must have \"question\" and an \"explanation\".\n\n    Returns:\n        list of dict: A list of messages, simulating a conversation with\n            few-shot examples, followed by the current user query.\n    \"\"\"\n\n    messages = [{\"role\": \"system\", \"content\": instruction}]\n    for item in cot_examples:\n        messages.append({\"role\": \"user\", \"content\": item[\"question\"]})\n        messages.append({\"role\": \"assistant\", \"content\": item[\"explanation\"]})\n\n    messages.append({\"role\": \"user\", \"content\": create_query_cot(input_question)})\n\n    return messages\n\ndef parse_answer_cot(text):\n    \"\"\"\n    Extracts the choice from a string that follows the pattern \"Answer: (Choice) Text\".\n\n    Args:\n    - text (str): The input string from which to extract the choice.\n\n    Returns:\n    - str: The extracted choice or a message indicating no match was found.\n    \"\"\"\n    # Regex pattern to match the answer part\n    pattern = r\"Answer: (.*)\"\n\n    # Search for the pattern in the text and extract the matching group\n    match = re.search(pattern, text)\n\n    if match:\n        if len(match.group(1)) > 1:\n            return match.group(1)[1]\n        else:\n            return \"\"\n    else:\n        return \"\"\n```", "```py\ncot_llama_answers = []\nfor item in tqdm(questions):\n    cot_prompt = build_cot_prompt(COT_INSTRUCTION, item, COT_EXAMPLES)\n    input_ids = tokenizer.apply_chat_template(cot_prompt, tokenize=True, return_tensors=\"pt\").cuda() #modified on 09/03/2024\n    # prompt = tokenizer.apply_chat_template(cot_prompt, tokenize=False)\n    # input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()    \n    outputs = model.generate(input_ids=input_ids, max_new_tokens=100, do_sample=False)\n    gen_text = tokenizer.batch_decode(outputs.detach().cpu().numpy()[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n    cot_llama_answers.append(gen_text.strip())\n\ncot_llama_predictions = [parse_answer_cot(x) for x in cot_llama_answers]\nprint(calculate_accuracy(ground_truth, cot_llama_predictions))\n```", "```py\nfrom openai import OpenAI\nimport re\nfrom tqdm import tqdm\n\n# assuming you have already set the secret key using env variable\n# if not, you can also instantiate the OpenAI client by providing the \n# secret key directly like so:\n# I highly recommend not doing this, as it is a best practice to not store\n# the api key in your code directly or in any plain-text file for security \n# reasons.\n# client = OpenAI(api_key = \"\")\n\nclient = OpenAI() \n```", "```py\n def get_response(messages, model_name, temperature = 0.0, max_tokens = 10):\n    \"\"\"\n    Obtains the responses/answers of the model through the chat-completions API.\n\n    Args:\n        messages (list of dict): The built messages provided to the API.\n        model_name (str): Name of the model to access through the API\n        temperature (float): A value between 0 and 1 that controls the randomness of the output.\n        A temperature value of 0 ideally makes the model pick the most likely token, making the outputs (mostly) deterministic.\n        max_tokens (int): Maximum number of tokens that the model should generate\n\n    Returns:\n        str: The response message content from the model.\n    \"\"\"\n    response = client.chat.completions.create(\n        model=model_name,\n        messages=messages,\n        temperature=temperature,\n        max_tokens=max_tokens\n    )\n    return response.choices[0].message.content\n```", "```py\nzero_shot_gpt_answers = []\nfor item in tqdm(questions):\n    zero_shot_prompt_messages = build_zero_shot_prompt(PROMPT, item)\n    answer = get_response(zero_shot_prompt_messages, model_name = \"gpt-3.5-turbo\", temperature = 0.0, max_tokens = 10)\n    zero_shot_gpt_answers.append(answer)\n\nzero_shot_gpt_predictions = [parse_answer(x) for x in zero_shot_gpt_answers]\nprint(calculate_accuracy(ground_truth, zero_shot_gpt_predictions))\n```", "```py\nfew_shot_gpt_answers = []\nfor item in tqdm(questions):\n    few_shot_prompt_messages = build_few_shot_prompt(PROMPT, item, few_shot_prompts)\n    answer = get_response(few_shot_prompt_messages, model_name= \"gpt-3.5-turbo\", temperature = 0.0, max_tokens = 10)\n    few_shot_gpt_answers.append(answer)\n\nfew_shot_gpt_predictions = [parse_answer(x) for x in few_shot_gpt_answers]\nprint(calculate_accuracy(ground_truth, few_shot_gpt_predictions))\n```", "```py\ncot_gpt_answers = []\nfor item in tqdm(questions):\n    cot_prompt = build_cot_prompt(COT_INSTRUCTION, item, COT_EXAMPLES)\n    answer = get_response(cot_prompt, model_name= \"gpt-3.5-turbo\", temperature = 0.0, max_tokens = 100)\n    cot_gpt_answers.append(answer)\n\ncot_gpt_predictions = [parse_answer_cot(x) for x in cot_gpt_answers]\nprint(calculate_accuracy(ground_truth, cot_gpt_predictions))\n```"]