<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A New Approach to AI Safety: Layer Enhanced Classification (LEC)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>A New Approach to AI Safety: Layer Enhanced Classification (LEC)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-new-approach-to-ai-safety-layer-enhanced-classification-lec-56141aa0f6be?source=collection_archive---------0-----------------------#2024-12-20">https://towardsdatascience.com/a-new-approach-to-ai-safety-layer-enhanced-classification-lec-56141aa0f6be?source=collection_archive---------0-----------------------#2024-12-20</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="0327" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><strong class="al"><em class="hd">LEC surpasses best in class models, like GPT-4o, by combining the efficiency of a ML classifier with the language understanding of an LLM</em></strong></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@sandibesen?source=post_page---byline--56141aa0f6be--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Sandi Besen" class="l ep by dd de cx" src="../Images/97361d97f50269f70b6621da2256bc29.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*gHEvwZHf-nDi0QXwnsUeFg.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--56141aa0f6be--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@sandibesen?source=post_page---byline--56141aa0f6be--------------------------------" rel="noopener follow">Sandi Besen</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--56141aa0f6be--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 20, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk ld le ab q ee lf lg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lb lc">6</span></p></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lh k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al li an ao ap ie lj lk ll" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lm cn"><div class="l ae"><div class="ab cb"><div class="ln lo lp lq lr ls ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="d9e9" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Imagine sitting in a boardroom, discussing the most transformative technology of our time — artificial intelligence — and realizing we’re riding a rocket with no reliable safety belt. The Bletchley Declaration, unveiled during the AI Safety Summit hosted by the UK government and backed by 29 countries, captures this sentiment perfectly [1]:</p><blockquote class="ng"><p id="bb66" class="nh ni fq bf nj nk nl nm nn no np nf dx">“There is potential for serious, even catastrophic, harm, either deliberate or unintentional, stemming from the most significant capabilities of these AI models”.</p></blockquote><figure class="nt nu nv nw nx ny nq nr paragraph-image"><div role="button" tabindex="0" class="nz oa ed ob bh oc"><div class="nq nr ns"><img src="../Images/4884f6a80146d35b7392d166238c9051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhdSs6ojYWO5DRkQ6z6A5A.jpeg"/></div></div><figcaption class="oe of og nq nr oh oi bf b bg z dx">Source: Dalle3</figcaption></figure><p id="f393" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">However, <strong class="mm fr">existing AI safety approaches force organizations into an un-winnable trade-off between cost, speed, and accuracy</strong>. Traditional machine learning classifiers struggle to capture the subtleties of natural language and LLM’s, while powerful, introduce significant computational overhead — requiring additional model calls that escalate costs for each AI safety check.</p><p id="ade4" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Our team (<a class="af oj" href="https://www.linkedin.com/in/mason-sawtell/" rel="noopener ugc nofollow" target="_blank">Mason Sawtell</a>,<a class="af oj" href="https://www.linkedin.com/in/sandibesen/" rel="noopener ugc nofollow" target="_blank"> Sandi Besen</a>, <a class="af oj" href="https://www.linkedin.com/in/tula-masterman/" rel="noopener ugc nofollow" target="_blank">Tula Masterman</a>, <a class="af oj" href="https://www.linkedin.com/in/jim-brown-71427356/" rel="noopener ugc nofollow" target="_blank">Jim Brown</a>), introduces a novel approach called LEC (Layer Enhanced Classification).</p><figure class="ol om on oo op ny nq nr paragraph-image"><div role="button" tabindex="0" class="nz oa ed ob bh oc"><div class="nq nr ok"><img src="../Images/264f7de5efe28359fc11be79b7459fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l2OZa7WxPu3Wd8I8dADnQQ.jpeg"/></div></div><figcaption class="oe of og nq nr oh oi bf b bg z dx">Image by : Sandi Besen, Tula Masterman, Mason Sawtell, Jim Brown</figcaption></figure><p id="726c" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><strong class="mm fr"><em class="oq">We prove LEC combines the computational efficiency of a machine learning classifier with the sophisticated language understanding of an LLM — so you don’t have to choose between cost, speed, and accuracy. LEC surpasses best in class models like GPT-4o and models specifically trained for identifying unsafe content and prompt injections. What’s better yet, we believe LEC can be modified to tackle non AI safety related text classification tasks like sentiment analysis, intent classification, product categorization, and more.</em></strong></p><p id="dd6a" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">The implications are profound. Whether you’re a technology leader navigating the complex terrain of AI safety, a product manager mitigating potential risks, or an executive charting a responsible innovation strategy, our approach offers a scalable and adaptable solution.</p><figure class="ol om on oo op ny nq nr paragraph-image"><div role="button" tabindex="0" class="nz oa ed ob bh oc"><div class="nq nr ok"><img src="../Images/bc6f73cbbb673ecbddbc6b8e358e15c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9h2_55ZxfuhonDFglXzpuQ.jpeg"/></div></div><figcaption class="oe of og nq nr oh oi bf b bg z dx">Figure 1: An example of an adapted model inference pipeline to include LEC Classifiers. Image by : Sandi Besen, Tula Masterman, Mason Sawtell, Jim Brown</figcaption></figure><p id="7aa2" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Further details can be found in the <a class="af oj" href="https://arxiv.org/abs/2412.13435" rel="noopener ugc nofollow" target="_blank">full paper</a>’s pre-print on Arxiv[2] or in <a class="af oj" rel="noopener" target="_blank" href="/introducing-layer-enhanced-classification-lec-4972f4f1c79f">Tula Masterman’s summarized article</a> about the paper.</p><h1 id="bcd1" class="or os fq bf ot ou ov gq ow ox oy gt oz pa pb pc pd pe pf pg ph pi pj pk pl pm bk">Applying LEC to Responsible AI Use Cases</h1><p id="40ee" class="pw-post-body-paragraph mk ml fq mm b go pn mo mp gr po mr ms mt pp mv mw mx pq mz na nb pr nd ne nf fj bk">Responsible AI has become a critical priority for technology leaders across the ecosystem — from model developers like Anthropic, OpenAI, Meta, Google, and IBM to enterprise consulting firms and AI service providers. As AI adoption accelerates, its importance becomes even more pronounced.</p><p id="5e3b" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Our research specifically targets two pivotal challenges in AI safety — content safety and prompt injection detection. Content safety refers to the process of identifying and preventing the generation of harmful, inappropriate, or potentially dangerous content that could pose risks to users or violate ethical guidelines. Prompt injection involves detecting attempts to manipulate AI systems by crafting input prompts designed to bypass safety mechanisms or coerce the model into producing unethical outputs.</p><p id="b8b7" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">To advance the field of ethical AI, we applied LEC’s capabilities to real-world responsible AI use cases. Our hope is that this methodology will be adopted widely, helping to make every AI system less vulnerable to exploitation.</p><h1 id="da82" class="or os fq bf ot ou ov gq ow ox oy gt oz pa pb pc pd pe pf pg ph pi pj pk pl pm bk">Using LEC for Content Safety Tasks</h1><p id="e049" class="pw-post-body-paragraph mk ml fq mm b go pn mo mp gr po mr ms mt pp mv mw mx pq mz na nb pr nd ne nf fj bk">We curated a content safety dataset of 5,000 examples to test LEC on both binary (2 categories) and multi-class (&gt;2 categories) classification. We used the SALAD Data dataset from OpenSafetyLab [3] to represent unsafe content and the “LMSYS-Chat-1M” dataset from LMSYS, to represent safe content [4].</p><p id="a968" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">For binary classification the content is either “safe” or “unsafe”. For multi-class classification, content is either categorized as “safe” or assigned to a specific specific “unsafe” category.</p><p id="e3ec" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">We compared model’s trained using LEC to GPT-4o (widely recognized as an industry leader), Llama Guard 3 1B and Llama Guard 3 8B (special purpose models specifically trained to tackle content safety tasks). We found that the models using LEC outperformed all models we compared them to using as few as 20 training examples for binary classification and 50 training examples for multi-class classification.</p><p id="88ce" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">The highest performing LEC model achieved a weighted F1 score (measures how well a system balances making correct predictions while minimizing mistakes) of .96 of a maximum score of 1 on the binary classification task compared to GPT-4o’s score of 0.82 or LlamaGuard 8B’s score of 0.71.</p><p id="5159" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><strong class="mm fr">This means that with as few as 15 examples, using LEC you can train a model to outperform industry leaders in identifying safe or unsafe content at a fraction of the computational cost.</strong></p><figure class="ol om on oo op ny nq nr paragraph-image"><div role="button" tabindex="0" class="nz oa ed ob bh oc"><div class="nq nr ok"><img src="../Images/bf71c4cd0d97dd59a6a287aad68f9155.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ha6f9ocj6g0m_zj_aeAYaQ.jpeg"/></div></div><figcaption class="oe of og nq nr oh oi bf b bg z dx">Summary of Content safety Results. Image by : Sandi Besen, Tula Masterman, Mason Sawtell, Jim Brown</figcaption></figure><h1 id="85b4" class="or os fq bf ot ou ov gq ow ox oy gt oz pa pb pc pd pe pf pg ph pi pj pk pl pm bk">Using LEC for Identifying Prompt Injections</h1><p id="ed21" class="pw-post-body-paragraph mk ml fq mm b go pn mo mp gr po mr ms mt pp mv mw mx pq mz na nb pr nd ne nf fj bk">We curated a prompt injection dataset using the SPML Chatbot Prompt Injection Dataset. We chose the SPML dataset because of its diversity and complexity in representing real-world chat bot scenarios. This dataset contained pairs of system and user prompts to identify user prompts that attempt to defy or manipulate the system prompt. This is especially relevant for businesses deploying public facing chatbots that are only meant to answer questions about specific domains.</p><p id="cb09" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">We compared model’s trained using LEC to GPT-4o (an industry leader) and deBERTa v3 Prompt Injection v2 (a model specifically trained to identify prompt injections). We found that the models using LEC outperformed both GPT-4o using 55 training examples and the the special purpose model using as few as 5 training examples.</p><p id="06ae" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">The highest performing LEC model achieved a weighted F1 score of .98 of a maximum score of 1 compared to GPT-4o’s score of 0.92 or deBERTa v2 Prompt Injection v2’s score of 0.73.</p><p id="dabf" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><strong class="mm fr">This means that with as few as 5 examples, using LEC you can train a model to outperform industry leaders in identifying prompt injection attacks.</strong></p><figure class="ol om on oo op ny nq nr paragraph-image"><div role="button" tabindex="0" class="nz oa ed ob bh oc"><div class="nq nr ok"><img src="../Images/8c579a1dc0fb1d4291fe30cd2d7bc05a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MflS6CqEsiqRK61A1mmahQ.jpeg"/></div></div><figcaption class="oe of og nq nr oh oi bf b bg z dx">Summary of Prompt Injection Results. Image by : Sandi Besen, Tula Masterman, Mason Sawtell, Jim Brown</figcaption></figure><p id="fdc0" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Full results and experimentation implementation details can be found in the Arxiv preprint.</p><h1 id="e224" class="or os fq bf ot ou ov gq ow ox oy gt oz pa pb pc pd pe pf pg ph pi pj pk pl pm bk">How Your Business Can Benefit From using LEC</h1><p id="e5b9" class="pw-post-body-paragraph mk ml fq mm b go pn mo mp gr po mr ms mt pp mv mw mx pq mz na nb pr nd ne nf fj bk">As organizations increasingly integrate AI into their operations, ensuring the safety and integrity of AI-driven interactions has become mission-critical. LEC provides a robust and flexible way to ensure that potentially unsafe information is being detected — resulting in reduce operational risk and increased end user trust. There are several ways that a LEC models can be incorporated into your AI Safety Toolkit to prevent unwanted vulnerabilities when using your AI tools including during LM inference, before/after LM inference, and even in multi-agent scenarios.</p><p id="df81" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><strong class="mm fr">During LM Inference</strong></p><p id="8ad5" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">If you are using an open-source model or have access to the inner workings of the closed-source model, you can use LEC as part of your inference pipeline for AI safety in near real time. This means that if any safety concerns arise while information is traveling through the language model, generation of any output can be halted. An example of what this might look like can be seen in figure 1.</p><p id="ba2c" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><strong class="mm fr">Before / After LM Inference</strong></p><p id="b521" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">If you don’t have access to the inner workings of the language model or want to check for safety concerns as a separate task you can use a LEC model before or after calling a language model. This makes LEC compatible with closed source models like the Claude and GPT families.</p><p id="245e" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Building a LEC Classifier into your deployment pipeline can save you from passing potentially harmful content into your LM and/or check for harmful content before an output is returned to the user.</p><p id="d69a" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><strong class="mm fr">Using LEC Classifiers with Agents</strong></p><p id="997a" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Agentic AI systems can amplify any existing unintended actions, leading to a compounding effect of unintended consequences. LEC Classifiers can be used at different times throughout an agentic scenario to can safeguard the agent from either receiving or producing harmful outputs. For instance, by including LEC models into your agentic architecture you can:</p><ul class=""><li id="3127" class="mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ps pt pu bk">Check that the request is ok to start working on</li><li id="f357" class="mk ml fq mm b go pv mo mp gr pw mr ms mt px mv mw mx py mz na nb pz nd ne nf ps pt pu bk">Ensure an invoked tool call does not violate any AI safety guidelines (e.g., generating inappropriate search topics for a keyword search)</li><li id="ef87" class="mk ml fq mm b go pv mo mp gr pw mr ms mt px mv mw mx py mz na nb pz nd ne nf ps pt pu bk">Make sure information returned to an agent is not harmful (e.g., results returned from RAG search or google search are “safe”)</li><li id="15b3" class="mk ml fq mm b go pv mo mp gr pw mr ms mt px mv mw mx py mz na nb pz nd ne nf ps pt pu bk">Validating the final response of an agent before passing it back to the user</li></ul><p id="e6da" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><strong class="mm fr">How to Implement LEC Based on Language Model Access</strong></p><p id="c3a5" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Enterprises with access to the internal workings of models can integrate LEC directly within the inference pipeline, enabling continuous safety monitoring throughout the AI’s content generation process. When using closed-source models via API (as is the case with GPT-4), businesses do not have direct access to the underlying information needed to train a LEC model. In this scenario, LEC can be applied before and/or after model calls. For example, before an API call, the input can be screened for unsafe content. Post-call, the output can be validated to ensure it aligns with business safety protocols.</p><p id="5f50" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><strong class="mm fr"><em class="oq">No matter which way you choose to implement LEC, using its powerful abilities provides you with superior content safety and prompt injection protection than existing techniques at a fraction of the time and cost.</em></strong></p><h1 id="6786" class="or os fq bf ot ou ov gq ow ox oy gt oz pa pb pc pd pe pf pg ph pi pj pk pl pm bk">Conclusion</h1><p id="e62d" class="pw-post-body-paragraph mk ml fq mm b go pn mo mp gr po mr ms mt pp mv mw mx pq mz na nb pr nd ne nf fj bk">Layer Enhanced Classification (LEC) is the safety belt for that AI rocket ship we’re on.</p><p id="d3a6" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">The value proposition is clear: LEC’s AI Safety models can mitigate regulatory risk, help ensure brand protection, and enhance user trust in AI-driven interactions. It signals a new era of AI development where accuracy, speed, and cost aren’t competing priorities and AI safety measures can be addressed both at inference time, before inference time, or after inference time.</p><p id="d34b" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">In our content safety experiments, the highest performing <strong class="mm fr">LEC model achieved a weighted F1 score of 0.96 </strong>out of 1 on binary classification, <strong class="mm fr">significantly outperforming GPT-4o’s score</strong> of 0.82 <strong class="mm fr">and LlamaGuard 8B’s score </strong>of 0.71 — and this was accomplished <strong class="mm fr">with as few as 15 training examples</strong>. Similarly, in prompt injection detection, <strong class="mm fr">our top LEC model reached a weighted F1 score of 0.98, compared to GPT-4o’s 0.92</strong> and deBERTa v2 Prompt Injection v2’s 0.73, and it was achieved with just 55 training examples. <strong class="mm fr">These results not only demonstrate superior performance, but also highlight LEC’s remarkable ability to achieve high accuracy with minimal training data.</strong></p><p id="0bf0" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Although our work focused on using LEC Models for AI safety use cases, we anticipate that our approach can be used for a wider variety of text classification tasks. <em class="oq">We encourage the research community to use our work as a stepping stone for exploring what else can be achieved — further open new pathways for more intelligent, safer, and more trustworthy AI systems.</em></p></div></div></div><div class="ab cb qa qb qc qd" role="separator"><span class="qe by bm qf qg qh"/><span class="qe by bm qf qg qh"/><span class="qe by bm qf qg"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="0727" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk"><em class="oq">Note: The opinions expressed both in this article and paper are solely those of the authors and do not necessarily reflect the views or policies of their respective employers.</em></p><p id="aee9" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">Interested in connecting? Drop me a DM on <a class="af oj" href="https://www.linkedin.com/in/sandibesen/" rel="noopener ugc nofollow" target="_blank">Linkedin</a>! I‘m always eager to engage in food for thought and iterate on my work.</p><p id="34ea" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">References:</p><p id="7c25" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">[1] <a class="af oj" href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023" rel="noopener ugc nofollow" target="_blank">https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023</a></p><p id="a71e" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">[2] <a class="af oj" href="https://arxiv.org/abs/2412.13435" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2412.13435</a></p><p id="f444" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">[3] <a class="af oj" href="https://huggingface.co/datasets/OpenSafetyLab/Salad-Data" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/datasets/OpenSafetyLab/Salad-Data</a></p><p id="b91d" class="pw-post-body-paragraph mk ml fq mm b go mn mo mp gr mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fj bk">[4] <a class="af oj" href="https://huggingface.co/datasets/lmsys/lmsys-chat-1m" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/datasets/lmsys/lmsys-chat-1m</a></p></div></div></div></div>    
</body>
</html>