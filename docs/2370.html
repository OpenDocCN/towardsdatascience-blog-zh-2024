<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Why Your Service Engineers Need a Chatbot: The Future of Troubleshooting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Why Your Service Engineers Need a Chatbot: The Future of Troubleshooting</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logiq-service-engineer-chatbot-04e229beee5c?source=collection_archive---------4-----------------------#2024-09-29">https://towardsdatascience.com/logiq-service-engineer-chatbot-04e229beee5c?source=collection_archive---------4-----------------------#2024-09-29</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="fo bh"><figure class="fp fo bh paragraph-image"><img src="../Images/8ede3be3aba1187f0602522551c573a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:2800/format:webp/1*GcIlw1PfzOmBIBmbIjXYPw.jpeg"/><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image: <a class="af fz" href="https://www.behance.net/gallery/73239099/The-New-Yorker-Widows" rel="noopener ugc nofollow" target="_blank">The New Yorker / Widows</a> © <a class="af fz" href="https://www.behance.net/mattchinworth" rel="noopener ugc nofollow" target="_blank">Matt Chinworth</a> | CC BY-NC-ND 4.0</figcaption></figure></div><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="5c5a" class="pw-subtitle-paragraph gz gb gc bf b ha hb hc hd he hf hg hh hi hj hk hl hm hn ho cq dx">As part of the Google AI Sprint 2024, I built a multimodal chatbot with Gemini 1.5 and here’s how it can revolutionize appliance support</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hp hq hr hs ht ab"><div><div class="ab hu"><div><div class="bm" aria-hidden="false"><a href="https://thisisashwinraj.medium.com/?source=post_page---byline--04e229beee5c--------------------------------" rel="noopener follow"><div class="l hv hw by hx hy"><div class="l ed"><img alt="Ashwin Raj" class="l ep by dd de cx" src="../Images/7bfb5e302bba2c12beafb6e09268832d.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*efV9_H2YbWZSqb4MzGuOlw.jpeg"/><div class="hz by l dd de em n ia eo"/></div></div></a></div></div><div class="ib ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--04e229beee5c--------------------------------" rel="noopener follow"><div class="l ic id by hx ie"><div class="l ed"><img alt="Towards Data Science" class="l ep by br if cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hz by l br if em n ia eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ig ab q"><div class="ab q ih"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ii ij bk"><a class="af ag ah ai aj ak al am an ao ap aq ar ik" data-testid="authorName" href="https://thisisashwinraj.medium.com/?source=post_page---byline--04e229beee5c--------------------------------" rel="noopener follow">Ashwin Raj</a></p></div></div></div><span class="il im" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ii ij dx"><button class="in io ah ai aj ak al am an ao ap aq ar ip iq ir" disabled="">Follow</button></p></div></div></span></div></div><div class="l is"><span class="bf b bg z dx"><div class="ab cn it iu iv"><div class="iw ix ab"><div class="bf b bg z dx ab iy"><span class="iz l is">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar ik ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--04e229beee5c--------------------------------" rel="noopener follow"><p class="bf b bg z ja jb jc jd je jf jg jh bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="il im" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="ji jj l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 29, 2024</span></div></span></div></span></div></div></div><div class="ab cp jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz"><div class="h k w ea eb q"><div class="kp l"><div class="ab q kq kr"><div class="pw-multi-vote-icon ed iz ks kt ku"><div class=""><div class="kv kw kx ky kz la lb am lc ld le ku"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l lf lg lh li lj lk ll"><p class="bf b dy z dx"><span class="kw">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kv lm ln ab q ee lo lp" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="fp"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q ka kb kc kd ke kf kg kh ki kj kk kl km kn ko"><div class="lq k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lr an ao ap ip ls lt lu" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lv cn"><div class="l ae"><div class="ab cb"><div class="lw lx ly lz ma fq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lr an ao ap ip mb mc lp md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lr an ao ap ip mb mc lp md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lr an ao ap ip mb mc lp md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="627e" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Across industries, effective troubleshooting is crucial for maintaining smooth operations, ensuring customer satisfaction, and optimizing the efficiency of service processes. However, troubleshooting appliances on-site can be a challenging task. With various models and countless potential issues, service engineers often find themselves sifting through manuals or searching online for solutions, an approach that can be both frustrating and time-consuming.</p><p id="b152" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This is where chatbots equipped with comprehensive servicing knowledge and access to the latest troubleshooting manuals can transform the experience. While one might assume that Retrieval-Augmented Generation (RAG) would be an ideal solution for such tasks, it often falls short in this scenario. This is because these handbooks often contain elements such as tables, images, and diagrams, which are difficult to extract and summarization may miss the knotty details typically found in them, making it unfit for production rollout.</p><p id="302f" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">In this article, we will work towards building a chatbot using Gemini to help onsite service engineers find the right information in a faster, more intuitive manner. We will also explore the advanced features offered by Gemini, such as context caching and File API integration for multimodal prompting. In the end, we will wrap this chatbot in a Streamlit interface, for easier interaction.</p><h1 id="4a0d" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Before you Begin</h1><p id="386a" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">To build the chatbot, we’ll be using Gemini, Python 3, and Streamlit. Start by installing Streamlit on your local machine by running the below command:</p><pre class="op oq or os ot ou ov ow bp ox bb bk"><span id="9769" class="oy np gc ov b bg oz pa l pb pc">pip install streamlit</span></pre><p id="8d28" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">For the database, we’ll rely on SQLite which comes preinstalled with Python. We will also need a Gemini API key to run inferences using Gemini 1.5 Flash. If you don’t have an API key yet, you can create one for free from this <a class="af fz" href="https://ai.google.dev/gemini-api/docs/api-key" rel="noopener ugc nofollow" target="_blank">link</a>. Once you have set up your key, install the Google AI Python SDK by running:</p><pre class="op oq or os ot ou ov ow bp ox bb bk"><span id="d8b6" class="oy np gc ov b bg oz pa l pb pc">pip install google-generativeai</span></pre><p id="7e9b" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">You can find the source code &amp; additional resources on my GitHub repo <a class="af fz" href="https://github.com/thisisashwinraj/LogIQ-Service-Engineer-Assistant" rel="noopener ugc nofollow" target="_blank">here</a></p><blockquote class="pd pe pf"><p id="0c20" class="ms mt pg mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="mu gd"><em class="gc">Acknowledgement:<br/></em></strong><em class="gc">Google Cloud credits are provided for this project, as part of #AISprint 2024</em></p></blockquote><h1 id="b560" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Architecture</h1><p id="1382" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">Before the implementation, let us examine the system architecture in detail. The process begins by fetching the required product manual from a database and passing it to Gemini. This acts as the knowledge base for our chatbot, providing essential troubleshooting information for the selected appliance.</p><figure class="op oq or os ot fo fv fw paragraph-image"><div role="button" tabindex="0" class="pi pj ed pk bh pl"><div class="fv fw ph"><img src="../Images/7565ffd5e34ede62623634e9e9b8703d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LrsTF94bCC85b_tHDt_rQA.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image by Author</figcaption></figure><p id="e3d0" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Once the documents are loaded, we leverage Gemini’s multimodal document processing capabilities to extract the required information from the product manual. Now, when a user interacts with the chatbot, the model combines the uploaded service manual data, chat history, and other contextual cues to deliver precise and insightful responses to the user’s queries.</p><p id="acec" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">To enhance performance, we’ll implement context caching, which optimizes response time for recurring queries. Finally, we’ll wrap this architecture in a simple yet intuitive Streamlit web application, allowing service engineers to seamlessly engage with the chat agent and access the information they need.</p><h1 id="cb00" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Loading Service Manuals into the Database</h1><p id="272a" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">To begin building the chatbot, the first step is to load the troubleshooting guides into our database for reference. Since these files are unstructured in nature, we can’t store them directly in our database. Instead, we store their filepaths:</p><pre class="op oq or os ot ou ov ow bp ox bb bk"><span id="37e8" class="oy np gc ov b bg oz pa l pb pc">class ServiceGuides:<br/>    def __init__(self, db_name="database/persistent/general.db"):<br/>        self.conn = sqlite3.connect(db_name)<br/>        self.create_table()<br/><br/>    def add_service_guide(self, model_number, guide_name, guide_file_url):<br/>        cursor = self.conn.cursor()<br/><br/>        cursor.execute('''<br/>            INSERT INTO service_guides (model, guide_name, guide_url)<br/>            VALUES (?, ?, ?)<br/>        ''', (model_number, guide_name, guide_file_url))<br/><br/>        self.conn.commit()<br/><br/>    def fetch_guides_by_model_number(self, model_number):<br/>        cursor = self.conn.cursor()<br/>        cursor.execute(<br/>            """SELECT guide_url FROM service_guides WHERE model = ?""",<br/>            (model_number,),<br/>        )<br/>        return cursor.fetchone()</span></pre><p id="d3da" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">In this project, we’ll store the manuals in a local directory, and save their file paths in a SQLite database. For better scalability however, its recommended to use an object storage service, such as Google Cloud Storage to store these files &amp; maintain URLs to the files in a database service like Google Cloud SQL</p><h1 id="8ff7" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Building the Conversational Agent with Gemini</h1><p id="65d7" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">Once the product manual is loaded into the database, the next step is to build the agent using 1.5 Flash. This lightweight model is part of the Gemini family and has been fine-tuned through a process known as “distillation,” where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model to support various high-volume tasks at scale.</p><figure class="op oq or os ot fo fv fw paragraph-image"><div role="button" tabindex="0" class="pi pj ed pk bh pl"><div class="fv fw ph"><img src="../Images/e0b374608d80284f7b5c0abd18a97431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4wIqdF_5BSx9BJNhyv5hJQ.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image from <a class="af fz" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/#gemini-model-updates" rel="noopener ugc nofollow" target="_blank">The Keyword</a> by Google</figcaption></figure><p id="962d" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Optimized for speed and operational efficiency, the 1.5 Flash model is highly proficient in multimodal reasoning and features a context window of up to 1 million tokens, making it the ideal choice for our service engineer’s use case.</p><h1 id="a6d8" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Multimodal Document Processing with 1.5 Flash</h1><p id="b714" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">To run inference on our service manuals, we first need to upload the files to Gemini. The Gemini API supports uploading media files separately from the prompt input, enabling us to reuse files across multiple requests. The File API supports up to 20 GB of files per project, with a maximum of 2 GB per file:</p><pre class="op oq or os ot ou ov ow bp ox bb bk"><span id="32a4" class="oy np gc ov b bg oz pa l pb pc">class ServiceEngineerChatbot:<br/>    def __init__(self):<br/>        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])<br/><br/><br/>    def post_service_guide_to_gemini(self, title, path_to_service_guide):<br/>        service_guide = genai.upload_file(<br/>            path=path_to_service_guide,<br/>            display_name=title,<br/>        )<br/><br/>        while service_guide.state.name == 'PROCESSING':<br/>            print('Waiting for file to be processed.')<br/>            time.sleep(2)<br/>            service_guide = genai.get_file(service_guide.name)<br/><br/>        return service_guide</span></pre><p id="1186" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">To upload a file, we use the upload_file() method, which takes as parameter the path (path to the file to be uploaded), name (filename in the destination, defaulting to a system-generated ID), mime_type (specifying the MIME type of the document, which’ll be inferred if unspecified), and the display_name.</p><p id="c018" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Before proceeding, we need to verify that the API has successfully stored the uploaded file by checking its metadata. If the file’s state is PROCESSING, it cannot yet be used for inference. Once the state changes to ACTIVE, the file is ready for use. A FAILED state, indicates file processing was unsuccessful.</p><h1 id="4177" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Conversational Response Generation</h1><p id="7034" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">After uploading the service manual, the next step is to leverage Gemini 1.5’s multimodal document processing capabilities for response generation. The chat feature of the API allows us to collect multiple rounds of questions and responses, facilitating in-depth analysis of issues &amp; step-by-step resolution.</p><figure class="op oq or os ot fo fv fw paragraph-image"><div role="button" tabindex="0" class="pi pj ed pk bh pl"><div class="fv fw ph"><img src="../Images/1540dd9ce6db00580a566619f3debedd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xw8SrEJmUCK801fRjlOBow.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image by Author</figcaption></figure><p id="b566" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">When initializing the model, it’s important to provide specific guidelines and context to shape the chatbot’s behavior throughout the interaction. This is done by supplying system instruction to the model. System instructions help maintain context, guide the style of interaction, ensure consistency, and set boundaries for the chatbot’s responses, while trying to prevent hallucination.</p><pre class="op oq or os ot ou ov ow bp ox bb bk"><span id="efda" class="oy np gc ov b bg oz pa l pb pc">class ServiceEngineerChatbot:<br/>    def __init__(self):<br/>        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])<br/><br/>    def construct_flash_model(self, brand, sub_category, model_number):<br/>        model_system_instruction = f"""<br/>        Add your detailed system instructions here.<br/>        These instructions should define the chatbot's behavior, tone, and <br/>        provide any necessary context. For example, you might include <br/>        guidelines about how to respond to queries, the structure of <br/>        responses, or information about what the chatbot should and should<br/>        not do. Checkout my repo for this chatbot's system instructions.<br/>        """<br/>        <br/>        model_generation_cofig = genai.types.GenerationConfig(<br/>            candidate_count=1,<br/>            max_output_tokens=1500,<br/>            temperature=0.4,<br/>        ),<br/><br/>        model = genai.GenerativeModel(<br/>            model_name="gemini-1.5-flash",<br/>            system_instruction=model_system_instruction,<br/>            generation_config=model_generation_cofig,<br/>        )<br/>        return model</span></pre><p id="8f49" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">We can further control the model’s response generation by tuning the model parameters through the GenerationConfig class. In our application, we’ve set the max_output_tokens to 1500, defining the maximum token limit for each response, and the temperature to 0.4, to maintain determinism in the response.</p><h1 id="eaa0" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Long context optimization with Context Caching</h1><p id="4849" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">In many cases, especially with recurring queries against the same document, we end up sending the same input tokens repeatedly to the model. While this approach may work, it's not optimal for large-scale, production-level rollouts</p><p id="72c3" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This is where Gemini’s context caching feature becomes essential, offering a more efficient solution by reducing both costs and latency for high-token workloads. With context caching, instead of sending same input tokens with every request, we can refer to the cached tokens for the subsequent requests</p><figure class="op oq or os ot fo fv fw paragraph-image"><div role="button" tabindex="0" class="pi pj ed pk bh pl"><div class="fv fw ph"><img src="../Images/1b41ca56dd2eb7728e323325dc577207.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jAO-wK5TjU_4rv3K4Y5wgA.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image by Author</figcaption></figure><p id="9aab" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">In this project, we cache both the system instruction and the service manual file. At scale, using cached tokens significantly reduces the cost compared to repeatedly passing the same data. By default the Time-to-Live (TTL) for these cached tokens is 1 hour, though it can be adjusted as required. Once the TTL expires, the cached tokens are automatically removed from Gemini’s context</p><pre class="op oq or os ot ou ov ow bp ox bb bk"><span id="1441" class="oy np gc ov b bg oz pa l pb pc">class ServiceEngineerChatbot:<br/>    def _generate_context_cache(<br/>        self,<br/>        brand,<br/>        sub_category,<br/>        model_number,<br/>        service_guide_title,<br/>        service_guide,<br/>        ttl_mins=70,<br/>    ):<br/>        context_cache = caching.CachedContent.create(<br/>            model='models/gemini-1.5-flash-001',<br/>            display_name=f"{service_guide_title}_cache",<br/>            system_instruction=model_system_instruction,<br/>            contents=[<br/>                service_guide<br/>            ],<br/>            ttl=datetime.timedelta(<br/>                minutes=ttl_mins<br/>            ),<br/>        )<br/><br/>        return context_cache</span></pre><p id="9048" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">It’s important to note that context caching is only available for an input token count of 32,768 or more. If token count is below this threshold, you’ll need to rely on the standard multimodal prompting capabilities of Gemini 1.5 Flash.</p><h1 id="22df" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Integrating Chatbot with Streamlit</h1><p id="e4ab" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">With our chatbot’s response generation capabilities in place, the final step is to wrap it in a Streamlit app to create an intuitive user interface for the users.</p><figure class="op oq or os ot fo fv fw paragraph-image"><div role="button" tabindex="0" class="pi pj ed pk bh pl"><div class="fv fw ph"><img src="../Images/d5221aaf47c78a7a5d1a43c8f0552755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UJSxi50o7NGMIwR7LrIuUw.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image by Author</figcaption></figure><p id="30e1" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The interface features a dropdown where the users can select the brand, and model of the appliance they are working with. After making the selection &amp; clicking the “Configure chatbot” button, the app will post the corresponding service manual to Gemini and present the chat interface. From thereon, the engineer can enter their queries &amp; the chatbot will provide relevant response</p><h1 id="0243" class="no np gc bf nq nr ns hc nt nu nv hf nw nx ny nz oa ob oc od oe of og oh oi oj bk">Future Scope</h1><p id="0375" class="pw-post-body-paragraph ms mt gc mu b ha ok mw mx hd ol mz na nb om nd ne nf on nh ni nj oo nl nm nn fj bk">Looking ahead, there are several promising directions to explore. The future iterations of the chatbot could integrate voice support, allowing engineers to communicate more naturally with the chatbot to get their queries addressed.</p><p id="636e" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Additionally, expanding the system to incorporate predictive diagnostics can enable engineers to preemptively identify potential issues before they lead to equipment failures. By continuing to evolve this tool, the goal is to create a comprehensive support system for service engineers, ultimately improving the customer experience, thus transforming the troubleshooting eco-system</p><p id="5cc3" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">With that, we have reached the end of this article. If you have any questions or believe I have made any mistake, please feel free to reach out to me! You can get in touch with me via <a class="af fz" href="mailto:rajashwin733@gmail.com" rel="noopener ugc nofollow" target="_blank">Email</a> or <a class="af fz" href="https://www.linkedin.com/in/thisisashwinraj/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>. Until then, happy learning!</p></div></div></div></div>    
</body>
</html>