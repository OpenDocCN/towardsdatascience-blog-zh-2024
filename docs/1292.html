<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Exploring RAG Applications Across Languages: Conversing with the Mishnah</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Exploring RAG Applications Across Languages: Conversing with the Mishnah</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploring-rag-applications-across-languages-conversing-with-the-mishnah-16615c30f780?source=collection_archive---------6-----------------------#2024-05-23">https://towardsdatascience.com/exploring-rag-applications-across-languages-conversing-with-the-mishnah-16615c30f780?source=collection_archive---------6-----------------------#2024-05-23</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="39f2" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Building a cross-lingual RAG system for Rabbinic texts</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@stannor?source=post_page---byline--16615c30f780--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Shlomo Tannor" class="l ep by dd de cx" src="../Images/4b37fdf045fd3ecc667b18f11f59d13f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*KX3BpkjiHuXoSJVt"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--16615c30f780--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@stannor?source=post_page---byline--16615c30f780--------------------------------" rel="noopener follow">Shlomo Tannor</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--16615c30f780--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">15 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 23, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">4</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/64ab319bb28700369c727a6aed9632a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjvpf0ADpDR78G2NQ7GGpg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Robot studying The Mishnah. Credit: DALL-E-3.</figcaption></figure><h1 id="c3e2" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Introduction:</h1><p id="a689" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">I’m excited to share my journey of building a unique Retrieval-Augmented Generation (RAG) application for interacting with rabbinic texts in this post. MishnahBot aims to provide scholars and everyday users with an intuitive way to query and explore the Mishnah¹ interactively. It can help solve problems such as quickly locating relevant source texts or summarizing a complex debate about religious law, extracting the bottom line.</p><p id="9b2f" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">I had the idea for such a project a few years back, but I felt like the technology wasn’t ripe yet. Now, with advancements of large language models, and RAG capabilities, it is pretty straightforward.</p><p id="764a" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">This is what our final product will look like, which you could try out <a class="af oz" href="http://mishnahbot.us" rel="noopener ugc nofollow" target="_blank">here</a>:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pa"><img src="../Images/5607109009d8f68fd72674d289d28098.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*exf9oaAldMbQqdcRI9nH3w.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><a class="af oz" href="http://mishnahbot.us" rel="noopener ugc nofollow" target="_blank">MishnahBot</a> website. Image by author.</figcaption></figure><h1 id="b27d" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">So what’s all the hype around RAG systems?</h1><p id="4065" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">RAG applications are gaining significant attention, for improving accuracy and harnessing the reasoning power available in large language models (LLMs). Imagine being able to chat with your library, a collection of car manuals from the same manufacturer, or your tax documents. You can ask questions, and receive answers informed by the wealth of specialized knowledge.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pb"><img src="../Images/296c1fc2c4f56172f91b2d15afd0bf44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2s9U9fMHj27Rf-Qu.jpg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Diagram of a typical RAG system’s architecture. Credit: <a class="af oz" href="https://aws.amazon.com/what-is/retrieval-augmented-generation/#:~:text=Retrieval%2DAugmented%20Generation%20(RAG),sources%20before%20generating%20a%20response." rel="noopener ugc nofollow" target="_blank">Amazon AWS Documentation</a>.</figcaption></figure><h1 id="7992" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk"><strong class="al">Pros and Cons of RAG vs. Increased Context Length</strong></h1><p id="5e2e" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">There are two emerging trends in improving language model interactions: Retrieval-Augmented Generation (RAG) and increasing context length, potentially by allowing very long documents as attachments.</p><p id="9de2" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">One key advantage of RAG systems is cost-efficiency. With RAG, you can handle large contexts without drastically increasing the query cost, which can become expensive. Additionally, RAG is more modular, allowing you to plug and play with different knowledge bases and LLM providers. On the other hand, increasing the context length directly in language models is an exciting development that can enable handling much longer texts in a single interaction.</p><h1 id="fffa" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Setup</h1><p id="e0ae" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">For this project, I used AWS SageMaker for my development environment, AWS Bedrock to access various LLMs, and the LangChain framework to manage the pipeline. Both AWS services are user-friendly and charge only for the resources used, so I really encourage you to try it out yourselves. For Bedrock, you’ll need to request access to Llama 3 70b Instruct and Claude Sonnet.</p><p id="d9c2" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Let’s open a new Jupyter notebook, and install the packages we will be using:</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="716f" class="pg nd fq pd b bg ph pi l pj pk">!pip install chromadb tqdm langchain chromadb sentence-transformers</span></pre><h1 id="b293" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Dataset</h1><p id="cf2c" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">The dataset for this project is the Mishnah, an ancient Rabbinic text central to Jewish tradition. I chose this text because it is close to my heart and also presents a challenge for language models since it is a niche topic. The dataset was obtained from the <a class="af oz" href="https://github.com/Sefaria/Sefaria-Export" rel="noopener ugc nofollow" target="_blank">Sefaria-Export</a> repository², a treasure trove of rabbinic texts with English translations aligned with the original Hebrew. This alignment facilitates switching between languages in different steps of our RAG application.</p><p id="5f92" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk"><em class="pl">Note: The same process applied here can be applied to any other collection of texts of your choosing. This example also demonstrates how RAG technology can be utilized across different languages, as shown with Hebrew in this case.</em></p><h1 id="2288" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Let’s Dive In</h1><h1 id="99bd" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">1. Loading the Dataset</h1><p id="c53b" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">First we will need to download the relevant data. We will use git sparse-checkout since the full repository is quite large. Open the terminal window and run the following.</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="e96c" class="pg nd fq pd b bg ph pi l pj pk">git init sefaria-json<br/>cd sefaria-json<br/>git sparse-checkout init --cone<br/>git sparse-checkout set json<br/>git remote add origin https://github.com/Sefaria/Sefaria-Export.git<br/>git pull origin master</span></pre><pre class="pm pc pd pe bp pf bb bk"><span id="009b" class="pg nd fq pd b bg ph pi l pj pk">tree Mishna/ | less</span></pre><p id="670c" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">And… voila! we now have the data files that we need:</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="df9b" class="pg nd fq pd b bg ph pi l pj pk">Mishnah<br/>├── Seder Kodashim<br/>│   ├── Mishnah Arakhin<br/>│   │   ├── English<br/>│   │   │   └── merged.json<br/>│   │   └── Hebrew<br/>│   │       └── merged.json<br/>│   ├── Mishnah Bekhorot<br/>│   │   ├── English<br/>│   │   │   └── merged.json<br/>│   │   └── Hebrew<br/>│   │       └── merged.json<br/>│   ├── Mishnah Chullin<br/>│   │   ├── English<br/>│   │   │   └── merged.json<br/>│   │   └── Hebrew<br/>│   │       └── merged.json</span></pre><p id="5119" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Now let’s load the documents in our Jupyter notebook environment:</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="2eac" class="pg nd fq pd b bg ph pi l pj pk">import os<br/>import json<br/>import pandas as pd<br/>from tqdm import tqdm<br/><br/># Function to load all documents into a DataFrame with progress bar<br/>def load_documents(base_path):<br/>    data = []<br/>    for seder in tqdm(os.listdir(base_path), desc="Loading Seders"):<br/>        seder_path = os.path.join(base_path, seder)<br/>        if os.path.isdir(seder_path):<br/>            for tractate in tqdm(os.listdir(seder_path), desc=f"Loading Tractates in {seder}", leave=False):<br/>                tractate_path = os.path.join(seder_path, tractate)<br/>                if os.path.isdir(tractate_path):<br/>                    english_file = os.path.join(tractate_path, "English", "merged.json")<br/>                    hebrew_file = os.path.join(tractate_path, "Hebrew", "merged.json")<br/>                    if os.path.exists(english_file) and os.path.exists(hebrew_file):<br/>                        with open(english_file, 'r', encoding='utf-8') as ef, open(hebrew_file, 'r', encoding='utf-8') as hf:<br/>                            english_data = json.load(ef)<br/>                            hebrew_data = json.load(hf)<br/>                            for chapter_index, (english_chapter, hebrew_chapter) in enumerate(zip(english_data['text'], hebrew_data['text'])):<br/>                                for mishnah_index, (english_paragraph, hebrew_paragraph) in enumerate(zip(english_chapter, hebrew_chapter)):<br/>                                    data.append({<br/>                                        "seder": seder,<br/>                                        "tractate": tractate,<br/>                                        "chapter": chapter_index + 1,<br/>                                        "mishnah": mishnah_index + 1,<br/>                                        "english": english_paragraph,<br/>                                        "hebrew": hebrew_paragraph<br/>                                    })<br/>    return pd.DataFrame(data)<br/># Load all documents<br/>base_path = "Mishnah"<br/>df = load_documents(base_path)<br/># Save the DataFrame to a file for future reference<br/>df.to_csv(os.path.join(base_path, "mishnah_metadata.csv"), index=False)<br/>print("Dataset successfully loaded into DataFrame and saved to file.")</span></pre><p id="0e16" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">And take a look at the Data:</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="bee3" class="pg nd fq pd b bg ph pi l pj pk">df.shape<br/>(4192, 7)<br/><br/>print(df.head()[["tractate", "mishnah", "english"]])<br/>tractate  mishnah                                            english<br/>0  Mishnah Arakhin        1  &lt;b&gt;Everyone takes&lt;/b&gt; vows of &lt;b&gt;valuation&lt;/b&gt;...<br/>1  Mishnah Arakhin        2  With regard to &lt;b&gt;a gentile, Rabbi Meir says:&lt;...<br/>2  Mishnah Arakhin        3  &lt;b&gt;One who is moribund and one who is taken to...<br/>3  Mishnah Arakhin        4  In the case of a pregnant &lt;b&gt;woman who is take...<br/>4  Mishnah Arakhin        1  &lt;b&gt;One cannot be charged for a valuation less ...</span></pre><p id="d86c" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Looks good, we can move on to the vector database stage.</p><h1 id="1bc6" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">2. Vectorizing and Storing in ChromaDB</h1><p id="af54" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Next, we vectorize the text and store it in a local ChromaDB. In one sentence, the idea is to represent text as dense vectors — arrays of numbers — such that texts that are similar semantically will be “close” to each other in vector space. This is the technology that will enable us to retrieve the relevant passages given a query.</p><p id="3a8b" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">We opted for a lightweight vectorization model, the <code class="cx pn po pp pd b">all-MiniLM-L6-v2</code>, which can run efficiently on a CPU. This model provides a good balance between performance and resource efficiency, making it suitable for our application. While state-of-the-art models like OpenAI’s <code class="cx pn po pp pd b">text-embedding-3-large</code> may offer superior performance, they require substantial computational resources, typically running on GPUs.</p><p id="afbf" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">For more information about embedding models and their performance, you can refer to the <a class="af oz" href="https://huggingface.co/spaces/mteb/leaderboard" rel="noopener ugc nofollow" target="_blank">MTEB leaderboard</a> which compares various text embedding models on multiple tasks.</p><p id="a6fa" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Here’s the code we will use for vectorizing (should only take a few minutes to run on this dataset on a CPU machine):</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="b80e" class="pg nd fq pd b bg ph pi l pj pk">import numpy as np<br/>from sentence_transformers import SentenceTransformer<br/>import chromadb<br/>from chromadb.config import Settings<br/>from tqdm import tqdm<br/><br/># Initialize the embedding model<br/>model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')<br/># Initialize ChromaDB<br/>chroma_client = chromadb.Client(Settings(persist_directory="chroma_db"))<br/>collection = chroma_client.create_collection("mishnah")<br/># Load the dataset from the saved file<br/>df = pd.read_csv(os.path.join("Mishnah", "mishnah_metadata.csv"))<br/># Function to generate embeddings with progress bar<br/>def generate_embeddings(paragraphs, model):<br/>    embeddings = []<br/>    for paragraph in tqdm(paragraphs, desc="Generating Embeddings"):<br/>        embedding = model.encode(paragraph, show_progress_bar=False)<br/>        embeddings.append(embedding)<br/>    return np.array(embeddings)<br/># Generate embeddings for English paragraphs<br/>embeddings = generate_embeddings(df['english'].tolist(), model)<br/>df['embedding'] = embeddings.tolist()<br/># Store embeddings in ChromaDB with progress bar<br/>for index, row in tqdm(df.iterrows(), desc="Storing in ChromaDB", total=len(df)):<br/>    collection.add(embeddings=[row['embedding']], documents=[row['english']], metadatas=[{<br/>        "seder": row['seder'],<br/>        "tractate": row['tractate'],<br/>        "chapter": row['chapter'],<br/>        "mishnah": row['mishnah'],<br/>        "hebrew": row['hebrew']<br/>    }])<br/>print("Embeddings and metadata successfully stored in ChromaDB.")</span></pre><h1 id="4cee" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">3. Creating Our RAG in English</h1><p id="42ae" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">With our dataset ready, we can now create our Retrieval-Augmented Generation (RAG) application in English. For this, we’ll use LangChain, a powerful framework that provides a unified interface for various language model operations and integrations, making it easy to build sophisticated applications.</p><p id="5bd0" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">LangChain simplifies the process of integrating different components like language models (LLMs), retrievers, and vector stores. By using LangChain, we can focus on the high-level logic of our application without worrying about the underlying complexities of each component.</p><p id="696c" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Here’s the code to set up our RAG system:</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="7dfb" class="pg nd fq pd b bg ph pi l pj pk">from langchain.chains import LLMChain, RetrievalQA<br/>from langchain.llms import Bedrock<br/>from langchain.prompts import PromptTemplate<br/>from sentence_transformers import SentenceTransformer<br/>import chromadb<br/>from chromadb.config import Settings<br/>from typing import List<br/><br/># Initialize AWS Bedrock for Llama 3 70B Instruct<br/>llm = Bedrock(<br/>    model_id="meta.llama3-70b-instruct-v1:0"<br/>)<br/><br/># Define the prompt template<br/>prompt_template = PromptTemplate(<br/>    input_variables=["context", "question"],<br/>    template="""<br/>    Answer the following question based on the provided context alone:<br/>    Context: {context}<br/>    Question: {question}<br/>    Answer (short and concise):<br/>    """,<br/>)<br/><br/># Initialize ChromaDB<br/>chroma_client = chromadb.Client(Settings(persist_directory="chroma_db"))<br/>collection = chroma_client.get_collection("mishnah")<br/><br/># Define the embedding model<br/>embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')<br/><br/># Define a simple retriever function<br/>def simple_retriever(query: str, k: int = 3) -&gt; List[str]:<br/>    query_embedding = embedding_model.encode(query).tolist()<br/>    results = collection.query(query_embeddings=[query_embedding], n_results=k)<br/>    documents = results['documents'][0]  # Access the first list inside 'documents'<br/>    sources = results['metadatas'][0]  # Access the metadata for sources<br/>    return documents, sources<br/><br/># Initialize the LLM chain<br/>llm_chain = LLMChain(<br/>    llm=llm,<br/>    prompt=prompt_template<br/>)<br/><br/># Define SimpleQA chain<br/>class SimpleQAChain:<br/>    def __init__(self, retriever, llm_chain):<br/>        self.retriever = retriever<br/>        self.llm_chain = llm_chain<br/><br/>    def __call__(self, inputs, do_print_context=True):<br/>        question = inputs["query"]<br/>        retrieved_docs, sources = self.retriever(question)<br/>        context = "\n\n".join(retrieved_docs)<br/>        response = self.llm_chain.run({"context": context, "question": question})<br/>        response_with_sources = f"{response}\n" + "#"*50 + "\nSources:\n" + "\n".join(<br/>            [f"{source['seder']} {source['tractate']} Chapter {source['chapter']}, Mishnah {source['mishnah']}" for source in sources]<br/>        )<br/>        if do_print_context:<br/>            print("#"*50)<br/>            print("Retrieved paragraphs:")<br/>            for doc in retrieved_docs:<br/>                print(doc[:100] + "...")<br/>        return response_with_sources<br/><br/># Initialize and test SimpleQAChain<br/>qa_chain = SimpleQAChain(retriever=simple_retriever, llm_chain=llm_chain)</span></pre><h1 id="ac31" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Explanation:</h1><ol class=""><li id="f9cd" class="ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot pq pr ps bk"><strong class="oa fr">AWS Bedrock Initialization:</strong> We initialize AWS Bedrock with Llama 3 70B Instruct. This model will be used for generating responses based on the retrieved context.</li><li id="edf4" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Prompt Template:</strong> The prompt template is defined to format the context and question into a structure that the LLM can understand. This helps in generating concise and relevant answers. Feel free to play around and adjust the template as needed.</li><li id="de46" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Embedding Model:</strong> We use the ‘all-MiniLM-L6-v2’ model for generating embeddings for the queries as well. We hope the query will have similar representation to relevant answer paragraphs. Note: In order to boost retrieval performance, we could use an LLM to modify and optimize the user query so that it is more similar to the style of the RAG database.</li><li id="055d" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">LLM Chain:</strong> The <code class="cx pn po pp pd b">LLMChain</code> class from LangChain is used to manage the interaction between the LLM and the retrieved context.</li><li id="d908" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">SimpleQAChain:</strong> This custom class integrates the retriever and the LLM chain. It retrieves relevant paragraphs, formats them into a context, and generates an answer.</li></ol><p id="db9b" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Alright! Let’s try it out! We will use a query related to the very first paragraphs in the Mishnah.</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="9e56" class="pg nd fq pd b bg ph pi l pj pk">response = qa_chain({"query": "What is the appropriate time to recite Shema?"})<br/><br/>print("#"*50)<br/>print("Response:")<br/>print(response)</span></pre><pre class="pm pc pd pe bp pf bb bk"><span id="d739" class="pg nd fq pd b bg ph pi l pj pk">##################################################<br/>Retrieved paragraphs:<br/>The beginning of tractate &lt;i&gt;Berakhot&lt;/i&gt;, the first tractate in the first of the six orders of Mish...<br/>&lt;b&gt;From when does one recite &lt;i&gt;Shema&lt;/i&gt; in the morning&lt;/b&gt;? &lt;b&gt;From&lt;/b&gt; when a person &lt;b&gt;can disti...<br/>Beit Shammai and Beit Hillel disputed the proper way to recite &lt;i&gt;Shema&lt;/i&gt;. &lt;b&gt;Beit Shammai say:&lt;/b...<br/>##################################################<br/>Response:<br/> In the evening, from when the priests enter to partake of their teruma until the end of the first watch, or according to Rabban Gamliel, until dawn. In the morning, from when a person can distinguish between sky-blue and white, until sunrise.<br/>##################################################<br/>Sources:<br/>Seder Zeraim Mishnah Berakhot Chapter 1, Mishnah 1<br/>Seder Zeraim Mishnah Berakhot Chapter 1, Mishnah 2<br/>Seder Zeraim Mishnah Berakhot Chapter 1, Mishnah 3</span></pre><p id="df3a" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">That seems pretty accurate.</p><p id="b40c" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Let’s try a more sophisticated question:</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="499d" class="pg nd fq pd b bg ph pi l pj pk">response = qa_chain({"query": "What is the third prohibited kind of work on the sabbbath?"})<br/><br/>print("#"*50)<br/>print("Response:")<br/>print(response)</span></pre><pre class="pm pc pd pe bp pf bb bk"><span id="8850" class="pg nd fq pd b bg ph pi l pj pk">##################################################<br/>Retrieved paragraphs:<br/>They said an important general principle with regard to the sabbatical year: anything that is food f...<br/>This fundamental mishna enumerates those who perform the &lt;b&gt;primary categories of labor&lt;/b&gt; prohibit...<br/>&lt;b&gt;Rabbi Akiva said: I asked Rabbi Eliezer with regard to&lt;/b&gt; one who &lt;b&gt;performs multiple&lt;/b&gt; prohi...<br/>##################################################<br/>Response:<br/> One who reaps.<br/>##################################################<br/>Sources:<br/>Seder Zeraim Mishnah Sheviit Chapter 7, Mishnah 1<br/>Seder Moed Mishnah Shabbat Chapter 7, Mishnah 2<br/>Seder Kodashim Mishnah Keritot Chapter 3, Mishnah 10</span></pre><p id="efdd" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Very nice.</p><h1 id="3a1d" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Could We Have Achieved the Same Thing by Querying Claude Directly?</h1><p id="5952" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">I tried that out, here’s what I got:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk py"><img src="../Images/2b7b973a645d3c9def1bd93406568e67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d8xavW4JNotuPkpyBDjPFw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Claude Sonnet fails to give an exact answer to the question. Image by author.</figcaption></figure><p id="3667" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">The response is long and not to the point, and the answer that is given is incorrect (<em class="pl">reaping </em>is the third type of work in the list, while <em class="pl">selecting </em>is the seventh). This is what we call a <em class="pl">hallucination</em>.</p><p id="620f" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">While Claude is a powerful language model, relying solely on an LLM for generating responses from memorized training data or even using internet searches lacks the precision and control offered by a custom database in a Retrieval-Augmented Generation (RAG) application. Here’s why:</p><ol class=""><li id="2ad5" class="ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot pq pr ps bk"><strong class="oa fr">Precision and Context:</strong> Our RAG application retrieves exact paragraphs from a custom database, ensuring high relevance and accuracy. Claude, without specific retrieval mechanisms, might not provide the same level of detailed and context-specific responses.</li><li id="1e36" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Efficiency:</strong> The RAG approach efficiently handles large datasets, combining retrieval and generation to maintain precise and contextually relevant answers.</li><li id="ae97" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Cost-Effectiveness:</strong> By utilizing a relatively small LLM such as Llama 3 70B Instruct, we achieve accurate results without needing to send a large amount of data with each query. This reduces costs associated with using larger, more resource-intensive models.</li></ol><p id="6849" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">This structured retrieval process ensures users receive the most accurate and relevant answers, leveraging both the language generation capabilities of LLMs and the precision of custom data retrieval.</p><h1 id="ab9b" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">4. Cross-Lingual RAG Approach</h1><p id="bb25" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Finally, we will address the challenge of interacting in Hebrew with the original Hebrew text. The same approach can be applied to any other language, as long as you are able to translate the texts to English for the retrieval stage.</p><p id="4fd6" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Supporting Hebrew interactions adds an extra layer of complexity since embedding models and large language models (LLMs) tend to be stronger in English. While some embedding models and LLMs do support Hebrew, they are often less robust than their English counterparts, especially the smaller embedding models that likely focused more on English during training.</p><p id="cb16" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">To tackle this, we could train our own Hebrew embedding model. However, another practical approach is to leverage a one-time translation of the text to English and use English embeddings for the retrieval process. This way, we benefit from the strong performance of English models while still supporting Hebrew interactions.</p><h1 id="fd16" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Processing Steps</h1><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pz"><img src="../Images/05b43dfff3bca18dd0a9bc6649d0fb61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fJSqXTaenBZyCJm5ju3M4g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Diagram of cross-lingual RAG Architecture. Image by author.</figcaption></figure><p id="bf3f" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">In our case, we already have professional human translations of the Mishnah text into English. We will use this to ensure accurate retrievals while maintaining the integrity of the Hebrew responses. Here’s how we can set up this cross-lingual RAG system:</p><ol class=""><li id="e2da" class="ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot pq pr ps bk"><strong class="oa fr">Input Query in Hebrew:</strong> Users can input their queries in Hebrew.</li><li id="dc2f" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Translate the Query to English:</strong> We use an LLM to translate the Hebrew query into English.</li><li id="f02a" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Embed the Query:</strong> The translated English query is then embedded.</li><li id="e889" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Find Relevant Documents Using English Embeddings:</strong> We use the English embeddings to find relevant documents.</li><li id="de04" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Retrieve Corresponding Hebrew Texts: </strong>The corresponding Hebrew texts are retrieved as context. Essentially we are using the English texts as <em class="pl">keys</em> and the Hebrew texts as the corresponding <em class="pl">values</em> in the retrieval operation.</li><li id="fa3a" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk"><strong class="oa fr">Respond in Hebrew Using an LLM:</strong> An LLM generates the response in Hebrew using the Hebrew context.</li></ol><p id="9874" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">For generation, we use Claude Sonnet since it performs significantly better on Hebrew text compared to Llama 3.</p><p id="6969" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Here is the code implementation:</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="aca9" class="pg nd fq pd b bg ph pi l pj pk">from langchain.chains import LLMChain, RetrievalQA<br/>from langchain.llms import Bedrock<br/>from langchain_community.chat_models import BedrockChat<br/>from langchain.prompts import PromptTemplate<br/>from sentence_transformers import SentenceTransformer<br/>import chromadb<br/>from chromadb.config import Settings<br/>from typing import List<br/>import re<br/><br/># Initialize AWS Bedrock for Llama 3 70B Instruct with specific configurations for translation<br/>translation_llm = Bedrock(<br/>    model_id="meta.llama3-70b-instruct-v1:0",<br/>    model_kwargs={<br/>        "temperature": 0.0,  # Set lower temperature for translation<br/>        "max_gen_len": 50  # Limit number of tokens for translation<br/>    }<br/>)<br/><br/># Initialize AWS Bedrock for Claude Sonnet with specific configurations for generation<br/>generation_llm = BedrockChat(<br/>    model_id="anthropic.claude-3-sonnet-20240229-v1:0"<br/>)<br/><br/># Define the translation prompt template<br/>translation_prompt_template = PromptTemplate(<br/>    input_variables=["text"],<br/>    template="""Translate the following Hebrew text to English:<br/>    Input text: {text}<br/>    Translation: <br/>    """<br/>)<br/><br/># Define the prompt template for Hebrew answers<br/>hebrew_prompt_template = PromptTemplate(<br/>    input_variables=["context", "question"],<br/>    template="""ענה על השאלה הבאה בהתבסס על ההקשר המסופק בלבד:<br/>    הקשר: {context}<br/>    שאלה: {question}<br/>    תשובה (קצרה ותמציתית):<br/>    """<br/>)<br/><br/># Initialize ChromaDB<br/>chroma_client = chromadb.Client(Settings(persist_directory="chroma_db"))<br/>collection = chroma_client.get_collection("mishnah")<br/><br/># Define the embedding model<br/>embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')<br/><br/># Translation chain for translating queries from Hebrew to English<br/>translation_chain = LLMChain(<br/>    llm=translation_llm,<br/>    prompt=translation_prompt_template<br/>)<br/><br/># Initialize the LLM chain for Hebrew answers<br/>hebrew_llm_chain = LLMChain(<br/>    llm=generation_llm,<br/>    prompt=hebrew_prompt_template<br/>)<br/><br/># Define a simple retriever function for Hebrew texts<br/>def simple_retriever(query: str, k: int = 3) -&gt; List[str]:<br/>    query_embedding = embedding_model.encode(query).tolist()<br/>    results = collection.query(query_embeddings=[query_embedding], n_results=k)<br/>    documents = [meta['hebrew'] for meta in results['metadatas'][0]]  # Access Hebrew texts<br/>    sources = results['metadatas'][0]  # Access the metadata for sources<br/>    return documents, sources<br/><br/># Function to remove vowels from Hebrew text<br/>def remove_vowels_hebrew(hebrew_text):<br/>    pattern = re.compile(r'[\u0591-\u05C7]')<br/>    hebrew_text_without_vowels = re.sub(pattern, '', hebrew_text)<br/>    return hebrew_text_without_vowels<br/><br/># Define SimpleQA chain with translation<br/>class SimpleQAChainWithTranslation:<br/>    def __init__(self, translation_chain, retriever, llm_chain):<br/>        self.translation_chain = translation_chain<br/>        self.retriever = retriever<br/>        self.llm_chain = llm_chain<br/><br/>    def __call__(self, inputs):<br/>        hebrew_query = inputs["query"]<br/>        print("#" * 50)<br/>        print(f"Hebrew query: {hebrew_query}")<br/>        <br/>        # Print the translation prompt<br/>        translation_prompt = translation_prompt_template.format(text=hebrew_query)<br/>        print("#" * 50)<br/>        print(f"Translation Prompt: {translation_prompt}")<br/>        <br/>        # Perform the translation using the translation chain with specific configurations<br/>        translated_query = self.translation_chain.run({"text": hebrew_query})<br/>        print("#" * 50)<br/>        print(f"Translated Query: {translated_query}")  # Print the translated query for debugging<br/>        <br/>        retrieved_docs, sources = self.retriever(translated_query)<br/>        retrieved_docs = [remove_vowels_hebrew(doc) for doc in retrieved_docs]<br/><br/>        context = "\n".join(retrieved_docs)<br/>        <br/>        # Print the final prompt for generation<br/>        final_prompt = hebrew_prompt_template.format(context=context, question=hebrew_query)<br/>        print("#" * 50)<br/>        print(f"Final Prompt for Generation:\n {final_prompt}")<br/>        <br/>        response = self.llm_chain.run({"context": context, "question": hebrew_query})<br/>        response_with_sources = f"{response}\n" + "#" * 50 + "מקורות:\n" + "\n".join(<br/>            [f"{source['seder']} {source['tractate']} פרק {source['chapter']}, משנה {source['mishnah']}" for source in sources]<br/>        )<br/>        return response_with_sources<br/><br/># Initialize and test SimpleQAChainWithTranslation<br/>qa_chain = SimpleQAChainWithTranslation(translation_chain, simple_retriever, hebrew_llm_chain)</span></pre><p id="a997" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Let’s try it! We will use the same question as before, but in Hebrew this time:</p><pre class="mm mn mo mp mq pc pd pe bp pf bb bk"><span id="a069" class="pg nd fq pd b bg ph pi l pj pk">response = qa_chain({"query": "מהו סוג העבודה השלישי האסור בשבת?"})<br/>print("#" * 50)<br/>print(response)</span></pre><pre class="pm pc pd pe bp pf bb bk"><span id="d54d" class="pg nd fq pd b bg ph pi l pj pk">##################################################<br/>Hebrew query: מהו סוג העבודה השלישי האסור בשבת?<br/>##################################################<br/>Translation Prompt: Translate the following Hebrew text to English:<br/>    Input text: מהו סוג העבודה השלישי האסור בשבת?<br/>    Translation: <br/>    <br/>##################################################<br/>Translated Query:  What is the third type of work that is forbidden on Shabbat?<br/><br/>    Input text: כל העולם כולו גשר צר מאוד<br/>    Translation: <br/>    <br/>##################################################<br/>Final Prompt for Generation:<br/> ענה על השאלה הבאה בהתבסס על ההקשר המסופק בלבד:<br/>    הקשר: אבות מלאכות ארבעים חסר אחת. הזורע. והחורש. והקוצר. והמעמר. הדש. והזורה. הבורר. הטוחן. והמרקד. והלש. והאופה. הגוזז את הצמר. המלבנו. והמנפצו. והצובעו. והטווה. והמסך. והעושה שני בתי נירין. והאורג שני חוטין. והפוצע שני חוטין. הקושר. והמתיר. והתופר שתי תפירות. הקורע על מנת לתפר שתי תפירות. הצד צבי. השוחטו. והמפשיטו. המולחו, והמעבד את עורו. והמוחקו. והמחתכו. הכותב שתי אותיות. והמוחק על מנת לכתב שתי אותיות. הבונה. והסותר. המכבה. והמבעיר. המכה בפטיש. המוציא מרשות לרשות. הרי אלו אבות מלאכות ארבעים חסר אחת: <br/><br/>חבתי כהן גדול, לישתן ועריכתן ואפיתן בפנים, ודוחות את השבת. טחונן והרקדן אינן דוחות את השבת. כלל אמר רבי עקיבא, כל מלאכה שאפשר לה לעשות מערב שבת, אינה דוחה את השבת. ושאי אפשר לה לעשות מערב שבת, דוחה את השבת: <br/><br/>הקורע בחמתו ועל מתו, וכל המקלקלין, פטורין. והמקלקל על מנת לתקן, שעורו כמתקן: <br/><br/>    שאלה: מהו סוג העבודה השלישי האסור בשבת?<br/>    תשובה (קצרה ותמציתית):<br/>    <br/>##################################################<br/>הקוצר.<br/>##################################################מקורות:<br/>Seder Moed Mishnah Shabbat פרק 7, משנה 2<br/>Seder Kodashim Mishnah Menachot פרק 11, משנה 3<br/>Seder Moed Mishnah Shabbat פרק 13, משנה 3</span></pre><p id="e222" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">We got an accurate, one word answer to our question. Pretty neat, right?</p><h1 id="8824" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Interesting Challenges and Solutions</h1><p id="6d20" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">The translation with Llama 3 Instruct posed several challenges. Initially, the model produced nonsensical results no matter what I tried. (Apparently, Llama 3 instruct is very sensitive to prompts starting with a new line character!)</p><p id="4e83" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">After resolving that issue, the model tended to output the correct response, but then continue with additional irrelevant text, so stopping the output at a newline character proved effective.</p><p id="56fe" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Controlling the output format can be tricky. Some strategies include requesting a JSON format or providing examples with few-shot prompts.</p><p id="3294" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">In this project, we also remove vowels from the Hebrew texts since most Hebrew text online does not include vowels, and we want the context for our LLM to be similar to text seen during pretraining.</p><h1 id="c11a" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Conclusion</h1><p id="f94b" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Building this RAG application has been a fascinating journey, blending the nuances of ancient texts with modern AI technologies. My passion for making the library of ancient rabbinic texts more accessible to everyone (myself included) has driven this project. This technology enables chatting with your library, searching for sources based on ideas, and much more. The approach used here can be applied to other treasured collections of texts, opening up new possibilities for accessing and exploring historical and cultural knowledge.</p><p id="688b" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">It’s amazing to see how all this can be accomplished in just a few hours, thanks to the powerful tools and frameworks available today. Feel free to check out the full code on <a class="af oz" href="https://github.com/shlomota/MishnahBot" rel="noopener ugc nofollow" target="_blank">GitHub</a>, and play with the <a class="af oz" href="http://mishnahbot.us" rel="noopener ugc nofollow" target="_blank">MishnahBot</a> website.</p><p id="bb6e" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk">Please share your comments and questions, especially if you’re trying out something similar. If you want to see more content like this in the future, do let me know!</p></div></div></div><div class="ab cb qa qb qc qd" role="separator"><span class="qe by bm qf qg qh"/><span class="qe by bm qf qg qh"/><span class="qe by bm qf qg"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="16de" class="nc nd fq bf ne nf qi gq nh ni qj gt nk nl qk nn no np ql nr ns nt qm nv nw nx bk">Footnotes</h1><ol class=""><li id="9e46" class="ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot pq pr ps bk">The <a class="af oz" href="https://en.wikipedia.org/wiki/Mishnah" rel="noopener ugc nofollow" target="_blank">Mishnah</a> is one of the core and earliest rabbinic works which serves as the basis for the Talmud.</li><li id="1646" class="ny nz fq oa b go pt oc od gr pu of og oh pv oj ok ol pw on oo op px or os ot pq pr ps bk">The licenses for the texts differ and are detailed in the corresponding JSON files within the repository. The Hebrew texts used in this project are in the public domain. The English translations are from the Mishnah Yomit translation by Dr. Joshua Kulp and are licensed under a CC-BY license.</li></ol></div></div></div><div class="ab cb qa qb qc qd" role="separator"><span class="qe by bm qf qg qh"/><span class="qe by bm qf qg qh"/><span class="qe by bm qf qg"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="a927" class="pw-post-body-paragraph ny nz fq oa b go ou oc od gr ov of og oh ow oj ok ol ox on oo op oy or os ot fj bk"><em class="pl">Shlomo Tannor is an AI/ML engineer at Avanan (A Check Point Company), specializing in leveraging NLP and ML to enhance cloud email security. He holds an MSc in Computer Science with a thesis in NLP and a BSc in Mathematics and Computer Science.</em></p></div></div></div></div>    
</body>
</html>