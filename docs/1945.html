<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Algorithm-Agnostic Model Building with MLflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Algorithm-Agnostic Model Building with MLflow</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://towardsdatascience.com/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=collection_archive---------0-----------------------#2024-08-10">https://towardsdatascience.com/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=collection_archive---------0-----------------------#2024-08-10</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="0c42" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A beginner-friendly step-by-step guide to creating generic ML pipelines using mlflow.pyfunc</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://menawang.medium.com/?source=post_page---byline--b106a5a29535--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Mena Wang, PhD" class="l ep by dd de cx" src="../Images/eac9fa55026f9fc119bc868439ff311b.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*qUfWZCdwnb6Bn7k4cO0O3Q.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--b106a5a29535--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://menawang.medium.com/?source=post_page---byline--b106a5a29535--------------------------------" rel="noopener follow">Mena Wang, PhD</a></p></div></div></div><div class="hz ia l"><div class="ab ib"><div class="ab"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewbox="0 0 16 16"><path fill="#437AFF" d="M15.163 8c0 .65-.459 1.144-.863 1.575-.232.244-.471.5-.563.719s-.086.543-.092.875c-.006.606-.018 1.3-.49 1.781-.47.481-1.15.494-1.744.5-.324.006-.655.013-.857.094s-.465.337-.704.575c-.422.412-.906.881-1.542.881-.637 0-1.12-.469-1.543-.881-.239-.238-.49-.482-.704-.575-.214-.094-.532-.088-.857-.094-.593-.006-1.273-.019-1.744-.5s-.484-1.175-.49-1.781c-.006-.332-.012-.669-.092-.875-.08-.207-.33-.475-.563-.719-.404-.431-.863-.925-.863-1.575s.46-1.144.863-1.575c.233-.244.472-.5.563-.719.092-.219.086-.544.092-.875.006-.606.019-1.3.49-1.781s1.15-.494 1.744-.5c.325-.006.655-.012.857-.094.202-.081.465-.337.704-.575C7.188 1.47 7.671 1 8.308 1s1.12.469 1.542.881c.239.238.49.481.704.575s.533.088.857.094c.594.006 1.273.019 1.745.5.47.481.483 1.175.49 1.781.005.331.011.669.091.875s.33.475.563.719c.404.431.863.925.863 1.575"/><path fill="#fff" d="M7.328 10.5c.195 0 .381.08.519.22.137.141.215.331.216.53 0 .066.026.13.072.177a.24.24 0 0 0 .346 0 .25.25 0 0 0 .071-.177c.001-.199.079-.389.216-.53a.73.73 0 0 1 .519-.22h1.959c.13 0 .254-.053.346-.146a.5.5 0 0 0 .143-.354V6a.5.5 0 0 0-.143-.354.49.49 0 0 0-.346-.146h-1.47c-.324 0-.635.132-.865.366-.23.235-.359.552-.359.884v2.5c0 .066-.025.13-.071.177a.24.24 0 0 1-.346 0 .25.25 0 0 1-.072-.177v-2.5c0-.332-.13-.65-.359-.884A1.21 1.21 0 0 0 6.84 5.5h-1.47a.49.49 0 0 0-.346.146A.5.5 0 0 0 4.88 6v4c0 .133.051.26.143.354a.49.49 0 0 0 .347.146z"/></svg></div></div></div><span class="ic id" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span><p class="bf b hw hx dx"><button class="ie if ah ai aj ak al am an ao ap aq ar ig ih ii" disabled="">Follow</button></p></div></div></span></div></div><div class="l ij"><span class="bf b bg z dx"><div class="ab cn ik il im"><div class="in io ab"><div class="bf b bg z dx ab ip"><span class="iq l ij">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--b106a5a29535--------------------------------" rel="noopener follow"><p class="bf b bg z ir is it iu iv iw ix iy bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ic id" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iz ja l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div><span data-testid="storyPublishDate">Aug 10, 2024</span></div></span></div></span></div></div></div><div class="ab cp jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq"><div class="h k w ea eb q"><div class="kg l"><div class="ab q kh ki"><div class="pw-multi-vote-icon ed iq kj kk kl"><div class=""><div class="km kn ko kp kq kr ks am kt ku kv kl"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kw kx ky kz la lb lc"><p class="bf b dy z dx"><span class="kn">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao km ld le ab q ee lf lg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lh"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jr js jt ju jv jw jx jy jz ka kb kc kd ke kf"><div class="li k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lj an ao ap ig lk ll lm" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ln cn"><div class="l ae"><div class="ab cb"><div class="lo lp lq lr ls lt ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lj an ao ap ig lu lv lg lw lx ly lz ma s mb mc md me mf mg mh u mi mj mk"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lj an ao ap ig lu lv lg lw lx ly lz ma s mb mc md me mf mg mh u mi mj mk"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lj an ao ap ig lu lv lg lw lx ly lz ma s mb mc md me mf mg mh u mi mj mk"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="ab5e" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">One common challenge in MLOps is the hassle of migrating between various algorithms or frameworks. This beginner-friendly article helps you tackle the challenge by leveraging algorithm-agnostic model building using <code class="cx nh ni nj nk b">mlflow.pyfunc</code>.</p><h1 id="a2c4" class="nl nm fq bf nn no np gq nq nr ns gt nt nu nv nw nx ny nz oa ob oc od oe of og bk"><strong class="al">Why Agorithm-Agonostic Model Building?</strong></h1><p id="297f" class="pw-post-body-paragraph ml mm fq mn b go oh mp mq gr oi ms mt mu oj mw mx my ok na nb nc ol ne nf ng fj bk">Consider this scenario: we have an sklearn model currently deployed in production for a particular use case. Later on, we find that a deep learning model performs even better. If the sklearn model was deployed in its native format, transitioning to the deep learning model could be a hassle ü§™ because the two model artifacts are very different.</p><figure class="op oq or os ot ou om on paragraph-image"><div role="button" tabindex="0" class="ov ow ed ox bh oy"><div class="om on oo"><img src="../Images/33a9e7864d65b8a617c6d295f3d2b53a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I20xIXwlgYSKdchh6kDWnQ.png"/></div></div><figcaption class="pa pb pc om on pd pe bf b bg z dx">Image generated by prompting Gemini</figcaption></figure><p id="e307" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">To address such a challenge, the <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model flavor provides a versatile and generic approach to building and deploying machine learning models in Python. üòé</p><p id="aea4" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk"><strong class="mn fr">1. Generic Model Building: </strong>The <code class="cx nh ni nj nk b">pyfunc</code> model flavor offers a uniform way to build models, regardless of the framework or library used for the build.</p><p id="34df" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk"><strong class="mn fr">2. Encapsulation of the ML Pipeline: </strong><code class="cx nh ni nj nk b">pyfunc</code> allows us to encapsulate the model with its pre- and post-processing steps or other custom logic desirable during model consumption.</p><p id="043d" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk"><strong class="mn fr">3. Unified Model Representation: </strong>We can deploy a model, a machine learning pipeline, or any python function using <code class="cx nh ni nj nk b">pyfunc</code> without worrying about the model's underlying format. Such a unified representation simplifies model deployment, redeployment, and downstream scoring.</p></div></div></div><div class="ab cb pf pg ph pi" role="separator"><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="6fcb" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">Sounds interesting? If yes, this article is here to get you started with <code class="cx nh ni nj nk b">mlflow.pyfunc</code>. ü•Ç</p><ul class=""><li id="7b43" class="ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng pn po pp bk">Firstly, let‚Äôs go through a simple toy example of creating <code class="cx nh ni nj nk b">mlflow.pyfunc</code> class.</li><li id="da9a" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng pn po pp bk">Then, we will define a <code class="cx nh ni nj nk b">mlflow.pyfunc</code> class that encapsulates a machine learning pipeline (an estimator plus some preprocessing logic as an example). We will also train, log and load this ML pipeline for inference.</li><li id="e228" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng pn po pp bk">Lastly, let‚Äôs take a deep dive into the encapsulated <code class="cx nh ni nj nk b">mlflow.pyfunc</code> object, explore the rich metadata and artifacts automatically tracked for us by <code class="cx nh ni nj nk b">mlflow</code>, and get a better grasp of the full power that <code class="cx nh ni nj nk b">mlflow.pyfunc</code> offers.</li></ul><p id="438f" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">üîó All code and config are available <a class="af pv" href="https://github.com/MenaWANG/mlflow-demo/blob/main/pyfunc_basic.ipynb" rel="noopener ugc nofollow" target="_blank">on GitHub</a>. üß∞</p><h1 id="8cab" class="nl nm fq bf nn no np gq nq nr ns gt nt nu nv nw nx ny nz oa ob oc od oe of og bk">{pyfunc} Simple Toy Model</h1><p id="69a7" class="pw-post-body-paragraph ml mm fq mn b go oh mp mq gr oi ms mt mu oj mw mx my ok na nb nc ol ne nf ng fj bk">First, let‚Äôs create a simple toy <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model and then use it with the mlflow workflow.</p><ul class=""><li id="245c" class="ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng pn po pp bk">Step 1: Create the model</li><li id="ea3f" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng pn po pp bk">Step 2: Log the model</li><li id="d0bc" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng pn po pp bk">Step 3: Load the logged model to perform the inference</li></ul><pre class="op oq or os ot pw nk px bp py bb bk"><span id="33bc" class="pz nm fq nk b bg qa qb l qc qd"># Step 1: Create a mlflow.pyfunc model<br/>class ToyModel(mlflow.pyfunc.PythonModel):<br/>    """<br/>    ToyModel is a simple example implementation of an MLflow Python model.<br/>    """<br/>    <br/>    def predict(self, context, model_input):<br/>        """<br/>        A basic predict function that takes a model_input list and returns a new list <br/>        where each element is increased by one.<br/><br/>        Parameters:<br/>        - context (Any): An optional context parameter provided by MLflow.<br/>        - model_input (list of int or float): A list of numerical values that the model will use for prediction.<br/><br/>        Returns:<br/>        - list of int or float: A list with each element in model_input is increased by one.<br/>        """<br/>        return [x + 1 for x in model_input]</span></pre><p id="60fe" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">As you can see from the example above, you can create an <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model to implement any customed Python function you see fit for your ML solution, which doesn‚Äôt have to be an off-the-shelf machine learning algorithm.</p><p id="6eee" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">You can then log this model and load it later to perform the inference.</p><pre class="op oq or os ot pw nk px bp py bb bk"><span id="0f1c" class="pz nm fq nk b bg qa qb l qc qd"># Step 2: log this model as an mlflow run<br/>with mlflow.start_run():<br/>    mlflow.pyfunc.log_model(<br/>        artifact_path = "model", <br/>        python_model=ToyModel()<br/>    )<br/>    run_id = mlflow.active_run().info.run_id</span></pre><pre class="qe pw nk px bp py bb bk"><span id="e1db" class="pz nm fq nk b bg qa qb l qc qd"># Step 3: load the logged model to perform inference<br/>model = mlflow.pyfunc.load_model(f"runs:/{run_id}/model")<br/># dummy new data<br/>x_new = [1,2,3]<br/># model inference for the new data<br/>print(model.predict(x_new))</span></pre><pre class="qe pw nk px bp py bb bk"><span id="5c3a" class="pz nm fq nk b bg qa qb l qc qd">[2, 3, 4]</span></pre><h1 id="a626" class="nl nm fq bf nn no np gq nq nr ns gt nt nu nv nw nx ny nz oa ob oc od oe of og bk"><strong class="al">{pyfunc} Encapsulated XGBoost Pipeline</strong></h1><p id="757a" class="pw-post-body-paragraph ml mm fq mn b go oh mp mq gr oi ms mt mu oj mw mx my ok na nb nc ol ne nf ng fj bk">Now, let‚Äôs create an ML pipeline encapsulating an estimator with additional custom logic.</p><p id="af86" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">In the example below, the <code class="cx nh ni nj nk b">XGB_PIPELINE</code> class is a wrapper that integrates the estimator with preprocessing steps, which can be desirable for some MLOps implementations. Leveraging <code class="cx nh ni nj nk b">mlflow.pyfunc</code>, this wrapper is estimator-agnostic and offers a uniform model representation. Specifically,</p><ul class=""><li id="e626" class="ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng pn po pp bk"><code class="cx nh ni nj nk b">fit()</code>: Instead of using XGBoost's native API (<code class="cx nh ni nj nk b">xgboost.train()</code>), this class uses <code class="cx nh ni nj nk b">.fit()</code>, which adheres to sklearn conventions, enabling straightforward integration into sklearn pipelines and ensuring consistency across different estimators.</li><li id="37d2" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng pn po pp bk"><code class="cx nh ni nj nk b">DMatrix()</code>: <code class="cx nh ni nj nk b">DMatrix</code> is a core data structure in XGBoost that optimizes data for training and prediction. In this class, the step to transform a pandas DataFrame into a <code class="cx nh ni nj nk b">DMatrix</code> is wrapped within the class, enabling seamless integration with pandas DataFrames like all other sklearn estimators.</li><li id="9dab" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng pn po pp bk"><code class="cx nh ni nj nk b">predict()</code> : This is the <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model‚Äôs universal inference API. It is consistent for this ML pipeline, for the toy model above, for any machine learning algorithms or custom logic we wrap in an <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model.</li></ul><pre class="op oq or os ot pw nk px bp py bb bk"><span id="185c" class="pz nm fq nk b bg qa qb l qc qd">import json<br/>import xgboost as xgb<br/>import mlflow.pyfunc<br/>from typing import Any, Dict, Union<br/>import pandas as pd<br/><br/><br/>class XGB_PIPELINE(mlflow.pyfunc.PythonModel):<br/>    """<br/>    XGBWithPreprocess is an example implementation of an MLflow Python model with XGBoost.<br/>    """<br/>    <br/>    def __init__(self, params: Dict[str, Union[str, int, float]]):<br/>        """<br/>        Initialize the model with given parameters.<br/><br/>        Parameters:<br/>        - params (Dict[str, Union[str, int, float]]): Parameters for the XGBoost model.<br/>        """<br/>        self.params = params<br/>        self.xgb_model = None<br/>        self.config = None      <br/><br/>    def preprocess_input(self, model_input: pd.DataFrame) -&gt; pd.DataFrame:<br/>        """<br/>        Preprocess the input data.<br/><br/>        Parameters:<br/>        - model_input (pd.DataFrame): The input data to preprocess.<br/><br/>        Returns:<br/>        - pd.DataFrame: The preprocessed input data.<br/>        """<br/>        processed_input = model_input.copy()<br/>        # put any desired preprocessing logic here<br/>        processed_input.drop(processed_input.columns[0], axis=1, inplace=True)<br/><br/>        return processed_input<br/><br/>    def fit(self, X_train: pd.DataFrame, y_train: pd.Series):<br/>        """<br/>        Train the XGBoost model.<br/><br/>        Parameters:<br/>        - X_train (pd.DataFrame): The training input data.<br/>        - y_train (pd.Series): The target values.<br/>        """<br/>        processed_model_input = self.preprocess_input(X_train.copy())<br/>        dtrain = xgb.DMatrix(processed_model_input, label=y_train)<br/>        self.xgb_model = xgb.train(self.params, dtrain)<br/><br/>    def predict(self, context: Any, model_input: pd.DataFrame) -&gt; Any:<br/>        """<br/>        Predict using the trained XGBoost model.<br/><br/>        Parameters:<br/>        - context (Any): An optional context parameter provided by MLflow.<br/>        - model_input (pd.DataFrame): The input data for making predictions.<br/><br/>        Returns:<br/>        - Any: The prediction results.<br/>        """<br/>        processed_model_input = self.preprocess_input(model_input.copy())<br/>        dmatrix = xgb.DMatrix(processed_model_input)<br/>        return self.xgb_model.predict(dmatrix)</span></pre><p id="111c" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">Now, let‚Äôs train and log this model.</p><pre class="op oq or os ot pw nk px bp py bb bk"><span id="9575" class="pz nm fq nk b bg qa qb l qc qd">from sklearn.datasets import make_regression<br/>from sklearn.model_selection import train_test_split<br/>import pandas as pd<br/><br/># Generate synthetic datasets for demo<br/>X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)<br/><br/># train and log the model<br/>with mlflow.start_run(run_name = 'xgb_demo') as run:<br/><br/>    # Create an instance of XGB_PIPELINE<br/>    params = {<br/>        'objective': 'reg:squarederror',  <br/>        'max_depth': 3,  <br/>        'learning_rate': 0.1,<br/>    }<br/>    model = XGB_PIPELINE(params)<br/><br/>    # Fit the model<br/>    model.fit(X_train=pd.DataFrame(X_train), y_train=y_train)<br/><br/>    # Log the model<br/>    model_info = mlflow.pyfunc.log_model(<br/>        artifact_path = 'model',<br/>        python_model = model,<br/>    )<br/><br/>    run_id = mlflow.active_run().info.run_id</span></pre><p id="d86f" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">The model has been logged successfully. ‚úå Ô∏èNow, let‚Äôs load it for inference-making.</p><pre class="op oq or os ot pw nk px bp py bb bk"><span id="a557" class="pz nm fq nk b bg qa qb l qc qd">loaded_model = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)<br/>loaded_model.predict(pd.DataFrame(X_test))</span></pre><pre class="qe pw nk px bp py bb bk"><span id="46de" class="pz nm fq nk b bg qa qb l qc qd">array([ 4.11692047e+00,  7.30551958e+00, -2.36042137e+01, -1.31888123e+02,<br/>       ...</span></pre><h1 id="87e7" class="nl nm fq bf nn no np gq nq nr ns gt nt nu nv nw nx ny nz oa ob oc od oe of og bk"><strong class="al">Deep Dive into the Mlflow.pyfunc Object</strong></h1><p id="64c0" class="pw-post-body-paragraph ml mm fq mn b go oh mp mq gr oi ms mt mu oj mw mx my ok na nb nc ol ne nf ng fj bk">The above process is pretty smooth, isn‚Äôt it? This represents the basic functionality of the <code class="cx nh ni nj nk b">mlflow.pyfunc</code> object. Now, let‚Äôs dive deeper to explore the full power that <code class="cx nh ni nj nk b">mlflow.pyfunc</code> has to offer.</p><p id="b719" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk"><strong class="mn fr"><em class="qf">1. model_info</em></strong></p><p id="fbcc" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">In the example above, the <code class="cx nh ni nj nk b">model_info</code> object returned by <code class="cx nh ni nj nk b">mlflow.pyfunc.log_model()</code> is an instance of <code class="cx nh ni nj nk b">mlflow.models.model.ModelInfo</code> class. It contains metadata and information about the logged model. For example</p><figure class="op oq or os ot ou om on paragraph-image"><div class="om on qg"><img src="../Images/db3200cecb1423a55f817cd3fa348526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*ECsH3CbJHy9M73TwXS04gg.png"/></div><figcaption class="pa pb pc om on pd pe bf b bg z dx">Some attributes of the model_info object</figcaption></figure><p id="8eda" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">Feel free to run <code class="cx nh ni nj nk b">dir(model_info)</code> to explore further or check out <a class="af pv" href="https://mlflow.org/docs/latest/_modules/mlflow/models/model.html" rel="noopener ugc nofollow" target="_blank">the source code</a> for all the attributes defined. The attribute I use the most is <code class="cx nh ni nj nk b">model_uri</code>, which indicates where the logged model can be found within the <code class="cx nh ni nj nk b">mlflow</code> tracking system.</p><p id="24ab" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk"><strong class="mn fr"><em class="qf">2. loaded_model</em></strong></p><p id="5227" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">It is worthwhile clarifying that the <code class="cx nh ni nj nk b">loaded_model</code> is not an instance of the <code class="cx nh ni nj nk b">XGB_PIPELINE</code> class, but rather a wrapper object provided by <code class="cx nh ni nj nk b">mlflow.pyfunc</code> for algorithm-agnostic inference making. As shown below, an error will be returned if you attempt to retrieve attributes of the <code class="cx nh ni nj nk b">XGB_PIPELINE</code> class from the <code class="cx nh ni nj nk b">loaded_model</code>.</p><pre class="op oq or os ot pw nk px bp py bb bk"><span id="df6c" class="pz nm fq nk b bg qa qb l qc qd">print(loaded_model.params)</span></pre><pre class="qe pw nk px bp py bb bk"><span id="2c94" class="pz nm fq nk b bg qa qb l qc qd">AttributeError: 'PyFuncModel' object has no attribute 'params'</span></pre><p id="d749" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk"><strong class="mn fr"><em class="qf">3. unwrapped_model</em></strong></p><p id="d596" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">All right, you may ask, then where is the trained instance of <code class="cx nh ni nj nk b">XGB_PIPELINE</code>? Is it logged and retrievable through <code class="cx nh ni nj nk b">mlflow</code>, too?</p><p id="6779" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">Don‚Äôt worry; it is kept safe for you to unwrap easily, as shown below.</p><pre class="op oq or os ot pw nk px bp py bb bk"><span id="6e1f" class="pz nm fq nk b bg qa qb l qc qd">unwrapped_model = loaded_model.unwrap_python_model()<br/>print(unwrapped_model.params)</span></pre><pre class="qe pw nk px bp py bb bk"><span id="b97c" class="pz nm fq nk b bg qa qb l qc qd">{'objective': 'reg:squarederror', 'max_depth': 3, 'learning_rate': 0.1}</span></pre><p id="131c" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">That‚Äôs how it is done. üòé With the <code class="cx nh ni nj nk b">unwrapped_model</code>, you can access any properties or methods of your custom ML pipeline just like this! I sometimes add handy methods such as <code class="cx nh ni nj nk b">explain_model</code> or <code class="cx nh ni nj nk b">post_processing</code> in the custom pipeline, or include helpful attributes to trace the model training process and offer diagnostics ü§©‚Ä¶ Well, I‚Äôd better stop here and leave those for the following articles. Suffice it to say, you can feel free to custom your ML pipeline for your use case and know that</p><ol class=""><li id="7df7" class="ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng qh po pp bk">You will have access to all these tailor-made methods and attributes for downstream use and</li><li id="a695" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng qh po pp bk">This tailor-made custom model will be wrapped within the uniform <code class="cx nh ni nj nk b">mlflow.pyfunc</code> inference API and hence enjoy a smooth migration to other estimators if necessary.</li></ol><p id="b63a" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk"><strong class="mn fr"><em class="qf">4. Context</em></strong></p><p id="4ddd" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">You may have noticed that there is a <code class="cx nh ni nj nk b">context</code> parameter for the <code class="cx nh ni nj nk b">predict</code> methods in both <code class="cx nh ni nj nk b">mlflow.pyfunc</code> class defined above. But interestingly, this parameter is not required when we make predictions with the loaded model. Why‚ùì</p><pre class="op oq or os ot pw nk px bp py bb bk"><span id="7f62" class="pz nm fq nk b bg qa qb l qc qd">loaded_model = mlflow.pyfunc.load_model(model_uri)<br/># the context parameter is not needed when calling `predict`<br/>loaded_model.predict(model_input)</span></pre><p id="3248" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">This is because the <code class="cx nh ni nj nk b">loaded_model</code> above is a wrapper object provided by <code class="cx nh ni nj nk b">mlflow</code>. If we use the unwrapped model instead, we need to define the context explicitly, as shown below; otherwise, the code will return an error.</p><pre class="op oq or os ot pw nk px bp py bb bk"><span id="1111" class="pz nm fq nk b bg qa qb l qc qd">unwrapped_model = loaded_model.unwrap_python_model()<br/># need to provide context mannually<br/>unwrapped_model.predict(context=None, model_input)</span></pre><p id="c62a" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">So, what is this <code class="cx nh ni nj nk b">context</code>? And what role does it play in the <code class="cx nh ni nj nk b">predict</code> method?</p><p id="8268" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">The <code class="cx nh ni nj nk b">context</code> is a <code class="cx nh ni nj nk b">PythonModelContext</code> object that contains artifacts the<code class="cx nh ni nj nk b">pyfunc</code> model can use when performing inference. It is created implicitly and automatically by the <code class="cx nh ni nj nk b">log_method()</code> method.</p><p id="ee35" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">Navigate to the <code class="cx nh ni nj nk b">mlruns</code> subfolder in your project repo, which is automatically created by <code class="cx nh ni nj nk b">mlflow</code> when you log an <code class="cx nh ni nj nk b">mlflow</code> model. Find the folder named after the model‚Äôs <code class="cx nh ni nj nk b">run_id</code>. Inside, you‚Äôll find the model artifacts automatically logged for you, as shown below.</p><pre class="op oq or os ot pw nk px bp py bb bk"><span id="a819" class="pz nm fq nk b bg qa qb l qc qd"># get run_id of a loaded model<br/>print(loaded_model.metadata.run_id)</span></pre><pre class="qe pw nk px bp py bb bk"><span id="c73f" class="pz nm fq nk b bg qa qb l qc qd">38a617d0f30645e8ae95eea4642a03c2</span></pre><figure class="op oq or os ot ou om on paragraph-image"><div class="om on qi"><img src="../Images/19ac0e4424ede80aedef7fde2314054d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*OrTyyad2ZrgVXYWq0BV2lg.png"/></div><figcaption class="pa pb pc om on pd pe bf b bg z dx">artifacts folder in a logged `mlflow.pyfunc` model</figcaption></figure><p id="49f7" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">Pretty neat, isn‚Äôt it?üòÅ Feel free to explore these artifacts at your leisure; below are the screenshots of the <code class="cx nh ni nj nk b">requirements</code> and <code class="cx nh ni nj nk b">MLmodel</code> file from the folder FYR.</p><p id="bd00" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">The <code class="cx nh ni nj nk b">requiarements</code> below specifies the versions of dependencies required to recreate the environment for running the model.</p><figure class="op oq or os ot ou om on paragraph-image"><div role="button" tabindex="0" class="ov ow ed ox bh oy"><div class="om on qj"><img src="../Images/60ec4a56daa108ee438d8ae822f0220c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PFrPFP_ROpdYjaI1uEyrPw.png"/></div></div><figcaption class="pa pb pc om on pd pe bf b bg z dx">The `requirements.txt` file in the artifacts folder</figcaption></figure><p id="8d6d" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">The <code class="cx nh ni nj nk b">MLmodel</code> doc below defines the metadata and configuration necessary to load and serve the model in YAML format.</p><figure class="op oq or os ot ou om on paragraph-image"><div role="button" tabindex="0" class="ov ow ed ox bh oy"><div class="om on qk"><img src="../Images/7e4d7a6e8cc4576ae6e3e756c44c8ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xqkplifayAC6u-EE9K16LA.png"/></div></div><figcaption class="pa pb pc om on pd pe bf b bg z dx">The `MLmodel` file in the artifacts folder</figcaption></figure></div></div></div><div class="ab cb pf pg ph pi" role="separator"><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="80f9" class="nl nm fq bf nn no ql gq nq nr qm gt nt nu qn nw nx ny qo oa ob oc qp oe of og bk"><strong class="al">Conclusion</strong></h1><p id="7ac8" class="pw-post-body-paragraph ml mm fq mn b go oh mp mq gr oi ms mt mu oj mw mx my ok na nb nc ol ne nf ng fj bk">There you have it, the <code class="cx nh ni nj nk b">mlflow.pyfunc</code> approach to model building. It is a lot of information, so let‚Äôs recap</p><ol class=""><li id="7e0f" class="ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng qh po pp bk"><code class="cx nh ni nj nk b">mlflow.pyfunc</code> offers a unified model representation unaffected by the underlying framework or libraries used to build the model.</li><li id="ed4f" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng qh po pp bk">We can even encapsulate rich custom logic into a <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model to tailor each use case while keeping the inference API consistent and unified.</li><li id="1a60" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng qh po pp bk">The underlying model can be unwrapped from the loaded <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model, allowing us to leverage more custom methods/attributes tailored for each use case.</li><li id="7c67" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng qh po pp bk">An <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model object is logged with rich metadata and artifacts that are automatically tracked by <code class="cx nh ni nj nk b">mlflow</code>.</li><li id="04f0" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng qh po pp bk">This unified <code class="cx nh ni nj nk b">mlflow.pyfunc</code> model representation can streamline the process of experimenting and migrating between different algorithms to achieve optimal performance (more on this in the following articles, pls see below)</li></ol><h1 id="cc42" class="nl nm fq bf nn no np gq nq nr ns gt nt nu nv nw nx ny nz oa ob oc od oe of og bk"><strong class="al">Next Steps</strong></h1><p id="7fa8" class="pw-post-body-paragraph ml mm fq mn b go oh mp mq gr oi ms mt mu oj mw mx my ok na nb nc ol ne nf ng fj bk">Now we have got the basics sorted, in the following articles, we can continue to discuss more advanced usage of <code class="cx nh ni nj nk b">mlflow.pyfunc</code>. üòé Below are some topics from the top of my head; feel free to leave a comment and let me know what you would like to see. ü•∞</p><ol class=""><li id="92c6" class="ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng qh po pp bk">Leverage the uniform API to experiment with various algorithms and identify the optimal solution for a use case.</li><li id="4829" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng qh po pp bk">Hyperparameter tuning with <code class="cx nh ni nj nk b">mlflow.pyfunc</code> custom models.</li><li id="6d3b" class="ml mm fq mn b go pq mp mq gr pr ms mt mu ps mw mx my pt na nb nc pu ne nf ng qh po pp bk">Encapsulating custom logic into an <code class="cx nh ni nj nk b">mlflow.pyfunc</code> ML pipeline to tailor model consumption and diagnostics.</li></ol><p id="32e3" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">If you enjoyed reading this article, follow me on <a class="af pv" href="https://menawang.medium.com/" rel="noopener">Medium</a>. üòÅ</p><p id="c3ef" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">üíº<a class="af pv" href="https://www.linkedin.com/in/mena-ning-wang/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> | üò∫<a class="af pv" href="https://github.com/MenaWANG" rel="noopener ugc nofollow" target="_blank">GitHub</a> | üïäÔ∏è<a class="af pv" href="https://x.com/mena_wang" rel="noopener ugc nofollow" target="_blank">Twitter/X</a></p></div></div></div><div class="ab cb pf pg ph pi" role="separator"><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="e9a5" class="pw-post-body-paragraph ml mm fq mn b go mo mp mq gr mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng fj bk">Unless otherwise noted, all images are by the author.</p></div></div></div></div>    
</body>
</html>