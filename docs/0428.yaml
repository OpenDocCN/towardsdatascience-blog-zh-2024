- en: The Needle In a Haystack Test
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大海捞针测试
- en: 原文：[https://towardsdatascience.com/the-needle-in-a-haystack-test-a94974c1ad38?source=collection_archive---------1-----------------------#2024-02-15](https://towardsdatascience.com/the-needle-in-a-haystack-test-a94974c1ad38?source=collection_archive---------1-----------------------#2024-02-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-needle-in-a-haystack-test-a94974c1ad38?source=collection_archive---------1-----------------------#2024-02-15](https://towardsdatascience.com/the-needle-in-a-haystack-test-a94974c1ad38?source=collection_archive---------1-----------------------#2024-02-15)
- en: '![](../Images/5d3dd87eaedfaa9810c9a5f571ce002f.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d3dd87eaedfaa9810c9a5f571ce002f.png)'
- en: Image created by author using Dall-E 3
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用 Dall-E 3 创建
- en: Evaluating the performance of RAG systems
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估 RAG 系统的表现
- en: '[](https://aparnadhinak.medium.com/?source=post_page---byline--a94974c1ad38--------------------------------)[![Aparna
    Dhinakaran](../Images/e431ee69563ecb27c86f3428ba53574c.png)](https://aparnadhinak.medium.com/?source=post_page---byline--a94974c1ad38--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a94974c1ad38--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a94974c1ad38--------------------------------)
    [Aparna Dhinakaran](https://aparnadhinak.medium.com/?source=post_page---byline--a94974c1ad38--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://aparnadhinak.medium.com/?source=post_page---byline--a94974c1ad38--------------------------------)[![Aparna
    Dhinakaran](../Images/e431ee69563ecb27c86f3428ba53574c.png)](https://aparnadhinak.medium.com/?source=post_page---byline--a94974c1ad38--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a94974c1ad38--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a94974c1ad38--------------------------------)
    [Aparna Dhinakaran](https://aparnadhinak.medium.com/?source=post_page---byline--a94974c1ad38--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a94974c1ad38--------------------------------)
    ·9 min read·Feb 15, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a94974c1ad38--------------------------------)
    ·阅读时间 9 分钟 ·2024年2月15日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*My thanks to* [*Greg Kamradt*](https://twitter.com/GregKamradt) *and* [*Evan
    Jolley*](https://www.linkedin.com/in/evanjolley/) *for their contributions to
    this piece*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢* [*Greg Kamradt*](https://twitter.com/GregKamradt) *和* [*Evan Jolley*](https://www.linkedin.com/in/evanjolley/)
    *对本文的贡献*'
- en: Retrieval-augmented generation (RAG) underpins many of the LLM applications
    in the real world today, from companies generating headlines to solo developers
    solving problems for small businesses.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）是当前许多大型语言模型（LLM）应用的基础，从公司生成标题到独立开发者为小型企业解决问题。
- en: '[RAG evaluation](https://arize.com/blog-course/rag-evaluation/), therefore,
    has become a critical part in the development and deployment of these systems.
    One new innovative approach to this challenge is the “Needle in a Haystack’’ test,
    first outlined by [Greg Kamradt](https://twitter.com/GregKamradt) in [this X post](https://twitter.com/GregKamradt/status/1722386725635580292?lang=en)
    and discussed in detail on his YouTube [here](https://www.youtube.com/watch?v=KwRRuiCCdmc).
    This test is designed to evaluate the performance of RAG systems across different
    sizes of context. It works by embedding specific, targeted information (the “needle”)
    within a larger, more complex body of text (the “haystack”). The goal is to assess
    an LLM’s ability to identify and utilize this specific piece of information amidst
    a vast amount of data.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[RAG 评估](https://arize.com/blog-course/rag-evaluation/)，因此，已成为这些系统开发和部署中的关键部分。应对这一挑战的一种新创新方法是“大海捞针”测试，最早由
    [Greg Kamradt](https://twitter.com/GregKamradt) 在 [这篇 X 帖子](https://twitter.com/GregKamradt/status/1722386725635580292?lang=en)
    中提出，并在他的 YouTube 频道 [这里](https://www.youtube.com/watch?v=KwRRuiCCdmc) 进行了详细讨论。该测试旨在评估
    RAG 系统在不同上下文规模下的表现。其工作原理是在更大、更复杂的文本（“干草堆”）中嵌入特定的目标信息（“针”）。目标是评估大型语言模型（LLM）在海量数据中识别和利用这段特定信息的能力。'
- en: Often in RAG systems, the context window is absolutely overflowing with information.
    Large pieces of context returned from a vector database are cluttered together
    with instructions for the language model, templating, and anything else that might
    exist in the prompt. The Needle in a Haystack evaluation tests the capabilities
    of an LLM to pinpoint specifics in amongst this mess. Your RAG system might do
    a stellar job of retrieving the most relevant context, but what use is this if
    the granular specifics within are overlooked?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RAG 系统中，上下文窗口通常充斥着大量信息。来自向量数据库的大块上下文与语言模型的指令、模板以及提示中可能存在的任何其他内容混杂在一起。“干草堆中的针”评估测试了
    LLM 在这片混乱中找出具体信息的能力。你的 RAG 系统可能在检索最相关的上下文方面表现出色，但如果其中的细节被忽略了，那又有什么用呢？
- en: We ran this test multiple times across several major language models. Let’s
    take a closer look at the process and overall results.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们多次在几种主要的语言模型上进行了此测试。让我们更仔细地看看这个过程和总体结果。
- en: Takeaways
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要结论
- en: Not all LLMs are the same. Models are trained with different objectives and
    requirements in mind. For example, Anthropic’s Claude is known for being a slightly
    wordier model, which often stems from its objective to not make unsubstantiated
    claims.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非所有 LLM 都相同。不同的模型在训练时有不同的目标和要求。例如，Anthropic 的 Claude 因稍显冗长而闻名，这通常源于它的目标是避免做出没有依据的声明。
- en: '**Minute differences in prompts can lead to drastically different outcomes**
    across models due to this fact. Some LLMs need more tailored prompting to perform
    well at specific tasks.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示中的微小差异可能会导致模型之间截然不同的结果**，这是因为这个事实。有些 LLM 需要更量身定制的提示才能在特定任务上表现良好。'
- en: When building on top of LLMs — especially when those models are connected to
    private data — it is necessary to **evaluate retrieval and model performance throughout
    development and deployment**. Seemingly insignificant differences can lead to
    incredibly large differences in performance.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在构建 LLM 基础上时——尤其是当这些模型与私有数据连接时——必须**在开发和部署过程中评估检索和模型的性能**。看似微不足道的差异可能会导致性能上的巨大差异。
- en: Understanding the Needle In a Haystack Test
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解“干草堆中的针”测试
- en: 'The Needle in a Haystack test was first used to evaluate the recall of two
    popular LLMs, OpenAI’s ChatGPT-4 and Anthropic’s Claude 2.1\. An out of place
    statement, “The best thing to do in San Francisco is eat a sandwich and sit in
    Dolores Park on a sunny day,” was placed at varying depths within snippets of
    varying lengths taken from [essays](https://paulgraham.com/articles.html) by Paul
    Graham, similar to this:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: “干草堆中的针”测试首次用于评估两款流行的语言模型（LLM），OpenAI 的 ChatGPT-4 和 Anthropic 的 Claude 2.1。一个不合时宜的语句：“在旧金山最好的事情就是吃个三明治，坐在阳光明媚的日子里去多洛雷斯公园，”被放置在从[Paul
    Graham 的文章](https://paulgraham.com/articles.html)中提取的不同长度片段中的不同深度位置，类似如下：
- en: '![](../Images/fda17ae9412103a6f11920bd500ff0e6.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fda17ae9412103a6f11920bd500ff0e6.png)'
- en: '*Figure 1: About 120 tokens and 50% depth* | Image by [Greg Kamradt](https://twitter.com/GregKamradt)
    on [X](https://twitter.com/GregKamradt/status/1722386725635580292), used here
    with author’s permission'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1：大约 120 个 token 和 50% 深度* | 图片由[Greg Kamradt](https://twitter.com/GregKamradt)提供，发表于[X](https://twitter.com/GregKamradt/status/1722386725635580292)，经作者许可使用'
- en: 'The models were then prompted to answer what the best thing to do in San Francisco
    was, only using the provided context. This was then repeated for different depths
    between 0% (top of document) and 100% (bottom of document) and different context
    lengths between 1K tokens and the token limit of each model (128k for GPT-4 and
    200k for Claude 2.1). The below graphs document the performance of these two models:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，模型被提示回答在旧金山做什么是最好的，仅使用提供的上下文。这个测试在不同的深度（从 0%（文档顶部）到 100%（文档底部））和不同的上下文长度（从
    1K token 到每个模型的 token 限制（GPT-4 为 128k，Claude 2.1 为 200k））之间反复进行。下面的图表记录了这两款模型的表现：
- en: '![](../Images/6016bcb61c2d84a0d250f1bd99bc4857.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6016bcb61c2d84a0d250f1bd99bc4857.png)'
- en: 'Figure 2: ChatGPT-4’s performance | Image by [Greg Kamradt](https://twitter.com/GregKamradt)
    on [X](https://twitter.com/GregKamradt/status/1722386725635580292), used here
    with author’s permission'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：ChatGPT-4 的表现 | 图片由[Greg Kamradt](https://twitter.com/GregKamradt)提供，发表于[X](https://twitter.com/GregKamradt/status/1722386725635580292)，经作者许可使用
- en: As you can see, ChatGPT’s performance begins to decline at <64k tokens and sharply
    falls at 100k and over. Interestingly, if the “needle” is positioned towards the
    beginning of the context, the model tends to overlook or “forget” it — whereas
    if it’s placed towards the end or as the very first sentence, the model’s performance
    remains solid.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，ChatGPT的表现开始在<64k token时下降，并在100k及以上时急剧下降。有趣的是，如果“针”被放置在上下文的前面，模型往往会忽视或“忘记”它——而如果将其放在末尾或作为第一句话，模型的表现则保持稳定。
- en: '![](../Images/32ac9bfcaf7e2b20842a4d4b61596967.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32ac9bfcaf7e2b20842a4d4b61596967.png)'
- en: 'Figure 3: Claude 2.1’s performance | | Image by [Greg Kamradt](https://twitter.com/GregKamradt)
    on [X](https://twitter.com/GregKamradt/status/1722386725635580292), used here
    with author’s permission'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：Claude 2.1的表现 | | 图片由[Greg Kamradt](https://twitter.com/GregKamradt)提供，发布在[X](https://twitter.com/GregKamradt/status/1722386725635580292)，在此感谢作者授权使用
- en: For Claude, initial testing did not go as smoothly, finishing with an overall
    score of 27% retrieval accuracy. A similar phenomenon was observed with performance
    declining as context length increased, performance generally increasing as the
    needle was hidden closer to the bottom of the document, and 100% accuracy retrieval
    if the needle was the first sentence of the context.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Claude，初始测试并不顺利，最终的检索准确率为27%。随着上下文长度增加，表现普遍下降，且当针被隐藏在文档底部时，表现有所提升。如果针是上下文中的第一句话，检索准确率则达到100%。
- en: Anthropic’s Response
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Anthropic的回应
- en: In response to these findings, Anthropic published an [article](https://www.anthropic.com/news/claude-2-1-prompting)
    detailing their re-run of this test with a few key changes.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这些发现，Anthropic发布了一篇[文章](https://www.anthropic.com/news/claude-2-1-prompting)，详细说明了他们在进行测试时所做的一些关键调整。
- en: First, they changed the needle to more closely mirror the topic of the haystack.
    Claude 2.1 was trained to “not [answer] a question based on a document if it doesn’t
    contain enough information to justify that answer.” Thus, Claude may well have
    correctly identified eating a sandwich in Dolores Park as the best thing to do
    in San Francisco. However, along with an essay about doing great work, this small
    piece of information may have appeared unsubstantiated. This could have led to
    a verbose response explaining that Claude cannot confirm that eating a sandwich
    is the best thing to do in San Francisco or an omission of the detail entirely.
    When re-running the experiments, researchers at Anthropic found that changing
    the needle to a small detail originally mentioned in the essay led to significantly
    increased outcomes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，他们将针的内容更改为与干草堆的主题更为贴近。Claude 2.1被训练成“如果文档中没有足够的信息支持该回答，就不[回答]问题”。因此，Claude可能确实正确地识别出在Dolores公园吃三明治是旧金山最好的活动。然而，若它与关于做伟大工作的文章一起出现，这个小细节可能显得没有充分证据。这可能导致模型给出冗长的回答，解释Claude无法确认在旧金山吃三明治是最好的事情，或者完全省略这一细节。重新进行实验时，Anthropic的研究人员发现，将针改为原文中提到的小细节后，结果显著提升。
- en: Second, a small edit was made to the prompt template used to query the model.
    A single line — *here is the most relevant sentence in the context* — was added
    to the end of the template, directing the model to simply return the most relevant
    sentence provided in the context. Similar to the first, this change allows us
    to circumvent the model’s propensity to avoid unsubstantiated claims by directing
    it to simply return a sentence rather than make an assertion.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，对查询模型使用的提示模板做了一些小编辑。在模板的末尾增加了一行——*这里是上下文中最相关的句子*——指示模型仅返回上下文中提供的最相关句子。与之前的调整类似，这一改变使我们能够绕过模型避免不充分声明的倾向，直接指示其返回句子，而非作出断言。
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'These changes led to a significant jump in Claude’s overall retrieval accuracy:
    from 27% to 98%! Finding this initial research fascinating, we decided to run
    our own set of experiments using the Needle in a Haystack test.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变化导致Claude的整体检索准确率显著提高：从27%跃升至98%! 我们对这一初步研究感到非常有趣，于是决定通过“干草堆中的针”测试进行一系列实验。
- en: Further Experiments
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步实验
- en: 'In conducting a new series of tests, we implemented several modifications to
    the original experiments. The needle we used was a random number that changed
    each iteration, eliminating the possibility of caching. Additionally, we used
    our open source Phoenix evals [library](https://docs.arize.com/phoenix/llm-evals/running-pre-tested-evals)
    (full disclosure: I lead the team that built Phoenix) to reduce the testing time
    and use rails to search directly for the random number in the output, cutting
    through wordiness that would decrease a retrieval score. Finally, we considered
    the negative case where the system fails to retrieve the results, marking it as
    unanswerable. We ran a separate test for this negative case to assess how well
    the system recognizes when it can’t retrieve the data. These modifications allowed
    us to conduct a more rigorous and comprehensive evaluation.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行一系列新测试时，我们对原始实验进行了若干修改。我们使用的针是一个随机数，每次迭代都会变化，从而消除了缓存的可能性。此外，我们使用了我们的开源 Phoenix
    评估 [库](https://docs.arize.com/phoenix/llm-evals/running-pre-tested-evals)（完全公开：我是构建
    Phoenix 团队的负责人）来缩短测试时间，并使用 rails 直接在输出中搜索随机数，从而避免了冗长的内容，防止降低检索得分。最后，我们考虑了系统未能检索结果的负面情况，并将其标记为无法回答。我们为这种负面情况运行了单独的测试，以评估系统在无法检索数据时的识别能力。这些修改使我们能够进行更严格和全面的评估。
- en: 'The updated tests were run across several different configurations using four
    different large language models: ChatGPT-4, Claude 2.1 (with and without the aforementioned
    change to the prompt that Anthropic suggested), and Mistral AI’s [Mixtral-8X7B](https://arize.com/blog/mistral-ai)-v0.1
    and 7B Instruct. Given that small nuances in prompting can lead to vastly different
    results across models, we used several prompt templates in the attempt to compare
    these models performing at their best. The simple template we used for ChatGPT
    and Mixtral was as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的测试在四种不同的大型语言模型配置上运行：ChatGPT-4、Claude 2.1（有和没有 Anthropic 建议的提示修改）以及 Mistral
    AI 的 [Mixtral-8X7B](https://arize.com/blog/mistral-ai)-v0.1 和 7B Instruct。考虑到提示的小细节差异可能导致模型之间结果的巨大差异，我们使用了几个提示模板，力图比较这些模型在最佳表现下的表现。我们为
    ChatGPT 和 Mixtral 使用的简单模板如下：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For Claude, we tested both previously discussed templates.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Claude，我们测试了前面讨论的两种模板。
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: All code run to complete these tests can be found in [this GitHub repository](https://github.com/Arize-ai/LLMTest_NeedleInAHaystack).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些测试所运行的所有代码可以在 [此 GitHub 仓库](https://github.com/Arize-ai/LLMTest_NeedleInAHaystack)中找到。
- en: Results
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: '![](../Images/3eddc04a8685a9a9df55ec5fed5f02c9.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3eddc04a8685a9a9df55ec5fed5f02c9.png)'
- en: 'Figure 7: Comparison of GPT-4 results between the initial research (Run #1)
    and our testing (Run #2) | Image by author'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7：GPT-4 在初始研究（Run #1）和我们的测试（Run #2）之间的对比 | 图像由作者提供'
- en: '![](../Images/ed7e0c7a1308960520963cbb485fa689.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed7e0c7a1308960520963cbb485fa689.png)'
- en: 'Figure 8: Comparison of Claude 2.1 (without prompting guidance) results between
    Run #1 and Run #2 | Image by author'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8：Claude 2.1（无提示指导）在 Run #1 和 Run #2 之间的对比 | 图像由作者提供'
- en: 'Our results for ChatGPT and Claude (without prompting guidance) did not stray
    far from Mr. Kamradt’s findings, and the generated graphs appear relatively similar:
    the upper right (long context, needle near the beginning of the context) is where
    LLM information retrieval sufferers.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对于 ChatGPT 和 Claude（无提示指导）的结果与 Kamradt 先生的研究结果相差不大，生成的图表也相对相似：右上方（长上下文，针接近上下文开头）是
    LLM 信息检索的痛点所在。
- en: '![](../Images/1c1a96ba84a13180a3a67282298894c6.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c1a96ba84a13180a3a67282298894c6.png)'
- en: 'Figure 9: Comparison of Claude 2.1 results with and without prompting guidance'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：Claude 2.1 结果与是否使用提示指导的对比
- en: Although we were not able to replicate Anthropic’s results of 98% retrieval
    accuracy for Claude 2.1 with prompting guidance, we did see a significant decrease
    in total misses when the prompt was updated (from 165 to 74). This jump was achieved
    by simply adding a 10 word instruction to the end of the existing prompt, highlighting
    that small differences in prompts can have drastically different outcomes for
    LLMs.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们未能复制 Anthropic 所报告的 Claude 2.1 在提示指导下 98% 检索准确率的结果，但我们确实看到，在更新提示后，总漏检数大幅下降（从
    165 降至 74）。这个变化是通过简单地在现有提示的末尾添加 10 个字的指令实现的，突显了提示中的小差异如何对 LLM 的结果产生巨大影响。
- en: '![](../Images/5871e33962023634315d861adec2a6de.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5871e33962023634315d861adec2a6de.png)'
- en: 'Figure 10: Mixtral results | Image by author'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：Mixtral 结果 | 图像由作者提供
- en: Last but certainly not least, it is interesting to see just how well Mixtral
    performed at this task despite these being by far the smallest models tested.
    The Mixture of Experts (MOEs) model was far better than 7B-Instruct, and we are
    finding that MOEs do much better for retrieval evaluations.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但绝对不容忽视的是，尽管Mixtral是迄今为止测试中最小的模型，但它在这项任务中的表现令人惊讶。混合专家（MOE）模型远远优于7B-Instruct，我们发现MOE在检索评估中表现得更好。
- en: Conclusion
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The Needle in a Haystack test is a clever way to quantify an LLM’s ability to
    parse context to find needed information. [Our research](https://arize.com/blog-course/the-needle-in-a-haystack-test-evaluating-the-performance-of-llm-rag-systems/)
    concluded with a few main takeaways. First, ChatGPT-4 is the industry’s current
    leader in this arena along with many other evaluations that we and others have
    carried out. Second, at first Claude 2.1 seemed to underperform this test, but
    with tweaks to the prompt structure the model showed significant improvement.
    Claude is a bit wordier than some other models, and taking extra care to direct
    it can go a long way in terms of results. Finally, Mixtral MOE greatly outperformed
    our expectations, and we are excited to see Mixtral models continually overperform
    expectations.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: “干草堆中的针”测试是一种巧妙的方法，用于量化大型语言模型（LLM）解析上下文以寻找所需信息的能力。[我们的研究](https://arize.com/blog-course/the-needle-in-a-haystack-test-evaluating-the-performance-of-llm-rag-systems/)得出了几条主要结论。首先，ChatGPT-4在这一领域是当前行业的领导者，这一点得到了我们和其他人进行的多项评估的验证。其次，最初Claude
    2.1在这一测试中似乎表现不佳，但通过调整提示结构，模型表现出了显著的改进。Claude比其他一些模型更加冗长，因此更加注意如何引导它会在结果上取得更好的效果。最后，Mixtral
    MOE大大超出了我们的预期，我们对Mixtral模型不断超越预期的表现感到兴奋。
