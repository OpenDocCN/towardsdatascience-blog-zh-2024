- en: Optimizing Small Language Models on a Free T4 GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/optimizing-small-language-models-on-a-free-t4-gpu-008c37700d57?source=collection_archive---------7-----------------------#2024-01-30](https://towardsdatascience.com/optimizing-small-language-models-on-a-free-t4-gpu-008c37700d57?source=collection_archive---------7-----------------------#2024-01-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Comprehensive Guide to Fine-Tuning Phi-2 using Direct Preference Optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@yanli.liu?source=post_page---byline--008c37700d57--------------------------------)[![Yanli
    Liu](../Images/31342655ab635eb38e3ce501235f1b89.png)](https://medium.com/@yanli.liu?source=post_page---byline--008c37700d57--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--008c37700d57--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--008c37700d57--------------------------------)
    [Yanli Liu](https://medium.com/@yanli.liu?source=post_page---byline--008c37700d57--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--008c37700d57--------------------------------)
    ·11 min read·Jan 30, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/658323d7ef569529110ababc07d7f772.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Donald Wu](https://unsplash.com/@donaldwuid?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: “Small” Language Models (LLMs) are rapidly becoming a game-changer in the field
    of artificial intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the traditional LLMs which require significant computational resources,
    these models are much smaller and more efficient. While their performance would
    be that of the larger ones, they can easily operate on standard devices such as
    laptops, and even go to the edge. This also means that they can be easily customized
    and integrated for use on your data set.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will first explain the basics and inner workings of the model
    fine-tuning and alignment processes. Then, I’ll guide you through the process
    of preference fine-tuning Phi 2, a small LLM with 2 billion parameters, using
    a novel approach called Direct Preference Optimization (DPO).
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to the small size of the model and optimization techniques such as quantization
    and QLoRA, we’ll be able to perform this process through Google Colab using the
    free T4 GPU! This requires some adaptation of the settings and hyperparameters
    used by Hugging Face to train its Zephyr 7B model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table of Contents:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Why We Need Fine-Tuning**…'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
