# 发现Llama模型中每个神经元的作用

> 原文：[https://towardsdatascience.com/-0927524e4807?source=collection_archive---------6-----------------------#2024-10-25](https://towardsdatascience.com/-0927524e4807?source=collection_archive---------6-----------------------#2024-10-25)

## Transluce的新工具正在改变AI透明度的游戏规则——一个测试案例和一些思考材料

[](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)[![Ben Hagag](../Images/a06fa102dfbe84afc6da846c622265a3.png)](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------) [Ben Hagag](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------) ·7分钟阅读·2024年10月25日

--

![](../Images/a37c05472f6079eaec9558314ca0054d.png)

图片由作者提供——拍下了使用新工具的瞬间！

[Transluce](https://transluce.org/)，一个具有启发性使命的非营利研究实验室，刚刚发布了一个引人入胜的工具，提供了LLM中神经元行为的洞察。或者用他们自己的话来说：

> 当AI系统的行为出乎意料时，我们希望了解“思考过程”，以解释为何会发生这种行为。这让我们能够预测并修复AI模型中的问题，揭示隐藏的知识，揭露学到的偏见和虚假的关联。

为了实现他们的使命，他们推出了一个可观察性界面，你可以在其中输入自己的提示语，获取回应，并查看哪些神经元被激活。你可以进一步探索这些激活的神经元及其对模型输出的归因，所有这些都得益于他们通过创新方法自动生成高质量的神经元描述。

如果你想测试这个工具，可以[点击这里](https://monitor.transluce.org/dashboard/chat)。他们还提供了一些有用的教程。在本文中，我将尝试提供另一个用例，并分享我自己的经验。

你可能需要了解很多内容（具体取决于你的背景），但我将重点介绍两个关键特性：激活值和归因。

> **激活值**衡量的是神经元的（归一化）激活值。Llama使用门控MLP，这意味着激活值可以是正数也可以是负数。我们通过神经元在大规模数据集上的10–5分位数值进行归一化。
> 
> ***归因*** *衡量神经元对模型输出的影响程度。归因必须基于特定的输出标记，并等于该输出标记概率相对于神经元激活的梯度，乘以神经元的激活值。归因值没有标准化，以绝对值的形式报告。*

利用这两个特征，你可以探索模型的行为、神经元的行为，甚至注意到神经元行为现象的模式（或者他们称之为“聚类”）。

如果模型输出不是你期望的，或者模型得出了错误的结果，该工具允许你通过加强或抑制与概念相关的神经元来引导并“修复”问题（有许多出色的工作讲解如何根据概念进行引导 —— 其中之一是[这篇](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d066d21c619d0a78c5b557fa3291a8f4-Abstract-Conference.html)出色的工作）。

所以，出于好奇，我用我自己的提示进行了测试。

我选择了一个大多数今天的模型无法解决的简单逻辑问题。

问题：“𝗔𝗹𝗶𝗰𝗲 有 4 个兄弟和 2 个姐妹。爱丽丝的兄弟有多少个姐妹？”

![](../Images/6c41be48fd76516494d0442bce1e91b0.png)

主页。图片来自[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)

**瞧，成功了……**

![](../Images/0d39acc9f66ced5a61b6a8b549963162.png)

Llama 做错了。图片来自[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)

**或者没有。**

在左侧，你可以看到提示和输出。在右侧，你可以看到“激活”最多的神经元，并观察这些神经元聚集的主要簇。

如果你将鼠标悬停在左侧的标记上，你可以看到最高的概率。如果你点击其中一个标记，你可以找到哪些神经元参与了预测该标记。

![](../Images/1d67a52b25dad4a1afc90411715c2468.png)

将鼠标悬停在“in”上。我们可以看到最高概率的标记。图片来自[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)

**正如你所看到的，逻辑和答案都是错误的。**

“因为爱丽丝有 4 个兄弟，所以我们需要找出他们共有多少个姐妹” >>> 哎呀！你已经知道答案了。

当然，如果爱丽丝有两个姐妹（这是输入中给定的），**这并不意味着爱丽丝的兄弟有 2 个姐妹 :(**

所以，让我们试着修复这个问题。在检查神经元之后，我注意到“多样性”概念过于活跃（也许它对爱丽丝的身份感到困惑？）。因此，我尝试调整这些神经元。

![](../Images/b7a1954b87ef3876f4e203a9c5965741.png)

引导窗口。图片来自[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)

我抑制了与此概念相关的神经元，并重新尝试：

![](../Images/28c482a5f7e57c723dc472f51b631904.png)

调整后的模型在引导后。图片来自[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)

如你所见，它仍然输出了错误的答案。但如果仔细观察输出，逻辑已经有所变化，看起来好多了——它捕捉到我们需要“转变”到“其中一个兄弟的视角”。而且，它也理解了爱丽丝是一个姐妹（终于！）。

最终答案仍然不正确。

我决定加强“性别角色”这一概念，认为这有助于模型更好地理解问题中兄妹的角色，同时保持它对爱丽丝与她兄妹关系的理解。

![](../Images/a3da0f27dc4528db009dc4e99ebd31c3.png)

另一个调整。图片来自[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)

好吧，答案仍然不正确，但似乎推理过程略有改善。模型表示“提到的是爱丽丝的两个姐妹”。句子的前半部分表现出一定的理解（是的，这部分也在输入中。并且不，我并不是在争论模型或任何模型能否真正理解——这是另一个讨论的话题），即爱丽丝有两个姐妹。它也依然认知到爱丽丝自己是一个姐妹（“…这个兄弟有2个姐妹——爱丽丝和另一个姐妹…”）。但答案还是错的。真是差一点……

现在我们接近正确答案了，我注意到一个无关的概念（“化学化合物与反应”）影响了“2”这个符号（左侧以橙色高亮显示）。我不确定为什么这个概念会有这么大的影响，但我决定它与问题无关，于是将其抑制了。

结果如何？

![](../Images/10e6ad6d150d44a9cd1c9cb98925e0d2.png)

最终结果。图片来自[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)

成功了！！（差不多）

如上所示，它终于得到了正确的答案。

但是……推理过程如何呢？

嗯……

![](../Images/f30bd90c65a2c7d35c8e06db1026ad6f.png)

最终输出。图片来自[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)

它跟随了一种奇怪的逻辑过程，带有一些角色扮演上的混乱，但最终还是得出了正确的答案（如果你能解释这个过程，请分享）。

所以，在一些试错后，我几乎成功了。在调整了与性别和化学化合物相关的神经元后，模型给出了正确答案，但推理过程还不够完善。我不确定，也许通过更多的微调和调整（或许更好的概念和神经元选择），我能够同时得到正确的答案和正确的逻辑。我挑战你试试看。

这仍然是实验性的，我没有使用任何系统化的方法，但说实话，我很受震撼，认为这非常有前景。为什么？因为能够观察并获取每个神经元的描述，理解（即使是部分理解）它们的影响，并实时地引导行为（无需重新训练或提示）真是令人印象深刻——是的，也有点上瘾，所以要小心！

另一个想法是：如果这些描述是准确的（反映了实际行为），而且如果我们能够手动尝试不同的设置，为什么不尝试基于神经元激活和归因值构建一个模型呢？Transluce团队，如果你们在看这条信息……你们怎么看？

总的来说，做得很好。我强烈建议深入研究一下。它的易用性和观察神经元行为的能力非常有吸引力，我相信我们会看到更多的工具采用这些技术来帮助我们更好地理解我们的模型。

我现在打算在一些最具挑战性的法律推理用例中测试这个——看看它如何捕捉更复杂的逻辑结构。

这对人工智能意味着什么？我们得拭目以待……但就像GPT如此迅速自然地被接受一样，我认为这个版本的发布为大语言模型的可解释性开辟了新篇章。更重要的是，它将我们带得更近，朝着构建更加对齐和负责任的工具迈进。

既然他们的工作是开源的，那么就由社区来挑战它、改进它或在此基础上进行构建。

所以，试试看吧。

与此同时，你怎么看？

**一些限制（简要说明）：**

+   该工具就在昨天发布，我还没有完全有机会审阅整个文档。

+   我成功地尝试了简单的问题，但当我提出带有不同属性的类似问题时，逻辑仍然失败。归纳能力是这里的关键——尝试在可观察性工具中“捕捉”某些归纳性，将使其达到新的高度。

+   即使在低温或零温设置下，也并非总是可以重现。

+   没有单一的路径可以同时获得正确答案和逻辑推理。

+   它涉及到相当多的反复试验。在几次迭代后，我开始“感觉到”它的运作，但这和刚开始使用GPT时很像——当它有效时令人兴奋，但常常让你陷入困惑，“这里到底发生了什么？”因此，仍然需要进一步的工作。
