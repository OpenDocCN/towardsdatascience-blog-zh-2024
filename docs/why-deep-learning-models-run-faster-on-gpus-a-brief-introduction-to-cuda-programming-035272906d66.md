# ä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ GPU ä¸Šè¿è¡Œæ›´å¿«ï¼šCUDA ç¼–ç¨‹ç®€è¦ä»‹ç»

> åŸæ–‡ï¼š[https://towardsdatascience.com/why-deep-learning-models-run-faster-on-gpus-a-brief-introduction-to-cuda-programming-035272906d66?source=collection_archive---------1-----------------------#2024-04-17](https://towardsdatascience.com/why-deep-learning-models-run-faster-on-gpus-a-brief-introduction-to-cuda-programming-035272906d66?source=collection_archive---------1-----------------------#2024-04-17)

## å¯¹äºé‚£äº›æƒ³äº†è§£`.to("cuda")`çš„ä½œç”¨çš„äºº

[](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)[![Lucas de Lima Nogueira](../Images/76edd8ee4005d4c0b8bd476261eb06ae.png)](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------) [Lucas de Lima Nogueira](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------) Â·15 åˆ†é’Ÿé˜…è¯» Â·2024å¹´4æœˆ17æ—¥

--

![](../Images/38705e373a34d8ee180d497825e35868.png)

å›¾ç‰‡ç”±ä½œè€…å’Œ AI ååŠ©åˆ¶ä½œ ([https://copilot.microsoft.com/images/create](https://copilot.microsoft.com/images/create))

å¦‚ä»Šï¼Œå½“æˆ‘ä»¬è°ˆè®ºæ·±åº¦å­¦ä¹ æ—¶ï¼Œé€šå¸¸ä¼šå°†å…¶å®ç°ä¸åˆ©ç”¨ GPU ä»¥æé«˜æ€§èƒ½è”ç³»åœ¨ä¸€èµ·ã€‚

GPUï¼ˆå›¾å½¢å¤„ç†å•å…ƒï¼‰æœ€åˆæ˜¯ä¸ºäº†åŠ é€Ÿå›¾åƒã€2D å’Œ 3D å›¾å½¢çš„æ¸²æŸ“è€Œè®¾è®¡çš„ã€‚ç„¶è€Œï¼Œç”±äºå…¶èƒ½å¤Ÿæ‰§è¡Œå¤§é‡å¹¶è¡Œæ“ä½œçš„èƒ½åŠ›ï¼ŒGPU çš„åº”ç”¨èŒƒå›´è¶…è¶Šäº†è¿™ä¸€ç‚¹ï¼Œæ‰©å±•åˆ°äº†æ·±åº¦å­¦ä¹ ç­‰é¢†åŸŸã€‚

GPU åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„ä½¿ç”¨å§‹äº 2000 å¹´ä»£ä¸­åæœŸï¼Œå¹¶åœ¨ 2012 å¹´éšç€ AlexNet çš„å‡ºç°å˜å¾—éå¸¸æµè¡Œã€‚AlexNet æ˜¯ç”± Alex Krizhevskyã€Ilya Sutskever å’Œ Geoffrey Hinton è®¾è®¡çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå®ƒåœ¨ 2012 å¹´èµ¢å¾—äº† ImageNet å¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜èµ›ï¼ˆILSVRCï¼‰ã€‚è¿™ä¸€èƒœåˆ©æ ‡å¿—ç€æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å›¾åƒåˆ†ç±»ä¸­çš„æœ‰æ•ˆæ€§ä»¥åŠ GPU åœ¨è®­ç»ƒå¤§å‹æ¨¡å‹ä¸­çš„é‡è¦ä½œç”¨ã€‚

åœ¨è¿™ä¸€çªç ´ä¹‹åï¼ŒGPU åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„ä½¿ç”¨å˜å¾—è¶Šæ¥è¶Šæ™®åŠï¼Œè¿™ä¿ƒè¿›äº†åƒ PyTorch å’Œ TensorFlow è¿™æ ·çš„æ¡†æ¶çš„åˆ›å»ºã€‚

å¦‚ä»Šï¼Œæˆ‘ä»¬åªéœ€åœ¨ PyTorch ä¸­å†™ `.to("cuda")` å°±èƒ½å°†æ•°æ®å‘é€åˆ° GPUï¼Œå¹¶æœŸæœ›è®­ç»ƒè¿‡ç¨‹åŠ é€Ÿã€‚ä½†æ˜¯ï¼Œæ·±åº¦å­¦ä¹ ç®—æ³•æ˜¯å¦‚ä½•åœ¨å®é™…ä¸­åˆ©ç”¨ GPU çš„è®¡ç®—æ€§èƒ½çš„å‘¢ï¼Ÿè®©æˆ‘ä»¬ä¸€æ¢ç©¶ç«Ÿï¼

æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå¦‚ç¥ç»ç½‘ç»œã€å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œå˜æ¢å™¨ï¼ˆtransformersï¼‰ï¼ŒåŸºæœ¬ä¸Šæ˜¯é€šè¿‡æ•°å­¦è¿ç®—æ„å»ºçš„ï¼Œæ¯”å¦‚çŸ©é˜µåŠ æ³•ã€çŸ©é˜µä¹˜æ³•ä»¥åŠå°†ä¸€ä¸ªå‡½æ•°åº”ç”¨äºçŸ©é˜µã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æ‰¾åˆ°ä¼˜åŒ–è¿™äº›è¿ç®—çš„æ–¹æ³•ï¼Œå°±å¯ä»¥æé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ã€‚

é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬ä»ç®€å•çš„å¼€å§‹ã€‚å‡è®¾ä½ æƒ³è¦å°†ä¸¤ä¸ªå‘é‡ç›¸åŠ  *C = A + B*ã€‚

![](../Images/2e831e31e1d8d8b0315146a0d898fab1.png)

ä¸‹é¢æ˜¯ä¸€ä¸ªç”¨ C å®ç°çš„ç®€å•ä¾‹å­ï¼š

```py
void AddTwoVectors(flaot A[], float B[], float C[]) {
    for (int i = 0; i < N; i++) {
        C[i] = A[i] + B[i];
    }
}
```

æ­£å¦‚ä½ æ‰€æ³¨æ„åˆ°çš„ï¼Œè®¡ç®—æœºå¿…é¡»éå†å‘é‡ï¼Œåœ¨æ¯æ¬¡è¿­ä»£ä¸­é¡ºåºåœ°æ·»åŠ æ¯ä¸€å¯¹å…ƒç´ ã€‚ä½†è¿™äº›æ“ä½œæ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚ç¬¬ *i* å¯¹å…ƒç´ çš„åŠ æ³•å¹¶ä¸ä¾èµ–äºä»»ä½•å…¶ä»–å¯¹ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬èƒ½å¤Ÿå¹¶è¡Œæ‰§è¡Œè¿™äº›æ“ä½œï¼Œå°†æ‰€æœ‰å…ƒç´ å¯¹åŒæ—¶ç›¸åŠ ï¼Œä¼šæ€ä¹ˆæ ·å‘¢ï¼Ÿ

ä¸€ç§ç›´æ¥çš„æ–¹æ³•æ˜¯ä½¿ç”¨ CPU å¤šçº¿ç¨‹æ¥å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰è®¡ç®—ã€‚ç„¶è€Œï¼Œå¯¹äºæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæˆ‘ä»¬å¤„ç†çš„æ˜¯å¤§é‡çš„å‘é‡ï¼ŒåŒ…å«æ•°ç™¾ä¸‡ä¸ªå…ƒç´ ã€‚æ™®é€šçš„ CPU æœ€å¤šåªèƒ½åŒæ—¶å¤„ç†åå‡ ä¸ªçº¿ç¨‹ã€‚æ­¤æ—¶ï¼ŒGPU å°±æ´¾ä¸Šç”¨åœºäº†ï¼ç°ä»£çš„ GPU å¯ä»¥åŒæ—¶è¿è¡Œæ•°ç™¾ä¸‡ä¸ªçº¿ç¨‹ï¼Œä»è€Œå¢å¼ºè¿™äº›æ•°å­¦è¿ç®—åœ¨å¤§è§„æ¨¡å‘é‡ä¸Šçš„æ€§èƒ½ã€‚

# GPU ä¸ CPU çš„å¯¹æ¯”

å°½ç®¡å•æ¬¡æ“ä½œæ—¶ CPU çš„è®¡ç®—å¯èƒ½æ¯” GPU æ›´å¿«ï¼Œä½† GPU çš„ä¼˜åŠ¿åœ¨äºå®ƒçš„å¹¶è¡ŒåŒ–èƒ½åŠ›ã€‚å…¶åŸå› åœ¨äº CPU å’Œ GPU çš„è®¾è®¡ç›®æ ‡ä¸åŒã€‚CPU è®¾è®¡çš„ç›®çš„æ˜¯å°½å¯èƒ½å¿«åœ°æ‰§è¡Œä¸€ç³»åˆ—æ“ä½œï¼ˆçº¿ç¨‹ï¼‰ï¼Œå¹¶ä¸”åªèƒ½åŒæ—¶æ‰§è¡Œå‡ åä¸ªçº¿ç¨‹ï¼Œè€Œ GPU çš„è®¾è®¡ç›®æ ‡æ˜¯å¹¶è¡Œæ‰§è¡Œæˆåƒä¸Šä¸‡çš„æ“ä½œï¼ˆå°½ç®¡ç‰ºç‰²äº†æ¯ä¸ªçº¿ç¨‹çš„é€Ÿåº¦ï¼‰ã€‚

è¯·çœ‹ä¸‹é¢çš„è§†é¢‘ï¼š

ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾ CPU å°±åƒä¸€è¾†æ³•æ‹‰åˆ©ï¼Œè€Œ GPU å°±åƒä¸€è¾†å…¬äº¤è½¦ã€‚å¦‚æœä½ çš„ä»»åŠ¡æ˜¯æ¬è¿ä¸€ä¸ªäººï¼Œæ³•æ‹‰åˆ©ï¼ˆCPUï¼‰æ˜¾ç„¶æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚ç„¶è€Œï¼Œå¦‚æœä½ è¦æ¬è¿å¤šäººï¼Œå°½ç®¡æ³•æ‹‰åˆ©ï¼ˆCPUï¼‰æ¯æ¬¡çš„é€Ÿåº¦æ›´å¿«ï¼Œä½†å…¬äº¤è½¦ï¼ˆGPUï¼‰èƒ½å¤Ÿä¸€æ¬¡æ€§å°†æ‰€æœ‰äººéƒ½è¿é€åˆ°ç›®çš„åœ°ï¼Œæ¯”èµ·æ³•æ‹‰åˆ©å¤šæ¬¡å¾€è¿”ï¼Œå…¬äº¤è½¦èƒ½å¤Ÿæ›´å¿«åœ°å®Œæˆè¿è¾“ã€‚æ‰€ä»¥ï¼ŒCPU æ›´é€‚åˆå¤„ç†é¡ºåºæ“ä½œï¼Œè€Œ GPU æ›´é€‚åˆå¤„ç†å¹¶è¡Œæ“ä½œã€‚

![](../Images/a1a871c965e587ba2104a0c62b78a33c.png)

ä½œè€…å€ŸåŠ© AI æä¾›çš„å›¾åƒï¼ˆ[https://copilot.microsoft.com/images/create](https://copilot.microsoft.com/images/create)ï¼‰

ä¸ºäº†æä¾›æ›´é«˜çš„å¹¶è¡Œèƒ½åŠ›ï¼ŒGPU çš„è®¾è®¡å°†æ›´å¤šçš„æ™¶ä½“ç®¡åˆ†é…ç»™æ•°æ®å¤„ç†ï¼Œè€Œéæ•°æ®ç¼“å­˜å’Œæµæ§åˆ¶ï¼Œè¿™ä¸ CPU çš„è®¾è®¡ä¸åŒï¼ŒCPU é€šå¸¸å°†å¤§é‡æ™¶ä½“ç®¡åˆ†é…ç»™è¿™äº›ç›®çš„ï¼Œä»¥ä¼˜åŒ–å•çº¿ç¨‹æ€§èƒ½å’Œå¤æ‚æŒ‡ä»¤æ‰§è¡Œã€‚

ä¸‹å›¾å±•ç¤ºäº† CPU ä¸ GPU çš„èŠ¯ç‰‡èµ„æºåˆ†é…æƒ…å†µã€‚

![](../Images/b2bc61a6cffc46a6ab7e554fa5f3daf3.png)

ä½œè€…æ‰€ç”¨å›¾åƒçµæ„Ÿæ¥æºäº[CUDA C++ ç¼–ç¨‹æŒ‡å—](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf)

CPUæ‹¥æœ‰å¼ºå¤§çš„æ ¸å¿ƒå’Œæ›´å¤æ‚çš„ç¼“å­˜å†…å­˜æ¶æ„ï¼ˆä¸ºæ­¤åˆ†é…äº†å¤§é‡æ™¶ä½“ç®¡ï¼‰ã€‚è¿™ç§è®¾è®¡ä½¿å¾—é¡ºåºæ“ä½œå¤„ç†æ›´å¿«ã€‚å¦ä¸€æ–¹é¢ï¼ŒGPUä¼˜å…ˆè€ƒè™‘æ‹¥æœ‰å¤§é‡æ ¸å¿ƒï¼Œä»¥å®ç°æ›´é«˜ç¨‹åº¦çš„å¹¶è¡Œæ€§ã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»ç†è§£äº†è¿™äº›åŸºæœ¬æ¦‚å¿µï¼Œå¦‚ä½•åœ¨å®è·µä¸­åˆ©ç”¨è¿™äº›å¹¶è¡Œè®¡ç®—èƒ½åŠ›å‘¢ï¼Ÿ

# CUDAç®€ä»‹

å½“ä½ è¿è¡Œä¸€äº›æ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶ï¼Œä½ å¯èƒ½ä¼šé€‰æ‹©ä½¿ç”¨ä¸€äº›æµè¡Œçš„Pythonåº“ï¼Œå¦‚PyTorchæˆ–TensorFlowã€‚ç„¶è€Œï¼Œä¼—æ‰€å‘¨çŸ¥ï¼Œè¿™äº›åº“çš„æ ¸å¿ƒåœ¨åº•å±‚è¿è¡Œçš„æ˜¯C/C++ä»£ç ã€‚å¦å¤–ï¼Œæ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼Œä½ å¯èƒ½ä¼šä½¿ç”¨GPUæ¥åŠ é€Ÿå¤„ç†ã€‚è¿™æ—¶ï¼ŒCUDAå°±æ´¾ä¸Šç”¨åœºäº†ï¼CUDAä»£è¡¨*è®¡ç®—ç»Ÿä¸€æ¶æ„*ï¼Œå®ƒæ˜¯NVIDIAä¸ºå…¶GPUä¸Šçš„é€šç”¨å¤„ç†å¼€å‘çš„å¹³å°ã€‚å› æ­¤ï¼Œå°½ç®¡DirectXè¢«æ¸¸æˆå¼•æ“ç”¨æ¥å¤„ç†å›¾å½¢è®¡ç®—ï¼ŒCUDAä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿå°†NVIDIAçš„GPUè®¡ç®—èƒ½åŠ›é›†æˆåˆ°ä»–ä»¬çš„é€šç”¨è½¯ä»¶åº”ç”¨ä¸­ï¼Œè¶…è¶Šäº†ä»…ä»…æ˜¯å›¾å½¢æ¸²æŸ“çš„åº”ç”¨ã€‚

ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼ŒCUDAæä¾›äº†ä¸€ä¸ªç®€å•çš„åŸºäºC/C++çš„æ¥å£ï¼ˆCUDA C/C++ï¼‰ï¼Œä½¿å¾—å¯ä»¥è®¿é—®GPUçš„è™šæ‹ŸæŒ‡ä»¤é›†å’Œç‰¹å®šæ“ä½œï¼ˆå¦‚åœ¨CPUå’ŒGPUä¹‹é—´ç§»åŠ¨æ•°æ®ï¼‰ã€‚

åœ¨è¿›ä¸€æ­¥æ¢è®¨ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆç†è§£ä¸€äº›åŸºæœ¬çš„CUDAç¼–ç¨‹æ¦‚å¿µå’Œæœ¯è¯­ï¼š

+   *host*ï¼šæŒ‡çš„æ˜¯CPUåŠå…¶å†…å­˜ï¼›

+   *device*ï¼šæŒ‡çš„æ˜¯GPUåŠå…¶å†…å­˜ï¼›

+   *kernel*ï¼šæŒ‡çš„æ˜¯åœ¨è®¾å¤‡ï¼ˆGPUï¼‰ä¸Šæ‰§è¡Œçš„å‡½æ•°ï¼›

å› æ­¤ï¼Œåœ¨ä½¿ç”¨CUDAç¼–å†™çš„åŸºæœ¬ä»£ç ä¸­ï¼Œç¨‹åºåœ¨*host*ï¼ˆCPUï¼‰ä¸Šè¿è¡Œï¼Œå‘é€æ•°æ®åˆ°*device*ï¼ˆGPUï¼‰ï¼Œå¹¶å¯åŠ¨åœ¨*device*ï¼ˆGPUï¼‰ä¸Šæ‰§è¡Œçš„*kernels*ï¼ˆå‡½æ•°ï¼‰ã€‚è¿™äº›å†…æ ¸ç”±å¤šä¸ªçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œã€‚æ‰§è¡Œåï¼Œç»“æœä»*device*ï¼ˆGPUï¼‰ä¼ å›*host*ï¼ˆCPUï¼‰ã€‚

è®©æˆ‘ä»¬å›åˆ°æ·»åŠ ä¸¤ä¸ªå‘é‡çš„é—®é¢˜ï¼š

```py
#include <stdio.h>

void AddTwoVectors(flaot A[], float B[], float C[]) {
    for (int i = 0; i < N; i++) {
        C[i] = A[i] + B[i];
    }
}

int main() {
    ...
    AddTwoVectors(A, B, C);
    ...
}
```

åœ¨CUDA C/C++ä¸­ï¼Œç¨‹åºå‘˜å¯ä»¥å®šä¹‰C/C++å‡½æ•°ï¼Œç§°ä¸º*kernels*ï¼Œå½“è°ƒç”¨æ—¶ï¼Œè¿™äº›å†…æ ¸ä¼šè¢«Nä¸ªä¸åŒçš„CUDAçº¿ç¨‹å¹¶è¡Œæ‰§è¡ŒNæ¬¡ã€‚

è¦å®šä¹‰ä¸€ä¸ªå†…æ ¸ï¼Œä½ å¯ä»¥ä½¿ç”¨`__global__`å£°æ˜ç¬¦ï¼Œå¹¶ä¸”æ‰§è¡Œæ­¤å†…æ ¸çš„CUDAçº¿ç¨‹æ•°å¯ä»¥é€šè¿‡`<<<...>>>`ç¬¦å·æ¥æŒ‡å®šï¼š

```py
#include <stdio.h>

// Kernel definition
__global__ void AddTwoVectors(float A[], float B[], float C[]) {
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}

int main() {
    ...
    // Kernel invocation with N threads
    AddTwoVectors<<<1, N>>>(A, B, C);
    ...
}
```

æ¯ä¸ªçº¿ç¨‹æ‰§è¡Œå†…æ ¸ï¼Œå¹¶è¢«èµ‹äºˆä¸€ä¸ªå”¯ä¸€çš„çº¿ç¨‹ID `threadIdx`ï¼Œå¯ä»¥é€šè¿‡å†…ç½®å˜é‡åœ¨å†…æ ¸ä¸­è®¿é—®ã€‚ä¸Šé¢çš„ä»£ç å°†ä¸¤ä¸ªå¤§å°ä¸ºNçš„å‘é‡Aå’ŒBç›¸åŠ ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åˆ°å‘é‡Cä¸­ã€‚æ­£å¦‚ä½ æ‰€æ³¨æ„åˆ°çš„ï¼Œä¸å…¶ä½¿ç”¨å¾ªç¯é¡ºåºæ‰§è¡Œæ¯å¯¹åŠ æ³•æ“ä½œï¼ŒCUDAå…è®¸æˆ‘ä»¬åŒæ—¶æ‰§è¡Œæ‰€æœ‰è¿™äº›æ“ä½œï¼Œä½¿ç”¨Nä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç†ã€‚

ä½†åœ¨æˆ‘ä»¬èƒ½å¤Ÿè¿è¡Œæ­¤ä»£ç ä¹‹å‰ï¼Œè¿˜éœ€è¦è¿›è¡Œå¦ä¸€ä¸ªä¿®æ”¹ã€‚é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œ*å†…æ ¸*å‡½æ•°æ˜¯åœ¨è®¾å¤‡ï¼ˆGPUï¼‰å†…è¿è¡Œçš„ã€‚å› æ­¤ï¼Œæ‰€æœ‰æ•°æ®éƒ½éœ€è¦å­˜å‚¨åœ¨è®¾å¤‡å†…å­˜ä¸­ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹CUDAå†…ç½®å‡½æ•°æ¥å®ç°ï¼š

```py
#include <stdio.h>

// Kernel definition
__global__ void AddTwoVectors(float A[], float B[], float C[]) {
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}

int main() {

    int N = 1000; // Size of the vectors
    float A[N], B[N], C[N]; // Arrays for vectors A, B, and C

    ...

    float *d_A, *d_B, *d_C; // Device pointers for vectors A, B, and C

    // Allocate memory on the device for vectors A, B, and C
    cudaMalloc((void **)&d_A, N * sizeof(float));
    cudaMalloc((void **)&d_B, N * sizeof(float));
    cudaMalloc((void **)&d_C, N * sizeof(float));

    // Copy vectors A and B from host to device
    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);

    // Kernel invocation with N threads
    AddTwoVectors<<<1, N>>>(d_A, d_B, d_C);

    // Copy vector C from device to host
    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);

}
```

æˆ‘ä»¬éœ€è¦ä½¿ç”¨æŒ‡é’ˆï¼Œè€Œä¸æ˜¯ç›´æ¥å°†å˜é‡Aã€Bå’ŒCä¼ é€’ç»™*å†…æ ¸*ã€‚åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œä¸èƒ½ç›´æ¥åœ¨å†…æ ¸å¯åŠ¨ï¼ˆ`<<<...>>>`ï¼‰ä¸­ä½¿ç”¨*ä¸»æœº*æ•°ç»„ï¼ˆå¦‚ç¤ºä¾‹ä¸­çš„`A`ã€`B`å’Œ`C`ï¼‰ã€‚CUDAå†…æ ¸åœ¨è®¾å¤‡å†…å­˜ä¸Šæ“ä½œï¼Œå› æ­¤éœ€è¦å°†è®¾å¤‡æŒ‡é’ˆï¼ˆ`d_A`ã€`d_B`å’Œ`d_C`ï¼‰ä¼ é€’ç»™å†…æ ¸ï¼Œä»¥ä¾¿å®ƒèƒ½å¤Ÿåœ¨è®¾å¤‡ä¸Šæ‰§è¡Œæ“ä½œã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨`cudaMalloc`åœ¨*è®¾å¤‡*ä¸Šåˆ†é…å†…å­˜ï¼Œå¹¶ä½¿ç”¨`cudaMemcpy`åœ¨*ä¸»æœº*å’Œ*è®¾å¤‡*ä¹‹é—´å¤åˆ¶æ•°æ®ã€‚

ç°åœ¨æˆ‘ä»¬å¯ä»¥æ·»åŠ å‘é‡Aå’ŒBçš„åˆå§‹åŒ–ï¼Œå¹¶åœ¨ä»£ç æœ«å°¾åˆ·æ–°cudaå†…å­˜ã€‚

```py
#include <stdio.h>

// Kernel definition
__global__ void AddTwoVectors(float A[], float B[], float C[]) {
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}

int main() {

    int N = 1000; // Size of the vectors
    float A[N], B[N], C[N]; // Arrays for vectors A, B, and C

    // Initialize vectors A and B
    for (int i = 0; i < N; ++i) {
        A[i] = 1;
        B[i] = 3;
    }

    float *d_A, *d_B, *d_C; // Device pointers for vectors A, B, and C

    // Allocate memory on the device for vectors A, B, and C
    cudaMalloc((void **)&d_A, N * sizeof(float));
    cudaMalloc((void **)&d_B, N * sizeof(float));
    cudaMalloc((void **)&d_C, N * sizeof(float));

    // Copy vectors A and B from host to device
    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);

    // Kernel invocation with N threads
    AddTwoVectors<<<1, N>>>(d_A, d_B, d_C);

    // Copy vector C from device to host
    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
}
```

æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨è°ƒç”¨å†…æ ¸ä¹‹åéœ€è¦æ·»åŠ `cudaDeviceSynchronize();`ã€‚è¿™æ˜¯ä¸€ä¸ªç”¨äºåŒæ­¥ä¸»æœºçº¿ç¨‹å’Œè®¾å¤‡çš„å‡½æ•°ã€‚è°ƒç”¨æ­¤å‡½æ•°æ—¶ï¼Œä¸»æœºçº¿ç¨‹å°†ç­‰å¾…ï¼Œç›´åˆ°è®¾å¤‡ä¸Šæ‰€æœ‰å…ˆå‰å‘å‡ºçš„CUDAå‘½ä»¤å®Œæˆï¼Œæ‰ä¼šç»§ç»­æ‰§è¡Œã€‚

æ­¤å¤–ï¼Œæ·»åŠ ä¸€äº›CUDAé”™è¯¯æ£€æŸ¥éå¸¸é‡è¦ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½åœ¨GPUä¸Šè¯†åˆ«å‡ºé”™è¯¯ã€‚å¦‚æœä¸æ·»åŠ æ­¤æ£€æŸ¥ï¼Œä»£ç å°†ç»§ç»­æ‰§è¡Œ*ä¸»æœº*çº¿ç¨‹ï¼ˆCPUï¼‰ï¼Œå¹¶ä¸”å¾ˆéš¾è¯†åˆ«ä¸CUDAç›¸å…³çš„é”™è¯¯ã€‚

ä»¥ä¸‹æ˜¯è¿™ä¸¤ç§æŠ€æœ¯çš„å®ç°ï¼š

```py
#include <stdio.h>

// Kernel definition
__global__ void AddTwoVectors(float A[], float B[], float C[]) {
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}

int main() {

    int N = 1000; // Size of the vectors
    float A[N], B[N], C[N]; // Arrays for vectors A, B, and C

    // Initialize vectors A and B
    for (int i = 0; i < N; ++i) {
        A[i] = 1;
        B[i] = 3;
    }

    float *d_A, *d_B, *d_C; // Device pointers for vectors A, B, and C

    // Allocate memory on the device for vectors A, B, and C
    cudaMalloc((void **)&d_A, N * sizeof(float));
    cudaMalloc((void **)&d_B, N * sizeof(float));
    cudaMalloc((void **)&d_C, N * sizeof(float));

    // Copy vectors A and B from host to device
    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);

    // Kernel invocation with N threads
    AddTwoVectors<<<1, N>>>(d_A, d_B, d_C);

    // Check for error
    cudaError_t error = cudaGetLastError();
    if(error != cudaSuccess) {
        printf("CUDA error: %s\n", cudaGetErrorString(error));
        exit(-1);
    }

    // Waits untill all CUDA threads are executed
    cudaDeviceSynchronize();

    // Copy vector C from device to host
    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
}
```

è¦ç¼–è¯‘å’Œè¿è¡ŒCUDAä»£ç ï¼Œæ‚¨éœ€è¦ç¡®ä¿CUDAå·¥å…·åŒ…å·²å®‰è£…åœ¨æ‚¨çš„ç³»ç»Ÿä¸Šã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`nvcc`ï¼ŒNVIDIA CUDAç¼–è¯‘å™¨ï¼Œæ¥ç¼–è¯‘ä»£ç ã€‚å¦‚æœæ‚¨çš„è®¡ç®—æœºä¸Šæ²¡æœ‰GPUï¼Œå¯ä»¥ä½¿ç”¨Google Colabã€‚åªéœ€è¦åœ¨è¿è¡Œæ—¶â†’ç¬”è®°æœ¬è®¾ç½®ä¸­é€‰æ‹©ä¸€ä¸ªGPUï¼Œç„¶åå°†ä»£ç ä¿å­˜åˆ°`example.cu`æ–‡ä»¶ä¸­å¹¶è¿è¡Œï¼š

```py
%%shell
nvcc example.cu -o compiled_example # compile
./compiled_example # run

# you can also run the code with bug detection sanitizer
compute-sanitizer --tool memcheck ./compiled_example 
```

ç„¶è€Œï¼Œæˆ‘ä»¬çš„ä»£ç ä»ç„¶æ²¡æœ‰å®Œå…¨ä¼˜åŒ–ã€‚ä¸Šé¢çš„ç¤ºä¾‹ä½¿ç”¨äº†ä¸€ä¸ªå¤§å°ä¸ºN = 1000çš„å‘é‡ã€‚ä½†è¿™æ˜¯ä¸€ä¸ªå°æ•°å­—ï¼Œæ— æ³•å……åˆ†å±•ç¤ºGPUçš„å¹¶è¡ŒåŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œåœ¨å¤„ç†æ·±åº¦å­¦ä¹ é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¤„ç†å…·æœ‰æ•°ç™¾ä¸‡ä¸ªå‚æ•°çš„å¤§è§„æ¨¡å‘é‡ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å°è¯•è®¾ç½®ï¼Œä¾‹å¦‚ï¼ŒN = 500000å¹¶ä½¿ç”¨`<<<1, 500000>>>`è¿è¡Œä¸Šé¢çš„å†…æ ¸ï¼Œå®ƒå°†æŠ›å‡ºä¸€ä¸ªé”™è¯¯ã€‚å› æ­¤ï¼Œä¸ºäº†æ”¹è¿›ä»£ç å¹¶æ‰§è¡Œæ­¤ç±»æ“ä½œï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦äº†è§£CUDAç¼–ç¨‹ä¸­çš„ä¸€ä¸ªé‡è¦æ¦‚å¿µï¼šçº¿ç¨‹å±‚æ¬¡ç»“æ„ã€‚

# çº¿ç¨‹å±‚æ¬¡ç»“æ„

å†…æ ¸å‡½æ•°çš„è°ƒç”¨ä½¿ç”¨`<<<number_of_blocks, threads_per_block>>>`è¡¨ç¤ºæ³•è¿›è¡Œã€‚å› æ­¤ï¼Œåœ¨æˆ‘ä»¬ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬è¿è¡Œ1ä¸ªå—ï¼ŒåŒ…å«Nä¸ªCUDAçº¿ç¨‹ã€‚ç„¶è€Œï¼Œæ¯ä¸ªå—å¯¹å…¶æ”¯æŒçš„çº¿ç¨‹æ•°é‡æœ‰é™åˆ¶ã€‚è¿™æ˜¯å› ä¸ºæ¯ä¸ªå—ä¸­çš„çº¿ç¨‹éƒ½éœ€è¦ä½äºåŒä¸€ä¸ªæµå¼å¤šå¤„ç†å™¨æ ¸å¿ƒï¼Œå¹¶ä¸”å¿…é¡»å…±äº«è¯¥æ ¸å¿ƒçš„å†…å­˜èµ„æºã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ç‰‡æ®µè·å–æ­¤é™åˆ¶ï¼š

```py
int device;
cudaDeviceProp props;
cudaGetDevice(&device);
cudaGetDeviceProperties(&props, device);
printf("Maximum threads per block: %d\n", props.maxThreadsPerBlock);
```

åœ¨å½“å‰çš„Colab GPUä¸Šï¼Œä¸€ä¸ªçº¿ç¨‹å—æœ€å¤šå¯ä»¥åŒ…å«1024ä¸ªçº¿ç¨‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ›´å¤šçš„å—æ¥æ‰§è¡Œæ›´å¤šçš„çº¿ç¨‹ï¼Œä»¥å¤„ç†ç¤ºä¾‹ä¸­çš„å¤§å‘é‡ã€‚æ­¤å¤–ï¼Œå—è¢«ç»„ç»‡æˆç½‘æ ¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![](../Images/748e7f97d26b7d7fa6f8f8ed799b0c0a.png)

[https://handwiki.org/wiki/index.php?curid=1157670](https://handwiki.org/wiki/index.php?curid=1157670) ([CC BY-SA 3.0)](https://creativecommons.org/licenses/by-sa/3.0/%7C)

ç°åœ¨ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è®¿é—®çº¿ç¨‹IDï¼š

```py
int i = blockIdx.x * blockDim.x + threadIdx.x;
```

æ‰€ä»¥ï¼Œæˆ‘ä»¬çš„è„šæœ¬å˜æˆäº†ï¼š

```py
#include <stdio.h>

// Kernel definition
__global__ void AddTwoVectors(float A[], float B[], float C[], int N) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < N) // To avoid exceeding array limit
        C[i] = A[i] + B[i];
}

int main() {
    int N = 500000; // Size of the vectors
    int threads_per_block;
    int device;
    cudaDeviceProp props;
    cudaGetDevice(&device);
    cudaGetDeviceProperties(&props, device);
    threads_per_block = props.maxThreadsPerBlock;
    printf("Maximum threads per block: %d\n", threads_per_block); // 1024

    float A[N], B[N], C[N]; // Arrays for vectors A, B, and C

    // Initialize vectors A and B
    for (int i = 0; i < N; ++i) {
        A[i] = 1;
        B[i] = 3;
    }

    float *d_A, *d_B, *d_C; // Device pointers for vectors A, B, and C

    // Allocate memory on the device for vectors A, B, and C
    cudaMalloc((void **)&d_A, N * sizeof(float));
    cudaMalloc((void **)&d_B, N * sizeof(float));
    cudaMalloc((void **)&d_C, N * sizeof(float));

    // Copy vectors A and B from host to device
    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);

    // Kernel invocation with multiple blocks and threads_per_block threads per block
    int number_of_blocks = (N + threads_per_block - 1) / threads_per_block;
    AddTwoVectors<<<number_of_blocks, threads_per_block>>>(d_A, d_B, d_C, N);

    // Check for error
    cudaError_t error = cudaGetLastError();
    if (error != cudaSuccess) {
        printf("CUDA error: %s\n", cudaGetErrorString(error));
        exit(-1);
    }

    // Wait until all CUDA threads are executed
    cudaDeviceSynchronize();

    // Copy vector C from device to host
    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);

}
```

# æ€§èƒ½æ¯”è¾ƒ

ä¸‹é¢æ˜¯ä¸åŒå‘é‡å¤§å°ä¸‹CPUå’ŒGPUè¿›è¡Œè¿™ä¸¤ä¸ªå‘é‡åŠ æ³•æ“ä½œçš„æ¯”è¾ƒã€‚

![](../Images/b8e80e991576bd43865f4bd9783f4b52.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

å¦‚ä½ æ‰€è§ï¼ŒGPUå¤„ç†çš„ä¼˜åŠ¿åªæœ‰åœ¨å‘é‡å¤§å°Néå¸¸å¤§çš„æƒ…å†µä¸‹æ‰ä¼šæ˜¾ç°å‡ºæ¥ã€‚æ­¤å¤–ï¼Œè¯·è®°ä½ï¼Œè¿™ä¸ªæ—¶é—´æ¯”è¾ƒä»…ä»…è€ƒè™‘äº†å†…æ ¸/å‡½æ•°çš„æ‰§è¡Œæ—¶é—´ï¼Œå¹¶æ²¡æœ‰è€ƒè™‘åœ¨*ä¸»æœº*å’Œ*è®¾å¤‡*ä¹‹é—´å¤åˆ¶æ•°æ®çš„æ—¶é—´ï¼Œå°½ç®¡åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹è¿™ä¸ªæ—¶é—´å¯èƒ½ä¸æ˜¾è‘—ï¼Œä½†åœ¨æˆ‘ä»¬è¿™ä¸ªç®€å•çš„åŠ æ³•æ“ä½œä¸­ï¼Œå®ƒç›¸å¯¹æ¥è¯´æ˜¯æ¯”è¾ƒå¯è§‚çš„ã€‚å› æ­¤ï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼ŒGPUè®¡ç®—åªæœ‰åœ¨å¤„ç†é«˜åº¦è®¡ç®—å¯†é›†ä¸”é«˜åº¦å¹¶è¡Œçš„è®¡ç®—æ—¶æ‰å±•ç¤ºå…¶ä¼˜åŠ¿ã€‚

# å¤šç»´çº¿ç¨‹

å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬çŸ¥é“å¦‚ä½•æé«˜ä¸€ä¸ªç®€å•æ•°ç»„æ“ä½œçš„æ€§èƒ½ã€‚ä½†åœ¨å¤„ç†æ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†çŸ©é˜µå’Œå¼ é‡æ“ä½œã€‚åœ¨æˆ‘ä»¬ä¹‹å‰çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬åªä½¿ç”¨äº†ä¸€ç»´å—å’ŒNä¸ªçº¿ç¨‹ã€‚ç„¶è€Œï¼Œä¹Ÿå¯ä»¥æ‰§è¡Œå¤šç»´çº¿ç¨‹å—ï¼ˆæœ€å¤šæ”¯æŒ3ä¸ªç»´åº¦ï¼‰ã€‚å› æ­¤ï¼Œä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œå¦‚æœä½ éœ€è¦æ‰§è¡ŒçŸ©é˜µæ“ä½œï¼Œä½ å¯ä»¥è¿è¡Œä¸€ä¸ªNxMçº¿ç¨‹çš„çº¿ç¨‹å—ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥è·å–çŸ©é˜µçš„è¡Œåˆ—ç´¢å¼•ï¼Œæ–¹æ³•æ˜¯`row = threadIdx.x, col = threadIdx.y`ã€‚åŒæ ·ï¼Œä¸ºäº†æ–¹ä¾¿ï¼Œä½ å¯ä»¥ä½¿ç”¨`dim3`å˜é‡ç±»å‹æ¥å®šä¹‰`number_of_blocks`å’Œ`threads_per_block`ã€‚

ä¸‹é¢çš„ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•åŠ æ³•ä¸¤ä¸ªçŸ©é˜µã€‚

```py
#include <stdio.h>

// Kernel definition
__global__ void AddTwoMatrices(float A[N][N], float B[N][N], float C[N][N]) {
    int i = threadIdx.x;
    int j = threadIdx.y;
    C[i][j] = A[i][j] + B[i][j];
}

int main() {
    ...
    // Kernel invocation with 1 block of NxN threads
    dim3 threads_per_block(N, N);
    AddTwoMatrices<<<1, threads_per_block>>>(A, B, C);
    ...
}
```

ä½ ä¹Ÿå¯ä»¥æ‰©å±•è¿™ä¸ªç¤ºä¾‹æ¥å¤„ç†å¤šä¸ªå—ï¼š

```py
#include <stdio.h>

// Kernel definition
__global__ void AddTwoMatrices(float A[N][N], float B[N][N], float C[N][N]) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    if (i < N && j < N) {
        C[i][j] = A[i][j] + B[i][j];
    }
}

int main() {
    ...
    // Kernel invocation with 1 block of NxN threads
    dim3 threads_per_block(32, 32);
    dim3 number_of_blocks((N + threads_per_block.x - 1) âˆ• threads_per_block.x, (N + threads_per_block.y - 1) âˆ• threads_per_block.y);
    AddTwoMatrices<<<number_of_blocks, threads_per_block>>>(A, B, C);
    ...
}
```

ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ç›¸åŒçš„æ€è·¯æ‰©å±•è¿™ä¸ªç¤ºä¾‹æ¥å¤„ç†ä¸‰ç»´æ“ä½œã€‚

ç°åœ¨ä½ çŸ¥é“å¦‚ä½•æ“ä½œå¤šç»´æ•°æ®äº†ï¼Œè¿˜æœ‰ä¸€ä¸ªé‡è¦ä¸”ç®€å•çš„æ¦‚å¿µéœ€è¦å­¦ä¹ ï¼šå¦‚ä½•åœ¨å†…æ ¸ä¸­è°ƒç”¨å‡½æ•°ã€‚åŸºæœ¬ä¸Šï¼Œè¿™æ˜¯é€šè¿‡ä½¿ç”¨`__device__`å£°æ˜ä¿®é¥°ç¬¦æ¥å®Œæˆçš„ã€‚è¿™å®šä¹‰äº†å¯ä»¥ç”±*è®¾å¤‡*ï¼ˆGPUï¼‰ç›´æ¥è°ƒç”¨çš„å‡½æ•°ã€‚å› æ­¤ï¼Œå®ƒä»¬åªèƒ½ä»`__global__`æˆ–å¦ä¸€ä¸ª`__device__`å‡½æ•°ä¸­è°ƒç”¨ã€‚ä¸‹é¢çš„ç¤ºä¾‹å¯¹å‘é‡åº”ç”¨äº†sigmoidæ“ä½œï¼ˆè¿™æ˜¯æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­éå¸¸å¸¸è§çš„æ“ä½œï¼‰ã€‚

```py
#include <math.h>

// Sigmoid function
__device__ float sigmoid(float x) {
    return 1 / (1 + expf(-x));
}

// Kernel definition for applying sigmoid function to a vector
__global__ void sigmoidActivation(float input[], float output[]) {
    int i = threadIdx.x;
    output[i] = sigmoid(input[i]);

}
```

æ‰€ä»¥ï¼Œç°åœ¨ä½ å·²ç»äº†è§£äº†CUDAç¼–ç¨‹çš„ä¸€äº›åŸºæœ¬é‡è¦æ¦‚å¿µï¼Œä½ å¯ä»¥å¼€å§‹åˆ›å»ºCUDAå†…æ ¸ã€‚åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå®ƒä»¬åŸºæœ¬ä¸Šæ˜¯ä¸€äº›çŸ©é˜µå’Œå¼ é‡æ“ä½œï¼Œå¦‚åŠ æ³•ã€ä¹˜æ³•ã€å·ç§¯ã€å½’ä¸€åŒ–ç­‰ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç®€å•çš„çŸ©é˜µä¹˜æ³•ç®—æ³•å¯ä»¥åƒä¸‹é¢è¿™æ ·è¿›è¡Œå¹¶è¡ŒåŒ–ï¼š

![](../Images/eea3441283b27a0b357d8f148ba9f6e5.png)

```py
// GPU version

__global__ void matMul(float A[M][N], float B[N][P], float C[M][P]) {
    int row = blockIdx.x * blockDim.x + threadIdx.x;
    int col = blockIdx.y * blockDim.y + threadIdx.y;

    if (row < M && col < P) {
        float C_value = 0;
        for (int i = 0; i < N; i++) {
            C_value += A[row][i] * B[i][col];
        }
        C[row][col] = C_value;
    }
}
```

ç°åœ¨ï¼Œå°†è¿™ä¸ªä¸ä¸‹é¢çš„æ™®é€šCPUå®ç°çš„ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•è¿›è¡Œå¯¹æ¯”ï¼š

```py
// CPU version

void matMul(float A[M][N], float B[N][P], float C[M][P]) {
    for (int row = 0; row < M; row++) {
        for (int col = 0; col < P; col++) {
            float C_value = 0;
            for (int i = 0; i < N; i++) {
                C_value += A[row][i] * B[i][col];
            }
            C[row][col] = C_value;
        }
    }
}
```

ä½ å¯ä»¥æ³¨æ„åˆ°ï¼Œåœ¨GPUç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬çš„å¾ªç¯æ¬¡æ•°æ›´å°‘ï¼Œä»è€Œä½¿å¾—æ“ä½œçš„å¤„ç†é€Ÿåº¦æ›´å¿«ã€‚ä¸‹é¢æ˜¯CPUå’ŒGPUåœ¨NxNçŸ©é˜µä¹˜æ³•æ€§èƒ½å¯¹æ¯”ï¼š

![](../Images/fa9aef35ede725268ad91f948b4e9ca6.png)

ä½œè€…æä¾›çš„å›¾ç‰‡

æ­£å¦‚ä½ æ‰€è§‚å¯Ÿåˆ°çš„ï¼Œéšç€çŸ©é˜µå¤§å°çš„å¢åŠ ï¼ŒGPUå¤„ç†çš„æ€§èƒ½æå‡åœ¨çŸ©é˜µä¹˜æ³•æ“ä½œä¸­è¡¨ç°å¾—æ›´åŠ æ˜æ˜¾ã€‚

ç°åœ¨ï¼Œè€ƒè™‘ä¸€ä¸ªåŸºæœ¬çš„ç¥ç»ç½‘ç»œï¼Œå®ƒä¸»è¦æ¶‰åŠ**y** = Ïƒ(W**x** + **b**)çš„æ“ä½œï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![](../Images/568620fec12aad34ce87ccd1c37caaca.png)

ä½œè€…æä¾›çš„å›¾ç‰‡

è¿™äº›æ“ä½œä¸»è¦åŒ…æ‹¬çŸ©é˜µä¹˜æ³•ã€çŸ©é˜µåŠ æ³•å’Œå¯¹æ•°ç»„åº”ç”¨å‡½æ•°ï¼Œæ‰€æœ‰è¿™äº›ä½ å·²ç»ç†Ÿæ‚‰å¹¶è¡ŒåŒ–æŠ€æœ¯ã€‚å› æ­¤ï¼Œç°åœ¨ä½ å·²ç»èƒ½å¤Ÿä»é›¶å¼€å§‹å®ç°ä¸€ä¸ªè¿è¡Œåœ¨GPUä¸Šçš„ç¥ç»ç½‘ç»œï¼

# ç»“è®º

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å…³äºGPUå¤„ç†çš„åŸºç¡€æ¦‚å¿µï¼Œä»¥æé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œä¹Ÿéœ€è¦æåˆ°çš„æ˜¯ï¼Œä½ æ‰€çœ‹åˆ°çš„è¿™äº›æ¦‚å¿µä»…ä»…æ˜¯åŸºç¡€ï¼Œè¿˜æœ‰å¾ˆå¤šä¸œè¥¿éœ€è¦å­¦ä¹ ã€‚åƒPyTorchå’ŒTensorFlowè¿™æ ·çš„åº“å®ç°äº†ä¼˜åŒ–æŠ€æœ¯ï¼Œæ¶‰åŠå…¶ä»–æ›´å¤æ‚çš„æ¦‚å¿µï¼Œå¦‚ä¼˜åŒ–å†…å­˜è®¿é—®ã€æ‰¹å¤„ç†æ“ä½œç­‰ï¼ˆå®ƒä»¬åˆ©ç”¨äº†åŸºäºCUDAçš„åº“ï¼Œå¦‚cuBLASå’ŒcuDNNï¼‰ã€‚ä½†æˆ‘å¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½å¸®åŠ©ä½ ç†æ¸…å½“ä½ ç¼–å†™`.to("cuda")`å¹¶åœ¨GPUä¸Šæ‰§è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶ï¼ŒèƒŒåå‘ç”Ÿäº†ä»€ä¹ˆã€‚

åœ¨æœªæ¥çš„æ–‡ç« ä¸­ï¼Œæˆ‘å°†å°è¯•å¸¦æ¥æ›´å¤šå…³äºCUDAç¼–ç¨‹çš„å¤æ‚æ¦‚å¿µã€‚è¯·åœ¨è¯„è®ºä¸­å‘Šè¯‰æˆ‘ä½ å¯¹è¿™ç¯‡æ–‡ç« çš„çœ‹æ³•ï¼Œæˆ–è€…ä½ å¸Œæœ›æˆ‘æ¥ä¸‹æ¥å†™äº›ä»€ä¹ˆï¼éå¸¸æ„Ÿè°¢ä½ çš„é˜…è¯»ï¼ğŸ˜Š

# è¿›ä¸€æ­¥é˜…è¯»

[CUDAç¼–ç¨‹æŒ‡å—](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf) â€” NVIDIA CUDAç¼–ç¨‹æ–‡æ¡£ã€‚

[CUDAæ–‡æ¡£](https://docs.nvidia.com/cuda/) â€” NVIDIAå®Œæ•´çš„CUDAæ–‡æ¡£ã€‚

[CUDAç¥ç»ç½‘ç»œè®­ç»ƒå®ç°](https://luniak.io/cuda-neural-network-implementation-part-1/) â€” ç”¨çº¯CUDA C++å®ç°çš„ç¥ç»ç½‘ç»œè®­ç»ƒã€‚

[CUDA LLMè®­ç»ƒå®ç°](https://github.com/karpathy/llm.c) â€” ç”¨çº¯CUDA Cå®ç°çš„LLMè®­ç»ƒã€‚
