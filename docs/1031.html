<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Differential Privacy and Federated Learning for Medical Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Differential Privacy and Federated Learning for Medical Data</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/differential-privacy-and-federated-learning-for-medical-data-0f2437d6ece9?source=collection_archive---------7-----------------------#2024-04-23">https://towardsdatascience.com/differential-privacy-and-federated-learning-for-medical-data-0f2437d6ece9?source=collection_archive---------7-----------------------#2024-04-23</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="b183" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A practical assessment of Differential Privacy &amp; Federated Learning in the medical context.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@eric.boernert?source=post_page---byline--0f2437d6ece9--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Eric Boernert" class="l ep by dd de cx" src="../Images/3038e5e8f0cd468ec69794caecf32bba.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*MrsTi3Q7Zmg9jQy4159ZkQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--0f2437d6ece9--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@eric.boernert?source=post_page---byline--0f2437d6ece9--------------------------------" rel="noopener follow">Eric Boernert</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--0f2437d6ece9--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 23, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/f8e948c4524bfa196d71cadef58061a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5SoMMUuZ7waWGRDh"/></div></div></figure><p id="f178" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">(Bing AI generated image, original, full ownership)</p><h1 id="699a" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Sensitive data cries out for more protection</h1><p id="cc83" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">The need for data privacy seems to be generally at ease nowadays in the era of large language models trained on everything from the public internet, regardless of <a class="af ot" href="https://futurism.com/video-openai-cto-sora-training-data" rel="noopener ugc nofollow" target="_blank">actual intellectual property</a> which their respective <a class="af ot" href="https://www.theguardian.com/technology/2024/jan/08/ai-tools-chatgpt-copyrighted-material-openai" rel="noopener ugc nofollow" target="_blank">company leaders openly admit</a>.</p><p id="c466" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">But there’s a much more sensitive parallel universe when it comes to patients’ data, our health records, which are undoubtedly much more sensitive and in need of <a class="af ot" href="https://www.youtube.com/watch?v=4-7jSoINyq4" rel="noopener ugc nofollow" target="_blank">protection</a>.</p><p id="d26e" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Also the regulations are getting stronger all over the world, the trend is unanimously towards more stricter data protection regulations, including AI.</p><p id="e03b" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">There are obvious ethical reasons which we don’t have to explain, but from the enterprise levels regulatory and legal reasons that require pharmaceutical companies, labs and hospitals to use state of the art technologies to protect data privacy of patients.</p><h1 id="80f2" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Federated paradigm is here to help</h1><p id="60b5" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">Federated analytics and learning are great options to be able to analyze data and train models on patients’ data without accessing any raw data.</p><p id="390b" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">In case of federated analytics it means, for instance, we can get correlation between blood glucose and patients BMI without accessing any raw data that could lead to patients re-identification.</p><p id="e3d1" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">In the case of machine learning, let’s use the example of diagnostics, where models are trained on patients’ images to detect malignant changes in their tissues and detect early stages of cancer, for instance. This is literally a life saving application of machine learning. Models are trained locally at the hospital level using local images and labels assigned by professional radiologists, then there’s aggregation which combines all those local models into a single more generalized model. The process repeats for tens or hundreds of rounds to improve the performance of the model.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ou"><img src="../Images/2adfedf9f70a43b17a534cd0d78e5a60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8L5zljOLOPiOg_CI"/></div></div></figure><p id="0be9" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 1. Federated learning in action, sharing model updates, not data.</em></p><p id="3697" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">The reward for each individual hospital is that they will benefit from a better trained model able to detect disease in future patients with higher probability. It’s a win-win situation for everyone, especially patients.</p><p id="4d35" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Of course there’s a variety of federated network topologies and model aggregation strategies, but for the sake of this article we tried to focus on the typical example.</p><h1 id="c85c" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Trust building with the help of technology</h1><p id="6961" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">It’s believed that <a class="af ot" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6376961/" rel="noopener ugc nofollow" target="_blank">vast amounts of clinical data are not being used</a> due to a (justified) <a class="af ot" href="https://bmcpublichealth.biomedcentral.com/articles/10.1186/1471-2458-14-1144" rel="noopener ugc nofollow" target="_blank">reluctance of data owners to share their data</a> with partners.</p><p id="3cd9" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Federated learning is a key strategy to build that trust backed up by the technology, not only on contracts and faith in ethics of particular employees and partners of the organizations forming consortia.</p><p id="e618" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">First of all, the data remains at the source, never leaves the hospital, and is not being centralized in a single, potentially vulnerable location. Federated approach means there aren’t any external copies of the data that may be hard to remove after the research is completed.</p><p id="b3f2" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">The technology blocks access to raw data because of multiple techniques that follow defense in depth principle. Each of them is minimizing the risk of data exposure and patient re-identification by tens or thousands of times. Everything to make it economically unviable to discover nor reconstruct raw level data.</p><p id="340c" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Data is minimized first to expose only the necessary properties to machine learning agents running locally, PII data is stripped, and we also use anonymization techniques.</p><p id="5705" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Then local nodes protect local data against the so-called too curious data scientist threat by allowing only the code and operations accepted by local data owners to run against their data. For instance model training code deployed locally at the hospital as a package is allowed or not by the local data owners. Remote data scientists cannot just send any code to remote nodes as that would allow them for instance to return raw level data. This requires a new, decentralized way of thinking to embrace different mindset and technologies for permission management, an interesting topic for another time.</p><h1 id="be23" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Are models private enough?</h1><p id="d4df" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">Assuming all those layers of protection are in place there’s still concern related to the safety of model weights themselves.</p><p id="6e4a" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">There’s growing concern in the AI community about machine learning models as the super compression of the data, not as black-boxy as previously considered, and revealing more information about the underlying data than previously thought.</p><p id="9a47" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">And that means that with enough skills, time, effort and powerful hardware a motivated adversary can try to reconstruct the original data, or at least prove with high probability that a given patient was in the group that was used to train the model (Membership Inference Attack (MIA)) . Other <a class="af ot" href="https://arxiv.org/pdf/2211.14952.pdf" rel="noopener ugc nofollow" target="_blank">types of attacks</a> possible such as extraction, reconstruction and evasion.</p><p id="6eb0" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">To make things even worse, the progress of generative AI that we all admire and benefit from, delivers new, more effective techniques for image reconstruction (<a class="af ot" href="https://arxiv.org/abs/2202.06924" rel="noopener ugc nofollow" target="_blank">for example, lung scan of the patients</a>). The same ideas that are used by all of us to generate images on demand can be used by adversaries to reconstruct original images from MRI/CT scan machines. Other modalities of data such as <a class="af ot" href="https://arxiv.org/pdf/2208.08114.pdf" rel="noopener ugc nofollow" target="_blank">tabular data</a>, text, sound and video can now be reconstructed using gen AI.</p><h1 id="a4f2" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Differential Privacy to the rescue</h1><p id="900a" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">Differential privacy (DP) algorithms promise that we exchange some of the model’s accuracy for much improved resilience against inference attacks. This is another privacy-utility trade-off that is worth considering.</p><p id="c599" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><a class="af ot" href="https://blog.openmined.org/differential-privacy-using-pydp/" rel="noopener ugc nofollow" target="_blank">Differential privacy</a> means in practice we add a very special type of noise and clipping, that in return will result in a <a class="af ot" href="https://privacytools.seas.harvard.edu/files/privacytools/files/nissim_et_al_-_differential_privacy_primer_for_non-technical_audiences_1.pdf" rel="noopener ugc nofollow" target="_blank">very good ratio of privacy gains versus accuracy loss</a>.</p><p id="6d79" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">It can be as easy as least effective Gaussian noise but nowadays we embrace the development of much more sophisticated algorithms such as Sparse Vector Technique (SVT), Opacus library as practical implementation of differentially private stochastic gradient descent (DP-SGD), plus venerable Laplacian noise based libraries (i.e. PyDP).</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/e66c98be78968db9ff7da231d8c762aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eGUx8DE4H5T6WpQp"/></div></div></figure><p id="2500" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 2. On device differential privacy that we all use all the time.</em></p><p id="777d" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">And, by the way, we all benefit from this technique without even realizing that it even exists, and it is happening right now. Our telemetry data from mobile devices (<a class="af ot" href="https://machinelearning.apple.com/research/learning-with-privacy-at-scale" rel="noopener ugc nofollow" target="_blank">Apple iOS</a>, <a class="af ot" href="https://developers.googleblog.com/2021/01/how-were-helping-developers-with-differential-privacy.html?m=1" rel="noopener ugc nofollow" target="_blank">Google Android</a>) and desktop OSes (<a class="af ot" href="https://blogs.microsoft.com/on-the-issues/2020/06/24/differential-privacy-harvard-opendp/" rel="noopener ugc nofollow" target="_blank">Microsoft Windows</a>) is using differential privacy and federated learning algorithms to train models without sending raw data from our devices. And it’s been around for years now.</p><p id="3b74" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Now, there’s growing adoption for other use cases including our favorite siloed federated learning case, with relatively few participants with large amounts of data in on-purpose established consortia of different organizations and companies.</p><p id="dddb" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Differential privacy is not specific to federated learning. However, there are different strategies of applying DP in federated learning scenarios as well as different selection of algorithms. Different algorithms which work better for federated learning setups, different for local data privacy (LDP) and centralized data processing.</p><p id="d9b2" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">In the context of federated learning we anticipate a drop in model accuracy after applying differential privacy, but still (and to some extent hopefully) expect the model to perform better than local models without federated aggregation. So the federated model should still retain its advantage despite added noise and clipping (DP).</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ow"><img src="../Images/33bb671540c98ab5748bd857a92d1618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r066s1py-Kuojq44"/></div></div></figure><p id="e531" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 3. What we can expect based on known papers and our experiences.</em></p><p id="bb53" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Differential privacy can be applied as early as at the source data (Local Differential Privacy (LDP)).</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ox"><img src="../Images/4215a9e94305aef91a8b158d3654068c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H2xbTr5sFjB0sp0b"/></div></div></figure><p id="ff23" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 4, different places where DP can be applied to improve data protection</em></p><p id="f180" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">There are also cases of federated learning within a network of partners who have all data access rights and are less concerned about data protection levels so there might be no DP at all.</p><p id="58dc" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">On the other hand when the model is going to be shared with the outside world or sold commercially it might be a good idea to apply DP for the global model as well.</p><h1 id="96d9" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Practical experimentation results</h1><p id="202f" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">At Roche’s Federated Open Science team, <a class="af ot" href="https://developer.nvidia.com/flare" rel="noopener ugc nofollow" target="_blank">NVIDIA Flare</a> is our tool of choice for federated learning as the most mature open source federated framework on the market. We also collaborate with the NVIDIA team on <a class="af ot" href="https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/" rel="noopener ugc nofollow" target="_blank">future development of NVIDIA Flare</a> and are glad to help to improve an already great solution for federated learning.</p><p id="7aff" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">We tested three different DP algorithms:</p><ul class=""><li id="57c7" class="mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr oy oz pa bk"><a class="af ot" href="https://github.com/pytorch/opacus" rel="noopener ugc nofollow" target="_blank">Opacus</a></li><li id="82c3" class="mw mx fq my b go pb na nb gr pc nd ne nf pd nh ni nj pe nl nm nn pf np nq nr oy oz pa bk"><a class="af ot" href="https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/filters/svt_privacy.py" rel="noopener ugc nofollow" target="_blank">SVT</a></li><li id="8507" class="mw mx fq my b go pb na nb gr pc nd ne nf pd nh ni nj pe nl nm nn pf np nq nr oy oz pa bk"><a class="af ot" href="https://github.com/NVIDIA/NVFlare/blob/main/research/quantifying-data-leakage/src/nvflare_gradinv/filters/gaussian_privacy.py" rel="noopener ugc nofollow" target="_blank">Gaussian noise</a></li></ul><p id="95d9" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">We applied differential privacy for the models using different strategies:</p><ul class=""><li id="aa70" class="mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr oy oz pa bk">Every federated learning round</li><li id="60f1" class="mw mx fq my b go pb na nb gr pc nd ne nf pd nh ni nj pe nl nm nn pf np nq nr oy oz pa bk">Only the first round (of federated training)</li><li id="3d3d" class="mw mx fq my b go pb na nb gr pc nd ne nf pd nh ni nj pe nl nm nn pf np nq nr oy oz pa bk">Each Nth round (of federated training)</li></ul><p id="6ac1" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">for three different cases (datasets and algorithms):</p><ul class=""><li id="7a2b" class="mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr oy oz pa bk">FLamby Tiny IXI dataset</li><li id="adcd" class="mw mx fq my b go pb na nb gr pc nd ne nf pd nh ni nj pe nl nm nn pf np nq nr oy oz pa bk">Breast density classification</li><li id="2524" class="mw mx fq my b go pb na nb gr pc nd ne nf pd nh ni nj pe nl nm nn pf np nq nr oy oz pa bk">Higgs classification</li></ul><p id="94a4" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">So, we tried three dimensions of algorithm, strategy and dataset (case).</p><p id="902b" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">The results are conforming with our expectations of model accuracy degradation that was larger with lower privacy budgets (as expected).</p><h1 id="5c65" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">FLamby Tiny IXI dataset</h1><p id="48c0" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">(Dataset source: <a class="af ot" href="https://owkin.github.io/FLamby/fed_ixi.html" rel="noopener ugc nofollow" target="_blank">https://owkin.github.io/FLamby/fed_ixi.html</a>)</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pg"><img src="../Images/a878aa9570490b92fdc7705b1e450ca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TzNZgbEb51MzwCq3"/></div></div></figure><p id="3146" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 5. Models performance without DP</em></p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pg"><img src="../Images/d1fa7a6c6e5a7c5e925df2ca556067c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bZGIQF6742gS5XV2"/></div></div></figure><p id="d4a0" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 6. Models performance with DP on first round</em></p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pg"><img src="../Images/ae7a6c918def2d29b01335393c43045b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PrPIeQTdHGBR8QqR"/></div></div></figure><p id="a8b7" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 7. SVT applied every second round (with decreasing threshold)</em></p><p id="f993" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">We observe significant improvement of accuracy with SVT applied on the first round compared to SVT filter applied to every round.</p><h1 id="d555" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Breast density case</h1><p id="2cfd" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">(Dataset source <a class="af ot" href="https://www.kaggle.com/code/theoviel/breast-density-classification-using-monai" rel="noopener ugc nofollow" target="_blank">Breast Density Classification using MONAI | Kaggle</a>)</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pg"><img src="../Images/6d79ec0cd119de736d026df28b2de5c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BArysvYxiolq_zi7"/></div></div></figure><p id="3061" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 8. Models performance without DP</em></p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pg"><img src="../Images/84ba2dad1d9e2ab32f33e37d46b71413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GtG1N5irLsABQD3a"/></div></div></figure><p id="eea4" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 9. DP applied to the first round</em></p><p id="cec0" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">We observe a mediocre accuracy loss after applying a Gaussian noise filter.</p><p id="cfa7" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">This dataset was the most troublesome and sensitive to DP (major accuracy loss, unpredictability).</p><h1 id="40d7" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Higgs classification</h1><p id="e52c" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">(Dataset source <a class="af ot" href="https://archive.ics.uci.edu/dataset/280/higgs" rel="noopener ugc nofollow" target="_blank">HIGGS — UCI Machine Learning Repository</a>)</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pg"><img src="../Images/b52ce7bd21ec84c112083f3575e297da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9qji7OQwY1PxO18Y"/></div></div></figure><p id="c756" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 10. Models performance with percentile value 95.</em></p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pg"><img src="../Images/59fc53bec323a0e2af6a500807da9f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wxMlpTfx6Y67dM6L"/></div></div></figure><p id="7ace" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">Fig. 11. Percentile value 50.</em></p><p id="0bb0" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">We observe minor, acceptable accuracy loss related to DP.</p><h1 id="c71e" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">Lessons learned</h1><p id="b37d" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">Important lesson learned is that differential privacy outcomes are very sensitive to parameters of a given DP algorithm and it’s hard to tune it to avoid total collapse of model accuracy.</p><p id="5770" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Also, we experienced some kind of anxiety, based on the impression of not really really knowing how much privacy protection we have gained for what price. We only saw the “cost” side (accuracy degradation).</p><p id="d9d9" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">We had to rely to a major extent on known literature, that says and demonstrated, that even small amounts of DP-noise are helping to secure data.</p><p id="20d0" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">As engineers, we’d like to see some type of automatic measure that would prove how much privacy we gained for how much accuracy lost, and maybe even some kind of AutoDP tuning. Seems to be far, far away from the current state of technology and knowledge.</p><p id="9a94" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Then we applied privacy meters to see if there’s a visible difference between models without DP versus models with DP and we observed changes in the curve, but it’s really hard to quantify how much we gained.</p><p id="9ed3" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">Some algorithms didn’t work at all, some required many attempts to tune them properly to deliver viable results. There was no clear guidance on how to tune different parameters for particular dataset and ML models.</p><p id="dc63" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">So our current opinion is that DP for FL is hard, but totally feasible. It requires a lot of iterations, and trial and error loops to achieve acceptable results while believing in privacy improvements of orders of magnitude based on the trust in algorithms.</p><h1 id="2643" class="ns nt fq bf nu nv nw gq nx ny nz gt oa ob oc od oe of og oh oi oj ok ol om on bk">The future</h1><p id="c0e9" class="pw-post-body-paragraph mw mx fq my b go oo na nb gr op nd ne nf oq nh ni nj or nl nm nn os np nq nr fj bk">Federated learning is a great option to improve patients’ outcomes and treatment efficacy because of the improved ML models while preserving patients’ data.</p><p id="727d" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">But data protection never comes without any price and differential privacy for federated learning is a perfect example of that trade-off.</p><p id="e100" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">It’s great to see improvements in algorithms of differential privacy for federated learning scenarios to minimize the impact on accuracy while maximizing resilience of models against inference attacks.</p><p id="3428" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">As with all trade-offs the decisions have to be made balancing usefulness of models for practical applications against the risks of data leakage and reconstruction.</p><p id="941d" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">And that’s where our expectation for privacy meters are growing to know more precisely what we are selling and we are “buying”, what the exchange ratio is.</p><p id="c8f6" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">The landscape is dynamic, with better tools available for both those who want to better protect their data and those who are motivated to violate those rules and expose sensitive data.</p><p id="bf0b" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">We also invite other federated minds to build upon and contribute to the collective effort of advancing patient data privacy for Federated Learning.</p></div></div></div><div class="ab cb ph pi pj pk" role="separator"><span class="pl by bm pm pn po"/><span class="pl by bm pm pn po"/><span class="pl by bm pm pn"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="6345" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk">The author would like to thank <a class="af ot" href="https://www.linkedin.com/in/jacekchmiel/" rel="noopener ugc nofollow" target="_blank">Jacek Chmiel</a> for significant impact on the blog post itself, as well as the people who helped develop these ideas and bring them to practice: <a class="af ot" href="https://www.linkedin.com/in/jacekchmiel/" rel="noopener ugc nofollow" target="_blank">Jacek Chmiel</a>, <a class="af ot" href="https://www.linkedin.com/in/%C5%82ukasz-antczak-a3475910b/" rel="noopener ugc nofollow" target="_blank">Lukasz Antczak</a>, Grzegory Gajda and the Federated Open Science team at Roche.</p><p id="49b0" class="pw-post-body-paragraph mw mx fq my b go mz na nb gr nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr fj bk"><em class="ov">All images in this article were created by the authors.</em></p></div></div></div></div>    
</body>
</html>