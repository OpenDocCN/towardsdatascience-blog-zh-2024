<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Semantic Segmentation of Remote Sensing Imagery using k-Means</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Semantic Segmentation of Remote Sensing Imagery using k-Means</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/semantic-segmentation-of-remote-sensing-imagery-using-k-means-e4c165d9218e?source=collection_archive---------2-----------------------#2024-03-14">https://towardsdatascience.com/semantic-segmentation-of-remote-sensing-imagery-using-k-means-e4c165d9218e?source=collection_archive---------2-----------------------#2024-03-14</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="9711" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">From scratch in python🐍</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@alexroz?source=post_page---byline--e4c165d9218e--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Aleksei Rozanov" class="l ep by dd de cx" src="../Images/748b69bfaccf39c9aa568a9e6f41eec3.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*JISS93SvFnwE3NMNTl8HAQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e4c165d9218e--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@alexroz?source=post_page---byline--e4c165d9218e--------------------------------" rel="noopener follow">Aleksei Rozanov</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e4c165d9218e--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 14, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">4</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/904dc8dee478d11729c5abcd698f3412.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Up0V_ZIypuLZXdbKlhSsxw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="3278" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk nz"><span class="l oa ob oc bo od oe of og oh ed">O</span>ne of the most simple and genius ML models, in my opinion, is k-Means clustering. It relates to the group of unsupervised learning algorithms and is capable of finding patterns inside an unlabeled dataset. The most pleasant feature is that it lacks complicated math, and basically any high school student can successfully implement and use this method. So in this article I want to share how you can build k-Means algorithm from scratch in python using only <em class="oi">numpy</em> and <em class="oi">pandas</em> libraries and apply it to a real world problem — semantic segmentation of satellite imagery.</p><h2 id="82a3" class="oj ok fq bf ol om on oo op oq or os ot nm ou ov ow nq ox oy oz nu pa pb pc pd bk">Firstly, let’s talk about the data we have.</h2><p id="572a" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">In one of my previous articles, I talked about the problem of the Aral Sea shrinkage. As a result, we managed to get remote sensing imagery from MODIS using Google Earth Engine, which strongly indicates that the sea is drying. So I wondered, how can we estimate the change of the water surface between 2000 and 2023 using ML semantic segmentation? The answer is k-Means!</p><div class="pj pk pl pm pn po"><a href="https://medium.com/@alexroz/how-can-a-sea-disappear-case-study-of-the-aral-sea-using-python-and-modis-data-c59429cb73dd?source=post_page-----e4c165d9218e--------------------------------" rel="noopener follow" target="_blank"><div class="pp ab ig"><div class="pq ab co cb pr ps"><h2 class="bf fr hw z io pt iq ir pu it iv fp bk">How can a sea disappear? Case study of the Aral Sea using Python and MODIS data.</h2><div class="pv l"><h3 class="bf b hw z io pt iq ir pu it iv dx">Let’s create a timelapse and check if it’s true!</h3></div><div class="pw l"><p class="bf b dy z io pt iq ir pu it iv dx">medium.com</p></div></div><div class="px l"><div class="py l pz qa qb px qc lr po"/></div></div></a></div><p id="ed01" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Before diving into coding, let’s have a look at the data we are going to use in this tutorial. These are two RGB images of the same area with an interval of 23 years, however it’s clear that the land surface properties and atmospheric conditions (clouds, aerosols etc.) are different. That’s why I decided to train two separate k-Means models, one for each image.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qd"><img src="../Images/2cfcc0332a5f81c03112fc9ecc408c78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oh6lg2-JwR_EWjbVNJQL8Q.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><blockquote class="qe qf qg"><p id="a681" class="nd ne oi nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To follow up the tutorial, you can download and run the notebook <a class="af nc" href="https://github.com/alexxxroz/Medium/blob/main/Medium_k_Means.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="nf fr">here</strong></a>.</p></blockquote><p id="1641" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">First of all, let’s import the necessary libraries and upload the data to the notebook:</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="dba0" class="ql ok fq qi b bg qm qn l qo qp">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/><br/>img = mpimg.imread('MOD_01.jpg')<br/>img2 = mpimg.imread('MOD_24.jpg')</span></pre><p id="97c2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">You can see that the area covered by the images is quite large, so I suggest to zoom in a little:</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="ef71" class="ql ok fq qi b bg qm qn l qo qp">img = img[140:600,110:500,:]<br/>img2 = img2[140:600,110:500,:]<br/><br/>fig, ax = plt.subplots(ncols=2, figsize=(16,9))<br/>ax[0].imshow(img)<br/>ax[1].imshow(img2)<br/>for i in range(2):<br/>  ax[i].set_facecolor('black')<br/>  ax[i].set_xticks([])<br/>  ax[i].set_yticks([])<br/>ax[0].set_title('2000-08-01', fontsize=26)<br/>ax[1].set_title('2023-08-01', fontsize=26)<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qd"><img src="../Images/03b13a7e33bfb6dd16192ee0c087b008.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*035jZfpDbrgPUHkzXX3Q0w.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="5769" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And the last step before the ML phase, let’s convert our images to <em class="oi">pandas</em> dataframes (one column for each image channel). I do that for the sake of visibility of my explanations. If you want to get it optimized, it’s better to use <em class="oi">numpy</em> arrays instead.</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="e2ba" class="ql ok fq qi b bg qm qn l qo qp">df = pd.DataFrame({'R': img[:,:, 0].flatten(), 'G': img[:,:, 1].flatten(), 'B':img[:,:, 2].flatten()})<br/>df2 = pd.DataFrame({'R': img2[:,:, 0].flatten(), 'G': img2[:,:, 1].flatten(), 'B':img2[:,:, 2].flatten()})</span></pre><h1 id="ae93" class="qq ok fq bf ol qr qs gq op qt qu gt ot qv qw qx qy qz ra rb rc rd re rf rg rh bk">k-Means</h1><p id="32c9" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">So what is the idea behind the algorithm?</p><p id="a35e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Imagine that you judge about the taste of food using two criteria: sweetness and price. Keeping this in mind, I’ll give you a set of possible options to eat:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ri"><img src="../Images/3bd99b33a1a63713051e4885099ad0dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xqBqerLyYcz_uVJRnCcckQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="4480" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">I bet your brain has already split the options into three clusters: fruits, drinks and bakery. Basically, you unconsciously clustered the 2-dimensional data, which are defined by a pair of values — (sweetness; price).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ri"><img src="../Images/1003f1dda8b9e40cced2c3a901d42e22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ye03TsOhhyR1LKlFlSMkw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="28e3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In the case of<strong class="nf fr"> k-Means</strong>, the goal of the algorithm is quite similar — to find a <em class="oi">pre-set</em> number of cluster, <strong class="nf fr">k</strong>, in n-dimensional space (e.g. besides sweetness and price you want to account for nutrition, health, presence of the food in your fridge, and in this case, n = 5).</p><h1 id="5a85" class="qq ok fq bf ol qr qs gq op qt qu gt ot qv qw qx qy qz ra rb rc rd re rf rg rh bk">The algorithms includes the following stages:</h1><h2 id="1487" class="oj ok fq bf ol om on oo op oq or os ot nm ou ov ow nq ox oy oz nu pa pb pc pd bk">I. Define the number of clusters.</h2><p id="44e4" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">As I mentioned beforehand, <strong class="nf fr">k </strong>in k-Means is the number of clusters you want to get in the end, and you’re supposed to set this value <strong class="nf fr">before</strong> training the model.</p><h2 id="5ff7" class="oj ok fq bf ol om on oo op oq or os ot nm ou ov ow nq ox oy oz nu pa pb pc pd bk">II. Randomly initialize centroids.</h2><p id="739b" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">Centroid is an integral part of k-Means. Basically, centroid is a circle with a center, which is defined a set of coordinates, and each centroid represents a cluster. For instance, in our previous example there are 3 centroids.</p><h2 id="816d" class="oj ok fq bf ol om on oo op oq or os ot nm ou ov ow nq ox oy oz nu pa pb pc pd bk">III. Calculate distances and assign clusters.</h2><p id="8694" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">Now we need to find how far each point is from each centroid. Based on this calculations, we assign each point to the least distant centroid (cluster).</p><h2 id="40e7" class="oj ok fq bf ol om on oo op oq or os ot nm ou ov ow nq ox oy oz nu pa pb pc pd bk">IV. Calculate new centroids.</h2><p id="6338" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">Now each of our clusters contains at least one points, so it’s time to re-calculate the centroids simply by taking mean coordinates across all cluster points.</p><p id="81b8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And that’s it! We repeat steps 2–4 until centroids are not changing.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rj"><img src="../Images/e7c1dcf0ff1310e65cf999afb3f7c39c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*FNFdKRvsH8gggnXr9rTBKQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><h1 id="5d95" class="qq ok fq bf ol qr qs gq op qt qu gt ot qv qw qx qy qz ra rb rc rd re rf rg rh bk">Time To Code.</h1><p id="46a6" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">Now let’s wrap this really simple idea behind k-Means into python code.</p><blockquote class="qe qf qg"><p id="4e05" class="nd ne oi nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Reminder: in this task we have <strong class="nf fr">3D</strong> problem, i.e. our <strong class="nf fr">X</strong>, <strong class="nf fr">Y</strong> and <strong class="nf fr">Z</strong> are <strong class="nf fr">Red</strong>, <strong class="nf fr">Green</strong> and <strong class="nf fr">Blue</strong> image channels!</p></blockquote><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="761a" class="ql ok fq qi b bg qm qn l qo qp">def kmeans(data, K, kind):<br/>  L = list()<br/>  new_centroids = data.sample(K).values<br/><br/>  data = distance(data.copy(), new_centroids, kind)<br/>  old_centroids = new_centroids.copy()<br/>  new_centroids = np.array([data[data.Class == Class][['R', 'G', 'B']].mean().values for Class in data.loc[:,'C1':f'C{K}'].columns])<br/>  i = 1<br/>  print(f'Iteration: {i}\tDistance: {abs(new_centroids.mean()-old_centroids.mean())}')<br/>  while abs(new_centroids.mean()-old_centroids.mean())&gt;0.001:<br/>    L.append(abs(new_centroids.mean()-old_centroids.mean()))<br/>    data = distance(data, new_centroids, kind)<br/>    old_centroids = new_centroids.copy()<br/>    new_centroids = np.array([data[data.Class == Class][['R', 'G', 'B']].mean().values for Class in data.loc[:,'C1':f'C{K}'].columns])<br/>    i+=1<br/>    print(f'Iteration: {i}\tDistance: {abs(new_centroids.mean()-old_centroids.mean())}')<br/>  print(f"k-Means has ended with {i} iteratinons")<br/>  return data, L</span></pre><p id="f242" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">On the first stage we create a list <strong class="nf fr">L</strong> to collect all the distances between clusters to visualize them afterwards and randomly sample K points from the dataset to make them our centroids (or alternatively, you can assign random values to the centroids).</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="0d98" class="ql ok fq qi b bg qm qn l qo qp">L = list()<br/>new_centroids = data.sample(K).values</span></pre><p id="56ea" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now we need to calculate the distances between centroids and data points. There are lots of different distance metrics in Data Science, but let’s focus on the following ones — Euclidean, Manhattan, Chebyshev.</p><p id="7725" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For Euclidean distance:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rk"><img src="../Images/3b94c0589edc3248b5a6e9327a831cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*fBQuG1JuzWu2NjffI_BUWA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="7911" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For Manhattan:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rl"><img src="../Images/ab3ef1f64e041902d895fe4f4217963f.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*-7AglIREneL9vVQDO5v6PA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="2d4e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For Chebyshev:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rm"><img src="../Images/fcffdf977d6d12766b4d9f542421497f.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*trLp9cF7ZtofcBGeQjGR6A.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="3184" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To use this formulas, let’s write a versatile function for <strong class="nf fr">any</strong> number of dimensions:</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="f820" class="ql ok fq qi b bg qm qn l qo qp">def distance(data, centroids, kind):<br/>  #kind = euclidean, manhattan, chebyshev<br/>  #Here we add to the dataframe as many clusters C-ith as needed<br/>  cols=list()<br/>  for i in range(1,k+1):<br/>    if kind=='euclidean':<br/>      data[f'C{i}'] = ((centroids[i-1][0]-data.R)**2+(centroids[i-1][1]-data.G)**2+(centroids[i-1][2]-data.B)**2)**0.5<br/>    elif kind=='manhattan':<br/>      data[f'C{i}'] = abs(centroids[i-1][0]-data.R)+abs(centroids[i-1][1]-data.G)+abs(centroids[i-1][2]-data.B)<br/>    elif kind=='chebyshev':<br/>      merged=pd.concat([centroids[i-1][0]-data.R, centroids[i-1][1]-data.G, centroids[i-1][2]-data.B], axis=1)<br/>      data[f'C{i}'] = merged.max(axis=1)<br/>    cols.append(f'C{i}')<br/>  data['Class'] = data[cols].abs().idxmin(axis=1) #assigning clusters to points<br/>  return data #returning the dataframe with k cluster columns and one Class column with the final cluster</span></pre><p id="6c00" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">So now we can simply calculate distances and assign a cluster to each data point. Thus, our new centroids became old, so we store them in another variable and recalculate the new ones. To do that we iterate over each cluster and take a mean across all the coordinates (in our case, across RGB channels). Therefore, the variable new_centroids has a shape of <strong class="nf fr">(k,3)</strong>.</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="38d2" class="ql ok fq qi b bg qm qn l qo qp">data = distance(data.copy(), new_centroids, kind)<br/>old_centroids = new_centroids.copy()<br/>new_centroids = np.array([data[data.Class == Class][['R', 'G', 'B']].mean().values for Class in data.loc[:,'C1':f'C{K}'].columns])</span></pre><p id="e8ae" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Finally, we repeat all these steps until centroids’ coordinates don’t change anymore. I expressed this condition as this: the difference between average cluster coordinates should be less than 0.001. But you can play around with other numbers here.</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="2945" class="ql ok fq qi b bg qm qn l qo qp">while abs(new_centroids.mean()-old_centroids.mean())&gt;0.001:<br/>    L.append(abs(new_centroids.mean()-old_centroids.mean()))<br/>    data = distance(data, new_centroids, kind)<br/>    old_centroids = new_centroids.copy()<br/>    new_centroids = np.array([data[data.Class == Class][['R', 'G', 'B']].mean().values for Class in data.loc[:,'C1':f'C{K}'].columns])</span></pre><p id="d311" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And that’s it. The algorithm is ready to be trained! So let’s set k = 3 and store the results into dictionaries.</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="fc96" class="ql ok fq qi b bg qm qn l qo qp">k = 3<br/>segmented_1, segmented_2, distances_1, distances_2 = {}, {}, {}, {}<br/>segmented_1['euclidean'], distances_1['euclidean'] = kmeans(df, k, 'euclidean')<br/>segmented_2['euclidean'], distances_2['euclidean'] = kmeans(df2, k, 'euclidean')<br/>segmented_1['manhattan'], distances_1['manhattan'] = kmeans(df, k, 'manhattan')<br/>segmented_2['manhattan'], distances_2['manhattan'] = kmeans(df2, k, 'manhattan')<br/>segmented_1['chebyshev'], distances_1['chebyshev'] = kmeans(df, k, 'chebyshev')<br/>segmented_2['chebyshev'], distances_2['chebyshev'] = kmeans(df2, k, 'chebyshev')</span></pre><p id="9148" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">I decided to compare all the distance metrics for this particular task as you can see, and it’s evident that here Manhattan distance was the fastest.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rn"><img src="../Images/3bec8b58dce86ff8c83f8b20c27e9bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NKDJwPQZb03Bk0EfSiuDHA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="2220" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Before visualizing the clusters, let’s convert the clusters names into int type:</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="25e3" class="ql ok fq qi b bg qm qn l qo qp">d = {'C1':0, 'C2': 1, 'C3':2}<br/>for key in segmented_1.keys():<br/>  segmented_1[key].Class = segmented_1[key].Class.apply(lambda x: d[x])<br/>  segmented_2[key].Class = segmented_2[key].Class.apply(lambda x: d[x])</span></pre><p id="5b81" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Time make the final plots!</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="b191" class="ql ok fq qi b bg qm qn l qo qp">for key in segmented_1.keys():<br/>  fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(10,10))<br/>  ax[0, 0].imshow(img)<br/>  ax[0, 1].imshow(segmented_1[key].Class.values.reshape(460,390))<br/>  ax[0, 0].set_title('MOD09GA RGB', fontsize=18)<br/>  ax[0, 1].set_title(f'kMeans\n{key[0].upper()+key[1:]} Distance', fontsize=18)<br/><br/>  ax[1, 0].imshow(img2)<br/>  ax[1, 1].imshow(segmented_2[key].Class.values.reshape(460,390))<br/>  ax[1, 0].set_title('MOD09GA RGB', fontsize=18)<br/>  ax[1, 1].set_title(f'kMeans\n{key[0].upper()+key[1:]} Distance', fontsize=18)<br/><br/>  for i in range(2):<br/>    for j in range(2):<br/>      ax[i, j].set_facecolor('black')<br/>      ax[i, j].set_xticks([])<br/>      ax[i, j].set_yticks([])<br/><br/>  plt.savefig(f'{key}.png')<br/>  plt.tight_layout()<br/>  plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ro"><img src="../Images/b00aff5116c9cbab942e585d4252f441.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dtDvGwsws_jjhXBdXtQAxw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ro"><img src="../Images/492f7beda408d7069bb741e67a3163b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zkovtMPRn7KFI7M7W2_Ehg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ro"><img src="../Images/dfe919b855acb1e371c3bbe9e8bb4ee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lCLUWBMCmZEiI7grdXOTZQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="8c40" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">It’s not hard to see that Euclidean and Manhattan distance turned out be the most suitable for this particular task. But to make sure that it’s true, let’s evaluate the k-Means clustering results using the Silhouette Coefficient. This metric is perfect for training results assessment when there are no labeled true values for the clustered points.</p><p id="f08c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To calculate it we will use <em class="oi">sklearn</em> function <a class="af nc" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score" rel="noopener ugc nofollow" target="_blank">[1]</a>.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rp"><img src="../Images/ac04245c27d5fd1d3c6482d2a748d9a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*6_J0OL_JUKED2gG22TNCtw.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score" rel="noopener ugc nofollow" target="_blank">sklearn</a>.</figcaption></figure><ul class=""><li id="01a5" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny rq rr rs bk"><strong class="nf fr">a — </strong>the mean distance between a sample and all other points in the same class.</li><li id="4617" class="nd ne fq nf b go rt nh ni gr ru nk nl nm rv no np nq rw ns nt nu rx nw nx ny rq rr rs bk"><strong class="nf fr">b — </strong>the mean distance between a sample and all other points in the <em class="oi">next nearest cluster</em>.</li></ul><p id="10d0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The range of values of the Silhouette Coefficient is [-1,1]. And yep, it’s computationally expensive, as you need to calculate distances between thousands of point several times, so be ready to wait.</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="5a0b" class="ql ok fq qi b bg qm qn l qo qp">scores_1, scores_2 = {}, {}<br/>for key in segmented_1.keys(): #key is a metric for the distance estimation<br/>  scores_1[key]=round(silhouette_score(segmented_1[key].loc[:, :'C3'], segmented_1[key].Class, metric=key),2)<br/>  scores_2[key]=round(silhouette_score(segmented_2[key].loc[:, :'C3'], segmented_2[key].Class, metric=key),2)<br/>  print(f'Distance: {key}\t Img 1: {scores_1[key]}\t Img 2: {scores_2[key]}')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ry"><img src="../Images/11dad952095ba1c10b5e3f8be1e2cc4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*YwBFjv7cjt-64BfxmdGGkQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="c758" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now you can see that we proved it: Euclidean and Manhattan distances have similarly good performance, so let’s estimate the water surface area loss, using both of them.</p><pre class="mm mn mo mp mq qh qi qj bp qk bb bk"><span id="bacd" class="ql ok fq qi b bg qm qn l qo qp">for metric, Class in zip(['euclidean', 'manhattan'], [2,1]):<br/>  img1_water = np.count_nonzero(segmented_1[metric].Class.values == Class)*500*500*1e-6 #pixel size is 500, so the area is 500*500 and to convert to km2 * 1e-6<br/>  img2_water = np.count_nonzero(segmented_2[metric].Class.values == Class)*500*500*1e-6<br/><br/>  print(f'Distance: {metric}\tWater Area Before: {round(img1_water)}km\u00b2\tWater Area After: {round(img2_water)}km\u00b2\tChange: -{100-round(img2_water/img1_water*100)}%')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rz"><img src="../Images/3eb0a222f2765449872f20b68e294596.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*62fSpItiNuNcIvqrp6cJQg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="e59e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">— — — —</p><p id="da7c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Distance: euclidean <br/>Water Area Before: 17125 km² <br/>Water Area After: 1960 km² <br/>Change: -89%</p><p id="e322" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">— — — — —</p><p id="2ad5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Distance: manhattan<br/>Water Area Before: 16244 km² <br/>Water Area After: 2003 km² <br/>Change: -88%</p><p id="7fdc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As you can see, according to our clustering results, the change in water surface area is almost <strong class="nf fr">90% (!!!) water loss </strong>over last 23 years, which is real proof of the fact that the Aral Sea shrinkage is a planetary tragedy…</p><p id="f6d9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">===========================================</p><p id="40c0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Reference:</strong></p><p id="d1bd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[1] <a class="af nc" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score</a></p><p id="91e6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">===========================================</p><p id="991f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr"><em class="oi">All my publications on Medium are free and open-access, that’s why I’d really appreciate if you followed me here!</em></strong></p><p id="22a6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">P.s. I’m extremely passionate about (Geo)Data Science, ML/AI and Climate Change. So if you want to work together on some project pls contact me in <a class="af nc" href="https://www.linkedin.com/in/alexxxroz/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>.</p><p id="623f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">🛰️Follow for more🛰️</p></div></div></div></div>    
</body>
</html>