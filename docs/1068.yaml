- en: Towards Infinite LLM Context Windows
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朝向无限LLM上下文窗口
- en: 原文：[https://towardsdatascience.com/towards-infinite-llm-context-windows-e099225abaaf?source=collection_archive---------0-----------------------#2024-04-28](https://towardsdatascience.com/towards-infinite-llm-context-windows-e099225abaaf?source=collection_archive---------0-----------------------#2024-04-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/towards-infinite-llm-context-windows-e099225abaaf?source=collection_archive---------0-----------------------#2024-04-28](https://towardsdatascience.com/towards-infinite-llm-context-windows-e099225abaaf?source=collection_archive---------0-----------------------#2024-04-28)
- en: It all started with GPT having an input context window of 512 tokens. After
    only 5 years the newest LLMs are capable of handling 1M+ context inputs. Where’s
    the limit?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一切始于GPT具有512个标记的输入上下文窗口。仅仅五年后，最新的LLM已经能够处理超过100万个上下文输入。那么，极限在哪里呢？
- en: '[](https://medium.com/@krzysztof.kornel?source=post_page---byline--e099225abaaf--------------------------------)[![Krzysztof
    K. Zdeb](../Images/4531b37707bf6a01ef635e4b9ecfc03f.png)](https://medium.com/@krzysztof.kornel?source=post_page---byline--e099225abaaf--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e099225abaaf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e099225abaaf--------------------------------)
    [Krzysztof K. Zdeb](https://medium.com/@krzysztof.kornel?source=post_page---byline--e099225abaaf--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@krzysztof.kornel?source=post_page---byline--e099225abaaf--------------------------------)[![Krzysztof
    K. Zdeb](../Images/4531b37707bf6a01ef635e4b9ecfc03f.png)](https://medium.com/@krzysztof.kornel?source=post_page---byline--e099225abaaf--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e099225abaaf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e099225abaaf--------------------------------)
    [Krzysztof K. Zdeb](https://medium.com/@krzysztof.kornel?source=post_page---byline--e099225abaaf--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e099225abaaf--------------------------------)
    ·9 min read·Apr 28, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e099225abaaf--------------------------------)
    ·阅读时间9分钟·2024年4月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/991696e8052dfe143c32539a274be31a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/991696e8052dfe143c32539a274be31a.png)'
- en: I like to think of the **LLMs** (specifically, of the models’ parameters, i.e.,
    their weights of the neural network layers and weights of the attention mechanisms)
    as a vast memory bank filled with a wide range of information about the world
    mixed with linguistic knowledge on how to process text. It’s like static knowledge
    it has once learned during the model pre-training and (optionally) fine-tuning;
    a common core reusable by all conversations with the model, no matter who asks
    the questions. The **input context**, on the other hand, is where the magic happens.
    It’s like passing a note to the model with special instructions or information.
    This can be anything from a question we want answered to unique information we
    have or even a history of past chats we’ve had with it. It’s a way of giving the
    model a personal memory.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢将**LLMs**（具体来说，是模型的参数，即神经网络层的权重和注意力机制的权重）看作是一个庞大的记忆库，里面包含了关于世界的各种信息，并且混合了如何处理文本的语言知识。这就像是模型在预训练过程中学习到的静态知识，（可选地）经过微调后，形成了一个可以在所有与模型的对话中重用的公共核心，无论是谁提出问题。另一方面，**输入上下文**则是魔法发生的地方。它就像是向模型传递一条带有特殊指令或信息的便条。这可以是我们希望模型回答的问题，也可以是我们拥有的独特信息，甚至是我们与模型之前对话的历史。这是一种给模型提供个人记忆的方式。
- en: Evolution of Context Size
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上下文大小的演变
- en: One of the key characteristics of an LLM is its input context size. It can be
    defined as the number of words (or [**tokens**](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them),
    to be precise) that a language model takes into consideration when generating
    a…
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '一个LLM的关键特性之一是它的输入上下文大小。它可以定义为语言模型在生成时考虑的单词数量（或者更准确地说，是[**标记**](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)）。  '
