- en: 'A Weekend AI Project: Running LLaMA and Gemma AI Models on the Android Phone'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-weekend-ai-project-running-llama-and-gemma-ai-models-on-the-android-phone-47a261d257a7?source=collection_archive---------6-----------------------#2024-03-09](https://towardsdatascience.com/a-weekend-ai-project-running-llama-and-gemma-ai-models-on-the-android-phone-47a261d257a7?source=collection_archive---------6-----------------------#2024-03-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Running LLaMA and Gemma LLMs with C++ and Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://dmitryelj.medium.com/?source=post_page---byline--47a261d257a7--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--47a261d257a7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--47a261d257a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--47a261d257a7--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--47a261d257a7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--47a261d257a7--------------------------------)
    ·7 min read·Mar 9, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b7dee53944f0c0f84ecbb551767801a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Magnet.me, [Unsplash](https://unsplash.com/@magnetme)
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, “mobile AI” is a fast-growing trend. Smartphones become more powerful,
    and large models become more efficient. Some customers may want to wait until
    new features are added by phone manufacturers, but can we use the latest AI models
    on our own? Indeed, we can, and the results are fun. In this article, I will show
    how to run LLaMA and Gemma large language models on an Android phone, and we will
    see how it works. As usual in all my tests, all models will run locally, and no
    cloud APIs or payments are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get into it!
  prefs: []
  type: TYPE_NORMAL
- en: Termux
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first component of our test is [Termux](https://wiki.termux.com/wiki/Main_Page),
    a full-fledged Linux terminal made as an Android application. It is free, and
    it does not require root access; all Linux components are running exclusively
    in a Termux folder. Termux can be downloaded from [Google Play](https://play.google.com/store/apps/details?id=com.termux),
    but at the time of writing this text, that version was pretty old, and the “pkg
    update” command in Termux did not work anymore. A newer version is available as
    an APK on the [F-Droid](https://f-droid.org/en/packages/com.termux/) website;
    it works well, and I had no problems with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'When Termux is installed on the phone, we can run it and see a standard Linux
    command-line interface:'
  prefs: []
  type: TYPE_NORMAL
