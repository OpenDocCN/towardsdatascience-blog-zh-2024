- en: 'Through the Uncanny Mirror: Do LLMs Remember Like the Human Mind?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过那面神秘的镜子：LLMs是否像人类大脑一样记忆？
- en: 原文：[https://towardsdatascience.com/through-the-uncanny-mirror-do-llms-remember-like-the-human-mind-cc9c63677610?source=collection_archive---------7-----------------------#2024-09-19](https://towardsdatascience.com/through-the-uncanny-mirror-do-llms-remember-like-the-human-mind-cc9c63677610?source=collection_archive---------7-----------------------#2024-09-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/through-the-uncanny-mirror-do-llms-remember-like-the-human-mind-cc9c63677610?source=collection_archive---------7-----------------------#2024-09-19](https://towardsdatascience.com/through-the-uncanny-mirror-do-llms-remember-like-the-human-mind-cc9c63677610?source=collection_archive---------7-----------------------#2024-09-19)
- en: '|LLM|AI|HUMAN MIND|MEMORY|COGNITION|'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '|LLM|人工智能|人类大脑|记忆|认知|'
- en: Exploring the Eerie Parallels and Profound Differences Between AI and Human
    Memory
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索人工智能与人类记忆之间的神秘相似与深刻差异
- en: '[](https://salvatore-raieli.medium.com/?source=post_page---byline--cc9c63677610--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page---byline--cc9c63677610--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--cc9c63677610--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--cc9c63677610--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--cc9c63677610--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://salvatore-raieli.medium.com/?source=post_page---byline--cc9c63677610--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page---byline--cc9c63677610--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--cc9c63677610--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--cc9c63677610--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--cc9c63677610--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--cc9c63677610--------------------------------)
    ·10 min read·Sep 19, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--cc9c63677610--------------------------------)
    ·阅读时间10分钟·2024年9月19日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/60a5523343be60b49897ceca8b28f392.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/60a5523343be60b49897ceca8b28f392.png)'
- en: image by the author using DALL-E
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者使用DALL-E创作的图像
- en: '**The limits of my language** are **the limits of my** mind. — Ludwig Wittgenstein'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**我的语言的界限**就是**我的**思想的界限。— 路德维希·维特根斯坦'
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The true art of memory is the art of attention. — Samuel Johnson
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 记忆的真正艺术是专注的艺术。— 塞缪尔·约翰逊
- en: '[Language](https://en.wikipedia.org/wiki/Language) is one of the most important
    capabilities of human beings; it enables us to communicate and transfer knowledge,
    and it is considered a pillar of civilization. That is why the incredible capabilities
    displayed by [Large Language Models (LLMs)](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20is%20a%20Large%20Language%20Model%20(LLM)%3F)
    have astounded the world, and made it ask the question: are they intelligent?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[语言](https://en.wikipedia.org/wiki/Language)是人类最重要的能力之一；它使我们能够沟通和传递知识，并被视为文明的支柱。这就是为什么[大型语言模型（LLMs）](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20is%20a%20Large%20Language%20Model%20(LLM)%3F)所展现的惊人能力让世界震惊，并使人们提出了一个问题：它们是否具有智能？'
- en: 'All this has been achieved by huge amounts of text and a simple learning function:
    predicting the next word in a sequence. The model behind this success is the [Transformer](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)),
    and today modern derived LLMs are currently used by a large segment of the population
    for tasks such as translation, summarization, question answering, or generating
    articles.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是通过大量的文本和一个简单的学习功能实现的：预测序列中的下一个词。支撑这一成功的模型是[Transformer](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture))，如今现代衍生的LLM正在被大量用户用于翻译、摘要、问答或生成文章等任务。
