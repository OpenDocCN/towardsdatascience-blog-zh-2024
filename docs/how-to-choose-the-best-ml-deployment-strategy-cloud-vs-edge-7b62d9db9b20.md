# 如何选择最佳的机器学习部署策略：云端 vs. 边缘

> 原文：[https://towardsdatascience.com/how-to-choose-the-best-ml-deployment-strategy-cloud-vs-edge-7b62d9db9b20?source=collection_archive---------3-----------------------#2024-10-14](https://towardsdatascience.com/how-to-choose-the-best-ml-deployment-strategy-cloud-vs-edge-7b62d9db9b20?source=collection_archive---------3-----------------------#2024-10-14)

## 选择云端还是边缘部署可能决定了你的项目成败

[](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)[![Vincent Vandenbussche](../Images/b2febfc63ca0efbda0af5501f6080ab7.png)](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------) [Vincent Vandenbussche](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------) ·14分钟阅读·2024年10月14日

--

![](../Images/670dca37200cce7a7304957e014758b6.png)

照片由[Jakob Owens](https://unsplash.com/@jakobowens1?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

作为一名机器学习工程师，我经常看到社交媒体上的讨论强调部署机器学习模型的重要性。我完全同意——模型部署是 MLOps 的关键组成部分。随着机器学习的普及，对可扩展且高效的部署方法的需求日益增加，但具体方法往往仍不明确。

那么，这是否意味着模型部署在任何情况下都是相同的呢？事实上，正好相反：我已经部署机器学习模型大约十年了，在不同项目之间，部署的方式可能差异很大。部署机器学习模型有很多种方式，拥有一种方法的经验并不意味着你对其他方法也足够熟练。

剩下的问题是：**部署机器学习模型的方法有哪些**，以及**我们如何选择合适的方法**？

模型可以通过多种方式进行部署，但通常可以分为两大类：

+   云端部署

+   边缘部署

这听起来可能很简单，但实际上有一个陷阱。对于这两大类部署，实际上还有很多子类别。以下是我们将在本文中探讨的一个非详尽的部署图示：

![](../Images/70f0d9d6cbcae7b724cde834f082013a.png)

本文中探讨的部署子类别图示。图像来自作者。

在谈论如何选择合适的方法之前，**让我们探索一下每个类别：它是什么，优点，缺点，典型的技术栈，我还将分享一些我在这个背景下做的部署的个人示例**。让我们深入了解！

# 云部署

从我所见，云部署似乎是迄今为止 **在 ML 部署中最受欢迎的选择**。这通常是部署模型时需要掌握的内容。但云部署通常意味着以下几种方式之一，具体取决于上下文：

+   API 部署

+   无服务器部署

+   批量处理

即使在这些子类别中，可能还会有另一个层次的分类，但我们在这篇文章中不会探讨那么深入。让我们看看它们的含义、优缺点以及典型的技术栈。

## API 部署

API 代表应用程序编程接口。这是一种在云中部署模型的非常流行的方式。许多流行的机器学习模型都是作为 API 部署的：例如，Google Maps 和 OpenAI 的 ChatGPT 都可以通过它们的 API 进行查询。

如果你不熟悉 API，了解它通常是通过简单的查询调用的。例如，在终端中输入以下命令来获取前 20 个宝可梦的名字：

```py
curl -X GET https://pokeapi.co/api/v2/pokemon
```

在幕后，当调用一个 API 时，实际发生的可能更为复杂。API 部署通常涉及包括负载均衡器、自动扩展器和与数据库交互的标准技术栈：

![](../Images/e6dd59aa3082e1c70e16efd4f871e817.png)

这是在云基础设施中进行 API 部署的典型示例。图片由作者提供。

*备注：API 可能有不同的需求和基础设施，本文中的示例已简化以便于理解。*

API 部署因几个原因而流行：

+   易于实现并集成到各种技术栈中

+   它易于扩展：使用云中的横向扩展可以高效地进行扩展；此外，云提供商的托管服务可能减少手动干预的需求。

+   它允许集中管理模型版本和日志，从而实现高效的跟踪和可重现性。

虽然 API 是一个非常流行的选择，但它也有一些缺点：

+   可能会面临延迟问题，特别是由于潜在的网络开销或地理距离；当然，这也需要一个良好的互联网连接。

+   对于高流量，成本可能会迅速攀升（假设自动扩展）。

+   维护开销可能会变得很昂贵，无论是托管服务的费用还是基础设施团队的成本。

总结来说，**API 部署在许多初创公司和技术公司中被广泛使用**，**因为它的灵活性**和较短的市场投入时间。然而，**对于高流量，成本可能会迅速上升**，维护成本也可能相当高。

关于技术栈：开发API有很多方式，但在机器学习中最常见的可能是[FastAPI](https://fastapi.tiangolo.com/)和[Flask](https://flask.palletsprojects.com/en/3.0.x/)。然后，它们可以通过docker镜像非常容易地部署到主要的云提供商（AWS、GCP、Azure等）。可以通过托管服务或Kubernetes进行编排，具体取决于团队的选择、规模和技能。

作为一个API云部署的例子，我曾经为一个面向客户的网页应用部署了一个机器学习解决方案，用来自动化电动汽车充电站的定价。如果你想了解更多，可以在这里查看这个项目：

[如何利用机器学习助力雷诺提升电动汽车销售](https://pub.towardsai.net/how-renault-leveraged-machine-learning-to-scale-electric-vehicles-sales-4f42bee34a12?source=post_page-----7b62d9db9b20--------------------------------)

### 我如何在几个月内构建并部署一个基于机器学习的解决方案，帮助雷诺扩大电动汽车的销售……

[pub.towardsai.net](https://pub.towardsai.net/how-renault-leveraged-machine-learning-to-scale-electric-vehicles-sales-4f42bee34a12?source=post_page-----7b62d9db9b20--------------------------------)

即使这篇文章没有涉及代码，它也能让你对API部署能做些什么有一个很好的了解。

API部署因其易于集成到任何项目中而非常流行。但有些项目可能需要更多的灵活性和更低的维护成本：这时无服务器部署可能是一种解决方案。

## 无服务器部署

另一个受欢迎但可能使用较少的选项是无服务器部署。无服务器计算意味着**你运行你的模型**（或者实际上是任何代码）**无需拥有或配置任何服务器**。

无服务器部署提供了几个显著的优势，并且非常容易设置：

+   无需管理或维护服务器。

+   不需要处理高流量情况下的扩展问题。

+   你只需为使用的部分付费：没有流量意味着几乎没有成本，因此没有任何开销。

但它也有一些局限性：

+   与托管API相比，它通常不适用于大量查询时的成本效益。

+   冷启动延迟是一个潜在问题，因为服务器可能需要启动，从而导致延迟。

+   内存占用通常是按设计限制的：你不能总是运行大型模型。

+   执行时间也有限：不可能运行超过几分钟的任务（例如AWS Lambda限制为15分钟）。

总的来说，我认为无服务器部署是一个**在你启动新项目时，流量不大且不想在基础设施管理上花费太多的好选择**。

所有主要的云提供商都以不同的名称提供无服务器计算：最受欢迎的有[AWS Lambda](https://aws.amazon.com/lambda/)、[Azure Functions](https://azure.microsoft.com/en-us/products/functions/)和[Google Cloud Functions](https://cloud.google.com/functions)。

就我个人而言，我从未部署过无服务器解决方案（由于我主要从事深度学习工作，通常会受到上述无服务器限制的制约），但有很多文档可以帮助你正确地进行部署，例如[AWS的这篇文章](https://aws.amazon.com/blogs/compute/deploying-machine-learning-models-with-serverless-templates/)。

虽然无服务器部署提供了一种灵活的按需解决方案，但某些应用可能需要更有计划的方法，比如批处理。

## 批处理

另一种在云上部署的方式是通过定时批处理。虽然无服务器架构和API通常用于实时预测，但在某些情况下，批量预测更有意义。

无论是数据库更新、仪表盘更新、缓存预测……只要**没有实时预测的需求，批处理通常是最好的选择**：

+   处理大批量数据比实时处理更具资源效率，且能够减少开销。

+   处理可以安排在非高峰时段进行，从而减少总体负载，进而降低成本。

当然，这也有其相关的缺点：

+   批处理会导致资源使用激增，如果没有适当的规划，可能会导致系统超载。

+   错误处理在批处理过程中至关重要，因为你需要一次性优雅地处理整个批次。

**对于任何不需要实时结果的任务，都应该考虑批处理**：通常它更加具有成本效益。但当然，对于任何实时应用，它并不是一个可行的选择。

它在许多公司中得到了广泛应用，主要是在ETL（提取、转换、加载）管道中，这些管道可能包含机器学习，也可能不包含。以下是一些最流行的工具：

+   Apache Airflow，用于工作流编排和任务调度

+   Apache Spark，用于快速、大规模数据处理

作为批处理的一个例子，我曾经从事YouTube视频收入预测的工作。根据视频收入的初始数据点，我们会预测未来最多5年的收入，使用多目标回归和曲线拟合：

![](../Images/5e891c0b723fb52a7b5e9269012dfedd.png)

表示初始数据、多目标回归预测和曲线拟合的图表。图像来源：作者。

对于这个项目，我们需要每月重新进行所有数据的重新预测，以确保我们的初始预测与最新预测之间没有偏差。为此，我们使用了托管的Airflow，每月会自动根据最新的数据触发新的预测，并将这些数据存储到我们的数据库中。如果你想了解更多关于这个项目的信息，可以查看这篇文章：

[## 如何预测YouTube视频收入](https://medium.datadriveninvestor.com/how-to-forecast-youtube-video-revenue-e35c60bd1105?source=post_page-----7b62d9db9b20--------------------------------)

### 该方法在对数十个YouTuber的收入预测中取得了低于6%的错误率

[medium.datadriveninvestor.com](https://medium.datadriveninvestor.com/how-to-forecast-youtube-video-revenue-e35c60bd1105?source=post_page-----7b62d9db9b20--------------------------------)

在探索了用于云部署的各种策略和工具后，显然这种方法提供了显著的灵活性和可扩展性。然而，云部署并不总是每个机器学习应用的最佳选择，特别是当实时处理、隐私问题或财务资源限制成为因素时。

![](../Images/578ee44791128a7decddea53afe8da55.png)

云部署的优缺点列表。图片由作者提供。

这就是边缘部署作为一种可行选项的焦点所在。让我们现在深入了解边缘部署，看看什么时候它可能是最佳选择。

# 边缘部署

根据我自己的经验，边缘部署很少被视为主要的部署方式。几年前，连我自己也认为它并不是一个真正有趣的部署选项。但现在通过更多的视角和经验，我认为**它必须在任何可以的情况下作为首选部署方式**。

就像云部署一样，边缘部署涵盖了广泛的应用场景：

+   原生手机应用

+   网络应用

+   边缘服务器和特定设备

虽然它们都具有一些相似的特性，例如资源有限和水平扩展的限制，但每种部署选择可能都有其独特的特点。让我们来看看。

## 原生应用

我们现在看到越来越多的智能手机应用集成了AI，未来这种趋势可能会进一步增长。虽然一些大科技公司如OpenAI或谷歌为他们的大型语言模型（LLM）选择了API部署方式，但苹果目前正在通过像[OpenELM](https://machinelearning.apple.com/research/openelm)这样的解决方案，专注于iOS应用部署模型，这是一种小型LLM。实际上，这种方式有几个优点：

+   基础设施成本几乎为零：无需维护云端，一切都在设备上运行

+   更好的隐私：你不需要将任何数据发送到API，所有计算都可以在本地完成

+   你的模型直接集成到你的应用中，无需维护多个代码库

*此外，苹果为iOS上的模型部署打造了一个极好的生态系统：你可以在他们的Apple芯片（如M1、M2等）上高效运行机器学习模型，并利用神经引擎进行非常快速的推理。据我所知，安卓略微落后，但也有一个出色的生态系统。*

虽然在许多情况下这可能是一个非常有益的方法，但仍然存在一些限制：

+   手机资源限制了模型的大小和性能，并且这些资源与其他应用共享

+   重型模型可能会很快消耗电池，这可能会对用户体验产生误导性影响

+   设备碎片化，以及iOS和Android应用使得覆盖整个市场变得困难

+   与云部署相比，去中心化的模型更新可能会更加具有挑战性

尽管存在一些缺点，但原生应用部署通常是针对在应用中运行的机器学习解决方案的一个强有力的选择。**在开发阶段看起来可能更复杂**，但一旦部署，相比云部署，它将**便宜得多**。

在技术栈方面，实际上有两种主要的部署方式：iOS和Android。它们各自有自己的栈，但共享相同的属性：

+   应用开发：iOS使用Swift，Android使用Kotlin

+   模型格式：iOS使用Core ML，Android使用TensorFlow Lite

+   硬件加速器：iOS的Apple Neural Engine，Android的Neural Network API

*注意：这只是对技术栈的简化描述。这个不完全的概述旨在覆盖要点，并让你如果有兴趣，可以进一步深入了解。*

作为这种部署的个人例子，我曾经参与过一个Android平台的图书阅读应用，在这个应用中，他们希望让用户通过手机的运动来浏览书籍。例如，左摇动手机翻到上一页，右摇动翻到下一页，其他特定的动作执行特定的命令。为此，我训练了一个模型，使用手机加速度计的特征来识别运动，并且使用了一个相对较小的模型。然后，这个模型直接作为TensorFlow Lite模型部署到应用中。

原生应用具有强大的优势，但仅限于一种类型的设备，例如在笔记本电脑上无法运行。Web应用可以克服这些局限。

## Web应用

Web应用部署意味着在客户端运行模型。基本上，它意味着**在浏览器使用的设备上运行模型推理**，无论是平板电脑、智能手机还是笔记本电脑（等等）。这种部署方式非常方便：

+   你的部署可以在任何能够运行Web浏览器的设备上工作

+   推理成本几乎为零：无需服务器，无需维护基础设施……只需要客户的设备

+   所有设备只需一个代码库：无需同时维护iOS应用和Android应用

*注意：在服务器端运行模型将等同于上面提到的云部署选项之一。*

虽然Web部署提供了诱人的好处，但它也有显著的局限性：

+   使用TensorFlow.js时，合理利用资源，尤其是GPU推理，可能会面临挑战

+   你的Web应用必须能够在所有设备和浏览器上运行：无论是否有GPU，使用Safari还是Chrome，是否有Apple M1芯片等等……这可能是一个很重的负担，且维护成本较高

+   你可能需要为较慢和较老的设备准备一个备份方案：如果设备太慢而无法处理你的模型怎么办？

*与原生应用不同，模型没有官方的大小限制。然而，较小的模型下载速度更快，整体体验也更加流畅，因此应该优先考虑。而且一个非常大的模型可能根本无法正常工作。*

总结来说，虽然网页部署功能强大，但它有显著的局限性，必须谨慎使用。另一个优点是，它可能是我未提及的另一种部署方式的入口：微信小程序。

技术栈通常与网页开发相同：HTML、CSS、JavaScript（以及你想要的任何框架），当然还有用于模型部署的TensorFlow Lite。如果你对如何在浏览器中部署机器学习感兴趣，可以看看这篇文章，我从零开始在浏览器中运行了一个实时人脸识别模型：

[](/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75?source=post_page-----7b62d9db9b20--------------------------------) [## BlazeFace：如何在浏览器中运行实时物体检测

### BlazeFace模型训练的逐步指南，从Python训练管道到JavaScript演示，详细介绍了整个过程……

[towardsdatascience.com](/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75?source=post_page-----7b62d9db9b20--------------------------------)

本文从PyTorch中的模型训练讲起，最终实现了一个可工作的网页应用，可能对这种特定类型的部署有所启发。

在某些情况下，原生应用和网页应用都不是可行的选择：我们可能没有合适的设备，无法联网，或者受到其他限制。这时，边缘服务器和特定设备就派上了用场。

## 边缘服务器和特定设备

除了原生应用和网页应用，边缘部署还包括其他情况：

+   在边缘服务器上的部署：在某些情况下，会有本地服务器运行模型，例如某些工厂生产线、CCTV等…由于隐私要求，这种解决方案有时是唯一可用的。

+   在特定设备上的部署：无论是传感器、微控制器、智能手表、耳塞、自动驾驶汽车等，都可能内部运行机器学习模型。

在边缘服务器上的部署可以与云端API部署非常接近，技术栈也可能非常相似。

*备注：也可以在边缘服务器上运行批处理，或者使用一个单一的脚本来完成所有任务。*

但在特定设备上的部署可能涉及使用[FPGA](https://en.wikipedia.org/wiki/Field-programmable_gate_array)或低级语言。这是另一种完全不同的技能集，针对每种设备类型可能有所不同。这个领域有时被称为TinyML，是一个非常有趣且不断发展的话题。

在这两种情况下，它们面临与其他边缘部署方法相同的一些挑战：

+   资源有限，通常无法进行横向扩展。

+   电池可能是一个限制因素，模型大小和内存占用也是如此。

即使有这些限制和挑战，在某些情况下，它仍然是唯一可行的解决方案，或者是最具成本效益的方案。

我曾为一家公司做过一个边缘服务器部署示例，该公司希望自动检查快餐店订单的有效性。一个俯视的摄像头会观察平台，使用计算机视觉和物体检测技术将摄像头看到的内容与实际订单进行对比，在发现不匹配时发出警报。由于某些原因，该公司希望将此系统部署在快餐店内部的边缘服务器上。

总结一下，以下是主要的部署类型及其优缺点：

![](../Images/03465e3c6a42058a4aafcc2c9d2269fc.png)

云部署的优缺点列表。图片来自作者。

鉴于此，**如何实际选择合适的部署方式？**这个问题没有单一的答案，但让我们尝试在下一节给出一些规则，以便简化选择过程。

# 如何选择合适的部署方式

在得出结论之前，让我们制作一个决策树，帮助你选择最适合的解决方案。

选择合适的部署方式需要理解具体的需求和限制，通常需要与利益相关者进行讨论。记住，每个案例都是特定的，可能是一个边缘案例。但在下面的图表中，我试图概括出最常见的情况，帮助你做出决策：

![](../Images/6f7ccb5214d4bfecc3380b38a08cf0ea.png)

部署决策图。请注意，每个使用场景都是特定的。图片来自作者。

这个图表虽然相当简化，但可以归结为几个问题，帮助你走向正确的方向：

+   你需要实时处理吗？如果不需要，首先考虑批处理；如果需要，请考虑边缘部署

+   你的解决方案是运行在手机上还是在网页上？在可能的情况下，探索这些部署方式

+   处理过程是否相当复杂且繁重？如果是，请考虑云部署

再次强调，这虽然很简单，但在许多情况下非常有帮助。同时，请注意，为了清晰起见，省略了一些问题，但在某些情况下，它们实际上非常重要：你有隐私限制吗？你有连接性限制吗？你团队的技能如何？

根据使用场景，可能还会出现其他问题；随着经验的积累和对你生态系统的了解，这些问题会变得越来越自然。但希望这些内容能帮助你更轻松地进行机器学习模型的部署。

# 结论和最终思考

尽管云部署通常是机器学习模型的默认选择，但边缘部署可以提供显著的优势：成本效益和更好的隐私控制。尽管处理能力、内存和能源约束等挑战存在，但我相信边缘部署在许多情况下都是一个值得考虑的选项。最终，最佳的部署策略应该与您的业务目标、资源限制和具体需求相契合。

如果你读到这里，我很想听听你在项目中使用过的部署方法的看法。
