- en: Deploy Models with AWS SageMaker Endpoints — Step-by-Step Implementation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AWS SageMaker端点部署模型——逐步实现
- en: 原文：[https://towardsdatascience.com/deploy-models-with-aws-sagemaker-endpoints-step-by-step-implementation-1700316afd1d?source=collection_archive---------14-----------------------#2024-08-30](https://towardsdatascience.com/deploy-models-with-aws-sagemaker-endpoints-step-by-step-implementation-1700316afd1d?source=collection_archive---------14-----------------------#2024-08-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deploy-models-with-aws-sagemaker-endpoints-step-by-step-implementation-1700316afd1d?source=collection_archive---------14-----------------------#2024-08-30](https://towardsdatascience.com/deploy-models-with-aws-sagemaker-endpoints-step-by-step-implementation-1700316afd1d?source=collection_archive---------14-----------------------#2024-08-30)
- en: A 4-step tutorial on creating a SageMaker endpoint and calling it.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这是一个关于创建SageMaker端点并调用它的四步教程。
- en: '[](https://medium.com/@fmnobar?source=post_page---byline--1700316afd1d--------------------------------)[![Farzad
    Nobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page---byline--1700316afd1d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1700316afd1d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1700316afd1d--------------------------------)
    [Farzad Nobar](https://medium.com/@fmnobar?source=post_page---byline--1700316afd1d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fmnobar?source=post_page---byline--1700316afd1d--------------------------------)[![Farzad
    Nobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page---byline--1700316afd1d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1700316afd1d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1700316afd1d--------------------------------)
    [Farzad Nobar](https://medium.com/@fmnobar?source=post_page---byline--1700316afd1d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1700316afd1d--------------------------------)
    ·11 min read·Aug 30, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1700316afd1d--------------------------------)
    ·阅读时间：11分钟·2024年8月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7e51da1b21b1ea39b00de951b3372c17.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e51da1b21b1ea39b00de951b3372c17.png)'
- en: Photo by [Ayla Verschueren](https://unsplash.com/@moob?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/white-and-brown-long-coated-dog-lying-on-black-laptop-computer-V4YuRB6o7R4?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Ayla Verschueren](https://unsplash.com/@moob?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)来自[Unsplash](https://unsplash.com/photos/white-and-brown-long-coated-dog-lying-on-black-laptop-computer-V4YuRB6o7R4?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: 'In offline experimentations, we are used to testing various machine learning
    models, training and/or fine-tuning them and then using them for prediction (i.e.
    inference). Now imagine that we would like to move beyond just offline experimentation
    and provide our customers access to our amazing models so that they also can use
    them for prediction. In such cases, we can “deploy” our model to a SageMaker “endpoint”.
    Then our customers can send their requests to the deployed endpoint and receive
    real-time predictions. These endpoints provide certain benefits, including:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在离线实验中，我们习惯于测试各种机器学习模型，训练和/或微调它们，然后用来进行预测（即推理）。现在假设我们希望超越单纯的离线实验，向我们的客户提供访问我们出色模型的权限，使他们也能用来进行预测。在这种情况下，我们可以将我们的模型“部署”到一个SageMaker“端点”上。然后，我们的客户可以向已部署的端点发送请求，并接收实时预测。这些端点提供了一些好处，包括：
- en: '**Access:** An endpoint is just a web address where the model is hosted (or
    deployed). Therefore, we can use it just like any other web address where we can
    send the request (i.e. payload) and receive a response (i.e. model prediction).'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**访问权限：** 端点只是托管（或部署）模型的一个网址。因此，我们可以像使用任何其他网址一样使用它，发送请求（即负载）并接收响应（即模型预测）。'
- en: '**Scalable:** Once an endpoint is created, Amazon/AWS will take care of dedicating
    the necessary computational resources to serve our customers. For example, let’s
    say my laptop is only capable of processing 10 requests per second but I expect
    to have 10,000 customer requests per second. AWS will scale up the endpoint and
    provision enough hardware to support all 10,000…'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可扩展性：** 一旦端点创建完成，Amazon/AWS将负责提供必要的计算资源来服务我们的客户。例如，假设我的笔记本只能处理每秒10个请求，但我预期每秒会有10,000个客户请求。AWS会扩展端点并提供足够的硬件来支持所有10,000个请求……'
