- en: 'Spoiler Alert: The Magic of RAG Does Not Come from AI'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 剧透警告：RAG的魔力并不来自AI
- en: 原文：[https://towardsdatascience.com/spoiler-alert-the-magic-of-rag-does-not-come-from-ai-8a0ed2ad4800?source=collection_archive---------0-----------------------#2024-11-17](https://towardsdatascience.com/spoiler-alert-the-magic-of-rag-does-not-come-from-ai-8a0ed2ad4800?source=collection_archive---------0-----------------------#2024-11-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/spoiler-alert-the-magic-of-rag-does-not-come-from-ai-8a0ed2ad4800?source=collection_archive---------0-----------------------#2024-11-17](https://towardsdatascience.com/spoiler-alert-the-magic-of-rag-does-not-come-from-ai-8a0ed2ad4800?source=collection_archive---------0-----------------------#2024-11-17)
- en: Why retrieval, not generation, makes RAG systems magical
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么检索而非生成使RAG系统变得神奇
- en: '[](https://medium.com/@frankw_usa?source=post_page---byline--8a0ed2ad4800--------------------------------)[![Frank
    Wittkampf](../Images/3dbd69f8ef648074fa170fac451645fd.png)](https://medium.com/@frankw_usa?source=post_page---byline--8a0ed2ad4800--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8a0ed2ad4800--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8a0ed2ad4800--------------------------------)
    [Frank Wittkampf](https://medium.com/@frankw_usa?source=post_page---byline--8a0ed2ad4800--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@frankw_usa?source=post_page---byline--8a0ed2ad4800--------------------------------)[![Frank
    Wittkampf](../Images/3dbd69f8ef648074fa170fac451645fd.png)](https://medium.com/@frankw_usa?source=post_page---byline--8a0ed2ad4800--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8a0ed2ad4800--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8a0ed2ad4800--------------------------------)
    [Frank Wittkampf](https://medium.com/@frankw_usa?source=post_page---byline--8a0ed2ad4800--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8a0ed2ad4800--------------------------------)
    ·8 min read·Nov 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8a0ed2ad4800--------------------------------)
    ·阅读时长8分钟·2024年11月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Quick POCs
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速POC
- en: Most quick proof of concepts (POCs) which allow a user to explore data with
    the help of conversational AI simply blow you away. It feels like pure magic when
    you can all of a sudden talk to your documents, or data, or code base.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数允许用户借助对话式AI探索数据的快速概念验证（POC）会让你惊叹不已。当你突然间能够与文档、数据或代码库进行对话时，那感觉就像是纯粹的魔法。
- en: 'These POCs work wonders on small datasets with a limited count of docs. However,
    as with almost anything when you bring it to production, you quickly run into
    problems at scale. When you do a deep dive and you inspect the answers the AI
    gives you, you notice:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这些POC在小数据集和有限数量的文档中表现出色。然而，就像几乎所有东西一样，当你将它投入生产时，很快就会遇到规模化的问题。当你深入调查并检查AI给出的答案时，你会发现：
- en: Your agent doesn’t reply with complete information. It missed some important
    pieces of data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的代理没有回复完整的信息。它漏掉了一些重要的数据。
- en: Your agent doesn’t reliably give the same answer
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的代理并不能可靠地给出相同的答案。
- en: Your agent isn’t able to tell you how and where it got which information, making
    the answer significantly less useful
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的代理无法告诉你它是如何以及从哪里获得这些信息的，这使得答案的实用性大大降低。
- en: It turns out that the **real magic in RAG** does not happen in the generative
    AI step, but in the process of retrieval and composition. Once you dive in, it’s
    pretty obvious why…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，**RAG中的真正魔力**并不发生在生成式AI步骤中，而是在检索和组合的过程中。一旦你深入了解，就会明白为什么…
- en: '** RAG = Retrieval Augmented Generation —* [*Wikipedia Definition of RAG*](https://en.wikipedia.org/wiki/Retrieval-augmented_generation)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '** RAG = 检索增强生成 —* [*Wikipedia定义的RAG*](https://en.wikipedia.org/wiki/Retrieval-augmented_generation)'
- en: '![](../Images/1546c06f10cd9e6f67fbd43ec17c1601.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1546c06f10cd9e6f67fbd43ec17c1601.png)'
- en: RAG process — Illustration
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: RAG过程 — 插图
- en: So, how does a RAG-enabled AI agent answer a question?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 那么，一个启用RAG的AI代理是如何回答问题的呢？
- en: 'A quick recap of how a simple RAG process works:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 简要回顾一下简单的RAG过程如何工作：
- en: It all starts with a **query**. The user asked a question, or some system is
    trying to answer a question.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一切都从**查询**开始。用户提出问题，或者某个系统正在尝试回答一个问题。
- en: A **search** is done with the query. Mostly you’d embed the query and do a similarity
    search, but you can also do a classic elastic search or a combination of both,
    or a straight lookup of information
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**搜索**是通过查询来进行的。通常你会嵌入查询并进行相似度搜索，但你也可以进行经典的弹性搜索，或两者的结合，或者直接查找信息。'
- en: The search result is a set of **documents** (or document snippets, but let’s
    simply call them documents for now)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索结果是一组**文档**（或文档片段，但我们暂且称之为文档）。
- en: The documents and the essence of the query are combined into some easily readable
    **context** so that the AI can work with it
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文档和查询的要点被组合成易于阅读的**上下文**，以便AI能够使用它
- en: The **AI interprets** the question and the documents and generates an answer
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**AI解读**问题和文档，并生成答案'
- en: Ideally this answer is **fact checked**, to see if the AI based the answer on
    the documents, and/or if it is appropriate for the audience
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理想情况下，这个答案会被**事实核对**，以查看AI是否是基于文档得出的答案，或者是否适合目标受众
- en: Where’s the magic?
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 魔法在哪里？
- en: The dirty little secret is that the essence of the RAG process is that you have
    to provide the answer to the AI (before it even does anything), so that it is
    able to give you the reply that you’re looking for.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一个不为人知的秘密是，RAG流程的本质是你必须在AI做任何事情之前就向它提供答案，这样它才能给你你想要的回复。
- en: 'In other words:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说：
- en: the work that the AI does (step 5) is **apply judgement, and properly articulate
    the answer**
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI所做的工作（步骤5）是**应用判断，并正确地表达答案**
- en: the work that the engineer does (step 3 and 4) is **find the answer and compose
    it such that AI can digest it**
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工程师所做的工作（步骤3和4）是**找到答案并将其组合成AI能够理解的形式**
- en: Which is more important? The answer is, of course, it depends, because if judgement
    is the critical element, then the AI model does all the magic. But for an endless
    amount of business use cases, finding and properly composing the pieces that make
    up the answer, is the more important part.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 哪个更重要？答案当然是，视情况而定，因为如果判断是关键要素，那么AI模型就完成了所有的“魔法”。但是对于无数的业务用例来说，找到并正确组合构成答案的各个部分，才是更重要的部分。
- en: What are the typical engineering problems to solve if you want proper RAG process?
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如果你想要一个合适的RAG流程，典型的工程问题有哪些？
- en: The first set of problems to solve when running a RAG process are the data ingestion,
    splitting, chunking, document interpretation issues. I’ve written about a few
    of these in [prior articles](https://medium.com/@frankw_usa), but am ignoring
    them here. For now let’s assume you have properly solved your data ingestion,
    you have a lovely vector store or search index.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 运行RAG流程时需要解决的第一个问题是数据摄取、拆分、分块和文档解析问题。我在[之前的文章](https://medium.com/@frankw_usa)中写过一些相关内容，但在这里不再提及。暂时假设你已经解决了数据摄取问题，拥有一个漂亮的向量存储或搜索索引。
- en: 'Typical challenges:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 典型挑战：
- en: '**Duplication** — Even the simplest production systems often have duplicate
    documents. More so when your system is large, you have extensive users or tenants,
    you connect to multiple data sources, or you deal with versioning, etc.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重复性** — 即使是最简单的生产系统也常常会有重复文档。当系统规模很大，用户或租户众多，连接多个数据源，或处理版本控制等情况时，重复现象会更加严重。'
- en: '**Near duplication** — Documents which largely contain the same data, but with
    minor changes. There are two types of near duplication:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**近似重复** — 文档中大部分内容相同，但有一些小的变化。近似重复有两种类型：'
- en: — Meaningful — E.g. a small correction, or a minor addition, e.g. a date field
    with an update
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: — 有意义的 — 例如一个小的修正，或者一个小的添加，例如更新了日期字段
- en: '— Meaningless — E.g.: minor punctuation, syntax, or spacing differences, or
    just differences introduced by timing or intake processing'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: — 无意义的 — 例如：小的标点符号、语法或空格差异，或者仅仅是由时间差或输入处理引起的差异
- en: '**Volume** — Some queries have a very large relevant response data set'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数量** — 某些查询可能涉及到一个非常大的相关响应数据集'
- en: '**Data freshness vs quality** — Which snippets of the response data set have
    the most high quality content for the AI to use vs which snippets are most relevant
    from a time (freshness) perspective?'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的新鲜度与质量** — 哪些响应数据片段具有最高质量的内容供AI使用，而哪些片段则是从时间（新鲜度）角度最相关的？'
- en: '**Data variety** — How do we ensure a variety of search results such that the
    AI is properly informed?'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据多样性** — 如何确保搜索结果多样性，以确保AI获得充分的信息？'
- en: '**Query phrasing and ambiguity** — The prompt that triggered the RAG flow,
    might not be phrased in such a way that it yields the optimal result, or might
    even be ambiguous'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询措辞与模糊性** — 触发RAG流程的提示，可能没有以一种能产生最佳结果的方式表达，或者可能本身就存在模糊性'
- en: '**Response Personalization** — The query might require a different response
    based on who asks it'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应个性化** — 查询可能需要根据提问者不同而给出不同的回答'
- en: This list goes on, but you get the gist.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表还可以继续，但你明白了大概意思。
- en: 'Sidebar: Don’t unlimited context windows solve this?'
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 旁注：无限上下文窗口不解决这个问题吗？
- en: 'Short answer: no.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 简短的回答：不。
- en: The cost and performance impact of using extremely large context windows shouldn’t
    be underestimated (you easily 10x or 100x your per query cost), not including
    any follow up interaction that the user/system has.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用极大上下文窗口的成本和性能影响不容小觑（你可能会将每次查询的成本提高10倍甚至100倍），更不用提用户/系统的任何后续交互。
- en: However, putting that aside. Imagine the following situation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，抛开这些不谈，想象一下以下情形。
- en: 'We put Anne in room with a piece of paper. The paper says: *patient Joe: complex
    foot fracture.* Now we ask Anne, does the patient have a foot fracture? Her answer
    is “yes, he does”.'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们让安妮进入一个房间，桌子上有一张纸。纸上写着：*病人乔：复杂性脚部骨折*。现在我们问安妮，病人是否有脚部骨折？她的回答是：“是的，他有”。
- en: ''
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now we give Anne a hundred pages of medical history on Joe. Her answer becomes
    “well, depending on what time you are referring to, he had …”
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在我们给安妮提供了乔的100页病历记录。她的回答变成了：“嗯，这取决于你指的是哪个时间点，他曾经有过……”
- en: ''
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now we give Anne thousands of pages on all the patients in the clinic…
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在我们给安妮提供了关于诊所所有病人的成千上万页文档……
- en: What you quickly notice, is that how we define the question (or the prompt in
    our case) starts to get very important. **The larger the context window, the more
    nuance the query needs.**
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你很快会注意到，我们如何定义问题（或者在我们这里是提示）变得非常重要。**上下文窗口越大，查询所需的细节越多**。
- en: Additionally, **the larger the context window,** **the universe of possible
    answers grows.** This can be a positive thing, but in practice, it’s a method
    that invites lazy engineering behavior, and is likely to reduce the capabilities
    of your application if not handled intelligently.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，**上下文窗口越大，** **可能的答案范围也越广**。这可能是件好事，但实际上，这种方法容易引发懒惰的工程行为，如果处理不当，可能会削弱应用程序的能力。
- en: Suggested approaches
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐方法
- en: As you scale a RAG system from POC to production, here’s how to address typical
    data challenges with specific solutions.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将一个RAG系统从POC（概念验证）扩展到生产环境时，以下是如何通过具体解决方案应对典型数据挑战。
- en: Duplication
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重复
- en: Duplication is inevitable in multi-source systems. By using fingerprinting (hashing
    content), document IDs, or semantic hashing, you can identify exact duplicates
    at ingestion and prevent redundant content. However, consolidating metadata across
    duplicates can also be valuable; this lets users know that certain content appears
    in multiple sources, which can add credibility or highlight repetition in the
    dataset.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在多来源系统中，重复是不可避免的。通过使用指纹识别（哈希内容）、文档ID或语义哈希，你可以在数据摄取时识别出完全重复的内容并防止冗余。然而，整合重复项之间的元数据也是有价值的；这可以让用户知道某些内容出现在多个来源中，这可能会增加可信度或突出数据集中的重复内容。
- en: '[PRE0]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Near Duplication
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接近重复
- en: Near-duplicate documents (similar but not identical) often contain important
    updates or small additions. Given that a minor change, like a status update, can
    carry critical information, freshness becomes crucial when filtering near duplicates.
    A practical approach is to use cosine similarity for initial detection, then retain
    the freshest version within each group of near-duplicates while flagging any meaningful
    updates.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 接近重复的文档（相似但不完全相同）通常包含重要的更新或小的补充内容。考虑到像状态更新这样的微小变化可能包含关键信息，因此在过滤接近重复项时，新鲜度变得至关重要。一种实用方法是先使用余弦相似度进行初步检测，然后在每个接近重复的文档组中保留最新版本，同时标记任何有意义的更新。
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Volume
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据量
- en: 'When a query returns a high volume of relevant documents, effective handling
    is key. One approach is a **layered strategy**:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当查询返回大量相关文档时，如何有效处理至关重要。一种方法是采用**分层策略**：
- en: '**Theme Extraction**: Preprocess documents to extract specific themes or summaries.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主题提取**：预处理文档以提取特定的主题或摘要。'
- en: '**Top-k Filtering**: After synthesis, filter the summarized content based on
    relevance scores.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Top-k过滤**：在合成后，基于相关性评分过滤摘要内容。'
- en: '**Relevance Scoring**: Use similarity metrics (e.g., BM25 or cosine similarity)
    to prioritize the top documents before retrieval.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性评分**：使用相似性度量（例如BM25或余弦相似度）在检索前优先排序最相关的文档。'
- en: This approach reduces the workload by retrieving synthesized information that’s
    more manageable for the AI. Other strategies could involve batching documents
    by theme or pre-grouping summaries to further streamline retrieval.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法通过检索经过合成的信息，减轻了工作负担，使得AI处理起来更为高效。其他策略可能包括按主题批量处理文档或预先对摘要进行分组，以进一步简化检索过程。
- en: Data Freshness vs. Quality
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据的新鲜度与质量
- en: 'Balancing quality with freshness is essential, especially in fast-evolving
    datasets. Many scoring approaches are possible, but here’s a general tactic:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速变化的数据集中，平衡质量与新鲜度至关重要。虽然有多种评分方法，但这里有一种通用策略：
- en: '**Composite Scoring**: Calculate a quality score using factors like source
    reliability, content depth, and user engagement.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复合评分**：通过源可靠性、内容深度和用户参与等因素计算质量得分。'
- en: '**Recency Weighting**: Adjust the score with a timestamp weight to emphasize
    freshness.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时效加权**：通过时间戳权重调整得分，以强调新鲜度。'
- en: '**Filter by Threshold**: Only documents meeting a combined quality and recency
    threshold proceed to retrieval.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**按阈值过滤**：只有满足质量和时效阈值的文档才会进行检索。'
- en: Other strategies could involve scoring only high-quality sources or applying
    decay factors to older documents.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 其他策略可能涉及仅对高质量来源评分或对较旧文档应用衰减因子。
- en: Data Variety
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据多样性
- en: Ensuring diverse data sources in retrieval helps create a balanced response.
    Grouping documents by source (e.g., different databases, authors, or content types)
    and selecting top snippets from each source is one effective method. Other approaches
    include scoring by unique perspectives or applying diversity constraints to avoid
    over-reliance on any single document or perspective.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 确保检索中的数据来源多样化有助于创建平衡的响应。通过来源（例如，不同的数据库、作者或内容类型）对文档进行分组，并从每个来源选择最佳片段是一种有效方法。其他方法包括按独特视角评分或应用多样性约束，以避免过度依赖任何单一文档或视角。
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Query Phrasing and Ambiguity
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询措辞和模糊性
- en: Ambiguous queries can lead to suboptimal retrieval results. Using the exact
    user prompt is mostly not be the best way to retrieve the results they require.
    E.g. there might have been an information exchange earlier on in the chat which
    is relevant. Or the user pasted a large amount of text with a question about it.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊查询可能导致次优的检索结果。直接使用用户的原始提示通常不是检索所需结果的最佳方式。例如，可能在聊天的早期有一个相关的信息交换，或者用户粘贴了一大段文本并提出了相关问题。
- en: 'To ensure that you use a refined query, one approach is to ensure that a RAG
    tool provided to the model asks it to rephrase the question into a more detailed
    search query, similar to how one might carefully craft a search query for Google.
    This approach improves alignment between the user’s intent and the RAG retrieval
    process. The phrasing below is suboptimal, but it provides the gist of it:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保使用精确的查询，一种方法是确保提供给模型的RAG工具要求其将问题重新表述为更详细的搜索查询，类似于人们为Google精心设计搜索查询的方式。这种方法提高了用户意图和RAG检索过程之间的对齐度。下面的措辞虽然不理想，但大致传达了意思：
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Response Personalization
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 响应个性化
- en: For tailored responses, integrate user-specific context directly into the RAG
    context composition. By adding a user-specific layer to the final context, you
    allow the AI to take into account individual preferences, permissions, or history
    without altering the core retrieval process.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供量身定制的响应，直接将用户特定的上下文整合到RAG上下文组成中。通过在最终上下文中添加用户特定的层，允许AI考虑个人偏好、权限或历史记录，而不改变核心检索过程。
- en: By addressing these data challenges, your RAG system can evolve from a compelling
    POC into a reliable production-grade solution. Ultimately, the effectiveness of
    RAG relies more on careful engineering than on the AI model itself. While AI can
    generate fluent answers, the real magic lies in how well we retrieve and structure
    information. So the next time you’re impressed by an AI system’s conversational
    abilities, remember that it’s likely the result of an expertly designed retrieval
    process working behind the scenes.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解决这些数据挑战，你的RAG系统可以从一个有说服力的概念验证（POC）进化为一个可靠的生产级解决方案。最终，RAG的有效性更多依赖于精心的工程设计，而不是AI模型本身。虽然AI可以生成流畅的答案，但真正的“魔力”在于我们如何检索和构建信息。因此，下次当你对AI系统的对话能力感到印象深刻时，请记住，这很可能是得益于背后精心设计的检索过程。
- en: I hope this article provided you some insight into the RAG process, and why
    the magic that you experience when talking to your data isn’t necessarily coming
    from the AI model, but is largely dependent on the design of your retrieval process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这篇文章能为你提供一些关于RAG过程的见解，并解释为什么在与数据交谈时，你体验到的“魔力”不一定来自AI模型，而更多依赖于你的检索过程设计。
- en: Please comment with your thoughts.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评论，分享你的想法。
