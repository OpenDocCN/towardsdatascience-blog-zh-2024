["```py\npip install turftopic datasets\n```", "```py\nfrom datasets import load_dataset\n\nds = load_dataset(\"CShorten/ML-ArXiv-Papers\", split=\"train\")\n```", "```py\nfrom turftopic import SemanticSignalSeparation\n\nmodel = SemanticSignalSeparation(10, encoder=\"all-MiniLM-L12-v2\")\nmodel.fit(ds[\"abstract\"])\n\nmodel.print_topics()\n```", "```py\nimport numpy as np\n\nvocab = model.get_vocab()\n\n# We will produce a BoW matrix to extract term frequencies\ndocument_term_matrix = model.vectorizer.transform(ds[\"abstract\"])\nfrequencies = document_term_matrix.sum(axis=0)\nfrequencies = np.squeeze(np.asarray(frequencies))\n\n# We select the 99th percentile\nselected_terms_mask = frequencies > np.quantile(frequencies, 0.99)\n```", "```py\nimport pandas as pd\n\n# model.components_ is a n_topics x n_terms matrix\n# It contains the strength of all components for each word.\n# Here we are selecting components for the words we selected earlier\n\nterms_with_axes = pd.DataFrame({\n    \"inference\": model.components_[7][selected_terms],\n    \"measurement_devices\": model.components_[1][selected_terms],\n    \"noise\": model.components_[6][selected_terms],\n    \"term\": vocab[selected_terms]\n })\n```", "```py\nimport plotly.express as px\n\npx.scatter(\n    terms_with_axes,\n    text=\"term\",\n    x=\"inference\",\n    y=\"noise\",\n    color=\"measurement_devices\",\n    template=\"plotly_white\",\n    color_continuous_scale=\"Bluered\",\n).update_layout(\n    width=1200,\n    height=800\n).update_traces(\n    textposition=\"top center\",\n    marker=dict(size=12, line=dict(width=2, color=\"white\"))\n)\n```"]