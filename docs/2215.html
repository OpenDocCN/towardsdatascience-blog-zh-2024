<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>XPER: Unveiling the Driving Forces of Predictive Performance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>XPER: Unveiling the Driving Forces of Predictive Performance</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://towardsdatascience.com/xper-unveiling-the-driving-forces-of-predictive-performance-309ce4f10b0a?source=collection_archive---------12-----------------------#2024-09-10">https://towardsdatascience.com/xper-unveiling-the-driving-forces-of-predictive-performance-309ce4f10b0a?source=collection_archive---------12-----------------------#2024-09-10</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="dd1a" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><span class="l hd he hf bo hg hh hi hj hk ed">A</span> new method for decomposing your favorite performance metrics</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hl hm hn ho hp ab"><div><div class="ab hq"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@seb.saurin?source=post_page---byline--309ce4f10b0a--------------------------------" rel="noopener follow"><div class="l hr hs by ht hu"><div class="l ed"><img alt="S√©bastien Saurin" class="l ep by dd de cx" src="../Images/18c4fac70a326896f095a44e8f48b929.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*XU6PYWVjVOh3xS5lyPZI4Q.jpeg"/><div class="hv by l dd de em n hw eo"/></div></div></a></div></div><div class="hx ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--309ce4f10b0a--------------------------------" rel="noopener follow"><div class="l hy hz by ht ia"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ib cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hv by l br ib em n hw eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ic ab q"><div class="ab q id"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ie if bk"><a class="af ag ah ai aj ak al am an ao ap aq ar ig" data-testid="authorName" href="https://medium.com/@seb.saurin?source=post_page---byline--309ce4f10b0a--------------------------------" rel="noopener follow">S√©bastien Saurin</a></p></div></div></div><span class="ih ii" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span><p class="bf b ie if dx"><button class="ij ik ah ai aj ak al am an ao ap aq ar il im in" disabled="">Follow</button></p></div></div></span></div></div><div class="l io"><span class="bf b bg z dx"><div class="ab cn ip iq ir"><div class="is it ab"><div class="bf b bg z dx ab iu"><span class="iv l io">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar ig ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--309ce4f10b0a--------------------------------" rel="noopener follow"><p class="bf b bg z iw ix iy iz ja jb jc jd bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ih ii" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="je jf l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div><span data-testid="storyPublishDate">Sep 10, 2024</span></div></span></div></span></div></div></div><div class="ab cp jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv"><div class="h k w ea eb q"><div class="kl l"><div class="ab q km kn"><div class="pw-multi-vote-icon ed iv ko kp kq"><div class=""><div class="kr ks kt ku kv kw kx am ky kz la kq"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l lb lc ld le lf lg lh"><p class="bf b dy z dx"><span class="ks">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kr li lj ab q ee lk ll" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lm"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk"><div class="ln k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lo an ao ap il lp lq lr" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ls cn"><div class="l ae"><div class="ab cb"><div class="lt lu lv lw lx ly ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lo an ao ap il lz ma ll mb mc md me mf s mg mh mi mj mk ml mm u mn mo mp"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lo an ao ap il lz ma ll mb mc md me mf s mg mh mi mj mk ml mm u mn mo mp"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lo an ao ap il lz ma ll mb mc md me mf s mg mh mi mj mk ml mm u mn mo mp"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mt mu mv mw mx my mq mr paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mq mr ms"><img src="../Images/4f1d2a607b94cdbf45159deedd2d0f0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0RukQquDhNSLADa4tEH-tA.png"/></div></div><figcaption class="ne nf ng mq mr nh ni bf b bg z dx">Photo by <a class="af nj" href="https://www.123rf.com/profile_siraanamwong" rel="noopener ugc nofollow" target="_blank">Sira Anamwong</a> on <a class="af nj" href="https://www.123rf.com/" rel="noopener ugc nofollow" target="_blank">123RF</a></figcaption></figure><p id="a16c" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Co-authored with S. Hu√©, C. Hurlin, and C. P√©rignon.</p><h1 id="cbdd" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">I - From explaining model forecasts to explaining model performance</h1><p id="e40c" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">Trustability and acceptability of sensitive AI systems largely depend on the capacity of the users to understand the associated models, or at least their forecasts. To lift the veil on opaque AI applications, eXplainable AI (XAI) methods such as post-hoc interpretability tools (e.g. SHAP, LIME), are commonly utilized today, and the insights generated from their outputs are now widely comprehended.</p><p id="589b" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Beyond individual forecasts, we show in this article how to identify the drivers of the performance metrics (e.g. AUC, R2) of any classification or regression model using the eXplainable PERformance (XPER) methodology. Being able to identify the driving forces of the statistical or economic performance of a predictive model lies at the very core of modeling and is of great importance for both data scientists and experts basing their decisions on such models. The XPER library outlined below has proven to be an efficient tool to decompose performance metrics into individual feature contributions.</p><p id="c0dd" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">While they are grounded in the same mathematical principles, XPER and SHAP are fundamentally different and simply have different goals. While SHAP pinpoints the features that significantly influence the model‚Äôs individual predictions, XPER identifies the features that contribute the most to the performance of the model. The latter analysis can be conducted at the global (model) level or local (instance) level. In practice, the feature with the strongest impact on individual forecasts (say feature A) may not be the one with the strongest impact on performance. Indeed, feature A drives individual decisions when the model is correct but also when the model makes an error. Conceptually, if feature A mainly impacts erroneous predictions, it may rank lower with XPER than it does with SHAP.</p><p id="3877" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">What is a performance decomposition used for? First, it can enhance any post-hoc interpretability analysis by offering a more comprehensive insight into the model‚Äôs inner workings. This allows for a deeper understanding of why the model is, or is not, performing effectively. Second, XPER can help identify and address heterogeneity concerns. Indeed, by analyzing individual XPER values, it is possible to pinpoint subsamples in which the features have similar effects on performance. Then, one can estimate a separate model for each subsample to boost the predictive performance. Third, XPER can help to understand the origin of overfitting. Indeed, XPER permits us to identify some features which contribute more to the performance of the model in the training sample than in the test sample.</p><h1 id="39e2" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk"><strong class="al">II - XPER values</strong></h1><p id="d6d2" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">The XPER framework is a theoretically grounded method that is based on Shapley values (Shapley, 1953), a decomposition method from coalitional game theory. While the Shapley values decompose a payoff among players in a game, XPER values decompose a performance metric (e.g., AUC, R2) among features in a model.</p><p id="3ac1" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Suppose that we train a classification model using three features and that its predictive performance is measured with an AUC equal to 0.78. An example of XPER decomposition is the following:</p><figure class="mt mu mv mw mx my mq mr paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mq mr ph"><img src="../Images/ed19686e81aac20f5f77192ce2e89c3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tw-LXgO2nDq7gOScK-pDqw.png"/></div></div></figure><p id="09a1" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The first XPER value ùúô‚ÇÄ is referred to as the benchmark and represents the performance of the model if none of the three features provided any relevant information to predict the target variable. When the AUC is used to evaluate the predictive performance of a model, the value of the benchmark corresponds to a random classification. As the AUC of the model is greater than 0.50, it implies that at least one feature contains useful information to predict the target variable. The difference between the AUC of the model and the benchmark represents the contribution of features to the performance of the model, which can be decomposed with XPER values. In this example, the decomposition indicates that the first feature is the main driver of the predictive performance of the model as it explains half of the difference between the AUC of the model and a random classification (ùúô‚ÇÅ), followed by the second feature (ùúô‚ÇÇ) and the third one (ùúô‚ÇÉ). These results thus measure the global effect of each feature on the predictive performance of the model and to rank them from the least important (the third feature) to the most important (the first feature).</p><p id="7f84" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">While the XPER framework can be used to conduct a global analysis of the model predictive performance, it can also be used to provide a local analysis at the instance level. At the local level, the XPER value corresponds to the contribution of a given instance and feature to the predictive performance of the model. The benchmark then represents the contribution of a given observation to the predictive performance if the target variable was independent from the features, and the difference between the individual contribution and the benchmark is explained by individual XPER values. Therefore, individual XPER values allow us to understand why some observations contribute more to the predictive performance of a model than others, and can be used to address heterogeneity issues by identifying groups of individuals for which features have similar effects on performance.</p><p id="2801" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">It is also important to note that XPER is both model and metric-agnostic. It implies that XPER values can be used to interpret the predictive performance of any econometric or machine learning model, and to break down any performance metric, such as predictive accuracy measures (AUC, accuracy), statistical loss functions (MSE, MAE), or economic performance measure (profit-and-loss functions).</p><h1 id="de0e" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">III - XPER in Python</h1><p id="e456" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk"><strong class="nm fr">01 ‚Äî Download Library ‚öôÔ∏è</strong></p><p id="1acc" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The XPER approach is implemented in Python through the <a class="af nj" href="https://github.com/hi-paris/XPER/tree/main" rel="noopener ugc nofollow" target="_blank">XPER library</a>. To compute XPER values, first one has to install the XPER library as follows:</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="dab2" class="pm oh fq pj b bg pn po l pp pq">pip install XPER</span></pre><p id="0a8b" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><strong class="nm fr">02 ‚Äî Import Library üì¶</strong></p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="9480" class="pm oh fq pj b bg pn po l pp pq">import XPER<br/>import pandas as pd</span></pre><p id="476f" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><strong class="nm fr">03 ‚Äî Load example dataset üíΩ</strong></p><p id="398f" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">To illustrate how to use XPER values in Python, let us take a concrete example. Consider a classification problem whose main objective is to predict credit default. The dataset can be directly imported from the XPER library such as:</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="c2e2" class="pm oh fq pj b bg pn po l pp pq">import XPER<br/>from XPER.datasets.load_data import loan_status<br/>loan = loan_status().iloc[:, :6]<br/><br/>display(loan.head())<br/>display(loan.shape)</span></pre><figure class="mt mu mv mw mx my mq mr paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mq mr pr"><img src="../Images/0cd5be96b19de9169cd43441a17ecb35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dnnAFbw0oacvcwHq"/></div></div></figure><p id="497f" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The primary goal of this dataset, given the included variables, appears to be building a predictive model to determine the ‚ÄúLoan_Status‚Äù of a potential borrower. In other words, we want to predict whether a loan application will be approved (‚Äú1‚Äù) or not (‚Äú0‚Äù) based on the information provided by the applicant.</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="304c" class="pm oh fq pj b bg pn po l pp pq"># Remove 'Loan_Status' column from 'loan' dataframe and assign it to 'X'<br/>X = loan.drop(columns='Loan_Status')<br/><br/># Create a new dataframe 'Y' containing only the 'Loan_Status' column from 'loan' dataframe<br/>Y = pd.Series(loan['Loan_Status'])</span></pre><p id="1d01" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><strong class="nm fr">04 ‚Äî Estimate the Model ‚öôÔ∏è</strong></p><p id="3b66" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Then, we need to train a predictive model and to measure its performance in order to compute the associated XPER values. For illustration purposes, we split the initial dataset into a training and a test set and fit a XGBoost classifier on the training set:</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="2d97" class="pm oh fq pj b bg pn po l pp pq">from sklearn.model_selection import train_test_split<br/><br/># Split the data into training and testing sets<br/># X: input features<br/># Y: target variable<br/># test_size: the proportion of the dataset to include in the testing set (in this case, 15%)<br/># random_state: the seed value used by the random number generator for reproducible results<br/>X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=3)<br/><br/>import xgboost as xgb<br/><br/># Create an XGBoost classifier object<br/>gridXGBOOST = xgb.XGBClassifier(eval_metric="error")<br/><br/># Train the XGBoost classifier on the training data<br/>model = gridXGBOOST.fit(X_train, y_train)</span></pre><p id="2441" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><strong class="nm fr">05 ‚Äî Evaluate Performance üéØ</strong></p><p id="279b" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The XPER library offers an intuitive and simple way to compute the predictive performance of a predictive model. Considering that the performance metric of interest is the Areas Under the ROC Curve (AUC), it can be measured on the test set as follows:</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="fc59" class="pm oh fq pj b bg pn po l pp pq">from XPER.compute.Performance import ModelPerformance<br/><br/># Define the evaluation metric(s) to be used<br/>XPER = ModelPerformance(X_train.values, <br/>                        y_train.values, <br/>                        X_test.values, <br/>                        y_test.values, <br/>                        model)<br/><br/># Evaluate the model performance using the specified metric(s)<br/>PM = XPER.evaluate(["AUC"])<br/><br/># Print the performance metrics<br/>print("Performance Metrics: ", round(PM, 3))</span></pre><p id="9187" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><strong class="nm fr">06 ‚Äî Calculate XPER values ‚≠êÔ∏è</strong></p><p id="853c" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Finally, to explain the driving forces of the AUC the XPER values can be computed such as:</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="20e4" class="pm oh fq pj b bg pn po l pp pq"># Calculate XPER values for the model's performance<br/>XPER_values = XPER.calculate_XPER_values(["AUC"],kernel=False)</span></pre><p id="6d37" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The ¬´ XPER_values ¬ª is a tuple including two elements: the XPER values and the individual XPER values of the features.</p><p id="6654" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">For use cases above 10 feature variables it is advised to used the default option kernel=True for computation efficiency ‚û°Ô∏è</p><p id="f74e" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><strong class="nm fr">07 ‚Äî Visualization üìä</strong></p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="5f01" class="pm oh fq pj b bg pn po l pp pq">from XPER.viz.Visualisation import visualizationClass as viz<br/><br/>labels = list(loan.drop(columns='Loan_Status').columns)</span></pre><p id="b27a" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">To analyze the driving force at the global level, the XPER library proposes a <strong class="nm fr">bar plot</strong> representation of XPER values.</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="108f" class="pm oh fq pj b bg pn po l pp pq">viz.bar_plot(XPER_values=XPER_values, X_test=X_test, labels=labels, p=5,percentage=True)</span></pre><figure class="mt mu mv mw mx my mq mr paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mq mr ps"><img src="../Images/96d2f3b66c151c225f3bab9e8e57c57b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*God3qxZWVP4DDuLSusuWbg.png"/></div></div></figure><p id="bca8" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">For ease of presentation, feature contributions are expressed in percentage of the spread between the AUC and its benchmark, i.e., 0.5 for the AUC, and are ordered from the largest to lowest. From this figure, we can see that more than 78% of the over-performance of the model over a random predictor comes from <em class="pt">Credit History</em>, followed by <em class="pt">Applicant Income </em>contributing around 16% to the performance, and <em class="pt">Co-applicant Income</em> and <em class="pt">Loan Amount Term </em>each<em class="pt"> </em>accounting for less than 6%. On the other hand, we can see that the variable <em class="pt">Loan Amount </em>almost does not help the model to better predict the probability of default as its contribution is close to 0.</p><p id="0bac" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The XPER library also proposes graphical representations to analyze XPER values at the local level. First, a <strong class="nm fr">force plot</strong> can be used to analyze driving forces of the performance for a given observation:</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="c8d1" class="pm oh fq pj b bg pn po l pp pq">viz.force_plot(XPER_values=XPER_values, instance=1, X_test=X_test, variable_name=labels, figsize=(16,4))</span></pre><figure class="mt mu mv mw mx my mq mr paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mq mr pu"><img src="../Images/9b282ac045d0fc6657a119937bfa7e7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Li7HXRKEywfwubV-knshLg.png"/></div></div></figure><p id="e1e0" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The preceding code plots the positive (negative) XPER values of the observation #10 in red (blue), as well as the benchmark (0.33) and contribution (0.46) of this observation to the AUC of the model. The over-performance of borrower #10 is due to the positive XPER values of <em class="pt">Loan Amount Term, Applicant Income</em>, and <em class="pt">Credit History. </em>On the other hand, <em class="pt">Co-Applicant Income </em>and<em class="pt"> Loan Amount </em>had a negative effect and decreased the contribution of this borrower.</p><p id="84f3" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">We can see that while <em class="pt">Applicant Income </em>and <em class="pt">Loan Amount </em>have a positive effect<em class="pt"> </em>on the AUC at the global level, these variables have a negative effect for the borrower #10. Analysis of individual XPER values can thus identify groups of observations for which features have different effects on performance, potentially highlighting an heterogeneity issue.</p><p id="d76a" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Second, it is possible to represent the XPER values of each observation and feature on a single plot. For that purpose, one can rely on a <strong class="nm fr">beeswarm plot</strong> which represents the XPER values for each feature as a function of the feature value.</p><pre class="mt mu mv mw mx pi pj pk bp pl bb bk"><span id="81d6" class="pm oh fq pj b bg pn po l pp pq">viz.beeswarn_plot(XPER_values=XPER_values,X_test=X_test,labels=labels)</span></pre><figure class="mt mu mv mw mx my mq mr paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mq mr pv"><img src="../Images/92e09764e5f1dd8a52e04657e33ecb80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_R0onEGZdiVXW0jFMaNQXg.png"/></div></div></figure><p id="1fd5" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">On this figure, each dot represents an observation. The horizontal axis represents the contribution of each observation to the performance of the model, while the vertical axis represents the magnitude of feature values. Similarly to the bar plot shown previously, features are ordered from those that contribute the most to the performance of the model to those that contribute the least. However, with the beeswarm plot it is also possible to analyze the effect of feature values on XPER values. In this example, we can see large values of <em class="pt">Credit History </em>are associated with relatively small contributions (in absolute value), whereas low values lead to larger contributions (in absolute value).</p><p id="2b20" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><em class="pt">All images, unless otherwise stated, are by the author.</em></p><h1 id="7ccd" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">IV - Acknowledgements</h1><p id="31c4" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">The contributors to this library are:</p><ul class=""><li id="49e3" class="nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of pw px py bk"><a class="af nj" href="https://www.amse-aixmarseille.fr/fr/membres/hu%C3%A9" rel="noopener ugc nofollow" target="_blank">Sullivan Hu√©</a></li><li id="c976" class="nk nl fq nm b go pz no np gr qa nr ns nt qb nv nw nx qc nz oa ob qd od oe of pw px py bk"><a class="af nj" href="https://sites.google.com/view/christophe-hurlin/home" rel="noopener ugc nofollow" target="_blank">Christophe Hurlin</a></li><li id="0101" class="nk nl fq nm b go pz no np gr qa nr ns nt qb nv nw nx qc nz oa ob qd od oe of pw px py bk"><a class="af nj" href="https://people.hec.edu/perignon/" rel="noopener ugc nofollow" target="_blank">Christophe P√©rignon</a></li><li id="cdad" class="nk nl fq nm b go pz no np gr qa nr ns nt qb nv nw nx qc nz oa ob qd od oe of pw px py bk"><a class="af nj" href="https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=4582330" rel="noopener ugc nofollow" target="_blank">S√©bastien Saurin</a></li><li id="e54b" class="nk nl fq nm b go pz no np gr qa nr ns nt qb nv nw nx qc nz oa ob qd od oe of pw px py bk"><a class="af nj" href="https://www.linkedin.com/in/awais-hussain-sani-87a35757/" rel="noopener ugc nofollow" target="_blank">Awais Sani</a></li><li id="8776" class="nk nl fq nm b go pz no np gr qa nr ns nt qb nv nw nx qc nz oa ob qd od oe of pw px py bk"><a class="af nj" href="https://www.linkedin.com/in/gaetan-brison/" rel="noopener ugc nofollow" target="_blank">Ga√´tan Brison</a></li></ul><h1 id="4966" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">V - References</h1><p id="3ff9" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">[1] L. Shapley, <a class="af nj" href="https://www.degruyter.com/document/doi/10.1515/9781400829156-012/pdf?licenseType=restricted" rel="noopener ugc nofollow" target="_blank"><strong class="nm fr">A Value for n-Person Games</strong></a><strong class="nm fr"> (1953), </strong>Contributions to the Theory of Games, 2:307‚Äì317</p><p id="9ba8" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">[2] S. Lundberg, S. Lee, <a class="af nj" href="https://dl.acm.org/doi/10.5555/3295222.3295230" rel="noopener ugc nofollow" target="_blank"><strong class="nm fr">A unified approach to interpreting model predictions</strong></a><strong class="nm fr"> (2017)</strong>, Advances in Neural Information Processing Systems</p><p id="b992" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">[3] S. Hu√©, C. Hurlin, C. P√©rignon, S. Saurin, <a class="af nj" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4280563" rel="noopener ugc nofollow" target="_blank"><strong class="nm fr">Measuring the Driving Forces of Predictive Performance: Application to Credit Scoring</strong></a><strong class="nm fr"> (2023), </strong>HEC Paris Research Paper No. FIN-2022‚Äì1463</p></div></div></div></div>    
</body>
</html>