- en: 'Short and Sweet: Enhancing LLM Performance with Constrained Chain-of-Thought'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/short-and-sweet-enhancing-llm-performance-with-constrained-chain-of-thought-c4479361d995?source=collection_archive---------4-----------------------#2024-08-07](https://towardsdatascience.com/short-and-sweet-enhancing-llm-performance-with-constrained-chain-of-thought-c4479361d995?source=collection_archive---------4-----------------------#2024-08-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '|LLM|PROMPT ENGINEERING|COT|REASONING|'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes few words are enough: reducing output length for increasing accuracy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://salvatore-raieli.medium.com/?source=post_page---byline--c4479361d995--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page---byline--c4479361d995--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c4479361d995--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c4479361d995--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--c4479361d995--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c4479361d995--------------------------------)
    ·9 min read·Aug 7, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46d3ba9bc12c1d09841c8f19a65b017b.png)'
  prefs: []
  type: TYPE_IMG
- en: image created by the author using AI
  prefs: []
  type: TYPE_NORMAL
- en: Brevity is a great charm of eloquence. — Marcus Tullius Cicero
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Brevity and conciseness are the parents of correction. — Hosea Ballou
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Large language models (LLMs)](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=Large%20Language%20Models,-What%20is%20a)
    have shown interesting capabilities in the field of reasoning. With their use,
    a new field of application has emerged: [prompt engineering](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20is%20a%20prompt%3F%20What%20is%20prompt%20engineering%3F).
    In fact, interaction with these models occurs through the use of prompts, and
    for this reason, techniques have been developed to improve these capabilities
    of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pub.towardsai.net/prompt-engineering-to-leverage-in-context-learning-in-large-language-models-72296e1f09c3?source=post_page-----c4479361d995--------------------------------)
    [## Prompt Engineering to Leverage In-Context Learning in Large Language Models'
  prefs: []
  type: TYPE_NORMAL
- en: How to modify your text prompt to obtain the best from an LLM without training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pub.towardsai.net](https://pub.towardsai.net/prompt-engineering-to-leverage-in-context-learning-in-large-language-models-72296e1f09c3?source=post_page-----c4479361d995--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: One of the most intriguing techniques is [chain-of-thought (CoT) prompting](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20is%20Chain%2Dof%2DThought%20(CoT)%3F);
    this technique increases correctness in reasoning problems and explains how the
    model arrives at the solution (or what reasoning errors it…
  prefs: []
  type: TYPE_NORMAL
