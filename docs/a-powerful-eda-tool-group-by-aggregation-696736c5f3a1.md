# ä¸€ç§å¼ºå¤§çš„ EDA å·¥å…·ï¼šåˆ†ç»„èšåˆ

> åŸæ–‡ï¼š[`towardsdatascience.com/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=collection_archive---------5-----------------------#2024-07-04`](https://towardsdatascience.com/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=collection_archive---------5-----------------------#2024-07-04)

![](img/691a811bf777523ac010794feed190fa.png)

ç…§ç‰‡ç”±[Mourizal Zativa](https://unsplash.com/@mourimoto?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)æä¾›ï¼Œæ¥è‡ª[Unsplash](https://unsplash.com/s/photos/lego-pieces?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

## å­¦ä¹ å¦‚ä½•ä½¿ç”¨åˆ†ç»„èšåˆä»æ•°æ®ä¸­å‘ç°æ´å¯Ÿ

[](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)![Pararawendy Indarjo](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------) [Pararawendy Indarjo](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------) Â·é˜…è¯»æ—¶é—´ï¼š7 åˆ†é’ŸÂ·2024 å¹´ 7 æœˆ 4 æ—¥

--

æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰æ˜¯æ•°æ®åˆ†æå¸ˆçš„æ ¸å¿ƒèƒ½åŠ›ã€‚æ¯å¤©ï¼Œæ•°æ®åˆ†æå¸ˆçš„ä»»åŠ¡æ˜¯çœ‹åˆ°â€œæœªè§ä¹‹äº‹â€ï¼Œæˆ–è€…ä»æµ©ç€šçš„æ•°æ®æµ·æ´‹ä¸­æå–æœ‰ç”¨çš„æ´å¯Ÿã€‚

åœ¨è¿™æ–¹é¢ï¼Œæˆ‘æƒ³åˆ†äº«ä¸€ç§æˆ‘è®¤ä¸ºæœ‰åŠ©äºä»æ•°æ®ä¸­æå–ç›¸å…³æ´å¯Ÿçš„æŠ€å·§ï¼šåˆ†ç»„èšåˆã€‚

ä¸ºæ­¤ï¼Œæœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†å°†æŒ‰ä»¥ä¸‹æ–¹å¼å®‰æ’ï¼š

1.  åœ¨ Pandas ä¸­è¿›è¡Œåˆ†ç»„èšåˆçš„è§£é‡Š

1.  æ•°æ®é›†ï¼šåœ°é“å·é™…äº¤é€š

1.  åœ°é“äº¤é€šæ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰

# åˆ†ç»„èšåˆ

åˆ†ç»„èšåˆæ˜¯ä¸€ç§æ•°æ®æ“ä½œæŠ€å·§ï¼ŒåŒ…å«ä¸¤ä¸ªæ­¥éª¤ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ ¹æ®ç‰¹å®šåˆ—çš„å€¼å¯¹æ•°æ®è¿›è¡Œåˆ†ç»„ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åœ¨åˆ†ç»„æ•°æ®ä¸Šæ‰§è¡Œä¸€äº›èšåˆæ“ä½œï¼ˆä¾‹å¦‚ï¼Œæ±‚å’Œã€å¹³å‡ã€æ±‚ä¸­ä½æ•°ã€è®¡æ•°å”¯ä¸€å€¼ç­‰ï¼‰ã€‚

åˆ†ç»„èšåˆåœ¨æ•°æ®ç²’åº¦è¾ƒç»†æ—¶å°¤å…¶æœ‰ç”¨ï¼Œå…¸å‹çš„å¦‚äº‹å®è¡¨ï¼ˆäº¤æ˜“æ•°æ®ï¼‰å’Œé—´éš”è¾ƒçª„çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚é€šè¿‡åœ¨æ¯”åŸå§‹æ•°æ®ç²’åº¦æ›´é«˜çš„å±‚æ¬¡è¿›è¡Œèšåˆï¼Œæˆ‘ä»¬å¯ä»¥ä»¥æ›´ç´§å‡‘çš„æ–¹å¼è¡¨ç¤ºæ•°æ®â€”â€”å¹¶ä¸”å¯èƒ½åœ¨æ­¤è¿‡ç¨‹ä¸­æç‚¼å‡ºæœ‰ç”¨çš„æ´å¯Ÿã€‚

åœ¨ pandas ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹é€šç”¨è¯­æ³•å½¢å¼è¿›è¡Œåˆ†ç»„èšåˆã€‚

```py
df.groupby(['base_col']).agg(
  agg_col=('ori_col','agg_func')
)
```

å…¶ä¸­ï¼Œ`base_col`æ˜¯ä½œä¸ºåˆ†ç»„åŸºç¡€çš„åˆ—ï¼Œ`agg_col`æ˜¯é€šè¿‡å¯¹`ori_col`åˆ—è¿›è¡Œ`agg_func`èšåˆåå®šä¹‰çš„æ–°åˆ—ã€‚

ä¾‹å¦‚ï¼Œè€ƒè™‘è‘—åçš„æ³°å¦å°¼å…‹å·æ•°æ®é›†ï¼Œä»¥ä¸‹æ˜¾ç¤ºäº†å…¶äº”è¡Œæ•°æ®ã€‚

```py
import pandas as pd
import seaborn as sns

# import titanic dataset
titanic = sns.load_dataset("titanic")
titanic.head()
```

![](img/4868ab3226336b94d70b44529881f531.png)

æ³°å¦å°¼å…‹å·æ•°æ®çš„å‰ 5 è¡Œï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

æˆ‘ä»¬å¯ä»¥é€šè¿‡`survived`åˆ—å¯¹è¿™äº›æ•°æ®è¿›è¡Œåˆ†ç»„ï¼Œç„¶åé€šè¿‡è®¡ç®—`fare`åˆ—çš„ä¸­ä½æ•°æ¥èšåˆï¼Œå¾—åˆ°ä»¥ä¸‹ç»“æœã€‚

![](img/11515715275245f95bac895b569a7168.png)

æŒ‰ç”Ÿå­˜çŠ¶æ€åˆ’åˆ†çš„æ³°å¦å°¼å…‹å·ä¹˜å®¢ç¥¨ä»·ä¸­ä½æ•°ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

çªç„¶é—´ï¼Œæˆ‘ä»¬çœ‹åˆ°ä¸€ä¸ªæœ‰è¶£çš„è§è§£ï¼šç”Ÿè¿˜çš„ä¹˜å®¢æœ‰æ›´é«˜çš„ç¥¨ä»·ä¸­ä½æ•°ï¼Œä¸”å‡ ä¹ç¿»å€ã€‚è¿™å¯èƒ½ä¸ä¼˜å…ˆä¸ºé«˜çº§èˆ±ä¹˜å®¢ï¼ˆå³ç¥¨ä»·è¾ƒé«˜çš„ä¹˜å®¢ï¼‰æä¾›æ•‘ç”Ÿè‰‡æœ‰å…³ã€‚

å¸Œæœ›è¿™ä¸ªç®€å•çš„ä¾‹å­èƒ½å¤Ÿå±•ç¤ºé€šè¿‡åˆ†ç»„èšåˆä»æ•°æ®ä¸­æå–è§è§£çš„æ½œåŠ›ã€‚é‚£ä¹ˆï¼Œç°åœ¨è®©æˆ‘ä»¬åœ¨ä¸€ä¸ªæ›´æœ‰è¶£çš„æ•°æ®é›†ä¸Šå°è¯•ä¸€ä¸‹åˆ†ç»„èšåˆï¼

# æ•°æ®é›†

æˆ‘ä»¬å°†ä½¿ç”¨åœ°é“å·é™…äº¤é€šé‡æ•°æ®é›†ã€‚è¿™æ˜¯ä¸€ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†ï¼Œå…·æœ‰[åˆ›æ„å…±äº« 4.0 è®¸å¯è¯](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)ï¼ˆå…è®¸ä»¥ä»»ä½•ç›®çš„å…±äº«å’Œä¿®æ”¹æ•°æ®é›†ï¼‰ã€‚

è¯¥æ•°æ®é›†åŒ…å« 2012-2018 å¹´é—´æ˜å°¼é˜¿æ³¢åˆ©æ–¯-åœ£ä¿ç½—ï¼Œæ˜å°¼è‹è¾¾å· I-94 è¥¿è¡Œçš„æ¯å°æ—¶äº¤é€šé‡æ•°æ®ï¼ŒåŒæ—¶ä¹ŸåŒ…å«å¤©æ°”è¯¦æƒ…ã€‚æ•°æ®å­—å…¸ä¿¡æ¯å¯ä»¥åœ¨å…¶[UCI æœºå™¨å­¦ä¹ åº“](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)é¡µé¢æ‰¾åˆ°ã€‚

```py
import pandas as pd

# load dataset
df = pd.read_csv("dir/to/Metro_Interstate_Traffic_Volume.csv")

# convert date_time column from object to proper datetime format
df['date_time'] = pd.to_datetime(df['date_time'])

# head
df.head()
```

![](img/32fdeb6df51b8acd7fcde2589ae5b6ff.png)

äº¤é€šæ•°æ®ï¼ˆdfï¼‰å¤´éƒ¨ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

å¯¹äºè¿™ä¸ªåšå®¢ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä»…ä½¿ç”¨ 2016 å¹´åŠä¹‹åçš„æ•°æ®ï¼Œå› ä¸ºæ—©æœŸçš„äº¤é€šæ•°æ®ç¼ºå¤±ï¼ˆè‡ªå·±å°è¯•æ£€æŸ¥ä¸€ä¸‹ï¼Œä½œä¸ºç»ƒä¹ ï¼ï¼‰ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ·»åŠ ä¸€ä¸ªæ–°çš„åˆ—`is_congested`ï¼Œå¦‚æœ`traffic_volume`è¶…è¿‡ 5000ï¼Œåˆ™å€¼ä¸º 1ï¼Œå¦åˆ™ä¸º 0ã€‚

```py
# only consider 2016 onwards data
df = df.loc[df['date_time']>="2016-01-01",:]

# feature engineering is_congested column
df['is_congested'] = df['traffic_volume'].apply(lambda x: 1 if x > 5000 else 0)
```

# åœ°é“äº¤é€š EDA

ä»¥åˆ†ç»„èšåˆä½œä¸ºä¸»è¦æ–¹æ³•ï¼Œæˆ‘ä»¬å°†å°è¯•å›ç­”ä»¥ä¸‹åˆ†æé—®é¢˜ã€‚

1.  äº¤é€šé‡çš„æœˆåº¦å˜åŒ–å¦‚ä½•ï¼Ÿ

1.  ä¸€å‘¨å†…æ¯å¤©çš„äº¤é€šæ¦‚å†µå¦‚ä½•ï¼ˆæ˜ŸæœŸä¸€ã€æ˜ŸæœŸäºŒç­‰ï¼‰ï¼Ÿ

1.  å…¸å‹çš„ 24 å°æ—¶äº¤é€šé‡æ˜¯å¦‚ä½•å˜åŒ–çš„ï¼ŒæŒ‰å·¥ä½œæ—¥ä¸å‘¨æœ«è¿›è¡ŒåŒºåˆ†ï¼Ÿ

1.  å“ªäº›å¤©æ°”æ¡ä»¶ä¸æ›´é«˜çš„æ‹¥å µç‡ç›¸å…³ï¼Ÿ

## äº¤é€šé‡çš„æœˆåº¦å˜åŒ–

è¿™ä¸ªé—®é¢˜è¦æ±‚æˆ‘ä»¬æŒ‰æœˆèšåˆï¼ˆæ±‚å’Œï¼‰äº¤é€šé‡æ•°æ®ã€‚ç”±äºæˆ‘ä»¬æ²¡æœ‰`month`åˆ—ï¼Œæˆ‘ä»¬éœ€è¦åŸºäº`date_time`åˆ—æ´¾ç”Ÿå‡ºè¯¥åˆ—ã€‚

æœ‰äº†`month`åˆ—ï¼Œæˆ‘ä»¬å¯ä»¥åŸºäºè¯¥åˆ—è¿›è¡Œåˆ†ç»„ï¼Œå¹¶è®¡ç®—`traffic_volume`çš„æ€»å’Œã€‚ä»£ç å¦‚ä¸‹æ‰€ç¤ºã€‚

```py
# create month column based on date_time
# sample values: 2016-01, 2026-02
df['month'] = df['date_time'].dt.to_period("M")

# get sum of traffic_volume by month
monthly_traffic = df.groupby('month', as_index=False).agg(
    total_traffic = ('traffic_volume', 'sum')
)

# convert month column to string for viz
monthly_traffic['month'] = monthly_traffic['month'].astype(str)

monthly_traffic.head()
```

![](img/dae775c6786baf7cb6a9c5ecad22263a.png)

æœˆåº¦äº¤é€šå¤´éƒ¨ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

æˆ‘ä»¬å¯ä»¥ä»è¿™ä¸ªæ•°æ®æ¡†ä¸­ç»˜åˆ¶æŠ˜çº¿å›¾ï¼

```py
# draw time series plot
plt.figure(figsize=(12,5))
sns.lineplot(data=monthly_traffic, x ="month", y="total_traffic")
plt.xticks(rotation=90)
plt.title("Monthly Traffic Volume")
plt.show()
```

![](img/6ab9165cf2cfe4d78db6ad1b200f250b.png)

æœˆåº¦äº¤é€šé‡ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

ä¸Šé¢çš„å¯è§†åŒ–æ˜¾ç¤ºï¼Œåœ¨æ‰€è€ƒè™‘çš„æ•°æ®æœŸé—´å†…ï¼Œäº¤é€šé‡æ™®éå¢åŠ ã€‚

## æ¯æ—¥äº¤é€šæ¦‚å†µ

ä¸ºäº†åˆ†æè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸¤ä¸ªé¢å¤–çš„åˆ—ï¼š`date`å’Œ`dayname`ã€‚å‰è€…ç”¨ä½œä¸»è¦çš„åˆ†ç»„ä¾æ®ï¼Œè€Œåè€…ç”¨äºåœ¨å±•ç¤ºæ•°æ®æ—¶è¿›è¡Œç»†åˆ†ã€‚

åœ¨æ¥ä¸‹æ¥çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†`date`å’Œ`dayname`åˆ—ã€‚ä¹‹åï¼Œæˆ‘ä»¬åŸºäºè¿™ä¸¤åˆ—è¿›è¡Œåˆ†ç»„ï¼Œä»¥è·å–`traffic_volume`çš„æ€»å’Œã€‚è¯·æ³¨æ„ï¼Œç”±äº`dayname`æ¯”`date`æ›´ç²—ç•¥ï¼ˆèšåˆå±‚çº§è¾ƒé«˜ï¼‰ï¼Œå®é™…ä¸Šæ„å‘³ç€æˆ‘ä»¬æ˜¯åŸºäº`date`å€¼è¿›è¡Œèšåˆçš„ã€‚

```py
# create column date from date_time
# sample values: 2016-01-01, 2016-01-02
df['date'] = df['date_time'].dt.to_period('D')

# create  dayname column
# sample values: Monday, Tuesday
df['dayname'] = df['date_time'].dt.day_name()

# get sum of traffic, at date level
daily_traffic = df.groupby(['dayname','date'], as_index=False).agg(
    total_traffic = ('traffic_volume', 'sum')
)

# map dayname to number for viz later
dayname_map = {
    'Monday': 1,
    'Tuesday': 2,
    'Wednesday': 3,
    'Thursday': 4,
    'Friday': 5,
    'Saturday': 6,
    'Sunday': 7
}

daily_traffic['dayname_index'] = daily_traffic['dayname'].map(dayname_map)
daily_traffic = daily_traffic.sort_values(by='dayname_index')

daily_traffic.head()
```

![](img/276b382c99b6e35b87a65c410af1b682.png)

daily_traffic å¤´éƒ¨æ•°æ®ï¼ˆå›¾åƒæ¥æºï¼šä½œè€…ï¼‰

ä¸Šè¡¨åŒ…å«äº†æŒ‰æ˜ŸæœŸåç§°åˆ’åˆ†çš„æ¯æ—¥æ€»äº¤é€šé‡çš„ä¸åŒè¡¨ç°å½¢å¼ã€‚ç®±å½¢å›¾å¯æœ‰æ•ˆå±•ç¤ºè¿™äº›äº¤é€šé‡çš„å˜åŒ–ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿç†è§£æ˜ŸæœŸä¸€ã€æ˜ŸæœŸäºŒç­‰çš„äº¤é€šé‡å·®å¼‚ã€‚

```py
# draw boxplot per day name
plt.figure(figsize=(12,5))
sns.boxplot(data=daily_traffic, x="dayname", y="total_traffic")
plt.xticks(rotation=90)
plt.title("Daily Traffic Volume")
plt.show()
```

![](img/f16f99935a28b55c6b2cb92e791c7921.png)

ä¸Šå›¾æ˜¾ç¤ºï¼Œæ‰€æœ‰å·¥ä½œæ—¥ï¼ˆå‘¨ä¸€è‡³å‘¨äº”ï¼‰çš„äº¤é€šå¯†åº¦å¤§è‡´ç›¸åŒã€‚å‘¨æœ«ï¼ˆå‘¨å…­å’Œå‘¨æ—¥ï¼‰çš„äº¤é€šè¾ƒå°‘ï¼Œå…¶ä¸­å‘¨æ—¥çš„äº¤é€šæœ€å°‘ã€‚

## æŒ‰å‘¨æœ«çŠ¶æ€ç»†åˆ†çš„å°æ—¶äº¤é€šæ¨¡å¼

ä¸ä¹‹å‰çš„é—®é¢˜ç±»ä¼¼ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸¤ä¸ªæ–°åˆ—æ¥å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œå³`hour`å’Œ`is_weekend`ã€‚

ä½¿ç”¨ç›¸åŒçš„æŠ€å·§ï¼Œæˆ‘ä»¬å°†æŒ‰`is_weekend`å’Œ`hour`åˆ—è¿›è¡Œåˆ†ç»„ï¼Œä»¥è·å–`traffic_volume`çš„å¹³å‡å€¼ã€‚

```py
# extract hour digit from date_time
# sample values: 1,2,3
df['hour'] = df['date_time'].dt.hour

# create is_weekend flag based on dayname
df['is_weekend'] = df['dayname'].apply(lambda x: 1 if x in ['Saturday', 'Sunday'] else 0)

# get average traffic at hour level, broken down by is_weekend flag
hourly_traffic = df.groupby(['is_weekend','hour'], as_index=False).agg(
    avg_traffic = ('traffic_volume', 'mean')
)

hourly_traffic.head()
```

![](img/d375c70aabf7ca5a524c4d0c70828ef4.png)

hourly_traffic å¤´éƒ¨æ•°æ®ï¼ˆå›¾åƒæ¥æºï¼šä½œè€…ï¼‰

å¯¹äºå¯è§†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¡å½¢å›¾ï¼Œå¹¶æŒ‰ç…§`is_weekend`æ ‡å¿—è¿›è¡Œç»†åˆ†ã€‚

```py
# draw as barplot with hue = is_weekend
plt.figure(figsize=(20,6))
sns.barplot(data=hourly_traffic, x='hour', y='avg_traffic', hue='is_weekend')
plt.title("Average Hourly Traffic Volume: Weekdays (blue) vs Weekend (orange)", fontsize=14)
plt.show()
```

![](img/c34979eebbbc1661a4b9e0f846e0921b.png)

æŒ‰å‘¨æœ«çŠ¶æ€åˆ’åˆ†çš„å°æ—¶äº¤é€šæ¨¡å¼ï¼ˆå›¾åƒæ¥æºï¼šä½œè€…ï¼‰

éå¸¸æœ‰è¶£ä¸”ä¸°å¯Œçš„å¯è§†åŒ–ï¼è§‚å¯Ÿç»“æœï¼š

1.  å·¥ä½œæ—¥çš„äº¤é€šå‘ˆåŒå³°åˆ†å¸ƒæ¨¡å¼ã€‚å®ƒåœ¨æ—©ä¸Š 6 ç‚¹åˆ° 8 ç‚¹å’Œä¸‹åˆ 4 ç‚¹åˆ° 5 ç‚¹ä¹‹é—´è¾¾åˆ°äº¤é€šé‡çš„å³°å€¼ã€‚è¿™æ˜¯ç›´è§‚çš„ï¼Œå› ä¸ºè¿™äº›æ—¶é—´æ®µä»£è¡¨ç€äººä»¬ä¸Šä¸‹ç­çš„æ—¶é—´ã€‚

1.  å‘¨æœ«çš„äº¤é€šéµå¾ªå®Œå…¨ä¸åŒçš„æ¨¡å¼ã€‚å®ƒå‘ˆå•å³°å½¢çŠ¶ï¼Œä¸”æœ‰ä¸€ä¸ªè¾ƒå¤§çš„é«˜å³°åŒºé—´ï¼ˆ12â€“17 ç‚¹ï¼‰ã€‚å°½ç®¡æ€»ä½“ä¸Šï¼ˆäº¤é€šé‡è¾ƒå°‘ï¼‰ä½äºå·¥ä½œæ—¥çš„åŒä¸€æ—¶æ®µï¼Œä½†å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå‘¨æœ«çš„æ·±å¤œæ—¶æ®µï¼ˆ22â€“2 ç‚¹ï¼‰äº¤é€šå®é™…ä¸Šæ›´é«˜ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºäººä»¬åœ¨å‘¨æœ«æ™šä¸Šå¾…å¾—æ›´æ™šã€‚

## ä¸æ‹¥å µç›¸å…³çš„å¤©æ°”ç±»å‹

ä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ•°æ®é›†ä¸­æ¯ç§å¤©æ°”æ¡ä»¶ä¸‹çš„æ‹¥å µç‡ï¼ˆåˆ©ç”¨`is_congested`åˆ—ï¼‰ã€‚æˆ‘ä»¬èƒ½é€šè¿‡åˆ†ç»„èšåˆæ¥è®¡ç®—å—ï¼Ÿå½“ç„¶å¯ä»¥ï¼

éœ€è¦æ³¨æ„çš„å…³é”®ç‚¹æ˜¯ï¼Œ`is_congested`åˆ—æ˜¯äºŒè¿›åˆ¶çš„ã€‚å› æ­¤ï¼Œæ‹¥å µç‡å¯ä»¥é€šè¿‡ç®€å•åœ°å¯¹è¯¥åˆ—æ±‚å¹³å‡å€¼æ¥è®¡ç®—ï¼äºŒè¿›åˆ¶åˆ—çš„å¹³å‡å€¼ç­‰äº`count(rows with value = 1)/count(all rows)` â€”â€” è¿™å°±æ˜¯æ‹¥å µç‡çš„å®šä¹‰ã€‚

åŸºäºè¿™ä¸€ç²¾å¦™çš„è§‚å¯Ÿï¼Œæˆ‘ä»¬æ‰€è¦åšçš„å°±æ˜¯æŒ‰`weather_description`åˆ†ç»„ï¼Œå¯¹`is_congested`æ±‚å¹³å‡å€¼ï¼ˆå³å‡å€¼ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æŒ‰`congested_rate`é™åºæ’åˆ—ç»“æœã€‚

```py
# rate of congestion (is_congested) , grouped by weather description
congested_weather = df.groupby('weather_description', as_index=False).agg(
    congested_rate = ('is_congested', 'mean')
).sort_values(by='congested_rate', ascending=False, ignore_index=True)

congested_weather.head()
```

![](img/dcb0a5842e7936cb2dee5f7fa295da63.png)

æ‹¥å µå¤©æ°”å¤´ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

```py
# draw as barplot
plt.figure(figsize=(20,6))
sns.barplot(data=congested_weather, x='weather_description', y='congested_rate')
plt.xticks(rotation=90)
plt.title('Top Weather with High Congestion Rates')
plt.show()
```

![](img/b7b2ea4c435d20fdc4c0983da5822c05.png)

åŸºäºæ‹¥å µç‡çš„å¤©æ°”æ’è¡Œï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

ä»å›¾è¡¨æ¥çœ‹ï¼š

1.  æ‹¥å µç‡æœ€é«˜çš„ä¸‰ç§å¤©æ°”æƒ…å†µæ˜¯å†°é›¹ã€å°é˜µé›ªå’Œæš´é›¨ã€‚

1.  ä¸æ­¤åŒæ—¶ï¼Œå°é›¨å’Œé›ªã€å¸¦æ¯›æ¯›é›¨çš„é›·æš´ã€å†°å†»é›¨å’Œé˜µé£å¹¶æœªå¼•èµ·ä»»ä½•æ‹¥å µã€‚åœ¨å¦‚æ­¤æç«¯çš„å¤©æ°”ä¸‹ï¼Œäººä»¬ä¸€å®šéƒ½å¾…åœ¨å®¤å†…äº†ï¼

# ç»“å°¾

åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å¦‚ä½•åœ¨ EDA ç»ƒä¹ ä¸­ä½¿ç”¨åˆ†ç»„èšåˆã€‚æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œè¿™é¡¹æŠ€æœ¯åœ¨ä»æ•°æ®ä¸­æ­ç¤ºæœ‰è¶£ä¸”æœ‰ç”¨çš„è§è§£æ—¶éå¸¸æœ‰æ•ˆï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ç²’åº¦æ•°æ®æ—¶ã€‚

å¸Œæœ›ä½ èƒ½åœ¨ä¸‹ä¸€ä¸ª EDA é¡¹ç›®ä¸­ç»ƒä¹ ä½¿ç”¨åˆ†ç»„èšåˆï¼æ€»çš„æ¥è¯´ï¼Œæ„Ÿè°¢ä½ çš„é˜…è¯»ï¼Œæ¬¢è¿åœ¨[LinkedIn](https://www.linkedin.com/in/pararawendy-indarjo/)ä¸Šä¸æˆ‘è”ç³»ï¼ğŸ‘‹
