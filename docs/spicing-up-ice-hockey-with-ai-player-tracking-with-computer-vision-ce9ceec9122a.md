# ç”¨ AI ä¸ºå†°çƒå¢æ·»è¶£å‘³ï¼šåˆ©ç”¨è®¡ç®—æœºè§†è§‰è¿›è¡Œçƒå‘˜è¿½è¸ª

> åŸæ–‡ï¼š[`towardsdatascience.com/spicing-up-ice-hockey-with-ai-player-tracking-with-computer-vision-ce9ceec9122a?source=collection_archive---------0-----------------------#2024-07-09`](https://towardsdatascience.com/spicing-up-ice-hockey-with-ai-player-tracking-with-computer-vision-ce9ceec9122a?source=collection_archive---------0-----------------------#2024-07-09)

![](img/c26f194ba6b3bcdd31b1a7dfbad44347.png)

## ä½¿ç”¨ PyTorchã€è®¡ç®—æœºè§†è§‰æŠ€æœ¯å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œæˆ‘å¼€å‘äº†ä¸€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥è¿½è¸ªçƒå‘˜ã€çƒé˜Ÿä»¥åŠåŸºæœ¬çš„è¡¨ç°ç»Ÿè®¡æ•°æ®

[](https://medium.com/@raul.vizcarrach?source=post_page---byline--ce9ceec9122a--------------------------------)![Raul Vizcarra Chirinos](https://medium.com/@raul.vizcarrach?source=post_page---byline--ce9ceec9122a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ce9ceec9122a--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ce9ceec9122a--------------------------------) [Raul Vizcarra Chirinos](https://medium.com/@raul.vizcarrach?source=post_page---byline--ce9ceec9122a--------------------------------)

Â·å‘å¸ƒäº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ce9ceec9122a--------------------------------) Â·30 åˆ†é’Ÿé˜…è¯»Â·2024 å¹´ 7 æœˆ 9 æ—¥

--

ç°åœ¨ï¼Œæˆ‘ä¸åƒä»¥å‰é‚£æ ·é¢‘ç¹åœ°æ‰“å†°çƒäº†ï¼Œä½†ä»å°å†°çƒå°±æ˜¯æˆ‘ç”Ÿæ´»çš„ä¸€éƒ¨åˆ†ã€‚æœ€è¿‘ï¼Œæˆ‘æœ‰æœºä¼šåœ¨åˆ©é©¬ä¸¾åŠçš„é¦–å±Šå†°çƒé”¦æ ‡èµ›ï¼ˆ3 å¯¹ 3ï¼‰ä¸­ï¼ŒååŠ©è£åˆ¤å°å¹¶è®°å½•ä¸€äº›ç»Ÿè®¡æ•°æ®ã€‚æ­¤æ¬¡æ´»åŠ¨å¾—åˆ°äº†ç§˜é²æ»‘å†°æ›²æ£çƒåä¼šï¼ˆAPHLï¼‰çš„å·¨å¤§æ”¯æŒï¼Œå¹¶ä¸”[å‹è°Šè”ç›Ÿ](https://friendshipleague.org/)ä¹Ÿäº²åˆ‡åœ°å‚ä¸å…¶ä¸­ã€‚ä¸ºäº†åŠ å…¥ä¸€äº› AI å…ƒç´ ï¼Œæˆ‘ä½¿ç”¨äº†**PyTorch**ã€**è®¡ç®—æœºè§†è§‰**æŠ€æœ¯å’Œ**å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰**æ¥æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œè¿½è¸ªçƒå‘˜å’Œçƒé˜Ÿï¼Œå¹¶æ”¶é›†ä¸€äº›åŸºæœ¬çš„è¡¨ç°æ•°æ®ã€‚

æœ¬æ–‡æ—¨åœ¨æˆä¸ºè®¾è®¡å’Œéƒ¨ç½²è¯¥æ¨¡å‹çš„**å¿«é€ŸæŒ‡å—**ã€‚å°½ç®¡æ¨¡å‹ä»éœ€è¿›è¡Œä¸€äº›å¾®è°ƒï¼Œä½†æˆ‘å¸Œæœ›å®ƒèƒ½å¸®åŠ©ä»»ä½•äººå…¥é—¨è®¡ç®—æœºè§†è§‰åœ¨ä½“è‚²ä¸­çš„åº”ç”¨ã€‚æˆ‘è¿˜è¦ç‰¹åˆ«æ„Ÿè°¢å¹¶æ„Ÿè°¢[ç§˜é²æ»‘å†°æ›²æ£çƒåä¼šï¼ˆAPHLï¼‰](https://www.instagram.com/aphl.pe/?igsh=MThvZWxhNThwdXpibA%3D%3D)å…è®¸æˆ‘ä½¿ç”¨æ¯”èµ›çš„ 40 ç§’è§†é¢‘æ ·æœ¬è¿›è¡Œæ­¤é¡¹ç›®ï¼ˆ*ä½ å¯ä»¥åœ¨*[*é¡¹ç›®çš„ GitHub ä»“åº“*](https://github.com/rvizcarra15/IceHockey_ComputerVision_PyTorch)*æ‰¾åˆ°è§†é¢‘è¾“å…¥æ ·æœ¬*ï¼‰ã€‚

# æ¶æ„

åœ¨ç»§ç»­è¿›è¡Œé¡¹ç›®ä¹‹å‰ï¼Œæˆ‘åšäº†ä¸€äº›å¿«é€Ÿç ”ç©¶ï¼Œæ‰¾åˆ°ä¸€ä¸ªå¯ä»¥ä½œä¸ºåŸºå‡†çš„æ–¹å‘ï¼Œä»¥é¿å…â€œé‡æ–°å‘æ˜è½®å­â€ã€‚æˆ‘å‘ç°ï¼Œåœ¨ä½¿ç”¨è®¡ç®—æœºè§†è§‰è¿½è¸ªçƒå‘˜æ–¹é¢ï¼Œæœ‰å¾ˆå¤šæœ‰è¶£çš„ç ”ç©¶æˆæœï¼Œå°¤å…¶æ˜¯åœ¨è¶³çƒé¢†åŸŸï¼ˆ*è¿™å¹¶ä¸ä»¤äººæƒŠè®¶ï¼Œè¶³çƒæ˜¯ä¸–ç•Œä¸Šæœ€å—æ¬¢è¿çš„å›¢é˜Ÿè¿åŠ¨*ï¼‰ã€‚ç„¶è€Œï¼Œæˆ‘å¹¶æ²¡æœ‰æ‰¾åˆ°å¾ˆå¤šå†°çƒæ–¹é¢çš„èµ„æºã€‚[Roboflow](https://universe.roboflow.com/search?q=hockey) æä¾›äº†ä¸€äº›æœ‰è¶£çš„é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒè‡ªå·±çš„æ¨¡å‹ï¼Œä½†ä½¿ç”¨æ‰˜ç®¡æ¨¡å‹æ—¶å‡ºç°äº†ä¸€äº›å»¶è¿Ÿé—®é¢˜ï¼Œç¨åæˆ‘ä¼šè¿›ä¸€æ­¥è§£é‡Šã€‚æœ€ç»ˆï¼Œæˆ‘å€Ÿç”¨äº†è¶³çƒç›¸å…³çš„èµ„æ–™æ¥è¯»å–è§†é¢‘å¸§å¹¶è·å¾—å•ç‹¬çš„è·Ÿè¸ª IDï¼Œéµå¾ªäº†[è¿™ä¸ªæ•™ç¨‹](https://youtu.be/neBZ6huolkg?feature=shared)ä¸­è§£é‡Šçš„åŸºæœ¬åŸç†å’Œè·Ÿè¸ªæ–¹æ³•ï¼ˆ*å¦‚æœä½ æœ‰å…´è¶£æ›´å¥½åœ°ç†è§£ä¸€äº›åŸºæœ¬çš„è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œæˆ‘å»ºè®®è‡³å°‘è§‚çœ‹å‰ä¸€ä¸ªåŠå°æ—¶çš„æ•™ç¨‹*ï¼‰ã€‚

åœ¨è¦†ç›–äº†è·Ÿè¸ª ID åï¼Œæˆ‘å¼€å§‹æ„å»ºè‡ªå·±çš„è·¯å¾„ã€‚åœ¨æœ¬æ–‡çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°è¿™ä¸ªé¡¹ç›®æ˜¯å¦‚ä½•ä»ä¸€ä¸ªç®€å•çš„ç‰©ä½“æ£€æµ‹ä»»åŠ¡å‘å±•æˆä¸€ä¸ªèƒ½å¤Ÿå…¨é¢æ£€æµ‹çƒå‘˜ã€çƒé˜Ÿå¹¶æä¾›ä¸€äº›åŸºæœ¬è¡¨ç°æŒ‡æ ‡çš„æ¨¡å‹çš„ï¼ˆ*ç¤ºä¾‹å‰ªè¾‘ä» 01 åˆ° 08ï¼Œä½œè€…è‡ªåˆ›*ï¼‰ã€‚

![](img/e100ca9ea1c1eb7ab22675a9de0f18ef.png)

æ¨¡å‹æ¶æ„ã€‚ä½œè€…è‡ªåˆ›

# è·Ÿè¸ªæœºåˆ¶

è·Ÿè¸ªæœºåˆ¶æ˜¯æ¨¡å‹çš„æ ¸å¿ƒã€‚å®ƒç¡®ä¿è§†é¢‘ä¸­çš„æ¯ä¸ªæ£€æµ‹åˆ°çš„ç‰©ä½“éƒ½èƒ½è¢«è¯†åˆ«å¹¶åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ ‡è¯†ç¬¦ï¼Œä¿æŒè¯¥èº«ä»½åœ¨æ¯ä¸€å¸§ä¸­çš„ä¸€è‡´æ€§ã€‚è·Ÿè¸ªæœºåˆ¶çš„ä¸»è¦ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼š

1.  **YOLOï¼ˆYou Only Look Onceï¼‰ï¼š** å®ƒæ˜¯ä¸€ç§å¼ºå¤§çš„å®æ—¶ç‰©ä½“æ£€æµ‹ç®—æ³•ï¼Œæœ€åˆåœ¨ 2015 å¹´çš„è®ºæ–‡â€œ[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)â€ä¸­æå‡ºã€‚å®ƒä»¥é€Ÿåº¦å’Œåœ¨å¤§çº¦ 80 ä¸ªé¢„è®­ç»ƒç±»åˆ«ä¸­çš„é€šç”¨æ€§ä¸ºç‰¹ç‚¹ï¼ˆ*å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå®ƒè¿˜å¯ä»¥åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥æ£€æµ‹ç‰¹å®šç‰©ä½“*ï¼‰ã€‚å¯¹äºæˆ‘ä»¬çš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œæˆ‘ä»¬å°†ä¾èµ– YOLOv8xï¼Œè¿™æ˜¯ä¸€ç§ç”± Ultralytics åŸºäºä¹‹å‰ç‰ˆæœ¬çš„ YOLO æ„å»ºçš„è®¡ç®—æœºè§†è§‰æ¨¡å‹ã€‚ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/ultralytics/ultralytics)ä¸‹è½½å®ƒã€‚

1.  **ByteTrack è·Ÿè¸ªå™¨ï¼š** è¦ç†è§£ ByteTrackï¼Œæˆ‘ä»¬å¿…é¡»å…ˆäº†è§£å¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼ŒMultiple Object Trackingï¼‰ï¼Œå®ƒæ¶‰åŠåœ¨è§†é¢‘åºåˆ—ä¸­è¿½è¸ªå¤šä¸ªç‰©ä½“çš„è¿åŠ¨ï¼Œå¹¶å°†å½“å‰å¸§ä¸­æ£€æµ‹åˆ°çš„ç‰©ä½“ä¸å‰ä¸€å¸§ä¸­çš„ç›¸åº”ç‰©ä½“è¿›è¡Œå…³è”ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ ByteTrackï¼ˆ*2021 å¹´åœ¨è®ºæ–‡â€œ[*ByteTrack: Multi-Object Tracking by Associating Every Detection Box*](https://arxiv.org/abs/2110.06864)â€ä¸­æå‡º*ï¼‰ã€‚ä¸ºäº†å®ç° ByteTrack è·Ÿè¸ªå™¨å¹¶ä¸ºæ£€æµ‹åˆ°çš„ç‰©ä½“åˆ†é…è½¨è¿¹ IDï¼Œæˆ‘ä»¬å°†ä¾èµ– Python çš„ supervision åº“ã€‚

1.  **OpenCVï¼š** æ˜¯ä¸€ä¸ªå¹¿æ³›åº”ç”¨äºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„ Python åº“ã€‚å¯¹äºæˆ‘ä»¬çš„ç”¨ä¾‹ï¼Œæˆ‘ä»¬å°†ä¾èµ–[OpenCV](https://opencv.org/)æ¥å¯è§†åŒ–å¹¶æ ‡æ³¨è§†é¢‘å¸§ä¸­çš„è¾¹ç•Œæ¡†å’Œæ¯ä¸ªæ£€æµ‹ç‰©ä½“çš„æ–‡æœ¬ä¿¡æ¯ã€‚

ä¸ºäº†æ„å»ºæˆ‘ä»¬çš„è¿½è¸ªæœºåˆ¶ï¼Œæˆ‘ä»¬å°†ä»ä»¥ä¸‹ä¸¤æ­¥å¼€å§‹ï¼š

+   ä½¿ç”¨ ByteTrack éƒ¨ç½² YOLO æ¨¡å‹æ¥æ£€æµ‹ç‰©ä½“ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯çƒå‘˜ï¼‰å¹¶åˆ†é…å”¯ä¸€çš„è¿½è¸ª IDã€‚

+   åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸ï¼Œå°†ç‰©ä½“è¿½è¸ªä¿¡æ¯å­˜å‚¨åœ¨ä¸€ä¸ª pickleï¼ˆpklï¼‰æ–‡ä»¶ä¸­ã€‚è¿™å°†æå¤§åœ°å¸®åŠ©æˆ‘ä»¬é¿å…æ¯æ¬¡è¿è¡Œä»£ç æ—¶éƒ½éœ€è¦é€å¸§æ‰§è¡Œè§†é¢‘ç‰©ä½“æ£€æµ‹è¿‡ç¨‹ï¼ŒèŠ‚çœå¤§é‡æ—¶é—´ã€‚

å¯¹äºæ¥ä¸‹æ¥çš„æ­¥éª¤ï¼Œæˆ‘ä»¬éœ€è¦ä»¥ä¸‹ Python åŒ…ï¼š

```py
pip install ultralytics
pip install supervision
pip install opencv-python
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æŒ‡å®šæˆ‘ä»¬çš„åº“å’Œæ ·æœ¬è§†é¢‘æ–‡ä»¶ä»¥åŠ pickle æ–‡ä»¶çš„è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼›å¦‚æœæ²¡æœ‰ï¼Œä»£ç ä¼šåˆ›å»ºä¸€ä¸ªå¹¶å°†å…¶ä¿å­˜åœ¨ç›¸åŒè·¯å¾„ä¸‹ï¼‰ï¼š

```py
#**********************************LIBRARIES*********************************#
from ultralytics import YOLO
import supervision as sv
import pickle
import os
import cv2

# INPUT-video file
video_path = 'D:/PYTHON/video_input.mp4'
# OUTPUT-Video File
output_video_path = 'D:/PYTHON/output_video.mp4'
# PICKLE FILE (IF AVAILABLE LOADS IT IF NOT, SAVES IT IN THIS PATH)
pickle_path = 'D:/PYTHON/stubs/track_stubs.pkl'
```

ç°åœ¨è®©æˆ‘ä»¬ç»§ç»­å®šä¹‰æˆ‘ä»¬çš„è¿½è¸ªæœºåˆ¶*ï¼ˆä½ å¯ä»¥åœ¨[*é¡¹ç›®çš„ GitHub ä»“åº“*](https://github.com/rvizcarra15/IceHockey_ComputerVision_PyTorch)ä¸­æ‰¾åˆ°è§†é¢‘è¾“å…¥ç¤ºä¾‹ï¼‰*ï¼š

```py
#*********************************TRACKING MECHANISM**************************#
class HockeyAnalyzer:
    def __init__(self, model_path):
        self.model = YOLO(model_path) 
        self.tracker = sv.ByteTrack()

    def detect_frames(self, frames):
        batch_size = 20 
        detections = [] 
        for i in range(0, len(frames), batch_size):
            detections_batch = self.model.predict(frames[i:i+batch_size], conf=0.1)
            detections += detections_batch
        return detections

#********LOAD TRACKS FROM FILE OR DETECT OBJECTS-SAVES PICKLE FILE************#

    def get_object_tracks(self, frames, read_from_stub=False, stub_path=None):
        if read_from_stub and stub_path is not None and os.path.exists(stub_path):
            with open(stub_path, 'rb') as f:
                tracks = pickle.load(f)
            return tracks

        detections = self.detect_frames(frames)

        tracks = {"person": []}

        for frame_num, detection in enumerate(detections):
            cls_names = detection.names
            cls_names_inv = {v: k for k, v in cls_names.items()}

            # Tracking Mechanism
            detection_supervision = sv.Detections.from_ultralytics(detection)
            detection_with_tracks = self.tracker.update_with_detections(detection_supervision)
            tracks["person"].append({})

            for frame_detection in detection_with_tracks:
                bbox = frame_detection[0].tolist()
                cls_id = frame_detection[3]
                track_id = frame_detection[4]

                if cls_id == cls_names_inv.get('person', None):
                    tracks["person"][frame_num][track_id] = {"bbox": bbox}

            for frame_detection in detection_supervision:
                bbox = frame_detection[0].tolist()
                cls_id = frame_detection[3]

        if stub_path is not None:
            with open(stub_path, 'wb') as f:
                pickle.dump(tracks, f)

        return tracks

#***********************BOUNDING BOXES AND TRACK-IDs**************************#

    def draw_annotations(self, video_frames, tracks):
        output_video_frames = []
        for frame_num, frame in enumerate(video_frames):
            frame = frame.copy() 
            player_dict = tracks["person"][frame_num]

            # Draw Players
            for track_id, player in player_dict.items():
                color = player.get("team_color", (0, 0, 255))  
                bbox = player["bbox"]
                x1, y1, x2, y2 = map(int, bbox)         
            # Bounding boxes
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            # Track_id 
                cv2.putText(frame, str(track_id), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

            output_video_frames.append(frame)

        return output_video_frames
```

è¯¥æ–¹æ³•é¦–å…ˆåˆå§‹åŒ– YOLO æ¨¡å‹å’Œ ByteTrack è¿½è¸ªå™¨ã€‚æ¥ä¸‹æ¥ï¼Œæ¯ä¸€å¸§ä»¥ 20 å¸§ä¸ºä¸€æ‰¹è¿›è¡Œå¤„ç†ï¼Œä½¿ç”¨ YOLO æ¨¡å‹æ£€æµ‹å¹¶æ”¶é›†æ¯æ‰¹ä¸­çš„ç‰©ä½“ã€‚å¦‚æœ pickle æ–‡ä»¶å­˜åœ¨äºè·¯å¾„ä¸­ï¼Œå®ƒä¼šä»æ–‡ä»¶ä¸­é¢„è®¡ç®—å‡ºè¿½è¸ªä¿¡æ¯ã€‚å¦‚æœ pickle æ–‡ä»¶ä¸å­˜åœ¨*ï¼ˆä½ æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œä»£ç æˆ–è€…åˆ é™¤äº†ä¹‹å‰çš„ pickle æ–‡ä»¶ï¼‰*ï¼Œ**get_object_tracks** å°†æ¯ä¸ªæ£€æµ‹è½¬æ¢ä¸º ByteTrack æ‰€éœ€çš„æ ¼å¼ï¼Œç”¨è¿™äº›æ£€æµ‹æ›´æ–°è¿½è¸ªå™¨ï¼Œå¹¶å°†è¿½è¸ªä¿¡æ¯ä¿å­˜åœ¨æŒ‡å®šè·¯å¾„çš„ä¸€ä¸ªæ–° pickle æ–‡ä»¶ä¸­ã€‚æœ€åï¼Œä»£ç ä¼šè¿­ä»£æ¯ä¸€å¸§ï¼Œä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„ç‰©ä½“ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œè¿½è¸ª IDã€‚

è¦æ‰§è¡Œè¿½è¸ªå™¨å¹¶ä¿å­˜å¸¦æœ‰è¾¹ç•Œæ¡†å’Œè¿½è¸ª ID çš„æ–°è¾“å‡ºè§†é¢‘ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š

```py
#*************** EXECUTES TRACKING MECHANISM AND OUTPUT VIDEO****************#

# Read the video frames
video_frames = []
cap = cv2.VideoCapture(video_path)
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    video_frames.append(frame)
cap.release()

#********************* EXECUTE TRACKING METHOD WITH YOLO**********************#
tracker = HockeyAnalyzer('D:/PYTHON/yolov8x.pt')
tracks = tracker.get_object_tracks(video_frames, read_from_stub=True, stub_path=pickle_path)
annotated_frames = tracker.draw_annotations(video_frames, tracks)

#*********************** SAVES VIDEO FILE ************************************#
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
height, width, _ = annotated_frames[0].shape
out = cv2.VideoWriter(output_video_path, fourcc, 30, (width, height))

for frame in annotated_frames:
    out.write(frame)
out.release()
```

å¦‚æœä½ çš„ä»£ç ä¸€åˆ‡æ­£å¸¸ï¼Œä½ åº”è¯¥ä¼šå¾—åˆ°ä¸€ä¸ªç±»ä¼¼äº**ç¤ºä¾‹å‰ªè¾‘ 01**çš„è§†é¢‘è¾“å‡ºã€‚

![](img/d5caaaa073f19f9f874cb779de45aa22.png)

ç¤ºä¾‹å‰ªè¾‘ 01ï¼šåŸºç¡€è¿½è¸ªæœºåˆ¶ï¼ˆç‰©ä½“ä¸è¿½è¸ª IDï¼‰

> **æç¤º #01ï¼š** ä¸è¦ä½ä¼°ä½ çš„è®¡ç®—èƒ½åŠ›ï¼ç¬¬ä¸€æ¬¡è¿è¡Œä»£ç æ—¶ï¼Œé¢„è®¡å¸§å¤„ç†å¯èƒ½ä¼šèŠ±è´¹ä¸€äº›æ—¶é—´ï¼Œè¿™å–å†³äºä½ çš„è®¡ç®—èƒ½åŠ›ã€‚å¯¹æˆ‘æ¥è¯´ï¼Œä½¿ç”¨ CPU é…ç½®å¤„ç†å¤§çº¦éœ€è¦ 45 åˆ° 50 åˆ†é’Ÿï¼ˆå¯ä»¥è€ƒè™‘ä½¿ç”¨ CUDA ä½œä¸ºé€‰é¡¹ï¼‰ã€‚å°½ç®¡ YOLOv8x è¿½è¸ªæœºåˆ¶éå¸¸å¼ºå¤§ï¼Œä½†å®ƒéœ€è¦ç›¸å½“å¤§çš„è®¡ç®—èµ„æºï¼ˆæœ‰æ—¶æˆ‘çš„å†…å­˜å ç”¨ç‡è¾¾åˆ°äº† 99%ï¼Œå¸Œæœ›å®ƒæ²¡æœ‰å´©æºƒï¼ğŸ™„ï¼‰ã€‚å¦‚æœä½ é‡åˆ° YOLO çš„æ­¤ç‰ˆæœ¬é—®é¢˜ï¼Œå¯ä»¥è®¿é—®[Ultralyticsâ€™ GitHub](https://github.com/ultralytics/ultralytics)ï¼Œé‚£é‡Œæœ‰æ›´è½»é‡çš„æ¨¡å‹æ¥å¹³è¡¡å‡†ç¡®æ€§å’Œè®¡ç®—èƒ½åŠ›ã€‚

# å†°çƒåœº

æ­£å¦‚ä½ ä»ç¬¬ä¸€æ­¥ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬é‡åˆ°äº†ä¸€äº›æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œæ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œæ¨¡å‹æ•æ‰åˆ°æ‰€æœ‰ç§»åŠ¨ç‰©ä½“ï¼ŒåŒ…æ‹¬çƒå‘˜ã€è£åˆ¤ï¼Œç”šè‡³å†°åœºå¤–çš„ç‰©ä½“ã€‚å…¶æ¬¡ï¼Œè¿™äº›çº¢è‰²è¾¹ç•Œæ¡†ä¼šè®©è·Ÿè¸ªçƒå‘˜å˜å¾—æœ‰äº›ä¸æ¸…æ™°ï¼Œä¹Ÿä¸å¤ªé€‚åˆå±•ç¤ºã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºå°†æ£€æµ‹èŒƒå›´ç¼©å°åˆ°ä»…å†°åœºå†…çš„ç‰©ä½“ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¼šå°†åº•éƒ¨çš„è¾¹ç•Œæ¡†æ›¿æ¢ä¸ºæ¤­åœ†ï¼Œä»¥ç¡®ä¿æ›´æ¸…æ™°çš„å¯è§†æ€§ã€‚

è®©æˆ‘ä»¬å…ˆä»ä½¿ç”¨çŸ©å½¢æ¡†åˆ‡æ¢åˆ°ä½¿ç”¨æ¤­åœ†ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åªéœ€åœ¨ç°æœ‰ä»£ç ä¸­çš„æ ‡ç­¾å’Œè¾¹ç•Œæ¡†æ–¹æ³•ä¸Šæ–¹æ·»åŠ ä¸€ä¸ªæ–°çš„æ–¹æ³•ï¼š

```py
#************ Design of Ellipse for tracking players instead of Bounding boxes**************#

    def draw_ellipse(self, frame, bbox, color, track_id=None, team=None):
        y2 = int(bbox[3])
        x_center = (int(bbox[0]) + int(bbox[2])) // 2
        width = int(bbox[2]) - int(bbox[0])
        color = (255, 0, 0)
        text_color = (255, 255, 255)

        cv2.ellipse(
            frame,
            center=(x_center, y2),
            axes=(int(width) // 2, int(0.35 * width)),
            angle=0.0,
            startAngle=-45,
            endAngle=235,
            color=color,
            thickness=2,
            lineType=cv2.LINE_4
        )

        if track_id is not None:
            rectangle_width = 40
            rectangle_height = 20
            x1_rect = x_center - rectangle_width // 2
            x2_rect = x_center + rectangle_width // 2
            y1_rect = (y2 - rectangle_height // 2) + 15
            y2_rect = (y2 + rectangle_height // 2) + 15

            cv2.rectangle(frame,
                          (int(x1_rect), int(y1_rect)),
                          (int(x2_rect), int(y2_rect)),
                          color,
                          cv2.FILLED)

            x1_text = x1_rect + 12
            if track_id > 99:
                x1_text -= 10
            font_scale = 0.4
            cv2.putText(
                frame,
                f"{track_id}",
                (int(x1_text), int(y1_rect + 15)),
                cv2.FONT_HERSHEY_SIMPLEX,
                font_scale,
                text_color,
                thickness=2
            )

        return frame
```

æˆ‘ä»¬è¿˜éœ€è¦æ›´æ–°æ³¨é‡Šæ­¥éª¤ï¼Œé€šè¿‡è°ƒç”¨æ¤­åœ†æ–¹æ³•æ¥æ›¿æ¢è¾¹ç•Œæ¡†å’Œ IDï¼š

```py
#***********************BOUNDING BOXES AND TRACK-IDs**************************#

    def draw_annotations(self, video_frames, tracks):
        output_video_frames = []
        for frame_num, frame in enumerate(video_frames):
            frame = frame.copy() 
            player_dict = tracks["person"][frame_num]

            # Draw Players
            for track_id, player in player_dict.items():
                bbox = player["bbox"]

            # Draw ellipse and tracking IDs
                self.draw_ellipse(frame, bbox, (0, 255, 0), track_id)

                x1, y1, x2, y2 = map(int, bbox)

            output_video_frames.append(frame)

        return output_video_frames
```

é€šè¿‡è¿™äº›ä¿®æ”¹ï¼Œä½ çš„è§†é¢‘è¾“å‡ºåº”è¯¥çœ‹èµ·æ¥æ›´æ•´æ´ï¼Œå¦‚**ç¤ºä¾‹å‰ªè¾‘ 02**æ‰€ç¤ºã€‚

![](img/0e17fb82b7df8f4b41e25e34b5da15d6.png)

ç¤ºä¾‹å‰ªè¾‘ 02ï¼šç”¨æ¤­åœ†æ›¿ä»£è¾¹ç•Œæ¡†

ç°åœ¨ï¼Œä¸ºäº†å¤„ç†å†°åœºè¾¹ç•Œï¼Œæˆ‘ä»¬éœ€è¦å¯¹è®¡ç®—æœºè§†è§‰ä¸­çš„åˆ†è¾¨ç‡æœ‰ä¸€äº›åŸºæœ¬äº†è§£ã€‚åœ¨æˆ‘ä»¬çš„ä½¿ç”¨åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ 720pï¼ˆ1280x720 åƒç´ ï¼‰æ ¼å¼ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¤„ç†çš„æ¯ä¸€å¸§å›¾åƒçš„å°ºå¯¸ä¸º 1280 åƒç´ ï¼ˆå®½åº¦ï¼‰ä¹˜ 720 åƒç´ ï¼ˆé«˜åº¦ï¼‰ã€‚

***ä½¿ç”¨ 720pï¼ˆ1280x720 åƒç´ ï¼‰æ ¼å¼æ„å‘³ç€ä»€ä¹ˆï¼Ÿ*** è¿™æ„å‘³ç€å›¾åƒç”± 1280 ä¸ªæ°´å¹³åƒç´ å’Œ 720 ä¸ªå‚ç›´åƒç´ ç»„æˆã€‚åœ¨è¿™ç§æ ¼å¼ä¸‹ï¼Œåæ ‡ä»å›¾åƒçš„å·¦ä¸Šè§’ï¼ˆ0, 0ï¼‰å¼€å§‹ï¼Œx åæ ‡éšç€å‘å³ç§»åŠ¨è€Œå¢åŠ ï¼Œy åæ ‡éšç€å‘ä¸‹ç§»åŠ¨è€Œå¢åŠ ã€‚è¿™äº›åæ ‡ç”¨äºæ ‡è®°å›¾åƒä¸­çš„ç‰¹å®šåŒºåŸŸï¼Œæ¯”å¦‚ä½¿ç”¨ï¼ˆx1, y1ï¼‰è¡¨ç¤ºå·¦ä¸Šè§’ï¼Œä½¿ç”¨ï¼ˆx2, y2ï¼‰è¡¨ç¤ºçŸ©å½¢æ¡†çš„å³ä¸‹è§’ã€‚ç†è§£è¿™ä¸€ç‚¹æœ‰åŠ©äºæˆ‘ä»¬æµ‹é‡è·ç¦»å’Œé€Ÿåº¦ï¼Œå¹¶å†³å®šåœ¨è§†é¢‘ä¸­å…³æ³¨çš„åˆ†æåŒºåŸŸã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ä»£ç å¼€å§‹æ ‡è®°å¸§è¾¹æ¡†ä¸ºç»¿è‰²çº¿æ¡ï¼š

```py
#********************* Border Definition for Frame***********************
import cv2

video_path = 'D:/PYTHON/video_input.mp4'
cap = cv2.VideoCapture(video_path)

#**************Read, Define and Draw corners of the frame****************
ret, frame = cap.read()

bottom_left = (0, 720)
bottom_right = (1280, 720)
upper_left = (0, 0)
upper_right = (1280, 0)

cv2.line(frame, bottom_left, bottom_right, (0, 255, 0), 2)
cv2.line(frame, bottom_left, upper_left, (0, 255, 0), 2)
cv2.line(frame, bottom_right, upper_right, (0, 255, 0), 2)
cv2.line(frame, upper_left, upper_right, (0, 255, 0), 2)

#*******************Save the frame with marked corners*********************
output_image_path = 'rink_area_marked_VALIDATION.png'
cv2.imwrite(output_image_path, frame)
print("Rink area saved:", output_image_path)
```

ç»“æœåº”è¯¥æ˜¯ä¸€ä¸ªç»¿è‰²çŸ©å½¢ï¼Œå¦‚**ç¤ºä¾‹å‰ªè¾‘ 03**ä¸­ï¼ˆaï¼‰æ‰€ç¤ºã€‚ä½†ä¸ºäº†åªè¿½è¸ªå†°åœºå†…çš„ç§»åŠ¨ç‰©ä½“ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ›´åƒï¼ˆbï¼‰ä¸­çš„è¾¹ç•Œã€‚

![](img/e6de1323015e8fa64b0a9667df89ff1c.png)

å›¾ 03ï¼šå†°åœºè¾¹ç•Œå®šä¹‰ï¼ˆä½œè€…è‡ªåˆ›ï¼‰

å¾—åˆ°ï¼ˆbï¼‰çš„æ­£ç¡®è¾¹ç•Œå°±åƒä¸€ä¸ªåå¤è¯•éªŒçš„è¿‡ç¨‹ï¼Œä½ éœ€è¦æµ‹è¯•ä¸åŒçš„åæ ‡ï¼Œç›´åˆ°æ‰¾åˆ°æœ€é€‚åˆä½ æ¨¡å‹çš„è¾¹ç•Œã€‚æœ€åˆï¼Œæˆ‘çš„ç›®æ ‡æ˜¯å®Œå…¨åŒ¹é…å†°åœºè¾¹ç•Œã€‚ç„¶è€Œï¼Œè·Ÿè¸ªç³»ç»Ÿåœ¨è¾¹ç¼˜é™„è¿‘å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†æé«˜å‡†ç¡®æ€§ï¼Œæˆ‘ç¨å¾®æ‰©å¤§äº†è¾¹ç•Œï¼Œä»¥ç¡®ä¿æ‰€æœ‰å†°åœºå†…çš„è·Ÿè¸ªç‰©ä½“éƒ½è¢«æ•æ‰åˆ°ï¼ŒåŒæ—¶æ’é™¤åœºå¤–çš„ç‰©ä½“ã€‚æœ€ç»ˆçš„ç»“æœï¼Œå¦‚ï¼ˆbï¼‰æ‰€ç¤ºï¼Œæ˜¯æˆ‘èƒ½å¾—åˆ°çš„æœ€å¥½çš„ç»“æœ*(ä½ ä»ç„¶å¯ä»¥å°è¯•æ›´å¥½çš„æƒ…å†µ)*ï¼Œç”±è¿™äº›åæ ‡å®šä¹‰ï¼š

+   å·¦ä¸‹è§’ï¼š (-450, 710)

+   å³ä¸‹è§’ï¼š (2030, 710)

+   å·¦ä¸Šè§’ï¼š (352, 61)

+   å³ä¸Šè§’ï¼š (948, 61)

æœ€åï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸¤ä¸ªé¢å¤–çš„åŒºåŸŸï¼šç™½é˜Ÿå’Œé»„é˜Ÿçš„**è¿›æ”»åŒº**ï¼ˆ*æ¯ä¸ªé˜Ÿä¼çš„ç›®æ ‡åŒºåŸŸ*ï¼‰ã€‚è¿™å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ”¶é›†æ¯ä¸ªé˜Ÿä¼åœ¨å…¶å¯¹æ‰‹åŒºåŸŸå†…çš„ä¸€äº›åŸºæœ¬ä½ç½®ç»Ÿè®¡æ•°æ®å’Œå‹åŠ›æŒ‡æ ‡ã€‚

![](img/b8ea5a739ce6098b9345c2d7cfe8b332.png)

å›¾ 04ï¼šè¿›æ”»åŒºï¼ˆä½œè€…è‡ªåˆ›ï¼‰

```py
#**************YELLOW TEAM OFFENSIVE ZONE****************
Bottom Left Corner: (-450, 710)
Bottom Right Corner: (2030, 710)
Upper Left Corner: (200, 150)
Upper Right Corner: (1160, 150)

#**************WHITE TEAM OFFENSIVE ZONE****************
Bottom Left Corner: (180, 150)
Bottom Right Corner: (1100, 150)
Upper Left Corner: (352, 61)
Upper Right Corner: (900, 61)
```

æˆ‘ä»¬ç°åœ¨å…ˆæš‚æ—¶æç½®è¿™äº›åæ ‡ï¼Œå¹¶åœ¨ä¸‹ä¸€æ­¥ä¸­è§£é‡Šæˆ‘ä»¬å°†å¦‚ä½•å¯¹æ¯ä¸ªå›¢é˜Ÿè¿›è¡Œåˆ†ç±»ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æŠŠæ‰€æœ‰å†…å®¹æ±‡æ€»åˆ°æˆ‘ä»¬æœ€åˆçš„è·Ÿè¸ªæ–¹æ³•ä¸­ã€‚

# ä½¿ç”¨æ·±åº¦å­¦ä¹ è¿›è¡Œå›¢é˜Ÿé¢„æµ‹

è‡ªä» 1943 å¹´ Warren McCulloch å’Œ Walter Pitts å‘è¡¨äº†ã€Š*[*ç¥ç»æ´»åŠ¨ä¸­å›ºæœ‰æ€æƒ³çš„é€»è¾‘æ¼”ç®—*](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf)*ã€‹ä¸€æ–‡ä»¥æ¥ï¼Œå·²ç»è¿‡å»äº† 80 å¤šå¹´ã€‚è¿™ç¯‡è®ºæ–‡ä¸ºæ—©æœŸçš„ç¥ç»ç½‘ç»œç ”ç©¶å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚åæ¥ï¼Œåœ¨ 1957 å¹´ï¼Œä¸€ä¸ªç®€åŒ–çš„ç¥ç»å…ƒæ•°å­¦æ¨¡å‹ï¼ˆ*æ¥æ”¶è¾“å…¥ã€å¯¹è¿™äº›è¾“å…¥åº”ç”¨æƒé‡ã€å¯¹å…¶æ±‚å’Œå¹¶è¾“å‡ºäºŒè¿›åˆ¶ç»“æœ*ï¼‰å¯å‘äº†[Frank Rosenblatt æ„å»ºäº† Mark I](https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon)ã€‚è¿™æ˜¯ç¬¬ä¸€ä¸ªç¡¬ä»¶å®ç°ï¼Œæ—¨åœ¨å±•ç¤º[æ„ŸçŸ¥æœº](https://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf)çš„æ¦‚å¿µï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶è¿›è¡ŒäºŒåˆ†ç±»çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚ä»é‚£æ—¶èµ·ï¼Œè®©è®¡ç®—æœºåƒæˆ‘ä»¬ä¸€æ ·æ€è€ƒçš„è¿½æ±‚å°±æ²¡æœ‰åœæ­‡ã€‚å¦‚æœè¿™æ˜¯ä½ ç¬¬ä¸€æ¬¡æ·±å…¥å­¦ä¹ ç¥ç»ç½‘ç»œï¼Œæˆ–è€…ä½ æƒ³è¦åˆ·æ–°å¹¶å·©å›ºä½ çš„çŸ¥è¯†ï¼Œæˆ‘æ¨èé˜…è¯»[Shreya Rao çš„è¿™ç³»åˆ—æ–‡ç« ](https://medium.com/@shreya.rao/list/deep-learning-illustrated-ae6c27de1640)ï¼Œä½œä¸ºæ·±åº¦å­¦ä¹ çš„ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚æ­¤å¤–ï¼Œä½ è¿˜å¯ä»¥è®¿é—®æˆ‘æ”¶é›†çš„[è¿™ç³»åˆ—æ•…äº‹ï¼ˆä¸åŒçš„è´¡çŒ®è€…ï¼‰](https://medium.com/@raul.vizcarrach/list/neural-networks-098e9b594f19)ï¼Œä½ å¯èƒ½ä¼šå‘ç°å®ƒä»¬æœ‰ç”¨ã€‚

***ä¸ºä»€ä¹ˆé€‰æ‹©å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Ÿ*** è¯´å®è¯ï¼Œè¿™å¹¶ä¸æ˜¯æˆ‘æœ€åˆçš„é€‰æ‹©ã€‚æœ€åˆï¼Œæˆ‘å°è¯•ä½¿ç”¨[LandingAI](https://landing.ai/)ï¼Œä¸€ä¸ªé€‚åˆäº‘éƒ¨ç½²çš„ç”¨æˆ·å‹å¥½å¹³å°ï¼Œå¹¶ä¸”æ”¯æŒé€šè¿‡[Python API è¿æ¥](https://landing.ai/blog/build-your-custom-computer-vision-app-with-python-library)ã€‚ç„¶è€Œï¼Œå‡ºç°äº†å»¶è¿Ÿé—®é¢˜ï¼ˆ*éœ€è¦å¤„ç†è¶…è¿‡ 1,000 å¸§çš„æ•°æ®*ï¼‰ã€‚å³ä¾¿æ˜¯åœ¨[Roboflow](https://universe.roboflow.com/)çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œå°½ç®¡å®ƒä»¬æä¾›äº†é«˜è´¨é‡çš„æ•°æ®é›†å’Œæ¨¡å‹ï¼Œä»ç„¶é‡åˆ°äº†ç±»ä¼¼çš„å»¶è¿Ÿé—®é¢˜ã€‚æ„è¯†åˆ°å¿…é¡»åœ¨æœ¬åœ°è¿è¡Œåï¼Œæˆ‘å°è¯•äº†åŸºäºå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰çš„æ–¹æ³•æ¥åˆ†ç±»é˜Ÿä¼å’Œè£åˆ¤çš„çƒè¡£é¢œè‰²ã€‚å°½ç®¡è¿™ç§æ–¹æ³•çœ‹ä¼¼æ˜¯æœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼Œä½†å…¶å‡†ç¡®æ€§è¾ƒä½ã€‚ç»è¿‡å‡ å¤©çš„åå¤è¯•éªŒï¼Œæˆ‘æœ€ç»ˆè½¬å‘äº† CNNã€‚åœ¨ä¼—å¤šæ·±åº¦å­¦ä¹ æ–¹æ³•ä¸­ï¼ŒCNN éå¸¸é€‚åˆè¿›è¡Œç‰©ä½“æ£€æµ‹ï¼Œè€Œ LSTM æˆ– RNN æ›´é€‚ç”¨äºåƒè¯­è¨€è½¬å½•æˆ–ç¿»è¯‘ç­‰åºåˆ—æ•°æ®ã€‚

åœ¨æ·±å…¥ç ”ç©¶ä»£ç ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆäº†è§£ä¸€äº›å…³äºå…¶æ¶æ„çš„åŸºæœ¬æ¦‚å¿µï¼š

+   **å­¦ä¹ çš„æ ·æœ¬æ•°æ®é›†ï¼š** æ•°æ®é›†å·²è¢«åˆ†ä¸ºä¸‰ç±»ï¼š**è£åˆ¤**ã€**å®¢é˜Ÿ**ï¼ˆç™½è‰²çƒè¡£çš„çƒå‘˜ï¼‰å’Œ**ä¸»é˜Ÿ**ï¼ˆé»„è‰²çƒè¡£çš„çƒå‘˜ï¼‰ã€‚æ¯ä¸€ç±»çš„æ ·æœ¬è¢«åˆ†ä¸ºä¸¤ä¸ªå­é›†ï¼šè®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ®ã€‚è®­ç»ƒæ•°æ®å°†åœ¨æ¯æ¬¡è¿­ä»£ï¼ˆEpochï¼‰ä¸­è¢« CNN ä½¿ç”¨ï¼Œç”¨ä»¥â€œå­¦ä¹ â€å¤šä¸ªå±‚æ¬¡ä¸­çš„æ¨¡å¼ã€‚éªŒè¯æ•°æ®å°†åœ¨æ¯æ¬¡è¿­ä»£ç»“æŸæ—¶ç”¨æ¥è¯„ä¼°æ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶è¡¡é‡æ¨¡å‹å¯¹æ–°æ•°æ®çš„æ³›åŒ–èƒ½åŠ›ã€‚åˆ›å»ºæ ·æœ¬æ•°æ®é›†å¹¶ä¸å›°éš¾ï¼›æˆ‘å¤§çº¦èŠ±äº† 30 åˆ° 40 åˆ†é’Ÿçš„æ—¶é—´ï¼Œä»è§†é¢‘ä¸­è£å‰ªå‡ºæ¯ä¸€ç±»çš„æ ·æœ¬å›¾åƒå¹¶å°†å®ƒä»¬æ•´ç†åˆ°å­ç›®å½•ä¸­ã€‚æˆ‘æˆåŠŸåˆ›å»ºäº†ä¸€ä¸ªçº¦ 90 å¼ å›¾åƒçš„æ ·æœ¬æ•°æ®é›†ï¼Œä½ å¯ä»¥åœ¨[é¡¹ç›®çš„ GitHub ä»“åº“](https://github.com/rvizcarra15/IceHockey_ComputerVision_PyTorch)ä¸­æ‰¾åˆ°ã€‚

+   **æ¨¡å‹æ˜¯å¦‚ä½•å­¦ä¹ çš„ï¼Ÿ** è¾“å…¥æ•°æ®ä¼šé€šè¿‡ç¥ç»ç½‘ç»œçš„æ¯ä¸€å±‚ï¼Œæ¯ä¸€å±‚å¯ä»¥æ˜¯ä¸€ä¸ªæˆ–å¤šä¸ªç›¸äº’è¿æ¥çš„å±‚ï¼Œç”¨æ¥è¿›è¡Œé¢„æµ‹ã€‚æ¯ä¸€å±‚éƒ½ä½¿ç”¨æ¿€æ´»å‡½æ•°æ¥å¤„ç†æ•°æ®ï¼Œä»è€Œè¿›è¡Œé¢„æµ‹æˆ–å¯¹æ•°æ®è¿›è¡Œæ›´æ”¹ã€‚è¿™äº›å±‚ä¹‹é—´çš„æ¯ä¸ªè¿æ¥éƒ½æœ‰ä¸€ä¸ªæƒé‡ï¼Œå†³å®šäº†ä¸€ä¸ªå±‚çš„è¾“å‡ºå¯¹ä¸‹ä¸€ä¸ªå±‚çš„å½±å“ç¨‹åº¦ã€‚ç›®æ ‡æ˜¯æ‰¾åˆ°è¿™äº›æƒé‡çš„æ­£ç¡®ç»„åˆï¼Œä»¥æœ€å°åŒ–é¢„æµ‹ç»“æœçš„é”™è¯¯ã€‚é€šè¿‡ä¸€ä¸ªå«åšåå‘ä¼ æ’­çš„è¿‡ç¨‹å’ŒæŸå¤±å‡½æ•°ï¼Œæ¨¡å‹ä¼šè°ƒæ•´è¿™äº›æƒé‡ï¼Œä»¥å‡å°‘è¯¯å·®å¹¶æé«˜å‡†ç¡®æ€§ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šåœ¨æ‰€è°“çš„**Epochï¼ˆå‰å‘ä¼ æ’­ + åå‘ä¼ æ’­ï¼‰**ä¸­é‡å¤è¿›è¡Œï¼Œéšç€æ¯ä¸ªå‘¨æœŸæ¨¡å‹ä»é”™è¯¯ä¸­å­¦ä¹ ï¼Œå®ƒåœ¨é¢„æµ‹ä¸Šçš„è¡¨ç°ä¹Ÿä¼šé€æ¸å˜å¥½ã€‚

+   **æ¿€æ´»å‡½æ•°:** å¦‚å‰æ‰€è¿°ï¼Œæ¿€æ´»å‡½æ•°åœ¨æ¨¡å‹å­¦ä¹ è¿‡ç¨‹ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ã€‚æˆ‘é€‰æ‹©äº†**ReLUï¼ˆä¿®æ­£çº¿æ€§å•å…ƒï¼‰**ï¼Œå› ä¸ºå®ƒåœ¨è®¡ç®—ä¸Šéå¸¸é«˜æ•ˆï¼Œå¹¶èƒ½ç¼“è§£æ‰€è°“çš„æ¶ˆå¤±æ¢¯åº¦é—®é¢˜*ï¼ˆå³å¤šå±‚ç½‘ç»œå¯èƒ½æ— æ³•æœ‰æ•ˆå­¦ä¹ ï¼‰*ã€‚è™½ç„¶ ReLU å·¥ä½œå¾—å¾ˆå¥½ï¼Œ[å…¶ä»–å‡½æ•°](https://www.v7labs.com/blog/neural-networks-activation-functions)å¦‚**sigmoid**ã€**tanh**æˆ–**swish**ä¹Ÿæœ‰å…¶åº”ç”¨ï¼Œå…·ä½“å–å†³äºç½‘ç»œçš„å¤æ‚æ€§ã€‚

+   **è®­ç»ƒè½®æ•°ï¼ˆEpochsï¼‰:** è®¾ç½®åˆé€‚çš„è®­ç»ƒè½®æ•°éœ€è¦å®éªŒã€‚ä½ åº”è¯¥è€ƒè™‘æ•°æ®é›†çš„å¤æ‚æ€§ã€CNN æ¨¡å‹çš„æ¶æ„å’Œè®¡ç®—èµ„æºç­‰å› ç´ ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæœ€å¥½åœ¨æ¯æ¬¡è¿­ä»£ä¸­ç›‘æ§æ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶åœ¨æ”¹è¿›å˜å¾—å¾®ä¹å…¶å¾®æ—¶åœæ­¢è®­ç»ƒï¼Œä»¥é¿å…è¿‡æ‹Ÿåˆã€‚è€ƒè™‘åˆ°æˆ‘å°çš„è®­ç»ƒæ•°æ®é›†ï¼Œ**æˆ‘å†³å®šä»¥ 10 è½®ä¸ºåŸºå‡†**å¼€å§‹ã€‚ç„¶è€Œï¼Œåœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œæ ¹æ®æŒ‡æ ‡è¡¨ç°å’ŒéªŒè¯ç»“æœï¼Œå¯èƒ½éœ€è¦åšå‡ºè°ƒæ•´ã€‚

+   **Adamï¼ˆè‡ªé€‚åº”çŸ©ä¼°è®¡ï¼‰:** æœ€ç»ˆç›®æ ‡æ˜¯å‡å°‘é¢„æµ‹è¾“å‡ºä¸çœŸå®è¾“å‡ºä¹‹é—´çš„è¯¯å·®ã€‚å¦‚å‰æ‰€è¿°ï¼Œåå‘ä¼ æ’­åœ¨æ­¤è¿‡ç¨‹ä¸­èµ·ç€å…³é”®ä½œç”¨ï¼Œé€šè¿‡è°ƒæ•´å’Œæ›´æ–°ç¥ç»ç½‘ç»œæƒé‡æ¥éšç€æ—¶é—´çš„æ¨ç§»æ”¹è¿›é¢„æµ‹ã€‚åå‘ä¼ æ’­åŸºäºæŸå¤±å‡½æ•°çš„æ¢¯åº¦å¤„ç†æƒé‡æ›´æ–°ï¼Œè€Œ Adam ç®—æ³•é€šè¿‡åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡æ¥è¿›ä¸€æ­¥ä¼˜åŒ–è¿™ä¸€è¿‡ç¨‹ï¼Œä»è€Œé€æ­¥å‡å°‘è¯¯å·®æˆ–æŸå¤±å‡½æ•°ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒå¾®è°ƒäº†æ¨¡å‹å­¦ä¹ çš„é€Ÿåº¦ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸ºäº†è¿è¡Œæˆ‘ä»¬çš„ CNN æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä»¥ä¸‹ Python åŒ…ï¼š

```py
pip install torch torchvision 
pip install matplotlib 
pip install scikit-learn
```

> **æç¤º-02:** ç¡®ä¿ PyTorch æ­£ç¡®å®‰è£…ã€‚æˆ‘æ‰€æœ‰çš„å·¥å…·éƒ½åœ¨ Anaconda ç¯å¢ƒä¸­è®¾ç½®ï¼Œå½“æˆ‘å®‰è£… PyTorch æ—¶ï¼Œä¸€å¼€å§‹çœ‹èµ·æ¥å®ƒä¼¼ä¹æ­£ç¡®å®‰è£…äº†ã€‚ç„¶è€Œï¼Œåœ¨è¿è¡Œä¸€äº›åº“æ—¶å‡ºç°äº†ä¸€äº›é—®é¢˜ã€‚æœ€åˆï¼Œæˆ‘ä»¥ä¸ºæ˜¯ä»£ç çš„é—®é¢˜ï¼Œä½†ç»è¿‡å¤šæ¬¡ä¿®æ”¹ä»ç„¶æ²¡æœ‰æˆåŠŸï¼Œæˆ‘åªå¥½é‡æ–°å®‰è£… Anacondaï¼Œå¹¶åœ¨å¹²å‡€çš„ç¯å¢ƒä¸­é‡æ–°å®‰è£… PyTorchï¼Œé—®é¢˜å°±è¿™æ ·è§£å†³äº†ï¼

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æŒ‡å®šæˆ‘ä»¬çš„åº“å’Œæ ·æœ¬æ•°æ®é›†çš„è·¯å¾„ï¼š

```py
# ************CONVOLUTIONAL NEURAL NETWORK-THREE CLASSES DETECTION**************************
# REFEREE
# WHITE TEAM (Team_away)
# YELLOW TEAM (Team_home)

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

#Training and Validation Datasets
#Download the teams_sample_dataset file from the project's GitHub repository
data_dir = 'D:/PYTHON/teams_sample_dataset' 
```

é¦–å…ˆï¼Œæˆ‘ä»¬å°†ç¡®ä¿æ¯å¼ å›¾ç‰‡çš„å¤§å°ä¸€è‡´ï¼ˆè°ƒæ•´ä¸º 150x150 åƒç´ ï¼‰ï¼Œç„¶åå°†å…¶è½¬æ¢ä¸ºä»£ç èƒ½å¤Ÿç†è§£çš„æ ¼å¼ï¼ˆåœ¨ PyTorch ä¸­ï¼Œè¾“å…¥æ•°æ®é€šå¸¸è¡¨ç¤ºä¸º Tensor å¯¹è±¡ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è°ƒæ•´é¢œè‰²ï¼Œä»¥ä¾¿æ¨¡å‹æ›´å®¹æ˜“å¤„ç†ï¼ˆå½’ä¸€åŒ–ï¼‰ï¼Œå¹¶è®¾ç½®åŠ è½½å›¾ç‰‡çš„ç¨‹åºã€‚è¿™äº›æ­¥éª¤å…±åŒå¸®åŠ©å‡†å¤‡å›¾ç‰‡ï¼Œå¹¶å°†å®ƒä»¬æ•´ç†å¥½ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»ä¸­å­¦ä¹ ï¼Œé¿å…å› æ•°æ®æ ¼å¼å¯¼è‡´çš„åå·®ã€‚

```py
#******************************Data transformation***********************************
transform = transforms.Compose([
    transforms.Resize((150, 150)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Load dataset
train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)
val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å®šä¹‰ CNN çš„æ¶æ„ï¼š

```py
#********************************CNN Model Architecture**************************************
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(128 * 18 * 18, 512)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(512, 3)  #Three Classes (Referee, Team_away,Team_home)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(-1, 128 * 18 * 18)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)  
        return x
```

ä½ ä¼šæ³¨æ„åˆ°æˆ‘ä»¬çš„ CNN æ¨¡å‹æœ‰ä¸‰å±‚ï¼ˆconv1ï¼Œconv2ï¼Œconv3ï¼‰ã€‚æ•°æ®é¦–å…ˆè¿›å…¥å·ç§¯å±‚ï¼ˆconvï¼‰ï¼Œåœ¨è¿™é‡Œåº”ç”¨äº†æ¿€æ´»å‡½æ•°ï¼ˆReLUï¼‰ã€‚è¯¥å‡½æ•°ä½¿å¾—ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼å’Œå…³ç³»ã€‚æ¥ç€ï¼Œæ± åŒ–å±‚è¢«æ¿€æ´»ã€‚***ä»€ä¹ˆæ˜¯æœ€å¤§æ± åŒ–ï¼Ÿ***å®ƒæ˜¯ä¸€ç§å‡å°‘å›¾åƒå¤§å°çš„æŠ€æœ¯ï¼ŒåŒæ—¶ä¿ç•™é‡è¦ç‰¹å¾ï¼Œæœ‰åŠ©äºé«˜æ•ˆè®­ç»ƒå¹¶ä¼˜åŒ–å†…å­˜èµ„æºã€‚è¿™ä¸ªè¿‡ç¨‹åœ¨ conv1 åˆ° conv3 ä¹‹é—´é‡å¤è¿›è¡Œã€‚æœ€åï¼Œæ•°æ®é€šè¿‡å…¨è¿æ¥å±‚ï¼ˆfc1ï¼Œfc2ï¼‰è¿›è¡Œæœ€ç»ˆåˆ†ç±»ï¼ˆæˆ–å†³ç­–ï¼‰ã€‚

ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬åˆå§‹åŒ–æ¨¡å‹ï¼Œé…ç½®ç±»åˆ«äº¤å‰ç†µä¸ºæŸå¤±å‡½æ•°*(é€šå¸¸ç”¨äºåˆ†ç±»ä»»åŠ¡)*ï¼Œå¹¶å°† Adam ä½œä¸ºä¼˜åŒ–å™¨ã€‚å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬å°†åœ¨ 10 ä¸ªå‘¨æœŸå†…æ‰§è¡Œæ¨¡å‹ã€‚

```py
#********************************CNN TRAINING**********************************************

# Model-loss function-optimizer
model = CNNModel()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

#*********************************Training*************************************************
num_epochs = 10
train_losses, val_losses = [], []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        labels = labels.type(torch.LongTensor)  
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    train_losses.append(running_loss / len(train_loader))

    model.eval()
    val_loss = 0.0
    all_labels = []
    all_preds = []
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs)
            labels = labels.type(torch.LongTensor)  
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)  
            all_labels.extend(labels.tolist())
            all_preds.extend(preds.tolist())
```

ä¸ºäº†è·Ÿè¸ªæ€§èƒ½ï¼Œæˆ‘ä»¬å°†æ·»åŠ ä¸€äº›ä»£ç æ¥è·Ÿè¸ªè®­ç»ƒè¿›åº¦ï¼Œæ‰“å°éªŒè¯æŒ‡æ ‡å¹¶ç»˜åˆ¶å›¾è¡¨ã€‚æœ€åï¼Œæˆ‘ä»¬å°†æ¨¡å‹ä¿å­˜ä¸º**hockey_team_classifier.pth**ï¼Œä¿å­˜åœ¨ä½ é€‰æ‹©çš„æŒ‡å®šè·¯å¾„ä¸­ã€‚

```py
#********************************METRICS & PERFORMANCE************************************

    val_losses.append(val_loss / len(val_loader))
    val_accuracy = accuracy_score(all_labels, all_preds)
    val_precision = precision_score(all_labels, all_preds, average='macro', zero_division=1)
    val_recall = recall_score(all_labels, all_preds, average='macro', zero_division=1)
    val_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=1)

    print(f"Epoch [{epoch + 1}/{num_epochs}], "
          f"Loss: {train_losses[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, "
          f"Val Acc: {val_accuracy:.2%}, "
          f"Val Precision: {val_precision:.4f}, "
          f"Val Recall: {val_recall:.4f}, "
          f"Val F1 Score: {val_f1:.4f}")

#*******************************SHOW METRICS & PERFORMANCE**********************************
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.legend()
plt.show()

# SAVE THE MODEL FOR THE GH_CV_track_teams CODE
torch.save(model.state_dict(), 'D:/PYTHON/hockey_team_classifier.pth')
```

æ­¤å¤–ï¼Œé™¤äº†ä½ çš„â€œpthâ€æ–‡ä»¶ï¼Œåœ¨å®Œæˆä¸Šè¿°æ‰€æœ‰æ­¥éª¤å*(ä½ å¯ä»¥åœ¨[*é¡¹ç›®çš„ GitHub ä»“åº“*](https://github.com/rvizcarra15/IceHockey_ComputerVision_PyTorch)ä¸­æ‰¾åˆ°å®Œæ•´ä»£ç )*ï¼Œä½ åº”è¯¥èƒ½çœ‹åˆ°å¦‚ä¸‹è¾“å‡ºï¼ˆæŒ‡æ ‡å¯èƒ½ç•¥æœ‰ä¸åŒï¼‰ï¼š

![](img/91ff066093e4c561b0f5b20528f75f57.png)

å›¾ 05ï¼šCNN æ¨¡å‹æ€§èƒ½æŒ‡æ ‡

```py
#**************CNN PERFORMANCE ACROSS TRAINING EPOCHS************************

Epoch [1/10], Loss: 1.5346, Val Loss: 1.2339, Val Acc: 47.37%, Val Precision: 0.7172, Val Recall: 0.5641, Val F1 Score: 0.4167
Epoch [2/10], Loss: 1.1473, Val Loss: 1.1664, Val Acc: 55.26%, Val Precision: 0.6965, Val Recall: 0.6296, Val F1 Score: 0.4600
Epoch [3/10], Loss: 1.0139, Val Loss: 0.9512, Val Acc: 57.89%, Val Precision: 0.6054, Val Recall: 0.6054, Val F1 Score: 0.5909
Epoch [4/10], Loss: 0.8937, Val Loss: 0.8242, Val Acc: 60.53%, Val Precision: 0.7222, Val Recall: 0.5645, Val F1 Score: 0.5538
Epoch [5/10], Loss: 0.7936, Val Loss: 0.7177, Val Acc: 63.16%, Val Precision: 0.6667, Val Recall: 0.6309, Val F1 Score: 0.6419
Epoch [6/10], Loss: 0.6871, Val Loss: 0.7782, Val Acc: 68.42%, Val Precision: 0.6936, Val Recall: 0.7128, Val F1 Score: 0.6781
Epoch [7/10], Loss: 0.6276, Val Loss: 0.5684, Val Acc: 78.95%, Val Precision: 0.8449, Val Recall: 0.7523, Val F1 Score: 0.7589
Epoch [8/10], Loss: 0.4198, Val Loss: 0.5613, Val Acc: 86.84%, Val Precision: 0.8736, Val Recall: 0.8958, Val F1 Score: 0.8653
Epoch [9/10], Loss: 0.3959, Val Loss: 0.3824, Val Acc: 92.11%, Val Precision: 0.9333, Val Recall: 0.9213, Val F1 Score: 0.9243
Epoch [10/10], Loss: 0.2509, Val Loss: 0.2651, Val Acc: 97.37%, Val Precision: 0.9762, Val Recall: 0.9792, Val F1 Score: 0.9769 
```

å®Œæˆ 10 ä¸ªè®­ç»ƒå‘¨æœŸåï¼ŒCNN æ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡æœ‰æ‰€æ”¹å–„ã€‚æœ€åˆï¼Œåœ¨ç¬¬ 1 ä¸ªå‘¨æœŸæ—¶ï¼Œæ¨¡å‹çš„è®­ç»ƒæŸå¤±ä¸º 1.5346ï¼ŒéªŒè¯å‡†ç¡®ç‡ä¸º 47.37%ã€‚***æˆ‘ä»¬åº”å¦‚ä½•ç†è§£è¿™ä¸ªåˆå§‹ç‚¹ï¼Ÿ***

**å‡†ç¡®ç‡**æ˜¯è¯„ä¼°åˆ†ç±»æ€§èƒ½æœ€å¸¸è§çš„æŒ‡æ ‡ä¹‹ä¸€ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå®ƒè¡¨ç¤ºæ­£ç¡®é¢„æµ‹çš„ç±»åˆ«å æ€»ç±»åˆ«çš„æ¯”ä¾‹ã€‚**ç„¶è€Œï¼Œå•é é«˜å‡†ç¡®ç‡å¹¶ä¸èƒ½ä¿è¯æ•´ä½“æ¨¡å‹çš„è¡¨ç°**ï¼›ä½ ä»ç„¶å¯èƒ½åœ¨æŸäº›ç±»åˆ«ä¸Šåšå‡ºä¸å¥½çš„é¢„æµ‹ï¼ˆæ­£å¦‚æˆ‘åœ¨æ—©æœŸå®éªŒä¸­æ‰€ç»å†çš„é‚£æ ·ï¼‰ã€‚å…³äº**è®­ç»ƒæŸå¤±**ï¼Œå®ƒè¡¡é‡æ¨¡å‹å°†è¾“å…¥æ•°æ®æ˜ å°„åˆ°æ­£ç¡®æ ‡ç­¾çš„æ•ˆæœã€‚ç”±äºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯åˆ†ç±»å‡½æ•°ï¼Œ**äº¤å‰ç†µæŸå¤±**é‡åŒ–äº†é¢„æµ‹çš„ç±»åˆ«æ¦‚ç‡ä¸å®é™…æ ‡ç­¾ä¹‹é—´çš„å·®å¼‚ã€‚åƒ 1.5346 è¿™æ ·çš„åˆå§‹å€¼è¡¨ç¤ºé¢„æµ‹ç±»åˆ«ä¸å®é™…ç±»åˆ«ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼›ç†æƒ³æƒ…å†µä¸‹ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œè¿™ä¸ªå€¼åº”è¯¥è¶‹è¿‘äº 0ã€‚éšç€è®­ç»ƒå‘¨æœŸçš„è¿›è¡Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°è®­ç»ƒæŸå¤±æ˜¾è‘—ä¸‹é™ï¼ŒéªŒè¯å‡†ç¡®ç‡æé«˜ã€‚åˆ°æœ€åä¸€ä¸ªè®­ç»ƒå‘¨æœŸæ—¶ï¼Œè®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±åˆ†åˆ«é™åˆ° 0.2509 å’Œ 0.2651 çš„æœ€ä½ç‚¹ã€‚

ä¸ºäº†æµ‹è¯•æˆ‘ä»¬çš„ CNN æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸€éƒ¨åˆ†çƒå‘˜å›¾åƒå¹¶è¯„ä¼°å…¶é¢„æµ‹èƒ½åŠ›ã€‚ä¸ºäº†æµ‹è¯•ï¼Œä½ å¯ä»¥è¿è¡Œä»¥ä¸‹ä»£ç å¹¶ä½¿ç”¨ [é¡¹ç›®çš„ GitHub ä»“åº“](https://github.com/rvizcarra15/IceHockey_ComputerVision_PyTorch)ä¸­çš„**validation_dataset æ–‡ä»¶å¤¹**ã€‚

```py
# *************TEST CNN MODEL WITH SAMPLE DATASET***************************

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image

# SAMPLE DATASET FOR VALIDATION
test_dir = 'D:/PYTHON/validation_dataset'

# CNN MODEL FOR TEAM PREDICTIONS
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(128 * 18 * 18, 512)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(512, 3) 

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(-1, 128 * 18 * 18)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)  
        return x

# CNN MODEL PREVIOUSLY SAVED
model = CNNModel()
model.load_state_dict(torch.load('D:/PYTHON/hockey_team_classifier.pth'))
model.eval()

transform = transforms.Compose([
    transforms.Resize((150, 150)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

#******************ITERATION ON SAMPLE IMAGES-ACCURACY TEST*****************************

class_names = ['team_referee', 'team_away', 'team_home']

def predict_image(image_path, model, transform):
# LOADS DATASET
    image = Image.open(image_path)
    image = transform(image).unsqueeze(0)  

# MAKES PREDICTIONS
    with torch.no_grad():
        output = model(image)
        _, predicted = torch.max(output, 1)  
        team = class_names[predicted.item()]
    return team

for image_name in os.listdir(test_dir):
    image_path = os.path.join(test_dir, image_name)
    if os.path.isfile(image_path):  
        predicted_team = predict_image(image_path, model, transform)
        print(f'Image {image_name}: The player belongs to {predicted_team}')
```

è¾“å‡ºåº”å¦‚ä¸‹æ‰€ç¤ºï¼š

```py
 # *************CNN MODEL TEST - OUTPUT ***********************************#

Image Away_image04.jpg: The player belongs to team_away
Image Away_image12.jpg: The player belongs to team_away
Image Away_image14.jpg: The player belongs to team_away
Image Home_image07.jpg: The player belongs to team_home
Image Home_image13.jpg: The player belongs to team_home
Image Home_image16.jpg: The player belongs to team_home
Image Referee_image04.jpg: The player belongs to team_referee
Image Referee_image09.jpg: The player belongs to team_referee
Image Referee_image10.jpg: The player belongs to team_referee
Image Referee_image11.jpg: The player belongs to team_referee
```

å¦‚ä½ æ‰€è§ï¼Œæ¨¡å‹åœ¨è¯†åˆ«é˜Ÿä¼å¹¶æ’é™¤è£åˆ¤ä½œä¸ºé˜Ÿå‘˜æ–¹é¢è¡¨ç°å¾—ç›¸å½“ä¸é”™ã€‚

> **å°è´´å£« #03ï¼š** åœ¨ CNN è®¾è®¡è¿‡ç¨‹ä¸­æˆ‘å­¦åˆ°çš„ä¸€ç‚¹æ˜¯ï¼Œå¢åŠ å¤æ‚æ€§å¹¶ä¸æ€»èƒ½æå‡æ€§èƒ½ã€‚ä¸€å¼€å§‹ï¼Œæˆ‘å°è¯•äº†æ›´æ·±çš„æ¨¡å‹ï¼ˆæ›´å¤šçš„å·ç§¯å±‚ï¼‰å’ŒåŸºäºé¢œè‰²çš„å¢å¼ºæ¥æé«˜çƒå‘˜çƒè¡£çš„è¯†åˆ«ç‡ã€‚ç„¶è€Œï¼Œåœ¨æˆ‘çš„å°æ•°æ®é›†ä¸Šï¼Œæˆ‘é‡åˆ°äº†è¿‡æ‹Ÿåˆï¼Œè€Œä¸æ˜¯å­¦ä¹ åˆ°å¯ä»¥æ³›åŒ–çš„ç‰¹å¾ï¼ˆæ‰€æœ‰å›¾åƒéƒ½è¢«é¢„æµ‹ä¸ºç™½é˜Ÿçƒå‘˜æˆ–è£åˆ¤ï¼‰ã€‚æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œå¦‚ dropout å’Œæ‰¹é‡å½’ä¸€åŒ–ä¹Ÿå¾ˆé‡è¦ï¼›å®ƒä»¬æœ‰åŠ©äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ–½åŠ çº¦æŸï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°æ³›åŒ–åˆ°æ–°æ•°æ®ã€‚å°‘å³æ˜¯å¤šï¼Œç»“æœæœ‰æ—¶ä¼šæ›´å¥½ğŸ˜ã€‚

# **å°†ä¸€åˆ‡æ•´åˆåœ¨ä¸€èµ·**

å°†æ‰€æœ‰å†…å®¹æ•´åˆåœ¨ä¸€èµ·éœ€è¦å¯¹æˆ‘ä»¬ä¹‹å‰æè¿°çš„è·Ÿè¸ªæœºåˆ¶è¿›è¡Œä¸€äº›è°ƒæ•´ã€‚ä¸‹é¢æ˜¯æ›´æ–°åçš„ä»£ç é€æ­¥è§£æã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å°†è®¾ç½®æ‰€éœ€çš„åº“å’Œè·¯å¾„ã€‚è¯·æ³¨æ„ï¼Œç°åœ¨å·²ç»æŒ‡å®šäº† pickle æ–‡ä»¶å’Œ CNN æ¨¡å‹çš„è·¯å¾„ã€‚**è¿™æ¬¡ï¼Œå¦‚æœæ‰¾ä¸åˆ°è·¯å¾„ä¸­çš„ pickle æ–‡ä»¶ï¼Œä»£ç å°†æŠ›å‡ºä¸€ä¸ªé”™è¯¯**ã€‚å¦‚æœéœ€è¦ï¼Œä½¿ç”¨ä¹‹å‰çš„ä»£ç ç”Ÿæˆ pickle æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨æ­¤æ›´æ–°ç‰ˆæœ¬æ¥æ‰§è¡Œè§†é¢‘åˆ†æï¼š

```py
 import cv2
import numpy as np
from ultralytics import YOLO
import pickle
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image

# MODEL INPUTS
model_path = 'D:/PYTHON/yolov8x.pt'
video_path = 'D:/PYTHON/video_input.mp4'
output_path = 'D:/PYTHON/output_video.mp4'
tracks_path = 'D:/PYTHON/stubs/track_stubs.pkl'
classifier_path = 'D:/PYTHON/hockey_team_classifier.pth'
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åŠ è½½æ¨¡å‹ï¼ŒæŒ‡å®šå†°åœºåæ ‡ï¼Œå¹¶å¯åŠ¨æ¯å¸§å›¾åƒçš„æ‰¹é‡æ£€æµ‹è¿‡ç¨‹ï¼Œæ¯æ¬¡æ‰¹é‡ä¸º 20 å¸§ï¼Œå’Œä¹‹å‰ä¸€æ ·ã€‚è¯·æ³¨æ„ï¼Œç›®å‰æˆ‘ä»¬åªä¼šä½¿ç”¨å†°åœºè¾¹ç•Œæ¥èšç„¦åˆ†æèŒƒå›´ã€‚æ–‡ç« çš„æœ€åå‡ æ­¥ä¸­ï¼Œå½“æˆ‘ä»¬åŒ…å«æ€§èƒ½ç»Ÿè®¡æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¿›æ”»åŒºåæ ‡ã€‚

```py
 #*************************** Loads models and rink coordinates********************#
class_names = ['Referee', 'Tm_white', 'Tm_yellow']

class HockeyAnalyzer:
    def __init__(self, model_path, classifier_path):
        self.model = YOLO(model_path)
        self.classifier = self.load_classifier(classifier_path)
        self.transform = transforms.Compose([
            transforms.Resize((150, 150)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        self.rink_coordinates = np.array([[-450, 710], [2030, 710], [948, 61], [352, 61]])
        self.zone_white = [(180, 150), (1100, 150), (900, 61), (352, 61)]
        self.zone_yellow = [(-450, 710), (2030, 710), (1160, 150), (200, 150)]

#******************** Detect objects in each frame **********************************#
    def detect_frames(self, frames):
        batch_size = 20 
        detections = [] 
        for i in range(0, len(frames), batch_size):
            detections_batch = self.model.predict(frames[i:i+batch_size], conf=0.1)
            detections += detections_batch
        return detections
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ·»åŠ é¢„æµ‹æ¯ä¸ªçƒå‘˜é˜Ÿä¼çš„è¿‡ç¨‹ï¼š

```py
#*********************** Loads CNN Model**********************************************#

    def load_classifier(self, classifier_path):
        model = CNNModel()
        model.load_state_dict(torch.load(classifier_path, map_location=torch.device('cpu')))
        model.eval()
        return model

    def predict_team(self, image):
        with torch.no_grad():
            output = self.classifier(image)
            _, predicted = torch.max(output, 1)
            predicted_index = predicted.item()
            team = class_names[predicted_index]
        return team
```

ä½œä¸ºä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬å°†æ·»åŠ ä¹‹å‰æè¿°çš„æ–¹æ³•ï¼Œä»è¾¹ç•Œæ¡†è½¬æ¢ä¸ºæ¤­åœ†å½¢ï¼š

```py
#************ Ellipse for tracking players instead of Bounding boxes*******************#
    def draw_ellipse(self, frame, bbox, color, track_id=None, team=None):
        y2 = int(bbox[3])
        x_center = (int(bbox[0]) + int(bbox[2])) // 2
        width = int(bbox[2]) - int(bbox[0])

        if team == 'Referee':
            color = (0, 255, 255)
            text_color = (0, 0, 0)
        else:
            color = (255, 0, 0)
            text_color = (255, 255, 255)

        cv2.ellipse(
            frame,
            center=(x_center, y2),
            axes=(int(width) // 2, int(0.35 * width)),
            angle=0.0,
            startAngle=-45,
            endAngle=235,
            color=color,
            thickness=2,
            lineType=cv2.LINE_4
        )

        if track_id is not None:
            rectangle_width = 40
            rectangle_height = 20
            x1_rect = x_center - rectangle_width // 2
            x2_rect = x_center + rectangle_width // 2
            y1_rect = (y2 - rectangle_height // 2) + 15
            y2_rect = (y2 + rectangle_height // 2) + 15

            cv2.rectangle(frame,
                          (int(x1_rect), int(y1_rect)),
                          (int(x2_rect), int(y2_rect)),
                          color,
                          cv2.FILLED)

            x1_text = x1_rect + 12
            if track_id > 99:
                x1_text -= 10
            font_scale = 0.4
            cv2.putText(
                frame,
                f"{track_id}",
                (int(x1_text), int(y1_rect + 15)),
                cv2.FONT_HERSHEY_SIMPLEX,
                font_scale,
                text_color,
                thickness=2
            )

        return frame
```

ç°åœ¨ï¼Œæ˜¯æ—¶å€™æ·»åŠ åˆ†æå™¨äº†ï¼Œå®ƒåŒ…æ‹¬è¯»å– pickle æ–‡ä»¶ã€å°†åˆ†æèŒƒå›´ç¼©å°åˆ°æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„å†°åœºè¾¹ç•Œï¼Œå¹¶è°ƒç”¨ CNN æ¨¡å‹ä»¥è¯†åˆ«æ¯ä¸ªçƒå‘˜çš„é˜Ÿä¼å¹¶æ·»åŠ æ ‡ç­¾ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åŒ…æ‹¬äº†ä¸€ä¸ªç‰¹æ€§ï¼Œç”¨ä¸åŒçš„é¢œè‰²æ ‡è®°è£åˆ¤ï¼Œå¹¶ä¸”æ”¹å˜ä»–ä»¬æ¤­åœ†å½¢çš„é¢œè‰²ã€‚ä»£ç çš„æœ€åä¼šå°†å¤„ç†è¿‡çš„å¸§å†™å…¥è¾“å‡ºè§†é¢‘ã€‚

```py
#******************* Loads Tracked Data (pickle file )**********************************#

    def analyze_video(self, video_path, output_path, tracks_path):
          with open(tracks_path, 'rb') as f:
              tracks = pickle.load(f)

          cap = cv2.VideoCapture(video_path)
          if not cap.isOpened():
              print("Error: Could not open video.")
              return

          fps = cap.get(cv2.CAP_PROP_FPS)
          frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
          frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

          fourcc = cv2.VideoWriter_fourcc(*'XVID')
          out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

          frame_num = 0
          while cap.isOpened():
              ret, frame = cap.read()
              if not ret:
                  break

#***********Checks if the player falls within the rink area**********************************#
              mask = np.zeros(frame.shape[:2], dtype=np.uint8)
              cv2.fillConvexPoly(mask, self.rink_coordinates, 1)
              mask = mask.astype(bool)
              # Draw rink area
              #cv2.polylines(frame, [self.rink_coordinates], isClosed=True, color=(0, 255, 0), thickness=2)

              # Get tracks from frame
              player_dict = tracks["person"][frame_num]
              for track_id, player in player_dict.items():
                  bbox = player["bbox"]

              # Check if the player is within the Rink Area
                  x_center = int((bbox[0] + bbox[2]) / 2)
                  y_center = int((bbox[1] + bbox[3]) / 2)

                  if not mask[y_center, x_center]:
                      continue  

#**********************************Team Prediction********************************************#
                  x1, y1, x2, y2 = map(int, bbox)
                  cropped_image = frame[y1:y2, x1:x2]
                  cropped_pil_image = Image.fromarray(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))
                  transformed_image = self.transform(cropped_pil_image).unsqueeze(0)
                  team = self.predict_team(transformed_image)

#************ Ellipse for tracked players and labels******************************************#
                  self.draw_ellipse(frame, bbox, (0, 255, 0), track_id, team)

                  font_scale = 1  
                  text_offset = -20  

                  if team == 'Referee':
                      rectangle_width = 60
                      rectangle_height = 25
                      x1_rect = x1
                      x2_rect = x1 + rectangle_width
                      y1_rect = y1 - 30
                      y2_rect = y1 - 5
                      # Different setup for Referee
                      cv2.rectangle(frame,
                                    (int(x1_rect), int(y1_rect)),
                                    (int(x2_rect), int(y2_rect)),
                                    (0, 0, 0),  
                                    cv2.FILLED)
                      text_color = (255, 255, 255)  
                  else:
                      if team == 'Tm_white':
                          text_color = (255, 215, 0)  # White Team: Blue labels
                      else:
                          text_color = (0, 255, 255)  # Yellow Team: Yellow labels

              # Draw Team labels
                  cv2.putText(
                      frame,
                      team,
                      (int(x1), int(y1) + text_offset), 
                      cv2.FONT_HERSHEY_PLAIN,            
                      font_scale,
                      text_color,
                      thickness=2
                  )

              # Write output video
              out.write(frame)
              frame_num += 1

          cap.release()
          out.release()
```

æœ€åï¼Œæˆ‘ä»¬æ·»åŠ  CNN çš„æ¶æ„ï¼ˆåœ¨ CNN è®¾è®¡è¿‡ç¨‹ä¸­å®šä¹‰ï¼‰å¹¶æ‰§è¡Œå†°çƒåˆ†æå™¨ï¼š

```py
 #**********************CNN Model Architecture ******************************#
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(128 * 18 * 18, 512)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(512, len(class_names))  

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(-1, 128 * 18 * 18)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

#*********Execute HockeyAnalyzer/classifier and Save Output************#
analyzer = HockeyAnalyzer(model_path, classifier_path)
analyzer.analyze_video(video_path, output_path, tracks_path)
```

è¿è¡Œæ‰€æœ‰æ­¥éª¤åï¼Œä½ çš„è§†é¢‘è¾“å‡ºåº”è¯¥å¦‚ä¸‹æ‰€ç¤ºï¼š

![](img/98890f2c70834d1f61d97b6135b3afe5.png)

ç¤ºä¾‹ç‰‡æ®µ 06ï¼šè·Ÿè¸ªçƒå‘˜å’Œé˜Ÿä¼

è¯·æ³¨æ„ï¼Œåœ¨è¿™æ¬¡æ›´æ–°ä¸­ï¼Œç‰©ä½“æ£€æµ‹ä»…é™äºå†°çƒåœºå†…ï¼Œä¸”é˜Ÿä¼å’Œè£åˆ¤å·²è¢«åŒºåˆ†å¼€æ¥ã€‚è™½ç„¶ CNN æ¨¡å‹ä»éœ€å¾®è°ƒï¼Œå¹¶ä¸”å¶å°”åœ¨ä¸€äº›çƒå‘˜èº«ä¸Šä¼šå¤±å»ç¨³å®šæ€§ï¼Œä½†åœ¨æ•´ä¸ªè§†é¢‘ä¸­ï¼Œå®ƒä»ç„¶å¤§éƒ¨åˆ†æ—¶é—´æ˜¯å¯é ä¸”å‡†ç¡®çš„ã€‚

# **é€Ÿåº¦ã€è·ç¦»å’Œè¿›æ”»å‹åŠ›**

è·Ÿè¸ªé˜Ÿä¼å’Œçƒå‘˜çš„èƒ½åŠ›ä¸ºè¡¡é‡è¡¨ç°å¼€è¾Ÿäº†ä»¤äººå…´å¥‹çš„å¯èƒ½æ€§ï¼Œä¾‹å¦‚ç”Ÿæˆçƒ­å›¾ã€åˆ†æé€Ÿåº¦å’Œè¦†ç›–çš„è·ç¦»ã€è·Ÿè¸ªå¦‚åŒºåŸŸè¿›å…¥æˆ–é€€å‡ºç­‰åŠ¨ä½œï¼Œä»¥åŠæ·±å…¥ç ”ç©¶çƒå‘˜çš„è¯¦ç»†æŒ‡æ ‡ã€‚ä¸ºäº†è®©æˆ‘ä»¬èƒ½æ„Ÿå—è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†æ·»åŠ ä¸‰é¡¹è¡¨ç°æŒ‡æ ‡ï¼š**æ¯ä¸ªçƒå‘˜çš„å¹³å‡é€Ÿåº¦**ã€æ¯æ”¯é˜Ÿä¼æ»‘è¡Œçš„**è·ç¦»**ï¼Œä»¥åŠ**è¿›æ”»å‹åŠ›**ï¼ˆ*ä»¥æ¯æ”¯é˜Ÿä¼åœ¨å¯¹æ–¹åŒºåŸŸå†…æ‰€èŠ±è´¹çš„è·ç¦»å æ€»è·ç¦»çš„ç™¾åˆ†æ¯”æ¥è¡¡é‡*ï¼‰ã€‚æˆ‘å°†æŠŠæ›´è¯¦ç»†çš„ç»Ÿè®¡æ•°æ®ç•™ç»™ä½ ä»¬ï¼

æˆ‘ä»¬å¼€å§‹å°†å†°åœºçš„åæ ‡ä»åŸºäºåƒç´ çš„åº¦é‡è½¬æ¢ä¸ºè¿‘ä¼¼ç±³æ•°ã€‚è¿™ä¸€è°ƒæ•´ä½¿æˆ‘ä»¬èƒ½å¤Ÿä»¥ç±³ä¸ºå•ä½è¯»å–æ•°æ®ï¼Œè€Œéåƒç´ ã€‚è§†é¢‘ä¸­çœ‹åˆ°çš„å†°åœºçš„å®é™…å°ºå¯¸å¤§çº¦ä¸º 15mx30mï¼ˆå®½åº¦ä¸º 15 ç±³ï¼Œé«˜åº¦ä¸º 30 ç±³ï¼‰ã€‚ä¸ºäº†æ–¹ä¾¿è¿™ä¸€è½¬æ¢ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å°†åƒç´ åæ ‡è½¬æ¢ä¸ºç±³çš„æ–¹å¼ã€‚é€šè¿‡å®šä¹‰å†°åœºçš„å®é™…å°ºå¯¸ï¼Œå¹¶ä½¿ç”¨å…¶è§’è½çš„åƒç´ åæ ‡ï¼ˆä»å·¦åˆ°å³ï¼Œä»ä¸Šåˆ°ä¸‹ï¼‰ï¼Œæˆ‘ä»¬è·å¾—äº†è½¬æ¢å› å­ã€‚è¿™äº›å› å­å°†æ”¯æŒæˆ‘ä»¬ä¼°ç®—ç±³æ•°å’Œæ¯ç§’ç±³æ•°é€Ÿåº¦çš„è¿‡ç¨‹ã€‚*ï¼ˆå¦ä¸€ä¸ªæœ‰è¶£çš„æŠ€æœ¯æ˜¯é€è§†å˜æ¢ï¼Œä½ å¯ä»¥æ¢ç´¢å¹¶åº”ç”¨å®ƒï¼‰*

```py
#*********************Loads models and rink coordinates*****************#
class_names = ['Referee', 'Tm_white', 'Tm_yellow']

class HockeyAnalyzer:
    def __init__(self, model_path, classifier_path):
        *
        *
        *
        *
        *
        *
        self.pixel_to_meter_conversion() #<------ Add this utility method

#***********Pixel-based measurements to meters***************************#
    def pixel_to_meter_conversion(self):
        #Rink real dimensions in meters
        rink_width_m = 15
        rink_height_m = 30

        #Pixel coordinates for rink dimensions
        left_pixel, right_pixel = self.rink_coordinates[0][0], self.rink_coordinates[1][0]
        top_pixel, bottom_pixel = self.rink_coordinates[2][1], self.rink_coordinates[0][1]

        #Conversion factors
        self.pixels_per_meter_x = (right_pixel - left_pixel) / rink_width_m
        self.pixels_per_meter_y = (bottom_pixel - top_pixel) / rink_height_m

    def convert_pixels_to_meters(self, distance_pixels):
        #Convert pixels to meters
        return distance_pixels / self.pixels_per_meter_x, distance_pixels / self.pixels_per_meter_y
```

æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½**ä»¥æ¯ç§’ç±³æ•°ä¸ºå•ä½æ·»åŠ æ¯ä¸ªçƒå‘˜çš„é€Ÿåº¦**ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œä¸‰å¤„ä¿®æ”¹ã€‚é¦–å…ˆï¼Œåœ¨**HockeyAnalyzer ç±»**ä¸­åˆå§‹åŒ–ä¸€ä¸ªåä¸º**previous_positions**çš„ç©ºå­—å…¸ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬æ¯”è¾ƒçƒå‘˜çš„å½“å‰å’Œå‰ä¸€ä¸ªä½ç½®ã€‚åŒæ ·ï¼Œæˆ‘ä»¬è¿˜å°†åˆ›å»ºä¸€ä¸ª**team_stats**ç»“æ„æ¥å­˜å‚¨æ¯æ”¯é˜Ÿä¼çš„ç»Ÿè®¡æ•°æ®ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥å¯è§†åŒ–ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ·»åŠ ä¸€ä¸ª**é€Ÿåº¦æ–¹æ³•**æ¥ä¼°ç®—çƒå‘˜çš„é€Ÿåº¦ï¼ˆä»¥æ¯ç§’åƒç´ æ•°ä¸ºå•ä½ï¼‰ï¼Œç„¶åä½¿ç”¨å‰é¢è§£é‡Šçš„è½¬æ¢å› å­å°†å…¶è½¬æ¢ä¸ºæ¯ç§’ç±³æ•°ã€‚æœ€åï¼Œåœ¨**analyze_video æ–¹æ³•**ä¸­ï¼Œæˆ‘ä»¬å°†è°ƒç”¨æ–°çš„é€Ÿåº¦æ–¹æ³•ï¼Œå¹¶å°†é€Ÿåº¦æ·»åŠ åˆ°æ¯ä¸ªè¿½è¸ªçš„å¯¹è±¡ï¼ˆçƒå‘˜å’Œè£åˆ¤ï¼‰ä¸­ã€‚è¿™å°±æ˜¯è¿™äº›æ›´æ”¹çš„æ•ˆæœï¼š

```py
#*********************Loads models and rink coordinates*****************#
class_names = ['Referee', 'Tm_white', 'Tm_yellow']

class HockeyAnalyzer:
    def __init__(self, model_path, classifier_path):
        *
        *
        *
        *
        *
        *
        *
        self.pixel_to_meter_conversion() 
        self.previous_positions = {} #<------ Add this.Initializes empty dictionary 
        self.team_stats = {
                    'Tm_white': {'distance': 0, 'speed': [], 'count': 0, 'offensive_pressure': 0},
                    'Tm_yellow': {'distance': 0, 'speed': [], 'count': 0, 'offensive_pressure': 0}
                } #<------ Add this.Initializes empty dictionary

#**************** Speed: meters per second********************************#
    def calculate_speed(self, track_id, x_center, y_center, fps):
        current_position = (x_center, y_center)
        if track_id in self.previous_positions:
            prev_position = self.previous_positions[track_id]
            distance_pixels = np.linalg.norm(np.array(current_position) - np.array(prev_position))
            distance_meters_x, distance_meters_y = self.convert_pixels_to_meters(distance_pixels)
            speed_meters_per_second = (distance_meters_x**2 + distance_meters_y**2)**0.5 * fps
        else:
            speed_meters_per_second = 0
        self.previous_positions[track_id] = current_position
        return speed_meters_per_second

#******************* Loads Tracked Data (pickle file )**********************************#

    def analyze_video(self, video_path, output_path, tracks_path):
          with open(tracks_path, 'rb') as f:
              tracks = pickle.load(f)

        *
        *
        *
        *
        *
        *
        *
        *
              # Draw Team label
                  cv2.putText(
                      frame,
                      team,
                      (int(x1), int(y1) + text_offset), 
                      cv2.FONT_HERSHEY_PLAIN,            
                      font_scale,
                      text_color,
                      thickness=2
                  )

#**************Add these lines of code --->:

                  speed = self.calculate_speed(track_id, x_center, y_center, fps)
                  # Speed label 
                  speed_font_scale = 0.8  
                  speed_y_position = int(y1) + 20
                  if speed_y_position > int(y1) - 5:
                      speed_y_position = int(y1) - 5

                  cv2.putText(
                      frame,
                      f"Speed: {speed:.2f} m/s",  
                      (int(x1), speed_y_position),  
                      cv2.FONT_HERSHEY_PLAIN,       
                      speed_font_scale,
                      text_color,
                      thickness=2
                  )

              # Write output video
              out.write(frame)
              frame_num += 1

          cap.release()
          out.release()
```

å¦‚æœä½ åœ¨æ·»åŠ è¿™äº›æ–°ä»£ç æ—¶é‡åˆ°é—®é¢˜ï¼Œä½ å¯ä»¥éšæ—¶è®¿é—®[é¡¹ç›®çš„ GitHub ä»“åº“](https://github.com/rvizcarra15/IceHockey_ComputerVision_PyTorch)ï¼Œåœ¨è¿™é‡Œä½ å¯ä»¥æ‰¾åˆ°å®Œæ•´çš„é›†æˆä»£ç ã€‚æ­¤æ—¶ï¼Œä½ çš„è§†é¢‘è¾“å‡ºåº”è¯¥å¦‚ä¸‹æ‰€ç¤ºï¼ˆ*æ³¨æ„é€Ÿåº¦å·²æ·»åŠ åˆ°æ¯ä¸ªçƒå‘˜çš„æ ‡ç­¾ä¸Š*ï¼‰ï¼š

![](img/56fe2cf37374ce478a5baaa91c6c66a7.png)

ç¤ºä¾‹ç‰‡æ®µ 07ï¼šè·Ÿè¸ªçƒå‘˜å’Œé€Ÿåº¦

æœ€åï¼Œè®©æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªç»Ÿè®¡æ¿ï¼Œè·Ÿè¸ªæ¯æ”¯é˜Ÿä¼æ¯ä¸ªçƒå‘˜çš„å¹³å‡é€Ÿåº¦ï¼Œå¹¶æ˜¾ç¤ºå…¶ä»–æ•°æ®ï¼Œä¾‹å¦‚è¡Œè¿›çš„è·ç¦»å’Œåœ¨å¯¹æ–¹åŒºåŸŸå†…çš„è¿›æ”»å‹åŠ›ã€‚

æˆ‘ä»¬å·²ç»å®šä¹‰äº†è¿›æ”»åŒºåŸŸå¹¶å°†å…¶é›†æˆåˆ°æˆ‘ä»¬çš„ä»£ç ä¸­ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦è·Ÿè¸ªæ¯ä¸ªçƒå‘˜è¿›å…¥å¯¹æ–¹åŒºåŸŸçš„æ¬¡æ•°ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªæ–¹æ³•ï¼Œä½¿ç”¨[**å°„çº¿æŠ•å°„ç®—æ³•**](https://medium.com/@girishajmera/exploring-algorithms-to-determine-points-inside-or-outside-a-polygon-038952946f87)ã€‚è¿™ä¸ªç®—æ³•æ£€æŸ¥çƒå‘˜çš„ä½ç½®æ˜¯å¦åœ¨ç™½é˜Ÿæˆ–é»„é˜Ÿçš„è¿›æ”»åŒºåŸŸå†…ã€‚å®ƒé€šè¿‡ä»çƒå‘˜åˆ°ç›®æ ‡åŒºåŸŸç”»ä¸€æ¡è™šæ‹Ÿçº¿æ¥å·¥ä½œã€‚å¦‚æœè¿™æ¡çº¿ç©¿è¿‡ä¸€ä¸ªè¾¹ç•Œï¼Œåˆ™è¡¨ç¤ºçƒå‘˜åœ¨å†…éƒ¨ï¼›å¦‚æœç©¿è¿‡å¤šä¸ªè¾¹ç•Œï¼ˆåœ¨æˆ‘ä»¬è¿™ä¸ªæ¡ˆä¾‹ä¸­æ˜¯ç©¿è¿‡å››ä¸ªè¾¹ç•Œä¸­çš„ä¸¤ä¸ªï¼‰ï¼Œåˆ™è¡¨ç¤ºçƒå‘˜åœ¨å¤–éƒ¨ã€‚ä»£ç æ¥ç€æ‰«ææ•´ä¸ªè§†é¢‘ï¼Œç¡®å®šæ¯ä¸ªè·Ÿè¸ªç‰©ä½“çš„åŒºåŸŸçŠ¶æ€ã€‚

```py
 #************ Locate player's position in Target Zone***********************#

    def is_inside_zone(self, position, zone):
          x, y = position
          n = len(zone)
          inside = False
          p1x, p1y = zone[0]
          for i in range(n + 1):
              p2x, p2y = zone[i % n]
              if y > min(p1y, p2y):
                  if y <= max(p1y, p2y):
                      if x <= max(p1x, p2x):
                          if p1y != p2y:
                              xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x
                          if p1x == p2x or x <= xinters:
                              inside = not inside
              p1x, p1y = p2x, p2y
          return inside
```

ç°åœ¨ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ·»åŠ ä¸€ä¸ªæ–¹æ³•æ¥å¤„ç†è¡¨ç°æŒ‡æ ‡ï¼Œè¯¥æ–¹æ³•å°†åœ¨è¡¨æ ¼æ ¼å¼ä¸­ä¸ºæ¯æ”¯é˜Ÿä¼æ˜¾ç¤º**çƒå‘˜å¹³å‡é€Ÿåº¦**ã€**æ€»è¡Œè¿›è·ç¦»**å’Œ**è¿›æ”»å‹åŠ›**ï¼ˆåœ¨å¯¹æ–¹åŒºåŸŸå†…çš„æ—¶é—´ç™¾åˆ†æ¯”ï¼‰ã€‚ä½¿ç”¨ OpenCVï¼Œæˆ‘ä»¬å°†è¿™äº›æŒ‡æ ‡æ ¼å¼åŒ–ä¸ºè¦†ç›–åœ¨è§†é¢‘ä¸Šçš„è¡¨æ ¼ï¼Œå¹¶å°†åŠ å…¥åŠ¨æ€æ›´æ–°æœºåˆ¶ï¼Œä»¥ä¿æŒæ¸¸æˆè¿‡ç¨‹ä¸­çš„å®æ—¶ç»Ÿè®¡ã€‚

```py
#*******************************Performance metrics*********************************************#
    def draw_stats(self, frame):
         avg_speed_white = np.mean(self.team_stats['Tm_white']['speed']) if self.team_stats['Tm_white']['count'] > 0 else 0
         avg_speed_yellow = np.mean(self.team_stats['Tm_yellow']['speed']) if self.team_stats['Tm_yellow']['count'] > 0 else 0
         distance_white = self.team_stats['Tm_white']['distance']
         distance_yellow = self.team_stats['Tm_yellow']['distance']

         offensive_pressure_white = self.team_stats['Tm_white'].get('offensive_pressure', 0)
         offensive_pressure_yellow = self.team_stats['Tm_yellow'].get('offensive_pressure', 0)

         Pressure_ratio_W = offensive_pressure_white/distance_white   *100  if self.team_stats['Tm_white']['distance'] > 0 else 0
         Pressure_ratio_Y = offensive_pressure_yellow/distance_yellow *100  if self.team_stats['Tm_yellow']['distance'] > 0 else 0

         table = [
             ["", "Away_White", "Home_Yellow"],
             ["Average Speed\nPlayer", f"{avg_speed_white:.2f} m/s", f"{avg_speed_yellow:.2f} m/s"],
             ["Distance\nCovered", f"{distance_white:.2f} m", f"{distance_yellow:.2f} m"],
             ["Offensive\nPressure %", f"{Pressure_ratio_W:.2f} %", f"{Pressure_ratio_Y:.2f} %"],
         ]

         text_color = (0, 0, 0)  
         start_x, start_y = 10, 590  
         row_height = 30     # Manage Height between rows
         column_width = 150  # Manage Width  between rows
         font_scale = 1  

         def put_multiline_text(frame, text, position, font, font_scale, color, thickness, line_type, line_spacing=1.0):
             y0, dy = position[1], int(font_scale * 20 * line_spacing)  # Adjust line spacing here
             for i, line in enumerate(text.split('\n')):
                 y = y0 + i * dy
                 cv2.putText(frame, line, (position[0], y), font, font_scale, color, thickness, line_type)

         for i, row in enumerate(table):
             for j, text in enumerate(row):
                 if i in [1,2, 3]:  
                     put_multiline_text(
                         frame,
                         text,
                         (start_x + j * column_width, start_y + i * row_height),
                         cv2.FONT_HERSHEY_PLAIN,
                         font_scale,
                         text_color,
                         1,
                         cv2.LINE_AA,
                         line_spacing= 0.8 
                     )
                 else:
                     cv2.putText(
                         frame,
                         text,
                         (start_x + j * column_width, start_y + i * row_height),
                         cv2.FONT_HERSHEY_PLAIN,
                         font_scale,
                         text_color,
                         1,
                         cv2.LINE_AA,
                     )       

#****************** Track and update game stats****************************************#

    def update_team_stats(self, team, speed, distance, position):
        if team in self.team_stats:
            self.team_stats[team]['speed'].append(speed)
            self.team_stats[team]['distance'] += distance
            self.team_stats[team]['count'] += 1

            if team == 'Tm_white':
                if self.is_inside_zone(position, self.zone_white):
                    self.team_stats[team]['offensive_pressure'] += distance
            elif team == 'Tm_yellow':
                if self.is_inside_zone(position, self.zone_yellow):
                    self.team_stats[team]['offensive_pressure'] += distance
```

ä¸ºäº†åœ¨è§†é¢‘ä¸­æ˜¾ç¤ºç»Ÿè®¡æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦è°ƒç”¨**analyze_video æ–¹æ³•**ï¼Œå› æ­¤è¯·ç¡®ä¿åœ¨å®šä¹‰é€Ÿåº¦æ ‡ç­¾åã€å¤„ç†è¾“å‡ºè§†é¢‘ä¹‹å‰ï¼Œæ·»åŠ è¿™äº›é¢å¤–çš„ä»£ç è¡Œï¼š

```py
*
*
*
*
*
*
*
#Speed label 
                  speed_font_scale = 0.8  
                  speed_y_position = int(y1) + 20
                  if speed_y_position > int(y1) - 5:
                      speed_y_position = int(y1) - 5

                  cv2.putText(
                      frame,
                      f"Speed: {speed:.2f} m/s",  
                      (int(x1), speed_y_position),  
                      cv2.FONT_HERSHEY_PLAIN,       
                      speed_font_scale,
                      text_color,
                      thickness=2
                  )
#**************Add these lines of code--->:

                  distance = speed / fps
                  position = (x_center, y_center)
                  self.update_team_stats(team, speed, distance, position)

              # Write output video
              out.write(frame)
              frame_num += 1
```

æ¯ä¸ªçƒå‘˜æ‰€è¦†ç›–çš„è·ç¦»ï¼ˆå•ä½ï¼šç±³ï¼‰æ˜¯é€šè¿‡å°†å…¶é€Ÿåº¦ï¼ˆä»¥ç±³/ç§’ä¸ºå•ä½ï¼‰é™¤ä»¥å¸§ç‡ï¼ˆä»¥å¸§/ç§’ä¸ºå•ä½ï¼‰æ¥è®¡ç®—çš„ã€‚è¿™ä¸ªè®¡ç®—æ–¹æ³•ä½¿æˆ‘ä»¬èƒ½å¤Ÿä¼°ç®—æ¯ä¸ªçƒå‘˜åœ¨è§†é¢‘ä¸­æ¯æ¬¡å¸§å˜åŒ–ä¹‹é—´ç§»åŠ¨çš„è·ç¦»ã€‚å¦‚æœä¸€åˆ‡é¡ºåˆ©ï¼Œæœ€ç»ˆçš„è§†é¢‘è¾“å‡ºåº”è¯¥æ˜¯è¿™æ ·çš„ï¼š

![](img/7a960baa2383b62cff2c4cf942ad002a.png)

ç¤ºä¾‹ç‰‡æ®µ 08ï¼šæœ€ç»ˆè¾“å‡º

# è€ƒè™‘äº‹é¡¹ä¸æœªæ¥å·¥ä½œ

è¯¥æ¨¡å‹æ˜¯ä½¿ç”¨è®¡ç®—æœºè§†è§‰è¿½è¸ªå†°çƒæ¯”èµ›ä¸­çƒå‘˜çš„åŸºæœ¬è®¾ç½®ï¼ˆæˆ–ä»»ä½•å›¢é˜Ÿè¿åŠ¨ï¼‰ã€‚ç„¶è€Œï¼Œè¿˜æœ‰è®¸å¤šç²¾ç»†è°ƒä¼˜å¯ä»¥æ”¹è¿›ï¼Œå¹¶ä¸”å¯ä»¥æ·»åŠ æ–°åŠŸèƒ½ã€‚ä»¥ä¸‹æ˜¯æˆ‘æ­£åœ¨ç ”ç©¶çš„ä¸€äº›æƒ³æ³•ï¼Œç”¨äºä¸‹ä¸€ç‰ˆæœ¬ 2.0ï¼Œä½ ä¹Ÿå¯ä»¥è€ƒè™‘è¿™äº›æƒ³æ³•ï¼š

***è·Ÿè¸ªå†°çƒçš„æŒ‘æˆ˜ï¼š*** æ ¹æ®ç›¸æœºçš„æœå‘å’Œåˆ†è¾¨ç‡ï¼Œè·Ÿè¸ªå†°çƒæ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå› ä¸ºå®ƒçš„å°ºå¯¸ç›¸è¾ƒäºè¶³çƒæˆ–ç¯®çƒçƒæ¥è¯´è¾ƒå°ã€‚ä½†å¦‚æœä½ èƒ½å¤Ÿå®ç°è¿™ä¸€ç‚¹ï¼Œä¾¿èƒ½å¼€å¯ä¸€äº›æœ‰è¶£çš„å¯èƒ½æ€§æ¥è¿½è¸ªè¡¨ç°ï¼Œä¾‹å¦‚æ§çƒæ—¶é—´ã€è¿›æ”»æœºä¼šæˆ–å°„é—¨æ•°æ®ã€‚è¿™åŒæ ·é€‚ç”¨äºä¸ªåˆ«çƒå‘˜çš„è¡¨ç°ï¼›åœ¨å†°çƒä¸­ï¼Œçƒå‘˜çš„æ¢äººé¢‘ç‡è¿œé«˜äºå…¶ä»–å›¢é˜Ÿè¿åŠ¨ï¼Œå› æ­¤ï¼Œåœ¨ä¸€ä¸ªæ—¶æ®µå†…è¿½è¸ªæ¯ä¸ªçƒå‘˜çš„è¡¨ç°ä¹Ÿæ˜¯ä¸€ç§æŒ‘æˆ˜ã€‚

***è®¡ç®—èµ„æºï¼Œå“¦ï¼Œä¸ºä»€ä¹ˆæ˜¯è®¡ç®—ï¼*** æˆ‘åœ¨ä¸€ä¸ª CPU é…ç½®ä¸Šè¿è¡Œäº†æ‰€æœ‰ä»£ç ï¼Œä½†ç”±äºåœ¨è®¾è®¡è¿‡ç¨‹ä¸­å†…å­˜ä¸è¶³ï¼ˆæœ‰æ—¶å¯¼è‡´è“å± ğŸ˜¥ï¼‰ï¼Œé‡åˆ°äº†é—®é¢˜ï¼ˆå»ºè®®ä½¿ç”¨ CUDA è®¾ç½®ï¼‰ã€‚æˆ‘ä»¬çš„ç¤ºä¾‹è§†é¢‘å¤§çº¦ 40 ç§’é•¿ï¼Œæœ€åˆä¸º 5 MBï¼Œä½†åœ¨è¿è¡Œæ¨¡å‹åï¼Œè¾“å‡ºæ–‡ä»¶çš„å¤§å°å¢åŠ åˆ° 34 MBã€‚æƒ³è±¡ä¸€ä¸‹å®Œæ•´çš„ 20 åˆ†é’Ÿæ¯”èµ›æœŸé—´çš„å¤§å°ã€‚æ‰€ä»¥ï¼Œåœ¨æ‰©å±•æ—¶ï¼Œä½ åº”è¯¥è€ƒè™‘è®¡ç®—èµ„æºå’Œå­˜å‚¨ã€‚

***ä¸è¦ä½ä¼° MLOpsï¼š*** è¦å¿«é€Ÿéƒ¨ç½²å’Œæ‰©å±•ï¼Œæˆ‘ä»¬éœ€è¦é«˜æ•ˆçš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œæ”¯æŒé¢‘ç¹æ‰§è¡Œï¼Œå¹¶ä¸”å¯é ã€‚è¿™éœ€è¦è€ƒè™‘**æŒç»­é›†æˆ-éƒ¨ç½²-è®­ç»ƒæ–¹æ³•**ã€‚æˆ‘ä»¬çš„ç”¨ä¾‹æ˜¯ä¸ºç‰¹å®šåœºæ™¯æ„å»ºçš„ï¼Œä½†å¦‚æœæ¡ä»¶å‘ç”Ÿå˜åŒ–ï¼Œæ¯”å¦‚æ‘„åƒå¤´æ–¹å‘æˆ–çƒè¡£é¢œè‰²å˜åŒ–æ€ä¹ˆåŠï¼Ÿä¸ºäº†æ‰©å±•ï¼Œæˆ‘ä»¬å¿…é¡»é‡‡çº³ CI/CD/CT æ€ç»´æ¨¡å¼ã€‚

å¸Œæœ›ä½ å¯¹è¿™ä¸ªè®¡ç®—æœºè§†è§‰é¡¹ç›®æ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥åœ¨[è¿™ä¸ª GitHub ä»“åº“](https://github.com/rvizcarra15/IceHockey_ComputerVision_PyTorch)è®¿é—®å®Œæ•´çš„ä»£ç ã€‚å¦‚æœä½ æƒ³æ”¯æŒè¯¥åœ°åŒºçš„å†°çƒå’Œå†°çƒè¿åŠ¨å‘å±•ï¼Œå¯ä»¥å…³æ³¨[APHL](https://www.instagram.com/aphl.pe/?igsh=MThvZWxhNThwdXpibA%3D%3D) *(æˆ‘ä»¬æ€»æ˜¯éœ€è¦æ‚¨æèµ çš„äºŒæ‰‹è®¾å¤‡ï¼Œä¾›å¹´è½»çƒå‘˜ä½¿ç”¨ï¼Œå¹¶æ­£åœ¨å»ºè®¾æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå®˜æ–¹å†°çƒåœº)*ï¼Œå…¨çƒèŒƒå›´å†…ï¼Œä¹Ÿå¯ä»¥å…³æ³¨å¹¶æ”¯æŒ[Friendship League](https://friendshipleague.org/)ã€‚

***æˆ‘æ¼æ‰äº†ä»€ä¹ˆå—ï¼Ÿ*** æ¬¢è¿æå‡ºå»ºè®®ã€‚è®©æˆ‘ä»¬ç»§ç»­äº¤æµï¼
