- en: 'Breaking It Down : Chunking for Better RAG'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/breaking-it-down-chunking-techniques-for-better-rag-3fd288bf25a0?source=collection_archive---------3-----------------------#2024-09-23](https://towardsdatascience.com/breaking-it-down-chunking-techniques-for-better-rag-3fd288bf25a0?source=collection_archive---------3-----------------------#2024-09-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Mastering chunking for efficient retrieval in RAG systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)[![Abhinav
    Kimothi](../Images/ed5548c99e1910e7dc35bfcac26cb314.png)](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)
    [Abhinav Kimothi](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)
    ·16 min read·Sep 23, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/abcbc7730840cce9e65a7c001518abe9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Chunking is a crucial component of RAG systems (Source: AI Image generated
    by the author using FLUX)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Preamble : RAG and the need for a Knowledge Base'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a short time, **Large Language Models (LLMs)** have found a wide applicability
    in modern language processing tasks and even paved the way for autonomous AI agents.
    There are high chances that you’ve heard about, if not personally used, ChatGPT.
    ChatGPT is powered by a generative AI technique called Large Language Models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Retrieval Augmented Generation**, or **RAG**, has emerged to be one of the
    most popular techniques in the applied generative AI world. Despite Large Language
    Models demonstrating unprecedented ability to generate text, their responses are
    not always correct. Upon more careful observation, you may notice that LLM responses
    are plagued with sub-optimal information and inherent memory limitations. [RAG
    addresses these limitations of LLMs by providing them with information external
    to these models.](https://arxiv.org/abs/2005.11401) Thereby, resulting in LLM
    responses that are more reliable and trustworthy. The basic concept of RAG is
    *illustrated in the example below*. Here we provide external information to ChatGPT
    (manually) to make it respond accurately.'
  prefs: []
  type: TYPE_NORMAL
