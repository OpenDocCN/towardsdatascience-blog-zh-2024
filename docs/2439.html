<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Scaling RAG from POC to Production</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Scaling RAG from POC to Production</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scaling-rag-from-poc-to-production-31bd45d195c8?source=collection_archive---------0-----------------------#2024-10-07">https://towardsdatascience.com/scaling-rag-from-poc-to-production-31bd45d195c8?source=collection_archive---------0-----------------------#2024-10-07</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="a86d" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Common challenges and architectural components to enable scaling</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@bhagatanurag03?source=post_page---byline--31bd45d195c8--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Anurag Bhagat" class="l ep by dd de cx" src="../Images/3711a1fce6e2a45d649e534f08c3d0ca.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*8uoJyDv2KSQC_czPcsr8cA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--31bd45d195c8--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@bhagatanurag03?source=post_page---byline--31bd45d195c8--------------------------------" rel="noopener follow">Anurag Bhagat</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--31bd45d195c8--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 7, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">8</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/ee14c78dc3f1d708f7e587a83fe8d0db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*33pjuHPUAC-01Hik"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Source: Generated with the help of AI (OpenAI’s Dall-E model)</em></figcaption></figure><h1 id="a4dc" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">1. Introduction</h1><h2 id="4f87" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">1.1. Overview of RAG</h2><p id="33ae" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">Those of you who have been immersed in generative AI and its large-scale applications outside of personal productivity apps have likely come across the notion of Retrieval Augmented Generation or RAG. The RAG architecture consists of two key components—the retrieval component which uses vector databases to do an index based search on a large corpus of documents. This is then sent over to a large language model (LLM) to generate a grounded response based on the richer context in the prompt.</p><p id="d827" class="pw-post-body-paragraph ot ou fq ov b go pm ox oy gr pn pa pb og po pd pe ok pp pg ph oo pq pj pk pl fj bk">Whether you are building customer-facing chatbots to answer repetitive questions and reduce workload from customer service agents, or building a co-pilot for engineers to help them navigate complex user manuals step-by-step, RAG has become a key archetype of the application of LLMs. This has enabled LLMs to provide a contextually relevant response based on ground truth of hundreds or millions of documents, reducing hallucinations and improving the reliability of LLM-based applications.</p><h2 id="d9f7" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">1.2. Why scale from Proof of Concept(POC) to production</h2><p id="4b84" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">If you are asking this question, I might challenge you to answer why are you even building a POC if there is no intent of getting it to production. Pilot purgatory is a common risk with organisations that start to experiment, but then get stuck in experimentation mode. Remember that POCs are expensive, and true value realisation only happens once you go into production and do things at scale- either freeing up resources, making them more efficient, or creating additional revenue streams.</p><h1 id="c849" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">2. Key challenges in scaling RAG</h1><h2 id="29ec" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">2.1. Performance</h2><p id="7375" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">Performance challenges in RAGs come in various flavours. The speed of retrieval is generally not the primary challenge unless your knowledge corpus has millions of documents, and even then it can be solved by setting up the right infrastructure- of course, we are limited by inference times. The second performance problem we encounter is around getting the “right” chunks to be fed to the LLMs for generation, with a high level of precision and recall. The poorer the retrieval process is, the less contextually relevant the LLM response will be.</p><h2 id="d86b" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">2.2. Data Management</h2><p id="2f7e" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">We have all heard the age-old saying “garbage in garbage out (GIGO)”. RAG is nothing but a set of tools we have at our disposal, but the real value comes from the actual data. As RAG systems work with unstructured data, it comes with its own set of challenges including but not limited to- version control of documents, and format conversion (e.g. pdf to text), among others.</p><h2 id="e6eb" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">2.3. Risk</h2><p id="08b5" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">One of the biggest reasons corporations hesitate to move from testing the waters to jumping in is the possible risks that come with using AI based systems. Hallucinations are definitely lowered with the use of RAG, but are still non-zero. There are other associated risks including risks for bias, toxicity, regulatory risks etc. which could have long term implications.</p><h2 id="a93e" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">2.4. Integration into existing workflows</h2><p id="3634" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">Building an offline solution is easier, but bringing in the end users’ perspective is crucial to make sure the solution does not feel like a burden. No users want to go to another screen to use the “new AI feature”- users want the AI features built into their existing workflows so the technology is assistive, and not disruptive to the day-to-day.</p><h2 id="a74e" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">2.5. Cost</h2><p id="9df7" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">Well, this one seems sort of obvious, doesn’t it? Organisations are implementing GenAI use cases so that they can create business impact. If the benefits are lower than we planned, or there are cost overruns, the impact would be severely diminished, or also completely negated.</p><h1 id="5db2" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">3. Architectural components needed for Scaling</h1><p id="4add" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">It would be unfair to only talk about challenges if we don’t talk about the “so what do we do”. There are a few essential components you can add to your architecture stack to overcome/diminish some of the problems we outlined above.</p><h2 id="847e" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">3.1. Scalable vector databases</h2><p id="1244" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">A lot of teams, rightfully, start with open-source vector databases like <a class="af pr" href="https://www.trychroma.com/" rel="noopener ugc nofollow" target="_blank">ChromaDB</a>, which are great for POCs as they are easy to use and customise. However, it may face challenges with large-scale deployments. This is where scalable vector databases come in (such as <a class="af pr" href="https://www.pinecone.io/" rel="noopener ugc nofollow" target="_blank">Pinecone</a>, <a class="af pr" href="https://weaviate.io/platform" rel="noopener ugc nofollow" target="_blank">Weaviate</a>, <a class="af pr" href="https://milvus.io/" rel="noopener ugc nofollow" target="_blank">Milvus</a>, etc.) which are optimised for high-dimensional vector searches, enabling fast (sub-millisecond), accurate retrieval even as the dataset size increases into the millions or billions of vectors as they use <a class="af pr" href="https://www.mongodb.com/resources/basics/ann-search" rel="noopener ugc nofollow" target="_blank">Approximate Nearest Neighbour</a> search techniques. These vector databases have APIs, plugins, and SDKs that allow for easier workflow integration and they are also horizontally scalable. Depending on the platform one is working on- it might make sense to explore vector databases offered by <a class="af pr" href="https://www.databricks.com/product/machine-learning/vector-search" rel="noopener ugc nofollow" target="_blank">Databricks</a> or <a class="af pr" href="https://aws.amazon.com/opensearch-service/" rel="noopener ugc nofollow" target="_blank">AWS</a>.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/6f8562c4e112308a47a06f348db3715d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8WfH_YWkpuH4w-n-"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Source: Generated with the help of AI (OpenAI’s Dall-E model)</em></figcaption></figure><h2 id="7772" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">3.2. Caching Mechanisms</h2><p id="63bb" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">The concept of caching has been around almost as long as the internet, <a class="af pr" href="https://cacm.acm.org/opinion/ibms-single-processor-supercomputer-efforts/#:~:text=a.,computer%20system%20to%20use%20cache" rel="noopener ugc nofollow" target="_blank">dating back to</a> the 1960’s. The same concept applies to GenerativeAI as well—If there are a large number of queries, maybe in the millions (very common in the customer service function), it is likely that many queries are the same or extremely similar. Caching allows one to avoid sending a request to the LLM if we can instead return a response from a recent cached response. This serves two purposes- reduced costs, as well as better response times for common queries.</p><p id="a8ff" class="pw-post-body-paragraph ot ou fq ov b go pm ox oy gr pn pa pb og po pd pe ok pp pg ph oo pq pj pk pl fj bk">This can be implemented as a memory Cache (in-memory caches like <a class="af pr" href="https://redis.io/" rel="noopener ugc nofollow" target="_blank">Redis</a> or <a class="af pr" href="https://memcached.org/" rel="noopener ugc nofollow" target="_blank">Memcached</a>), Disk Cache for less frequent queries or distributed Cache (Redis Cluster). Some model providers like Anthropic offer <a class="af pr" href="https://www.anthropic.com/news/prompt-caching" rel="noopener ugc nofollow" target="_blank">prompt caching</a> as part of their APIs.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/eb99db871ae334a898f3493fc951fc01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*75sRhd3kFKHQYtM3"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Source: Generated with the help of AI (OpenAI’s Dall-E model)</em></figcaption></figure><h1 id="07b2" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">3.3. Advanced Search Techniques</h1><p id="3c48" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">While not as crisply an architecture component, multiple techniques can help elevate the search to enhance both efficiency and accuracy. Some of these include:</p><ul class=""><li id="a028" class="ot ou fq ov b go pm ox oy gr pn pa pb og po pd pe ok pp pg ph oo pq pj pk pl ps pt pu bk"><strong class="ov fr">Hybrid Search: I</strong>nstead of relying only on semantic search(using vector databases), or keyword search, use a combination to boost your search.</li><li id="54ce" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk"><strong class="ov fr">Re-ranking: </strong>Use a LLM or SLM to calculate a relevancy score for the query with each search result, and re-rank them to extract and share only the highly relevant ones. This is particularly useful for complex domains, or domains where one may have many documents being returned. One example of this is <a class="af pr" href="https://aws.amazon.com/marketplace/pp/prodview-pf7d2umihcseq" rel="noopener ugc nofollow" target="_blank">Cohere’s Rerank</a>.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/10211b4b3b6985b8800c7a4427794dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_sNyvu_DKRMbauBo"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Source: Generated with the help of AI (OpenAI’s Dall-E model)</em></figcaption></figure><h1 id="152b" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">3.4. Responsible AI layer</h1><p id="8c8a" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">Your Responsible AI modules have to be designed to mitigate bias, ensure transparency, align with your organisation’s ethical values, continuously monitor for user feedback and track compliance to regulation among other things, relevant to your industry/function. There are many ways to go about it, but fundamentally this has to be enabled programmatically, with human oversight. A few ways it can be done that can be done:</p><ul class=""><li id="4cfc" class="ot ou fq ov b go pm ox oy gr pn pa pb og po pd pe ok pp pg ph oo pq pj pk pl ps pt pu bk"><strong class="ov fr">Pre-processing: </strong>Filter user queries before they are ever sent over to the foundational model. This may include things like checking for bias, toxicity, un-intended use etc.</li><li id="5f6a" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk"><strong class="ov fr">Post-processing: </strong>Apply another set of checks after the results come back from the FMs, before exposing them to the end users.</li></ul><p id="17d0" class="pw-post-body-paragraph ot ou fq ov b go pm ox oy gr pn pa pb og po pd pe ok pp pg ph oo pq pj pk pl fj bk">These checks can be enabled as small reusable modules you buy from an external provider, or build/customise for your own needs. One common way organisations have approached this is to use carefully engineered prompts and foundational models to orchestrate a workflow and prevent a result reaching the end user till it passes all checks.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/184aa917e7c7eebc06ae752d9ef78de8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rFY6iQj3GT100a6z"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Source: Generated with the help of AI (OpenAI’s Dall-E model)</em></figcaption></figure><h2 id="f2c8" class="nz ne fq bf nf oa ob oc ni od oe of nl og oh oi oj ok ol om on oo op oq or os bk">3.5. API Gateway</h2><p id="a6e4" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">An API Gateway can serve multiple purposes helping manage costs, and various aspects of Responsible AI:</p><ul class=""><li id="5c5c" class="ot ou fq ov b go pm ox oy gr pn pa pb og po pd pe ok pp pg ph oo pq pj pk pl ps pt pu bk">Provide a unified interface to interact with foundational models, experiment with them</li><li id="281c" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk">Help develop a fine-grained view into costs and usage by team/use case/cost centre — including rate-limiting, speed throttling, quota management</li><li id="347b" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk">Serve as a responsible AI layer, filtering out in-intended requests/data before they ever hit the models</li><li id="140a" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk">Enable audit trails and access control</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/cb937658eacc1f107b854540ff8edb4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_3O2kndIydQq9cva"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Source: Generated with the help of AI (OpenAI’s Dall-E model)</em></figcaption></figure><h1 id="aedf" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">4. Is this enough, or do we need more?</h1><p id="29e0" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">Of course not. There are a few other things that also need to be kept in mind, including but not limited to:</p><ul class=""><li id="e252" class="ot ou fq ov b go pm ox oy gr pn pa pb og po pd pe ok pp pg ph oo pq pj pk pl ps pt pu bk">Does the use case occupy a strategic place in your roadmap of use cases? This enables you to have leadership backing, and right investments to support the development and maintenance.</li><li id="94e2" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk">A clear evaluation criterion to measure the performance of the application, against dimensions of accuracy, cost, latency and responsible AI</li><li id="29a9" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk">Improve business processes to keep knowledge up to date, maintain version control etc.</li><li id="c764" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk">Architect the RAG system so that it only accesses documents based on the end user permission levels, to prevent unauthorised access.</li><li id="d262" class="ot ou fq ov b go pv ox oy gr pw pa pb og px pd pe ok py pg ph oo pz pj pk pl ps pt pu bk">Use design thinking to integrate the application into the workflow of the end user e.g. if you are building a bot to answer technical questions over Confluence as the knowledge base, should you build a separate UI, or integrate this with Teams/Slack/other applications users already use?</li></ul><h1 id="044b" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">5. Conclusion</h1><p id="fb1e" class="pw-post-body-paragraph ot ou fq ov b go ow ox oy gr oz pa pb og pc pd pe ok pf pg ph oo pi pj pk pl fj bk">RAGs are a prominent use case archetype, and one of the first few ones that organisations try to implement. Scaling RAG from POC to production comes with its challenges, but with careful planning and execution, many of these can be overcome. Some of these can be solved by tactical investment in the architecture and technology, some require better strategic direction and tactful planning. As LLM inference costs continue to drop, either owing to reduced inference costs or heavier adoption of open-source models, cost barriers may not be a concern for many new use cases.</p><p id="a282" class="pw-post-body-paragraph ot ou fq ov b go pm ox oy gr pn pa pb og po pd pe ok pp pg ph oo pq pj pk pl fj bk"><em class="qa">All views in this article are the Author’s and don’t represent an endorsement of any products or services.</em></p></div></div></div></div>    
</body>
</html>