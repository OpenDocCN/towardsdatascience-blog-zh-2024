["```py\nX = [[i] for i in range(-20, 40)]\nY = [1 if z[0] < 10 else 0 for z in X]\n```", "```py\nmodel = nn.Sequential(nn.Linear(1,1), nn.Sigmoid())\nd = model.state_dict()\nd[\"0.weight\"] = torch.tensor([[-1]]).float()\nd['0.bias'] = torch.tensor([10]).float()\nmodel.load_state_dict(d)\ny_pred = model(x).detach().reshape(-1)\n```", "```py\nX_2D = [\n[random.randrange(-50, 50),\n random.randrange(-50, 50)]\n for i in range(1000)\n]\nY = [min(a, b) for a, b in X_2D]\n```", "```py\nmin(a, b) = 0.5 (a + b -|a - b|) = 0.5 (a + b - ReLU(b - a) - ReLU(a - b))\n```", "```py\nclass MinModel(nn.Module):\n  def __init__(self):\n      super(MinModel, self).__init__()\n\n      # For ReLU(a-b)\n      self.fc1 = nn.Linear(2, 1)\n      self.relu1 = nn.ReLU()\n      # For ReLU(b-a)\n      self.fc2 = nn.Linear(2, 1)\n      self.relu2 = nn.ReLU()\n      # Takes 4 inputs\n      # [a, b, ReLU(a-b), ReLU(b-a)]\n      self.output_layer = nn.Linear(4, 1)\n\n  def forward(self, x):\n      relu_output1 = self.relu1(self.fc1(x))\n      relu_output2 = self.relu2(self.fc2(x))\n      return self.output_layer(\n          torch.cat(\n             (x, Relu_output1, relu_output2),\n             dim=-1\n          )\n      )\n```", "```py\n>> for k, v in model.state_dict().items():\n>>   print(k, \": \", torch.round(v, decimals=2).numpy())\n\nfc1.weight :  [[-0\\. -0.]]\nfc1.bias :  [0.]\nfc2.weight :  [[ 0.71 -0.71]]\nfc2.bias :  [-0.]\noutput_layer.weight :  [[ 1\\.    0\\.    0\\.   -1.41]]\noutput_layer.bias :  [0.]\n```", "```py\nmodel([a,b]) = a - 1.41 * 0.71 ReLU(a-b) â‰ˆ a - ReLU(a-b)\n```", "```py\nX = [[i] for i in range(0, 16)]\nY = [z[0] % 2 for z in X]\n```", "```py\ndef create_sequential_model(layers_list = [1,2,2,2,2,2,1]):\n  layers = []\n  for i in range(1, len(layers_list)):\n      layers.append(nn.Linear(layers_list[i-1], layers_list[i]))\n      layers.append(nn.ReLU())\n  return nn.Sequential(*layers)\n\n# This weight matrix implements |ABS| using ReLU neurons.\n# |x-b| = Relu(-(x-b)) + Relu(x-b)\nabs_weight_matrix = torch_tensor([[-1, -1],\n                                  [1, 1]])\n# Returns the pair of biases used for each of the ReLUs.\nget_relu_bias = lambda b: torch_tensor([b, -b])\n\nd = model.state_dict()\nd['0.weight'], d['0.bias'] = torch_tensor([[-1],[1]]), get_relu_bias(8)\nd['2.weight'], d['2.bias'] = abs_weight_matrix, get_relu_bias(4)\nd['4.weight'], d['4.bias'] = abs_weight_matrix, get_relu_bias(2)\nd['6.weight'], d['6.bias'] = abs_weight_matrix, get_relu_bias(1)\nd['8.weight'], d['8.bias'] = abs_weight_matrix, get_relu_bias(1)\nd['10.weight'], d['10.bias'] = torch_tensor([[1, 1]]), torch_tensor([0])\nmodel.load_state_dict(d)\nmodel.state_dict()\n```"]