- en: A Fresh Look at Nonlinearity in Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习中的非线性全新视角
- en: 原文：[https://towardsdatascience.com/a-fresh-look-at-nonlinearity-in-deep-learning-a79b6955d2ad?source=collection_archive---------1-----------------------#2024-08-15](https://towardsdatascience.com/a-fresh-look-at-nonlinearity-in-deep-learning-a79b6955d2ad?source=collection_archive---------1-----------------------#2024-08-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-fresh-look-at-nonlinearity-in-deep-learning-a79b6955d2ad?source=collection_archive---------1-----------------------#2024-08-15](https://towardsdatascience.com/a-fresh-look-at-nonlinearity-in-deep-learning-a79b6955d2ad?source=collection_archive---------1-----------------------#2024-08-15)
- en: The traditional reasoning behind why we need nonlinear activation functions
    is only one dimension of this story.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们需要非线性激活函数的传统理由只是这个故事的一个维度。
- en: '[](https://medium.com/@crackalamoo?source=post_page---byline--a79b6955d2ad--------------------------------)[![Harys
    Dalvi](../Images/cf7fa3865063408efd1fd4c0b4b603db.png)](https://medium.com/@crackalamoo?source=post_page---byline--a79b6955d2ad--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a79b6955d2ad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a79b6955d2ad--------------------------------)
    [Harys Dalvi](https://medium.com/@crackalamoo?source=post_page---byline--a79b6955d2ad--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@crackalamoo?source=post_page---byline--a79b6955d2ad--------------------------------)[![Harys
    Dalvi](../Images/cf7fa3865063408efd1fd4c0b4b603db.png)](https://medium.com/@crackalamoo?source=post_page---byline--a79b6955d2ad--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a79b6955d2ad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a79b6955d2ad--------------------------------)
    [Harys Dalvi](https://medium.com/@crackalamoo?source=post_page---byline--a79b6955d2ad--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a79b6955d2ad--------------------------------)
    ·8 min read·Aug 15, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a79b6955d2ad--------------------------------)
    ·阅读时间8分钟·2024年8月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: What do the softmax, ReLU, sigmoid, and tanh functions have in common? They’re
    all **activation functions** — and they’re all **nonlinear**. But why do we need
    activation functions in the first place, specifically nonlinear activation functions?
    There’s a traditional reasoning, and also a new way to look at it.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: softmax、ReLU、sigmoid 和 tanh 函数有什么共同点？它们都是**激活函数**——而且它们都是**非线性**的。但我们为什么一开始就需要激活函数，特别是非线性激活函数呢？有一种传统的解释，也有一种新的看法。
- en: 'The traditional reasoning is this: without a nonlinear activation function,
    a deep neural network is just a composition of matrix multiplications and adding
    biases. These are **linear transformations**, and you can prove using linear algebra
    that **the composition of linear transformations is just another linear transformation.**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的理由是：如果没有非线性激活函数，一个深度神经网络仅仅是矩阵乘法和加偏置的组合。这些是**线性变换**，你可以通过线性代数证明，**线性变换的组合仍然是线性变换**。
- en: So no matter how many linear layers we stack together, without activation functions,
    our entire model is no better than a linear regression. It will completely fail
    to capture nonlinear relationships, even simple ones like XOR.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 所以无论我们堆叠多少线性层，没有激活函数，我们的整个模型也不过比线性回归更差。它将完全无法捕捉到非线性关系，甚至是像 XOR 这样简单的关系。
- en: 'Enter activation functions: by allowing the model to **learn a nonlinear function**,
    we gain the ability to model all kinds of complicated real-world relationships.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 引入激活函数：通过允许模型**学习一个非线性函数**，我们获得了建模各种复杂真实世界关系的能力。
- en: This story, which you may already be familiar with, is entirely correct. But
    the study of any topic benefits from a variety of viewpoints, especially deep
    learning with all its interpretability challenges. Today I want to share with
    you another way to look at the need for activation functions, and what it reveals
    about the inner workings of deep learning models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个你可能已经很熟悉的故事完全正确。但任何话题的研究都能从不同的角度受益，尤其是深度学习，其具备许多可解释性挑战。今天，我想和你分享一种看待激活函数需求的全新方式，以及它揭示的深度学习模型内部工作原理。
- en: 'In short, what I want to share with you is this: the way we normally construct
    deep learning classifiers creates an **inductive bias** in the model. Specifically,
    **using a linear layer for the output** means that the rest of the model must
    find a **linearly separable** transformation of the input. The intuition behind
    this can be really useful, so I’ll share some examples that I hope will clarify
    some of this jargon.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我想和你分享的是：我们通常构建深度学习分类器的方式会在模型中引入 **归纳偏差**。具体来说，**使用线性层作为输出**意味着模型的其余部分必须找到输入的
    **线性可分** 转换。这背后的直觉非常有用，所以我将分享一些例子，希望能澄清这些术语。
- en: The Traditional Explanation
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统解释
- en: 'Let’s revisit the traditional rationale for nonlinear activation functions
    with an example. We’ll look at a simple case: **XOR**.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来重新审视传统的非线性激活函数的理由。我们将看一个简单的案例：**XOR**。
- en: '![](../Images/f0424716ac2c88fc1fc19f5e79acdea2.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0424716ac2c88fc1fc19f5e79acdea2.png)'
- en: A plot of the XOR function with colored ground truth values. Background color
    represents linear regression predictions. Image by author.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个带有彩色真实值的 XOR 函数图。背景颜色代表线性回归的预测值。图片由作者提供。
- en: 'Here I’ve trained a linear regression model on the XOR function with two binary
    inputs (ground truth values are plotted as dots). I’ve plotted the outputs of
    the regression as the background color. The regression didn’t learn anything at
    all: it guessed 0.5 in all cases.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我训练了一个线性回归模型来拟合 XOR 函数，输入为两个二进制值（真实值以点的形式绘制）。我将回归的输出作为背景颜色绘制。回归模型什么也没学到：它在所有情况下都预测为
    0.5。
- en: Now, instead of a linear model, I’m going to train a very basic deep learning
    model with MSE loss. Just **one linear layer with two neurons**, followed by the
    **ReLU** activation function, and then finally the output neuron. To keep things
    simple, I’ll use only weights, no biases.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我将训练一个非常基础的深度学习模型，使用 MSE 损失函数。只有**一个具有两个神经元的线性层**，接着是 **ReLU** 激活函数，最后是输出神经元。为了简化起见，我只使用权重，不使用偏置。
- en: '![](../Images/0bb7b0034adfc776cefb578791227eae.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0bb7b0034adfc776cefb578791227eae.png)'
- en: A diagram of our basic neural network. Made with [draw.io](https://draw.io)
    by author.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基本神经网络的示意图。由作者使用 [draw.io](https://draw.io) 制作。
- en: What happens now?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在会发生什么？
- en: '![](../Images/310f6466f2f98cb2e64bccc17299aaaa.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/310f6466f2f98cb2e64bccc17299aaaa.png)'
- en: Another plot of the XOR function, this time with predictions from a simple deep
    learning model. Image by author.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个 XOR 函数的图，这次是用一个简单的深度学习模型的预测结果绘制的。图片由作者提供。
- en: Wow, now it’s perfect! What do the weights look like?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，现在完美了！权重看起来怎么样？
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'So for two inputs *x* and *y*, our output is:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以对于两个输入 *x* 和 *y*，我们的输出是：
- en: '![](../Images/4cab0448d796f359f93fa820b785f7ec.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4cab0448d796f359f93fa820b785f7ec.png)'
- en: This is really similar to
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的很像
- en: '![](../Images/333873bfa4a427577ae863213d520414.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/333873bfa4a427577ae863213d520414.png)'
- en: which you can verify is exactly the XOR function for inputs *x*, *y* in {0,
    1}.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以验证，这是对于输入 *x* 和 *y* 在 {0, 1} 中的 XOR 函数。
- en: 'If we didn’t have the ReLU in there, we could simplify our model to 0.001*y*
    - 0.13*x*, a linear function that wouldn’t work at all. So there you have it,
    the traditional explanation: since XOR is an inherently nonlinear function, it
    can’t be precisely modeled by any linear function. Even a composition of linear
    functions won’t work, because that’s just another linear function. **Introducing
    the nonlinear ReLU function** allows us to capture nonlinear relationships.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有 ReLU，我们可以将模型简化为 0.001*y* - 0.13*x*，这是一个完全不起作用的线性函数。所以就是这样，传统的解释：由于 XOR
    是一个本质上非线性的函数，它不能被任何线性函数精确建模。即使是线性函数的组合也不行，因为那仍然是另一个线性函数。**引入非线性 ReLU 函数** 让我们能够捕捉到非线性关系。
- en: 'Digging Deeper: Inductive Bias'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入挖掘：归纳偏差
- en: Now we’re going to work on the same XOR model, but we’ll look at it through
    a different lens and get a better sense of the **inductive bias** of this model.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将继续研究相同的 XOR 模型，但我们将通过不同的视角来观察它，以更好地理解该模型的 **归纳偏差**。
- en: What is an inductive bias? Given any problem, there are many ways to solve it.
    Essentially, an inductive bias is something built into the architecture of a model
    that leads it to choose a particular method of solving a problem over any other
    method.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是归纳偏差？面对任何问题，都有许多解决方法。本质上，归纳偏差是模型架构中内建的一种特性，使得模型倾向于选择某种特定的方法来解决问题，而不是其他方法。
- en: In this deep learning model, our final layer is a simple linear layer. This
    means our model can’t work at all unless the model’s output immediately before
    the final layer can be solved by linear regression. In other words, **the final
    hidden state before the output must be linearly separable for the model to work.**
    This inductive bias is a property of our model architecture, not the XOR function.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个深度学习模型中，我们的最终层是一个简单的线性层。这意味着，除非模型在最终层之前的输出能够通过线性回归求解，否则模型完全无法工作。换句话说，**输出前的最后一个隐藏状态必须是线性可分的，模型才能正常工作。**这种归纳偏差是我们模型架构的特性，而不是XOR函数的特性。
- en: Luckily, in this model, our hidden state has only two neurons. Therefore, we
    can visualize it in two dimensions. What does it look like?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，在这个模型中，我们的隐藏状态只有两个神经元。因此，我们可以在二维空间中进行可视化。它看起来是什么样子？
- en: '![](../Images/76f551b445afda3a4c213c30b7058d14.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76f551b445afda3a4c213c30b7058d14.png)'
- en: The input representation for the XOR function transformed into a hidden representation
    with deep learning (after one linear layer and ReLU). Background color represents
    the predictions of a linear regression model. Image by author.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: XOR函数的输入表示通过深度学习转化为隐藏表示（经过一层线性层和ReLU激活）。背景颜色表示线性回归模型的预测。图片来源：作者。
- en: As we saw before, a linear regression model alone is not effective for the XOR
    input. But once we pass the input through the first layer and ReLU of our neural
    network, our output classes can be neatly *separated by a line* (**linearly separable**).
    This means linear regression will now work, and in fact our final layer effectively
    just performs this linear regression.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所见，单独的线性回归模型对XOR输入并不有效。但是，一旦我们将输入通过神经网络的第一层和ReLU激活函数，输出类别就可以被**一条线**整齐地*分开*（**线性可分**）。这意味着线性回归现在可以起作用，实际上我们最终的层只是在执行这种线性回归。
- en: Now, what does this tell us about inductive bias? Since our last layer is a
    linear layer, the representation before this layer **must** be at least approximately
    linearly separable. Otherwise the last layer, which functions as a linear regression,
    will fail.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这告诉我们关于归纳偏差什么信息呢？由于我们最后一层是一个线性层，因此该层之前的表示**必须**至少大致是线性可分的。否则，作为线性回归功能的最后一层将会失败。
- en: Linear Classifier Probes
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性分类器探针
- en: For the XOR model, this might look like a trivial extension of the traditional
    view we saw before. But how does this work for more complex models? As models
    get deeper, we can get more insight by looking at nonlinearity in this way. [This
    paper](https://arxiv.org/pdf/1610.01644) by Guillaume Alain and Yoshua Bengio
    investigates this idea using **linear classifier probes**.[1]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于XOR模型，这看起来可能只是我们之前看到的传统观点的一个微不足道的扩展。但是，如何处理更复杂的模型呢？随着模型的加深，我们可以通过这种方式观察非线性，从而获得更多的洞察。[这篇论文](https://arxiv.org/pdf/1610.01644)由Guillaume
    Alain和Yoshua Bengio撰写，探讨了这个思想，并使用**线性分类器探针**进行研究。[1]
- en: '![](../Images/5d4de7a0a208ab7263c4051305bd8758.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d4de7a0a208ab7263c4051305bd8758.png)'
- en: “The hex dump represented at the left has more information contents than the
    image at the right. Only one of them can be processed by the human brain in time
    to save their lives. Computational convenience matters. Not just entropy.” Figure
    and caption from Alain & Bengio, 2018 ([Link](https://arxiv.org/pdf/1610.01644)).
    [1]
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: “左侧的十六进制转储包含的信息内容比右侧的图像多。只有其中之一可以被人脑处理，以便及时挽救他们的生命。计算的便利性很重要。不仅仅是熵。” 图示和说明来自Alain
    & Bengio, 2018（[链接](https://arxiv.org/pdf/1610.01644)）。[1]
- en: 'For many cases like MNIST handwritten digits, all the information needed to
    make a prediction already exists in the input: it’s just a matter of processing
    it. Alain and Bengio observe that as we get deeper into a model, we actually have
    *less* information at each layer, not more. But the upside is that at each layer,
    the information we do have becomes “easier to use”. What we mean by this is that
    the information becomes increasingly linearly separable after each hidden layer.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像MNIST手写数字这样的许多情况，做出预测所需的所有信息已经存在于输入中：只是需要处理这些信息。Alain和Bengio观察到，随着模型的加深，我们实际上在每一层的可用信息**减少**，而不是增加。但好处是，在每一层，已有的信息变得“更容易使用”。我们所指的是，每一层之后，信息变得越来越**线性可分**。
- en: How do we find out how linearly separable the model’s representation is after
    each layer? Alain and Bengio suggest using what they call **linear classifier
    probes**. The idea is that after each layer, we train a **linear regression to
    predict the final output, using the hidden states at that layer as input.**
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何找出每一层之后模型的表示有多线性可分？Alain 和 Bengio 建议使用他们所称的**线性分类器探针**。其想法是在每一层之后，我们训练一个**线性回归模型，使用该层的隐状态作为输入来预测最终输出**。
- en: 'This is essentially what we did for the last XOR plot: we trained a linear
    regression on the hidden states right before the last layer, and we found that
    this regression successfully predicted the final output (1 or 0). We were unable
    to do this with the raw input, when the data was not linearly separable. Remember
    that the final layer is basically linear regression, so in a sense this method
    is like creating a new final layer that is shifted earlier in the model.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上就是我们在最后的 XOR 图中所做的：我们在倒数第二层的隐状态上训练了一个线性回归模型，发现这个回归成功地预测了最终输出（1 或 0）。在数据不线性可分时，我们无法使用原始输入来完成这一任务。记住，最后一层本质上是线性回归，因此在某种意义上，这种方法就像是在模型中提前创建了一个新的最终层。
- en: 'Alain and Bengio applied this to a convolutional neural network trained on
    MNIST handwritten digits: before and after each convolution, ReLU, and pooling,
    they added a linear probe. What they found is that the test error almost always
    decreased from one probe to the next, indicating an increase in linear separability.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Alain 和 Bengio 将这一方法应用于一个在 MNIST 手写数字数据集上训练的卷积神经网络：在每次卷积、ReLU 激活和池化之后，他们都加入了一个线性探针。他们发现，测试误差几乎总是从一个探针到下一个探针时减少，表明线性可分性在增加。
- en: Why does the data become linearly separable, and not “polynomially separable”
    or something else? Since the last layer is linear, the loss function we use will
    pressure all the other layers in the model to work together and create a linearly
    separable representation for the final layer to predict from.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么数据会变得线性可分，而不是“多项式可分”或其他形式的可分？因为最后一层是线性的，我们使用的损失函数会迫使模型中的其他层一起工作，并为最终层创造一个线性可分的表示，以便进行预测。
- en: 'Does this idea apply to large language models (LLMs) as well? In fact, it does.
    [Jin et al. (2024)](https://arxiv.org/pdf/2404.07066) used linear classifier probes
    to demonstrate how LLMs learn various concepts. They found that **simple concepts**,
    such as whether a given city is the capital of a given country, **become linearly
    separable early in the model**: just a few nonlinear activations are required
    to model these relationships. In contrast, many **reasoning skills do not become
    linearly separable until later in the model**, or not at all for smaller models.[2]'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是否同样适用于大型语言模型（LLM）？事实上，是的。[Jin 等人 (2024)](https://arxiv.org/pdf/2404.07066)使用线性分类器探针展示了
    LLM 如何学习不同的概念。他们发现，**简单的概念**，例如某个城市是否是某个国家的首都，**在模型的早期阶段就变得线性可分**：仅需少数几个非线性激活就能建模这些关系。相比之下，许多**推理技能**直到模型的后期才变得线性可分，或者对于较小的模型来说完全无法线性可分。[2]
- en: Conclusion
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: When we use **activation functions**, we introduce **nonlinearity** into our
    deep learning models. This is certainly good to know, but we can get even more
    value by interpreting the consequences of linearity and nonlinearity in multiple
    ways.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用**激活函数**时，我们将**非线性**引入到深度学习模型中。这当然是很重要的知识，但通过从多种角度解读线性和非线性的后果，我们能获得更多的价值。
- en: While the above interpretation looks at the model as a whole, one useful mental
    model centers on the **final linear layer** of a deep learning model. Since this
    is a linear layer, whatever comes before it has to be linearly separable; otherwise,
    the model won’t work. Therefore, when training, the rest of the layers of the
    model will work together to **find a linear representation that the final layer
    can use** for its prediction.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上述解释是从整体上看待模型，但一个有用的思维模型集中在深度学习模型的**最终线性层**上。由于这是一个线性层，之前的所有内容必须是线性可分的；否则，模型无法正常工作。因此，在训练过程中，模型的其他层会共同协作，**找到一个线性表示，供最终层用于预测**。
- en: 'It’s always good to have more than one intuition for the same thing. This is
    especially true in deep learning where models can be so black-box that any trick
    to gain better interpretability is helpful. Many papers have applied this intuition
    to get fascinating results: Alain and Bengio (2018) used it to develop the concept
    of **linear classifier probing**, while Jin et al. (2024) built on this to watch
    increasingly complicated concepts develop in a language model layer-by-layer.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于同一事物，拥有多种直觉总是有益的。在深度学习中尤为如此，因为模型可能是如此的黑箱化，任何能够提升可解释性的技巧都很有帮助。许多论文都应用了这一直觉，取得了令人着迷的结果：Alain
    和 Bengio（2018）利用这一直觉提出了**线性分类器探测**的概念，而 Jin 等人（2024）在此基础上，逐层观察语言模型中越来越复杂的概念发展。
- en: I hope this new mental model for the purpose of nonlinearities was helpful to
    you, and that you’ll now be able to shed some more light on black-box deep neural
    networks!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这个新的非线性思维模型对你有所帮助，并且你现在能够为黑箱深度神经网络带来更多的启示！
- en: '![](../Images/cfef086479d2ed4ae94c1923d8bc86c2.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfef086479d2ed4ae94c1923d8bc86c2.png)'
- en: Photo by [Nashad Abdu](https://unsplash.com/@nashadabdu?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Nashad Abdu](https://unsplash.com/@nashadabdu?utm_source=medium&utm_medium=referral)
    via [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: References
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] G. Alain and Y. Bengio, [Understanding intermediate layers using linear
    classifier probes](https://arxiv.org/abs/1610.01644) (2018), arXiv'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] G. Alain 和 Y. Bengio，[使用线性分类器探测理解中间层](https://arxiv.org/abs/1610.01644)（2018），arXiv'
- en: '[2] M. Jin et al., [Exploring Concept Depth: How Large Language Models Acquire
    Knowledge at Different Layers?](https://arxiv.org/abs/2404.07066) (2024), arXiv'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] M. Jin 等人，[探索概念深度：大规模语言模型如何在不同层次上获取知识？](https://arxiv.org/abs/2404.07066)（2024），arXiv'
