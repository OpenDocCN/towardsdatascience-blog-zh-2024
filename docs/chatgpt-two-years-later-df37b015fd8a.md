# ChatGPT：两年之后

> 原文：[https://towardsdatascience.com/chatgpt-two-years-later-df37b015fd8a?source=collection_archive---------1-----------------------#2024-11-21](https://towardsdatascience.com/chatgpt-two-years-later-df37b015fd8a?source=collection_archive---------1-----------------------#2024-11-21)

## 追踪生成性人工智能革命的影响

[](https://dataista0.medium.com/?source=post_page---byline--df37b015fd8a--------------------------------)[![Julián Peller](../Images/6b6e6bca0e750ea6493477b87c0d96a6.png)](https://dataista0.medium.com/?source=post_page---byline--df37b015fd8a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--df37b015fd8a--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--df37b015fd8a--------------------------------) [Julián Peller](https://dataista0.medium.com/?source=post_page---byline--df37b015fd8a--------------------------------)

·发布在[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--df37b015fd8a--------------------------------) ·阅读时间19分钟·2024年11月21日

--

![](../Images/81819377dfa895a41d94dad45fd02966.png)

追踪生成性人工智能革命的影响（照片由[vackground.com](https://unsplash.com/@vackground?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)）。

# 生日快乐，聊天机器人先生

今年11月30日标志着ChatGPT发布两周年，这一事件在科技、社会和经济领域引起了震动。这一里程碑所开启的领域，并不总是那么容易——甚至可能不可能——区分现实与期望。例如，今年，Nvidia在一场惊人的牛市中成为全球最具价值的上市公司。该公司生产的硬件被ChatGPT等模型使用，其市值是两年前的七倍。每个人都在问一个明显的问题：它真的值那么多吗，还是我们正处在集体错觉之中？这个问题——而非它最终的答案——定义了当前的时刻。

人工智能不仅在股市掀起波澜。上个月，人工智能领域的知名人物首次获得了诺贝尔物理学奖和化学奖。约翰·J·霍普菲尔德和杰弗里·E·辛顿因其在神经网络发展中的基础性贡献获得了物理学奖。在化学领域，德米斯·哈萨比斯和约翰·跳跃因AlphaFold在使用人工智能进行蛋白质设计方面的进展而获奖。这些奖项一方面让人惊讶，另一方面也让传统科学家产生了可以理解的[失望](https://www.nature.com/articles/d41586-024-03310-8)，因为计算方法占据了主导地位。

![](../Images/fc114d99039baa4edcf67f1f0bb0589d.png)

ChatGPT于2022年11月30日发布（照片由[Rolf van Root](https://unsplash.com/@freshvanroot?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)）。

在这种背景下，我旨在回顾自那年十一月以来发生的事情，反思生成性人工智能迄今为止的实际和潜在影响，考虑哪些承诺已经兑现，哪些仍在进行中，以及哪些似乎被遗弃在了路旁。

# D日

让我们从回忆发布的那一天开始。ChatGPT 3.5是一个远远超越以往任何已知的聊天机器人，在对话和智能能力方面具有显著优势。那时的技术与ChatGPT所能做到的差距引发了巨大的兴趣，该产品迅速走红：它仅用了两个月就达到了1亿用户，远远超过了许多被认为是病毒式传播的应用（如TikTok、Instagram、Pinterest、Spotify等）。它还进入了大众媒体和公共辩论：人工智能进入了主流，突然之间，每个人都在谈论ChatGPT。更令人惊讶的是，仅仅几个月后，OpenAI推出了GPT-4，这一模型在智能方面远超3.5，并且能够理解图像。

这一情况引发了关于这一特定技术所固有的众多可能性和问题的辩论，包括版权、虚假信息、生产力和劳动力市场问题。它还引发了关于推动人工智能研究的中长期风险的担忧，比如生存风险（“终结者”情景）、工作的终结以及人工意识的潜力。在这一广泛且充满激情的讨论中，我们听到了各种各样的意见。随着时间的推移，我相信辩论开始逐渐成熟和理性。由于ChatGPT的进展使我们所有人都有些措手不及，适应这个产品花了一些时间。从那时起发生了什么呢？

# 巨人戈利亚的失足

就科技公司而言，过去两年堪称过山车。OpenAI的出现，凭借其未来感的进展以及其CEO拥有“创业”精神与形象，开始对Google在技术上的领导地位提出质疑，而这一地位直到那时一直无人撼动。作为回应，Google竭尽所能确认了这些质疑，屡次在公众面前自我羞辱。首先是[Bard发布的尴尬](https://theweek.com/google/959623/googles-bard-ai-chatbot-makes-100bn-mistake)——一个旨在与ChatGPT竞争的聊天机器人。在演示视频中，模型犯了一个事实错误：当被问及詹姆斯·韦布太空望远镜时，它声称该望远镜是第一个拍摄到太阳系外行星的望远镜，然而这一说法是错误的。这个失误导致Google的股价在接下来的一周内下跌了9%。后来，在[新Gemini模型的展示](https://techcrunch.com/2023/12/07/googles-best-gemini-demo-was-faked/)中——这是另一个与GPT-4竞争的模型——Google再次失去了信誉，因为揭示出演示中展示的惊人能力（本应将其置于研究的前沿）实际上是捏造的，基于的是远远更有限的能力。

![](../Images/5302dd7e220e01cbaa4b23919cddf4f1.png)

巨人跌倒的一天（照片由[Shutter Speed](https://unsplash.com/@shutter_speed_?utm_source=medium&utm_medium=referral)提供，来源：[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)）。

与此同时，微软——比尔·盖茨创办的古老公司，曾推出过老版的Windows 95，并且像Google被年轻人喜爱一样，也曾被年轻人深恶痛绝——重新出现在舞台上，并与小公司大卫联手，将ChatGPT整合进Bing，呈现出一种灵活而不羁的形象。“我希望人们知道我们让他们跳舞了，”[微软CEO萨蒂亚·纳德拉](https://www.youtube.com/watch?v=KSixVG8Z5rQ)说道，指的是Google。2023年，微软焕发新生，而Google却在老去。

这种局面持续了一段时间，OpenAI依然在技术评估和主观用户反馈（即“氛围检查”）中稳居不败之地，GPT-4位居前沿。但随着时间的推移，情况发生了变化，正如GPT-4在2022年底达成独特领导地位一样，到2024年中期，它的近亲后继版本（GPT-4o）已经与其他同类竞相竞争：Google的Gemini 1.5 Pro、Anthropic的Claude Sonnet 3.5以及xAI的Grok 2。创新所带来的，创新也会带走。

这种情况可能再次发生变化，随着OpenAI在2024年9月宣布的[o1](https://openai.com/o1/)以及2024年10月25日[关于新发布的传闻](https://www.forbes.com/sites/torconstantino/2024/10/25/openai-reported-to-launch-its-orion-model-in-december---or-maybe-not/)的流言。尽管如此，目前无论o1有多优秀（我们很快会谈到），它似乎并没有像ChatGPT那样产生巨大的影响，也没有给竞争格局带来不可逾越的鸿沟感。

为了完整呈现这一系列的起伏、失败与史诗般的复出，我们必须谈论开源世界。这个新的AI时代开始时，开源社区遭遇了两次重击。首先，尽管OpenAI的名字暗示它是一个倡导公开的机构，它却是首个阻止公开披露基础技术进展的先驱。在OpenAI之前，人工智能研究的规范——至少在2022年前的黄金时代——是对研究成果进行详细公开。在那个时期，主要企业与学术界建立了积极的反馈循环，发表论文，这在之前是相当罕见的。事实上，ChatGPT和生成式AI革命整体上都基于谷歌2017年的一篇论文——著名的[*Attention Is All You Need*](https://arxiv.org/pdf/1706.03762)*，*该文介绍了Transformer神经网络架构。这个架构支撑着目前所有的语言模型，也是GPT中的“T”。在一个戏剧性的情节反转中，OpenAI利用谷歌的这一公开发现获得了优势，并开始追求闭门研究，GPT-4的发布标志着这两个时代之间的转折点：OpenAI对这一先进模型的内部工作完全没有披露。从那时起，许多闭源模型，如Gemini 1.5 Pro和Claude Sonnet，开始涌现，根本上恶化了研究生态系统。

对开源社区的第二次打击是新模型的规模之大。直到GPT-2，一台普通的GPU就足以训练深度学习模型。从GPT-3开始，基础设施成本飞涨，训练模型变得几乎无法被个人或大多数机构所接触。基础性进展落入了少数几家大公司的手中。

但是，在经历了这些打击后，随着每个人都期待一场决定性的打击，开源界进行了反击，并证明了自己能够迎接挑战。出乎意料的是，它有了一个意外的冠军。马克·扎克伯格，地球上最令人讨厌的爬行动物般的安卓人，彻底改变了形象，将自己定位为开源与自由在生成性AI领域的旗手。Meta，这个控制着西方大部分数字通信网络并按照自己设计和意志行事的巨头，承担起了将开源引入LLM时代的任务，推出了LLaMa模型系列。在这个时代，成为道德绝对主义者无疑是个糟糕的时机。LLaMa系列从最初的谨慎开放许可和有限功能开始（尽管社区作出了重大努力来认为并非如此）。然而，随着LLaMa 3.1和3.2的最新发布，它与私有模型之间的差距开始显著缩小。这使得开源界和公共研究能够继续处于技术创新的前沿。

![](../Images/f266f8ddb3355a39b835ce604d4b7c23.png)

LLaMa模型是开源的替代品，用于替代封闭源的企业LLM（照片来源：[Paul Lequay](https://unsplash.com/@paulequay?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)）。

# 技术进步

在过去两年中，关于类似ChatGPT的模型（被称为大语言模型，LLMs）的研究取得了丰硕成果。第一个现在被视为理所当然的基础性进展是，企业成功地增加了模型的**上下文窗口**（即模型能够读取并生成多少单词），同时大幅度**降低了每个单词的成本**。我们还看到了模型变得多模态，不仅接受文本输入，还能处理图像、音频和视频输入。此外，这些模型还被**赋能使用工具——最显著的是互联网搜索——**并在整体能力上持续改进。

在另一个方面，各种**量化与蒸馏**技术应运而生，使得巨大的模型能够压缩成更小的版本，甚至能够在桌面电脑上运行语言模型（尽管有时这会以不可接受的性能下降为代价）。这一优化趋势似乎走在正轨上，正在将我们带向**小型语言模型（SLMs），这些模型最终可以在智能手机上运行。**

另一方面，**在控制臭名昭著的幻觉问题**——由模型生成的看似合理的错误输出——方面没有取得重大进展。曾经作为一个新奇的现象，这个问题现在似乎已被确认是技术的一个结构性特征。对于我们这些在日常工作中使用这项技术的人来说，依赖一个大多数时候表现得像专家，但每十次中就有一次犯下严重错误或直接编造信息的工具，实在让人感到沮丧。从这个角度来看，Meta AI的负责人、AI领域的主要人物Yann LeCun似乎得到了证明，因为在2023年的炒作高峰期，他对LLM持有更加审慎的立场。

然而，指出LLM的局限性并不意味着关于它们的能力或它们可能带我们走向何方的争论已经结束。例如，Sam Altman [相信](https://www.youtube.com/watch?v=xXCBz_8hM9w)当前的研究计划在突破瓶颈之前仍有很多可供探索的空间，而且正如我们稍后看到的，市场似乎也同意这一观点。过去两年中我们看到的许多进展支持了这一乐观态度。OpenAI推出了其**语音助手**以及一个改进版，能够在近实时互动中处理中断——更像是人类对话，而不是轮流发言。最近，我们还看到**LLM获得访问和控制用户计算机**的首次先进尝试，如在GPT-4o演示中所示（尚未发布）以及在[Claude 3.5](https://www.anthropic.com/news/3-5-models-and-computer-use)中展示的功能，该版本已面向最终用户提供。尽管这些工具仍处于起步阶段，但它们提供了近未来可能呈现的一个面貌，其中**LLM拥有更大的自主性**。类似地，在**自动化软件工程**方面也有许多突破，突出表现为一些有争议的里程碑，例如[Devin](https://www.cognition.ai/blog/introducing-devin)，首个“人工软件工程师”。尽管其演示遭到[严重批评](https://www.youtube.com/watch?v=tNmgmwEtoWE)，但这一领域——尽管存在炒作——已经取得了不可否认、具有影响力的进展。例如，在SWE-bench基准测试中，评估AI模型解决软件工程问题的能力，年初时，最佳模型只能解决不到13%的练习。目前，这一数字已超过49%，这为当前研究计划提供了信心，认为其能够提升LLM在规划和复杂任务解决方面的能力。

同样，OpenAI最近宣布的**o1模型**标志着一条具有巨大潜力的新研究方向，尽管目前发布的版本（o1-preview）与已经知道的内容相差不远。事实上，o1基于一个新颖的理念：利用推理时间——而非训练时间——来提高生成响应的质量。通过这种方法，模型并不会立即生成最可能的下一个词，而是能够“暂停思考”再作回应。公司的一位研究人员表示，最终这些模型可能在生成响应之前使用数小时甚至数天的计算时间。初步结果激起了高度期望，因为利用推理时间来优化质量以前被认为是不可行的。我们现在等待该系列后续模型（o2、o3、o4）来确认它是否如目前所见般有前景。

除了语言模型，这两年还见证了其他领域的巨大进展。首先，我们必须提到**图像生成**。文本到图像模型在聊天机器人之前就开始获得关注，并且一直在加速发展，扩展到**视频生成**。这个领域在OpenAI推出Sora模型时达到了一个高峰，这个模型能够生成极高质量的视频，尽管它没有公开发布。稍微不那么为人所知，但同样令人印象深刻的是**音乐生成**的进展，像Suno和Udio这样的平台，以及**语音生成**，这个领域经历了革命，达到了极高的质量标准，领军者是Eleven Labs。

对于我们这些从事这一领域的人来说，过去两年无疑是充满强烈技术进步和几乎每天都有创新的两年。

# 市场繁荣

如果我们将目光转向这一现象的金融层面，我们会看到大量资本以持续增长的方式注入人工智能领域。我们目前正处于一场人工智能的淘金热中，没有人愿意错过这一技术，其发明者谦虚地将其[呈现](https://openai.com/index/gpts-are-gpts/)为等同于蒸汽机、印刷机或互联网的技术。

这可能是一个暗示，表明在这场热潮中获利最多的公司并不销售人工智能，而是销售作为其基础设施的硬件，这与古老的格言相吻合：在淘金热时期，一个致富的好方法是卖铁锹和镐。如前所述，**英伟达已经将自己定位为全球最有价值的公司**，市值达到3.5万亿美元。为提供背景，$3,500,000,000,000是一个[远远超出](https://x.com/MorningBrew/status/1803814254044139836)法国GDP的数字。

![](../Images/cd06af02f5e7080d8375fb8a1a68ed10.png)

我们目前正处在一场人工智能淘金热的中期，没有人愿意被落下（照片由[Dimitri Karastelev](https://unsplash.com/@dkfra19?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)）。

另一方面，如果我们查看市值[最高的上市公司](https://companiesmarketcap.com/)列表，我们会发现，与人工智能相关的科技巨头部分或完全主导了这一榜单。苹果、英伟达、微软和谷歌是目前排名前四的公司，截至本文撰写时，它们的**市值总和超过了**[**12万亿美元**](https://www.investors.com/news/sp500-stocks-12-trillion-market-cap-earnings-amazon-apple-google-meta-microsoft/)。作为参考，在2022年11月，这四家公司的市值总和还不到这个值的一半。与此同时，硅谷的生成性人工智能初创公司正在吸引创纪录的投资。人工智能市场呈现出强劲的上涨势头。

尽管技术发展迅速，但生成性人工智能的商业模式——除了主要的LLM提供商和少数特定案例——仍然不明确。随着这一热潮的持续，一些声音，包括最近的经济学诺贝尔奖得主达龙·阿西莫格鲁，表达了对人工智能是否能证明其所吸引的大量资金价值的怀疑。例如，在[这篇](https://www.bloomberg.com/news/articles/2024-10-02/ai-can-only-do-5-of-jobs-says-mit-economist-who-fears-crash)彭博采访中，阿西莫格鲁认为，目前的生成性人工智能在未来十年内仅能自动化不到5%的现有工作任务，这使得它不太可能引发投资者所期待的生产力革命。

**这是人工智能热潮，还是更像是人工智能的狂热幻觉？** 目前，牛市的上涨没有停歇的迹象，像任何泡沫一样，回过头来看它将容易被识别。但在这一过程中，我们无法确定是否会有修正，若有的话，又会发生何时。我们是否正处于一个即将破裂的泡沫中，正如阿西莫格鲁所认为的，还是，正如[一位投资者所建议](https://www.ft.com/content/4c9b009f-7d33-4975-b4be-a36c714bf1a8)，英伟达正朝着在十年内成为一个50万亿美元市值的公司迈进？这是百万美元的问题，遗憾的是，亲爱的读者，我无法给出答案。一切迹象表明，就像在互联网泡沫中一样，我们将从这场局势中走出，一些公司会借势而起，而许多公司则会陷入困境。

# 社会影响

现在让我们讨论生成性人工智能到来带来的更广泛的社会影响。与其发布前社会普遍认知的技术前景相比，ChatGPT所代表的质量飞跃引起了显著的骚动，开启了关于这项特定技术的机遇与风险，以及更先进技术发展潜在机遇与风险的辩论。

***未来的问题*** 有关**人工通用智能（AGI）**——即人工智能达到人类或超人类能力——的辩论在Geoffrey Hinton（现为诺贝尔物理学奖得主）辞去谷歌职务，警告这一发展可能带来的风险时，获得了公众关注。存在性风险——即超能力的人工智能可能失控，进而摧毁或奴役人类——不再仅仅是小说中的情节，而成为了一个具体的政治问题。我们看到一些具有中立、不煽动性立场的知名人物在公共辩论中表达了关切，甚至在美国参议院的[听证会](https://www.brennancenter.org/our-work/analysis-opinion/senate-ai-hearings-highlight-increased-need-regulation)上提出警告。他们警告说，AGI可能在未来十年内到来，并且这一进展将带来巨大的问题。

![](../Images/169824b34b34e2be997d532d7ddd53d8.png)

围绕这一辩论的紧迫性现在似乎已经消退，回顾过去，AGI看起来比2023年时更远了（照片由[Axel Richter](https://unsplash.com/@trisolarian?utm_source=medium&utm_medium=referral)拍摄，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)）。

围绕这一辩论的紧迫性现在似乎已经消退，回顾过去，AGI看起来比2023年时更远了。人们常常在事后高估成就，就像随着时间的推移低估成就也是常见的现象。这后一种现象甚至有一个名字：AI效应，指的是该领域的重大进展随着时间推移逐渐失去最初的光辉，不再被认为是“真正的智能”。如果今天能够生成连贯的论述——就像下棋的能力——不再令人惊讶，这不应让我们忽视该技术进步的时间表。1997年，[深蓝](https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov)模型击败了国际象棋冠军加里·卡斯帕罗夫。2016年，AlphaGo[击败](https://www.youtube.com/watch?v=WXuK6gekU1Y)了围棋大师李世石。2022年，ChatGPT生成了高质量的、有条理的语言，甚至挑战了著名的[图灵测试](https://en.wikipedia.org/wiki/Turing_test)，作为衡量机器智能的标准。我认为，尽管这些风险似乎不再迫在眉睫或紧急，但仍然有必要持续进行有关未来风险的讨论。否则，恐惧与平静的周期会阻碍成熟的辩论。无论是通过o1所开启的研究方向，还是其他新途径，几年的时间内我们可能会看到类似于2022年ChatGPT的突破，届时提前进行相关讨论将是明智之举。

关于人工通用智能（AGI）和人工智能安全的单独章节涉及了**OpenAI的企业戏剧**，堪比黄金时段的电视节目。2023年底，Sam Altman被董事会突然解除职务。尽管具体细节从未澄清，但Altman的反对者指出，OpenAI存在一个涉嫌秘密文化，并且在AI开发中的安全问题上存在分歧。这一决定立即引发了OpenAI员工的反抗，并引起了该公司最大投资者微软的关注。在一场戏剧性的反转中，Altman被恢复职务，而解除他职务的董事会成员则被解雇。这一冲突在OpenAI内部留下了裂痕：AI安全研究负责人Jan Leike加入了Anthropic，而OpenAI的联合创始人、AI开发核心人物Ilya Sutskever则离开创办了Safe Superintelligence Inc.。这似乎证实了最初的争议围绕着对安全的重视问题。最后，最近的传闻表明OpenAI可能会失去其非盈利身份，并向Altman授予股份，触发了公司领导层的又一波辞职潮，进一步加剧了不稳定感。

从技术角度来看，我们看到了Anthropic在AI安全方面的重大突破。该公司在**大语言模型可解释性方面取得了一个基础性里程碑**，帮助更好地理解这些模型的“黑箱”特性。通过他们的[发现](https://www.anthropic.com/news/mapping-mind-language-model)，揭示了神经元的多义性特征以及提取代表概念的神经激活模式的方法，似乎突破了控制Transformer模型的主要障碍——至少在它们可能误导我们的能力方面是如此。通过[故意改变电路](https://www.anthropic.com/news/golden-gate-claude)，积极修改这些模型的可观察行为，这一进展也令人鼓舞，并带来了一些安心，缓解了模型能力与我们对它们理解之间的差距。

***当前的问题*** 暂且不谈人工智能的未来及其潜在影响，我们来关注生成型人工智能的实际影响。与互联网或社交媒体的到来不同，这次社会似乎反应迅速，表现出对这项新技术带来的影响和挑战的担忧。除了前面提到的关于存在风险的深入讨论——聚焦于未来技术的发展和进步速度——现有语言模型的影响也引起了广泛讨论。**生成型人工智能的主要问题包括对虚假信息和数字污染的放大担忧、版权和私人数据使用的重大问题，以及对生产力和劳动力市场的影响。**

关于**虚假信息**，这项[研究](https://misinforeview.hks.harvard.edu/article/misinformation-reloaded-fears-about-the-impact-of-generative-ai-on-misinformation-are-overblown/)表明，至少目前为止，生成式人工智能并没有显著增加人们接触虚假信息的程度。尽管这一点很难明确证实，但我的个人印象与此一致：尽管虚假信息仍然盛行——并且近年来可能有所增加——但它并没有因为生成式人工智能的出现而发生显著的相变。这并不意味着虚假信息今天不是一个关键问题。这里较弱的论点是，生成式人工智能似乎并没有显著加剧这一问题——至少目前没有。

然而，我们已经看到了**深度伪造**的实例，例如近期涉及使用[真实人物面孔](https://www.bbc.com/news/articles/cg4yerrg451o)制作的AI生成色情内容的案件，以及更为严重的案件，在[学校中](https://www.bbc.com/news/articles/cpdlpj9zn9go)——尤其是年轻女孩——受到影响。这些案件极其严重，必须加强司法和执法系统来应对。然而，至少初步看来，这些案件是可以管理的，并且从宏观角度来看，与生成式人工智能引发的虚假信息的假想噩梦相比，它们的影响相对较小。或许法律系统的反应时间比我们希望的要长，但也有迹象表明，至少在处理未成年色情内容的深度伪造方面，相关机构有可能应对得当，正如英国一名因制作和传播此类材料而被判刑18年的[示范性案例](https://www.bbc.com/news/articles/cq6l241z5mjo)所示。

其次，关于**劳动力市场和生产力**的影响——即市场繁荣的反面——这一辩论仍然没有定论。目前尚不清楚这项技术在提高工人生产力、减少或增加就业方面能够走多远。在网络上，关于这项技术影响的观点层出不穷。诸如“AI替代任务，而非人类”或“AI不会取代你，但使用AI的人会取代你”这样的说法被信心满满地提出，但却没有任何支持证据——这一点讽刺地让人想起语言模型的幻觉现象。确实，ChatGPT无法完成复杂的任务，而我们这些每天使用它的人也深知它的显著且令人沮丧的局限性。但同样也有一个事实，那就是像起草专业邮件或审核大量文本以提取特定信息这样的任务变得更为高效。根据我的经验，借助像Copilot或Cursor这样的AI辅助编程环境，编程和数据科学的生产力有了显著提高。在我的团队中，初级成员获得了更大的自主性，每个人的编码速度也比以前更快。尽管如此，编码速度的提升也可能是一把双刃剑，因为[一些研究](https://gitclear-public.s3.us-west-2.amazonaws.com/Coding-on-Copilot-2024-Developer-Research.pdf)表明，使用生成性AI助手生成的代码可能比没有此类助手帮助下人工编写的代码质量更低。

如果当前大语言模型（LLMs）的影响尚不完全明确，那么这种不确定性又被与之相关的技术进展所加剧，例如o1所开启的研究方向或Claude 3.5所预示的桌面控制。这些发展增加了对这些技术在短期内可能实现的能力的猜测和不确定性。尽管市场对由生成性人工智能驱动的生产力激增寄予厚望，但正如前文在讨论这一现象的金融方面时提到的，许多严肃的声音却在淡化这项技术对劳动力市场的潜在影响。从原则上讲，这项技术最显著的局限性（例如幻觉问题）不仅没有得到解决，而且现在似乎越来越不可能得到解决。与此同时，人类机构的反应不如技术本身灵活和革命性，这也使得相关讨论降温，冷却了那些期望该技术带来巨大且立竿见影影响的热情。

无论如何，如果这种对职场的巨大革命能够实现，它至少在过去两年内并未真正显现。考虑到这项技术的加速应用（根据[这项研究](https://www.nber.org/papers/w32966)，目前超过24%的美国工人每周至少使用一次生成式 AI），并假设最先采用这项技术的可能是那些能获得最大利益的人，我们可以认为我们已经看到了这项技术在生产力方面的影响。就我个人的日常工作和我的团队来说，到目前为止，虽然生产力的影响是显著、明显且可见的，但也相对有限。

生成式 AI 崛起所伴随的另一个主要挑战是**版权问题**。内容创作者——包括艺术家、作家和媒体公司——对他们的作品未经授权被用于训练 AI 模型表示不满，认为这侵犯了他们的知识产权。另一方面，AI 公司通常辩称，使用受保护的材料来训练模型属于“合理使用”，而且这些模型的制作构成了合法且富有创意的转化，而非复制。

这种冲突导致了许多诉讼案件，例如 Getty Images 起诉 Stability AI 未经授权使用图片来训练模型，或者像 Sarah Silverman 这样的艺术家和作家对 OpenAI、Meta 和其他 AI 公司提起诉讼。另一个著名的案件涉及唱片公司起诉 Suno 和 Udio，指控它们未经授权使用受保护的歌曲来训练生成音乐模型，侵犯了版权。

在这种对“灵感与抄袭”之间长期分歧的未来重解中，法院尚未明确判定哪一方胜出。尽管这些诉讼的某些方面已经允许继续进行，但另一些则被驳回，维持了一种不确定的氛围。近期的法律文件和公司策略——例如 Adobe、Google 和 OpenAI 为客户提供赔偿——表明这个问题仍未得到解决，目前法律争端仍在继续，没有明确的结论。

![](../Images/ff648c0a7f801e25f931351272e3f6d9.png)

欧盟将通过《人工智能法案》来监管人工智能，这是全球首部全面的人工智能法律（照片由[Guillaume Périgois](https://unsplash.com/@guillaumeperigois?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)）。

人工智能的监管框架也取得了显著进展，全球范围内最值得注意的进展是**欧洲联盟于2024年3月批准的**[**《人工智能法案》](https://en.wikipedia.org/wiki/Artificial_Intelligence_Act)。这项立法使欧洲成为全球首个采用全面人工智能监管框架的地区，并建立了一个分阶段实施的系统，确保合规，计划从2025年2月开始并逐步推进。

《人工智能法案》对人工智能风险进行了分类，禁止“不可接受风险”的情况，如利用技术进行欺诈或社会评分。尽管在讨论过程中一些条款有所软化，以确保所有模型都能适用基本规则，并对敏感领域的应用实施更严格的监管，但业内人士对这一框架所带来的负担表示担忧。尽管《人工智能法案》并非因ChatGPT而直接产生，且早在此之前就已在讨论，但其批准进程因生成性人工智能模型的突然兴起和影响而加速。

在这些紧张、机遇和挑战的背景下，显而易见的是，生成性人工智能的影响标志着社会、经济和法律领域深刻变革的新阶段的开始，而我们对这一变革的全面理解才刚刚起步。

# 即将到来

我在写这篇文章时以为ChatGPT的热潮已经过去，它的涟漪效应也在平息。然而回顾过去两年的事件让我改变了看法：这两年是伟大的进步和飞速发展的两年。

这是一个充满激动与期待的时代——人工智能的真正春天——令人印象深刻的突破不断涌现，充满前景的研究领域等待着被探索。另一方面，这也是一个充满不确定性的时期。怀疑自己身处泡沫之中的情绪，以及对重大情绪和市场调整的预期，都是完全合理的。但和任何市场调整一样，关键不在于预测*它是否会发生*，而是准确知道*何时*发生。

2025年会发生什么？Nvidia的股票会崩盘吗，还是该公司会继续其看涨行情，兑现成为[5万亿美元](https://www.ft.com/content/4c9b009f-7d33-4975-b4be-a36c714bf1a8?utm_source=chatgpt.com)公司十年的承诺？人工智能股市总体会如何发展？由o1发起的推理模型研究线会怎样？它会碰到瓶颈，还是像GPT系列从1、2、3、4版本逐步推进那样，开始展现进展？今天那些控制桌面和数字环境的初级基于LLM的代理将会有多大的改善？

我们很快就会知道答案，因为我们正朝着那个方向前进。

![](../Images/56b912fdd854c899d2e7d9eceb28c89c.png)

生日快乐，ChatGPT！(图片来源：[Nick Stephenson](https://unsplash.com/@therealnick?utm_source=medium&utm_medium=referral) 通过 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral))
