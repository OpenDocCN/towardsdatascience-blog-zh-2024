- en: 9.11 or 9.9 ‚Äî which one is higher?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/9-11-or-9-9-which-one-is-higher-6efbdbd6a025?source=collection_archive---------7-----------------------#2024-07-25](https://towardsdatascience.com/9-11-or-9-9-which-one-is-higher-6efbdbd6a025?source=collection_archive---------7-----------------------#2024-07-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Evaluating the uncertainty and brittleness in LLM prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)[![Armin
    Catovic](../Images/046042098f3fec885e756f7f8ee94e6a.png)](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)
    [Armin Catovic](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)
    ¬∑5 min read¬∑Jul 25, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: 'This ChatGPT prompt and its corresponding (incorrect) response were recently
    shared and re-posted on LinkedIn countless times. They were given as a solid proof
    that the AGI is just not there yet. Further re-posts also pointed out that re-arranging
    the prompt to: *‚ÄúWhich one is higher: 9.11 or 9.9?‚Äù,* guarantees a correct answer,
    and further emphasizes the brittleness of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: After evaluating both prompts against a random group of ChatGPT users, we found
    that in both cases the answer is **incorrect about 50%** of the time. As some
    users have correctly pointed out, there is a subtle ambiguity with the question,
    i.e. are we referring to mathematical inequality of two real numbers, or are we
    referring to two dates (e.g. September 11 vs September 9), or two sub-sections
    in a document (e.g. chapter 9.11 or 9.9)?
  prefs: []
  type: TYPE_NORMAL
- en: We decided to perform a more controlled experiment by using OpenAI APIs. This
    way we have full control over both the system prompt and the user prompt; we can
    also take out the sampling uncertainty out of the equation as far as possible
    by e.g. setting the temperature low.
  prefs: []
  type: TYPE_NORMAL
- en: '**The final results are very interesting!**'
  prefs: []
  type: TYPE_NORMAL
- en: Hypotheses and Experimental Design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our hypotheses can be stated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Given the same prompt, without any additional context, and with temperature
    kept close to zero, we should nearly always obtain the same output, with stable
    log probabilities. While people refer to LLMs as ‚Äústochastic‚Äù, for a given input,
    LLM should always generate the same output; the ‚Äúhallucinations‚Äù or variance comes
    from the sampling mechanism outside of the LLM, and this we can dampen significantly
    by setting a very low temperature value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on our random user tests with ChatGPT, we would expect both the original
    prompt, and the re-worded version to give incorrect answer 50% of the time ‚Äî in
    other words, without further disambiguation or context, we wouldn‚Äôt expect one
    prompt to perform better than the other.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our experiment design, we perform the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We conduct a number of experiments, starting with the original prompt, followed
    by a series of ‚Äúinterventions‚Äù
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each experiment/intervention, we execute 1 000 trials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use OpenAI‚Äôs most advanced GPT-4o model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We set the temperature to 0.1 to essentially eliminate the randomness due to
    sampling; we experiment with both random seed as well as fixed seed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To gauge the ‚Äúconfidence‚Äù of the answer, we collect the log probability and
    calculate the linear probability of the answer in each trial; we plot the Kernel
    Density Estimate (KDE) of the linear probabilities across the 1 000 trials for
    each of the experiments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The full code for our experimental design is available [here](https://github.com/acatovic/llm-prompt-uncertainty-test).
  prefs: []
  type: TYPE_NORMAL
- en: Experiment (A) ‚Äî Original Prompt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The user prompt is set to *‚Äú9.11 or 9.9 ‚Äî which one is higher?‚Äù*.
  prefs: []
  type: TYPE_NORMAL
- en: In line with what social media users have reported, **GPT-4o gives the correct
    answer 55% of the time** ‚òπÔ∏è. The model is also not very certain ‚Äî on large number
    of trials, **its ‚Äúconfidence‚Äù in the answer is ~80%**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/303e02b6da3e317bb99c38ca028ad4fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1 ‚Äî Smoothed histogram (KDE) of confidence values (0‚Äì100%) across 1000
    trials, when the original user prompt is used; image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Experiment (B) ‚Äî Re-worded User Prompt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the re-worded user prompt, no additional context/disambiguation is provided,
    but the wording is slightly changed to: *‚ÄúWhich one is higher, 9.11 or 9.9?‚Äù*'
  prefs: []
  type: TYPE_NORMAL
- en: Amazingly, and contrary to our ChatGPT user tests, the **correct answer is reached
    100% of the time** across 1 000 trials. Furthermore, the model exhibits **very
    high confidenc**e in its answer ü§î.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd2ac34fa08ee808f5ab358f41a3e665.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2 ‚Äî Smoothed histogram (KDE) of confidence values (0‚Äì100%) across 1000
    trials, when the original user prompt is slightly re-worded; image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Experiment (C) ‚Äî Original User Prompt with Reasoning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There has been significant work recently in trying to induce improved ‚Äúreasoning‚Äù
    capabilities in LLMs with chain-of-thought (CoT) prompting being the most popular.
    [Huang et al](https://arxiv.org/pdf/2212.10403) have published a very comprehensive
    survey on LLM reasoning capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: As such, we modify the original user prompt by also telling the LLM to explain
    its reasoning. Interestingly enough, the **probability of correct answer improves
    to 62%**, however the answers come with **even greater uncertainty**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c8d22876d032feec673a6dce588b7c6d.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3 ‚Äî Smoothed histogram (KDE) of confidence values (0‚Äì100%) across 1000
    trials, when the original user prompt is modified to also ‚Äúexplain its reasoning‚Äù;
    image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Experiment (D) ‚Äî Original User Prompt with Reasoning in the System Prompt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final experiment is the same as experiment ‚ÄúC‚Äù, however we instead bootstrap
    the **system prompt** by telling the LLM to ‚Äúexplain its reasoning‚Äù. Incredibly,
    we now see the **correct answer 100% of the time**, with **very high confidence**.
    We see identical results if we use the re-worded user prompt as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c7fbb5db47568c2f787a98e7d755c7dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4 ‚Äî Smoothed histogram (KDE) of confidence values (0‚Äì100%) across 1000
    trials, with the original user prompt, and system prompt amended with instructions
    to ‚Äúexplain its reasoning‚Äù; image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion and Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What started off as a simple experiment to validate some of the statements
    seen on social media, ended up with some very interesting findings. Let‚Äôs summarize
    the key takeaways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**For an identical prompt, with both temperature set very low (essentially
    eliminating sampling uncertainty), and a fixed seed value, we see very large variance
    in log probabilities**. Slight variance can be explained by hardware precision,
    but variance this large is very difficult to explain. It indicates that either
    (1) sampling mechanism is a LOT more complicated, or (2) there are more layers/models
    upstream beyond our control.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In line with previous literature, **simply instructing the LLM to ‚Äúexplain its
    reasoning‚Äù improves its performance**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**There is clearly a distinct handling between the system prompt and the user
    prompt**. Bootstrapping a role in the system prompt as opposed to the user prompt,
    seems to result in significantly better performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can clearly see how brittle the prompts can be. The key takeaway here is
    that we should always aim to provide disambiguation and clear context in our prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Disclaimer:*** *due to heavy coverage on social media, it is likely that
    the lovely people at OpenAI have in fact improved the above behaviour, so the
    results may not be directly reproducible. However the key takeaways are still
    very valid!*'
  prefs: []
  type: TYPE_NORMAL
