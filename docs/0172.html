<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Temporal Graph Learning in 2024</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Temporal Graph Learning in 2024</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/temporal-graph-learning-in-2024-feaa9371b8e2?source=collection_archive---------1-----------------------#2024-01-18">https://towardsdatascience.com/temporal-graph-learning-in-2024-feaa9371b8e2?source=collection_archive---------1-----------------------#2024-01-18</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="df51" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Continue the journey for evolving networks</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@shenyanghuang1996?source=post_page---byline--feaa9371b8e2--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Shenyang(Andy) Huang" class="l ep by dd de cx" src="../Images/ab63c37868db97b19480d536388930c5.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*x8WcQqAPZ0Ww7PkRKOn8VA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--feaa9371b8e2--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@shenyanghuang1996?source=post_page---byline--feaa9371b8e2--------------------------------" rel="noopener follow">Shenyang(Andy) Huang</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--feaa9371b8e2--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">20 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 18, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="b873" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Many complex networks evolve over time including transaction networks, traffic networks, social networks and more. Temporal Graph Learning (TGL) is a fast growing field which aims to learn, predict and understand evolving networks. See our <a class="af nf" rel="noopener" target="_blank" href="/temporal-graph-learning-in-2023-d28d1640dbf2">previous blog post</a> for an introduction to temporal graph learning and a summary of advancements last year.</p><p id="84d3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In 2023, we saw significantly increased interest from both academia and the industry in the development of TGL. Compared to last year, the number of submissions at the <a class="af nf" href="https://sites.google.com/view/tglworkshop-2023/home" rel="noopener ugc nofollow" target="_blank">temporal graph learning workshop @ NeurIPS 2023</a> tripled, resulting in 35 accepted papers. In addition, the <a class="af nf" href="https://www.cs.mcgill.ca/~shuang43/rg.html" rel="noopener ugc nofollow" target="_blank">temporal graph learning reading group</a>, started in February 2023, has now hosted 28 research talks (find the recordings on <a class="af nf" href="https://www.youtube.com/@TGL_RG" rel="noopener ugc nofollow" target="_blank">YouTube</a>). With nearly 200 researchers signed up for the reading group, we are glad to witness interest in the topic and an extremely active community.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh ni"><img src="../Images/dea62afaf0827b1d3fd11fc1ef12e1ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T75nt3vNPYCedINJ"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Image by authors, generated via <a class="af nf" href="https://openai.com/dall-e-3" rel="noopener ugc nofollow" target="_blank">DALL.E 3</a></figcaption></figure></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="7db3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><em class="oh">This post was co-authored with </em><a class="af nf" href="https://www.emanuelerossi.co.uk/" rel="noopener ugc nofollow" target="_blank"><em class="oh">Emanuele Rossi</em></a>, <a class="af nf" href="https://migalkin.github.io/" rel="noopener ugc nofollow" target="_blank"><em class="oh">Michael Galkin</em></a> ,<a class="af nf" href="https://andreacini.github.io/" rel="noopener ugc nofollow" target="_blank"><em class="oh">Andrea Cini</em></a><em class="oh"> and </em><a class="af nf" href="https://www.ingoscholtes.net/" rel="noopener ugc nofollow" target="_blank"><em class="oh">Ingo Scholtes</em></a><em class="oh">.</em></p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="992a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This blog post covers a selection of exciting developments in TGL while pointing out research directions for 2024. We also ask leading researchers for their take on what the future holds for TGL. This blog also aims to provide references and act as starting points for those who want to learn more about temporal graph learning. Please share with us in the comment section any other advances you are excited about. For advancements on graph learning, checkout <a class="af nf" href="https://mgalkin.medium.com/" rel="noopener">Michael Galkin</a>’s excellent <a class="af nf" rel="noopener" target="_blank" href="/graph-geometric-ml-in-2024-where-we-are-and-whats-next-part-i-theory-architectures-3af5d38376e1">blog post</a>.</p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="b91a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Table of Contents:</strong></p><ol class=""><li id="eefc" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne oi oj ok bk"><a class="af nf" href="#fffa" rel="noopener ugc nofollow">Temporal Graph Benchmark</a></li><li id="bde3" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne oi oj ok bk"><a class="af nf" href="#4d80" rel="noopener ugc nofollow">Novel Architectures for Link Prediction</a></li><li id="a5ec" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne oi oj ok bk"><a class="af nf" href="#3e08" rel="noopener ugc nofollow">Spatiotemporal Graphs and Graph Deep Learning for Time Series Processing</a></li><li id="b2e0" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne oi oj ok bk"><a class="af nf" href="#1bf1" rel="noopener ugc nofollow">Temporal Knowledge Graph</a></li><li id="c97b" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne oi oj ok bk"><a class="af nf" href="#bfbb" rel="noopener ugc nofollow">Causality-Aware Temporal Graph Learning</a></li><li id="cc0b" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne oi oj ok bk"><a class="af nf" href="#4876" rel="noopener ugc nofollow">Explainable Temporal Graph Methods</a></li><li id="4e6c" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne oi oj ok bk"><a class="af nf" href="#328d" rel="noopener ugc nofollow">Adversarial Attacks on Temporal Graphs</a></li><li id="53cb" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne oi oj ok bk"><a class="af nf" href="#00ae" rel="noopener ugc nofollow">Libraries and Benchmarks</a></li><li id="2962" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne oi oj ok bk"><a class="af nf" href="#31ef" rel="noopener ugc nofollow">Joining Temporal Graph Learning Community</a></li></ol></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="fffa" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Temporal Graph Benchmark</h1><p id="7c78" class="pw-post-body-paragraph mj mk fq ml b go pm mn mo gr pn mq mr ms po mu mv mw pp my mz na pq nc nd ne fj bk">One of the driving forces of the rapid development of machine learning on graphs is the availability of standardized and diverse benchmarks such as the <a class="af nf" href="https://ogb.stanford.edu/" rel="noopener ugc nofollow" target="_blank">Open Graph Benchmark</a> (OGB), the <a class="af nf" href="https://openreview.net/forum?id=in7XC5RcjEn" rel="noopener ugc nofollow" target="_blank">Long Range Graph Benchmark</a> and <a class="af nf" href="https://blog.research.google/2022/05/graphworld-advances-in-graph.html" rel="noopener ugc nofollow" target="_blank">GraphWorld</a>. However, these benchmarks are designed for static graphs and lack the fine-grained timestamp information required for temporal graph learning. Therefore, progress in temporal graph learning has been held back by the lack of large high-quality datasets, as well as the lack of proper evaluation resulting in over-optimistic performances.</p><p id="4a3c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To address this gap, the <a class="af nf" href="https://tgb.complexdatalab.com/" rel="noopener ugc nofollow" target="_blank">Temporal Graph Benchmark (TGB)</a> was presented recently, including a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evaluation for machine learning on temporal graphs. TGB provides a <a class="af nf" href="https://pypi.org/project/py-tgb/" rel="noopener ugc nofollow" target="_blank">pypi package</a> to automatically download and process nine datasets from five distinct domains with up to 72 million edges and 30 million timestamps. TGB also provides standardized evaluation motivated by real applications.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh pr"><img src="../Images/2968f4a125d9de1a57a71b9aa3234353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6U7-I5TEq1GTn71g"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">TGB: Challenging and Realistic Benchmark for Temporal Graph Learning.<br/>Image source: <a class="af nf" href="https://openreview.net/forum?id=qG7IkQ7IBO" rel="noopener ugc nofollow" target="_blank">Huang et al. 2023</a>, by authors.</figcaption></figure><p id="efb6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">TGB includes both link and node level tasks and an extensive empirical comparison of state-of-the-art TG models on all datasets. The first task is the dynamic link property prediction task which predicts the property (often existence) of a link between a pair of nodes at a future time. In TGB, this task is modeled as a ranking problem and evaluated with the filtered Mean Reciprocal Rank (MRR) metric. Results show that model rankings vary significantly across datasets with different ratios of test set edges which are never observed during training. In addition, model performance deteriorates as more negative samples (non-existence edges) are used in the evaluation. Interestingly, the extent of performance drop varies across models as well.</p><p id="bf1f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In the dynamic node property prediction task, the goal is to predict the property of a node at a given time. More specifically we focus on the node affinity prediction task which models how the user preference towards different items shift over time. Here, we use the Normalized Discounted Cumulative Gain of the top 10 items (NDCG@10) to compare the relative order of the predicted items to that of the ground truth. Interesting, we found that single heuristics outperform existing TG models and this highlights the need for more models focusing on node level tasks in the future. The <a class="af nf" href="https://tgb.complexdatalab.com/docs/leader_linkprop/" rel="noopener ugc nofollow" target="_blank">TGB leaderboard</a> is public and you are welcome to submit your model via a <a class="af nf" href="https://docs.google.com/forms/d/e/1FAIpQLSfmvBRgRPeR8bK3ubiwvJd1k26PDI_yVZDRXXRGgU7uSqJWZg/viewform" rel="noopener ugc nofollow" target="_blank">google form</a>. For more details, see the <a class="af nf" href="https://medium.com/towards-data-science/temporal-graph-benchmark-bb5cc26fcf11" rel="noopener">TGB blog post</a> by the authors of this blog.</p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="4d80" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Novel Architectures for Link Prediction</h1><blockquote class="ps pt pu"><p id="1c57" class="mj mk oh ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">“Link prediction in the realm of temporal graph learning poses a significant challenge. The learning algorithms must extend beyond the limited expressive power typically found in traditional message passing architectures like GNNs. Additionally, they must emphasize computational efficiency. A critical aspect of this is ensuring low latency in responding to link prediction queries, striking a balance between the expressive power of the model and the speed of its predictions in a dynamic and complex data environment.” — Pan Li, Assistant Professor, Georgia Institute of Technology</p></blockquote><p id="0c73" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A recent survey by <a class="af nf" href="https://openreview.net/forum?id=pHCdMat0gI&amp;referrer=%5BTMLR%5D%28%2Fgroup%3Fid%3DTMLR%29" rel="noopener ugc nofollow" target="_blank">Longa et al.</a> provides a comprehensive overview of temporal GNNs. Many approaches proposed specialized architectures for dynamic link prediction, often aiming to capture important structure properties or correlations. For example, <a class="af nf" href="https://arxiv.org/abs/2209.01084" rel="noopener ugc nofollow" target="_blank">Luo et al.</a> aimed to explicitly model the joint neighborhood of a set of nodes for future link prediction where they designed the <strong class="ml fr">N</strong>eighborhood-<strong class="ml fr">A</strong>ware <strong class="ml fr">T</strong>emporal network model (NAT). The joint neighborhood is not captured by traditional Graph Neural Network (GNN) based approaches as the node embedding vectors are generated independently for each node. In the following example, node <em class="oh">v</em> and <em class="oh">w</em> have the same structural contexts thus indistinguishable in the eyes of GNNs. In reality, the link between node <em class="oh">u</em> and <em class="oh">v</em> at t₃ is more likely to form due to the triadic closure law while this is not sure for the link between <em class="oh">u</em> and <em class="oh">w</em> at t₃. In comparison, NAT adapted a novel dictionary-type neighborhood representation which records k-hop neighborhood information and allows fast construction of structure features of joint neighborhood of multiple nodes. The dictionary representation is maintained by an efficient cache technique named N-cache. N-caches allowed NAT to construct the joint neighborhood features for a batch of node pairs for fast link prediction.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh pv"><img src="../Images/613d7fba8ce836fcc6dad7fbd2dc2f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UG1-GW4W7m2jdEr6"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">GNN embeddings of node <em class="pw">v</em> and w would be identical.<br/>Image source: <a class="af nf" href="https://arxiv.org/abs/2209.01084" rel="noopener ugc nofollow" target="_blank">Luo et al. 2022</a></figcaption></figure><p id="ba87" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Second, <a class="af nf" href="https://openreview.net/forum?id=xHNzWHbklj" rel="noopener ugc nofollow" target="_blank">Yu et al.</a> aim to capture long-term temporal dependencies by proposing DyGFormer, a new Transformer-based architecture for temporal graph learning. Given a query between node <em class="oh">u</em> and node <em class="oh">v </em>at time <em class="oh">t</em>, the first step is to extract historical first-hop interactions of node <em class="oh">u</em> and <em class="oh">v </em>before time <em class="oh">t</em>. This includes the encodings of neighbors, links, time intervals as well as the frequencies of every neighbor’s appearances of <em class="oh">u</em> and <em class="oh">v</em>. The assumption is that if <em class="oh">u</em> and <em class="oh">v </em>share more common historical neighbors in the past, then they are more likely to interact in the future. After encoding the historical interactions in a sequence, it is then divided into multiple patches and fed into a transformer for capturing temporal dependencies.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh px"><img src="../Images/213d11dc93944f290c9be0ba52cd291f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ACyTR-uEJXmXUYm7"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Framework of DyGFormer<br/>Image source:<a class="af nf" href="https://openreview.net/forum?id=xHNzWHbklj" rel="noopener ugc nofollow" target="_blank"> Yu et al. 2023</a></figcaption></figure><p id="1c07" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Another question is <em class="oh">do we really need complicated model architectures for temporal networks?</em> In a paper with the same name, <a class="af nf" href="https://openreview.net/forum?id=ayPPc0SyLv1" rel="noopener ugc nofollow" target="_blank">Cong et al.</a> examined the necessity of common modules used in temporal graph learning such as Recurrent Neural Network (RNN) and the self-attention mechanism. They showed that these modules are not always necessary for dynamic link prediction. In particular, their proposed GraphMixer model is based entirely on multi-layer perceptrons (MLPs) and neighbor mean-pooling while performing strongly against baselines with RNN and self-attention. GraphMixer contains three modules: a <em class="oh">link-encoder</em> summarizes the information from temporal links, a <em class="oh">node-encoder</em> extracts information from nodes and a <em class="oh">link-classifier </em>which combines the above information for prediction. Interestingly, <a class="af nf" href="https://openreview.net/forum?id=ayPPc0SyLv1" rel="noopener ugc nofollow" target="_blank">Cong et al.</a> argued that a trainable time-encoding function could cause instability during training and instead opted for a fixed time-encoding function <em class="oh">z(t) = cos(tω) </em>where fixed features <em class="oh">capture</em> the relative difference between two timestamps as shown below.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh py"><img src="../Images/f552a8d490b6e445f452de05df940622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BmzdQ0FhSlYInL2L"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Fixed time encoding function to convert <em class="pw">t </em>into a vector <em class="pw">cos(tω)</em>. <br/>x-axis is the vector dimension and y-axis is the cosine value. <br/>Image source: <a class="af nf" href="https://openreview.net/forum?id=ayPPc0SyLv1" rel="noopener ugc nofollow" target="_blank">Cong et al. 2023</a></figcaption></figure><p id="c635" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Lastly, <a class="af nf" href="https://dl.acm.org/doi/abs/10.1145/3543507.3583476" rel="noopener ugc nofollow" target="_blank">Suresh et al.</a> pointed out that existing methods maximizes accuracy independently over future links, ignoring the fact that future links often have dependency between each other. This is seen when a user selects among a list of items to purchase or a set of users to connect in a social network. Therefore, Suresh et al. treat dynamic link prediction as a ranking problem and propose <strong class="ml fr">T</strong>emporal <strong class="ml fr">G</strong>raph network for <strong class="ml fr">RANK</strong>ing (TGRank) to learn to rank over a list of candidates. The pipeline of TGRank is shown below. The task query now contains a center node <em class="oh">s </em>(in the example) with a set of candidate nodes (all other nodes in the subgraph) and the goal is to rank the most likely candidate as the destination of node <em class="oh">s</em>. To this end, TGRank follows three steps. First, the node <em class="oh">s</em> is labeled differently from other nodes. Then, GNNs are used to diffuse the center node label to every ranking candidate. This parametrized label diffusion step aggregates timestamps, multiplicity as well as features of historical interactions along the network from the center node to all candidates and provides provably more expressive power for link prediction. Lastly, a list-wise loss is used to optimize the ranking amongst candidates jointly. Empirically, it is also shown that with a listwise ranking loss, popular models such as <a class="af nf" href="https://arxiv.org/abs/2006.10637" rel="noopener ugc nofollow" target="_blank">TGN</a> and <a class="af nf" href="https://arxiv.org/abs/2002.07962" rel="noopener ugc nofollow" target="_blank">TGAT</a> also perform better than their original setup with binary classification loss.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh pz"><img src="../Images/b452c8a5094427bee68c6aa119670a18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5330k4KQ-akiJONa"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Pipeline of TGRank. The center node is node <em class="pw">s</em>.<br/>Image source: <a class="af nf" href="https://dl.acm.org/doi/abs/10.1145/3543507.3583476" rel="noopener ugc nofollow" target="_blank">Suresh et al. 2023</a></figcaption></figure></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="3e08" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Spatiotemporal Graphs and Graph Deep Learning for Time Series Processing</h1><blockquote class="ps pt pu"><p id="2b8f" class="mj mk oh ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">“Basing our predictions primarily on the most related observations is sensible, yet not always straightforward, as relevant data relations often hide in plain sight. Unveiling them is a captivating challenge, particularly when they are dynamic or involve more than two entities.” — Daniele Zambon, PostDoc at The Swiss AI Lab IDSIA</p></blockquote><p id="175c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In the temporal graph learning community, the term <em class="oh">spatiotemporal graph </em>has been often used to indicate a graph with fixed topology and node features that change over time, usually at discrete time steps corresponding to regularly sampled observations. More recently the problem of processing data with such a structure is being considered from a different perspective, i.e., by considering the dynamic node feature as time series and edges as functional dependencies among sequences of observations (<a class="af nf" href="https://arxiv.org/abs/2310.15978" rel="noopener ugc nofollow" target="_blank">Cini et al. 2023</a>, <a class="af nf" href="https://arxiv.org/abs/2307.03759" rel="noopener ugc nofollow" target="_blank">Ming et al. 2023</a>). From this perspective, which significantly deviates from many of the settings discussed elsewhere in this blog post, spatiotemporal graph-based representations allow for processing collections of correlated time series by taking advantage of the architectural biases typical of graph neural networks.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh ni"><img src="../Images/1f7d08d5aa14384b4ae4e0d9bcd53c9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ozjDBfu7eQGl8nlH"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Correlated time series with relational side information <br/>Image source: <a class="af nf" href="https://arxiv.org/abs/2310.15978" rel="noopener ugc nofollow" target="_blank">Cini et al. 2023</a>, by authors.</figcaption></figure><p id="3a43" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Such sets of correlated time series can be generated by sensors, either physical or not. An example is in the traffic domain, where time series might correspond to readings of sensors measuring the number of vehicles passing by at a crossroads. Each sensor will correspond to a different node and an adjacency matrix can be obtained, for instance, by joining with an edge only those sensors directly connected by a road segment. Besides traffic forecasting (<a class="af nf" href="https://openreview.net/forum?id=SJiHXGWAZ" rel="noopener ugc nofollow" target="_blank">Li et al. 2018</a>, <a class="af nf" href="https://www.ijcai.org/proceedings/2018/505" rel="noopener ugc nofollow" target="_blank">Yu et al. 2018</a>), these representations have been used in a wide range of time series processing applications ranging from air quality monitoring (<a class="af nf" href="https://dl.acm.org/doi/10.1145/3631713" rel="noopener ugc nofollow" target="_blank">Chen et al. 2021</a>) and energy analytics (<a class="af nf" href="https://ojs.aaai.org/index.php/AAAI/article/view/25880" rel="noopener ugc nofollow" target="_blank">Cini et al. 2023</a>) to biomedical data processing (<a class="af nf" href="https://openreview.net/forum?id=Kwm8I7dU-l5" rel="noopener ugc nofollow" target="_blank">Zhang et al. 2022</a>) and financial time series analysis (<a class="af nf" href="https://arxiv.org/abs/1909.10660" rel="noopener ugc nofollow" target="_blank">Matsunaga et al. 2019</a>).</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qa"><img src="../Images/d48b917c91b2d348893a61a1f6ad501c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fseYXIQWqtsF49JP"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Example of correlated time series from the traffic domain.<br/>Image source: <a class="af nf" href="https://gmlg.ch/tutorials/graph-based-processing/ecml-2023" rel="noopener ugc nofollow" target="_blank">tutorial at ECML PKDD 2023</a> by authors.</figcaption></figure><p id="2b38" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To process this data, the standard message-passing framework needs to be updated to handle sequences of observations coming from the neighborhood of each node. This can easily be done by replacing the proper operators (i.e., the message and update functions) with operators able to process the data along the temporal dimension, e.g., recurrent cells (<a class="af nf" href="https://arxiv.org/abs/1612.07659" rel="noopener ugc nofollow" target="_blank">Seo et al. 2018</a>), spatiotemporal convolutions (<a class="af nf" href="https://www.ijcai.org/proceedings/2019/0264" rel="noopener ugc nofollow" target="_blank">Wu et al. 2019</a>) and attention-based architectures (<a class="af nf" href="https://papers.nips.cc/paper_files/paper/2022/hash/cf70320e93c08b39b1b29a348097a376-Abstract-Conference.html" rel="noopener ugc nofollow" target="_blank">Marisca et al. 2022</a>). The resulting models are known as spatiotemporal graph neural networks (STGNNs) and there has been a large amount of research dedicated to coming up with effective architectures (see <a class="af nf" href="https://arxiv.org/abs/2307.03759" rel="noopener ugc nofollow" target="_blank">Ming et al. 2023</a>). One of the main advantages of using STGNNs is that the same set of parameters can be used to forecast any subset of time series, while taking dependencies into account throughout the processing. This is a massive advantage over standard multivariate time series forecasting models that usually would have to forecast each time series separately or give up parameter sharing. Hybrid STGNNs, with some time-series-specific parameters, can also be considered and, as we have shown in <a class="af nf" href="https://openreview.net/forum?id=x2PH6q32LR" rel="noopener ugc nofollow" target="_blank">a recent NeurIPS paper</a>, often outperform models where all parameters are shared. Besides the model architecture, graph-based representations, as shown by <a class="af nf" href="https://openreview.net/forum?id=SFeKNSxect" rel="noopener ugc nofollow" target="_blank">Zambon et al.</a>, can also help in assessing the optimality of a forecasting model by focusing the spatiotemporal correlation analysis to interconnected nodes.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qa"><img src="../Images/5e4d1ef2c085ad6c04f2fe38a418f15d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*j6DWj3tH8he2PNud"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">A spatiotemporal graph neural network.<br/>Image by authors.</figcaption></figure><p id="ba0b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Several challenges are inherent to the field, starting from dealing with <a class="af nf" href="https://arxiv.org/abs/2012.00168" rel="noopener ugc nofollow" target="_blank">irregularly sampled time series</a> and missing data; indeed, both are quite common phenomena when dealing with actual cyber-physical systems. Luckily, graph-based models are useful in this context as well, for example allowing to <a class="af nf" href="https://openreview.net/forum?id=kOu3-S3wJ7" rel="noopener ugc nofollow" target="_blank">condition the reconstruction on observations at neighboring sensors</a>. Scalability is another major concern as differently from standard GNNs, message-passing is often performed w.r.t. each time step. Existing scalable architectures mostly rely on <a class="af nf" href="https://assets.amazon.science/50/90/df9385f840c7b0363febf882a6ad/spatio-temporal-multi-graph-networks-fordemand-forecasting-in-online-marketplaces.pdf" rel="noopener ugc nofollow" target="_blank">subsampling</a> and/or <a class="af nf" href="https://ojs.aaai.org/index.php/AAAI/article/view/25880" rel="noopener ugc nofollow" target="_blank">pre-computed node features</a>. When no prior relation information is available, the challenge becomes that of learning a latent graph directly from the time series. The problem has been tackled, for example, by directly learning an adjacency matric (e.g., <a class="af nf" href="https://www.ijcai.org/proceedings/2019/0264" rel="noopener ugc nofollow" target="_blank">Wu et al. 2019</a>) or, under a probabilistic framework, by relying on <a class="af nf" href="https://proceedings.mlr.press/v80/kipf18a" rel="noopener ugc nofollow" target="_blank">reparametrization tricks</a> and <a class="af nf" href="https://www.jmlr.org/papers/v24/22-1154.html" rel="noopener ugc nofollow" target="_blank">score-based estimators</a>.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qa"><img src="../Images/29f300758be7f7f4f941ad96bcf14338.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F4avGrE93wH2yyqJ"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">A scalable spatiotemporal graph neural network <br/>Image source: <a class="af nf" href="https://ojs.aaai.org/index.php/AAAI/article/view/25880" rel="noopener ugc nofollow" target="_blank">Cini et al. 2023</a>. by authors</figcaption></figure><p id="76a0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Since this topic was not covered in last year’s blog post, the objective here was to give a short overview of the settings and the problems that can be modeled. Many directions are currently being explored, from <a class="af nf" href="https://arxiv.org/abs/2301.01741" rel="noopener ugc nofollow" target="_blank">graph state-space models</a> and <a class="af nf" href="https://arxiv.org/abs/2303.12021" rel="noopener ugc nofollow" target="_blank">graph Kalman filters</a> to <a class="af nf" href="https://dl.acm.org/doi/10.1145/3589132.3625614" rel="noopener ugc nofollow" target="_blank">diffusion-based </a>and <a class="af nf" href="https://openreview.net/forum?id=Oq5XKRVYpQ" rel="noopener ugc nofollow" target="_blank">continuous space-time</a> models. If you are interested in knowing more and/or using these models in practice, we recently released a comprehensive <a class="af nf" href="https://arxiv.org/abs/2310.15978" rel="noopener ugc nofollow" target="_blank">tutorial</a> paper on the topic. You can also check out <a class="af nf" href="https://torch-spatiotemporal.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">Torch Spatiotemporal (tsl)</a>, our library to build graph-based time series processing pipelines.</p><ul class=""><li id="0d77" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qb oj ok bk">Tutorial paper: <a class="af nf" href="https://arxiv.org/abs/2310.15978" rel="noopener ugc nofollow" target="_blank">Graph Deep Learning for Time Series Forecasting</a></li><li id="c54b" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">Library: <a class="af nf" href="https://torch-spatiotemporal.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">Torch Spatiotemporal (tsl)</a></li></ul></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="1bf1" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Temporal Knowledge Graph</h1><p id="560f" class="pw-post-body-paragraph mj mk fq ml b go pm mn mo gr pn mq mr ms po mu mv mw pp my mz na pq nc nd ne fj bk">There were surprisingly few temporal KG papers in this year’s top ML conferences: <strong class="ml fr">TILP</strong> (<a class="af nf" href="https://openreview.net/forum?id=_X12NmQKvX" rel="noopener ugc nofollow" target="_blank">Xiong et al. 2023</a>) on deriving temporal rule learning competitive with neural methods, and theory work by <a class="af nf" href="https://openreview.net/forum?id=AtHJ7TLheF" rel="noopener ugc nofollow" target="_blank">Chen and Wang</a> to measure expressiveness of temporal GNNs. In fact, the most interesting (to me) papers on this topic were found at the TGL workshop at NeurIPS’23 (one more reason for you to follow the venue!), e.g., predicting future time intervals by <a class="af nf" href="https://openreview.net/forum?id=9B8ocBg4VJ" rel="noopener ugc nofollow" target="_blank">Pop and Kostylev</a>, or identifying leakages in standard benchmarking datasets by <a class="af nf" href="https://openreview.net/forum?id=UMokRwWfLW" rel="noopener ugc nofollow" target="_blank">Pan et al</a>. Finally, I’d outline the <strong class="ml fr">Unified Urban KG (UUKG)</strong> by <a class="af nf" href="https://arxiv.org/abs/2306.11443" rel="noopener ugc nofollow" target="_blank">Ning et al</a> as a fresh look on temporal KG datasets that actually make practical sense and a use-case — modeling transportation flows in the city.</p><p id="e2a6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">UUKG illustrates the biggest problem of the shrinking temporal KG community — the lack of practically important tasks and datasets where it would be possible to demonstrate the utility of the data modeling paradigm in real-world tasks. That is, adding 1% of MRR/Hits@10 on 10-year old KG embedding benchmarks is rather useless these days compared to the successes of Geometric Deep Learning in biology or materials science (or compared to LLMs, but that’s a story for another day). Hopefully, we will see more UUKG-like practically useful datasets.</p><p id="587a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Perhaps another adjacent area where temporal KGs might make a difference is heterogeneous graphs (that usually have typed edges) that are much more used in industry. For example, the recent <a class="af nf" href="https://relbench.stanford.edu/" rel="noopener ugc nofollow" target="_blank">RelBench</a> (Relational Deep Learning Benchmark) formulates a temporal prediction problem over relational databases that can be easily converted to KGs or hypergraphs.</p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="bfbb" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Causality-Aware Temporal Graph Learning</h1><blockquote class="ps pt pu"><p id="133f" class="mj mk oh ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">“Einstein said the arrow of time flies in only one direction. […] And who among us, offered the chance, would not relive the day or hour in which we first knew love, or ecstasy, or made a choice that forever altered our future, negating a life we might have had? Such chances are rarely granted.” — Greg Iles, The Quiet Game</p></blockquote><p id="8016" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">One reason why temporal graph learning is interesting is that — depending on the data at hand — it requires different perspectives. As an example, consider temporal graphs data with high-resolution (possibly continuous) time stamps. In such data, discrete-time graph learning techniques that utilize sequences of snapshot graphs require a coarse-graining of time, where each snapshot consists of edges occurring in a certain time interval. This coarse-graining allows to generalize (static) graph learning techniques to time series data. But it introduces a major issue: Each snapshots discards information on the temporal order in which edges occurred, which is the foundation of <em class="oh">causal </em>or <em class="oh">time-respecting paths</em><a class="af nf" href="https://www.sciencedirect.com/science/article/pii/S0022000002918295" rel="noopener ugc nofollow" target="_blank"> (Kempe et al. 2000)</a>. Like paths in static graphs, time-respecting paths are important since they tell us which nodes can causally influence each other indirectly. Below, we illustrate this in a simple temporal graph with two undirected edges <em class="oh">(a,b)</em> and <em class="oh">(b,c)</em> occurring at times <em class="oh">t₁</em> and <em class="oh">t₂</em> respectively. If <em class="oh">(a,b)</em> occurs before <em class="oh">(b,c)</em>, <em class="oh">a</em> can causally influence <em class="oh">c</em> via a time-respecting path (indicated in purple) passing through <em class="oh">b</em>. If the temporal order of edges is reversed, <em class="oh">a</em> cannot causally influence <em class="oh">c</em>, since any influence must propagate backwards in time. Note that the directedness of the influence from <em class="oh">a</em> to <em class="oh">c</em> is due to the directed arrow of time and despite the fact that both edges are undirected. Moreover, while two edges <em class="oh">(a,b)</em> and <em class="oh">(b,c)</em> in a static, time-aggregated graph imply a transitive path from <em class="oh">a</em> via <em class="oh">b</em> to <em class="oh">c</em> (purple) and vice-versa (orange), this is not true for temporal graphs.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qc"><img src="../Images/1c51adfe45fe86ccf53bc1661740a9a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kT-rbkd5O1vfqHf9"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Time-respecting path from node a to node c.<br/>Image by authors.</figcaption></figure><p id="0d24" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Several works have shown that — due to the arrow of time — the <em class="oh">causal topology</em> <em class="oh">of temporal graphs</em>, i.e. which nodes can possibly causally influence each other via time-respecting paths, strongly differs from their static counterparts, with interesting implications for epidemic spreading (<a class="af nf" href="https://link.aps.org/doi/10.1103/PhysRevLett.110.198701" rel="noopener ugc nofollow" target="_blank">Pfitzner et al. 2013</a>), diffusion speed (<a class="af nf" href="https://www.nature.com/articles/ncomms6024" rel="noopener ugc nofollow" target="_blank">Scholtes et al. 2014</a>), node centralities (<a class="af nf" href="https://www.nature.com/articles/ncomms5630" rel="noopener ugc nofollow" target="_blank">Rosvall et al. 2014</a>), or community detection (<a class="af nf" href="https://www.nature.com/articles/s41567-019-0459-y" rel="noopener ugc nofollow" target="_blank">Lambiotte et al. 2019</a>). Can we make deep learning methods aware of patterns in the causal topology of temporal graphs? Advances presented at this year show that this can be achieved based on models that generalize commonly used static representations of temporal graphs. Consider a weighted time-aggregated graph, where a (directed) edge <em class="oh">(a,b)</em> with weight five captures that <em class="oh">(a,b)</em> occurred five times in a temporal graph. Such a weighted, time-aggregated graph is illustrated in the bottom of panel 2 in the figure below.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qa"><img src="../Images/c823d73a9ca3e993e9903aebfcf14986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mUzW9U1UhpRL6_nU"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Pipeline to predict temporal centralities of nodes in a temporal graph.<br/>Image source: <a class="af nf" href="https://arxiv.org/abs/2310.15865" rel="noopener ugc nofollow" target="_blank">Heeg et al.</a>, by authors</figcaption></figure><p id="0e45" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Each edge in the temporal graph is a time-respecting path with length one. A weighted time-aggregated graph thus corresponds to a first-order model for the causal topology of a temporal graph, which captures time-respecting paths of length one. It neglects the temporal ordering of edges, since we only count how often each edge occurred. A line graph transformation enables us to generalize this idea to<strong class="ml fr"> </strong>causality-aware models<em class="oh"> </em>that facilitate temporal graph learning: We simply replace edges in the first-order graph by nodes in a <em class="oh">second-order</em> graph, i.e. we turn edges <em class="oh">(a,b)</em> and <em class="oh">(b,c)</em> into nodes <em class="oh">“a→b”</em> and <em class="oh">“b→c”</em>, respectively. In the resulting second-order graph (see the top graph in panel 2 in figure), we can use edges to represent time-respecting paths of length two, i.e. edge <em class="oh">(a→b, b→c)</em> indicates that <em class="oh">a </em>causally influence <em class="oh">c</em> via <em class="oh">b</em>. However, the reverse order of edges are not included. If the edges occur in reverse order, we do not include <em class="oh">(a→b, b→c)</em>. Importantly, such a second-order graph is sensitive to the temporal ordering of edges, while a first-order graph is not! In <a class="af nf" href="https://dl.acm.org/doi/10.1145/3097983.3098145" rel="noopener ugc nofollow" target="_blank">Scholtes, 2017</a>, this is generalized to higher orders, which yields <strong class="ml fr">k-th order De Bruijn graph models for the causal topology of</strong> <strong class="ml fr">temporal graphs</strong>.</p><p id="b2ec" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><a class="af nf" href="https://proceedings.mlr.press/v198/qarkaxhija22a/qarkaxhija22a.pdf" rel="noopener ugc nofollow" target="_blank">Qarkaxhija et al.</a> have shown that neural message passing in such higher-order De Bruijn graphs yields a <strong class="ml fr">causality-aware graph neural network architecture</strong> for temporal graphs. Building on these <strong class="ml fr">De Bruijn Graph Neural Networks (DBGNN)</strong>, in a poster at this year’s TGL workshop, <a class="af nf" href="https://arxiv.org/abs/2310.15865" rel="noopener ugc nofollow" target="_blank">Heeg and Scholtes</a> address the challenge to predict temporal betweenness and closeness centralities of nodes. Since they are influenced by the arrow of time, temporal node centralities can drastically differ from static centralities. Moreover, it is costly to compute them! This is addressed by training a DBGNN model on a first time interval of a temporal graph, then using the trained model to forecast temporal centralities in the remaining data. The overall approach is illustrated above. Empirically results are promising and showcased the potential of causality-aware graph learning. We also hope to see more attention from the community in learning causal structure on temporal graphs in 2024.</p><p id="d4b6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Interested in causality-aware temporal graph learning? Then there’s good news! The techniques above are implemented in the Open Source library<a class="af nf" href="https://www.pathpy.net/" rel="noopener ugc nofollow" target="_blank"> pathpyG</a>, which builds on <a class="af nf" href="https://pyg.org/" rel="noopener ugc nofollow" target="_blank">PyG</a>. There is an <a class="af nf" href="https://www.pathpy.net/dev/tutorial/" rel="noopener ugc nofollow" target="_blank">introductory video and a tutorial</a> available. A <a class="af nf" href="https://youtu.be/IezbzMMp9QM?si=1_B8rMag5Gpk0Vqx" rel="noopener ugc nofollow" target="_blank">recorded talk given in the temporal graph reading group</a> provides an in-depth introduction of the underlying research.</p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="4876" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Explainable Temporal Graph Methods</h1><blockquote class="ps pt pu"><p id="2700" class="mj mk oh ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">“Most important graph-structured data in real-world settings are temporal in nature. Explainable temporal graph models have the potential to unveil the long-standing questions on effective strategies and knowledge that can be leveraged to make temporal predictions, enabling extraction of insights from deep learning models and assisting scientific discovery and forecasting.” — Rex Ying, Assistant Professor, Yale University</p></blockquote><p id="6c66" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">2023 saw the first approaches for explaining temporal GNN methods. Explainers are important for high-stake applications such as fraud detection and disease progression prediction in healthcare. <a class="af nf" href="https://openreview.net/forum?id=BR_ZhvcYbGJ" rel="noopener ugc nofollow" target="_blank">Xia et al.</a> proposed T-GNNExplainer as the first explainer designed for temporal graph models. T-GNNExplainer is model-agnostic and finds important events from a set of candidate events to best explain the model prediction. Xia et al. treat the problem of identifying a subset of explaining events as a combinatorial optimization problem by searching over a subset of the temporal graph within a given size. To tackle this, T-GNNExplainer employs an explorer-navigator framework. The navigator is trained from multiple target events to capture inductive correlations between events while the explorer searches out a specific combination of events based on Monte Carlo Tree Search, including node selection, node expansion, reward simulation and backprop. Which events are pruned is inferred from the navigator. The diagram below shows the framework of T-GNNExplainer.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qa"><img src="../Images/2e8097a22cf7af9ee4686e1af17cf30e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_plLsmgJd1me0itt"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Framework of T-GNNExplainer.<br/>Image source: <a class="af nf" href="https://openreview.net/forum?id=BR_ZhvcYbGJ" rel="noopener ugc nofollow" target="_blank">Xia et al. 2023</a></figcaption></figure><p id="ec5c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Recently, <a class="af nf" href="https://arxiv.org/abs/2310.19324" rel="noopener ugc nofollow" target="_blank">Chen et al.</a> argued that to form human intelligible explanations for temporal graph events requires the explanation to be events that are temporally proximate and spatially adjacent to that of the prediction, referred to as <em class="oh">cohesive explanations</em>. Utilizing <em class="oh">temporal motifs, </em>recurring substructures within the temporal graph, is a natural solution to form cohesive explanations for temporal graphs. This is because temporal motifs are crucial factors that guide the generative process of future events. In the following example, the preferential attachment rule (often facilitating influencer effect in e-commerce) and triadic closure rule (explains common-friend rules in social networks) forms cohesive and plausible explanations.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qd"><img src="../Images/15c2737fed1e3529dffee8d9bffab28f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BFHW8ye4-v-ZkPeuBfQxKw.png"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx"><em class="pw">Cohesive explanations</em> are temporally approximate and spatially adjacent.<br/>Image source: <a class="af nf" href="https://arxiv.org/abs/2310.19324" rel="noopener ugc nofollow" target="_blank">Chen et al. 2023</a></figcaption></figure><p id="f445" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Therefore, <a class="af nf" href="https://arxiv.org/abs/2310.19324" rel="noopener ugc nofollow" target="_blank">Chen et al.</a> proposed TempME, a novel Temporal Motif-based Explainer to identify important temporal motifs to explain temporal GNNs. The framework of TempME is shown in the below figure. First, temporal motifs surrounding the target prediction are extracted. Then these candidate motifs are encoded via the <em class="oh">Motif Encoder </em>which leverages event anonymization, message passing and graph pooling to generate an embedding for each motif. Then, based on the Information-bottleneck principle, TempME assigns importance scores to these motifs constrained by both explanation accuracy and information compression. Lastly, explanations are constructed by sampling from the Bernoulli distribution based on the importance score.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qe"><img src="../Images/9baa6fe57cec7a96c033167b51ca3dec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pr-37GLMfng3Zma1dolKlw.png"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Framework of TempME, numbers on the edges denote the temporal order.<br/>Image credit: <a class="af nf" href="https://arxiv.org/abs/2310.19324" rel="noopener ugc nofollow" target="_blank">Chen et al. 2023</a></figcaption></figure></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="328d" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Adversarial Attacks on Temporal Graphs</h1><blockquote class="ps pt pu"><p id="568b" class="mj mk oh ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">“As temporal graphs are adopted to be used for important tasks, like fraud detection, it is important to understand their failure points under adversarial attacks. Understanding and quantifying such blind spots is the first step towards creating robust and reliable temporal GNN models. Such efforts are necessary to ensure industry adoption of these models.” - Srijan Kumar, Assistant Professor at Georgia Institute of Technology</p></blockquote><p id="2419" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Adversarial attacks can target the privacy of customers or affect critical decisions in financial systems. As temporal graph models are deployed to applications such as recommendation systems and fraud detection, it is important to investigate attacks and design defense mechanisms for TG models. <a class="af nf" href="https://arxiv.org/abs/1911.10561" rel="noopener ugc nofollow" target="_blank">Chen et al.</a> proposed the first adversarial attack for dynamic link prediction called Time-aware Gradient Attack (TGA) for discrete time dynamic graphs. TGA rewires a limited number of links from the original network and the most valuable links to the predicted link are determined by the gradient information generated by the TG model.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh qf"><img src="../Images/ae39ba65201cfb39a0605af3c6e55601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QTdXCn9PMn3-kThdSJTaeQ.png"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Overview of the Temporal Dynamics-aware Perturbation attack. <br/>The attacker can flip the prediction of the model while evading detection. <br/>Image source: <a class="af nf" href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599517" rel="noopener ugc nofollow" target="_blank">Sharma et al. 2023</a></figcaption></figure><p id="e23a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Recently, <a class="af nf" href="https://dl.acm.org/doi/abs/10.1145/3580305.3599517" rel="noopener ugc nofollow" target="_blank">Sharma et al.</a> argued that effective attacks on temporal graphs must optimize both edge and time perturbations while preserving the original graph evolution. This is because drastic attacks that disturb the graph evolution would be easily detected by anomaly detection methods. Therefore, Sharma et al. formulated <em class="oh">evolution-preserving attacks</em> on discrete-time dynamic graphs as the <strong class="ml fr">T</strong>emporal <strong class="ml fr">D</strong>ynamics-<strong class="ml fr">A</strong>ware <strong class="ml fr">P</strong>erturbation (TDAP) constraint. TDAP asserts that perturbations added at a given timestamp must only be a small fraction of the actual number of changes with respect to the preceding timestamp. TDAP is shown to preserve the rate of change in both the structure and the embedding spaces. An overview of TDAP is shown in the figure below. Sharma et al. then proposes a novel attack method called <strong class="ml fr">T</strong>emporal <strong class="ml fr">D</strong>ynamics-aware <strong class="ml fr">P</strong>rojected <strong class="ml fr">G</strong>radient <strong class="ml fr">D</strong>escent (TD-PGD) which is shown to have a closed-form projection operator under the TDAP constraint. An online version of TD-PGD is also proposed where perturbations can be added in real time. Lastly, it is shown empirically that TDAP-constrained perturbations can indeed evade attacks by embedding-based anomaly detection methods.</p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="00ae" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Libraries and Benchmarks</h1><p id="1078" class="pw-post-body-paragraph mj mk fq ml b go pm mn mo gr pn mq mr ms po mu mv mw pp my mz na pq nc nd ne fj bk">In 2023 saw a significant push towards standardized libraries and benchmarks for temporal graph learning. <a class="af nf" href="https://tgb.complexdatalab.com/" rel="noopener ugc nofollow" target="_blank">TGB</a> provides an open and standardized benchmark for node and link level tasks. <a class="af nf" href="https://github.com/yule-BUAA/DyGLib" rel="noopener ugc nofollow" target="_blank">DyGLib</a> is a library which includes standard training pipelines, extensible coding interfaces, and comprehensive evaluation strategies for temporal graph learning. <a class="af nf" href="https://openreview.net/forum?id=zr1e15kczE" rel="noopener ugc nofollow" target="_blank">Zhang et al.</a> introduced the novel concept of <a class="af nf" href="https://livegraphlab.github.io/" rel="noopener ugc nofollow" target="_blank"><em class="oh">Live Graph Lab</em></a>, providing live graphs according to blockchain transactions. With a set of tools for downloading, parsing, cleaning, and analyzing blockchain transactions, Live Graph Lab offers researchers the opportunity to extract update to date temporal graph data any time and use it for analysis or testing. <a class="af nf" href="https://dl.acm.org/doi/10.1145/3581784.3607056" rel="noopener ugc nofollow" target="_blank">Zhou et al.</a> noticed that node memory used in TG models favors small batch sizes and needs to be maintained synchronously across all trainers. Therefore, they proposed <a class="af nf" href="https://github.com/amazon-science/disttgl" rel="noopener ugc nofollow" target="_blank">DistTGL</a>, an efficient and scalable solution to train memory-based TGNNs on distributed GPU clusters. Enabling multi-GPU training on large datasets is an important direction to deploy TG models on large datasets. We present an updated list of libraries and benchmarks for temporal graph learning:</p><ul class=""><li id="85e5" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qb oj ok bk">TGB <a class="af nf" href="https://tgb.complexdatalab.com/" rel="noopener ugc nofollow" target="_blank">website</a> and <a class="af nf" href="https://pypi.org/project/py-tgb/" rel="noopener ugc nofollow" target="_blank">pypi install</a></li><li id="83b6" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">DyGLib <a class="af nf" href="https://github.com/yule-BUAA/DyGLib" rel="noopener ugc nofollow" target="_blank">Github</a></li><li id="a6c8" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">Live Graph Lab <a class="af nf" href="https://livegraphlab.github.io/" rel="noopener ugc nofollow" target="_blank">website</a> and <a class="af nf" href="https://zenodo.org/records/8267012" rel="noopener ugc nofollow" target="_blank">dataset</a></li><li id="66d0" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">DistTGL <a class="af nf" href="https://github.com/amazon-science/disttgl" rel="noopener ugc nofollow" target="_blank">Github</a></li><li id="f3dd" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">Torch Spatiotemporal (TSL) <a class="af nf" href="https://torch-spatiotemporal.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">website</a> and <a class="af nf" href="https://github.com/TorchSpatiotemporal/tsl" rel="noopener ugc nofollow" target="_blank">Github</a></li><li id="0d1e" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">pathpyG <a class="af nf" href="https://www.pathpy.net/dev/" rel="noopener ugc nofollow" target="_blank">website</a> and <a class="af nf" href="https://github.com/pathpy/pathpyG" rel="noopener ugc nofollow" target="_blank">Github</a></li><li id="5db0" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">RelBench <a class="af nf" href="https://relbench.stanford.edu/" rel="noopener ugc nofollow" target="_blank">website</a> and <a class="af nf" href="https://github.com/snap-stanford/relbench" rel="noopener ugc nofollow" target="_blank">Github</a></li><li id="d112" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk"><a class="af nf" href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html" rel="noopener ugc nofollow" target="_blank">Pytorch Geometric Temporal</a></li><li id="c756" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">TGL <a class="af nf" href="https://assets.amazon.science/88/aa/0323050941cab9403763ffdde180/tgl-a-general-framework-for-temporal-gnn-training-on-billion-scale-graphs-scalable-data-science.pdf" rel="noopener ugc nofollow" target="_blank">paper</a> and <a class="af nf" href="https://github.com/amazon-science/tgl" rel="noopener ugc nofollow" target="_blank">Github</a></li><li id="f93f" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">DGB <a class="af nf" href="https://pypi.org/project/dgb/" rel="noopener ugc nofollow" target="_blank">pypi install</a>, <a class="af nf" href="https://openreview.net/forum?id=1GVpwr2Tfdg" rel="noopener ugc nofollow" target="_blank">paper</a> and <a class="af nf" href="https://zenodo.org/records/7213796#.Y8QicOzMJB2" rel="noopener ugc nofollow" target="_blank">datasets</a></li><li id="b6a8" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">Chartalist Blockchain Network <a class="af nf" href="https://www.chartalist.org/" rel="noopener ugc nofollow" target="_blank">website</a>, <a class="af nf" href="https://openreview.net/forum?id=10iA3OowAV3" rel="noopener ugc nofollow" target="_blank">paper</a> and <a class="af nf" href="https://github.com/cakcora/chartalist" rel="noopener ugc nofollow" target="_blank">Github</a></li><li id="1e7c" class="mj mk fq ml b go ol mn mo gr om mq mr ms on mu mv mw oo my mz na op nc nd ne qb oj ok bk">TKG Forecasting Evaluation <a class="af nf" href="https://github.com/JuliaGast/JuliaGast.github.io/blob/master/files/gastinger_evaluation_paper_TKG.pdf" rel="noopener ugc nofollow" target="_blank">paper</a> and <a class="af nf" href="https://github.com/nec-research/TKG-Forecasting-Evaluation" rel="noopener ugc nofollow" target="_blank">Github</a></li></ul></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="31ef" class="oq or fq bf os ot ou gq ov ow ox gt oy oz pa pb pc pd pe pf pg ph pi pj pk pl bk">Joining Temporal Graph Learning Community</h1><p id="27a5" class="pw-post-body-paragraph mj mk fq ml b go pm mn mo gr pn mq mr ms po mu mv mw pp my mz na pq nc nd ne fj bk">To join the fast growing TG community, sign up for the weekly temporal graph reading group <a class="af nf" href="https://forms.gle/wausEzsgm7DvyLPs7" rel="noopener ugc nofollow" target="_blank">here</a>. Visit the <a class="af nf" href="https://www.cs.mcgill.ca/~shuang43/rg.html" rel="noopener ugc nofollow" target="_blank">reading group website</a> and <a class="af nf" href="https://www.youtube.com/@TGL_RG" rel="noopener ugc nofollow" target="_blank">Youtube</a> to see all upcoming and recorded past talks. We also include the invitation link to the TG slack on the website (updated monthly). The second edition of <a class="af nf" href="https://sites.google.com/view/tglworkshop-2023/home" rel="noopener ugc nofollow" target="_blank">temporal graph learning workshop @ NeurIPS 2023</a> includes an exciting lineup of <a class="af nf" href="https://openreview.net/group?id=NeurIPS.cc%2F2023%2FWorkshop%2FTGL#tab-accept-long-paper" rel="noopener ugc nofollow" target="_blank">35 posters</a> for cutting edge research in TG. You can also find the talk recordings on the <a class="af nf" href="https://neurips.cc/virtual/2023/workshop/66544" rel="noopener ugc nofollow" target="_blank">NeurIPS virtual site</a> (will be public in a month). If you want to be a reviewer for the next edition of the workshop, sign up <a class="af nf" href="https://forms.gle/4UuiTUDEqkvQ4pHC8" rel="noopener ugc nofollow" target="_blank">here</a>. To find more about the research from the authors of this post, see our websites: <a class="af nf" href="https://cs.mcgill.ca/~shuang43/" rel="noopener ugc nofollow" target="_blank">Shenyang(Andy) Huang</a>, <a class="af nf" href="https://www.emanuelerossi.co.uk/" rel="noopener ugc nofollow" target="_blank">Emanuele Rossi</a>, <a class="af nf" href="https://migalkin.github.io/" rel="noopener ugc nofollow" target="_blank">Michael Galkin</a> ,<a class="af nf" href="https://andreacini.github.io/" rel="noopener ugc nofollow" target="_blank">Andrea Cini</a> and <a class="af nf" href="https://www.ingoscholtes.net/" rel="noopener ugc nofollow" target="_blank">Ingo Scholtes</a>. Hope to see you at the reading group or the next edition of the workshop!</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div class="ng nh qg"><img src="../Images/63a42f043a6b9654d313b283180a13ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*esb5Yy5KYR7cNDwa"/></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Logo of the NeurIPS 2023 Temporal Graph Learning Workshop. <br/>Image by authors.</figcaption></figure></div></div></div></div>    
</body>
</html>