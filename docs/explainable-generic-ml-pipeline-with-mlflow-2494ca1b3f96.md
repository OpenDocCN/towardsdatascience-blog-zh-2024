# å¯è§£é‡Šçš„é€šç”¨æœºå™¨å­¦ä¹ ç®¡é“ä¸MLflow

> åŸæ–‡ï¼š[https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26](https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26)

## ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç¤ºèŒƒï¼Œå°†é¢„å¤„ç†å™¨å’Œè§£é‡Šå™¨åŒ…è£…æˆä¸€ä¸ªç®—æ³•æ— å…³çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œä½¿ç”¨`mlflow.pyfunc`

[](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Mena Wang, PhD](../Images/eac9fa55026f9fc119bc868439ff311b.png)](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------) [Mena Wang, PhD](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------) Â·13åˆ†é’Ÿé˜…è¯»Â·2024å¹´11æœˆ26æ—¥

--

![](../Images/718ec8036048d1449b127442c59434ab.png)

å›¾ç‰‡ç”± [Hannah Murrell](https://unsplash.com/@hannahj236?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) æä¾›ï¼Œæ¥æº [Unsplash](https://unsplash.com/photos/person-holding-ball-focus-on-tree-pTfdcT0hxGc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)

# **ä»‹ç»**

MLOpsä¸­çš„ä¸€ä¸ªå¸¸è§æŒ‘æˆ˜æ˜¯è¿ç§»ä¸åŒç®—æ³•æˆ–æ¡†æ¶æ—¶çš„éº»çƒ¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¿™æ˜¯æˆ‘å…³äºä½¿ç”¨`mlflow.pyfunc`è¿›è¡Œé€šç”¨æ¨¡å‹æ„å»ºçš„ç¬¬äºŒç¯‡æ–‡ç« ã€‚

åœ¨æˆ‘ä¹‹å‰çš„æ–‡ç« ä¸­ï¼Œæˆ‘æä¾›äº†ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„é€æ­¥ç¤ºèŒƒï¼Œå±•ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªæç®€çš„ç®—æ³•æ— å…³æ¨¡å‹åŒ…è£…å™¨ã€‚

[](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------) [## ä½¿ç”¨MLflowè¿›è¡Œç®—æ³•æ— å…³æ¨¡å‹æ„å»º

### ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„é€æ­¥æŒ‡å—ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨mlflow.pyfuncåˆ›å»ºé€šç”¨æœºå™¨å­¦ä¹ ç®¡é“

towardsdatascience.com](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)

ä¸ºäº†æ¨è¿›æˆ‘ä»¬çš„æ—…ç¨‹ï¼Œåœ¨æœ¬æ–‡ç»“æŸæ—¶ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ›´ä¸ºå¤æ‚çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œå…·å¤‡ä»¥ä¸‹åŠŸèƒ½ï¼š

1.  è¯¥ç®¡é“æ”¯æŒåˆ†ç±»ï¼ˆäºŒåˆ†ç±»ï¼‰å’Œå›å½’ä»»åŠ¡ã€‚å®ƒé€‚ç”¨äºscikit-learnæ¨¡å‹ä»¥åŠå…¶ä»–éµå¾ªscikit-learnæ¥å£çš„ç®—æ³•ï¼ˆå³ï¼Œfitã€predict/predict_probaï¼‰ã€‚

1.  å¼•å…¥ä¸€ä¸ªåŠŸèƒ½å®Œå¤‡çš„`é¢„å¤„ç†å™¨`ï¼Œå®ƒå¯ä»¥åœ¨è®­ç»ƒæ•°æ®ä¸Šæ‹Ÿåˆï¼Œç„¶åç”¨äºè½¬æ¢æ–°æ•°æ®ï¼Œä»¥ä¾›æ¨¡å‹ä½¿ç”¨ã€‚è¿™ä¸ªé¢„å¤„ç†å™¨å¯ä»¥å¤„ç†æ•°å€¼å‹å’Œç±»åˆ«å‹ç‰¹å¾ï¼Œå¹¶èƒ½é€šè¿‡å„ç§æ’è¡¥ç­–ç•¥å¤„ç†ç¼ºå¤±å€¼ã€‚

1.  æ·»åŠ ä¸€ä¸ª`explainer`æ¥é˜æ˜æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œè¿™å¯¹äºæ¨¡å‹é€‰æ‹©ã€ç›‘æ§å’Œå®ç°è‡³å…³é‡è¦ã€‚ç”±äºä¸åŒæœºå™¨å­¦ä¹ ç®—æ³•å¯¹SHAPå€¼çš„å®ç°å„å¼‚ï¼Œè¿™é¡¹ä»»åŠ¡å¯èƒ½ä¼šå¾ˆæ£˜æ‰‹ã€‚ä½†æ²¡é—®é¢˜ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬æ–‡ä¸­è§£å†³è¿™ä¸ªæŒ‘æˆ˜ã€‚ğŸ˜

ä¸å‰ä¸€ç¯‡æ–‡ç« ä¸€è‡´ï¼Œ

1.  ä½ å°†çœ‹åˆ°åˆ‡æ¢ä¸åŒè‡ªå®šä¹‰é¢„å¤„ç†å™¨æ˜¯å¤šä¹ˆç®€å•ï¼Œç±»ä¼¼äºåˆ‡æ¢ä¸åŒçš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚

1.  è¿™ä¸ªæœºå™¨å­¦ä¹ ç®¡é“å°†æ‰€æœ‰è‡ªå®šä¹‰çš„ç®¡é“å…ƒç´ å°è£…åœ¨èƒŒåï¼ŒåŒæ—¶ä»ç„¶æä¾›ç»Ÿä¸€çš„`pyfunc`æ¨¡å‹è¡¨ç¤ºï¼Œä»¥ç®€åŒ–æ¨¡å‹çš„éƒ¨ç½²ã€é‡æ–°éƒ¨ç½²å’Œä¸‹æ¸¸è¯„åˆ†ã€‚

ğŸ”— æ‰€æœ‰ä»£ç å’Œé…ç½®å¯ä»¥åœ¨[GitHub](https://github.com/MenaWANG/mlflow-demo/blob/main/pyfunc_pipeline.ipynb)ä¸Šæ‰¾åˆ°ã€‚ğŸ§°

# **é¢„å¤„ç†å™¨ï¼ˆV1ï¼‰**

è®¸å¤šæœºå™¨å­¦ä¹ ç®—æ³•â€”â€”ä¾‹å¦‚çº¿æ€§æ¨¡å‹ï¼ˆå¦‚çº¿æ€§å›å½’ã€æ”¯æŒå‘é‡æœºï¼‰ã€åŸºäºè·ç¦»çš„æ¨¡å‹ï¼ˆå¦‚KNNã€PCAï¼‰ä»¥åŠåŸºäºæ¢¯åº¦çš„æ¨¡å‹ï¼ˆå¦‚æ¢¯åº¦æå‡æ–¹æ³•æˆ–æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ï¼‰â€”â€”é€šå¸¸åœ¨å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œç¼©æ”¾åè¡¨ç°æ›´å¥½ï¼Œå› ä¸ºç¼©æ”¾å¯ä»¥é˜²æ­¢å…·æœ‰è¾ƒå¤§èŒƒå›´çš„ç‰¹å¾ä¸»å¯¼å­¦ä¹ è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œç°å®ä¸–ç•Œä¸­çš„æ•°æ®é€šå¸¸åŒ…å«ç¼ºå¤±å€¼ã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸ªç¬¬ä¸€ç‰ˆä¸­ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªé¢„å¤„ç†å™¨ï¼Œå®ƒå¯ä»¥è®­ç»ƒæ¥ç¼©æ”¾æ–°æ•°æ®å¹¶å¡«å……ç¼ºå¤±å€¼ï¼Œä¸ºæ¨¡å‹çš„ä½¿ç”¨åšå‡†å¤‡ã€‚

ä¸€æ—¦è¿™ä¸ªé¢„å¤„ç†å™¨æ„å»ºå®Œæˆï¼Œæˆ‘å°†æ¼”ç¤ºå¦‚ä½•è½»æ¾åœ°å°†å®ƒé›†æˆåˆ°`pyfunc`æœºå™¨å­¦ä¹ ç®¡é“ä¸­ã€‚å¬èµ·æ¥ä¸é”™å§ï¼Ÿæˆ‘ä»¬å¼€å§‹å§ã€‚ğŸ¤ 

```py
class PreProcessor(BaseEstimator, TransformerMixin):
    """
    Custom preprocessor for numeric features.

    - Handles scaling of numeric data
    - Performs imputation of missing values

    Attributes:
        transformer (Pipeline): Pipeline for numeric preprocessing
        features (List[str]): Names of input features
    """

    def __init__(self):
        """
        Initialize preprocessor.

        - Creates placeholder for transformer pipeline
        """
        self.transformer = None

    def fit(self, X, y=None):
        """
        Fits the transformer on the provided dataset.

        - Configures scaling for numeric features
        - Sets up imputation for missing values
        - Stores feature names for later use

        Parameters:
            X (pd.DataFrame): The input features to fit the transformer.
            y (pd.Series, optional): Target variable, not used in this method.

        Returns:
            PreProcessor: The fitted transformer instance.
        """
        self.features = X.columns.tolist()

        if self.features:
            self.transformer = Pipeline(steps=[
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler())
            ])
            self.transformer.fit(X[self.features])

        return self

    def transform(self, X):
        """
        Transform input data using fitted pipeline.

        - Applies scaling to numeric features
        - Handles missing values through imputation

        Parameters:
            X (pd.DataFrame): Input features to transform

        Returns:
            pd.DataFrame: Transformed data with scaled and imputed features
        """
        X_transformed = pd.DataFrame()

        if self.features:
            transformed_data = self.transformer.transform(X[self.features])
            X_transformed[self.features] = transformed_data

        X_transformed.index = X.index

        return X_transformed

    def fit_transform(self, X, y=None):
        """
        Fits the transformer on the input data and then transforms it.

        Parameters:
            X (pd.DataFrame): The input features to fit and transform.
            y (pd.Series, optional): Target variable, not used in this method.

        Returns:
            pd.DataFrame: The transformed data.
        """
        self.fit(X, y)
        return self.transform(X)
```

è¿™ä¸ªé¢„å¤„ç†å™¨å¯ä»¥åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œæ‹Ÿåˆï¼Œç„¶åç”¨äºå¤„ç†ä»»ä½•æ–°çš„æ•°æ®ã€‚å®ƒå°†æˆä¸ºä¸‹é¢æœºå™¨å­¦ä¹ ç®¡é“ä¸­çš„ä¸€ä¸ªå…ƒç´ ï¼Œä½†å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç‹¬ç«‹ä½¿ç”¨æˆ–æµ‹è¯•å®ƒã€‚è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåˆæˆæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨é¢„å¤„ç†å™¨æ¥è½¬æ¢å®ƒã€‚

```py
# Set parameters for synthetic data
n_feature = 10
n_inform = 4
n_redundant = 0
n_samples = 1000

# Generate synthetic classification data
X, y = make_classification(
    n_samples=n_samples,
    n_features=n_feature,
    n_informative=n_inform,
    n_redundant=n_redundant,
    shuffle=False,
    random_state=12
)

# Create feature names
feat_names = [f'inf_{i+1}' for i in range(n_inform)] + \
            [f'rand_{i+1}' for i in range(n_feature - n_inform)]

# Convert to DataFrame with named features
X = pd.DataFrame(X, columns=feat_names)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=22
)
```

ä»¥ä¸‹æ˜¯{sweetViz}æŠ¥å‘Šåœ¨ç¼©æ”¾å‰åçš„æˆªå›¾ï¼›ä½ å¯ä»¥çœ‹åˆ°ï¼Œç¼©æ”¾æ²¡æœ‰æ”¹å˜æ¯ä¸ªç‰¹å¾åˆ†å¸ƒçš„åŸºæœ¬å½¢çŠ¶ï¼Œåªæ˜¯é‡æ–°ç¼©æ”¾å¹¶ç§»åŠ¨äº†å®ƒã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œåªéœ€è¦ä¸¤è¡Œä»£ç å°±èƒ½ç”Ÿæˆä¸€ä»½éå¸¸å…¨é¢çš„EDAæŠ¥å‘Šï¼Œ{sweetViz}çš„ä»£ç å¯ä»¥åœ¨ä¸Šé¢é“¾æ¥çš„GitHubä»“åº“ä¸­æ‰¾åˆ°ã€‚ğŸ¥‚

![](../Images/7a1b3029a4739afeff34a9d50170c3d3.png)

é¢„å¤„ç†å‰åSweetVizæŠ¥å‘Šçš„æˆªå›¾

# **å¸¦é¢„å¤„ç†å™¨çš„æœºå™¨å­¦ä¹ ç®¡é“**

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`mlflow.pyfunc`é£æ ¼çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œå®ƒå¯ä»¥å°è£…è¿™ä¸ªé¢„å¤„ç†å™¨ã€‚

```py
class ML_PIPELINE(mlflow.pyfunc.PythonModel):
    """
    Custom ML pipeline for classification and regression.

    - work with any scikit-learn compatible model
    - Combines preprocessing and model training
    - Handles model predictions
    - Compatible with MLflow tracking
    - Supports MLflow deployment

    Attributes:
        model (BaseEstimator or None): A scikit-learn compatible model instance
        preprocessor (Any or None): Data preprocessing pipeline
        config (Any or None): Optional config for model settings 
        task(str): Type of ML task ('classification' or 'regression')
    """

    def __init__(self, model=None, preprocessor=None, config=None):
        """
        Initialize the ML_PIPELINE.

        Parameters:
            model (BaseEstimator, optional): 
                - Scikit-learn compatible model
                - Defaults to None

            preprocessor (Any, optional):
                - Transformer or pipeline for data preprocessing
                - Defaults to None

            config (Any, optional):
                - Additional model settings
                - Defaults to None
        """
        self.model = model
        self.preprocessor = preprocessor
        self.config = config
        self.task = "classification" if hasattr(self.model, "predict_proba") else "regression"

    def fit(self, X_train: pd.DataFrame, y_train: pd.Series):
        """
        Train the model on provided data.

        - Applies preprocessing to features
        - Fits model on transformed data

        Parameters:
            X_train (pd.DataFrame): Training features
            y_train (pd.Series): Target values
        """
        X_train_preprocessed = self.preprocessor.fit_transform(X_train.copy())
        self.model.fit(X_train_preprocessed, y_train)

    def predict(
            self, context: Any, model_input: pd.DataFrame
            ) -> np.ndarray:
        """
        Generate predictions using trained model.

        - Applies preprocessing to new data
        - Uses model to make predictions

        Parameters:
            context (Any): Optional context information provided 
                by MLflow during the prediction phase
            model_input (pd.DataFrame): Input features

        Returns:
            Any: Model predictions or probabilities
        """
        processed_model_input = self.preprocessor.transform(model_input.copy())
        if self.task == "classification":
            prediction = self.model.predict_proba(processed_model_input)[:,1]
        elif self.task == "regression":
            prediction = self.model.predict(processed_model_input)
        return prediction
```

ä¸Šé¢å®šä¹‰çš„æœºå™¨å­¦ä¹ ç®¡é“å°†é¢„å¤„ç†å™¨å’Œæœºå™¨å­¦ä¹ ç®—æ³•ä½œä¸ºå‚æ•°ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨ç¤ºä¾‹

```py
# define the ML pipeline instance with lightGBM classifier
ml_pipeline = ML_PIPELINE(model = lgb.LGBMClassifier(),
                          preprocessor = PreProcessor())
```

å°±æ˜¯è¿™ä¹ˆç®€å•ï¼ğŸ‰ å¦‚æœä½ æƒ³å°è¯•å…¶ä»–ç®—æ³•ï¼Œåªéœ€åƒä¸‹é¢ä¸€æ ·äº¤æ¢å³å¯ã€‚ä½œä¸ºåŒ…è£…å™¨ï¼Œå®ƒå¯ä»¥å°è£…å›å½’å’Œåˆ†ç±»ç®—æ³•ã€‚å¯¹äºåè€…ï¼Œå°†è¿”å›é¢„æµ‹çš„æ¦‚ç‡ï¼Œå¦‚ä¸Šä¾‹æ‰€ç¤ºã€‚

```py
# define the ML pipeline instance with random forest regressor
ml_pipeline = ML_PIPELINE(model = RandomForestRegressor(),
                          preprocessor = PreProcessor())
```

å¦‚ä¸‹æ–¹ä»£ç ç‰‡æ®µæ‰€ç¤ºï¼Œå‘ç®—æ³•ä¼ é€’è¶…å‚æ•°éå¸¸ç®€å•ï¼Œè¿™ä½¿å¾—è¯¥MLç®¡é“æˆä¸ºè¶…å‚æ•°è°ƒä¼˜çš„å®Œç¾å·¥å…·ã€‚æˆ‘å°†åœ¨åç»­çš„æ–‡ç« ä¸­è¯¦ç»†è®²è§£è¿™ä¸ªè¯é¢˜ã€‚

```py
params = {
    'n_estimators': 100,
    'max_depth': 6,
    'learning_rate': 0.1 
}
model = xgb.XGBClassifier(**params)
ml_pipeline = ML_PIPELINE(model = model,
                          preprocessor = PreProcessor())
```

å› ä¸ºè¿™ä¸ªMLç®¡é“æ˜¯åŸºäº`mlflow.pyfunc`ç‰ˆæœ¬æ„å»ºçš„ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`mlflow`è‡ªåŠ¨ä¿å­˜çš„ä¸°å¯Œå…ƒæ•°æ®è¿›è¡Œæ—¥å¿—è®°å½•ï¼Œä¾›ä¸‹æ¸¸ä½¿ç”¨ã€‚éƒ¨ç½²åï¼Œæˆ‘ä»¬å¯ä»¥å°†å…ƒæ•°æ®ä½œä¸º`context`ä¼ é€’ç»™æ¨¡å‹ï¼Œåœ¨`predict`å‡½æ•°ä¸­ä½¿ç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚æ›´å¤šä¿¡æ¯å’Œæ¼”ç¤ºå¯ä»¥åœ¨æˆ‘ä¹‹å‰çš„æ–‡ç« ä¸­æ‰¾åˆ°ï¼Œé“¾æ¥å·²åœ¨æ–‡ä¸­ç»™å‡ºã€‚

```py
# train the ML pipeline
ml_pipeline.fit(X_train, y_train)

# use the trained pipeline for prediction
y_prob = ml_pipeline.predict(
    context=None, # provide metadata for model in production
    model_input=X_test
)
auc = roc_auc_score(y_test, y_prob)
print(f"auc: {auc:.3f}")
```

# é¢„å¤„ç†å™¨ï¼ˆV2ï¼‰

ä¸Šé¢çš„é¢„å¤„ç†å™¨åˆ°ç›®å‰ä¸ºæ­¢è¡¨ç°è‰¯å¥½ï¼Œä½†æˆ‘ä»¬å°†é€šè¿‡ä¸‹é¢çš„ä¸¤ç§æ–¹å¼è¿›è¡Œæ”¹è¿›ï¼Œç„¶åå±•ç¤ºå¦‚ä½•è½»æ¾åˆ‡æ¢é¢„å¤„ç†å™¨ã€‚

1.  å…è®¸ç”¨æˆ·è‡ªå®šä¹‰é¢„å¤„ç†è¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼ŒæŒ‡å®šå¡«å……ç­–ç•¥ã€‚

1.  æ‰©å±•é¢„å¤„ç†å™¨çš„èƒ½åŠ›ï¼Œä»¥å¤„ç†ç±»åˆ«ç‰¹å¾ã€‚

```py
 class PreProcessor_v2(BaseEstimator, TransformerMixin):
    """
    Custom transformer for data preprocessing.

    - Scales numeric features
    - Encodes categorical features
    - Handles missing values via imputation
    - Compatible with scikit-learn pipeline

    Attributes:
        num_impute_strategy (str): Numeric imputation strategy
        cat_impute_strategy (str): Categorical imputation strategy
        num_transformer (Pipeline): Numeric preprocessing pipeline
        cat_transformer (Pipeline): Categorical preprocessing pipeline
        transformed_cat_cols (List[str]): One-hot encoded column names
        num_features (List[str]): Numeric feature names
        cat_features (List[str]): Categorical feature names
    """

    def __init__(self, num_impute_strategy='median', 
                 cat_impute_strategy='most_frequent'):
        """
        Initialize the transformer.

        - Sets up numeric data transformer
        - Sets up categorical data transformer
        - Configures imputation strategies

        Parameters:
            num_impute_strategy (str): Strategy for numeric missing values
            cat_impute_strategy (str): Strategy for categorical missing values
        """
        self.num_impute_strategy = num_impute_strategy
        self.cat_impute_strategy = cat_impute_strategy

    def fit(self, X, y=None):
        """
        Fit transformer on input data.

        - Identifies feature types
        - Configures feature scaling
        - Sets up encoding
        - Fits imputation strategies

        Parameters:
            X (pd.DataFrame): Input features
            y (pd.Series, optional): Target variable, not used

        Returns:
            CustomTransformer: Fitted transformer
        """
        self.num_features = X.select_dtypes(include=np.number).columns.tolist()
        self.cat_features = X.select_dtypes(exclude=np.number).columns.tolist()

        if self.num_features:
            self.num_transformer = Pipeline(steps=[
                ('imputer', SimpleImputer(strategy=self.num_impute_strategy)),
                ('scaler', StandardScaler())
            ])
            self.num_transformer.fit(X[self.num_features])

        if self.cat_features:
            self.cat_transformer = Pipeline(steps=[
                ('imputer', SimpleImputer(strategy=self.cat_impute_strategy)),
                ('encoder', OneHotEncoder(handle_unknown='ignore'))
            ])
            self.cat_transformer.fit(X[self.cat_features])

        return self

    def get_transformed_cat_cols(self):
        """
        Get transformed categorical column names.

        - Creates names after one-hot encoding
        - Combines category with encoded values

        Returns:
            List[str]: One-hot encoded column names
        """
        cat_cols = []
        cats = self.cat_features
        cat_values = self.cat_transformer['encoder'].categories_
        for cat, values in zip(cats, cat_values):
            cat_cols += [f'{cat}_{value}' for value in values]

        return cat_cols

    def transform(self, X):
        """
        Transform input data.

        - Applies fitted scaling
        - Applies fitted encoding
        - Handles numeric and categorical features

        Parameters:
            X (pd.DataFrame): Input features

        Returns:
            pd.DataFrame: Transformed data
        """
        X_transformed = pd.DataFrame()

        if self.num_features:
            transformed_num_data = self.num_transformer.transform(X[self.num_features])
            X_transformed[self.num_features] = transformed_num_data

        if self.cat_features:
            transformed_cat_data = self.cat_transformer.transform(X[self.cat_features]).toarray()
            self.transformed_cat_cols = self.get_transformed_cat_cols()
            transformed_cat_df = pd.DataFrame(transformed_cat_data, columns=self.transformed_cat_cols)
            X_transformed = pd.concat([X_transformed, transformed_cat_df], axis=1)

        X_transformed.index = X.index

        return X_transformed

    def fit_transform(self, X, y=None):
        """
        Fit and transform input data.

        - Fits transformer to data
        - Applies transformation
        - Combines both operations

        Parameters:
            X (pd.DataFrame): Input features
            y (pd.Series, optional): Target variable, not used

        Returns:
            pd.DataFrame: Transformed data
        """
        self.fit(X, y)
        return self.transform(X)
```

# **è‡ªå®šä¹‰é¢„å¤„ç†å™¨çš„è½»æ¾åˆ‡æ¢**

å°±æ˜¯è¿™æ ·ï¼šä¸€ä¸ªæ–°çš„é¢„å¤„ç†å™¨ï¼Œå®ƒ 1ï¼‰æ›´åŠ å¯å®šåˆ¶ï¼Œ2ï¼‰èƒ½å¤Ÿå¤„ç†æ•°å€¼ç‰¹å¾å’Œç±»åˆ«ç‰¹å¾ã€‚è®©æˆ‘ä»¬ç”¨å®ƒå®šä¹‰ä¸€ä¸ªMLç®¡é“å®ä¾‹ã€‚

```py
# Define a PreProcessor (V2) instance while specifying impute strategy
preprocessor = PreProcessor_v2(
    num_impute_strategy = 'mean'
)
# Define an ML Pipeline instance with this preprocessor
ml_pipeline = ML_PIPELINE(
    model = xgb.XGBClassifier(), # switch ML algorithms
    preprocessor = PreProcessor # switch pre-processors 
)
```

è®©æˆ‘ä»¬ç”¨å¦ä¸€ä¸ªåŒ…å«æ•°å€¼ç‰¹å¾å’Œç±»åˆ«ç‰¹å¾çš„åˆæˆæ•°æ®é›†æµ‹è¯•è¿™ä¸ªæ–°çš„MLç®¡é“å®ä¾‹ã€‚

```py
# add missings
np.random.seed(42) 
missing_rate = 0.20 
n_missing = int(np.floor(missing_rate * X.size))
rows = np.random.randint(0, X.shape[0], n_missing)
cols = np.random.randint(0, X.shape[1], n_missing)
X.values[rows, cols] = np.nan
actual_missing_rate = X.isna().sum().sum() / X.size
print(f"Target missing rate: {missing_rate:.2%}")
print(f"Actual missing rate: {actual_missing_rate:.2%}")

# change X['inf_1] to categorical
percentiles = [0, 0.1, 0.5, 0.9, 1]
labels = ['bottom', 'lower-mid', 'upper-mid', 'top']
X['inf_1'] = pd.qcut(X['inf_1'], q=percentiles, labels=labels)
```

å°±æ˜¯è¿™æ ·â€”â€”è¿™ä¸ªMLç®¡é“åœ¨æ–°æ•°æ®ä¸Šè¿è¡Œé¡ºåˆ©ã€‚ç„¶è€Œï¼Œæ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œå¦‚æœæˆ‘ä»¬ç”¨ä¹‹å‰çš„é¢„å¤„ç†å™¨å®šä¹‰MLç®¡é“ï¼Œç„¶ååœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè¿è¡Œå®ƒï¼Œæˆ‘ä»¬å°†é‡åˆ°é”™è¯¯ï¼Œå› ä¸ºä¹‹å‰çš„é¢„å¤„ç†å™¨å¹¶æ²¡æœ‰è®¾è®¡æ¥å¤„ç†ç±»åˆ«ç‰¹å¾ã€‚

```py
# create an ML pipeline instance with PreProcessor v1
ml_pipeline = ML_PIPELINE(
    model = lgb.LGBMClassifier(verbose = -1), 
    preprocessor = PreProcessor()
)

try:
    ml_pipeline.fit(X_train, y_train)
except Exception as e:
    print(f"Error: {e}")
```

```py
Error: Cannot use median strategy with non-numeric data:
could not convert string to float: 'lower-mid'
```

# å¯è§£é‡Šçš„MLç®¡é“çš„å¥½å¤„

åœ¨MLç®¡é“ä¸­æ·»åŠ è§£é‡Šå™¨åœ¨å¤šä¸ªæ–¹é¢éƒ½éå¸¸æœ‰å¸®åŠ©ï¼š

1.  **æ¨¡å‹é€‰æ‹©**ï¼šé€šè¿‡è¯„ä¼°æ¨¡å‹æ¨ç†çš„åˆç†æ€§ï¼Œå®ƒæœ‰åŠ©äºæˆ‘ä»¬é€‰æ‹©æœ€ä½³æ¨¡å‹ã€‚ä¸¤ä¸ªç®—æ³•åœ¨åƒAUCæˆ–ç²¾åº¦è¿™æ ·çš„æŒ‡æ ‡ä¸Šå¯èƒ½è¡¨ç°ç›¸ä¼¼ï¼Œä½†å®ƒä»¬ä¾èµ–çš„å…³é”®ç‰¹å¾å¯èƒ½ä¸åŒã€‚ä¸é¢†åŸŸä¸“å®¶ä¸€èµ·å›é¡¾æ¨¡å‹çš„æ¨ç†ï¼Œè®¨è®ºåœ¨è¿™ç§æƒ…å†µä¸‹å“ªä¸ªæ¨¡å‹æ›´åˆç†æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚

1.  **æ•…éšœæ’é™¤**ï¼šä¸€ç§æœ‰åŠ©äºæ¨¡å‹æ”¹è¿›çš„ç­–ç•¥æ˜¯åˆ†æé”™è¯¯èƒŒåçš„æ¨ç†ã€‚ä¾‹å¦‚ï¼Œåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è¯†åˆ«å‡ºæ¨¡å‹æœ€æœ‰ä¿¡å¿ƒçš„å‡é˜³æ€§ï¼ˆå³é¢„æµ‹çš„å¯èƒ½æ€§æœ€é«˜ï¼‰ï¼Œå¹¶è°ƒæŸ¥æ¨ç†ä¸­å‡ºäº†ä»€ä¹ˆé—®é¢˜ï¼Œå“ªäº›å…³é”®ç‰¹å¾å¯¼è‡´äº†é”™è¯¯ã€‚

1.  **æ¨¡å‹ç›‘æ§**ï¼šé™¤äº†æ•°æ®æ¼‚ç§»å’Œæ€§èƒ½æŒ‡æ ‡ç­‰å…¸å‹ç›‘æ§å…ƒç´ å¤–ï¼Œç›‘æ§æ¨¡å‹æ¨ç†åŒæ ·å…·æœ‰é‡è¦æ„ä¹‰ã€‚å¦‚æœç”Ÿäº§ä¸­é©±åŠ¨æ¨¡å‹å†³ç­–çš„å…³é”®ç‰¹å¾å‘ç”Ÿäº†æ˜¾è‘—å˜åŒ–ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ”¶åˆ°è­¦æŠ¥ã€‚

1.  **æ¨¡å‹å®ç°**ï¼šåœ¨æŸäº›åœºæ™¯ä¸­ï¼Œæä¾›æ¨¡å‹æ¨ç†å’Œæ¨¡å‹é¢„æµ‹çš„ç»“åˆå¯¹äºæœ€ç»ˆç”¨æˆ·æ¥è¯´æ˜¯éå¸¸æœ‰ç›Šçš„ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†å¸®åŠ©å®¢æˆ·æœåŠ¡äººå‘˜æœ€æœ‰æ•ˆåœ°æŒ½ç•™æµå¤±å®¢æˆ·ï¼Œæˆ‘ä»¬å¯ä»¥æä¾›æµå¤±è¯„åˆ†ä»¥åŠè´¡çŒ®è¯¥è¯„åˆ†çš„å®¢æˆ·ç‰¹å¾ã€‚

# å°†è§£é‡Šå™¨æ·»åŠ åˆ°æœºå™¨å­¦ä¹ ç®¡é“ä¸­

å› ä¸ºæˆ‘ä»¬çš„æœºå™¨å­¦ä¹ ç®¡é“æ˜¯ç®—æ³•æ— å…³çš„ï¼Œå› æ­¤è§£é‡Šå™¨ä¹Ÿå¿…é¡»èƒ½å¤Ÿè·¨ç®—æ³•å·¥ä½œã€‚

SHAPï¼ˆShapleyåŠ æ€§è§£é‡Šï¼‰å€¼æ˜¯æˆ‘ä»¬ç›®çš„çš„ç†æƒ³é€‰æ‹©ï¼Œå› ä¸ºå®ƒä»¬åŸºäºåšå¼ˆè®ºæä¾›ç†è®ºä¸Šç¨³å¥çš„è§£é‡Šã€‚å®ƒä»¬è®¾è®¡ä¸Šèƒ½å¤Ÿåœ¨å„ç§ç®—æ³•ä¸­ä¸€è‡´å·¥ä½œï¼ŒåŒ…æ‹¬åŸºäºæ ‘çš„å’ŒéåŸºäºæ ‘çš„æ¨¡å‹ï¼Œå¯¹äºåè€…ä¼šæœ‰ä¸€äº›è¿‘ä¼¼ã€‚æ­¤å¤–ï¼ŒSHAPè¿˜æä¾›ä¸°å¯Œçš„å¯è§†åŒ–åŠŸèƒ½ï¼Œå¹¶è¢«å¹¿æ³›è®¤ä¸ºæ˜¯è¡Œä¸šæ ‡å‡†ã€‚

åœ¨ä¸‹é¢çš„ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘æ·±å…¥æ¢è®¨äº†SHAPåœ¨å„ç§æœºå™¨å­¦ä¹ ç®—æ³•ä¸­çš„å®ç°çš„ç›¸ä¼¼æ€§ä¸å·®å¼‚ã€‚

+   [SHAPç”¨äºå›å½’æ¨¡å‹](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_regression.ipynb)

+   [SHAPç”¨äºXGBooståˆ†ç±»å™¨](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb)

+   [SHAPç”¨äºéšæœºæ£®æ—åˆ†ç±»å™¨](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_RF_classification.ipynb)

+   [SHAPç”¨äºLightGBMåˆ†ç±»å™¨](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_lightgbm_classification.ipynb)

è¦ä¸ºæˆ‘ä»¬çš„æœºå™¨å­¦ä¹ ç®¡é“åˆ›å»ºä¸€ä¸ªé€šç”¨çš„è§£é‡Šå™¨ï¼Œéœ€è¦è§£å†³çš„å…³é”®å·®å¼‚æ˜¯

> ***1\. æ¨¡å‹æ˜¯å¦è¢«*** `***shap.Explainer***` ***ç›´æ¥æ”¯æŒ***

ç‰¹å®šæ¨¡å‹çš„SHAPè§£é‡Šå™¨æ¯”æ¨¡å‹æ— å…³çš„è§£é‡Šå™¨æ›´é«˜æ•ˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œé‡‡ç”¨çš„æ–¹æ³•æ˜¯

+   é¦–å…ˆå°è¯•ä½¿ç”¨ç›´æ¥çš„SHAPè§£é‡Šå™¨æ¥é€‚åº”æ¨¡å‹ç±»å‹ï¼Œ

+   å¦‚æœè¿™å¤±è´¥äº†ï¼Œåˆ™å›é€€åˆ°ä½¿ç”¨predictå‡½æ•°çš„æ¨¡å‹æ— å…³è§£é‡Šå™¨ã€‚

> ***2\. SHAPå€¼çš„å½¢çŠ¶***

å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼ŒSHAPå€¼å¯ä»¥æœ‰ä¸¤ç§æ ¼å¼/å½¢çŠ¶ã€‚

+   **æ ¼å¼ 1**ï¼šä»…æ˜¾ç¤ºå¯¹æ­£ç±»çš„å½±å“

```py
shape = (n_samples, n_features) # 2d array
```

+   **æ ¼å¼ 2**ï¼šæ˜¾ç¤ºå¯¹ä¸¤ä¸ªç±»åˆ«çš„å½±å“

```py
shape = (n_samples, n_features, n_classes) # 3d array
```

+   ä»¥ä¸‹çš„è§£é‡Šå™¨å®ç°æ€»æ˜¯å±•ç¤ºå¯¹æ­£ç±»çš„å½±å“ã€‚å½“SHAPå€¼ä¸­åŒæ—¶æœ‰æ­£ç±»å’Œè´Ÿç±»çš„å½±å“æ—¶ï¼Œå®ƒä¼šé€‰æ‹©æ­£ç±»çš„å½±å“ã€‚

è¯·å‚è§ä¸‹é¢çš„ä»£ç ï¼Œäº†è§£ä¸Šè¿°æ–¹æ³•çš„å®ç°ã€‚

```py
class ML_PIPELINE(mlflow.pyfunc.PythonModel):
    """
    Custom ML pipeline for classification and regression.

    - Works with scikit-learn compatible models
    - Handles data preprocessing
    - Manages model training and predictions
    - Provide global and local model explanation
    - Compatible with MLflow tracking
    - Supports MLflow deployment

    Attributes:
        model (BaseEstimator or None): A scikit-learn compatible model instance
        preprocessor (Any or None): Data preprocessing pipeline
        config (Any or None): Optional config for model settings 
        task(str): Type of ML task ('classification' or 'regression')
        both_class (bool): Whether SHAP values include both classes
        shap_values (shap.Explanation): SHAP values for model explanation
        X_explain (pd.DataFrame): Processed features for SHAP explanation
    """

    # ------- same code as above ---------

    def explain_model(self,X):
        """
        Generate SHAP values and plots for model interpretation. 
        This method:
        1\. Transforms the input data using the fitted preprocessor
        2\. Creates a SHAP explainer appropriate for the model type
        3\. Calculates SHAP values for feature importance
        4\. Generates a summary plot of feature importance

        Parameters:
            X : pd.DataFrame
                Input features to generate explanations for. 

        Returns: None
            The method stores the following attributes in the class:
            - self.X_explain : pd.DataFrame
                Transformed data with original numeric values for interpretation
            - self.shap_values : shap.Explanation
                SHAP values for each prediction
            - self.both_class : bool
                Whether the model outputs probabilities for both classes          
        """
        X_transformed = self.preprocessor.transform(X.copy())
        self.X_explain = X_transformed.copy()
        # get pre-transformed values for numeric features
        self.X_explain[self.preprocessor.num_features] = X[self.preprocessor.num_features]
        self.X_explain.reset_index(drop=True)
        try:
            # Attempt to create an explainer that directly supports the model
            explainer = shap.Explainer(self.model)
        except:
            # Fallback for models or shap versions where direct support may be limited
            explainer = shap.Explainer(self.model.predict, X_transformed)
        self.shap_values = explainer(X_transformed)  

        # get the shape of shap values and extract accordingly
        self.both_class = len(self.shap_values.values.shape) == 3
        if self.both_class:
            shap.summary_plot(self.shap_values[:,:,1])
        elif self.both_class == False:
            shap.summary_plot(self.shap_values)

    def explain_case(self,n):
        """
        Generate SHAP waterfall plot for one specific case.

        - Shows feature contributions
        - Starts from base value
        - Ends at final prediction
        - Shows original feature values for better interpretability

        Parameters:
            n (int): Case index (1-based)
                     e.g., n=1 explains the first case.

        Returns:
            None: Displays SHAP waterfall plot

        Notes:
            - Requires explain_model() first
            - Shows positive class for binary tasks
        """
        if self.shap_values is None:
            print("""
                  Please explain model first by running
                  `explain_model()` using a selected dataset
                  """)
        else:
            self.shap_values.data = self.X_explain
            if self.both_class:
                shap.plots.waterfall(self.shap_values[:,:,1][n-1])
            elif self.both_class == False:
                shap.plots.waterfall(self.shap_values[n-1]) 
```

ç°åœ¨ï¼Œæ›´æ–°åçš„æœºå™¨å­¦ä¹ ç®¡é“å®ä¾‹å¯ä»¥é€šè¿‡ä¸€è¡Œä»£ç ä¸ºä½ åˆ›å»ºè§£é‡Šæ€§å›¾è¡¨ã€‚ğŸ˜

![](../Images/130400a4a9c80519ff731a20d3ede222.png)

ç”¨äºæ¨¡å‹å…¨å±€è§£é‡Šçš„SHAPå›¾

![](../Images/b20822a6bb527748b1849d31e4cb83d0.png)

ç”¨äºç‰¹å®šæ¡ˆä¾‹å±€éƒ¨è§£é‡Šçš„SHAPå›¾

# **è®°å½•å¹¶ä½¿ç”¨æ¨¡å‹**

å½“ç„¶ï¼Œä½ å¯ä»¥ä½¿ç”¨`mlflow`è®°å½•è®­ç»ƒå¥½çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œå¹¶äº«å—æ‰€æœ‰å…³äºæ¨¡å‹éƒ¨ç½²å’Œå¯é‡å¤æ€§çš„å…ƒæ•°æ®ã€‚åœ¨ä¸‹é¢çš„æˆªå›¾ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°ï¼Œé™¤äº†pickleä¿å­˜çš„`pyfunc`æ¨¡å‹æœ¬èº«ï¼ŒPythonç¯å¢ƒã€æŒ‡æ ‡å’Œè¶…å‚æ•°éƒ½å·²ç»åœ¨ä¸‹é¢çš„å‡ è¡Œä»£ç ä¸­è®°å½•ä¸‹æ¥äº†ã€‚æƒ³äº†è§£æ›´å¤šï¼Œè¯·å‚è€ƒæˆ‘ä¹‹å‰å…³äº`mlflow.pyfunc`çš„æ–‡ç« ï¼Œé“¾æ¥å·²åœ¨æ–‡ä¸­æåˆ°ã€‚

```py
# Log the model with MLflow
with mlflow.start_run() as run:

    # Log the custom model with auto-captured conda environment
    model_info = mlflow.pyfunc.log_model(
        artifact_path="model",
        python_model=ml_pipeline,
        conda_env=mlflow.sklearn.get_default_conda_env()
    )
    # Log model parameters
    mlflow.log_params(ml_pipeline.model.get_params())

    # Log metrics
    mlflow.log_metric("rmse", rmse)

    # Get the run ID
    run_id = run.info.run_id
```

![](../Images/d1ce888009587f800ff1a165eb1fb61a.png)

ä½¿ç”¨mlflowè®°å½•ä¸°å¯Œçš„æ¨¡å‹å…ƒæ•°æ®å’Œå·¥ä»¶

# **ç»“è®ºä¸ä¸‹ä¸€æ­¥**

å°±æ˜¯è¿™æ ·ï¼Œä¸€ä¸ªé€šç”¨ä¸”å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œé€‚ç”¨äºåˆ†ç±»å’Œå›å½’ç®—æ³•ã€‚æ‹¿èµ°ä»£ç å¹¶æ‰©å±•å®ƒä»¥é€‚åº”ä½ çš„ä½¿ç”¨æ¡ˆä¾‹ã€‚ğŸ¤— å¦‚æœä½ è§‰å¾—è¿™ä¸ªæœ‰ç”¨ï¼Œè¯·ç»™æˆ‘ä¸€ä¸ªæŒå£° ğŸ‘ğŸ¥°

ä¸ºäº†è¿›ä¸€æ­¥æ¨è¿›`mlflow.pyfunc`ç³»åˆ—çš„æ—…ç¨‹ï¼Œä»¥ä¸‹æ˜¯æˆ‘æ­£åœ¨è€ƒè™‘çš„ä¸€äº›è¯é¢˜ã€‚æ¬¢è¿ç•™è¨€å‘Šè¯‰æˆ‘ä½ å¸Œæœ›çœ‹åˆ°å“ªäº›å†…å®¹ã€‚ğŸ¥°

+   ç‰¹å¾é€‰æ‹©

+   è¶…å‚æ•°è°ƒä¼˜

+   å¦‚æœä¸é€‰æ‹©åœ¨ç°æˆç®—æ³•ä¸­*æŒ‘é€‰*ä¸€ä¸ªï¼Œè€Œæ˜¯å†³å®š*é›†æˆ*å¤šä¸ªç®—æ³•æˆ–æ‹¥æœ‰é«˜åº¦å®šåˆ¶çš„è§£å†³æ–¹æ¡ˆï¼Œä»–ä»¬ä¾ç„¶å¯ä»¥äº«å—é€šç”¨æ¨¡å‹è¡¨ç¤ºå’Œé€šè¿‡`mlflow.pyfunc`çš„æ— ç¼è¿ç§»ã€‚

æ•¬è¯·å…³æ³¨å¹¶åœ¨[Medium](https://menawang.medium.com/)ä¸Šå…³æ³¨æˆ‘ã€‚ğŸ˜

ğŸ’¼[LinkedIn](https://www.linkedin.com/in/mena-ning-wang/) | ğŸ˜º[GitHub](https://github.com/MenaWANG) | ğŸ•Šï¸[Twitter/X](https://x.com/mena_wang)

é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…æä¾›ã€‚
