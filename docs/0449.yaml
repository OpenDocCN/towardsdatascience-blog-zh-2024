- en: 2 Silent PySpark Mistakes You Should Be Aware Of
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/2-silent-pyspark-mistakes-you-should-be-aware-of-de52c3a188c4?source=collection_archive---------14-----------------------#2024-02-16](https://towardsdatascience.com/2-silent-pyspark-mistakes-you-should-be-aware-of-de52c3a188c4?source=collection_archive---------14-----------------------#2024-02-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Small mistakes can lead to severe consequences when working with large datasets.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://sonery.medium.com/?source=post_page---byline--de52c3a188c4--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page---byline--de52c3a188c4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--de52c3a188c4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--de52c3a188c4--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page---byline--de52c3a188c4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--de52c3a188c4--------------------------------)
    ·5 min read·Feb 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6d67208592c34319ca46e35f9a5143c.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ernie A. Stephens](https://unsplash.com/@eas071?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/stack-of-stack-of-books-KflQqYcFknk?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: In programming, when we make a mistake, we don’t always get an error. The code
    works, doesn’t throw an exception and we think everything is fine. Those mistakes
    that don’t cause our script to fail are difficult to notice and debug.
  prefs: []
  type: TYPE_NORMAL
- en: It’s even more challenging to catch such mistakes in data science because we
    don’t usually get a single output.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say we have a dataset with millions of rows. We make a mistake in calculating
    the sales quantities. Then, we create aggregate features based on the sales quantities
    such as weekly total, the moving average of the last 14 days, and so on. These
    features are used in a machine learning model that predicts the demand in the
    next week.
  prefs: []
  type: TYPE_NORMAL
- en: We evaluate the predictions and find out the accuracy is not good enough. Then,
    we spend lots of time trying different things to improve the accuracy such as
    feature engineering or hyperparameter tuning. These strategies don’t have a big
    impact on the accuracy because the problem is in the data.
  prefs: []
  type: TYPE_NORMAL
- en: This is a scenario that we may encounter when working with large datasets. In
    this article, we’ll go over two specific PySpark mistakes that might cause unexpected…
  prefs: []
  type: TYPE_NORMAL
