<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Intro to LLM Agents with Langchain: When RAG is Not Enough</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Intro to LLM Agents with Langchain: When RAG is Not Enough</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/intro-to-llm-agents-with-langchain-when-rag-is-not-enough-7d8c08145834?source=collection_archive---------0-----------------------#2024-03-15">https://towardsdatascience.com/intro-to-llm-agents-with-langchain-when-rag-is-not-enough-7d8c08145834?source=collection_archive---------0-----------------------#2024-03-15</a></blockquote><div><div class="em ff fg fh fi fj"/><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><div/><div><h2 id="ee93" class="pw-subtitle-paragraph go fq fr bf b gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd cq dx">First-order principles of brain structure for AI assistants</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://alexhonchar.medium.com/?source=post_page---byline--7d8c08145834--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Alex Honchar" class="l ep by dd de cx" src="../Images/fd30740a0ee12701b0d8670143ba7a9b.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*iNhT3ND48_WSNLMz44OnzA.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--7d8c08145834--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://alexhonchar.medium.com/?source=post_page---byline--7d8c08145834--------------------------------" rel="noopener follow">Alex Honchar</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--7d8c08145834--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk ld le ab q ee lf lg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lb lc">15</span></p></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lh k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al li an ao ap ie lj lk ll" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lm cn"><div class="l ae"><div class="ab cb"><div class="ln lo lp lq lr ls ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="5a38" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">Hello everyone, this article is a written form of a tutorial I conducted two weeks ago with <a class="af ng" href="https://neurons-lab.com/" rel="noopener ugc nofollow" target="_blank">Neurons Lab</a>. If you prefer a narrative walkthrough, you can find the YouTube video here:</p><figure class="nh ni nj nk nl nm"><div class="nn ip l ed"><div class="no np l"/></div></figure><p id="c0be" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">As always, you can find <a class="af ng" href="https://github.com/Rachnog/intro_to_llm_agents" rel="noopener ugc nofollow" target="_blank">the code on GitHub</a>, and here are separate Colab Notebooks:</p><ol class=""><li id="41a6" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf nq nr ns bk"><a class="af ng" href="https://colab.research.google.com/drive/1SplDwEIbVfo9zNt6JOK0gJlV0wCNuz0F?usp=sharing" rel="noopener ugc nofollow" target="_blank">Planning and reasoning</a></li><li id="6e87" class="mk ml fr mm b gp nt mo mp gs nu mr ms mt nv mv mw mx nw mz na nb nx nd ne nf nq nr ns bk"><a class="af ng" href="https://colab.research.google.com/drive/13b_pD27aqcNXYI2M7fBxK1fRIO2pygZJ?usp=sharing" rel="noopener ugc nofollow" target="_blank">Different types of memories</a></li><li id="4851" class="mk ml fr mm b gp nt mo mp gs nu mr ms mt nv mv mw mx nw mz na nb nx nd ne nf nq nr ns bk"><a class="af ng" href="https://colab.research.google.com/drive/1-VpwkmSvzA-zQ_iVK-xjOQf5kA-Lzwg9?usp=sharing" rel="noopener ugc nofollow" target="_blank">Various types of tools</a></li><li id="53a1" class="mk ml fr mm b gp nt mo mp gs nu mr ms mt nv mv mw mx nw mz na nb nx nd ne nf nq nr ns bk"><a class="af ng" href="https://colab.research.google.com/drive/1aC9AUNNYYz36atE8BUJH4fZIfknHa9Pk?usp=sharing" rel="noopener ugc nofollow" target="_blank">Building complete agents</a></li></ol><h1 id="f209" class="ny nz fr bf oa ob oc gr od oe of gu og oh oi oj ok ol om on oo op oq or os ot bk">Introduction to the agents</h1><figure class="nh ni nj nk nl nm ou ov paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ou ov ow"><img src="../Images/e9d979f7bddb7cefa7b8a51fed6ea16f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3O1QAj_62FzWydQj.png"/></div></div><figcaption class="pc pd pe ou ov pf pg bf b bg z dx">Illustration by author. LLMs are often augmented with external memory via RAG architecture. Agents extend this concept to memory, reasoning, tools, answers, and actions</figcaption></figure><p id="188e" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">Let’s begin the lecture by exploring various examples of LLM agents. While the topic is widely discussed, few are actively utilizing agents; often, what we perceive as agents are simply large language models. Let’s consider such a simple task as <strong class="mm fs">searching for football game results and saving them as a CSV file</strong>. We can compare several available tools:</p><ul class=""><li id="7291" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ph nr ns bk"><strong class="mm fs">GPT-4 with search and plugins</strong>: as you will find in the <a class="af ng" href="https://chat.openai.com/share/2ecd61a9-dbd9-4287-aa75-14618106a34c" rel="noopener ugc nofollow" target="_blank">chat history here</a>, GPT-4 failed to do the task due to code errors</li><li id="dfa2" class="mk ml fr mm b gp nt mo mp gs nu mr ms mt nv mv mw mx nw mz na nb nx nd ne nf ph nr ns bk"><strong class="mm fs">AutoGPT</strong> through <a class="af ng" href="https://evo.ninja/" rel="noopener ugc nofollow" target="_blank">https://evo.ninja/</a> at least could generate some kind of CSV (not ideal though):</li></ul><figure class="nh ni nj nk nl nm ou ov paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ou ov pi"><img src="../Images/bf2d41707b6fd266beb26e4f705cd0ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sE-7Qc9j1Mb-tA8Wr5SjNA.png"/></div></div></figure><ul class=""><li id="5de0" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ph nr ns bk"><strong class="mm fs">AgentGPT</strong> through <a class="af ng" href="https://agentgpt.reworkd.ai/" rel="noopener ugc nofollow" target="_blank">https://agentgpt.reworkd.ai/</a>: decided to treat this task as a synthetic data generator which is not what we asked about, check the <a class="af ng" href="https://agentgpt.reworkd.ai/agent?id=clsyfh1t101t9jv08yaof890k" rel="noopener ugc nofollow" target="_blank">chat history here</a></li></ul><p id="5c18" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk"><strong class="mm fs">Since the available tools are not great</strong>, let’s learn from the first principles of how to build agents from scratch. I am using amazing <a class="af ng" href="https://lilianweng.github.io/posts/2023-06-23-agent/" rel="noopener ugc nofollow" target="_blank">Lilian’s blog article</a> as a structure reference but adding more examples on my own.</p><h1 id="b6d4" class="ny nz fr bf oa ob oc gr od oe of gu og oh oi oj ok ol om on oo op oq or os ot bk">Step 1: Planning</h1><figure class="nh ni nj nk nl nm ou ov paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ou ov pj"><img src="../Images/571a9bacf9092b0cc86e2cf8fa5d34ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yxAbOIUpirgInz-t.png"/></div></div><figcaption class="pc pd pe ou ov pf pg bf b bg z dx">The visual difference between simple “input-output” LLM usage and such techniques as a chain of thought, a chain of thought with self-consistency, a tree of thought</figcaption></figure><p id="64f7" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">You might have come across various techniques aimed at improving the performance of large language models, such as <a class="af ng" href="https://twitter.com/literallydenis/status/1730965217125839142" rel="noopener ugc nofollow" target="_blank">offering tips</a> or even jokingly threatening them. One popular technique is called “<a class="af ng" href="https://www.promptingguide.ai/techniques/cot" rel="noopener ugc nofollow" target="_blank">chain of thought</a>,” where the <strong class="mm fs">model is asked to think step by step, enabling self-correction</strong>. This approach has evolved into more advanced versions like the “<a class="af ng" href="https://www.promptingguide.ai/techniques/consistency" rel="noopener ugc nofollow" target="_blank">chain of thought with self-consistency</a>” and the generalized “<a class="af ng" href="https://medium.com/@astropomeai/implementing-the-tree-of-thoughts-in-langchains-chain-f2ebc5864fac" rel="noopener">tree of thoughts</a>,” <strong class="mm fs">where multiple thoughts are created, re-evaluated, and consolidated to provide an output</strong>.</p><p id="f826" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">In this tutorial, I am using heavily <a class="af ng" href="https://www.langchain.com/langsmith" rel="noopener ugc nofollow" target="_blank">Langsmith</a>, a platform for productionizing LLM applications. For example, while building the tree of thoughts prompts, I save my sub-prompts in the <strong class="mm fs">prompts repository</strong> and load them:</p><pre class="nh ni nj nk nl pk pl pm bp pn bb bk"><span id="bca6" class="po nz fr pl b bg pp pq l pr ps">from langchain import hub<br/>from langchain.chains import SequentialChain<br/><br/>cot_step1 = hub.pull("rachnogstyle/nlw_jan24_cot_step1")<br/>cot_step2 = hub.pull("rachnogstyle/nlw_jan24_cot_step2")<br/>cot_step3 = hub.pull("rachnogstyle/nlw_jan24_cot_step3")<br/>cot_step4 = hub.pull("rachnogstyle/nlw_jan24_cot_step4")<br/><br/>model = "gpt-3.5-turbo"<br/><br/>chain1 = LLMChain(<br/>    llm=ChatOpenAI(temperature=0, model=model),<br/>    prompt=cot_step1,<br/>    output_key="solutions"<br/>)<br/><br/>chain2 = LLMChain(<br/>    llm=ChatOpenAI(temperature=0, model=model),<br/>    prompt=cot_step2,<br/>    output_key="review"<br/>)<br/><br/>chain3 = LLMChain(<br/>    llm=ChatOpenAI(temperature=0, model=model),<br/>    prompt=cot_step3,<br/>    output_key="deepen_thought_process"<br/>)<br/><br/>chain4 = LLMChain(<br/>    llm=ChatOpenAI(temperature=0, model=model),<br/>    prompt=cot_step4,<br/>    output_key="ranked_solutions"<br/>)<br/><br/>overall_chain = SequentialChain(<br/>    chains=[chain1, chain2, chain3, chain4],<br/>    input_variables=["input", "perfect_factors"],<br/>    output_variables=["ranked_solutions"],<br/>    verbose=True<br/>)</span></pre><p id="fed9" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">You can see in <a class="af ng" href="https://github.com/Rachnog/intro_to_llm_agents/blob/main/1_planning.ipynb" rel="noopener ugc nofollow" target="_blank">this notebook</a> the result of such reasoning, the point I want to make here is the right process for defining your reasoning steps and versioning them in such <strong class="mm fs">an LLMOps system like Langsmith</strong>. Also, you can see other examples of popular reasoning techniques in public repositories like ReAct or Self-ask with search:</p><pre class="nh ni nj nk nl pk pl pm bp pn bb bk"><span id="e899" class="po nz fr pl b bg pp pq l pr ps">prompt = hub.pull("hwchase17/react")<br/>prompt = hub.pull("hwchase17/self-ask-with-search")</span></pre><p id="6dca" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">Other notable approaches are:</p><ul class=""><li id="a49a" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ph nr ns bk"><strong class="mm fs">Reflexion</strong> (<a class="af ng" href="https://arxiv.org/abs/2303.11366" rel="noopener ugc nofollow" target="_blank">Shinn &amp; Labash 2023</a>) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills.</li><li id="4433" class="mk ml fr mm b gp nt mo mp gs nu mr ms mt nv mv mw mx nw mz na nb nx nd ne nf ph nr ns bk"><strong class="mm fs">Chain of Hindsight</strong> (CoH; <a class="af ng" href="https://arxiv.org/abs/2302.02676" rel="noopener ugc nofollow" target="_blank">Liu et al. 2023</a>) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback.</li></ul><h1 id="3703" class="ny nz fr bf oa ob oc gr od oe of gu og oh oi oj ok ol om on oo op oq or os ot bk">Step 2: Memory</h1><figure class="nh ni nj nk nl nm ou ov paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ou ov pt"><img src="../Images/e3c6c61abf60034387cbdcb5f7007f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PYaUY5Cy4P7fUxFK.png"/></div></div><figcaption class="pc pd pe ou ov pf pg bf b bg z dx">We can map different types of memories in our brain to the components of the LLM agents' architecture</figcaption></figure><ul class=""><li id="07af" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ph nr ns bk"><strong class="mm fs">Sensory Memory:</strong> This component of memory captures immediate sensory inputs, like what we see, hear or feel. In the context of prompt engineering and AI models, a prompt serves as a transient input, similar to a momentary touch or sensation. It’s the initial stimulus that triggers the model’s processing.</li><li id="43de" class="mk ml fr mm b gp nt mo mp gs nu mr ms mt nv mv mw mx nw mz na nb nx nd ne nf ph nr ns bk"><strong class="mm fs">Short-Term Memory:</strong> Short-term memory holds information temporarily, typically related to the ongoing task or conversation. In prompt engineering, this equates to retaining the recent chat history. This memory enables the agent to maintain context and coherence throughout the interaction, ensuring that responses align with the current dialogue. <strong class="mm fs">In code, you typically add it as conversation history</strong>:</li></ul><pre class="nh ni nj nk nl pk pl pm bp pn bb bk"><span id="f52b" class="po nz fr pl b bg pp pq l pr ps">from langchain_community.chat_message_histories import ChatMessageHistory<br/>from langchain_core.runnables.history import RunnableWithMessageHistory<br/>from langchain.agents import AgentExecutor<br/>from langchain.agents import create_openai_functions_agent<br/><br/>llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)<br/>tools = [retriever_tool]<br/>agent = create_openai_functions_agent(<br/>    llm, tools, prompt)<br/>agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)<br/><br/>message_history = ChatMessageHistory()<br/>agent_with_chat_history = RunnableWithMessageHistory(<br/>    agent_executor,<br/>    lambda session_id: message_history,<br/>    input_messages_key="input",<br/>    history_messages_key="chat_history",<br/>)</span></pre><ul class=""><li id="b42c" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ph nr ns bk"><strong class="mm fs">Long-Term Memory:</strong> Long-term memory stores both factual knowledge and procedural instructions. In AI models, this is represented by the data used for training and fine-tuning. Additionally, long-term memory supports the operation of RAG frameworks, allowing agents to access and integrate learned information into their responses. It’s like the comprehensive knowledge repository that agents draw upon to generate informed and relevant outputs. <strong class="mm fs">In code, you typically add it as a vectorized database</strong>:</li></ul><pre class="nh ni nj nk nl pk pl pm bp pn bb bk"><span id="9adf" class="po nz fr pl b bg pp pq l pr ps">from langchain.text_splitter import RecursiveCharacterTextSplitter<br/>from langchain_community.document_loaders import WebBaseLoader<br/>from langchain_community.vectorstores import FAISS<br/>from langchain_openai import OpenAIEmbeddings<br/><br/>loader = WebBaseLoader("https://neurons-lab.com/")<br/>docs = loader.load()<br/>documents = RecursiveCharacterTextSplitter(<br/>    chunk_size=1000, chunk_overlap=200<br/>).split_documents(docs)<br/>vector = FAISS.from_documents(documents, OpenAIEmbeddings())<br/>retriever = vector.as_retriever()</span></pre><h1 id="ff40" class="ny nz fr bf oa ob oc gr od oe of gu og oh oi oj ok ol om on oo op oq or os ot bk">Step 3: Tools</h1><figure class="nh ni nj nk nl nm ou ov paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ou ov ow"><img src="../Images/6585f6b90c5882221fd42d4f294545e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RBAkErphxB2Pc2Md.png"/></div></div><figcaption class="pc pd pe ou ov pf pg bf b bg z dx">In practice, you want to augment your agent with a separate line of reasoning (which can be another LLM, i.e. domain-specific or another ML model for image classification) or with something more rule-based or API-based</figcaption></figure><p id="7964" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">ChatGPT <a class="af ng" href="https://openai.com/blog/chatgpt-plugins" rel="noopener ugc nofollow" target="_blank">Plugins</a> and <strong class="mm fs">OpenAI API</strong> <a class="af ng" href="https://platform.openai.com/docs/guides/gpt/function-calling" rel="noopener ugc nofollow" target="_blank">function calling</a> are good examples of LLMs augmented with tool use capability working in practice.</p><ul class=""><li id="cd80" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ph nr ns bk"><strong class="mm fs">Built-in Langchain tools</strong>: Langchain has a <a class="af ng" href="https://python.langchain.com/docs/integrations/tools/" rel="noopener ugc nofollow" target="_blank">pleiad of built-in tools</a> ranging from internet search and Arxiv toolkit to Zapier and Yahoo Finance. For this simple tutorial, we will experiment with the internet search provided by <a class="af ng" href="https://tavily.com/" rel="noopener ugc nofollow" target="_blank">Tavily</a>:</li></ul><pre class="nh ni nj nk nl pk pl pm bp pn bb bk"><span id="98c2" class="po nz fr pl b bg pp pq l pr ps">from langchain.utilities.tavily_search import TavilySearchAPIWrapper<br/>from langchain.tools.tavily_search import TavilySearchResults<br/><br/>search = TavilySearchAPIWrapper()<br/>tavily_tool = TavilySearchResults(api_wrapper=search)<br/><br/>llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.0)<br/>agent_chain = initialize_agent(<br/>    [retriever_tool, tavily_tool],<br/>    llm,<br/>    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,<br/>    verbose=True,<br/>)</span></pre><ul class=""><li id="bf8d" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ph nr ns bk"><strong class="mm fs">Custom tools</strong>: it’s also very easy to define your own tools. Let’s dissect the simple example of a tool that calculates the length of the string. You need to use the <code class="cx pu pv pw pl b">@tool</code>decorator to make Langchain know about it. Then, don’t forget about the type of input and the output. But the most important part will be the function comment between <code class="cx pu pv pw pl b">""" """</code> — this is how your agent will know what this tool does and will compare this description to descriptions of the other tools:</li></ul><pre class="nh ni nj nk nl pk pl pm bp pn bb bk"><span id="e340" class="po nz fr pl b bg pp pq l pr ps">from langchain.pydantic_v1 import BaseModel, Field<br/>from langchain.tools import BaseTool, StructuredTool, tool<br/><br/>@tool<br/>def calculate_length_tool(a: str) -&gt; int:<br/>    """The function calculates the length of the input string."""<br/>    return len(a)<br/><br/>llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.0)<br/>agent_chain = initialize_agent(<br/>    [retriever_tool, tavily_tool, calculate_length_tool],<br/>    llm,<br/>    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,<br/>    verbose=True,<br/>)</span></pre><p id="4af2" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">You can find examples of how it works <a class="af ng" href="https://github.com/Rachnog/intro_to_llm_agents/blob/main/3_tools.ipynb" rel="noopener ugc nofollow" target="_blank">in this script</a>, <strong class="mm fs">but you also can see an error </strong>— it doesn't pull the correct description of the Neurons Lab company and despite calling the right custom function of length calculation, the final result is wrong. Let’s try to fix it!</p><h1 id="1601" class="ny nz fr bf oa ob oc gr od oe of gu og oh oi oj ok ol om on oo op oq or os ot bk">Step 4: All together</h1><p id="c466" class="pw-post-body-paragraph mk ml fr mm b gp px mo mp gs py mr ms mt pz mv mw mx qa mz na nb qb nd ne nf fk bk">I am providing a clean version of combining all the pieces of architecture together <a class="af ng" href="https://github.com/Rachnog/intro_to_llm_agents/blob/main/4_agents.ipynb" rel="noopener ugc nofollow" target="_blank">in this script</a>. Notice, how we can easily decompose and define separately:</p><ul class=""><li id="ca2e" class="mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ph nr ns bk">All kinds of <strong class="mm fs">tools</strong> (search, custom tools, etc)</li><li id="dad9" class="mk ml fr mm b gp nt mo mp gs nu mr ms mt nv mv mw mx nw mz na nb nx nd ne nf ph nr ns bk">All kinds of <strong class="mm fs">memories</strong> (<strong class="mm fs">sensory</strong> as a prompt, <strong class="mm fs">short-term</strong> as runnable message history, and as a sketchpad within the prompt, and <strong class="mm fs">long-term</strong> as a retrieval from the vector database)</li><li id="ae25" class="mk ml fr mm b gp nt mo mp gs nu mr ms mt nv mv mw mx nw mz na nb nx nd ne nf ph nr ns bk">Any kind of <strong class="mm fs">planning strategy</strong> (as a <strong class="mm fs">part of a prompt</strong> pulled from the LLMOps system)</li></ul><p id="3da4" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">The final definition of the agent will look as simple as this:</p><pre class="nh ni nj nk nl pk pl pm bp pn bb bk"><span id="4273" class="po nz fr pl b bg pp pq l pr ps">llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)<br/>agent = create_openai_functions_agent(llm, tools, prompt)<br/>agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)<br/>agent_with_chat_history = RunnableWithMessageHistory(<br/>    agent_executor,<br/>    lambda session_id: message_history,<br/>    input_messages_key="input",<br/>    history_messages_key="chat_history",<br/>)</span></pre><p id="fb02" class="pw-post-body-paragraph mk ml fr mm b gp mn mo mp gs mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf fk bk">As you can see in the <a class="af ng" href="https://github.com/Rachnog/intro_to_llm_agents/blob/main/4_agents.ipynb" rel="noopener ugc nofollow" target="_blank">outputs of the script</a> (or you can run it yourself), it solves the issue in the previous part related to tools. What changed? We defined a <strong class="mm fs">complete architecture</strong>, where short-term memory plays a crucial role. Our agent obtained <strong class="mm fs">message history and a sketchpad as a part of the reasoning structure</strong> which allowed it to pull the correct website description and calculate its length.</p><h1 id="ce80" class="ny nz fr bf oa ob oc gr od oe of gu og oh oi oj ok ol om on oo op oq or os ot bk">Outro</h1><p id="5544" class="pw-post-body-paragraph mk ml fr mm b gp px mo mp gs py mr ms mt pz mv mw mx qa mz na nb qb nd ne nf fk bk">I hope this walkthrough through the core elements of the LLM agent architecture will help you design functional bots for the cognitive tasks you aim to automate. To complete, I would like to emphasize again the importance of having all elements of the agent in place. As we can see, missing short-term memory or having an incomplete description of a tool can mess with the agent’s reasoning and provide incorrect answers even for very simple tasks like summary generation and its length calculation. Good luck with your AI projects and don’t hesitate <a class="af ng" href="https://linktr.ee/alexhonchar" rel="noopener ugc nofollow" target="_blank">to reach out</a> if you need help at your company!</p></div></div></div></div>    
</body>
</html>