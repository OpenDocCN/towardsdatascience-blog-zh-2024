# 应对音乐AI中数据匮乏的三大实用技巧

> 原文：[https://towardsdatascience.com/3-practical-tips-to-combat-data-scarcity-in-music-ai-58e52c771aef?source=collection_archive---------6-----------------------#2024-05-22](https://towardsdatascience.com/3-practical-tips-to-combat-data-scarcity-in-music-ai-58e52c771aef?source=collection_archive---------6-----------------------#2024-05-22)

## 从你的音乐数据中获取更多

[](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)[![Max Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------) [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)

·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------) ·阅读时长11分钟·2024年5月22日

--

![](../Images/9346d558a628e376261a4172b6e0566a.png)

标题图像由作者使用DALL-E 2生成。

**标注音频数据在音乐AI中长期匮乏**。在这篇文章中，我将分享一些在这种情况下构建强大模型的技巧。

与计算机视觉或自然语言处理（NLP）等其他领域相比，寻找适合音乐AI的公共数据集通常是困难的。无论你是想进行情绪识别、噪音检测还是乐器标注，你都可能会在寻找合适的数据时遇到困难。

然而，数据匮乏不仅影响到业余程序员和学生。渴望发展的音乐技术初创公司甚至一些已建立的音乐公司也面临同样的问题。在AI时代，许多人**急切地尝试收集专有数据资源**以用于机器学习。

话虽如此，让我们深入探讨一下我的**从音乐数据中获取更多信息的三大技巧**。

# 提示1：应用自然数据增强

![](../Images/0726f6e00bcddac17f509fd4881f3af7.png)

横幅由作者使用DALL-E 2生成。

如果你是一名数据科学家，你可能听说过数据增强。基本的想法是从我们现有的数据集中获取现有样本，并稍微改变它们来生成**新的合成训练样本**。这个概念最容易通过图像来说明。例如，如果我们的数据集中包含一张猫的图片，我们可以通过平移和旋转原始猫的图片，轻松生成新的合成猫图像。

![](../Images/ef948ce570253f52a6174d1a32ef452f.png)

图像数据增强示例。图像灵感来源于[Suki Lau](/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2)，并由作者使用[Alexander London](https://unsplash.com/de/@alxndr_london)拍摄的猫的照片重新创作。

数据增强特别对**较小的数据集有效**。如果你的数据集只有100张猫的照片，那么所有可能的角度和旋转正确表示的几率就很低。这些数据集中的盲点将自动转化为AI感知和判断中的盲点。通过合成创建现有图像的变化，我们可以减轻这种风险。

## 数据增强在音乐AI中的不同之处

虽然数据增强在计算机视觉中是一个游戏规则改变者，但在音乐AI中，它**不那么直接**。音乐AI模型的最常见输入是声谱图（了解更多[这里](/getting-to-know-the-mel-spectrogram-31bca3e2d9d0)）。但你尝试过旋转和移动一个声谱图吗？

![](../Images/3da1b59b1f06533b6fe538653047eed5.png)

无效的音频数据增强示例。图像来自作者。

很容易看出，计算机视觉中的相同技巧不能直接应用于音乐AI。但为什么这个例子如此荒谬呢？答案是，与猫的例子相比，这种增强对于声谱图来说是**不自然的**。

当所做的变化代表了模型在**实际应用中**可能遇到的变化时，数据增强是自然的。虽然旋转一个声谱图显然会改变数据，但在视觉上它毫无意义，且在实际中永远不会发生。相反，我们需要为音乐数据找到特别的自然变化。

## 使用效果进行自然音频增强

最常见的自然音乐数据增强方法是对音频信号应用效果。每个音乐制作人都知道一堆来自数字音频工作站（DAW）的效果：

+   时间拉伸

+   音高移位

+   压缩器、限制器、失真

+   混响、回声、合唱

+   以及更多…

这些效果可以应用于任何音乐作品，改变数据同时保持其主要的音乐特征。如果你想知道如何在实践中实现这一点，**查看我关于这个话题的文章：**

[](/natural-audio-data-augmentation-using-spotifys-pedalboard-212ea59d39ce?source=post_page-----58e52c771aef--------------------------------) [## 使用Spotify的Pedalboard进行自然音频数据增强

### 提供现成的Python代码和预设

towardsdatascience.com](/natural-audio-data-augmentation-using-spotifys-pedalboard-212ea59d39ce?source=post_page-----58e52c771aef--------------------------------)

数据增强不仅在许多音乐AI研究论文中得到应用，我自己也取得了很好的效果。当数据稀缺时，数据增强可以**让你的模型从不可用转变为可接受**。即使数据量较大，它仍能增加一些额外的可靠性，这在生产环境中可能至关重要。

在实际实施音乐数据增强时，重要的是要牢记以下三点：

1.  **保持自然。** 增强后听一下你的数据，确保它听起来仍然自然。否则，模型可能会学习到错误的模式。

1.  **并非每个训练样本都应该被增强。** 为了确保你的模型主要从真实的、未被修改的音乐中学习，增强样本应仅占你训练数据的一部分（20%–30%）。你还可以在训练时使用样本加权来调整增强样本对模型的影响。

1.  **不要增强你的验证和测试数据。** 增强可以帮助模型学习通用的模式。你的验证和测试数据应该保持未修改，以便能够在真实示例上进行准确的基准测试。

是时候通过数据增强提升你的模型效果了！

# 提示 2：使用更小的模型和输入数据

![](../Images/5046d53a4c179647371dd557ac835595.png)

横幅由作者使用 DALL-E 2 生成。

## 更大 = 更好？

在 AI 中，更大通常意味着更好——前提是有足够的数据来训练这些大型模型。然而，数据有限时，**更大的模型更容易发生过拟合**。过拟合发生在模型记住了训练数据中的某些模式，但这些模式无法很好地推广到真实世界中的数据示例。但在这个背景下，我发现还有另一种方法值得考虑，这种方法甚至更有说服力。

假设你有一个小型的谱图数据集，并在选择一个小的 CNN 模型（10万参数）和一个大的 CNN 模型（1000万参数）之间做决定。记住，**每个模型参数实际上都是从训练数据集中得出的最佳猜测值**。如果我们这么想，显然让一个模型准确地获得10万个参数比准确地获得1000万个参数更容易。

最终，两个观点得出的结论是相同的：

> 如果数据稀缺，考虑构建专注于基本模式的小型模型。

那么，我们如何在实践中实现更小的模型呢？

## 不要用大锤砸胡桃

我的音乐 AI 学习之旅一直被深度学习主导。直到一年前，我几乎用大型神经网络解决了所有问题。虽然对于复杂的任务，如音乐标签或乐器识别，这样做是有道理的，**并不是所有任务都那么复杂**。

例如，一个不错的 BPM 估计器或调性检测器可以通过分析音符的开始时间，或者通过将色谱图与调性配置文件进行关联来构建，而不需要任何机器学习。

即使是像音乐标签这样的任务，也不一定非得使用深度学习模型。我通过一个简单的 K-近邻分类器在嵌入空间（例如 CLAP）上取得了很好的情绪标签结果。

尽管音乐 AI 中大多数最先进的方法都是基于深度学习的，**在数据稀缺的情况下，应该考虑替代解决方案**。

## 注意数据输入大小

比模型选择更重要的通常是输入数据的选择。在音乐AI中，我们很少使用原始波形作为输入，因为它们在数据效率上较低。通过将波形转换成（梅尔）声谱图，我们可以将输入数据的维度**减少100倍以上**。这很重要，因为大规模的数据输入通常需要更大和/或更复杂的模型来处理。

为了最小化模型输入的大小，我们可以采取两条路线

1.  **使用更小的音乐片段**

1.  **使用更压缩/简化的音乐表示。**

## 使用更小的音乐片段

使用较小的音乐片段尤其有效，如果我们关心的结果是全局性的，即适用于整首歌的每个部分。例如，我们可以假设一首歌曲的类型在整首歌的过程中保持相对稳定。因此，我们可以轻松地使用10秒钟的片段，而不是完整的歌曲（或者非常常见的30秒片段）来进行音乐类型分类任务。

这有两个优点：

1.  较短的片段意味着每个训练示例的数据点更少，这样可以使用更小的模型。

1.  通过绘制三个10秒的片段，而不是一个30秒的片段，我们可以将训练观察次数增加三倍。总的来说，这意味着我们可以构建更少依赖数据的模型，同时给它们提供比之前更多的训练示例。

然而，这里有**两个潜在的风险**。首先，片段大小必须足够长，才能进行有效的分类。例如，即使是人类，在面对3秒钟的片段时，也很难进行类型分类。我们应当仔细选择片段大小，并将这个决定视为我们AI解决方案的超参数。

其次，**并不是每个音乐属性都是全局性的**。例如，如果一首歌包含人声，并不意味着它就没有器乐部分。如果我们将歌曲切割成非常短的片段，我们就会在训练数据集中引入许多错误标签的例子。

## 使用更高效的音乐表示

如果你十年前学习过音乐AI（当时这一切还叫做“音乐信息检索”），你会了解到色度图、MFCC和节拍直方图。这些手工设计的特征旨在让音乐数据能够与传统的机器学习方法配合使用。随着深度学习的崛起，这些特征似乎已经**完全被（梅尔）声谱图所取代**。

声谱图将音乐压缩成图像，并且几乎没有信息丢失，这使得它们与计算机视觉模型**非常适配**。我们不再需要为不同任务设计定制的特征，而是可以使用相同的输入数据表示和模型来处理大多数音乐AI问题——前提是你有成千上万的训练示例来喂给这些模型。

当数据稀缺时，我们希望**尽可能压缩信息**，以便模型更容易从数据中提取出相关模式。请考虑以下四种音乐表示方式，并告诉我哪一种能帮助你最快地识别音乐的调性。

![](../Images/55215645b179c94abd112faf5942cbc9.png)

四种不同表示同一首歌（Tina Turner 的《Honky Tonk Woman》）的示例。尽管色调图比波形图小约 70 万，但它能更有效地帮助我们识别调性（C# 大调）。图像由作者创建。

尽管梅尔频谱图可以用作调性检测系统的输入（如果你有足够的数据，可能应该使用它），但沿时间维度平均的简单色调图能更快地揭示特定信息。这就是为什么频谱图需要像 CNN 这样的复杂模型，而色调图则可以通过传统模型，如逻辑回归或决策树，轻松分析的原因。

**总结**，已建立的频谱图 + CNN 组合在许多问题中仍然非常有效，只要你有足够的数据。然而，针对较小的数据集，可能需要重新审视一些来自 MIR 的特征工程技术，或开发自己特定任务的表示。

# 提示 3：利用预训练模型或嵌入

![](../Images/fa31b750c204546c8248df9e884c5e9d.png)

横幅由作者使用 DALL-E 2 生成。

当数据稀缺时，最有效的策略之一是利用预训练模型或嵌入。这种方法可以让你**在现有知识的基础上构建**，利用在大规模数据集上训练的模型，从而缓解较小数据集的限制。

## 为什么使用预训练模型？

预训练模型已经学会了从其训练数据中识别和提取有意义的特征。例如，一个在流派分类任务上训练的模型，很可能在训练过程中学到了多种**有意义的音乐模式**。如果我们现在想构建自己的情感标签模型，使用预训练的流派模型**作为起点**可能是有意义的。

如果预训练模型是在类似任务上训练的，你可以将它们学到的表示转移到你的特定任务中。这一过程被称为*迁移学习*。迁移学习可以大幅减少从零开始训练自己模型所需的数据量和计算资源。

## 音乐 AI 中的流行预训练模型

几年前，最常见的方法是使用像流派分类器这样的预训练模型，并将其微调以执行特定任务。像 [MusiCNN](https://github.com/jordipons/musicnn) 这样的模型通常被用于这种情况。

然而，现在更常见的是使用那些专门训练过的预训练模型，这些模型可以产生有意义的音乐嵌入，即歌曲的向量表示。以下是三种常用的预训练嵌入模型：

1.  [Mert-v1](https://huggingface.co/m-a-p/MERT-v1-330M) 由 m-a-p 提供

1.  [CLAP](https://huggingface.co/laion/clap-htsat-unfused) 由LAION提供

1.  [CLAP](https://github.com/microsoft/CLAP) 由微软提供

根据我个人的经验，使用微软的CLAP进行迁移学习，和使用LAION CLAP进行相似性搜索，效果最好。

## 利用预训练模型的不同方式

预训练模型可以以多种方式使用：

1.  **完全微调**：使用一个预训练的分类模型或嵌入模型，并在一个较小的任务特定数据集上进行微调。如果你能够使用完整的大型模型进行训练和推理，并且知道如何实现它，这种方法通常能获得最佳结果。

1.  **嵌入作为输入特征**：一种更高效的资源使用方法是从预训练模型中提取嵌入，并将它们作为新模型的输入。由于这些嵌入通常是500到1000维的向量，可以附加一个具有几千个参数的较小神经网络来进行更高效的微调。对于小型数据集，这种方法**通常优于完全微调**。

1.  **直接使用嵌入**：即使没有任何微调，嵌入也可以直接使用。例如，来自预训练模型的嵌入通常用于音乐相似性搜索。CLAP模型甚至可以用于文本到音乐的检索，或者（尽管效果还不理想）用于零-shot分类，即没有训练的分类。

利用预训练模型的嵌入可以显著增强你的音乐AI项目。通过在这些模型的学习模式识别基础上构建，你**避免了重新发明轮子**。当数据稀缺时，预训练模型应该始终被考虑。

# 结论

不要让数据稀缺成为你的阻碍！许多几年前需要成千上万训练样本的使用案例，现在几乎已经成为商品。

要在小数据集上实现稳健的性能，你的首要任务应该是不要浪费任何宝贵的数据。让我们回顾一下本文的要点：

1.  **数据增强**是一种让模型通过小但有效的变化多次从训练样本中学习的好方法，从而增强其鲁棒性。

1.  **更小的模型和更高效的数据表示**迫使你的模型专注于数据中最重要的、潜在的模式，从而避免过拟合。

1.  **预训练模型**让你通过微调借用一些来自更大AI系统的智能。再也不需要从头开始训练了！

当然，使用小数据集时你能实现的效果有其天然的局限性。如果你有100个标注样本，而你的目标是建立一个具有10个类别和30个子类别的多标签流派分类器，那么即使你使用了我所有的技巧，也不会走得太远。

尽管如此，我已经开发出了令人惊讶的能力强大的流派和情绪分类器，仅用1000首标注歌曲。仅仅两年前，凭借这么小的数据集实现这一目标几乎是不可能的。我认为，这些去中心化效应是当前AI热潮中最令人兴奋的方面之一。

> 如果你有一个小而高质量的音乐数据集，并且正在考虑用它进行机器学习，现在正是尝试的最佳时机！

# 对音乐 AI 感兴趣吗？

如果你喜欢这篇文章，或许你会想看看我其他的一些作品：

+   [“2024年值得期待的三大音乐AI突破”](https://medium.com/towards-data-science/3-music-ai-breakthroughs-to-expect-in-2024-2d945ae6b5fd)。Medium博客

+   [“生成式AI音乐中的人类元素”](https://www.youtube.com/watch?v=fr5PlnNGKVw)。Audiosocket播客视频采访

+   [“谷歌如何利用你的数据来改进其音乐AI”](https://medium.com/towards-data-science/how-google-used-your-data-to-improve-their-music-ai-8948a1e85491)。Medium博客

你还可以通过[Linkedin](https://www.linkedin.com/in/max-hilsdorf/)关注我，获取有关音乐AI的新论文和趋势的最新信息。

**感谢阅读本文！**
