# 为什么机器学习不适用于因果估计

> 原文：[https://towardsdatascience.com/why-machine-learning-is-not-made-for-causal-estimation-f2add4a36e85?source=collection_archive---------0-----------------------#2024-07-18](https://towardsdatascience.com/why-machine-learning-is-not-made-for-causal-estimation-f2add4a36e85?source=collection_archive---------0-----------------------#2024-07-18)

## 预测推断与因果推断：一个至关重要的区别

[](https://medium.com/@quentin.gallea?source=post_page---byline--f2add4a36e85--------------------------------)[![Quentin Gallea, PhD](../Images/457af55dd9c6121da7ec97f8e2991c43.png)](https://medium.com/@quentin.gallea?source=post_page---byline--f2add4a36e85--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f2add4a36e85--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f2add4a36e85--------------------------------) [Quentin Gallea, PhD](https://medium.com/@quentin.gallea?source=post_page---byline--f2add4a36e85--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f2add4a36e85--------------------------------) ·13分钟阅读·2024年7月18日

--

![](../Images/4b6605a18f5ad4bbdf67340018305b18.png)

图片由作者提供，使用 Dall-E 3 生成。

> *“如果你手里只有一把锤子，那么一切看起来都像钉子。”*

在人工智能/机器学习时代，机器学习常常被当作解决所有问题的万能工具。虽然机器学习在很多方面非常有用且重要，但它并非总是解决问题的最佳方案。

最重要的是，机器学习本质上是为了预测推断而设计的，这与因果推断有着本质的不同。预测模型是非常强大的工具，能够帮助我们发现模式和关联，但它们在解释事件发生的原因时力不从心。这正是因果推断发挥作用的地方，它能提供更为明智的决策依据，从而有效地影响结果，并超越简单的关联。

> 预测推断利用相关性。因此，如果你知道“相关性不代表因果关系”，你应该明白机器学习不应盲目用于衡量因果效应。

将预测推断误认为因果推断可能会导致代价高昂的错误，正如我们将共同看到的！为了避免犯这样的错误，我们将探讨这两种方法的主要区别，讨论使用机器学习进行因果估计的局限性，探索如何正确选择合适的方法，如何在解决问题的不同部分时，两者如何协同工作，并探讨如何在因果机器学习的框架下有效地整合两者。

## 本文将回答以下问题：

+   **什么是因果推断，什么是预测推断？**

+   **它们之间的主要区别是什么，为什么相关性不意味着因果关系？**

+   **为什么使用机器学习来推断因果效应是有问题的？**

+   **何时使用每种类型的推断？**

+   **如何将因果推断和预测推断结合使用？**

+   **什么是因果机器学习，它如何适应这个背景？**

# 什么是预测推断？

机器学习是关于预测的。

**预测推断**涉及基于其他变量的值（如它们的实际值）来估计某个事物（结果）的值。如果你看向窗外，人们戴着手套和帽子，那很可能是冷的。

**示例：**

+   **垃圾邮件过滤：**机器学习算法被用来根据电子邮件的内容、发件人以及其他附加信息来过滤安全邮件和垃圾邮件。

+   **肿瘤检测：**机器学习（深度学习）可以用于通过MRI图像检测脑肿瘤。

+   **欺诈检测：**在银行业，机器学习被用来根据信用卡活动检测潜在的欺诈行为。

**偏差-方差：**在预测推断中，你希望有一个能够很好地预测结果的模型，大部分时间能在样本外（使用新数据）进行预测。如果偏差能使预测的方差降低，你可能会接受一些偏差。

# 什么是因果推断？

因果推断是研究因果关系的学科，它关注的是影响评估。

**因果推断**旨在衡量当你改变其他事物的值时，结果的值会发生什么变化。在因果推断中，你想知道如果改变某个变量（特征）的值，而其他条件保持不变，会发生什么。这与预测推断完全不同，后者是试图根据特征的不同观测值预测结果的值。

**示例：**

+   **营销活动投资回报率：**因果推断帮助衡量营销活动（原因）对营销效果（后果）的影响。

+   **政治经济学：**因果推断通常被用来衡量政策（原因）对结果（后果）的影响。

+   **医学研究：**因果推断是衡量药物或行为（原因）对健康结果（后果）影响的关键。

**偏差-方差：**在因果推断中，你不关注预测的质量，比如R方等指标。因果推断旨在衡量一个无偏的系数。即使预测能力较低，只要因果效应能够解释结果方差的一小部分，也有可能构建出一个有效的因果推断模型。

**关键概念差异：**因果推断的复杂性在于，我们想要衡量的东西是我们永远无法实际观察到的。要衡量因果效应，你需要一个参考点：反事实。反事实是没有治疗或干预的世界。因果效应通过将观察到的情况与这个参考（反事实）进行比较来衡量。

假设你头痛。你服下了一颗药丸，过了一会儿，头痛消失了。但这真的是药丸的作用吗？是因为你喝了茶或大量水吗？还是仅仅因为时间过去了？我们无法知道哪个因素或哪些因素的组合起了作用，因为这些效应是混杂在一起的。唯一能够完美回答这个问题的方法是拥有两个平行世界。在两个世界中，一个你服用了药丸，另一个你没有服用药丸。因为药丸是这两种情况之间唯一的不同，所以它能让你声称它是因果关系的原因。但显然，我们没有平行世界可以进行实验。在因果推断中，我们称之为：**因果推断的基本问题**。

![](../Images/128b83f7913ca95a4e03a2ffe56a19c5.png)

理想情况下，我们需要平行世界来衡量因果效应。图像来源：作者。

因此，因果推断的整个思想是通过找到一个好的反事实来接近这个不可能的理想平行世界情况。这就是为什么黄金标准是随机实验。如果你在一个有代表性的群体中随机分配治疗（药丸与安慰剂），那么唯一的系统性差异（假设所有操作都是正确的）就是治疗方式，因此，结果的统计显著差异可以归因于治疗。

![](../Images/d708cfe92c4d6173b98708d6f54ce176.png)

随机实验的示意图。图像来源：作者。

请注意，随机实验也有其局限性，且通过观察数据也可以衡量因果效应。如果你想了解更多，我在这里深入解释了这些概念和因果推断：

[](/the-science-and-art-of-causality-part-1-5d6fb55b7a7c?source=post_page-----f2add4a36e85--------------------------------) [## 因果关系的科学与艺术（第一部分）

### 如果我们无法直接测试因果关系，我们该怎么办？

[towardsdatascience.com](/the-science-and-art-of-causality-part-1-5d6fb55b7a7c?source=post_page-----f2add4a36e85--------------------------------)

# 为什么相关性不意味着因果关系？

我们都知道“相关性不意味着因果关系”。但是，为什么呢？

有两种主要情况。首先，如下面的案例1所示，溺水事故和冰淇淋销售之间的正相关可能仅仅是由于一个共同原因：天气。当阳光明媚时，这两者都会发生，但溺水事故和冰淇淋销售之间并没有直接的因果关系。这就是我们所说的虚假相关。第二种情况如案例2所示。教育对表现有直接影响，但认知能力影响两者。所以在这种情况下，教育与工作表现之间的正相关与认知能力的影响是混杂在一起的。

![](../Images/b6b2497b7a2a72016b8143e4e6e77886.png)

“相关性不意味着因果关系”的主要原因。箭头代表因果图中的因果关系方向。图像来源：作者。

正如我在介绍中提到的，预测推断利用的是相关性。因此，任何知道“相关性不代表因果性”的人应该明白，机器学习本质上并不适合因果推断。冰淇淋销售可能是溺水事故当天风险的**良好预测因子**，即使它们之间**没有因果关系**。这种关系只是相关性，并由一个共同原因——天气——驱动。

然而，如果你想研究冰淇淋销售对溺水事故的潜在因果影响，你必须考虑到这个第三变量（天气）。否则，由于著名的遗漏变量偏差，你对因果关系的估计将会有偏差。一旦你将这个第三变量纳入分析，你很可能会发现冰淇淋销售对溺水事故不再有影响。通常，解决这一问题的简单方法是将这个变量包含在模型中，这样它就不再是“遗漏”的。然而，混杂变量通常是不可观察的，因此无法简单地将其纳入模型中。因果推断有多种方法来解决这一问题，但讨论这些超出了本文的范围。如果你想了解更多关于因果推断的内容，你可以参考我的指南，点击这里：

[](/how-to-learn-causal-inference-on-your-own-for-free-98503abc0a06?source=post_page-----f2add4a36e85--------------------------------) [## 如何免费自学因果推断

### 针对所有级别的终极自学指南

towardsdatascience.com](/how-to-learn-causal-inference-on-your-own-for-free-98503abc0a06?source=post_page-----f2add4a36e85--------------------------------)

> 因此，因果推断与预测推断之间的一个核心区别在于如何选择“特征”。

在机器学习中，你通常会包括可能提高预测质量的特征，且你的算法可以根据预测能力来帮助选择最佳特征。然而，在因果推断中，一些特征必须无论如何都要包括在内（如混杂变量/共同原因），即使它们的预测能力较低，且效应在统计上不显著。混杂变量的主要兴趣点不是它的预测能力，而是它如何影响我们研究的因果关系的系数。此外，有些特征不应包括在因果推断模型中，例如中介变量。中介变量代表了间接的因果路径，控制这些变量会妨碍我们测量感兴趣的总因果效应（见下图）。因此，主要区别在于，因果推断中是否包括某个特征取决于变量之间假设的因果关系。

![](../Images/22306ceaf8d5284aea4098b5dbbc4ea3.png)

中介变量的示例。这里，动机是训练对生产力影响的中介变量。假设员工培训直接提高了他们的生产力，但也通过他们的动机间接提高生产力。员工现在更有动力，因为他们学到了新技能，并看到雇主在员工技能提升方面投入了努力。如果你想衡量培训的效果，大多数时候，你需要衡量治疗的总效果（直接和间接），而将动机作为控制变量会阻止你这样做。图片来源：作者。

这是一个微妙的话题。有关更多细节，请参考[“好与坏控制的速成课程” Cinelli等（2002）](https://ftp.cs.ucla.edu/pub/stat_ser/r493.pdf)。

# 为什么使用机器学习推断因果效应是有问题的？

假设你将冰淇淋销售和溺水事故之间的正相关关系解释为因果关系。你可能会想方设法禁止冰淇淋。但当然，这可能对结果几乎没有影响。

一个著名的相关性是巧克力消费与诺贝尔奖得主之间的关系[(Messerli (2012))](https://www.biostat.jhsph.edu/courses/bio621/misc/Chocolate%20consumption%20cognitive%20function%20and%20nobel%20laurates%20(NEJM).pdf)。作者发现，在国家层面，巧克力消费与诺贝尔奖得主之间存在0.8的线性相关系数。虽然这听起来是一个吃更多巧克力的好理由，但它不应被解释为因果关系。（请注意，Messerli（2012）中提出的潜在因果关系的论点后来被推翻了（例如，[P Maurage等人（2013）](https://pubmed.ncbi.nlm.nih.gov/23616517/)）。

![](../Images/97a0dbb3e33556c6fa6d8fd4cfa6e5bc.png)

诺贝尔奖得主与每百万人口巧克力消费（千克/年/人）之间的正相关关系（见Messerli（2012））。图片来源：作者。

现在让我分享一个更为严肃的例子。假设你试图优化一个内容创作者的帖子。为此，你构建了一个包含众多特征的机器学习模型。分析结果表明，下午晚些时候或晚上发布的帖子表现最好。因此，你推荐一个精确的时间表，让你仅在下午5点到晚上9点之间发布帖子。然而，一旦实施后，每个帖子的展示量却急剧下降。发生了什么？机器学习算法基于当前模式进行预测，按数据的表面情况进行解读：晚些时候发布的帖子与更高的展示量相关联。最终，晚上发布的帖子往往是更具自发性、不太有计划的，作者并不是特别为了迎合观众，而是分享一些有价值的内容。所以，问题不在于时间，而在于帖子的性质。这种自发的性质可能很难通过机器学习模型捕捉到（即使你编码了一些特征，如长度、语气等，也可能不容易捕捉到这一点）。

在营销中，预测模型通常用于衡量营销活动的投资回报率（ROI）。

> 通常，像简单的 **营销组合建模（MMM）** 这样的模型会受到遗漏变量偏差的影响，ROI 的衡量会产生误导。

通常，竞争对手的行为可能与我们的营销活动相关联，并且也会影响我们的销售。如果没有正确考虑这一点，投资回报率（ROI）可能会被低估或高估，导致次优的商业决策和广告支出。

这个概念对于政策和决策制定也非常重要。在 Covid-19 大流行初期，一位法国“专家”使用一张图表来论证封锁政策是适得其反的（见下图）。图表显示封锁措施的严格程度与 Covid-19 相关死亡人数之间存在正相关关系（更严格的封锁与更多的死亡相关）。然而，这种关系很可能是由相反的因果关系推动的：当情况严重（死亡人数多）时，各国会实施严格措施。这被称为逆向因果关系。实际上，当你正确地研究一个国家在封锁期间病例和死亡人数的变化，并控制潜在的混杂因素时，你会发现一个强烈的负面影响（参见 [Bonardi et al. (2023)](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2022.4652)）。

![](../Images/ee131f954f320b94dea06a8f9aa406df.png)

重复使用图表来论证封锁措施无效。绿色表示最低封锁措施，红色表示最严格的封锁措施。图片由作者提供。

# 每种类型的推论应该在什么情况下使用？

> 机器学习和因果推论都是非常有用的；它们只是服务于不同的目的。

和数字及统计数据一样，问题通常不在于度量本身，而在于它们的解释。因此，相关性是有价值的信息，但只有在你盲目地将其解释为因果效应时，它才会变得有问题。

**何时使用因果推论：** 当你想理解因果关系并进行影响评估时。

+   **政策评估：** 用于确定新政策的影响，例如新教育项目对学生表现的影响。

+   **医学研究：** 用于评估新药物或治疗对健康结果的有效性。

+   **经济学：** 用于理解利率变化对通货膨胀或就业等经济指标的影响。

+   **营销：** 用于评估营销活动对销售的影响。

**因果推论中的关键问题：**

+   X 对 Y 的影响是什么？

+   改变 X 会导致 Y 的变化吗？

+   如果我们对 X 进行干预，Y 会发生什么变化？

**何时使用预测推论：** 当你想进行准确的预测（特征与结果之间的关联）并从数据中学习模式时。

+   **风险评估：** 用于预测信用违约或保险索赔的可能性。

+   **推荐系统：** 基于用户的过去行为向其推荐产品或内容。

+   **诊断：** 用于疾病检测的医学图像分类。

**预测推断的关键问题：**

+   给定X，Y的期望值是多少？

+   我们能否基于关于X的新数据预测Y？

+   我们能够多准确地使用当前和历史上的X数据来预测Y？

# 如何将因果推断和预测推断结合使用？

虽然因果推断和预测推断有不同的目的，但它们有时会一起工作。Dima Goldenberg，Booking.com的高级机器学习经理，在与Aleksander Molak（《Python中的因果推断与发现》一书的作者）的一次[podcast](https://www.youtube.com/watch?v=xkx1tXLAP-o)中完美地展示了这一点。

Booking.com显然在推荐系统方面下了很大功夫。“推荐”是一个预测问题：“客户X更倾向于看到哪种类型的产品？”因此，这一步通常通过机器学习来解决。然而，还有一个相关的问题：“这个新推荐系统对销售/转化等方面的影响是什么？”在这里，**“effect … on”** 这个关键词应该让你意识到，第二步必须使用因果推断来解决。此步骤将需要因果推断，准确来说是随机实验（A/B 测试）。

> 这是一个典型的工作流程，展示了机器学习和因果推断的互补角色。你通过机器学习开发预测模型，然后通过因果推断评估其影响。

# 那么，因果机器学习是什么，它在这个背景下如何发挥作用？

最近，出现了一个新领域：因果机器学习。虽然这是一个重要的突破，但我认为它增加了混淆。

> 很多人看到“因果机器学习（Causal ML）”这个术语时，往往误以为可以随便使用机器学习进行因果推断。

因果机器学习是两者世界的优雅结合。然而，因果机器学习并不是盲目地使用机器学习进行因果推断。它实际上是将机器学习与因果推断结合在一起，以提高结果。因果推断的关键区别概念在因果机器学习中依然有效。特征选择依赖于假设的因果关系。

让我展示因果机器学习中的两种主要方法，来说明这种有趣的结合。

## A. 处理高维数据和复杂的函数形式

在某些情况下，你的因果推断模型中有大量的控制变量。为了减少遗漏变量偏误的风险，你加入了许多潜在的混杂因素。该如何处理这么多的控制变量呢？也许你在一组控制变量之间有多重共线性，或者也许你应该控制非线性效应或交互效应。这很快就会变得非常复杂，并且使用传统的因果推断方法来解决可能显得非常随意。

由于机器学习在处理高维数据方面特别高效，它可以用来应对这些挑战。机器学习将被用于找到最佳的控制组和正确的函数形式，以确保模型不会遭受多重共线性问题，同时仍能满足衡量因果效应的条件（见：双重机器学习方法）。

## B. 异质性处理效应

因果推断历史上专注于衡量平均处理效应（ATE），这是治疗平均效果的一个衡量标准。然而，正如你一定知道的，平均值是有用的，但它也可能具有误导性。治疗的效果可能会根据受试者的不同而导致不同的效果。想象一下，一种新药物平均能显著降低癌症风险，但实际上，整个效果是由男性的结果推动的，而对女性的效果则为零。或者，想象一下一个营销活动，虽然总体上提高了转化率，但实际上在某些特定区域却产生了负面影响。

> 因果机器学习使我们能够超越平均处理效应，揭示这种异质性，通过识别条件平均处理效应（CATE）。换句话说，它有助于识别不同受试者特征条件下的处理效应。

揭示条件平均处理效应的主要方法叫做因果森林。然而，需要注意的是，尽管这种方法可以帮助我们找到对治疗有不同反应的子群体，但通过机器学习揭示的这些群体的特征不一定是因果的。想象一下，模型揭示广告对智能手机用户和对平板用户的效果完全不同。‘设备’不应被解读为这种差异的原因。可能真正的原因并未被测量，但与这一特征相关，例如，年龄。

# 结论

如今，区分预测与因果推断是至关重要的，这可以避免在营销、政策制定和医学研究等多个领域出现代价高昂的错误。我们探讨了为何尽管机器学习具有显著的预测能力，但由于它依赖于相关性/关联性而非因果关系，它本质上并不适合因果推断。希望你能够理解这一区分，并为不同类型的问题选择合适的模型。

![](../Images/630306462fc50e607b6531c292a14222.png)

说明为何将相关性误认为因果效应会导致糟糕的决策。图片来源：War and Peas，Elizabeth Pich 和 Jonathan Kunz。

如果你想了解更多关于因果机器学习的内容，这里有一些有价值且可靠的**资源：**

**因果机器学习：**

+   [营销中的因果机器学习](https://ijbms.net/assets/files/1721058154.pdf)

+   [机器学习对因果推断的价值：来自重新审视的研究的证据](https://arxiv.org/abs/2101.00878)

+   [预测治疗结果的因果机器学习](https://www.nature.com/articles/s41591-024-02902-1)

**双重机器学习：**

+   [Matheus Facure 书籍章节](https://matheusfacure.github.io/python-causality-handbook/22-Debiased-Orthogonal-Machine-Learning.html)

+   [展示该方法论的研究论文](https://arxiv.org/abs/1608.00060)

**异质性治疗效应：**

+   [Matheus Facure 书籍章节](https://matheusfacure.github.io/python-causality-handbook/18-Heterogeneous-Treatment-Effects-and-Personalization.html)

+   [斯坦福大学 Susan Athe 课堂](https://www.gsb.stanford.edu/faculty-research/labs-initiatives/sil/research/methods/ai-machine-learning/short-course)
