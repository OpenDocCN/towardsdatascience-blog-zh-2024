# 使用爬山算法解决经典的世界大赛下注问题

> 原文：[https://towardsdatascience.com/solving-the-classic-betting-on-the-world-series-problem-using-hill-climbing-5e9766e1565d?source=collection_archive---------2-----------------------#2024-11-10](https://towardsdatascience.com/solving-the-classic-betting-on-the-world-series-problem-using-hill-climbing-5e9766e1565d?source=collection_archive---------2-----------------------#2024-11-10)

## 一个简单的爬山算法示例——解决一个在没有优化技术的帮助下很难解决的问题

[](https://medium.com/@wkennedy934?source=post_page---byline--5e9766e1565d--------------------------------)[![W Brett Kennedy](../Images/b3ce55ffd028167326c117d47c64c467.png)](https://medium.com/@wkennedy934?source=post_page---byline--5e9766e1565d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5e9766e1565d--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5e9766e1565d--------------------------------) [W Brett Kennedy](https://medium.com/@wkennedy934?source=post_page---byline--5e9766e1565d--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5e9766e1565d--------------------------------) ·15分钟阅读·2024年11月10日

--

世界大赛下注是一个古老、有趣且富有挑战性的谜题。这也是一个很好的问题，可以用来展示一种叫做爬山算法的优化技术，我将在本文中详细介绍。

爬山算法是一种成熟且相对直接的优化技术。网上有许多其他的示例应用它，但我认为这个问题提供了一个有趣的应用案例，值得深入研究。

这个谜题可以在[UC Davis](https://www.math.ucdavis.edu/~gravner/MAT135A/resources/chpr.pdf)的网页上看到。为了省去你查找的麻烦，我在这里重复一遍：

> [E. Berlekamp] 赌注在世界大赛上。你是一个经纪人；你的工作是满足客户的要求，同时不让个人资本承担任何风险。你的客户希望在世界大赛的结果上下注1,000美元，这是一场棒球比赛，决出先赢得4场比赛的其中一个队伍。也就是说，客户在大赛开始前将1,000美元存入你这里。比赛结束时，如果他的队伍获胜，他需要从你这里获得2,000美元，如果他的队伍失败，则什么也得不到。没有针对整个世界大赛的市场。但你可以在每场比赛上分别下注，金额可以相等。你的策略是什么，以便在单场比赛中下注，从而实现客户要求的累计结果？

所以，有必要逐场进行投注（虽然也可以选择跳过某些比赛，只对这些比赛下注$0）。每场比赛后，我们将获得或失去正好是我们对该场比赛下注的金额。我们从客户提供的$1000开始。如果我们的队伍赢得了整个系列赛，我们希望最终余额为$2000；如果他们输了，我们希望最终余额为$0。

如果你之前没有见过这个问题，并且希望尝试手动解决，现在是一个机会，在我们介绍如何通过编程解决之前。这个问题本身非常有趣，直接尝试解决它是值得的，之后再考虑使用爬坡算法。

# 接近问题的解决

对于这个问题，我假设暂时亏损是可以接受的。也就是说，在世界大赛期间，如果我们的余额降到零以下，这是可以的（我们是一家规模较大的经纪公司，可以撑过去），只要我们最终能够确保余额为$0或$2000。然后，我们将$0或$2000返还给客户。

为这个问题提出一个大多数情况下有效的解决方案是相对简单的，但并不一定适用于每种情况。实际上，我在网上看到过一些关于这个谜题的描述，它们提供了一些解决方案的草图，但似乎并没有完全测试所有可能的胜负序列。

一种下注策略的示例是：$125、$250、$500、$125、$250、$500、$1000。在这个策略中，我们对第一场比赛下注$125，对第二场比赛下注$250，以此类推，直到比赛结束。例如，如果系列赛只进行五场比赛，我们下注的金额将是：$125、$250、$500、$125、$250。这个策略在大多数情况下有效，尽管不是对所有情况都适用。

考虑以下序列：1111，其中0表示团队0赢得一场比赛，1表示团队1赢得一场比赛。在这个序列中，团队1赢得了四场比赛，因此赢得了系列赛。假设我们的队伍是团队1，那么我们需要最终余额为$2000。

查看比赛、下注和每场比赛后所持有的金额，我们得到：

```py
Game    Bet  Outcome   Money Held
----    ---   ----     ----------
Start    -     -         1000
1       125    1         1125
2       250    1         1375
3       500    1         1875
4       125    1         2000
```

也就是说，我们从$1000开始。我们在第一场比赛下注$125。团队1赢得了那场比赛，所以我们赢得了$125，现在我们有$1125。接着我们在第二场比赛下注$250。团队1再次获胜，我们赢得$250，现在我们有$1375。接下来，我们对接下来的两场比赛分别下注$500和$125。在这种情况下，我们最终正确地拥有$2000。

测试序列0000（其中团队0在四场比赛中获胜）：

```py
Game    Bet  Outcome  Money Held
----    ---   ----    ----------
Start    -     -        1000
1       125    0         875
2       250    0         625
3       500    0         125
4       125    0           0
```

在这里，我们正确地（假设团队0赢得了系列赛）最终余额为$0。

测试序列0101011（其中团队1在七场比赛中获胜）：

```py
Game    Bet  Outcome  Money Held
----    ---   ----    ----------
Start    -     -        1000
1       125    0         875
2       250    1        1125 
3       500    0         625
4       125    1         750
5       250    0         500 
6       500    1        1000
7      1000    1        2000
```

在这里，我们再次正确地最终拥有$2000。

然而，在序列1001101中，这个策略无法奏效：

```py
Game    Bet  Outcome  Money Held
----    ---   ----    ----------
Start    -    -        1000
1       125   1        1125 
2       250   0         875
3       500   0         375
4       125   1         500
5       250   1         750
6       500   0         250
7      1000   1        1250
```

这里，尽管团队1赢得了系列赛（在7场比赛中赢得4场），但最终我们只有$1250，而不是$2000。

# 测试某个给定的策略

由于比赛序列可能有很多种，这使得手动测试变得非常困难（而且在测试许多可能的策略时也非常繁琐），所以接下来我们将开发一个函数来测试给定的策略是否正常工作：即它是否能正确地在队伍1赢得系列赛时最终保持至少$2000，在队伍0赢得系列赛时保持至少$0。

这个策略以一个七个数字的数组形式传入，表示在七场比赛中每场的投注金额。在只有四场、五场或六场比赛的系列赛中，策略数组中最后几项的值将不会被使用。上述策略可以表示为[125, 250, 500, 125, 250, 500, 1000]。

```py
def evaluate_policy(policy, verbose=False):    
    if verbose: print(policy)
    total_violations = 0

    for i in range(int(math.pow(2, 7))):
        s = str(bin(i))[2:]
        s = '0'*(7-len(s)) + s  # Pad the string to ensure it covers 7 games
        if verbose: 
          print()
          print(s)

        money = 1000
        number_won = 0
        number_lost = 0
        winner = None

        for j in range(7):
            current_bet = policy[j]

            # Update the money
            if s[j] == '0':
                number_lost += 1
                money -= current_bet
            else:
                number_won += 1
                money += current_bet
            if verbose: print(f"Winner: {s[j]}, bet: {current_bet}, now have: {money}")

            # End the series if either team has won 4 games
            if number_won == 4:
                winner = 1
                break
            if number_lost == 4:
                winner = 0
                break

        if verbose: print("winner:", winner)
        if (winner == 0) and (money < 0):
            total_violations += (0 - money)
        if (winner == 1) and (money < 2000):
            total_violations += (2000 - money)

    return total_violations
```

这从创建每种可能的胜负序列的字符串表示开始。这样会创建一个由2⁷（128）个字符串组成的集合，字符串从‘0000000’开始，然后是‘0000001’，依此类推，直到‘1111111’。其中一些是冗余的，因为某些序列会在七场比赛之前结束——一旦某个队伍赢得四场比赛。在实际生产中，我们可能会清理这些冗余序列以减少执行时间，但为了简化，我们仅仅遍历所有2⁷种组合。这在后续有一些好处，因为它平等对待所有2⁷（同样可能的）组合。

对于这些可能的序列，我们应用策略来确定每场比赛的投注，并持续跟踪所持有的资金。也就是说，我们遍历所有2⁷种可能的胜负序列（直到某个队伍赢得四场比赛为止），对于每个序列，我们遍历序列中的每场比赛，逐场进行投注。

最终，如果队伍0赢得了系列赛，我们理想中的金额是$0；如果队伍1赢得了系列赛，我们理想中的金额是$2000，虽然如果超过这个金额也没有惩罚（或好处）。

如果我们在一场比赛序列结束时没有得到正确的资金数额，我们将确定短缺的金额；这就是该序列的成本。我们将所有可能的比赛序列中的短缺金额加起来，从而得到对该策略总体表现的评估。

要确定给定的策略是否正常工作，我们可以简单地调用此方法并传入给定的策略（以数组形式），然后检查它是否返回0。返回值大于0表示存在一个或多个序列，其中经纪人最终剩余的资金过少。

# 山地攀登

我不会过多详细讨论山地攀登法，因为它已经被广泛理解并且在许多地方有详细文档，但我会快速描述其基本思想。山地攀登是一种优化技术。我们通常从生成问题的候选解决方案开始，然后在小的步骤中修改它，每一步都会得到更好的解决方案，直到我们最终达到最优解（或者被困在局部最优解中）。

为了解决这个问题，我们可以从任何可能的策略开始。例如，我们可以从[-1000, -1000, -1000, -1000, -1000, -1000, -1000]开始。这个特定的策略肯定效果不好——我们实际上会在所有七场比赛中对Team 1下注很多。但这没关系。爬山法是从任何地方开始，然后逐步朝更好的解决方案移动，因此即使从一个糟糕的解决方案开始，我们最终也理想地会达到一个强的解决方案。尽管如此，在某些情况下，我们可能无法达到最优解，有时需要（或至少有用）从不同的起点重新运行爬山算法。在这种情况下，从一个非常糟糕的初始策略开始也没问题。

在编写代码之前先手动操作这个难题，我们可能得出结论，一个策略比单纯的七个值的数组要复杂一些。那种策略形式完全基于是哪场比赛来决定每次下注的大小，而忽略了到目前为止的胜负记录。我们实际需要表示策略的是一个二维数组，如下所示：

```py
[[-1000, -1000, -1000, -1000, -1000, -1000, -1000],
 [-1000, -1000, -1000, -1000, -1000, -1000, -1000],
 [-1000, -1000, -1000, -1000, -1000, -1000, -1000],
 [-1000, -1000, -1000, -1000, -1000, -1000, -1000]]
```

还有其他方法可以做到这一点，但正如我们下面所展示的，这种方法效果相当好。

这里，行表示到目前为止Team 1的获胜场数：0、1、2或3。列，如前所述，表示当前的比赛编号：1、2、3、4、5、6或7。

再次说明，在这个策略中，我们会在每场比赛中都对Team 1下注$1000，无论如何，因此几乎任何随机策略都可能稍微好一点。

这个策略有4x7，或者说28个值。虽然其中一些是多余的，可以优化一下。我选择了简单而不是高效，但一般来说，在生产环境中我们会进行更多优化。在这种情况下，我们可以去除一些不可能的情况，比如在第5、6或7场比赛中有0场胜利（如果第5场比赛时Team 1没有胜利，Team 0必须有4场胜利，从而结束系列赛）。28个单元格中有12个实际上是无法达到的，其余的16个是相关的。

为了简单起见，在这个例子中没有使用，但实际上相关的字段如下，我已放置了-1000：

```py
[[-1000, -1000, -1000, -1000,  n/a,   n/a,   n/a ],
 [ n/a,  -1000, -1000, -1000, -1000,  n/a,   n/a ],
 [ n/a,   n/a,  -1000, -1000, -1000, -1000,  n/a ],
 [ n/a,   n/a,   n/a,  -1000, -1000, -1000, -1000]]
```

标记为“n/a”的单元格不相关。例如，在第一场比赛中，不可能已经有1、2或3场胜利；那时只能有0场胜利。另一方面，到第四场比赛时，可能已经有0、1、2或3场胜利。

在编写任何代码之前，如果先手动操作一下，就能看到每个下注额很可能是$1000的二分之一、四分之一、八分之一、十六分之一等等的倍数。虽然这不一定是最优解，但我将假设所有的下注都是$500、$250、$125、$62.50或$31.25的倍数，并且它们可能是$0。

不过，我假设永远没有反对Team 1下注的情况；虽然初始策略以负数下注开始，但生成新候选策略的过程只使用$0到$1000之间（包括$0和$1000）的下注额。

因此，每个投注有33种可能的值（从$0到$1000的每个$31.25的倍数）。考虑到完整的28个单元格，并假设投注是31.25的倍数，那么政策可能的组合数为33²⁸。所以，测试所有可能的组合是不可行的。如果将其限制为使用的16个单元格，仍然有33¹⁶种可能的组合。可能会有进一步的优化，但无论如何，要全面检查所有的组合，数量极其庞大，远远超出可行的范围。也就是说，直接用程序解决这个问题是可能的，但如果仅依赖于这里假设的条件，暴力破解法将是无法处理的。

因此，像爬山算法这样的优化技术在这里非常适用。通过从解决方案空间的一个随机位置开始（一个随机的政策，以4x7矩阵的形式表示），不断地（比喻地）向上移动（每次我们都朝着一个比之前稍微更好的解决方案前进），最终我们到达最高点，在这种情况下就是一个适用于世界系列投注问题的可行政策。

# 评估方法的更新

鉴于政策将以二维矩阵而非一维数组的形式表示，确定当前投注的代码将从以下内容变更：

```py
current_bet = policy[j]
```

改为：

```py
current_bet = policy[number_won][j]
```

也就是说，我们根据目前为止赢得的比赛数和当前比赛的编号来确定当前投注。否则，evaluate_policy()方法与上述相同。上述用于评估政策的代码实际上是大部分代码的核心。

# 寻找解决方案的代码

接下来，我们展示主要代码，它从一个随机政策开始，然后循环（最多10,000次），每次修改并（希望）改进此政策。每次循环，它生成当前最佳解的10个随机变体，选出其中最好的一个作为新的当前解决方案（如果没有更好的解，则保留当前解，并继续循环，直到找到更好的解）。

```py
import numpy as np
import math
import copy

policy = [[-1000, -1000, -1000, -1000, -1000, -1000, -1000], 
          [-1000, -1000, -1000, -1000, -1000, -1000, -1000],
          [-1000, -1000, -1000, -1000, -1000, -1000, -1000],
          [-1000, -1000, -1000, -1000, -1000, -1000, -1000]]
best_policy = copy.deepcopy(policy)
best_policy_score = evaluate_policy(policy)
print("starting score:", best_policy_score)

for i in range(10_000):
    if i % 100 == 0: print(i)

    # Each iteration, generate 10 candidate solutions similar to the
    # current best solution and take the best of these (if any are better
    # than the current best).
    for j in range(10):
        policy_candidate = vary_policy(policy)
        policy_score = evaluate_policy(policy_candidate)
        if policy_score <= best_policy_score:
            best_policy_score = policy_score
            best_policy = policy_candidate
    policy = copy.deepcopy(best_policy)
    print(best_policy_score) 
    display(policy)
    if best_policy_score == 0:
        print(f"Breaking after {i} iterations")
        break

print()
print("FINAL")
print(best_policy_score)    
display(policy)
```

运行此代码时，主循环执行了1,541次才找到解决方案。每次迭代，它调用vary_policy()（下面描述）十次来生成当前政策的十个变体。然后它调用evaluate_policy()来评估每个变体。这个方法之前已经定义过，提供一个得分（以美元为单位），表示使用该政策时，代理商在128个世界系列实例的平均集下，能够容忍的亏损金额（我们可以将其除以128，以获得任何单一世界系列的预期损失）。得分越低，结果越好。

初始解决方案的得分为153,656.25，表现非常差，正如预期的那样。从那里开始，快速改善，迅速下降到约100,000，然后是70,000，50,000，以此类推。随着代码执行，打印出迄今为止找到的最佳政策，也会呈现越来越合理的政策。

# 生成随机变体的方法

以下代码生成当前政策的一个单一变体：

```py
def vary_policy(policy):
    new_policy = copy.deepcopy(policy)
    num_change = np.random.randint(1, 10)
    for _ in range(num_change):    
        win_num = np.random.choice(4)
        game_num = np.random.choice(7)
        new_val = np.random.choice([x*31.25 for x in range(33)])
        new_policy[win_num][game_num] = new_val
    return new_policy
```

在这里，我们首先选择4x7策略中需要修改的单元格数量，范围在1到10之间。可以修改更少的单元格，这有助于在得分接近零时提升表现。也就是说，一旦我们拥有了一个强大的策略，我们可能希望减少对它的修改，而不是在过程初期进行大量修改，因为初期的解决方案往往较弱，更加注重搜索空间的探索。

然而，始终修改少量固定数量的单元格可能会导致陷入局部最优解（有时没有对策略进行修改，比如修改1或2个单元格后效果会更好，因此必须修改更多的单元格才能看到提升），并不总是能取得良好的效果。随机选择若干个单元格进行修改可以避免这种情况。不过，将这里的最大单元格数设置为10只是为了演示，并不是经过任何调优后的结果。

如果我们将自己限制在4x7矩阵中的16个相关单元格内进行修改，这段代码只需做一些小改动，简单地跳过对这些单元格的更新，并在显示矩阵时用一个特殊符号（相当于‘n/a’，如np.NaN）标记它们，以便清晰显示。

# 结果

最终，算法能够找到以下策略。也就是说，在第一场比赛中，我们将没有胜利，因此会投注$312.50。在第二场比赛中，我们可能没有胜利，也可能有一次胜利，但无论哪种情况，我们的投注都是$312.50。在第三场比赛中，我们可能没有胜利，也可能有一次或两次胜利，因此投注额为$250、$375或$250，依此类推，最多为七场比赛。如果我们进入第七场比赛，我们必须有3次胜利，并将在该场比赛中投注$1000。

```py
[[312.5, 312.5, 250.0, 125.0, 718.75, 31.25, 281.25],
 [375.0, 312.5, 375.0, 375.0, 250.0, 312.5, 343.75],
 [437.5, 156.25, 250.0, 375.0, 500.0, 500.0, 781.25],
 [750.0, 718.75, 343.75, 125.0, 250.0, 500.0, 1000.0]]
```

我还制作了一个图表，展示了目前为止找到的最佳策略的得分如何随着1,541次迭代逐步下降（也就是变得更好——数值越小越好）：

![](../Images/5c39cb7d4cbcf5c116dbd7f8d566388d.png)

迭代过程中找到的最佳策略的得分，直到找到一个合适的解决方案（得分为0）。

由于得分最初较大，这一变化有些难以察觉，因此我们再次绘制图表，跳过前15步：

![](../Images/c76f13ca9f8e0c1880b82eb146ada8ae.png)

迭代过程中找到的最佳策略的得分（跳过前15次迭代），直到找到一个合适的解决方案（得分为0）。

我们可以看到，得分最初会迅速下降，即使在前15步之后，得分仍继续下降，随后进入一个长时间的小幅提升期，直到最终找到对当前策略的小幅调整，使得得分有所提升，然后再次出现下降，直到我们最终达到完美的0分（即对于任何可能的胜负序列，得分都短缺$0）。

# 相似类型的问题

我们在这里处理的问题是一个*约束满足问题*的例子，我们只是希望找到一个满足所有给定约束的解决方案（在这种情况下，我们将约束视为硬约束——对于任何可能有效的游戏序列，必须以$0或$2000结束）。

给定两个或更多完整的解决方案时，没有哪个解决方案比另一个更好；任何有效的解决方案都是好的，一旦我们找到了可行的策略，就可以停止。N皇后问题和数独是这种类型问题的两个其他例子。

其他类型的问题可能具有最优性。例如，对于旅行商问题，任何访问每个城市一次的解决方案都是有效的，但每个解决方案的评分不同，有些解决方案优于其他解决方案。在这种类型的问题中，我们通常无法确定何时达到了最优解，我们通常只会尝试固定次数的迭代（或固定时间），或者直到我们找到了一个至少达到某个最低质量水平的解决方案。爬山法也可以用于这些类型的问题。

也可以制定一个问题，要求找到所有可行的解决方案，而不仅仅是一个。在世界大赛投注问题的情况下，找到一个可行的解决方案很简单，但找到所有解决方案会更加困难，需要进行穷举搜索（尽管可以优化，快速排除等价情况，或者在策略具有明显结果时提前停止评估）。

类似地，我们可以重新制定世界大赛投注问题，只要求一个好的解决方案，而不是完美的解决方案。例如，我们可以接受经纪人大部分时间没有盈亏，仅在其他情况下稍微亏损的解决方案。在这种情况下，爬山法仍然可以使用，但像随机搜索或网格搜索也是可行的——在固定次数的试验后，选择找到的最佳策略，这种方法在这种情况下可能足够有效。

在比世界大赛投注问题更困难的问题中，像我们这里使用的简单爬山法可能不够充分。例如，可能需要保持之前策略的记忆，或者包括一个叫做*模拟退火*的过程（在这种过程中，我们偶尔采取一个次优的步骤——一个可能实际质量低于当前解的步骤——以帮助突破局部最优解）。

对于更复杂的问题，可能更适合使用贝叶斯优化、进化算法、粒子群智能或其他更先进的方法。我希望在未来的文章中涵盖这些内容，但这个问题相对简单，直接的爬山法效果很好（尽管如前所述，可以很容易地优化使其效果更好）。

# 结论

这篇文章提供了一个简单的爬山法例子。这个问题相对直接，因此希望对于没有接触过爬山法的人来说足够简单，也可以作为一个很好的例子，即使你已经熟悉这种技术。

我认为有趣的是，尽管这个问题本可以通过其他方式解决，但像这里使用的优化技术可能是最简单且最有效的解决手段。虽然如果不使用这种方法，问题可能很难解决，但使用爬山法后，解决起来相当简单。  

所有图片由作者提供  
