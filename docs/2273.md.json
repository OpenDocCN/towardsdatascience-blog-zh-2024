["```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KernelDensity\n\n# Generate sample data\nnp.random.seed(14)\nuniform_data = np.random.uniform(low=1, high=7, size=20)\nnormal_data = np.random.normal(loc=3, scale=0.7, size=20)\n\n# Combine both distributions\ncombined_data = np.concatenate([uniform_data, normal_data])\n\n# Compute histogram\nhist, bin_edges = np.histogram(combined_data, bins=9, density=True)\n\n# Compute KDE\nkde = KernelDensity(kernel='gaussian').fit(combined_data[:, None])\nx = np.linspace(min(combined_data), max(combined_data), 1000)[:, None]\nlog_density = kde.score_samples(x)\ndensity = np.exp(log_density)\n\n# Plot histogram\nplt.hist(combined_data, bins=9, density=True, color='blue', edgecolor='black', label='Histogram')\n\n# Plot KDE\nplt.plot(x, density, color='red', label='KDE')\n\n# Add labels and legend\nplt.ylabel('Density')\nplt.title('Histogram and KDE')\nplt.legend()\n\n# Show plot\nplt.show()\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generate sample data\nnp.random.seed(14)\ndata = np.random.normal(loc=0, scale=1, size=40)\n\n# Sort the data\ndata_sorted = np.sort(data)\n\n# Compute ECDF values\necdf_y = np.arange(1, len(data_sorted)+1) / len(data_sorted)\n\n# Generate x values for the normal CDF\nx = np.linspace(-4, 4, 1000)\ncdf_y = norm.cdf(x)\n\n# Create the plot\nplt.figure(figsize=(6, 4))\nplt.step(data_sorted, ecdf_y, where='post', color='blue', label='ECDF')\nplt.plot(x, cdf_y, color='gray', label='Normal CDF')\nplt.plot(data_sorted, np.zeros_like(data_sorted), '|', color='black', label='Data points')\n\n# Label axes\nplt.xlabel('X')\nplt.ylabel('Cumulative Probability')\n\n# Add grid\nplt.grid(True)\n\n# Set limits\nplt.xlim([-4, 4])\nplt.ylim([0, 1])\n\n# Add legend\nplt.legend()\n\n# Show plot\nplt.show()\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\n\n# Generate sample data\nnp.random.seed(14)\ndata = np.random.normal(loc=0, scale=1, size=100)\n\n# Define the bandwidths\nbandwidths = [0.1, 0.3]\n\n# Plot the histogram and KDE for each bandwidth\nplt.figure(figsize=(12, 8))\nplt.hist(data, bins=30, density=True, color='gray', alpha=0.3, label='Histogram')\n\nx = np.linspace(-5, 5, 1000)\nfor bw in bandwidths:\n    kde = gaussian_kde(data , bw_method=bw)\n    plt.plot(x, kde(x), label=f'Bandwidth = {bw}')\n\n# Add labels and title\nplt.title('Impact of Bandwidth Selection on KDE')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.legend()\nplt.show()\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KernelDensity\n\n# Generate sample data\nnp.random.seed(14)\ndata = np.random.normal(loc=0, scale=1, size=100)[:, np.newaxis]  # reshape for sklearn\n\n# Intialize a constant bandwidth\nbandwidth = 0.6\n\n# Define different kernel functions\nkernels = [\"gaussian\", \"epanechnikov\", \"exponential\", \"linear\"]\n\n# Plot the histogram (transparent) and KDE for each kernel\nplt.figure(figsize=(12, 8))\n\n# Plot the histogram\nplt.hist(data, bins=30, density=True, color=\"gray\", alpha=0.3, label=\"Histogram\")\n\n# Plot KDE for each kernel function\nx = np.linspace(-5, 5, 1000)[:, np.newaxis]\nfor kernel in kernels:\n    kde = KernelDensity(bandwidth=bandwidth, kernel=kernel)\n    kde.fit(data)\n    log_density = kde.score_samples(x)\n    plt.plot(x[:, 0], np.exp(log_density), label=f\"Kernel = {kernel}\")\n\nplt.title(\"Impact of Different Kernel Functions on KDE\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.show()\n```"]