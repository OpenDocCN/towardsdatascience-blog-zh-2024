- en: Binary Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/binary-classification-unpacking-the-real-significance-and-limitations-of-traditional-metrics-810069be630c?source=collection_archive---------11-----------------------#2024-01-12](https://towardsdatascience.com/binary-classification-unpacking-the-real-significance-and-limitations-of-traditional-metrics-810069be630c?source=collection_archive---------11-----------------------#2024-01-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Unpacking the Real Significance and Limitations of Traditional Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)[![gabriel
    costa](../Images/7ae80a70ac22128573243d5cb9764102.png)](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)
    [gabriel costa](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)
    ·9 min read·Jan 12, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The work of classification can be seen as a way of summarizing the complexity
    of structures into finite classes, and it is often useful to make life boring
    enough that we can reduce such structures into *two single types*. These labels
    may have obvious interpretations, as in the case where we differentiate Statisticians
    from Data Scientists (possibly using income as a unique plausible feature), or
    they may even be a suffocating attempt to reduce experimental evidence into sentences,
    rejecting or not a null hypothesis. Embracing the metalanguage, we attribute a
    classification label to the work itself of sum up stuff into two different types:
    **Binary Classification**. This work is an attempt at a deeper description of
    this specific label, *bringing a probabilistic interpretation of what the decision
    process means and the metrics we use to evaluate our results.*'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling populations as distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we try to describe and differentiate an object, we aim to find specific
    characteristics that highlight its uniqueness. *It is expected that for many attributes
    this difference is not consistently accurate across a population.*
  prefs: []
  type: TYPE_NORMAL
- en: 'For an usual problem of two classes with different n features (V1, … Vn), we
    can se how these feature values distribute and try to make conclusions from them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b5ab6ecf21e310b75e2beb2c58d51dcf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Distribution of 8 different features Vn for two different classes
    (negative class: red; positive class: blue). This data is from a Kaggle challenge
    which is referenced at the end of the text.'
  prefs: []
  type: TYPE_NORMAL
- en: If the task were to use one of those features to guide our decision process,
    the strategy of deciding, given an individual’s *v_n* value,
  prefs: []
  type: TYPE_NORMAL
- en: it would be intuitive to predict the class with the highest frequency (or highest
    probability, if our histograms are good estimators of our distributions). For
    instance, if v4 measure for a individual were higher than 5, then it would be
    very likely that it is a positive.
  prefs: []
  type: TYPE_NORMAL
- en: However, *we can do more than that*, and take advantage different features,
    so that we can synthesize the information into a single distribution. **This is
    the job of the score function *S(x)***. The score function will do a regression
    to squeeze the feature distributions in one unique distribution ***P(s, y)***,
    which can be conditioned to each of the classes, with ***P(s|y=0)* for negatives**
    *(y=0)* and ***P(s|y=1)* for positives** *(y=1)*.
  prefs: []
  type: TYPE_NORMAL
- en: From this single distribution, **we choose** **a decision threshold t** that
    determines whether our estimate for a given point — which is represented by *ŷ*
    — will be positive or negative. **If s is greater than *t*, we assign a positive
    label; otherwise, a negative.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d44cfd6bb8e63197363e22a89615bc7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: graphical illustration of binary classification process. The score
    function squeezes the n-dimensional feature space into a distribution P(s, y).'
  prefs: []
  type: TYPE_NORMAL
- en: '***Given the distribution******P(s, y, t)*** *where s, y and t represents the
    values of the score, class and threshold respectively,* ***we have a complete
    description of our classifier.***'
  prefs: []
  type: TYPE_NORMAL
- en: Metrics for our classifier (marginal and conditional distributions)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Developing metrics for our classifier can be regarded as the pursuit of quantifying
    the discriminative nature of p(s|P) and p(s|N).*'
  prefs: []
  type: TYPE_NORMAL
- en: Typically will be a overlap over the two distributions *p(s|P)* and *p(s|N)*
    that makes a perfect classification impossible. So, given a threshold, one could
    ask what is the probability *p(s > t|N)* — False Positive Rate (FPR) — that we
    are misclassifying negative individuals as positives, for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Surely we can pile up a bunch of metrics and even give names — inconsistently
    — for each of them. But, for all purposes, it will be sufficient define four probabilities
    and their associated rates for the classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Positive Rate (*tpr*)**: *p(s > t|P) = TP/(TP+FN)*;'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**False Positive Rate (*fpr*):** *p(s > t|N) = FP/(FP+TN)*;'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**True Negative Rate (*tnr*):** *p(s ≤ t|N) = TN/(FP+TN)*;'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**False Negative Rate (*fnr*):** *p(s ≤ t|P) = FN/(TP+FN)*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are already familiar with the subject, you may have noticed that *these
    are the metrics that we define from confusion matrix of our classifier*. As this
    matrix is defined for each chosen decision threshold, we can view it as a representation
    of the conditional distribution *P(ŷ, y|t)*, where each of these objects is part
    of a class of confusion matrices that completely describe the performance of our
    classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a5663e68de330b06703f6189c7735c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Each confusion matrix can be viewed as a conditional *p(ŷ, y|t),
    and* a class of all possible confusion matrices becomes a complete description
    of the classifier’s performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the error ratios *fpr* and *fnr* are metrics that quantifies how
    and how much the two conditional score distributions intersect:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/15e9c69be544b6caf8b2aaaeb74a15e6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: the performance estimators for a classifier are different measures
    used to describe the overlap or separation between the two distributions, p(s|P)
    and p(s|N).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Summarizing performance: the ROC curve'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Since the ratios are constrained* by *tpr* + *fnr* = 1 and *fpr* + *tnr* =
    1, this would mean that w*e have just 2 degrees of freedom to describe our performance*.'
  prefs: []
  type: TYPE_NORMAL
- en: The ROC curve is a curve parameterized by *t*, described by *(x(t), y(t)) =
    (fpr(t), tpr(t))* as points against orthogonal axes. This will provide a digestible
    summary to visualize the performance of our classifier for all different threshold
    values, rather than just a single one.
  prefs: []
  type: TYPE_NORMAL
- en: The best choice of ***t*** is not generally known in advance but must be determined
    as part of the classifier construction. — ROC Curves for Continuous Data (2009,
    Chapman and Hall).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We are aiming to explore the concept of treating probability distributions,
    so let's imagine *what would be the base case for a completely inefficient classifier.*
    Since the effectiveness of our predictions hinges on the discriminative nature
    *p(s|P)* and *p(s|N)* are, in the case where *p(s|P) = p(s|N) = p(s)*, we encounter
    a prime example of this inefficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we do the exercise of modeling each of these conditionals as gaussians with
    means separated by different values, we can see how the performance varies clearly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c9469a4a07ec4f96ca8f33cb2fb04275.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The performance of a classifier improves as score distributions become
    more discriminative.'
  prefs: []
  type: TYPE_NORMAL
- en: This visualization will serve as a valuable aid in comprehending the probabilistic
    interpretation of a crucial classifier metric — named Area Under the Curve (AUC)
    — that we will delve into later.
  prefs: []
  type: TYPE_NORMAL
- en: Some properties of the ROC curve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ROC curve can be described as a function *y = h(x)* where *x* and *y* are
    the false and true positive rates respectively, which are in turn parameterized
    by *t* in the form *x(t) = p(s > t|N)* and and *y(t) = p(s > t|P)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can take advantage of this to derive the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '***y = h(x) is a monotone increasing function that lies above the line defined
    by (0, 0) and (1, 1);***'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***The ROC curve is unaltered if the classification scores undergo a strictly
    increasing transformation;***'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/9c111b8bd9edefdaf4d0406cd739c011.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: A monotonically increasing transformation applied to the score distribution
    does not alter the ROC curve, as it preserves the order of the regression.'
  prefs: []
  type: TYPE_NORMAL
- en: '**This property is what makes the calibration process for a classifier possible.**'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. ***For a well-defined slope of ROC at the point with threshold value t:***
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f837e538b46b20c86912cb92e4f3d8bf.png)'
  prefs: []
  type: TYPE_IMG
- en: '***where p(t|P) represents the density distribution for the cumulative distribution
    p(s ≤ t | P) (and same for p(t|N)).***'
  prefs: []
  type: TYPE_NORMAL
- en: 'Binary Classification as Hypothesis Testing: justifying our approach'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When viewing the classification process through a Bayesian inference lens, our
    objective is to deduce the posterior probability *p(P|t)*, which represents the
    odds of a point with threshold value *t* belonging to the positive class. Therefore,
    **the slope derivative defined on property 3 can be viewed as the likelihood ratio
    *L(t).***
  prefs: []
  type: TYPE_NORMAL
- en: This ratio *[L(t)]* tell us how much probable is a value of t of the classifier
    to have occurred in population P than in population N, which in turn can be interpreted
    as a measure of confidence in allocation to population P. — ROC Curves for Continuous
    Data (2009, Chapman and Hall).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is an important fact because, by establishing an equivalence relationship
    between the binary classification process and hypothesis testing, we have a justification
    for why we classify based on a threshold.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we formulate the classification problem with the *null hypothesis H0 that
    the individual belongs to population N against the alternative H1 that he belongs
    to population P*, we can draw the relationship:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a7f611c319c6a896fb27d9548d706474.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: The connection between the Binary Classification process and Hypothesis
    Testing is visualized through the confusion matrix. The marginal ratio metrics
    are related to the standard alpha and beta values in Hypothesis Testing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Neyman-Pearson Lemma** establishes that the most powerful test — which
    achieves the highest *1-β* value — with a significance level *α*, possesses a
    region *R* encompassing all *s* values of *S* for which:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0fb1caf9c90e053cf9bdcbed5b2e3079.png)'
  prefs: []
  type: TYPE_IMG
- en: where *α* is sufficient to determine *k* by the condition *p(s* ∈ *R|N) = α.*
  prefs: []
  type: TYPE_NORMAL
- en: This implies that when we score the population in a manner where *L(s)* is monotonically
    increasing, a one-to-one relationship between *s* and *k* ensures that choosing
    a rule that exceeds a particular threshold is the optimal decision.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our fictitious cases where our classifier assigns a normal distribution
    for each class, it''s direct the likelihood will satisfy this condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5675ac3396f75ae4ed22aa74a237e118.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: the likelihood ratio is strictly increasing (and, more precisely,
    exponentially) for the case of binormal distribution of scores.'
  prefs: []
  type: TYPE_NORMAL
- en: This is not always the case for a real-world problem, where score distributions
    are not necessarily well-behaved in this sense. We can use the *Kaggle* dataset
    to understand this, estimating the density of our conditionals by Kernel Density
    Estimation (KDE).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/89a056e1b2baeb8734a3932afdf2a67f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: This is the assignment of scores made by a logistic regression in
    a balanced data situation. The classifier was trained without parameter tuning.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/49ec9627282ae6bc704c6e8f4198dfe9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: for a real case (Kaggle dataset), we can see that the likelihood
    is not necessarily monotonic.'
  prefs: []
  type: TYPE_NORMAL
- en: '**This means that higher scores are not necessarily associated with a greater
    chance of the individual being from a positive class.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**ROC-AUC probabilistic interpretation, and why we should take care with it**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Area Under the Curve (AUC)* is probably the most widely used value to summarize
    the results expressed by a ROC curve. *It is defined as the integral of y(x) from
    0 to 1*, as the name suggests. Notably, a perfect classifier’s performance is
    epitomized by the point (0, 1) on the orthogonal axis, denoting zero probability
    of misclassification negative points and an unambiguous assurance of correctly
    classifying positives.
  prefs: []
  type: TYPE_NORMAL
- en: The approach treated on figure 5 give us a hint that the probabilistic interpretation
    of a good fit must have to do with consistency in assigning high score values
    for positive individuals and low score for negatives ones. This is exactly the
    case, since one can prove — as referred in [1] — that *the AUC is equivalent to
    the probability of a positive individual have a score value (Sp) higher than a
    negative individual score (Sn):*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a108b375acccbb36861e8533a4aa65e3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The critical point to consider is this: AUC is designed to provide a single-number
    estimate of your classifier’s performance. However, when it comes to making practical
    decisions, a threshold *t* must be chosen to suit the specific requirements of
    your problem. The challenge arises because, as discussed earlier, the optimal
    decision based on a threshold occurs when the likelihood ratio is monotonically
    increasing, which is not always the case in practice.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Consequently, even if you have a high AUC value, very close to 1, it may not
    be sufficient to determine whether your classifier is truly capable of optimal
    classification based on a decision boundary. In such cases,* ***achieving a high
    AUC value alone may not guarantee the effectiveness of your classifier in practical
    decision-making scenarios.***'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This probability interpretation of binary classification may offers a profound
    understanding of the intricacies involved in the process. By modeling populations
    as distributions, we can make informed decisions based on the likelihood of an
    individual belonging to a particular class. The ROC curve serves as a valuable
    tool for **summarize** how the choice of threshold impacts classification efficiency.
    Furthermore, **the connection between binary classification and hypothesis testing
    emphasizes the reason why we classify by threshold values**. It is essential to
    remember that while the Area Under the Curve (AUC) is a commonly used performance
    metric, **it may not always guarantee optimal practical decision-making**, underscoring
    the significance of choosing the right threshold. **This probabilistic interpretation
    enriches our understanding of binary classification, making it a powerful framework
    for tackling real-world problems.**
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Special thanks to Renato Vicente, who introduced me to visualizing the classifier
    through the space of confusion matrices, and encouraged me to write this article.
  prefs: []
  type: TYPE_NORMAL
- en: '*All images and graphs are by the author.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Also, you can find me on* [***Linkedin***](https://www.linkedin.com/in/gcosta98/)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Krzanowski, Wojtek J., and David J. Hand. *ROC curves for continuous data*.
    Crc Press, 2009'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Muschelli, John (2019–12–23). “ROC and AUC with a binary predictor: a potentially
    misleading metric”. *Journal of Classification*. Springer Science and Business
    Media LLC. **37** (3): 696–708\. [doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1007/s00357–019–09345–1](https://doi.org/10.1007%2Fs00357-019-09345-1).
    [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier)) [0176–4268](https://www.worldcat.org/issn/0176-4268).'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Credit Card Fraud (kaggle.com)](https://www.kaggle.com/datasets/joebeachcapital/credit-card-fraud)'
  prefs: []
  type: TYPE_NORMAL
