<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Linear Algebra 5: Linear Independence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Linear Algebra 5: Linear Independence</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-algebra-5-linear-independence-d350759debee?source=collection_archive---------4-----------------------#2024-03-21">https://towardsdatascience.com/linear-algebra-5-linear-independence-d350759debee?source=collection_archive---------4-----------------------#2024-03-21</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="fr fs ft fu fv fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/4d3d3691c84ee497c3611cd1a8245093.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2VTDk7fQ7rcOqcfwOkUcpg@2x.jpeg"/></div></div></figure><div/><div><h2 id="54bf" class="pw-subtitle-paragraph hc ge gf bf b hd he hf hg hh hi hj hk hl hm hn ho hp hq hr cq dx">Ax = 0 and proving a set of vectors is linearly independent</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hs ht hu hv hw ab"><div><div class="ab hx"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@t9nz?source=post_page---byline--d350759debee--------------------------------" rel="noopener follow"><div class="l hy hz by ia ib"><div class="l ed"><img alt="tenzin migmar (t9nz)" class="l ep by dd de cx" src="../Images/d9a3e1fe10afba1f1dc0fc7e4d241d73.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*wvgr4eWe2lY0ONThAVqroQ.jpeg"/><div class="ic by l dd de em n id eo"/></div></div></a></div></div><div class="ie ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d350759debee--------------------------------" rel="noopener follow"><div class="l if ig by ia ih"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ii cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ic by l br ii em n id eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ij ab q"><div class="ab q ik"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b il im bk"><a class="af ag ah ai aj ak al am an ao ap aq ar in" data-testid="authorName" href="https://medium.com/@t9nz?source=post_page---byline--d350759debee--------------------------------" rel="noopener follow">tenzin migmar (t9nz)</a></p></div></div></div><span class="io ip" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b il im dx"><button class="iq ir ah ai aj ak al am an ao ap aq ar is it iu" disabled="">Follow</button></p></div></div></span></div></div><div class="l iv"><span class="bf b bg z dx"><div class="ab cn iw ix iy"><div class="iz ja ab"><div class="bf b bg z dx ab jb"><span class="jc l iv">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar in ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d350759debee--------------------------------" rel="noopener follow"><p class="bf b bg z jd je jf jg jh ji jj jk bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="io ip" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="jl jm l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 21, 2024</span></div></span></div></span></div></div></div><div class="ab cp jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="h k w ea eb q"><div class="ks l"><div class="ab q kt ku"><div class="pw-multi-vote-icon ed jc kv kw kx"><div class=""><div class="ky kz la lb lc ld le am lf lg lh kx"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l li lj lk ll lm ln lo"><p class="bf b dy z dx"><span class="kz">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ky lp lq ab q ee lr ls" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lt"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q kd ke kf kg kh ki kj kk kl km kn ko kp kq kr"><div class="lu k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lv an ao ap is lw lx ly" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lz cn"><div class="l ae"><div class="ab cb"><div class="ma mb mc md me gb ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lv an ao ap is mf mg ls mh mi mj mk ml s mm mn mo mp mq mr ms u mt mu mv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lv an ao ap is mf mg ls mh mi mj mk ml s mm mn mo mp mq mr ms u mt mu mv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lv an ao ap is mf mg ls mh mi mj mk ml s mm mn mo mp mq mr ms u mt mu mv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><h2 id="e498" class="mw mx gf bf my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Preface</h2><p id="e6d1" class="pw-post-body-paragraph nu nv gf nw b hd nx ny nz hg oa ob oc nh od oe of nl og oh oi np oj ok ol om fj bk">Welcome back to the fifth edition of my ongoing series on the basics of Linear Algebra, the foundational math behind machine learning. In my previous <a class="af on" href="https://medium.com/@t9nz/linear-algebra-1-1-15b70e48bab9" rel="noopener">article</a>, I walked through the matrix equation Ax = <strong class="nw gg">b</strong>. This essay will investigate the important concept of linear independence and how it connects to everything we’ve learned so far.</p><p id="6266" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">This article would best serve readers if read in accompaniment with Linear Algebra and Its Applications by David C. Lay, Steven R. Lay, and Judi J. McDonald. Consider this series as a companion resource.</p><p id="b147" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">Feel free to share thoughts, questions, and critique.</p><h2 id="4656" class="mw mx gf bf my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Linear Independence in ℝⁿ</h2><p id="4a43" class="pw-post-body-paragraph nu nv gf nw b hd nx ny nz hg oa ob oc nh od oe of nl og oh oi np oj ok ol om fj bk">Previously, we learned about matrix products and matrix equations in the form <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">b</strong>. We covered that <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">b </strong>has a solution <strong class="nw gg">x</strong> if <strong class="nw gg">b</strong> is a linear combination of the set of vectors (columns) in matrix <em class="ot">A</em>.</p><figure class="ov ow ox oy oz fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp ou"><img src="../Images/11dcd81a10712976ba1c5b355fb8f55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1qG76LCKBaeLZm5V.jpeg"/></div></div></figure><p id="e412" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">There is a special matrix equation in Linear Algebra <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">0</strong> which we refer to as a homogenous linear system. <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">0 </strong>will always have at least one solution where <strong class="nw gg">x</strong> = <strong class="nw gg">0</strong> which is called the trivial solution because it is trivially easy to show that any matrix <em class="ot">A </em>multiplied by the <strong class="nw gg">0 </strong>vector <strong class="nw gg">x</strong> will result in the <strong class="nw gg">0 </strong>vector.</p><figure class="ov ow ox oy oz fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/df93b59487211315eb5ddc8763d6c2ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JZr-6Ht0lJRYgNvq78InVQ@2x.jpeg"/></div></div></figure><p id="8362" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">What we’re really interested in learning is whether the matrix equation <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">0</strong> has <em class="ot">only </em>the trivial solution. If <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">0</strong> has only the trivial solution <strong class="nw gg">x</strong> = 0, then the set of vectors that make up the columns of <em class="ot">A</em> are linearly independent. In other words: v₁ + c₂v₂ + … + cₐvₐ = 0 where c₁, c₂, … cₐ must all be 0. A different way of thinking about this is that none of the vectors in the set can be written as a linear combination of another.</p><p id="8524" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">On the other hand, if there exists a solution where <strong class="nw gg">x</strong> ≠ 0 then the set of vectors are linearly dependent. Then it follows that at least one of the vectors in the set can be written as a linear combination of another: c₁v₁ + c₂v₂ + … + cₐvₐ = 0 where not all where c₁, c₂, … cₐ equal 0.</p><p id="4c61" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">A neat, intuitive way of thinking about the concept of linear independence is the question of can you find a set of weights that will collapse the linear combination of a set of vectors to the origin? If a set of vectors is linearly independent, then 0 is the only weight that can be applied to each vector for the linear combination to equal the zero vector. If the vectors are linearly dependent, then there exists at least one set of non-zero weights such that the vector linear combination is zero.</p><figure class="ov ow ox oy oz fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/4d3d3691c84ee497c3611cd1a8245093.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2VTDk7fQ7rcOqcfwOkUcpg@2x.jpeg"/></div></div></figure><h2 id="e0f9" class="mw mx gf bf my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Determining Linear Independence</h2><p id="9c8c" class="pw-post-body-paragraph nu nv gf nw b hd nx ny nz hg oa ob oc nh od oe of nl og oh oi np oj ok ol om fj bk">For sets with only one vector, determining linear independence is trivial. If the vector is the zero vector, then it is linearly dependent. This is because any non-zero weight multiplied to the zero vector will equal the zero vector and so there exists infinitely many solutions for <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">0</strong>. If the vector is not the zero vector, then the vector is linearly independent since any vector multiplied by zero will become the zero vector.</p><p id="c7ab" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">If a set contains two vectors, the vectors are linearly dependent if one vectors is a multiple of the other. Otherwise, they are linearly independent.</p><figure class="ov ow ox oy oz fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/6963ce12226b1c0a8319dc6b31b4d01e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YdRYLmt6v6yErQ7k_8ucIw@2x.jpeg"/></div></div></figure><p id="6a29" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">In the case of sets with more than two vectors, more computation is involved. Let the vectors form the columns of matrix <em class="ot">A</em> and row reduce matrix <em class="ot">A</em> to reduced row echelon form. If the reduced row echelon form of the matrix has a pivot entry in every column, then the set of vectors is linearly independent. Otherwise, the set of vectors is linearly dependent. Why is this the case? Consider the process of row reducing a matrix to its reduced row echelon form. We perform a series of elementary row operations such as multiplying rows by constants, swapping rows, adding one row to another in pursuit of a matrix in a simpler form so that its underlying properties are clear while the solution space is preserved.</p><p id="536f" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">In the case of linear independence, the quality of having a pivot in each column indicates that each vector plays a leading role in at least one part of the linear combination equation. If each vector contributes independently to the linear system, then no vector can be expressed as a linear combination of the others and so the system is linearly independent. Conversely, if there is a column in RREF without a pivot entry, it means that the corresponding variable (or vector) is a dependent variable and can be expressed in terms of the other vectors. In other words, there exists a redundancy in the system, indicating linear dependence among the vectors.</p><p id="7220" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">A concise way to summarize this idea involves the rank of a matrix. The rank is the maximum number of linearly independent columns in a matrix and so it follows that the rank is equal to the number of pivots in reduced row echelon form.</p><p id="450c" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">If the number of columns in a matrix is equal to the rank, then the matrix is linearly independent. Otherwise, the matrix is linearly dependent.</p><figure class="ov ow ox oy oz fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pa"><img src="../Images/17ac6310fd0aa55970cd8158d56b60c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TBg4mRUAF42-Cw6k.jpeg"/></div></div></figure><figure class="ov ow ox oy oz fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/c351975238f19cabce9ef5fa7b90eab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LsHcX0QU38lvnHLtiw6QBA@2x.jpeg"/></div></div></figure><h2 id="9190" class="mw mx gf bf my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Linear Independence with Numpy</h2><p id="f8e3" class="pw-post-body-paragraph nu nv gf nw b hd nx ny nz hg oa ob oc nh od oe of nl og oh oi np oj ok ol om fj bk">Attempting computations made by hand is a worthwhile exercise in better understanding linear independence, but a more practical approach would be to use the capabilities built into the Numpy library to both test for linear independence and to derive the solution space for <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">0 </strong>of a given matrix.</p><p id="394d" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">We can approach checking if a matrix is linearly independent using the rank. As mentioned previously, a matrix is linearly independent if the rank of a matrix is equal to the number of columns so our code will be written around this criteria.</p><figure class="ov ow ox oy oz fw"><div class="pb jd l ed"><div class="pc pd l"/></div></figure><p id="4ca3" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">The following code generates the solution space of vectors for <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">0</strong>.</p><figure class="ov ow ox oy oz fw"><div class="pb jd l ed"><div class="pc pd l"/></div></figure><h2 id="6f52" class="mw mx gf bf my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Conclusion</h2><p id="74e8" class="pw-post-body-paragraph nu nv gf nw b hd nx ny nz hg oa ob oc nh od oe of nl og oh oi np oj ok ol om fj bk">Linear independence, while fundamental to Linear Algebra, also serves as a cornerstone in machine learning applications. Linear independence is crucial in feature selection and dimensionality reduction techniques such as principal component analysis (PCA) which operates on the collinearity or linear dependence between features in the dataset.</p><p id="149e" class="pw-post-body-paragraph nu nv gf nw b hd oo ny nz hg op ob oc nh oq oe of nl or oh oi np os ok ol om fj bk">You’ll continue to see linear independence pop up in machine learning!</p><h2 id="9f67" class="mw mx gf bf my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Summary</h2><ul class=""><li id="542b" class="nu nv gf nw b hd nx ny nz hg oa ob oc nh od oe of nl og oh oi np oj ok ol om pe pf pg bk">A system of linear equations is referred to as homogenous if it can be written in the form <em class="ot">A</em><strong class="nw gg">x</strong> = <strong class="nw gg">0</strong>.</li><li id="8ccb" class="nu nv gf nw b hd ph ny nz hg pi ob oc nh pj oe of nl pk oh oi np pl ok ol om pe pf pg bk">Linearly independent vectors cannot be expressed as a linear combination of each other (except the trivial combination where all coefficients are zero).</li><li id="d245" class="nu nv gf nw b hd ph ny nz hg pi ob oc nh pj oe of nl pk oh oi np pl ok ol om pe pf pg bk">Linearly dependent vectors are those where at least one vector in the set can be expressed as a linear combination of the others.</li><li id="d59b" class="nu nv gf nw b hd ph ny nz hg pi ob oc nh pj oe of nl pk oh oi np pl ok ol om pe pf pg bk">Numpy, a Python library for working with arrays offers fantastic support for both checking if a matrix is linearly independent and also solving Ax = 0 for a given matrix.</li></ul><h2 id="40af" class="mw mx gf bf my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Notes</h2><p id="16bc" class="pw-post-body-paragraph nu nv gf nw b hd nx ny nz hg oa ob oc nh od oe of nl og oh oi np oj ok ol om fj bk">*All images created by the author unless otherwise noted.</p><figure class="ov ow ox oy oz fw fo fp paragraph-image"><div class="fo fp pm"><img src="../Images/74c2602358c7142bde6453236c11dad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*35DWvBX99Nyqy7ZA.jpeg"/></div></figure></div></div></div></div>    
</body>
</html>