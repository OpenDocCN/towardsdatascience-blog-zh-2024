<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Leverage OpenAI Tool calling: Building a reliable AI Agent from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Leverage OpenAI Tool calling: Building a reliable AI Agent from Scratch</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/leverage-openai-tool-calling-building-a-reliable-ai-agent-from-scratch-4e21fcd15b62?source=collection_archive---------0-----------------------#2024-03-26">https://towardsdatascience.com/leverage-openai-tool-calling-building-a-reliable-ai-agent-from-scratch-4e21fcd15b62?source=collection_archive---------0-----------------------#2024-03-26</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="fr fs ft fu fv fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/f07cd9ca3af69f6002589e76d59e1898.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YJJYR9BvwGcMUnLh8AxiFw.jpeg"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Created with <a class="af gi" href="https://labs.openai.com/s/1rNDsRujptitO6sPd57aWyZp" rel="noopener ugc nofollow" target="_blank">DALL·E</a></figcaption></figure><div/><div><h2 id="55e5" class="pw-subtitle-paragraph hi gk gl bf b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx cq dx">Step-by-Step Workflow for developing and refining an AI Agent while dealing with errors</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hy hz ia ib ic ab"><div><div class="ab id"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@lukas.kowejsza?source=post_page---byline--4e21fcd15b62--------------------------------" rel="noopener follow"><div class="l ie if by ig ih"><div class="l ed"><img alt="Lukasz Kowejsza" class="l ep by dd de cx" src="../Images/8d920478bee9ad674a6c79462128b0db.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*gH4EgquV4LSB3aBWcBvU1Q.jpeg"/><div class="ii by l dd de em n ij eo"/></div></div></a></div></div><div class="ik ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--4e21fcd15b62--------------------------------" rel="noopener follow"><div class="l il im by ig in"><div class="l ed"><img alt="Towards Data Science" class="l ep by br io cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ii by l br io em n ij eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ip ab q"><div class="ab q iq"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ir is bk"><a class="af ag ah ai aj ak al am an ao ap aq ar it" data-testid="authorName" href="https://medium.com/@lukas.kowejsza?source=post_page---byline--4e21fcd15b62--------------------------------" rel="noopener follow">Lukasz Kowejsza</a></p></div></div></div><span class="iu iv" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ir is dx"><button class="iw ix ah ai aj ak al am an ao ap aq ar iy iz ja" disabled="">Follow</button></p></div></div></span></div></div><div class="l jb"><span class="bf b bg z dx"><div class="ab cn jc jd je"><div class="jf jg ab"><div class="bf b bg z dx ab jh"><span class="ji l jb">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar it ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--4e21fcd15b62--------------------------------" rel="noopener follow"><p class="bf b bg z jj jk jl jm jn jo jp jq bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="iu iv" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">16 min read</span><div class="jr js l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 26, 2024</span></div></span></div></span></div></div></div><div class="ab cp jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki"><div class="h k w ea eb q"><div class="ky l"><div class="ab q kz la"><div class="pw-multi-vote-icon ed ji lb lc ld"><div class=""><div class="le lf lg lh li lj lk am ll lm ln ld"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l lo lp lq lr ls lt lu"><p class="bf b dy z dx"><span class="lf">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao le lx ly ab q ee lz ma" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lw"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lv lw">11</span></p></button></div></div></div><div class="ab q kj kk kl km kn ko kp kq kr ks kt ku kv kw kx"><div class="mb k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al mc an ao ap iy md me mf" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep mg cn"><div class="l ae"><div class="ab cb"><div class="mh mi mj mk ml gb ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al mc an ao ap iy mm mn ma mo mp mq mr ms s mt mu mv mw mx my mz u na nb nc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al mc an ao ap iy mm mn ma mo mp mq mr ms s mt mu mv mw mx my mz u na nb nc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al mc an ao ap iy mm mn ma mo mp mq mr ms s mt mu mv mw mx my mz u na nb nc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="217f" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When we think about the future of AI, we envision intuitive everyday helpers seamlessly integrating into our workflows and taking on complex, routinely tasks. We all have found touchpoints that relieve us from the tedium of mental routine work. Yet, the main tasks currently tackled involve text creation, correction, and brainstorming, underlined by the significant role RAG (Retrieval-Augmented Generation) pipelines play in ongoing development. We aim to provide Large Language Models with better context to generate more valuable content.</p><p id="66a4" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Thinking about the future of AI conjures images of Jarvis from Iron Man or Rasputin from Destiny (the game) for me. In both examples, the AI acts as a voice-controlled interface to a complex system, offering high-level abstractions. For instance, Tony Stark uses it to manage his research, conduct calculations, and run simulations. Even R2D2 can respond to voice commands to interface with unfamiliar computer systems and extract data or interact with building systems.</p><p id="2dae" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In these scenarios, AI enables interaction with complex systems without requiring the end user to have a deep understanding of them. This could be likened to an ERP system in a large corporation today. It’s rare to find someone in a large corporation who fully knows and understands every facet of the in-house ERP system. It’s not far-fetched to imagine that, in the near future, AI might assist nearly every interaction with an ERP system. From the end user managing customer data or logging orders to the software developer fixing bugs or implementing new features, these interactions could soon be facilitated by AI assistants familiar with all aspects and processes of the ERP system. Such an AI assistant would know which database to enter customer data into and which processes and code might be relevant to a bug.</p><p id="fc7c" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To achieve this, several challenges and innovations lie ahead. We need to rethink processes and their documentation. Today’s ERP processes are designed for human use, with specific roles for different users, documentation for humans, input masks for humans, and user interactions designed to be intuitive and error-free. The design of these aspects will look different for AI interactions. We need specific roles for AI interactions and different process designs to enable intuitive and error-free AI interaction. This is already evident in our work with prompts. What we consider to be a clear task often turns out not to be so straightforward.</p><h1 id="0da5" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">From Concept to Reality: Building the Basis for AI Agents</h1><p id="b2f0" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">However, let’s first take a step back to the concept of agents. Agents, or AI assistants that can perform tasks using the tools provided and make decisions on how to use these tools, are the building blocks that could eventually enable such a system. They are the process components we’d want to integrate into every facet of a complex system. But as highlighted in a previous article, they are challenging to deploy reliably. In this article, I will demonstrate how we can design and optimize an agent capable of reliably interacting with a database.</p><p id="c675" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">While the grand vision of AI’s future is inspiring, it’s crucial to take practical steps towards realizing this vision. To demonstrate how we can start building the foundation for such advanced AI systems, let’s focus on creating a prototype agent for a common task: expense tracking. This prototype will serve as a tangible example of how AI can assist in managing financial transactions efficiently, showcasing the potential of AI in automating routine tasks and highlighting the challenges and considerations involved in designing an AI system that interacts seamlessly with databases. By starting with a specific and relatable use case, we can gain valuable insights that will inform the development of more complex AI agents in the future.</p><h1 id="ea6d" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">The Aim of This Article</h1><p id="9514" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">This article will lay the groundwork for a series of articles aimed at developing a chatbot that can serve as a single point of interaction for a small business to support and execute business processes or a chatbot that in your personal life organizes everything you need to keep track of. From data, routines, files, to pictures, we want to simply chat with our Assistant, allowing it to figure out where to store and retrieve your data.</p><p id="1dfa" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Transitioning from the grand vision of AI’s future to practical applications, let’s zoom in on creating a prototype agent. This agent will serve as a foundational step towards realizing the ambitious goals discussed earlier. We will embark on developing an “Expense Tracking” agent, a straightforward yet essential task, demonstrating how AI can assist in managing financial transactions efficiently.</p><p id="d26e" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This “Expense Tracking” prototype will not only showcase the potential of AI in automating routine tasks but also illuminate the challenges and considerations involved in designing an AI system that interacts seamlessly with databases. By focusing on this example, we can explore the intricacies of agent design, input validation, and the integration of AI with existing systems — laying a solid foundation for more complex applications in the future.</p><h1 id="b4a8" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">1. Hands-On: Testing OpenAI Tool Call</h1><p id="7ebc" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">To bring our prototype agent to life and identify potential bottlenecks, we’re venturing into testing the tool call functionality of OpenAI. Starting with a basic example of expense tracking, we’re laying down a foundational piece that mimics a real-world application. This stage involves creating a base model and transforming it into the OpenAI tool schema using the langchain library’s <code class="cx pa pb pc pd b">convert_to_openai_tool</code> function. Additionally, crafting a <code class="cx pa pb pc pd b">report_tool</code> enables our future agent to communicate results or highlight missing information or issues:</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="532c" class="pm oa gl pd b bg pn po l pp pq">from pydantic.v1 import BaseModel, validator  <br/>from datetime import datetime<br/>from langchain_core.utils.function_calling import convert_to_openai_tool<br/>  <br/>  <br/>class Expense(BaseModel):    <br/>   description: str    <br/>   net_amount: float    <br/>   gross_amount: float    <br/>   tax_rate: float    <br/>   date: datetime<br/><br/><br/>class Report(BaseModel):<br/>   report: str<br/><br/>add_expense_tool = convert_to_openai_tool(Expense)<br/>report_tool = convert_to_openai_tool(Report)</span></pre><p id="6597" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">With the data model and tools set up, the next step is to use the OpenAI client SDK to initiate a simple tool call. In this initial test, we’re intentionally providing insufficient information to the model to see if it can correctly indicate what’s missing. This approach not only tests the functional capability of the agent but also its interactive and error-handling capacities.</p><h1 id="ac1b" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">Calling OpenAI API</h1><p id="3048" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Now, we’ll use the OpenAI client SDK to initiate a simple tool call. In our first test, we deliberately provide the model with insufficient information to see if it can notify us of the missing details.</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="3b53" class="pm oa gl pd b bg pn po l pp pq">from openai import OpenAI  <br/>from langchain_core.utils.function_calling import convert_to_openai_tool  <br/>  <br/>SYSTEM_MESSAGE = """You are tasked with completing specific objectives and <br/>must report the outcomes. At your disposal, you have a variety of tools, <br/>each specialized in performing a distinct type of task.  <br/>  <br/>For successful task completion:  <br/>Thought: Consider the task at hand and determine which tool is best suited <br/>based on its capabilities and the nature of the work.  <br/>  <br/>Use the report_tool with an instruction detailing the results of your work.  <br/>If you encounter an issue and cannot complete the task:  <br/>  <br/>Use the report_tool to communicate the challenge or reason for the <br/>task's incompletion.  <br/>You will receive feedback based on the outcomes of <br/>each tool's task execution or explanations for any tasks that <br/>couldn't be completed. This feedback loop is crucial for addressing <br/>and resolving any issues by strategically deploying the available tools.  <br/>"""  <br/>user_message = "I have spend 5$ on a coffee today please track my expense. The tax rate is 0.2."<br/>  <br/>client = OpenAI()  <br/>model_name = "gpt-3.5-turbo-0125"  <br/>  <br/>messages = [  <br/>    {"role":"system", "content": SYSTEM_MESSAGE},  <br/>    {"role":"user", "content": user_message}  <br/>]  <br/>  <br/>response = client.chat.completions.create(  <br/>            model=model_name,  <br/>            messages=messages,  <br/>            tools=[  <br/>                convert_to_openai_tool(Expense),  <br/>                convert_to_openai_tool(ReportTool)]  <br/>        )</span></pre><p id="73e8" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Next, we’ll need a new function to read the arguments of the function call from the response:</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="ace6" class="pm oa gl pd b bg pn po l pp pq">def parse_function_args(response):<br/>    message = response.choices[0].message<br/>    return json.loads(message.tool_calls[0].function.arguments)<br/><br/>print(parse_function_args(response))</span></pre><pre class="pr pj pd pk bp pl bb bk"><span id="b278" class="pm oa gl pd b bg pn po l pp pq">{'description': 'Coffee',<br/> 'net_amount': 5,<br/> 'gross_amount': None,<br/> 'tax_rate': 0.2,<br/> 'date': '2023-10-06T12:00:00Z'}</span></pre><p id="c36d" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As we can observe, we have encountered several issues in the execution:</p><ol class=""><li id="8b23" class="nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny ps pt pu bk">The gross_amount is not calculated.</li><li id="8e50" class="nd ne gl nf b hj pv nh ni hm pw nk nl nm px no np nq py ns nt nu pz nw nx ny ps pt pu bk">The date is hallucinated.</li></ol><p id="3c3f" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">With that in mind. Let’s try to resolve this issues and optimize our agent workflow.</p><h1 id="c335" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">2. Optimize Tool handling</h1><p id="56a6" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">To optimize the agent workflow, I find it crucial to prioritize <strong class="nf gm">workflow over prompt engineering</strong>. While it might be tempting to fine-tune the prompt so that the agent learns to use the tools provided perfectly and makes no mistakes, it’s more advisable to first adjust the tools and processes. When a typical error occurs, the initial consideration should be <strong class="nf gm">how to fix it code-based</strong>.</p><h1 id="8e32" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">Handling Missing Information</h1><p id="aeb0" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Handling missing information effectively is an essential topic for creating robust and reliable agents. In the previous example, providing the agent with a tool like “get_current_date” is a workaround for specific scenarios. However, we must assume that missing information will occur in various contexts, and we cannot rely solely on prompt engineering and adding more tools to prevent the model from hallucinating missing information.</p><p id="333c" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A simple workaround for this scenario is to modify the tool schema to treat all parameters as optional. This approach ensures that the agent only submits the parameters it knows, preventing unnecessary hallucination.</p><p id="871b" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Therefore, let’s take a look at openai tool schema:</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="7fa9" class="pm oa gl pd b bg pn po l pp pq">add_expense_tool = convert_to_openai_tool(Expense)<br/>print(add_expense_tool)</span></pre><pre class="pr pj pd pk bp pl bb bk"><span id="58a4" class="pm oa gl pd b bg pn po l pp pq">{'type': 'function',<br/> 'function': {'name': 'Expense',<br/>  'description': '',<br/>  'parameters': {'type': 'object',<br/>   'properties': {'description': {'type': 'string'},<br/>    'net_amount': {'type': 'number'},<br/>    'gross_amount': {'type': 'number'},<br/>    'tax_rate': {'type': 'number'},<br/>    'date': {'type': 'string', 'format': 'date-time'}},<br/>   'required': ['description',<br/>    'net_amount',<br/>    'gross_amount',<br/>    'tax_rate',<br/>    'date']}}}</span></pre><p id="777e" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As we can see we have special key <code class="cx pa pb pc pd b">required</code> , which we need to remove. Here’s how you can adjust the <code class="cx pa pb pc pd b">add_expense_tool</code> schema to make parameters optional by removing the <code class="cx pa pb pc pd b">required</code> key:</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="1b69" class="pm oa gl pd b bg pn po l pp pq">del add_expense_tool["function"]["parameters"]["required"]</span></pre><h1 id="54a7" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">Designing Tool class</h1><p id="9593" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Next, we can design a Tool class that initially checks the input parameters for missing values. We create the <code class="cx pa pb pc pd b">Tool</code> class with two methods: <code class="cx pa pb pc pd b">.run()</code>, <code class="cx pa pb pc pd b">.validate_input()</code>, and a property <code class="cx pa pb pc pd b">openai_tool_schema</code>, where we manipulate the tool schema by removing required parameters. Additionally, we define the <code class="cx pa pb pc pd b">ToolResult</code> BaseModel with the fields <code class="cx pa pb pc pd b">content</code> and <code class="cx pa pb pc pd b">success</code> to serve as the output object for each tool run.</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="204c" class="pm oa gl pd b bg pn po l pp pq">from pydantic import BaseModel<br/>from typing import Type, Callable, Dict, Any, List<br/><br/>class ToolResult(BaseModel):  <br/>    content: str  <br/>    success: bool  <br/>  <br/>class Tool(BaseModel):  <br/>    name: str  <br/>    model: Type[BaseModel]  <br/>    function: Callable  <br/>    validate_missing: bool = False  <br/>  <br/>    class Config:  <br/>        arbitrary_types_allowed = True  <br/>  <br/>    def run(self, **kwargs) -&gt; ToolResult:<br/>        if self.validate_missing:<br/>            missing_values = self.validate_input(**kwargs)  <br/>            if missing_values:  <br/>                content = f"Missing values: {', '.join(missing_values)}"  <br/>                return ToolResult(content=content, success=False)  <br/>        result = self.function(**kwargs)  <br/>        return ToolResult(content=str(result), success=True)  <br/>      <br/>    def validate_input(self, **kwargs) -&gt; List[str]:  <br/>        missing_values = []  <br/>        for key in self.model.__fields__.keys():  <br/>            if key not in kwargs:  <br/>                missing_values.append(key)  <br/>        return missing_values<br/>    @property<br/>    def openai_tool_schema(self) -&gt; Dict[str, Any]:<br/>        schema = convert_to_openai_tool(self.model)<br/>        if "required" in schema["function"]["parameters"]:<br/>            del schema["function"]["parameters"]["required"]<br/>        return schema</span></pre><p id="05c3" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The <code class="cx pa pb pc pd b">Tool</code> class is a crucial component in the AI agent's workflow, serving as a blueprint for creating and managing various tools that the agent can utilize to perform specific tasks. It is designed to handle input validation, execute the tool's function, and return the result in a standardized format.</p><h2 id="37f5" class="qa oa gl bf ob qb qc qd oe qe qf qg oh nm qh qi qj nq qk ql qm nu qn qo qp qq bk">The <code class="cx pa pb pc pd b">Tool</code> class key components:</h2><ol class=""><li id="15b0" class="nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny ps pt pu bk"><code class="cx pa pb pc pd b">name</code>: The name of the tool.</li><li id="0e75" class="nd ne gl nf b hj pv nh ni hm pw nk nl nm px no np nq py ns nt nu pz nw nx ny ps pt pu bk"><code class="cx pa pb pc pd b">model</code>: The Pydantic BaseModel that defines the input schema for the tool.</li><li id="6730" class="nd ne gl nf b hj pv nh ni hm pw nk nl nm px no np nq py ns nt nu pz nw nx ny ps pt pu bk"><code class="cx pa pb pc pd b">function</code>: The callable function that the tool executes.</li><li id="f676" class="nd ne gl nf b hj pv nh ni hm pw nk nl nm px no np nq py ns nt nu pz nw nx ny ps pt pu bk"><code class="cx pa pb pc pd b">validate_missing</code>: A boolean flag indicating whether to validate missing input values (default is <code class="cx pa pb pc pd b">False</code>).</li></ol><h2 id="d38d" class="qa oa gl bf ob qb qc qd oe qe qf qg oh nm qh qi qj nq qk ql qm nu qn qo qp qq bk">The <code class="cx pa pb pc pd b">Tool</code> class two main methods:</h2><ol class=""><li id="fe43" class="nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny ps pt pu bk"><code class="cx pa pb pc pd b"><strong class="nf gm">run(self, **kwargs) -&gt; ToolResult</strong></code><strong class="nf gm">: </strong>This method is responsible for executing the tool’s function with the provided input arguments. It first checks if <code class="cx pa pb pc pd b">validate_missing</code> is set to <code class="cx pa pb pc pd b">True</code>. If so, it calls the <code class="cx pa pb pc pd b">validate_input()</code> method to check for missing input values. If any missing values are found, it returns a <code class="cx pa pb pc pd b">ToolResult</code> object with an error message and <code class="cx pa pb pc pd b">success</code> set to <code class="cx pa pb pc pd b">False</code>. If all required input values are present, it proceeds to execute the tool's <code class="cx pa pb pc pd b">function</code> with the provided arguments and returns a <code class="cx pa pb pc pd b">ToolResult</code> object with the result and <code class="cx pa pb pc pd b">success</code> set to <code class="cx pa pb pc pd b">True</code>.</li><li id="5533" class="nd ne gl nf b hj pv nh ni hm pw nk nl nm px no np nq py ns nt nu pz nw nx ny ps pt pu bk"><code class="cx pa pb pc pd b"><strong class="nf gm">validate_input(self, **kwargs) -&gt; List[str]</strong></code><strong class="nf gm">: </strong>This method compares the input arguments passed to the tool with the expected input schema defined in the <code class="cx pa pb pc pd b">model</code>. It iterates over the fields defined in the <code class="cx pa pb pc pd b">model</code> and checks if each field is present in the input arguments. If any field is missing, it appends the field name to a list of missing values. Finally, it returns the list of missing values.</li></ol><p id="5b06" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The <code class="cx pa pb pc pd b">Tool</code> class also has a property called <code class="cx pa pb pc pd b">openai_tool_schema</code>, which returns the OpenAI tool schema for the tool. It uses the <code class="cx pa pb pc pd b">convert_to_openai_tool()</code> function to convert the <code class="cx pa pb pc pd b">model</code> to the OpenAI tool schema format. Additionally, it removes the <code class="cx pa pb pc pd b">"required"</code> key from the schema, making all input parameters optional. This allows the agent to provide only the available information without the need to hallucinate missing values.</p><p id="9c5f" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">By encapsulating the tool’s functionality, input validation, and schema generation, the <code class="cx pa pb pc pd b">Tool</code> class provides a clean and reusable interface for creating and managing tools in the AI agent's workflow. It abstracts away the complexities of handling missing values and ensures that the agent can gracefully handle incomplete information while executing the appropriate tools based on the available input.</p><h1 id="f896" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">Testing Missing Information Handling</h1><p id="d0fc" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Next, we will extend our OpenAI API call. We want the client to utilize our tool, and our response object to directly trigger a tool.run(). For this, we need to initialize our tools in our newly created Tool class. We define two dummy functions which return a success message string.</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="9736" class="pm oa gl pd b bg pn po l pp pq">def add_expense_func(**kwargs):  <br/>    return f"Added expense: {kwargs} to the database."<br/><br/>add_expense_tool = Tool(  <br/>    name="add_expense_tool",  <br/>    model=Expense,  <br/>    function=add_expense_func  <br/>)  <br/>  <br/>def report_func(report: str = None):  <br/>    return f"Reported: {report}"  <br/>  <br/>report_tool = Tool(  <br/>    name="report_tool",  <br/>    model=ReportTool,  <br/>    function=report_func  <br/>)  <br/>  <br/>tools = [add_expense_tool, report_tool]</span></pre><p id="a905" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Next we define our helper function, that each take client response as input an help to interact with out tools.</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="81c0" class="pm oa gl pd b bg pn po l pp pq">def get_tool_from_response(response, tools=tools):  <br/>    tool_name = response.choices[0].message.tool_calls[0].function.name  <br/>    for t in tools:  <br/>        if t.name == tool_name:  <br/>            return t  <br/>    raise ValueError(f"Tool {tool_name} not found in tools list.")<br/><br/>def parse_function_args(response):  <br/>    message = response.choices[0].message  <br/>    return json.loads(message.tool_calls[0].function.arguments)<br/><br/>def run_tool_from_response(response, tools=tools):  <br/>    tool = get_tool_from_response(response, tools)  <br/>    tool_kwargs = parse_function_args(response)  <br/>    return tool.run(**tool_kwargs)</span></pre><p id="6a6d" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now, we can execute our client with our new tools and use the <code class="cx pa pb pc pd b">run_tool_from_response</code> function.</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="6b70" class="pm oa gl pd b bg pn po l pp pq">response = client.chat.completions.create(  <br/>            model=model_name,  <br/>            messages=messages,  <br/>            tools=[tool.openai_tool_schema for tool in tools]  <br/>        )<br/><br/>tool_result = run_tool_from_response(response, tools=tools)<br/>print(tool_result)</span></pre><pre class="pr pj pd pk bp pl bb bk"><span id="cc0a" class="pm oa gl pd b bg pn po l pp pq">content='Missing values: gross_amount, date' success=False</span></pre><p id="fb61" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Perfectly, we now see our tool indicating that missing values are present. Thanks to our trick of sending all parameters as optional, we now avoid hallucinated parameters.</p><h1 id="112a" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">3. Building the Agent Workflow</h1><p id="8a83" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Our process, as it stands, doesn’t yet represent a true agent. So far, we’ve only executed a single API tool call. To transform this into an agent workflow, we need to introduce an iterative process that feeds the results of tool execution back to the client. The basic process should like this:</p><figure class="pe pf pg ph pi fw fo fp paragraph-image"><div class="fo fp qr"><img src="../Images/41aa2536800140285336ed2dd1dabdaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*rLoF4WgLIrdumus4HOSeWQ.png"/></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image by author</figcaption></figure><p id="46ff" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s get started by creating a new OpenAIAgent class:</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="e909" class="pm oa gl pd b bg pn po l pp pq">class StepResult(BaseModel):  <br/>    event: str   <br/>    content: str  <br/>    success: bool<br/><br/><br/>class OpenAIAgent:  <br/>      <br/>    def __init__(  <br/>            self,   <br/>            tools: list[Tool],   <br/>            client: OpenAI,   <br/>            system_message: str = SYSTEM_MESSAGE,   <br/>            model_name: str = "gpt-3.5-turbo-0125",  <br/>            max_steps: int = 5,  <br/>            verbose: bool = True  <br/>    ):  <br/>        self.tools = tools  <br/>        self.client = client  <br/>        self.model_name = model_name  <br/>        self.system_message = system_message  <br/>        self.step_history = []  <br/>        self.max_steps = max_steps  <br/>        self.verbose = verbose  <br/>      <br/>      <br/>    def to_console(self, tag: str, message: str, color: str = "green"):  <br/>        if self.verbose:  <br/>            color_prefix = Fore.__dict__[color.upper()]  <br/>            print(color_prefix + f"{tag}: {message}{Style.RESET_ALL}")</span></pre><p id="968a" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Like our <code class="cx pa pb pc pd b">ToolResult</code>object, we’ve defined a <code class="cx pa pb pc pd b">StepResult</code> as an object for each agent step. We then defined the <code class="cx pa pb pc pd b">__init__</code> method of the OpenAIAgent class and a <code class="cx pa pb pc pd b">to_console()</code> method to print our intermediate steps and tool calls to the console, using colorama for colorful printouts. Next, we define the heart of the agent, the <code class="cx pa pb pc pd b">run()</code> and the <code class="cx pa pb pc pd b">run_step()</code> method.</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="5e4d" class="pm oa gl pd b bg pn po l pp pq">class OpenAIAgent:<br/><br/>    # ... __init__...<br/>    <br/>    # ... to_console ...<br/>    <br/>    def run(self, user_input: str):  <br/>        <br/>        openai_tools = [tool.openai_tool_schema for tool in self.tools]    <br/>        self.step_history = [    <br/>            {"role":"system", "content":self.system_message},    <br/>            {"role":"user", "content":user_input}    <br/>        ]    <br/>          <br/>        step_result = None    <br/>        i = 0<br/>        <br/>        self.to_console("START", f"Starting Agent with Input: {user_input}")<br/>          <br/>        while i &lt; self.max_steps:  <br/>            step_result = self.run_step(self.step_history, openai_tools)    <br/>            <br/>            if step_result.event == "finish":    <br/>                break  <br/>            elif step_result.event == "error":  <br/>                self.to_console(step_result.event, step_result.content, "red")  <br/>            else:  <br/>                self.to_console(step_result.event, step_result.content, "yellow")  <br/>            i += 1   <br/>              <br/>        self.to_console("Final Result", step_result.content, "green")  <br/>        return step_result.content</span></pre><p id="9426" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In the <code class="cx pa pb pc pd b">run()</code> method, we start by initializing the <code class="cx pa pb pc pd b">step_history</code>, which will serve as our message memory, with the predefined system_message and the user_input. Then we start our while loop, where we call <code class="cx pa pb pc pd b">run_step</code> during each iteration, which will return a StepResult Object. We identify if the agent finished his task or if an error occurred, which will be passed to the console as well.</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="48a1" class="pm oa gl pd b bg pn po l pp pq">class OpenAIAgent:<br/><br/>    # ... __init__...<br/>    <br/>    # ... to_console ...<br/>    # ... run ...<br/>    def run_step(self, messages: list[dict], tools):  <br/>          <br/>        # plan the next step  <br/>        response = self.client.chat.completions.create(  <br/>            model=self.model_name,  <br/>            messages=messages,  <br/>            tools=tools  <br/>        )  <br/>          <br/>        # add message to history  <br/>        self.step_history.append(response.choices[0].message)  <br/>        <br/>        # check if tool call is present  <br/>        if not response.choices[0].message.tool_calls:  <br/>            return StepResult(<br/>                event="Error",<br/>                content="No tool calls were returned.", <br/>                success=False<br/>                )  <br/>          <br/>        tool_name = response.choices[0].message.tool_calls[0].function.name  <br/>        tool_kwargs = parse_function_args(response)  <br/>          <br/>        # execute the tool call  <br/>        self.to_console(<br/>        "Tool Call", f"Name: {tool_name}\nArgs: {tool_kwargs}", "magenta"<br/>        )  <br/>        tool_result = run_tool_from_response(response, tools=self.tools)  <br/>        tool_result_msg = self.tool_call_message(response, tool_result)  <br/>        self.step_history.append(tool_result_msg)  <br/>          <br/>        if tool_result.success:  <br/>            step_result = StepResult(  <br/>                event="tool_result",   <br/>                content=tool_result.content,   <br/>                success=True)  <br/>        else:  <br/>            step_result = StepResult(  <br/>                event="error",   <br/>                content=tool_result.content,   <br/>                success=False  <br/>            )   <br/>          <br/>        return step_result  <br/>          <br/>      <br/>    def tool_call_message(self, response, tool_result: ToolResult):  <br/>        tool_call = response.choices[0].message.tool_calls[0]  <br/>        return {  <br/>            "tool_call_id": tool_call.id,  <br/>            "role": "tool",  <br/>            "name": tool_call.function.name,  <br/>            "content": tool_result.content,  <br/>        }</span></pre><p id="c169" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now we’ve defined the logic for each step. We first obtain a response object by our previously tested client API call with tools. We append the response message object to our <code class="cx pa pb pc pd b">step_history</code>. We then verify if a tool call is included in our response object, otherwise, we return an error in our StepResult. Then we log our tool call to the console and run the selected tool with our previously defined method <code class="cx pa pb pc pd b">run_tool_from_response()</code>. We also need to append the tool result to our message history. OpenAI has defined a specific format for this purpose, so that the Model knows which tool call refers to which output by passing a tool_call_id into our message dict. This is done by our method <code class="cx pa pb pc pd b">tool_call_message()</code>, which takes the response object and the tool_result as input arguments. At the end of each step, we assign the tool result to a StepResult Object, which also indicates if the step was successful or not, and return it to our loop in <code class="cx pa pb pc pd b">run()</code>.</p><h1 id="db8a" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">4. Running the Agent</h1><p id="017f" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Now we can test our agent with the previous example, directly equipping it with a <code class="cx pa pb pc pd b">get_current_date_tool</code> as well. Here, we can set our previously defined <code class="cx pa pb pc pd b">validate_missing</code> attribute to <code class="cx pa pb pc pd b">False</code>, since the tool doesn't need any input argument.</p><pre class="pe pf pg ph pi pj pd pk bp pl bb bk"><span id="da2e" class="pm oa gl pd b bg pn po l pp pq">class DateTool(BaseModel):  <br/>    x: str = None  <br/><br/>get_date_tool = Tool(  <br/>    name="get_current_date",  <br/>    model=DateTool,  <br/>    function=lambda: datetime.now().strftime("%Y-%m-%d"),  <br/>    validate_missing=False  <br/>)  <br/>      <br/>tools = [  <br/>    add_expense_tool,   <br/>    report_tool,  <br/>    get_date_tool  <br/>]  <br/>  <br/>agent = OpenAIAgent(tools, client)<br/>agent.run("I have spent 5$ on a coffee today please track my expense. The tax rate is 0.2.")</span></pre><pre class="pr pj pd pk bp pl bb bk"><span id="9fa9" class="pm oa gl pd b bg pn po l pp pq">START: Starting Agent with Input: <br/>"I have spend 5$ on a coffee today please track my expense. The tax rate is 0.2."<br/><br/><br/>Tool Call: get_current_date<br/>Args: {}<br/>tool_result: 2024-03-15<br/><br/><br/>Tool Call: add_expense_tool<br/>Args: {'description': 'Coffee expense', 'net_amount': 5, 'tax_rate': 0.2, 'date': '2024-03-15'}<br/>error: Missing values: gross_amount<br/><br/><br/>Tool Call: add_expense_tool<br/>Args: {'description': 'Coffee expense', 'net_amount': 5, 'tax_rate': 0.2, 'date': '2024-03-15', 'gross_amount': 6}<br/>tool_result: Added expense: {'description': 'Coffee expense', 'net_amount': 5, 'tax_rate': 0.2, 'date': '2024-03-15', 'gross_amount': 6} to the database.<br/>Error: No tool calls were returned.<br/><br/><br/>Tool Call: Name: report_tool<br/>Args: {'report': 'Expense successfully tracked for coffee purchase.'}<br/>tool_result: Reported: Expense successfully tracked for coffee purchase.<br/><br/><br/>Final Result: Reported: Expense successfully tracked for coffee purchase.</span></pre><p id="1a00" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Following the successful execution of our prototype agent, it’s noteworthy to emphasize how effectively the agent utilized the designated tools according to plan. Initially, it invoked the <code class="cx pa pb pc pd b">get_current_date_tool</code>, establishing a foundational timestamp for the expense entry. Subsequently, when attempting to log the expense via the <code class="cx pa pb pc pd b">add_expense_tool</code>, our intelligently designed tool class identified a missing <code class="cx pa pb pc pd b">gross_amount</code>—a crucial piece of information for accurate financial tracking. Impressively, the agent autonomously resolved this by calculating the <code class="cx pa pb pc pd b">gross_amount</code> using the provided <code class="cx pa pb pc pd b">tax_rate</code>.</p><p id="3724" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">It’s important to mention that in our test run, the nature of the input expense — whether the $5 spent on coffee was net or gross — wasn’t explicitly specified. At this juncture, such specificity wasn’t required for the agent to perform its task successfully. However, this brings to light a valuable insight for refining our agent’s understanding and interaction capabilities: Incorporating such detailed information into our initial system prompt could significantly enhance the agent’s accuracy and efficiency in processing expense entries. This adjustment would ensure a more comprehensive grasp of financial data right from the outset.</p><h1 id="f9e8" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">Key Takeaways</h1><ol class=""><li id="a814" class="nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny ps pt pu bk"><strong class="nf gm">Iterative Development</strong>: The project underscores the critical nature of an iterative development cycle, fostering continuous improvement through feedback. This approach is paramount in AI, where variability is the norm, necessitating an adaptable and responsive development strategy.</li><li id="0dc0" class="nd ne gl nf b hj pv nh ni hm pw nk nl nm px no np nq py ns nt nu pz nw nx ny ps pt pu bk"><strong class="nf gm">Handling Uncertainty</strong>: Our journey highlighted the significance of elegantly managing ambiguities and errors. Innovations such as optional parameters and rigorous input validation have proven instrumental in enhancing both the reliability and user experience of the agent.</li><li id="50ee" class="nd ne gl nf b hj pv nh ni hm pw nk nl nm px no np nq py ns nt nu pz nw nx ny ps pt pu bk"><strong class="nf gm">Customized Agent Workflows for Specific Tasks</strong>: A key insight from this work is the importance of customizing agent workflows to suit particular use cases. Beyond assembling a suite of tools, the strategic design of tool interactions and responses is vital. This customization ensures the agent effectively addresses specific challenges, leading to a more focused and efficient problem-solving approach.</li></ol><p id="15bd" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The journey we have embarked upon is just the beginning of a larger exploration into the world of AI agents and their applications in various domains. As we continue to push the boundaries of what’s possible with AI, we invite you to join us on this exciting adventure. By building upon the foundation laid in this article and staying tuned for the upcoming enhancements, you will witness firsthand how AI agents can revolutionize the way businesses and individuals handle their data and automate complex tasks.</p><p id="ce1a" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Together, let us embrace the power of AI and unlock its potential to transform the way we work and interact with technology. The future of AI is bright, and we are at the forefront of shaping it, one reliable agent at a time.</p><h1 id="97a0" class="nz oa gl bf ob oc od hl oe of og ho oh oi oj ok ol om on oo op oq or os ot ou bk">Looking Ahead</h1><p id="ab1a" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">As we continue our journey in exploring the potential of AI agents, the upcoming articles will focus on expanding the capabilities of our prototype and integrating it with real-world systems. In the next article, we will dive into designing a robust project structure that allows our agent to interact seamlessly with SQL databases. By leveraging the agent developed in this article, we will demonstrate how AI can efficiently manage and manipulate data stored in databases, opening up a world of possibilities for automating data-related tasks.</p><p id="9ee7" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Building upon this foundation, the third article in the series will introduce advanced query features, enabling our agent to handle more complex data retrieval and manipulation tasks. We will also explore the concept of a routing agent, which will act as a central hub for managing multiple subagents, each responsible for interacting with specific database tables. This hierarchical structure will allow users to make requests in natural language, which the routing agent will then interpret and direct to the appropriate subagent for execution.</p><p id="fe37" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To further enhance the practicality and security of our AI-powered system, we will introduce a role-based access control system. This will ensure that users have the appropriate permissions to access and modify data based on their assigned roles. By implementing this feature, we can demonstrate how AI agents can be deployed in real-world scenarios while maintaining data integrity and security.</p><p id="ff18" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Through these upcoming enhancements, we aim to showcase the true potential of AI agents in streamlining data management processes and providing a more intuitive and efficient way for users to interact with databases. By combining the power of natural language processing, database management, and role-based access control, we will be laying the groundwork for the development of sophisticated AI assistants that can revolutionize the way businesses and individuals handle their data.</p><p id="118a" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Stay tuned for these exciting developments as we continue to push the boundaries of what’s possible with AI agents in data management and beyond.</p><h2 id="9c7e" class="qa oa gl bf ob qb qc qd oe qe qf qg oh nm qh qi qj nq qk ql qm nu qn qo qp qq bk">Source Code</h2><p id="ec6c" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Additionally, the entire source code for the projects covered is available on GitHub. You can access it at <a class="af gi" href="https://github.com/elokus/AgentDemo" rel="noopener ugc nofollow" target="_blank">https://github.com/elokus/AgentDemo</a>.</p></div></div></div></div>    
</body>
</html>