<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Dynamic Visualizations in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Dynamic Visualizations in Python</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/animated-plotting-in-python-with-opencv-and-matplotlib-d640462c41f4?source=collection_archive---------3-----------------------#2024-11-21">https://towardsdatascience.com/animated-plotting-in-python-with-opencv-and-matplotlib-d640462c41f4?source=collection_archive---------3-----------------------#2024-11-21</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="12a5" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How to animate plots with OpenCV and Matplotlib</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@flip.flo.dev?source=post_page---byline--d640462c41f4--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Florian Trautweiler" class="l ep by dd de cx" src="../Images/63aa57830a244986c400982f7b78d614.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*aAi1iWg3xugW5DYRllftdw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d640462c41f4--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@flip.flo.dev?source=post_page---byline--d640462c41f4--------------------------------" rel="noopener follow">Florian Trautweiler</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d640462c41f4--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 21, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/5c206bd2b728441d5c595ce0f3b6404f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WiDK96J-_PciTF_JwNwYjg.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Tracking a ball trajectory and visualizing it’s vertical position in real-time animated plots</figcaption></figure><p id="8405" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In <strong class="ne fr">Computer Vision</strong> a fundamental goal is to extract meaningful information from static images or video sequences. To understand these signals, it is often helpful to <strong class="ne fr">visualize</strong> them.</p><p id="199c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For example when tracking individual cars on a highway, we could draw bounding boxes around them or in the case of detecting problems in a product line on a conveyor belt, we could use a distinct color for anomalies. But what if the extracted information is of a more <strong class="ne fr">numerical</strong> nature and you want to visualize the <strong class="ne fr">time dynamics</strong> of this signal?</p><p id="50df" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Just showing the value as a number on the screen might not give you enough insight, especially when the signal is changing rapidly. In these cases a great way to visualize the signal is a plot with a <strong class="ne fr">time axis</strong>. In this post I am going to show you how you can combine the power of <strong class="ne fr">OpenCV</strong> and <strong class="ne fr">Matplotlib</strong> to create animated real-time visualizations of such signals.</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="a737" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The code and video I used for this project is available on GitHub:</p><div class="og oh oi oj ok ol"><a href="https://github.com/trflorian/ball-tracking-live-plot?source=post_page-----d640462c41f4--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="om ab ig"><div class="on ab co cb oo op"><h2 class="bf fr hw z io oq iq ir or it iv fp bk">GitHub - trflorian/ball-tracking-live-plot: Tracking a ball using OpenCV and plotting the…</h2><div class="os l"><h3 class="bf b hw z io oq iq ir or it iv dx">Tracking a ball using OpenCV and plotting the trajectory using Matplotlib - trflorian/ball-tracking-live-plot</h3></div><div class="ot l"><p class="bf b dy z io oq iq ir or it iv dx">github.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz lr ol"/></div></div></a></div><h1 id="8e53" class="pa pb fq bf pc pd pe gq pf pg ph gt pi pj pk pl pm pn po pp pq pr ps pt pu pv bk">Plotting a Ball Trajectory</h1><p id="75ab" class="pw-post-body-paragraph nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx fj bk">Let’s explore a toy problem where I recorded a video of a ball thrown vertically into the air. The goal is to track the ball in the video and plot it’s <strong class="ne fr">position <em class="qb">p(t)</em></strong>, <strong class="ne fr">velocity <em class="qb">v(t)</em> </strong>and <strong class="ne fr">acceleration <em class="qb">a(t)</em> </strong>over time.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/cbb6dde91a35cfe409e6e7077d25dfa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JghyDAHgIhAP7X-AJmajRA.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Input Video</figcaption></figure><p id="74ab" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s define our reference frame to be the camera and for simplicity we only track the vertical position of the ball in the image. We expect the position to be a parabola, the velocity to linearly decrease and the acceleration to be constant.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qc"><img src="../Images/e0854134188a624ac8728d8b27a37126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nR3o11tDSahaw0dJXVZx5Q.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Sketch of graphs we should expect</figcaption></figure><h2 id="18e1" class="qd pb fq bf pc qe qf qg pf qh qi qj pi nl qk ql qm np qn qo qp nt qq qr qs qt bk">Ball Segmentation</h2><p id="8a2f" class="pw-post-body-paragraph nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx fj bk">In a first step we need to identify the ball in each frame of the video sequence. Since the camera remains static, an easy way to detect the ball is using a background subtraction model, combined with a color model to remove the hand in the frame.</p><p id="ba74" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First let’s get our video clip displayed with a simple loop using <a class="af qu" href="https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">VideoCapture</strong></a> from <strong class="ne fr">OpenCV</strong>. We simply restart the video clip once it has reached its end. We also make sure to playback the video at the original frame rate by calculating the <strong class="ne fr">sleep_time</strong> in milliseconds based on the FPS of the video. Also make sure to release the resources at the end and close the windows.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="82e4" class="qz pb fq qw b bg ra rb l rc rd">import cv2<br/><br/>cap = cv2.VideoCapture("ball.mp4")<br/>fps = int(cap.get(cv2.CAP_PROP_FPS))<br/><br/>while True:<br/>    ret, frame = cap.read()<br/>    if not ret:<br/>        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)<br/>        continue<br/><br/>    cv2.imshow("Frame", frame)<br/><br/>    sleep_time = 1000 // fps<br/>    key = cv2.waitKey(sleep_time) &amp; 0xFF<br/>    if key &amp; 0xFF == ord("q"):<br/>        break<br/><br/>cap.release()<br/>cv2.destroyAllWindows()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/de085d4139f222d448033a6c43aa09a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O2dyPoKK8F6Aeg8udY3OMw.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Visualization of Input Video</figcaption></figure><p id="5ee3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s first work on extracting a binary segmentation mask for the ball. This essentially means that we want to create a mask that is active for pixels of the ball and inactive for all other pixels. To do this, I will combine two masks: a motion mask and a color mask. The motion mask extracts the moving parts and the color mask mainly gets rid of the hand in the frame.</p><p id="1a07" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For the color filter, we can convert the image to the <a class="af qu" href="https://en.wikipedia.org/wiki/HSL_and_HSV" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">HSV</strong></a> color space and select a specific hue range (20–100) that contains the green colors of the ball but no skin color tones. I don’t filter on the saturation or brightness values, so we can use the full range (0–255).</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="853d" class="qz pb fq qw b bg ra rb l rc rd"># filter based on color<br/>hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)<br/>mask_color = cv2.inRange(hsv, (20, 0, 0), (100, 255, 255))</span></pre><p id="2b24" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To create a motion mask we can use a simple <a class="af qu" href="https://en.wikipedia.org/wiki/Foreground_detection#Background_mixture_models" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">background subtraction</strong></a> model. We use the first frame of the video for the background by setting the <strong class="ne fr">learning rate to 1</strong>. In the loop, we apply the background model to get the foreground mask, but don’t integrate new frames into it by setting the <strong class="ne fr">learning rate to 0</strong>.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="e8ae" class="qz pb fq qw b bg ra rb l rc rd">...<br/><br/># initialize background model<br/>bg_sub = cv2.createBackgroundSubtractorMOG2(varThreshold=50, detectShadows=False)<br/>ret, frame0 = cap.read()<br/>if not ret:<br/>    print("Error: cannot read video file")<br/>    exit(1)<br/>bg_sub.apply(frame0, learningRate=1.0)<br/><br/>while True:<br/>  ...<br/>  # filter based on motion<br/>  mask_fg = bg_sub.apply(frame, learningRate=0)</span></pre><p id="7490" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In the next step, we can combine the two masks and apply a <a class="af qu" href="https://en.wikipedia.org/wiki/Opening_(morphology)" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">opening morphology</strong></a><strong class="ne fr"> </strong>to get rid of the small noise and we end up with a perfect segmentation of the ball.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="666a" class="qz pb fq qw b bg ra rb l rc rd"># combine both masks<br/>mask = cv2.bitwise_and(mask_color, mask_fg)<br/>mask = cv2.morphologyEx(<br/>    mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (13, 13))<br/>)</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/9267b761f4ad6bc0b8b5c340245d198d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Z_S6NgjgTu-2zkMVNDvsA.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><strong class="bf pc">Top Left:</strong> Video Sequence, <strong class="bf pc">Top Right:</strong> Color Mask, <strong class="bf pc">Bottom Left:</strong> Motion Mask, <strong class="bf pc">Bottom Right:</strong> Combined Mask</figcaption></figure><h2 id="e261" class="qd pb fq bf pc qe qf qg pf qh qi qj pi nl qk ql qm np qn qo qp nt qq qr qs qt bk">Tracking the Ball</h2><p id="fea3" class="pw-post-body-paragraph nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx fj bk">The only thing we’re left with is our ball in the mask. To track the center of the ball, I first extract the contour of the ball and then take the center of its bounding box as reference point. In case some noise would make it through our mask, I am filtering the detected contours by size and only look at the largest one.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="3387" class="qz pb fq qw b bg ra rb l rc rd"># find largest contour corresponding to the ball we want to track<br/>contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)<br/>if len(contours) &gt; 0:<br/>    largest_contour = max(contours, key=cv2.contourArea)<br/>    x, y, w, h = cv2.boundingRect(largest_contour)<br/>    center = (x + w // 2, y + h // 2)</span></pre><p id="fcae" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can also add some annotations to our frame to visualize our detection. I am going to draw two circles, one for the center and one for the perimeter of the ball.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="32d4" class="qz pb fq qw b bg ra rb l rc rd">cv2.circle(frame, center, 30, (255, 0, 0), 2)<br/>cv2.circle(frame, center, 2, (255, 0, 0), 2)</span></pre><p id="9eac" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To keep track of the ball position, we can use a <strong class="ne fr">list</strong>. Whenever we detect the ball, we simply add the center position to the list. We can also visualize the trajectory by drawing lines between each of the segments in the tracked position list.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="e5bf" class="qz pb fq qw b bg ra rb l rc rd">tracked_pos = []<br/><br/><br/>while True:<br/>  ...<br/><br/>  if len(contours) &gt; 0:<br/>    ... <br/>    tracked_pos.append(center)<br/>  <br/><br/>  # draw trajectory<br/>  for i in range(1, len(tracked_pos)):<br/>      cv2.line(frame, tracked_pos[i - 1], tracked_pos[i], (255, 0, 0), 1)</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk re"><img src="../Images/f650435618b04b8ca29fd3cd5b1b6325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Im3OZebDvxYUGHWBtNqiw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Visualization of the Ball Trajectory</figcaption></figure><h2 id="904d" class="qd pb fq bf pc qe qf qg pf qh qi qj pi nl qk ql qm np qn qo qp nt qq qr qs qt bk">Creating the Plot</h2><p id="0678" class="pw-post-body-paragraph nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx fj bk">Now that we can track the ball, let’s start exploring how we can plot the signal using <strong class="ne fr">matplotlib</strong>. In a first step, we can create the final plot at the end of our video first and then in a second step we worry about how to animate it in real-time. To show the position, velocity and acceleration we can use three horizontally aligned subplots:</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="ad3e" class="qz pb fq qw b bg ra rb l rc rd">fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 2), dpi=100)<br/><br/>axs[0].set_title("Position")<br/>axs[0].set_ylim(0, 700)<br/>axs[1].set_title("Velocity")<br/>axs[1].set_ylim(-200, 200)<br/>axs[2].set_title("Acceleration")<br/>axs[2].set_ylim(-30, 10)<br/><br/>for ax in axs:<br/>    ax.set_xlim(0, 20)<br/>    ax.grid(True)</span></pre><p id="b808" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We are only interested in the y position in the image (array index 1), and to get a zero-offset position plot, we can subtract the first position.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="5749" class="qz pb fq qw b bg ra rb l rc rd">pos0 = tracked_pos[0][1]<br/>pos = np.array([pos0 - pos[1] for pos in tracked_pos])</span></pre><p id="b236" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For the velocity we can use the difference in position as an approximation and for the acceleration we can use the difference of the velocity.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="5cc7" class="qz pb fq qw b bg ra rb l rc rd">vel = np.diff(pos)<br/>acc = np.diff(vel)</span></pre><p id="4895" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And now we can plot these three values:</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="e529" class="qz pb fq qw b bg ra rb l rc rd">axs[0].plot(range(len(pos)), pos, c="b")<br/>axs[1].plot(range(len(vel)), vel, c="b")<br/>axs[2].plot(range(len(acc)), acc, c="b")<br/><br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rf"><img src="../Images/1d470d2c80763c501bdbc00c9af25a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RHe61NgX0CYOEZ7NjS0A9g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Static Plots of the Position, Velocity and Acceleration</figcaption></figure><h2 id="be3d" class="qd pb fq bf pc qe qf qg pf qh qi qj pi nl qk ql qm np qn qo qp nt qq qr qs qt bk">Animating the Plot</h2><p id="f558" class="pw-post-body-paragraph nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx fj bk">Now on to the fun part, we want to make this plot dynamic! Since we are working in an OpenCV GUI loop, we cannot directly use the <strong class="ne fr">show</strong> function from <strong class="ne fr">matplotlib</strong>, as this will just block the loop and not run our program. Instead we need to make use of some trickery ✨</p><p id="937b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The main idea is to draw the plots in memory into a buffer and then display this buffer in our OpenCV window. By manually calling the draw function of the canvas, we can force the figure to be rendered to a buffer. We can then get this buffer and convert it to an array. Since the buffer is in <strong class="ne fr">RGB</strong> format, but OpenCV uses <strong class="ne fr">BGR</strong>, we need to convert the color order.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="9ecb" class="qz pb fq qw b bg ra rb l rc rd">fig.canvas.draw()<br/><br/>buf = fig.canvas.buffer_rgba()<br/>plot = np.asarray(buf)<br/>plot = cv2.cvtColor(plot, cv2.COLOR_RGB2BGR)</span></pre><p id="3f1f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Make sure that the <strong class="ne fr">axs.plot</strong> calls are now inside the frame loop:</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="5e2b" class="qz pb fq qw b bg ra rb l rc rd">while True:<br/>  ...<br/><br/>  axs[0].plot(range(len(pos)), pos, c="b")<br/>  axs[1].plot(range(len(vel)), vel, c="b")<br/>  axs[2].plot(range(len(acc)), acc, c="b")<br/><br/>  ... </span></pre><p id="53e4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now we can simply display the plot using the <strong class="ne fr">imshow</strong> function from OpenCV.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="8553" class="qz pb fq qw b bg ra rb l rc rd">cv2.imshow("Plot", plot)</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rg"><img src="../Images/4587f731ece8dfd1948f4c91e8287b31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*AUCcY1OyPlv_ZC64OiGnZQ.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Animated Plots</figcaption></figure><p id="7386" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And voilà, you get your animated plot! However you will notice that the performance is quite low. Re-drawing the full plot every frame is quite expensive. To improve the performance, we need to make use of <a class="af qu" href="https://matplotlib.org/stable/users/explain/animations/blitting.html" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">blitting</strong></a>. This is an advanced rendering technique, that draws static parts of the plot into a background image and only re-draws the changing foreground elements. To set this up, we first need to define a reference to each of our three plots before the frame loop.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="a742" class="qz pb fq qw b bg ra rb l rc rd">pl_pos = axs[0].plot([], [], c="b")[0]<br/>pl_vel = axs[1].plot([], [], c="b")[0]<br/>pl_acc = axs[2].plot([], [], c="b")[0]</span></pre><p id="ab0a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then we need to draw the background of the figure once before the loop and get the background of each axis.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="dc2e" class="qz pb fq qw b bg ra rb l rc rd">fig.canvas.draw()<br/>bg_axs = [fig.canvas.copy_from_bbox(ax.bbox) for ax in axs]</span></pre><p id="cff0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In the loop, we can now change the data for each of the plots and then for each subplot we need to restore the region’s background, draw the new plot and then call the <strong class="ne fr">blit</strong> function to apply the changes.</p><pre class="mm mn mo mp mq qv qw qx bp qy bb bk"><span id="90d4" class="qz pb fq qw b bg ra rb l rc rd"># Update plot data<br/>pl_pos.set_data(range(len(pos)), pos)<br/>pl_vel.set_data(range(len(vel)), vel)<br/>pl_acc.set_data(range(len(acc)), acc)<br/><br/># Blit Pos<br/>fig.canvas.restore_region(bg_axs[0])<br/>axs[0].draw_artist(pl_pos)<br/>fig.canvas.blit(axs[0].bbox)<br/><br/># Blit Vel<br/>fig.canvas.restore_region(bg_axs[1])<br/>axs[1].draw_artist(pl_vel)<br/>fig.canvas.blit(axs[1].bbox)<br/><br/># Blit Acc<br/>fig.canvas.restore_region(bg_axs[2])<br/>axs[2].draw_artist(pl_acc)<br/>fig.canvas.blit(axs[2].bbox)</span></pre><p id="dd71" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And here we go, the plotting is sped up and the performance has drastically improved.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rg"><img src="../Images/e9a892839ffccb8b9c85b6df8e94d300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*UxwyfZn5XclplPhw6cp1ig.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Optimized Plots</figcaption></figure><h1 id="cf78" class="pa pb fq bf pc pd pe gq pf pg ph gt pi pj pk pl pm pn po pp pq pr ps pt pu pv bk">Conclusion</h1><p id="9a53" class="pw-post-body-paragraph nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx fj bk">In this post, you learned how to apply simple Computer Vision techniques to extract a moving foreground object and track it’s trajectory. We then created an animated plot using <strong class="ne fr">matplotlib</strong> and <strong class="ne fr">OpenCV</strong>. The plotting is demonstrated on a toy example video with a ball being thrown vertically into the air. However, the tools and techniques used in this project are useful for all kinds of tasks and real-world applications! The full source code is available from my GitHub. I hope you learned something today, happy coding and take care!</p><div class="og oh oi oj ok ol"><a href="https://github.com/trflorian/ball-tracking-live-plot?source=post_page-----d640462c41f4--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="om ab ig"><div class="on ab co cb oo op"><h2 class="bf fr hw z io oq iq ir or it iv fp bk">GitHub - trflorian/ball-tracking-live-plot: Tracking a ball using OpenCV and plotting the…</h2><div class="os l"><h3 class="bf b hw z io oq iq ir or it iv dx">Tracking a ball using OpenCV and plotting the trajectory using Matplotlib - trflorian/ball-tracking-live-plot</h3></div><div class="ot l"><p class="bf b dy z io oq iq ir or it iv dx">github.com</p></div></div><div class="ou l"><div class="rh l ow ox oy ou oz lr ol"/></div></div></a></div></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="2a20" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qb">All visualizations in this post were created by the author.</em></p></div></div></div></div>    
</body>
</html>