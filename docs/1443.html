<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Task-Aware RAG Strategies for When Sentence Similarity Fails</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Task-Aware RAG Strategies for When Sentence Similarity Fails</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/task-aware-rag-strategies-for-when-sentence-similarity-fails-54c44690fee3?source=collection_archive---------2-----------------------#2024-06-10">https://towardsdatascience.com/task-aware-rag-strategies-for-when-sentence-similarity-fails-54c44690fee3?source=collection_archive---------2-----------------------#2024-06-10</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="a911" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Improving retrieval beyond semantic similarity</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@aimichael?source=post_page---byline--54c44690fee3--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Michael Ryaboy" class="l ep by dd de cx" src="../Images/783a6c1ed59277776003aaeab69f0b07.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*iTWSk2J3q-7jAnKaxSgKnQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--54c44690fee3--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@aimichael?source=post_page---byline--54c44690fee3--------------------------------" rel="noopener follow">Michael Ryaboy</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--54c44690fee3--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">16 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 10, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/29b772c537ea929ba301f21b378a2693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uK7pt6aRYTf-2l6f7T_5og.jpeg"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by <a class="af nb" href="https://unsplash.com/@joshgmit" rel="noopener ugc nofollow" target="_blank">Joshua Golde</a> on <a class="af nb" href="https://unsplash.com/photos/white-stage-qIu77BsFdds" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b494" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Vector databases have revolutionized the way we search and retrieve information by allowing us to embed data and quickly search over it using the same embedding model, with only the query being embedded at inference time. However, despite their impressive capabilities, vector databases have a fundamental flaw: they treat queries and documents in the same way. This can lead to suboptimal results, especially when dealing with complex tasks like matchmaking, where queries and documents are inherently different.</p><p id="7635" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The challenge of Task-aware RAG (Retriever-augmented Generation) lies in its requirement to retrieve documents based not only on their semantic similarity but also on additional contextual instructions. This adds a layer of complexity to the retrieval process, as it must consider multiple dimensions of relevance.</p><h2 id="5eeb" class="ny nz fq bf oa ob oc od oe of og oh oi nl oj ok ol np om on oo nt op oq or os bk">Here are some examples of Task-Aware RAG problems:</h2><p id="cf7a" class="pw-post-body-paragraph nc nd fq ne b go ot ng nh gr ou nj nk nl ov nn no np ow nr ns nt ox nv nw nx fj bk"><strong class="ne fr">1. Matching Company Problem Statements to Job Candidates</strong></p><ul class=""><li id="2107" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oy oz pa bk">Query: “Find candidates with experience in scalable system design and a proven track record in optimizing large-scale databases, suitable for addressing our current challenge of enhancing data retrieval speeds by 30% within the existing infrastructure.”</li><li id="61dd" class="nc nd fq ne b go pb ng nh gr pc nj nk nl pd nn no np pe nr ns nt pf nv nw nx oy oz pa bk">Context: This query aims to directly connect the specific technical challenge of a company with potential job candidates who have relevant skills and experience.</li></ul><p id="4ba4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">2. Matching Pseudo-Domains to Startup Descriptions</strong></p><ul class=""><li id="55ef" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oy oz pa bk">Query: “Match a pseudo-domain for a startup that specializes in AI-driven, personalized learning platforms for high school students, emphasizing interactive and adaptive learning technologies.”</li><li id="da2e" class="nc nd fq ne b go pb ng nh gr pc nj nk nl pd nn no np pe nr ns nt pf nv nw nx oy oz pa bk">Context: Designed to find an appropriate, catchy pseudo-domain name that reflects the innovative and educational focus of the startup. A pseudo-domain name is a domain name based on a pseudo-word, which is a word that sound real but isn’t.</li></ul><p id="66a3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">3. Investor-Startup Matchmaking</strong></p><ul class=""><li id="cac6" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oy oz pa bk">Query: “Identify investors interested in early-stage biotech startups, with a focus on personalized medicine and a history of supporting seed rounds in the healthcare sector.”</li><li id="21fa" class="nc nd fq ne b go pb ng nh gr pc nj nk nl pd nn no np pe nr ns nt pf nv nw nx oy oz pa bk">Context: This query seeks to match startups in the biotech field, particularly those working on personalized medicine, with investors who are not only interested in biotech but have also previously invested in similar stages and sectors.</li></ul><p id="ae82" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">4. Retrieving Specific Kinds of Documents</strong></p><ul class=""><li id="0432" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oy oz pa bk">Query: “Retrieve recent research papers and case studies that discuss the application of blockchain technology in securing digital voting systems, with a focus on solutions tested in the U.S. or European elections.”</li><li id="ee81" class="nc nd fq ne b go pb ng nh gr pc nj nk nl pd nn no np pe nr ns nt pf nv nw nx oy oz pa bk">Context: Specifies the need for academic and practical insights on a particular use of blockchain, highlighting the importance of geographical relevance and recent applications</li></ul><h2 id="1a63" class="ny nz fq bf oa ob oc od oe of og oh oi nl oj ok ol np om on oo nt op oq or os bk">The Challenge</h2><p id="7151" class="pw-post-body-paragraph nc nd fq ne b go ot ng nh gr ou nj nk nl ov nn no np ow nr ns nt ox nv nw nx fj bk">Let’s consider a scenario where a company is facing various problems, and we want to match these problems with the most relevant job candidates who have the skills and experience to address them. Here are some example problems:</p><ol class=""><li id="3d1f" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pg oz pa bk">“High employee turnover is prompting a reassessment of core values and strategic objectives.”<br/>2. “Perceptions of opaque decision-making are affecting trust levels within the company.”<br/>3. “Lack of engagement in remote training sessions signals a need for more dynamic content delivery.”</li></ol><p id="b42b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can generate true positive and hard negative candidates for each problem using an LLM. For example:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="cf50" class="pl nz fq pi b bg pm pn l po pp">problem_candidates = {<br/> "High employee turnover is prompting a reassessment of core values and strategic objectives.": {<br/> "True Positive": "Initiated a company-wide cultural revitalization project that focuses on autonomy and purpose to enhance employee retention.",<br/> "Hard Negative": "Skilled in rapid recruitment to quickly fill vacancies and manage turnover rates."<br/> },<br/> # … (more problem-candidate pairs)<br/>}</span></pre><p id="5abe" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Even though the hard negatives may appear similar on the surface and could be closer in the embedding space to the query, the true positives are clearly better fits for addressing the specific problems.</p><h2 id="f308" class="ny nz fq bf oa ob oc od oe of og oh oi nl oj ok ol np om on oo nt op oq or os bk">The Solution: Instruction-Tuned Embeddings, Reranking, and LLMs</h2><p id="8dfa" class="pw-post-body-paragraph nc nd fq ne b go ot ng nh gr ou nj nk nl ov nn no np ow nr ns nt ox nv nw nx fj bk">To tackle this challenge, we propose a multi-step approach that combines instruction-tuned embeddings, reranking, and LLMs:</p><h2 id="7bcc" class="ny nz fq bf oa ob oc od oe of og oh oi nl oj ok ol np om on oo nt op oq or os bk">1. Instruction-Tuned Embeddings</h2><p id="e675" class="pw-post-body-paragraph nc nd fq ne b go ot ng nh gr ou nj nk nl ov nn no np ow nr ns nt ox nv nw nx fj bk">Instruction-Tuned embeddings function like a bi-encoder, where both the query and document embeddings are processed separately and then their embeddings are compared. By providing additional instructions to each embedding, we can bring them to a new embedding space where they can be more effectively compared.</p><p id="30c5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The key advantage of instruction-tuned embeddings is that they allow us to encode specific instructions or context into the embeddings themselves. This is particularly useful when dealing with complex tasks like job description-resume matchmaking, where the queries (job descriptions) and documents (resumes) have different structures and content.</p><p id="e6d4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By prepending task-specific instructions to the queries and documents before embedding them, we can theoretically guide the embedding model to focus on the relevant aspects and capture the desired semantic relationships. For example:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="1121" class="pl nz fq pi b bg pm pn l po pp">documents_with_instructions = [<br/> "Represent an achievement of a job candidate achievement for retrieval: " + document <br/> if document in true_positives <br/> else document <br/> for document in documents<br/>]</span></pre><p id="8bc8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This instruction prompts the embedding model to represent the documents as job candidate achievements, making them more suitable for retrieval based on the given job description.<br/>Still, RAG systems are difficult to interpret without evals, so let’s write some code to check the accuracy of three different approaches:<br/>1. Naive Voyage AI instruction-tuned embeddings with no additional instructions.</p><p id="dac1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">2. Voyage AI instruction-tuned embeddings with additional context to the query and document.</p><p id="8df9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">3. Voyage AI non-instruction-tuned embeddings.</p><p id="d3aa" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We use Voyage AI embeddings because they are currently best-in-class, and at the time of this writing comfortably sitting at the top of the MTEB leaderboard. We are also able to use three different strategies with vectors of the same size, which will make comparing them easier. 1024 dimensions also happens to be much smaller than any embedding modals that come even close to performing as well.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pq"><img src="../Images/9041170cc2c5481c9ba3b1c1f4fe87b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0V8-GGL9SG1ecANcKUXjvg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">MTEB leaderboard</figcaption></figure><p id="ed02" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In theory, we should see instruction-tuned embeddings perform better at this task than non-instruction-tuned embeddings, even if just because they are higher on the leaderboard. To check, we will first embed our data.</p><p id="c698" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">When we do this, we try prepending the string: “Represent the most relevant experience of a job candidate for retrieval: “ to our documents, which gives our embeddings a bit more context about our documents.</p><p id="54b4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If you want to follow along, check out this <a class="af nb" href="https://colab.research.google.com/drive/1iPy1WtOEPHU5YqEzHdiSpvUFL4JElGVJ?usp=sharing" rel="noopener ugc nofollow" target="_blank">colab link</a>.</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="7ed5" class="pl nz fq pi b bg pm pn l po pp">import voyageai<br/><br/>vo = voyageai.Client(api_key="VOYAGE_API_KEY")</span></pre><pre class="pr ph pi pj bp pk bb bk"><span id="82c3" class="pl nz fq pi b bg pm pn l po pp">problems = []<br/>true_positives = []<br/>hard_negatives = []<br/>for problem, candidates in problem_candidates.items():<br/>    problems.append(problem)<br/>    true_positives.append(candidates["True Positive"])<br/>    hard_negatives.append(candidates["Hard Negative"])<br/><br/>documents = true_positives + hard_negatives<br/>documents_with_instructions = ["Represent the most relevant experience of a job candidate for retrieval: " + document for document in documents]<br/><br/>batch_size = 50<br/><br/>resume_embeddings_naive = []<br/>resume_embeddings_task_based = []<br/>resume_embeddings_non_instruct  = []<br/><br/>for i in range(0, len(documents), batch_size):<br/>    resume_embeddings_naive += vo.embed(<br/>        documents[i:i + batch_size], model="voyage-large-2-instruct", input_type='document'<br/>    ).embeddings<br/><br/>for i in range(0, len(documents), batch_size):<br/>    resume_embeddings_task_based += vo.embed(<br/>        documents_with_instructions[i:i + batch_size], model="voyage-large-2-instruct", input_type=None<br/>    ).embeddings<br/><br/>for i in range(0, len(documents), batch_size):<br/>    resume_embeddings_non_instruct += vo.embed(<br/>        documents[i:i + batch_size], model="voyage-2", input_type='document' # we are using a non-instruct model to see how well it works<br/>    ).embeddings</span></pre><p id="c16f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We then insert our vectors into a vector database. We don’t strictly need one for this demo, but a vector database with metadata filtering capabilities will allow for cleaner code, and for eventually scaling this test up. We will be using KDB.AI, where I’m a Developer Advocate. However, any vector database with metadata filtering capabilities will work just fine.</p><p id="fbdc" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To get started with KDB.AI, go to <a class="af nb" href="https://kdb.ai" rel="noopener ugc nofollow" target="_blank">kdb.ai</a> to fetch your endpoint and api key.</p><p id="eb9b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then, let’s instantiate the client and import some libraries.</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="0d57" class="pl nz fq pi b bg pm pn l po pp">!pip install kdbai_client<br/><br/>import os<br/>from getpass import getpass<br/>import kdbai_client as kdbai<br/>import time</span></pre><p id="4919" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Connect to our session with our endpoint and api key.</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="4a54" class="pl nz fq pi b bg pm pn l po pp">KDBAI_ENDPOINT = (<br/>    os.environ["KDBAI_ENDPOINT"]<br/>    if "KDBAI_ENDPOINT" in os.environ<br/>    else input("KDB.AI endpoint: ")<br/>)<br/>KDBAI_API_KEY = (<br/>    os.environ["KDBAI_API_KEY"]<br/>    if "KDBAI_API_KEY" in os.environ<br/>    else getpass("KDB.AI API key: ")<br/>)<br/><br/>session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)</span></pre><p id="7221" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Create our table:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="8a3c" class="pl nz fq pi b bg pm pn l po pp"># We use the default database<br/>database = session.database("default")<br/><br/># Define the schema<br/>schema = [<br/>    {"name": "id", "type": "str"},<br/>    {"name": "embedding_type", "type": "str"},<br/>    {"name": "vectors", "type": "float64s"}  # Use float64s as per the migration guide<br/>]<br/><br/># Define the index<br/>indexes = [<br/>    {<br/>        "name": "embedding_index",  # Name of the index<br/>        "type": "flat",  # Index type<br/>        "params": {"dims": 1024, "metric": "CS"},  # Specify the dimensions and metric<br/>        "column": "vectors"  # Apply the index to the 'vectors' column<br/>    }<br/>]<br/><br/># Create the table<br/>table = database.create_table("data", schema=schema, indexes=indexes)</span></pre><p id="941a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Insert the candidate achievements into our index, with an “embedding_type” metadata filter to separate our embeddings:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="f86f" class="pl nz fq pi b bg pm pn l po pp">import pandas as pd<br/>embeddings_df = pd.DataFrame(<br/>    {<br/>        "id": documents + documents + documents,<br/>        "embedding_type": ["naive"] * len(documents) + ["task"] * len(documents) + ["non_instruct"] * len(documents),<br/>        "vectors": resume_embeddings_naive + resume_embeddings_task_based + resume_embeddings_non_instruct,<br/>    }<br/>)<br/><br/>table.insert(embeddings_df)</span></pre><p id="0dc7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And finally, evaluate the three methods above:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="f9d7" class="pl nz fq pi b bg pm pn l po pp">import numpy as np<br/><br/># Function to embed problems and calculate similarity<br/>def get_embeddings_and_results(problems, true_positives, model_type, tag, input_prefix=None):<br/>    if input_prefix:<br/>        problems = [input_prefix + problem for problem in problems]<br/>    embeddings = vo.embed(problems, model=model_type, input_type="query" if input_prefix else None).embeddings<br/><br/>    # Retrieve most similar items<br/>    results = []<br/>    most_similar_items = table.search(<br/>        vectors={"embedding_index": embeddings},<br/>        n=1,<br/>        filter=[("=", "embedding_type", tag)]<br/>    )<br/>    most_similar_items = np.array(most_similar_items)<br/>    for i, item in enumerate(most_similar_items):<br/>        most_similar = item[0][0] # the fist item<br/>        results.append((problems[i], most_similar == true_positives[i]))<br/>    return results<br/><br/># Function to calculate and print results<br/>def print_results(results, model_name):<br/>    true_positive_count = sum([result[1] for result in results])<br/>    percent_true_positives = true_positive_count / len(results) * 100<br/>    print(f"\n{model_name} Model Results:")<br/>    for problem, is_true_positive in results:<br/>        print(f"Problem: {problem}, True Positive Found: {is_true_positive}")<br/>    print("\nPercent of True Positives Found:", percent_true_positives, "%")<br/><br/># Embedding, result computation, and tag for each model<br/>models = [<br/>    ("voyage-large-2-instruct", None, 'naive'),<br/>    ("voyage-large-2-instruct", "Represent the problem to be solved used for suitable job candidate retrieval: ", 'task'),<br/>    ("voyage-2", None, 'non_instruct'),<br/>]<br/><br/>for model_type, prefix, tag in models:<br/>    results = get_embeddings_and_results(problems, true_positives, model_type, tag, input_prefix=prefix)<br/>    print_results(results, tag)</span></pre><p id="f925" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here are the results:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="3a5d" class="pl nz fq pi b bg pm pn l po pp">naive Model Results:<br/>Problem: High employee turnover is prompting a reassessment of core values and strategic objectives., True Positive Found: True<br/>Problem: Perceptions of opaque decision-making are affecting trust levels within the company., True Positive Found: True<br/>...<br/>Percent of True Positives Found: 27.906976744186046 %<br/><br/>task Model Results:<br/>...<br/>Percent of True Positives Found: 27.906976744186046 %<br/><br/>non_instruct Model Results:<br/>...<br/>Percent of True Positives Found: 39.53488372093023 %</span></pre><p id="aae0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The instruct model performed worse on this task!</p><p id="e5df" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Our dataset is small enough that this isn’t a significantly large difference (under 35 high quality examples.)</p><p id="5bcf" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Still, this shows that</p><p id="ded3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">a) instruct models alone are not enough to deal with this challenging task.</p><p id="2f3e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">b) while instruct models can lead to good performance on similar tasks, it’s important to always run evals, because in this case I suspected they would do better, which wasn’t true</p><p id="9ef2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">c) there are tasks for which instruct models perform worse</p><h2 id="f133" class="ny nz fq bf oa ob oc od oe of og oh oi nl oj ok ol np om on oo nt op oq or os bk">2. Reranking</h2><p id="0c55" class="pw-post-body-paragraph nc nd fq ne b go ot ng nh gr ou nj nk nl ov nn no np ow nr ns nt ox nv nw nx fj bk">While instruct/regular embedding models can narrow down our candidates somewhat, we clearly need something more powerful that has a better understanding of the relationship between our documents.</p><p id="0a69" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After retrieving the initial results using instruction-tuned embeddings, we employ a cross-encoder (reranker) to further refine the rankings. The reranker considers the specific context and instructions, allowing for more accurate comparisons between the query and the retrieved documents.</p><p id="1602" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Reranking is crucial because it allows us to assess the relevance of the retrieved documents in a more nuanced way. Unlike the initial retrieval step, which relies solely on the similarity between the query and document embeddings, reranking takes into account the actual content of the query and documents.</p><p id="d8d4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By jointly processing the query and each retrieved document, the reranker can capture fine-grained semantic relationships and determine the relevance scores more accurately. This is particularly important in scenarios where the initial retrieval may return documents that are similar on a surface level but not truly relevant to the specific query.</p><p id="ce5b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here’s an example of how we can perform reranking using the Cohere AI reranker (Voyage AI also has an excellent reranker, but when I wrote this article Cohere’s outperformed it. Since then they have come out with a new reranker that according to their internal benchmarks performs just as well or better.)</p><p id="dc10" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First, let’s define our reranking function. We can also use Cohere’s Python client, but I chose to use the REST API because it seemed to run faster.</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="b4ce" class="pl nz fq pi b bg pm pn l po pp">import requests<br/>import json<br/><br/>COHERE_API_KEY = 'COHERE_API_KEY'<br/><br/>def rerank_documents(query, documents, top_n=3):<br/><br/>    # Prepare the headers<br/>    headers = {<br/>        'accept': 'application/json',<br/>        'content-type': 'application/json',<br/>        'Authorization': f'Bearer {COHERE_API_KEY}'<br/>    }<br/><br/>    # Prepare the data payload<br/>    data = {<br/>        "model": "rerank-english-v3.0",<br/>        "query": query,<br/>        "top_n": top_n,<br/>        "documents": documents,<br/>        "return_documents": True<br/>    }<br/><br/>    # URL for the Cohere rerank API<br/>    url = 'https://api.cohere.ai/v1/rerank'<br/><br/>    # Send the POST request<br/>    response = requests.post(url, headers=headers, data=json.dumps(data))<br/><br/>    # Check the response and return the JSON payload if successful<br/>    if response.status_code == 200:<br/>        return response.json()  # Return the JSON response from the server<br/>    else:<br/>        # Raise an exception if the API call failed<br/>        response.raise_for_status()</span></pre><p id="b5d5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, let’s evaluate our reranker. Let’s also see if adding additional context about our task improves performance.</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="fb69" class="pl nz fq pi b bg pm pn l po pp">import cohere<br/><br/>co = cohere.Client('COHERE_API_KEY')<br/>def perform_reranking_evaluation(problem_candidates, use_prefix):<br/>    results = []<br/><br/>    for problem, candidates in problem_candidates.items():<br/>        if use_prefix:<br/>            prefix = "Relevant experience of a job candidate we are considering to solve the problem: "<br/>            query = "Here is the problem we want to solve: " + problem<br/>            documents = [prefix + candidates["True Positive"]] + [prefix + candidate for candidate in candidates["Hard Negative"]]<br/>        else:<br/>            query = problem<br/>            documents = [candidates["True Positive"]]+ [candidate for candidate in candidates["Hard Negative"]]<br/><br/>        reranking_response = rerank_documents(query, documents)<br/>        top_document = reranking_response['results'][0]['document']['text']<br/>        if use_prefix:<br/>            top_document = top_document.split(prefix)[1]<br/><br/>        # Check if the top ranked document is the True Positive<br/>        is_correct = (top_document.strip() == candidates["True Positive"].strip())<br/>        results.append((problem, is_correct))<br/>        # print(f"Problem: {problem}, Use Prefix: {use_prefix}")<br/>        # print(f"Top Document is True Positive: {is_correct}\n")<br/><br/>    # Evaluate overall accuracy<br/>    correct_answers = sum([result[1] for result in results])<br/>    accuracy = correct_answers / len(results) * 100<br/>    print(f"Overall Accuracy with{'out' if not use_prefix else ''} prefix: {accuracy:.2f}%")<br/><br/># Perform reranking with and without prefixes<br/>perform_reranking_evaluation(problem_candidates, use_prefix=True)<br/>perform_reranking_evaluation(problem_candidates, use_prefix=False)</span></pre><p id="1506" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, here are our results:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="8cfd" class="pl nz fq pi b bg pm pn l po pp">Overall Accuracy with prefix: 48.84% <br/>Overall Accuracy without prefixes: 44.19%</span></pre><p id="51ed" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By adding additional context about our task, it might be possible to improve reranking performance. We also see that our reranker performed better than all embedding models, even without additional context, so it should definitely be added to the pipeline. Still, our performance is lacking at under 50% accuracy (we retrieved the top result first for less than 50% of queries), there must be a way to do much better!</p><p id="b758" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The best part of rerankers are that they work out of the box, but we can use our golden dataset (our examples with hard negatives) to <a class="af nb" href="https://docs.cohere.com/docs/rerank-starting-the-training" rel="noopener ugc nofollow" target="_blank">fine-tune</a> our reranker to make it much more accurate. This might improve our reranking performance by a lot, but it might not generalize to different kinds of queries, and fine-tuning a reranker every time our inputs change can be frustrating.</p><h2 id="2fb5" class="ny nz fq bf oa ob oc od oe of og oh oi nl oj ok ol np om on oo nt op oq or os bk">3. LLMs</h2><p id="062f" class="pw-post-body-paragraph nc nd fq ne b go ot ng nh gr ou nj nk nl ov nn no np ow nr ns nt ox nv nw nx fj bk">In cases where ambiguity persists even after reranking, LLMs can be leveraged to analyze the retrieved results and provide additional context or generate targeted summaries.</p><p id="b974" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">LLMs, such as GPT-4, have the ability to understand and generate human-like text based on the given context. By feeding the retrieved documents and the query to an LLM, we can obtain more nuanced insights and generate tailored responses.</p><p id="bb25" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For example, we can use an LLM to summarize the most relevant aspects of the retrieved documents in relation to the query, highlight the key qualifications or experiences of the job candidates, or even generate personalized feedback or recommendations based on the matchmaking results.</p><p id="8b20" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This is great because it can be done after the results are passed to the user, but what if we want to rerank dozens or hundreds of results? Our LLM’s context will be exceeded, and it will take too long to get our output. This doesn’t mean you shouldn’t use an LLM to evaluate the results and pass additional context to the user, but it does mean we need a better final-step reranking option.<br/>Let’s imagine we have a pipeline that looks like this:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ps"><img src="../Images/3d69f7309d972dfb1bdf22c6976abfb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hx32_0ofLRsEIP_2A5M6Sg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Simple Pipeline</figcaption></figure><p id="6de6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This pipeline can narrow down millions of possible documents to just a few dozen. But the last few dozen is extremely important, we might be passing only three or four documents to an LLM! If we are displaying a job candidate to a user, it’s very important that the first candidate shown is a much better fit than the fifth.</p><p id="7767" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We know that LLMs are excellent rerankers, and there are a few reasons for that:</p><ol class=""><li id="5e11" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pg oz pa bk"><strong class="ne fr">LLMs are list aware. </strong>This means they can see other candidates and compare them, which is additional information that can be used. Imagine you (a human) were asked to rate a candidate from 1–10. Would showing you all other candidates help? Of course!</li><li id="c3ba" class="nc nd fq ne b go pb ng nh gr pc nj nk nl pd nn no np pe nr ns nt pf nv nw nx pg oz pa bk"><strong class="ne fr">LLMs are really smart. </strong>LLMs understand the task they are given, and based on this can very effectively understand whether a candidate is a good fit, regardless of simple semantic similarity.</li></ol><p id="92e8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can exploit the second reason with a perplexity based classifier. Perplexity is a metric which estimates how much an LLM is ‘confused’ by a particular output. In other words, we can ask an LLM to classify our candidate into ‘a very good fit’ or ‘not a very good fit’. Based on the certainty with which it places our candidate into ‘a very good fit’ (the perplexity of this categorization,) we can effectively rank our candidates. <br/>There are all kinds of optimizations that can be made, but on a good GPU (which is highly recommended for this part) we can rerank 50 candidates in about the same time that cohere can rerank 1 thousand. However, we can parallelize this calculation on multiple GPUs to speed this up and scale to reranking thousands of candidates.</p><p id="b3c1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First, let’s install and import <a class="af nb" href="https://github.com/asahi417/lmppl" rel="noopener ugc nofollow" target="_blank">lmppl</a>, a library that let’s us evaluate the perplexity of certain LLM completions. We will also create a scorer, which is a large T5 model (anything larger runs too slowly, and smaller performs much worse.) If you can achieve similar results with a decoder model, please let me know, as that would make additional performance gains much easier (decoders are getting better and cheaper much more quickly than encoder-decoder models.)</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="04ba" class="pl nz fq pi b bg pm pn l po pp">!pip install lmppl<br/>import lmppl<br/><br/># Initialize the scorer for a encoder-decoder model, such as flan-t5. Use small, large, or xl depending on your needs. (xl will run much slower unless you have a GPU and a lot of memory) I recommend large for most tasks.<br/>scorer = lmppl.EncoderDecoderLM('google/flan-t5-large')</span></pre><p id="1e2b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, let’s create our evaluation function. This can be turned into a general function for any reranking task, or you can change the classes to see if that improves performance. This example seems to work well. We cache responses so that running the same values is faster, but this isn’t too necessary on a GPU.</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="709e" class="pl nz fq pi b bg pm pn l po pp">cache = {}<br/><br/>def evaluate_candidates(query, documents, personality, additional_command=""):<br/>    """<br/>    Evaluate the relevance of documents to a given query using a specified scorer,<br/>    caching individual document scores to avoid redundant computations.<br/><br/>    Args:<br/>    - query (str): The query indicating the type of document to evaluate.<br/>    - documents (list of str): List of document descriptions or profiles.<br/>    - personality (str): Personality descriptor or model configuration for the evaluation.<br/>    - additional_command (str, optional): Additional command to include in the evaluation prompt.<br/><br/>    Returns:<br/>    - sorted_candidates_by_score (list of tuples): List of tuples containing the document description and its score, sorted by score in descending order.<br/>    """<br/>    try:<br/>        uncached_docs = []<br/>        cached_scores = []<br/><br/>        # Identify cached and uncached documents<br/>        for document in documents:<br/>            key = (query, document, personality, additional_command)<br/>            if key in cache:<br/>                cached_scores.append((document, cache[key]))<br/>            else:<br/>                uncached_docs.append(document)<br/><br/>        # Process uncached documents<br/>        if uncached_docs:<br/>            input_prompts_good_fit = [<br/>                f"{personality} Here is a problem statement: '{query}'. Here is a job description we are determining if it is a very good fit for the problem: '{doc}'. Is this job description a very good fit? Expected response: 'a great fit.', 'almost a great fit', or 'not a great fit.' This document is: "<br/>                for doc in uncached_docs<br/>            ]<br/><br/>            print(input_prompts_good_fit)<br/><br/>            # Mocked scorer interaction; replace with actual API call or logic<br/>            outputs_good_fit = ['a very good fit.'] * len(uncached_docs)<br/>            # Calculate perplexities for combined prompts<br/>            perplexities = scorer.get_perplexity(input_texts=input_prompts_good_fit, output_texts=outputs_good_fit)<br/><br/>            # Store scores in cache and collect them for sorting<br/>            for doc, good_ppl in zip(uncached_docs, perplexities):<br/>                score = (good_ppl)<br/>                cache[(query, doc, personality, additional_command)] = score<br/>                cached_scores.append((doc, score))<br/><br/>        # Combine cached and newly computed scores<br/>        sorted_candidates_by_score = sorted(cached_scores, key=lambda x: x[1], reverse=False)<br/><br/>        print(f"Sorted candidates by score: {sorted_candidates_by_score}")<br/><br/>        print(query, ": ", sorted_candidates_by_score[0])<br/><br/>        return sorted_candidates_by_score<br/><br/>    except Exception as e:<br/>        print(f"Error in evaluating candidates: {e}")<br/>        return None</span></pre><p id="7dc6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, let’s rerank and evaluate:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="3048" class="pl nz fq pi b bg pm pn l po pp">def perform_reranking_evaluation_neural(problem_candidates):<br/>    results = []<br/><br/>    for problem, candidates in problem_candidates.items():<br/>        personality = "You are an extremely intelligent classifier (200IQ), that effectively classifies a candidate into 'a great fit', 'almost a great fit' or 'not a great fit' based on a query (and the inferred intent of the user behind it)."<br/>        additional_command = "Is this candidate a great fit based on this experience?"<br/><br/>        reranking_response = evaluate_candidates(problem, [candidates["True Positive"]]+ [candidate for candidate in candidates["Hard Negative"]], personality)<br/>        top_document = reranking_response[0][0]<br/><br/>        # Check if the top ranked document is the True Positive<br/>        is_correct = (top_document == candidates["True Positive"])<br/>        results.append((problem, is_correct))<br/>        print(f"Problem: {problem}:")<br/>        print(f"Top Document is True Positive: {is_correct}\n")<br/><br/>    # Evaluate overall accuracy<br/>    correct_answers = sum([result[1] for result in results])<br/>    accuracy = correct_answers / len(results) * 100<br/>    print(f"Overall Accuracy Neural: {accuracy:.2f}%")<br/><br/>perform_reranking_evaluation_neural(problem_candidates)</span></pre><p id="3ad6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And our result:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="cbc0" class="pl nz fq pi b bg pm pn l po pp">Overall Accuracy Neural: 72.09%</span></pre><p id="c254" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This is much better than our rerankers, and required no fine-tuning! Not only that, but this is much more flexible towards any task, and easier to get performance gains just by modifying classes and prompt engineering. The drawback is that this architecture is unoptimized, it’s difficult to deploy (I recommend <a class="af nb" href="http://modal.com" rel="noopener ugc nofollow" target="_blank">modal</a>.com for serverless deployment on multiple GPUs, or to deploy a GPU on a VPS.)<br/>With this neural task aware reranker in our toolbox, we can create a more robust reranking pipeline:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pt"><img src="../Images/1e06164e97d6d7f44554a6e3f5ecb7b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*caHe9xPjPGTnvSbMSolgkA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Robust Multi-Stage Reranking Pipeline</figcaption></figure><p id="e532" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Conclusion</strong></p><p id="b7ca" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Enhancing document retrieval for complex matchmaking tasks requires a multi-faceted approach that leverages the strengths of different AI techniques:</p><p id="fc92" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">1. <strong class="ne fr">Instruction-tuned embeddings</strong> provide a foundation by encoding task-specific instructions to guide the model in capturing relevant aspects of queries and documents. However, evaluations are crucial to validate their performance.</p><p id="2528" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">2.<strong class="ne fr"> Reranking </strong>refines the retrieved results by deeply analyzing content relevance. It can benefit from additional context about the task at hand.</p><p id="2907" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">3. <strong class="ne fr">LLM-based classifiers</strong> serve as a powerful final step, enabling nuanced reranking of the top candidates to surface the most pertinent results in an order optimized for the end user.</p><p id="3b51" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By thoughtfully orchestrating instruction-tuned embeddings, rerankers, and LLMs, we can construct robust AI pipelines that excel at challenges like matching job candidates to role requirements. Meticulous prompt engineering, top-performing models, and the inherent capabilities of LLMs allow for better Task-Aware RAG pipelines — in this case delivering outstanding outcomes in aligning people with ideal opportunities. Embracing this multi-pronged methodology empowers us to build retrieval systems that just retrieving semantically similar documents, but truly intelligent and finding documents that fulfill our unique needs.</p><p id="3e6f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Connect with me on <a class="af nb" href="https://www.linkedin.com/in/michael-ryaboy-software-engineer/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> for more AI Engineering tips.</p></div></div></div></div>    
</body>
</html>