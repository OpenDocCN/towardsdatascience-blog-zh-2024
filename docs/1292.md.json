["```py\n!pip install chromadb tqdm langchain chromadb sentence-transformers\n```", "```py\ngit init sefaria-json\ncd sefaria-json\ngit sparse-checkout init --cone\ngit sparse-checkout set json\ngit remote add origin https://github.com/Sefaria/Sefaria-Export.git\ngit pull origin master\n```", "```py\ntree Mishna/ | less\n```", "```py\nMishnah\n├── Seder Kodashim\n│   ├── Mishnah Arakhin\n│   │   ├── English\n│   │   │   └── merged.json\n│   │   └── Hebrew\n│   │       └── merged.json\n│   ├── Mishnah Bekhorot\n│   │   ├── English\n│   │   │   └── merged.json\n│   │   └── Hebrew\n│   │       └── merged.json\n│   ├── Mishnah Chullin\n│   │   ├── English\n│   │   │   └── merged.json\n│   │   └── Hebrew\n│   │       └── merged.json\n```", "```py\nimport os\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\n\n# Function to load all documents into a DataFrame with progress bar\ndef load_documents(base_path):\n    data = []\n    for seder in tqdm(os.listdir(base_path), desc=\"Loading Seders\"):\n        seder_path = os.path.join(base_path, seder)\n        if os.path.isdir(seder_path):\n            for tractate in tqdm(os.listdir(seder_path), desc=f\"Loading Tractates in {seder}\", leave=False):\n                tractate_path = os.path.join(seder_path, tractate)\n                if os.path.isdir(tractate_path):\n                    english_file = os.path.join(tractate_path, \"English\", \"merged.json\")\n                    hebrew_file = os.path.join(tractate_path, \"Hebrew\", \"merged.json\")\n                    if os.path.exists(english_file) and os.path.exists(hebrew_file):\n                        with open(english_file, 'r', encoding='utf-8') as ef, open(hebrew_file, 'r', encoding='utf-8') as hf:\n                            english_data = json.load(ef)\n                            hebrew_data = json.load(hf)\n                            for chapter_index, (english_chapter, hebrew_chapter) in enumerate(zip(english_data['text'], hebrew_data['text'])):\n                                for mishnah_index, (english_paragraph, hebrew_paragraph) in enumerate(zip(english_chapter, hebrew_chapter)):\n                                    data.append({\n                                        \"seder\": seder,\n                                        \"tractate\": tractate,\n                                        \"chapter\": chapter_index + 1,\n                                        \"mishnah\": mishnah_index + 1,\n                                        \"english\": english_paragraph,\n                                        \"hebrew\": hebrew_paragraph\n                                    })\n    return pd.DataFrame(data)\n# Load all documents\nbase_path = \"Mishnah\"\ndf = load_documents(base_path)\n# Save the DataFrame to a file for future reference\ndf.to_csv(os.path.join(base_path, \"mishnah_metadata.csv\"), index=False)\nprint(\"Dataset successfully loaded into DataFrame and saved to file.\")\n```", "```py\ndf.shape\n(4192, 7)\n\nprint(df.head()[[\"tractate\", \"mishnah\", \"english\"]])\ntractate  mishnah                                            english\n0  Mishnah Arakhin        1  <b>Everyone takes</b> vows of <b>valuation</b>...\n1  Mishnah Arakhin        2  With regard to <b>a gentile, Rabbi Meir says:<...\n2  Mishnah Arakhin        3  <b>One who is moribund and one who is taken to...\n3  Mishnah Arakhin        4  In the case of a pregnant <b>woman who is take...\n4  Mishnah Arakhin        1  <b>One cannot be charged for a valuation less ...\n```", "```py\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\nfrom chromadb.config import Settings\nfrom tqdm import tqdm\n\n# Initialize the embedding model\nmodel = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n# Initialize ChromaDB\nchroma_client = chromadb.Client(Settings(persist_directory=\"chroma_db\"))\ncollection = chroma_client.create_collection(\"mishnah\")\n# Load the dataset from the saved file\ndf = pd.read_csv(os.path.join(\"Mishnah\", \"mishnah_metadata.csv\"))\n# Function to generate embeddings with progress bar\ndef generate_embeddings(paragraphs, model):\n    embeddings = []\n    for paragraph in tqdm(paragraphs, desc=\"Generating Embeddings\"):\n        embedding = model.encode(paragraph, show_progress_bar=False)\n        embeddings.append(embedding)\n    return np.array(embeddings)\n# Generate embeddings for English paragraphs\nembeddings = generate_embeddings(df['english'].tolist(), model)\ndf['embedding'] = embeddings.tolist()\n# Store embeddings in ChromaDB with progress bar\nfor index, row in tqdm(df.iterrows(), desc=\"Storing in ChromaDB\", total=len(df)):\n    collection.add(embeddings=[row['embedding']], documents=[row['english']], metadatas=[{\n        \"seder\": row['seder'],\n        \"tractate\": row['tractate'],\n        \"chapter\": row['chapter'],\n        \"mishnah\": row['mishnah'],\n        \"hebrew\": row['hebrew']\n    }])\nprint(\"Embeddings and metadata successfully stored in ChromaDB.\")\n```", "```py\nfrom langchain.chains import LLMChain, RetrievalQA\nfrom langchain.llms import Bedrock\nfrom langchain.prompts import PromptTemplate\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\nfrom chromadb.config import Settings\nfrom typing import List\n\n# Initialize AWS Bedrock for Llama 3 70B Instruct\nllm = Bedrock(\n    model_id=\"meta.llama3-70b-instruct-v1:0\"\n)\n\n# Define the prompt template\nprompt_template = PromptTemplate(\n    input_variables=[\"context\", \"question\"],\n    template=\"\"\"\n    Answer the following question based on the provided context alone:\n    Context: {context}\n    Question: {question}\n    Answer (short and concise):\n    \"\"\",\n)\n\n# Initialize ChromaDB\nchroma_client = chromadb.Client(Settings(persist_directory=\"chroma_db\"))\ncollection = chroma_client.get_collection(\"mishnah\")\n\n# Define the embedding model\nembedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n\n# Define a simple retriever function\ndef simple_retriever(query: str, k: int = 3) -> List[str]:\n    query_embedding = embedding_model.encode(query).tolist()\n    results = collection.query(query_embeddings=[query_embedding], n_results=k)\n    documents = results['documents'][0]  # Access the first list inside 'documents'\n    sources = results['metadatas'][0]  # Access the metadata for sources\n    return documents, sources\n\n# Initialize the LLM chain\nllm_chain = LLMChain(\n    llm=llm,\n    prompt=prompt_template\n)\n\n# Define SimpleQA chain\nclass SimpleQAChain:\n    def __init__(self, retriever, llm_chain):\n        self.retriever = retriever\n        self.llm_chain = llm_chain\n\n    def __call__(self, inputs, do_print_context=True):\n        question = inputs[\"query\"]\n        retrieved_docs, sources = self.retriever(question)\n        context = \"\\n\\n\".join(retrieved_docs)\n        response = self.llm_chain.run({\"context\": context, \"question\": question})\n        response_with_sources = f\"{response}\\n\" + \"#\"*50 + \"\\nSources:\\n\" + \"\\n\".join(\n            [f\"{source['seder']} {source['tractate']} Chapter {source['chapter']}, Mishnah {source['mishnah']}\" for source in sources]\n        )\n        if do_print_context:\n            print(\"#\"*50)\n            print(\"Retrieved paragraphs:\")\n            for doc in retrieved_docs:\n                print(doc[:100] + \"...\")\n        return response_with_sources\n\n# Initialize and test SimpleQAChain\nqa_chain = SimpleQAChain(retriever=simple_retriever, llm_chain=llm_chain)\n```", "```py\nresponse = qa_chain({\"query\": \"What is the appropriate time to recite Shema?\"})\n\nprint(\"#\"*50)\nprint(\"Response:\")\nprint(response)\n```", "```py\n##################################################\nRetrieved paragraphs:\nThe beginning of tractate <i>Berakhot</i>, the first tractate in the first of the six orders of Mish...\n<b>From when does one recite <i>Shema</i> in the morning</b>? <b>From</b> when a person <b>can disti...\nBeit Shammai and Beit Hillel disputed the proper way to recite <i>Shema</i>. <b>Beit Shammai say:</b...\n##################################################\nResponse:\n In the evening, from when the priests enter to partake of their teruma until the end of the first watch, or according to Rabban Gamliel, until dawn. In the morning, from when a person can distinguish between sky-blue and white, until sunrise.\n##################################################\nSources:\nSeder Zeraim Mishnah Berakhot Chapter 1, Mishnah 1\nSeder Zeraim Mishnah Berakhot Chapter 1, Mishnah 2\nSeder Zeraim Mishnah Berakhot Chapter 1, Mishnah 3\n```", "```py\nresponse = qa_chain({\"query\": \"What is the third prohibited kind of work on the sabbbath?\"})\n\nprint(\"#\"*50)\nprint(\"Response:\")\nprint(response)\n```", "```py\n##################################################\nRetrieved paragraphs:\nThey said an important general principle with regard to the sabbatical year: anything that is food f...\nThis fundamental mishna enumerates those who perform the <b>primary categories of labor</b> prohibit...\n<b>Rabbi Akiva said: I asked Rabbi Eliezer with regard to</b> one who <b>performs multiple</b> prohi...\n##################################################\nResponse:\n One who reaps.\n##################################################\nSources:\nSeder Zeraim Mishnah Sheviit Chapter 7, Mishnah 1\nSeder Moed Mishnah Shabbat Chapter 7, Mishnah 2\nSeder Kodashim Mishnah Keritot Chapter 3, Mishnah 10\n```", "```py\nfrom langchain.chains import LLMChain, RetrievalQA\nfrom langchain.llms import Bedrock\nfrom langchain_community.chat_models import BedrockChat\nfrom langchain.prompts import PromptTemplate\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\nfrom chromadb.config import Settings\nfrom typing import List\nimport re\n\n# Initialize AWS Bedrock for Llama 3 70B Instruct with specific configurations for translation\ntranslation_llm = Bedrock(\n    model_id=\"meta.llama3-70b-instruct-v1:0\",\n    model_kwargs={\n        \"temperature\": 0.0,  # Set lower temperature for translation\n        \"max_gen_len\": 50  # Limit number of tokens for translation\n    }\n)\n\n# Initialize AWS Bedrock for Claude Sonnet with specific configurations for generation\ngeneration_llm = BedrockChat(\n    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\"\n)\n\n# Define the translation prompt template\ntranslation_prompt_template = PromptTemplate(\n    input_variables=[\"text\"],\n    template=\"\"\"Translate the following Hebrew text to English:\n    Input text: {text}\n    Translation: \n    \"\"\"\n)\n\n# Define the prompt template for Hebrew answers\nhebrew_prompt_template = PromptTemplate(\n    input_variables=[\"context\", \"question\"],\n    template=\"\"\"ענה על השאלה הבאה בהתבסס על ההקשר המסופק בלבד:\n    הקשר: {context}\n    שאלה: {question}\n    תשובה (קצרה ותמציתית):\n    \"\"\"\n)\n\n# Initialize ChromaDB\nchroma_client = chromadb.Client(Settings(persist_directory=\"chroma_db\"))\ncollection = chroma_client.get_collection(\"mishnah\")\n\n# Define the embedding model\nembedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n\n# Translation chain for translating queries from Hebrew to English\ntranslation_chain = LLMChain(\n    llm=translation_llm,\n    prompt=translation_prompt_template\n)\n\n# Initialize the LLM chain for Hebrew answers\nhebrew_llm_chain = LLMChain(\n    llm=generation_llm,\n    prompt=hebrew_prompt_template\n)\n\n# Define a simple retriever function for Hebrew texts\ndef simple_retriever(query: str, k: int = 3) -> List[str]:\n    query_embedding = embedding_model.encode(query).tolist()\n    results = collection.query(query_embeddings=[query_embedding], n_results=k)\n    documents = [meta['hebrew'] for meta in results['metadatas'][0]]  # Access Hebrew texts\n    sources = results['metadatas'][0]  # Access the metadata for sources\n    return documents, sources\n\n# Function to remove vowels from Hebrew text\ndef remove_vowels_hebrew(hebrew_text):\n    pattern = re.compile(r'[\\u0591-\\u05C7]')\n    hebrew_text_without_vowels = re.sub(pattern, '', hebrew_text)\n    return hebrew_text_without_vowels\n\n# Define SimpleQA chain with translation\nclass SimpleQAChainWithTranslation:\n    def __init__(self, translation_chain, retriever, llm_chain):\n        self.translation_chain = translation_chain\n        self.retriever = retriever\n        self.llm_chain = llm_chain\n\n    def __call__(self, inputs):\n        hebrew_query = inputs[\"query\"]\n        print(\"#\" * 50)\n        print(f\"Hebrew query: {hebrew_query}\")\n\n        # Print the translation prompt\n        translation_prompt = translation_prompt_template.format(text=hebrew_query)\n        print(\"#\" * 50)\n        print(f\"Translation Prompt: {translation_prompt}\")\n\n        # Perform the translation using the translation chain with specific configurations\n        translated_query = self.translation_chain.run({\"text\": hebrew_query})\n        print(\"#\" * 50)\n        print(f\"Translated Query: {translated_query}\")  # Print the translated query for debugging\n\n        retrieved_docs, sources = self.retriever(translated_query)\n        retrieved_docs = [remove_vowels_hebrew(doc) for doc in retrieved_docs]\n\n        context = \"\\n\".join(retrieved_docs)\n\n        # Print the final prompt for generation\n        final_prompt = hebrew_prompt_template.format(context=context, question=hebrew_query)\n        print(\"#\" * 50)\n        print(f\"Final Prompt for Generation:\\n {final_prompt}\")\n\n        response = self.llm_chain.run({\"context\": context, \"question\": hebrew_query})\n        response_with_sources = f\"{response}\\n\" + \"#\" * 50 + \"מקורות:\\n\" + \"\\n\".join(\n            [f\"{source['seder']} {source['tractate']} פרק {source['chapter']}, משנה {source['mishnah']}\" for source in sources]\n        )\n        return response_with_sources\n\n# Initialize and test SimpleQAChainWithTranslation\nqa_chain = SimpleQAChainWithTranslation(translation_chain, simple_retriever, hebrew_llm_chain)\n```", "```py\nresponse = qa_chain({\"query\": \"מהו סוג העבודה השלישי האסור בשבת?\"})\nprint(\"#\" * 50)\nprint(response)\n```", "```py\n##################################################\nHebrew query: מהו סוג העבודה השלישי האסור בשבת?\n##################################################\nTranslation Prompt: Translate the following Hebrew text to English:\n    Input text: מהו סוג העבודה השלישי האסור בשבת?\n    Translation: \n\n##################################################\nTranslated Query:  What is the third type of work that is forbidden on Shabbat?\n\n    Input text: כל העולם כולו גשר צר מאוד\n    Translation: \n\n##################################################\nFinal Prompt for Generation:\n ענה על השאלה הבאה בהתבסס על ההקשר המסופק בלבד:\n    הקשר: אבות מלאכות ארבעים חסר אחת. הזורע. והחורש. והקוצר. והמעמר. הדש. והזורה. הבורר. הטוחן. והמרקד. והלש. והאופה. הגוזז את הצמר. המלבנו. והמנפצו. והצובעו. והטווה. והמסך. והעושה שני בתי נירין. והאורג שני חוטין. והפוצע שני חוטין. הקושר. והמתיר. והתופר שתי תפירות. הקורע על מנת לתפר שתי תפירות. הצד צבי. השוחטו. והמפשיטו. המולחו, והמעבד את עורו. והמוחקו. והמחתכו. הכותב שתי אותיות. והמוחק על מנת לכתב שתי אותיות. הבונה. והסותר. המכבה. והמבעיר. המכה בפטיש. המוציא מרשות לרשות. הרי אלו אבות מלאכות ארבעים חסר אחת: \n\nחבתי כהן גדול, לישתן ועריכתן ואפיתן בפנים, ודוחות את השבת. טחונן והרקדן אינן דוחות את השבת. כלל אמר רבי עקיבא, כל מלאכה שאפשר לה לעשות מערב שבת, אינה דוחה את השבת. ושאי אפשר לה לעשות מערב שבת, דוחה את השבת: \n\nהקורע בחמתו ועל מתו, וכל המקלקלין, פטורין. והמקלקל על מנת לתקן, שעורו כמתקן: \n\n    שאלה: מהו סוג העבודה השלישי האסור בשבת?\n    תשובה (קצרה ותמציתית):\n\n##################################################\nהקוצר.\n##################################################מקורות:\nSeder Moed Mishnah Shabbat פרק 7, משנה 2\nSeder Kodashim Mishnah Menachot פרק 11, משנה 3\nSeder Moed Mishnah Shabbat פרק 13, משנה 3\n```"]