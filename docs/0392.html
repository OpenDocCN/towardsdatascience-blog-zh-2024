<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Speech to Text to Speech with AI Using Python — a How-To Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Speech to Text to Speech with AI Using Python — a How-To Guide</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=collection_archive---------1-----------------------#2024-02-11">https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=collection_archive---------1-----------------------#2024-02-11</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="b463" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How to Create a Speech-to-Text-to-Speech Program</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Naomi Kriger" class="l ep by dd de cx" src="../Images/14839f859e1375965c046912f00df5b9.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*IXcoooR9WpE8XCrYp1SsPg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------" rel="noopener follow">Naomi Kriger</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 11, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">7</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/9373a2a21c40ba755fe7e692fc61b292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ai0UNZUQI8jW0nau"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><a class="af nc" href="https://unsplash.com/photos/aaujbh59zqI" rel="noopener ugc nofollow" target="_blank">Image</a> by <a class="af nc" href="https://unsplash.com/@maria_shalabaieva" rel="noopener ugc nofollow" target="_blank">Mariia Shalabaieva</a> from <a class="af nc" href="http://unsplash.com" rel="noopener ugc nofollow" target="_blank">unsplash</a></figcaption></figure><p id="dfad" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">It’s been exactly a decade since I started attending GeekCon (yes, a geeks’ conference 🙂) — a weekend-long hackathon-makeathon in which all projects must be useless and just-for-fun, and this year there was an exciting twist: all projects were required to incorporate some form of AI.</p><p id="0771" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">My group’s project was a speech-to-text-to-speech game, and here’s how it works: the user selects a character to talk to, and then verbally expresses anything they’d like to the character. This spoken input is transcribed and sent to ChatGPT, which responds as if it were the character. The response is then read aloud using text-to-speech technology.</p><p id="79ce" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now that the game is up and running, bringing laughs and fun, I’ve crafted this how-to guide to help you create a similar game on your own. Throughout the article, we’ll also explore the various considerations and decisions we made during the hackathon.</p><p id="b3d7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Want to see the full code? <a class="af nc" href="https://github.com/NaomiKriger/speech_to_speech_magician" rel="noopener ugc nofollow" target="_blank">Here is the link</a>!</p><h1 id="c441" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">The Program’s Flow</h1><p id="e8f1" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Once the server is running, the user will hear the app “talking”, prompting them to choose the figure they want to talk to and start conversing with their selected character. Each time they want to talk out loud — they should press and hold a key on the keyboard while talking. When they finish talking (and release the key), their recording will be transcribed by <code class="cx pa pb pc pd b"><a class="af nc" href="https://platform.openai.com/docs/guides/speech-to-text/quickstart" rel="noopener ugc nofollow" target="_blank">Whisper</a></code> (a speech-to-text model by <code class="cx pa pb pc pd b"><a class="af nc" href="https://platform.openai.com/docs/introduction/overview" rel="noopener ugc nofollow" target="_blank">OpenAI</a></code>), and the transcription will be sent to <code class="cx pa pb pc pd b"><a class="af nc" href="https://platform.openai.com/docs/guides/gpt/chat-completions-api" rel="noopener ugc nofollow" target="_blank">ChatGPT</a></code> for a response. The response will be read out loud using a text-to-speech library, and the user will hear it.</p><h1 id="e920" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Implementation</h1><h2 id="77ab" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">Disclaimer</h2><p id="739a" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Note: The project was developed on a Windows operating system and incorporates the <code class="cx pa pb pc pd b">pyttsx3</code> library, which lacks compatibility with M1/M2 chips. As <code class="cx pa pb pc pd b">pyttsx3</code> is not supported on Mac, users are advised to explore alternative text-to-speech libraries that are compatible with macOS environments.</p><h2 id="77cf" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">Openai Integration</h2><p id="bc83" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">I utilized two <code class="cx pa pb pc pd b">OpenAI</code> models: <code class="cx pa pb pc pd b">Whisper</code>, for speech-to-text transcription, and the <code class="cx pa pb pc pd b">ChatGPT</code> API for generating responses based on the user’s input to their selected figure. While doing so costs money, the pricing model is very cheap, and personally, my bill is still under $1 for all my usage. To get started, I made an initial deposit of $5, and to date, I have not exhausted this deposit, and this initial deposit won’t expire until a year from now.<br/>I’m not receiving any payment or benefits from <code class="cx pa pb pc pd b">OpenAI</code> for writing this.</p><p id="d295" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Once you get your <code class="cx pa pb pc pd b">OpenAI</code> API key — set it as an environment variable to use upon making the API calls. Make sure not to push your key to the codebase or any public location, and not to share it unsafely.</p><h2 id="8795" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">Speech to Text — Create Transcription</h2><p id="9a58" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">The implementation of the speech-to-text feature was achieved using <code class="cx pa pb pc pd b">Whisper</code>, an <code class="cx pa pb pc pd b">OpenAI</code> model.</p><p id="e7ea" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Below is the code snippet for the function responsible for transcription:</p><pre class="mm mn mo mp mq pv pd pw bp px bb bk"><span id="181e" class="py oa fq pd b bg pz qa l qb qc">async def get_transcript(audio_file_path: str, <br/>                         text_to_draw_while_waiting: str) -&gt; Optional[str]:<br/>    openai.api_key = os.environ.get("OPENAI_API_KEY")<br/>    audio_file = open(audio_file_path, "rb")<br/>    transcript = None<br/><br/>    async def transcribe_audio() -&gt; None:<br/>        nonlocal transcript<br/>        try:<br/>            response = openai.Audio.transcribe(<br/>                model="whisper-1", file=audio_file, language="en")<br/>            transcript = response.get("text")<br/>        except Exception as e:<br/>            print(e)<br/><br/>    draw_thread = Thread(target=print_text_while_waiting_for_transcription(<br/>        text_to_draw_while_waiting))<br/>    draw_thread.start()<br/><br/>    transcription_task = asyncio.create_task(transcribe_audio())<br/>    await transcription_task<br/><br/>    if transcript is None:<br/>        print("Transcription not available within the specified timeout.")<br/><br/>    return transcript</span></pre><p id="6bf5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This function is marked as asynchronous (async) since the API call may take some time to return a response, and we await it to ensure that the program doesn’t progress until the response is received.</p><p id="fd99" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As you can see, the <code class="cx pa pb pc pd b">get_transcript</code> function also invokes the <code class="cx pa pb pc pd b">print_text_while_waiting_for_transcription</code> function. Why? Since obtaining the transcription is a time-consuming task, we wanted to keep the user informed that the program is actively processing their request and not stuck or unresponsive. As a result, this text is gradually printed as the user awaits the next step.</p><h2 id="1b39" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">String Matching Using FuzzyWuzzy for Text Comparison</h2><p id="2f8e" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">After transcribing the speech into text, we either utilized it as is, or attempted to compare it with an existing string.</p><p id="4306" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The comparison use cases were: selecting a figure from a predefined list of options, deciding whether to continue playing or not, and when opting to continue - deciding whether to choose a new figure or stick with the current one.</p><p id="34d3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In such cases, we wanted to compare the user’s spoken input transcription with the options in our lists, and therefore we decided to use the <code class="cx pa pb pc pd b">FuzzyWuzzy</code> library for string matching.</p><p id="853b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This enabled choosing the closest option from the list, as long as the matching score exceeded a predefined threshold.</p><p id="c4ab" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here’s a snippet of our function:</p><pre class="mm mn mo mp mq pv pd pw bp px bb bk"><span id="cc31" class="py oa fq pd b bg pz qa l qb qc">def detect_chosen_option_from_transcript(<br/>        transcript: str, options: List[str]) -&gt; str:<br/>    best_match_score = 0<br/>    best_match = ""<br/><br/>    for option in options:<br/>        score = fuzz.token_set_ratio(transcript.lower(), option.lower())<br/>        if score &gt; best_match_score:<br/>            best_match_score = score<br/>            best_match = option<br/><br/>    if best_match_score &gt;= 70:<br/>        return best_match<br/>    else:<br/>        return ""</span></pre><p id="2403" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If you want to learn more about the <code class="cx pa pb pc pd b">FuzzyWuzzy</code> library and its functions — you can check out an article I wrote about it <a class="af nc" rel="noopener" target="_blank" href="/string-comparison-is-easy-with-fuzzywuzzy-library-611cc1888d97">here</a>.</p><h2 id="0911" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">Get ChatGPT Response</h2><p id="dfff" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Once we have the transcription, we can send it over to <code class="cx pa pb pc pd b">ChatGPT</code> to get a response.</p><p id="5647" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For each <code class="cx pa pb pc pd b">ChatGPT</code> request, we added a prompt asking for a short and funny response. We also told <code class="cx pa pb pc pd b">ChatGPT</code> which figure to pretend to be.</p><p id="14db" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">So our function looked as follows:</p><pre class="mm mn mo mp mq pv pd pw bp px bb bk"><span id="e884" class="py oa fq pd b bg pz qa l qb qc">def get_gpt_response(transcript: str, chosen_figure: str) -&gt; str:<br/>    system_instructions = get_system_instructions(chosen_figure)<br/>    try:<br/>        return make_openai_request(<br/>            system_instructions=system_instructions, <br/>            user_question=transcript).choices[0].message["content"]<br/>    except Exception as e:<br/>        logging.error(f"could not get ChatGPT response. error: {str(e)}")<br/>        raise e</span></pre><p id="b829" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">and the system instructions looked as follows:</p><pre class="mm mn mo mp mq pv pd pw bp px bb bk"><span id="e042" class="py oa fq pd b bg pz qa l qb qc">def get_system_instructions(figure: str) -&gt; str:<br/>    return f"You provide funny and short answers. You are: {figure}"</span></pre><h2 id="7dab" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">Text to Speech</h2><p id="a381" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">For the text-to-speech part, we opted for a Python library called <code class="cx pa pb pc pd b">pyttsx3</code>. This choice was not only straightforward to implement but also offered several additional advantages. It’s free of charge, provides two voice options — male and female — and allows you to select the speaking rate in words per minute (speech speed).</p><p id="3460" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When a user starts the game, they pick a character from a predefined list of options. If we couldn’t find a match for what they said within our list, we’d randomly select a character from our “fallback figures” list. In both lists, each character was associated with a gender, so our text-to-speech function also received the voice ID corresponding to the selected gender.</p><p id="f3c9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This is what our text-to-speech function looked like:</p><pre class="mm mn mo mp mq pv pd pw bp px bb bk"><span id="9a73" class="py oa fq pd b bg pz qa l qb qc">def text_to_speech(text: str, gender: str = Gender.FEMALE.value) -&gt; None:<br/>    engine = pyttsx3.init()<br/><br/>    engine.setProperty("rate", WORDS_PER_MINUTE_RATE)<br/>    voices = engine.getProperty("voices")<br/>    voice_id = voices[0].id if gender == "male" else voices[1].id<br/>    engine.setProperty("voice", voice_id)<br/><br/>    engine.say(text)<br/>    engine.runAndWait()</span></pre><h2 id="0a16" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">The Main Flow</h2><p id="df58" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Now that we’ve more or less got all the pieces of our app in place, it’s time to dive into the gameplay! The main flow is outlined below. You might notice some functions we haven’t delved into (e.g. <code class="cx pa pb pc pd b">choose_figure</code>, <code class="cx pa pb pc pd b">play_round</code>), but you can explore the full code by <a class="af nc" href="https://github.com/NaomiKriger/speech_to_speech_magician" rel="noopener ugc nofollow" target="_blank">checking out the repo</a>. Eventually, most of these higher-level functions tie into the internal functions we’ve covered above.</p><p id="6b88" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here’s a snippet of the main game flow:</p><pre class="mm mn mo mp mq pv pd pw bp px bb bk"><span id="64d8" class="py oa fq pd b bg pz qa l qb qc">import asyncio<br/><br/>from src.handle_transcript import text_to_speech<br/>from src.main_flow_helpers import choose_figure, start, play_round, \<br/>    is_another_round<br/><br/><br/>def farewell() -&gt; None:<br/>    farewell_message = "It was great having you here, " \<br/>                       "hope to see you again soon!"<br/>    print(f"\n{farewell_message}")<br/>    text_to_speech(farewell_message)<br/><br/><br/>async def get_round_settings(figure: str) -&gt; dict:<br/>    new_round_choice = await is_another_round()<br/>    if new_round_choice == "new figure":<br/>        return {"figure": "", "another_round": True}<br/>    elif new_round_choice == "no":<br/>        return {"figure": "", "another_round": False}<br/>    elif new_round_choice == "yes":<br/>        return {"figure": figure, "another_round": True}<br/><br/><br/>async def main():<br/>    start()<br/>    another_round = True<br/>    figure = ""<br/><br/>    while True:<br/>        if not figure:<br/>            figure = await choose_figure()<br/><br/>        while another_round:<br/>            await play_round(chosen_figure=figure)<br/>            user_choices = await get_round_settings(figure)<br/>            figure, another_round = \<br/>                user_choices.get("figure"), user_choices.get("another_round")<br/>            if not figure:<br/>                break<br/><br/>        if another_round is False:<br/>            farewell()<br/>            break<br/><br/><br/>if __name__ == "__main__":<br/>    asyncio.run(main())</span></pre><h1 id="f020" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">The Roads Not Taken</h1><p id="7da6" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">We had several ideas in mind that we didn’t get to implement during the hackathon. This was either because we did not find an API we were satisfied with during that weekend, or due to the time constraints preventing us from developing certain features. These are the paths we didn’t take for this project:</p><h2 id="f1d6" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">Matching the Response Voice with the Chosen Figure’s “Actual” Voice</h2><p id="2815" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Imagine if the user chose to talk to Shrek, Trump, or Oprah Winfrey. We wanted our text-to-speech library or API to articulate responses using voices that matched the chosen figure. However, we couldn’t find a library or API during the hackathon that offered this feature at a reasonable cost. We’re still open to suggestions if you have any =)</p><h2 id="a5d9" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">Let the Users Talk to “Themselves”</h2><p id="9344" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Another intriguing idea was to prompt users to provide a vocal sample of themselves speaking. We would then train a model using this sample and have all the responses generated by ChatGPT read aloud in the user’s own voice. In this scenario, the user could choose the tone of the responses (affirmative and supportive, sarcastic, angry, etc.), but the voice would closely resemble that of the user. However, we couldn’t find an API that supported this within the constraints of the hackathon.</p><h2 id="bb50" class="pe oa fq bf ob pf pg ph oe pi pj pk oh nm pl pm pn nq po pp pq nu pr ps pt pu bk">Adding a Frontend to Our Application</h2><p id="ff65" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Our initial plan was to include a frontend component in our application. However, due to a last-minute change in the number of participants in our group, we decided to prioritize the backend development. As a result, the application currently runs on the command line interface (CLI) and doesn’t have frontend side.</p><h1 id="a8ca" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Additional Improvements We Have In Mind</h1><p id="e079" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Latency is what bothers me most at the moment.</p><p id="ee81" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">There are several components in the flow with a relatively high latency that in my opinion slightly harm the user experience. For example: the time it takes from finishing providing the audio input and receiving a transcription, and the time it takes since the user presses a button until the system actually starts recording the audio. So if the user starts talking right after pressing the key — there will be at least one second of audio that won’t be recorded due to this lag.</p><h1 id="9029" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Link to the Repo &amp; Credits</h1><p id="6c67" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Want to see the whole project? <a class="af nc" href="https://github.com/NaomiKriger/speech_to_speech_magician" rel="noopener ugc nofollow" target="_blank">It’s right here</a>!</p><p id="32e2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Also, warm credit goes to <a class="af nc" href="https://www.linkedin.com/in/lioryardeni" rel="noopener ugc nofollow" target="_blank">Lior Yardeni</a>, my hackathon partner with whom I created this game.</p><h1 id="8a1a" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Summing Up</h1><p id="736a" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">In this article, we learned how to create a speech-to-text-to-speech game using Python, and intertwined it with AI. We’ve used the <code class="cx pa pb pc pd b">Whisper</code> model by <code class="cx pa pb pc pd b">OpenAI</code> for speech recognition, played around with the <code class="cx pa pb pc pd b">FuzzyWuzzy</code> library for text matching, tapped into <code class="cx pa pb pc pd b">ChatGPT</code>’s conversational magic via their developer API, and brought it all to life with <code class="cx pa pb pc pd b">pyttsx3</code> for text-to-speech. While <code class="cx pa pb pc pd b">OpenAI</code>’s services (<code class="cx pa pb pc pd b">Whisper</code> and <code class="cx pa pb pc pd b">ChatGPT</code> for developers) do come with a modest cost, it’s budget-friendly.</p><p id="1804" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We hope you’ve found this guide enlightening and that it’s motivating you to embark on your projects.</p><p id="02d4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Cheers to coding and fun! 🚀</p></div></div></div></div>    
</body>
</html>