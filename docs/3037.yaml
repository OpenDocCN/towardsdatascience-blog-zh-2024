- en: 'From Prototype to Production: Enhancing LLM Accuracy'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从原型到生产：提高LLM的准确性
- en: 原文：[https://towardsdatascience.com/from-prototype-to-production-enhancing-llm-accuracy-791d79b0af9b?source=collection_archive---------0-----------------------#2024-12-19](https://towardsdatascience.com/from-prototype-to-production-enhancing-llm-accuracy-791d79b0af9b?source=collection_archive---------0-----------------------#2024-12-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/from-prototype-to-production-enhancing-llm-accuracy-791d79b0af9b?source=collection_archive---------0-----------------------#2024-12-19](https://towardsdatascience.com/from-prototype-to-production-enhancing-llm-accuracy-791d79b0af9b?source=collection_archive---------0-----------------------#2024-12-19)
- en: Implementing evaluation frameworks to optimize accuracy in real-world applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施评估框架以优化现实应用中的准确性
- en: '[](https://miptgirl.medium.com/?source=post_page---byline--791d79b0af9b--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page---byline--791d79b0af9b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--791d79b0af9b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--791d79b0af9b--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page---byline--791d79b0af9b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://miptgirl.medium.com/?source=post_page---byline--791d79b0af9b--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page---byline--791d79b0af9b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--791d79b0af9b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--791d79b0af9b--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page---byline--791d79b0af9b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--791d79b0af9b--------------------------------)
    ·20 min read·Dec 19, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--791d79b0af9b--------------------------------)
    ·20分钟阅读·2024年12月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/5398f4ac2eeb0542c8deeb07151f9e87.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5398f4ac2eeb0542c8deeb07151f9e87.png)'
- en: Image created by DALL-E 3
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由DALL-E 3生成
- en: Building a prototype for an LLM application is surprisingly straightforward.
    You can often create a functional first version within just a few hours. This
    initial prototype will likely provide results that look legitimate and be a good
    tool to demonstrate your approach. However, this is usually not enough for production
    use.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 构建LLM应用程序的原型出乎意料地简单。你通常可以在几个小时内创建一个功能性的初始版本。这个初始原型可能会提供看起来合法的结果，并且是展示你方法的一个很好的工具。然而，这通常不足以满足生产环境的需求。
- en: LLMs are probabilistic by nature, as they generate tokens based on the distribution
    of likely continuations. This means that in many cases, we get the answer close
    to the “correct” one from the distribution. Sometimes, this is acceptable — for
    example, it doesn’t matter whether the app says “Hello, John!” or “Hi, John!”.
    In other cases, the difference is critical, such as between “The revenue in 2024
    was 20M USD” and “The revenue in 2024 was 20M GBP”.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs本质上是概率性的，因为它们根据可能的延续分布生成标记。这意味着在许多情况下，我们从分布中得到的答案接近“正确”答案。有时，这种结果是可以接受的——例如，应用程序说“Hello,
    John!”或“Hi, John!”并没有什么区别。在其他情况下，差异则至关重要，比如“2024年的收入是2000万美元”和“2024年的收入是2000万英镑”之间的区别。
- en: In many real-world business scenarios, precision is crucial, and “almost right”
    isn’t good enough. For example, when your LLM application needs to execute API
    calls, or you’re doing a summary of financial reports. From my experience, ensuring
    the accuracy and consistency of results is far more complex and time-consuming
    than building the initial prototype.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多现实世界的商业场景中，精度至关重要，“差不多正确”是不够的。例如，当你的LLM应用需要执行API调用，或者你在做财务报告的总结时。根据我的经验，确保结果的准确性和一致性比构建初始原型要复杂且耗时得多。
- en: In this article, I will discuss how to approach measuring and improving accuracy.
    We’ll build an SQL Agent where precision is vital for ensuring that queries are
    executable. Starting with a basic prototype, we’ll explore methods to measure
    accuracy and test various techniques to enhance it, such as self-reflection and
    retrieval-augmented generation (RAG).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将讨论如何衡量和提高准确性。我们将构建一个SQL代理，其中精度对于确保查询可执行至关重要。从一个基本的原型开始，我们将探索衡量准确性的方法，并测试各种增强准确性的技术，如自我反思和检索增强生成（RAG）。
- en: Setup
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置
- en: As usual, let’s begin with the setup. The core components of our SQL agent solution
    are the LLM model, which generates queries, and the SQL database, which executes
    them.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，让我们从设置开始。我们SQL代理解决方案的核心组件是LLM模型，它生成查询，以及执行查询的SQL数据库。
- en: LLM model — Llama
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM模型 — Llama
- en: For this project, we will use an open-source Llama model released by Meta. I’ve
    chosen [Llama 3.1 8B](https://ollama.com/library/llama3.1:8b) because it is lightweight
    enough to run on my laptop while still being quite powerful (refer to the [documentation](https://ai.meta.com/blog/meta-llama-3-1/)
    for details).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，我们将使用Meta发布的开源Llama模型。我选择了[Llama 3.1 8B](https://ollama.com/library/llama3.1:8b)，因为它足够轻量，可以在我的笔记本上运行，同时仍然相当强大（详细信息请参阅[文档](https://ai.meta.com/blog/meta-llama-3-1/)）。
- en: If you haven’t installed it yet, you can find guides [here](https://www.llama.com/docs/llama-everywhere).
    I use it locally on MacOS via [Ollama](https://ollama.com/). Using the following
    command, we can download the model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有安装，可以在[这里](https://www.llama.com/docs/llama-everywhere)找到指南。我通过[Ollama](https://ollama.com/)在MacOS上本地使用它。使用以下命令，我们可以下载该模型。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will use Ollama with [LangChain](https://python.langchain.com/docs/how_to/local_llms/),
    so let’s start by installing the required package.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Ollama与[LangChain](https://python.langchain.com/docs/how_to/local_llms/)一起，所以让我们从安装所需的包开始。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, we can run the Llama model and see the first results.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行Llama模型并查看第一个结果。
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We would like to pass a system message alongside customer questions. So, following
    [the Llama 3.1 model documentation](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1),
    let’s put together a helper function to construct a prompt and test this function.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望在客户提问时传递系统消息。所以，按照[《Llama 3.1模型文档》](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1)，让我们编写一个辅助函数来构造提示并测试这个函数。
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The new system prompt has changed the answer significantly, so it works. With
    this, our local LLM setup is ready to go.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 新的系统提示显著改变了答案，因此它是有效的。至此，我们的本地LLM设置已经准备好。
- en: Database — ClickHouse
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库 — ClickHouse
- en: I will use an open-source database [ClickHouse](https://clickhouse.com/). I’ve
    chosen ClickHouse because it has a specific SQL dialect. LLMs have likely encountered
    fewer examples of this dialect during training, making the task a bit more challenging.
    However, you can choose any other database.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用一个开源数据库[ClickHouse](https://clickhouse.com/)。我选择ClickHouse是因为它有一个特定的SQL方言。在训练过程中，LLM模型可能遇到的这种方言的示例较少，这使得任务稍微具有挑战性。然而，你可以选择任何其他数据库。
- en: Installing ClickHouse is pretty straightforward — just follow the instructions
    provided in [the documentation](https://clickhouse.com/docs/en/getting-started/quick-start).
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 安装ClickHouse相当简单 — 只需按照[文档](https://clickhouse.com/docs/en/getting-started/quick-start)中提供的指示操作。
- en: 'We will be working with two tables: `ecommerce.users` and `ecommerce.sessions`.
    These tables contain fictional data, including customer personal information and
    their session activity on the e-commerce website.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两个表：`ecommerce.users`和`ecommerce.sessions`。这些表包含虚构的数据，包括客户个人信息和他们在电商网站上的会话活动。
- en: '![](../Images/a8e953baae8a4221a6e942633e8368b9.png)![](../Images/26d6e8347db23de82055050ce6574c00.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8e953baae8a4221a6e942633e8368b9.png)![](../Images/26d6e8347db23de82055050ce6574c00.png)'
- en: You can find the code for generating synthetic data and uploading it on [GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/analyst_agent/generate_synthetic_data_for_sql.ipynb).
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以在[GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/analyst_agent/generate_synthetic_data_for_sql.ipynb)上找到生成合成数据并上传的代码。
- en: With that, the setup is complete, and we’re ready to move on to building the
    basic prototype.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，设置完成，我们准备好开始构建基础原型。
- en: The first prototype
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一个原型
- en: 'As discussed, our goal is to build an SQL Agent — an application that generates
    SQL queries to answer customer questions. In the future, we can add another layer
    to this system: executing the SQL query, passing both the initial question and
    the database results back to the LLM, and asking it to generate a human-friendly
    answer. However, for this article, we’ll focus on the first step.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们的目标是构建一个SQL代理——一个生成SQL查询以回答客户问题的应用程序。未来，我们可以在这个系统上添加另一层：执行SQL查询，将初始问题和数据库结果传回LLM，并让它生成一个易于理解的答案。然而，本文将集中于第一步。
- en: The best practice with LLM applications (similar to any other complex tasks)
    is to start simple and then iterate. The most straightforward implementation is
    to do one LLM call and share all the necessary information (such as schema description)
    in the system prompt. So, the first step is to put together the prompt.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM应用程序的最佳实践（类似于任何其他复杂任务）是从简单开始，然后进行迭代。最直接的实现方法是执行一次LLM调用，并在系统提示中共享所有必要的信息（如模式描述）。因此，第一步是准备提示语。
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: I’ve included the example values for each field in the prompt to ensure that
    LLM understands the data format.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我在提示中为每个字段包含了示例值，以确保LLM理解数据格式。
- en: And that’s it! With this, we have our first functional prototype for the SQL
    Agent. Now, it’s time to put it to the test.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！通过这个，我们获得了SQL代理的第一个功能原型。现在，是时候进行测试了。
- en: '[PRE5]sql'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE5]sql'
- en: SELECT COUNT(DISTINCT u.user_id)
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SELECT COUNT(DISTINCT u.user_id)
- en: FROM ecommerce.sessions s
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FROM ecommerce.sessions s
- en: JOIN ecommerce.users u ON s.user_id = u.user_id
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JOIN ecommerce.users u ON s.user_id = u.user_id
- en: WHERE
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: WHERE
- en: EXTRACT(YEAR FROM s.action_date) = 2024
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EXTRACT(YEAR FROM s.action_date) = 2024
- en: AND EXTRACT(MONTH FROM s.action_date) = 12
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AND EXTRACT(MONTH FROM s.action_date) = 12
- en: AND revenue > 0;
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AND revenue > 0;
- en: '[PRE6]sql'
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[PRE6]sql'
- en: SELECT COUNT(DISTINCT u.user_id)
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SELECT COUNT(DISTINCT u.user_id)
- en: FROM ecommerce.sessions s
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FROM ecommerce.sessions s
- en: JOIN ecommerce.users u ON s.user_id = u.user_id
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JOIN ecommerce.users u ON s.user_id = u.user_id
- en: WHERE
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: WHERE
- en: EXTRACT(YEAR FROM s.action_date) = 2024
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EXTRACT(YEAR FROM s.action_date) = 2024
- en: AND EXTRACT(MONTH FROM s.action_date) = 12
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AND EXTRACT(MONTH FROM s.action_date) = 12
- en: AND revenue > 0;
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AND revenue > 0;
- en: format TabSeparatedWithNames;
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 格式 TabSeparatedWithNames;
- en: '[PRE7]'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The agent produced a fairly decent result, but there’s one issue — the LLM returned
    not only the SQL query but also some commentary. Since we plan to execute SQL
    queries later, this format is not suitable for our task. Let’s work on fixing
    it.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 代理生成了一个相当不错的结果，但有一个问题——LLM不仅返回了SQL查询，还返回了一些评论。由于我们计划稍后执行SQL查询，这种格式并不适合我们的任务。让我们来解决这个问题。
- en: Fortunately, this problem has already been solved, and we don’t need to parse
    the SQL queries from the text manually. We can use the chat model [ChatOllama](https://python.langchain.com/docs/integrations/chat/ollama/).
    Unfortunately, it doesn’t support structured output, but we can leverage tool
    calling to achieve the same result.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这个问题已经得到解决，我们不需要手动从文本中解析SQL查询。我们可以使用聊天模型[ChatOllama](https://python.langchain.com/docs/integrations/chat/ollama/)。不幸的是，它不支持结构化输出，但我们可以通过工具调用实现相同的结果。
- en: To do this, we will define a dummy tool to execute the query and instruct the
    model in the system prompt always to call this tool. I’ve kept the `comments`
    in the output to give the model some space for reasoning, following the chain-of-thought
    pattern.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将定义一个虚拟工具来执行查询，并在系统提示中指示模型始终调用该工具。我在输出中保留了`comments`，以便给模型一些推理空间，遵循思维链模式。
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'With the tool calling, we can now get the SQL query directly from the model.
    That’s an excellent result. However, the generated query is not entirely accurate:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通过工具调用，我们现在可以直接从模型中获得SQL查询。这是一个很好的结果。然而，生成的查询并不完全准确：
- en: It includes a filter for `is_active = 1`, even though we didn’t specify the
    need to filter out inactive customers.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它包含了`is_active = 1`的过滤条件，尽管我们没有明确要求过滤掉非活跃客户。
- en: The LLM missed specifying the format despite our explicit request in the system
    prompt.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管我们在系统提示中明确要求指定格式，LLM还是没有做到这一点。
- en: Clearly, we need to focus on improving the model’s accuracy. But as Peter Drucker
    famously said, *“You can’t improve what you don’t measure.”* So, the next logical
    step is to build a system for evaluating the model’s quality. This system will
    be a cornerstone for performance improvement iterations. Without it, we’d essentially
    be navigating in the dark.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们需要专注于提高模型的准确性。但正如彼得·德鲁克（Peter Drucker）所说的那样，*“你不能改进你无法衡量的东西。”* 所以，下一步就是建立一个系统来评估模型的质量。这个系统将成为性能改进迭代的基石。如果没有它，我们基本上是在黑暗中摸索前进。
- en: Evaluating the accuracy
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估准确性
- en: Evaluation basics
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估基础
- en: To ensure we’re improving, we need a robust way to measure accuracy. The most
    common approach is to create a “golden” evaluation set with questions and correct
    answers. Then, we can compare the model’s output with these “golden” answers and
    calculate the share of correct ones. While this approach sounds simple, there
    are a few nuances worth discussing.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们在改进，需要一个可靠的方式来衡量准确性。最常见的方法是创建一个“黄金”评估集，其中包含问题和正确答案。然后，我们可以将模型的输出与这些“黄金”答案进行比较，并计算正确答案的比例。虽然这个方法听起来很简单，但还是有一些值得讨论的细节。
- en: First, you might feel overwhelmed at the thought of creating a comprehensive
    set of questions and answers. Building such a dataset can seem like a daunting
    task, potentially requiring weeks or months. However, we can start small by creating
    an initial set of 20–50 examples and iterating on it.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你可能会觉得创建一个全面的问答集让人不知所措。构建这样一个数据集看起来可能是一个令人生畏的任务，可能需要数周甚至数月的时间。然而，我们可以从小做起，先创建一个20到50个示例的初步集，并在此基础上进行迭代。
- en: 'As always, quality is more important than quantity. Our goal is to create a
    representative and diverse dataset. Ideally, this should include:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，质量比数量更重要。我们的目标是创建一个具有代表性且多样化的数据集。理想情况下，这应该包括：
- en: '**Common questions.** In most real-life cases, we can take the history of actual
    questions and use it as our initial evaluation set.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常见问题。** 在大多数实际情况下，我们可以采用实际问题的历史，并将其作为我们初步的评估集。'
- en: '**Challenging edge cases.** It’s worth adding examples where the model tends
    to hallucinate. You can find such cases either while experimenting yourself or
    by gathering feedback from the first prototype.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**挑战性的边界案例。** 值得添加一些模型容易产生幻觉的示例。你可以通过自己实验或者收集第一个原型的反馈来发现这些案例。'
- en: 'Once the dataset is ready, the next challenge is how to score the generated
    results. We can consider several approaches:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据集准备好，接下来的挑战是如何为生成的结果打分。我们可以考虑几种方法：
- en: '**Comparing SQL queries.** The first idea is to compare the generated SQL query
    with the one in the evaluation set. However, it might be tricky. Similarly-looking
    queries can yield completely different results. At the same time, queries that
    look different can lead to the same conclusions. Additionally, simply comparing
    SQL queries doesn’t verify whether the generated query is actually executable.
    Given these challenges, I wouldn’t consider this approach the most reliable solution
    for our case.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**比较SQL查询。** 第一个想法是将生成的SQL查询与评估集中的查询进行比较。然而，这可能会有些棘手。看似相似的查询可能会产生完全不同的结果。同时，看起来不同的查询也可能得出相同的结论。此外，单纯比较SQL查询并不能验证生成的查询是否能够实际执行。鉴于这些挑战，我不会认为这种方法是我们案例中最可靠的解决方案。'
- en: '**Exact matches.** We can use old-school exact matching when answers in our
    evaluation set are deterministic. For example, if the question is, “How many customers
    are there?” and the answer is “592800”, the model’s response must match precisely.
    However, this approach has its limitations. Consider the example above, and the
    model responds, *“There are 592,800 customers”*. While the answer is absolutely
    correct, an exact match approach would flag it as invalid.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确匹配。** 当我们的评估集中的答案是确定性的时，可以使用传统的精确匹配。例如，如果问题是“有多少个客户？”而答案是“592800”，那么模型的回答必须完全匹配。然而，这种方法也有其局限性。考虑上面的例子，模型回应为*“有592,800个客户”*。虽然答案完全正确，但精确匹配的方法会将其标记为无效。'
- en: '**Using LLMs for scoring.** A more robust and flexible approach is to leverage
    LLMs for evaluation. Instead of focusing on query structure, we can ask the LLM
    to compare the results of SQL executions. This method is particularly effective
    in cases where the query might differ but still yields correct outputs.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用LLM进行评分。** 一个更强大且灵活的方法是利用LLM进行评估。我们不再关注查询结构，而是让LLM比较SQL执行的结果。这种方法在查询可能不同但仍能得出正确结果的情况下特别有效。'
- en: It’s worth keeping in mind that evaluation isn’t a one-time task; it’s a continuous
    process. To push our model’s performance further, we need to expand the dataset
    with examples causing the model’s hallucinations. In production mode, we can create
    a feedback loop. By gathering input from users, we can identify cases where the
    model fails and include them in our evaluation set.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 值得记住的是，评估并非一次性任务；它是一个持续的过程。为了进一步提升模型的性能，我们需要通过添加导致模型产生幻觉的示例来扩展数据集。在生产模式下，我们可以创建一个反馈循环。通过收集用户反馈，我们可以识别模型失败的案例，并将其纳入我们的评估集中。
- en: In our example, we will be assessing only whether the result of execution is
    valid (SQL query can be executed) and correct. Still, you can look at other parameters
    as well. For example, if you care about efficiency, you can compare the execution
    times of generated queries against those in the golden set.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将只评估执行结果是否有效（SQL查询能否执行）和正确性。当然，你也可以查看其他参数。例如，如果你关心效率，可以将生成查询的执行时间与黄金集中的查询执行时间进行比较。
- en: Evaluation set and validation
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估集和验证
- en: 'Now that we’ve covered the basics, we’re ready to put them into practice. I
    spent about 20 minutes putting together a set of 10 examples. While small, this
    set is sufficient for our toy task. It consists of a list of questions paired
    with their corresponding SQL queries, like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了基础知识，就准备将其付诸实践。我花了大约20分钟时间准备了一组10个示例。虽然这组数据量小，但足以完成我们的简单任务。它由一组问题和相应的SQL查询组成，格式如下：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can find the full list on GitHub — [link](https://github.com/miptgirl/miptgirl_medium/blob/main/sql_agent_accuracy/golden_set.json).
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以在GitHub上找到完整的列表 —— [链接](https://github.com/miptgirl/miptgirl_medium/blob/main/sql_agent_accuracy/golden_set.json)。
- en: We can load the dataset into a DataFrame, making it ready for use in the code.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将数据集加载到DataFrame中，使其准备好在代码中使用。
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: First, let’s generate the SQL queries for each question in the evaluation set.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们为评估集中的每个问题生成SQL查询。
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Before moving on to the LLM-based scoring of query outputs, it’s important to
    first ensure that the SQL query is valid. To do this, we need to execute the queries
    and examine the database output.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行基于LLM的查询输出评分之前，首先确保SQL查询是有效的非常重要。为此，我们需要执行查询并检查数据库输出。
- en: I’ve created a function that runs a query in ClickHouse. It also ensures that
    the output format is correctly specified, as this may be critical in business
    applications.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经创建了一个在ClickHouse中运行查询的函数。它还确保输出格式正确指定，因为这在业务应用中可能至关重要。
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The next step is to execute both the generated and golden queries and then save
    their outputs.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是执行生成的查询和标准查询，然后保存它们的输出。
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Next, let’s check the output to see whether the SQL query is valid or not.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们检查输出，看看SQL查询是否有效。
- en: '[PRE14]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Then, we can evaluate the SQL validity for both the golden and generated sets.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以评估生成集和标准集的SQL有效性。
- en: '![](../Images/f08fffac61b75163a4cd0b3d5895a561.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f08fffac61b75163a4cd0b3d5895a561.png)'
- en: The initial results are not very promising; the LLM was unable to generate even
    a single valid query. Looking at the errors, it’s clear that the model failed
    to specify the right format despite it being explicitly defined in the system
    prompt. So, we definitely need to work more on the accuracy.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 初始结果不太理想；LLM甚至未能生成一个有效的查询。从错误来看，很明显模型没有按照系统提示中明确定义的格式进行操作。所以，我们确实需要更多地关注准确性。
- en: Checking the correctness
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查正确性
- en: However, validity alone is not enough. It’s crucial that we not only generate
    valid SQL queries but also produce the correct results. Although we already know
    that all our queries are invalid, let’s now incorporate output evaluation into
    our process.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅验证有效性是不够的。我们不仅需要生成有效的SQL查询，还必须生成正确的结果。尽管我们已经知道所有查询都是无效的，但现在让我们将输出评估纳入到我们的过程中。
- en: As discussed, we will use LLMs to compare the outputs of the SQL queries. I
    typically prefer using more powerful model for evaluation, following the day-to-day
    logic where a senior team member reviews the work. For this task, I’ve chosen
    [OpenAI GPT 4o-mini](https://python.langchain.com/docs/integrations/chat/openai/).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将使用LLM比较SQL查询的输出。我通常更倾向于使用更强大的模型进行评估，这符合日常逻辑，即由资深团队成员审查工作。对于这个任务，我选择了[OpenAI
    GPT 4o-mini](https://python.langchain.com/docs/integrations/chat/openai/)。
- en: Similar to our generation flow, I’ve set up all the building blocks necessary
    for accuracy assessment.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们的生成流程类似，我已经设置好了所有进行准确性评估所需的构件。
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, it’s time to test the accuracy assessment process.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候测试准确性评估过程了。
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Fantastic! It looks like everything is working as expected. Let’s now encapsulate
    this into a function.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！看起来一切都按预期工作。接下来，让我们将其封装成一个函数。
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Putting the evaluation approach together
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 整合评估方法
- en: As we discussed, building an LLM application is an iterative process, so we’ll
    need to run our accuracy assessment multiple times. It will be helpful to have
    all this logic encapsulated in a single function.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，构建LLM应用程序是一个迭代过程，因此我们需要多次运行准确性评估。将所有这些逻辑封装到一个函数中将非常有帮助。
- en: 'The function will take two arguments as input:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将接受两个参数作为输入：
- en: '`generate_query_func`: a function that generates an SQL query for a given question.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_query_func`：一个根据给定问题生成SQL查询的函数。'
- en: '`golden_df`: an evaluation dataset with questions and correct answers in the
    form of a pandas DataFrame.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`golden_df`：一个包含问题和正确答案的评估数据集，形式为pandas DataFrame。'
- en: As output, the function will return a DataFrame with all evaluation results
    and a couple of charts displaying the main KPIs.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 作为输出，函数将返回一个包含所有评估结果的数据框，并展示几个显示主要KPI的图表。
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: With that, we’ve completed the evaluation setup and can now move on to the core
    task of improving the model’s accuracy.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们已经完成了评估设置，接下来可以进入提高模型准确性的核心任务。
- en: 'Improving accuracy: Self-reflection'
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高准确性：自我反思
- en: Let’s do a quick recap. We’ve built and tested the first version of SQL Agent.
    Unfortunately, all generated queries were invalid because they were missing the
    output format. Let’s address this issue.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速回顾一下。我们已经构建并测试了SQL Agent的第一个版本。不幸的是，所有生成的查询都是无效的，因为它们缺少输出格式。让我们解决这个问题。
- en: One potential solution is self-reflection. We can make an additional call to
    the LLM, sharing the error and asking it to correct the bug. Let’s create a function
    to handle generation with self-reflection.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一种潜在的解决方案是自我反思。我们可以向LLM发出额外的请求，分享错误并要求其修正bug。让我们创建一个函数来处理带有自我反思的生成任务。
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now, let’s use our evaluation function to check whether the quality has improved.
    Assessing the next iteration has become effortless.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用评估函数检查质量是否有所改善。评估下一个迭代变得轻松起来。
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Wonderful! We’ve achieved better results — 50% of the queries are now valid,
    and all format issues have been resolved. So, self-reflection is pretty effective.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们取得了更好的结果——现在50%的查询是有效的，所有格式问题都已解决。因此，自我反思非常有效。
- en: '![](../Images/63565d380cffadf15d0a96cc68e4012c.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63565d380cffadf15d0a96cc68e4012c.png)'
- en: However, self-reflection has its limitations. When we examine the accuracy,
    we see that the model returns the correct answer for only one question. So, our
    journey is not over yet.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，自我反思有其局限性。当我们检查准确性时，我们发现模型仅对一个问题返回了正确答案。所以，我们的旅程还没有结束。
- en: '![](../Images/f0d6c215fce6284d676ef0d3d13ae6a3.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0d6c215fce6284d676ef0d3d13ae6a3.png)'
- en: 'Improving accuracy: RAG'
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高准确性：RAG
- en: Another approach to improving accuracy is using RAG (retrieval-augmented generation).
    The idea is to identify question-and-answer pairs similar to the customer query
    and include them in the system prompt, enabling the LLM to generate a more accurate
    response.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 提高准确性的另一种方法是使用RAG（检索增强生成）。其理念是识别与客户查询相似的问题和答案对，并将其包含在系统提示中，使得LLM能够生成更准确的回答。
- en: 'RAG consists of the following stages:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: RAG包含以下阶段：
- en: '**Loading documents:** importing data from available sources.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加载文档：** 从可用数据源导入数据。'
- en: '**Splitting documents:** creating smaller chunks.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拆分文档：** 创建较小的文档片段。'
- en: '**Storage:** using vector stores to process and store data efficiently.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储：** 使用向量存储高效处理和存储数据。'
- en: '**Retrieval:** extracting documents that are relevant to the query.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索：** 提取与查询相关的文档。'
- en: '**Generation:** passing a question and relevant documents to LLM to generate
    the final answer**.**'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成：** 将问题和相关文档传递给LLM以生成最终答案**。**'
- en: '![](../Images/c31e55cce3e7ee98abf62bc796f10882.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c31e55cce3e7ee98abf62bc796f10882.png)'
- en: 'If you’d like a refresher on RAG, you can check out my previous article, [“RAG:
    How to Talk to Your Data.”](https://medium.com/towards-data-science/rag-how-to-talk-to-your-data-eaf5469b83b0)'
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你想回顾RAG的内容，可以查看我之前的文章，[“RAG：如何与数据对话。”](https://medium.com/towards-data-science/rag-how-to-talk-to-your-data-eaf5469b83b0)
- en: We will use the Chroma database as a local vector storage — to store and retrieve
    embeddings.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Chroma数据库作为本地向量存储——用于存储和检索嵌入。
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Vector stores are using embeddings to find chunks that are similar to the query.
    For this purpose, we will use OpenAI embeddings.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储使用嵌入查找与查询相似的片段。为此，我们将使用OpenAI的嵌入。
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Since we can’t use examples from our evaluation set (as they are already being
    used to assess quality), I’ve created a separate set of question-and-answer pairs
    for RAG. You can find it on [GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/sql_agent_accuracy/rag_set.json).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不能使用评估集中的示例（因为它们已经用于评估质量），我创建了一个独立的问题和答案对集用于RAG。你可以在[GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/sql_agent_accuracy/rag_set.json)上找到它。
- en: 'Now, let’s load the set and create a list of pairs in the following format:
    `Question: %s; Answer: %s`.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，让我们加载数据集并创建以下格式的对列表：`Question: %s; Answer: %s`。'
- en: '[PRE23]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Next, I used LangChain’s text splitter by character to create chunks, with each
    question-and-answer pair as a separate chunk. Since we are splitting the text
    semantically, no overlap is necessary.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我使用LangChain的按字符拆分器将文档拆分为片段，每个问题和答案对作为一个独立的片段。由于我们是从语义上拆分文本，因此不需要重叠。
- en: '[PRE24]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The final step is to load the chunks into our vector storage.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将这些数据块加载到我们的向量存储中。
- en: '[PRE25]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Now, we can test the retrieval to see the results. They look quite similar to
    the customer question.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以测试检索来查看结果。它们看起来与客户问题非常相似。
- en: '[PRE26]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Let’s adjust the system prompt to include the examples we retrieved.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们调整系统提示，包含我们检索到的示例。
- en: '[PRE27]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Once again, let’s create the generate query function with RAG.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 再一次，让我们使用RAG创建生成查询函数。
- en: '[PRE28]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As usual, let’s use our evaluation function to test the new approach.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，让我们使用我们的评估函数来测试这个新方法。
- en: '[PRE29]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We can see a significant improvement, increasing from 1 to 6 correct answers
    out of 10\. It’s still not ideal, but we’re moving in the right direction.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到一个显著的改进，从10个中的1个正确答案增加到6个。虽然仍然不理想，但我们正在朝着正确的方向前进。
- en: '![](../Images/f30d73b1e415ab57414572251435a6f8.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f30d73b1e415ab57414572251435a6f8.png)'
- en: 'We can also experiment with combining two approaches: RAG and self-reflection.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以尝试将两种方法结合起来：RAG和自我反思。
- en: '[PRE30]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can see another slight improvement: we’ve completely eliminated invalid
    SQL queries (thanks to self-reflection) and increased the number of correct answers
    to 7 out of 10.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到另一个轻微的改进：我们已经完全消除了无效的SQL查询（得益于自我反思），并且将正确答案的数量提高到了10个中的7个。
- en: '![](../Images/d989bf6f8488b48e7e17811ea05b6b4b.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d989bf6f8488b48e7e17811ea05b6b4b.png)'
- en: That’s it. It’s been quite a journey. We started with 0 valid SQL queries and
    have now achieved 70% accuracy.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。这是一次相当的旅程。我们从0个有效的SQL查询开始，现在已经达到了70%的准确率。
- en: You can find the complete code on [GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/sql_agent_accuracy/sql_agent_poc.ipynb).
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 您可以在[GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/sql_agent_accuracy/sql_agent_poc.ipynb)上找到完整的代码。
- en: Summary
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this article, we explored the iterative process of improving accuracy for
    LLM applications.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们探讨了提高LLM应用准确性的迭代过程。
- en: We built an evaluation set and the scoring criteria that allowed us to compare
    different iterations and understand whether we were moving in the right direction.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们构建了一个评估集和评分标准，允许我们比较不同的迭代，并了解我们是否朝着正确的方向前进。
- en: We leveraged self-reflection to allow the LLM to correct its mistakes and significantly
    reduce the number of invalid SQL queries.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们利用自我反思来让LLM修正其错误，并显著减少无效的SQL查询数量。
- en: Additionally, we implemented Retrieval-Augmented Generation (RAG) to further
    enhance the quality, achieving an accuracy rate of 60–70%.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，我们实现了检索增强生成（RAG），进一步提高了质量，达到了60%到70%的准确率。
- en: While this is a solid result, it still falls short of the 90%+ accuracy threshold
    typically expected for production applications. To achieve such a high bar, we
    need to use fine-tuning, which will be the topic of the next article.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一个稳健的结果，但它仍然未达到通常对于生产应用期望的90%以上的准确率。为了达到这样的高标准，我们需要使用微调，这将是下一篇文章的主题。
- en: Thank you a lot for reading this article. I hope this article was insightful
    for you. If you have any follow-up questions or comments, please leave them in
    the comments section.
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 非常感谢您阅读这篇文章。希望这篇文章对您有所启发。如果您有任何后续问题或评论，请在评论区留言。
- en: Reference
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考
- en: '*All the images are produced by the author unless otherwise stated.*'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均由作者制作。*'
- en: This article is inspired by the [“Improving Accuracy of LLM Applications”](https://www.deeplearning.ai/short-courses/improving-accuracy-of-llm-applications/)
    short course from DeepLearning.AI.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的灵感来源于DeepLearning.AI的[“提高LLM应用准确性”](https://www.deeplearning.ai/short-courses/improving-accuracy-of-llm-applications/)短期课程。
