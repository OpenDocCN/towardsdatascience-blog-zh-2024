- en: Machine Learning Operations (MLOps) For Beginners
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/machine-learning-operations-mlops-for-beginners-a5686bfe02b2?source=collection_archive---------0-----------------------#2024-08-29](https://towardsdatascience.com/machine-learning-operations-mlops-for-beginners-a5686bfe02b2?source=collection_archive---------0-----------------------#2024-08-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: End-to-end Project Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@prasadmahamulkar?source=post_page---byline--a5686bfe02b2--------------------------------)[![Prasad
    Mahamulkar](../Images/ed895003bf372f0c109f70e08458dad8.png)](https://medium.com/@prasadmahamulkar?source=post_page---byline--a5686bfe02b2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a5686bfe02b2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a5686bfe02b2--------------------------------)
    [Prasad Mahamulkar](https://medium.com/@prasadmahamulkar?source=post_page---byline--a5686bfe02b2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a5686bfe02b2--------------------------------)
    ·19 min read·Aug 29, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4e4347f61e9dc1b6ed4aaddf273822a0.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by the author
  prefs: []
  type: TYPE_NORMAL
- en: Developing, deploying, and maintaining machine learning models in production
    can be challenging and complex. This is where Machine Learning Operations (MLOps)
    comes into play. MLOps is a set of practices that automate and simplify machine
    learning (ML) workflows and deployments. In this article, I will be sharing some
    basic MLOps practices and tools through an end-to-end project implementation that
    will help you manage machine learning projects more efficiently, from development
    to production.
  prefs: []
  type: TYPE_NORMAL
- en: 'After reading this article, you will know:'
  prefs: []
  type: TYPE_NORMAL
- en: How to use **DVC** for data versioning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to track logs, artifacts, and register model versions using **MLflow.**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to deploy a model using **FastAPI**, **Docker**, and **AWS ECS**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to monitor a model in production using **Evidently AI**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the code used in this article is available on [GitHub](https://github.com/prsdm/mlops-project).
  prefs: []
  type: TYPE_NORMAL
- en: Please note that GIF examples might not load completely in the Medium app but
    should work fine in a browser.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Before we start, let’s first quickly understand what is MLOps.
  prefs: []
  type: TYPE_NORMAL
- en: What is MLOps?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLOps is a set of techniques and practices designed to simplify and automate
    the lifecycle of machine learning (ML) systems. MLOps aims to improve the efficiency
    and reliability of deploying ML models into production by providing clear guidelines
    and responsibilities for professionals and researchers. It bridges the gap between
    ML development and production, ensuring that machine learning models can be efficiently
    developed, deployed, managed, and maintained in real-world environments. This
    approach helps reduce system design errors, enabling more robust and accurate
    predictions in real-world settings.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/433e86c6688830bd32fc52cd42c760bf.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by the author
  prefs: []
  type: TYPE_NORMAL
- en: '**Why do we need MLOps?**'
  prefs: []
  type: TYPE_NORMAL
- en: Typically, any machine learning project starts with defining the business problem.
    Once the problem is defined, data extraction, data preparation, feature engineering,
    and model training steps are implemented to develop the model. After the model
    is developed, it is usually stored somewhere so that the engineering and operations
    teams can deploy it for production use.
  prefs: []
  type: TYPE_NORMAL
- en: '**What is wrong with this approach?**'
  prefs: []
  type: TYPE_NORMAL
- en: It creates a gap between the development and deployment phases, leading to inefficiencies
    and potential errors. Without collaboration between data scientists and engineers,
    models may not be optimized for production, which can result in issues such as
    performance degradation, lack of scalability, and maintenance difficulties.
  prefs: []
  type: TYPE_NORMAL
- en: MLOps solves these problems by creating a unified workflow that integrates development
    and operations. It ensures that models are reliable, scalable, and easier to maintain.
    This approach reduces the risk of errors, accelerates deployment, and keeps models
    effective and up-to-date through continuous monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a basic understanding of MLOps, let’s move on to the implementation
    part.
  prefs: []
  type: TYPE_NORMAL
- en: Project Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning project requires a standard project structure to ensure it
    can be easily maintained and modified. A good project structure allows team members
    to collaborate easily and effectively.
  prefs: []
  type: TYPE_NORMAL
- en: For this project, we will use a very basic structure that will help us manage
    the entire lifecycle of a machine learning project, including data ingestion,
    preprocessing, model training, evaluation, deployment, and monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, clone the mlops-project repository from [GitHub](https://github.com/prsdm/mlops-project)
    and follow along.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'After cloning the repository the project structure will look something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a breakdown of the structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '**data**: Stores data files used for model training and evaluation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**docs**: Contains project documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**models**: Stores trained machine learning models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mlruns**: Contains logs and artifacts generated by MLflow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**steps**: Includes source code for data ingestion, cleaning, and model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tests**: Includes unit tests to verify the functionality of the code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**app.py**: Contains the FastAPI application code for deploying the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config.yml**: Configuration file for storing project parameters and paths.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data.dvc**: Tracks data files and their versions using DVC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dataset.py**: Script for downloading or generating data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dockerfile**: Used to build a Docker image for containerizing the FastAPI
    application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**main.py**: Automates the model training process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Makefile**: Contains commands for automating tasks such as training or testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mkdocs.yml**: Configuration file for MkDocs, used to generate project documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**requirements.txt**: Contains all the required packages for the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**samples.json**: Contains sample data for testing purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**monitor.ipynb**: Jupyter notebook for monitoring model performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**production_data.html** and **test_data.html**: Stores monitoring results
    for test and production data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This project structure is designed to organize the entire machine learning project,
    from development to monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create a virtual environment and activate it using the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '**For bash:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**For cmd:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Next, install all required packages using the `requirements.txt` file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/488421180facfca41024fb0e159dc7fd.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of project setup
  prefs: []
  type: TYPE_NORMAL
- en: With the environment set up and dependencies installed, we can now move on to
    the model training part.
  prefs: []
  type: TYPE_NORMAL
- en: Model Training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In model training, the first step is to get data from the source, which could
    be either local storage or remote storage. To do this, run the `dataset.py` file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This script retrieves the data from its source, splits it into training and
    testing datasets, and then stores them in the `data/` directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/8efa34dfc2f40d4e48f1356718dbffe0.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of data extraction
  prefs: []
  type: TYPE_NORMAL
- en: Once the data is stored in the data directory, the next steps include cleaning,
    processing, and model training. The `steps/` folder contains modules for each
    of these stages.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at what each file does:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ingestion.py` handles the initial data ingestion, ensuring that data is correctly
    loaded and available for the next stages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clean.py` focuses on data cleaning tasks, such as handling missing values,
    removing duplicates, and making other data quality improvements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train.py` responsible for training the model on the cleaned data and saving
    the model as `model.pkl` in the `models/` directory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict.py`is used to evaluate model performance on test data using the trained
    model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note:** These files can be changed or removed depending on project requirements.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To run all these steps in sequence, execute the `main.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s how the `main.py` file looks in this project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**Example:**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/6c5658496e301f579e1ff3d2b6d49497.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of model training
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s see how we can improve this project using tools like DVC and MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: Data Version Control (DVC)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s start with Data Version Control (DVC), a free, open-source tool designed
    to manage large datasets, automate ML pipelines, and handle experiments. It helps
    data science and machine learning teams manage their data more effectively, ensure
    reproducibility, and improve collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why use DVC over GitHub?**'
  prefs: []
  type: TYPE_NORMAL
- en: Git is excellent for versioning source code and text files, but it has limitations
    when dealing with large binary files such as datasets. Git does not provide meaningful
    comparisons between versions of binary files; it only stores new versions without
    showing detailed differences, making it challenging to track changes over time.
    Additionally, storing large datasets or sensitive data in GitHub is not ideal,
    as it can lead to bloated repositories and potential security risks.
  prefs: []
  type: TYPE_NORMAL
- en: DVC addresses these issues by managing large files through metadata and external
    storage (such as S3, Google Cloud Storage, or Azure Blob Storage) while maintaining
    detailed tracking of data changes and version history. DVC uses human-readable
    metafiles to define data versions and integrates with Git or any source control
    management (SCM) tool to version and share the entire project, including data
    assets. Additionally, it provides secure collaboration by controlling access to
    project components and sharing them with designated teams and individuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started with DVC, first install it (if it’s not already installed):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, initialize DVC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This sets up the necessary DVC configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, add data files to DVC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This tracks the data files with DVC, storing the actual data in external storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure remote storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Replace `<remote_name>` with a name for remote storage and `<remote_storage_path>`
    with the path to the remote storage (e.g., s3://mybucket/mydata).
  prefs: []
  type: TYPE_NORMAL
- en: 'Push data to remote storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This uploads data to the configured remote storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Push all committed changes to git:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/621cfc48be2931844cdb2bfd443bf86f.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of DVC push
  prefs: []
  type: TYPE_NORMAL
- en: 'To pull the latest data version from remote storage to the local directory,
    use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/486c09f9c048043971f6ceccee56fd54.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of DVC pull
  prefs: []
  type: TYPE_NORMAL
- en: By integrating DVC, we can manage large datasets efficiently while keeping the
    Git repository focused on source code.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** We can use DVC to version models just like data files.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After versioning data with DVC, it’s crucial to maintain a clear record of model
    training, version changes, and parameter configurations, even if we are not actively
    experimenting with multiple models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Without systematic tracking, several issues can arise:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Loss of Version Details**: Without keeping track of which parameters and
    code changes were used for each model version, it becomes hard to reproduce or
    build on past work. This can slow down the progress and cause repeated mistakes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Difficulty in Version Comparison**: Consistently recording how well each
    model performs helps compare different versions. Without this, it is tough to
    see if a model is improving or not.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Collaboration Challenges**: In a team, not having a clear way to manage model
    versions can lead to confusion and accidental overwrites of each other’s work,
    complicating the collaborative process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is where MLflow comes in. MLflow is not just for experimenting; it also
    plays a critical role in tracking the lifecycle of ML models. It logs metrics,
    artifacts, and parameters, ensuring that every version change is documented and
    easily retrievable. With MLflow, we can monitor each run, and compare different
    versions. So that the most effective model is always identifiable and ready for
    deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'To integrate MLflow, first install MLflow (if it’s not already installed):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Then update the `main.py` file to include logging of parameters, metrics, and
    models. The code will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, run the `main.py` script and view experiment details using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Open the provided URL `http://127.0.0.1:5000` in a browser to explore and compare
    logged parameters, metrics, and models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/2b0c5e829afeb61208545943899ba635.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of MLflow tracking
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/76fa71c6428e417e297efad96fbdc37b.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of MLflow model comparison
  prefs: []
  type: TYPE_NORMAL
- en: By using MLflow, we can easily track model versions and manage changes, ensuring
    reproducibility and the ability to select the most effective model for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move to the deployment part, let’s take a look at the `Makefile` and
    `config.yml` files that are present in the project. These files help simplify
    the workflow and ensure consistency in the project setup and configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Makefile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using `make` file can be very helpful for managing Python projects. Many Data
    Scientists and ML Engineers don’t realize this but `make`can automate routine
    tasks such as setting up the environment, installing dependencies, model training,
    running tests, and cleaning up files, which saves time and reduces mistakes. `make`
    file is commonly used in software development because it helps manage long and
    complex commands that are difficult to remember.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `make` file in this project looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bash:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: For Windows (**cmd**), the file needs to be modified a little bit.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a breakdown of each part:'
  prefs: []
  type: TYPE_NORMAL
- en: '**make setup**: Creates a virtual environment (`venv`), upgrades `pip`, and
    installs the required packages from `requirements.txt`. This ensures that all
    dependencies are consistently installed across different environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**make run**: Executes the `main.py` using the Python interpreter from the
    virtual environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**make mlflow**: Starts the `mlflow ui` for tracking experiments and model
    metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**make test**: This command runs all test cases defined in the project using
    `pytest`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**make clean**: Removes cache files such as `__pycache__`, `.pytest_cache`,
    and other temporary files to keep the directory clean.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**make remove**: Removes the virtual environment (`venv`) completely from the
    project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sample commands to run make file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/41fc482a0cc487231ca3bf1574c4647b.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Make Commands
  prefs: []
  type: TYPE_NORMAL
- en: By using the `make` file, we can automate and streamline various tasks, ensuring
    consistency and reducing manual errors across different environments.
  prefs: []
  type: TYPE_NORMAL
- en: Config.yml
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: YAML files are a great way to store and manage configuration settings for Machine
    Learning models. They help manage data/model paths, model parameters, and other
    configurations, making it easier to experiment with different configurations and
    maintain code reusability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Config.yml` file looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s what each part does:'
  prefs: []
  type: TYPE_NORMAL
- en: '**data**: Specifies the paths to the training, test, and production (latest)
    datasets. This ensures that the data locations are managed in one place and can
    be easily updated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**train**: Contains parameters for splitting the data into training and test
    sets, such as `test_size`, `random_state`, and whether to `shuffle` the data.
    These settings help maintain consistent data splitting and reproducibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model**: Defines the model name, its parameters, and the location for storing
    the trained model. This configuration enables easy switching between different
    models, offering flexibility in model selection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the `config.yml` file simplifies the management of model parameters and
    paths. It allows for easy experimentation with different configurations and models,
    improves reproducibility by keeping parameter settings consistent, and helps maintain
    cleaner code by separating configuration from code logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the following example model is changed to **‘**GradientBoostingClassifier’
    based on the configuration specified in the `config.yml` file.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ece4352cdd5170ffa837850b64d05f68.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of config.yml file
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s move on to the deployment part, where we will use FastAPI, Docker
    and AWS ECS. This setup will help us create a scalable and easily manageable application
    for serving machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: FastAPI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FastAPI is a modern framework for building APIs with Python. It is efficient
    for serving machine learning models due to its speed and simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, install FastAPI and Uvicorn (if it’s not already installed):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Define the FastAPI application and endpoints for serving the model in the `app.py`file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, test the FastAPI server locally at `[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs.)`using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/ff6022408bfec3ee5ca68f5b95dbdc63.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of FastAPI
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now containerize this API using Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker is an open-source platform that simplifies the deployment of software
    applications by packaging them into containers. These containers act as lightweight,
    portable units that include everything needed to run the application across different
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why Use Containers?**'
  prefs: []
  type: TYPE_NORMAL
- en: Containers offer a streamlined way to isolate and deploy applications, ensuring
    they run consistently across various environments, whether on a developer’s laptop
    or the cloud. This isolation enhances portability and resource efficiency, making
    docker an essential tool for modern software development.
  prefs: []
  type: TYPE_NORMAL
- en: To install Docker, follow the instructions on the Docker [website](https://docs.docker.com/engine/install/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, create a `Dockerfile` in the project directory to build the Docker image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, build a Docker image using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/6a4b94e713432e4dd043e616c9252956.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of docker build
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, run the Docker container to test the API at `[http://localhost:80/predict](http://localhost:8000/predict)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/987e60966002426488027646f2a2da9c.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of docker run
  prefs: []
  type: TYPE_NORMAL
- en: 'To stop a running Docker container, find the container ID or name of the running
    container using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the container ID or name is identified, it can be stopped using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/17f265eb272f9f80a8365c4045e2be0e.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of stopping running container
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to push the Docker image to Docker Hub, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'List all Docker images on the system along with their tags and find the correct
    image to be pushed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Tag the image with the desired repository and name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Upload the tagged image to Docker Hub using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This command will upload the image to the specified repository on [Docker Hub](https://hub.docker.com/r/prsdm17/ml-fastapi).
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/6cbeca077321b30125b63f03cf8c8cca.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Docker Push Commands
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cd391dafbbf7faacc837a7544a304b52.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Docker Hub Repository
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have pushed the Docker image to [Docker Hub](https://hub.docker.com/r/prsdm17/ml-fastapi),
    we can move on to deploy it on AWS Elastic Container Service (ECS).
  prefs: []
  type: TYPE_NORMAL
- en: AWS ECS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AWS ECS is a fully managed container orchestration service that allows running
    and scaling Docker containers on AWS easily. It supports both EC2 and Fargate
    launch types. Here is a step-by-step guide:'
  prefs: []
  type: TYPE_NORMAL
- en: '**First, create an ECS Cluster:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1:** Log in to the [AWS](https://aws.amazon.com/console/) account then
    go to the ECS service and create a new ECS cluster by selecting “Create Cluster.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 2:** Give a name to the cluster, select AWS Fargate (serverless), and
    click on “Create.” (This will take a few minutes.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/73c0a880af4734335fbe9f7195681157.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of AWS Cluster
  prefs: []
  type: TYPE_NORMAL
- en: '**Then, define a Task Definition:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1:** In the ECS console, go to “Task Definitions” and create a new task
    definition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 2:** Give the task a name and configure settings such as memory and
    CPU requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 3:** Docker image URL from Docker Hub in the container definitions and
    keep the container port mappings default. Click on “Create.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/19ce792b71f55a9c6a2631e354032621.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Task Definition
  prefs: []
  type: TYPE_NORMAL
- en: '**After that, add a Security Group:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1:** Go to EC2, then in Networks and Security, select Security Groups
    and click on “Create Security Group.” Give it a name and description.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 2:** In Inbound Rules, select the type HTTP and source Anywhere-IPv4
    first, then do the same for Anywhere-IPv6\. Click “Create Security Group.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/c84e4e7149e7fe304b8dc251c35ec1af.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of AWS security Group
  prefs: []
  type: TYPE_NORMAL
- en: '**Then, create a Service:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1:** Go to the ECS cluster that was created and add a new service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 2:** Select the ‘launch type’ compute options and ‘Fargate’ launch type.
    Then select the task definition that was created and give the service name in
    the deployment configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 3:** Finally, select the security group created earlier under Networking
    and click “Create.” (This will take 5–8 minutes to create the service.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/a98607ff0fc23752d7c68c3b904ba920.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of services
  prefs: []
  type: TYPE_NORMAL
- en: '**And Finally, Access the Running Service:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the service is deployed, go to the ECS cluster’s “Services” tab. Find
    service, go to the “Tasks” tab, and select a running task. Open the public IP
    address of the task to access the FastAPI application. It will look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e699102eb90f96d1c722da9f5ba8dfb.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Public IP
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c29015d8e8feecab646eeb5264dd2d3c.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of deployed service
  prefs: []
  type: TYPE_NORMAL
- en: By following these steps, we can deploy the FastAPI application in a Docker
    container to AWS ECS. This enables a scalable and manageable environment for serving
    machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** We can also add Elastic Load Balancing (ELB) if needed.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: After successfully deploying the model, the next step is to continuously monitor
    the model in production to ensure it performs well on production data. Model monitoring
    involves evaluating various factors such as server metrics (e.g., CPU usage, memory
    consumption, latency), data quality, data drift, target drift, concept drift,
    performance metrics, etc.
  prefs: []
  type: TYPE_NORMAL
- en: To keep it beginner-friendly, we are going to focus on a few methods such as
    data drift, target drift, and data quality using Evidently AI.
  prefs: []
  type: TYPE_NORMAL
- en: Evidently AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Evidently AI is a good tool for monitoring model performance, detecting data
    drift, and data quality over time. It helps ensure that the model remains accurate
    and reliable as new data comes in. Evidently AI provides detailed insights into
    how model performance evolves and identifies any significant shifts in the data
    distribution, which is crucial for maintaining model accuracy in production environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Evidently AI use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, run `monitor.ipynb` file to detect data quality, data drifts, and target
    drifts. The file looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Example of Test data:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/909559efedea6b04a1634846dc5d2385.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Test data quality and drift detect
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of Production data:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/1f9483ebcf1b453e4e82edb3bd5c0699.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Production data quality and drift detect
  prefs: []
  type: TYPE_NORMAL
- en: Run the monitoring script regularly on incoming data to generate reports on
    data drift and model performance. These reports can help us identify when retraining
    is needed and ensure that our model remains accurate and reliable over time.
  prefs: []
  type: TYPE_NORMAL
- en: With this step, we have successfully completed the MLOps project implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we covered basic MLOps practices and tools through a hands-on
    project. We versioned data with DVC, tracked and registered models using MLflow,
    and deployed a model with FastAPI, Docker, and AWS ECR. We also set up model monitoring
    (data quality, data drift, and target drift) with Evidently AI. These steps provide
    a solid foundation for managing machine learning projects using MLOps tools and
    practices, from development to production. As you gain experience with these tools
    and techniques, you can explore more advanced automation and orchestration methods
    to enhance your MLOps workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Machine Learning Operations (MLOps): Overview, Definition, and Architecture.
    ([https://arxiv.org/pdf/2205.02302](https://arxiv.org/pdf/2205.02302))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Data Version Control (DVC): [https://dvc.org/doc](https://dvc.org/doc)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'MLflow: [https://mlflow.org/docs/latest/index.html](https://mlflow.org/docs/latest/index.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'FastAPI: [https://fastapi.tiangolo.com/tutorial/](https://fastapi.tiangolo.com/tutorial/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Docker: [https://docs.docker.com/](https://docs.docker.com/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Evidently AI: [https://docs.evidentlyai.com/tutorials-and-examples/examples](https://docs.evidentlyai.com/tutorials-and-examples/examples)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Subscribe for free to get notified when I publish a new article.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@prasadmahamulkar/subscribe?source=post_page-----a5686bfe02b2--------------------------------)
    [## Get an email whenever Prasad Mahamulkar publishes'
  prefs: []
  type: TYPE_NORMAL
- en: Get an email whenever Prasad Mahamulkar publishes Learn about data science,
    machine learning, and more. By signing up…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@prasadmahamulkar/subscribe?source=post_page-----a5686bfe02b2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: You can also find me on [LinkedIn](https://www.linkedin.com/in/prasad-mahamulkar/)
    and [Twitter](https://x.com/prsdm_)!
  prefs: []
  type: TYPE_NORMAL
