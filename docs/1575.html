<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Llama Is Open-Source, But Why?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Llama Is Open-Source, But Why?</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/llama-is-open-source-but-why-3f87d290d0d5?source=collection_archive---------5-----------------------#2024-06-25">https://towardsdatascience.com/llama-is-open-source-but-why-3f87d290d0d5?source=collection_archive---------5-----------------------#2024-06-25</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="dbba" class="fo fp fq bf b dy fr fs ft fu fv fw dx fx" aria-label="kicker paragraph">OPINION</h2><div/><div><h2 id="9469" class="pw-subtitle-paragraph gs fz fq bf b gt gu gv gw gx gy gz ha hb hc hd he hf hg hh cq dx">An analysis of Meta’s open-source large model strategy</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hi hj hk hl hm ab"><div><div class="ab hn"><div><div class="bm" aria-hidden="false"><a href="https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------" rel="noopener follow"><div class="l ho hp by hq hr"><div class="l ed"><img alt="Haifeng Jin" class="l ep by dd de cx" src="../Images/705d6ecaed975b6376fac19087f2c02c.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*RMJMO_yegbLzax5fZyaPBw.png"/><div class="hs by l dd de em n ht eo"/></div></div></a></div></div><div class="hu ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------" rel="noopener follow"><div class="l hv hw by hq hx"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hy cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hs by l br hy em n ht eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hz ab q"><div class="ab q ia"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ib ic bk"><a class="af ag ah ai aj ak al am an ao ap aq ar id" data-testid="authorName" href="https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------" rel="noopener follow">Haifeng Jin</a></p></div></div></div><div class="ie if l"><div class="ab ig"><div class="ab"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewbox="0 0 16 16"><path fill="#437AFF" d="M15.163 8c0 .65-.459 1.144-.863 1.575-.232.244-.471.5-.563.719s-.086.543-.092.875c-.006.606-.018 1.3-.49 1.781-.47.481-1.15.494-1.744.5-.324.006-.655.013-.857.094s-.465.337-.704.575c-.422.412-.906.881-1.542.881-.637 0-1.12-.469-1.543-.881-.239-.238-.49-.482-.704-.575-.214-.094-.532-.088-.857-.094-.593-.006-1.273-.019-1.744-.5s-.484-1.175-.49-1.781c-.006-.332-.012-.669-.092-.875-.08-.207-.33-.475-.563-.719-.404-.431-.863-.925-.863-1.575s.46-1.144.863-1.575c.233-.244.472-.5.563-.719.092-.219.086-.544.092-.875.006-.606.019-1.3.49-1.781s1.15-.494 1.744-.5c.325-.006.655-.012.857-.094.202-.081.465-.337.704-.575C7.188 1.47 7.671 1 8.308 1s1.12.469 1.542.881c.239.238.49.481.704.575s.533.088.857.094c.594.006 1.273.019 1.745.5.47.481.483 1.175.49 1.781.005.331.011.669.091.875s.33.475.563.719c.404.431.863.925.863 1.575"/><path fill="#fff" d="M7.328 10.5c.195 0 .381.08.519.22.137.141.215.331.216.53 0 .066.026.13.072.177a.24.24 0 0 0 .346 0 .25.25 0 0 0 .071-.177c.001-.199.079-.389.216-.53a.73.73 0 0 1 .519-.22h1.959c.13 0 .254-.053.346-.146a.5.5 0 0 0 .143-.354V6a.5.5 0 0 0-.143-.354.49.49 0 0 0-.346-.146h-1.47c-.324 0-.635.132-.865.366-.23.235-.359.552-.359.884v2.5c0 .066-.025.13-.071.177a.24.24 0 0 1-.346 0 .25.25 0 0 1-.072-.177v-2.5c0-.332-.13-.65-.359-.884A1.21 1.21 0 0 0 6.84 5.5h-1.47a.49.49 0 0 0-.346.146A.5.5 0 0 0 4.88 6v4c0 .133.051.26.143.354a.49.49 0 0 0 .347.146z"/></svg></div></div></div><span class="ih ii" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ib ic dx"><button class="ij ik ah ai aj ak al am an ao ap aq ar il im in" disabled="">Follow</button></p></div></div></span></div></div><div class="l io"><span class="bf b bg z dx"><div class="ab cn ip iq ir"><div class="is it ab"><div class="bf b bg z dx ab iu"><span class="iv l io">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar id ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------" rel="noopener follow"><p class="bf b bg z iw ix iy iz ja jb jc jd bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ih ii" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="je jf l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 25, 2024</span></div></span></div></span></div></div></div><div class="ab cp jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv"><div class="h k w ea eb q"><div class="kl l"><div class="ab q km kn"><div class="pw-multi-vote-icon ed iv ko kp kq"><div class=""><div class="kr ks kt ku kv kw kx am ky kz la kq"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l lb lc ld le lf lg lh"><p class="bf b dy z dx"><span class="ks">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kr li lj ab q ee lk ll" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lm"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk"><div class="ln k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lo an ao ap il lp lq lr" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ls cn"><div class="l ae"><div class="ab cb"><div class="lt lu lv lw lx ly ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lo an ao ap il lz ma ll mb mc md me mf s mg mh mi mj mk ml mm u mn mo mp"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lo an ao ap il lz ma ll mb mc md me mf s mg mh mi mj mk ml mm u mn mo mp"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lo an ao ap il lz ma ll mb mc md me mf s mg mh mi mj mk ml mm u mn mo mp"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mt mu mv mw mx my mq mr paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mq mr ms"><img src="../Images/9f9d46a904ceb1062f3aa0c3d67d63d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9pvHGNlM5_X1aThKj3zyqw.jpeg"/></div></div><figcaption class="ne nf ng mq mr nh ni bf b bg z dx">Image by the author using DALL-E</figcaption></figure><p id="930e" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Training a large language model can cost millions of dollars. Why would Meta spend so much money training a model and letting everyone use it for free?</p><p id="33c2" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This article analyzes Meta’s GenAI and large model strategy to understand the considerations of open-sourcing their large models. We also discuss how this wave of open-source models is similar to and different from traditional open-source software.</p><p id="0228" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">DISCLAIMER: Whether the Llama models are genuinely open-source falls outside the scope of this article. All information is from public sources.</p><h2 id="ad53" class="of og fq bf oh oi oj ok ol om on oo op ns oq or os nw ot ou ov oa ow ox oy fw bk">The illusion of proprietary models</h2><p id="f2e6" class="pw-post-body-paragraph nj nk fq nl b gt oz nn no gw pa nq nr ns pb nu nv nw pc ny nz oa pd oc od oe fj bk">If Meta open-sources its models, wouldn’t people just build their own services instead of paying for the service (e.g., the chatbot on <a class="af pe" href="https://www.meta.ai/" rel="noopener ugc nofollow" target="_blank">Meta AI</a>, an API based on Llama, or helping you fine-tune the model and serve it efficiently) provided by Meta?</p><p id="9372" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Preventing people from building their own solutions by keeping the models proprietary is just an illusion. Regardless of whether you open-source your models, others, like <a class="af pe" href="https://docs.mistral.ai/#open-source" rel="noopener ugc nofollow" target="_blank">Mistral AI</a>, <a class="af pe" href="https://github.com/QwenLM/Qwen2" rel="noopener ugc nofollow" target="_blank">Alibaba</a>, and even <a class="af pe" href="https://blog.google/technology/developers/gemma-open-models/" rel="noopener ugc nofollow" target="_blank">Google</a>, open-sourced their models.</p><p id="958c" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">For now, OpenAI, Anthropic, and Google have not open-sourced their largest/best models because they still think they are in a realm that no open-source models can reach regarding capabilities and quality. Open-sourcing their models would hurt their business.</p><p id="747a" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Unless your model is better than any other open-source models by several orders of magnitude, whether you open-source your model wouldn’t affect the quality of the applications the users can build upon open-source models.</p><p id="cb8b" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Your only choices are to be the first and the leader of open-source models or to be a follower by releasing your models later.</p><h2 id="e8ed" class="of og fq bf oh oi oj ok ol om on oo op ns oq or os nw ot ou ov oa ow ox oy fw bk">Why be the leader of open-source models?</h2><p id="2102" class="pw-post-body-paragraph nj nk fq nl b gt oz nn no gw pa nq nr ns pb nu nv nw pc ny nz oa pd oc od oe fj bk">Being the leader of open-source models has many benefits, but the most important is attracting talent.</p><p id="e639" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The war of GenAI is a talent competition bottlenecked by computing power. How much computing power you get largely depends on the cash flow relationship with Nvidia, <a class="af pe" rel="noopener" target="_blank" href="/tpus-are-not-for-sale-but-why-5964f87f7a15">except Google</a>. However, how many talents you have is another story.</p><p id="a4ca" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">According to <a class="af pe" href="https://youtu.be/2BfMuHDfGJI?t=2748" rel="noopener ugc nofollow" target="_blank">Elon Musk</a>, Google had two-thirds of the AI talent, and to counter Google’s power, they founded OpenAI. Then, some of the best people left OpenAI and founded Anthropic to focus on AI safety. So, these three companies have the best and the most AI experts right now in the market. Everyone else is super hungry for more AI experts.</p><p id="e47b" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Being the leader of open-source models would help Meta bridge this gap of AI experts. Open-source models attract talent in two different ways.</p><p id="4634" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, the AI experts want to work for Meta. It is super cool to have the whole world use the model you built. It gives you so much exposure for your work, amplifies your professional impact, and benefits your future career. So, many talented people would like to work for them.</p><p id="b9a0" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Second, the AI experts in the community do the work for Meta for free. Right after the release of Llama, people started to experiment with it. They help you develop new serving technologies to reduce costs, fine-tune your models to discover new applications and scrutinize your model to discover vulnerabilities to make it safer. For example, according to <a class="af pe" href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither" rel="noopener ugc nofollow" target="_blank">this article</a>, they did instruction tuning, quantization, quality improvements, human evals, multimodality, and RLHF for Llama within a month after its initial release. Delegating this work to the community saves Meta huge amounts of computing and human resources.</p><h2 id="5f63" class="of og fq bf oh oi oj ok ol om on oo op ns oq or os nw ot ou ov oa ow ox oy fw bk">Iterate fast with the community.</h2><p id="7d23" class="pw-post-body-paragraph nj nk fq nl b gt oz nn no gw pa nq nr ns pb nu nv nw pc ny nz oa pd oc od oe fj bk">With open-source models, Meta can iterate quickly with the community by directly incorporating their newly developed methods.</p><p id="0cbe" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">How much would it cost Google to adopt a new method from the community? The process consists of two phases: implementation and evaluation. First, they need to reimplement the method for Gemini. This involves rewriting the code in JAX, which requires a fair amount of engineering resources. During the evaluation, they need to run a list of benchmarks on it, which requires a lot of computing power. Most importantly, it takes time. It stopped them from iterating on the latest technologies when they were first available.</p><p id="a672" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Conversely, if Meta wants to adopt a new method from the community, it will cost them nothing. The community has done the experiments and benchmarks on the Llama model directly, so not much further evaluation is needed. The code is written in PyTorch. They can just copy and paste it into their system.</p><p id="380d" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Llama built a flywheel between Meta and the community. Meta brings in the latest technology from the community and rolls out its next-generation model to the community. PyTorch is the common language they speak.</p><h2 id="6a90" class="of og fq bf oh oi oj ok ol om on oo op ns oq or os nw ot ou ov oa ow ox oy fw bk">Can they still make money?</h2><p id="0c54" class="pw-post-body-paragraph nj nk fq nl b gt oz nn no gw pa nq nr ns pb nu nv nw pc ny nz oa pd oc od oe fj bk">The model is open-source. Wouldn’t people just build their own service? Why would they want to pay Meta for a service built on an open-source model? Of course, they will. The service is difficult to build even with an open-source model.</p><p id="9a91" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">How do you fine-tune and align the model to your specific application? How do you balance between the service cost and the model quality? Are you aware of all the tricks to fully utilize your GPUs?</p><p id="cb12" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The people who know the answers to these questions are expensive to hire. Even with enough people, it is hard to get the computing power to fine-tune and serve the model. Imagine how hard it is to build <a class="af pe" href="https://www.meta.ai/" rel="noopener ugc nofollow" target="_blank">Meta AI</a> from the open-source Llama model. I would expect hundreds of employees and GPUs to be involved.</p><p id="711b" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, it is likely that people will still pay for Meta’s GenAI service if they have any in the future.</p><h2 id="6582" class="of og fq bf oh oi oj ok ol om on oo op ns oq or os nw ot ou ov oa ow ox oy fw bk">It’s just like open-source software, but not quite.</h2><p id="f1bd" class="pw-post-body-paragraph nj nk fq nl b gt oz nn no gw pa nq nr ns pb nu nv nw pc ny nz oa pd oc od oe fj bk">The situation is very similar to traditional open-source software. The “<a class="af pe" rel="noopener" target="_blank" href="/tensorflow-is-open-source-but-why-512d849f59d2">free code paid service</a>” framework still applies. The code or the model is free to attract more users to the ecosystem. With a larger ecosystem, the owner collects more benefits. The service built upon the free code is for profit.</p><p id="0cdc" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">However, it is also NOT like open-source software. The main difference can be summarized as low user retention and a new type of ecosystem.</p><h2 id="e104" class="of og fq bf oh oi oj ok ol om on oo op ns oq or os nw ot ou ov oa ow ox oy fw bk">Low user retention</h2><p id="b2d9" class="pw-post-body-paragraph nj nk fq nl b gt oz nn no gw pa nq nr ns pb nu nv nw pc ny nz oa pd oc od oe fj bk">Open-source models have lower user retention. Migrating to a new model is much easier than to new software.</p><p id="942f" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It is hard to migrate software. PyTorch and HuggingFace have established a strong ecosystem for deep learning frameworks and model pools. Imagine how hard it would be to shift their dominance even slightly if you created a new deep learning framework or model pool to compete with them.</p><p id="8488" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">A good example is JAX. It has better support for large-scale distributed training, but it is hard to onboard users to JAX because it has a smaller ecosystem and community. It lacks a helpful community to support users with issues. Moreover, the engineering cost of migrating the entire infra to a new framework is too high for most companies.</p><p id="d318" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Open-source models do not have these problems. They are easy to migrate and require almost no user support. Therefore, it is easy for people to shift to the latest and best models. To maintain your leadership in open-source models, you must constantly release new models at the top of the leaderboard. This is also noted as a downside or challenge to be the leader in open-source models.</p><h2 id="b554" class="of og fq bf oh oi oj ok ol om on oo op ns oq or os nw ot ou ov oa ow ox oy fw bk">A new type of ecosystem</h2><p id="031f" class="pw-post-body-paragraph nj nk fq nl b gt oz nn no gw pa nq nr ns pb nu nv nw pc ny nz oa pd oc od oe fj bk">Open-source models create a new type of ecosystem. Unlike open-source software, which creates ecosystems of contributors and new software built upon them, open-source models create ecosystems of fine-tuned and quantized models, which can be seen as forks of the original model.</p><p id="957d" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">As a result, an open-source foundational model doesn’t have to be super good at every specific task because users would fine-tune it for their applications with domain-specific data. The most important feature of a foundational model is to meet the deployment requirements of the users, such as low latency in inferencing or being small enough to fit an end device.</p><p id="78ce" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This is why Llama has multiple sizes for each version. For example, Llama-3 has three versions: 8B, 70B, and 400B. They want to ensure they cover all deployment scenarios.</p><h2 id="327e" class="of og fq bf oh oi oj ok ol om on oo op ns oq or os nw ot ou ov oa ow ox oy fw bk">Summary</h2><p id="a7d9" class="pw-post-body-paragraph nj nk fq nl b gt oz nn no gw pa nq nr ns pb nu nv nw pc ny nz oa pd oc od oe fj bk">Even if Meta did not open-source their model, others would. So, it would be wise for Meta to open-source it early and lead the open-source models. Then, Meta can iterate quickly with the community to improve its models and catch up with OpenAI and Google.</p><p id="966a" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">When open-sourcing your model, there is no need to worry about people not using your service since there is still a huge gap between the foundational model and a well-built service.</p><p id="1295" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Open-source models are similar to open-source software in that they all follow the “free code paid service” framework but differ in user retention rate and the type of ecosystem they create.</p><p id="b044" class="pw-post-body-paragraph nj nk fq nl b gt nm nn no gw np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In the future, I would expect to see more open-source models from more companies. Unlike the deep learning frameworks converged on PyTorch, open-source models will remain diverse and competitive for a long time.</p></div></div></div></div>    
</body>
</html>