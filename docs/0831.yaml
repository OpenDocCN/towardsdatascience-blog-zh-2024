- en: How to Build a Local Open-Source LLM Chatbot With RAG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-build-a-local-open-source-llm-chatbot-with-rag-f01f73e2a131?source=collection_archive---------1-----------------------#2024-03-31](https://towardsdatascience.com/how-to-build-a-local-open-source-llm-chatbot-with-rag-f01f73e2a131?source=collection_archive---------1-----------------------#2024-03-31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Talking to PDF documents with Google’s Gemma-2b-it, LangChain, and Streamlit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@leoneversberg?source=post_page---byline--f01f73e2a131--------------------------------)[![Dr.
    Leon Eversberg](../Images/56dc3579a29933f7047a9ce60be4697a.png)](https://medium.com/@leoneversberg?source=post_page---byline--f01f73e2a131--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f01f73e2a131--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f01f73e2a131--------------------------------)
    [Dr. Leon Eversberg](https://medium.com/@leoneversberg?source=post_page---byline--f01f73e2a131--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f01f73e2a131--------------------------------)
    ·12 min read·Mar 31, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be316330826a614eb9201a18879fcfd1.png)'
  prefs: []
  type: TYPE_IMG
- en: The LLM chatbot with RAG we will build in this article answers specific questions
    using a washing machine user manual. Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) are remarkable at compressing knowledge about the
    world into their billions of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, LLMs have two major limitations: They only have up-to-date knowledge
    up to the time of the last training iteration. And they sometimes tend to make
    up knowledge (hallucinate) when asked specific questions.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the RAG technique, we can give pre-trained LLMs access to very specific
    information as additional context when answering our questions.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will walk through the theory and practice of implementing
    Google’s LLM Gemma with additional RAG capabilities using the Hugging Face transformers
    library, LangChain, and the Faiss vector database.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of the RAG pipeline is shown in the figure below, which we will
    implement step by step.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd04d3634055266566928f252271a642.png)'
  prefs: []
  type: TYPE_IMG
- en: Overview of the RAG pipeline implementation. Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval-Augmented Generation (RAG)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
