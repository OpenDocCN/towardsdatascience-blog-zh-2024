- en: 'No GPU, No Party : Fine-Tune BERT for Sentiment Analysis with Vertex AI Custom
    jobs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 没有GPU，没派对：使用Vertex AI自定义作业微调BERT进行情感分析
- en: 原文：[https://towardsdatascience.com/no-gpu-no-party-fine-tune-bert-for-sentiment-analysis-with-vertex-ai-custom-jobs-d8fc410e908b?source=collection_archive---------5-----------------------#2024-06-03](https://towardsdatascience.com/no-gpu-no-party-fine-tune-bert-for-sentiment-analysis-with-vertex-ai-custom-jobs-d8fc410e908b?source=collection_archive---------5-----------------------#2024-06-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/no-gpu-no-party-fine-tune-bert-for-sentiment-analysis-with-vertex-ai-custom-jobs-d8fc410e908b?source=collection_archive---------5-----------------------#2024-06-03](https://towardsdatascience.com/no-gpu-no-party-fine-tune-bert-for-sentiment-analysis-with-vertex-ai-custom-jobs-d8fc410e908b?source=collection_archive---------5-----------------------#2024-06-03)
- en: Speed up the training process with serverless jobs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过无服务器作业加速训练过程
- en: '[](https://medium.com/@benjamin_47408?source=post_page---byline--d8fc410e908b--------------------------------)[![Benjamin
    Etienne](../Images/cad8bc2d4b900575e76b7cf9debc9eea.png)](https://medium.com/@benjamin_47408?source=post_page---byline--d8fc410e908b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d8fc410e908b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d8fc410e908b--------------------------------)
    [Benjamin Etienne](https://medium.com/@benjamin_47408?source=post_page---byline--d8fc410e908b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@benjamin_47408?source=post_page---byline--d8fc410e908b--------------------------------)[![Benjamin
    Etienne](../Images/cad8bc2d4b900575e76b7cf9debc9eea.png)](https://medium.com/@benjamin_47408?source=post_page---byline--d8fc410e908b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d8fc410e908b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d8fc410e908b--------------------------------)
    [Benjamin Etienne](https://medium.com/@benjamin_47408?source=post_page---byline--d8fc410e908b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d8fc410e908b--------------------------------)
    ·13 min read·Jun 3, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d8fc410e908b--------------------------------)
    ·13分钟阅读·2024年6月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/de04296aee8fcd10eae449ceb2f6d4ce.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de04296aee8fcd10eae449ceb2f6d4ce.png)'
- en: Photo by [yns plt](https://unsplash.com/@ynsplt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[yns plt](https://unsplash.com/@ynsplt?utm_source=medium&utm_medium=referral)于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '*TL;DR: How to launch a training job with Pytorch with GPUs on Vertex. Code
    with examples.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*TL;DR：如何在Vertex上使用GPU启动Pytorch训练作业。包含示例代码。*'
- en: 'In my [previous article](/machine-learning-on-gcp-from-dev-to-prod-with-vertex-ai-c9e42c4b366f),
    I mentioned the fact that training locally huge models is not always a good practice
    when you have limited resources. Sometimes you just don’t have a choice, but sometimes
    you have at your disposal a Cloud provider such as Google Cloud Platform which
    can significantly speed up your trainings by:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我[之前的文章](/machine-learning-on-gcp-from-dev-to-prod-with-vertex-ai-c9e42c4b366f)中，我提到过，当本地训练大规模模型时，如果资源有限，这并不是一个好习惯。有时候你根本没有选择，但有时候，你可以使用像
    Google Cloud Platform 这样的云服务提供商，它能够显著加速你的训练过程，方法如下：
- en: Providing you cutting-edge machines with custom configurations (memory, GPUs,
    etc.)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供您定制配置（内存、GPU 等）的先进机器
- en: Allowing you to launch several jobs simultaneously and choose the best model
    in the end
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许您同时启动多个作业，并最终选择最佳模型
- en: '*Not to mention that offloading the training to the cloud will relieve your
    personal machine. I already saw the battery melt after leaving my personal laptop
    train a model for 1 week. Back from holidays, my touchpad was literally popping
    out.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*更不用说，将训练任务卸载到云端将减轻您个人机器的负担。我已经亲眼看到，个人笔记本电脑训练模型一周后电池几乎融化。假期回来后，我的触控板居然快要掉出来了。*'
- en: '**In this article, we will take a concrete use case where we will fine-tune
    a BERT model on social media comments to perform sentiment analysis. As we will
    see, training this kind of model on a CPU is very cumbersome and not optimal.
    We will therefore see how we can leverage Google Cloud Platform to speed up the
    process by using a GPU for only 60 cents.**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**在本文中，我们将以一个具体的用例为例，展示如何在社交媒体评论上微调BERT模型进行情感分析。正如我们所看到的，使用CPU训练这种模型是非常繁琐且不理想的。因此，我们将探讨如何利用Google
    Cloud Platform通过仅花费60美分来加速这一过程，使用GPU进行训练。**'
- en: Summary
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: What is BERT
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是BERT
- en: What is Sentiment Analysis
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是情感分析
- en: Get and prepare the data
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取并准备数据
- en: Use a small BERT pretrained model
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用小型BERT预训练模型
- en: Create the dataloaders
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建数据加载器。
- en: Write the main script to train the model
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写主要脚本以训练模型。
- en: Dockerize the script
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将脚本Docker化。
- en: Build and push an image to Google Cloud
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建并推送镜像到Google Cloud。
- en: Create a job on Vertex AI
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Vertex AI上创建一个作业。
- en: What is BERT ?
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是BERT？
- en: BERT stands for Bidirectional Encoder Representations from Transformers and
    was open-sourced by Google in 2018\. It is mainly used for NLP tasks as it was
    trained to capture semantics in sentences and provide rich word embeddings (representations).
    The difference with other models such as Word2Vec and Glove lies in the fact that
    it uses Transformers to process text. Transformers (refer to my previous article
    if you want to know more) are a family of neural networks which, a little bit
    like RNNs, have the ability to process sequences in both directions, therefore
    able to capture context around a word for example.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: BERT代表双向编码器表示（Bidirectional Encoder Representations from Transformers），由Google于2018年开源。它主要用于NLP任务，因为它被训练用来捕捉句子的语义并提供丰富的词向量（表示）。与其他模型如Word2Vec和Glove的不同之处在于，它使用Transformers来处理文本。Transformers（如果你想了解更多，可以参考我之前的文章）是一类神经网络，它们有点像RNN，可以双向处理序列，因此能够捕捉到例如一个词的上下文。
- en: What is Sentiment Analysis ?
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是情感分析？
- en: Sentiment Analysis is a specific task within the NLP domain which objective
    is to classify text into categories related to the tonality of it. Tonality is
    often expressed as *positive*, *negative*, or *neutral*. It is very commonly used
    to analyze verbatims, posts on social media, product reviews, etc.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析是NLP领域中的一项特定任务，目标是将文本分类为与其情感色彩相关的类别。情感色彩通常表现为*积极*、*消极*或*中立*。它通常用于分析文字记录、社交媒体上的帖子、产品评论等。
- en: Fine-tuning a BERT model on social media data
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在社交媒体数据上微调BERT模型。
- en: Getting and preparing the data
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取和准备数据。
- en: 'The dataset we will use comes from Kaggle, you can download it here : [https://www.kaggle.com/datasets/farisdurrani/sentimentsearch](https://www.kaggle.com/datasets/farisdurrani/sentimentsearch)
    (CC BY 4.0 License). In my experiments, I only chose the datasets from Facebook
    and Twitter.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的数据集来自Kaggle，你可以在这里下载：[https://www.kaggle.com/datasets/farisdurrani/sentimentsearch](https://www.kaggle.com/datasets/farisdurrani/sentimentsearch)（CC
    BY 4.0许可证）。在我的实验中，我只选择了来自Facebook和Twitter的数据集。
- en: The following snippet will take the csv files and save 3 splits (training, validation,
    and test) to where you want. I recommend saving them in Google Cloud Storage.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段将处理csv文件，并将数据分割为3部分（训练集、验证集和测试集），然后保存到你指定的位置。我建议将它们保存在Google Cloud Storage中。
- en: 'You can run the script with:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令运行脚本：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The data should look roughly like this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据大致应如下所示：
- en: '![](../Images/bd678c8886d35aadd886a31d031ad2ed.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd678c8886d35aadd886a31d031ad2ed.png)'
- en: (image from author)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: （作者提供的图片）
- en: Using a small BERT pretrained model
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用小型BERT预训练模型。
- en: For our model, we will use a lightweight BERT model, BERT-Tiny. This model has
    already been pretrained on vasts amount of data, but not necessarily with social
    media data and not necessarily with the objective of doing Sentiment Analysis.
    This is why we will fine-tune it.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的模型，我们将使用轻量级BERT模型BERT-Tiny。该模型已经在大量数据上进行了预训练，但不一定是社交媒体数据，也不一定是为了进行情感分析而预训练的。因此，我们将对其进行微调。
- en: It contains only 2 layers with a 128-units dimension, the full list of models
    can be seen [here](https://github.com/google-research/bert) if you want to take
    a larger one.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 它仅包含2层，每层有128个单元，完整的模型列表可以在[这里](https://github.com/google-research/bert)查看，如果你想使用更大的模型。
- en: 'Let’s first create a `main.py` file, with all necessary modules:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们创建一个`main.py`文件，包含所有必要的模块：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s also write down our requirements in a dedicated `requirements.txt`
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也在一个专用的`requirements.txt`文件中写下我们的需求。
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will now load 2 parts to train our model:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将加载两部分数据来训练我们的模型：
- en: The ***tokenizer***, which will take care of splitting the text inputs into
    tokens that BERT has been trained with.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***分词器***，它将负责将文本输入拆分为BERT训练时使用的词元。'
- en: The ***model*** itself.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***模型***本身。'
- en: 'You can obtain both from Huggingface [here](http://google/bert_uncased_L-2_H-128_A-2).
    You can also download them to Cloud Storage. That is what I did, and will therefore
    load them with:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从Huggingface[这里](http://google/bert_uncased_L-2_H-128_A-2)获得这两者。你也可以将它们下载到Cloud
    Storage中。我就是这么做的，因此会通过以下方式加载它们：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s now add the following piece to our file:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将以下内容添加到文件中：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: A little break here. We have several options when it comes to reusing an existing
    model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里稍作休息。我们在重用现有模型时有几种选择。
- en: '**Transfer learning** : we freeze the weights of the model and use it as a
    “feature extractor”. We can therefore append additional layers downstream. This
    is frequently used in Computer Vision where models like VGG, Xception, etc. can
    be reused to train a custom model on small datasets'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迁移学习**：我们冻结模型的权重，并将其作为“特征提取器”。因此，我们可以在后续添加额外的层。这在计算机视觉中非常常见，比如VGG、Xception等模型可以在小数据集上被重新训练，作为自定义模型的一部分。'
- en: '**Fine-tuning** : we unfreeze all or part of the weights of the model and retrain
    the model on a custom dataset. This is the preferred approach when training custom
    LLMs.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调**：我们解冻模型的全部或部分权重，并在自定义数据集上重新训练模型。这是在训练自定义LLM时的首选方法。'
- en: 'More details on Transfer learning and Fine-tuning [here](https://www.tensorflow.org/tutorials/images/transfer_learning):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 关于迁移学习和微调的更多细节，请参见[这里](https://www.tensorflow.org/tutorials/images/transfer_learning)：
- en: In the model, we have chosen to unfreeze all the model, but feel free to freeze
    one or more layers of the pretrained BERT module and see how it influences the
    performance.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型中，我们选择解冻整个模型，但也可以选择冻结预训练BERT模块中的一层或多层，看看它对性能的影响。
- en: The key part here is to add a fully connected layer after the BERT module to
    “link” it to our classification task, hence the final layer with 3 units. This
    will allow us to reuse the pretrained BERT weights and adapt our model to our
    task.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键是，在BERT模块后添加一个全连接层，将其“连接”到我们的分类任务，因此最终的层有3个单元。这将使我们能够重用预训练BERT的权重，并将我们的模型调整到我们的任务。
- en: Creating the dataloaders
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建数据加载器
- en: 'To create the dataloaders we will need the Tokenizer loaded above. The Tokenizer
    takes a string as input, and returns several outputs amongst which we can find
    the tokens (‘input_ids’ in our case):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建数据加载器，我们将需要上述加载的Tokenizer。Tokenizer接受一个字符串作为输入，并返回多个输出，其中包括我们可以找到的标记（在我们的案例中是‘input_ids’）：
- en: '![](../Images/894b0cbe3aec033e162d3be5ca1ddc3d.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/894b0cbe3aec033e162d3be5ca1ddc3d.png)'
- en: 'The BERT tokenizer is a bit special and will return several outputs, but the
    most important one is the `input_ids`: they are the tokens used to encode our
    sentence. They might be words, or parts or words. For example, the word “looking”
    might be made of 2 tokens, “look” and “##ing”.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: BERT的分词器有点特殊，它会返回多个输出，但最重要的是`input_ids`：它们是用于编码我们句子的标记。它们可能是单词，或者单词的一部分。例如，单词“looking”可能由两个标记组成：“look”和“##ing”。
- en: 'Let’s now create a dataloader module which will handle our datasets :'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建一个数据加载器模块来处理我们的数据集：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Writing the main script to train the model
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写训练模型的主脚本
- en: 'Let us define first and foremost two functions to handle the training and evaluation
    steps:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义两个函数来处理训练和评估步骤：
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We are getting closer to getting our main script up and running. Let’s stitch
    pieces together. We have:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们离让主脚本运行起来越来越近了。让我们将各个部分拼接在一起。我们有：
- en: A `BertDataset` class to handle the loading of the data
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`BertDataset`类，用于处理数据的加载
- en: A `SentimentBERT` model which takes our Tiny-BERT model and adds an additional
    layer for our custom use case
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`SentimentBERT`模型，它基于我们的Tiny-BERT模型并添加了一个额外的层来适应我们的自定义用例
- en: '`train()` and `eval()` functions to handle those steps'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train()`和`eval()`函数，用于处理这些步骤'
- en: A `train_and_eval()` functions that bundles everything
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`train_and_eval()`函数，将所有内容组合在一起
- en: We will use `argparse` to be able to launch our script with arguments. Such
    arguments are typically the train/eval/test files to run our model with any datasets,
    the path where our model will be stored, and parameters related to the training.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`argparse`来使我们能够通过参数启动脚本。这些参数通常是训练/评估/测试文件，用于将数据集传递给我们的模型，模型存储路径以及与训练相关的参数。
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This is great, but unfortunately, this model will take a long time to train.
    Indeed, with around 4.7M parameters to train, one step will take around 3s on
    a 16Gb Macbook Pro with Intel chip.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但不幸的是，这个模型需要很长时间才能训练完成。实际上，训练约470万参数时，每一步大约需要3秒，在一台配备Intel芯片、16GB内存的MacBook
    Pro上进行训练。
- en: '![](../Images/b5a00cef328f5d4ab3879f010a18ff24.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5a00cef328f5d4ab3879f010a18ff24.png)'
- en: 3s per step can be quite long when you have 1238 steps to go and 10 epochs to
    complete…
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 每步3秒，对于1238步和10个epoch的训练来说，可能是相当长的时间…
- en: No GPU, no party.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 没有GPU，就没有派对。
- en: How to use Vertex AI and start the party?
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用Vertex AI并启动派对？
- en: '*Short answer : Docker and gcloud.*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*简短回答：Docker和gcloud。*'
- en: 'If you do not have a powerful GPU on your laptop (as most of us do), and/or
    want to avoid burning your laptop’s cooling fan, you may want to move your script
    on a Cloud platform such as Google Cloud (disclaimer: I use Google Cloud at my
    job).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的笔记本电脑没有强大的 GPU（就像我们大多数人一样），和/或您不想烧坏笔记本电脑的散热风扇，您可能希望将脚本移至 Google Cloud 等云平台（免责声明：我在工作中使用
    Google Cloud）。
- en: The nice thing about Google is it offers 300$ in credits when you open your
    own project with your Gmail account.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Google 的一个优点是，当您使用 Gmail 账户创建自己的项目时，会提供 300 美元的信用额度。
- en: And as always, when it comes to transferring your code to somewhere else, Docker
    is usually the go-to solution.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，当需要将代码转移到其他地方时，Docker 通常是首选解决方案。
- en: Dockerizing the script
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将脚本 Docker 化
- en: Let’s write a Docker image with GPU enabled. There are a lot of Docker images
    you can find on the official Docker repository, I chose the *pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime*
    as I use a Pytorch 2.2.2 version. Be sure to select a version with CUDA, otherwise
    you will have to install it yourself in your Dockerfile, and trust me, you don’t
    want to do that, except if you really have to.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个启用了 GPU 的 Docker 镜像。您可以在官方 Docker 仓库中找到许多 Docker 镜像，我选择了 *pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime*，因为我使用的是
    Pytorch 2.2.2 版本。请确保选择一个带有 CUDA 的版本，否则您将需要在 Dockerfile 中自己安装它，相信我，除非必须，否则您不希望这样做。
- en: This Dockerfile will preinstall necessary CUDA dependencies and drivers and
    ensure we can use them in a custom training job, and run your python `main.py`
    file with the arguments that you will pass once you call the image.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Dockerfile 会预安装必要的 CUDA 依赖和驱动程序，确保我们能够在自定义训练作业中使用它们，并在调用镜像时，使用您传递的参数运行 Python
    `main.py` 文件。
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Building and pushing an image to Google Cloud
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Google Cloud 上构建并推送镜像
- en: Once our image is ready to be built, we need to build it and push it to a registry.
    It can be on any registry you like, but Google Cloud offers a service for that
    called Artefact Registry. You will therefore be able to store your images on Google
    Cloud very easily.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的镜像准备好构建，我们需要构建它并将其推送到一个注册表。您可以选择任何注册表，但 Google Cloud 提供了一个名为 Artefact Registry
    的服务。因此，您将能够非常轻松地将镜像存储在 Google Cloud 上。
- en: 'Write this little file at the root of your directory, and be sure that the
    Dockerfile is at the same level:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的目录根目录下创建这个小文件，并确保 Dockerfile 文件与其在同一级别：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Run the `build.sh` file, and after waiting a couple of minutes for the image
    to build, you should see something like:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `build.sh` 文件，等待几分钟镜像构建完成后，您应该会看到类似的内容：
- en: '**eu.gcr.io/<your-project-id>/pt_bert_sentiment:dev SUCCESS**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**eu.gcr.io/<your-project-id>/pt_bert_sentiment:dev SUCCESS**'
- en: Creating a job on Vertex AI
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Vertex AI 上创建作业
- en: Once your image has been built and pushed to Artefact Registry, we will now
    be able to tell Vertex AI to run this image on any machine we want, including
    ones with powerful GPUs ! Google offers a $300 credit when you create your own
    GCP project, it will be largely sufficient to run our model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的镜像构建并推送到 Artefact Registry，我们就可以告诉 Vertex AI 在我们想要的任何机器上运行这个镜像，包括带有强大 GPU
    的机器！Google 在您创建自己的 GCP 项目时会提供 300 美元的信用额度，这对于运行我们的模型是非常足够的。
- en: Costs are available [here](https://cloud.google.com/vertex-ai/pricing#custom-trained_models).
    In our case, we will take the *n1-standard-4* machine at $0.24/hr, and attach
    a *NVIDIA T4* GPU at $0.40/hr.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 费用详情请见 [这里](https://cloud.google.com/vertex-ai/pricing#custom-trained_models)。在我们的案例中，我们将选择每小时
    0.24 美元的 *n1-standard-4* 机器，并附加每小时 0.40 美元的 *NVIDIA T4* GPU。
- en: '![](../Images/8405cc80d311c01147fa5b3ed826a415.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8405cc80d311c01147fa5b3ed826a415.png)'
- en: '(source : Google Cloud)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: （来源：Google Cloud）
- en: '![](../Images/0cd5fc0930e342b345abb1060e0593f1.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cd5fc0930e342b345abb1060e0593f1.png)'
- en: '(source : Google Cloud)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: （来源：Google Cloud）
- en: Create a `job.sh` file as follows, by specifying which region you are in and
    what kind of machine you use. Refer to the link above if you are in a different
    region as costs may vary.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 `job.sh` 文件，内容如下，指定您所在的地区和使用的机器类型。如果您在其他地区，费用可能会有所不同，请参考上面的链接。
- en: 'You’ll also need to pass arguments to your training script. The syntax for
    the `gcloud ai custom-jobs create` consists of 2 parts:'
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 您还需要传递参数给您的训练脚本。`gcloud ai custom-jobs create` 的语法由两部分组成：
- en: ''
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- the arguments related to the job itself : `--region` , `--display-name` ,
    `--worker-pool-spec` , `--service-account` , and `--args`'
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '- 与作业本身相关的参数：`--region`、`--display-name`、`--worker-pool-spec`、`--service-account`
    和 `--args`'
- en: ''
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- the arguments related to the training : `--training-file` , `--epochs` ,
    etc.'
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '- 与训练相关的参数：`--training-file`、`--epochs` 等。'
- en: ''
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The latter needs to be preceded by the `--args` to indicate that all following
    arguments are related to the training Python script.
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 后者需要以`--args`开头，表示所有后续的参数都与训练 Python 脚本相关。
- en: ''
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Ex: supposing our script takes 2 arguments x and y, we would have:'
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如：假设我们的脚本有 2 个参数 x 和 y，我们可以这样写：
- en: '`--args=x=1,y=2`'
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`--args=x=1,y=2`'
- en: '[PRE11]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Running the job on Vertex AI
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Vertex AI 上运行任务
- en: Launch the script, and navigate to your GCP project, in the Training section
    under the Vertex menu .
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 启动脚本并进入你的 GCP 项目，在 Vertex 菜单下的“训练”部分。
- en: '![](../Images/d622336b28fc8d7f5f60fbb0431498ca.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d622336b28fc8d7f5f60fbb0431498ca.png)'
- en: (image from author)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: （图片来自作者）
- en: Launch the script, and navigate to the console. You should see the job status
    as “Pending”, and then “Training”.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 启动脚本并进入控制台。你应该会看到任务状态为“等待中”，然后是“训练中”。
- en: 'To ensure the GPU is being used, you can check the job and its ressources :'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保正在使用 GPU，你可以检查任务及其资源：
- en: '![](../Images/4f18577283659330ba871d2d88baf21b.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f18577283659330ba871d2d88baf21b.png)'
- en: (image from author)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: （图片来自作者）
- en: 'This indicates that we are training with a GPU, we should therefore expect
    a significant speed-up now ! Let’s have a look at the logs:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们正在使用 GPU 进行训练，因此现在应该能够显著加速！让我们来看一下日志：
- en: '![](../Images/959225237e7b4fa03ac158ba31a68e23.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/959225237e7b4fa03ac158ba31a68e23.png)'
- en: Less than 10 minutes to run 1 epoch, vs 1hr/epoch on CPU ! We have offloaded
    the training to Vertex and accelerated the training process. We could decide to
    launch other jobs with different configurations, without overloading our laptop’s
    capabilities.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 1 个周期不到 10 分钟，而在 CPU 上需要 1 小时/周期！我们已经将训练任务转移到 Vertex，并加速了训练过程。我们可以选择启动其他配置不同的任务，而不会超载我们笔记本的能力。
- en: What about the final accuracy of the model ? Well after 10 epochs, it is around
    94–95%. We could let it run even longer and see if the score improves (we can
    also add an early stopping callback to avoid overfitting)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 那么模型的最终准确率如何呢？在经过 10 个周期后，它大约为 94% 到 95%。我们可以让它继续运行更长时间，看看分数是否提高（我们还可以添加早停回调来避免过拟合）
- en: '![](../Images/40b37ce0f0bb8c48db7b04e1152a1ef2.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40b37ce0f0bb8c48db7b04e1152a1ef2.png)'
- en: How does our model perform ?
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的模型表现如何？
- en: '![](../Images/b3808a8189226c3c73eacc46470f071c.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3808a8189226c3c73eacc46470f071c.png)'
- en: (image from author)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: （图片来自作者）
- en: Time to party !
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 到派对时间了！
