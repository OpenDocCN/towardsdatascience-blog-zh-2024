- en: Benchmarking Pytest with CICD Using GitHub Action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/benchmarking-pytest-with-cicd-using-github-action-17af32b4a30b?source=collection_archive---------12-----------------------#2024-03-05](https://towardsdatascience.com/benchmarking-pytest-with-cicd-using-github-action-17af32b4a30b?source=collection_archive---------12-----------------------#2024-03-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Making Pytest benchmark automated, actionable, and intuitive
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://kayjanwong.medium.com/?source=post_page---byline--17af32b4a30b--------------------------------)[![Kay
    Jan Wong](../Images/28e803eca6327d97b6aa97ee4095d7bd.png)](https://kayjanwong.medium.com/?source=post_page---byline--17af32b4a30b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--17af32b4a30b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--17af32b4a30b--------------------------------)
    [Kay Jan Wong](https://kayjanwong.medium.com/?source=post_page---byline--17af32b4a30b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--17af32b4a30b--------------------------------)
    ·7 min read·Mar 5, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/91d1029fc1a185f52d71c7f6b3f2c6ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Lucas Santos](https://unsplash.com/@_staticvoid?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: “Your code is slow” is something that is easily said, but it would take a lot
    of trial and error and testing to find out which part of the code is slow, and
    how slow is *slow*? Once the bottleneck of the code is found, does it scale well
    with an input that is 100 times or 1000 times larger, with results averaged across
    10 iterations?
  prefs: []
  type: TYPE_NORMAL
- en: This is where pytest-benchmark comes in handy
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Complementing the idea of unit testing, which is to test a single unit or small
    part of the codebase, we can expand on this and measure code performance easily
    with `pytest-benchmark`.
  prefs: []
  type: TYPE_NORMAL
- en: This article will touch on how to set up, run, and interpret the benchmark timing
    results of `pytest-benchmark`. To properly enforce benchmarking in a project,
    the advanced sections also touch on how to **compare benchmark timing results
    across runs** and reject commits if they fail certain thresholds, and how to **store
    and view historical benchmark timing results** in a box plot and line chart!
  prefs: []
  type: TYPE_NORMAL
