- en: Data Disruptions to Elevate Entity Embeddings
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据破坏以提升实体嵌入
- en: 原文：[https://towardsdatascience.com/data-disruptions-to-elevate-entity-embeddings-b1ddf86a3c95?source=collection_archive---------7-----------------------#2024-06-04](https://towardsdatascience.com/data-disruptions-to-elevate-entity-embeddings-b1ddf86a3c95?source=collection_archive---------7-----------------------#2024-06-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/data-disruptions-to-elevate-entity-embeddings-b1ddf86a3c95?source=collection_archive---------7-----------------------#2024-06-04](https://towardsdatascience.com/data-disruptions-to-elevate-entity-embeddings-b1ddf86a3c95?source=collection_archive---------7-----------------------#2024-06-04)
- en: Injecting random values during neural network training can help you get more
    from your categoricals
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在神经网络训练过程中注入随机值可以帮助你从类别特征中获得更多信息。
- en: '[](https://medium.com/@vla6?source=post_page---byline--b1ddf86a3c95--------------------------------)[![Valerie
    Carey](../Images/9ef394fe5a6a5439521c1905e0195751.png)](https://medium.com/@vla6?source=post_page---byline--b1ddf86a3c95--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b1ddf86a3c95--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b1ddf86a3c95--------------------------------)
    [Valerie Carey](https://medium.com/@vla6?source=post_page---byline--b1ddf86a3c95--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vla6?source=post_page---byline--b1ddf86a3c95--------------------------------)[![Valerie
    Carey](../Images/9ef394fe5a6a5439521c1905e0195751.png)](https://medium.com/@vla6?source=post_page---byline--b1ddf86a3c95--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b1ddf86a3c95--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b1ddf86a3c95--------------------------------)
    [Valerie Carey](https://medium.com/@vla6?source=post_page---byline--b1ddf86a3c95--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b1ddf86a3c95--------------------------------)
    ·11 min read·Jun 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b1ddf86a3c95--------------------------------)
    ·阅读时长 11 分钟·2024年6月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/65a2fea5cd298a5eeaefac2afe531fcc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65a2fea5cd298a5eeaefac2afe531fcc.png)'
- en: Photo by [dylan nolte](https://unsplash.com/@dylan_nolte?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[dylan nolte](https://unsplash.com/@dylan_nolte?utm_source=medium&utm_medium=referral)
    于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Today I will discuss a **stochastic regularization** method to improve generalizability
    of entity embeddings in neural network models. I use a data generator to randomly
    inject selected input values into data during training, to help a model learn
    how to deal with unseen codes.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我将讨论一种**随机正则化**方法，旨在提高神经网络模型中实体嵌入的泛化能力。我使用数据生成器在训练过程中随机注入选定的输入值，帮助模型学习如何处理未见过的代码。
- en: '**Performance improvements are especially dramatic for hierarchical categorical
    features.** Randomization helps models leverage higher-level group information
    to compensate for unseen lower-level codes.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于层次类别特征，性能提升尤其显著。** 随机化有助于模型利用更高级别的组信息来弥补未见过的低级别代码。'
- en: Adding noise, removing information, or otherwise messing with data, is often
    used to increase model robustness and reduce overfitting [1,2]. Here, it’s used
    to help a model learn what to do with missing categorical information. I examine
    one public test dataset, comparing unmodified data with randomization done two
    ways.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 添加噪声、移除信息或以其他方式破坏数据，通常用于提高模型的鲁棒性并减少过拟合[1,2]。在这里，它被用来帮助模型学习如何处理缺失的类别信息。我将检查一个公共测试数据集，比较未修改数据与以两种方式进行随机化的数据。
- en: When unseen codes matter, randomly injecting vales helps a model generalize.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当未见过的代码起作用时，随机注入值有助于模型进行泛化。
- en: Using a data generator to shuffles random values so each mini-batch sees different
    scenarios performs better than static data modification.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据生成器随机打乱值，这样每个小批量都看到不同的场景，效果优于静态数据修改。
- en: A caveat is that overfitting can occur when a coding hierarchy is unrelated
    to…
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个警告是，当编码层次结构与实际情况无关时，可能会发生过拟合...
