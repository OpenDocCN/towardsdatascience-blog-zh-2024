<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Reranking Using Huggingface Transformers for Optimizing Retrieval in RAG Pipelines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Reranking Using Huggingface Transformers for Optimizing Retrieval in RAG Pipelines</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reranking-using-huggingface-transformers-for-optimizing-retrieval-in-rag-pipelines-fbfc6288c91f?source=collection_archive---------5-----------------------#2024-11-08">https://towardsdatascience.com/reranking-using-huggingface-transformers-for-optimizing-retrieval-in-rag-pipelines-fbfc6288c91f?source=collection_archive---------5-----------------------#2024-11-08</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="1bde" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Understanding when reranking makes a difference</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@daniel-klitzke?source=post_page---byline--fbfc6288c91f--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Daniel Klitzke" class="l ep by dd de cx" src="../Images/4471634e1a0f0546402d582dcc36c7c4.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*Lx-ErwMknkXr0fxAEaHJ2A.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--fbfc6288c91f--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@daniel-klitzke?source=post_page---byline--fbfc6288c91f--------------------------------" rel="noopener follow">Daniel Klitzke</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--fbfc6288c91f--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 8, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/359bc87027b4ad46eb508e67dcf91b20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cS58svREtLPTwlfQpX4d0Q.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Visualization of the reranking results for the user query “What is rigid motion?”. Original ranks on the left, new ranks on the right. (image create by author)</figcaption></figure><p id="17a2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In this article I will show you how you can use the <a class="af nx" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank"><strong class="nd fr">Huggingface Transformers</strong></a> and <a class="af nx" href="https://github.com/UKPLab/sentence-transformers" rel="noopener ugc nofollow" target="_blank"><strong class="nd fr">Sentence Transformers</strong></a> libraries to boost you RAG pipelines using <strong class="nd fr">reranking</strong> models. Concretely we will do the following:</p><ol class=""><li id="b445" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">Establish a <strong class="nd fr">baseline</strong> with a simple vanilla RAG pipeline.</li><li id="a782" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Integrate a simple <strong class="nd fr">reranking model</strong> using the Huggingface Transformers library.</li><li id="066c" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Evaluate in which cases the <strong class="nd fr">reranking model</strong> is significantly improving context quality to gain a better understanding on the benefits.</li></ol><p id="f177" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For all of this, I will link to the corresponding code on <a class="af nx" href="https://github.com/Renumics/reranking-blogpost/blob/main/reranker_test.ipynb" rel="noopener ugc nofollow" target="_blank">Github</a>.</p><h1 id="81ba" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">What is Reranking?</h1><p id="cf2e" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">Before we dive right into our evaluation I want to say few words on <strong class="nd fr">what rerankers are</strong>. Rerankers are usually applied as follows:</p><ol class=""><li id="9923" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">A simple embedding-based retrieval approach is used to retrieve an <strong class="nd fr">initial set of candidates</strong> in the retrieval step of a RAG pipeline.</li><li id="334b" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">A Reranker is used to <strong class="nd fr">reorder the results</strong> to provide a new result order that betters suits the user queries.</li></ol><p id="3456" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">But why should the reranker model yield something different than my already quite powerful embedding model, and why do I not leverage the semantic understanding of a reranker in an earlier stage you may ask yourself? This is quite multi-faceted but some key points are that e.g. the bge-reranker we use here is inherently <strong class="nd fr">processing queries and documents together</strong> in a cross-encoding approach and can thus explicitely model query-document interactions. Another major difference is that the reranking model is <strong class="nd fr">trained in a supervised manner</strong> on predicting <strong class="nd fr">relevance scores</strong> that are obtained through human annotation. What that means in practice will also be shown in the evaluation section later-on.</p><h1 id="063a" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Our Baseline</h1><p id="996c" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">For our baseline we choose the simplest possible RAG pipeline possible and focus solely on the retrieval part. Concretely, we:</p><ol class=""><li id="ae16" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">Choose one large PDF document. I went for my Master’s Thesis, but you can choose what ever you like.</li><li id="3c61" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Extract the text from the PDF and split it into equal chunks of about 10 sentences each.</li><li id="b94d" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Create embedding for our chunks and insert them in a vector database, in this case LanceDB.</li></ol><blockquote class="ph pi pj"><p id="4bff" class="nb nc pk nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="fq">For details, about this part, check our the notebook on </em><a class="af nx" href="https://github.com/Renumics/reranking-blogpost/blob/main/reranker_test.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="fq">Github</em></a><em class="fq">.</em></p></blockquote><p id="a1bb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">After following this, a simple <strong class="nd fr">semantic search</strong> would be possible in two lines of code, namely:</p><pre class="ml mm mn mo mp pl pm pn bp po bb bk"><span id="0019" class="pp oh fq pm b bg pq pr l ps pt">query_embedding = model.encode([query])[0]<br/>results = table.search(query_embedding).limit(INITIAL_RESULTS).to_pandas()</span></pre><p id="6092" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Here query would be the query provided by the user, e.g., the question “What is shape completion about?”. Limit, in this case, is the number of results to retrieve. In a normal RAG pipeline, the retrieved results would now just be directly be provided as <strong class="nd fr">context to the LLM</strong> that will synthesize the answer. In many cases, this is also perfectly valid, however for this post we want to explore the benefits of reranking.</p><h1 id="580c" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Implementing Reranking</h1><p id="9708" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">With libraries such as <a class="af nx" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">Huggingface Transformers</a>, using <strong class="nd fr">reranker models</strong> is a piece of cake. To use reranking to improve our “RAG pipeline” we extend our approach as follows:</p><ol class=""><li id="96a6" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">As previously, simply retrieve an <strong class="nd fr">initial number of results</strong> through a standard embedding model. However we increase the count of the results from 10 to around 50.</li><li id="9b1f" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">After retrieving this larger number of initial sources, we apply a reranker model to <strong class="nd fr">reorder the sources</strong>. This is done by computing relevance scores for each query-source pair.</li><li id="3a47" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">For <strong class="nd fr">answer generation</strong>, we then would normally use the new top x results. (In our case we use the top 10)</li></ol><p id="44e5" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In code this is also looking fairly simple and can be implemented in few lines of code:</p><pre class="ml mm mn mo mp pl pm pn bp po bb bk"><span id="0ebe" class="pp oh fq pm b bg pq pr l ps pt"># Instantiate the reranker<br/>from transformers import AutoModelForSequenceClassification, AutoTokenizer<br/><br/>reranker_tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-v2-m3')<br/>reranker_model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-v2-m3').to("mps")<br/>reranker_model.eval()<br/><br/># results = ... put code to query your vector database here...<br/># Note that in our case the results are a dataframe containing the text<br/># in the "chunk" column.<br/><br/># Perform a reranking<br/># Form query-chunk-pairs<br/>pairs = [[query, row['chunk']] for _, row in results.iterrows()]<br/><br/># Calculate relevance scores<br/>with torch.no_grad():<br/>    inputs = reranker_tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512).to("mps")<br/>    scores = reranker_model(**inputs, return_dict=True).logits.view(-1,).float()<br/><br/># Add scores to the results DataFrame<br/>results['rerank_score'] = scores.tolist()<br/><br/># Sort results by rerank score and add new rank<br/>reranked_results = results.sort_values('rerank_score', ascending=False).reset_index(drop=True)</span></pre><blockquote class="ph pi pj"><p id="2702" class="nb nc pk nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Again, for seeing the full code for context check <a class="af nx" href="https://github.com/Renumics/reranking-blogpost/blob/main/reranker_test.ipynb" rel="noopener ugc nofollow" target="_blank">Github</a></p></blockquote><p id="c069" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As you can see, the main mechanism is simply to provide the model with <strong class="nd fr">pairs of query and potentially relevant text</strong>. It outputs a <strong class="nd fr">relevance score</strong> which we then can use to reorder our result list. But is this worth it? In which cases is it worth the extra inference time?</p><h1 id="9bcc" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Evaluating The Reranker</h1><p id="f727" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">For evaluating our system we need to define some test queries. In my case I chose to use the following question categories:</p><ol class=""><li id="4014" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk"><strong class="nd fr">Factoid Questions</strong> such as “What is rigid motion?”<br/>Those should usually have one specific source in the document and are worded such that they could probably even found by text search.</li><li id="c42a" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk"><strong class="nd fr">Paraphrased Factoid Questions</strong> such as “What is the mechanism in the architecture of some point cloud classification methods that is making them invariant to the order of the points?”<br/>As you can see, those are less specific in mentioning certain terms and require e.g. recognizing the relation of point cloud classification and the PointNet architecture.</li><li id="354a" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk"><strong class="nd fr">Multi Source Questions</strong> such as “How does the Co-Fusion approach work, compared to the approach presented in the thesis. What are similarities and differences?”<br/>Those Questions need the retrieval of multiple source that should either be listed or be compared with each other.</li><li id="1b4a" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk"><strong class="nd fr">Questions for Summaries or Table</strong> such as “”What were the networks and parameter sizes used for hand segmentation experiments?”<br/>Those questions target summaries in text and table form, such as a comparison table for model results. They are here to test wether rerankers recognize better that it can be useful to retrieve a summarization part in the document.</li></ol><p id="5229" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As I was quite lazy I only defined 5 questions per category to get a rough impression and evaluated the retrieved context with and without reranking. The criteria I chose for evaluation were for example:</p><ol class=""><li id="15b8" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">Did the reranking <strong class="nd fr">add important information</strong> to the context.</li><li id="8803" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Did the reranking <strong class="nd fr">reduce redundancy</strong> to the context.</li><li id="ba52" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Did the reranking give the most relevant result a higher position in the list (<strong class="nd fr">better prioritization</strong>).</li><li id="cc92" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">…</li></ol><p id="8df4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">So what about the results?</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pu"><img src="../Images/8ddc309a63790552d1924690bfe2ebbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPV7Gj1CsF2MoTthtBKH7w.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Overview of mean average rank change and initially neglected results (that were not in the top 10). (image create by author)</figcaption></figure><p id="d765" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Even in the overview, we can see, that there is a <strong class="nd fr">significant difference between the categories</strong> of questions, specifically there seems to be a lot of reranking going on for the multi_source_question category. When we look closer on the distributions of the metrics this is additionally confirmed.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pv"><img src="../Images/d2257ce34fbe71765343dc27f0fd6766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kMRctEnEfWHvxtFGt8nhjA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Distribution of neglected results metric by question category. (image create by author)</figcaption></figure><p id="fbef" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Specifically for 3 of our 5 questions in this category nearly all results in the final top 10 end up there through the reranking step. Now it is about finding out why that is the case. We therefore look at the two queries that are most significantly (positively) influenced by the reranking.</p><blockquote class="ph pi pj"><p id="dac1" class="nb nc pk nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Question1: “How does the Co-Fusion approach work, compare to the approach presented in the thesis. What are similarities and differences?”</p></blockquote><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pw"><img src="../Images/978aba73199c4ab60565c09617db49f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2L7R9jX8GqHmNiHJX2ID4A.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Reranking result for the top 10 sources and their former positions. (image create by author)</figcaption></figure><p id="96ac" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The first impression here is that the reranker for this query definitely had two major effects. It prioritized the chunk from position 6 as the top result. Also, it pulled several really low-ranking results into the top 10. When inspecting these chunks further we see the following:</p><ol class=""><li id="ff65" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">The reranker managed to bring up a chunk that is highly related and describes SLAM approaches <strong class="nd fr">as opposed to</strong> the approach in the thesis.</li><li id="4978" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">The reranker also managed to include a chunk that <strong class="nd fr">mentions Co-Fusion</strong> as one example for a SLAM approach that can deal with dynamic objects and includes discussion about the limitations.</li></ol><p id="d24c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In general, the main pattern that emerges here is, that the reranker is able to <strong class="nd fr">capture nuances in the tone of the speech</strong>. Concretely formulations such as “SLAM approaches are closely related to the method presented in the thesis, however” paired with potential sparse mentions of Co-Fusion will be ranked way higher than by using a standard embedding model. That probably is because an Embedding model does most likely <strong class="nd fr">not capture</strong> that Co-Fusion is a SLAM approach and the predominant pattern in the text is general Information about SLAM. So, the reranker can give us two things here:</p><ol class=""><li id="1330" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk"><strong class="nd fr">Focusing on details</strong> in the respective chunk rather than going for the average semantic content.</li><li id="5681" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk"><strong class="nd fr">Focusing more on the user intent</strong> to compare some method with the thesis’ approach.</li></ol><blockquote class="ph pi pj"><p id="5b1d" class="nb nc pk nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Question 2: “Provide a summary of the fulfilment of the objectives set out in the introduction based on the results of each experiment”</p></blockquote><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj px"><img src="../Images/736859d43cabb618a80cb8236fb1bcec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_LMRyoyUSklSCZvY8lFsw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Reranking result for the top 10 sources and their former positions. (image create by author)</figcaption></figure><p id="aedb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Also, here we realize that a lot of low-ranking sources are pulled into the top 10 sources through the reranking step. So let’s investigate why this is the case once more:</p><ol class=""><li id="864d" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">The reranker again managed to capture <strong class="nd fr">nuanced intent</strong> of the question and reranks e.g. a chunk that contains the formulation “it was thus suscpected… ” as highly relevant, which it truly is because what follows is then describing wether the assumptions were valid and if the approach could make use of that.</li><li id="202c" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">The reranker gives as a lot of cryptically formulated experimental results that include also a bunch of tabular overviews on results of the ML-trainings, potentially <strong class="nd fr">understanding the summarizing character</strong> of these sections.</li></ol><h1 id="b536" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Conclusion</h1><p id="4d0c" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">Implementing reranking is not a hard task with packages such as Huggingface Transformers providing <strong class="nd fr">easy to use interfaces</strong> to integrate them into your RAG pipeline and the major RAG frameworks like <a class="af nx" href="https://github.com/run-llama/llama_index" rel="noopener ugc nofollow" target="_blank">llama-index</a> and <a class="af nx" href="https://github.com/langchain-ai/langchain" rel="noopener ugc nofollow" target="_blank">langchain</a> supporting them out of the box. Also, there are <strong class="nd fr">API-based rerankers</strong> such as the one from <a class="af nx" href="https://cohere.com/rerank" rel="noopener ugc nofollow" target="_blank">Cohere</a> you could use in your application.<br/>From our evaluation we also see, that rerankers are most useful for things such as:</p><ul class=""><li id="766e" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw py nz oa bk"><strong class="nd fr">Capturing nuanced semantics</strong> hidden in a chunk with either different or cryptic content. E.g., a single mention of a method that is only once related to a concept within the chunk (SLAM and Co-Fusion)</li><li id="bdf6" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw py nz oa bk"><strong class="nd fr">Capturing user intent</strong>, e.g. comparing some approach to the thesis approach. The reranker can then focus on formulations that imply that there is a comparison going on instead of the other semantics.</li></ul><p id="63a5" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">I’m sure there are a lot more cases, but for this data and our test questions these were the dominant patterns and I feel they outline clearly what a supervisedly trained reranker can add over using only an an embedding model.</p></div></div></div></div>    
</body>
</html>