- en: Safeguard Your LLM Chatbot With Llama Guard 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/safeguard-your-llm-chatbot-with-llama-guard-2-ff5f5aa0f894?source=collection_archive---------9-----------------------#2024-05-13](https://towardsdatascience.com/safeguard-your-llm-chatbot-with-llama-guard-2-ff5f5aa0f894?source=collection_archive---------9-----------------------#2024-05-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to apply content moderation to your LLM’s inputs and outputs for a more
    responsible AI system
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)[![Dr.
    Leon Eversberg](../Images/56dc3579a29933f7047a9ce60be4697a.png)](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)
    [Dr. Leon Eversberg](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)
    ·9 min read·May 13, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f8058b6fb5ad17e0cdf1fd34fe4db5ef.png)'
  prefs: []
  type: TYPE_IMG
- en: Llama Guard. Image created by author with Adobe Photoshop’s AI image generation.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Responsible AI is a big umbrella term that has seen increased interest since
    the rise of ChatGPT and Large Language Models (LLMs).
  prefs: []
  type: TYPE_NORMAL
- en: In general, the term means that AI systems should not harm humans. In the case
    of LLMs, this can mean for example that language models should not produce hateful
    responses or help the user with illegal activities.
  prefs: []
  type: TYPE_NORMAL
- en: Llama Guard is an LLM-based safeguard for chatbots, developed by Meta. It is
    part of Meta’s [Purple Llama](https://llama.meta.com/purple-llama/) umbrella project
    for responsible AI.
  prefs: []
  type: TYPE_NORMAL
- en: Meta recently released Llama Guard 2\. This is an update of the old Llama Guard
    version 1, which was based on Llama 2.
  prefs: []
  type: TYPE_NORMAL
- en: Llama Guard 2 is a trained LLM that acts as a **binary classifier**, classifying
    user questions and also LLM responses as either **unsafe or safe**. The model
    is **based on the new Llama 3** and can be freely downloaded from Hugging Face
    after accepting Meta’s Llama 3 community license agreement [1].
  prefs: []
  type: TYPE_NORMAL
