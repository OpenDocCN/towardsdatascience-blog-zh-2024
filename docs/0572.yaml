- en: Towards increased truthfulness in LLM applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朝着提高LLM应用中的真实性前进
- en: 原文：[https://towardsdatascience.com/towards-increased-truthfulness-in-llm-applications-d25fc35c7ef9?source=collection_archive---------7-----------------------#2024-03-01](https://towardsdatascience.com/towards-increased-truthfulness-in-llm-applications-d25fc35c7ef9?source=collection_archive---------7-----------------------#2024-03-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/towards-increased-truthfulness-in-llm-applications-d25fc35c7ef9?source=collection_archive---------7-----------------------#2024-03-01](https://towardsdatascience.com/towards-increased-truthfulness-in-llm-applications-d25fc35c7ef9?source=collection_archive---------7-----------------------#2024-03-01)
- en: Application-oriented methods from current research
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当前研究中的面向应用的方法
- en: '[](https://medium.com/@Marlon_H?source=post_page---byline--d25fc35c7ef9--------------------------------)[![Marlon
    Hamm](../Images/fc8c340a9729c9d1623692445e651e57.png)](https://medium.com/@Marlon_H?source=post_page---byline--d25fc35c7ef9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d25fc35c7ef9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d25fc35c7ef9--------------------------------)
    [Marlon Hamm](https://medium.com/@Marlon_H?source=post_page---byline--d25fc35c7ef9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@Marlon_H?source=post_page---byline--d25fc35c7ef9--------------------------------)[![Marlon
    Hamm](../Images/fc8c340a9729c9d1623692445e651e57.png)](https://medium.com/@Marlon_H?source=post_page---byline--d25fc35c7ef9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d25fc35c7ef9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d25fc35c7ef9--------------------------------)
    [Marlon Hamm](https://medium.com/@Marlon_H?source=post_page---byline--d25fc35c7ef9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d25fc35c7ef9--------------------------------)
    ·10 min read·Mar 1, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d25fc35c7ef9--------------------------------)
    ·阅读时间：10分钟·2024年3月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Abstract
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This article explores methods to enhance the truthfulness of Retrieval Augmented
    Generation (RAG) application outputs, focusing on mitigating issues like hallucinations
    and reliance on pre-trained knowledge. I identify the causes of untruthful results,
    evaluate methods for assessing truthfulness, and propose solutions to improve
    accuracy. The study emphasizes the importance of groundedness and completeness
    in RAG outputs, recommending fine-tuning Large Language Models (LLMs) and employing
    element-aware summarization to ensure factual accuracy. Additionally, it discusses
    the use of scalable evaluation metrics, such as the Learnable Evaluation Metric
    for Text Simplification (LENS), and Chain of Thought-based (CoT) evaluations,
    for real-time output verification. The article highlights the need to balance
    the benefits of increased truthfulness against potential costs and performance
    impacts, suggesting a selective approach to method implementation based on application
    needs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本文探讨了增强检索增强生成（RAG）应用输出真实性的方法，重点解决诸如幻觉现象和依赖预训练知识等问题。我分析了不真实结果的原因，评估了评估真实性的方法，并提出了解决方案以提高准确性。本研究强调了RAG输出中基础性和完整性的重要性，建议对大型语言模型（LLM）进行微调，并采用元素感知摘要方法以确保事实准确性。此外，文章还讨论了可扩展的评估指标的使用，如可学习评估指标（LENS）和基于思维链（CoT）的评估，用于实时输出验证。文章强调了在增加真实性的好处与可能带来的成本和性能影响之间保持平衡的必要性，并建议根据应用需求选择性地实施这些方法。
- en: 1\. Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: A widely used Large Language Model (LLM) architecture which can provide insight
    into application outputs and reduce hallucinations is Retrieval Augmented Generation
    (RAG). RAG is a method to expand LLM memory by combining parametric memory (i.e.
    LLM pre-trained) with non-parametric (i.e. document retrieved) memories. To do
    this, the most relevant documents are retrieved from a vector database and, together
    with the user question and a customised prompt, passed to an LLM, which generates
    a response (see Figure 1). For further details, see Lewis et al. (2021).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一种广泛使用的、大型语言模型（LLM）架构是检索增强生成（RAG）。RAG是一种通过将参数化记忆（即LLM预训练模型）与非参数化记忆（即检索到的文档）结合来扩展LLM记忆的方法。为此，从向量数据库中检索最相关的文档，并将它们与用户问题和定制的提示一起传递给LLM，LLM根据这些信息生成回答（见图1）。更多详细信息，请参阅Lewis等人（2021年）。
- en: '![](../Images/6a9c52e4fc242cc2c7cfc03e70b57cae.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a9c52e4fc242cc2c7cfc03e70b57cae.png)'
- en: Figure 1 — Simplified RAG architecture
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图1 — 简化的RAG架构
- en: A real-world application can, for instance, connect an LLM to a database of
    medical guideline documents. Medical practitioners can replace manual look-up
    by asking natural language questions using RAG as a “search engine”. The application
    would answer the user’s question and reference the source guideline. If the answer
    is based on parametric memory, e.g. answering on guidelines contained in the pre-training
    but not the connected database, or if the LLM hallucinates, this could have drastic
    implications.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个现实世界的应用实例可以将LLM连接到医疗指南文档的数据库中。医疗从业人员可以通过向RAG询问自然语言问题，取代手动查找，作为一种“搜索引擎”来使用。该应用将回答用户的问题，并引用源指南。如果答案基于参数化记忆，例如回答的是包含在预训练中而不是连接数据库中的指南，或者如果LLM产生幻觉，这可能会产生严重影响。
- en: Firstly, if the medical practitioners verify with the referenced guidelines,
    they could lose trust in the application answers, leading to less usage. Secondly,
    and more worryingly, if not every answer is verified, an answer can be falsely
    assumed to be based on the queried medical guidelines, directly affecting the
    patient’s treatment. This highlights the relevance of the truthfulness of output
    in RAG applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果医疗从业人员核实了引用的指南，他们可能会对应用的回答失去信任，导致使用量下降。其次，更令人担忧的是，如果不是每个答案都经过核实，可能会错误地假设答案是基于查询的医疗指南，这将直接影响患者的治疗。这突显了RAG应用中输出真实性的重要性。
- en: In this article assessing RAG, truth is defined as being firmly grounded in
    factual knowledge of the retrieved document. To investigate this issue, one General
    Research Question (GRQ) and three Specific Research Questions (SRQ) are derived.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，评估RAG时，真实性被定义为在检索文档的事实知识中扎实根植。为了解决这个问题，衍生出了一个总体研究问题（GRQ）和三个具体研究问题（SRQ）。
- en: 'GRQ: How can the truthfulness of RAG outputs be improved?'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 'GRQ: 如何提高RAG输出的真实性？'
- en: 'SRQ 1: What causes untruthful results to be generated by RAG applications?'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 'SRQ 1: 什么原因导致RAG应用产生不真实的结果？'
- en: 'SRQ 2: How can truthfulness be evaluated?'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 'SRQ 2: 如何评估真实性？'
- en: 'SRQ 3: What methods can be used to increase truthfulness?'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 'SRQ 3: 可以使用哪些方法来提高真实性？'
- en: To answer the GRQ, the SRQs are analysed sequentially on the basis of literature
    research. The aim is to identify methods that can be implemented for use cases
    such as the above example from the medical field. Ultimately two categories of
    solution methods will be recommended for further analysis and customisation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答GRQ，SRQ将根据文献研究按顺序进行分析。目的是识别可以实施的解决方法，适用于医学领域中上述例子的使用场景。最终将推荐两类解决方案方法，以便进一步分析和定制。
- en: 2\. Untruthful RAG output
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 不真实的RAG输出
- en: As previously defined, a truthful answer should be firmly grounded in factual
    knowledge of the retrieved document. One metric for this is factual consistency,
    measuring if the summary contains untruthful or misleading facts that are not
    supported by the source text (Liu et al., 2023). It is used as a critical evaluation
    metric in multiple benchmarks (Kim et al., 2023; Fabbri et al., 2021; Deutsch
    & Roth, 2022; Wang et al., 2023; Wu et al., 2023). In the area of RAG, this is
    often referred to as groundedness (Levonian et al., 2023). Moreover, to take the
    usefulness of a truthful answer into consideration, its completeness is also of
    relevance. The following paragraphs give insight into the reason behind untruthful
    RAG results. This refers to the Generation Step in Figure 1, which summarises
    the retrieved documents with respect to the user question.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所定义，真实的答案应当扎实地基于检索文档中的事实知识。衡量这一点的一个指标是事实一致性，衡量摘要中是否包含未经源文献支持的不真实或误导性事实（Liu等，2023）。这一指标被作为多个基准中的关键评估指标（Kim等，2023；Fabbri等，2021；Deutsch
    & Roth，2022；Wang等，2023；Wu等，2023）。在RAG领域，这通常被称为“扎实性”（Levonian等，2023）。此外，为了考虑真实答案的实用性，其完整性也具有重要意义。接下来的段落将深入探讨RAG结果不真实的原因。这指的是图1中的生成步骤，该步骤根据用户问题总结检索到的文档。
- en: Firstly, the groundedness of an RAG application is impacted if the LLM answer
    is based on parametric memory rather than the factual knowledge of the retrieved
    document. This can, for instance, occur if the answer comes from pre-trained knowledge
    or is caused by hallucinations. Hallucinations still remain a fundamental problem
    of LLMs (Bang et al., 2023; Ji et al., 2023; Zhang & Gao, 2023), from which even
    powerful LLMs suffer (Liu et al., 2023). As per definition, low groundedness results
    in untruthful RAG results.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，RAG 应用的基础性（groundedness）受到 LLM 的回答是基于参数记忆而非检索文档中的事实知识的影响。例如，如果回答来源于预训练知识或是由于幻觉现象引起的，这种情况可能会发生。幻觉仍然是
    LLM 的一个根本问题（Bang 等, 2023；Ji 等, 2023；Zhang & Gao, 2023），即使是强大的 LLM 也会受到其影响（Liu
    等, 2023）。根据定义，低基础性会导致不真实的 RAG 结果。
- en: Secondly, completeness describes if an LLM´s answer lacks factual knowledge
    from the documents. This can be due to the low summarisation capability of an
    LLM or missing domain knowledge to interpret the factual knowledge (T. Zhang et
    al., 2023). The output could still be highly grounded. Nevertheless, an answer
    could be incomplete with respect to the documents. Leading to incorrect user perception
    of the content of the database. In addition, if factual knowledge from the document
    is missing, the LLM can be encouraged to make up for this by answering with its
    own parametric memory, raising the abovementioned issue.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，完整性描述了 LLM 的回答是否缺乏文档中的事实知识。这可能是由于 LLM 的总结能力较弱，或缺乏理解事实知识所需的领域知识（T. Zhang 等,
    2023）。输出可能依然高度基于事实。然而，回答可能相对于文档而言是不完整的，从而导致用户对数据库内容的错误认知。此外，如果文档中的事实知识缺失，LLM 可能会通过利用其自身的参数记忆来弥补这一点，进而引发上述问题。
- en: Having established the key causes of untruthful outputs, it is necessary to
    first measure and quantify these errors before a solution can be pursued. Therefore,
    the following section will cover the methods of measurement for the aforementioned
    sources of untruthful RAG outputs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定了不真实输出的关键原因之后，有必要首先测量并量化这些错误，然后才能寻找解决方案。因此，以下部分将介绍针对上述不真实RAG输出来源的测量方法。
- en: 3\. Evaluating truthfulness
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 评估真实性
- en: Having elaborated on groundedness and completeness and their origins, this section
    intends to guide through their measurement methods. I will begin with the widely
    known general-purpose methods and continue by highlighting recent trends. TruLens´s
    Feedback Functions plot serves here as a valuable reference for scalability and
    meaningfulness (see Figure2).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在阐述了基础性和完整性及其来源后，本节旨在指导它们的测量方法。我将从广为人知的通用方法开始，并继续突出最近的趋势。TruLens 的反馈功能图在可扩展性和意义性方面提供了宝贵的参考（见图
    2）。
- en: When talking about natural language generation evaluations, traditional evaluation
    metrics like ROUGE (Lin, 2004) and BLEU (Papineni et al., 2002) are widely used
    but tend to show a discrepancy from human assessments (Liu et al., 2023). Furthermore,
    Medium Language Models (MLMs) have demonstrated superior results to traditional
    evaluation metrics, but can be replaced by LLMs in many areas (X. Zhang & Gao,
    2023). Lastly, another well-known evaluation method is the human evaluation of
    generated text, which has apparent drawbacks of scale and cost (Fabbri et al.,
    2021). Due to the downsides of these methods (see Figure 2), these are not relevant
    for further consideration in this paper.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论自然语言生成评估时，传统的评估指标如 ROUGE（Lin, 2004）和 BLEU（Papineni 等, 2002）被广泛使用，但往往与人工评估存在差异（Liu
    等, 2023）。此外，中型语言模型（MLM）在传统评估指标上展示了优异的表现，但在许多领域中可以被大型语言模型（LLM）替代（X. Zhang & Gao,
    2023）。最后，另一种著名的评估方法是对生成文本的人工评估，但这种方法在规模和成本上存在明显的缺点（Fabbri 等, 2021）。由于这些方法的缺点（见图
    2），它们在本文中不再进一步讨论。
- en: '![](../Images/fb4848d5356e302c9d8324125089d93d.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb4848d5356e302c9d8324125089d93d.png)'
- en: Figure 2 — Feedback functions (Feedback Functions — TruLens, o. J.)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2 — 反馈功能（反馈功能 — TruLens，o. J.）
- en: Concerning recent trends, evaluation metrics have developed with the increase
    in the popularity of LLMs. One such development are LLM evaluations, allowing
    another LLM through Chain of Thought (CoT) reasoning to evaluate the generated
    text (Liu et al., 2023). Through bespoke prompting strategies, areas of focus
    like groundedness and completeness can be emphasised and numerically scored (Kim
    et al., 2023). For this method, it has been shown that a larger model size is
    beneficial for summarisation evaluation (Liu et al., 2023). Moreover, this evaluation
    can also be based on references or collected ground truth, comparing generated
    text and reference text (Wu et al., 2023). For open-ended tasks without a single
    correct answer, LLM-based evaluation outperforms reference-based metrics in terms
    of correlation with human quality judgements. Moreover, ground-truth collection
    can be costly. Therefore, reference or ground-truth based metrics are outside
    the scope of this assessment (Liu et al., 2023; *Feedback Functions — TruLens*,
    o. J.).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 关于近期趋势，评估指标随着大语言模型（LLMs）普及的增加而发展。其中一种发展是LLM评估，允许另一个LLM通过思维链（CoT）推理来评估生成的文本（Liu
    et al., 2023）。通过定制化的提示策略，可以强调并用数值打分聚焦于诸如真实性和完整性等方面（Kim et al., 2023）。对于这种方法，已有研究表明，较大的模型规模有利于摘要评估（Liu
    et al., 2023）。此外，这种评估还可以基于参考或收集的真实数据，比较生成的文本和参考文本（Wu et al., 2023）。对于没有唯一正确答案的开放性任务，基于LLM的评估在与人工质量判断的相关性方面优于基于参考的指标。此外，收集真实数据的成本可能很高。因此，基于参考或真实数据的指标不在本评估范围之内（Liu
    et al., 2023；*反馈函数 — TruLens*，o. J.）。
- en: Concluding with a noteworthy recent development, the **L**earnable **E**valuatio**n**
    Metric for Text **S**implification (LENS), stated to be “the first supervised
    automatic metric for text simplification evaluation” by Maddela et al. (2023),
    has demonstrated promising outcomes in recent benchmarks. It is recognized for
    its effectiveness in identifying hallucinations (Kew et al., 2023). In terms of
    scalability and meaningfulness this is expected to be slightly more scalable,
    due to lower cost, and slightly less meaningful than LLM evaluations, placing
    LENS close to LLM Evals in the right top corner of Figure 2\. Nevertheless, further
    assessment would be required to verify these claims. This would conclude the evaluations
    methods in scope and the next section is focusing on methods of their application.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，介绍一个值得注意的近期进展，即**L**可学习**评**估**指标**用于文本**简化**（LENS），Maddela等人（2023）称其为“首个监督自动化的文本简化评估指标”，在最近的基准测试中展现了良好的结果。它以其在识别幻觉（Kew
    et al., 2023）方面的有效性而著称。在可扩展性和有效性方面，预计该方法由于成本较低，具有较高的可扩展性，但在意义性上略逊色于LLM评估，因此LENS接近于图2右上角的LLM评估。然而，仍需进一步评估以验证这些说法。至此，评估方法的讨论已结束，下一节将聚焦于这些方法的应用。
- en: 4\. Toward increased truthfulness
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 朝向更高的真实性
- en: Having established in section 1, the relevance of truthfulness in RAG applications,
    with SRQ1 the causes of untruthful output and with SRQ2 its evaluation, this section
    will focus on SRQ3\. Hence, detailing specific recommended methods improving groundedness
    and completeness to increase truthful responses. These methods can be categorised
    into two groups, improvements in the generation of output and validation of output.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一节中已确立了RAG应用中真实性的重要性，并通过SRQ1探讨了不真实输出的原因，通过SRQ2进行了评估，本节将聚焦于SRQ3。因此，将详细描述改善真实性和完整性的具体推荐方法，以提高真实的回应。这些方法可分为两类：输出生成的改进和输出验证。
- en: In order to improve the generation step of the RAG application, this article
    will highlight two methods. These are visualised in Figure 3, with the simplified
    RAG architecture referenced on the left. The first methods is fine-tuning the
    generation LLM. Instruction tuning over model size is critical to the LLM’s zero-shot
    summarisation capability. Thus, state-of-the-art LLMs can perform on par with
    summaries written by freelance writers (T. Zhang et al., 2023). The second method
    focuses on element-aware summarisation. With CoT prompting, like presented in
    SumCoT, LLMs can generate summaries step by step, emphasising the factual entities
    of the source text (Wang et al., 2023). Specifically, in an additional step, factual
    elements are extracted from the relevant documents and made available to the LLM
    in addition to the context for the summarisation, see Figure 3\. Both methods
    have shown promising results for improving the groundedness and completeness of
    LLM-generated summaries.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进RAG应用的生成步骤，本文将重点介绍两种方法。这些方法在图3中得到了可视化，并且左侧参考了简化的RAG架构。第一种方法是微调生成LLM。模型大小上的指令调整对LLM的零-shot摘要能力至关重要。因此，最先进的LLM能够与自由职业者编写的摘要相媲美（T.
    Zhang等，2023）。第二种方法专注于元素感知摘要。通过CoT提示，如SumCoT中所展示的，LLM可以逐步生成摘要，强调源文本中的事实实体（Wang等，2023）。具体来说，在额外的一步中，相关文档中的事实元素被提取，并与摘要的上下文一起提供给LLM，见图3。两种方法在提高LLM生成摘要的基础性和完整性方面已显示出良好的效果。
- en: '![](../Images/8fc1964dfeef26680b2ff843985779af.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8fc1964dfeef26680b2ff843985779af.png)'
- en: Figure 3 — Improved generation step
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3 — 改进的生成步骤
- en: In validation of the RAG outputs, LLM-generated summaries are evaluated for
    groundedness and completeness. This can be done by CoT prompting an LLM to aggregate
    a groundedness and completeness score. In Figure 4 an example CoT prompt is depicted,
    which can be forwarded to an LLM of larger model size for completion. Furthermore,
    this step can be replaced or advanced by using supervised metrics like LENS. At
    last, the generated evaluation is compared against a threshold. In case of not
    grounded or incomplete outputs, those can be modified, raised to the user or potentially
    rejected.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证RAG输出时，LLM生成的摘要会根据其基础性和完整性进行评估。这可以通过CoT提示将LLM的基础性和完整性得分进行聚合来完成。图4中展示了一个CoT提示示例，您可以将其转发给更大模型的LLM以进行完成。此外，这一步可以通过使用监督指标（如LENS）来替代或推进。最后，生成的评估结果将与阈值进行比较。如果输出没有基础性或不完整，则可以对其进行修改、提升给用户，或可能被拒绝。
- en: '![](../Images/c340417353118f5143a2970195f46942.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c340417353118f5143a2970195f46942.png)'
- en: Figure 4 — Output validation
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4 — 输出验证
- en: Before adapting these methods to RAG applications, it should be considered that
    evaluation at run-time and fine-tuning the generation model will lead to additional
    costs. Furthermore, the evaluation step will affect the applications’ answering
    speed. Lastly, no answer due to output rejections and raised truthfulness concerns
    might confuse application users. Consequently, it is critical to evaluate these
    methods with respect to the field of application, the functionality of the application
    and the user´s expectations. Leading to a customised approach increasing outputs
    truthfulness of RAG applications.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在将这些方法应用于RAG时，应考虑到运行时评估和生成模型的微调会导致额外的成本。此外，评估步骤会影响应用的回答速度。最后，由于输出被拒绝或提升了真实性问题而没有答案，可能会使应用用户感到困惑。因此，评估这些方法时需要根据应用领域、应用功能和用户期望进行综合考虑。这将导致一种定制化的方法，提升RAG应用输出的真实性。
- en: Unless otherwise noted, all images are by the author.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有注明，所有图片均由作者提供。
- en: List of References
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献列表
- en: Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H.,
    Ji, Z., Yu, T., Chung, W., Do, Q. V., Xu, Y., & Fung, P. (2023). *A Multitask,
    Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and
    Interactivity* (arXiv:2302.04023). arXiv. [https://doi.org/10.48550/arXiv.2302.04023](https://doi.org/10.48550/arXiv.2302.04023)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H.,
    Ji, Z., Yu, T., Chung, W., Do, Q. V., Xu, Y., & Fung, P. (2023). *A Multitask,
    Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and
    Interactivity* (arXiv:2302.04023). arXiv. [https://doi.org/10.48550/arXiv.2302.04023](https://doi.org/10.48550/arXiv.2302.04023)
- en: Deutsch, D., & Roth, D. (2022). *Benchmarking Answer Verification Methods for
    Question Answering-Based Summarization Evaluation Metrics* (arXiv:2204.10206).
    arXiv. [https://doi.org/10.48550/arXiv.2204.10206](https://doi.org/10.48550/arXiv.2204.10206)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Deutsch, D., & Roth, D. (2022). *基准测试基于问答的摘要评估度量的答案验证方法* (arXiv:2204.10206).
    arXiv. [https://doi.org/10.48550/arXiv.2204.10206](https://doi.org/10.48550/arXiv.2204.10206)
- en: 'Fabbri, A. R., Kryściński, W., McCann, B., Xiong, C., Socher, R., & Radev,
    D. (2021). *SummEval: Re-evaluating Summarization Evaluation* (arXiv:2007.12626).
    arXiv. [https://doi.org/10.48550/arXiv.2007.12626](https://doi.org/10.48550/arXiv.2007.12626)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 'Fabbri, A. R., Kryściński, W., McCann, B., Xiong, C., Socher, R., & Radev,
    D. (2021). *SummEval: 重新评估摘要评估方法* (arXiv:2007.12626). arXiv. [https://doi.org/10.48550/arXiv.2007.12626](https://doi.org/10.48550/arXiv.2007.12626)'
- en: '*Feedback Functions — TruLens*. (o. J.). Abgerufen 11\. Februar 2024, von [https://www.trulens.org/trulens_eval/core_concepts_feedback_functions/#feedback-functions](https://www.trulens.org/trulens_eval/core_concepts_feedback_functions/#feedback-functions)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*反馈函数 — TruLens*。(o. J.)。于2024年2月11日访问，来自[https://www.trulens.org/trulens_eval/core_concepts_feedback_functions/#feedback-functions](https://www.trulens.org/trulens_eval/core_concepts_feedback_functions/#feedback-functions)'
- en: Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Dai,
    W., Madotto, A., & Fung, P. (2023). Survey of Hallucination in Natural Language
    Generation. *ACM Computing Surveys*, *55*(12), 1–38\. [https://doi.org/10.1145/3571730](https://doi.org/10.1145/3571730)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Dai,
    W., Madotto, A., & Fung, P. (2023). 关于自然语言生成中的幻觉问题的调查. *ACM计算机评论*, *55*(12), 1–38\.
    [https://doi.org/10.1145/3571730](https://doi.org/10.1145/3571730)
- en: 'Kew, T., Chi, A., Vásquez-Rodríguez, L., Agrawal, S., Aumiller, D., Alva-Manchego,
    F., & Shardlow, M. (2023). *BLESS: Benchmarking Large Language Models on Sentence
    Simplification* (arXiv:2310.15773). arXiv. [https://doi.org/10.48550/arXiv.2310.15773](https://doi.org/10.48550/arXiv.2310.15773)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 'Kew, T., Chi, A., Vásquez-Rodríguez, L., Agrawal, S., Aumiller, D., Alva-Manchego,
    F., & Shardlow, M. (2023). *BLESS: 基准测试大规模语言模型在句子简化上的表现* (arXiv:2310.15773). arXiv.
    [https://doi.org/10.48550/arXiv.2310.15773](https://doi.org/10.48550/arXiv.2310.15773)'
- en: Kim, J., Park, S., Jeong, K., Lee, S., Han, S. H., Lee, J., & Kang, P. (2023).
    *Which is better? Exploring Prompting Strategy For LLM-based Metrics* (arXiv:2311.03754).
    arXiv. [https://doi.org/10.48550/arXiv.2311.03754](https://doi.org/10.48550/arXiv.2311.03754)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Kim, J., Park, S., Jeong, K., Lee, S., Han, S. H., Lee, J., & Kang, P. (2023).
    *哪种更好？探索基于LLM度量的提示策略* (arXiv:2311.03754). arXiv. [https://doi.org/10.48550/arXiv.2311.03754](https://doi.org/10.48550/arXiv.2311.03754)
- en: 'Levonian, Z., Li, C., Zhu, W., Gade, A., Henkel, O., Postle, M.-E., & Xing,
    W. (2023). *Retrieval-augmented Generation to Improve Math Question-Answering:
    Trade-offs Between Groundedness and Human Preference* (arXiv:2310.03184). arXiv.
    [https://doi.org/10.48550/arXiv.2310.03184](https://doi.org/10.48550/arXiv.2310.03184)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Levonian, Z., Li, C., Zhu, W., Gade, A., Henkel, O., Postle, M.-E., & Xing,
    W. (2023). *增强检索生成以提高数学问答的表现：基础性与人类偏好之间的权衡* (arXiv:2310.03184). arXiv. [https://doi.org/10.48550/arXiv.2310.03184](https://doi.org/10.48550/arXiv.2310.03184)
- en: Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler,
    H., Lewis, M., Yih, W., Rocktäschel, T., Riedel, S., & Kiela, D. (2021). *Retrieval-Augmented
    Generation for Knowledge-Intensive NLP Tasks* (arXiv:2005.11401). arXiv. [https://doi.org/10.48550/arXiv.2005.11401](https://doi.org/10.48550/arXiv.2005.11401)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler,
    H., Lewis, M., Yih, W., Rocktäschel, T., Riedel, S., & Kiela, D. (2021). *基于检索增强生成的知识密集型NLP任务*
    (arXiv:2005.11401). arXiv. [https://doi.org/10.48550/arXiv.2005.11401](https://doi.org/10.48550/arXiv.2005.11401)
- en: 'Lin, C.-Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries.
    *Text Summarization Branches Out*, 74–81\. [https://aclanthology.org/W04-1013](https://aclanthology.org/W04-1013)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 'Lin, C.-Y. (2004). ROUGE: 一种自动化摘要评估工具包. *文本摘要的扩展应用*, 74–81\. [https://aclanthology.org/W04-1013](https://aclanthology.org/W04-1013)'
- en: 'Liu, Y., Iter, D., Xu, Y., Wang, S., Xu, R., & Zhu, C. (2023). *G-Eval: NLG
    Evaluation using GPT-4 with Better Human Alignment* (arXiv:2303.16634). arXiv.
    [https://doi.org/10.48550/arXiv.2303.16634](https://doi.org/10.48550/arXiv.2303.16634)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 'Liu, Y., Iter, D., Xu, Y., Wang, S., Xu, R., & Zhu, C. (2023). *G-Eval: 使用GPT-4的NLG评估与更好的人工对齐*
    (arXiv:2303.16634). arXiv. [https://doi.org/10.48550/arXiv.2303.16634](https://doi.org/10.48550/arXiv.2303.16634)'
- en: 'Maddela, M., Dou, Y., Heineman, D., & Xu, W. (2023). *LENS: A Learnable Evaluation
    Metric for Text Simplification* (arXiv:2212.09739). arXiv. [https://doi.org/10.48550/arXiv.2212.09739](https://doi.org/10.48550/arXiv.2212.09739)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 'Maddela, M., Dou, Y., Heineman, D., & Xu, W. (2023). *LENS: 一种可学习的文本简化评估度量*
    (arXiv:2212.09739). arXiv. [https://doi.org/10.48550/arXiv.2212.09739](https://doi.org/10.48550/arXiv.2212.09739)'
- en: 'Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). Bleu: A Method for
    Automatic Evaluation of Machine Translation. In P. Isabelle, E. Charniak, & D.
    Lin (Hrsg.), *Proceedings of the 40th Annual Meeting of the Association for Computational
    Linguistics* (S. 311–318). Association for Computational Linguistics. [https://doi.org/10.3115/1073083.1073135](https://doi.org/10.3115/1073083.1073135)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). Bleu：一种自动评估机器翻译的方法.
    载于 P. Isabelle, E. Charniak, & D. Lin (编辑), *第40届计算语言学会年会论文集* (第311–318页). 计算语言学会.
    [https://doi.org/10.3115/1073083.1073135](https://doi.org/10.3115/1073083.1073135)
- en: 'Wang, Y., Zhang, Z., & Wang, R. (2023). *Element-aware Summarization with Large
    Language Models: Expert-aligned Evaluation and Chain-of-Thought Method* (arXiv:2305.13412).
    arXiv. [https://doi.org/10.48550/arXiv.2305.13412](https://doi.org/10.48550/arXiv.2305.13412)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Wang, Y., Zhang, Z., & Wang, R. (2023). *具有元素感知的大型语言模型摘要：专家对齐评估与思维链方法* (arXiv:2305.13412).
    arXiv. [https://doi.org/10.48550/arXiv.2305.13412](https://doi.org/10.48550/arXiv.2305.13412)
- en: Wu, N., Gong, M., Shou, L., Liang, S., & Jiang, D. (2023). *Large Language Models
    are Diverse Role-Players for Summarization Evaluation* (arXiv:2303.15078). arXiv.
    [https://doi.org/10.48550/arXiv.2303.15078](https://doi.org/10.48550/arXiv.2303.15078)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Wu, N., Gong, M., Shou, L., Liang, S., & Jiang, D. (2023). *大型语言模型在摘要评估中的多样化角色*
    (arXiv:2303.15078). arXiv. [https://doi.org/10.48550/arXiv.2303.15078](https://doi.org/10.48550/arXiv.2303.15078)
- en: Zhang, T., Ladhak, F., Durmus, E., Liang, P., McKeown, K., & Hashimoto, T. B.
    (2023). *Benchmarking Large Language Models for News Summarization* (arXiv:2301.13848).
    arXiv. [https://doi.org/10.48550/arXiv.2301.13848](https://doi.org/10.48550/arXiv.2301.13848)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Zhang, T., Ladhak, F., Durmus, E., Liang, P., McKeown, K., & Hashimoto, T. B.
    (2023). *基准测试大型语言模型在新闻摘要中的表现* (arXiv:2301.13848). arXiv. [https://doi.org/10.48550/arXiv.2301.13848](https://doi.org/10.48550/arXiv.2301.13848)
- en: Zhang, X., & Gao, W. (2023). *Towards LLM-based Fact Verification on News Claims
    with a Hierarchical Step-by-Step Prompting Method* (arXiv:2310.00305). arXiv.
    [https://doi.org/10.48550/arXiv.2310.00305](https://doi.org/10.48550/arXiv.2310.00305)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Zhang, X., & Gao, W. (2023). *基于大型语言模型的新闻声明事实验证：一种分层逐步提示方法* (arXiv:2310.00305).
    arXiv. [https://doi.org/10.48550/arXiv.2310.00305](https://doi.org/10.48550/arXiv.2310.00305)
