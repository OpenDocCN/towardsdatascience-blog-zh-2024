- en: Unlearning to Build Great AI Apps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摆脱旧思维，构建优秀的AI应用
- en: 原文：[https://towardsdatascience.com/unlearning-to-build-great-ai-apps-29c9f5c2f321?source=collection_archive---------4-----------------------#2024-01-08](https://towardsdatascience.com/unlearning-to-build-great-ai-apps-29c9f5c2f321?source=collection_archive---------4-----------------------#2024-01-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unlearning-to-build-great-ai-apps-29c9f5c2f321?source=collection_archive---------4-----------------------#2024-01-08](https://towardsdatascience.com/unlearning-to-build-great-ai-apps-29c9f5c2f321?source=collection_archive---------4-----------------------#2024-01-08)
- en: Product strategies from Classical ML to adapt (or ditch) for the generative
    AI world
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从经典机器学习到适应（或抛弃）生成式AI世界的产品策略
- en: '[](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)[![Sam
    Stone](../Images/c241f50c3904ef8ee56c826f813fa8e1.png)](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------)
    [Sam Stone](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)[![Sam
    Stone](../Images/c241f50c3904ef8ee56c826f813fa8e1.png)](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------)
    [Sam Stone](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------)
    ·9 min read·Jan 8, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------)
    ·9分钟阅读·2024年1月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/0cc2e5bbc15b261108b01f07c19c5442.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cc2e5bbc15b261108b01f07c19c5442.png)'
- en: 'Image source: Tome'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Tome
- en: 'Years ago, the first piece of advice my boss at Opendoor gave me was succinct:
    *“Invest in backtesting. AI product teams succeed or fail based on the quality
    of their backtesting.”* At the time, this advice was tried-and-true; it had been
    learned the hard way by teams across search, recommendations, life sciences, finance,
    and other high-stakes products. It’s advice I held dear for the better part of
    a decade.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 多年前，我在Opendoor的老板给我的第一条建议简洁而深刻：*“投资回测。AI产品团队的成败取决于回测的质量。”* 当时，这条建议是经过实践验证的；它通过搜索、推荐、生命科学、金融等多个高风险领域的团队艰难获得的经验。这也是我珍视了近十年的建议。
- en: 'But I’ve come to believe it’s not axiomatic for building *generative* AI products.
    A year ago, I switched from classical ML products (which produce simple output:
    numbers, categories, ordered lists) to generative AI products. Along the way,
    I discovered many principles from classical ML no longer serve me and my teams.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 但我逐渐相信，这并不是构建*生成式*AI产品的公理。大约一年前，我从经典机器学习产品（输出简单结果：数字、类别、有序列表）转向了生成式AI产品。在这个过程中，我发现许多经典机器学习的原则不再适用于我和我的团队。
- en: 'Through my work at Tome, where I’m Head of Product, and conversations with
    leaders at generative AI startups, I’ve recognized 3 behaviors that distinguish
    the teams shipping the most powerful, useful generative AI features. These teams:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我在Tome的工作（我担任产品负责人），以及与生成式AI初创公司领导者的对话，我意识到有三种行为特征，区分了那些推出最强大、最有用的生成式AI功能的团队。这些团队：
- en: Simultaneously work backwards (from user problems) and forwards (from technology
    opportunities)
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同时从用户问题（向后工作）和技术机会（向前工作）两个方向进行探索
- en: Design low-friction feedback loops from the outset
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一开始就设计低摩擦的反馈循环
- en: Reconsider the research and development tools from classical ML
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新思考经典机器学习中的研发工具
- en: These behaviors require “unlearning” numerous things that remain best practices
    for classical ML. Some may seem counter-intuitive at first. Nonetheless, they
    apply to generative AI applications broadly, ranging from horizontal to vertical
    software, and startups to incumbents. Let’s dive in!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行为需要“摆脱”许多仍然是经典机器学习最佳实践的内容。乍看之下，其中一些可能显得违反直觉。然而，这些原则广泛适用于生成式AI应用，从横向到纵向的软件产品，从初创公司到行业巨头。让我们深入探讨吧！
- en: '*(Wondering why automated backtesting is no longer a tenet for generative AI
    application teams? And what to replace it with? Read on to Principle 3)*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*(想知道为什么自动化回测不再是生成式AI应用团队的基本原则了吗？该用什么替代它？继续阅读原则3)*'
- en: '*(More interested in tactics, rather than process, for how generative AI apps’
    UI/UX should differ from classical ML products?* [*Check out this blog post.*](/the-design-of-everyday-ai-things-26516d928566)*)*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*(更关心生成式 AI 应用的 UI/UX 应该如何与经典机器学习产品有所不同，而不是关心过程？* [*查看这篇博客文章。*](/the-design-of-everyday-ai-things-26516d928566)*)*'
- en: 'Principle 1: Simultaneously work backwards (from user problems) and forwards
    (from technology opportunities)'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原则 1：同时从用户问题出发（倒推）和从技术机会出发（正推）
- en: “Working backwards” from user problems is a credo in many product and design
    circles, [made famous by Amazon](https://www.nytimes.com/2021/02/13/business/dealbook/amazon-working-backwards.html).
    Study users, size their pain points, write UX requirements to mitigate the top
    one, identify the best technology to implement, then rinse and repeat. In other
    words, figure out “This is the most important nail for us to hit, then which hammer
    to use.”
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: “从用户问题倒推”是许多产品和设计圈中的信条，[由亚马逊所闻名](https://www.nytimes.com/2021/02/13/business/dealbook/amazon-working-backwards.html)。研究用户，找出他们的痛点，编写用户体验需求以缓解最严重的痛点，识别最合适的技术进行实施，然后不断重复。换句话说，弄清楚“这是我们要解决的最重要的问题，然后选择哪个工具来解决它。”
- en: 'This approach makes less sense when enabling technologies are advancing very
    rapidly. ChatGPT was not built by working backwards from a user pain point. It
    took off because it offered a powerful, new enabling technology through a simple,
    open-ended UI. In other words: “We’ve invented a new hammer, let’s see which nails
    users will hit with it.”'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用技术发展得非常迅速时，这种方法的意义就不大了。ChatGPT 不是通过从用户痛点倒推来构建的。它之所以成功，是因为它通过一个简单、开放式的用户界面提供了一个强大而全新的启用技术。换句话说：“我们发明了一把新锤子，看看用户会用它敲哪些钉子。”
- en: 'The best generative AI application teams work backwards and forwards simultaneously.
    They do the user research and understand the breadth and depth of pain points.
    But they don’t simply progress through a ranked list sequentially. Everyone on
    the team, PMs and designers included, is deeply immersed in recent AI advances.
    They connect these unfolding technological opportunities to user pain points in
    ways that are often more complex than one-to-one mappings. For example, a team
    will see that user pain points #2, #3, and #6 could all be mitigated via model
    breakthrough X. Then it may make sense for the next project to focus on “working
    forwards” by incorporating model breakthrough X, rather than “working backwards”
    from pain point #1.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '最优秀的生成式人工智能应用团队会同时进行正推和倒推。他们做用户研究，理解痛点的广度和深度。但他们不仅仅是按顺序处理一个排序列表。团队中的每个人，包括产品经理和设计师，都深度沉浸在最新的人工智能进展中。他们将这些不断发展的技术机会与用户痛点联系起来，这种联系往往比一对一的映射更为复杂。例如，某个团队可能会发现，用户痛点
    #2、#3 和 #6 都可以通过模型突破 X 来缓解。那么，下一个项目可能会选择“正推”——通过结合模型突破 X，而不是“倒推”用户痛点 #1。'
- en: Deep immersion in recent AI advances means understanding how they apply to your
    real-world application, not just reading research papers. This requires prototyping.
    Until you’ve tried a new technology in your application environment, estimates
    of user benefit are just speculation. The elevated importance of prototyping requires
    flipping the traditional ***spec → prototype → build*** process to ***prototype
    → spec → build***. More prototypes are discarded, but that’s the only way to spec
    features consistently that match useful new technologies to broad, deep user needs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 深度沉浸在近期人工智能的进展中，意味着要理解这些进展如何应用于你的实际应用，而不仅仅是阅读研究论文。这需要原型设计。只有在你的应用环境中亲自尝试新技术，用户收益的估算才不只是猜测。原型设计的重要性提升要求颠覆传统的
    ***规格 → 原型 → 构建*** 过程，变成 ***原型 → 规格 → 构建***。更多的原型会被舍弃，但这是唯一能够持续精确匹配广泛且深刻的用户需求与有用新技术的方式。
- en: 'Principle 2: Design low-friction feedback loops from the outset'
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原则 2：从一开始就设计低摩擦反馈回路
- en: '**Feedback for system improvement**'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**系统改进反馈**'
- en: 'Classical ML products produce relatively simple output types: numbers, categories,
    ordered lists. And users tend to accept or reject these outputs: you click a link
    in the Google search results page, or mark an email as spam. Each user interaction
    provides data that is fed directly back into model retraining, so the link between
    real-world use and model improvement is strong (and mechanical).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的机器学习产品输出相对简单：数字、类别、排序列表。用户通常会接受或拒绝这些输出：你点击谷歌搜索结果页面上的一个链接，或者将邮件标记为垃圾邮件。每一次用户互动都会生成数据，直接反馈到模型的再训练中，因此实际使用和模型改进之间的联系是强大的（而且是机械的）。
- en: 'Unfortunately, most generative AI products tend not to produce new, ground-truth
    training data with each user interaction. This challenge is tied to what makes
    generative models so powerful: their ability to produce complex artifacts that
    combine text, images, video, audio, code, etc. For a complex artifact, it’s rare
    for a user to “take it or leave it”. Instead, most users refine the model output,
    either with more/different AI or manually. For example, a user may copy ChatGPT
    output into Word, edit it, and then send it to a colleague. This behavior prevents
    the application (ChatGPT) from “seeing” the final, desired form of the artifact.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，大多数生成式AI产品往往不会随着每次用户互动产生新的、真实的训练数据。这个挑战与生成式模型的强大之处息息相关：它们能够生成复杂的产物，这些产物融合了文本、图像、视频、音频、代码等。对于复杂的产物，用户很少会“接受或拒绝”。相反，大多数用户会对模型输出进行精细化调整，无论是通过更多/不同的AI，还是手动调整。例如，用户可能会将ChatGPT的输出复制到Word中，编辑后再发送给同事。这种行为使得应用程序（ChatGPT）无法“看到”产物的最终、期望形式。
- en: 'One implication is to allow users to iterate on output within your application.
    But that does not eliminate the problem: when a user does not iterate on an output,
    does that mean “wow” or “woe”? You could add a sentiment indicator (e.g. thumbs
    up/down) to each AI response, but interaction-level feedback response rates tend
    to be *very* low. And the responses that are submitted tend to be biased towards
    the extremes. Users mostly perceive sentiment collection efforts as additional
    friction, as they mostly don’t help the user immediately get to a better output.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个含义是允许用户在你的应用程序中对输出进行迭代。但这并不解决问题：当用户没有对输出进行迭代时，这意味着“哇”还是“哀愁”？你可以为每个AI响应添加一个情感指示器（例如，点赞/点踩），但互动级别的反馈响应率往往是*非常*低的。而提交的反馈通常偏向极端。用户大多将情感收集工作视为额外的障碍，因为它们大多不能帮助用户立即获得更好的输出。
- en: A better strategy is to identify a step in the user’s workflow that signifies
    “this output is now good enough”. Build that step into your app and make sure
    to log what the output looked like at this point. For Tome, where we help users
    craft presentations with AI, the key step is sharing a presentation with another
    person. To bring this into our app, we’ve invested heavily in sharing features.
    And then we evaluate which AI outputs were “sharable” and which required massive
    manual editing to be shareable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的策略是识别用户工作流程中的某一步，标志着“这个输出现在足够好”。将这一步构建到你的应用中，并确保记录此时输出的样子。对于Tome，我们帮助用户使用AI制作演示文稿，关键步骤是将演示文稿分享给另一个人。为了在我们的应用中实现这一点，我们在共享功能上进行了大量投资。然后，我们评估哪些AI输出是“可共享的”，哪些则需要大量手动编辑才能共享。
- en: '**Feedback for user assistance**'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**用户协助反馈**'
- en: 'Free text has emerged as the dominant user-desired method of interacting with
    generative AI applications. But free text is a Pandora’s box: give a user free
    text input to AI, and they’ll ask the product to do all sorts of things it cannot.
    Free text is a notoriously difficult input mechanism through which to convey a
    product’s constraints; in contrast, an old-fashioned web form makes it very clear
    what information can and must be submitted, and in exactly what format.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 自由文本已经成为用户希望与生成式AI应用交互的主要方式。但自由文本是一个潘多拉的盒子：给用户自由文本输入AI，他们会要求产品做一些它无法完成的事情。自由文本是一种
    notoriously 难以传达产品限制的输入机制；相比之下，老式的网页表单能清晰地表明可以和必须提交哪些信息，以及必须以什么格式提交。
- en: 'But users don’t want forms when doing creative or complex work. They want free
    text — and guidance on how to craft great prompts, specific to their task at hand.
    Tactics for assisting users include example prompts or templates, guidance around
    optimal prompt length and formatting (should they include [few-shot examples](https://www.promptingguide.ai/techniques/fewshot)?).
    Human-readable error messages are also key (for example: “This prompt was in language
    X, but we only support languages Y and Z.”)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，用户在进行创意或复杂工作时并不想要表单。他们需要自由文本——并且需要关于如何根据当前任务编写优秀提示的指导。帮助用户的策略包括示例提示或模板，关于最优提示长度和格式的指导（他们是否应该包括[少量示例](https://www.promptingguide.ai/techniques/fewshot)？）。人类可读的错误信息也是关键（例如：“该提示使用了X语言，但我们仅支持Y和Z语言。”）
- en: One upshot of free text inputs is that unsupported requests can be a fantastic
    source of inspiration for what to build next. The trick is to be able to identify
    and cluster what users are trying to do in free text. More on that in the next
    section…
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 自由文本输入的一个好处是，未被支持的请求可以成为下一个开发灵感的绝佳来源。诀窍在于能够识别和聚类用户在自由文本中试图做的事情。关于这一点将在下一节中详细讨论…
- en: 'Principle 3: Reconsider the research and development tools from classical ML'
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原则三：重新考虑经典机器学习中的研发工具
- en: '*Something to build, something to keep, something to discard*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*构建一些，保留一些，舍弃一些*'
- en: '**Build: natural language analytics**'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Build: 自然语言分析**'
- en: 'Many generative AI applications allow users to pursue very different workflows
    from the same entry point: an open-ended, free-text interface. Users are not selecting
    from a drop-down “I’m brainstorming” or “I want to solve a math problem” — their
    desired workflow is implicit in their text input. So understanding users’ desired
    workflows requires segmenting that free text input. Some segmenting approaches
    are likely to be enduring — at Tome, we are always interested in desired language
    and audience type. There are also ad hoc segmentations, to answer specific questions
    on the product roadmap — for example, how many prompts request a visual element
    like an image, video, table or chart, and thus which visual element should we
    invest in?'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 许多生成性 AI 应用程序允许用户从同一个入口点执行非常不同的工作流：一个开放式、自由文本的界面。用户并不是从下拉菜单中选择“我在头脑风暴”或“我想解决一个数学问题”——他们期望的工作流隐含在他们的文本输入中。因此，理解用户期望的工作流需要对这些自由文本输入进行切分。一些切分方法可能会长期有效——在
    Tome，我们一直关注所需的语言和目标受众类型。也有一些临时的切分方法，用于回答产品路线图上的特定问题——例如，多少个提示请求视觉元素，如图像、视频、表格或图表，因此我们应该在这些视觉元素上进行投资？
- en: 'Natural language analytics should complement, not supplant, traditional research
    approaches. NLP is especially powerful when paired with structured data (e.g.,
    traditional SQL). Lots of key data is not free text: when did the user sign up,
    what are the user’s attributes (organization, job, geography, etc). At Tome, we
    tend to look at language clusters by job function, geography, and free/paid user
    status — all of which require traditional SQL.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言分析应该是对传统研究方法的补充，而不是取而代之。自然语言处理（NLP）与结构化数据（例如传统的 SQL）结合时尤其强大。许多关键数据不是自由文本：用户何时注册、用户的属性（如组织、职位、地理位置等）。在
    Tome，我们倾向于根据职位功能、地理位置和自由/付费用户状态来查看语言聚类——所有这些都需要传统的 SQL。
- en: And quant insights should never be relied on without qualitative insights. I’ve
    found that watching a user navigate our product *live* can sometimes generate
    10x the insight of a user interview (where the user discusses their product impression
    *post-hoc*). And I’ve found scenarios where one good user interview unlocked 10x
    the insight of quant analysis.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 定量分析的洞察永远不应单独依赖于定性分析。我发现，观察用户实时使用我们的产品*现场*演示，有时能获得是用户访谈（用户事后讨论其产品印象）十倍的洞察力。而且我也遇到过某个优秀的用户访谈，解锁了定量分析十倍的洞察。
- en: '**Keep: tooling for low-code prototyping**'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Keep: 低代码原型设计工具**'
- en: 'Two tooling types enable high-velocity, high-quality generative AI app development:
    prototyping tools and output quality assessment tools.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 两种工具类型能促进高速度、高质量的生成性 AI 应用开发：原型设计工具和输出质量评估工具。
- en: There are many different ways to improve an ML application, but one strategy
    that is both fast and accessible is [prompt engineering](https://platform.openai.com/docs/guides/prompt-engineering).
    It’s fast because it does not require model retraining; it’s accessible because
    it involves natural language, not code. Allowing non-engineers to manipulate prompt
    engineering approaches (in a dev or local environment) can dramatically increase
    velocity and quality. Often this can be implemented via a notebook. The notebook
    may contain a lot of code, but a non-engineer can make significant advances iterating
    on the natural language prompts without touching the code.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的方式可以改进机器学习应用，但有一种既快速又易于接触的策略是[提示工程](https://platform.openai.com/docs/guides/prompt-engineering)。它之所以快速，是因为它不需要重新训练模型；之所以易于接触，是因为它涉及的是自然语言，而不是代码。允许非工程师在开发环境或本地环境中操作提示工程方法，可以显著提高开发速度和质量。通常，这可以通过笔记本实现。笔记本中可能包含大量代码，但非工程师也可以在不接触代码的情况下，通过迭代自然语言提示取得显著进展。
- en: 'Assessing prototype output quality is often quite hard, especially when building
    a net-new feature. Rather than investing in automated quality measurement, I’ve
    found it significantly faster and more useful to poll colleagues or users in a
    “beta tester program” for 10–100 structured evaluations (scores + notes). The
    enabling technology for a “polling approach” can be light: a notebook to generate
    input/output examples at modest scale and pipe them into a Google Sheet. This
    allows manual evaluation to be parallelized, and it’s normally easy to get ~100
    examples evaluated, across a handful of people, in under a day. Evaluators’ notes,
    which provide insights into patterns of failure or excellence, are an added perk;
    notes tend to be more useful for identifying what to fix or build next than the
    numeric scores.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '**Discard: automated, backtested measures of quality**'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A tenet of classical ML engineering is to invest in a robust backtest. Teams
    retrain classical models frequently (weekly or daily), and a good backtest ensures
    only good new candidates are released to production. This makes sense for models
    outputting numbers or categories, which can be scored against a ground-truth set
    easily.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: But scoring accuracy is harder with complex (perhaps multi-modal) output. You
    may have a text that you consider great and thus you’re inclined to call it “ground
    truth”, but if the model output deviates from it by 1 word, is that meaningful?
    By 1 sentence? What if the facts are all the same, but the structure is different?
    What if it’s text and images together?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: But not all is lost. Humans tend to find it easy to assess whether generative
    AI output meets their quality bar. That doesn’t mean it’s easy to transform bad
    output into good, just that users tend to be able to make a judgment about whether
    text, image, audio, etc. is “good or bad” in a few seconds. Moreover, most generative
    AI systems at the application layer are not retrained on a daily, weekly, or even
    monthly basis, because of compute costs and/or the long timelines needed to acquire
    sufficient user signal to warrant retraining. So we don’t need quality evaluation
    processes that are run every day (unless you’re Google or Meta or OpenAI).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Given the ease with which humans can evaluate generative AI output, and the
    infrequency of retraining, it often makes sense to evaluate new model candidates
    based on internal, manual testing (e.g. the polling approach described in the
    subsection above) rather than an automated backtest.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Developing great generative AI applications requires more than just innovative
    engineering; it requires product and design to work in ways that are fundamentally
    different from the tenets of classical ML or non-ML products. Some patterns need
    to be unlearned (“invest in your backtest!”), some need to be reformulated (“work
    backwards and forwards”), and some are net-new (“build for feedback loops from
    the outset.”)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: It can be a lot of process and people rewiring, but the upside is enormous —
    and if you don’t do it, the revolution will pass you by.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能需要大量的流程和人员重组，但好处是巨大的——如果你不这么做，革命将会与你擦肩而过。
