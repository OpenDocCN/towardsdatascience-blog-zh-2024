<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>ML Engineering 101: A Thorough Explanation of The Error “DataLoader worker (pid(s) xxx) exited unexpectedly”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>ML Engineering 101: A Thorough Explanation of The Error “DataLoader worker (pid(s) xxx) exited unexpectedly”</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ml-engineering-101-a-thorough-explanation-of-the-error-dataloader-worker-pid-s-xxx-exited-f3a6a983911e?source=collection_archive---------6-----------------------#2024-06-03">https://towardsdatascience.com/ml-engineering-101-a-thorough-explanation-of-the-error-dataloader-worker-pid-s-xxx-exited-f3a6a983911e?source=collection_archive---------6-----------------------#2024-06-03</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="e6f3" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A deep dive into PyTorch DataLoader with Multiprocessing</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://mengliuz.medium.com/?source=post_page---byline--f3a6a983911e--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Mengliu Zhao" class="l ep by dd de cx" src="../Images/0b950a0785fa065db3319ed5be4a91de.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*siAyGzGqa7K3xsa639R_2w.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f3a6a983911e--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://mengliuz.medium.com/?source=post_page---byline--f3a6a983911e--------------------------------" rel="noopener follow">Mengliu Zhao</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f3a6a983911e--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 3, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="9eb9" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">As one of the many who use the PyTorch library on a day-to-day basis, I believe many ML engineer sooner or later encounters the problem “DataLoader worker (pid(s) xxx) exited unexpectedly” during training.</p><p id="29ca" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">It’s frustrating.</p><p id="6c6a" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">This error is often triggered when calling the DataLoader with parameter <em class="ne">num_workers &gt; 0</em>. Many online posts provide simple solutions like setting the num_workers=0, which makes the current issue go away but causes problems new in reality.</p><p id="70e2" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">This post will show you some tricks that may help resolve the problem. I’m going to do a deeper dive into the Torch.multiprocessing module and show you some useful virtual memory monitoring and leakage-preventing techniques. In a really rare case, the asynchronous memory occupation and release of the torch.multiprocessing workers could still trigger the issue, even without leakage. The ultimate solution is to optimize the virtual memory usage and understand the torch.multiprocessing behaviour, and perform garbage collection in the __getitem_ method.</p><p id="3f02" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Note: the platform I worked on is Ubuntu 20.04. To adapt to other platforms, many terminal commands need to be changed.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nh"><img src="../Images/506f6a7810c2c2408d0d19a4c61dc831.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wV2saM1BFsrZN97dvHMReg.jpeg"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Image source: <a class="af ny" href="https://pxhere.com/en/photo/1379760#google_vignette" rel="noopener ugc nofollow" target="_blank">https://pxhere.com/en/photo/1379760#google_vignette</a></figcaption></figure></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="b8de" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Brute-force Solution and the Cons</strong></p><p id="b3e1" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">If you search on the web, most people encountering the same issue will tell you the brute-force solution; just set num_workers=0 in the DataLoader, and the issue will be gone.</p><p id="4d85" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">It will be the easiest solution if you have a small dataset and can tolerate the training time. However, the underlying issue is still there, and if you have a very large dataset, setting <em class="ne">num_workers=0</em> will result in a very slow performance, sometimes 10x slower. That’s why we must look into the issue further and seek alternative solutions.</p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="0875" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Monitor Your Virtual Memory Usage</strong></p><p id="79b1" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">What exactly happens when the dataloader worker exits?</p><p id="5507" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To catch the last error log in the system, run the following command in the terminal, which will give you a more detailed error message.</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="f707" class="ol om fq oi b bg on oo l op oq">dmesg -T</span></pre><p id="023a" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Usually, you’ll see the real cause is “out of memory”. But why is there an out-of-memory issue? What specifically caused the extra memory consumption?</p><p id="23e0" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">When we set <em class="ne">num_workers =0</em> in the DataLoader, a single main process runs the training script. It will run properly as long as the data batch can fit into memory.</p><p id="942e" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">However, when setting <em class="ne">num_workers &gt; 0</em>, things become different. DataLoader will start child processes alongside preloading <em class="ne">prefetch_factor*num_workers</em> into the memory to speed things up. By default, <em class="ne">prefetch_factor = 2</em>. The prefetched data will consume the machine’s virtual memory (but the good news is that it doesn’t eat up GPUs, so you don’t need to shrink the batch size). So, the first thing we need to do is to monitor the system’s virtual memory usage.</p><p id="9eac" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">One of the easiest ways to monitor virtual memory usage is the <em class="ne">psutil</em> package, which will monitor the percentage of virtual memory being used</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="73bb" class="ol om fq oi b bg on oo l op oq">import psutil<br/>print(psutil.virtual_memory().percent)</span></pre><p id="09d7" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">You can also use the tracemalloc package, which will give you more detailed information:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="7928" class="ol om fq oi b bg on oo l op oq">snapshot = tracemalloc.take_snapshot()<br/>top_stats = snapshot.statistics('lineno')<br/>for stat in top_stats[:10]:<br/>    print(stat)</span></pre><p id="6795" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">When the actual RAM is full, idle data will flow into the swap space (so it’s part of your virtual memory). To check the swap, use the command:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="978e" class="ol om fq oi b bg on oo l op oq">free -m</span></pre><p id="65a5" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">And to change your swap size temporarily during training (e.g., increase to 16G) in the terminal:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="8281" class="ol om fq oi b bg on oo l op oq">swapoff -a<br/>fallocate -l 16G /swapfile<br/>chmod 600 /swapfile<br/>mkswap /swapfile<br/>swapon /swapfile</span></pre><p id="6bad" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><em class="ne">/dev/shm</em> (or, in certain cases, <em class="ne">/run/shm</em> ) is another file system for storing temporary files, which should be monitored. Simply run the following, and you will see the list of drives in your file system:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="107d" class="ol om fq oi b bg on oo l op oq">df -h</span></pre><p id="cff3" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To resize it temporarily (e.g., increase to 16GB), simply run:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="68ae" class="ol om fq oi b bg on oo l op oq">sudo mount -o remount,size=16G /dev/shm</span></pre></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="d88f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Torch.multiprocessing Best Practices</strong></p><p id="7ae7" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">However, virtual memory is only one side of the story. What if the issue doesn’t go away after adjusting the swap disk?</p><p id="f77e" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The other side of the story is the underlying issues of the torch.multiprocessing module. There are a number of best practices recommendations on the official webpage:</p><div class="or os ot ou ov ow"><a href="https://pytorch.org/docs/stable/notes/multiprocessing.html?source=post_page-----f3a6a983911e--------------------------------#" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab ig"><div class="oy ab co cb oz pa"><h2 class="bf fr hw z io pb iq ir pc it iv fp bk">Multiprocessing best practices - PyTorch 2.3 documentation</h2><div class="pd l"><h3 class="bf b hw z io pb iq ir pc it iv dx">torch.multiprocessing is a drop in replacement for Python's module. It supports the exact same operations, but extends…</h3></div><div class="pe l"><p class="bf b dy z io pb iq ir pc it iv dx">pytorch.org</p></div></div></div></a></div><p id="651e" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">But besides these, three more approaches should be considered, especially regarding memory usage.</p><p id="1b36" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">The first thing is shared memory leakage</strong>. Leakage means that memory is not released properly after each run of the child worker, and you will observe this phenomenon when you monitor the virtual memory usage at runtime. Memory consumption will keep increasing and reach the point of being “out of memory.” This is a very typical memory leakage.</p><p id="5807" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">So what will cause the leakage?</p><p id="2989" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Let’s take a look at the DataLoader class itself:</p><p id="5035" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><a class="af ny" href="https://github.com/pytorch/pytorch/blob/main/torch/utils/data/dataloader.py" rel="noopener ugc nofollow" target="_blank">https://github.com/pytorch/pytorch/blob/main/torch/utils/data/dataloader.py</a></p><p id="674f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Looking under the hood of DataLoader, we’ll see that when nums_worker &gt; 0, _MultiProcessingDataLoaderIter is called. Inside _MultiProcessingDataLoaderIter, Torch.multiprocessing creates the worker queue. Torch.multiprocessing uses two different strategies for memory sharing and caching: <em class="ne">file_descriptor </em>and <em class="ne">file_system. </em>While <em class="ne">file_system</em> requires no file descriptor caching, it is prone to shared memory leaks.</p><p id="50a8" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To check what sharing strategy your machine is using, simply add in the script:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="aa3f" class="ol om fq oi b bg on oo l op oq">torch.multiprocessing.get_sharing_strategy()</span></pre><p id="2ae1" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To get your system file descriptor limit (Linux), run the following command in the terminal:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="0c98" class="ol om fq oi b bg on oo l op oq">ulimit -n</span></pre><p id="bfef" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To switch your sharing strategy to <em class="ne">file_descriptor</em>:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="579a" class="ol om fq oi b bg on oo l op oq">torch.multiprocessing.set_sharing_strategy(‘file_descriptor’)</span></pre><p id="4132" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To count the number of opened file descriptors, run the following command:</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="76a4" class="ol om fq oi b bg on oo l op oq">ls /proc/self/fd | wc -l</span></pre><p id="11c1" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">As long as the system allows, the <em class="ne">file_descriptor </em>strategy is recommended.</p><p id="99c3" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">The second is the multiprocessing worker starting method. </strong>Simply put, it’s the debate as to whether to use a fork or spawn as the worker-starting method. Fork is the default way to start multiprocessing in Linux and can avoid certain file copying, so it is much faster, but it might have issues handling CUDA tensors and third-party libraries like OpenCV in your DataLoader.</p><p id="32b4" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To use the spawn method, you can simply pass the argument <em class="ne">multiprocessing_context=</em> <em class="ne">“spawn”</em>. to the DataLoader.</p><p id="a331" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Three, make the Dataset Objects Pickable/Serializable</strong></p><p id="8724" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">There is a super nice post further discussing the “copy-on-read” effect for process folding: <a class="af ny" href="https://ppwwyyxx.com/blog/2022/Demystify-RAM-Usage-in-Multiprocess-DataLoader/" rel="noopener ugc nofollow" target="_blank">https://ppwwyyxx.com/blog/2022/Demystify-RAM-Usage-in-Multiprocess-DataLoader/</a></p><p id="1e72" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Simply put, it’s <strong class="mk fr">no longer a good approach</strong> to create a list of filenames and load them in the __getitem__ method. Create a numpy array or panda dataframe to store the list of filenames for serialization purposes. And if you’re familiar with HuggingFace, using a CSV/dataframe is the recommended way to load a local dataset: <a class="af ny" href="https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/loading_methods#datasets.load_dataset.example-2" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/loading_methods#datasets.load_dataset.example-2</a></p></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="7b0f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">What If You Have a Really Slow Loader?</strong></p><p id="2b38" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Okay, now we have a better understanding of the multiprocessing module. But is it the end of the story?</p><p id="974a" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">It sounds really crazy. If you have a large and heavy dataset (e.g., each data point &gt; 5 MB), there is a weird chance of encountering the above issues, and I’ll tell you why. The secret is the asynchronous memory release of the multiprocessing workers.</p><p id="9a1d" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The trick is simple: hack into the torch library and add a <em class="ne">psutil.virtual_memory().percent</em> line before and after the data queue in the _MultiProcessingDataLoaderIter class:</p><div class="or os ot ou ov ow"><a href="https://github.com/pytorch/pytorch/blob/70d8bc2da1da34915ce504614495c8cf19c85df2/torch/utils/data/dataloader.py?source=post_page-----f3a6a983911e--------------------------------#L1130" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab ig"><div class="oy ab co cb oz pa"><h2 class="bf fr hw z io pb iq ir pc it iv fp bk">pytorch/torch/utils/data/dataloader.py at 70d8bc2da1da34915ce504614495c8cf19c85df2 ·…</h2><div class="pd l"><h3 class="bf b hw z io pb iq ir pc it iv dx">Tensors and Dynamic neural networks in Python with strong GPU acceleration - pytorch/torch/utils/data/dataloader.py at…</h3></div><div class="pe l"><p class="bf b dy z io pb iq ir pc it iv dx">github.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk lq ow"/></div></div></a></div><p id="c3a9" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Something like</p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="5d5e" class="ol om fq oi b bg on oo l op oq">print(“before clearing”, psutil.virtual_memory().percent)<br/>data = self._data_queue.get(timeout=timeout)<br/>print("after", psutil.virtual_memory().percent)</span></pre><p id="b4dd" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In my case, I started my DataLoader with num_workers=8 and observed something like the following:</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div class="nf ng pl"><img src="../Images/f36f97f1e7987c83092f6e9ea35452e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*aMGIXNePgyPZACun7pahqA.png"/></div></figure><p id="554d" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">So the memory keeps flowing up — but is it memory leakage? Not really. It’s simply because the dataloader workers load faster than they release, creating 8 jobs while releasing 2. And that’s the root cause of the memory overflowing. The solution is simple: just add a garbage collector to the beginning of your <em class="ne">__getitem__ </em>method<em class="ne">:</em></p><pre class="ni nj nk nl nm oh oi oj bp ok bb bk"><span id="198e" class="ol om fq oi b bg on oo l op oq">import gc<br/>def __getitem__(self, idx):<br/>    gc.collect()</span></pre><p id="a227" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">And now you’re good!</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div class="nf ng pm"><img src="../Images/3be6a5dc984f45eb7fb8957b5f146e25.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*O2tes6P9F8kqIdOxxoz7CQ.png"/></div></figure></div></div></div><div class="ab cb nz oa ob oc" role="separator"><span class="od by bm oe of og"/><span class="od by bm oe of og"/><span class="od by bm oe of"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="9724" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">References</strong></p><ul class=""><li id="bb82" class="mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd pn po pp bk"><a class="af ny" href="https://pytorch.org/docs/stable/multiprocessing.html#sharing-strategies" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/multiprocessing.html#sharing-strategies</a></li><li id="db16" class="mi mj fq mk b go pq mm mn gr pr mp mq mr ps mt mu mv pt mx my mz pu nb nc nd pn po pp bk"><a class="af ny" href="https://stackoverflow.com/questions/76491885/how-many-file-descriptors-are-open" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.com/questions/76491885/how-many-file-descriptors-are-open</a></li><li id="efbe" class="mi mj fq mk b go pq mm mn gr pr mp mq mr ps mt mu mv pt mx my mz pu nb nc nd pn po pp bk"><a class="af ny" href="https://psutil.readthedocs.io/en/latest/index.html#psutil.virtual_memory" rel="noopener ugc nofollow" target="_blank">https://psutil.readthedocs.io/en/latest/index.html#psutil.virtual_memory</a></li><li id="1672" class="mi mj fq mk b go pq mm mn gr pr mp mq mr ps mt mu mv pt mx my mz pu nb nc nd pn po pp bk"><a class="af ny" href="https://stackoverflow.com/questions/4970421/whats-the-difference-between-virtual-memory-and-swap-space" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.com/questions/4970421/whats-the-difference-between-virtual-memory-and-swap-space</a></li><li id="90cd" class="mi mj fq mk b go pq mm mn gr pr mp mq mr ps mt mu mv pt mx my mz pu nb nc nd pn po pp bk"><a class="af ny" href="https://ploi.io/documentation/server/change-swap-size-in-ubuntu" rel="noopener ugc nofollow" target="_blank">https://ploi.io/documentation/server/change-swap-size-in-ubuntu</a></li><li id="3b40" class="mi mj fq mk b go pq mm mn gr pr mp mq mr ps mt mu mv pt mx my mz pu nb nc nd pn po pp bk"><a class="af ny" href="https://stackoverflow.com/questions/58804022/how-to-resize-dev-shm" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.com/questions/58804022/how-to-resize-dev-shm</a></li><li id="c51d" class="mi mj fq mk b go pq mm mn gr pr mp mq mr ps mt mu mv pt mx my mz pu nb nc nd pn po pp bk"><a class="af ny" href="https://pytorch.org/docs/stable/data.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/data.html</a></li><li id="b893" class="mi mj fq mk b go pq mm mn gr pr mp mq mr ps mt mu mv pt mx my mz pu nb nc nd pn po pp bk"><a class="af ny" href="https://britishgeologicalsurvey.github.io/science/python-forking-vs-spawn/" rel="noopener ugc nofollow" target="_blank">https://britishgeologicalsurvey.github.io/science/python-forking-vs-spawn/</a></li><li id="9cdb" class="mi mj fq mk b go pq mm mn gr pr mp mq mr ps mt mu mv pt mx my mz pu nb nc nd pn po pp bk"><a class="af ny" href="https://stackoverflow.com/questions/64095876/multiprocessing-fork-vs-spawn" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.com/questions/64095876/multiprocessing-fork-vs-spawn</a></li></ul></div></div></div></div>    
</body>
</html>