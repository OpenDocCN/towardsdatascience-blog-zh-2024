- en: Generative AI is a Gamble Enterprises Should Take in 2024
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成性AI是企业应在2024年接受的赌注
- en: 原文：[https://towardsdatascience.com/generative-ai-is-a-gamble-enterprises-should-take-in-2024-9120e54f6349?source=collection_archive---------15-----------------------#2024-01-04](https://towardsdatascience.com/generative-ai-is-a-gamble-enterprises-should-take-in-2024-9120e54f6349?source=collection_archive---------15-----------------------#2024-01-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/generative-ai-is-a-gamble-enterprises-should-take-in-2024-9120e54f6349?source=collection_archive---------15-----------------------#2024-01-04](https://towardsdatascience.com/generative-ai-is-a-gamble-enterprises-should-take-in-2024-9120e54f6349?source=collection_archive---------15-----------------------#2024-01-04)
- en: LLMs today suffer from inaccuracies at scale, but that doesn’t mean you should
    cede competitive ground by waiting to adopt generative AI.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目前，大型语言模型（LLMs）在大规模应用时存在不准确性，但这并不意味着你应该通过等待来采用生成性AI，从而失去竞争优势。
- en: '[](https://databrett.medium.com/?source=post_page---byline--9120e54f6349--------------------------------)[![Brett
    A. Hurt](../Images/d120f98c1d5e06b14add6b5b9f4eb936.png)](https://databrett.medium.com/?source=post_page---byline--9120e54f6349--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9120e54f6349--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9120e54f6349--------------------------------)
    [Brett A. Hurt](https://databrett.medium.com/?source=post_page---byline--9120e54f6349--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://databrett.medium.com/?source=post_page---byline--9120e54f6349--------------------------------)[![Brett
    A. Hurt](../Images/d120f98c1d5e06b14add6b5b9f4eb936.png)](https://databrett.medium.com/?source=post_page---byline--9120e54f6349--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9120e54f6349--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9120e54f6349--------------------------------)
    [Brett A. Hurt](https://databrett.medium.com/?source=post_page---byline--9120e54f6349--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9120e54f6349--------------------------------)
    ·6 min read·Jan 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9120e54f6349--------------------------------)
    ·阅读时长6分钟·2024年1月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/69c21cf26e4eac65662be8762774c3a1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69c21cf26e4eac65662be8762774c3a1.png)'
- en: Building an AI-ready workforce with data.world OWLs, as imagined by OpenAI’s
    GPT-4
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 构建具有AI准备能力的工作队伍，使用data.world的OWLs，正如OpenAI的GPT-4所设想的那样
- en: 'Every enterprise technology has a purpose or it wouldn’t exist. Generative
    AI’s enterprise purpose is to produce human-usable output from technical, business,
    and language data rapidly and at scale to drive productivity, efficiency, and
    business gains. But this primary function of generative AI — to provide a witty
    answer — is also the source of large language models’ (LLMs) biggest barrier to
    enterprise adoption: so-called “hallucinations”.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每项企业技术都有其存在的目的，否则它就不会存在。生成性AI的企业目的是从技术、商业和语言数据中快速且大规模地生成可供人类使用的输出，以推动生产力、效率和商业收益。但生成性AI的这一主要功能——提供巧妙的答案——也是大型语言模型（LLMs）在企业采用过程中面临的最大障碍：所谓的“幻觉”问题。
- en: Why do hallucinations happen at all? Because, at their core, LLMs are complex
    statistical matching systems. They analyze billions of data points in an effort
    to determine patterns and predict the most likely response to any given prompt.
    But while these models may impress us with the usefulness, depth, and creativity
    of their answers, seducing us to trust them each time, they are far from reliable.
    New [research](https://vectara.com/measuring-hallucinations-in-rag-systems/) from
    Vectara found that chatbots can “invent” new information *up to 27% of the time*.
    In an enterprise setting where question complexity can vary greatly, that number
    climbs even higher. A [recent benchmark](https://arxiv.org/pdf/2311.07509.pdf)
    from data.world’s AI Lab using real business data found that when deployed as
    a standalone solution, LLMs return accurate responses to most basic business queries
    *only 25.5% of the time*. When it comes to intermediate or expert level queries,
    which are still well within the bounds of typical, data-driven enterprise queries,
    *accuracy dropped to ZERO percent*!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么幻觉会发生呢？因为，从本质上讲，大型语言模型（LLMs）是复杂的统计匹配系统。它们分析数十亿个数据点，努力确定模式，并预测对任何给定提示的最可能回应。但是，尽管这些模型可能通过它们的回答给我们留下深刻印象，展示了有用性、深度和创造力，并诱使我们每次都信任它们，但它们远非可靠。Vectara的最新[研究](https://vectara.com/measuring-hallucinations-in-rag-systems/)发现，聊天机器人“发明”新信息的频率*高达27%*。在企业环境中，问题的复杂性可能变化很大，这个数字还会更高。数据.world的AI实验室进行的[最新基准测试](https://arxiv.org/pdf/2311.07509.pdf)使用了真实的商业数据，发现当作为独立解决方案部署时，大型语言模型仅*25.5%的时间*能返回准确的基本商业查询回答。对于中级或专家级问题，这些问题仍在典型的数据驱动企业查询的范围内，*准确率降至零*！
- en: The tendency to hallucinate may be inconsequential for individuals playing around
    with ChatGPT for small or novelty use cases. But when it comes to enterprise deployment,
    hallucinations present a systemic risk. The consequences range from inconvenient
    (a service chatbot sharing irrelevant information in a customer interaction) to
    catastrophic, such as inputting the wrong numeral on an SEC filing.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉的倾向对那些仅在小范围或新奇用途上玩耍的个人来说可能无关紧要。但当涉及到企业部署时，幻觉却构成了系统性的风险。其后果从不便（例如，服务聊天机器人在客户互动中提供无关信息）到灾难性（例如，在美国证券交易委员会（SEC）报告中输入错误的数字）不等。
- en: 'As it stands, generative AI is still a gamble for the enterprise. However,
    it’s also a necessary one. As we learned at OpenAI’s first developer conference,
    [92% of Fortune 500 companies](https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference)
    are using OpenAI APIs. The potential of this technology in the enterprise is so
    transformative that the path forward is resoundingly clear: start adopting generative
    AI — knowing that the rewards come with serious risks. The alternative is to insulate
    yourself from the risks, and swiftly fall behind the competition. The [inevitable
    productivity lift](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321)
    is so obvious now that to not take advantage of it could be existential to an
    enterprise’s survival. So, faced with this illusion of choice, how can organizations
    go about integrating generative AI into their workflows, while simultaneously
    mitigating risk?'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，生成式AI对企业来说仍然是一场赌博。然而，这也是一场必不可少的赌博。正如我们在OpenAI的第一次开发者大会上所了解到的，[92%的财富500强公司](https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference)正在使用OpenAI的API。这项技术在企业中的潜力如此具有变革性，以至于未来的路径已经非常明确：开始采用生成式AI——明白回报与风险并存。另一种选择是将自己与风险隔离开来，迅速落后于竞争对手。[不可避免的生产力提升](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321)现在已经如此明显，以至于不利用它可能会对企业的生存构成存在性的威胁。所以，在面对这种选择的幻象时，组织应该如何在将生成式AI整合到工作流程中，同时降低风险呢？
- en: '**First, you need to prioritize your data foundation.** Like any modern enterprise
    technology, generative AI solutions are only as good as the data they’re built
    on top of — and according to Cisco’s recent [AI Readiness Index](https://www.cisco.com/c/dam/m/en_us/solutions/ai/readiness-index/documents/cisco-global-ai-readiness-index.pdf),
    intention is outpacing ability, particularly on the data front. Cisco found that
    while 84% of companies worldwide believe AI will have a significant impact on
    their business, 81% lack the data centralization needed to leverage AI tools to
    their full potential, and only 21% say their network has ‘optimal’ latency to
    support demanding AI workloads. It’s a similar story when it comes to data governance
    as well; just three out of ten respondents currently have comprehensive AI policies
    and protocols, while only four out of ten have systematic processes for AI bias
    and fairness corrections.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**首先，你需要优先考虑你的数据基础。** 就像任何现代企业技术一样，生成式 AI 解决方案的好坏取决于其所建立的数据基础——根据思科最近发布的[AI
    准备度指数](https://www.cisco.com/c/dam/m/en_us/solutions/ai/readiness-index/documents/cisco-global-ai-readiness-index.pdf)，意图正在超越能力，尤其是在数据方面。思科发现，虽然全球
    84% 的公司认为 AI 将对其业务产生重大影响，但 81% 的公司缺乏实现 AI 工具潜力所需的数据集中化，而只有 21% 的公司表示其网络具有支持高负载
    AI 工作负载的“最佳”延迟。关于数据治理，情况也相似；目前只有三分之一的受访者拥有全面的 AI 政策和协议，只有四分之一的受访者拥有系统性的 AI 偏见和公平性修正流程。'
- en: As benchmarking demonstrates, LLMs have a hard enough time already retrieving
    factual answers reliably. Combine that with poor data quality, a lack of data
    centralization / management capabilities, and limited governance policies, and
    the risk of hallucinations — and accompanying consequences — *skyrockets*. Put
    simply, companies with a strong data architecture have better and more accurate
    information available to them and, by extension, their AI solutions are equipped
    to make better decisions. Working with a data catalog or evaluating internal governance
    and data entry processes may not feel like the most exciting part of adopting
    generative AI. But it’s those considerations — data governance, lineage, and quality
    — that could make or break the success of a generative AI Initiative. It not only
    enables organizations to deploy enterprise AI solutions faster and more responsibly,
    but also allows them to keep pace with the market as the technology evolves.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如基准测试所示，LLM 已经很难可靠地检索事实性答案。如果再加上数据质量差、缺乏数据集中化/管理能力，以及有限的治理政策，幻觉现象的风险——以及随之而来的后果——*将急剧上升*。简单来说，拥有强大数据架构的公司可以更好、更准确地获得信息，进而其
    AI 解决方案能够做出更好的决策。使用数据目录或评估内部治理和数据录入流程可能并不是采用生成式 AI 最令人兴奋的部分。但正是这些考虑——数据治理、血统和质量——可能决定生成式
    AI 项目的成败。它不仅使组织能够更快、更负责任地部署企业级 AI 解决方案，还能够帮助它们在技术发展的过程中跟上市场的步伐。
- en: '**Second, you need to build an AI-educated workforce.** Research points to
    the fact that techniques like [advanced prompt engineering](https://amatriain.net/blog/hallucinations#advancedprompting)
    can prove useful in identifying and mitigating hallucinations. Other methods,
    such as fine-tuning, have been shown to dramatically improve LLM accuracy, even
    to the point of outperforming larger, more advanced general purpose models. However,
    employees can only deploy these tactics if they’re empowered with the latest training
    and education to do so. And let’s be honest: most employees aren’t. We are just
    over the one-year mark since the launch of ChatGPT on November 30, 2022!'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**第二，你需要建立一个具备 AI 知识的员工队伍。** 研究表明，[高级提示工程](https://amatriain.net/blog/hallucinations#advancedprompting)等技术对于识别和减轻幻觉现象有帮助。其他方法，如微调，已被证明能显著提高大语言模型（LLM）的准确性，甚至在某些情况下超过更大、更先进的通用模型。然而，员工只有在接受了最新的培训和教育后，才能应用这些技巧。说实话，大多数员工并未具备这种能力。自
    2022 年 11 月 30 日 ChatGPT 发布至今，已经过去了一年多！'
- en: When a major vendor such as Databricks or Snowflake releases new capabilities,
    organizations flock to webinars, conferences, and workshops to ensure they can
    take advantage of the latest features. Generative AI should be no different. Create
    a culture in 2024 where educating your team on AI best practices is your default;
    for example, by providing stipends for AI-specific L&D programs or bringing in
    an outside training consultant, such as the work we’ve done at data.world with
    [Rachel Woods](https://medium.com/u/4c866ecaad84?source=post_page---user_mention--9120e54f6349--------------------------------),
    who serves on our Advisory Board and founded and leads The AI Exchange. We also
    promoted [Brandon Gadoci](https://medium.com/u/fa1e06871025?source=post_page---user_mention--9120e54f6349--------------------------------),
    our first data.world employee outside of me and my co-founders, to be our VP of
    AI Operations. The staggering lift we’ve already had in our internal productivity
    is nothing short of inspirational (I wrote about it in [this three-part series](https://data.world/blog/meet-archie-who-is-helping-all-of-us-get-smarter-than-any-of-us-at-the-speed-of-ai/).)
    Brandon [just reported yesterday](https://bgadoci.com/thoughts/my-new-adventure-vp-of-ai-ops)
    that we’ve seen an astounding 25% increase in our team’s productivity through
    the use of our internal AI tools across all job roles in 2023! Adopting this type
    of culture will go a long way toward ensuring your organization is equipped to
    understand, recognize, and mitigate the threat of hallucinations.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当像Databricks或Snowflake这样的主要供应商发布新功能时，组织通常会涌向网络研讨会、会议和工作坊，以确保他们能够利用最新的功能。生成式人工智能应该也不例外。在2024年，建立一种文化，使得教育您的团队掌握人工智能最佳实践成为您的默认选项；例如，通过提供针对人工智能的L&D项目补贴或聘请外部培训顾问（比如我们在data.world与[Rachel
    Woods](https://medium.com/u/4c866ecaad84?source=post_page---user_mention--9120e54f6349--------------------------------)的合作，她在我们的顾问委员会中任职，并创办并领导了The
    AI Exchange）。我们还提升了[Brandon Gadoci](https://medium.com/u/fa1e06871025?source=post_page---user_mention--9120e54f6349--------------------------------)，我和我的共同创始人之外的第一位data.world员工，担任我们的人工智能运营副总裁。我们在内部生产力上已经取得的惊人提升，简直令人鼓舞（我在[这个三篇系列文章](https://data.world/blog/meet-archie-who-is-helping-all-of-us-get-smarter-than-any-of-us-at-the-speed-of-ai/)中写到了这点）。Brandon[昨天刚报告](https://bgadoci.com/thoughts/my-new-adventure-vp-of-ai-ops)我们通过在2023年全职岗位中使用内部人工智能工具，团队的生产力惊人地提高了25%！采纳这种文化将大大帮助您的组织理解、识别和减轻幻觉威胁。
- en: '**Third, you need to stay on top of the burgeoning AI ecosystem.** As with
    any new paradigm-shifting tech, AI is surrounded by a proliferation of emerging
    practices, software, and processes to minimize risk and maximize value. As transformative
    as LLMs may become, the wonderful truth is that we’re just at the start of the
    long arc of AI’s evolution.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**第三，您需要保持对新兴人工智能生态系统的关注。** 就像任何新的范式改变技术一样，人工智能周围充斥着大量新兴的实践、软件和流程，旨在最小化风险并最大化价值。尽管大型语言模型（LLMs）可能会带来巨大变革，但令人欣慰的事实是，我们才刚刚踏上人工智能演变的漫长道路。'
- en: Technologies once foreign to your organization may become critical. The aforementioned
    [benchmark](https://data.world/blog/generative-ai-benchmark-increasing-the-accuracy-of-llms-in-the-enterprise-with-a-knowledge-graph/)
    we released saw LLMs backed by a knowledge graph — a decades-old architecture
    for contextualizing data in three dimensions (mapping and relating data much like
    a human brain works) *— can improve accuracy by 300%*!Likewise, technologies like
    vector databases and retrieval augmented generation (RAG) have also risen to prominence
    given their ability to help address the hallucination problem with LLMs. Long-term,
    the ambitions of AI extend far beyond the APIs of the major LLM providers available
    today, so remain curious and nimble in your enterprise AI investments.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 曾经对您的组织而言陌生的技术可能会变得至关重要。我们发布的前述[基准测试](https://data.world/blog/generative-ai-benchmark-increasing-the-accuracy-of-llms-in-the-enterprise-with-a-knowledge-graph/)显示，结合知识图谱的LLMs——一种用于在三维中情境化数据的数十年历史架构（像人类大脑一样映射和关联数据）*—可以提高准确性300%*！同样，向量数据库和增强检索生成（RAG）等技术也因其在解决LLMs的幻觉问题方面的能力而崭露头角。从长远来看，人工智能的雄心远超目前主要LLM提供商的API，因此在企业的人工智能投资中，保持好奇心和灵活性是至关重要的。
- en: 'Like any new technology, generative AI solutions are not perfect, and their
    tendency to hallucinate poses a very real threat to their current viability for
    widespread enterprise deployment. However, these hallucinations shouldn’t stop
    organizations from experimenting and integrating these models into their workflows.
    Quite the opposite, in fact, as so eloquently [stated](https://x.com/emollick/status/1716156085445239265?s=20)
    by AI pioneer and Wharton entrepreneurship professor Ethan Mollick: “…understanding
    comes from experimentation.” Rather, the risk hallucinations impose should act
    as a forcing function for enterprise decision-makers to recognize what’s at stake,
    take steps to mitigate that risk accordingly, and reap the early benefits of LLMs
    in the process. 2024 is the year that your enterprise should take the leap.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 像任何新技术一样，生成式人工智能解决方案并不完美，它们产生幻觉的倾向对其目前在企业广泛部署中的可行性构成了现实威胁。然而，这些幻觉不应阻止组织进行实验并将这些模型集成到工作流程中。事实上，正如人工智能先驱、沃顿商学院创业教授Ethan
    Mollick在[推文](https://x.com/emollick/status/1716156085445239265?s=20)中所言：“……理解来自实验。”相反，幻觉带来的风险应当成为促使企业决策者认识到风险所在、采取相应措施来降低风险，并在过程中获得大语言模型（LLM）早期收益的推动力。2024年是你的企业应当跨出这一步的一年。
