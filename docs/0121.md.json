["```py\nimport pandas as pd\nheart_failure_data = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n```", "```py\nheart_failure_data.head(10)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nheart_failure_data_std = scaler.fit_transform(heart_failure_data.iloc[:,:-1])\n```", "```py\nX_train, X_test, y_train, y_test = train_test_split(\n    heart_failure_data_std, heart_failure_data.DEATH_EVENT, test_size = 0.2, random_state=10\n)\n```", "```py\nX_train = torch.from_numpy(X_train).type(torch.float)\nX_test = torch.from_numpy(X_test).type(torch.float)\ny_train = torch.from_numpy(y_train.values).type(torch.float)\ny_test = torch.from_numpy(y_test.values).type(torch.float)\n```", "```py\nfrom torch import nn\n\nclass LinearModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer_1 = nn.Linear(in_features=12, out_features=5)\n        self.layer_2 = nn.Linear(in_features=5, out_features=1)\n\n    def forward(self, x):\n        return self.layer_2(self.layer_1(x))\n```", "```py\nmodel_0 = nn.Sequential(\n nn.Linear(in_features=12, out_features=5),\n nn.Linear(in_features=5, out_features=1)\n)\n```", "```py\n# Binary Cross entropy\nloss_fn = nn.BCEWithLogitsLoss()\n\n# Stochastic Gradient Descent for Optimizer\noptimizer = torch.optim.SGD(params=model_0.parameters(), \n lr=0.01)\n```", "```py\ndef compute_accuracy(y_true, y_pred):\n    tp_tn = torch.eq(y_true, y_pred).sum().item()\n    acc = (tp_tn / len(y_pred)) * 100 \n    return acc\n```", "```py\ntorch.manual_seed(42)\n\nepochs = 1000\n\ntrain_acc_ev = []\ntest_acc_ev = []\n\n# Build training and evaluation loop\nfor epoch in range(epochs):\n\n    model_0.train()\n\n    y_logits = model_0(X_train).squeeze()\n\n    loss = loss_fn(y_logits,\n                   y_train) \n    # Calculating accuracy using predicted logists\n    acc = compute_accuracy(y_true=y_train, \n                      y_pred=torch.round(torch.sigmoid(y_logits))) \n\n    train_acc_ev.append(acc)\n\n    # Training steps\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    model_0.eval()\n\n    # Inference mode for prediction on the test data\n    with torch.inference_mode():\n\n        test_logits = model_0(X_test).squeeze() \n        test_loss = loss_fn(test_logits,\n                            y_test)\n        test_acc = compute_accuracy(y_true=y_test,\n                               y_pred=torch.round(torch.sigmoid(test_logits)))\n        test_acc_ev.append(test_acc)\n\n    # Print out accuracy and loss every 100 epochs\n    if epoch % 100 == 0:\n        print(f\"Epoch: {epoch}, Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")\n```", "```py\ndeeper_model = nn.Sequential(\n nn.Linear(in_features=12, out_features=20),\n nn.Linear(in_features=20, out_features=20),\n nn.Linear(in_features=20, out_features=1)\n)\n```", "```py\nmodel_non_linear = nn.Sequential(\n nn.Linear(in_features=12, out_features=5),\n nn.ReLU(),\n nn.Linear(in_features=5, out_features=1)\n)\n```"]