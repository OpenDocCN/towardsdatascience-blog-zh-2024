<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Framework for Optimizing Generative AI to Meet Business Needs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Framework for Optimizing Generative AI to Meet Business Needs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/framework-for-optimizing-generative-ai-to-meet-business-needs-02ac6932d55d?source=collection_archive---------2-----------------------#2024-03-04">https://towardsdatascience.com/framework-for-optimizing-generative-ai-to-meet-business-needs-02ac6932d55d?source=collection_archive---------2-----------------------#2024-03-04</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="f31e" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">The playbook for selecting right optimization strategy guided by clear business objectives to better meet the needs of customers.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Sarthak Handa" class="l ep by dd de cx" src="../Images/0c75ba0f085fdb22a221705450047c40.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*gQdzjTlAAyqFByyRYi1vMg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------" rel="noopener follow">Sarthak Handa</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 4, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/087c9599cd2cdaa90b7b4119bf0d4642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6TrKiWlMQNwaFUKIq_08xg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Source: Dalle3</figcaption></figure><p id="4485" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Generating human-like text and speech was once only possible in science fiction. But the rapid evolution of Large Language Models (LLMs) like GPT-3 and PaLM has brought this vision closer to reality, unlocking a range of promising business applications from chatbots to content creation.</p><p id="32df" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Yet, the general-purpose foundation models often fail to meet the needs of industry use cases. Businesses have different requirements for their generative AI applications — from <strong class="ne fr">performance</strong>, <strong class="ne fr">cost</strong>, <strong class="ne fr">latency</strong> to <strong class="ne fr">explainability</strong>. Moreover, the nature and quantity of the data available for model training can differ significantly. It is therefore important for product teams to outline key business criteria for their generative AI application and select the right toolkit of optimization techniques to meet these needs.</p><p id="93a1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this post, we outline a framework for identifying and prioritizing strategic focus areas for your generative AI application. We will also explore popular optimization methods and discuss their unique strengths, ideal applications, and trade-offs in meeting the application requirements. With the right optimization strategy guided by clear business objectives, companies can develop custom AI solutions that balance the priorities critical to their success. Let’s dive in!</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="8df6" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Framework to Assess Business Needs &amp; Constraints</h1><p id="8468" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">To tailor the strategy for optimizing LLMs effectively, product teams should start by building a deep understanding of the business objectives and the constraints within which they’re operating. Assess and prioritize the key dimensions listed below for your business use case:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/9208171a2136d7bb407d35336b95456d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qTIgjXcnw0pCPYSDNjNnAw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">SourceL Author</figcaption></figure><p id="9876" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">1. Performance Goal</strong>: Define the measure and level of performance your AI needs to achieve. This could be combination of factual accuracy, alignment with human values, or other task-specific metrics.</p><blockquote class="pi pj pk"><p id="2b60" class="nc nd pl ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Questions to Consider</strong>: <em class="fq">What are the best dimensions for measuring performance? What is the minimum acceptable performance bar? How does performance align with user expectations in your industry?</em></p></blockquote><p id="c45f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">2. Latency Targets</strong>: Determine the maximum response time that your application can afford without negatively impacting user experience. This could be especially important when LLMs are deployed in time-sensitive or resource-constrained scenarios (e.g., voice assistant, edge devices).</p><blockquote class="pi pj pk"><p id="4fb3" class="nc nd pl ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Questions to Consider</strong>: <em class="fq">How does latency impact user satisfaction and retention? What are industry standards for response time?</em></p></blockquote><p id="44eb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">3. Cost Efficiency</strong>: Evaluate the cost of operating AI with the expected ROI. Higher initial costs may be justified when they lead to substantial savings, revenue growth, or strategic benefits that outweigh investment.</p><blockquote class="pi pj pk"><p id="9d1f" class="nc nd pl ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Questions to Consider</strong>: <em class="fq">How does the cost of operating LLMs impact your budget? How does the ROI compare with the cost of AI deployment?</em></p></blockquote><p id="b865" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">4. Explainability &amp; Trust: </strong>Determine if there is a need to ensure that the AI decisions are easily understood by users, which is critical for building trust, especially in fields with stringent regulatory demands.</p><blockquote class="pi pj pk"><p id="a736" class="nc nd pl ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Questions to Consider</strong>: <em class="fq">Is your industry regulated, requiring transparency in AI’s decisions? How does explainability affect user trust and adoption?</em></p></blockquote><p id="7e81" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">5. External Knowledge</strong>: Assess if your AI needs access to external data sources to remain relevant and provide accurate responses.</p><blockquote class="pi pj pk"><p id="f44a" class="nc nd pl ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Questions to Consider</strong>: <em class="fq">Does your AI need real-time data to make decisions?</em></p></blockquote><p id="6b54" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">6. Data Availability</strong>: The nature and quantity of data available for training your AI could widely impact optimization strategy.</p><blockquote class="pi pj pk"><p id="9762" class="nc nd pl ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Questions to Consider</strong>: <em class="fq">Do you have access to a large dataset for training, or will you need to use synthetic or augmented data? How often will you need to update the training data to keep the AI relevant?</em></p></blockquote><p id="2284" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Presented below is a table outlining <strong class="ne fr">three distinct use cases</strong> for generative AI applications, with a corresponding evaluation of priorities for each dimension within the framework:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pm"><img src="../Images/68e86d6781466a2dd27403007758c812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GeB9RgjlIOqr3eMj-s9ZiQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">SourceL Author</figcaption></figure><p id="2db8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As you can see, the priorities and constrains can vary widely across different use cases.</p><p id="d814" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For instance, consider a company aiming to develop a <em class="pl">customer support chatbot</em> to ease the workload on human staff. In this scenario, <strong class="ne fr">accuracy performance</strong> and <strong class="ne fr">external data integration</strong> are of high priority to deliver responses that are not only factually correct but also up-to-date. While <strong class="ne fr">latency</strong> holds some significance, users may be willing to tolerate brief delays. Typically, such a company will have access to an <strong class="ne fr">extensive archive</strong> of past customer support interactions that can be used for training models.</p><p id="6e33" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In contrast, the critical application of AI for <em class="pl">assessing software code quality and risk</em> demands a increased focus on <strong class="ne fr">factual accuracy</strong> and <strong class="ne fr">explainability</strong> of the AI’s insights, often due to the potential consequences of errors. <strong class="ne fr">Cost</strong> and <strong class="ne fr">latency</strong> are secondary considerations in this context. This use case could benefit from <strong class="ne fr">external data integration </strong>in some cases, and it usually faces constraints regarding the availability of rich training datasets.</p><p id="b430" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A solid understanding of strategic priorities and constraints associated with the use case can help teams develop a tailored strategy for optimizing LLMs to meet the unique needs of the users.</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="da6d" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Diving Deeper Into LLM Optimization Techniques</h1><p id="9554" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">This section delves into the various optimization techniques, highlighting their objectives, ideal use-cases, and inherent trade-offs, particularly in the light of balancing the business goals discussed above.</p><p id="c75e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Techniques Table Breakdown:</strong></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pn"><img src="../Images/b2a403e1382512ae0bca1ffd4ed8cd8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*slZ7wf0sCfKRtEq36RtPog.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Source: Author</figcaption></figure><h1 id="e762" class="og oh fq bf oi oj po gq ol om pp gt oo op pq or os ot pr ov ow ox ps oz pa pb bk">1. Prompt Engineering:</h1><p id="d134" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk"><strong class="ne fr">Execution Complexity</strong>: Low</p><p id="221a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">When to Use</strong>: For reshaping response and quick improvement without altering the model. Start with this technique to maximize a pre-trained model’s effectiveness before trying more complex optimization methods.</p><p id="7688" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">What it entails: </strong>Prompt engineering involves crafting the input query to a model in a way that elicits the desired output. It requires understanding how the model responds to different types of instructions but doesn’t require retraining the model or altering its architecture. This method merely optimizes the way the existing model accesses and applies its pre-trained knowledge, and does not enhance the model’s intrinsic capabilities.</p><p id="31a4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pl">“It’s like adjusting the way you ask a question to a knowledgeable friend to get the best possible answer.”</em></p><p id="491d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Examples:</strong></p><ul class=""><li id="c88b" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">Asking a language model to “Write a poem in the style of Shakespeare” versus “Write a poem” to elicit a response in a specific literary style.</li><li id="c1f4" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Providing a detailed scenario in prompt for a conversational AI to ensure the model understands its role as customer service agent.</li></ul><p id="ef3e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Trade-offs</strong>:</p><ul class=""><li id="75c1" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk"><strong class="ne fr">Trial &amp; Error: </strong>Designing the most effective prompt requires iterations, since relationship between prompt and AI output is not always intuitive.</li><li id="5681" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne fr">Output Quality: </strong>The quality of the output is highly dependent on the design of the prompt, and there are limitations to the level of improvements that you can achieve through this method.</li></ul><h1 id="b040" class="og oh fq bf oi oj po gq ol om pp gt oo op pq or os ot pr ov ow ox ps oz pa pb bk">2. Fine-Tuning:</h1><p id="ed6c" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk"><strong class="ne fr">Execution Complexity</strong>: Medium</p><p id="f0d9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">When to Use</strong>: Fine-tuning should be considered when you need the model to adapt to a specific domain or task that may not be well-covered by the base pre-trained model. It is a step towards increasing domain specific accuracy and creating a more specialized model that can handle domain specific data and terminology.</p><p id="318d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">What it entails: </strong>Fine-tuning is the process of continuing the training of a pre-trained model on a new dataset that is representative of the target task or domain. This new dataset consists of input-output pairs that provide examples of the desired behavior. During fine-tuning, the model’s weights are updated to minimize the loss on this new dataset, effectively adapting the model to the new domain.</p><p id="a39d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pl">“Think of it as giving your friend a crash course on a topic you want them to become an expert in; showing them multiple examples of questions that may come in a test and the sample answers that they are expected to respond with.”</em></p><p id="d8ba" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Examples</strong>:</p><ul class=""><li id="2482" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">A general-purpose language model can be fine-tuned on legal documents to improve its performance for reviewing such documents.</li><li id="b389" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">An image recognition model can be fine-tuned with medical imaging datasets to better identify specific diseases in X-rays or MRIs.</li></ul><p id="d7a9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Trade-offs</strong>:</p><ul class=""><li id="c721" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk"><strong class="ne fr">Data Requirement:</strong> Fine-tuning requires a labeled dataset that is relevant to the task, which can be resource-intensive to create.</li><li id="a0eb" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne fr">Overfitting Risk:</strong> There is a potential risk of the model becoming too specialized to the fine-tuning data, which can decrease its ability to generalize to other contexts or datasets.</li></ul><h1 id="f00c" class="og oh fq bf oi oj po gq ol om pp gt oo op pq or os ot pr ov ow ox ps oz pa pb bk">3. Retrieval-Augmented Generation (RAG):</h1><p id="881d" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk"><strong class="ne fr">Execution Complexity</strong>: High</p><p id="a4b7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">When</strong> <strong class="ne fr">to use</strong>: RAG should be considered when there is a need for the AI model to access and incorporate external information to generate responses. This is especially relevant when the model is expected to provide up-to-date or highly specific information that is not contained within its pre-trained knowledge base.</p><p id="96dd" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">What it entails: </strong>RAG combines the generative capabilities of an LLM with a retrieval system. The retrieval system queries a database, knowledge base, or the internet to find information relevant to the input prompt. The retrieved information is then provided to the language model, which incorporates this context to generate a richer and more accurate response. By citing the sources used by the RAG system to generate responses, generative AI applications can offer enhanced explainability to the users.</p><p id="64d0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In the coming years, this optimization technique is expected to gain widespread popularity as an increasing number of products seek to leverage their latest business data to tailor experiences for customers.</p><p id="e5fe" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pl">“It’s akin to your friend being able to look up information online to answer questions that are outside their immediate expertise. It’s an open book exam.”</em></p><p id="df35" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Examples</strong>:</p><ul class=""><li id="37fb" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">In a RAG-based online chatbot, retriever can pull relevant information from a database or the internet to provide up-to-date answers.</li><li id="6d5f" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">A homework assistant AI could use RAG to fetch the most recent scientific data to answer a student’s question about climate change.</li></ul><p id="137f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Trade-offs</strong>:</p><ul class=""><li id="c989" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk"><strong class="ne fr">Complex Implementation:</strong> RAG systems require a well-integrated retrieval system, which can be challenging to set up and maintain.</li><li id="1163" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne fr">Quality of Information:</strong> The usefulness of the generated response is highly dependent on the relevance and accuracy of retrieved information. If the retrieval system’s sources are outdated or incorrect, the responses will reflect that.</li><li id="9117" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne fr">Slow Response Time:</strong> Retrieving information from external source to generate response can add latency.</li></ul><h1 id="42fb" class="og oh fq bf oi oj po gq ol om pp gt oo op pq or os ot pr ov ow ox ps oz pa pb bk">4. Reinforcement Learning from Human Feedback (RLHF):</h1><p id="1add" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk"><strong class="ne fr">Execution Complexity</strong>: Very High</p><p id="eeea" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">When to use</strong>: RLHF should be used when the model’s outputs need to align closely with complex human judgments and preferences.</p><p id="c192" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">What it entails: </strong>RLHF is a sophisticated reinforcement learning technique that refines a model’s behavior by incorporating human evaluations directly into the training process. This process typically involves collecting data from human operators who rank the outputs from AI on various quality metrics such as relevance, helpfulness, tone, etc. These data signals are then used to train a reward model, which guides the reinforcement learning process to produce outputs that are more closely aligned with human preferences.</p><p id="24d2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pl">“It’s similar to your friend learning from past conversations about what makes a discussion enjoyable, and using that knowledge to improve future interactions.”</em></p><p id="7330" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Examples</strong>:</p><ul class=""><li id="04c8" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">A social media platform could use RLHF to train a moderation bot that not only identifies inappropriate content but also responds to users in a way that is constructive and sensitive to context.</li><li id="0a61" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">A virtual assistant could be fine-tuned using RLHF to provide more personalized and context-aware responses to user requests.</li></ul><p id="083d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Trade-offs</strong>:</p><ul class=""><li id="2c55" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk"><strong class="ne fr">High Complexity: </strong>RLHF involves complex, resource-intensive processes, including human feedback gathering, reward modeling, and reinforcement learning.</li><li id="6c4e" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne fr">Quality Risk: </strong>There’s a risk of bias in the feedback data, which can lead to affect model quality. Ensuring consistent quality of human feedback and aligning the reward model with desired outcomes can be difficult.</li></ul><h1 id="a7e4" class="og oh fq bf oi oj po gq ol om pp gt oo op pq or os ot pr ov ow ox ps oz pa pb bk">5. Knowledge Distillation</h1><p id="9722" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk"><strong class="ne fr">Execution Complexity</strong>: Moderate to High</p><p id="96d2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">When to use</strong>: Knowledge distillation is used when you need to deploy sophisticated models on devices with limited computational power or in applications where response time is critical.</p><p id="83b8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">What it entails: </strong>It’s a compression technique where a smaller, more efficient model (known as the student) is trained to replicate the performance of a larger, more complex model (the teacher). The training goes beyond just learning the correct answers (hard targets), and involves the student trying to produce similar probabilities as the teacher’s predictions (soft targets). This approach enables the student model to capture the nuanced patterns and insights that teacher model has learned.</p><p id="03ee" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pl">“This is similar to distilling the wisdom of a seasoned expert into a concise guidebook that a novice can use to make expert-level decisions without going through years of experience.”</em></p><p id="522e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Examples</strong>:</p><ul class=""><li id="e2cb" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">A large-scale language model could be distilled into a smaller model that runs efficiently on smartphones for real-time language translation.</li><li id="3122" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">An image recognition system used in autonomous vehicles can be distilled into a light model that can run on vehicle’s onboard computer.</li></ul><p id="251e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Trade-offs</strong>:</p><ul class=""><li id="da73" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk"><strong class="ne fr">Performance vs. Size: </strong>The distilled model may not always match the performance of the teacher model, leading to a potential decrease in accuracy or quality.</li><li id="ff4e" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne fr">Training Complexity</strong>: The distillation process is time-consuming and involves careful experimentation to ensure the student model learns effectively. It requires a deep understanding of models’ architectures and the ability to translate knowledge from one to another.</li></ul><p id="e3e9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now let’s take a look at a real-world example in action.</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="d9bf" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Example: Customer Support Chatbot</h1><p id="65ad" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Let’s revisit the use case of building customer support chatbot to reduce workload on human support staff.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/a9afcbd5ed94718665a3356efa82af4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U2leM8FZedxDHaoSnjpd7Q.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Source: Dalle</figcaption></figure><p id="659e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The requirements/ constraints included:</p><ol class=""><li id="082c" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx qb pu pv bk"><strong class="ne fr">Performance</strong>: High Priority (Emphasis on Factual Accuracy)</li><li id="e6d8" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx qb pu pv bk"><strong class="ne fr">External Knowledge</strong>: High Priority</li><li id="b91d" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx qb pu pv bk"><strong class="ne fr">Latency Targets</strong>: Medium Priority</li><li id="ed79" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx qb pu pv bk"><strong class="ne fr">Cost Efficiency</strong>: Low Priority</li><li id="5af0" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx qb pu pv bk"><strong class="ne fr">Explainability &amp; Trust</strong>: Medium Priority</li><li id="53ef" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx qb pu pv bk"><strong class="ne fr">Data Availability</strong>: Ample (Past Conversations Data)</li></ol><p id="eae5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">With the clear understanding of business context and priorities, product builders can devise the most effective optimization strategy.</p><p id="84f0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">LLM Optimization Decision Steps:</strong></p><ol class=""><li id="44fd" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx qb pu pv bk"><strong class="ne fr">Prompt Engineering</strong> should serve as the first step to improve chatbot’s initial understanding and response capabilities. However, this alone is unlikely to suffice for specialized domain accuracy.</li><li id="2834" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx qb pu pv bk"><strong class="ne fr">Fine-Tuning</strong> the model with historic customer conversation data is critical for boosting chatbot’s accuracy performance, and making the model adept at handling, nuanced industry-specific inquiries.</li><li id="c385" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx qb pu pv bk">Incorporating <strong class="ne fr">Retrieval-Augmented Generation (RAG)</strong> is vital for providing users up-to-date product information and relevant web links.</li><li id="a2be" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx qb pu pv bk">While a certain degree of latency is tolerable, monitoring and potentially <strong class="ne fr">optimizing response times</strong> will still be advisable. Optimization strategies here could include caching common queries to speed up responses and using prompt engineering strategically to reduce unnecessary external data retrievals.</li></ol><p id="1881" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As you can see, a combination of strategies is often necessary to meet the specific demands of a use case. Flexibility in optimization strategies can be crucial, as requirements can change over time, and systems need to balance multiple requirements simultaneously.</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="60cc" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Conclusion</h1><p id="d948" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Optimizing LLMs for a business use case is both an art and a science, which requires a deep understanding of the underlying technology and the objectives at hand. As AI continues to evolve, the choice of optimization techniques will become increasingly strategic, influencing not only the performance of individual applications but also the overall trajectory of AI’s role in society.</p><p id="3af3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Whether you’re optimizing for speed, accuracy, cost, or transparency, the techniques discussed above offer a toolkit for enhancing LLMs to meet the demands of tomorrow’s generative AI powered business applications. By thoughtfully applying these methods, we can create AI that’s not only effective but also responsible and attuned to the nuanced needs of users.</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="3a48" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pl">Thanks for reading! If these insights resonate with you or spark new thoughts, let’s continue the conversation. Share your perspectives in the comments below or connect with me on </em><a class="af qc" href="https://www.linkedin.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr"><em class="pl">LinkedIn</em></strong></a><em class="pl">.</em></p></div></div></div></div>    
</body>
</html>