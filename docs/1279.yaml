- en: 3 Practical Tips to Combat Data Scarcity in Music AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应对音乐AI中数据匮乏的三大实用技巧
- en: 原文：[https://towardsdatascience.com/3-practical-tips-to-combat-data-scarcity-in-music-ai-58e52c771aef?source=collection_archive---------6-----------------------#2024-05-22](https://towardsdatascience.com/3-practical-tips-to-combat-data-scarcity-in-music-ai-58e52c771aef?source=collection_archive---------6-----------------------#2024-05-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/3-practical-tips-to-combat-data-scarcity-in-music-ai-58e52c771aef?source=collection_archive---------6-----------------------#2024-05-22](https://towardsdatascience.com/3-practical-tips-to-combat-data-scarcity-in-music-ai-58e52c771aef?source=collection_archive---------6-----------------------#2024-05-22)
- en: Get more out of your music data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从你的音乐数据中获取更多
- en: '[](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page---byline--58e52c771aef--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------)
    ·11 min read·May 22, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--58e52c771aef--------------------------------)
    ·阅读时长11分钟·2024年5月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/9346d558a628e376261a4172b6e0566a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9346d558a628e376261a4172b6e0566a.png)'
- en: Title image generated with DALL-E 2 by the author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 标题图像由作者使用DALL-E 2生成。
- en: '**Labeled audio data is chronically scarce** in Music AI. In this post, I will
    share some tips on building strong models under these circumstances.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**标注音频数据在音乐AI中长期匮乏**。在这篇文章中，我将分享一些在这种情况下构建强大模型的技巧。'
- en: 'Compared to other fields like Computer Vision or Natural Language Processing
    (NLP), finding suitable public datasets for Music AI is often difficult. Whether
    you want to do mood recognition, noise detection, or instrument tagging: you will
    likely struggle to find the right data.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与计算机视觉或自然语言处理（NLP）等其他领域相比，寻找适合音乐AI的公共数据集通常是困难的。无论你是想进行情绪识别、噪音检测还是乐器标注，你都可能会在寻找合适的数据时遇到困难。
- en: However, data scarcity affects not only hobby programmers and students. Aspiring
    music tech startups and even established music companies have the exact same problem.
    In the age of AI, many are **desperately trying to gather proprietary data assets**
    for machine learning purposes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数据匮乏不仅影响到业余程序员和学生。渴望发展的音乐技术初创公司甚至一些已建立的音乐公司也面临同样的问题。在AI时代，许多人**急切地尝试收集专有数据资源**以用于机器学习。
- en: With that said, let us dive into my **top 3 tips to get more out of your music
    data**.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，让我们深入探讨一下我的**从音乐数据中获取更多信息的三大技巧**。
- en: 'Tip 1: Apply Natural Data Augmentation'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示1：应用自然数据增强
- en: '![](../Images/0726f6e00bcddac17f509fd4881f3af7.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0726f6e00bcddac17f509fd4881f3af7.png)'
- en: Banner generated with DALL-E 2 by the author.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 横幅由作者使用DALL-E 2生成。
- en: If you are a data scientist, you have probably heard about data augmentation.
    The basic idea is to take existing examples in our dataset and alter them slightly
    to produce **new synthetic training examples**. This is best illustrated with
    images. For instance, if our dataset contains an image of a cat, we can easily
    create new synthetic cats by shifting and rotating the original cat image.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一名数据科学家，你可能听说过数据增强。基本的想法是从我们现有的数据集中获取现有样本，并稍微改变它们来生成**新的合成训练样本**。这个概念最容易通过图像来说明。例如，如果我们的数据集中包含一张猫的图片，我们可以通过平移和旋转原始猫的图片，轻松生成新的合成猫图像。
- en: '![](../Images/ef948ce570253f52a6174d1a32ef452f.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef948ce570253f52a6174d1a32ef452f.png)'
- en: Example for image data augmentation. Image inspired by [Suki Lau](/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2)
    and recreated by the author using a cat photo by [Alexander London](https://unsplash.com/de/@alxndr_london).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图像数据增强示例。图像灵感来源于[Suki Lau](/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2)，并由作者使用[Alexander
    London](https://unsplash.com/de/@alxndr_london)拍摄的猫的照片重新创作。
- en: Data augmentation is particularly **effective for smaller datasets**. If your
    dataset has only 100 images of cats, the odds that all possible angles and rotations
    are represented properly are low. These blind spots in the dataset will automatically
    translate to blind spots in the AI’s perception and judgment. By synthetically
    creating alterations of existing images, we can mitigate this risk.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强特别对**较小的数据集有效**。如果你的数据集只有100张猫的照片，那么所有可能的角度和旋转正确表示的几率就很低。这些数据集中的盲点将自动转化为AI感知和判断中的盲点。通过合成创建现有图像的变化，我们可以减轻这种风险。
- en: Data Augmentation is Different in Music AI
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据增强在音乐AI中的不同之处
- en: While data augmentation is a game-changer in Computer Vision, it is **less straightforward
    in Music A**I. The most common input to Music AI models is the spectrogram (learn
    more [here](/getting-to-know-the-mel-spectrogram-31bca3e2d9d0)). But have you
    tried rotating and shifting a spectrogram?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据增强在计算机视觉中是一个游戏规则改变者，但在音乐AI中，它**不那么直接**。音乐AI模型的最常见输入是声谱图（了解更多[这里](/getting-to-know-the-mel-spectrogram-31bca3e2d9d0)）。但你尝试过旋转和移动一个声谱图吗？
- en: '![](../Images/3da1b59b1f06533b6fe538653047eed5.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3da1b59b1f06533b6fe538653047eed5.png)'
- en: Example of ineffective data augmentation for audio data. Image by the author.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 无效的音频数据增强示例。图像来自作者。
- en: It is easy to see that the same tricks from Computer Vision cannot be applied
    directly to music AI. But why is this example so ridiculous? The answer is that,
    in contrast to the cat example, this kind of augmentation is **not natural** for
    a spectrogram.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易看出，计算机视觉中的相同技巧不能直接应用于音乐AI。但为什么这个例子如此荒谬呢？答案是，与猫的例子相比，这种增强对于声谱图来说是**不自然的**。
- en: An augmentation is natural when the changes made represent alterations that
    the model might encounter in **real-world applications**. While rotating a spectrogram
    certainly alters the data, visually, it is nonsensical and would never occur in
    practice. Instead, we need to find natural alterations specifically for music
    data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当所做的变化代表了模型在**实际应用中**可能遇到的变化时，数据增强是自然的。虽然旋转一个声谱图显然会改变数据，但在视觉上它毫无意义，且在实际中永远不会发生。相反，我们需要为音乐数据找到特别的自然变化。
- en: Using Effects for Natural Audio Augmentation
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用效果进行自然音频增强
- en: 'The most common natural music data augmentation involves applying effects to
    the audio signal. There are a bunch of effects that every musician knows from
    their DAW:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的自然音乐数据增强方法是对音频信号应用效果。每个音乐制作人都知道一堆来自数字音频工作站（DAW）的效果：
- en: Time stretching
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间拉伸
- en: Pitch shifting
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音高移位
- en: Compressors, Limiters, Distortion
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 压缩器、限制器、失真
- en: Reverb, Echo, Chorus
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混响、回声、合唱
- en: and many more…
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及更多…
- en: These effects can be applied to any piece of music, altering the data while
    preserving its main musical characteristics. If you want to know how to implement
    this in practice, **check my article about this topic:**
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些效果可以应用于任何音乐作品，改变数据同时保持其主要的音乐特征。如果你想知道如何在实践中实现这一点，**查看我关于这个话题的文章：**
- en: '[](/natural-audio-data-augmentation-using-spotifys-pedalboard-212ea59d39ce?source=post_page-----58e52c771aef--------------------------------)
    [## Natural Audio Data Augmentation Using Spotify’s Pedalboard'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/natural-audio-data-augmentation-using-spotifys-pedalboard-212ea59d39ce?source=post_page-----58e52c771aef--------------------------------)
    [## 使用Spotify的Pedalboard进行自然音频数据增强'
- en: With Ready-To-Use Python Code & Presets
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提供现成的Python代码和预设
- en: towardsdatascience.com](/natural-audio-data-augmentation-using-spotifys-pedalboard-212ea59d39ce?source=post_page-----58e52c771aef--------------------------------)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/natural-audio-data-augmentation-using-spotifys-pedalboard-212ea59d39ce?source=post_page-----58e52c771aef--------------------------------)
- en: Data augmentation is not only used in many Music AI research papers, but I have
    also had great results with it myself. When data is scarce, data augmentation
    can **push your model from unusable to acceptable**. Even with higher data volumes,
    it adds that extra bit of reliability that can be crucial in production.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强不仅在许多音乐AI研究论文中得到应用，我自己也取得了很好的效果。当数据稀缺时，数据增强可以**让你的模型从不可用转变为可接受**。即使数据量较大，它仍能增加一些额外的可靠性，这在生产环境中可能至关重要。
- en: 'When implementing music data augmentation in practice, it is important to keep
    these three things in mind:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际实施音乐数据增强时，重要的是要牢记以下三点：
- en: '**Stay natural.** Listen to your data after augmentation and make sure it still
    sounds natural. Otherwise, your model might learn false patterns.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**保持自然。** 增强后听一下你的数据，确保它听起来仍然自然。否则，模型可能会学习到错误的模式。'
- en: '**Not every training example should be augmented.** To make sure that your
    model primarily learns from real, unaltered music, augmented examples should only
    be a portion of your training data (20–30%). You can also use sample weighting
    during training to adjust the impact of your augmented examples on the model.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**并非每个训练样本都应该被增强。** 为了确保你的模型主要从真实的、未被修改的音乐中学习，增强样本应仅占你训练数据的一部分（20%–30%）。你还可以在训练时使用样本加权来调整增强样本对模型的影响。'
- en: '**Don’t augment your validation and test data.** Augmentations help the model
    learn generalizable patterns. Your validation and test data should be unaltered
    to enable accurate benchmarks on real examples.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不要增强你的验证和测试数据。** 增强可以帮助模型学习通用的模式。你的验证和测试数据应该保持未修改，以便能够在真实示例上进行准确的基准测试。'
- en: Time to boost your model effectiveness with data augmentation!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候通过数据增强提升你的模型效果了！
- en: 'Tip 2: Use Smaller Models and Input Data'
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示 2：使用更小的模型和输入数据
- en: '![](../Images/5046d53a4c179647371dd557ac835595.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5046d53a4c179647371dd557ac835595.png)'
- en: Banner generated with DALL-E 2 by the author.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 横幅由作者使用 DALL-E 2 生成。
- en: Bigger = Better?
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更大 = 更好？
- en: In AI, bigger is often better — if there is enough data to feed these large
    models. However, with limited data, **bigger models are more prone to overfitting**.
    Overfitting occurs when the model memorizes patterns from the training data that
    do not generalize well to real-world data examples. But there is another way to
    approach this that I find even more compelling in this context.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AI 中，更大通常意味着更好——前提是有足够的数据来训练这些大型模型。然而，数据有限时，**更大的模型更容易发生过拟合**。过拟合发生在模型记住了训练数据中的某些模式，但这些模式无法很好地推广到真实世界中的数据示例。但在这个背景下，我发现还有另一种方法值得考虑，这种方法甚至更有说服力。
- en: Suppose you have a small dataset of spectrograms and are deciding between a
    small CNN model (100k parameters) or a large CNN (10 million parameters). Remember
    that **every model parameter is effectively a best-guess number derived from the
    training dataset**. If we think of it this way, it is obvious that it is easier
    for a model to get 100k parameters right than it is to nail 10 million.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个小型的谱图数据集，并在选择一个小的 CNN 模型（10万参数）和一个大的 CNN 模型（1000万参数）之间做决定。记住，**每个模型参数实际上都是从训练数据集中得出的最佳猜测值**。如果我们这么想，显然让一个模型准确地获得10万个参数比准确地获得1000万个参数更容易。
- en: 'In the end, both arguments lead to the same conclusion:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，两个观点得出的结论是相同的：
- en: If data is scarce, consider building smaller models that focus only on the essential
    patterns.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果数据稀缺，考虑构建专注于基本模式的小型模型。
- en: But how can we achieve smaller models in practice?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何在实践中实现更小的模型呢？
- en: Don’t Crack Walnuts with a Sledgehammer
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不要用大锤砸胡桃
- en: My learning journey in Music AI has been dominated by deep learning. Up until
    a year ago, I had solved almost every problem using large neural networks. While
    this makes sense for complex tasks like music tagging or instrument recognition,
    **not every task is that complicated**.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我的音乐 AI 学习之旅一直被深度学习主导。直到一年前，我几乎用大型神经网络解决了所有问题。虽然对于复杂的任务，如音乐标签或乐器识别，这样做是有道理的，**并不是所有任务都那么复杂**。
- en: For instance, a decent BPM estimator or key detector can be built without any
    machine learning by analyzing the time between onsets or by correlating chromagrams
    with key profiles, respectively.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个不错的 BPM 估计器或调性检测器可以通过分析音符的开始时间，或者通过将色谱图与调性配置文件进行关联来构建，而不需要任何机器学习。
- en: Even for tasks like music tagging, it doesn’t always have to be a deep learning
    model. I’ve achieved good results in mood tagging through a simple K-Nearest Neighbor
    classifier over an embedding space (e.g. CLAP).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是像音乐标签这样的任务，也不一定非得使用深度学习模型。我通过一个简单的 K-近邻分类器在嵌入空间（例如 CLAP）上取得了很好的情绪标签结果。
- en: While most state-of-the-art methods in Music AI are based on deep learning,
    **alternative solutions should be considered under data scarcity**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管音乐 AI 中大多数最先进的方法都是基于深度学习的，**在数据稀缺的情况下，应该考虑替代解决方案**。
- en: Pay Attention to the Data Input Size
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注意数据输入大小
- en: More important than the choice of models is usually the choice of input data.
    In Music AI, we rarely use raw waveforms as input due to their data inefficiency.
    By transforming waveforms into (mel)spectrograms, we can decrease the input data
    dimensionality **by a factor of 100 or more**. This matters because large data
    inputs typically require larger and/or more complex models to process them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 比模型选择更重要的通常是输入数据的选择。在音乐AI中，我们很少使用原始波形作为输入，因为它们在数据效率上较低。通过将波形转换成（梅尔）声谱图，我们可以将输入数据的维度**减少100倍以上**。这很重要，因为大规模的数据输入通常需要更大和/或更复杂的模型来处理。
- en: To minimize the size of the model input, we can take two routes
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化模型输入的大小，我们可以采取两条路线
- en: '**Using smaller music snippets**'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用更小的音乐片段**'
- en: '**Using more compressed/simplified music representations.**'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用更压缩/简化的音乐表示。**'
- en: Using Smaller Music Snippets
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用更小的音乐片段
- en: Using smaller music snippets is especially effective if the outcome we are interested
    in is global, i.e. applies to every section of the song. For example, we can assume
    that the genre of a track remains relatively stable over the course of the track.
    Because of that, we can easily use 10-second snippets instead of full tracks (or
    the very common 30-second snippets) for a genre classification task.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用较小的音乐片段尤其有效，如果我们关心的结果是全局性的，即适用于整首歌的每个部分。例如，我们可以假设一首歌曲的类型在整首歌的过程中保持相对稳定。因此，我们可以轻松地使用10秒钟的片段，而不是完整的歌曲（或者非常常见的30秒片段）来进行音乐类型分类任务。
- en: 'This has two advantages:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这有两个优点：
- en: Shorter snippets result in fewer data points per training example, allowing
    you to use smaller models.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 较短的片段意味着每个训练示例的数据点更少，这样可以使用更小的模型。
- en: By drawing three 10-second snippets instead of one 30-second snippet, we can
    triple the number of training observations. All in all, this means that we can
    build less data-hungry models and, at the same time, feed them more training examples
    than before.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过绘制三个10秒的片段，而不是一个30秒的片段，我们可以将训练观察次数增加三倍。总的来说，这意味着我们可以构建更少依赖数据的模型，同时给它们提供比之前更多的训练示例。
- en: However, there are **two potential dangers here**. Firstly, the snippet size
    must be long enough so that a classification is possible. For example, even humans
    struggle with genre classification when presented with 3-second snippets. We should
    choose the snippet size carefully and view this decision as a hyperparameter of
    our AI solution.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这里有**两个潜在的风险**。首先，片段大小必须足够长，才能进行有效的分类。例如，即使是人类，在面对3秒钟的片段时，也很难进行类型分类。我们应当仔细选择片段大小，并将这个决定视为我们AI解决方案的超参数。
- en: Secondly, **not every musical attribute is global**. For example, if a song
    features vocals, this doesn’t mean that there are no instrumental sections. If
    we cut the track into really short snippets, we would introduce many falsely-labelled
    examples into our training dataset.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，**并不是每个音乐属性都是全局性的**。例如，如果一首歌包含人声，并不意味着它就没有器乐部分。如果我们将歌曲切割成非常短的片段，我们就会在训练数据集中引入许多错误标签的例子。
- en: Using More Efficient Music Representations
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用更高效的音乐表示
- en: If you studied Music AI ten years ago (back when all of this was called “Music
    Information Retrieval”), you learned about chromagrams, MFCCs, and beat histograms.
    These handcrafted features were designed to make music data work with traditional
    ML approaches. With the rise of deep learning, it might seem like these features
    have been **entirely replaced by (mel)spectrograms**.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你十年前学习过音乐AI（当时这一切还叫做“音乐信息检索”），你会了解到色度图、MFCC和节拍直方图。这些手工设计的特征旨在让音乐数据能够与传统的机器学习方法配合使用。随着深度学习的崛起，这些特征似乎已经**完全被（梅尔）声谱图所取代**。
- en: Spectrograms compress music into images without much information loss, making
    them **ideal in combination with computer vision models**. Instead of engineering
    custom features for different tasks, we can now use the same input data representation
    and model for most Music AI problems — provided you have tens of thousands of
    training examples to feed these models with.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 声谱图将音乐压缩成图像，并且几乎没有信息丢失，这使得它们与计算机视觉模型**非常适配**。我们不再需要为不同任务设计定制的特征，而是可以使用相同的输入数据表示和模型来处理大多数音乐AI问题——前提是你有成千上万的训练示例来喂给这些模型。
- en: When data is scarce, we want to **compress the information as much as possible**
    to make it easier for the model to extract relevant patterns from the data. Consider
    these four music representations below and tell me which one helps you identify
    the musical key the fastest.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据稀缺时，我们希望**尽可能压缩信息**，以便模型更容易从数据中提取出相关模式。请考虑以下四种音乐表示方式，并告诉我哪一种能帮助你最快地识别音乐的调性。
- en: '![](../Images/55215645b179c94abd112faf5942cbc9.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55215645b179c94abd112faf5942cbc9.png)'
- en: Examples of four different representations of the same song (“Honky Tonk Woman”
    by Tina Turner). Although the chromagram is roughly 700k smaller than the waveform,
    it lets us identify the key much more effectively (C# major). Image created by
    the author.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 四种不同表示同一首歌（Tina Turner 的《Honky Tonk Woman》）的示例。尽管色调图比波形图小约 70 万，但它能更有效地帮助我们识别调性（C#
    大调）。图像由作者创建。
- en: While mel spectrograms can be used as an input for key detection systems (and
    possibly should be if you have enough data), a simple chromagram averaged along
    the time dimension reveals this specific information much quicker. That is why
    spectrograms require complex models like CNNs while a chromagram can be easily
    analyzed by traditional models like logistic regression or decision trees.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管梅尔频谱图可以用作调性检测系统的输入（如果你有足够的数据，可能应该使用它），但沿时间维度平均的简单色调图能更快地揭示特定信息。这就是为什么频谱图需要像
    CNN 这样的复杂模型，而色调图则可以通过传统模型，如逻辑回归或决策树，轻松分析的原因。
- en: '**In summary**, the established spectrogram + CNN combination remains highly
    effective for many problems, provided you have enough data. However, with smaller
    datasets, it might make sense to revisit some feature engineering techniques from
    MIR or develop your own task-specific representations.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**，已建立的频谱图 + CNN 组合在许多问题中仍然非常有效，只要你有足够的数据。然而，针对较小的数据集，可能需要重新审视一些来自 MIR
    的特征工程技术，或开发自己特定任务的表示。'
- en: 'Tip 3: Leverage Pretrained Models or Embeddings'
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示 3：利用预训练模型或嵌入
- en: '![](../Images/fa31b750c204546c8248df9e884c5e9d.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa31b750c204546c8248df9e884c5e9d.png)'
- en: Banner generated with DALL-E 2 by the author.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 横幅由作者使用 DALL-E 2 生成。
- en: When data is scarce, one of the most effective strategies is to leverage pretrained
    models or embeddings. This approach allows you to **build upon existing knowledge**
    from models that have been trained on large datasets, thereby mitigating the limitations
    of your smaller dataset.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据稀缺时，最有效的策略之一是利用预训练模型或嵌入。这种方法可以让你**在现有知识的基础上构建**，利用在大规模数据集上训练的模型，从而缓解较小数据集的限制。
- en: Why Use Pretrained Models?
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么使用预训练模型？
- en: Pretrained models have already learned to identify and extract meaningful features
    from their training data. For instance, a model trained on genre classification
    has likely learned a variety of **meaningful musical patterns** during training.
    If we now want to build our own mood tagging model, it might make sense to use
    the pretrained genre model **as a starting point**.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型已经学会了从其训练数据中识别和提取有意义的特征。例如，一个在流派分类任务上训练的模型，很可能在训练过程中学到了多种**有意义的音乐模式**。如果我们现在想构建自己的情感标签模型，使用预训练的流派模型**作为起点**可能是有意义的。
- en: If the pretrained model was trained on a similar task, you can transfer their
    learned representations to your specific task. This process is known as *transfer
    learning*. Transfer learning can drastically reduce the amount of data and computational
    resources needed to train your own model from scratch.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预训练模型是在类似任务上训练的，你可以将它们学到的表示转移到你的特定任务中。这一过程被称为*迁移学习*。迁移学习可以大幅减少从零开始训练自己模型所需的数据量和计算资源。
- en: Popular Pretrained Models in Music AI
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音乐 AI 中的流行预训练模型
- en: A few years ago, the most common approach was to take pretrained models like
    genre classifiers and finetune them on specific tasks. Models like [MusiCNN](https://github.com/jordipons/musicnn)
    were commonly used for this.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，最常见的方法是使用像流派分类器这样的预训练模型，并将其微调以执行特定任务。像 [MusiCNN](https://github.com/jordipons/musicnn)
    这样的模型通常被用于这种情况。
- en: 'However, nowadays, it is more common to use pretrained models that were specifically
    trained to yield meaningful music embeddings, i.e. vector representations of songs.
    Here are three pretrained embedding models that are commonly used:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在更常见的是使用那些专门训练过的预训练模型，这些模型可以产生有意义的音乐嵌入，即歌曲的向量表示。以下是三种常用的预训练嵌入模型：
- en: '[Mert-v1](https://huggingface.co/m-a-p/MERT-v1-330M) by m-a-p'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Mert-v1](https://huggingface.co/m-a-p/MERT-v1-330M) 由 m-a-p 提供'
- en: '[CLAP](https://huggingface.co/laion/clap-htsat-unfused) by LAION'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[CLAP](https://huggingface.co/laion/clap-htsat-unfused) 由LAION提供'
- en: '[CLAP](https://github.com/microsoft/CLAP) by Microsoft'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[CLAP](https://github.com/microsoft/CLAP) 由微软提供'
- en: From my personal experience, I’ve had the best results using Microsoft’s CLAP
    for transfer learning and LAION CLAP for similarity search.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我个人的经验，使用微软的CLAP进行迁移学习，和使用LAION CLAP进行相似性搜索，效果最好。
- en: Different Ways to Leverage Pretrained Models
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用预训练模型的不同方式
- en: 'Pretrained models can be used in a variety of ways:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型可以以多种方式使用：
- en: '**Full Fine-Tuning:** Use a pretrained classification or embedding model and
    fine-tune it on a smaller dataset of task-specific data. This method often achieves
    optimal results, if you can afford to use the full, large model for training and
    inference and know how to implement it.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**完全微调**：使用一个预训练的分类模型或嵌入模型，并在一个较小的任务特定数据集上进行微调。如果你能够使用完整的大型模型进行训练和推理，并且知道如何实现它，这种方法通常能获得最佳结果。'
- en: '**Embeddings as Input Features**: A more resource-efficient approach can be
    to extract embeddings from a pretrained model to use them as inputs for a new,
    much smaller model. As these embeddings are often 500–1000 dimensional vectors,
    a smaller neural network with a few thousand parameters can be attached to fine-tune
    more efficiently. For smaller datasets, this method is **usually preferred over
    a full tine-tune**.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入作为输入特征**：一种更高效的资源使用方法是从预训练模型中提取嵌入，并将它们作为新模型的输入。由于这些嵌入通常是500到1000维的向量，可以附加一个具有几千个参数的较小神经网络来进行更高效的微调。对于小型数据集，这种方法**通常优于完全微调**。'
- en: '**Using Embeddings Directly**: Even without any fine-tuning, embeddings can
    be used directly. For instance, embeddings from pretrained models are commonly
    used for music similarity search. CLAP models can even be used for text-to-music
    retrieval or (although still rather poorly) for zero-shot classification, i.e.
    classification without training.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**直接使用嵌入**：即使没有任何微调，嵌入也可以直接使用。例如，来自预训练模型的嵌入通常用于音乐相似性搜索。CLAP模型甚至可以用于文本到音乐的检索，或者（尽管效果还不理想）用于零-shot分类，即没有训练的分类。'
- en: Leveraging embeddings from pretrained models can significantly enhance your
    Music AI projects. By building on the learned pattern-recognition of these models,
    you **avoid reinventing the wheel**. When data is scarce, pretrained models should
    always be considered.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 利用预训练模型的嵌入可以显著增强你的音乐AI项目。通过在这些模型的学习模式识别基础上构建，你**避免了重新发明轮子**。当数据稀缺时，预训练模型应该始终被考虑。
- en: Conclusion
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Don’t let data scarcity hold you back! Many use cases that required hundreds
    of thousands of training examples a few years ago have now essentially become
    commodities.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 不要让数据稀缺成为你的阻碍！许多几年前需要成千上万训练样本的使用案例，现在几乎已经成为商品。
- en: 'To achieve robust performance with small datasets, your number one priority
    should be not to waste any of your valuable data. Let’s review the main points
    from this article:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要在小数据集上实现稳健的性能，你的首要任务应该是不要浪费任何宝贵的数据。让我们回顾一下本文的要点：
- en: '**Data augmentation** is a great way to let your models learn from training
    examples several times with small but effective variations, increasing robustness.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据增强**是一种让模型通过小但有效的变化多次从训练样本中学习的好方法，从而增强其鲁棒性。'
- en: '**Smaller models and more efficient data representations** force your model
    to focus on the most important, underlying patterns in the data, avoiding overfitting.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更小的模型和更高效的数据表示**迫使你的模型专注于数据中最重要的、潜在的模式，从而避免过拟合。'
- en: '**Pretrained models** allow you to borrow some of the intelligence from larger
    AI systems through fine-tuning. No reason to train from scratch anymore!'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预训练模型**让你通过微调借用一些来自更大AI系统的智能。再也不需要从头开始训练了！'
- en: Of course, there are natural limitations to what you can achieve with small
    datasets. If you have 100 labeled tracks and your goal is to build a multi-label
    genre classifier with 10 genres and 30 subgenres, you will not get very far —
    even if you use all of my tricks.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，使用小数据集时你能实现的效果有其天然的局限性。如果你有100个标注样本，而你的目标是建立一个具有10个类别和30个子类别的多标签流派分类器，那么即使你使用了我所有的技巧，也不会走得太远。
- en: Still, I’ve developed surprisingly capable genre & mood classifiers with as
    little as 1000 labeled songs. Only 2 years ago, achieving this with such a small
    dataset would have been impossible. These democratization effects are one of the
    most exciting aspects of the current AI hype, in my opinion.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我已经开发出了令人惊讶的能力强大的流派和情绪分类器，仅用1000首标注歌曲。仅仅两年前，凭借这么小的数据集实现这一目标几乎是不可能的。我认为，这些去中心化效应是当前AI热潮中最令人兴奋的方面之一。
- en: If you have a small but high-quality music dataset and are considering using
    it for machine learning, now is the best time to give it a try!
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你有一个小而高质量的音乐数据集，并且正在考虑用它进行机器学习，现在正是尝试的最佳时机！
- en: Interested in Music AI?
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对音乐 AI 感兴趣吗？
- en: 'If you liked this article, you might want to check out some of my other work:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，或许你会想看看我其他的一些作品：
- en: '[“3 Music AI Breakthroughs to Expect in 2024”](https://medium.com/towards-data-science/3-music-ai-breakthroughs-to-expect-in-2024-2d945ae6b5fd).
    Medium Blog'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“2024年值得期待的三大音乐AI突破”](https://medium.com/towards-data-science/3-music-ai-breakthroughs-to-expect-in-2024-2d945ae6b5fd)。Medium博客'
- en: '[“The Human Element in a World of Generative AI Music”](https://www.youtube.com/watch?v=fr5PlnNGKVw).
    Video interview on the Audiosocket podcast'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“生成式AI音乐中的人类元素”](https://www.youtube.com/watch?v=fr5PlnNGKVw)。Audiosocket播客视频采访'
- en: “[How Google Used Your Data to Improve their Music AI](https://medium.com/towards-data-science/how-google-used-your-data-to-improve-their-music-ai-8948a1e85491)”.
    Medium Blog
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“谷歌如何利用你的数据来改进其音乐AI”](https://medium.com/towards-data-science/how-google-used-your-data-to-improve-their-music-ai-8948a1e85491)。Medium博客'
- en: You can also follow me on [Linkedin](https://www.linkedin.com/in/max-hilsdorf/)
    to stay updated about new papers and trends in Music AI.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过[Linkedin](https://www.linkedin.com/in/max-hilsdorf/)关注我，获取有关音乐AI的新论文和趋势的最新信息。
- en: '**Thanks for reading this article!**'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**感谢阅读本文！**'
