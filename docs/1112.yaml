- en: Starting ML Product Initiatives on the Right Foot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/starting-ml-product-initiatives-on-the-right-foot-cf24cbe163b3?source=collection_archive---------7-----------------------#2024-05-02](https://towardsdatascience.com/starting-ml-product-initiatives-on-the-right-foot-cf24cbe163b3?source=collection_archive---------7-----------------------#2024-05-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Top 3 lessons learned: the problem, the size, and the data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://annaviaba.medium.com/?source=post_page---byline--cf24cbe163b3--------------------------------)[![Anna
    Via](../Images/7e8fe5c1a485a789edad3a6d118bcf45.png)](https://annaviaba.medium.com/?source=post_page---byline--cf24cbe163b3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--cf24cbe163b3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--cf24cbe163b3--------------------------------)
    [Anna Via](https://annaviaba.medium.com/?source=post_page---byline--cf24cbe163b3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--cf24cbe163b3--------------------------------)
    ·9 min read·May 2, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e36df53a10143bc46a22e23ced3b2392.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Picture by*[](https://unsplash.com/es/@theyshane)[*Snapwire*](https://www.pexels.com/es-es/@snapwire/)*,
    on* [*Pexels*](https://www.pexels.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: '*This blog post is an updated version of part of a conference talk I gave on
    GOTO Amsterdam last year. The talk is also available to* [*watch online*](https://www.youtube.com/watch?v=dFxFYukNmvE)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: As a Machine Learning Product Manager, I am fascinated by the intersection of
    Machine Learning and Product Management, particularly when it comes to creating
    solutions that provide value and positive impact on the product, company, and
    users. However, managing to provide this value and positive impact is not an easy
    job. One of the main reasons for this complexity is the fact that, in Machine
    Learning initiatives developed for digital products, two sources of uncertainty
    intersect.
  prefs: []
  type: TYPE_NORMAL
- en: From a Product Management perspective, the field is uncertain by definition.
    It is hard to know the impact a solution will have on the product, how users will
    react to it, and if it will improve product and business metrics or not… Having
    to work with this uncertainty is what makes Product Managers potentially different
    from other roles like Project Managers or Product Owners. Product strategy, product
    discovery, sizing of opportunities, prioritization, agile, and fast experimentation,
    are some strategies to overcome this uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: The field of Machine Learning also has a strong link to uncertainty. I always
    like to say *“With predictive models, the goal is to predict things you don’t
    know are predictable”*. This translates into projects that are hard to scope and
    manage, not being able to commit beforehand to a quality deliverable (good model
    performance), and many initiatives staying forever as offline POCs. Defining well
    the problem to solve, initial data analysis and exploration, starting small, and
    being close to the product and business, are actions that can help tackle the
    ML uncertainty in projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mitigating this uncertainty risk from the beginning is key to developing initiatives
    that end up providing value to the product, company, and users. In this blog post,
    I’ll deep-dive into **my top 3 lessons learned when starting ML Product initiatives
    to manage this uncertainty from the beginning**. These learnings are mainly based
    on my experience, first as a Data Scientist and now as an ML Product Manager,
    and are helpful to improve the likelihood that an ML solution will reach production
    and achieve a positive impact. Get ready to explore:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with the problem, and define how predictions will be used from the beginning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start small, and maintain small if you can.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data, data, and data: quality, volume, and historic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Start with the problem (and define how predictions will be used)**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/45f503eef49b87c80d62825a075db218.png)'
  prefs: []
  type: TYPE_IMG
- en: Start from the right problem, [Steve Johnson](https://www.pexels.com/es-es/@steve/)
    @ [Pexels](https://www.pexels.com/)
  prefs: []
  type: TYPE_NORMAL
- en: I have to admit, I have learned this the hard way. I’ve been involved in projects
    where, once the model was developed and prediction performance was determined
    to be “good enough”, the model’s predictions weren’t really usable for any specific
    use case, or were not useful to help solve any problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many reasons this can happen, but the ones I’ve found more frequently
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution-driven initiatives**: even before GenAI, Machine Learning, and predictive
    models were “cool” solutions, and because of that some initiatives started from
    the ML solution: “*let’s try to predict churn*” (users or clients who abandon
    a company), “*let’s try to predict user segments*”… Current GenAI hype has worsened
    this trend, putting pressure on companies to integrate GenAI solutions “anywhere”
    they fit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of end-to-end design of the solution**: in very few cases, the predictive
    model is a standalone solution. Usually, though, models and their predictions
    are integrated into a bigger system to solve a specific use case or enable a new
    functionality. If this end-to-end solution is not defined from the beginning,
    it can happen that the model, once already implemented, is found to be useless.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To start an ML initiative on the right foot, it is key to **start with the good
    problem to solve**. This is foundational in Product Management, and recurrently
    reinforced product leaders like *Marty Cagan* and *Melissa Perri*. It includes
    product discovery (through user interviews, market research, data analysis…),
    and sizing and prioritization of opportunities (by taking into account quantitative
    and qualitative data).
  prefs: []
  type: TYPE_NORMAL
- en: Once opportunities are identified, the **second step is to explore potential
    solutions** for the problem, which should include Machine Learning and GenAI techniques,
    if they can help solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: If it is decided to try out a solution that includes the use of predictive models,
    the **third step would be to do an end-to-end definition and design of the solution
    or system**. This way, we can ensure the requirements on how to use the predictions
    by the system, influence the design and implementation of the predictive piece
    (what to predict, data to be used, real-time vs batch, technical feasibility checks…).
  prefs: []
  type: TYPE_NORMAL
- en: However, I’d like to add there might be **a notable exception in this topic**.
    Starting from GenAI solutions, instead of from the problem, can make sense if
    this technology ends up truly revolutionizing your sector or the world as we know
    it. There are a lot of discussions about this, but I’d say it is not clear yet
    whether that will happen or not. Up until now, we have seen this revolution in
    very specific sectors (customer support, marketing, design…) and related to people’s
    efficiency when performing certain tasks (coding, writing, creating…). For most
    companies though, unless it’s considered R&D work, delivering short/mid-term value
    still should mean focusing on problems, and considering GenAI just as any other
    potential solution to them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Start small (and maintain small if you can)**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tough experiences lead to this learning as well. Those experiences had in common
    a big ML project defined in a waterfall manner. The kind of project that is set
    to take 6 months, and follow the ML lifecycle phase by phase.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/341dd62046b3c92675775d17c5e303d8.png)'
  prefs: []
  type: TYPE_IMG
- en: Waterfall project planning following the ML Lifecycle phases, image by author
  prefs: []
  type: TYPE_NORMAL
- en: What could go wrong, right? Let me remind you of my previous quote *“With predictive
    models, the goal is to predict things you don’t know are predictable”*! In a situation
    like this, it can happen that you arrive at month 5 of the project, and during
    the model evaluation realize there is no way the model is able to predict whatever
    it needs to predict with good enough quality. Or worse, you arrive at month 6,
    with a super model deployed in production, and realize it is not bringing any
    value.
  prefs: []
  type: TYPE_NORMAL
- en: This risk combines with the uncertainties related to Product, and makes it mandatory
    to avoid big, waterfall initiatives if possible. This is not something new or
    related only to ML initiatives, so there is a lot we can learn from traditional
    software development, Agile, Lean, and other methodologies and mindsets. By starting
    small, validating assumptions soon and continuously, and iteratively experimenting
    and scaling, we can effectively mitigate this risk, adapt to insights and be more
    cost-efficient.
  prefs: []
  type: TYPE_NORMAL
- en: While these principles are well-established in traditional software and product
    development, their application to ML initiatives is a bit more complex, as it
    is not easy to define “small” for an ML model and deployment. There are some approaches,
    though, that can help start small in ML initiatives.
  prefs: []
  type: TYPE_NORMAL
- en: '**Rule-based approaches**, simplifying a predictive model through a decision
    tree. This way, “predictions” can be easily implemented as “if-else statements”
    in production as part of the functionality or system, without the need to deploy
    a model.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Proofs of Concept** (POCs), as a way to validate offline the predictive feasibility
    of the ML solution, and hint on the potential (or not) of the predictive step
    once in production.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Minimum Viable Products** (MVPs), to first focus on essential features, functionalities,
    or user segments, and expand the solution only if the value has been proven. For
    an ML model this can mean, for example, only the most straightforward, priority
    input features, or predicting only for a segment of data points.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Buy instead of build,** to leverage existing ML solutions or platforms to
    help reduce development time and initial costs. Only when proved valuable and
    costs increase too much, might be the right time to decide to develop the ML solution
    in-house.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using GenAI as an MVP,** for some use cases (especially if they involve text
    or images), genAI APIs can be used as a first approach to solve the prediction
    step of the system. Tasks like classifying text, sentiment analysis, or image
    detection, where GenAI models deliver impressive results. When the value is validated
    and if costs increase too much, the team can decide to build a specific “traditional”
    ML model in-house.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that using GenAI models for image or text classification, while possible
    and fast, means using a way too big an complex model (expensive, lack of control,
    hallucinations…) for something that could be predicted with a much simpler and
    controllable one. A fun analogy would be the idea of *delivering a pizza with
    a truck*: it is feasible, but why not just use a bike?'
  prefs: []
  type: TYPE_NORMAL
- en: Data, data, and data (quality, volume, historic)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/4241612c7a1a70ec4a38941ac0460f1f.png)'
  prefs: []
  type: TYPE_IMG
- en: Picture by [Tima Miroshnichenko](https://www.pexels.com/es-es/@tima-miroshnichenko/),
    on [Pexels](https://www.pexels.com/)
  prefs: []
  type: TYPE_NORMAL
- en: Data is THE recurring problem Data Scientist and ML teams encounter when starting
    ML initiatives. How many times have you been surprised by data with duplicates,
    errors, missing batches, weird values… And how different that is from the toy
    datasets you find in online courses!
  prefs: []
  type: TYPE_NORMAL
- en: 'It can also happen that the data you need is simply not there: the tracking
    of the specific event was never implemented, collection and proper ETLs where
    implemented recently… I have experienced how this translates into having to wait
    some months to be able to start a project with enough historic and volume data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All this relates to the adage “*Garbage in, garbage out*”: ML models are only
    as good as the data they’re trained on. Many times, solutions have a bigger potential
    to be improve by improving the data than by improving the models ([Data Centric
    AI](https://datacentricai.org/)). Data needs to be sufficient in volume, historic
    (data generated during years can bring more value than the same volume generated
    in just a week), and quality. To achieve that, mature data governance, collection,
    cleaning, and preprocessing are critical.'
  prefs: []
  type: TYPE_NORMAL
- en: From the **ethical AI** point of view, data is also a primary source of bias
    and discrimination, so acknowledging that and taking action to mitigate these
    risks is paramount. Considering data governance principles, privacy and regulatory
    compliance (e.g. EU’s *GDPR*), is also key to ensure a responsible use of data
    (especially when dealing with personal data).
  prefs: []
  type: TYPE_NORMAL
- en: 'With **GenAI models** this is pivoting: huge volumes of data are already used
    to train them. When using these types of models, we might not need volume and
    quality data for training, but we might need it for fine-tuning (see [Good Data
    = Good GenAI](https://medium.com/mit-initiative-on-the-digital-economy/good-data-good-genai-930c7ff83fe1)),
    or to construct the prompts (nurture the context, few-shot learning, Retrieval
    Augmented Generation… — I explained all these concepts in a [previous post](https://medium.com/towards-data-science/the-4-new-trendy-ai-concepts-and-their-potential-in-digital-products-cf5e1b85bff9)!).'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to note that by using these models we are losing control of
    the data used to train them, and we can suffer from the lack of quality or type
    of data used there: there are many known examples of bias and discrimination in
    GenAI outputs that can negatively impact our solution. A good example was Bloomberg’s
    article on how “[How ChatGPT is a recruiter’s dream tool — tests show there’s
    racial bias](https://www.bloomberg.com/graphics/2024-openai-gpt-hiring-racial-discrimination/)”.
    [LLM leaderboards testing for biases](https://ai-sandbox.list.lu/llm-leaderboard/),
    or [LLMs specifically trained to avoid these biases](https://www.latimer.ai/)
    can be useful in this sense.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a00a75709821c3066751fe9a165e9cbb.png)'
  prefs: []
  type: TYPE_IMG
- en: Gender bias example with ChatGPT (prompting on May 1st 2024)
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping it up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We started this blogpost discussing what makes ML Product initiatives especially
    tricky: the combination of the uncertainty related to developing solutions in
    digital products, with the uncertainty related to trying to predict things through
    the use of ML models.'
  prefs: []
  type: TYPE_NORMAL
- en: It is comforting to know there are actionable steps and strategies available
    to mitigate these risks. Yet, perhaps the best ones, are related to starting the
    initiatives off on the right foot! To do so, it can really help to start with
    the right problem and an end-to-end design of the solution, reduce initial scope,
    and prioritize data quality, volume, and historical accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this post was useful and that it will help you challenge how you start
    working in future new initiatives related to ML Products!
  prefs: []
  type: TYPE_NORMAL
