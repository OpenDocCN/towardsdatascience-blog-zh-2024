# ä½¿ç”¨ mergekit åˆå¹¶å¤§è¯­è¨€æ¨¡å‹

> åŸæ–‡ï¼š[`towardsdatascience.com/merge-large-language-models-with-mergekit-2118fb392b54?source=collection_archive---------0-----------------------#2024-01-08`](https://towardsdatascience.com/merge-large-language-models-with-mergekit-2118fb392b54?source=collection_archive---------0-----------------------#2024-01-08)

## è½»æ¾åˆ›å»ºä½ è‡ªå·±çš„æ¨¡å‹ï¼Œæ— éœ€ GPUï¼

[](https://medium.com/@mlabonne?source=post_page---byline--2118fb392b54--------------------------------)![Maxime Labonne](https://medium.com/@mlabonne?source=post_page---byline--2118fb392b54--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2118fb392b54--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2118fb392b54--------------------------------) [Maxime Labonne](https://medium.com/@mlabonne?source=post_page---byline--2118fb392b54--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2118fb392b54--------------------------------) Â·é˜…è¯»æ—¶é—´ï¼š11 åˆ†é’ŸÂ·2024 å¹´ 1 æœˆ 8 æ—¥

--

![](img/3250f7b46dc7b58c13e186d2b0230d38.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

æ¨¡å‹åˆå¹¶æ˜¯ä¸€ç§**å°†ä¸¤ä¸ªæˆ–æ›´å¤š LLM æ¨¡å‹**åˆå¹¶ä¸ºå•ä¸ªæ¨¡å‹çš„æŠ€æœ¯ã€‚è¿™æ˜¯ä¸€ç§ç›¸å¯¹è¾ƒæ–°ä¸”å®éªŒæ€§çš„æ–¹æ³•ï¼Œç”¨äºä»¥ä½æˆæœ¬ï¼ˆæ— éœ€ GPUï¼‰åˆ›å»ºæ–°æ¨¡å‹ã€‚æ¨¡å‹åˆå¹¶æ•ˆæœå‡ºä¹æ„æ–™åœ°å¥½ï¼Œå¹¶ä¸”äº§ç”Ÿäº†è®¸å¤šåœ¨[Open LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)ä¸Šæ’åé å‰çš„é¡¶å°–æ¨¡å‹ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[mergekit](https://github.com/cg123/mergekit)åº“æ¥å®ç°ã€‚æ›´å…·ä½“åœ°ï¼Œæˆ‘ä»¬å°†å›é¡¾å››ç§åˆå¹¶æ–¹æ³•ï¼Œå¹¶æä¾›é…ç½®ç¤ºä¾‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ mergekit åˆ›å»ºæˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹ï¼Œ[Marcoro14â€“7B-slerp](https://huggingface.co/mlabonne/Marcoro14-7B-slerp)ï¼Œè¯¥æ¨¡å‹åœ¨ Open LLM æ’è¡Œæ¦œï¼ˆ2024 å¹´ 1 æœˆ 2 æ—¥ï¼‰ä¸Šè¡¨ç°æœ€ä½³ã€‚

ä»£ç å¯åœ¨[GitHub](https://github.com/mlabonne/llm-course/blob/main/Mergekit.ipynb)å’Œ[Google Colab](https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing)ä¸Šæ‰¾åˆ°ã€‚æˆ‘æ¨èä½¿ç”¨æˆ‘çš„è‡ªåŠ¨åŒ–ç¬”è®°æœ¬æ¥è½»æ¾è¿è¡Œ mergekitï¼š[ğŸ¥± LazyMergekit](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing)ã€‚

*ç‰¹åˆ«æ„Ÿè°¢* [*Charles Goddard*](https://www.linkedin.com/in/charles-goddard-7b6797b/)*ï¼Œmergekit åº“çš„ä½œè€…ï¼Œæ„Ÿè°¢ä»–å®¡é˜…æœ¬æ–‡ã€‚*

![](img/c43a26493b1d996b35c6c341845a3a97.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

# ğŸ¤ åˆå¹¶ç®—æ³•

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»[mergekit](https://github.com/cg123/mergekit)ä¸­ç›®å‰å®ç°çš„å››ç§æ–¹æ³•ã€‚è¯·æ³¨æ„ï¼Œè¿˜æœ‰å…¶ä»–æ–¹æ³•ï¼Œå¦‚[çº¿æ€§æ’å€¼](https://github.com/cg123/mergekit/tree/1011ef3a84e4c5545473602baf7ef32d535044a9#linear)å’Œ[ä»»åŠ¡ç®—æœ¯](https://arxiv.org/abs/2212.04089)ã€‚å¦‚æœä½ å¯¹æ¨¡å‹åˆå¹¶çš„è®ºæ–‡æ„Ÿå…´è¶£ï¼Œæ¨èæŸ¥çœ‹[è¿™ä¸ªä¼˜ç§€çš„åˆé›†](https://huggingface.co/collections/osanseviero/model-merging-65097893623330a3a51ead66)ã€‚

## 1\. SLERP

**çƒé¢çº¿æ€§æ’å€¼**ï¼ˆSLERPï¼‰æ˜¯ä¸€ç§åœ¨ä¸¤ä¸ªå‘é‡ä¹‹é—´å¹³æ»‘æ’å€¼çš„æ–¹æ³•ã€‚å®ƒä¿æŒæ’å®šçš„å˜åŒ–é€Ÿç‡ï¼Œå¹¶ä¿ç•™å‘é‡æ‰€å¤„çƒé¢ç©ºé—´çš„å‡ ä½•å±æ€§ã€‚

æœ‰å‡ ä¸ªç†ç”±æ›´å€¾å‘äºä½¿ç”¨ SLERP è€Œä¸æ˜¯ä¼ ç»Ÿçš„çº¿æ€§æ’å€¼ã€‚ä¾‹å¦‚ï¼Œåœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œçº¿æ€§æ’å€¼å¯èƒ½ä¼šå¯¼è‡´æ’å€¼å‘é‡çš„**å¤§å°å‡å°**ï¼ˆå³å‡å°‘æƒé‡çš„å°ºåº¦ï¼‰ã€‚æ­¤å¤–ï¼Œæƒé‡çš„æ–¹å‘å˜åŒ–é€šå¸¸ä»£è¡¨äº†**æ›´æœ‰æ„ä¹‰çš„ä¿¡æ¯**ï¼ˆå¦‚ç‰¹å¾å­¦ä¹ å’Œè¡¨ç¤ºï¼‰ï¼Œè€Œä¸æ˜¯å˜åŒ–çš„å¤§å°ã€‚

SLERP çš„å®ç°æ­¥éª¤å¦‚ä¸‹ï¼š

1.  å°†è¾“å…¥å‘é‡æ ‡å‡†åŒ–ä¸ºå•ä½é•¿åº¦ï¼Œç¡®ä¿å®ƒä»¬è¡¨ç¤ºçš„æ˜¯æ–¹å‘è€Œéå¤§å°ã€‚

1.  ä½¿ç”¨å®ƒä»¬çš„ç‚¹ç§¯è®¡ç®—è¿™äº›å‘é‡ä¹‹é—´çš„è§’åº¦ã€‚

1.  å¦‚æœå‘é‡å‡ ä¹å…±çº¿ï¼Œåˆ™é»˜è®¤ä½¿ç”¨çº¿æ€§æ’å€¼ä»¥æé«˜æ•ˆç‡ã€‚å¦åˆ™ï¼ŒSLERP ä¼šæ ¹æ®æ’å€¼å› å­`t`ï¼ˆ`t=0` = 100%çš„ç¬¬ä¸€ä¸ªå‘é‡ï¼Œ`t=1` = 100%çš„ç¬¬äºŒä¸ªæ¨¡å‹ï¼‰å’Œå‘é‡ä¹‹é—´çš„è§’åº¦è®¡ç®—ç¼©æ”¾å› å­ã€‚

1.  è¿™äº›å› ç´ ç”¨äºåŠ æƒåŸå§‹å‘é‡ï¼Œç„¶åå°†å…¶æ±‚å’Œä»¥å¾—åˆ°æ’å€¼å‘é‡ã€‚

SLERP ç›®å‰æ˜¯æœ€æµè¡Œçš„åˆå¹¶æ–¹æ³•ï¼Œä½†å®ƒä»…é™äºä¸€æ¬¡åˆå¹¶ä¸¤ä¸ªæ¨¡å‹ã€‚ä»ç„¶å¯ä»¥å±‚æ¬¡åŒ–åœ°åˆå¹¶å¤šä¸ªæ¨¡å‹ï¼Œå¦‚åœ¨[Mistral-7B-Merge-14-v0.1](https://huggingface.co/EmbeddedLLM/Mistral-7B-Merge-14-v0.1)ä¸­æ‰€ç¤ºã€‚

*é…ç½®ç¤ºä¾‹ï¼š*

```py
slices:
  - sources:
      - model: OpenPipe/mistral-ft-optimized-1218
        layer_range: [0, 32]
      - model: mlabonne/NeuralHermes-2.5-Mistral-7B
        layer_range: [0, 32]
merge_method: slerp
base_model: OpenPipe/mistral-ft-optimized-1218
parameters:
  t:
    - filter: self_attn
      value: [0, 0.5, 0.3, 0.7, 1]
    - filter: mlp
      value: [1, 0.5, 0.7, 0.3, 0]
    - value: 0.5
dtype: bfloat16
```

è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„ SLERP é…ç½®ï¼Œåº”ç”¨äºä¸¤ä¸ªæ¨¡å‹çš„æ¯ä¸€å±‚ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬è¾“å…¥ä¸€ä¸ªå€¼æ¢¯åº¦ä½œä¸ºæ’å€¼å› å­`t`ã€‚è‡ªæ³¨æ„åŠ›å±‚å’Œ MLP å±‚çš„å‚æ•°å°†ä½¿ç”¨[OpenPipe/mistral-ft-optimized-1218](https://huggingface.co/OpenPipe/mistral-ft-optimized-1218)å’Œ[mlabonne/NeuralHermes-2.5-Mistral-7B](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B)çš„ä¸åŒç»„åˆã€‚å…¶ä»–å±‚åˆ™æ˜¯ä¸¤ä¸ªæ¨¡å‹çš„ 50/50 æ··åˆã€‚

ä½ å¯ä»¥åœ¨ Hugging Face Hub ä¸Šæ‰¾åˆ°æœ€ç»ˆæ¨¡å‹ï¼š[mlabonne/NeuralPipe-7B-slerp](https://huggingface.co/mlabonne/NeuralPipe-7B-slerp)ã€‚

## 2\. TIES

åœ¨[Yadav ç­‰äºº](https://arxiv.org/abs/2306.01708)çš„[è®ºæ–‡](https://arxiv.org/abs/2306.01708)ä¸­æå‡ºçš„**TIES-Merging**æ—¨åœ¨é«˜æ•ˆåœ°å°†å¤šä¸ªä»»åŠ¡ç‰¹å®šçš„æ¨¡å‹åˆå¹¶ä¸ºä¸€ä¸ªå¤šä»»åŠ¡æ¨¡å‹ã€‚å®ƒè§£å†³äº†æ¨¡å‹åˆå¹¶ä¸­çš„ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼š

+   **æ¨¡å‹å‚æ•°ä¸­çš„å†—ä½™**ï¼šå®ƒè¯†åˆ«å¹¶æ¶ˆé™¤ä»»åŠ¡ç‰¹å®šæ¨¡å‹ä¸­çš„å†—ä½™å‚æ•°ã€‚é€šè¿‡å…³æ³¨å¾®è°ƒè¿‡ç¨‹ä¸­æ‰€åšçš„å˜åŒ–ï¼Œè¯†åˆ«æœ€é‡è¦çš„å‰ k%å˜åŒ–ï¼Œå¹¶ä¸¢å¼ƒå…¶ä½™éƒ¨åˆ†ã€‚

+   **å‚æ•°ç¬¦å·ä¹‹é—´çš„åˆ†æ­§**ï¼šå½“ä¸åŒæ¨¡å‹å¯¹åŒä¸€å‚æ•°æå‡ºç›¸åè°ƒæ•´æ—¶ï¼Œä¼šäº§ç”Ÿå†²çªã€‚TIES-Merging é€šè¿‡åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç¬¦å·å‘é‡æ¥è§£å†³è¿™äº›å†²çªï¼Œè¡¨ç¤ºæ‰€æœ‰æ¨¡å‹ä¸­æœ€ä¸»å¯¼çš„å˜åŒ–æ–¹å‘ã€‚

TIES-Merging åˆ†ä¸ºä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š

1.  **ä¿®å‰ª**ï¼šé€šè¿‡ä»…ä¿ç•™æœ€é‡è¦å‚æ•°ï¼ˆå¯†åº¦å‚æ•°ï¼‰çš„éƒ¨åˆ†ï¼Œé‡ç½®å…¶ä½™éƒ¨åˆ†ä¸ºé›¶ï¼Œä»è€Œå‡å°‘ä»»åŠ¡ç‰¹å®šæ¨¡å‹ä¸­çš„å†—ä½™ã€‚

1.  **é€‰æ‹©ç¬¦å·**ï¼šé€šè¿‡åŸºäºç´¯ç§¯å¤§å°çš„æœ€ä¸»å¯¼æ–¹å‘ï¼ˆæ­£æˆ–è´Ÿï¼‰åˆ›å»ºç»Ÿä¸€ç¬¦å·å‘é‡ï¼Œè§£å†³ä¸åŒæ¨¡å‹ä¹‹é—´çš„ç¬¦å·å†²çªã€‚

1.  **ä¸ç›¸äº¤åˆå¹¶**ï¼šå¹³å‡ä¸ç»Ÿä¸€ç¬¦å·å‘é‡å¯¹é½çš„å‚æ•°å€¼ï¼Œæ’é™¤é›¶å€¼ã€‚

ä¸ SLERP ä¸åŒï¼ŒTIES å¯ä»¥ä¸€æ¬¡åˆå¹¶å¤šä¸ªæ¨¡å‹ã€‚

*é…ç½®ç¤ºä¾‹ï¼š*

```py
models:
  - model: mistralai/Mistral-7B-v0.1
    # no parameters necessary for base model
  - model: OpenPipe/mistral-ft-optimized-1218
    parameters:
      density: 0.5
      weight: 0.5
  - model: mlabonne/NeuralHermes-2.5-Mistral-7B
    parameters:
      density: 0.5
      weight: 0.3
merge_method: ties
base_model: mistralai/Mistral-7B-v0.1
parameters:
  normalize: true
dtype: float16
```

ä½¿ç”¨æ­¤é…ç½®ï¼Œæˆ‘ä»¬ä½¿ç”¨ Mistral-7B ä½œä¸ºåŸºç¡€æ¨¡å‹æ¥è®¡ç®—å¢é‡æƒé‡ã€‚æˆ‘ä»¬åˆå¹¶ç›¸åŒçš„ä¸¤ä¸ªæ¨¡å‹ï¼š[mistral-ft-optimized-1218](https://huggingface.co/OpenPipe/mistral-ft-optimized-1218)ï¼ˆ50%ï¼‰å’Œ[NeuralHermes-2.5-Mistral-7B](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B)ï¼ˆ30%ï¼‰ï¼Œå¹¶è¿›è¡Œå½’ä¸€åŒ–ã€‚è¿™é‡Œçš„å¯†åº¦è¡¨ç¤ºæˆ‘ä»¬åªä¿ç•™æ¯ä¸ªæ¨¡å‹ 50%çš„å‚æ•°ï¼ˆå¦ä¸€åŠæ¥è‡ªåŸºç¡€æ¨¡å‹ï¼‰ã€‚

è¯·æ³¨æ„ï¼Œé…ç½®ä¸­çš„æƒé‡æ€»å’Œä¸ç­‰äº 1ï¼Œä½†`normalize: true`å‚æ•°ä¼šè‡ªåŠ¨åœ¨å†…éƒ¨å¯¹å…¶è¿›è¡Œå½’ä¸€åŒ–ã€‚è¯¥é…ç½®çµæ„Ÿæ¥è‡ªäº[OpenHermes-2.5-neural-chat-7b-v3â€“1â€“7B](https://huggingface.co/Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B)ä½œè€…æä¾›çš„å‚æ•°ã€‚

æ‚¨å¯ä»¥åœ¨ Hugging Face Hub ä¸Šæ‰¾åˆ°æœ€ç»ˆæ¨¡å‹ï¼š[mlabonne/NeuralPipe-7B-ties](https://huggingface.co/mlabonne/NeuralPipe-7B-ties)ã€‚

## 3\. DARE

ç”± Yu ç­‰äººï¼ˆ2023 å¹´ï¼‰æå‡ºçš„[DARE](https://arxiv.org/abs/2311.03099)é‡‡ç”¨äº†ç±»ä¼¼äº TIES çš„æ–¹æ³•ï¼Œä¸»è¦æœ‰ä¸¤ä¸ªä¸åŒä¹‹å¤„ï¼š

+   **å‰ªæ**ï¼šDARE å°†å¾®è°ƒåçš„æƒé‡éšæœºé‡ç½®ä¸ºå…¶åŸå§‹å€¼ï¼ˆå³åŸºç¡€æ¨¡å‹çš„å€¼ï¼‰ã€‚

+   **é‡æ–°ç¼©æ”¾**ï¼šDARE é€šè¿‡é‡æ–°ç¼©æ”¾æƒé‡æ¥ä¿æŒæ¨¡å‹è¾“å‡ºçš„æœŸæœ›å€¼å¤§è‡´ä¸å˜ã€‚å®ƒå°†ä¸¤ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰æ¨¡å‹çš„é‡æ–°ç¼©æ”¾æƒé‡ä¸åŸºç¡€æ¨¡å‹çš„æƒé‡é€šè¿‡ä¸€ä¸ªç¼©æ”¾å› å­ç›¸åŠ ã€‚

Mergekit å¯¹æ­¤æ–¹æ³•çš„å®ç°æœ‰ä¸¤ç§å½¢å¼ï¼šä¸€ç§æ˜¯å¸¦æœ‰ TIES ç¬¦å·é€‰æ‹©æ­¥éª¤ï¼ˆ`dare_ties`ï¼‰ï¼Œå¦ä¸€ç§æ˜¯æ²¡æœ‰çš„ï¼ˆ`dare_linear`ï¼‰ã€‚

*é…ç½®ç¤ºä¾‹ï¼š*

```py
models:
  - model: mistralai/Mistral-7B-v0.1
    # No parameters necessary for base model
  - model: samir-fama/SamirGPT-v1
    parameters:
      density: 0.53
      weight: 0.4
  - model: abacusai/Slerp-CM-mist-dpo
    parameters:
      density: 0.53
      weight: 0.3
  - model: EmbeddedLLM/Mistral-7B-Merge-14-v0.2
    parameters:
      density: 0.53
      weight: 0.3
merge_method: dare_ties
base_model: mistralai/Mistral-7B-v0.1
parameters:
  int8_mask: true
dtype: bfloat16
```

åœ¨æ­¤é…ç½®ä¸­ï¼Œæˆ‘ä»¬åŸºäº Mistral-7B åˆå¹¶äº†ä¸‰ç§ä¸åŒçš„æ¨¡å‹ï¼Œä½¿ç”¨äº†`dare_ties`ã€‚è¿™æ¬¡ï¼Œæˆ‘é€‰æ‹©äº†æƒé‡ä¹‹å’Œä¸º 1 çš„ç»„åˆï¼ˆæƒé‡å’Œåº”è¯¥åœ¨ 0.9 åˆ° 1.1 ä¹‹é—´ï¼‰ã€‚å¯†åº¦å‚æ•°æ¯”è®ºæ–‡ä¸­æ¨èçš„å€¼ï¼ˆ<0.5ï¼‰ç¨é«˜ï¼Œä½†çœ‹èµ·æ¥å®ƒ consistently ç»™å‡ºäº†æ›´å¥½çš„ç»“æœï¼ˆå‚è§[è¿™ä¸ªè®¨è®º](https://github.com/cg123/mergekit/issues/26)ï¼‰ã€‚

ä½ å¯ä»¥åœ¨ Hugging Face Hub ä¸Šæ‰¾åˆ°å®ƒï¼Œåœ°å€æ˜¯[mlabonne/Daredevil-7B](https://huggingface.co/mlabonne/Daredevil-7B)ã€‚å®ƒä¹Ÿæ˜¯æœ¬æ–‡ä¸­è¡¨ç°æœ€å¥½çš„åˆå¹¶æ¨¡å‹ï¼Œç”šè‡³è¶…è¿‡äº† Marcoro14â€“7B-slerpã€‚

## 4\. é€ä¼ 

é€ä¼ æ–¹æ³•ä¸ä¹‹å‰çš„å‡ ç§æ–¹æ³•æœ‰æ˜¾è‘—ä¸åŒã€‚é€šè¿‡å°†æ¥è‡ªä¸åŒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å±‚çº§è¿›è¡Œæ‹¼æ¥ï¼Œå®ƒå¯ä»¥ç”Ÿæˆå…·æœ‰**ç‹¬ç‰¹å‚æ•°æ•°é‡**çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œä¸¤ä¸ª 7B å‚æ•°æ¨¡å‹åˆå¹¶ç”Ÿæˆ 9B æ¨¡å‹ï¼‰ã€‚è¿™äº›æ¨¡å‹é€šå¸¸è¢«ç¤¾åŒºç§°ä¸ºâ€œå¼—å…°è‚¯åˆå¹¶â€æˆ–â€œå¼—å…°è‚¯æ–¯å¦æ¨¡å‹â€ã€‚

è¿™ä¸ªæŠ€æœ¯éå¸¸å®éªŒæ€§ï¼Œä½†å®ƒæˆåŠŸåœ°åˆ›é€ äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ¨¡å‹ï¼Œæ¯”å¦‚ä½¿ç”¨ä¸¤ä¸ª Llama 2 70B æ¨¡å‹åˆå¹¶çš„[goliath-120b](https://huggingface.co/alpindale/goliath-120b)ã€‚æœ€è¿‘å‘å¸ƒçš„[SOLAR-10.7B-v1.0](https://huggingface.co/upstage/SOLAR-10.7B-v1.0)ä¹Ÿé‡‡ç”¨äº†ç›¸åŒçš„ç†å¿µï¼Œç§°ä¸ºæ·±åº¦å‘ä¸Šæ‰©å±•ï¼Œè¯¦è§ä»–ä»¬çš„è®ºæ–‡[è¿™é‡Œ](https://arxiv.org/abs/2312.15166)ã€‚

*é…ç½®ç¤ºä¾‹ï¼š*

```py
slices:
  - sources:
    - model: OpenPipe/mistral-ft-optimized-1218
      layer_range: [0, 32]
  - sources:
    - model: mlabonne/NeuralHermes-2.5-Mistral-7B
      layer_range: [24, 32]
merge_method: passthrough
dtype: bfloat16
```

ç»“æœçš„å¼—å…°è‚¯åˆå¹¶å°†æ‹¥æœ‰æ¥è‡ªç¬¬ä¸€ä¸ªæ¨¡å‹çš„æ‰€æœ‰ 32 å±‚ï¼Œä»¥åŠæ¥è‡ªç¬¬äºŒä¸ªæ¨¡å‹çš„ 8 å±‚ã€‚è¿™åˆ›å»ºäº†ä¸€ä¸ªæ€»å…± 40 å±‚å’Œ 8.99B å‚æ•°çš„å¼—å…°è‚¯åˆå¹¶æ¨¡å‹ã€‚æ­¤é…ç½®çµæ„Ÿæ¥è‡ªäº[GML-Mistral-merged-v1](https://huggingface.co/zyh3826/GML-Mistral-merged-v1)ã€‚

ä½ å¯ä»¥åœ¨ Hugging Face Hub ä¸Šæ‰¾åˆ°æœ€ç»ˆæ¨¡å‹ï¼Œåœ°å€æ˜¯[mlabonne/NeuralPipe-9B-merged](https://huggingface.co/mlabonne/NeuralPipe-9B-merged)ã€‚

# ğŸ’» åˆå¹¶ä½ è‡ªå·±çš„æ¨¡å‹

åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ mergekit åŠ è½½åˆå¹¶é…ç½®ï¼Œè¿è¡Œå®ƒï¼Œå¹¶å°†åˆå¹¶åçš„æ¨¡å‹ä¸Šä¼ åˆ° Hugging Face Hubã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬ç›´æ¥ä»æºä»£ç å®‰è£… mergekitï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
!git clone https://github.com/cg123/mergekit.git
!cd mergekit && pip install -q -e .
```

åœ¨æ¥ä¸‹æ¥çš„ä»£ç å—ä¸­ï¼Œæˆ‘ä»¬åŠ è½½åˆå¹¶é…ç½®æ–‡ä»¶ï¼ˆYAML æ ¼å¼ï¼‰ã€‚æˆ‘ä»¬è¿˜æŒ‡å®šäº†åˆå¹¶åæ¨¡å‹çš„åç§°ï¼Œä»¥ä¾›ä»¥åä½¿ç”¨ã€‚ä½ å¯ä»¥å°†ä¸Šä¸€èŠ‚ä¸­çš„ä»»ä½•é…ç½®å¤åˆ¶/ç²˜è´´åˆ°è¿™é‡Œã€‚

è¿™æ¬¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹ï¼š[Marcoroni-7B-v3](https://huggingface.co/AIDC-ai-business/Marcoroni-7B-v3) å’Œ [Mistral-7B-Merge-14-v0.1](https://huggingface.co/EmbeddedLLM/Mistral-7B-Merge-14-v0.1)ï¼Œå¹¶ä½¿ç”¨ SLERP æ–¹æ³•å°†å®ƒä»¬åˆå¹¶ã€‚æˆ‘ä»¬å°†é…ç½®ä¿å­˜ä¸º yaml æ–‡ä»¶ï¼Œä»¥ä¾¿ä½œä¸ºè¾“å…¥ä½¿ç”¨åœ¨åˆå¹¶å‘½ä»¤ä¸­ã€‚

```py
import yaml

MODEL_NAME = "Marcoro14-7B-slerp"
yaml_config = """
slices:
  - sources:
      - model: AIDC-ai-business/Marcoroni-7B-v3
        layer_range: [0, 32]
      - model: EmbeddedLLM/Mistral-7B-Merge-14-v0.1
        layer_range: [0, 32]
merge_method: slerp
base_model: AIDC-ai-business/Marcoroni-7B-v3
parameters:
  t:
    - filter: self_attn
      value: [0, 0.5, 0.3, 0.7, 1]
    - filter: mlp
      value: [1, 0.5, 0.7, 0.3, 0]
    - value: 0.5
dtype: bfloat16

"""

# Save config as yaml file
with open('config.yaml', 'w', encoding="utf-8") as f:
    f.write(yaml_config)
```

æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å‚æ•°è¿è¡Œåˆå¹¶å‘½ä»¤ï¼š

+   `--copy-tokenizer` ç”¨äºä»åŸºç¡€æ¨¡å‹å¤åˆ¶åˆ†è¯å™¨

+   `--allow-crimes` å’Œ `--out-shard-size` ç”¨äºå°†æ¨¡å‹åˆ†å‰²æˆè¾ƒå°çš„åˆ†ç‰‡ï¼Œä»¥ä¾¿åœ¨ä½å†…å­˜çš„ CPU ä¸Šè®¡ç®—ã€‚

+   `--lazy-unpickle` ä»¥å¯ç”¨å®éªŒæ€§çš„æ‡’åŠ è½½è§£åŒ…å™¨ï¼Œä»è€Œå‡å°‘å†…å­˜ä½¿ç”¨ã€‚

æ­¤å¤–ï¼Œä¸€äº›æ¨¡å‹å¯èƒ½éœ€è¦`--trust_remote_code`æ ‡å¿—ï¼ˆMistral-7B ä¸éœ€è¦æ­¤æ ‡å¿—ï¼‰ã€‚

è¿™ä¸ªå‘½ä»¤å°†ä¸‹è½½åˆå¹¶é…ç½®ä¸­åˆ—å‡ºçš„æ‰€æœ‰æ¨¡å‹çš„æƒé‡ï¼Œå¹¶è¿è¡Œé€‰å®šçš„åˆå¹¶æ–¹æ³•ï¼ˆå¤§çº¦éœ€è¦ 10 åˆ†é’Ÿï¼‰ã€‚

```py
# Merge models
!mergekit-yaml config.yaml merge --copy-tokenizer --allow-crimes --out-shard-size 1B --lazy-unpickl
```

æ¨¡å‹ç°åœ¨å·²ç»åˆå¹¶å¹¶ä¿å­˜åœ¨`merge`ç›®å½•ä¸­ã€‚åœ¨ä¸Šä¼ ä¹‹å‰ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯å¤ç°æ€§æ‰€éœ€ä¿¡æ¯çš„ README æ–‡ä»¶ã€‚ä»¥ä¸‹ä»£ç å—å®šä¹‰äº†ä¸€ä¸ª Jinja æ¨¡æ¿ï¼Œå¹¶è‡ªåŠ¨å¡«å……æ¥è‡ªåˆå¹¶é…ç½®çš„æ•°æ®ã€‚

```py
!pip install -qU huggingface_hub

from huggingface_hub import ModelCard, ModelCardData
from jinja2 import Template

username = "mlabonne"

template_text = """
---
license: apache-2.0
tags:
- merge
- mergekit
- lazymergekit
{%- for model in models %}
- {{ model }}
{%- endfor %}
---

# {{ model_name }}

{{ model_name }} is a merge of the following models using [mergekit](https://github.com/cg123/mergekit):

{%- for model in models %}
* [{{ model }}](https://huggingface.co/{{ model }})
{%- endfor %}

## ğŸ§© Configuration

```yaml

{{- yaml_config -}}

```py
"""

# Create a Jinja template object
jinja_template = Template(template_text.strip())

# Get list of models from config
data = yaml.safe_load(yaml_config)
if "models" in data:
    models = [data["models"][i]["model"] for i in range(len(data["models"])) if "parameters" in data["models"][i]]
elif "parameters" in data:
    models = [data["slices"][0]["sources"][i]["model"] for i in range(len(data["slices"][0]["sources"]))]
elif "slices" in data:
    models = [data["slices"][i]["sources"][0]["model"] for i in range(len(data["slices"]))]
else:
    raise Exception("No models or slices found in yaml config")

# Fill the template
content = jinja_template.render(
    model_name=MODEL_NAME,
    models=models,
    yaml_config=yaml_config,
    username=username,
)

# Save the model card
card = ModelCard(content)
card.save('merge/README.md')
```

ç°åœ¨æˆ‘ä»¬æœ‰äº†æ¨¡å‹å¡ç‰‡ï¼Œå¯ä»¥å°†æ•´ä¸ªæ–‡ä»¶å¤¹æ¨é€åˆ° Hubã€‚

```py
from google.colab import userdata
from huggingface_hub import HfApi

username = "mlabonne"

# Defined in the secrets tab in Google Colab
api = HfApi(token=userdata.get("HF_TOKEN"))

api.create_repo(
    repo_id=f"{username}/{MODEL_NAME}",
    repo_type="model"
)
api.upload_folder(
    repo_id=f"{username}/{MODEL_NAME}",
    folder_path="merge",
)
```

è¯¥æ¨¡å‹ç°åœ¨å¯ä»¥åœ¨ Hugging Face Hub ä¸Šè·å–ï¼Œé“¾æ¥ä¸º[mlabonne/Marcoro14â€“7B-slerp](https://huggingface.co/mlabonne/Marcoro14-7B-slerp)ã€‚åœ¨å¦ä¸€ä¸ªç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åœ¨å…è´¹çš„ T4 GPU ä¸Šå°è¯•è¯¥æ¨¡å‹ï¼š

```py
!pip install -qU transformers accelerate

from transformers import AutoTokenizer
import transformers
import torch

model = "mlabonne/Marcoro14-7B-slerp"
messages = [{"role": "user", "content": "What is a large language model?"}]

tokenizer = AutoTokenizer.from_pretrained(model)
prompt = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
pipeline = transformers.pipeline(
    "text-generation",
    model=model,
    torch_dtype=torch.float16,
    device_map="auto",
)

outputs = pipeline(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
```

æˆ‘ä»¬æå‡ºäº†â€œä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿâ€è¿™ä¸ªé—®é¢˜ï¼Œå¹¶è·å¾—äº†ä»¥ä¸‹è¾“å‡ºï¼š

> *å¤§è¯­è¨€æ¨¡å‹æ˜¯ä¸€ç§äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ç³»ç»Ÿï¼Œå®ƒé€šè¿‡å¤§é‡çš„æ–‡æœ¬æ•°æ®è¿›è¡Œè®­ç»ƒã€‚å…¶è®¾è®¡ç›®çš„æ˜¯ç†è§£å’Œç”Ÿæˆç±»ä¼¼äººç±»çš„è¯­è¨€ï¼Œé¢„æµ‹å¥å­æˆ–æ–‡æ¡£ä¸­æ¥ä¸‹æ¥å¯èƒ½å‡ºç°çš„å•è¯æˆ–çŸ­è¯­ã€‚è¿™äº›æ¨¡å‹ä½¿ç”¨å¤æ‚çš„ç®—æ³•å’Œç¥ç»ç½‘ç»œæ¶æ„ï¼Œä»æ•°æ®ä¸­å­¦ä¹ ï¼Œå¹¶éšç€æ—¶é—´çš„æ¨ç§»æé«˜å…¶è¡¨ç°ã€‚ä¸€äº›è‘—åçš„å¤§è¯­è¨€æ¨¡å‹åŒ…æ‹¬ OpenAI çš„ GPT-3 å’Œ Google çš„ BERTã€‚*

ä¸€åˆ‡çœ‹èµ·æ¥ä¸é”™ï¼Œä½†æˆ‘ä»¬éœ€è¦æ›´å…¨é¢çš„è¯„ä¼°ã€‚å¯¹äºè¿™ç§é€šç”¨æ¨¡å‹ï¼Œæœ‰ä¸€äº›æœ‰è¶£çš„åŸºå‡†æµ‹è¯•ï¼š

+   [**Chatbot Arena**](https://chat.lmsys.org/)ï¼Œå®ƒæ ¹æ®äººç±»æŠ•ç¥¨ç¼–åˆ¶äº†ä¸€ä¸ªåŸºäº Elo çš„ LLM æ’è¡Œæ¦œã€‚

+   [**MT-bench**](https://chat.lmsys.org/)ï¼ˆåŒä¸€ä¸ªé“¾æ¥ï¼‰ï¼Œå®ƒä½¿ç”¨ GPT-4 ä½œä¸ºè£åˆ¤ï¼ŒåŸºäºä¸€ç»„å¤šè½®é—®é¢˜å¯¹æ¨¡å‹çš„å›ç­”è¿›è¡Œè¯„åˆ†ã€‚

+   [**NousResearch åŸºå‡†å¥—ä»¶**](https://github.com/teknium1/LLM-Benchmark-Logs)ï¼Œå®ƒæ±‡é›†äº†å››ä¸ªåŸºå‡†æµ‹è¯•ï¼šAGIEvalã€GPT4ALLã€TruthfulQA å’Œ Bigbenchã€‚GPT4ALL æœ¬èº«åŒ…æ‹¬ HellaSwagã€OpenBookQAã€Winograndeã€ARC-Easyã€ARC-Challengeã€BoolQ å’Œ PIQAã€‚

+   [**Open LLM æ’è¡Œæ¦œ**](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)ï¼Œå®ƒæ±‡é›†äº†å…­ä¸ªåŸºå‡†æµ‹è¯•ï¼šARCã€HellaSwagã€MMLUã€Winograndeã€GSM8K å’Œ TruthfulQAã€‚

ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬æ— æ³•å°†æ¨¡å‹æäº¤åˆ° Chatbot Arenaã€‚ç›¸åï¼Œæˆ‘é€‰æ‹©ä½¿ç”¨ Open LLM æ’è¡Œæ¦œå’Œ NousResearch åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°å®ƒã€‚

æˆ‘å°†æˆ‘ä»¬çš„æ¨¡å‹æäº¤åˆ°äº†[Open LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)ï¼ˆâ€œğŸš€ Submit here!â€æ ‡ç­¾ï¼‰ã€‚å¦‚ä»‹ç»æ‰€ç¤ºï¼Œå®ƒåœ¨æ’è¡Œæ¦œä¸­æ’åä¸º**æœ€ä½³ 7B å‚æ•°æ¨¡å‹**ã€‚ä»¥ä¸‹æ˜¯å®Œæ•´çš„ç»“æœï¼š

![](img/f4226bad511e593527bd4a16b408aca6.png)

ä½œè€…æä¾›çš„å›¾åƒ

Open LLM Leaderboard çš„é—®é¢˜åœ¨äºè¿™äº›åŸºå‡†æ˜¯å…¬å¼€çš„ã€‚è¿™æ„å‘³ç€äººä»¬å¯ä»¥åœ¨æµ‹è¯•æ•°æ®ä¸Šè®­ç»ƒ LLMs ä»¥è·å¾—æ›´å¥½çš„ç»“æœã€‚é€šè¿‡åˆå¹¶æœ€ä½³æ¨¡å‹ï¼Œæˆ‘ä»¬ä¹Ÿæ±¡æŸ“äº†è‡ªå·±çš„ç»“æœã€‚å¯ä»¥å®‰å…¨åœ°å‡è®¾**Marcoro14â€“7B-slerp å·²è¢«æ±¡æŸ“**ï¼Œå¹¶ä¸”æœ¬æ¬¡åˆå¹¶ä¸­ä½¿ç”¨çš„æŸäº›æ¨¡å‹å¯èƒ½å·²åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¿‡è®­ç»ƒã€‚å¦‚æœæ‚¨æƒ³åˆ›å»ºæœ€å¥½çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯æ“æ§æ’è¡Œæ¦œï¼Œæˆ‘å»ºè®®ä»…ä½¿ç”¨éåˆå¹¶æ¨¡å‹æ¥åˆ›å»ºæ‚¨è‡ªå·±çš„åˆå¹¶æ¨¡å‹ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸æƒ³ä»…ä¾èµ– OpenLLM Leaderboardã€‚å¯¹äº NousResearch åŸºå‡†æµ‹è¯•å¥—ä»¶ï¼Œæˆ‘ä½¿ç”¨äº†[ğŸ§ LLM AutoEval](https://github.com/mlabonne/llm-autoeval)é€šè¿‡ç®€å•çš„ Colab ç¬”è®°æœ¬è‡ªåŠ¨è®¡ç®—åˆ†æ•°ã€‚ä»¥ä¸‹æ˜¯ä¸ä¼˜ç§€çš„[OpenHermes-2.5-Mistral-7B](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)ç›¸æ¯”çš„ç»“æœï¼š

![](img/dccb0dc2b74086db79fae8ace4c1bad8.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

æˆ‘ä»¬åœ¨**æ¯ä¸ªåŸºå‡†æµ‹è¯•**ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚è¯·æ³¨æ„ï¼ŒNousResearch åŸºå‡†æµ‹è¯•å¥—ä»¶ä¸ Open LLM Leaderboard å…±äº«ä¸€äº›ä»»åŠ¡ï¼šARC-Challengeã€TruthfulQAã€HellaSwag å’Œ Winograndeã€‚æ®æˆ‘æ‰€çŸ¥ï¼ŒBigbench æ˜¯å”¯ä¸€ä¸€ä¸ª 100% ä¸åŒçš„åŸºå‡†ï¼ˆå¦‚æœä¸æ˜¯ï¼Œè¯·éšæ—¶ä¸æˆ‘è”ç³»ï¼‰ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬åœ¨æ­¤åˆå¹¶ä¸­ä½¿ç”¨çš„æŸäº›æ¨¡å‹ä»ç„¶å¯èƒ½åœ¨ Bigbench ä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚

# ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å°† LLMs åˆå¹¶çš„å››ç§ä¸åŒæ–¹æ³•ã€‚æˆ‘ä»¬è¯¦ç»†è®²è§£äº† SLERPã€TIESã€DARE å’Œ passthrough çš„å·¥ä½œåŸç†ï¼Œå¹¶æä¾›äº†é…ç½®ç¤ºä¾‹ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ mergekit è¿è¡Œ SLERPï¼Œåˆ›å»ºäº†[Marcoro14â€“7B-slerp](https://huggingface.co/mlabonne/Marcoro14-7B-slerp)ï¼Œå¹¶å°†å…¶ä¸Šä¼ è‡³ Hugging Face Hubã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªåŸºå‡†æµ‹è¯•å¥—ä»¶ä¸Šå–å¾—äº†ä¼˜ç§€çš„è¡¨ç°ï¼šOpen LLM Leaderboardï¼ˆ**è¡¨ç°æœ€å¥½çš„ 7B æ¨¡å‹**ï¼‰å’Œ NousResearchã€‚å¦‚æœæ‚¨æƒ³åˆ›å»ºè‡ªå·±çš„åˆå¹¶æ¨¡å‹ï¼Œæˆ‘æ¨èä½¿ç”¨æˆ‘çš„è‡ªåŠ¨åŒ–ç¬”è®°æœ¬[ğŸ¥± LazyMergekit](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing)ã€‚

å¦ä¸€ç§åˆå¹¶å¤šä¸ªæ¨¡å‹çš„æ–¹æ³•æ˜¯å°†å®ƒä»¬åˆå¹¶åœ¨ Mixture of Experts (MoE) æ¶æ„ä¸­ã€‚åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†è¯¦ç»†è®¨è®ºå¦‚ä½•æ‰§è¡Œæ­¤æ“ä½œï¼Œå¹¶åˆ›å»ºæˆ‘ä»¬è‡ªå·±çš„[ç±»ä¼¼ Mixtral çš„æ¨¡å‹](https://huggingface.co/mlabonne/Beyonder-4x7B-v2)ã€‚å¦‚æœæ‚¨å–œæ¬¢æœ¬æ–‡ï¼Œè¯·åœ¨ Medium å’Œ Twitter ä¸Šå…³æ³¨æˆ‘[@maximelabonne](https://twitter.com/maximelabonne)ã€‚

*é€šè¿‡ç‚¹å‡»ä¸€æ¬¡ï¼Œäº†è§£æ›´å¤šå…³äºæœºå™¨å­¦ä¹ çš„ä¿¡æ¯å¹¶æ”¯æŒæˆ‘çš„å·¥ä½œâ€”â€”åœ¨è¿™é‡Œæˆä¸º Medium ä¼šå‘˜ï¼š*

[](https://medium.com/@mlabonne/membership?source=post_page-----2118fb392b54--------------------------------) [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium â€” Maxime Labonne

### ä½œä¸º Medium ä¼šå‘˜ï¼Œæ‚¨çš„ä¸€éƒ¨åˆ†ä¼šå‘˜è´¹ç”¨å°†ç”¨äºæ”¯æŒæ‚¨é˜…è¯»çš„ä½œå®¶ï¼ŒåŒæ—¶æ‚¨å¯ä»¥å®Œå…¨è®¿é—®æ¯ä¸ªæ•…äº‹â€¦

medium.com](https://medium.com/@mlabonne/membership?source=post_page-----2118fb392b54--------------------------------)
