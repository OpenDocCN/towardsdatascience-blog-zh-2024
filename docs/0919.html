<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Building a RAG chain using LangChain Expression Language (LCEL)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Building a RAG chain using LangChain Expression Language (LCEL)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-rag-chain-using-langchain-expression-language-lcel-3688260cad05?source=collection_archive---------1-----------------------#2024-04-11">https://towardsdatascience.com/building-a-rag-chain-using-langchain-expression-language-lcel-3688260cad05?source=collection_archive---------1-----------------------#2024-04-11</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="df58" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Learning the building blocks of LCEL to develop increasingly complex RAG chains</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@RSK2327?source=post_page---byline--3688260cad05--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Roshan Santhosh" class="l ep by dd de cx" src="../Images/2509f38bf7d5a40c453fa54575293f06.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/2*WZ0oPku8QDRZpZp9zdfjnQ.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--3688260cad05--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@RSK2327?source=post_page---byline--3688260cad05--------------------------------" rel="noopener follow">Roshan Santhosh</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--3688260cad05--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 11, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">3</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="6947" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this post, I will be going over the <strong class="ml fr">implementation of a Self-evaluation RAG pipeline for question-answering using LangChain Expression Language (LCEL)</strong>. The focus of this post will be on the use of LCEL for building pipelines and not so much on the actual RAG and self evaluation principles used, which are kept simple for ease of understanding.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nh"><img src="../Images/5c5464d056ec85924da8325acf133c35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X9hmWQYKaZevGO1SlGchGA.png"/></div></div></figure><p id="91cb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">I will be covering the following topics :</p><ol class=""><li id="2a40" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nt nu nv bk">Basic initialization steps</li><li id="a264" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk">Development of different variations of the RAG pipeline of increasing complexity using LCEL</li><li id="cefa" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk">Methods for extracting intermediate variables from a LCEL-scripted pipeline</li><li id="7acb" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk">Reasons for using LCEL</li></ol></div></div></div><div class="ab cb ob oc od oe" role="separator"><span class="of by bm og oh oi"/><span class="of by bm og oh oi"/><span class="of by bm og oh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="150e" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">The Setup</h1><p id="aa49" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">Before we jump into the development of the RAG chain, there are some basic setup steps that we need to perform to initialize this setup. These include :</p><h2 id="edd0" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk">Data Ingestion</h2><p id="933f" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">The data ingestion consists of two key steps :</p><ol class=""><li id="3840" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nt nu nv bk">Reading the text from the pdf</li><li id="db48" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk">Splitting up the pdf text into chunks for inputting to the vector database</li></ol><h2 id="f292" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk"><strong class="al">Prompt Templates</strong></h2><p id="865b" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">We will be using different prompts for the question-answering and self-evaluation tasks. We will be having 3 different prompt templates :</p><ol class=""><li id="efda" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nt nu nv bk">qa_prompt : Basic prompt for the question-answering task</li><li id="ba53" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk">qa_eval_prompt : Prompt for evaluator model that takes as input question-answer pair</li><li id="b382" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk">qa_eval_prompt_with_context : Similar to above prompt but additionally includes the context as well for the evaluation</li></ol><h2 id="3e4d" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk">Database Initialization</h2><p id="fce7" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">We initialize a simple vector database using FAISS and Open AI embeddings. For retrieval, we set k as 3 (return top 3 chunks for a given query)</p></div></div></div><div class="ab cb ob oc od oe" role="separator"><span class="of by bm og oh oi"/><span class="of by bm og oh oi"/><span class="of by bm og oh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="facc" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">RAG Development</h1><h2 id="1eed" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk">Simple QA RAG</h2><p id="3341" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">We start off with an example of a basic RAG chain that carries out the following steps :</p><ol class=""><li id="a512" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nt nu nv bk">Retrieves the relevant chunks (splits of pdf text) from the vector database based on the user’s question and merges them into a single string</li><li id="ff3b" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk">Passes the retrieved context text along with question to the prompt template to generate the prompt</li><li id="ae78" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk">Input generated prompt to LLM to generate final answer</li></ol><p id="f5c2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Using </strong><a class="af qb" href="https://python.langchain.com/docs/expression_language/" rel="noopener ugc nofollow" target="_blank"><strong class="ml fr">LangChain Expression Language(LCEL)</strong></a><strong class="ml fr">, this RAG would be implemented as such:</strong></p><pre class="ni nj nk nl nm qc qd qe bp qf bb bk"><span id="f542" class="qg ok fq qd b bg qh qi l qj qk">rag_chain = ( <br/>            RunnableParallel(context = retriever | format_docs, question = RunnablePassthrough() ) |<br/>            qa_prompt | <br/>            llm <br/>)</span></pre><p id="cd3c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The above code primarily follows the <a class="af qb" rel="noopener" target="_blank" href="/write-clean-python-code-using-pipes-1239a0f3abf5">pipe architecture</a> where the output from the preceding element is used as the input for the next element. The below diagram showcases the flow of data. Starting from the user’s input, it passes first through the RunnableParallel block, then through the qa_prompt to generate the prompt. This prompt is then sent to the LLM to generate the final output.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng ql"><img src="../Images/8a548f9e62b181beed8ea536bcca028e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tpm3KZ1Mzod7OkZsCUAQuw.png"/></div></div><figcaption class="qm qn qo nf ng qp qq bf b bg z dx">Basic LCEL input/output flow</figcaption></figure><p id="f25f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">There are two key additions to this pipeline that are unique to LangChain :</p><ol class=""><li id="1d62" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nt nu nv bk"><strong class="ml fr">RunnableParallel </strong>: As the name suggests, this class provides the <strong class="ml fr"><em class="qr">functionality to run multiple processes in parallel</em></strong>. As a result, the output of a RunnableParallel is a dict with the keys being the arguments provided during its initialization. In this case, the output would have two keys : <em class="qr">context</em> and <em class="qr">question</em>.<br/>So why do we need this in our current situation? Its required because the qa_prompt template requires two input values: the context and the question. Therefore we need to compute these values individually and then pass them together to the qa_prompt template.</li><li id="53fb" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk"><strong class="ml fr">RunnablePassthrough</strong> : This is a useful class when you want to pass through the input to the next stage without any modification. Essentially, this <strong class="ml fr"><em class="qr">acts as an identity function</em></strong> that returns whatever is passed as its input.</li></ol><p id="d08b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The flowchart for the above RAG would look like this :</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng qs"><img src="../Images/0a277631bbe470ee4cf767555c1e93a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dM-V2AQYihP7-FHkjEmQKA.png"/></div></div></figure></div></div></div><div class="ab cb ob oc od oe" role="separator"><span class="of by bm og oh oi"/><span class="of by bm og oh oi"/><span class="of by bm og oh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="eeb6" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk">QA RAG with Self Evaluation I</h2><p id="af51" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">Building over the previous RAG chain, we now introduce new elements into the chain to implement the self evaluation component.</p><p id="1db4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The self evaluation component is again a pretty straightforward implementation. We take the answer provided by the first LLM and pass it to the evaluator LLM along with the question and ask it to provide a binary response (Correct/Incorrect).</p><pre class="ni nj nk nl nm qc qd qe bp qf bb bk"><span id="bcc4" class="qg ok fq qd b bg qh qi l qj qk">rag_chain = ( <br/>            RunnableParallel(context = retriever | format_docs, question = RunnablePassthrough() ) |<br/>            RunnableParallel(answer= qa_prompt | llm | retrieve_answer, question = itemgetter("question") ) |<br/>            qa_eval_prompt | <br/>            llm_selfeval |<br/>            json_parser<br/>            )</span></pre><p id="3c3b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The first key difference is the addition of an additional RunnableParallel component. This is required because, similar to the initial prompt for the QA, the self eval prompt also requires two inputs : the base LLM’s answer as well as the user’s question.</p><p id="6830" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">So the output of the first RunnableParallel is the context text and the question while the output of the second RunnableParallel is the LLM answer along with the question.</p><blockquote class="qt qu qv"><p id="06fa" class="mj mk qr ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr"><em class="fq">NOTE:</em></strong><em class="fq"> For the second RunnableParallel, we use the itemgetter method to retain only the question value from the previous input and propagate it forward. This is done instead of using RunnablePassthrough as it would passed on the full input (dict with two keys) whereas we are only interested in passing on the question right now and not the context. Additionally, there is the issue of formatting as qa_eval_prompt expects a dict with str -&gt; str mapping but using RunnablePassthrough would results in a str-&gt; dict mapping</em></p></blockquote><p id="0653" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The flowchart for this RAG implementation would look like this:</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng qw"><img src="../Images/156a9c5f062931ab26da502dd4a0fd5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tduk_yvMpvdIatFu-nyCpQ.png"/></div></div></figure></div></div></div><div class="ab cb ob oc od oe" role="separator"><span class="of by bm og oh oi"/><span class="of by bm og oh oi"/><span class="of by bm og oh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="918f" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk">QA RAG with Self Evaluation II</h2><p id="bffd" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">For this variation, we make a change to the evaluation procedure. In addition to the question-answer pair, we also pass the retrieved context to the evaluator LLM.</p><p id="ef81" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To accomplish this, we add an additional itemgetter function in the second RunnableParallel to collect the context string and pass it to the new qa_eval_prompt_with_context prompt template.</p><pre class="ni nj nk nl nm qc qd qe bp qf bb bk"><span id="9c7a" class="qg ok fq qd b bg qh qi l qj qk">rag_chain = ( <br/>            RunnableParallel(context = retriever | format_docs, question = RunnablePassthrough() ) |<br/>            RunnableParallel(answer= qa_prompt | llm | retrieve_answer, question = itemgetter("question"), context = itemgetter("context") ) |<br/>            qa_eval_prompt_with_context | <br/>            llm_selfeval |<br/>            json_parser<br/>            )</span></pre><p id="2982" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Implementation Flowchart :</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng qx"><img src="../Images/ebfe9ffacb495748306f991ea660b5b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-sxRjQ890OiKP7iabnlfpw.png"/></div></div></figure><h1 id="c2b7" class="oj ok fq bf ol om qy gq oo op qz gt or os ra ou ov ow rb oy oz pa rc pc pd pe bk">Retrieving intermediate variables</h1><p id="da64" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">One of the common pain points with using a chain implementation like LCEL is the difficulty in accessing the intermediate variables, which is important for debugging pipelines. We look at few options where we can still access any intermediate variables we are interested using manipulations of the LCEL</p><h2 id="a5ca" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk">Using RunnableParallel to carry forward intermediate outputs</h2><p id="d766" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">As we saw earlier, RunnableParallel allows us to carry multiple arguments forward to the next step in the chain. So we use this ability of RunnableParallel to carry forward the required intermediate values all the way till the end.</p><p id="979e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In the below example, we modify the original self eval RAG chain to output the retrieved context text along with the final self evaluation output. The primary change is that we add a RunnableParallel object to every step of the process to carry forward the context variable.</p><p id="1bfb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Additionally, we also use the itemgetter function to clearly specify the inputs for the subsequent steps. For example, for the last two RunnableParallel objects, we use <em class="qr">itemgetter(‘input’) </em>to ensure that only the input argument from the previous step is passed on to the LLM/ Json parser objects.</p><pre class="ni nj nk nl nm qc qd qe bp qf bb bk"><span id="f4d5" class="qg ok fq qd b bg qh qi l qj qk">rag_chain = ( <br/>            RunnableParallel(context = retriever | format_docs, question = RunnablePassthrough() ) |<br/>            RunnableParallel(answer= qa_prompt | llm | retrieve_answer, question = itemgetter("question"), context = itemgetter("context") ) |<br/>            RunnableParallel(input =  qa_eval_prompt, context = itemgetter("context")) |<br/>            RunnableParallel(input = itemgetter("input") | llm_selfeval , context = itemgetter("context") ) | <br/>            RunnableParallel(input = itemgetter("input") | json_parser,  context = itemgetter("context") )<br/>            )</span></pre><p id="6406" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The output from this chain looks like the following :</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng rd"><img src="../Images/e44d743b97bcc76935b6a90ee2d85215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*58w4xipYJJWQRhufBWXMZA.png"/></div></div></figure><p id="a3f9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A more concise variation:</p><pre class="ni nj nk nl nm qc qd qe bp qf bb bk"><span id="880d" class="qg ok fq qd b bg qh qi l qj qk">rag_chain = ( <br/>            RunnableParallel(context = retriever | format_docs, question = RunnablePassthrough() ) |<br/>            RunnableParallel(answer= qa_prompt | llm | retrieve_answer, question = itemgetter("question"), context = itemgetter("context") ) |<br/>            RunnableParallel(input =  qa_eval_prompt | llm_selfeval | json_parser, context = itemgetter("context"))<br/>            )</span></pre><h2 id="2a05" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk">Using Global variables to save intermediate steps</h2><p id="9ba5" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">This method essentially uses the principle of a logger. We introduce a new function that saves its input to a global variable, thus allowing us access to the intermediate variable through the global variable</p><pre class="ni nj nk nl nm qc qd qe bp qf bb bk"><span id="e3e2" class="qg ok fq qd b bg qh qi l qj qk">global context<br/><br/>def save_context(x):<br/>    global context<br/>    context = x<br/>    return x<br/><br/>rag_chain = ( <br/>            RunnableParallel(context = retriever | format_docs | save_context, question = RunnablePassthrough() ) |<br/>            RunnableParallel(answer= qa_prompt | llm | retrieve_answer, question = itemgetter("question") ) |<br/>            qa_eval_prompt | <br/>            llm_selfeval |<br/>            json_parser<br/>            )</span></pre><p id="5d5a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Here we define a global variable called <em class="qr">context</em> and a function called <em class="qr">save_context</em> that saves its input value to the global <em class="qr">context</em> variable before returning the same input. In the chain, we add the <em class="qr">save_context</em> function as the last step of the context retrieval step.</p><p id="7c80" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This option allows you to access any intermediate steps without making major changes to the chain.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng re"><img src="../Images/6d75788fdbea9ddc770002e006ad204b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lGwzZVNdnRcAGQiz9WQTAQ.png"/></div></div><figcaption class="qm qn qo nf ng qp qq bf b bg z dx">Accessing intermediate variables using global variables</figcaption></figure><h2 id="4581" class="pk ok fq bf ol pl pm pn oo po pp pq or ms pr ps pt mw pu pv pw na px py pz qa bk">Using callbacks</h2><p id="cf6c" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">Attaching callbacks to your chain is another common method used for logging intermediate variable values. Theres a lot to cover on the topic of callbacks in LangChain, so I will be covering this in detail in a different post.</p></div></div></div><div class="ab cb ob oc od oe" role="separator"><span class="of by bm og oh oi"/><span class="of by bm og oh oi"/><span class="of by bm og oh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="484d" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">Why use LCEL?</h1><p id="0747" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk">The reasons for using LCEL are best explained by the authors of Langchain themselves in their <a class="af qb" href="https://python.langchain.com/docs/expression_language/" rel="noopener ugc nofollow" target="_blank">official documentation</a>.</p><p id="7639" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Of the points mentioned in the documentation, the following are some that I find especially useful :</p><ol class=""><li id="daef" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nt nu nv bk">I<a class="af qb" href="https://python.langchain.com/docs/expression_language/interface/#input-schema" rel="noopener ugc nofollow" target="_blank">nput and output schemas</a> : Will be covering this in detail in a different post</li><li id="b143" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk"><a class="af qb" href="https://python.langchain.com/docs/expression_language/interface/" rel="noopener ugc nofollow" target="_blank">Async support</a> : As we move towards production applications, it becomes more important to have async functionality. LCEL pipeline allow for the seamless transition to async operations.</li><li id="62d7" class="mj mk fq ml b go nw mn mo gr nx mq mr ms ny mu mv mw nz my mz na oa nc nd ne nt nu nv bk"><a class="af qb" href="https://python.langchain.com/docs/expression_language/primitives/parallel/" rel="noopener ugc nofollow" target="_blank">Optimized parallel execution</a></li></ol><p id="99a5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Above these reasons, as a matter of personal preference, I feel that using LCEL helps improve the readability of your code and allows for cleaner implementations.</p><h1 id="e895" class="oj ok fq bf ol om qy gq oo op qz gt or os ra ou ov ow rb oy oz pa rc pc pd pe bk">Resources</h1><p id="99ca" class="pw-post-body-paragraph mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne fj bk"><a class="af qb" href="https://github.com/rsk2327/AI-Workbook/blob/main/LangChain/Self%20Eval%20RAG.ipynb" rel="noopener ugc nofollow" target="_blank">Full code notebook</a></p><p id="eb3f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><a class="af qb" href="https://github.com/rsk2327/AI-Workbook/blob/main/LangChain/machine_learning_basics.pdf" rel="noopener ugc nofollow" target="_blank">PDF text</a></p><p id="c06a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Images : All images are created by the author</p></div></div></div><div class="ab cb ob oc od oe" role="separator"><span class="of by bm og oh oi"/><span class="of by bm og oh oi"/><span class="of by bm og oh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="c5c0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><em class="qr">In addition to Medium, I share my thoughts, ideas and other updates on </em><a class="af qb" href="https://www.linkedin.com/in/roshan-santhosh/" rel="noopener ugc nofollow" target="_blank"><em class="qr">Linkedin</em></a><em class="qr">.</em></p></div></div></div></div>    
</body>
</html>