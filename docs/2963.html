<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Are LLMs Better at Generating SQL, SPARQL, Cypher, or MongoDB Queries?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Are LLMs Better at Generating SQL, SPARQL, Cypher, or MongoDB Queries?</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-llms-talk-sql-sparql-cypher-and-mongodb-query-language-mql-equally-well-a478f64cc769?source=collection_archive---------3-----------------------#2024-12-09">https://towardsdatascience.com/can-llms-talk-sql-sparql-cypher-and-mongodb-query-language-mql-equally-well-a478f64cc769?source=collection_archive---------3-----------------------#2024-12-09</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="da2b" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Our NeurIPS’24 paper sheds light on this underinvestigated topic with a new and unique public dataset and benchmark.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@jf987?source=post_page---byline--a478f64cc769--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Jonathan Fürst" class="l ep by dd de cx" src="../Images/241a54ac752c0072f6e4b053bb5dbd90.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*tfLuGLZRGniL2bYjCABQXw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--a478f64cc769--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@jf987?source=post_page---byline--a478f64cc769--------------------------------" rel="noopener follow">Jonathan Fürst</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--a478f64cc769--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 9, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/5dc8d2837216f00fd34f96693435a3d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8cgvBRO4AxtOpsA30uugfQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">(Image by author)</figcaption></figure><p id="dd83" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Many recent works have been focusing on how to generate SQL from a natural language question using an LLM. However, there is little understanding of how well LLMs can generate other database query languages in a direct comparison. To answer the question, we created a completely new dataset and benchmark of 10K question-query pairs covering four databases and query languages. We evaluated several relevant closed and open-source LLMs from OpenAI, Google, and Meta together with common in-context-learning (ICL) strategies. The corresponding paper <em class="ny">“SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark”</em> [1] is published at NeurIPS 2024 in the Dataset and Benchmark track (<a class="af nz" href="https://arxiv.org/abs/2411.05521" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2411.05521</a>).<br/>All code and data are available at <a class="af nz" href="https://github.com/jf87/SM3-Text-to-Query" rel="noopener ugc nofollow" target="_blank">https://github.com/jf87/SM3-Text-to-Query</a> to enable you to test your own Text-to-Query method across four query languages. But before we look at Text-to-Query, let’s first take a step back and examine the more common paradigm of Text-to-SQL.</p><h1 id="a9c4" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk"><strong class="al">What is Text-to-SQL?</strong></h1><p id="682b" class="pw-post-body-paragraph nc nd fq ne b go ow ng nh gr ox nj nk nl oy nn no np oz nr ns nt pa nv nw nx fj bk">Text-to-SQL (also called NL-to-SQL) systems translate the provided natural language question into a corresponding SQL query. SQL has served as a primary query language for structured data sources (<a class="af nz" href="https://en.wikipedia.org/wiki/Relational_database" rel="noopener ugc nofollow" target="_blank">relational model</a>), offering a declarative interface for application developers to access information. Text-to-SQL systems thus aim to enable non-SQL expert users to access and fulfill their information needs by simply making their requests in natural language.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pb"><img src="../Images/73a5a93dadc3e6942e2f3b55583c2bd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4yiAMvne4txFYrgQHsib5A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 1. Overview Text-to-SQL. Users ask questions in natural language, which are then translated to the corresponding SQL query. The query is executed against a relational database such as PostgreSQL, and the response is returned to the users. (<em class="pc">Image by author</em>)</figcaption></figure></div></div></div><div class="ab cb pd pe pf pg" role="separator"><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="da75" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Text-to-SQL methods have recently increased in popularity and made substantial progress in terms of their generation capabilities. This can easily be seen from Text-to-SQL accuracies reaching 90% on the popular benchmark Spider (<a class="af nz" href="https://yale-lily.github.io/spider" rel="noopener ugc nofollow" target="_blank">https://yale-lily.github.io/spider</a>) and up to 74% on the more recent and more complex BIRD benchmark (<a class="af nz" href="https://bird-bench.github.io/" rel="noopener ugc nofollow" target="_blank">https://bird-bench.github.io/</a>). At the core of this success lie the advancements in<br/>transformer-based language models, from Bert [2] (340M parameters) and Bart [ 3 ] (148M parameters) to T5 [4 ] (3B parameters) to the advent of Large Language Models (LLMs), such as OpenAI’s GPT models, Anthropic Claude models or Meta’s LLaMA models (up to 100s of billions of parameters).</p><h1 id="d637" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Beyond Relational Databases: Document &amp; Graph Model</h1><p id="682f" class="pw-post-body-paragraph nc nd fq ne b go ow ng nh gr ox nj nk nl oy nn no np oz nr ns nt pa nv nw nx fj bk">While many structured data sources inside companies and organizations are indeed stored in a relational database and accessible through the SQL query language, there are other core database models (also often referred to as <a class="af nz" href="https://en.wikipedia.org/wiki/NoSQL" rel="noopener ugc nofollow" target="_blank">NoSQL</a>) that come with their own benefits and drawbacks in terms of ease of data modeling, query performance, and query simplicity:</p><ul class=""><li id="a282" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pl pm pn bk"><strong class="ne fr">Relational Database Model.</strong> Here, data is stored in tables (relations) with a fixed, hard-to-evolve schema that defines tables, columns, data types, and relationships. Each table consists of rows (records) and columns (attributes), where each row represents a unique instance of the entity described by the table (for example, a patient in a hospital), and each column represents a specific attribute of that entity. The relational model enforces data integrity through constraints such as primary keys (which uniquely identify each record) and foreign keys (which establish relationships between tables). Data is accessed through SQL. Popular relational databases include <a class="af nz" href="https://www.postgresql.org/" rel="noopener ugc nofollow" target="_blank">PostgreSQL</a>, <a class="af nz" href="https://www.mysql.com/" rel="noopener ugc nofollow" target="_blank">MySQL</a>, and <a class="af nz" href="https://www.oracle.com/database/" rel="noopener ugc nofollow" target="_blank">Oracle Database</a>.</li><li id="0d82" class="nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx pl pm pn bk"><strong class="ne fr">Document Database Model. </strong>Here, data is stored in a document structure (hierarchical data model) with a flexible schema that is easy to evolve. Each document is typically represented in formats such as JSON or BSON, allowing for a rich representation of data with nested structures. Unlike relational databases, where data must conform to a predefined schema, document databases allow different documents within the same collection to have varying fields and structures, facilitating rapid development and iteration. This flexibility means that attributes can be added or removed without affecting other documents, making it suitable for applications where requirements change frequently. Popular document databases include <a class="af nz" href="https://www.mongodb.com/" rel="noopener ugc nofollow" target="_blank">MongoDB</a>, <a class="af nz" href="https://couchdb.apache.org/" rel="noopener ugc nofollow" target="_blank">CouchDB</a>, and <a class="af nz" href="https://aws.amazon.com/documentdb/" rel="noopener ugc nofollow" target="_blank">Amazon DocumentDB</a>.</li><li id="83a8" class="nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx pl pm pn bk"><strong class="ne fr">Graph Database Model.</strong> Here, data is represented as nodes (entities) and edges (relationships) in a graph structure, allowing for the modeling of complex relationships and interconnected data. This model provides a flexible schema that can easily accommodate changes, as new nodes and relationships can be added without altering existing structures. Graph databases excel at handling queries involving relationships and traversals, making them ideal for applications such as social networks, recommendation systems, and fraud detection. Popular graph databases include <a class="af nz" href="https://neo4j.com/" rel="noopener ugc nofollow" target="_blank">Neo4j</a>, <a class="af nz" href="https://aws.amazon.com/neptune/" rel="noopener ugc nofollow" target="_blank">Amazon Neptune</a>, and <a class="af nz" href="https://arangodb.com/" rel="noopener ugc nofollow" target="_blank">ArangoDB</a>.</li></ul><h1 id="61a5" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">From Text-to-SQL to Text-to-Query</h1><p id="187b" class="pw-post-body-paragraph nc nd fq ne b go ow ng nh gr ox nj nk nl oy nn no np oz nr ns nt pa nv nw nx fj bk">The choice of database and the underlying core data model (relational, document, graph) has a large impact on read/write performance and query complexity. For example, the graph model naturally represents many-to-many relationships, such as connections between patients, doctors, treatments, and medical conditions. In contrast, relational databases require potentially expensive join operations and complex queries. Document databases have only rudimentary support for many-to-many relationships and aim at scenarios where data is not highly interconnected and stored in collections of documents with a flexible schema.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pt"><img src="../Images/f6ec18037a116f21550e321f3300417e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cFTqdm979fJqBhTJxiNGiw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 2. Differences across query languages and database systems for the same user request. (<em class="pc">Image by author</em>)</figcaption></figure><p id="6677" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">While these differences have been a known fact in database research and industry, their implications for the growing number of Text-to-Query systems have surprisingly not been investigated so far.</p><h1 id="1882" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">SM3-Text-to-Query Benchmark</h1><p id="c6e9" class="pw-post-body-paragraph nc nd fq ne b go ow ng nh gr ox nj nk nl oy nn no np oz nr ns nt pa nv nw nx fj bk">SM3-Text-to-Query is a new dataset and benchmark that enables the evaluation across four query languages (SQL, MongoDB Query Language, Cypher, and SPARQL) and three data models (relational, graph, document).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pu"><img src="../Images/5e822c38489b30798bba1588bb039c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-OWteiSPvdBf6xXnwjK4lQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 3. SM3-Text-to-Query Benchmark Construction. Combining synthetic patient data generation with ETL processes for four databases makes it possible to create arbitrarily large synthetic datasets. (<em class="pc">Image by author</em>)</figcaption></figure><p id="278f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">SM3-Text-to-Query is constructed from synthetic patient data created with Synthea. Synthea is an open-source synthetic patient generator that produces realistic electronic health record (EHR) data. It simulates patients' medical histories over time, including various demographics, diseases, medications, and treatments. This created data is then transformed and loaded into four different database systems: PostgreSQL, MongoDB, Neo4J, and GraphDB (RDF).</p><p id="930f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Based on a set of &gt; 400 manually created <a class="af nz" href="https://github.com/jf87/SM3-Text-to-Query/tree/main/data/question_templates" rel="noopener ugc nofollow" target="_blank">template questions</a> and the generated data, 10K question-query pairs are generated for each of the four query languages (SQL, MQL, Cypher, and SPARQL). However, based on the synthetic data generation process, adding additional template questions or generating your own patient data is also easily possible (for example, adapted to a specific region or in another language). It would even be possible to construct a (private) dataset with actual patient data.</p><h1 id="06ae" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Text-to-Query Results</h1><p id="1bb0" class="pw-post-body-paragraph nc nd fq ne b go ow ng nh gr ox nj nk nl oy nn no np oz nr ns nt pa nv nw nx fj bk">So, how do current LLMs perform in the generation across the four query languages? There are three main lessons that we can learn from the reported results.</p><p id="9fbb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Lesson 01: Schema information helps for all query languages but not equally well.</strong></p><p id="6e1c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Schema information helps for all query languages, but its effectiveness varies significantly. Models leveraging schema information outperform those that don’t — even more in one-shot scenarios where accuracy plummets otherwise. For SQL, Cypher, and MQL, it can more than double the performance. However, SPARQL shows only a small improvement. This suggests that LLMs may already be familiar with the underlying schema (SNOMED CT, <a class="af nz" href="https://www.snomed.org/" rel="noopener ugc nofollow" target="_blank">https://www.snomed.org</a>), which is a common medical ontology.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pv"><img src="../Images/9252cfb4c048ce22dc5f26b16622539f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8RukL4gaqVDrd7rpUX-Z0g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 4. Impact of Schema Information on Execution Accuracy. (<em class="pc">Image by author</em>)</figcaption></figure><p id="e91a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Lesson 02: Adding examples improves accuracy through in-context learning (ICL) for all LLMs and query languages; however, the rate of improvement varies greatly across query languages.</strong></p><p id="6cfa" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Examples enhance accuracy through in-context learning (ICL) across all LLMs and query languages. However, the degree of improvement varies greatly. For SQL, the most popular query language, larger LLMs (GPT-3.5, Llama3–70b, Gemini 1.0) already show a solid baseline accuracy of around 40% with zero-shot schema input, gaining only about 10% points with five-shot examples. However, the models struggle significantly with less common query languages such as SPARQL and MQL without examples. For instance, <strong class="ne fr">SPARQL’s zero-shot accuracy is below 4%.</strong> Still, with <strong class="ne fr">five-shot examples, it skyrockets to 30%,</strong> demonstrating that ICL supports models to generate more accurate queries when provided with relevant examples.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pw"><img src="../Images/70eb4bf3f675b398aa8a2c6d27c37e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yOcQnSPoJyyObfTAtZxLtg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 5. Impact of In-Context-Learning (ICL) through Few-shot Examples. (<em class="pc">Image by author</em>)</figcaption></figure><p id="06f0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Lesson 03: LLMs have varying levels of training knowledge across different query languages</strong></p><p id="7826" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">LLMs exhibit differing levels of proficiency across query languages. This is likely rooted in their training data sources. An analysis of Stack Overflow posts supports this assumption. There is a big contrast in the post-frequency for the different query languages:</p><ul class=""><li id="38ce" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pl pm pn bk">[SQL]: 673K posts</li><li id="7e09" class="nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx pl pm pn bk">[SPARQL]: 6K posts</li><li id="24f4" class="nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx pl pm pn bk">[MongoDB, MQL]: 176K posts</li><li id="c943" class="nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx pl pm pn bk">[Cypher, Neo4J]: 33K posts</li></ul><p id="d97d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This directly correlates with the zero-shot accuracy results, where SQL leads with the best model accuracy of 47.05%, followed by Cypher and MQL at 34.45% and 21.55%. SPARQL achieves just 3.3%. These findings align with existing research [5], indicating that the frequency and recency of questions on platforms like Stack Overflow significantly impact LLM performance. An intriguing exception arises with MQL, which underperforms compared to Cypher, likely due to the complexity and length of MQL queries.</p><h1 id="3d0e" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Conclusion</h1><p id="6e9a" class="pw-post-body-paragraph nc nd fq ne b go ow ng nh gr ox nj nk nl oy nn no np oz nr ns nt pa nv nw nx fj bk">SM3-Text-to-query is the first dataset that targets the cross-query language and cross-database model evaluation of the increasing number of Text-to-Query systems that are fueled by rapid progress in LLMs. Existing works have mainly focused on SQL. Other important query languages are underinvestigated. This new dataset and benchmark allow a direct comparison of four relevant query languages for the first time, making it a valuable resource for both researchers and practitioners who want to design and implement Text-to-Query systems.</p><p id="8e42" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The initial results already provide many interesting insights, and I encourage you to check out the full paper [1].</p><h1 id="6b5c" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Try it yourself</h1><p id="d514" class="pw-post-body-paragraph nc nd fq ne b go ow ng nh gr ox nj nk nl oy nn no np oz nr ns nt pa nv nw nx fj bk">All code and data are open-sourced on <a class="af nz" href="https://github.com/jf87/SM3-Text-to-Query" rel="noopener ugc nofollow" target="_blank">https://github.com/jf87/SM3-Text-to-Query</a>. Contributions are welcome. In a follow-up post, we will provide some hands-on instructions on how to deploy the different databases and try out your own Text-to-Query method.</p><p id="ee0a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[1] Sivasubramaniam, Sithursan, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, and Jonathan Fuerst. “SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark.” In <em class="ny">The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track</em>.<br/>[2] Devlin, Jacob. “Bert: Pre-training of deep bidirectional transformers for language understanding.” <em class="ny">arXiv preprint arXiv:1810.04805</em> (2018).<br/>[3]Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. <a class="af nz" href="https://aclanthology.org/2020.acl-main.703" rel="noopener ugc nofollow" target="_blank">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a>. In <em class="ny">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7871–7880, Online. Association for Computational Linguistics.<br/>[4] Raffel, Colin, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. “Exploring the limits of transfer learning with a unified text-to-text transformer.” <em class="ny">Journal of machine learning research</em> 21, no. 140 (2020): 1–67.<br/>[5] Kabir, Samia, David N. Udo-Imeh, Bonan Kou, and Tianyi Zhang. “Is stack overflow obsolete? an empirical study of the characteristics of chatgpt answers to stack overflow questions.” In <em class="ny">Proceedings of the CHI Conference on Human Factors in Computing Systems</em>, pp. 1–17. 2024.</p></div></div></div></div>    
</body>
</html>