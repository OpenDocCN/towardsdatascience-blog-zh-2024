<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Create Your Own CV Dataset Using Satellite Imagery: Wildfires from Space</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Create Your Own CV Dataset Using Satellite Imagery: Wildfires from Space</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-create-your-own-cv-dataset-using-satellite-imagery-wildfires-from-space-8295c0cca028?source=collection_archive---------6-----------------------#2024-05-09">https://towardsdatascience.com/how-to-create-your-own-cv-dataset-using-satellite-imagery-wildfires-from-space-8295c0cca028?source=collection_archive---------6-----------------------#2024-05-09</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="59a5" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Collecting images to train CNNs</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@alexroz?source=post_page---byline--8295c0cca028--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Aleksei Rozanov" class="l ep by dd de cx" src="../Images/748b69bfaccf39c9aa568a9e6f41eec3.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*JISS93SvFnwE3NMNTl8HAQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--8295c0cca028--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@alexroz?source=post_page---byline--8295c0cca028--------------------------------" rel="noopener follow">Aleksei Rozanov</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--8295c0cca028--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 9, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/7564fed75522e3ccc78cac4ee167c346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXeUElaQ80jtNqNtTBmIaw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Unless otherwise noted, all images are by the <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>, based on Sentinel-2 data.</figcaption></figure><p id="5846" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk nz"><span class="l oa ob oc bo od oe of og oh ed">H</span>ave you ever had this idea that a pet project on the application of ML to satellite images might significantly strengthen your data science portfolio? Or have you trained some models based on datasets developed by other people but not your own? If the answer is yes, I have a good piece of news for you!</p><p id="59c5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In this article I’ll guide you through the process of creating a Computer Vision (CV) dataset consisting of high-resolution satellite images, so you could use a similar approach and build a solid pet project!</p><p id="9f84" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">🔥<strong class="nf fr">The problem:</strong> wildfire detection (binary classification task).<br/><strong class="nf fr">🛰️The instrument:</strong> Sentinel 2 (10/20 m resolution). <br/><strong class="nf fr">⏰The time range:</strong> 2017/01/01–2024/01/01.<br/>🇬🇧<strong class="nf fr">The area of interest:</strong> the UK.<br/><strong class="nf fr">🐍The python code: </strong><a class="af nc" href="https://github.com/alexxxroz/Medium/blob/main/WF_Dataset.ipynb" rel="noopener ugc nofollow" target="_blank">GitHub</a><strong class="nf fr"><em class="oi">.</em></strong></p><h1 id="3792" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">I. Collecting information about the wildfires.</h1><p id="be4d" class="pw-post-body-paragraph nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny fj bk">Before acquiring any imagery, it’s vital to know where and when the wildfires were happening. To get such data, we will use the NASA Fire Information for Resource Management System (<a class="af nc" href="https://firms.modaps.eosdis.nasa.gov/download/" rel="noopener ugc nofollow" target="_blank">FIRMS</a>) archive. Based on your requirements, you can select there a source of data and the region of interest, submit a request, and get your data in a matter of minutes.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pk"><img src="../Images/1c4637b47fa2f85562f21fa2304bf8f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*lVj5RLJpJHC_XJMrXDeKNQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><a class="af nc" href="https://firms.modaps.eosdis.nasa.gov/download/create.php" rel="noopener ugc nofollow" target="_blank">FIRMS portal.</a></figcaption></figure><p id="615d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">I decided to use MODIS-based data in the form of a csv file. It comprises many different variables, but we are only interested in latitude, longitude, acquisition time, <strong class="nf fr">confidence</strong> and <strong class="nf fr">type</strong>. The last two variables are of particular interest to us. As you may guess, confidence is basically the probability that a wildfire was actually happening. So to exclude “wrong alarms” I decided to filter out everything lower than 70% confidence. The second important variable was type. Basically, it’s a classification of wildfires. I was interested only in burning vegetation, so only the class 0 is kept. The resulting dataset has <strong class="nf fr">1087</strong> cases of wildfires.</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="f40a" class="pp ok fq pm b bg pq pr l ps pt">df = pd.read_csv('./fires.csv')<br/>df = df[(df.confidence&gt;70)&amp;(df.type==0)]</span></pre><p id="3182" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now we can overlay the hotspots with the shape of the UK.</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="c730" class="pp ok fq pm b bg pq pr l ps pt">proj = ccrs.PlateCarree()<br/>fig, ax = plt.subplots(subplot_kw=dict(projection=proj), figsize=(16, 9))<br/><br/>shape.geometry.plot(ax=ax, color='black')<br/>gdf.geometry.plot(ax=ax, color='red', markersize=10)<br/><br/>ax.gridlines(draw_labels=True,linewidth=1, alpha=0.5, linestyle='--', color='black')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pu"><img src="../Images/48ae964d29c1e7ee4fcecde1dacdf5ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*wehuPzDdeF9zQreTqI1lgQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><h1 id="dfc2" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">II. Collecting Sentinel-2 images for wildifre events.</h1><p id="7dce" class="pw-post-body-paragraph nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny fj bk">The second stage of the work involves my favorite Google Earth Engine (GEE) and its python version <em class="oi">ee</em> (you can check out my other articles illustrating the capabilities of this service).</p><p id="b4e2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">At ideal conditions, Sentinel 2 derives images with a temporal resolution of 5 days and spatial resolution of 10 m for RGB bands and 20 m for SWIR bands (we will discuss later what these are). However, it doesn’t mean that we have an image of each location once in 5 days, since there are many factors influencing image acquisition, including <strong class="nf fr">clouds</strong>. So there is no chance we get 1087 images; the amount will be much lower.</p><p id="14ba" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s create a script, which would get for each point a Sentinel-2 image with cloud percentage lower than 50%. For each pair of coordinates we create a buffer and stretch it to a rectangle, which is cut off the bigger image later. All the images are converted to multidimensional array and saved as <em class="oi">.npy</em> file.</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="3ace" class="pp ok fq pm b bg pq pr l ps pt">import ee<br/>import pandas as pd<br/><br/>ee.Authenticate()<br/>ee.Initialize()<br/><br/>uk = ee.FeatureCollection('FAO/GAUL/2015/level2').filter(ee.Filter.eq('ADM0_NAME', 'U.K. of Great Britain and Northern Ireland'))<br/>SBands = ['B2', 'B3','B4', 'B11','B12']<br/>points = []<br/>for i in range(len(df)):<br/>    points.append(ee.Geometry.Point([df.longitude.values[i], df.latitude.values[i]]))<br/><br/>for i in range(len(df)):<br/>    startDate = pd.to_datetime(df.acq_date.values[i])<br/>    endDate = startDate+datetime.timedelta(days=1)<br/>    S2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\<br/>                .filterDate(startDate.strftime('%Y-%m-%d'), endDate.strftime('%Y-%m-%d'))\<br/>                .filterBounds(points[i].buffer(2500).bounds())\<br/>                .select(SBands)\<br/>                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))<br/>    if S2.size().getInfo()!=0:<br/>        S2_list = S2.toList(S2.size())<br/>        for j in range(S2_list.size().getInfo()):<br/>            img = ee.Image(S2_list.get(j)).select(SBands)<br/>            img = img.reproject('EPSG:4326', scale=10, crsTransform=None)<br/>            roi = points[i].buffer(2500).bounds()<br/>            array = ee.data.computePixels({<br/>              'expression': img.clip(roi),<br/>              'fileFormat': 'NUMPY_NDARRAY'<br/>            })<br/>            np.save(join('./S2',f'{i}_{j}.npy'), array)<br/>            print(f'Index: {i}/{len(df)-1}\tDate: {startDate}')</span></pre><p id="1f58" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">What are these SWIR bands (in particular, bands 11 and 12)? SWIR stands for Short-Wave Infrared. SWIR bands are a part of the electromagnetic spectrum that covers wavelengths ranging from approximately 1.4 to 3 micrometers.</p><p id="02b0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">SWIR bands are used in wildfire analysis for several reasons:</p><ol class=""><li id="fa56" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pv pw px bk"><strong class="nf fr">Thermal Sensitivity:</strong> SWIR bands are sensitive to temperature variations, allowing them to detect heat sources associated with wildfires. So SWIR bands can capture info about the location and intensity of the fire.</li><li id="086c" class="nd ne fq nf b go py nh ni gr pz nk nl nm qa no np nq qb ns nt nu qc nw nx ny pv pw px bk"><strong class="nf fr">Penetration of Smoke:</strong> Smoke generated by wildfires can obscure visibility in RGB images (i.e. you simply can’t see “under” the clouds). SWIR radiation has better penetration through smoke compared to visible range, allowing for more reliable fire detection even in smoky conditions.</li><li id="8d42" class="nd ne fq nf b go py nh ni gr pz nk nl nm qa no np nq qb ns nt nu qc nw nx ny pv pw px bk"><strong class="nf fr">Discrimination of Burned Areas:</strong> SWIR bands can help in identifying burned areas by detecting changes in surface reflectance caused by fire-induced damage. Burned vegetation and soil often exhibit distinct spectral signatures in SWIR bands, enabling the delineation of the extent of the fire-affected area.</li><li id="ea03" class="nd ne fq nf b go py nh ni gr pz nk nl nm qa no np nq qb ns nt nu qc nw nx ny pv pw px bk"><strong class="nf fr">Nighttime Detection:</strong> SWIR sensors can detect thermal emissions from fires even during nighttime when visible and near-infrared sensors are ineffective due to lack of sunlight. This enables continuous monitoring of wildfires round the clock.</li></ol><p id="8877" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">So if we have a look at a random image from the collected data, we will be able to see, that when based on RGB image it’s hard to say whether it’s smoke or cloud, SWIR bands clearly demonstrate the presence of fire.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qd"><img src="../Images/e39c7210118166b492979bce2748ff1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hjKDWNFYELGtNXVUx8-MUQ.png"/></div></div></figure><h1 id="dfab" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">III. Manual cleaning.</h1><p id="6929" class="pw-post-body-paragraph nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny fj bk">Now is my least favorite part. It’s crucial to go through all of the pictures and check if there is a wildfire on each image (remember, 70% confidence) and the picture is generally correct.</p><p id="3515" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For example, images like these (no hotspots are present) were acquired and automatically downloaded to the wildfire folder:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qe"><img src="../Images/228a127fcaa5e3e07a7619a59b4119ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HYIUZbN5ZCaCEyBvFz6jFg.png"/></div></div></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qe"><img src="../Images/1015b718c93b72f28c2fdbceb919fe93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vo5dXBkaHQ7cpesl9s9y2w.png"/></div></div></figure><p id="b6b5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The total amount of images after cleaning: <strong class="nf fr">228</strong>.</p><h1 id="d13b" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">IV. Getting no-wildfire images.</h1><p id="4445" class="pw-post-body-paragraph nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny fj bk">And the last stage is getting images without hotspots for our dataset. Since we are building a dataset for a classification task, we need to balance the two classes, so we need to get at least 200 pictures.</p><p id="6441" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To do that we will randomly sample points from the territory of the UK (I decided to sample 300):</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="eb3e" class="pp ok fq pm b bg pq pr l ps pt">min_x, min_y, max_x, max_y = polygon.bounds<br/>points = []<br/>while len(points)&lt;300:<br/>    random_point = Point(np.random.uniform(min_x, max_x), np.random.uniform(min_y, max_y))<br/>    if random_point.within(polygon):<br/>        points.append(ee.Geometry.Point(random_point.xy[0][0],random_point.xy[1][0]))<br/>print('Done!')</span></pre><p id="edac" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Then applying the code written above, we acquire Sentinel-2 images and save them.</p><h1 id="f88f" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">V. Manual cleaning again :((((</h1><p id="bc8b" class="pw-post-body-paragraph nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny fj bk">Boring stage again. Now we need to be sure that among these point there are no wildfires/disturbed or incorrect images.</p><p id="0f02" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After doing that, I ended up with <strong class="nf fr">242</strong> images like this:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qf"><img src="../Images/3eb8a69cc01f50dbf459faa89e212327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*mFYk4yYHmbTsbL63seUGBg.jpeg"/></div></figure><p id="78d0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">VI. Augmentation.</strong></p><p id="c5a3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The final stage is image augmentation. In simple words, the idea is to increase the amount of images in the dataset using the ones we already have. In this dataset we will simply rotate images on 180°, hence, getting a two-times greater amount of pictures in the dataset!</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qf"><img src="../Images/2ffa9254447febcb89a3247a09b7298c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*SfbeJush2FMWrpmS7QZIGA.jpeg"/></div></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qf"><img src="../Images/d8cbbe2ebd24f7c72a5fe4bf4311bd26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*6oJM_hUdtMSfSskXPg1Gtw.jpeg"/></div></figure><h1 id="ffa2" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">Results.</h1><p id="a481" class="pw-post-body-paragraph nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny fj bk">Now it’s possible to randomly sample two classess of images and visualize them.</p><p id="d77c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">No-WF:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qg"><img src="../Images/fed9cfa018dcfea460b3a8913cc8faad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fm0j1F__GrLRdUhfMH0-dg.png"/></div></div></figure><p id="3eef" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">WF:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qg"><img src="../Images/0e10bf99fe93822c4d7fa143f919e455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x94Pb-eY-TcZEq28PU6xeg.png"/></div></div></figure><p id="418a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">That’s it, we’re done! As you can see it’s not that hard to collect a lot of remote sensing data if you use GEE. The dataset we created now can be used as for training CNNs of different architectures and comparison of their performance. On my opinion, it’s a perfect project to add in your data science portfolio, since it solves non-trivial and important problem.</p><p id="4171" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Hopefully this article was informative and insightful for you!</p><p id="45e4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">===========================================</p><p id="658d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr"><em class="oi">References:</em></strong></p><ul class=""><li id="2a14" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qh pw px bk">NASA Near Real-Time and MCD14DL MODIS Active Fire Detections (TXT/CSV format). Dataset. Available online [<a class="af nc" href="https://www.earthdata.nasa.gov/learn/find-data/near-real-time/firms/active-fire-data" rel="noopener ugc nofollow" target="_blank">/learn/find-data/near-real-time/firms/active-fire-data</a>]</li><li id="138c" class="nd ne fq nf b go py nh ni gr pz nk nl nm qa no np nq qb ns nt nu qc nw nx ny qh pw px bk"><a class="af nc" href="https://www.earthdata.nasa.gov/learn/find-data/near-real-time/firms/mcd14dl-nrt" rel="noopener ugc nofollow" target="_blank">FIRMS Data Policy.</a></li><li id="ad95" class="nd ne fq nf b go py nh ni gr pz nk nl nm qa no np nq qb ns nt nu qc nw nx ny qh pw px bk"><a class="af nc" href="https://scihub.copernicus.eu/twiki/pub/SciHubWebPortal/TermsConditions/Sentinel_Data_Terms_and_Conditions.pdf" rel="noopener ugc nofollow" target="_blank">Sentinel-2 Data License.</a></li><li id="ded2" class="nd ne fq nf b go py nh ni gr pz nk nl nm qa no np nq qb ns nt nu qc nw nx ny qh pw px bk">Copernicus Sentinel data 2017–2024.</li></ul><p id="bf9c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">===========================================</p><p id="7279" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr"><em class="oi">All my publications on Medium are free and open-access, that’s why I’d really appreciate if you followed me here!</em></strong></p><p id="0f9c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">P.s. I’m extremely passionate about (Geo)Data Science, ML/AI and Climate Change. So if you want to work together on some project pls contact me in <a class="af nc" href="https://www.linkedin.com/in/alexxxroz/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>.</p><p id="ff40" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">🛰️Follow for more🛰️</p></div></div></div></div>    
</body>
</html>