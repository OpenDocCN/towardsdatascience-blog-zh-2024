- en: 6 Step Framework to Manage Reputational & Ethical Risks of Generative AI in
    Your Product
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理生成性AI产品中声誉与伦理风险的六步框架
- en: 原文：[https://towardsdatascience.com/6-step-framework-to-manage-ethical-risks-of-generative-ai-in-your-product-7ed46783d282?source=collection_archive---------7-----------------------#2024-02-19](https://towardsdatascience.com/6-step-framework-to-manage-ethical-risks-of-generative-ai-in-your-product-7ed46783d282?source=collection_archive---------7-----------------------#2024-02-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/6-step-framework-to-manage-ethical-risks-of-generative-ai-in-your-product-7ed46783d282?source=collection_archive---------7-----------------------#2024-02-19](https://towardsdatascience.com/6-step-framework-to-manage-ethical-risks-of-generative-ai-in-your-product-7ed46783d282?source=collection_archive---------7-----------------------#2024-02-19)
- en: A pragmatic guide to understand AI risks and build trust with users through
    responsible AI development
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一份务实的指南，帮助理解AI风险，并通过负责任的AI开发与用户建立信任
- en: '[](https://medium.com/@sarthakh330?source=post_page---byline--7ed46783d282--------------------------------)[![Sarthak
    Handa](../Images/0c75ba0f085fdb22a221705450047c40.png)](https://medium.com/@sarthakh330?source=post_page---byline--7ed46783d282--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7ed46783d282--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7ed46783d282--------------------------------)
    [Sarthak Handa](https://medium.com/@sarthakh330?source=post_page---byline--7ed46783d282--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@sarthakh330?source=post_page---byline--7ed46783d282--------------------------------)[![Sarthak
    Handa](../Images/0c75ba0f085fdb22a221705450047c40.png)](https://medium.com/@sarthakh330?source=post_page---byline--7ed46783d282--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7ed46783d282--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7ed46783d282--------------------------------)
    [Sarthak Handa](https://medium.com/@sarthakh330?source=post_page---byline--7ed46783d282--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7ed46783d282--------------------------------)
    ·9 min read·Feb 19, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7ed46783d282--------------------------------)
    ·阅读时间：9分钟·2024年2月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a0471e3425a437220dcefcbd1449eb78.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0471e3425a437220dcefcbd1449eb78.png)'
- en: 'Source: Dalle-3'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Dalle-3
- en: In the fast-paced technology landscape, product teams feel the relentless pressure
    to rush innovative AI offerings to market. However, prioritizing speed over ethical
    and safety considerations can severely backfire. When AI systems breach social
    norms and values, organizations bear the risk of facing long-lasting reputational
    damage and losing trust with users.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速发展的技术领域，产品团队感受到将创新型AI产品迅速推向市场的巨大压力。然而，将速度置于伦理和安全考虑之上可能会带来严重的负面后果。当AI系统违反社会规范和价值观时，组织面临的风险包括长时间的声誉损害和失去用户信任。
- en: Companies are caught in a real-world “*prisoner’s dilemma*” of the AI era —
    while collective adherence to ethical development is ideal, it’s often more tempting
    for companies to secure a first-mover advantage by compromising on these crucial
    standards. This tension is exemplified by the infamous **Facebook-Cambridge Analytica**
    scandal, where taking ethical shortcuts led to grave, long-lasting reputational
    damage. As AI becomes more entrenched in our daily lives, the stakes of this ethical
    gamble only heightens, with each player in the industry weighing immediate gains
    against the longer-term value of trust and responsibility.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 企业正处于AI时代的现实“*囚徒困境*”之中——虽然集体遵循伦理开发是理想的，但公司往往更倾向于通过妥协这些关键标准来获得先发优势。这一紧张局势通过臭名昭著的**Facebook-Cambridge
    Analytica**丑闻得到了体现，在该丑闻中，采取伦理上的捷径导致了严重且持久的声誉损害。随着AI在我们日常生活中的进一步渗透，这种伦理赌博的风险只会加剧，行业中的每个参与者都在权衡短期利益与长期信任和责任的价值。
- en: With the rise in AI adoption across industries since 2018, high-profile incidents
    of ethical violations have sharply increased. Mapping out these risks and mitigation
    strategies is now pivotal. This article probes the key source of AI risks, examines
    a few high-profile fallouts, and lays out a 6 steps framework for building products
    that counter these threats.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自2018年以来，随着各行业AI应用的增加，高曝光度的伦理违规事件急剧上升。现在，识别这些风险并制定缓解策略变得至关重要。本文探讨了AI风险的主要来源，回顾了几个高曝光度的失败案例，并提出了一个六步框架，用于构建能应对这些威胁的产品。
- en: Identifying the Risks of AI
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别AI的风险
- en: '***1\. Privacy Intrusion & Consent Issue***'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***1\. 隐私侵犯与同意问题***'
- en: '**Risk:** Arguably the most prevalent AI pitfall is the infringement of privacy
    and copyright laws. This entails two distinct types of failures: failure to secure
    consent for the use of data, and using the data for purposes beyond the scope
    for which the consent was given.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**风险：** 可以说，最普遍的AI陷阱是侵犯隐私和版权法。这涉及两种不同的失败：未能获得数据使用的同意，以及将数据用于超出同意范围的目的。'
- en: '**Example: A**rtists and writers have filed class action lawsuits against **OpenAI**
    and **MidJourney** for training models with their work without consent. Similarly,
    **Getty Images** is suing **Stability AI** for using its data for model training.
    Privacy breaches can also occur even when consent is given but the data is used
    for unintended purposes. For example, **Google DeepMind** used the data of 1.6
    million patients at the **Royal London NHS Foundation Trust** to build a new healthcare
    application. Although there was an implied consent that the data could be used
    to improve patients’ health, the Trust and DeepMind did not clearly communicate
    to patients that their information is being used to build an app.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 艺术家和作家已对**OpenAI**和**MidJourney**提起集体诉讼，指控这些公司未经同意使用他们的作品来训练模型。同样，**Getty
    Images**也在起诉**Stability AI**，指控其使用其数据进行模型训练。即便在给予同意的情况下，如果数据被用于未预料的目的，也可能发生隐私泄露。例如，**Google
    DeepMind**使用了**皇家伦敦NHS基金会信托**的160万患者数据，构建了一个新的医疗应用程序。尽管存在隐性同意，即这些数据可以用于改善患者健康，但信托和DeepMind未明确告知患者他们的信息被用于构建应用程序。'
- en: '[](https://www.reuters.com/legal/litigation/artists-take-new-shot-stability-midjourney-updated-copyright-lawsuit-2023-11-30/?source=post_page-----7ed46783d282--------------------------------)
    [## Artists take new shot at Stability, Midjourney in updated copyright lawsuit'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.reuters.com/legal/litigation/artists-take-new-shot-stability-midjourney-updated-copyright-lawsuit-2023-11-30/?source=post_page-----7ed46783d282--------------------------------)
    [## 艺术家再次起诉Stability，Midjourney，更新后的版权诉讼'
- en: A group of visual artists has filed an amended copyright lawsuit against Stability
    AI, Midjourney and other companies…
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一群视觉艺术家已经对Stability AI、Midjourney和其他公司提起了修改后的版权诉讼…
- en: www.reuters.com](https://www.reuters.com/legal/litigation/artists-take-new-shot-stability-midjourney-updated-copyright-lawsuit-2023-11-30/?source=post_page-----7ed46783d282--------------------------------)
    [](https://www.wired.co.uk/article/google-deepmind-nhs-health-data?source=post_page-----7ed46783d282--------------------------------)
    [## Why Google consuming DeepMind Health is scaring privacy experts
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[为什么Google收购DeepMind Health让隐私专家感到恐惧](https://www.reuters.com/legal/litigation/artists-take-new-shot-stability-midjourney-updated-copyright-lawsuit-2023-11-30/?source=post_page-----7ed46783d282--------------------------------)
    [](https://www.wired.co.uk/article/google-deepmind-nhs-health-data?source=post_page-----7ed46783d282--------------------------------)
    [## 为什么Google收购DeepMind Health让隐私专家感到恐惧'
- en: DeepMind Health has run into data protection problems before and it being moved
    fully into Google raises more…
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DeepMind Health曾遇到过数据保护问题，其完全并入Google后，问题可能更加严重…
- en: www.wired.co.uk](https://www.wired.co.uk/article/google-deepmind-nhs-health-data?source=post_page-----7ed46783d282--------------------------------)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.wired.co.uk](https://www.wired.co.uk/article/google-deepmind-nhs-health-data?source=post_page-----7ed46783d282--------------------------------)'
- en: '***2\. Algorithmic Bias***'
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***2. 算法偏见***'
- en: '**Risk**: This risk involves AI systems making biased predictions, which systematically
    disadvantages or excludes certain group of people based on characteristics like
    race, gender, or socio-economic background. Such biases can have significant societal
    impact, especially when the AI is used to make critical decisions impacting the
    lives of the individuals.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**风险**：此风险涉及AI系统做出有偏见的预测，这种预测会系统性地使某些群体处于不利或排除地位，基于如种族、性别或社会经济背景等特征。这类偏见可能对社会产生重大影响，特别是当AI被用来做出影响个人生活的关键决策时。'
- en: '**Example:** There was backlash against Apple in 2019, when allegations surfaced
    that men received higher credit limits for **Apple Credit Cards** than women,
    despite women having better credit scores in some cases. Other notable instances
    include AI-driven recruitment software and criminal justice applications, such
    as the **COMPAS** tool, which have been criticized for displaying racial and gender
    bias.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 2019年，苹果因涉嫌男性在**Apple Credit Cards**的信用额度高于女性而遭到反对，尽管在某些情况下女性的信用评分更高。其他显著的例子包括AI驱动的招聘软件和刑事司法应用程序，例如**COMPAS**工具，因表现出种族和性别偏见而受到批评。'
- en: '[](https://www.cnn.com/2019/11/12/business/apple-card-gender-bias/index.html?source=post_page-----7ed46783d282--------------------------------)
    [## Apple Card is accused of gender bias. Here''s how that can happen | CNN Business'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.cnn.com/2019/11/12/business/apple-card-gender-bias/index.html?source=post_page-----7ed46783d282--------------------------------](https://www.cnn.com/2019/11/12/business/apple-card-gender-bias/index.html?source=post_page-----7ed46783d282--------------------------------)
    [## 苹果卡被指控存在性别偏见。它是如何发生的 | CNN商业'
- en: Some Apple Card customers say the credit card's issuer, Goldman Sachs, is giving
    women far lower credit limits, even if…
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一些苹果卡用户表示，该信用卡的发行方高盛银行为女性设置了远低于男性的信用额度，即使…
- en: www.cnn.com](https://www.cnn.com/2019/11/12/business/apple-card-gender-bias/index.html?source=post_page-----7ed46783d282--------------------------------)
    [](https://www.nytimes.com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html?source=post_page-----7ed46783d282--------------------------------)
    [## Opinion | When an Algorithm Helps Send You to Prison (Published 2017)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.cnn.com](https://www.cnn.com/2019/11/12/business/apple-card-gender-bias/index.html?source=post_page-----7ed46783d282--------------------------------)
    [## 观点 | 当算法帮助你被送进监狱时（2017年发布）'
- en: Giving a computer program responsibility over sentences doesn't eliminate bias.
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将判刑的责任交给计算机程序并不能消除偏见。
- en: www.nytimes.com](https://www.nytimes.com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html?source=post_page-----7ed46783d282--------------------------------)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.nytimes.com](https://www.nytimes.com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html?source=post_page-----7ed46783d282--------------------------------)'
- en: '***3\. Accuracy Risk & Explainability Gap***'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***3. 精确度风险与可解释性差距***'
- en: '**Risk:** Significant risks arise when AI systems that are used for making
    high-stakes decisions provide inaccurate results or fail to offer a clear rationale
    for their output. The ‘black box’ nature of the AI makes it difficult for users
    to understand and verify its results, which obscures accountability and leads
    to a loss of trust.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**风险：** 当用于做出重大决策的人工智能系统提供不准确的结果，或未能为其输出提供清晰的理由时，可能会产生重大风险。人工智能的“黑箱”性质使得用户难以理解和验证其结果，这模糊了问责制并导致信任丧失。'
- en: '**Example:** **IBM Watson for Oncology** was designed to provide clinicians
    with personalized recommendations for cancer treatment. However, reports surfaced
    that Watson gave unsafe and incorrect treatment suggestions, which led to a loss
    of trust in technology and damaged IBM’s reputation.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**例子：** **IBM沃森肿瘤学**旨在为临床医生提供个性化的癌症治疗推荐。然而，有报告显示沃森给出了不安全和不正确的治疗建议，这导致了对技术的信任丧失，并损害了IBM的声誉。'
- en: '[](https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/?source=post_page-----7ed46783d282--------------------------------)
    [## IBM''s Watson supercomputer recommended ''unsafe and incorrect'' cancer treatments,
    internal documents…'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[## IBM的沃森超级计算机推荐了“危险且不正确”的癌症治疗方案，内部文件…](https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/?source=post_page-----7ed46783d282--------------------------------)'
- en: Slide decks presented last summer by an IBM Watson Health executive largely
    blame the problems on the training of…
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 去年夏天，IBM沃森健康部门的高管展示的幻灯片大多将问题归咎于…
- en: www.statnews.com](https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/?source=post_page-----7ed46783d282--------------------------------)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.statnews.com](https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/?source=post_page-----7ed46783d282--------------------------------)'
- en: '***4\. Security Risk***'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***4. 安全风险***'
- en: '**Risk**: A significant societal risks emerge from the use of AI to create
    deepfakes, which involves generating highly convincing images or video that makes
    it appear as though individuals are saying or doing things they never actually
    did. Deepfakes have been used to create deceptive and realistic media that can
    be used for committing fraud, spreading misinformation, or damaging reputations.
    Moreover, AI can be weaponized for cyberattacks and social engineering, like tailoring
    phishing campaigns, which can introduce extensive security vulnerabilities.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**风险：** 使用人工智能生成深度伪造内容会带来显著的社会风险，这涉及到生成高度逼真的图像或视频，让人们看起来像是在说或做他们实际上从未做过的事情。深度伪造已被用于制造欺骗性且逼真的媒体，可用于实施欺诈、传播虚假信息或破坏声誉。此外，人工智能还可能被用于网络攻击和社会工程学，如量身定制钓鱼攻击，这可能引入广泛的安全漏洞。'
- en: '**Example**: In the political domain, use of deepfakes to fabricate speeches
    or actions could sway public opinion during critical events like elections. During
    the **Russia-Ukraine conflict**, a deepfake showing Ukrainian president appearing
    to tell his soldiers to lay down arms and surrender was circulated, an act that
    could have demoralized troops and provided time-sensitive tactical advantage to
    Russia. In the cybersecurity realm, AI-powered voice imitation was used to impersonate
    a CEO’s voice convincingly, leading to a fraudulent transfer of funds.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.npr.org/2022/03/16/1087062648/deepfake-video-zelenskyy-experts-war-manipulation-ukraine-russia?source=post_page-----7ed46783d282--------------------------------)
    [## Deepfake video of Zelenskyy could be ''tip of the iceberg'' in info war, experts
    warn'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: A fake video of the Ukrainian president claiming defeat spread on social media
    on Wednesday.
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.npr.org](https://www.npr.org/2022/03/16/1087062648/deepfake-video-zelenskyy-experts-war-manipulation-ukraine-russia?source=post_page-----7ed46783d282--------------------------------)
    [](https://www.trendmicro.com/vinfo/mx/security/news/cyber-attacks/unusual-ceo-fraud-via-deepfake-audio-steals-us-243-000-from-u-k-company?source=post_page-----7ed46783d282--------------------------------)
    [## Unusual CEO Fraud via Deepfake Audio Steals US$243,000 From UK Company
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: An unusual case of CEO fraud used a deepfake audio, an artificial intelligence
    (AI)-generated audio, and was reported…
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.trendmicro.com](https://www.trendmicro.com/vinfo/mx/security/news/cyber-attacks/unusual-ceo-fraud-via-deepfake-audio-steals-us-243-000-from-u-k-company?source=post_page-----7ed46783d282--------------------------------)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '**6 Step Framework for Mitigating AI Risks**'
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing AI risks requires a thoughtful approach throughout the entire product
    life-cycle. Below is a six step framework, organized by different stages of AI
    development, that organizations can adopt to ensure the responsible use of AI
    technology in their products.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef48c5b206b4ec5173e6f452dc24bc0b.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: 'Source: Author'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '***1\. Pre-Development: Ethical Groundwork and Design Principles***'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before a single line of code is written, product teams should lay out the groundwork.
    Prioritize early engagement with a broad set of stakeholders, including users,
    technical experts, ethicists, legal professionals, and members of communities
    who may be impacted by the AI application. The goal is to identify both the overt
    and subtle risks associated with the product’s use case. Use these insights to
    chalk out the set of ethical guidelines and product capabilities that needs to
    be embedded into the product prior to its launch to preemptively address the identified
    risks.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '***2\. Development: Data Consent, Integrity, Diversity***'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data is the bedrock of AI and also the most significant source of AI risks.
    It is critical to ensure that all data procured for model training are ethically
    sourced and comes with consent for its intended use. For example, **Adobe** trained
    its image generation model (**Firefly**) with proprietary data which allows it
    to provide legal protection to users against copyright lawsuits.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是人工智能的基石，同时也是人工智能风险的最重要来源。确保所有用于模型训练的数据都具有道德来源，并且获得了用于其预定目的的同意，至关重要。例如，**Adobe**
    使用专有数据训练其图像生成模型（**Firefly**），使其能够为用户提供法律保护，避免版权诉讼。
- en: Further, Personally Identifiable Information (PII) should be removed from sensitive
    datasets used for training models to prevent potential harm. Access to such datasets
    should be appropriately gated and tracked to protect privacy. It’s equally important
    to ensure that the datasets represent the diversity of user base and the breadth
    of usage scenarios to mitigate bias and fairness risks. Companies like **Runway**
    have trained their text-to-image models with synthetic datasets containing AI-generated
    images of people from different ethnicities, genders, professions, and ages to
    ensure that their AI models exhibit diversity in the content they create.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，应该从用于训练模型的敏感数据集中删除个人身份信息（PII），以防止潜在伤害。对这些数据集的访问应适当设置门槛并进行跟踪，以保护隐私。同样重要的是，确保数据集能够代表用户群体的多样性和使用场景的广度，从而减少偏见和公平性风险。像**Runway**
    这样的公司已经使用合成数据集训练其文本到图像模型，这些数据集包含了来自不同种族、性别、职业和年龄段的人工智能生成的人的图像，以确保其人工智能模型在生成内容时体现多样性。
- en: '[](https://www.nasdaq.com/articles/how-adobes-copyright-protection-will-make-it-an-ai-leader?source=post_page-----7ed46783d282--------------------------------)
    [## How Adobe''s Copyright Protection Will Make it an AI Leader'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.nasdaq.com/articles/how-adobes-copyright-protection-will-make-it-an-ai-leader?source=post_page-----7ed46783d282--------------------------------)
    [## Adobe的版权保护如何使其成为AI领导者'
- en: Artificial intelligence (AI) is fundamentally reshaping many industries. AI
    will have many benefits, but it's also…
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能（AI）正在从根本上改变许多行业。人工智能将带来许多好处，但它也…
- en: www.nasdaq.com](https://www.nasdaq.com/articles/how-adobes-copyright-protection-will-make-it-an-ai-leader?source=post_page-----7ed46783d282--------------------------------)
    [](https://research.runwayml.com/publications/mitigating-stereotypical-biases-in-text-to-image-generative-systems?source=post_page-----7ed46783d282--------------------------------)
    [## Mitigating stereotypical biases in text to image generative systems | Runway
    Research
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.nasdaq.com](https://www.nasdaq.com/articles/how-adobes-copyright-protection-will-make-it-an-ai-leader?source=post_page-----7ed46783d282--------------------------------)
    [](https://research.runwayml.com/publications/mitigating-stereotypical-biases-in-text-to-image-generative-systems?source=post_page-----7ed46783d282--------------------------------)
    [## 缓解文本到图像生成系统中的刻板偏见 | Runway 研究'
- en: Reimagining creativity with artificial intelligence.
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用人工智能重新定义创意。
- en: research.runwayml.com](https://research.runwayml.com/publications/mitigating-stereotypical-biases-in-text-to-image-generative-systems?source=post_page-----7ed46783d282--------------------------------)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[研究.runwayml.com](https://research.runwayml.com/publications/mitigating-stereotypical-biases-in-text-to-image-generative-systems?source=post_page-----7ed46783d282--------------------------------)'
- en: '***3\. Development: Robustness Testing and Implementing Guardrails***'
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***3. 开发：稳健性测试与实施防护措施***'
- en: 'The testing phase is pivotal in determining AI’s readiness for a public release.
    This involves comparing AI’s output against the curated set of verified results.
    An effective testing uses:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 测试阶段在决定人工智能是否准备好公开发布中至关重要。这涉及将人工智能的输出与经过验证的结果集进行比较。有效的测试使用：
- en: '**Performance Metrics** aligned with user objectives and business values,'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与用户目标和商业价值对齐的**性能指标**，
- en: '**Evaluation Data** representing users from different demographics and covering
    a range of usage scenarios, including edge-cases'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代表不同人口统计群体并涵盖各种使用场景（包括边缘情况）的**评估数据**，
- en: In addition to performance testing, it is also critical to implement guardrails
    that prevents AI from producing harmful results. For instance, **ImageFX**, **Google**’s
    Image generation service, proactively blocks users from generating content that
    could be deemed inappropriate or used to spread misinformation. Similarly, **Anthropic**
    has proactively set guardrails and measures to avoid misuse of its AI services
    in 2024 elections.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 除了性能测试，实施防护措施同样至关重要，以防止人工智能产生有害结果。例如，**ImageFX**，**Google** 的图像生成服务，主动阻止用户生成可能被认为不适当或用于传播虚假信息的内容。同样，**Anthropic**
    已主动设定了防护措施，以避免其人工智能服务在2024年选举中被滥用。
- en: '[](https://blog.google/technology/ai/google-imagen-2/?source=post_page-----7ed46783d282--------------------------------#:~:text=Our%20responsible%20approach%20to%20building%20Imagen%202)
    [## New and better ways to create images with Imagen 2'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://blog.google/technology/ai/google-imagen-2/?source=post_page-----7ed46783d282--------------------------------#:~:text=Our%20responsible%20approach%20to%20building%20Imagen%202)
    [## 用Imagen 2创造图像的新方式和更好的方式'
- en: We're rolling out Imagen 2, a major update to our image generation technology.
    Try it out today in Bard, Image FX…
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们正在推出Imagen 2，这是我们图像生成技术的重大更新。今天就可以在Bard、Image FX中试用它……
- en: 'blog.google](https://blog.google/technology/ai/google-imagen-2/?source=post_page-----7ed46783d282--------------------------------#:~:text=Our%20responsible%20approach%20to%20building%20Imagen%202)
    [](https://www.linkedin.com/posts/anthropicresearch_preparing-for-global-elections-in-2024-activity-7164707718656643073-VcaW?utm_source=share&utm_medium=member_desktop&source=post_page-----7ed46783d282--------------------------------)
    [## Anthropic on LinkedIn: Preparing for global elections in 2024'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: blog.google](https://blog.google/technology/ai/google-imagen-2/?source=post_page-----7ed46783d282--------------------------------#:~:text=Our%20responsible%20approach%20to%20building%20Imagen%202)
    [](https://www.linkedin.com/posts/anthropicresearch_preparing-for-global-elections-in-2024-activity-7164707718656643073-VcaW?utm_source=share&utm_medium=member_desktop&source=post_page-----7ed46783d282--------------------------------)
    [## Anthropic在LinkedIn：为2024年全球选举做准备
- en: With high-stakes elections taking place around the world in 2024, we're shedding
    light on some of the work that our…
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随着全球2024年高风险选举的临近，我们正在揭示我们的一些工作……
- en: www.linkedin.com](https://www.linkedin.com/posts/anthropicresearch_preparing-for-global-elections-in-2024-activity-7164707718656643073-VcaW?utm_source=share&utm_medium=member_desktop&source=post_page-----7ed46783d282--------------------------------)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.linkedin.com](https://www.linkedin.com/posts/anthropicresearch_preparing-for-global-elections-in-2024-activity-7164707718656643073-VcaW?utm_source=share&utm_medium=member_desktop&source=post_page-----7ed46783d282--------------------------------)'
- en: '***4\. Development: Explainability & Empowerment***'
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***4\. 开发：可解释性与赋能***'
- en: 'In critical industry use cases where building trust is pivotal, it’s important
    for the AI to enable humans in an assistive role. This can be achieved by:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要建立信任的关键行业应用中，AI应当帮助人类担任辅助角色。这可以通过以下方式实现：
- en: Providing citations for the sources of the AI’s insights.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供AI洞察来源的引文。
- en: Highlighting the uncertainty or confidence-level of the AI’s prediction.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强调AI预测的 不确定性 或 信心级别。
- en: Offering users the option to opt-out of using the AI.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供让用户选择退出使用AI的选项。
- en: Creating application workflows that ensure human oversight and prevent some
    tasks from being fully automated.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建应用程序工作流，确保人工监督并防止某些任务被完全自动化。
- en: '***5\. Deployment: Progressive Roll Out & Transparency***'
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***5\. 部署：渐进式推出与透明度***'
- en: As you transition the AI systems from development to real-world deployment,
    adopting a phased roll-out strategy is crucial for assessing risks and gathering
    feedback in a controlled setting. It’s also important to clearly communicate the
    AI’s intended use case, capabilities, and limitations to users and stakeholders.
    Transparency at this stage helps manage expectations and mitigates reputational
    risks associated with unexpected failures of the AI system.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将AI系统从开发阶段过渡到实际部署时，采用渐进式的发布策略至关重要，这有助于在受控环境中评估风险并收集反馈。同时，清晰地向用户和利益相关者传达AI的预期使用案例、能力和局限性也非常重要。此阶段的透明度有助于管理期望，并减少与AI系统意外失败相关的声誉风险。
- en: '**OpenAI**, for example, demonstrated this approach with **Sora**, its latest
    text-to-video service, by initially making the service available to only a select
    group of red teamers and creative professionals. It has been upfront about Sora’s
    capabilities as well as its current limitations, such as challenges in generating
    video involving complex physical interactions. This level of disclosure ensures
    users understand where the technology excels and where it might fail, thereby
    managing expectations, earning users’ trust, and facilitating responsible adoption
    of the AI technology.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**OpenAI**，例如，通过其最新的文本转视频服务**Sora**展示了这种方法，最初仅向部分红队成员和创意专业人士提供该服务。它已经公开了Sora的能力和当前的局限性，比如在生成涉及复杂物理交互的视频时面临的挑战。这种程度的透明度确保了用户了解该技术的优势和可能失败的地方，从而管理期望，赢得用户的信任，并促进AI技术的负责任采用。'
- en: '[](https://openai.com/sora?source=post_page-----7ed46783d282--------------------------------#safety)
    [## Sora: Creating video from text'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://openai.com/sora?source=post_page-----7ed46783d282--------------------------------#safety)
    [## Sora：从文本创建视频'
- en: Sora is an AI model that can create realistic and imaginative scenes from text
    instructions. Read technical report All…
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Sora 是一个能够根据文本指令创建逼真和富有创意场景的 AI 模型。阅读技术报告 All…
- en: openai.com](https://openai.com/sora?source=post_page-----7ed46783d282--------------------------------#safety)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[openai.com](https://openai.com/sora?source=post_page-----7ed46783d282--------------------------------#safety)'
- en: '***6\. Deployment: Monitoring, Feedback, and Adaptation***'
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***6\. 部署：监控、反馈与适应***'
- en: After an AI system goes live, the work isn’t over. Now comes the task of keeping
    a close watch on how the AI behaves in the wild and tuning it based on what you
    find. Create an ongoing mechanism to track performance drifts and continually
    test and train the model on fresh data to avoid degradation in the AI performance.
    Make it easy for users to flag issues and use these insights to adapt AI and constantly
    update guardrails to meet high ethical standards. This will ensure that the AI
    systems remain reliable, trustworthy, and in step with the dynamic world they
    operate in.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AI 系统上线后，工作并未结束。接下来需要密切关注 AI 在实际环境中的表现，并根据观察结果进行调整。创建一个持续的机制，追踪性能漂移，并不断在新数据上测试和训练模型，以避免
    AI 性能的下降。使用户能够轻松标记问题，并利用这些反馈调整 AI，持续更新保护措施以符合高伦理标准。这将确保 AI 系统保持可靠、值得信赖，并与其操作的动态世界保持同步。
- en: '**Conclusion:**'
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论：**'
- en: As AI becomes further entrenched in our lives, managing ethical risks proactively
    is no longer optional — it is imperative. By embedding ethical considerations
    in every step of bringing AI products to life, companies not only mitigate risks
    but also build foundational trust with their users. The era of “*move fast and
    break things*” cannot be applied when dealing with technologies that are exponentially
    more powerful than anything we have seen before. There are no shortcuts when it
    comes to managing risks that can have far-reaching societal impacts.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 AI 在我们生活中的进一步渗透，主动管理伦理风险已不再是可选的——它是必须的。通过在每一个将 AI 产品推向市场的步骤中嵌入伦理考量，公司不仅可以降低风险，还能与用户建立起根本性的信任。当面对比我们之前见过的任何技术都要强大的技术时，*快速行动并破坏一切*的时代已经不能再适用。在处理可能对社会产生深远影响的风险时，没有捷径可走。
- en: AI product builders have a duty to society to move more intentionally and purposefully,
    making trust their true North Star. The future success and continued progress
    of AI hinges on getting the ethics right today.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: AI 产品构建者有责任更加有意图和有目的地行动，将信任作为他们的真正指南针。AI 的未来成功与持续进展取决于今天是否正确处理伦理问题。
- en: '*Thanks for reading! If these insights resonate with you or spark new thoughts,
    let’s continue the conversation. Share your perspectives in the comments below
    or connect with me on* [***LinkedIn***](https://www.linkedin.com/)*.*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢阅读！如果这些见解对你产生共鸣或激发了新的思考，让我们继续交流。请在下方评论区分享你的看法，或者在* [***LinkedIn***](https://www.linkedin.com/)*
    上与我联系。*'
