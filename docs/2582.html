<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Image Data Collection for Climate Change Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Image Data Collection for Climate Change Analysis</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-data-collection-for-climate-change-analysis-a-beginners-guide-628fe4923c7f?source=collection_archive---------12-----------------------#2024-10-22">https://towardsdatascience.com/image-data-collection-for-climate-change-analysis-a-beginners-guide-628fe4923c7f?source=collection_archive---------12-----------------------#2024-10-22</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="f9cd" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A beginner’s guide</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@pazmid?source=post_page---byline--628fe4923c7f--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Daniel Pazmiño Vernaza" class="l ep by dd de cx" src="../Images/2b2dff776ab94ba90e3ec91f92c0222e.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*X9XWWJwScvRL1aqTMD61hA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--628fe4923c7f--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@pazmid?source=post_page---byline--628fe4923c7f--------------------------------" rel="noopener follow">Daniel Pazmiño Vernaza</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--628fe4923c7f--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 22, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/a22960b7de8d42cd8debde5e65a17257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XUGXNGizYTuQpoxFRDVsaA.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Satellite Image of Mount Etna. Source: United States Geological Service (USGS) photo on Unsplash. Link: <a class="af nc" href="https://unsplash.com/es/fotos/una-imagen-satelital-de-un-area-roja-y-blanca-ZvLvu1gUcYA" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/es/fotos/una-imagen-satelital-de-un-area-roja-y-blanca-ZvLvu1gUcYA</a></figcaption></figure><p id="c078" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">I. Introduction</strong></p><p id="d1b6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Deep learning spread with success in Earth Observation. Its achievements led to more complex architectures and methodologies. However, in this process we lost sight of something important. It is better to have more quality data than better models.</p><p id="d2da" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Unfortunately, the development of EO datasets has been messy. Nowadays, there are hundreds of them. Despite several efforts to compile datasets, it is fair to say that they are scattered all over. Additionally, EO data have proliferated to serve very specific needs. Paradoxically, this is the opposite way we should be moving forward with them, especially if we want our deep learning models to work better.</p><p id="1e4a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For instance, <a class="af nc" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">ImageNet</a> compiled thousands of images to better train computer vision models. Yet, EO data is more complex than the ImageNet images database. Unfortunately, there has not been a similar initiative for EO purposes. This forces the EO community to try to adapt the ImageNet resource to our needs. This process is time-consuming and prone to errors.</p><p id="82ac" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Additionally, EO data has an uneven spatial distribution. Most of the data covers North America and Europe. This is a problem since climate change will affect developing countries more.</p><p id="38f9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><a class="af nc" href="https://medium.com/towards-data-science/introduction-to-computer-vision-for-climate-change-81d888f471bd" rel="noopener">In my last article</a>, I explored how computer vision is changing the way we tackle climate change. The justification for this new article emerges in light of the challenges of choosing EO data. I aim to simplify this important first step when we want to harness the power of AI for good.</p><p id="b158" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This article will answer questions such as: what do I need to know about EO data to be able to find what I am looking for? in a sea of data resources, where should I start my search? which are the most cost-effective solutions? what are the options if I have the resources to invest in high-quality data or computing power? What resources will speed up my results? how best to invest my learning time in data acquisition and processing? We will start addressing the following question: what type of image data should I focus on to analyze climate change?</p><p id="3a16" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">II. The Power of Remote Sensing Data</strong></p><p id="7093" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">There are several types of image data relevant to climate change. For example, aerial photographs, drone footage, and environmental monitoring camera feeds. But, remote sensing data (eg. satellite images) offers several advantages. Before describing them let’s describe what remote sensing is.</p><p id="ea01" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Remote sensors collect information about objects. But, they are not in physical contact with them. Remote sensing works based on the physical principle of reflectance. Sensors capture the ratio of the light reflected by a surface to the amount of light incident to it. Reflectance can provide information about the properties of surfaces. For example, it helps us discriminate vegetation, soil, water, and urban areas from an image. Different materials have different spectral reflectance properties. Meaning they reflect light at different wavelengths. By analyzing the reflectances across various wavelengths we can infer not only the composition of the Earth’s surface. We can also detect environmental changes.</p><p id="31c2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Besides reflectance, there are other remote sensing concepts that we should understand.</p><p id="fc84" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Spatial resolution:</strong> is the size of the smallest observable object in a scene. In other words, we will not be able to see entities smaller than the resolution of the image. For example, let’s imagine that we have a satellite image of a city with a resolution of 1 Km. This means that each pixel in the image represents an area of 1 Km by 1 Km of the urban area. If there is a park in the scene smaller than this area, we will not see it. At least not in a clear manner. But we will be able to see roads and big buildings.</p><p id="2b21" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Spectral resolution:</strong> refers to the number of wavebands a sensor is measuring. The wavebands relate to all possible frequencies of electromagnetic radiation. There are three main types of spectral resolution. Panchromatic data captures wavebands in the visible range. It is also called optical data. Multispectral data compile several wavebands at the same time. Color composites use these data. Hyperspectral data have hundreds of wavebands. This resolution allows much more spectral detail in the image.</p><p id="69d0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Temporal resolution:</strong> is also referred to as the revisit cycle. It is the time it takes a satellite to return to its initial position to collect data.</p><p id="5d74" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Swath width:</strong> refers to the ground width covered by the satellite.</p><p id="8005" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now that we know the basics about remote sensing, let’s discuss its advantages for researching climate change. Remote sensing data allows us to cover large areas. Also, satellite images often provide continuous data over time. Equally important, sensors can capture diverse wavelengths. This enables us to analyze the environment beyond our human vision capabilities. Finally, the most important reason is accessibility. Remote sensing data is often public. This means that is a cost-effective source of information.</p><p id="54bb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As a next step, we will learn where to find remote sensing data. Here we have to make a distinction. Some data platforms provide satellite images. And there are computing platforms that allow us to process data and that often also have data catalogs. We will explore data platforms first.</p><p id="d12a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">III. Geospatial Data Platforms</strong></p><p id="c8a3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Geospatial data is ubiquitous nowadays. The following table describes, to my knowledge, the most useful geospatial data platforms. The table privileges open-source data. It also includes a couple of commercial platforms as well. These commercial datasets can be expensive but worth knowing. They can provide high spatial resolution (ranging from 31 to 72 cm) for many applications.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk nz"><img src="../Images/65417cd9e92accdcc833136d47f253c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*DwdSfxmH-RPc1ikpBMpGbQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><strong class="bf oa">Popular Geospatial Data Platforms</strong></figcaption></figure><p id="a155" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This section presented several data platforms, but it is worth acknowledging something. The size and volume of geospatial data is growing. And everything indicates that this trend will continue in the future. Thus, it will be improbable that we continue to download images from platforms. This approach to processing data demands local computing resources. Most likely, we will pre-process and analyze data in cloud computing platforms.</p><p id="fedf" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">IV. Geospatial Cloud Computing Platforms</strong></p><p id="4681" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Geospatial cloud platforms offer powerful computing resources. Thus, it makes sense that these platforms provide their own data catalogs. We will review them in this section.</p><ol class=""><li id="8b51" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny ob oc od bk"><a class="af nc" href="https://earthengine.google.com/" rel="noopener ugc nofollow" target="_blank"><strong class="nf fr">Google Earth Engine (GEE)</strong></a></li></ol><p id="7131" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This platform provides several Application Programming Interfaces (APIs) to interact with. The main APIs run in two programming languages: JavaScript and Python. The original API uses JavaScript. Since I am more of a Pythonista, this was intimidating for me at the beginning. Although the actual knowledge of JavaScript that you must have is minimal. It is more important to master the GEE built-in functions which are very intuitive. The development of the Python API came later. Here is where we can unleash the full power of the GEE platform. This API allows us to take advantage of Python’s machine-learning libraries. The platform also allows us to develop web apps to deploy our geospatial analyses. Although the web app functionalities are pretty basic. As a data scientist, I am more comfortable using Streamlit to build and deploy my web apps. At least for minimal viable products.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk oe"><img src="../Images/a1f4e9773533c865fea4ca33ffdfa00f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CUInOnGrQIbZQotN-uijyw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Google Earth Engine Code Editor (JavaScript API). Source: <a class="af nc" href="https://code.earthengine.google.com/" rel="noopener ugc nofollow" target="_blank">https://code.earthengine.google.com/</a></figcaption></figure><p id="d3ad" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">2. </strong><a class="af nc" href="https://aws.amazon.com/?nc1=h_ls" rel="noopener ugc nofollow" target="_blank"><strong class="nf fr">Amazon Web Services (AWS)</strong></a></p><p id="1dae" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">AWS offers a range of capabilities. Firstly, it provides access to many geospatial data sources. These sources include open data and those from commercial third-party providers. Additionally, AWS can integrate our own satellite imagery or mapping data. Moreover, the platform facilitates collaboration. It enables us to share our data with our team. Furthermore, AWS’s robust computing capabilities empower us to efficiently process large-scale geospatial datasets. The processing occurs within a standardized environment, supported by available open-source libraries. Equally important, it accelerates model building through the provision of pre-trained machine-learning models. Also, within the AWS environment, we can generate high-quality labels. We can also deploy our models or containers to start predictions. Furthermore, AWS facilitates the exploration of predictions through its comprehensive visualization tools.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk of"><img src="../Images/61c6c7ff3817921e192fc5056d743a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9fKhSM34jwkfBefznQrMA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Amazon Web Services Geospatial Capabilities. Source: <a class="af nc" href="https://aws.amazon.com/es/sagemaker/geospatial/" rel="noopener ugc nofollow" target="_blank">https://aws.amazon.com/es/sagemaker/geospatial/</a></figcaption></figure><p id="a0f0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><a class="af nc" href="https://www.climateengine.org/" rel="noopener ugc nofollow" target="_blank"><strong class="nf fr">3. Climate Engine</strong></a></p><p id="9b10" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">I came across this platform a couple of days ago. The platform displays several geospatial datasets with varied spatial and temporal resolutions. Additionally, it offers an advantage over GEE and AWS as it does not require coding. We can perform our analyses and visualizations on the platform and download the results. The range of analyses is somewhat limited, as one might expect, since it does not require coding. However, it can be enough for many studies or at least for quick preliminary analyses.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk og"><img src="../Images/46485804c8856a7e47c5251b5c311ee2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ul8laZgpYbY3WP9vpf5aXA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Climate Engine Portal. Source: <a class="af nc" href="https://app.climateengine.org/climateEngine" rel="noopener ugc nofollow" target="_blank">https://app.climateengine.org/climateEngine</a></figcaption></figure><p id="494e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">4. </strong><a class="af nc" href="https://colab.google/" rel="noopener ugc nofollow" target="_blank"><strong class="nf fr">Colab</strong></a></p><p id="99e5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This is another fascinating Google product. If you ever had the chance to use a Jupyter Notebook on your local computer, you are going to love Colab. As with Jupyter Notebooks, it allows us to perform analyses with Python interactively. Yet, Colab does the same thing in the cloud. I identify three main advantages to using Google Colab for our geospatial analyses. First, Colab provides Graphical Computing Units (GPUs) capabilities. GPUs are efficient in handling graphics-related tasks. Additionally, Colab provides current versions of data science libraries (e.g. scikit-learn, Tensorflow, etc.). Finally, it allows us to connect to GEE. Thus, we can take advantage of GEE computing resources and data catalog.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk oh"><img src="../Images/5ba6943ca46559747bc7e2e89332d97f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PImaP2N4VJ8iMvNLpCsJKw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Geospatial Analyses in Google Colab</figcaption></figure><p id="46dc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">5. </strong><a class="af nc" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"><strong class="nf fr">Kaggle</strong></a></p><p id="674d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The famous platform for data science competitions also provides capabilities similar to Colab. With a Kaggle account, we can run Python notebooks interactively in the cloud. It also has GPU capabilities. The advantage of Kaggle over Colab is that it provides satellite image datasets.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk oi"><img src="../Images/44ccd87685406aaa7c41f0882d653ef8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NwfOFjaIgLsHmnwIVAw5Zw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Geospatial dataset search results in Kaggle</figcaption></figure><p id="750e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">V. Conclusion</strong></p><p id="5bb5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As we have seen, getting started with data acquisition is not a trivial task. There is a plethora of datasets developed for very specific purposes. Since the size and volume of these datasets have increased, it does not make sense to try to run our models locally. Nowadays we have fantastic cloud computing resources. These platforms even provide some free capabilities to get started.</p><p id="072a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As a gentle reminder, it is important to mention that the best we can do to improve our modeling is to use better data. As users of these data, we can contribute to pinpointing the gaps in this arena. It is worth highlighting two of them. First, the a lack of a general-purpose benchmark dataset designed for EO observations. Another one is the absence of more spatial coverage in developing countries.</p><p id="98f5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">My next article will explore the preprocessing techniques for image data. Stay tuned!</p><p id="68cf" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">References</strong></p><ul class=""><li id="b3e0" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oj oc od bk">Lavender, S., &amp; Lavender, A. (2023). <em class="ok">Practical handbook of remote sensing</em>. CRC Press.</li><li id="7451" class="nd ne fq nf b go ol nh ni gr om nk nl nm on no np nq oo ns nt nu op nw nx ny oj oc od bk">Schmitt, M., Ahmadi, S. A., Xu, Y., Taşkın, G., Verma, U., Sica, F., &amp; Hänsch, R. (2023). There are no data like more data: Datasets for deep learning in earth observation. <em class="ok">IEEE Geoscience and Remote Sensing Magazine</em>.</li></ul></div></div></div></div>    
</body>
</html>