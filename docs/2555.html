<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Cognitive Prompting in LLMs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Cognitive Prompting in LLMs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cognitive-prompting-in-llms-6234f6ab9a4b?source=collection_archive---------3-----------------------#2024-10-19">https://towardsdatascience.com/cognitive-prompting-in-llms-6234f6ab9a4b?source=collection_archive---------3-----------------------#2024-10-19</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="55e6" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Can we teach machines to think like humans?</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@Oliver_Kramer?source=post_page---byline--6234f6ab9a4b--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Oliver Kramer" class="l ep by dd de cx" src="../Images/1687be9e91f7e308df737b4d2c020116.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*fvGskjZqHzOtbXk_GO0oMA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--6234f6ab9a4b--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@Oliver_Kramer?source=post_page---byline--6234f6ab9a4b--------------------------------" rel="noopener follow">Oliver Kramer</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--6234f6ab9a4b--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 19, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/3e0141f321233bbc647675321cf0a43d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EWvoRykfbd261gsFqnr66A.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created with GPT-4o</figcaption></figure><h2 id="1408" class="nc nd fq bf ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk">Introduction</h2><p id="af2a" class="pw-post-body-paragraph oa ob fq oc b go od oe of gr og oh oi nn oj ok ol nr om on oo nv op oq or os fj bk">When I started to learn about AI one of the most fascinating ideas was that machines think like humans. But when taking a closer look at what AI and machine learning methods are actually doing, I was surprised there actually is a huge gap between what you can find in courses and books about how humans think, i.e., human cognition, and the way machines do. Examples of these gaps for me were: how a perceptron works, which is often referred to as “inspired by its biological pendant” and how real neurons work. Or how fuzzy logic tries to model human concepts of information and inference and how human inference actually seems to work. Or how humans cluster a cloud of points by looking at it and drawing circles around point clouds on a board and how algorithms like DBSCAN and k-means perform this task.</p><p id="bc4d" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">But now, LLMs like ChatGPT, Claude, and LLaMA have come into the spotlight. Based on billions or even trillions of these artificial neurons and mechanisms that also have an important part to play in cognition: attention (which is all you need obviously). We’ve come a long way, and meanwhile Nobel Prizes have been won to honor the early giants in this field. LLMs are insanely successful in summarizing articles, generating code, or even answering complex questions and being creative. A key point is — no doubts about it—the right prompt. The better you specify what you want from the model, the better is the outcome. Prompt engineering has become an evolving field, and it has even become a specialized job for humans (though I personally doubt the long-term future of this role). Numerous prompting strategies have been proposed: famous ones are Chain-of-thought (CoT) [2] or Tree-of-Thought (ToT) [3] that guide the language model reasoning step by step, mainly by providing the LLM steps of successful problem solving examples. But these steps are usually concrete examples and require an explicit design of a solution chain.</p><p id="f9e0" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">Other approaches try to optimize the prompting, for example with evolutionary algorithms (EAs) like PromptBreeder. Personally I think EAs are always a good idea. Very recently, a research team from Apple has shown that LLMs can easily be distracted from problem solving with different prompts [4]. As there are numerous good posts, also on TDS on CoT and prompt design (like <a class="af oy" rel="noopener" target="_blank" href="/create-your-own-prompt-enhancer-from-scratch-b870963a1ca0">here</a> recently), I feel no need to recap them here in more detail.</p><h2 id="8fcf" class="nc nd fq bf ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk"><strong class="al">What Is Cognitive Prompting?</strong></h2><p id="ac1a" class="pw-post-body-paragraph oa ob fq oc b go od oe of gr og oh oi nn oj ok ol nr om on oo nv op oq or os fj bk">Something is still missing, as there is obviously a gap to cognitive science. That all got me thinking: can we help these models “think” more like humans, and how? What if they could be guided by what cognitive science refers to as cognitive operations? For example, approaching a problem by breaking it down step by step, to filter out unnecessary information, and to recognize patterns that are present in the available information. Sounds a bit like what we do when solving difficult puzzles.</p><p id="f07d" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">That’s where <strong class="oc fr">cognitive prompting</strong> comes in. Imagine the AI cannot only answer your questions but also guide itself — and you when you read its output — through complex problem-solving processes by “thinking” in structured steps.</p><p id="133d" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">Imagine you’re solving a math word problem. The first thing you do is probably to clarify your goal: What exactly do I need to figure out, what is the outcome we expect? Then, you break the problem into smaller steps, a promising way is to identify relevant information, and perhaps to notice patterns that help guiding your thoughts closer toward the desired solution. In this example, let’s refer to these steps as goal clarification, decomposition, filtering, and pattern recognition. They are all examples of <strong class="oc fr">cognitive operations</strong> (COPs) we perform instinctively (or which we are taught to follow by a teacher in the best case).</p><h2 id="4654" class="nc nd fq bf ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk"><strong class="al">But How Does This Actually Work?</strong></h2><p id="4d2b" class="pw-post-body-paragraph oa ob fq oc b go od oe of gr og oh oi nn oj ok ol nr om on oo nv op oq or os fj bk">Here’s how the process unfolded. We define a sequence of COPs and ask the LLM to follow the sequence. Figure 1 shows an example of what the prompt looks like. Example COPs that turn out to be important are:</p><ul class=""><li id="20a8" class="oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os oz pa pb bk"><strong class="oc fr">Goal Clarification</strong>: The model first needed to restate the problem in a clear way — what exactly is it trying to solve, what is the desired outcome?</li><li id="0770" class="oa ob fq oc b go pc oe of gr pd oh oi nn pe ok ol nr pf on oo nv pg oq or os oz pa pb bk"><strong class="oc fr">Decomposition</strong>: Next, break the problem into manageable chunks. Instead of getting overwhelmed by all the information available, the model should focus on solving smaller parts — one at a time.</li><li id="9186" class="oa ob fq oc b go pc oe of gr pd oh oi nn pe ok ol nr pf on oo nv pg oq or os oz pa pb bk"><strong class="oc fr">Filtering</strong>: Ask the model to filter out unnecessary details, allowing it to focus on what really matters. This is often necessary to allow the model to put attention on the really important information.</li><li id="4280" class="oa ob fq oc b go pc oe of gr pd oh oi nn pe ok ol nr pf on oo nv pg oq or os oz pa pb bk"><strong class="oc fr">Pattern Recognition</strong>: Identify patterns to solve the problem efficiently. For example, if a problem involves repeated steps, ask the model to recognize a pattern and apply it.</li><li id="455d" class="oa ob fq oc b go pc oe of gr pd oh oi nn pe ok ol nr pf on oo nv pg oq or os oz pa pb bk"><strong class="oc fr">Integration</strong>: In the end it makes sense to synthesize all insights of the previous steps, in particular based on the last COPs and integrate them into a solution for the final answer.</li></ul><p id="b403" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">These structured steps mimic the way humans solve problems — logically, step by step. There are numerous further cognitive operations and the choice which to choose, which order and how to specify them for the prompt. This certainly leaves room for further improvement.</p><p id="4a84" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">We already extended the approach in the following way. Instead of following a <strong class="oc fr">deterministic</strong> order of COPs, we give the model the freedom to choose its own sequence of COPs based on the provided list — called <strong class="oc fr">self-adaptive</strong> cognitive prompting. It turns out that this approach works pretty well. In the next paragraph we compare both variants on a benchmark problem set.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/2be503ad4f150dc29b7282ab83caafe5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hnXjj2yD-6Ut5ImGUB7vuw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 1: Cognitive prompting: A general list of cognitive operations (COPs) to guide the LLM reasoning on the left, a specialized version adapted to arithmetic reasoning on the right.</figcaption></figure><p id="0b3b" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">What also turns out to improve the performance is adapting the COP descriptions to the specific problem domain. Figure 1, right, shows an example of a math-specific adaptation of the general COPs. They “unroll” to prompts like “Define each variable clearly” or “Solve the equations step by step”.</p><p id="ae73" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">In practice, it makes sense to advise the model to give the final answer as a JSON string. Some LLMs do not deliver a solution, but Python code to solve the problem. In our experimental analysis, we were fair and ran the code treating the answer as correct when the Python code returns the correct result.</p><h2 id="38ac" class="nc nd fq bf ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk">Example</h2><p id="fbdc" class="pw-post-body-paragraph oa ob fq oc b go od oe of gr og oh oi nn oj ok ol nr om on oo nv op oq or os fj bk">Let’s give a short example asking LLaMA3.1 70B to solve one of the 8.5k arithmetic problems from GSM8K [5]. Figure 2 shows the request.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pi"><img src="../Images/03d4b674bbf5dee7aa31b46322fb372e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vipCEjeK2JWt6Q18CKRC2w.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 2: Here is an example for arithmetic reasoning using deterministic cognitive prompting.</figcaption></figure><p id="fc54" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">Figure 3 shows the model’s output leading to a correct answer. It turns out the model systematically follows the sequence of COPs — even providing a nice problem-solving explanation for humans.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pj"><img src="../Images/faa60de9df990a31eeceea2dc90ee9c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MkS4gGJOsr8otOE_P61r7A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 3: Output of LLaMA3.1 70B to the cognitive prompting-based problem solution request of Figure 3.</figcaption></figure><h2 id="6aa1" class="nc nd fq bf ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk"><strong class="al">How Does Cognitive Prompting Perform — Scientifically?</strong></h2><p id="052d" class="pw-post-body-paragraph oa ob fq oc b go od oe of gr og oh oi nn oj ok ol nr om on oo nv op oq or os fj bk">Now, let’s become a little more systematic by testing cognitive prompting on a typical benchmark. We tested it on a set of math problems from the GSM8K [5] dataset — basically, a collection of math questions you’d find in grade school. Again, we used Meta’s LLaMA models to see if cognitive prompting could improve their problem-solving skills, appliying LLaMA with 8 billion parameters and the much larger version with 70 billion parameters.</p><p id="7e85" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">Figure 4 shows some results. The smaller model improved slightly with deterministic cognitive prompting. Maybe it is not big enough to handle the complexity of structured thinking. When it selects an own sequence of COPs, the win in performance is significantly.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pk"><img src="../Images/faf494200350f635af5db4e5a8998bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3EzRNecQYXTpCUKrrxOHaw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure 4: Results of Cognitive Prompting on GSM8k benchmark on the left and a histogram of chosen COP sequences on the right (goal clarification (GC), decomposition (DC), pattern recognition (PR), generalization (GN), and reorganization (RE)).</figcaption></figure><p id="cfff" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">Without cognitive prompting, the larger model scored about 87% on the math problems. When we added <strong class="oc fr">deterministic cognitive prompting</strong> (where the model followed a fixed sequence of cognitive steps), its score jumped to 89%. But when we allowed the model to adapt and choose the cognitive operations dynamically (self-adaptive prompting), the score shot up to 91%. Not bad for a machine getting quite general advice to reason like a human — without additional examples , right?</p><h2 id="05a2" class="nc nd fq bf ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk"><strong class="al">Why Does This Matter?</strong></h2><p id="74b9" class="pw-post-body-paragraph oa ob fq oc b go od oe of gr og oh oi nn oj ok ol nr om on oo nv op oq or os fj bk">Cognitive prompting is a method that organizes these human-like cognitive operations into a structured process and uses them to help LLMs solve complex problems. In essence, it’s like giving the model a structured “thinking strategy” to follow. While earlier approaches like CoT have been helpful, cognitive prompting offers even deeper reasoning layers by incorporating a variety of cognitive operations.</p><p id="2b53" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">This has exciting implications beyond math problems! Think about areas like decision-making, logical reasoning, or even creativity — tasks that require more than just regurgitating facts or predicting the next word in a sentence. By teaching AI to think more like us, we open the door to models that can reason through problems in ways that are closer to human cognition.</p><h2 id="da13" class="nc nd fq bf ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk"><strong class="al">Where Do We Go From Here?</strong></h2><p id="dffa" class="pw-post-body-paragraph oa ob fq oc b go od oe of gr og oh oi nn oj ok ol nr om on oo nv op oq or os fj bk">The results are promising, but this is just the beginning. Cognitive prompting could be adapted for other domains for sure, but it can also be combined with other ideas from AI. As we explore more advanced versions of cognitive prompting, the next big challenge will be figuring out how to optimize it across different problem types. Who knows? Maybe one day, we’ll have AI that can tackle anything from math problems to moral dilemmas, all while thinking as logically and creatively as we do. Have fun trying out cognitive prompting on your own!</p><h2 id="5d3c" class="nc nd fq bf ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk">References</h2><p id="953a" class="pw-post-body-paragraph oa ob fq oc b go od oe of gr og oh oi nn oj ok ol nr om on oo nv op oq or os fj bk">[1] O. Kramer, J. Baumann. <a class="af oy" href="https://arxiv.org/abs/2410.02953" rel="noopener ugc nofollow" target="_blank">Unlocking Structured Thinking in Language Models with Cognitive Prompting</a> (arXiv)</p><p id="705b" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">[2] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. H. Chi, Q. V. Le, and D. Zhou. Chain-of-thought prompting elicits reasoning in large language models. In S. Koyejo, S. Mohamed, A. Agarwal, D. Bel- grave, K. Cho, and A. Oh, editors, Neural Information Processing Systems (NeurIPS) Workshop, volume 35, pages 24824–24837, 2022</p><p id="b89c" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">[3] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y. Cao, and K. Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. In Neural Information Processing Systems (NeurIPS), volume 36, pages 11809–11822, 2023</p><p id="a82e" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">[4] I. Mirzadeh, K. Alizadeh, H. Shahrokhi, O. Tuzel, S. Bengio, and M. Farajtabar. <a class="af oy" href="https://arxiv.org/pdf/2410.05229" rel="noopener ugc nofollow" target="_blank">GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models.</a> 2024.</p><p id="25fa" class="pw-post-body-paragraph oa ob fq oc b go ot oe of gr ou oh oi nn ov ok ol nr ow on oo nv ox oq or os fj bk">[5] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plap- pert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and J. Schulman. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.</p></div></div></div></div>    
</body>
</html>