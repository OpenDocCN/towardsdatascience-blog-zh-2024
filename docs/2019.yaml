- en: 'K Nearest Neighbor Classifier, Explained: A Visual Guide with Code Examples
    for Beginners'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K最近邻分类器解析：初学者的可视化指南与代码示例
- en: 原文：[https://towardsdatascience.com/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=collection_archive---------2-----------------------#2024-08-20](https://towardsdatascience.com/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=collection_archive---------2-----------------------#2024-08-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=collection_archive---------2-----------------------#2024-08-20](https://towardsdatascience.com/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=collection_archive---------2-----------------------#2024-08-20)
- en: CLASSIFICATION ALGORITHM
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: The friendly neighbor approach to machine learning
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习中的友好邻居方法
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------)
    ·8 min read·Aug 20, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------)
    ·阅读时间：8分钟·2024年8月20日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/31276134251efc679092597eaa9db567.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31276134251efc679092597eaa9db567.png)'
- en: '`⛳️ More CLASSIFICATION ALGORITHM, explained: · [Dummy Classifier](/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    ▶ [K Nearest Neighbor Classifier](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    · [Bernoulli Naive Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)
    · [Gaussian Naive Bayes](/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c)
    · [Decision Tree Classifier](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    · [Logistic Regression](/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505)
    · [Support Vector Classifier](/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9)
    · [Multilayer Perceptron](/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c)`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`⛳️ 更多分类算法解析：· [虚拟分类器](/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    ▶ [K最近邻分类器](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    · [伯努利朴素贝叶斯](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)
    · [高斯朴素贝叶斯](/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c)
    · [决策树分类器](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    · [逻辑回归](/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505)
    · [支持向量分类器](/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9)
    · [多层感知机](/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c)`'
- en: Imagine a method that makes predictions by looking at the most similar examples
    it has seen before. This is the essence of the Nearest Neighbor Classifier — a
    simple yet intuitive algorithm that brings a touch of real-world logic to machine
    learning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一种方法，通过查看之前见过的最相似的例子来做出预测。这就是最近邻分类器的本质——一个简单而直观的算法，它为机器学习带来了一丝现实世界的逻辑。
- en: 'While the [dummy classifier](https://medium.com/towards-data-science/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    sets the bare minimum performance standard, the Nearest Neighbor approach mimics
    how we often make decisions in daily life: by recalling similar past experiences.
    It’s like asking your neighbors how they dressed for today’s weather to decide
    what you should wear. In the realm of data science, this classifier examines the
    closest data points to make its predictions.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 [虚拟分类器](https://medium.com/towards-data-science/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)设定了最低的性能标准，但最近邻方法模仿了我们在日常生活中做决策的方式：通过回忆类似的过去经历。这就像是问你的邻居今天根据天气如何穿衣，从而决定你应该穿什么。在数据科学领域，这个分类器通过检查最接近的数据点来做出预测。
- en: '![](../Images/b075e06729583b9a5f90a9ee64a83e9d.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b075e06729583b9a5f90a9ee64a83e9d.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有视觉元素：作者使用 Canva Pro 创建。已优化为适合移动设备；在桌面上可能会显得过大。
- en: Definition
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: A K Nearest Neighbor classifier is a machine learning model that makes predictions
    based on the majority class of the K nearest data points in the feature space.
    The KNN algorithm assumes that similar things exist in close proximity, making
    it intuitive and easy to understand.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: K 最近邻分类器是一个机器学习模型，它根据特征空间中 K 个最近数据点的多数类别来做出预测。KNN 算法假设相似的事物会存在于近距离内，这使得它直观且易于理解。
- en: '![](../Images/9ac3c976bc1cc4b51aa375372d697de8.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ac3c976bc1cc4b51aa375372d697de8.png)'
- en: Nearest Neighbor methods is one of the simplest algorithms in machine learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻方法是机器学习中最简单的算法之一。
- en: 📊 Dataset Used
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 📊 使用的数据集
- en: Throughout this article, we’ll use this simple artificial golf dataset (inspired
    by [1]) as an example. This dataset predicts whether a person will play golf based
    on weather conditions. It includes features like outlook, temperature, humidity,
    and wind, with the target variable being whether to play golf or not.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将使用这个简单的人工高尔夫数据集（灵感来自 [1]）作为例子。这个数据集预测一个人是否会根据天气条件打高尔夫。它包括天气、温度、湿度和风等特征，目标变量是是否打高尔夫。
- en: '![](../Images/e0709936f67841828da150d4160270fd.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0709936f67841828da150d4160270fd.png)'
- en: 'Columns: ‘Outlook’, ‘Temperature’, ‘Humidity’, ‘Wind’ and ‘Play’ (target feature)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 列：‘Outlook’（天气）、‘Temperature’（温度）、‘Humidity’（湿度）、‘Wind’（风）和‘Play’（目标特征）
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: KNN algorithm requires the data to be scaled first. [Convert categorical columns](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    into 0 & 1 and also [scale the numerical features](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    so that no single feature dominates the distance metric.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: KNN 算法要求首先对数据进行缩放。[将类别列转换](https://encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)为
    0 和 1，并且 [缩放数值特征](https://scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)，以确保没有单个特征主导距离度量。
- en: '![](../Images/2e13dc4bed27647caca187226dffff37.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e13dc4bed27647caca187226dffff37.png)'
- en: The categorical columns (Outlook & Windy) are encoded using one-hot encoding
    while the numerical columns are scaled using standard scaling (z-normalization).
    The process is done separately for training and test set.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 类别列（天气和风）使用独热编码进行编码，而数值列则使用标准化缩放（z 标准化）。此过程分别在训练集和测试集上进行。
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Main Mechanism
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要机制
- en: 'The KNN classifier operates by finding the K nearest neighbors to a new data
    point and then voting on the most common class among these neighbors. Here’s how
    it works:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: KNN 分类器通过找到离新数据点最近的 K 个邻居，然后对这些邻居中最常见的类别进行投票来进行工作。以下是其工作原理：
- en: Calculate the distance between the new data point and all points in the training
    set.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算新数据点与训练集中的所有点之间的距离。
- en: Select the K nearest neighbors based on these distances.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据这些距离选择 K 个最近的邻居。
- en: Take a majority vote of the classes of these K neighbors.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对这 K 个邻居的类别进行多数投票。
- en: Assign the majority class to the new data point.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将多数类别分配给新数据点。
- en: '![](../Images/72b63fbec5470322fed4ac538be8259b.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72b63fbec5470322fed4ac538be8259b.png)'
- en: For our golf dataset, a KNN classifier might look at the 5 most similar weather
    conditions in the past to predict whether someone will play golf today.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的高尔夫数据集，KNN 分类器可能会查看过去 5 个最相似的天气条件，以预测某人今天是否会打高尔夫。
- en: Training Steps
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练步骤
- en: 'Unlike many other algorithms, KNN doesn’t have a distinct training phase. Instead,
    it memorizes the entire training dataset. Here’s the process:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多其他算法不同，KNN 没有明确的训练阶段。相反，它记住整个训练数据集。以下是其过程：
- en: Choose a value for K (the number of neighbors to consider).
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个 K 值（要考虑的邻居数量）。
- en: '![](../Images/7bc23cbaf9d209db5e3ecfcb5ecf63f3.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7bc23cbaf9d209db5e3ecfcb5ecf63f3.png)'
- en: In 2D setting, it is like finding the majority of the closest colors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2D 设置中，就像是找出最接近的颜色的多数。
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 2\. Select a distance metric (e.g., Euclidean distance, Manhattan distance).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 选择一个距离度量（例如，欧几里得距离、曼哈顿距离）。
- en: '![](../Images/d2a1cd84b7e89aeac60d229ee175f395.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2a1cd84b7e89aeac60d229ee175f395.png)'
- en: The most common distance metric is Euclidean Distance. This is just like finding
    the straight line distance between two points in real world.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的距离度量是欧几里得距离。这就像是找出两个点之间的直线距离。
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 3\. Store/Memorize all the training data points and their corresponding labels.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 存储/记住所有训练数据点及其对应的标签。
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Classification Steps
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类步骤
- en: 'Once the Nearest Neighbor Classifier has been “trained” (i.e., the training
    data has been stored), here’s how it makes predictions for new instances:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦最近邻分类器被“训练”（即训练数据已存储），它将如何为新实例做出预测：
- en: '**Distance Calculation**: For the new instance, calculate its distance from
    all stored training instances using the chosen distance metric.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**距离计算**：对于新的实例，使用选择的距离度量计算其与所有存储的训练实例之间的距离。'
- en: '![](../Images/0fe732ea0723d899d9d69b95fabffd38.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0fe732ea0723d899d9d69b95fabffd38.png)'
- en: For ID 14, we calculate the distance to each member of the training set (ID
    0 — ID 13).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 ID 14，我们计算其与训练集每个成员（ID 0 — ID 13）之间的距离。
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '2\. **Neighbor Selection and Prediction**: Identify the K nearest neighbors
    based on the calculated distances, then assign the most common class among these
    neighbors as the predicted class for the new instance.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **邻居选择与预测**：基于计算的距离，识别 K 个最近的邻居，然后将这些邻居中最常见的类作为新实例的预测类。
- en: '![](../Images/544c2bf36d8672ed8b43a4cb302c1946.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/544c2bf36d8672ed8b43a4cb302c1946.png)'
- en: After calculating its distance to all stored data points and sorting from lowest
    to highest, we identify the 5 nearest neighbors (top 5). If the majority (3 or
    more) of these neighbors are labeled “NO”, we predict “NO” for ID 14.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算了它与所有存储数据点的距离，并按从低到高排序后，我们识别出 5 个最近的邻居（前 5）。如果这些邻居中大多数（3 个或更多）标记为“NO”，我们为
    ID 14 预测“NO”。
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Evaluation Step
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估步骤
- en: '![](../Images/0b41962fcacac9d33decd7f1a5c31a3a.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b41962fcacac9d33decd7f1a5c31a3a.png)'
- en: With this simple model, we manage to get good enough accuracy, much better than
    [guessing randomly](https://medium.com/towards-data-science/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个简单的模型，我们能获得足够好的准确性，远远优于[随机猜测](https://medium.com/towards-data-science/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)!
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Key Parameters
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键参数
- en: 'While KNN is conceptually simple, it does have a few important parameters:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 KNN 在概念上简单，但它确实有一些重要的参数：
- en: '**K**: The number of neighbors to consider. A smaller K can lead to noise-sensitive
    results, while a larger K may smooth out the decision boundary.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**K**：要考虑的邻居数量。较小的 K 值可能导致对噪声敏感的结果，而较大的 K 值可能会平滑决策边界。'
- en: '![](../Images/f6a1c3b887adfb52913295c5fc34fc61.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6a1c3b887adfb52913295c5fc34fc61.png)'
- en: The higher the value of k, the more likely that it will select the majority
    class (”YES”).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: k 值越大，越有可能选择大多数类（“YES”）。
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '2\. **Distance Metric**: This determines how similarity between points is calculated.
    Common options include:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **距离度量**：这决定了点与点之间相似度的计算方式。常见选项包括：
- en: Euclidean distance (straight-line distance)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欧几里得距离（直线距离）
- en: Manhattan distance (sum of absolute differences)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曼哈顿距离（绝对差值之和）
- en: Minkowski distance (a generalization of Euclidean and Manhattan distances)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 闵可夫斯基距离（欧几里得距离和曼哈顿距离的泛化）
- en: '3\. **Weight Function**: This decides how to weight the contribution of each
    neighbor. Options include:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. **权重函数**：这决定了如何对每个邻居的贡献进行加权。选项包括：
- en: '‘uniform’: All neighbors are weighted equally.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ‘uniform’：所有邻居的权重相等。
- en: '‘distance’: Closer neighbors have a greater influence than those farther away.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ‘distance’：较近的邻居比较远的邻居对结果有更大的影响。
- en: Pros & Cons
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优缺点
- en: Like any algorithm in machine learning, KNN has its strengths and limitations.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 就像机器学习中的任何算法一样，KNN 也有其优点和局限性。
- en: 'Pros:'
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优点：
- en: '**Simplicity**: Easy to understand and implement.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**简洁性**：容易理解和实现。'
- en: '**No Assumptions**: Doesn’t assume anything about the data distribution.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无假设**：不对数据分布做任何假设。'
- en: '**Versatility**: Can be used for both classification and regression tasks.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多功能性**：可以用于分类和回归任务。'
- en: '**No Training Phase**: Can quickly incorporate new data without retraining.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无需训练阶段**：可以快速整合新数据，无需重新训练。'
- en: 'Cons:'
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺点：
- en: '**Computationally Expensive**: Needs to compute distances to all training samples
    for each prediction.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算开销大**：每次预测时需要计算所有训练样本的距离。'
- en: '**Memory Intensive**: Requires storing all training data.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**内存密集型**：需要存储所有训练数据。'
- en: '**Sensitive to Irrelevant Features**: Can be thrown off by features that aren’t
    important to the classification.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对无关特征敏感**：可能会受到与分类无关的特征的干扰。'
- en: '**Curse of Dimensionality**: Performance degrades in high-dimensional spaces.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**维度灾难**：在高维空间中，性能会下降。'
- en: Final Remarks
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后备注
- en: The K-Nearest Neighbors (KNN) classifier stands out as a fundamental algorithm
    in machine learning, offering an intuitive and effective approach to classification
    tasks. Its simplicity makes it an ideal starting point for beginners, while its
    versatility ensures its value for experienced data scientists. KNN’s power lies
    in its ability to make predictions based on the proximity of data points, without
    requiring complex training processes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: K 最近邻（KNN）分类器作为机器学习中的基础算法，因其直观且高效的分类方法而脱颖而出。其简单性使其成为初学者的理想起点，而其多功能性确保了对经验丰富的数据科学家的价值。KNN
    的强大之处在于，它能够根据数据点的接近度进行预测，无需复杂的训练过程。
- en: However, it’s crucial to remember that KNN is just one tool in the vast machine
    learning toolkit. As you progress in your data science journey, use KNN as a stepping
    stone to understand more complex algorithms, always considering your specific
    data characteristics and problem requirements when choosing a model. By mastering
    KNN, you’ll gain valuable insights into classification techniques, setting a strong
    foundation for tackling more advanced machine learning challenges.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，必须记住，KNN 只是庞大机器学习工具箱中的一个工具。在数据科学旅程中前进时，可以将 KNN 作为理解更复杂算法的垫脚石，在选择模型时始终考虑你的数据特性和问题需求。通过掌握
    KNN，你将获得对分类技术的宝贵见解，为应对更复杂的机器学习挑战奠定坚实的基础。
- en: 🌟 k Nearest Neighbor Classifier Code Summarized
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🌟 k 最近邻分类器代码总结
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Further Reading
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: For a detailed explanation of the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
    and its implementation in scikit-learn, readers can refer to the official documentation
    [2], which provides comprehensive information on its usage and parameters.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 若想详细了解 [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
    及其在 scikit-learn 中的实现，读者可以参考官方文档 [2]，该文档提供了关于其用法和参数的详细信息。
- en: Technical Environment
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术环境
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用 Python 3.7 和 scikit-learn 1.5。虽然所讨论的概念通常适用，但不同版本之间的具体代码实现可能会有所不同。
- en: About the Illustrations
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插图说明
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者创作，融合了 Canva Pro 的授权设计元素。
- en: '![](../Images/ec10b257f55a9fa724d5f1978f5b3572.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec10b257f55a9fa724d5f1978f5b3572.png)'
- en: For a concise visual summary of K Nearest Neighbor, check out [the companion
    Instagram post.](https://www.instagram.com/p/C-ssgsAyFSI)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如需简明的 K 最近邻视觉总结，请查看 [配套 Instagram 帖子。](https://www.instagram.com/p/C-ssgsAyFSI)
- en: Reference
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] T. M. Mitchell, [Machine Learning](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)
    (1997), McGraw-Hill Science/Engineering/Math, pp. 59'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] T. M. Mitchell, [机器学习](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)（1997），麦格劳-希尔科学/工程/数学，
    第59页'
- en: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘾𝙡𝙖𝙨𝙨𝙞𝙛𝙞𝙘𝙖𝙩𝙞𝙤𝙣 𝘼𝙡𝙜𝙤𝙧𝙞𝙩𝙝𝙢𝙨 𝙝𝙚𝙧𝙚:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘾𝙡𝙖𝙨𝙨𝙞𝙛𝙞𝙘𝙖𝙩𝙞𝙤𝙣 𝘼𝙡𝙜𝙤𝙧𝙞𝙩𝙝𝙢𝙨 𝙝𝙚𝙧𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)'
- en: Classification Algorithms
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----a3d85cad00e1--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----a3d85cad00e1--------------------------------)8个故事![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
- en: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)'
- en: Regression Algorithms
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归算法
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----a3d85cad00e1--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This “dummy” doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----a3d85cad00e1--------------------------------)5个故事![一个带着辫子和粉色帽子的卡通玩偶。这个“假人”玩偶，通过其简单的设计和心形装饰的衣服，形象地代表了机器学习中假回归器的概念。就像这个玩具般的形象是对人的简化静态表现，假回归器则是作为基准模型，供更复杂的分析使用。](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)'
- en: Ensemble Learning
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成学习
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----a3d85cad00e1--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----a3d85cad00e1--------------------------------)4个故事![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
