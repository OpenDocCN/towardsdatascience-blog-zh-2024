<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>ASCVIT V1: Automatic Statistical Calculation, Visualization, and Interpretation Tool</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>ASCVIT V1: Automatic Statistical Calculation, Visualization, and Interpretation Tool</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ascvit-v1-automatic-statistical-calculation-visualization-and-interpretation-tool-aa910001a3a7?source=collection_archive---------2-----------------------#2024-09-16">https://towardsdatascience.com/ascvit-v1-automatic-statistical-calculation-visualization-and-interpretation-tool-aa910001a3a7?source=collection_archive---------2-----------------------#2024-09-16</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="8388" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Automated data analysis made easy: The first version of ASCVIT, the tool for statistical calculation, visualization, and interpretation</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@stefanpietrusky?source=post_page---byline--aa910001a3a7--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Stefan Pietrusky" class="l ep by dd de cx" src="../Images/f5abf75db277f3aec8d8e56877daafe4.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*_XYa6lOVGzIsZ67doGI91w.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--aa910001a3a7--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@stefanpietrusky?source=post_page---byline--aa910001a3a7--------------------------------" rel="noopener follow">Stefan Pietrusky</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--aa910001a3a7--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">30 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 16, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="ebc8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">During my studies, I attended a data science seminar and came into contact with the statistical programming language R for the first time. At the time, I was fascinated by the resulting potential uses. In the meantime, the statistical evaluation of data has become easier thanks to developments in the field of machine learning. Of course, a certain level of technical understanding is required, and you need to know what certain methods actually do. It is also necessary to know what data or input is required for certain methods to work at all or deliver meaningful results. In this article, I would like to discuss the development of a first version (V1) of a local app that can be used to automatically apply various statistical methods to any datasets. This is an open source project for educational and research purposes.</p><p id="7c87" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The data can be uploaded in either .csv or .xlsx format. The first version of the app provides a general data overview (data preview, data description, number of data points and categorization of variables), analyses in the field of descriptive statistics (histogram, boxplot, pairplot and correlation matrix), various hypothesis tests (t-test, ANOVA and chi-square test), regression analyses (linear, logistic and multivariate), time series analysis and supports various clustering methods (k-means, hierarchical and DBSCAN). The app is created using the Python framework Streamlit.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nh"><img src="../Images/2aeaafcbbff406fea620a84e506c2e8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c0i-eO0rYZ0zi9GvuI6d8A.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Overview of analysis methods (Image by author)</figcaption></figure><p id="9bc0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Due to the modular structure of the code, further statistical procedures can be easily implemented. The code is commented, which makes it easier to find your way around. When the app is executed, the interface looks like this after a dataset has been uploaded.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng ny"><img src="../Images/e7b5a06c2d4276d7fc811f32eb999b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l5sGIdJ8_dZ0TJiIU9qhLA.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Streamlit App (Image by author)</figcaption></figure><p id="a3bb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In addition to the automatic analysis in the various areas mentioned, a function has also been integrated that automatically analyses the statistically recorded values. The <em class="nz">“query_llm_via_cli” </em>function enables an exchange via CLI (command line interface) with an LLM using Ollama.</p><p id="eebc" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">I have already explained this principle in an article published on <a class="af oa" href="https://medium.com/towards-data-science/how-to-talk-to-a-pdf-file-without-using-proprietary-models-cli-streamlit-ollama-6c22437ed932" rel="noopener"><strong class="ml fr">Towards Data Science</strong></a> [1]. In the first version of the app, this functionality is only limited to the descriptive statistical analyses, but can also be transferred to the others. In concrete terms, this means that in addition to the automatic statistical calculation, the app also automatically interprets the data.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng ob"><img src="../Images/72272ad4d80906cdb2f175181563da74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O6x20FDFAyjHeQ6jxxuykg.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 CLI + OLLAMA + LMS (Image by author)</figcaption></figure><h2 id="e6cc" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">DATASET FOR TESTING THE APP</h2><p id="752c" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">If you do not have your own data available, there are various sites on the internet that provide datasets free of charge. The dataset used for the development and testing of the app comes from <a class="af oa" href="https://mavenanalytics.io/data-playground?accessType=open&amp;order=date_added%2Cdesc&amp;page=1&amp;pageSize=5" rel="noopener ugc nofollow" target="_blank"><strong class="ml fr">Maven Analytics</strong></a><strong class="ml fr"> </strong>(License: ODC-BY) [2].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pc"><img src="../Images/544d667fb9fd8ddd3896b0d2c5920415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYLHliBsikwgDfb1DQC9-g.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">MAVEN Analytics Data Playground (Screenshot by author)</figcaption></figure><p id="d51c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">There are numerous free datasets on the site. The data I have examined deals with the sales figures of video games in the period from 1976 to 2024. Specifically, it is the sales figures from North America, Japan, the EU, Africa and the rest of the world. A total of 64016 titles and their rating, genre, console, etc. are recorded.</p><p id="29a0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Unfortunately, not all information is available for all titles. There are many NaN (Not a Number) values that cause problems when analysed in Python or distort specific statistical analyses. I will briefly discuss the cleansing of data records below.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pd"><img src="../Images/193f5b427ac3d2335be5cdf1d3387001.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V6IrSFYIe5yJCGAug55x1Q.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Video Games Sales data from MAVEN Analytics (Screenshot by author)</figcaption></figure><h2 id="021e" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">CLEAN UP THE DATASET</h2><p id="6d3c" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">You can either clean the dataset before loading it into the app using a separate script, or you can perform the cleanup directly in the app. For the application in this article, I have implemented data cleansing directly in the app. If you want to clean up data records beforehand, you can do this using the following script.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="02cf" class="pi od fq pf b bg pj pk l pl pm">import pandas as pd<br/><br/>df = pd.read_csv('YOUR .CSV FILE')<br/>df_cleaned = df.dropna()<br/>df_cleaned.to_csv('cleaned_file.csv', index=False)<br/><br/>print("Lines with missing data have been removed and saved in 'cleaned_file.csv'.")</span></pre><p id="914d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The file is read using <em class="nz">“pd.read_csv(‘.csv’)”</em> and the data is saved in the DataFrame “df”. df.dropna()” removes all lines in the DataFrame that contain missing values ‘NaN’. The cleaned DataFrame is then saved in the variable <em class="nz">“df_cleaned”</em>. The data is saved in a new .csv file using <em class="nz">“df_cleaned.to_csv(‘cleaned_file.csv’, index=False)”</em>. Line indices are not saved. This is followed by an output for the successfully completed process <em class="nz">“print(…)”</em>. The code for this dataset cleanup can be found in the file <em class="nz">“clean.py”</em> and can also be downloaded later. Next, let’s move on to the actual code of the app.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pn"><img src="../Images/ede7322dd5c84e374c7cc838afe3d6cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LACppaDySWtAn8STFZXotg.gif"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Python Code snippet (GIF by author)</figcaption></figure><h2 id="7ca4" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">LIBRARIES AND MODULES THAT ARE REQUIRED</h2><p id="7569" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">To use the app, various libraries and modules are required, which in combination perform data visualization, statistical analysis and machine learning tasks.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="c54b" class="pi od fq pf b bg pj pk l pl pm">import re<br/>import subprocess<br/><br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import pandas as pd<br/>import plotly.express as px  <br/>import plotly.graph_objects as go  <br/>import seaborn as sns<br/>from matplotlib.patches import Patch<br/>from scipy import stats<br/>from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN<br/>from sklearn.decomposition import PCA<br/>from sklearn.linear_model import LinearRegression, LogisticRegression<br/>from statsmodels.stats.multicomp import pairwise_tukeyhsd<br/><br/>import streamlit as st</span></pre><p id="49f9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">A note regarding the representation of the diagrams. </strong>Some use <em class="nz">“pyplot” </em>(Matplotlib) and others use <em class="nz">“plotly”</em> (e.g. Boxplot). Even if the use of <em class="nz">“plotly” </em>leads to more interactive graphics, it does not make sense to use it for every type of diagram. Ultimately, the user must decide individually how the diagrams should be displayed. The code must be adapted accordingly.</p><p id="695d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The required libraries for the application can be installed using the requirements.txt file in the ZIP directory with the following command.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="ed88" class="pi od fq pf b bg pj pk l pl pm">pip install -r requirements.txt</span></pre><h2 id="1539" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">THE DATA OVERVIEW</h2><p id="87e4" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The function <em class="nz">“display_data_info()”</em> specifically analyses the Pandas DataFrame <em class="nz">“df”</em> and outputs statistical key figures (mean value, standard deviation, etc.) <em class="nz">“df.describe()”</em>. The total number of data points (rows) of the DataFrame is output <em class="nz">“len(df)”</em>. Likewise, the numerical <em class="nz">“numerical_columns” </em>and categorical <em class="nz">“categorical_columns” </em>(strings) variables of the DataFrame.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng po"><img src="../Images/7ebc74d3ca69d370554105df06d51e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*51k7uzslsOyujaC8D0gyBg.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 App Data Overviews (Image by author)</figcaption></figure><p id="ce0c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The dataset has a total of 64016 data points and 6 numerical and 8 categorical variables. Before you start with certain statistical procedures, you should first look at the data. In the <em class="nz">“Data overview” </em>section, you can obtain various information to draw conclusions whether certain tests can be carried out at all.</p><p id="03ad" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For example, if there is no date variable in the dataset, no time series analysis can be carried out. If there is no binary variable, no logistic regression can be carried out. The app is already designed to ask for certain variable categories or to display error messages if incorrect values are transmitted. Next, let’s move on to descriptive statistics.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="a33c" class="pi od fq pf b bg pj pk l pl pm">def display_data_info(df):<br/>    st.write("**Data description:**")<br/>    st.write(df.describe())<br/>    st.write(f"**Number of data points:** {len(df)}")<br/>    <br/>    numerical_columns = df.select_dtypes(include=np.number).columns.tolist()<br/>    categorical_columns = df.select_dtypes(include='object').columns.tolist()<br/><br/>    st.write("**Numerical variables:** ", ", ".join(numerical_columns))<br/>    st.write("**Categorical variables:** ", ", ".join(categorical_columns))<br/>    <br/>    return numerical_columns, categorical_columns</span></pre><h2 id="e47c" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">DESCRIPTIVE STATISTICS</h2><p id="44ad" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The <em class="nz">“descriptive_statistics()”</em> function allows the user to select different chart types (histogram, boxplot, pairplot and correlation matrix). A brief explanation of the type follows via <em class="nz">“st.markdown(”“”…“”“)”</em>. One or more numerical variables must then be selected “selected_vars”. The option whether logarithmic scaling <em class="nz">“apply_log_scale”</em> should be applied is available, except for the correlation matrix. Applying logarithmic scaling to a variable is particularly useful if the data is heavily distorted. The visualization is created using the corresponding diagram function.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="153a" class="pi od fq pf b bg pj pk l pl pm">def descriptive_statistics(df, numerical_columns):<br/>    chart_type = st.selectbox("Select the diagram:", ["Histogram", "Boxplot", "Pairplot", "Correlation matrix"])<br/>    <br/>    if chart_type == "Histogram":<br/>        st.markdown("""<br/>        **Histogram:**<br/>        A histogram shows the distribution of a numerical variable. It helps to <br/>        recognize how frequently certain values occur in the data and whether there are patterns, such as a normal distribution.<br/>        """)<br/>    elif chart_type == "Boxplot":<br/>        st.markdown("""<br/>        **Boxplot:**<br/>        A boxplot shows the distribution of a numerical variable through its quartiles. <br/>        It helps to identify outliers and visualize the dispersion of the data.<br/>        """)<br/>    elif chart_type == "Pairplot":<br/>        st.markdown("""<br/>        **Pairplot:**<br/>        A pairplot shows the relationships between different numerical variables through scatterplots.<br/>        It helps to identify possible relationships between variables.<br/>        """)<br/>    elif chart_type == "Correlation matrix":<br/>        st.markdown("""<br/>        *Correlation matrix:**<br/>        The correlation matrix shows the linear relationships between numerical variables.<br/>        A positive correlation indicates that high values in one variable also correlate with high values in another.<br/>        """)<br/><br/>    if chart_type in ["Pairplot", "Correlation matrix"]:<br/>        selected_vars = st.multiselect("Select variables:", numerical_columns, default=numerical_columns)<br/>    else:<br/>        selected_vars = [st.selectbox("Select a variable:", numerical_columns)]<br/>    <br/>    if chart_type != "Correlation matrix":<br/>        apply_log_scale = st.checkbox("Apply logarithmic scaling?", value=False)<br/>    else:<br/>        apply_log_scale = False <br/>    <br/>    if st.button("Create diagram"):<br/>        if chart_type == "Histogram":<br/>            plot_histogram(df, selected_vars[0], apply_log_scale)<br/>        elif chart_type == "Boxplot":<br/>            plot_boxplot(df, selected_vars[0], apply_log_scale)<br/>        elif chart_type == "Pairplot":<br/>            plot_pairplot(df, selected_vars)<br/>        elif chart_type == "Correlation matrix":<br/>            plot_correlation_matrix(df, selected_vars)</span></pre><h2 id="c906" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">THE HISTOGRAM FUNCTION</h2><p id="8c50" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The <em class="nz">“plot_histogram()”</em> function is used to create the histogram depending on the variable selected by the user. At the beginning, all NaN values are removed from the variable <em class="nz">“cleaned_data”</em>. Various statistical key figures (mean value <em class="nz">“mean_value”</em>, median <em class="nz">“median_value”</em>, standard deviation <em class="nz">“std_value”</em>, minimum <em class="nz">“min_value”</em> and maximum <em class="nz">“max_value” </em>and the upper and lower end of the standard deviation) are calculated.</p><p id="061c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Since the data is interpreted by an LLM, as mentioned at the beginning, the dispersion (standard deviation in relation to the range of the data) and distribution (difference between mean and median) of the data is classified. The histogram is created <em class="nz">“fix, ax = plt.subplots()”</em>, vertical lines are added to increase the informative value and finally the histogram is displayed <em class="nz">“st.pyplot(fig)”</em>. In the case of distorted or exponential data, logarithmic scaling can be activated, whereupon the y-axis of the histogram is adjusted. The graph then looks as follows [3].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pp"><img src="../Images/474b62510e5c5d8f8e38a129f663484f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kk0lpEvpJet-j7YXzZgVMg.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Histogram (pyplot) of critic_score and LLM interpretation (Image by author)</figcaption></figure><p id="cf6e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">As there are no models that can read out graphics directly, we create a universal context for the analysis by the LLM. The context contains the results of the statistical calculation and additional instructions or the desired interpretation. This means that the context, which serves as input for the LLM, can be applied to any dataset.</p><p id="5191" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Specifically, the input includes the aforementioned statistical key figures, an analysis of the distribution (symmetrical, right-skewed or left-skewed), an estimate of the spread (low, moderate or high) and an interpretation formatted for the LLM. Depending on the desired output, the context can be individually adapted and further specified.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pq"><img src="../Images/33136ad371a7207a0887e3d72893bdcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gpuc_BO6-Ksh8yhruigt5Q.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">LLM context example (Image by author)</figcaption></figure><p id="71e5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The analysis is sent to the LLM <em class="nz">“response = query_llm_via_cli(context)”</em>, whereupon an interpretation of the histogram takes place after a short time interval, depending on the performance of the local system <em class="nz">“st.write(f”**Histogram Interpretation:** {response}”)”</em>.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="d875" class="pi od fq pf b bg pj pk l pl pm">def plot_histogram(df, variable, apply_log_scale):<br/>    cleaned_data = df[variable].dropna()<br/><br/>    mean_value = cleaned_data.mean()<br/>    median_value = cleaned_data.median()<br/>    std_value = cleaned_data.std()<br/>    min_value = cleaned_data.min()<br/>    max_value = cleaned_data.max()<br/><br/>    std_upper = mean_value + std_value<br/>    std_lower = max(0, mean_value - std_value)  <br/><br/>    concentration_range = (mean_value - std_value, mean_value + std_value)<br/><br/>    if std_value &lt; (max_value - min_value) / 6:<br/>        scatter = "low"<br/>    elif std_value &lt; (max_value - min_value) / 3:<br/>        scatter = "moderate"<br/>    else:<br/>        scatter = "high"<br/><br/>    if abs(mean_value - median_value) &lt; 0.1 * std_value:<br/>        distribution = "symmetrical"<br/>    elif mean_value &gt; median_value:<br/>        distribution = "right-skewed"<br/>    else:<br/>        distribution = "left-skewed"<br/><br/>    fig, ax = plt.subplots()<br/>    ax.hist(cleaned_data, bins=30, edgecolor='black', alpha=0.7)<br/><br/>    ax.axvline(mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')<br/>    ax.axvline(median_value, color='green', linestyle='-', label=f'Median: {median_value:.2f}')<br/>    ax.axvline(std_upper, color='blue', linestyle=':', label=f'+1 Std: {std_upper:.2f}')<br/>    ax.axvline(std_lower, color='blue', linestyle=':', label=f'-1 Std: {std_lower:.2f}')<br/>    ax.set_title(f"Histogram of {variable}")<br/>    ax.legend(title=f'Std-Deviation: {std_value:.2f}')<br/><br/>    if apply_log_scale:<br/>        ax.set_yscale('log')<br/><br/>    st.pyplot(fig)<br/><br/>    context = (<br/>        f"Here is an analysis of the distribution of the variable '{variable}':\n"<br/>        f"- Mean: {mean_value:.2f}\n"<br/>        f"- Median: {median_value:.2f}\n"<br/>        f"- Standard deviation: {std_value:.2f}\n"<br/>        f"- Minimum: {min_value:.2f}\n"<br/>        f"- Maximum: {max_value:.2f}\n\n"<br/>        f"The distribution of the data shows a {distribution} distribution.\n"<br/>        f"The small difference between mean and median indicates a {distribution} distribution.\n"<br/>        f"A strong concentration of data points is observed between {concentration_range[0]:.2f} and {concentration_range[1]:.2f}.\n"<br/>        f"The scatter of the data is described as {scatter}, indicating a relatively tight distribution around the mean.\n\n"<br/>        f"Please analyze this distribution in the histogram, paying particular attention to symmetry, scatter, and potential deviations.\n"<br/>        f"Avoid calling the distribution normal unless there are explicit indications.\n"<br/>        f"Use only the names of the variables {variable} in the analysis!"<br/>    )<br/><br/>    response = query_llm_via_cli(context)<br/>    st.write(f"**Histogram Interpretation:** {response}")</span></pre><h2 id="6ba8" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">THE BOXPLOT FUNCTION</h2><p id="a8de" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The <em class="nz">“plot_boxplot()”</em> function creates a boxplot for a variable selected by the user. Statistical key figures are calculated from the DataFrame based on the variable in order to display the distribution of the data in the diagram and to enable an analysis of the central tendency and dispersion using an LLM. In addition to the mean value, the median and the standard deviation, as with the histogram, the lower <em class="nz">“q1”</em>, upper <em class="nz">“q3”</em>, the interquartile range <em class="nz">“iqr” </em>(Q3 — Q1) and the lower or upper whisker “lower_whisker” and <em class="nz">“upper_whisker”</em>, which are based on the interquartile range (1.5 * IQR), are also determined for the boxplot.</p><p id="af56" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The latter plays a role in identifying outliers and the other parameters where data is above or below a certain value. The boxplot is created using the Plotly library <em class="nz">“fig = px.box(df, y=variable)”</em> and finally displayed in the app <em class="nz">“st.plotly_chart(fig)”</em>. Logarithmic scaling can also be used for this chart type [4]. The chart then looks as follows:</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pr"><img src="../Images/1240490defa061076c18513fa0716b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RfE4ew4ZhSyZv2kCGFr1cw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Boxplot (plotly) of critic_score and LLM interpretation (Image by author)</figcaption></figure><p id="5e4b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">As with the histogram, a context is also created for the boxplot, which is forwarded to the LLM. The statistical key figures are transmitted as well as information about potential outliers that lie outside the whisker values. The text sent to the LLM is formatted so that the analysis is performed on these metrics.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="2e04" class="pi od fq pf b bg pj pk l pl pm">def plot_boxplot(df, variable, apply_log_scale):<br/>    mean_value = df[variable].mean()<br/>    median_value = df[variable].median()<br/>    std_value = df[variable].std()<br/>    q1 = df[variable].quantile(0.25)<br/>    q3 = df[variable].quantile(0.75)<br/>    iqr = q3 - q1<br/>    lower_whisker = max(df[variable].min(), q1 - 1.5 * iqr)<br/>    upper_whisker = min(df[variable].max(), q3 + 1.5 * iqr)<br/><br/>    fig = px.box(df, y=variable)<br/>    fig.update_layout(title=f"Boxplot of {variable}")<br/><br/>    if apply_log_scale:<br/>        fig.update_yaxes(type="log")  <br/>    <br/>    st.plotly_chart(fig)<br/><br/>    context = (<br/>        f"Here is an analysis of the distribution of the variable '{variable}' based on a boxplot:\n"<br/>        f"- Mean: {mean_value:.2f}\n"<br/>        f"- Median: {median_value:.2f}\n"<br/>        f"- Standard deviation: {std_value:.2f}\n"<br/>        f"- Lower quartile (Q1): {q1:.2f}\n"<br/>        f"- Upper quartile (Q3): {q3:.2f}\n"<br/>        f"- Interquartile range (IQR): {iqr:.2f}\n"<br/>        f"- Potential outliers outside values from {lower_whisker:.2f} to {upper_whisker:.2f}.\n"<br/>        f"Please analyze this distribution and identify patterns or outliers.\n"<br/>        f"Use only the names of the variables {variable} in the analysis!"<br/>    )<br/><br/>    response = query_llm_via_cli(context)<br/>    st.write(f"**Boxplot Interpretation:** {response}")</span></pre><h2 id="95b1" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">THE PAIRPLOT FUNCTION</h2><p id="1d31" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The <em class="nz">“plot_pairplot()”</em> function creates a pairplot based on the variables selected by the user. If less than two variables are selected, an error message is displayed. Scatter plots for all possible combinations of the variables and a linear regression line are displayed to show the relationships between the variables. For this to work, the regression statistics are calculated for all possible pairs of the selected variables using the <em class="nz">“calculate_regression_stats” </em>function. The NaN values are removed from the selected variables <em class="nz">“selected_vars”</em>.</p><p id="0fbf" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A linear regression is performed between the two variables. Here, <em class="nz">“var1” </em>is the independent variable x and <em class="nz">“var2”</em> is the dependent variable y. The slope and the R2 value <em class="nz">“r_squared” </em>are calculated. The results are returned as a list of tuples (var1, var2, slope, r_squared). If three variables are selected [<em class="nz">“A”, “B”, “C”</em>], the function will calculate the regression statistics for the pairs (A, B), (A, C), (B, A), (B, C), etc. [5].</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="ecf5" class="pi od fq pf b bg pj pk l pl pm">def calculate_regression_stats(df, selected_vars):<br/>    regression_results = []<br/>    for var1 in selected_vars:<br/>        for var2 in selected_vars:<br/>            if var1 != var2:<br/>                non_nan_data = df[[var1, var2]].dropna()<br/><br/>                X = non_nan_data[[var1]].values.reshape(-1, 1)<br/>                y = non_nan_data[var2].values<br/><br/>                if len(X) &gt; 0 and len(y) &gt; 0:<br/>                    model = LinearRegression()<br/>                    model.fit(X, y)<br/>                    r_squared = model.score(X, y)<br/>                    slope = model.coef_[0]<br/><br/>                    regression_results.append((var1, var2, slope, r_squared))<br/><br/>    return regression_results<br/><br/>def plot_pairplot(df, selected_vars):<br/>    if len(selected_vars) &gt; 1:<br/>        st.write("**Pairplot with regression lines:**")<br/>        pairplot_fig = sns.pairplot(df[selected_vars], kind='reg', diag_kind='kde', <br/>                                    plot_kws={'line_kws': {'color': 'red'}, 'scatter_kws': {'color': 'blue'}})<br/>        st.pyplot(pairplot_fig.fig)<br/><br/>        corr_matrix = df[selected_vars].corr()<br/>        regression_stats = calculate_regression_stats(df, selected_vars)<br/>        correlation_list = "\n".join(<br/>            [f"The correlation between {var1} and {var2} is {corr_matrix.at[var1, var2]:.2f}."<br/>             for var1 in corr_matrix.columns for var2 in corr_matrix.columns if var1 != var2]<br/>        )<br/><br/>        regression_list = "\n".join(<br/>            [f"The regression line for {var1} and {var2} has a slope of {slope:.2f} and an R² of {r_squared:.2f}."<br/>             for var1, var2, slope, r_squared in regression_stats]<br/>        )<br/><br/>        context = (<br/>            f"Here are the correlation and regression analyses between the selected variables:\n"<br/>            f"{correlation_list}\n\n"<br/>            f"{regression_list}\n\n"<br/>            f"Please analyze these relationships in detail based solely on the numerical values (correlation and regression lines).\n"<br/>            f"Use only the names of the variables {selected_vars} in the analysis!"<br/>        )<br/><br/>        response = query_llm_via_cli(context)<br/>        st.write(f"**Pairplot Interpretation:** {response}")<br/>    else:<br/>        st.error("At least two variables must be selected for a pairplot.")</span></pre><p id="98b7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">KDE (Kernel Density Estimation) is used in the<em class="nz"> “plot_pairplot()”</em> function for the diagonal to display the distribution of each individual variable. As with the previous functions, a context is again created for the analysis by the LLM. For this type of diagram, the LLM receives the data from the correlation and regression analysis. The text is formatted in such a way that a detailed interpretation of the relationship between the variables is generated.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng ps"><img src="../Images/6d2bd3af562582c6074c5c389c746db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c0eroT-7AnJB5wgRQd_26Q.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Pairplot (pyplot) of critic_score, na_sales, pal_sales and LLM interpretation (Image by author)</figcaption></figure><h2 id="adfe" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">THE CORRELATION MATRIX FUNCTION</h2><p id="61e0" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The <em class="nz">“plot_correlation_matrix”</em> function is used to create a correlation matrix based on the variables selected by the user <em class="nz">“if len(selected_vars) &gt; 1”</em>. If only one variable is selected, an error message is displayed. The visualization is done as a heatmap. The cells of the matrix are colored to show the strength and direction of the correlation. Correlations that are significant are automatically sent to the LLM for further analysis <em class="nz">“if var1 != var2 and abs(corr_matrix.at[var1, var2]) &gt;= 0.5”</em>.</p><p id="31c2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The linear correlation between the selected variables is displayed as the correlation coefficient (value between -1 and +1) <em class="nz">“corr_matrix = df[selected_vars].cor()”</em>. With a value of 0, there is no linear correlation. A value close to -1 indicates a strong negative correlation and a value close to +1 indicates a strong positive correlation. The pairs of variables and their correlation values are saved in <em class="nz">“high_correlations”</em> [4].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pt"><img src="../Images/6729066db61d5785023c97f0e3cc5af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*njH8vAmD7nCD8hJOFqw9Zw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Correlation Matrix (pyplot) with all variables and LLM interpretation (Image by author)</figcaption></figure><p id="3c15" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A context is created for the LLM. The existing significant correlations are classified for the textual description <em class="nz">“correlation_list”</em>. A strong correlation (positive or negative) is present with a value greater than 0.7. If the value is between 0.5 and 0.7, there is a moderate correlation and if the value is only just above 0.5, the correlation is weak. If no significant correlations were found, a corresponding message is displayed.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="abb0" class="pi od fq pf b bg pj pk l pl pm">def plot_correlation_matrix(df, selected_vars):<br/>    if len(selected_vars) &gt; 1:<br/>        corr_matrix = df[selected_vars].corr()<br/><br/>        fig, ax = plt.subplots()<br/>        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)<br/>        ax.set_title("Correlation Matrix")<br/>        st.pyplot(fig)<br/><br/>        high_correlations = []<br/>        for var1 in corr_matrix.columns:<br/>            for var2 in corr_matrix.columns:<br/>                if var1 != var2 and abs(corr_matrix.at[var1, var2]) &gt;= 0.5:  <br/>                    if (var2, var1) not in [(v1, v2) for v1, v2, _ in high_correlations]:  <br/>                        high_correlations.append((var1, var2, corr_matrix.at[var1, var2]))<br/><br/>        if high_correlations:<br/>            correlation_list = "\n".join([f"- {var1} and {var2} have a correlation value of {value:.2f}, "<br/>                                        f"indicating a {'strong' if abs(value) &gt; 0.7 else 'moderate' if abs(value) &gt; 0.5 else 'weak'} correlation."<br/>                                        for var1, var2, value in high_correlations])<br/><br/>            context = (<br/>                f"Here is an analysis of the significant correlations between the selected variables in the correlation matrix:\n"<br/>                f"{correlation_list}\n\n"<br/>                f"Please analyze the correlations solely based on their strength and significance.\n"<br/>                f"Use only the names of the variables {selected_vars} in the analysis!"<br/>                f"Focus in detail on the statistical relationship and patterns."<br/>            )<br/><br/>            response = query_llm_via_cli(context)<br/>            st.write(f"**Model Response:** {response}")<br/>        else:<br/>            st.write("**No significant correlations were found.**")<br/>    else:<br/>        st.write("**The correlation matrix cannot be displayed because fewer than two variables were selected.**")</span></pre><p id="e2a6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In the following statistical procedures, the interpretation of the respective key figures recorded by an LLM is not available. However, based on the previous procedure, independent implementation should not be a problem. Let us now turn to the various hypothesis tests.</p><h2 id="e75f" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">HYPOTHESIS TESTS SELECTION</h2><p id="2c4a" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">In the current version, three different tests (t-test, ANOVA and chi-square test) can be carried out <em class="nz">“test_type = st.selectbox()”</em>. Depending on the test selected, a brief explanation of its purpose appears. Depending on the area of application, this description can be expanded or removed. The t-test is used to compare the mean values of two groups. The analysis of variance (ANOVA) compares the mean value of more than two groups. The chi-square test tests the independence between two categorical variables. Depending on which test is selected, the corresponding function is performed.</p><h2 id="138c" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">T-TEST</h2><p id="2d4d" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">If the user has opted for the t-test, they must select a group variable (categorical) <em class="nz">“group_col”</em> and a value variable (numerical) <em class="nz">“value_col”</em>. The group variable defines the two groups to be compared. The value variable compares the mean value between the two groups. Once the selection has been made, the names of the two groups <em class="nz">“group1”</em> and <em class="nz">“group2”</em> must be entered in a text field <em class="nz">“st.text_input()”</em>. The two groups should appear in the selected categorical variable. The logarithmic scaling <em class="nz">“apply_log_scale”</em>, which is applied to the value variable, is also available here. When the test is performed, the data of the groups is extracted and the number of data points (after the NaN values have been removed) is output. The t-statistic and the p-value are displayed.</p><p id="25b5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The first value indicates the difference in the mean values between the two groups relative to the spread of the data. Whether the difference between the groups is statistically significant is indicated by the p-value. If it is less than 0.05, it is significant. To visually highlight the distribution of the two groups <em class="nz">“filtered_df = df[df[group_col].isin([group1, group2])]”</em>, a boxplot is created <em class="nz">“fig, ax = plt.subplots()”</em>. Here <em class="nz">“pyplot”</em> is used, alternatively you can also use <em class="nz">“plotly” </em>[6].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pu"><img src="../Images/0281425b6d6f039c3e18eac9de239395.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aia3I4LkvdYFw5Rn-znHHw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Boxplot with genre (Action/Shooter) and critic_score (Image by author)</figcaption></figure><p id="563d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this example, <em class="nz">“genre” </em>was selected as the group variable and <em class="nz">“critic_score”</em> as the value variable. Action (group 1) and Shooter (group 2) were defined as groups. The function also calculates whether there are significant outliers in the groups. An outlier is defined as a data point exceeding the upper quartile by more than 1.5 times the interquartile range <em class="nz">“outliers_group1/2”</em>. Finally, the outliers found are displayed to confirm the validity of the t-test. If the distortion is too large, this must be taken into account accordingly in order to better classify the reliability and interpretability of the test results.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="fcc5" class="pi od fq pf b bg pj pk l pl pm">def t_test(df, numerical_columns, categorical_columns):<br/>    group_col = st.selectbox("Choose the group variable:", categorical_columns)<br/>    value_col = st.selectbox("Choose the value variable:", numerical_columns)<br/>    <br/>    group1 = st.text_input("Name of group 1:")<br/>    group2 = st.text_input("Name of group 2:")<br/><br/>    apply_log_scale = st.checkbox("Apply logarithmic scaling?", value=False)<br/><br/>    if st.button("Perform t-Test"):<br/>        group1_data = df[df[group_col] == group1][value_col]<br/>        group2_data = df[df[group_col] == group2][value_col]<br/><br/>        initial_count_group1 = len(group1_data)<br/>        initial_count_group2 = len(group2_data)<br/><br/>        group1_data = group1_data.dropna()<br/>        group2_data = group2_data.dropna()<br/><br/>        remaining_count_group1 = len(group1_data)<br/>        remaining_count_group2 = len(group2_data)<br/><br/>        st.write(f"**Group 1 ({group1}):** Total number of data points: {initial_count_group1}, without NaN: {remaining_count_group1}")<br/>        st.write(f"**Group 2 ({group2}):** Total number of data points: {initial_count_group2}, without NaN: {remaining_count_group2}")<br/><br/>        if apply_log_scale:<br/>            group1_data = np.log1p(group1_data)<br/>            group2_data = np.log1p(group2_data)<br/><br/>        if not group1_data.empty and not group2_data.empty:<br/><br/>            t_stat, p_value = stats.ttest_ind(group1_data, group2_data)<br/>            st.markdown(f"**t-Statistic:** {t_stat}")<br/>            st.markdown(f"**p-Value:** {p_value}")<br/>            <br/>            filtered_df = df[df[group_col].isin([group1, group2])]<br/>            fig, ax = plt.subplots()<br/>            sns.boxplot(x=filtered_df[group_col], y=filtered_df[value_col], ax=ax, palette="Set2")<br/>            ax.set_title(f"Boxplot for {group1} vs. {group2}")<br/><br/>            if apply_log_scale:<br/>                ax.set_yscale('log')<br/><br/>            st.pyplot(fig)<br/><br/>            outliers_group1 = group1_data[group1_data &gt; group1_data.quantile(0.75) + 1.5 * (group1_data.quantile(0.75) - group1_data.quantile(0.25))]<br/>            outliers_group2 = group2_data[group2_data &gt; group2_data.quantile(0.75) + 1.5 * (group2_data.quantile(0.75) - group2_data.quantile(0.25))]<br/><br/>            st.write("**Outlier Analysis:**")<br/>            if not outliers_group1.empty:<br/>                st.write(f"In group 1 ({group1}) there are {len(outliers_group1)} outliers.")<br/>            else:<br/>                st.write(f"In group 1 ({group1}) there are no significant outliers.")<br/><br/>            if not outliers_group2.empty:<br/>                st.write(f"In group 2 ({group2}) there are {len(outliers_group2)} outliers.")<br/>            else:<br/>                st.write(f"In group 2 ({group2}) there are no significant outliers.")<br/>        else:<br/>            st.error("One or both groups contain no data after removing NaN values.")</span></pre><h2 id="774c" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk"><strong class="al">ANOVA-TEST</strong></h2><p id="f7b2" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The <em class="nz">“anova_test()”</em> function integrates the option of performing an ANOVA test. This test checks whether there are significant differences in the mean values of several groups. The data is first cleaned <em class="nz">“df_clean”</em>. If the ANOVA test is significant, a Tukey’s HSD test (Honestly Significant Difference) is also carried out. At the beginning, a group variable and a value variable are again defined. If a group has fewer than 2 data points, it is excluded <em class="nz">“valid_groups = group_sizes[group_sizes &gt;= 2].index”</em>.</p><p id="ea11" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If less than two groups remain after the adjustment, an error message is displayed and the test is not performed. The ANOVA test calculates the F-value and the p-value. The variability between the groups compared to the variability within the group is measured by the F-value. Whether the difference between the mean values of the group is significant is indicated by the p-value. If the value is less than 0.05, at least one group is significantly different. To visualize the results, a boxplot is created using <em class="nz">“pyplot”</em> [7].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pv"><img src="../Images/6cf3791fda75bcdaa972c48cde52e76f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3LWaibBGnyCw9ghWI-gP-Q.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Boxplot with console and critic_score (Image by author)</figcaption></figure><p id="48c3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If the ANOVA test produces significant results, a Tukey’s test is carried out to examine the differences between the individual group pairs in concrete terms. The ANOVA test therefore does not show which groups differ from each other. A diagram is created that shows the pairwise mean differences between the groups and their confidence interval <em class="nz">“st.pyplot(tukey.plot_simultaneous())”</em>.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pw"><img src="../Images/97edb4e4c3fa24a8ce648df77b1cba45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PI8EkWKMZG3wQGu_5vkLbw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Result of the Tukey Test (Image by author)</figcaption></figure><p id="965f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Below the diagram, the results are displayed in a table <em class="nz">“st.dataframe(tukey_results_df, height=400)”</em>. The table contains the two groups, the mean difference <em class="nz">“meandiff”</em>, the adjusted p-value <em class="nz">“p-adj”</em>, the confidence interval and whether the null hypothesis can be rejected or not <em class="nz">“reject” </em>(True = significant, Fals = not significant). A brief example of the confidence interval. For the 3DS and GBA consoles, the interval lies between -0.9319 and -0.0061 and is therefore completely below zero. The difference in the mean value is significant.</p><p id="aac5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The key figures can be used to have the results interpreted by an LLM. There is also an option to download the data as a .csv file for further statistical analyses (e.g. regression analyses) [7].</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="1a90" class="pi od fq pf b bg pj pk l pl pm">def anova_test(df, numerical_columns, categorical_columns):<br/>    group_col = st.selectbox("Choose the group variable:", categorical_columns)<br/>    value_col = st.selectbox("Choose the value variable:", numerical_columns)<br/><br/>    if st.button("Perform ANOVA"):<br/>        df_clean = df[[group_col, value_col]].dropna()<br/><br/>        group_sizes = df_clean.groupby(group_col).size()<br/>        valid_groups = group_sizes[group_sizes &gt;= 2].index<br/>        df_filtered = df_clean[df_clean[group_col].isin(valid_groups)]<br/><br/>        if len(valid_groups) &lt; 2:<br/>            st.error("After removing small groups, there are not enough groups left for the ANOVA test.")<br/>        else:<br/>            grouped_data = [group[value_col].values for name, group in df_filtered.groupby(group_col)]<br/>            try:<br/>                anova_result = stats.f_oneway(*grouped_data)<br/>                st.markdown(f"**F-Value:** {anova_result.statistic}")<br/>                st.markdown(f"**p-Value:** {anova_result.pvalue}")<br/><br/>                fig, ax = plt.subplots(figsize=(10, 6))<br/>                sns.boxplot(x=group_col, y=value_col, data=df_filtered, ax=ax)<br/>                plt.xticks(rotation=90)<br/>                st.pyplot(fig)<br/><br/>                if anova_result.pvalue &lt; 0.05:<br/>                    st.write("The ANOVA test is significant. Tukey's HSD test will be performed.")<br/>                    try:<br/>                        tukey = pairwise_tukeyhsd(endog=df_filtered[value_col], groups=df_filtered[group_col], alpha=0.05)<br/>                        st.pyplot(tukey.plot_simultaneous())<br/><br/>                        tukey_results_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])<br/>                        st.write("Results of the Tukey HSD test:")<br/>                        st.dataframe(tukey_results_df, height=400)<br/><br/>                        csv = tukey_results_df.to_csv(index=False)<br/>                        st.download_button(label="Download Tukey HSD results as CSV", data=csv, file_name='tukey_hsd_results.csv', mime='text/csv')<br/><br/>                    except Exception as e:<br/>                        st.error(f"An error occurred during Tukey's HSD test: {str(e)}")<br/><br/>            except ValueError as e:<br/>                st.error(f"An error occurred: {str(e)}.")</span></pre><h2 id="3a52" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk"><strong class="al">CHI-QUADRAT-TEST</strong></h2><p id="34e5" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The <em class="nz">“chi_square_test()”</em> function checks whether there is a statistically significant relationship between two categorical variables. As only categorical variables can be used, the option to activate logarithmic scaling is not required. Specifically, whether the frequency of observations in the categories is independent of each other or whether there is a correlation. The user selects two of the existing categorical variables. The NaN values are removed and only the top 10 most frequent categories are selected for each variable in order to keep the analysis manageable <em class="nz">“value_counts().nlargest(10).index”</em>.</p><p id="bbff" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A crosstab <em class="nz">“contingency_table”</em> is created, which shows the frequencies of the combinations of categories in the two selected variables using a heatmap. If the crosstab is not valid (too little data or only one category), the test is not performed [8].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pv"><img src="../Images/ef33476baee433f6277b1754200bb8ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bQX0gv5D4kyfo4-ovZsAoA.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Heatmap with genre and console (Image by author)</figcaption></figure><p id="ff59" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The test calculates various values. The chi-square value <em class="nz">“chi2”</em> determines the measure of the difference between the observed and expected frequencies. A strong difference is present with high values. As with the other analyses, the p-value<em class="nz"> “p”</em> shows whether the difference is significant. The number of degrees of freedom of the test <em class="nz">“dof”</em> is indicated as well as the expected frequencies <em class="nz">“expected”</em>.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="12fd" class="pi od fq pf b bg pj pk l pl pm">def chi_square_test(df, categorical_columns):<br/>    cat_var1 = st.selectbox("Choose the first group variable:", categorical_columns)<br/>    cat_var2 = st.selectbox("Choose the second group variable:", categorical_columns)<br/>    <br/>    if st.button("Perform Chi-square test"):<br/>        df_clean = df[[cat_var1, cat_var2]].dropna()<br/><br/>        top_cat_var1 = df_clean[cat_var1].value_counts().nlargest(10).index<br/>        top_cat_var2 = df_clean[cat_var2].value_counts().nlargest(10).index<br/>        df_filtered = df_clean[df_clean[cat_var1].isin(top_cat_var1) &amp; df_clean[cat_var2].isin(top_cat_var2)]<br/><br/>        try:<br/>            contingency_table = pd.crosstab(df_filtered[cat_var1], df_filtered[cat_var2])<br/><br/>            if contingency_table.empty or contingency_table.shape[0] &lt; 2 or contingency_table.shape[1] &lt; 2:<br/>                st.error("The contingency table is invalid. Check the variables.")<br/>            else:<br/>                chi2, p, dof, expected = stats.chi2_contingency(contingency_table)<br/>                st.markdown(f"**Chi-square:** {chi2}")<br/>                st.markdown(f"**p-Value:** {p}")<br/>                <br/>                st.write("**Heatmap of the contingency table:**")<br/>                fig, ax = plt.subplots(figsize=(12, 10))  # Larger display<br/>                sns.heatmap(contingency_table, annot=False, cmap="YlGnBu", ax=ax)<br/>                ax.set_title(f"Heatmap of the contingency table: {cat_var1} vs. {cat_var2} top 10")<br/>                plt.xticks(rotation=90)<br/>                st.pyplot(fig)<br/><br/>        except ValueError as e:<br/>            st.error(f"An error occurred: {str(e)}.")</span></pre><h2 id="c336" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">REGRESSION ANALYSIS SELECTION</h2><p id="611a" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The selection of the available regression analyses (linear, logistic and multivariate) is similar to the selection of the various hypothesis tests. Once an analysis method has been selected, a brief explanation is displayed and the corresponding function is called up.</p><h2 id="21ac" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">LINEAR REGRESSION ANALYSIS</h2><p id="2003" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">At the beginning of the <em class="nz">“linear_regression()”</em> function, a correlation matrix is created from all available numerical variables in the uploaded dataset <em class="nz">“corr_matrix = df[numerical_columns].corr()”</em>. The matrix is intended to help the user understand the relationships between the variables in order to identify the variables for which regression analyses are appropriate and those for which they are not (multicollinearity).</p><p id="0bbb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Finally, the dependent variable and one or more independent variables are selected. The data is cleaned and a linear regression model is created for all selected independent variables <em class="nz">“model = LinearRegression()”</em>. The regression coefficient and the intercept are specified. After the overall model has been run, a separate linear regression model is created for each independent variable and represented by a scatterplot [9].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng px"><img src="../Images/81dfffeb6570fce448f25ce65a1210d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yq-WoSQxZ6wyjWnRPR6zvQ.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Lineare Regression pal_sales, na_sales and total_sales (Image by author)</figcaption></figure><p id="076e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The regression coefficient shown indicates the extent to which the dependent variable is changed when the respective independent variable is changed by one unit. Assuming that all other variables remain constant. The value that the dependent variable assumes when all independent variables are zero is indicated by the intercept.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="5a81" class="pi od fq pf b bg pj pk l pl pm">def linear_regression(df, numerical_columns):<br/>    st.write("**Correlation matrix of numerical variables:**")<br/>    corr_matrix = df[numerical_columns].corr()<br/>    fig, ax = plt.subplots(figsize=(10, 8))<br/>    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)<br/>    st.pyplot(fig)<br/><br/>    dependent_var = st.selectbox("Choose the dependent variable:", numerical_columns)<br/>    independent_vars = st.multiselect("Choose the independent variables:", numerical_columns)<br/><br/>    if independent_vars:<br/>        if st.button("Perform regression"):<br/>            X = df[independent_vars].dropna()<br/>            y = df[dependent_var].loc[X.index]<br/>            y = y.dropna()<br/>            X = X.loc[y.index]<br/><br/>            if y.isnull().values.any():<br/>                st.error("The dependent variable still contains missing values. Please clean the data.")<br/>            else:<br/>                model = LinearRegression()<br/>                model.fit(X, y)<br/><br/>                st.markdown("**Regression coefficients:**")<br/>                for var, coef in zip(independent_vars, model.coef_):<br/>                    st.write(f"- {var}: {coef}")<br/>                st.write(f"**Intercept:** {model.intercept_}")<br/><br/>                for var in independent_vars:<br/>                    X_single_var = X[[var]]  # Use only the current independent variable<br/>                    model_single = LinearRegression()<br/>                    model_single.fit(X_single_var, y)<br/><br/>                    fig, ax = plt.subplots()<br/>                    ax.scatter(X[var], y, edgecolor='none', facecolors='blue', s=5, label='Data points')<br/><br/>                    ax.plot(X[var], model_single.predict(X_single_var), color='red', label='Regression line')<br/>                    ax.set_xlabel(var)<br/>                    ax.set_ylabel(dependent_var)<br/>                    ax.set_title(f"{dependent_var} vs {var}")<br/>                    ax.legend()<br/>                    st.pyplot(fig)</span></pre><h2 id="e54f" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">THE LOGISTIC REGRESSION ANALYSIS</h2><p id="b78e" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">As with the other functions, the user selects dependent and independent variables at the beginning. In this analysis method, the dependent variable must be binary (0/1). To demonstrate the function, I have created some data that has nothing to do with the dataset used so far. Alternatively, you can also manually adjust the values of variables, as long as there are not too many categories. If an incorrect variable is selected, a corresponding error message is displayed.</p><p id="13b9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If everything is defined correctly, the logistic regression is performed and the model uses the independent variables to model the probability for the target variable. Specifically, this is the probability that an event will occur. The coefficients are specified for each independent variable and the logistic function is visualized. This shows how the probability of the target result (1 instead of 0) changes when the independent variable changes [10].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng py"><img src="../Images/e7d6e5009edd8c76de604785d349d750.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgUKiY7AlPpkxPxw7uVX-A.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Logistic regression with fictitious values ​​for demonstration purposes (Image by author)</figcaption></figure><p id="08e8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In the scatterplot, the red line represents the prediction probability for the target result, i.e. the probability that result 1 will occur. The independent variable varies. The <em class="nz">“logistic_regression()”</em> function is very well suited to binary classification problems where you want to predict the occurrence of an event based on several factors.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="5a1b" class="pi od fq pf b bg pj pk l pl pm">def logistic_regression(df, numerical_columns):<br/>    dependent_var = st.selectbox("Choose the dependent variable (binary):", numerical_columns)<br/>    independent_vars = st.multiselect("Choose the independent variables:", numerical_columns)<br/><br/>    if independent_vars:<br/>        if st.button("Perform logistic regression"):<br/>            X = df[independent_vars].dropna()<br/>            y = df[dependent_var].loc[X.index].dropna()<br/>            X = X.loc[y.index]<br/><br/>            unique_values = y.unique()<br/>            if len(unique_values) != 2:<br/>                st.error("The dependent variable must be binary (e.g., 0 and 1).")<br/>            else:<br/>                model = LogisticRegression()<br/>                model.fit(X, y)<br/><br/>                st.write("**Logistic regression coefficients:**")<br/>                for var, coef in zip(independent_vars, model.coef_[0]):<br/>                    st.write(f"- {var}: {coef}")<br/>                st.write(f"**Intercept:** {model.intercept_[0]}")<br/><br/>                for var in independent_vars:<br/>                    fig, ax = plt.subplots()<br/><br/>                    ax.scatter(X[var], y, label='Data points')<br/>                    x_range = np.linspace(X[var].min(), X[var].max(), 300).reshape(-1, 1)<br/>                    X_copy = pd.DataFrame(np.tile(X.mean().values, (300, 1)), columns=X.columns)<br/>                    X_copy[var] = x_range.flatten()  # Vary the current variable var<br/>                    y_prob = model.predict_proba(X_copy)[:, 1]<br/><br/>                    ax.plot(x_range, y_prob, color='red', label='Logistic function')<br/>                    ax.set_xlabel(var)<br/>                    ax.set_ylabel(f'Probability ({dependent_var})')<br/>                    ax.set_title(f'Logistic regression: {dependent_var} vs {var}')<br/>                    ax.legend()<br/>                    st.pyplot(fig)</span></pre><h2 id="3a40" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">MULTIVARIATE REGRESSION ANALYSIS</h2><p id="5431" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">In multivariate regression analysis, the user must select several dependent variables and one or more independent variables. The analysis examines how the dependent variables are influenced by the independent variables. After the variable selection, the NaN values are removed again and an error message is displayed if necessary. The model outputs the regression coefficient and the intercept for all dependent variables.</p><p id="8e24" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A scatterplot with regression line is created for all combinations of independent and dependent variables. This function makes it possible to analyze several target variables simultaneously and to model their relationship to several predictors [11].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pz"><img src="../Images/8338266ad3f6ce75729c046c2603e435.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oRVHbn5N3_yL1vECbZEpgw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Multivariate regression (plotly) example (Image by author)</figcaption></figure><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="2431" class="pi od fq pf b bg pj pk l pl pm">def multivariate_regression(df, numerical_columns):<br/>    dependent_vars = st.multiselect("**Choose the dependent variables (multiple):**", numerical_columns)<br/>    independent_vars = st.multiselect("**Choose the independent variables:**", numerical_columns)<br/><br/>    if dependent_vars and independent_vars:<br/>        if st.button("Perform multivariate regression"):<br/>            X = df[independent_vars].dropna()<br/>            Y = df[dependent_vars].loc[X.index].dropna()<br/>            X = X.loc[Y.index]<br/><br/>            if X.shape[1] != len(independent_vars) or Y.shape[1] != len(dependent_vars):<br/>                st.error("The number of independent or dependent variables does not match.")<br/>                return<br/><br/>            model = LinearRegression()<br/>            model.fit(X, Y)<br/><br/>            st.write("**Multivariate regression coefficients:**")<br/>            for i, dep_var in enumerate(dependent_vars):<br/>                st.write(f"\nFor the dependent variable: **{dep_var}**")<br/>                st.write(f"Intercept: {model.intercept_[i]}")<br/>                for var, coef in zip(independent_vars, model.coef_[i]):<br/>                    st.write(f"- {var}: {coef}")<br/><br/>            for dep_var in dependent_vars:<br/>                for var in independent_vars:<br/>                    fig, ax = plt.subplots()<br/>                    ax.scatter(X[var], Y[dep_var], label='Data points')<br/><br/>                    x_range = np.linspace(X[var].min(), X[var].max(), 300).reshape(-1, 1)<br/>                    X_copy = pd.DataFrame(np.tile(X.mean().values, (300, 1)), columns=X.columns)<br/>                    X_copy[var] = x_range.flatten()<br/><br/>                    y_pred = model.predict(X_copy)<br/><br/>                    ax.plot(x_range, y_pred[:, dependent_vars.index(dep_var)], color='red', label='Regression line')<br/>                    ax.set_xlabel(var)<br/>                    ax.set_ylabel(dep_var)<br/>                    ax.set_title(f'Multivariate regression: {dep_var} vs {var}')<br/>                    ax.legend()<br/>                    st.plotly_chart(fig)</span></pre><h2 id="25f7" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">THE TIME SERIES ANALYSIS</h2><p id="526f" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">This analysis method performs an analysis over time. For this purpose, a given time series is grouped by year and the annual average of a value is calculated and displayed. A time variable is required for the analysis; if the dataset used does not contain one, it cannot be performed. In the dataset I have selected, there is the variable <em class="nz">“release_date”</em>, which contains the release date of the respective game.</p><p id="301f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The selected time variable is converted to the date format <em class="nz">“df[time_var]”</em>. If the data points are invalid, they are converted to NaN values and removed <em class="nz">“df = df.dropna(subset=[time_var])”</em>. The data is then grouped by year <em class="nz">“df[‘year’] = df[time_var].dt.year”</em> and the annual average for the specified value variable “value_var” is calculated <em class="nz">“yearly_avg”</em>. The minimum and maximum annual average values of the value variable are calculated as well as the overall average across all data points <em class="nz">“overall_avg”</em>. The annual average of the value variable per year is then displayed via a line chart. The overall average is integrated on the horizontal line. The values are displayed alternately above and below the data points to improve readability [12].</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pv"><img src="../Images/72c72193d79e866f168e57599dc1d787.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XRsNEWsxZastRklmmSWPvQ.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Time series analysis with year and critic_score (Image by author)</figcaption></figure><p id="908e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Important statistical key figures are displayed below the diagram, which can be easily interpreted as in the descriptive analysis using an LLM. Specifically, the standard deviation, the variance and the minimum and maximum of the value variable as well as the year are displayed. The <em class="nz">“perform_time_series_analysis()”</em> function is suitable for analyzing time trends in a data series. This allows an initial analysis of the variability over time.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="69c1" class="pi od fq pf b bg pj pk l pl pm">def perform_time_series_analysis(df, time_var, value_var):<br/>    df[time_var] = pd.to_datetime(df[time_var], errors='coerce')<br/>    df = df.dropna(subset=[time_var])<br/><br/>    if df.empty:<br/>        st.error("**Error:** The time variable has an incorrect format.")<br/>    else:<br/>        df['year'] = df[time_var].dt.year<br/>        yearly_avg = df.groupby('year')[value_var].mean().reset_index()<br/><br/>        y_min = yearly_avg[value_var].min()<br/>        y_max = yearly_avg[value_var].max()<br/>        y_range = y_max - y_min<br/>        y_buffer = y_range * 0.05<br/><br/>        overall_avg = df[value_var].mean()<br/><br/>        fig, ax = plt.subplots(figsize=(10, 6))<br/>        ax.plot(yearly_avg['year'], yearly_avg[value_var], marker='o', label='Yearly average')<br/>        ax.axhline(overall_avg, color='red', linestyle='--', label=f'Overall average: {overall_avg:.2f}')<br/>        ax.set_title(f'Average {value_var} per year')<br/>        ax.set_xlabel('Year')<br/>        ax.set_ylabel(f'Average {value_var}')<br/>        ax.set_ylim(y_min - y_buffer, y_max + y_buffer)<br/><br/>        ax.text(yearly_avg['year'].max() - (yearly_avg['year'].max() - yearly_avg['year'].min()) * 0.05, <br/>                overall_avg + y_buffer, <br/>                f'{overall_avg:.2f}', color='red', ha='right', va='center')<br/><br/>        for i in range(len(yearly_avg)):<br/>            if i % 2 == 0:<br/>                ax.text(yearly_avg['year'][i], yearly_avg[value_var][i] + y_buffer/2, <br/>                        f'{yearly_avg[value_var][i]:.2f}', color='blue', ha='center', va='bottom')<br/>            else:<br/>                ax.text(yearly_avg['year'][i], yearly_avg[value_var][i] - y_buffer/2, <br/>                        f'{yearly_avg[value_var][i]:.2f}', color='blue', ha='center', va='top')<br/><br/>        plt.xticks(rotation=45)<br/>        ax.legend()<br/>        st.pyplot(fig)<br/><br/>        st.write(f"**Standard deviation:** {df[value_var].std():.2f}")<br/>        st.write(f"**Variance:** {df[value_var].var():.2f}")<br/>        st.write(f"**Minimum {value_var}:** {y_min:.2f} in year {yearly_avg.loc[yearly_avg[value_var].idxmin(), 'year']}")<br/>        st.write(f"**Maximum {value_var}:** {y_max:.2f} in year {yearly_avg.loc[yearly_avg[value_var].idxmax(), 'year']}")</span></pre><h2 id="a8c2" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">CLUSTERING METHOD SELECTION</h2><p id="2362" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">As with the hypothesis tests and regression analyses, there are also various options to choose from in the area of clustering methods. The selection function has a similar structure to the others. A method is selected and the corresponding function is executed. A brief explanation of the method is also shown here. Depending on the method, the number of clusters must be defined. For k-Means and hierarchical clustering, a maximum of 10 clusters can be defined. For DBSCAN, the radius <em class="nz">“eps”</em> and the minimum number of points per cluster <em class="nz">“min_samples”</em> are queried. At least two numerical variables must be selected for each method.</p><h2 id="4175" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">k-MEANS CLUSTERING</h2><p id="029d" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The k-Means algorithm divides the data into <em class="nz">“n_clusters”</em>. The points are grouped in such a way that the distance between the points within the cluster is minimized. The number of clusters is determined by the user. Depending on the number, the algorithm calculates which data points belong to which cluster. The result is sent to the <em class="nz">“visualize_clusters()” </em>function for visualization [13].</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="8a51" class="pi od fq pf b bg pj pk l pl pm">def perform_kmeans(X, n_clusters):<br/>    kmeans = KMeans(n_clusters=n_clusters, random_state=42)<br/>    X['Cluster'] = kmeans.fit_predict(X)<br/>    <br/>    visualize_clusters(X, 'k-Means Clustering')</span></pre><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pv"><img src="../Images/bf09602a745cb7788a25d666df0efdf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1fpTg_4qPoTTqsiQFv3blw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 k-Means Clustering with PCA reduction (Image by author)</figcaption></figure><h2 id="e1a2" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">HIERARCHICAL CLUSTERING</h2><p id="df37" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">A hierarchy of clusters is created here, whereby agglomerative or divisive methods can be used. Agglomerative clustering is used in the function, whereby each data point is initially considered as a separate cluster before they are successively merged. The number of clusters is determined by the user and the algorithm divides the data according to the number. The same function as for k-Means is used for visualization <em class="nz">“visualize_clusters(X, ‘Hierarchical Clustering’)”</em> [14].</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="01f1" class="pi od fq pf b bg pj pk l pl pm">def perform_hierarchical_clustering(X, n_clusters):<br/>    hierarchical_clustering = AgglomerativeClustering(n_clusters=n_clusters)<br/>    X['Cluster'] = hierarchical_clustering.fit_predict(X)<br/>       <br/>    visualize_clusters(X, 'Hierarchical Clustering')</span></pre><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pv"><img src="../Images/8b1934c74ae21d70a6c215720b73422e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ey2xh0wvOSyqiulAYv23Nw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 Hierarchical Clustering with PCA reduction (Image by author)</figcaption></figure><h2 id="c763" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">DBSCAN CLUSTERING</h2><p id="f007" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">With this method, data points are grouped based on the density of their surroundings. The method is well suited to detecting outliers (noise) and finding clusters of any shape. Here, the user does not specify the number of clusters, but the maximum distance <em class="nz">“eps”</em> between two points before they are considered neighbors. The minimum number of points that occur in a cluster <em class="nz">“min_samples”</em> is also defined. The visualization is also created by <em class="nz">“visualize_clusters()”</em> [15].</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="5940" class="pi od fq pf b bg pj pk l pl pm">def perform_dbscan(X, eps, min_samples):<br/>    dbscan = DBSCAN(eps=eps, min_samples=min_samples)<br/>    X['Cluster'] = dbscan.fit_predict(X)<br/>    <br/>    visualize_clusters(X, 'DBSCAN Clustering')</span></pre><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pv"><img src="../Images/912638c2ef5cec406ef2be9277455bfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NrQtXC679v-7UkBkoy0olw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">ASCVIT V1 DBSCAN Clustering with PCA reduction (Image by author)</figcaption></figure><h2 id="add2" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">CLUSTER VISUALIZATION</h2><p id="c4f1" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The results of the three different clustering methods are visualized in the <em class="nz">“visualize_clusters”</em> function using Principal Component Analysis (PCA). The dimensions of the data are reduced by PCA to two components <em class="nz">“n_components”</em> in order to be able to display the clusters. It is checked whether there are enough data points and variables <em class="nz">“num_samples”</em>; if this is not the case, an error message is displayed. The clusters are visualized by a scatterplot that shows the data points in the first two PCA components.</p><p id="07c5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The clusters are displayed in different colors <em class="nz">“cmap=‘tab10’”</em>. In the diagrams, the axis label <em class="nz">“ax.set_x/ylabel”</em> and the legend <em class="nz">“legend_labels”</em> are adapted for better interpretation. The size of the data points “s” and the transparency <em class="nz">“alpha”</em> have also been adjusted to improve visibility. Outliers are automatically assigned to cluster -1 in DBSCAN. A table with the average values of the variable for each cluster is displayed below the visualization <em class="nz">“st.dataframe(cluster_means)”</em>.</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="3dc0" class="pi od fq pf b bg pj pk l pl pm">def visualize_clusters(X, title):<br/>    num_samples, num_features = X.shape<br/>    <br/>    n_components = min(num_samples, num_features, 2) <br/><br/>    if n_components &lt; 2:<br/>        st.error("Not enough data points or variables to perform PCA.")<br/>        return<br/><br/>    pca = PCA(n_components=n_components)<br/>    <br/>    try:<br/>        X_pca = pca.fit_transform(X.drop(columns=['Cluster']))<br/>        <br/>        fig, ax = plt.subplots(figsize=(10, 6))<br/>        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=X['Cluster'], cmap='tab10', s=25, alpha=0.4)<br/>        <br/>        ax.set_title(title)<br/>        ax.set_xlabel(f'PCA 1' if n_components &gt;= 1 else '')<br/>        ax.set_ylabel(f'PCA 2' if n_components == 2 else '')<br/><br/>        cluster_counts = X['Cluster'].value_counts()  <br/><br/>        legend_labels = [f"Cluster {int(cluster)} ({count} points)" for cluster, count in cluster_counts.items()]<br/>        legend1 = ax.legend(handles=scatter.legend_elements()[0], labels=legend_labels)<br/>        ax.add_artist(legend1)<br/><br/>        st.pyplot(fig)<br/><br/>        st.write(f"**Average values per cluster:**")<br/>        cluster_means = X.groupby('Cluster').mean()<br/>        st.dataframe(cluster_means)<br/><br/>    except ValueError as e:<br/>        st.error(f"**Error:** Not enough variables were selected.")</span></pre><h2 id="14c0" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">COMMUNICATION WITH THE LLM</h2><p id="271c" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">In this first version of the app, the output of the statistical calculations is only analyzed in the descriptive area. The key figures are interpreted using the <em class="nz">“query_llm_via_cli”</em> function. Specifically, the function is used to communicate with the LLM via a command line (CLI). To achieve this, the Python module <em class="nz">“subprocess”</em> is used to start the process via the command line. The LLM is started via the command [<em class="nz">“ollama”, “run”, “llama3.1”</em>]. The input is stored in <em class="nz">“stdin”</em>, the output in<em class="nz"> “stout”</em>.</p><p id="0125" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Errors and warnings are stored in <em class="nz">“stderr”</em>, which hopefully do not occur. The input is sent to the model via <em class="nz">“process.communicate”</em>. Specifically, the created <em class="nz">“context”</em> is sent to the function to communicate with the LLM. If there is no response from the model, a timeout mechanism <em class="nz">“timeout=40”</em> is included, which stops the execution after 40 seconds. Depending on the computing power of the system used, a response from the model should be displayed much earlier. The model’s response is cleaned up and passed to <em class="nz">“extract_relevant_answer”</em> in order to extract relevant information [1].</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="997f" class="pi od fq pf b bg pj pk l pl pm">def query_llm_via_cli(input_text):<br/>    """Sends the question and context to the LLM and receives a response"""<br/>    try:<br/>        process = subprocess.Popen(<br/>            ["ollama", "run", "llama3.1"],<br/>            stdin=subprocess.PIPE,<br/>            stdout=subprocess.PIPE,<br/>            stderr=subprocess.PIPE,<br/>            text=True,<br/>            encoding='utf-8',<br/>            errors='ignore',<br/>            bufsize=1<br/>        )<br/>        stdout, stderr = process.communicate(input=f"{input_text}\n", timeout=40)<br/><br/>        if process.returncode != 0:<br/>            return f"Error in the model request: {stderr.strip()}"<br/><br/>        response = re.sub(r'\x1b\[.*?m', '', stdout)<br/>        return extract_relevant_answer(response)<br/><br/>    except subprocess.TimeoutExpired:<br/>        process.kill()<br/>        return "Timeout for the model request"<br/>    except Exception as e:<br/>        return f"An unexpected error has occurred: {str(e)}"<br/><br/>def extract_relevant_answer(full_response):<br/>    response_lines = full_response.splitlines()<br/>    if response_lines:<br/>        return "\n".join(response_lines).strip()<br/>    return "No answer received"</span></pre><h2 id="3c2d" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">MAIN FUNCTION OF THE APP</h2><p id="2831" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The structure of the app is defined by the <em class="nz">“main()”</em> function. The title is set <em class="nz">“st.title()”</em> and the sidebar for uploading the dataset in CSV or Excel format <em class="nz">“uploaded_file”</em> is submitted. Once a file has been uploaded, it is analyzed and the numerical and categorical variables are extracted. Here and in many other situations, <em class="nz">“session_state”</em> is used by Streamlit to store certain parameters that are relevant for the selection in the analysis methods.</p><p id="f9cb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The variables <em class="nz">“numerical_columns”</em> and <em class="nz">“categorical_columns”</em> are updated as soon as a new dataset is uploaded. Once data is available, the user can select from the various analysis methods. Once a method has been selected, it is displayed and can be carried out after the corresponding variables have been defined. The main function controls the interactive statistical analysis of the app.</p><h2 id="00ac" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">CUSTOMIZATION OPTIONS</h2><p id="87f7" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">As already mentioned, the app can be expanded to include other analysis methods due to the modular structure of the code. The functionality of interpreting statistical key figures using an LLM can also be transferred to other methods. Llama3.1 (8B) from Meta is currently used, but another LLM (e.g. Mistral) from Ollama can also be used. The command in the <em class="nz">“query_llm_via_cli”</em> function must then be adapted accordingly.</p><p id="f5a4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Depending on the available power, models with more parameters can also be used. The design of the diagrams can be further refined, as can the transmitted contexts, in order to improve the output of the LLM. Alternatively, you can also create a new model file to adjust certain parameters (e.g. parameters) of the LLM and thereby improve the interpretation of the data.</p><h2 id="5aa1" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">ASCVIT V1 PYTHON SCRIPT [GITHUB]</h2><p id="8da5" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">The app code can be downloaded from the following <a class="af oa" href="https://github.com/stefanpietrusky/ASCVITV1" rel="noopener ugc nofollow" target="_blank"><strong class="ml fr">GitHub repository</strong></a>. The app is started in the corresponding directory using the following command:</p><pre class="ni nj nk nl nm pe pf pg bp ph bb bk"><span id="6845" class="pi od fq pf b bg pj pk l pl pm">Streamlit run app.py</span></pre><h2 id="afef" class="oc od fq bf oe of og oh oi oj ok ol om ms on oo op mw oq or os na ot ou ov ow bk">CONCLUSION</h2><p id="63b3" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">In this article, I showed how Streamlit can be used to create an app that can be used to analyze datasets using various methods. I also showed how an interpretation can be integrated into the app using an LLM, which results in real added value. Data is not only automatically visualized and statistical parameters are output, but also classified. The application offers a lot of potential for further development. I have listed some suggestions in the penultimate section. Have fun using and customizing the app.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng qa"><img src="../Images/6986252b10d7723e67c0529d265a19a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j6DnTo7-FNuMgfQOD6HrGA.gif"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">You can clap up to 50 times!</figcaption></figure><p id="bfa4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[1] Pietrusky, S. (2024, August 21). <em class="nz">How to talk to a PDF file without using proprietary models: CLI, Streamlit, Ollama.</em> <em class="nz">Towards Data Science</em>. <a class="af oa" href="https://medium.com/towards-data-science/how-to-talk-to-a-pdf-file-without-using-proprietary-models-cli-streamlit-ollama-6c22437ed932" rel="noopener">URL</a></p><p id="afac" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[2] Maven Analytics. (2024, Juni 10.). <em class="nz">Data Playground, Video Game Sales.</em> <a class="af oa" href="https://mavenanalytics.io/data-playground?accessType=open&amp;order=date_added%2Cdesc&amp;search=game" rel="noopener ugc nofollow" target="_blank">URL</a></p><p id="6f58" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[3] Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em class="nz">The elements of statistical learning: Data mining, inference, and prediction</em> (2nd ed.). Stanford University. <a class="af oa" href="https://hastie.su.domains/Papers/ESLII.pdf" rel="noopener ugc nofollow" target="_blank">URL</a></p><p id="512c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[4] Bruce, P., Bruce, A., &amp; Gedeck, P. (2021). <em class="nz">Praktische Statistik für Data Scientists: 50+ essenzielle Konzepte mit R und Python</em><strong class="ml fr"> </strong>(2nd ed.). O’Reilly.</p><p id="e32b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[5] VanderPlas J. (2017). <em class="nz">Python Data Science Handbook: Essential Tools for Working with Data</em>. O’Reilly. URL</p><p id="f48b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[6] Fahrmeir, L., Künstler, R., Pigeot, I., &amp; Tutz, G. (2016). <em class="nz">Statistik: Der Weg zur Datenanalyse</em> (8th ed.). Springer.</p><p id="e384" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[7] Montgomery, D. C. (2012). <em class="nz">Design and analysis of experiments</em> (8th ed.). Wiley. <a class="af oa" href="https://faculty.ksu.edu.sa/sites/default/files/douglas_c._montgomery-design_and_analysis_of_experiments-wiley_2012_edition_8.pdf" rel="noopener ugc nofollow" target="_blank">URL</a></p><p id="4ab1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[8] Moore, D. S., McCabe, G. P., Craig, B. A., &amp; Duckworth, W. M. (2021). <em class="nz">Introduction to the practice of statistics</em> (10th ed.). W. H. Freeman.</p><p id="9b72" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[9] Montgomery, D. C., Peck, E. A., &amp; Vining, G. G. (2012). <em class="nz">Introduction to linear regression analysis</em> (5th ed.). Wiley. <a class="af oa" href="https://ocd.lcwu.edu.pk/cfiles/Statistics/Stat-503/IntroductiontoLinearRegressionAnalysisbyDouglasC.MontgomeryElizabethA.PeckG.GeoffreyViningz-lib.org.pdf" rel="noopener ugc nofollow" target="_blank">URL</a></p><p id="607d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[10] Hosmer, D. W., Lemeshow, S., &amp; Sturdivant, R. X. (2013). <em class="nz">Applied logistic regression</em> (3rd ed.). Wiley.</p><p id="82fd" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[11] Johnson, R. A., &amp; Wichern, D. W. (2007). <em class="nz">Applied multivariate statistical analysis</em> (6th ed.). Pearson. <a class="af oa" href="https://alimoradi.iut.ac.ir/sites/alimoradi.iut.ac.ir/files/file_basepage/richard_arnold_johnson_dean_w._wichern_applied_bookzz.org_.pdf" rel="noopener ugc nofollow" target="_blank">URL</a></p><p id="4176" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[12] Box, G. E. P., Jenkins, G. M., Reinsel, G. C., &amp; Ljung, G. M. (2015). <em class="nz">Time series analysis: Forecasting and control</em> (5th ed.). Wiley. <a class="af oa" href="http://repo.darmajaya.ac.id/4781/1/Time%20Series%20Analysis_%20Forecasting%20and%20Control%20%28%20PDFDrive%20%29.pdf" rel="noopener ugc nofollow" target="_blank">URL</a></p><p id="fe56" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[13] Witten, I. H., &amp; Frank, E. (2005). <em class="nz">Data mining: Practical machine learning tools and techniques</em> (2nd ed.). Morgan Kaufmann.<a class="af oa" href="http://academia.dk/BiologiskAntropologi/Epidemiologi/DataMining/Witten_and_Frank_DataMining_Weka_2nd_Ed_2005.pdf" rel="noopener ugc nofollow" target="_blank">URL</a></p><p id="285a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[14] Everitt, B. S., Landau, S., Leese, M., &amp; Stahl, D. (2011). <em class="nz">Cluster analysis</em> (5th ed.). Wiley. <a class="af oa" href="https://cicerocq.wordpress.com/wp-content/uploads/2019/05/cluster-analysis_5ed_everitt.pdf" rel="noopener ugc nofollow" target="_blank">URL</a></p><p id="3489" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[15] Aggarwal, C. C., &amp; Reddy, C. K. (2014). <em class="nz">Data Clustering: Algorithms and Applications</em>. CRC Press <a class="af oa" href="https://people.cs.vt.edu/~reddy/papers/DCBOOK.pdf" rel="noopener ugc nofollow" target="_blank">URL</a></p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng qb"><img src="../Images/1eb59c043d8bcab8d8e926430e0f308d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W2V-_U9U1AdPAtMCTMqepg.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Just for the thumbnail (Image by author)</figcaption></figure></div></div></div></div>    
</body>
</html>