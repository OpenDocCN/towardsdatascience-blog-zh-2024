- en: The Intersection of Memory and Grounding in AI Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-intersection-of-memory-and-grounding-in-ai-systems-0fda53231011?source=collection_archive---------8-----------------------#2024-07-24](https://towardsdatascience.com/the-intersection-of-memory-and-grounding-in-ai-systems-0fda53231011?source=collection_archive---------8-----------------------#2024-07-24)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@sandibesen?source=post_page---byline--0fda53231011--------------------------------)[![Sandi
    Besen](../Images/97361d97f50269f70b6621da2256bc29.png)](https://medium.com/@sandibesen?source=post_page---byline--0fda53231011--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0fda53231011--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0fda53231011--------------------------------)
    [Sandi Besen](https://medium.com/@sandibesen?source=post_page---byline--0fda53231011--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0fda53231011--------------------------------)
    ·6 min read·Jul 24, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the 4 key types of memory (short term, short long term, long term,
    and working), the methods of language model grounding, and the role memory plays
    in the process of grounding.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of Language Models and Agentic AI, memory and grounding are both
    hot and emerging fields of research. And although they are often placed closely
    in a sentence and are often related, they serve different functions in practice.
    In this article, I hope to clear up the confusion around these two terms and demonstrate
    how memory can play a role in the overall grounding of a model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e36dde5c62d9f8a01a89f42a1c0ca99.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: Dalle3, Description: split parts of the brain potray memory and grounding
    in the style of a friendly cartoon'
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory in Language Models**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In my last article, we discussed the [important role of memory in Agentic AI](https://medium.com/towards-data-science/the-important-role-of-memory-in-agentic-ai-896b22542b3e).
    Memory in language models refers to the ability of AI systems to retain and recall
    pertinent information, contributing to its ability to reason and continuously
    learn from its experiences. **Memory can be thought of in 4 categories: short
    term memory, short long term memory, long term memory, and working memory.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'It sounds complex, but let’s break them down simply:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Short Term Memory (STM):**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: STM retains information for a very brief period of time, which could be seconds
    to minutes. If you ask a language model a question it needs to retain your messages
    for long enough to generate an answer to your question. Just like people, language
    models struggle to remember too many things simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: '[Miller’s law](https://www.simplypsychology.org/short-term-memory.html), states
    that “Short-term memory is a component of memory that holds a small amount of
    information in an active, readily available state for a brief period, typically
    a few seconds to a minute. The duration of STM seems to be between 15 and 30 seconds,
    and STM’s capacity is limited, often thought to be about 7±2 items.”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So if you ask a language model “what genre is that book that I mentioned in
    my previous message?” it needs to use its short term memory to reference recent
    messages and generate a relevant response.
  prefs: []
  type: TYPE_NORMAL
- en: '**Implementation:**'
  prefs: []
  type: TYPE_NORMAL
- en: Context is stored in external systems, such as session variables or databases,
    which hold a portion of the conversation history. Each new user input and assistant
    response is appended to the existing context to create conversation history. During
    inference, context is sent along with the user’s new query to the language model
    to generate a response that considers the entire conversation. This [research
    paper](https://openreview.net/pdf?id=QNW1OrjynpT) offers a more in depth view
    of the mechanisms that enable short term memory.
  prefs: []
  type: TYPE_NORMAL
- en: '**Short Long Term Memory (SLTM):**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SLTM retains information for a moderate period, which can be minutes to hours.
    For example, within the same session, you can pick back up where you left off
    in a conversation without having to repeat context because it has been stored
    as SLTM. This process is also an external process rather than part of the language
    model itself.
  prefs: []
  type: TYPE_NORMAL
- en: '**Implementation:**'
  prefs: []
  type: TYPE_NORMAL
- en: Sessions can be managed using identifiers that link user interactions over time.
    Context data is stored in a way that it can persist across user interactions within
    a defined period, such as a database. When a user resumes conversation, the system
    can retrieve the conversation history from previous sessions and pass that to
    the language model during inference. Much like in short term memory, each new
    user input and assistant response is appended to the existing context to keep
    conversation history current.
  prefs: []
  type: TYPE_NORMAL
- en: '**Long Term Memory (LTM):**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LTM retains information for a admin defined amount of time that could be indefinitely.
    For example, if we were to build an AI tutor, it would be important for the language
    model to understand what subjects the student performs well in, where they still
    struggle, what learning styles work best for them, and more. This way, the model
    can recall relevant information to inform its future teaching plans. [Squirrel
    AI](https://squirrelai.com/#/products/technology) is an example of a platform
    that uses long term memory to “craft personalized learning pathways, engages in
    targeted teaching, and provides emotional intervention when needed”.
  prefs: []
  type: TYPE_NORMAL
- en: '**Implementation:**'
  prefs: []
  type: TYPE_NORMAL
- en: Information can be stored in structured databases, knowledge graphs, or document
    stores that are queried as needed. Relevant information is retrieved based on
    the user’s current interaction and past history. This provides context for the
    language model that is passed back in with the user’s response or system prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '**Working Memory:**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Working memory is a component of the language model itself (unlike the other
    types of memory that are external processes). It enables the language model to
    hold information, manipulate it, and refine it — improving the model’s ability
    to reason. This is important because as the model processes the user’s ask, its
    understanding of the task and the steps it needs to take to execute on it can
    change. You can think of working memory as the model’s own scratch pad for its
    thoughts. For example, when provided with a multistep math problem such as (5
    + 3) * 2, the language model needs the ability to calculate the (5+3) in the parentheses
    and store that information before taking the sum of the two numbers and multiplying
    by 2\. If you’re interested in digging deeper into this subject, the [paper](https://arxiv.org/abs/2404.09173)
    “TransformerFAM: Feedback attention is working memory” offers a new approach to
    extending the working memory and enabling a language model to process inputs/context
    window of unlimited length.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Implementation:**'
  prefs: []
  type: TYPE_NORMAL
- en: Mechanisms like attention layers in transformers or hidden states in recurrent
    neural networks (RNNs) are responsible for maintaining intermediate computations
    and provide the ability to manipulate intermediate results within the same inference
    session. As the model processes input, it updates its internal state, which enables
    stronger reasoning abilities.
  prefs: []
  type: TYPE_NORMAL
- en: '*All 4 types of memory are important components of creating an AI system that
    can effectively manage and utilize information across various timeframes and contexts.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d7e13a9ce7878b0823aa6f457e6eeb6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table of Types of Memory in AI Systems, Source: Sandi Besen'
  prefs: []
  type: TYPE_NORMAL
- en: Grounding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**The response from a language model should always make sense in the context
    of the conversation — they shouldn’t just be a bunch of factual statements**.
    Grounding measures the ability of a model to produce an output that is contextually
    relevant and meaningful. The process of grounding a language model can be a combination
    of language model training, fine-tuning, and external processes (including memory!).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Language Model Training and Fine Tuning**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data that the model is initially trained on will make a substantial difference
    in how grounded the model is. Training a model on a large corpora of diverse data
    enables it to learn language patterns, grammar, and semantics, to predict the
    next most relevant word. The pre-trained model is then fine-tuned on domain-specific
    data, which helps it generate more relevant and accurate outputs for particular
    applications that require deeper domain specific knowledge. This is especially
    important if you require the model to perform well on specific texts which it
    might not have been exposed to during its initial training. Although our expectations
    of a language model’s capabilities are high, we can’t expect it to perform well
    on something it has never seen before. Just like we wouldn’t expect a student
    to perform well on an exam if they hadn’t studied the material.
  prefs: []
  type: TYPE_NORMAL
- en: '**External Context**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Providing the model with real-time or up-to-date context-specific information
    also helps it stay grounded. There are many methods of doing this, such as integrating
    it with external knowledge bases, APIs, and real-time data. This method is also
    known as Retrieval Augmented Generation (RAG).
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory Systems**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Memory systems in AI play a crucial role in ensuring that the system remains
    grounded based on its previously taken actions, lessons learned, performance over
    time, and experience with users and other systems. The four types of memory outlined
    previously in the article play a crucial role in grounding a language model’s
    ability to stay context-aware and produce relevant outputs. Memory systems work
    in tandem with grounding techniques like training, fine-tuning, and external context
    integration to enhance the model’s overall performance and relevance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Memory and grounding are interconnected elements that enhance the performance
    and reliability of AI systems. While memory enables AI to retain and manipulate
    information across different timeframes, grounding ensures that the AI’s outputs
    are contextually relevant and meaningful. By integrating memory systems and grounding
    techniques, AI systems can achieve a higher level of understanding and effectiveness
    in their interactions and tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: The opinions expressed both in this article and paper are solely those
    of the authors and do not necessarily reflect the views or policies of their respective
    employers.'
  prefs: []
  type: TYPE_NORMAL
- en: If you still have questions or think that something needs to be further clarified?
    Drop me a DM on [Linkedin](https://www.linkedin.com/in/sandibesen/)! I‘m always
    eager to engage in food for thought and iterate on my work.
  prefs: []
  type: TYPE_NORMAL
- en: 'References:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://openreview.net/pdf?id=QNW1OrjynpT](https://openreview.net/pdf?id=QNW1OrjynpT)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.simplypsychology.org/short-term-memory.html](https://www.simplypsychology.org/short-term-memory.html)'
  prefs: []
  type: TYPE_NORMAL
