<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Enhancing Interaction between Language Models and Graph Databases via a Semantic Layer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Enhancing Interaction between Language Models and Graph Databases via a Semantic Layer</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/enhancing-interaction-between-language-models-and-graph-databases-via-a-semantic-layer-0a78ad3eba49?source=collection_archive---------0-----------------------#2024-01-18">https://towardsdatascience.com/enhancing-interaction-between-language-models-and-graph-databases-via-a-semantic-layer-0a78ad3eba49?source=collection_archive---------0-----------------------#2024-01-18</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="4306" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Provide an LLM agent with a suite of robust tools it can use to interact with a graph database</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://bratanic-tomaz.medium.com/?source=post_page---byline--0a78ad3eba49--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Tomaz Bratanic" class="l ep by dd de cx" src="../Images/d5821aa70918fcb3fc1ff0013497b3d5.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*SnWQP0l4Vg9577WAErbjfw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--0a78ad3eba49--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://bratanic-tomaz.medium.com/?source=post_page---byline--0a78ad3eba49--------------------------------" rel="noopener follow">Tomaz Bratanic</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--0a78ad3eba49--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 18, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">8</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="532e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Knowledge graphs provide a great representation of data with flexible data schema that can store <a class="af nf" href="https://medium.com/neo4j/using-a-knowledge-graph-to-implement-a-devops-rag-application-b6ba24831b16" rel="noopener">structured and unstructured information</a>. You can use Cypher statements to retrieve information from a graph database like Neo4j. One option is to use LLMs to generate Cypher statements. While that option provides excellent flexibility, the truth is that base LLMs are still brittle at consistently generating precise Cypher statements. Therefore, we need to look for an alternative to guarantee consistency and robustness. What if, instead of developing Cypher statements, the LLM extracts parameters from user input and uses predefined functions or Cypher templates based on the user intent? In short, you could provide the LLM with a set of predefined tools and instructions on when and how to use them based on the user input, which is also known as the semantic layer.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh ni"><img src="../Images/aeeb64a2a96d1a41bf353ad6817a5d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yIoe92D0bM9DCPx-45mwSg.png"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Semantic layer is an intermediate step that provides additional accuracy and robust way of LLMs interacting with a Knowledge graph. Image by the author. Inspired by <a class="af nf" href="https://cube.dev/blog/semantic-layer-the-backbone-of-ai-powered-data-experiences" rel="noopener ugc nofollow" target="_blank">this image</a>.</figcaption></figure><p id="ebe7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A semantic layer consists of various tools exposed to an LLM that it can use to interact with a knowledge graph. They can be of various complexity. You can think of each tool in a semantic layer as a function. For example, take a look at the following function.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="bc68" class="od oe fq oa b bg of og l oh oi">def get_information(entity: str, type: str) -&gt; str:<br/>    candidates = get_candidates(entity, type)<br/>    if not candidates:<br/>        return "No information was found about the movie or person in the database"<br/>    elif len(candidates) &gt; 1:<br/>        newline = "\n"<br/>        return (<br/>            "Need additional information, which of these "<br/>            f"did you mean: {newline + newline.join(str(d) for d in candidates)}"<br/>        )<br/>    data = graph.query(<br/>        description_query, params={"candidate": candidates[0]["candidate"]}<br/>    )<br/>    return data[0]["context"]</span></pre><p id="d2b3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The tools can have multiple input parameters, like in the above example, which allows you to implement complex tools. Additionally, the workflow can consist of more than a database query, allowing you to handle any edge cases or exceptions as you see fit. The advantage is that you turn prompt engineering problems, which might work most of the time, into code engineering problems, which work every time exactly as scripted.</p><h2 id="c2c6" class="oj oe fq bf ok ol om on oo op oq or os ms ot ou ov mw ow ox oy na oz pa pb pc bk">Movie agent</h2><p id="19ae" class="pw-post-body-paragraph mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne fj bk">In this blog post, we will demonstrate how to implement a semantic layer that allows an LLM agent to interact with a knowledge graph that contains information about actors, movies, and their ratings.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh pi"><img src="../Images/e04d930fdbbd3e70efc04a3060abfcff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8YVAO4zOT1AS_3LucriYgA.png"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Movie agent architecture. Image by the author.</figcaption></figure><p id="e0f0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Taken from the documentation (also written by me):</p><blockquote class="pj pk pl"><p id="525b" class="mj mk pm ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The agent utilizes several tools to interact with the Neo4j graph database effectively.</p><p id="6819" class="mj mk pm ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">* Information tool</strong>: Retrieves data about movies or individuals, ensuring the agent has access to the latest and most relevant information.</p><p id="a0ec" class="mj mk pm ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">* Recommendation Tool</strong>: Provides movie recommendations based upon user preferences and input.</p><p id="5ad9" class="mj mk pm ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">* Memory Tool</strong>: Stores information about user preferences in the knowledge graph, allowing for a personalized experience over multiple interactions.</p></blockquote><p id="12f3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">An agent can use information or recommendation tools to retrieve information from the database or use the memory tool to store user preferences in the database.<br/>Predefined functions and tools empower the agent to orchestrate intricate user experiences, guiding individuals towards specific goals or delivering tailored information that aligns with their current position within the user journey.<br/>This predefined approach enhances the robustness of the system by reducing the artistic freedom of an LLM, ensuring that responses are more structured and aligned with predetermined user flows, thereby improving the overall user experience.</p><p id="2fb8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The semantic layer backend of a movie agent is implemented and available as a <a class="af nf" href="https://github.com/langchain-ai/langchain/tree/master/templates/neo4j-semantic-layer" rel="noopener ugc nofollow" target="_blank">LangChain template</a>. I have used this template to build a simple streamlit chat application.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh pn"><img src="../Images/8e94a84617ebaa1796729ef1cae7a77d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-KvT9QiV7wO3gdA2r-1J7g.png"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Streamlit chat interface. Image by the author.</figcaption></figure><p id="e72b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Code is available on <a class="af nf" href="https://github.com/tomasonjo/llm-movieagent" rel="noopener ugc nofollow" target="_blank">GitHub</a>. You can start the project by defining environment variables and executing the following command:</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="6b47" class="od oe fq oa b bg of og l oh oi">docker-compose up</span></pre><h2 id="23c0" class="oj oe fq bf ok ol om on oo op oq or os ms ot ou ov mw ow ox oy na oz pa pb pc bk">Graph model</h2><p id="02ae" class="pw-post-body-paragraph mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne fj bk">The graph is based on the <a class="af nf" href="https://grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank">MovieLens</a> dataset. It contains information about actors, movies, and 100k user ratings of movies.</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh po"><img src="../Images/1498878706b68d43ef3619c7bbbec6a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cyxO8NPhX-wnWZbev3njUg.png"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Graph schema. Image by the author.</figcaption></figure><p id="603f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The visualization depicts a knowledge graph of individuals who have either acted in or directed a movie, which is further categorized by genre. Each movie node holds information about its release date, title, and IMDb rating. The graph also contains user ratings, which we can use to provide recommendations.</p><p id="82eb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">You can populate the graph by executing the <code class="cx pp pq pr oa b">ingest.py</code> script, which is located in the root directory of the folder.</p><h2 id="cf8c" class="oj oe fq bf ok ol om on oo op oq or os ms ot ou ov mw ow ox oy na oz pa pb pc bk">Defining tools</h2><p id="1993" class="pw-post-body-paragraph mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne fj bk">Now, we will define the tools an agent can use to interact with the knowledge graph. We will start with the <strong class="ml fr">information tool</strong>. Information tool is designed to fetch relevant information about actors, directors, and movies. The Python code looks the following:</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="75ad" class="od oe fq oa b bg of og l oh oi">def get_information(entity: str, type: str) -&gt; str:<br/>    # Use full text index to find relevant movies or people<br/>    candidates = get_candidates(entity, type)<br/>    if not candidates:<br/>        return "No information was found about the movie or person in the database"<br/>    elif len(candidates) &gt; 1:<br/>        newline = "\n"<br/>        return (<br/>            "Need additional information, which of these "<br/>            f"did you mean: {newline + newline.join(str(d) for d in candidates)}"<br/>        )<br/>    data = graph.query(<br/>        description_query, params={"candidate": candidates[0]["candidate"]}<br/>    )<br/>    return data[0]["context"]</span></pre><p id="0186" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The function starts by finding relevant people or movies mentioned using a full-text index. The <a class="af nf" href="https://neo4j.com/docs/cypher-manual/current/indexes-for-full-text-search/" rel="noopener ugc nofollow" target="_blank">full-text index in Neo4j</a> uses Lucene under the hood. It enables a seamless implementation of text distance-based lookups, which allow the user to misspell some words and still get results. If no relevant entities are found, we can directly return a response. On the other hand, if multiple candidates are identified, we can guide the agent to ask the user a follow-up question and be more specific about the movie or person they are interested in. Imagine that a user asks, “Who is John?”.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="ae8e" class="od oe fq oa b bg of og l oh oi">print(get_information("John", "person"))<br/># Need additional information, which of these did you mean: <br/># {'candidate': 'John Lodge', 'label': 'Person'}<br/># {'candidate': 'John Warren', 'label': 'Person'}<br/># {'candidate': 'John Gray', 'label': 'Person'}</span></pre><p id="9d89" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this case, the tool informs the agent that it needs additional information. With simple prompt engineering, we can steer the agent to ask the user a follow-up question. Suppose the user is specific enough, which allows the tool to identify a particular movie or a person. In that case, we use a parametrized Cypher statement to retrieve relevant information.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="20ce" class="od oe fq oa b bg of og l oh oi">print(get_information("Keanu Reeves", "person"))<br/># type:Actor<br/># title: Keanu Reeves<br/># year: <br/># ACTED_IN: Matrix Reloaded, The, Side by Side, Matrix Revolutions, The, Sweet November, Replacements, The, Hardball, Matrix, The, Constantine, Bill &amp; Ted's Bogus Journey, Street Kings, Lake House, The, Chain Reaction, Walk in the Clouds, A, Little Buddha, Bill &amp; Ted's Excellent Adventure, The Devil's Advocate, Johnny Mnemonic, Speed, Feeling Minnesota, The Neon Demon, 47 Ronin, Henry's Crime, Day the Earth Stood Still, The, John Wick, River's Edge, Man of Tai Chi, Dracula (Bram Stoker's Dracula), Point Break, My Own Private Idaho, Scanner Darkly, A, Something's Gotta Give, Watcher, The, Gift, The<br/># DIRECTED: Man of Tai Chi</span></pre><p id="9be6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">With this information, the agent can answer most of the questions that concern Keanu Reeves.</p><p id="ddd9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now, let’s guide the agent on utilizing this tool effectively. Fortunately, with LangChain, the process is straightforward and efficient. First, we define the input parameters of the function using a Pydantic object.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="9e2b" class="od oe fq oa b bg of og l oh oi">class InformationInput(BaseModel):<br/>    entity: str = Field(description="movie or a person mentioned in the question")<br/>    entity_type: str = Field(<br/>        description="type of the entity. Available options are 'movie' or 'person'"<br/>    )</span></pre><p id="5511" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Here, we describe that both entity and entity_type parameters are strings. The entity parameter input is defined as the movie or a person mentioned in the question. On the other hand, with the entity_type, we also provide available options. When dealing with low cardinalities, meaning when there is a small number of distinct values, we can provide available options directly to an LLM so that it can use valid inputs. As we saw before, we use a full-text index to disambiguate movies or people as there are too many values to provide directly in the prompt.</p><p id="d2e3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now let’s put it all together in a Information tool definition.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="d5ea" class="od oe fq oa b bg of og l oh oi">class InformationTool(BaseTool):<br/>    name = "Information"<br/>    description = (<br/>        "useful for when you need to answer questions about various actors or movies"<br/>    )<br/>    args_schema: Type[BaseModel] = InformationInput<br/><br/>    def _run(<br/>        self,<br/>        entity: str,<br/>        entity_type: str,<br/>        run_manager: Optional[CallbackManagerForToolRun] = None,<br/>    ) -&gt; str:<br/>        """Use the tool."""<br/>        return get_information(entity, entity_type)</span></pre><p id="222e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Accurate and concise tool definitions are an important part of a semantic layer, so that an agent can correctly pick relevant tools when needed.</p><p id="fcbf" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The recommendation tool is slightly more complex.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="c208" class="od oe fq oa b bg of og l oh oi">def recommend_movie(movie: Optional[str] = None, genre: Optional[str] = None) -&gt; str:<br/>    """<br/>    Recommends movies based on user's history and preference<br/>    for a specific movie and/or genre.<br/>    Returns:<br/>        str: A string containing a list of recommended movies, or an error message.<br/>    """<br/>    user_id = get_user_id()<br/>    params = {"user_id": user_id, "genre": genre}<br/>    if not movie and not genre:<br/>        # Try to recommend a movie based on the information in the db<br/>        response = graph.query(recommendation_query_db_history, params)<br/>        try:<br/>            return ", ".join([el["movie"] for el in response])<br/>        except Exception:<br/>            return "Can you tell us about some of the movies you liked?"<br/>    if not movie and genre:<br/>        # Recommend top voted movies in the genre the user haven't seen before<br/>        response = graph.query(recommendation_query_genre, params)<br/>        try:<br/>            return ", ".join([el["movie"] for el in response])<br/>        except Exception:<br/>            return "Something went wrong"<br/><br/>    candidates = get_candidates(movie, "movie")<br/>    if not candidates:<br/>        return "The movie you mentioned wasn't found in the database"<br/>    params["movieTitles"] = [el["candidate"] for el in candidates]<br/>    query = recommendation_query_movie(bool(genre))<br/>    response = graph.query(query, params)<br/>    try:<br/>        return ", ".join([el["movie"] for el in response])<br/>    except Exception:<br/>        return "Something went wrong"</span></pre><p id="5897" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The first thing to notice is that both input parameters are optional. Therefore, we need to introduce workflows that handle all the possible combinations of input parameters and the lack of them. To produce personalized recommendations, we first get a <code class="cx pp pq pr oa b">user_id</code> , which is then passed into downstream Cypher recommendation statements.</p><p id="135d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Similarly as before, we need to present the input of the function to the agent.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="6dcb" class="od oe fq oa b bg of og l oh oi">class RecommenderInput(BaseModel):<br/>    movie: Optional[str] = Field(description="movie used for recommendation")<br/>    genre: Optional[str] = Field(<br/>        description=(<br/>            "genre used for recommendation. Available options are:" f"{all_genres}"<br/>        )<br/>    )</span></pre><p id="f5c3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Since only 20 available genres exist, we provide their values as part of the prompt. For movie disambiguation, we again use a full-text index within the function. As before, we finish with the tool definition to inform the LLM when to use it.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="19a2" class="od oe fq oa b bg of og l oh oi">class RecommenderTool(BaseTool):<br/>    name = "Recommender"<br/>    description = "useful for when you need to recommend a movie"<br/>    args_schema: Type[BaseModel] = RecommenderInput<br/><br/>    def _run(<br/>        self,<br/>        movie: Optional[str] = None,<br/>        genre: Optional[str] = None,<br/>        run_manager: Optional[CallbackManagerForToolRun] = None,<br/>    ) -&gt; str:<br/>        """Use the tool."""<br/>        return recommend_movie(movie, genre)</span></pre><p id="ea64" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">So far, we have defined two tools to retrieve data from the database. However, the information flow doesn’t have to be one-way. For example, when a user informs the agent they have already watched a movie and maybe liked it, we can store that information in the database and use it in further recommendations. Here is where the memory tool comes in handy.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="5226" class="od oe fq oa b bg of og l oh oi">def store_movie_rating(movie: str, rating: int):<br/>    user_id = get_user_id()<br/>    candidates = get_candidates(movie, "movie")<br/>    if not candidates:<br/>        return "This movie is not in our database"<br/>    response = graph.query(<br/>        store_rating_query,<br/>        params={"user_id": user_id, "candidates": candidates, "rating": rating},<br/>    )<br/>    try:<br/>        return response[0]["response"]<br/>    except Exception as e:<br/>        print(e)<br/>        return "Something went wrong"<br/><br/><br/>class MemoryInput(BaseModel):<br/>    movie: str = Field(description="movie the user liked")<br/>    rating: int = Field(<br/>        description=(<br/>            "Rating from 1 to 5, where one represents heavy dislike "<br/>            "and 5 represent the user loved the movie"<br/>        )<br/>    )</span></pre><p id="a4ab" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The memory tool has two mandatory input parameters that define the movie and its rating. It’s a straightforward tool. One thing I should mention is that I noticed in my testing that it probably makes sense to provide examples of when to give a specific rating, as the LLM isn’t the best at it out of the box.</p><h2 id="c3c7" class="oj oe fq bf ok ol om on oo op oq or os ms ot ou ov mw ow ox oy na oz pa pb pc bk">Agent</h2><p id="92e5" class="pw-post-body-paragraph mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne fj bk">Let’s put it now all together using <a class="af nf" href="https://python.langchain.com/docs/expression_language/" rel="noopener ugc nofollow" target="_blank">LangChain expression language</a> (LCEL) to define an agent.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="1b0b" class="od oe fq oa b bg of og l oh oi">llm = ChatOpenAI(temperature=0, model="gpt-4", streaming=True)<br/>tools = [InformationTool(), RecommenderTool(), MemoryTool()]<br/><br/>llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])<br/><br/>prompt = ChatPromptTemplate.from_messages(<br/>    [<br/>        (<br/>            "system",<br/>            "You are a helpful assistant that finds information about movies "<br/>            " and recommends them. If tools require follow up questions, "<br/>            "make sure to ask the user for clarification. Make sure to include any "<br/>            "available options that need to be clarified in the follow up questions "<br/>            "Do only the things the user specifically requested. ",<br/>        ),<br/>        MessagesPlaceholder(variable_name="chat_history"),<br/>        ("user", "{input}"),<br/>        MessagesPlaceholder(variable_name="agent_scratchpad"),<br/>    ]<br/>)<br/><br/>agent = (<br/>    {<br/>        "input": lambda x: x["input"],<br/>        "chat_history": lambda x: _format_chat_history(x["chat_history"])<br/>        if x.get("chat_history")<br/>        else [],<br/>        "agent_scratchpad": lambda x: format_to_openai_function_messages(<br/>            x["intermediate_steps"]<br/>        ),<br/>    }<br/>    | prompt<br/>    | llm_with_tools<br/>    | OpenAIFunctionsAgentOutputParser()<br/>)<br/><br/>agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True).with_types(<br/>    input_type=AgentInput, output_type=Output<br/>)</span></pre><p id="27be" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">LangChain expression language makes it very convenient to define an agent and expose all its functionalities. We won’t go into LCEL syntax as that is beyond the scope of this blog post.</p><p id="302e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The movie agent backend is exposed as an API endpoint using <a class="af nf" href="https://www.langchain.com/langserve" rel="noopener ugc nofollow" target="_blank">LangServe</a>.</p><h2 id="4ec6" class="oj oe fq bf ok ol om on oo op oq or os ms ot ou ov mw ow ox oy na oz pa pb pc bk">Streamlit chat application</h2><p id="fd1f" class="pw-post-body-paragraph mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne fj bk">Now we just have to implement a streamlit application that connects to the LangServe API endpoint and we are good to go. We’ll just look at the async function that is used to retrieve an agent response.</p><pre class="nj nk nl nm nn nz oa ob bp oc bb bk"><span id="2f61" class="od oe fq oa b bg of og l oh oi">async def get_agent_response(<br/>    input: str, stream_handler: StreamHandler, chat_history: Optional[List[Tuple]] = []<br/>):<br/>    url = "http://api:8080/movie-agent/"<br/>    st.session_state["generated"].append("")<br/>    remote_runnable = RemoteRunnable(url)<br/>    async for chunk in remote_runnable.astream_log(<br/>        {"input": input, "chat_history": chat_history}<br/>    ):<br/>        log_entry = chunk.ops[0]<br/>        value = log_entry.get("value")<br/>        if isinstance(value, dict) and isinstance(value.get("steps"), list):<br/>            for step in value.get("steps"):<br/>                stream_handler.new_status(step["action"].log.strip("\n"))<br/>        elif isinstance(value, str):<br/>            st.session_state["generated"][-1] += value<br/>            stream_handler.new_token(value)</span></pre><p id="d49c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The function <code class="cx pp pq pr oa b">get_agent_response</code> is designed to interact with a movie-agent API. It sends a request with the user's input and chat history to the API and then processes the response asynchronously. The function handles different types of responses, updating the stream handler with new statuses and appending the generated text to the session state, which allows us to stream results to the user.</p><p id="e30b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let’s now test it out</p><figure class="nj nk nl nm nn no ng nh paragraph-image"><div role="button" tabindex="0" class="np nq ed nr bh ns"><div class="ng nh ps"><img src="../Images/bce1fd1386d8ea222ccafa7738aa6b16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lXNHwBx0cZTxBUi5HhaHjQ.png"/></div></div><figcaption class="nu nv nw ng nh nx ny bf b bg z dx">Movie agent in action. Image by the author.</figcaption></figure><p id="fdc7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The resulting movie agent offers a surprisingly good and guided interaction with the user.</p><h2 id="fe67" class="oj oe fq bf ok ol om on oo op oq or os ms ot ou ov mw ow ox oy na oz pa pb pc bk">Conclusion</h2><p id="013d" class="pw-post-body-paragraph mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne fj bk">In conclusion, the integration of a semantic layer in language model interactions with graph databases, as exemplified by our Movie Agent, represents a significant leap forward in enhancing user experience and data interaction efficiency. By shifting the focus from generating arbitrary Cypher statements to utilizing a structured, predefined suite of tools and functions, the semantic layer brings a new level of precision and consistency to language model engagements. This approach not only streamlines the process of extracting relevant information from knowledge graphs but also ensures a more goal-oriented, user-centric experience.</p><p id="e014" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The semantic layer acts as a bridge, translating user intent into specific, actionable queries that the language model can execute with accuracy and reliability. As a result, users benefit from a system that not only understands their queries more effectively but also guides them towards their desired outcomes with greater ease and less ambiguity. Furthermore, by constraining the language model’s responses within the parameters of these predefined tools, we mitigate the risks of incorrect or irrelevant outputs, thereby enhancing the trustworthiness and reliability of the system.</p><p id="752d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The code is available on <a class="af nf" href="https://github.com/tomasonjo/llm-movieagent" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p><h2 id="1a92" class="oj oe fq bf ok ol om on oo op oq or os ms ot ou ov mw ow ox oy na oz pa pb pc bk">Dataset</h2><p id="0f19" class="pw-post-body-paragraph mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne fj bk">F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <a class="af nf" href="https://doi.org/10.1145/2827872" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1145/2827872</a></p></div></div></div></div>    
</body>
</html>