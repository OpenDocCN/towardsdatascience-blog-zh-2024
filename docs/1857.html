<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Integrating Microsoft GraphRAG into Neo4j</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Integrating Microsoft GraphRAG into Neo4j</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/integrating-microsoft-graphrag-into-neo4j-e0d4fa00714c?source=collection_archive---------0-----------------------#2024-07-31">https://towardsdatascience.com/integrating-microsoft-graphrag-into-neo4j-e0d4fa00714c?source=collection_archive---------0-----------------------#2024-07-31</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="f878" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Store the MSFT GraphRAG output into Neo4j and implement local and global retrievers with LangChain or LlamaIndex</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://bratanic-tomaz.medium.com/?source=post_page---byline--e0d4fa00714c--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Tomaz Bratanic" class="l ep by dd de cx" src="../Images/d5821aa70918fcb3fc1ff0013497b3d5.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*SnWQP0l4Vg9577WAErbjfw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e0d4fa00714c--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://bratanic-tomaz.medium.com/?source=post_page---byline--e0d4fa00714c--------------------------------" rel="noopener follow">Tomaz Bratanic</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e0d4fa00714c--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">16 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 31, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">10</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/b8dfacae208dd7c0c5efcd6495e436c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yoBKfh5RkKpz_3mu"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created with ChatGPT.</figcaption></figure><p id="c386" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><a class="af ny" href="https://microsoft.github.io/graphrag/" rel="noopener ugc nofollow" target="_blank">Microsoft’s GraphRAG implementation</a> has gained significant attention lately. In my <a class="af ny" href="https://medium.com/neo4j/implementing-from-local-to-global-graphrag-with-neo4j-and-langchain-constructing-the-graph-73924cc5bab4" rel="noopener">last blog post</a>, I discussed how the graph is constructed and explored some of the innovative aspects highlighted in the <a class="af ny" href="https://arxiv.org/abs/2404.16130" rel="noopener ugc nofollow" target="_blank">research paper</a>. At a high level, the input to the GraphRAG library are source documents containing various information. The documents are processed using an Large Language Model (LLM) to extract structured information about entities appearing in the documents along with their relationships. This extracted structured information is then used to construct a knowledge graph.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk nz"><img src="../Images/24791b4cf2a113c9a490245cdae794f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3-dqkOcFxHEYMRKP.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">High-level indexing pipeline as implemented in the GraphRAG paper by Microsoft — Image by author</figcaption></figure><p id="03d9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After the knowledge graph has been constructed, the GraphRAG library uses a combination of graph algorithms, specifically Leiden community detection algorithm, and LLM prompting to generate natural language summaries of communities of entities and relationships found in the knowledge graph.</p><p id="5f3d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this post, we’ll take the output from the <a class="af ny" href="https://github.com/microsoft/graphrag" rel="noopener ugc nofollow" target="_blank">GraphRAG library</a>, store it in Neo4j, and then set up retrievers directly from Neo4j using LangChain and LlamaIndex orchestration frameworks.</p><p id="c1b6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The code and GraphRAG output are accessible on <a class="af ny" href="https://github.com/tomasonjo/blogs/tree/master/msft_graphrag" rel="noopener ugc nofollow" target="_blank">GitHub</a>, allowing you to skip the GraphRAG extraction process.</p><h2 id="8cfc" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Dataset</h2><p id="075b" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">The dataset featured in this blog post is “A Christmas Carol” by Charles Dickens, which is freely accessible via the Gutenberg Project.</p><div class="pa pb pc pd pe pf"><a href="https://www.gutenberg.org/ebooks/19337?source=post_page-----e0d4fa00714c--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pg ab ig"><div class="ph ab co cb pi pj"><h2 class="bf fr hw z io pk iq ir pl it iv fp bk">A Christmas Carol by Charles Dickens</h2><div class="pm l"><h3 class="bf b hw z io pk iq ir pl it iv dx">Free kindle book and epub digitized and proofread by volunteers.</h3></div><div class="pn l"><p class="bf b dy z io pk iq ir pl it iv dx">www.gutenberg.org</p></div></div><div class="po l"><div class="pp l pq pr ps po pt lr pf"/></div></div></a></div><p id="b893" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We selected this book as the source document because it is highlighted in the <a class="af ny" href="https://microsoft.github.io/graphrag/posts/get_started/" rel="noopener ugc nofollow" target="_blank">introductory documentation</a>, allowing us to perform the extraction effortlessly.</p><h2 id="339f" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Graph construction</h2><p id="bbdc" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Even though you can skip the graph extraction part, we’ll talk about a couple of configuration options I think are the most important. For example, graph extraction can be very token-intensive and costly. Therefore, testing the extraction with a relatively cheap but good-performing LLM like gpt-4o-mini makes sense. The cost reduction from gpt-4-turbo can be significant while retaining good accuracy, as described in this <a class="af ny" href="https://blog.cubed.run/graphrag-gpt-4o-mini-building-an-ai-knowledge-graph-at-low-cost-a4282440d92e" rel="noopener ugc nofollow" target="_blank">blog post</a>.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="5ab1" class="py ob fq pv b bg pz qa l qb qc">GRAPHRAG_LLM_MODEL=gpt-4o-mini</span></pre><p id="7d5d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The most important configuration is the type of entities we want to extract. By default, organizations, people, events, and geo are extracted.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="527e" class="py ob fq pv b bg pz qa l qb qc">GRAPHRAG_ENTITY_EXTRACTION_ENTITY_TYPES=organization,person,event,geo</span></pre><p id="0e17" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">These default entity types might work well for a book, but make sure to change them accordingly to the domain of the documents you are looking at processing for a given use case.</p><p id="aafe" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Another important configuration is the max gleanings value. The authors identified, and we also validated separately, that an LLM doesn’t extract all the available information in a single extraction pass.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qd"><img src="../Images/9538bdd012d48b26296e1a04445c33f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*Dur0l2MdEydVntKK.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Number of extract entities given the size of text chunks — Image from the <a class="af ny" href="https://arxiv.org/abs/2404.16130" rel="noopener ugc nofollow" target="_blank">GraphRAG paper</a>, licensed under CC BY 4.0</figcaption></figure><p id="2dc1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The gleaning configuration allows the LLM to perform multiple extraction passes. In the above image, we can clearly see that we extract more information when performing multiple passes (gleanings). Multiple passes are token-intensive, so a cheaper model like gpt-4o-mini helps to keep the cost low.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="5a94" class="py ob fq pv b bg pz qa l qb qc">GRAPHRAG_ENTITY_EXTRACTION_MAX_GLEANINGS=1</span></pre><p id="0423" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Additionally, the claims or covariate information is not extracted by default. You can enable it by setting the <code class="cx qe qf qg pv b">GRAPHRAG_CLAIM_EXTRACTION_ENABLED</code> configuration.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="8bfe" class="py ob fq pv b bg pz qa l qb qc">GRAPHRAG_CLAIM_EXTRACTION_ENABLED=False<br/>GRAPHRAG_CLAIM_EXTRACTION_MAX_GLEANINGS=1</span></pre><p id="2500" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It seems that it’s a recurring theme that not all structured information is extracted in a single pass. Hence, we have the gleaning configuration option here as well.</p><p id="7197" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">What’s also interesting, but I haven’t had time to dig deeper is the prompt tuning section. Prompt tuning is optional, but highly encouraged as it can improve accuracy.</p><div class="pa pb pc pd pe pf"><a href="https://microsoft.github.io/graphrag/posts/prompt_tuning/auto_prompt_tuning/?source=post_page-----e0d4fa00714c--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pg ab ig"><div class="ph ab co cb pi pj"><h2 class="bf fr hw z io pk iq ir pl it iv fp bk">Prompt Tuning ⚙️</h2><div class="pm l"><h3 class="bf b hw z io pk iq ir pl it iv dx">GraphRAG provides the ability to create domain adaptive templates for the generation of the knowledge graph. This step…</h3></div><div class="pn l"><p class="bf b dy z io pk iq ir pl it iv dx">microsoft.github.io</p></div></div></div></a></div><p id="a995" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After the configuration has been set, we can follow the <a class="af ny" href="https://microsoft.github.io/graphrag/posts/get_started/" rel="noopener ugc nofollow" target="_blank">instructions to run the graph extraction pipeline</a>, which consists of the following steps.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qh"><img src="../Images/58d946343c0b8c5ffbc8daef9b5b6a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/0*s-p5ysea5rpKN8Sf.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Steps in the pipeline — Image from the <a class="af ny" href="https://arxiv.org/abs/2404.16130" rel="noopener ugc nofollow" target="_blank">GraphRAG paper</a>, licensed under CC BY 4.0</figcaption></figure><p id="ac3c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The extraction pipeline executes all the blue steps in the above image. Review my <a class="af ny" href="https://medium.com/neo4j/implementing-from-local-to-global-graphrag-with-neo4j-and-langchain-constructing-the-graph-73924cc5bab4" rel="noopener">previous blog post</a> to learn more about graph construction and community summarization. The output of the graph extraction pipeline of the MSFT GraphRAG library is a set of parquet files, as shown in the <a class="af ny" href="https://github.com/microsoft/graphrag/tree/main/examples_notebooks/inputs/operation%20dulce" rel="noopener ugc nofollow" target="_blank">Operation Dulce example</a>.</p><p id="d017" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">These parquet files can be easily imported into the Neo4j graph database for downstream analysis, visualization, and retrieval. We can <a class="af ny" href="https://neo4j.com/docs/operations-manual/current/installation/" rel="noopener ugc nofollow" target="_blank">use a free cloud Aura instance or set up a local Neo4j environment</a>. My friend <span class="ia"><span class="ia" aria-hidden="false"><a class="qi ib qj" href="https://medium.com/u/3865848842f9?source=post_page---user_mention--e0d4fa00714c--------------------------------" rel="noopener" target="_blank">Michael Hunger</a></span></span> did most of the work to import the parquet files into Neo4j. We’ll skip the import explanation in this blog post, but it consists of importing and constructing a knowledge graph from five or six CSV files. If you want to learn more about CSV importing, you can check the <a class="af ny" href="https://graphacademy.neo4j.com/courses/importing-cypher/" rel="noopener ugc nofollow" target="_blank">Neo4j Graph Academy course</a>.</p><p id="d69f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The import code is available as a <a class="af ny" href="https://github.com/tomasonjo/blogs/blob/master/msft_graphrag/ms_graphrag_import.ipynb" rel="noopener ugc nofollow" target="_blank">Jupyter notebook on GitHub</a> along with the example GraphRAG output.</p><div class="pa pb pc pd pe pf"><a href="https://github.com/tomasonjo/blogs/blob/master/msft_graphrag/ms_graphrag_import.ipynb?source=post_page-----e0d4fa00714c--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pg ab ig"><div class="ph ab co cb pi pj"><h2 class="bf fr hw z io pk iq ir pl it iv fp bk">blogs/msft_graphrag/ms_graphrag_import.ipynb at master · tomasonjo/blogs</h2><div class="pm l"><h3 class="bf b hw z io pk iq ir pl it iv dx">Jupyter notebooks that support my graph data science blog posts at https://bratanic-tomaz.medium.com/ …</h3></div><div class="pn l"><p class="bf b dy z io pk iq ir pl it iv dx">github.com</p></div></div><div class="po l"><div class="qk l pq pr ps po pt lr pf"/></div></div></a></div><p id="df33" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After the import is completed, we can open the Neo4j Browser to validate and visualize parts of the imported graph.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ql"><img src="../Images/92899dd2b556af48c66fd7870c915e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-Ndb0YYvKAM7C7-5_vwag.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Part of the imported graph. Image by the author.</figcaption></figure><h2 id="ac51" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Graph analysis</h2><p id="c14b" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Before moving onto retriever implementation, we’ll perform a simple graph analysis to familiarize ourselves with the extracted data. We start by defining the database connection and a function that executes a Cypher statement (graph database query language) and outputs a Pandas DataFrame.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="01bf" class="py ob fq pv b bg pz qa l qb qc">NEO4J_URI="bolt://localhost"<br/>NEO4J_USERNAME="neo4j"<br/>NEO4J_PASSWORD="password"<br/><br/>driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))<br/><br/>def db_query(cypher: str, params: Dict[str, Any] = {}) -&gt; pd.DataFrame:<br/>    """Executes a Cypher statement and returns a DataFrame"""<br/>    return driver.execute_query(<br/>        cypher, parameters_=params, result_transformer_=Result.to_df<br/>    )</span></pre><p id="b45a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">When performing the graph extraction, we used a chunk size of 300. Since then, the authors have changed the default chunk size to 1200. We can validate the chunk sizes using the following Cypher statement.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="718b" class="py ob fq pv b bg pz qa l qb qc">db_query(<br/>  "MATCH (n:__Chunk__) RETURN n.n_tokens as token_count, count(*) AS count"<br/>)<br/># token_count count<br/># 300         230<br/># 155         1</span></pre><p id="52e1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">230 chunks have 300 tokens, while the last one has only 155 tokens. Let’s now check an example entity and its description.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="d982" class="py ob fq pv b bg pz qa l qb qc">db_query(<br/>  "MATCH (n:__Entity__) RETURN n.name AS name, n.description AS description LIMIT 1"<br/>)</span></pre><p id="602c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qm">Results</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qn"><img src="../Images/35f18f3cc25aac41a57272e234289a80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uDvk4pepLbOslaDn3OYfrg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example entity name and description. Image by author.</figcaption></figure><p id="b377" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It seems that the project Gutenberg is described in the book somewhere, probably at the beginning. We can observe how a description can capture more detailed and intricate information than just an entity name, which the MSFT GraphRAG paper introduced to retain more sophisticated and nuanced data from text.</p><p id="dbd3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s check example relationships as well.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="c53a" class="py ob fq pv b bg pz qa l qb qc">db_query(<br/>  "MATCH ()-[n:RELATED]-&gt;() RETURN n.description AS description LIMIT 5"<br/>)</span></pre><p id="41db" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qm">Results</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qo"><img src="../Images/6f893ad3537c258ca75ad42e7879b6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NNdUll-fDgSVjRCkNDGZyA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example relationship descriptions. Image by author.</figcaption></figure><p id="eb4c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The MSFT GraphRAG goes beyond merely extracting simple relationship types between entities by capturing detailed relationship descriptions. This capability allows it to capture more nuanced information than straightforward relationship types.</p><p id="d0b7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can also examine a single community and its generated descriptions.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="edc8" class="py ob fq pv b bg pz qa l qb qc">db_query("""<br/>  MATCH (n:__Community__) <br/>  RETURN n.title AS title, n.summary AS summary, n.full_content AS full_content LIMIT 1<br/>""")</span></pre><p id="dbab" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qm">Results</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qp"><img src="../Images/a91072cfd28f72bcf4f76e20c8929c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ybpRKOk_p3c7MJphtxrQZA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example community description. Image by author.</figcaption></figure><p id="2386" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A community has a title, summary, and full content generated using an LLM. I haven’t seen if the authors use the full context or just the summary during retrieval, but we can choose between the two. We can observe citations in the full_content, which point to entities and relationships from which the information came. It’s funny that an LLM sometimes trims the citations if they are too long, like in the following example.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="710e" class="py ob fq pv b bg pz qa l qb qc">[Data: Entities (11, 177); Relationships (25, 159, 20, 29, +more)]</span></pre><p id="f1ec" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There is no way to expand the <code class="cx qe qf qg pv b">+more</code> sign, so this is a funny way of dealing with long citations by an LLM.</p><p id="df31" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s now evaluate some distributions. We’ll start by inspecting the distribution of the count of extracted entities from text chunks.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="5381" class="py ob fq pv b bg pz qa l qb qc">entity_df = db_query(<br/>    """<br/>MATCH (d:__Chunk__)<br/>RETURN count {(d)-[:HAS_ENTITY]-&gt;()} AS entity_count<br/>"""<br/>)<br/># Plot distribution<br/>plt.figure(figsize=(10, 6))<br/>sns.histplot(entity_df['entity_count'], kde=True, bins=15, color='skyblue')<br/>plt.axvline(entity_df['entity_count'].mean(), color='red', linestyle='dashed', linewidth=1)<br/>plt.axvline(entity_df['entity_count'].median(), color='green', linestyle='dashed', linewidth=1)<br/>plt.xlabel('Entity Count', fontsize=12)<br/>plt.ylabel('Frequency', fontsize=12)<br/>plt.title('Distribution of Entity Count', fontsize=15)<br/>plt.legend({'Mean': entity_df['entity_count'].mean(), 'Median': entity_df['entity_count'].median()})<br/>plt.show()</span></pre><p id="adaa" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qm">Results</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qq"><img src="../Images/31d7f4dc8a8dd0eb2cced392fb6494e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nSB_1gLktxuTKV1ikox5dQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of the count of extracted entities from text chunks. Image by author.</figcaption></figure><p id="ed13" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Remember, text chunks have 300 tokens. Therefore, the number of extracted entities is relatively small, with an average of around three entities per text chunk. The extraction was done without any gleanings (a single extraction pass). It would be interesting to see the distribution if we increased the gleaning count.</p><p id="8d97" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, we will evaluate the node degree distribution. A node degree is the number of relationships a node has.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="fb31" class="py ob fq pv b bg pz qa l qb qc">degree_dist_df = db_query(<br/>    """<br/>MATCH (e:__Entity__)<br/>RETURN count {(e)-[:RELATED]-()} AS node_degree<br/>"""<br/>)<br/># Calculate mean and median<br/>mean_degree = np.mean(degree_dist_df['node_degree'])<br/>percentiles = np.percentile(degree_dist_df['node_degree'], [25, 50, 75, 90])<br/># Create a histogram with a logarithmic scale<br/>plt.figure(figsize=(12, 6))<br/>sns.histplot(degree_dist_df['node_degree'], bins=50, kde=False, color='blue')<br/># Use a logarithmic scale for the x-axis<br/>plt.yscale('log')<br/># Adding labels and title<br/>plt.xlabel('Node Degree')<br/>plt.ylabel('Count (log scale)')<br/>plt.title('Node Degree Distribution')<br/># Add mean, median, and percentile lines<br/>plt.axvline(mean_degree, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_degree:.2f}')<br/>plt.axvline(percentiles[0], color='purple', linestyle='dashed', linewidth=1, label=f'25th Percentile: {percentiles[0]:.2f}')<br/>plt.axvline(percentiles[1], color='orange', linestyle='dashed', linewidth=1, label=f'50th Percentile: {percentiles[1]:.2f}')<br/>plt.axvline(percentiles[2], color='yellow', linestyle='dashed', linewidth=1, label=f'75th Percentile: {percentiles[2]:.2f}')<br/>plt.axvline(percentiles[3], color='brown', linestyle='dashed', linewidth=1, label=f'90th Percentile: {percentiles[3]:.2f}')<br/># Add legend<br/>plt.legend()<br/># Show the plot<br/>plt.show()</span></pre><p id="bbe5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qm">Results</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/202d970f10bd278b5aee8974cf48ae0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MyQ4LO2NXM4JXJmRFhQCoQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Node degree distribution. Image by author.</figcaption></figure><p id="66ed" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Most real-world networks follow a power-law node degree distribution, with most nodes having relatively small degrees and some important nodes having a lot. While our graph is small, the node degree follows the power law. It would be interesting to identify which entity has 120 relationships (connected to 43% of entities).</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="76d8" class="py ob fq pv b bg pz qa l qb qc">db_query("""<br/>  MATCH (n:__Entity__) <br/>  RETURN n.name AS name, count{(n)-[:RELATED]-()} AS degree<br/>  ORDER BY degree DESC LIMIT 5""")</span></pre><p id="e1e1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qm">Results</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qs"><img src="../Images/68f4527199ac6daafeca1cc648fb7fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*-d41s1gEKy03Vk9DDbkVAQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Entities with the most relationships. Image by author.</figcaption></figure><p id="488d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Without any hesitation, we can assume that Scrooge is the book’s main character. I would also venture a guess that <strong class="ne fr">Ebenezer Scrooge</strong> and <strong class="ne fr">Scrooge</strong> are actually the same entity, but as the MSFT GraphRAG lacks an entity resolution step, they weren’t merged.</p><p id="20ac" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It also shows that analyzing and cleaning the data is a vital step to reducing noise information, as Project Gutenberg has 13 relationships, even though they are not part of the book story.</p><p id="6dce" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Lastly, we’ll inspect the distribution of community size per hierarchical level.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="04b0" class="py ob fq pv b bg pz qa l qb qc">community_data = db_query("""<br/>  MATCH (n:__Community__)<br/>  RETURN n.level AS level, count{(n)-[:IN_COMMUNITY]-()} AS members<br/>""")<br/><br/>stats = community_data.groupby('level').agg(<br/>    min_members=('members', 'min'),<br/>    max_members=('members', 'max'),<br/>    median_members=('members', 'median'),<br/>    avg_members=('members', 'mean'),<br/>    num_communities=('members', 'count'),<br/>    total_members=('members', 'sum')<br/>).reset_index()<br/><br/># Create box plot<br/>plt.figure(figsize=(10, 6))<br/>sns.boxplot(x='level', y='members', data=community_data, palette='viridis')<br/>plt.xlabel('Level')<br/>plt.ylabel('Members')<br/><br/># Add statistical annotations<br/>for i in range(stats.shape[0]):<br/>    level = stats['level'][i]<br/>    max_val = stats['max_members'][i]<br/>    text = (f"num: {stats['num_communities'][i]}\n"<br/>            f"all_members: {stats['total_members'][i]}\n"<br/>            f"min: {stats['min_members'][i]}\n"<br/>            f"max: {stats['max_members'][i]}\n"<br/>            f"med: {stats['median_members'][i]}\n"<br/>            f"avg: {stats['avg_members'][i]:.2f}")<br/>    plt.text(level, 85, text, horizontalalignment='center', fontsize=9)<br/><br/>plt.show()</span></pre><p id="dc05" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qm">Results</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qt"><img src="../Images/2eba2f21b06f75caa3302f3a3ce41067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dTnb8hpjCw8vuoxgzPm8EQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Community size distribution per level. Image by author.</figcaption></figure><p id="6cb0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The Leiden algorithm identified three levels of communities, where the communities on higher levels are larger on average. However, there are some technical details that I’m not aware of because if you check the all_members count, and you can see that each level has a different number of all nodes, even though they should be the same in theory. Also, if communities merge at higher levels, why do we have 19 communities on level 0 and 22 on level 1? The authors have done some optimizations and tricks here, which I haven’t had a time to explore in detail yet.</p><h1 id="c1e0" class="qu ob fq bf oc qv qw gq og qx qy gt ok qz ra rb rc rd re rf rg rh ri rj rk rl bk">Implementing retrievers</h1><p id="3515" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">In the last part of this blog post, we will discuss the local and global retrievers as specified in the MSFT GraphRAG. The retrievers will be implemented and integrated with LangChain and LlamaIndex.</p><h2 id="6755" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Local retriever</h2><p id="1ab0" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">The local retriever starts by using vector search to identify relevant nodes, and then collects linked information and injects it into the LLM prompt.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rm"><img src="../Images/3526b6401fd23d76effcaf0a4022a12c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lInV6WWTDXYEVI1NS3KV9g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Local retriever architecture. Image from <a class="af ny" href="https://microsoft.github.io/graphrag/posts/query/1-local_search/" rel="noopener ugc nofollow" target="_blank">https://microsoft.github.io/graphrag/posts/query/1-local_search/</a></figcaption></figure><p id="c8ca" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">While this diagram might look complex, it can be easily implemented. We start by identifying relevant entities using a vector similarity search based on text embeddings of entity descriptions. Once the relevant entities are identified, we can traverse to related text chunks, relationships, community summaries, and so on. The pattern of using vector similarity search and then traversing throughout the graph can easily be implemented using a <code class="cx qe qf qg pv b">retrieval_query</code> feature in both LangChain and LlamaIndex.</p><p id="b716" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First, we need to configure the vector index.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="cc1b" class="py ob fq pv b bg pz qa l qb qc">index_name = "entity"<br/><br/>db_query(<br/>    """<br/>CREATE VECTOR INDEX """<br/>    + index_name<br/>    + """ IF NOT EXISTS FOR (e:__Entity__) ON e.description_embedding<br/>OPTIONS {indexConfig: {<br/> `vector.dimensions`: 1536,<br/> `vector.similarity_function`: 'cosine'<br/>}}<br/>"""<br/>)</span></pre><p id="617f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We’ll also calculate and store the community weight, which is defined as the number of distinct text chunks the entities in the community appear.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="1d07" class="py ob fq pv b bg pz qa l qb qc">db_query(<br/>    """<br/>MATCH (n:`__Community__`)&lt;-[:IN_COMMUNITY]-()&lt;-[:HAS_ENTITY]-(c)<br/>WITH n, count(distinct c) AS chunkCount<br/>SET n.weight = chunkCount"""<br/>)</span></pre><p id="b088" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The number of candidates (text units, community reports, …) from each section is <a class="af ny" href="https://microsoft.github.io/graphrag/posts/query/notebooks/local_search_nb/" rel="noopener ugc nofollow" target="_blank">configurable</a>. While the original implementation has slightly more involved filtering based on token counts, we’ll simplify it here. I developed the following simplified top candidate filter values based on the default configuration values.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="9761" class="py ob fq pv b bg pz qa l qb qc">topChunks = 3<br/>topCommunities = 3<br/>topOutsideRels = 10<br/>topInsideRels = 10<br/>topEntities = 10</span></pre><p id="f6e1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We will start with LangChain implementation. The only thing we need to define is the <code class="cx qe qf qg pv b">retrieval_query</code> , which is more involved.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="8a1b" class="py ob fq pv b bg pz qa l qb qc">lc_retrieval_query = """<br/>WITH collect(node) as nodes<br/>// Entity - Text Unit Mapping<br/>WITH<br/>collect {<br/>    UNWIND nodes as n<br/>    MATCH (n)&lt;-[:HAS_ENTITY]-&gt;(c:__Chunk__)<br/>    WITH c, count(distinct n) as freq<br/>    RETURN c.text AS chunkText<br/>    ORDER BY freq DESC<br/>    LIMIT $topChunks<br/>} AS text_mapping,<br/>// Entity - Report Mapping<br/>collect {<br/>    UNWIND nodes as n<br/>    MATCH (n)-[:IN_COMMUNITY]-&gt;(c:__Community__)<br/>    WITH c, c.rank as rank, c.weight AS weight<br/>    RETURN c.summary <br/>    ORDER BY rank, weight DESC<br/>    LIMIT $topCommunities<br/>} AS report_mapping,<br/>// Outside Relationships <br/>collect {<br/>    UNWIND nodes as n<br/>    MATCH (n)-[r:RELATED]-(m) <br/>    WHERE NOT m IN nodes<br/>    RETURN r.description AS descriptionText<br/>    ORDER BY r.rank, r.weight DESC <br/>    LIMIT $topOutsideRels<br/>} as outsideRels,<br/>// Inside Relationships <br/>collect {<br/>    UNWIND nodes as n<br/>    MATCH (n)-[r:RELATED]-(m) <br/>    WHERE m IN nodes<br/>    RETURN r.description AS descriptionText<br/>    ORDER BY r.rank, r.weight DESC <br/>    LIMIT $topInsideRels<br/>} as insideRels,<br/>// Entities description<br/>collect {<br/>    UNWIND nodes as n<br/>    RETURN n.description AS descriptionText<br/>} as entities<br/>// We don't have covariates or claims here<br/>RETURN {Chunks: text_mapping, Reports: report_mapping, <br/>       Relationships: outsideRels + insideRels, <br/>       Entities: entities} AS text, 1.0 AS score, {} AS metadata<br/>"""<br/><br/>lc_vector = Neo4jVector.from_existing_index(<br/>    OpenAIEmbeddings(model="text-embedding-3-small"),<br/>    url=NEO4J_URI,<br/>    username=NEO4J_USERNAME,<br/>    password=NEO4J_PASSWORD,<br/>    index_name=index_name,<br/>    retrieval_query=lc_retrieval_query<br/>)</span></pre><p id="ec9f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This Cypher query performs multiple analytical operations on a set of nodes to extract and organize related text data:</p><p id="ef13" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">1. <strong class="ne fr">Entity-Text Unit Mapping</strong>: For each node, the query identifies linked text chunks (`__Chunk__`), aggregates them by the number of distinct nodes associated with each chunk, and orders them by frequency. The top chunks are returned as `text_mapping`.</p><p id="18f5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">2. <strong class="ne fr">Entity-Report Mapping</strong>: For each node, the query finds the associated community (`__Community__`), and returns the summary of the top-ranked communities based on rank and weight.</p><p id="62e8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">3. <strong class="ne fr">Outside Relationships</strong>: This section extracts descriptions of relationships (`RELATED`) where the related entity (`m`) is not part of the initial node set. The relationships are ranked and limited to the top external relationships.</p><p id="b7b6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">4. <strong class="ne fr">Inside Relationships</strong>: Similarly to outside relationships, but this time it considers only relationships where both entities are within the initial set of nodes.</p><p id="557c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">5. <strong class="ne fr">Entities Description</strong>: Simply collects descriptions of each node in the initial set.</p><p id="4a6d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Finally, the query combines the collected data into a structured result comprising of chunks, reports, internal and external relationships, and entity descriptions, along with a default score and an empty metadata object. You have the option to remove some of the retrieval parts to test how they affect the results.</p><p id="7a35" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And now you can run the retriever using the following code:</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="51d3" class="py ob fq pv b bg pz qa l qb qc">docs = lc_vector.similarity_search(<br/>    "What do you know about Cratchitt family?",<br/>    k=topEntities,<br/>    params={<br/>        "topChunks": topChunks,<br/>        "topCommunities": topCommunities,<br/>        "topOutsideRels": topOutsideRels,<br/>        "topInsideRels": topInsideRels,<br/>    },<br/>)<br/># print(docs[0].page_content)</span></pre><p id="3829" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The same retrieval pattern can be implemented with LlamaIndex. For LlamaIndex, we first need to add metadata to nodes so that the vector index will work. <em class="qm">If the default metadata is not added to the relevant nodes, the vector index will return an error</em>.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="aa9f" class="py ob fq pv b bg pz qa l qb qc"># https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/vector_stores/utils.py#L32<br/>from llama_index.core.schema import TextNode<br/>from llama_index.core.vector_stores.utils import node_to_metadata_dict<br/><br/>content = node_to_metadata_dict(TextNode(), remove_text=True, flat_metadata=False)<br/><br/>db_query(<br/>    """<br/>  MATCH (e:__Entity__)<br/>  SET e += $content""",<br/>    {"content": content},<br/>)</span></pre><p id="edde" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Again, we can use the <code class="cx qe qf qg pv b">retrieval_query</code> feature in LlamaIndex to define the retriever. Unlike with LangChain, we will use the f-string instead of query parameters to pass the top candidate filter parameters.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="4a03" class="py ob fq pv b bg pz qa l qb qc">retrieval_query = f"""<br/>WITH collect(node) as nodes<br/>// Entity - Text Unit Mapping<br/>WITH<br/>nodes,<br/>collect {{<br/>    UNWIND nodes as n<br/>    MATCH (n)&lt;-[:HAS_ENTITY]-&gt;(c:__Chunk__)<br/>    WITH c, count(distinct n) as freq<br/>    RETURN c.text AS chunkText<br/>    ORDER BY freq DESC<br/>    LIMIT {topChunks}<br/>}} AS text_mapping,<br/>// Entity - Report Mapping<br/>collect {{<br/>    UNWIND nodes as n<br/>    MATCH (n)-[:IN_COMMUNITY]-&gt;(c:__Community__)<br/>    WITH c, c.rank as rank, c.weight AS weight<br/>    RETURN c.summary <br/>    ORDER BY rank, weight DESC<br/>    LIMIT {topCommunities}<br/>}} AS report_mapping,<br/>// Outside Relationships <br/>collect {{<br/>    UNWIND nodes as n<br/>    MATCH (n)-[r:RELATED]-(m) <br/>    WHERE NOT m IN nodes<br/>    RETURN r.description AS descriptionText<br/>    ORDER BY r.rank, r.weight DESC <br/>    LIMIT {topOutsideRels}<br/>}} as outsideRels,<br/>// Inside Relationships <br/>collect {{<br/>    UNWIND nodes as n<br/>    MATCH (n)-[r:RELATED]-(m) <br/>    WHERE m IN nodes<br/>    RETURN r.description AS descriptionText<br/>    ORDER BY r.rank, r.weight DESC <br/>    LIMIT {topInsideRels}<br/>}} as insideRels,<br/>// Entities description<br/>collect {{<br/>    UNWIND nodes as n<br/>    RETURN n.description AS descriptionText<br/>}} as entities<br/>// We don't have covariates or claims here<br/>RETURN "Chunks:" + apoc.text.join(text_mapping, '|') + "\nReports: " + apoc.text.join(report_mapping,'|') +  <br/>       "\nRelationships: " + apoc.text.join(outsideRels + insideRels, '|') + <br/>       "\nEntities: " + apoc.text.join(entities, "|") AS text, 1.0 AS score, nodes[0].id AS id, {{_node_type:nodes[0]._node_type, _node_content:nodes[0]._node_content}} AS metadata<br/>"""</span></pre><p id="1a1f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Additionally, the return is slightly different. We need to return the node type and content as metadata; otherwise, the retriever will break. Now we just instantiate the Neo4j vector store and use it as a query engine.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="578f" class="py ob fq pv b bg pz qa l qb qc">neo4j_vector = Neo4jVectorStore(<br/>    NEO4J_USERNAME,<br/>    NEO4J_PASSWORD,<br/>    NEO4J_URI,<br/>    embed_dim,<br/>    index_name=index_name,<br/>    retrieval_query=retrieval_query,<br/>)<br/>loaded_index = VectorStoreIndex.from_vector_store(neo4j_vector).as_query_engine(<br/>    similarity_top_k=topEntities, embed_model=OpenAIEmbedding(model="text-embedding-3-large")<br/>)</span></pre><p id="39f4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can now test the GraphRAG local retriever.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="b58a" class="py ob fq pv b bg pz qa l qb qc">response = loaded_index.query("What do you know about Scrooge?")<br/>print(response.response)<br/>#print(response.source_nodes[0].text)<br/># Scrooge is an employee who is impacted by the generosity and festive spirit <br/># of the Fezziwig family, particularly Mr. and Mrs. Fezziwig. He is involved <br/># in the memorable Domestic Ball hosted by the Fezziwigs, which significantly <br/># influences his life and contributes to the broader narrative of kindness <br/># and community spirit.</span></pre><p id="52e9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">One thing that immediately sparks to mind is that we can improve the local retrieval by using a hybrid approach (vector + keyword) to find relevant entities instead of vector search only.</p><h2 id="cc55" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Global retriever</h2><p id="1855" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">The <a class="af ny" href="https://microsoft.github.io/graphrag/posts/query/notebooks/global_search_nb/" rel="noopener ugc nofollow" target="_blank">global retriever architecture</a> is slightly more straightforward. It seems to iterate over all the community summaries on a specified hierarchical level, producing intermediate summaries and then generating a final response based on the intermediate summaries.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rn"><img src="../Images/69405ee5c3fd2d9bedc89f5b463fb816.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mcDNDMTmCqVAUv1SnzTtzA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Global retriever architecture. Image from <a class="af ny" href="https://microsoft.github.io/graphrag/posts/query/0-global_search/" rel="noopener ugc nofollow" target="_blank">https://microsoft.github.io/graphrag/posts/query/0-global_search/</a></figcaption></figure><p id="e905" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We have to decide which define in advance which hierarchical level we want to iterate over, which is a not a simple decision as we have no idea which one would work better. The higher up you go the hierarchical level, the larger the communities get, but there are fewer of them. This is the only information we have without inspecting summaries manually.</p><p id="f180" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Other parameters allow us to ignore communities below a rank or weight threshold, which we won’t use here. We’ll implement the global retriever using LangChain as use the same <a class="af ny" href="https://github.com/microsoft/graphrag/blob/main/graphrag/query/structured_search/global_search/map_system_prompt.py" rel="noopener ugc nofollow" target="_blank">map</a> and <a class="af ny" href="https://github.com/microsoft/graphrag/blob/main/graphrag/query/structured_search/global_search/reduce_system_prompt.py" rel="noopener ugc nofollow" target="_blank">reduce prompts</a> as in the GraphRAG paper. Since the system prompts are very long, we will not include them here or the chain construction. However, all the code is available in the <a class="af ny" href="https://github.com/tomasonjo/blogs/blob/master/msft_graphrag/ms_graphrag_retriever.ipynb" rel="noopener ugc nofollow" target="_blank">notebook</a>.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="c305" class="py ob fq pv b bg pz qa l qb qc">def global_retriever(query: str, level: int, response_type: str = response_type) -&gt; str:<br/>    community_data = graph.query(<br/>        """<br/>    MATCH (c:__Community__)<br/>    WHERE c.level = $level<br/>    RETURN c.full_content AS output<br/>    """,<br/>        params={"level": level},<br/>    )<br/>    intermediate_results = []<br/>    for community in tqdm(community_data, desc="Processing communities"):<br/>        intermediate_response = map_chain.invoke(<br/>            {"question": query, "context_data": community["output"]}<br/>        )<br/>        intermediate_results.append(intermediate_response)<br/>    final_response = reduce_chain.invoke(<br/>        {<br/>            "report_data": intermediate_results,<br/>            "question": query,<br/>            "response_type": response_type,<br/>        }<br/>    )<br/>    return final_response</span></pre><p id="6f9b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s now test it.</p><pre class="mm mn mo mp mq pu pv pw bp px bb bk"><span id="952d" class="py ob fq pv b bg pz qa l qb qc">print(global_retriever("What is the story about?", 2))</span></pre><p id="baa5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="qm">Results</em></p><blockquote class="ro rp rq"><p id="b1be" class="nc nd qm ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The story primarily revolves around Ebenezer Scrooge, a miserly man who initially embodies a cynical outlook towards life and despises Christmas. His transformation begins when he is visited by the ghost of his deceased business partner, Jacob Marley, followed by the appearances of three spirits—representing Christmas Past, Present, and Yet to Come. These encounters prompt Scrooge to reflect on his life and the consequences of his actions, ultimately leading him to embrace the Christmas spirit and undergo significant personal growth [Data: Reports (32, 17, 99, 86, +more)].<br/><br/>### The Role of Jacob Marley and the Spirits<br/><br/>Jacob Marley's ghost serves as a supernatural catalyst, warning Scrooge about the forthcoming visitations from the three spirits. Each spirit guides Scrooge through a journey of self-discovery, illustrating the impact of his choices and the importance of compassion. The spirits reveal to Scrooge how his actions have affected not only his own life but also the lives of others, particularly highlighting the themes of redemption and interconnectedness [Data: Reports (86, 17, 99, +more)].<br/><br/>### Scrooge's Relationships and Transformation<br/><br/>Scrooge's relationship with the Cratchit family, especially Bob Cratchit and his son Tiny Tim, is pivotal to his transformation. Through the visions presented by the spirits, Scrooge develops empathy, which inspires him to take tangible actions that improve the Cratchit family's circumstances. The narrative emphasizes that individual actions can have a profound impact on society, as Scrooge's newfound generosity fosters compassion and social responsibility within his community [Data: Reports (25, 158, 159, +more)].<br/><br/>### Themes of Redemption and Hope<br/><br/>Overall, the story is a timeless symbol of hope, underscoring themes such as empathy, introspection, and the potential for personal change. Scrooge's journey from a lonely miser to a benevolent figure illustrates that it is never too late to change; small acts of kindness can lead to significant positive effects on individuals and the broader community [Data: Reports (32, 102, 126, 148, 158, 159, +more)]. <br/><br/>In summary, the story encapsulates the transformative power of Christmas and the importance of human connections, making it a poignant narrative about redemption and the impact one individual can have on others during the holiday season.</p></blockquote><p id="a19b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The response is quite long and exhaustive as it fits a global retriever that iterates over all the communities on a specified level. You can test how the response changes if you change the community hierarchical level.</p><h2 id="656b" class="oa ob fq bf oc od oe of og oh oi oj ok nl ol om on np oo op oq nt or os ot ou bk">Summary</h2><p id="36c4" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">In this blog post we demonstrated how to integrate Microsoft’s GraphRAG into Neo4j and implement retrievers using LangChain and LlamaIndex. This should allows you to integrate GraphRAG with other retrievers or agents seamlessly. The local retriever combines vector similarity search with graph traversal, while the global retriever iterates over community summaries to generate comprehensive responses. This implementation showcases the power of combining structured knowledge graphs with language models for enhanced information retrieval and question answering. It’s important to note that there is room for customization and experimentation with such a knowledge graph, which we will look into in the next blog post.</p><p id="5186" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As always, the code is available on <a class="af ny" href="https://github.com/tomasonjo/blogs/tree/master/msft_graphrag" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p></div></div></div></div>    
</body>
</html>