- en: Towards Mamba State Space Models for Images, Videos and Time Series
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœç€ Mamba çŠ¶æ€ç©ºé—´æ¨¡å‹è¿ˆè¿›ï¼šå›¾åƒã€è§†é¢‘å’Œæ—¶é—´åºåˆ—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?source=collection_archive---------2-----------------------#2024-08-14](https://towardsdatascience.com/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?source=collection_archive---------2-----------------------#2024-08-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?source=collection_archive---------2-----------------------#2024-08-14](https://towardsdatascience.com/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?source=collection_archive---------2-----------------------#2024-08-14)
- en: '[ğŸ Towards Mamba State Space Models for Images, Videos and Time Series](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[ğŸ æœç€ Mamba çŠ¶æ€ç©ºé—´æ¨¡å‹è¿ˆè¿›ï¼šå›¾åƒã€è§†é¢‘å’Œæ—¶é—´åºåˆ—](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
- en: Part 1
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬1éƒ¨åˆ†
- en: '[](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)
    Â·16 min readÂ·Aug 14, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)
    Â·16åˆ†é’Ÿé˜…è¯»Â·2024å¹´8æœˆ14æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8e699ad3e8e2b18d79f099a7d89788ac.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e699ad3e8e2b18d79f099a7d89788ac.png)'
- en: Image by [Sascha Kirch](https://medium.com/@SaschaKirch)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Sascha Kirch](https://medium.com/@SaschaKirch) æä¾›
- en: This is part 1 of my new multi-part series [ğŸ Towards Mamba State Space Models
    for Images, Videos and Time Series](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb).
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘æ–°ç³»åˆ—çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œ[ğŸ æœç€ Mamba çŠ¶æ€ç©ºé—´æ¨¡å‹è¿ˆè¿›ï¼šå›¾åƒã€è§†é¢‘å’Œæ—¶é—´åºåˆ—](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb)ã€‚
- en: Is Mamba all you need? Certainly, people have thought that for a long time of
    the Transformer architecture introduced by A. Vaswani et. al. in [Attention is
    all you need](https://arxiv.org/abs/1706.03762) back in 2017\. And without any
    doubt, the transformer has revolutionized the field of deep learning over and
    over again. Its general-purpose architecture can easily be adapted for various
    data modalities such as text, images, videos and time series and it seems that
    the more compute resources and data you throw at the Transformer, the more performant
    it becomes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Mamba æ˜¯ä½ æ‰€éœ€çš„ä¸€åˆ‡å—ï¼Ÿå½“ç„¶ï¼Œé•¿æœŸä»¥æ¥äººä»¬ä¸€ç›´è®¤ä¸º A. Vaswani ç­‰äººåœ¨ 2017 å¹´æå‡ºçš„ [Attention is all you
    need](https://arxiv.org/abs/1706.03762) ä¸­çš„ Transformer æ¶æ„å°±æ˜¯å¦‚æ­¤ã€‚æ¯«æ— ç–‘é—®ï¼ŒTransformer
    ä¸€æ¬¡åˆä¸€æ¬¡åœ°å½»åº•æ”¹å˜äº†æ·±åº¦å­¦ä¹ é¢†åŸŸã€‚å®ƒçš„é€šç”¨æ¶æ„å¯ä»¥è½»æ¾é€‚åº”å¤šç§æ•°æ®æ¨¡å¼ï¼Œå¦‚æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’Œæ—¶é—´åºåˆ—ï¼Œè€Œä¸”ä¼¼ä¹ä½ å‘ Transformer æŠ•å…¥çš„è®¡ç®—èµ„æºå’Œæ•°æ®è¶Šå¤šï¼Œå®ƒçš„æ€§èƒ½å°±è¶Šå¼ºã€‚
- en: 'However, the Transformerâ€™s attention mechanism has a major drawback: it is
    of complexity *O(NÂ²)*, meaning it scales quadratically with the sequence length.
    This implies the larger the input sequence, the more compute resources you need,
    making large sequences often unfeasible to work with.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼ŒTransformer çš„æ³¨æ„åŠ›æœºåˆ¶æœ‰ä¸€ä¸ªä¸»è¦çš„ç¼ºç‚¹ï¼šå®ƒçš„å¤æ‚åº¦æ˜¯ *O(NÂ²)*ï¼Œè¿™æ„å‘³ç€å®ƒéšç€åºåˆ—é•¿åº¦çš„å¢åŠ è€Œå‘ˆäºŒæ¬¡æ–¹å¢é•¿ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¾“å…¥åºåˆ—è¶Šå¤§ï¼Œä½ éœ€è¦çš„è®¡ç®—èµ„æºå°±è¶Šå¤šï¼Œè¿™ä½¿å¾—å¤„ç†å¤§åºåˆ—å¾€å¾€å˜å¾—ä¸å¯è¡Œã€‚
- en: 'â“ The question is: can we do better? Is there a way we can reduce the *O(NÂ²)*
    complexity while still being performant? And what would this new architecture
    look like?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: â“ é—®é¢˜æ˜¯ï¼šæˆ‘ä»¬èƒ½åšå¾—æ›´å¥½å—ï¼Ÿæ˜¯å¦æœ‰åŠæ³•åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å‡å°‘ *O(NÂ²)* å¤æ‚åº¦ï¼Ÿé‚£ä¹ˆè¿™ç§æ–°æ¶æ„ä¼šæ˜¯ä»€ä¹ˆæ ·å­çš„å‘¢ï¼Ÿ
