- en: Towards Mamba State Space Models for Images, Videos and Time Series
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朝着 Mamba 状态空间模型迈进：图像、视频和时间序列
- en: 原文：[https://towardsdatascience.com/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?source=collection_archive---------2-----------------------#2024-08-14](https://towardsdatascience.com/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?source=collection_archive---------2-----------------------#2024-08-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?source=collection_archive---------2-----------------------#2024-08-14](https://towardsdatascience.com/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?source=collection_archive---------2-----------------------#2024-08-14)
- en: '[🐍 Towards Mamba State Space Models for Images, Videos and Time Series](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[🐍 朝着 Mamba 状态空间模型迈进：图像、视频和时间序列](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
- en: Part 1
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1部分
- en: '[](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--1e0bfdb5933a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)
    ·16 min read·Aug 14, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1e0bfdb5933a--------------------------------)
    ·16分钟阅读·2024年8月14日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8e699ad3e8e2b18d79f099a7d89788ac.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e699ad3e8e2b18d79f099a7d89788ac.png)'
- en: Image by [Sascha Kirch](https://medium.com/@SaschaKirch)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Sascha Kirch](https://medium.com/@SaschaKirch) 提供
- en: This is part 1 of my new multi-part series [🐍 Towards Mamba State Space Models
    for Images, Videos and Time Series](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb).
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是我新系列的第一部分，[🐍 朝着 Mamba 状态空间模型迈进：图像、视频和时间序列](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb)。
- en: Is Mamba all you need? Certainly, people have thought that for a long time of
    the Transformer architecture introduced by A. Vaswani et. al. in [Attention is
    all you need](https://arxiv.org/abs/1706.03762) back in 2017\. And without any
    doubt, the transformer has revolutionized the field of deep learning over and
    over again. Its general-purpose architecture can easily be adapted for various
    data modalities such as text, images, videos and time series and it seems that
    the more compute resources and data you throw at the Transformer, the more performant
    it becomes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Mamba 是你所需的一切吗？当然，长期以来人们一直认为 A. Vaswani 等人在 2017 年提出的 [Attention is all you
    need](https://arxiv.org/abs/1706.03762) 中的 Transformer 架构就是如此。毫无疑问，Transformer
    一次又一次地彻底改变了深度学习领域。它的通用架构可以轻松适应多种数据模式，如文本、图像、视频和时间序列，而且似乎你向 Transformer 投入的计算资源和数据越多，它的性能就越强。
- en: 'However, the Transformer’s attention mechanism has a major drawback: it is
    of complexity *O(N²)*, meaning it scales quadratically with the sequence length.
    This implies the larger the input sequence, the more compute resources you need,
    making large sequences often unfeasible to work with.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Transformer 的注意力机制有一个主要的缺点：它的复杂度是 *O(N²)*，这意味着它随着序列长度的增加而呈二次方增长。也就是说，输入序列越大，你需要的计算资源就越多，这使得处理大序列往往变得不可行。
- en: '❓ The question is: can we do better? Is there a way we can reduce the *O(N²)*
    complexity while still being performant? And what would this new architecture
    look like?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ❓ 问题是：我们能做得更好吗？是否有办法在保持性能的同时减少 *O(N²)* 复杂度？那么这种新架构会是什么样子的呢？
