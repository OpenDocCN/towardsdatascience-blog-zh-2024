# 使用GNNs进行符号化钢琴音乐中的声部与五线谱分离

> 原文：[https://towardsdatascience.com/voice-and-staff-separation-in-symbolic-piano-music-with-gnns-0cab100629cf?source=collection_archive---------2-----------------------#2024-10-27](https://towardsdatascience.com/voice-and-staff-separation-in-symbolic-piano-music-with-gnns-0cab100629cf?source=collection_archive---------2-----------------------#2024-10-27)

## 本文涵盖了我最近发表的论文***《集群与分离：基于GNN的乐谱雕刻中的声部与五线谱预测方法》***，该论文发表于ISMIR 2024。

[](https://manoskary.medium.com/?source=post_page---byline--0cab100629cf--------------------------------)[![Emmanouil Karystinaios](../Images/120d889f330aa7b433a0668a1224e1c8.png)](https://manoskary.medium.com/?source=post_page---byline--0cab100629cf--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0cab100629cf--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0cab100629cf--------------------------------) [Emmanouil Karystinaios](https://manoskary.medium.com/?source=post_page---byline--0cab100629cf--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0cab100629cf--------------------------------) ·9分钟阅读·2024年10月27日

--

![](../Images/35cb15f4617539ec42c48e0308c27ab2.png)

背景图像最初由Dall-E 3创建

# 介绍

用MIDI等格式编码的音乐，即使包含了量化的音符、节拍签名或小节信息，通常也缺少一些用于可视化的重要元素，比如声部和五线谱信息。这一限制同样适用于音乐生成、转录或编排系统的输出。因此，这种音乐无法轻松地转化为人类音乐家可以解读和演奏的可读乐谱。

值得注意的是，声部和五线谱分离只是乐谱雕刻系统可能需要解决的众多问题中的两个——其他问题还包括音高拼写、节奏分组和连音符创建等。

在音乐术语中，“声部”通常指的是一系列不重叠的音符，通常称为单声部。然而，当处理多声部乐器时，这一定义就显得不足。例如，声部也可以包括和弦，和弦是同时演奏的音符组，通常被视为一个整体。在这种情况下，我们将能够包含和弦的声部称为和声部。

# 问题

将量化的符号化音乐作品（例如MIDI文件）中的音符分离为多个声部和五线谱是一个重要且非平凡的任务。它是音乐乐谱雕刻（或乐谱排版）这一更大任务的基本部分，旨在为人类演奏者制作可读的乐谱。

乐谱是音乐家的一项重要工具，因为它能够以紧凑的图形形式传达音乐信息。与其他可能对机器来说更易定义和处理的音乐表示方式（如MIDI文件）相比，乐谱的特点在于训练有素的音乐家能够高效地读取它。

![](../Images/2c25e1bd58f924668aa559a33335a7e0.png)

给定一个量化的MIDI，有许多将其转换为可读格式的可能性，这通常包括将音符分配到不同的声音和五线谱中。

下面展示了其中两种可能性。它们展示了刻印系统通常是如何工作的。

![](../Images/49ba13108dc736eaf1b733000412a3bc.png)

大问题是，我们如何能让自动转录模型变得更好。

# 动机

为了开发一个更有效的系统，用于将音乐音符分离为声音和五线谱，特别是对于复杂的钢琴音乐，我们需要从不同的角度重新思考这个问题。我们的目标是改善从量化MIDI开始的转录音乐的可读性，这对于制作良好的乐谱刻印和提高音乐家表演效果至关重要。

对于良好的乐谱可读性，可能最重要的两个元素是：

+   五线谱的分离，将音符组织在上下五线谱之间；

+   和声音的分离，通过不同颜色的线条在这张图片中突显出来。

![](../Images/84fcb2362072c70b0251752ed7d2c4e2.png)

钢琴谱中的声音流

在钢琴谱中，如前所述，声音不是严格的单旋律，而是和声，这意味着单一的声音可以包含一个或多个同时演奏的音符。从现在开始，我们称这些为和弦。你可以在上面图片的底部五线谱中看到一些用紫色标出的和弦示例。

从**机器学习的角度**来看，我们需要解决两个任务：

+   第一个是**五线谱分离**，这是直接的，我们只需要为每个音符预测一个二元标签，指定为上五线谱或下五线谱，特别是对于钢琴谱。

+   **声音分离**任务看起来可能很相似，毕竟，如果我们能为每个声音预测声音编号，使用多类分类器，那么问题就能解决！

然而，直接预测声音标签是有问题的。我们需要固定系统可以接受的最大声音数量，但这会在系统的灵活性和数据中的类别不平衡之间造成权衡。

例如，如果我们将最大声音数量设置为8，以便在每个五线谱中容纳4个声音，这正如在音乐符号软件中常见的做法那样，我们可以预期在数据集中标签8和4的出现次数会非常少。

![](../Images/f844e660e329245c46607713c6f4f4ec.png)

使用绝对标签的声音分离

特别是看这段乐谱摘录，声音3、4和8完全缺失。高度不平衡的数据将降低多标签分类器的性能，如果我们设置更低的声音数量，我们就会失去系统的灵活性。

# 方法论

解决这些问题的办法是能够将系统在某些声音上学到的知识，迁移到其他声音上。为此，我们放弃了多类分类器的想法，并将**声音预测**框架为**链接预测**问题。如果两音符在同一声音中是连续的，我们希望将其连接。这种方法的优点是将一个复杂的问题分解为一组非常简单的问题，对于每对音符，我们再次预测一个二元标签，指示这两个音符是否链接。这种方法对于和弦也是有效的，如图中低音部分所示。

这个过程将创建一个我们称之为**输出图**的图。为了找到声音，我们可以简单地计算输出图的连接组件！

为了重复一下，我们将声音和五线谱分离问题框架为两个二元预测任务。

+   对于**五线谱分离**，我们预测每个音符的五线谱编号，

+   为了**分离声音**，我们预测每对音符之间的连接。

尽管不是绝对必要的，但我们发现为提高系统性能，添加一个额外的任务是有用的：

+   **和弦预测**，类似于声音，我们将每对属于同一和弦的音符连接起来。

让我们回顾一下到目前为止我们的系统样貌，我们有三个二元分类器，一个输入单个音符，另外两个输入音符对。现在我们需要的是良好的输入特征，这样我们的分类器才能在预测中使用上下文信息。使用深度学习术语，我们需要一个好的**音符编码器！**

我们选择使用图神经网络（GNN）作为音符编码器，因为它在符号音乐处理方面常常表现出色。因此，我们需要从音乐输入中创建一个图。

为此，我们从量化的MIDI中确定性地构建一个新的图，我们称之为**输入图**。

![](../Images/7425955fc727932733d104ab886a7db7.png)

创建这些输入图可以通过像[GraphMuse](https://github.com/manoskary/graphmuse)这样的工具轻松完成。

现在，将所有部分组合起来，我们的模型看起来像这样：

![](../Images/9c99e142a69c0acfa00084ed629d47fe.png)

1.  它从一些量化的MIDI开始，这些MIDI经过预处理后转化为图，生成输入图。

1.  输入图通过图神经网络（GNN）处理，以为每个音符创建一个中间潜在表示。因此我们对每个音符进行编码，这部分我们称之为GNN编码器；

1.  然后我们将其输入到一个浅层的MLP分类器中，进行我们的三个任务：声音、五线谱和和弦预测。我们也可以称这部分为解码器；

1.  预测完成后，我们得到一个输出图。

直到现在为止，这种方法可以看作是一种图到图的方法，我们从基于MIDI构建的输入图开始，预测包含声音和和弦链接以及五线谱标签的输出图。

5. 在最后一步，我们的输出图通过**后处理**程序生成一个美观且易于阅读的乐谱。

后处理的目标是去除可能导致无效输出的配置，如将一个声部分裂成两个声部。为了解决这些问题：

1.  我们根据和弦预测头将属于同一和弦的音符进行聚类。

1.  我们通过应用线性分配解决方案，确保每个节点最多有一个输入边和一个输出边；

1.  最后，将信息传播回原始节点。

![](../Images/e9538545fb724c6f5c6a85d39d6b8fe5.png)

我们系统的后处理例程

我们系统的一个突出特点是其在音乐分析和乐谱刻印方面超越了其他现有系统。与依赖于音乐启发式的传统方法不同——这些方法有时可能不可靠——我们的系统通过保持简单但稳健的方法，避免了这些问题。此外，我们的系统能够计算整个作品的全局解，无需因低内存和计算需求而进行分段处理。此外，它还能够处理无限数量的声部，使其成为处理复杂音乐作品的更灵活且强大的工具。这些优势突显了系统稳健的设计及其以更高精度和效率处理音乐问题的能力。

## 数据集

为了训练和评估我们的系统，我们使用了两个数据集。J-pop数据集包含811个流行钢琴乐谱，DCML浪漫语料库包含393个浪漫音乐钢琴乐谱。相比之下，DCML语料库更为复杂，因为它包含了许多具有挑战性的乐谱，如高声部数、声部交叉和五线谱交叉等。通过结合复杂和简易的数据，我们可以训练一个既稳健又灵活，能够适应各种输入类型的系统。

# 可视化预测结果

为了配合我们的系统，我们还开发了一个Web界面，可以在其中可视化和探索输入输出图形，用于调试复杂的案例，或者仅仅为了更好地理解图形创建过程。点击这里查看：[GitHub链接](https://github.com/fosfrancesco/musgviz/)。

![](../Images/9f12d5b97139d5a71e943230a6f60384.png)

我们的Web界面，MusGViz！

为了公平比较并更深入地理解我们的模型是如何工作的，以及预测结果如何变化，我们仔细观察了其中的一些例子。

我们将地面真值边（链接）与我们的和弦和声部预测的边进行比较。请注意，在您查看的示例中，输出图形是直接绘制在乐谱上的，借助我们的可视化工具。

![](../Images/7fe0f94f7b89f379b7c1099bfc6d4fc5.png)

前两小节处理得非常完美，但我们可以看到在第三小节时系统的一些局限性。在音高范围接近的同步音符中，不同的声部安排可能会造成问题。

我们的模型预测一个包含所有同步切分四分音符的和弦（而不是跨谱表分割），同时也错误预测了第一个D#4音符所在的谱表。要深入研究为什么会发生这种情况并不简单，因为神经网络是不可直接解释的。

# 开放挑战

尽管我们的系统具有优势，但仍存在一些挑战需要未来开发解决。目前，版本中未考虑到装饰音，并且重叠音符必须在输入中明确重复，这可能会造成困扰。此外，尽管我们已经开发了一个初步的MEI导出功能用于可视化结果，但这一功能仍需要进一步更新，以完全支持符号乐谱中遇到的各种例外情况和复杂性。解决这些问题将是提升系统多功能性并使其更适应多样化音乐作品的关键。

# 结论

本博客介绍了一种基于图的方法，用于同音声音分离和符号钢琴音乐中的谱表预测。这种新方法的表现优于现有的深度学习或启发式系统。最后，它还包括一个后处理步骤，可以去除模型中的问题预测，避免产生错误的乐谱。

[](https://github.com/CPJKU/piano_svsep/?source=post_page-----0cab100629cf--------------------------------) [## GitHub - CPJKU/piano_svsep: 论文《Cluster and Separate: 基于GNN的声音和谱表预测方法》代码]

### 论文《Cluster and Separate: 基于GNN的声音和谱表预测方法》代码

github.com](https://github.com/CPJKU/piano_svsep/?source=post_page-----0cab100629cf--------------------------------)

[所有图片均由作者提供]
