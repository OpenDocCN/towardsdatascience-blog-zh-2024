<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to practice data analyst interviews with AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to practice data analyst interviews with AI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-practice-data-analyst-interviews-with-ai-e933a027e609?source=collection_archive---------12-----------------------#2024-08-12">https://towardsdatascience.com/how-to-practice-data-analyst-interviews-with-ai-e933a027e609?source=collection_archive---------12-----------------------#2024-08-12</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="99e8" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Using LLMs to generate synthetic data and code</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@mathewnxwang?source=post_page---byline--e933a027e609--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Mathew Wang" class="l ep by dd de cx" src="../Images/487d76ba764d66af4f4bdd72f395d58f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*L3edraZM_qTJAJFev8L91g.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e933a027e609--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@mathewnxwang?source=post_page---byline--e933a027e609--------------------------------" rel="noopener follow">Mathew Wang</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e933a027e609--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 12, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/94cdfdd742c1f83f94ea057bf6d28d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eIVPOyOeX9CCaNAB"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@homajob?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Scott Graham</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="909b" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Intro</h1><p id="a117" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">I’ve been working on weekend LLM projects. When contemplating what to work on, two ideas struck me:</p><ol class=""><li id="4997" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pa pb pc bk"><strong class="ob fr">There are few resources for practicing data analytics interviews</strong> in contrast to other roles like software engineering and product management. I relied on friends in the industry to make up SQL and Python interview questions when I practiced interviewing for my first data analyst job.</li><li id="ddd4" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou pa pb pc bk"><strong class="ob fr">LLMs are really good at generating synthetic datasets and writing code.</strong></li></ol><p id="2deb" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">As a result, I’ve built the <strong class="ob fr">AI Data Analysis Interviewer </strong>which automatically creates a unique dataset and generates Python interview questions for you to solve!</p><p id="025f" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">This article provides an overview of how it works and its technical implementation. You can check out the repo <a class="af nc" href="https://github.com/mathewnxwang/data_analysis_interview_tool/tree/main" rel="noopener ugc nofollow" target="_blank">here</a>.</p><h1 id="f7c8" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Demo</h1><p id="9a3e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">When I launch the web app I’m prompted to provide details on the type of interview I want to practice for, specifically the company and a dataset description. Let’s say I’m interviewing for a data analyst role at Uber which focuses on analyzing ride data:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pi"><img src="../Images/75aed9c03ef8ff4d364477cc0e47299a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lxy8jvHJ8n2QVWVis4sAMQ.png"/></div></div></figure><p id="8b61" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">After clicking Submit and waiting for GPT to do its magic, I receive the AI generated questions, answers, and an input field where I can execute code on the AI generated dataset:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pj"><img src="../Images/e18b8f7b3ee76ed23e2a78d99c3ab8a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jXxP12u6X4OlnRoQqiFuAQ.png"/></div></div></figure><p id="3e7b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Awesome! Let’s try to solve the first question: calculate the total distance traveled each day. As is good analytics practice, let’s start with data exploration:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pk"><img src="../Images/73dcc32b41105c3c97ecd042f74041a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wgOQSXenDOdxYe9uPoQoAw.png"/></div></div></figure><p id="1536" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">It looks like we need to group by the ride_date field and sum the distance_miles field. Let’s write and submit that Pandas code:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pl"><img src="../Images/a541d03751698530798f9994483d4862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g2wMaVLa7IA2RtHFqyP7sQ.png"/></div></div></figure><p id="1d2a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Looks good to me! Does the AI answer agree with our approach?</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pm"><img src="../Images/f4c0dda442a99b7a9183da79e71dc9d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tIb83TAse9TrL3NjAeI0KQ.png"/></div></div></figure><p id="8898" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The AI answer uses a slightly different methodology but solves the problem essentially in the same way.</p><p id="0023" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I can rinse and repeat as much as needed to feel great before heading into an interview. Interviewing for Airbnb? This tool has you covered. It generates the questions:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pn"><img src="../Images/4cc47cd2ff09cdba93d2765d1d7d09c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLNSUNOI-TYQVVkYe_qHOA.png"/></div></div></figure><p id="05be" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Along with a dataset you can execute code on:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk po"><img src="../Images/2fffe8f5b44a4c0ab747bc7cf4ab41a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EABXsguco-v_5Fbp8R2eoA.png"/></div></div></figure><h1 id="4ddf" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">How to use the app</h1><p id="e045" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Check out the readme of the repo <a class="af nc" href="https://github.com/mathewnxwang/data_analysis_interview_tool/blob/main/README.md#how-to-run" rel="noopener ugc nofollow" target="_blank">here</a> to run the app locally. Unfortunately I didn’t host it but I might in the future!</p><h1 id="cd3a" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">High-level design</h1><p id="e2da" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">The rest of this article will cover the technical details on how I created the AI Data Analysis Interviewer.</p><h2 id="c5f8" class="pp ne fq bf nf pq pr ps ni pt pu pv nl oi pw px py om pz qa qb oq qc qd qe qf bk">LLM architecture</h2><p id="adde" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">I used OpenAI’s gpt-4o as it’s currently my go-to LLM model (it’s pretty easy to swap this out with another model though.)</p><p id="0c2d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">There are 3 types of LLM calls made:</p><ol class=""><li id="8c77" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pa pb pc bk"><strong class="ob fr">Dataset generation</strong>: we ask a LLM to generate a dataset suitable for an analytics interview.</li><li id="390e" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou pa pb pc bk"><strong class="ob fr">Question generation</strong>: we ask a LLM to generate a couple of analytics interview questions from that dataset.</li><li id="606d" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou pa pb pc bk"><strong class="ob fr">Answer generation</strong>: we ask a LLM to generate the answer code for each interview question.</li></ol><h2 id="e6f8" class="pp ne fq bf nf pq pr ps ni pt pu pv nl oi pw px py om pz qa qb oq qc qd qe qf bk">Front-end</h2><p id="1830" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">I built the front-end using Flask. It’s simple and not very interesting so I’ll focus on the LLM details below. Feel free to check out <a class="af nc" href="https://github.com/mathewnxwang/data_analysis_interview_tool/tree/main" rel="noopener ugc nofollow" target="_blank">the code in the repo</a> however!</p><h1 id="433c" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Design details</h1><h2 id="1bb9" class="pp ne fq bf nf pq pr ps ni pt pu pv nl oi pw px py om pz qa qb oq qc qd qe qf bk">LLM manager</h2><p id="f949" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">LLMManager is a simple class which handles making LLM API calls. It gets our OpenAI API key from a local secrets file and makes an OpenAI API call to pass a prompt to a LLM model. You’ll see some form of this in every LLM project.</p><pre class="mm mn mo mp mq qg qh qi bp qj bb bk"><span id="a737" class="qk ne fq qh b bg ql qm l qn qo">class LLMManager():<br/>    def __init__(self, model: str = 'gpt-4o'):<br/>        self.model = model<br/><br/>        load_dotenv("secrets.env")<br/>        openai_api_key = os.getenv("OPENAI_API_KEY")<br/>        self.client = OpenAI(api_key=openai_api_key)<br/><br/>    def call_llm(self, system_prompt: str, user_prompt: str, temperature: float) -&gt; str:<br/>        print(f"Calling LLM with system prompt: {system_prompt}\n\nUser prompt: {user_prompt}")<br/>        response: ChatCompletion = self.client.chat.completions.create(<br/>            messages=[<br/>                {"role": "system", "content": system_prompt},<br/>                {"role": "user", "content": user_prompt}<br/>            ],<br/>            model=self.model,<br/>            temperature=temperature<br/>        )<br/>        message = response.choices[0].message.content<br/>        print(response)<br/>        return message</span></pre><h2 id="b799" class="pp ne fq bf nf pq pr ps ni pt pu pv nl oi pw px py om pz qa qb oq qc qd qe qf bk">Dataset generation</h2><p id="30a9" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Here is where the fun starts!</p><p id="c13b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We first prompt a LLM to generate a dataset with the following prompt:</p><pre class="mm mn mo mp mq qg qh qi bp qj bb bk"><span id="8329" class="qk ne fq qh b bg ql qm l qn qo">SYSTEM_TEMPLATE = """You are a senior staff data analyst at a world class tech company.<br/>You are designing a data analysis interview for hiring candidates."""<br/><br/>DATA_GENERATION_USER_TEMPLATE = """Create a dataset for a data analysis interview that contains interesting insights.<br/>Specifically, generate comma delimited csv output with the following characteristics:<br/>- Relevant to company: {company}<br/>- Dataset description: {description}<br/>- Number of rows: 100<br/>- Number of columns: 5<br/>Only include csv data in your response. Do not include any other information.<br/>Start your output with the first header of the csv: "id,".<br/>Output: """</span></pre><p id="0fe7" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Let’s break it down:</p><ul class=""><li id="0489" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qp pb pc bk">Many LLM models follow a prompt structure where the LLM accepts a system and user message. The system message is intended to define general behavior and the user message is intended to provide specific instructions. Here we prompt the LLM to be a world class interviewer in the system message. It feels silly but hyping up a LLM is a proven prompt hack to get better performance.</li><li id="202a" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">We pass the user inputs about the company and dataset they want to practice interviewing with into the user template through the string variables {company} and {description}.</li><li id="e07d" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">We prompt the LLM to output data in csv format. This seems like the simplest tabular data format for a LLM to produce which we can later convert to a Pandas DataFrame for code analysis. JSON would also probably work but may be less reliable given the more complex and verbose syntax.</li><li id="5f38" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">We want the LLM output to be parseable csv, but gpt-4o tends to generate extra text likely because it was trained to be very helpful. The end of the user template strongly instructs the LLM to just output parseable csv data, but even so we need to post-process it.</li></ul><p id="0aea" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The class DataGenerator handles all things data generation and contains the generate_interview_dataset method which makes the LLM call to generate the dataset:</p><pre class="mm mn mo mp mq qg qh qi bp qj bb bk"><span id="8660" class="qk ne fq qh b bg ql qm l qn qo">    def generate_interview_dataset(self, company: str, description: str, mock_data: bool) -&gt; str:<br/>        if not mock_data:<br/>            data_generation_user_prompt = DATA_GENERATION_USER_TEMPLATE.format(company=company, description=description)<br/>            dataset = self.llm_manager.call_llm(<br/>                system_prompt=SYSTEM_TEMPLATE,<br/>                user_prompt=data_generation_user_prompt,<br/>                temperature=0<br/>            )<br/><br/>            dataset = self.clean_llm_dataset_output(dataset)<br/>            return dataset<br/>       <br/>        return MOCK_DATASET<br/>   <br/>    def clean_llm_dataset_output(self, dataset: str) -&gt; str:<br/>        cleaned_dataset = dataset[dataset.index("id,"):]<br/>        return cleaned_dataset</span></pre><p id="18f6" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Note that the clean_llm_dataset_output method does the light post-processing mentioned above. It removes any extraneous text before “id,” which denotes the start of the csv data.</p><p id="28e1" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">LLMs only can output strings so we need to transform the string output into an analyzable Pandas DataFrame. The convert_str_to_df method takes care of that:</p><pre class="mm mn mo mp mq qg qh qi bp qj bb bk"><span id="dc12" class="qk ne fq qh b bg ql qm l qn qo"> def convert_str_to_df(self, dataset: str) -&gt; pd.DataFrame:<br/>        csv_data = StringIO(dataset)<br/><br/>        try:<br/>            df = pd.read_csv(csv_data)<br/>        except Exception as e:<br/>            raise ValueError(f"Error in converting LLM csv output to DataFrame: {e}")<br/><br/>        return df</span></pre><h2 id="ed2b" class="pp ne fq bf nf pq pr ps ni pt pu pv nl oi pw px py om pz qa qb oq qc qd qe qf bk">Question generation</h2><p id="6978" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">We can prompt a LLM to generate interview questions off of the generated dataset with the following prompt:</p><pre class="mm mn mo mp mq qg qh qi bp qj bb bk"><span id="86f5" class="qk ne fq qh b bg ql qm l qn qo">QUESTION_GENERATION_USER_TEMPLATE = """Generate 3 data analysis interview questions that can be solved with Python pandas code based on the dataset below:<br/><br/>Dataset:<br/>{dataset}<br/><br/>Output the questions in a Python list where each element is a question. Start your output with [".<br/>Do not include question indexes like "1." in your output.<br/>Output: """</span></pre><p id="da47" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">To break it down once again:</p><ul class=""><li id="7f86" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qp pb pc bk">The same system prompt is used here as we still want the LLM to embody a world-class interviewer when writing the interview questions.</li><li id="f0fb" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">The string output from the dataset generation call is passed into the {dataset} string variable. Note that we have to maintain 2 representations of the dataset: 1. a string representation that a LLM can understand to generate questions and answers and 2. a structured representation (i.e. DataFrame) that we can execute code over.</li><li id="0f08" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">We prompt the LLM to return a list. We need the output to be structured so we can iterate over the questions in the answer generation step to generate an answer for every question.</li></ul><p id="d191" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The LLM call is made with the generate_interview_questions method of DataGenerator:</p><pre class="mm mn mo mp mq qg qh qi bp qj bb bk"><span id="3ef5" class="qk ne fq qh b bg ql qm l qn qo">    def generate_interview_questions(self, dataset: str) -&gt; InterviewQuestions:<br/>        <br/>        question_generation_user_prompt = QUESTION_GENERATION_USER_TEMPLATE.format(dataset=dataset)<br/>        questions = self.llm_manager.call_llm(<br/>            system_prompt=SYSTEM_TEMPLATE,<br/>            user_prompt=question_generation_user_prompt,<br/>            temperature=0<br/>        )<br/>        <br/>        try:<br/>            questions_list = literal_eval(questions)<br/>        except Exception as e:<br/>            raise ValueError(f"Error in converting LLM questions output to list: {e}")<br/>        <br/>        questions_structured = InterviewQuestions(<br/>            question_1=questions_list[0],<br/>            question_2=questions_list[1],<br/>            question_3=questions_list[2]<br/>        )<br/><br/>        return questions_structured</span></pre><h2 id="77fd" class="pp ne fq bf nf pq pr ps ni pt pu pv nl oi pw px py om pz qa qb oq qc qd qe qf bk">Answer generation</h2><p id="a33c" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">With both the dataset and the questions available, we finally generate the answers with the following prompt:</p><pre class="mm mn mo mp mq qg qh qi bp qj bb bk"><span id="6e25" class="qk ne fq qh b bg ql qm l qn qo">ANSWER_GENERATION_USER_TEMPLATE = """Generate an answer to the following data analysis interview Question based on the Dataset.<br/><br/>Dataset:<br/>{dataset}<br/><br/>Question: {question}<br/><br/>The answer should be executable Pandas Python code where df refers to the Dataset above.<br/>Always start your answer with a comment explaining what the following code does.<br/>DO NOT DEFINE df IN YOUR RESPONSE.<br/>Answer: """</span></pre><ul class=""><li id="201a" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qp pb pc bk">We make as many answer generation LLM calls as there are questions, so 3 since we hard coded the question generation prompt to ask for 3 questions. Technically you could ask a LLM to generate all 3 answers for all 3 questions in 1 call but I suspect that performance would worsen. We want the maximize the ability of the LLM to generate accurate answers. A (perhaps obvious) rule of thumb is that the harder the task given to a LLM, the less likely the LLM will perform it well.</li><li id="5cac" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">The prompt instructs the LLM to refer to the dataset as “df” because our interview dataset in DataFrame form is called “df” when the user code is executed by the CodeExecutor class below.</li></ul><pre class="mm mn mo mp mq qg qh qi bp qj bb bk"><span id="279b" class="qk ne fq qh b bg ql qm l qn qo">class CodeExecutor():<br/>    <br/>    def execute_code(self, df: pd.DataFrame, input_code: str):<br/><br/>        local_vars = {'df': df}<br/>        code_prefix = """import pandas as pd\nresult = """<br/>        try:<br/>            exec(code_prefix + input_code, {}, local_vars)<br/>        except Exception as e:<br/>            return f"Error in code execution: {e}\nCompiled code: {code_prefix + input_code}"<br/>        <br/>        execution_result = local_vars.get('result', None)<br/><br/>        if isinstance(execution_result, pd.DataFrame):<br/>            return execution_result.to_html()<br/><br/>        return execution_result</span></pre><h1 id="599e" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Conclusion</h1><p id="7824" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">I hope this article sheds light on how to build a simple and useful LLM project which utilizes LLMs in a variety of ways!</p><p id="ab5e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">If I continued to develop this project, I would focus on:</p><ol class=""><li id="4b86" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pa pb pc bk">Adding more validation on structured output from LLMs (i.e. parseable csv or lists). I already covered a couple of edge cases but LLMs are very unpredictable so this needs hardening.</li></ol><p id="b90c" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">2. Adding more features like</p><ul class=""><li id="4ede" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qp pb pc bk">Generating multiple relational tables and questions requiring joins</li><li id="3271" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">SQL interviews in addition to Python</li><li id="b154" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">Custom dataset upload</li><li id="8a0b" class="nz oa fq ob b go pd od oe gr pe og oh oi pf ok ol om pg oo op oq ph os ot ou qp pb pc bk">Difficulty setting</li></ul></div></div></div></div>    
</body>
</html>