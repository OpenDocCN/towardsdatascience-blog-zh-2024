<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Choosing Between LLM Agent Frameworks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Choosing Between LLM Agent Frameworks</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/choosing-between-llm-agent-frameworks-69019493b259?source=collection_archive---------0-----------------------#2024-09-21">https://towardsdatascience.com/choosing-between-llm-agent-frameworks-69019493b259?source=collection_archive---------0-----------------------#2024-09-21</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="2a5b" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><em class="hd">The tradeoffs between building bespoke code-based agents and the major agent frameworks.</em></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://aparnadhinak.medium.com/?source=post_page---byline--69019493b259--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Aparna Dhinakaran" class="l ep by dd de cx" src="../Images/e431ee69563ecb27c86f3428ba53574c.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*VbKXdndNnweCZQQa2TohWw.png"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--69019493b259--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://aparnadhinak.medium.com/?source=post_page---byline--69019493b259--------------------------------" rel="noopener follow">Aparna Dhinakaran</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--69019493b259--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 21, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk ld le ab q ee lf lg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lb lc">27</span></p></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lh k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al li an ao ap ie lj lk ll" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lm cn"><div class="l ae"><div class="ab cb"><div class="ln lo lp lq lr ls ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml mm"><img src="../Images/7f41def86bbb86b6e740c349eac8b70e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jRMs19HqSCazE5dY"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Image by author</figcaption></figure><p id="cef6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="nz">Thanks to John Gilhuly for his contributions to this piece.</em></p><p id="017e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Agents are having a moment. With multiple new frameworks and fresh <a class="af oa" href="https://foundationcapital.com/goodbye-aiops-welcome-agentsres-the-next-100b-opportunity/" rel="noopener ugc nofollow" target="_blank">investment</a> in the space, modern AI agents are overcoming <a class="af oa" href="https://arxiv.org/html/2405.13966v1" rel="noopener ugc nofollow" target="_blank">shaky origins</a> to rapidly supplant RAG as an implementation priority. So will 2024 finally be the year that autonomous AI systems that can take over writing our emails, booking flights, talking to our data, or seemingly any other task?</p><p id="66e8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Maybe, but much work remains to get to that point. Any developer building an agent must not only choose foundations — which model, use case, and architecture to use — but also which framework to leverage. Do you go with the long-standing LangGraph, or the newer entrant LlamaIndex Workflows? Or do you go the traditional route and code the whole thing yourself?</p><p id="e6d4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This post aims to make that choice a bit easier. Over the past few weeks, I built the same agent in major frameworks to examine some of the strengths and weaknesses of each at a technical level. All of the code for each agent is available in <a class="af oa" href="https://github.com/Arize-ai/phoenix/tree/main/examples/agent_framework_comparison" rel="noopener ugc nofollow" target="_blank">this repo</a>.</p><h2 id="4ec5" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Background on the Agent Used for Testing</h2><p id="874f" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">The agent used for testing includes function calling, multiple tools or skills, connections to outside resources, and shared state or memory.</p><p id="9644" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The agent has the following capabilities:</p><ol class=""><li id="36bf" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pb pc pd bk">Answering questions from a knowledge base</li><li id="19df" class="nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny pb pc pd bk">Talking to data: answering questions about telemetry data of an LLM application</li><li id="3e78" class="nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny pb pc pd bk">Analyzing data: analyzing higher-level trends and patterns in retrieved telemetry data</li></ol><p id="6618" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In order to accomplish these, the agent has three starting skills: RAG with product documentation, SQL generation on a trace database, and data analysis. A simple gradio-powered interface is used for the agent UI, with the agent itself structured as a chatbot.</p><h1 id="cf0a" class="pj oc fq bf od pk pl gq oh pm pn gt ol po pp pq pr ps pt pu pv pw px py pz qa bk">Code-Based Agent (No Framework)</h1><p id="82a8" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">The first option you have when developing an agent is to skip the frameworks entirely and build the agent fully yourself. When embarking on this project, this was the approach I started with.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qb"><img src="../Images/d10a779ccc5d91bfa0325de4b2665e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*trzs7Q9GA5WFrpBE62QOEg.jpeg"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Image by author</figcaption></figure><h2 id="47c8" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Pure Code Architecture</h2><p id="87dc" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">The code-based agent below is made up of an OpenAI-powered router that uses function calling to select the right skill to use. After that skill completes, it returns back to the router to either call another skill or respond to the user.</p><p id="70f8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The agent keeps an ongoing list of messages and responses that is passed fully into the router on each call to preserve context through cycles.</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="e2ec" class="qg oc fq qd b bg qh qi l qj qk">def router(messages):<br/>    if not any(<br/>        isinstance(message, dict) and message.get("role") == "system" for message in messages<br/>    ):<br/>        system_prompt = {"role": "system", "content": SYSTEM_PROMPT}<br/>        messages.append(system_prompt)<br/><br/>    response = client.chat.completions.create(<br/>        model="gpt-4o",<br/>        messages=messages,<br/>        tools=skill_map.get_combined_function_description_for_openai(),<br/>    )<br/><br/>    messages.append(response.choices[0].message)<br/>    tool_calls = response.choices[0].message.tool_calls<br/>    if tool_calls:<br/>        handle_tool_calls(tool_calls, messages)<br/>        return router(messages)<br/>    else:<br/>        return response.choices[0].message.content</span></pre><p id="4e0c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The skills themselves are defined in their own classes (e.g. GenerateSQLQuery) that are collectively held in a SkillMap. The router itself only interacts with the SkillMap, which it uses to load skill names, descriptions, and callable functions. This approach means that adding a new skill to the agent is as simple as writing that skill as its own class, then adding it to the list of skills in the SkillMap. The idea here is to make it easy to add new skills without disturbing the router code.</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="fa9e" class="qg oc fq qd b bg qh qi l qj qk">class SkillMap:<br/>    def __init__(self):<br/>        skills = [AnalyzeData(), GenerateSQLQuery()]<br/><br/>        self.skill_map = {}<br/>        for skill in skills:<br/>            self.skill_map[skill.get_function_name()] = (<br/>                skill.get_function_dict(),<br/>                skill.get_function_callable(),<br/>            )<br/><br/>    def get_function_callable_by_name(self, skill_name) -&gt; Callable:<br/>        return self.skill_map[skill_name][1]<br/><br/>    def get_combined_function_description_for_openai(self):<br/>        combined_dict = []<br/>        for _, (function_dict, _) in self.skill_map.items():<br/>            combined_dict.append(function_dict)<br/>        return combined_dict<br/><br/>    def get_function_list(self):<br/>        return list(self.skill_map.keys())<br/><br/>    def get_list_of_function_callables(self):<br/>        return [skill[1] for skill in self.skill_map.values()]<br/><br/>    def get_function_description_by_name(self, skill_name):<br/>        return str(self.skill_map[skill_name][0]["function"])</span></pre><p id="0e6d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Overall, this approach is fairly straightforward to implement but comes with a few challenges.</p><h2 id="5100" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Challenges with Pure Code Agents</h2><p id="3640" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">The first difficulty lies in structuring the router system prompt. Often, the router in the example above insisted on generating SQL itself instead of delegating that to the right skill. If you’ve ever tried to get an LLM <em class="nz">not</em> to do something, you know how frustrating that experience can be; finding a working prompt took many rounds of debugging. Accounting for the different output formats from each step was also tricky. Since I opted not to use structured outputs, I had to be ready for multiple different formats from each of the LLM calls in my router and skills.</p><h2 id="1d6c" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Benefits of a Pure Code Agent</h2><p id="ea84" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">A code-based approach provides a good baseline and starting point, offering a great way to learn how agents work without relying on canned agent tutorials from prevailing frameworks. Although convincing the LLM to behave can be challenging, the code structure itself is simple enough to use and might make sense for certain use cases (more in the analysis section below).</p><h1 id="98dd" class="pj oc fq bf od pk pl gq oh pm pn gt ol po pp pq pr ps pt pu pv pw px py pz qa bk">LangGraph</h1><p id="781a" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">LangGraph is one of the longest-standing agent frameworks, first releasing in January 2024. The framework is built to address the acyclic nature of existing pipelines and chains by adopting a Pregel graph structure instead. LangGraph makes it easier to define loops in your agent by adding the concepts of nodes, edges, and conditional edges to traverse a graph. LangGraph is built on top of LangChain, and uses the objects and types from that framework.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml ql"><img src="../Images/08d1c12009b7fdd2a59ea76f527eeee7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ekgbWEZG_RhfCWH6Wx_2vA.jpeg"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Image by author</figcaption></figure><h2 id="b2a9" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">LangGraph Architecture</h2><p id="1245" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">The LangGraph agent looks similar to the code-based agent on paper, but the code behind it is drastically different. LangGraph still uses a “router” technically, in that it calls OpenAI with functions and uses the response to continue to a new step. However the way the program moves between skills is controlled completely differently.</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="1a24" class="qg oc fq qd b bg qh qi l qj qk">tools = [generate_and_run_sql_query, data_analyzer]<br/>model = ChatOpenAI(model="gpt-4o", temperature=0).bind_tools(tools)<br/><br/>def create_agent_graph():<br/>    workflow = StateGraph(MessagesState)<br/><br/>    tool_node = ToolNode(tools)<br/>    workflow.add_node("agent", call_model)<br/>    workflow.add_node("tools", tool_node)<br/><br/>    workflow.add_edge(START, "agent")<br/>    workflow.add_conditional_edges(<br/>        "agent",<br/>        should_continue,<br/>    )<br/>    workflow.add_edge("tools", "agent")<br/><br/>    checkpointer = MemorySaver()<br/>    app = workflow.compile(checkpointer=checkpointer)<br/>    return app</span></pre><p id="f8d0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The graph defined here has a node for the initial OpenAI call, called “agent” above, and one for the tool handling step, called “tools.” LangGraph has a built-in object called ToolNode that takes a list of callable tools and triggers them based on a ChatMessage response, before returning to the “agent” node again.</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="abb5" class="qg oc fq qd b bg qh qi l qj qk">def should_continue(state: MessagesState):<br/>    messages = state["messages"]<br/>    last_message = messages[-1]<br/>    if last_message.tool_calls:<br/>        return "tools"<br/>    return END<br/><br/>def call_model(state: MessagesState):<br/>    messages = state["messages"]<br/>    response = model.invoke(messages)<br/>    return {"messages": [response]}</span></pre><p id="0a97" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After each call of the “agent” node (put another way: the router in the code-based agent), the should_continue edge decides whether to return the response to the user or pass on to the ToolNode to handle tool calls.</p><p id="71a1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Throughout each node, the “state” stores the list of messages and responses from OpenAI, similar to the code-based agent’s approach.</p><h2 id="a7e1" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Challenges with LangGraph</h2><p id="a1d9" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Most of the difficulties with LangGraph in the example stem from the need to use Langchain objects for things to flow nicely.</p><p id="17c8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Challenge #1: Function Call Validation</strong></p><p id="c618" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In order to use the ToolNode object, I had to refactor most of my existing Skill code. The ToolNode takes a list of callable functions, which originally made me think I could use my existing functions, however things broke down due to my function parameters.</p><p id="fac5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The skills were defined as classes with a callable member function, meaning they had “self” as their first parameter. GPT-4o was smart enough to not include the “self” parameter in the generated function call, however LangGraph read this as a validation error due to a missing parameter.</p><p id="a1e7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This took hours to figure out, because the error message instead marked the third parameter in the function (“args” on the data analysis skill) as the missing parameter:</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="0f9a" class="qg oc fq qd b bg qh qi l qj qk">pydantic.v1.error_wrappers.ValidationError: 1 validation error for data_analysis_toolSchema<br/>args field required (type=value_error.missing)</span></pre><p id="f9e2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">It is worth mentioning that the error message originated from Pydantic, not from LangGraph.</p><p id="5701" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">I eventually bit the bullet and redefined my skills as basic methods with Langchain’s @tool decorator, and was able to get things working.</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="dd8c" class="qg oc fq qd b bg qh qi l qj qk">@tool<br/>def generate_and_run_sql_query(query: str):<br/>    """Generates and runs an SQL query based on the prompt.<br/><br/>    Args:<br/>        query (str): A string containing the original user prompt.<br/><br/>    Returns:<br/>        str: The result of the SQL query.<br/>    """</span></pre><p id="2ea7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Challenge #2: Debugging</strong></p><p id="c00e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As mentioned, debugging in a framework is difficult. This primarily comes down to confusing error messages and abstracted concepts that make it harder to view variables.</p><p id="03a9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The abstracted concepts primarily show up when trying to debug the messages being sent around the agent. LangGraph stores these messages in state[“messages”]. Some nodes within the graph pull from these messages automatically, which can make it difficult to understand the value of messages when they are accessed by the node.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml mm"><img src="../Images/14b7cf88b1c2547c64d82b735e16a194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KuCg0WGHSklOKe6t"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx"><em class="hd">A sequential view of the agent’s actions (image by author)</em></figcaption></figure><h2 id="686e" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">LangGraph Benefits</h2><p id="d4d6" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">One of the main benefits of LangGraph is that it’s easy to work with. The graph structure code is clean and accessible. Especially if you have complex node logic, having a single view of the graph makes it easier to understand how the agent is connected together. LangGraph also makes it straightforward to convert an existing application built in LangChain.</p><h2 id="87b5" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Takeaway</h2><p id="d7b8" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">If you use everything in the framework, LangGraph works cleanly; if you step outside of it, prepare for some debugging headaches.</p><h1 id="e8d9" class="pj oc fq bf od pk pl gq oh pm pn gt ol po pp pq pr ps pt pu pv pw px py pz qa bk">LlamaIndex Workflows</h1><p id="cabf" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Workflows is a newer entrant into the agent framework space, premiering earlier this summer. Like LangGraph, it aims to make looping agents easier to build. Workflows also has a particular focus on running asynchronously.</p><p id="db07" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Some elements of Workflows seem to be in direct response to LangGraph, specifically its use of events instead of edges and conditional edges. Workflows use steps (analogous to nodes in LangGraph) to house logic, and emitted and received events to move between steps.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml ql"><img src="../Images/26b9e664d6cce92214a956f0faf4f485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EkZ9_qKSZ-nXbEkv2cmDMA.jpeg"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Image by author</figcaption></figure><p id="8068" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The structure above looks similar to the LangGraph structure, save for one addition. I added a setup step to the Workflow to prepare the agent context, more on this below. Despite the similar structure, there is very different code powering it.</p><h2 id="c3d7" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Workflows Architecture</h2><p id="2fa6" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">The code below defines the Workflow structure. Similar to LangGraph, this is where I prepared the state and attached the skills to the LLM object.</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="c8ac" class="qg oc fq qd b bg qh qi l qj qk">class AgentFlow(Workflow):<br/>    def __init__(self, llm, timeout=300):<br/>        super().__init__(timeout=timeout)<br/>        self.llm = llm<br/>        self.memory = ChatMemoryBuffer(token_limit=1000).from_defaults(llm=llm)<br/>        self.tools = []<br/>        for func in skill_map.get_function_list():<br/>            self.tools.append(<br/>                FunctionTool(<br/>                    skill_map.get_function_callable_by_name(func),<br/>                    metadata=ToolMetadata(<br/>                        name=func, description=skill_map.get_function_description_by_name(func)<br/>                    ),<br/>                )<br/>            )<br/><br/>    @step<br/>    async def prepare_agent(self, ev: StartEvent) -&gt; RouterInputEvent:<br/>        user_input = ev.input<br/>        user_msg = ChatMessage(role="user", content=user_input)<br/>        self.memory.put(user_msg)<br/><br/>        chat_history = self.memory.get()<br/>        return RouterInputEvent(input=chat_history)</span></pre><p id="7766" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This is also where I define an extra step, “prepare_agent”. This step creates a ChatMessage from the user input and adds it to the workflow memory. Splitting this out as a separate step means that we do return to it as the agent loops through steps, which avoids repeatedly adding the user message to the memory.</p><p id="c25f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In the LangGraph case, I accomplished the same thing with a run_agent method that lived outside the graph. This change is mostly stylistic, however it’s cleaner in my opinion to house this logic with the Workflow and graph as we’ve done here.</p><p id="ef67" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">With the Workflow set up, I then defined the routing code:</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="82f7" class="qg oc fq qd b bg qh qi l qj qk">@step<br/>async def router(self, ev: RouterInputEvent) -&gt; ToolCallEvent | StopEvent:<br/>    messages = ev.input<br/><br/>    if not any(<br/>        isinstance(message, dict) and message.get("role") == "system" for message in messages<br/>    ):<br/>        system_prompt = ChatMessage(role="system", content=SYSTEM_PROMPT)<br/>        messages.insert(0, system_prompt)<br/><br/>    with using_prompt_template(template=SYSTEM_PROMPT, version="v0.1"):<br/>        response = await self.llm.achat_with_tools(<br/>            model="gpt-4o",<br/>            messages=messages,<br/>            tools=self.tools,<br/>        )<br/><br/>    self.memory.put(response.message)<br/><br/>    tool_calls = self.llm.get_tool_calls_from_response(response, error_on_no_tool_call=False)<br/>    if tool_calls:<br/>        return ToolCallEvent(tool_calls=tool_calls)<br/>    else:<br/>        return StopEvent(result=response.message.content)</span></pre><p id="256e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And the tool call handling code:</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="9be5" class="qg oc fq qd b bg qh qi l qj qk">@step<br/>async def tool_call_handler(self, ev: ToolCallEvent) -&gt; RouterInputEvent:<br/>    tool_calls = ev.tool_calls<br/><br/>    for tool_call in tool_calls:<br/>        function_name = tool_call.tool_name<br/>        arguments = tool_call.tool_kwargs<br/>        if "input" in arguments:<br/>            arguments["prompt"] = arguments.pop("input")<br/><br/>        try:<br/>            function_callable = skill_map.get_function_callable_by_name(function_name)<br/>        except KeyError:<br/>            function_result = "Error: Unknown function call"<br/><br/>        function_result = function_callable(arguments)<br/>        message = ChatMessage(<br/>            role="tool",<br/>            content=function_result,<br/>            additional_kwargs={"tool_call_id": tool_call.tool_id},<br/>        )<br/><br/>        self.memory.put(message)<br/><br/>    return RouterInputEvent(input=self.memory.get())</span></pre><p id="83c7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Both of these look more similar to the code-based agent than the LangGraph agent. This is mainly because Workflows keeps the conditional routing logic in the steps as opposed to in conditional edges — lines 18–24 were a conditional edge in LangGraph, whereas now they are just part of the routing step — and the fact that LangGraph has a ToolNode object that does just about everything in the tool_call_handler method automatically.</p><p id="bd34" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Moving past the routing step, one thing I was very happy to see is that I could use my SkillMap and existing skills from my code-based agent with Workflows. These required no changes to work with Workflows, which made my life much easier.</p><h2 id="90d2" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Challenges with Workflows</h2><p id="3f90" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk"><strong class="nf fr">Challenge #1: Sync vs Async</strong></p><p id="5f03" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">While asynchronous execution is preferable for a live agent, debugging a synchronous agent is much easier. Workflows is designed to work asynchronously, and trying to force synchronous execution was very difficult.</p><p id="7aa8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">I initially thought I would just be able to remove the “async” method designations and switch from “achat_with_tools” to “chat_with_tools”. However, since the underlying methods within the Workflow class were also marked as asynchronous, it was necessary to redefine those in order to run synchronously. I ended up sticking to an asynchronous approach, but this didn’t make debugging more difficult.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml mm"><img src="../Images/86bb92ce7e47d92f16d5fb9bdcadc985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*78Hzqkiv9cI7W4UA"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx"><em class="hd">A sequential view of the agent’s actions (image by author)</em></figcaption></figure><p id="c93b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Challenge #2: Pydantic Validation Errors</strong></p><p id="7c6a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In a repeat of the woes with LangGraph, similar problems emerged around confusing Pydantic validation errors on skills. Fortunately, these were easier to address this time since Workflows was able to handle member functions just fine. I ultimately just ended up having to be more prescriptive in creating LlamaIndex FunctionTool objects for my skills:</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="c47a" class="qg oc fq qd b bg qh qi l qj qk">for func in skill_map.get_function_list(): <br/>            self.tools.append(FunctionTool(<br/>                skill_map.get_function_callable_by_name(func), <br/>                metadata=ToolMetadata(name=func, description=skill_map.get_function_description_by_name(func))))</span></pre><p id="c61f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="nz">Excerpt from AgentFlow.__init__ that builds FunctionTools</em></p><h2 id="af3a" class="ob oc fq bf od oe of og oh oi oj ok ol nm om on oo nq op oq or nu os ot ou ov bk">Benefits of Workflows</h2><p id="526c" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">I had a much easier time building the Workflows agent than I did the LangGraph agent, mainly because Workflows still required me to write routing logic and tool handling code myself instead of providing built-in functions. This also meant that my Workflow agent looked extremely similar to my code-based agent.</p><p id="3b61" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The biggest difference came in the use of events. I used two custom events to move between steps in my agent:</p><pre class="mn mo mp mq mr qc qd qe bp qf bb bk"><span id="c5f1" class="qg oc fq qd b bg qh qi l qj qk">class ToolCallEvent(Event):<br/>    tool_calls: list[ToolSelection]<br/><br/>class RouterInputEvent(Event):<br/>    input: list[ChatMessage]</span></pre><p id="ea26" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The emitter-receiver, event-based architecture took the place of directly calling some of the methods in my agent, like the tool call handler.</p><p id="35a9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If you have more complex systems with multiple steps that are triggering asynchronously and might emit multiple events, this architecture becomes very helpful to manage that cleanly.</p><p id="5d28" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Other benefits of Workflows include the fact that it is very lightweight and doesn’t force much structure on you (aside from the use of certain LlamaIndex objects) and that its event-based architecture provides a helpful alternative to direct function calling — especially for complex, asynchronous applications.</p><h1 id="353b" class="pj oc fq bf od pk pl gq oh pm pn gt ol po pp pq pr ps pt pu pv pw px py pz qa bk">Comparing Frameworks</h1><p id="fb4d" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Looking across the three approaches, each one has its benefits.</p><p id="075f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The no framework approach is the simplest to implement. Because any abstractions are defined by the developer (i.e. SkillMap object in the above example), keeping various types and objects straight is easy. The readability and accessibility of the code entirely comes down to the individual developer however, and it’s easy to see how increasingly complex agents could get messy without some enforced structure.</p><p id="9fcf" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">LangGraph provides quite a bit of structure, which makes the agent very clearly defined. If a broader team is collaborating on an agent, this structure would provide a helpful way of enforcing an architecture. LangGraph also might provide a good starting point with agents for those not as familiar with the structure. There is a tradeoff, however — since LangGraph does quite a bit for you, it can lead to headaches if you don’t fully buy into the framework; the code may be very clean, but you may pay for it with more debugging.</p><p id="fd52" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Workflows falls somewhere in the middle. The event-based architecture might be extremely helpful for some projects, and the fact that less is required in terms of using of LlamaIndex types provides greater flexibility for those not be fully using the framework across their application.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qm"><img src="../Images/e4c647265b3453dd773d7ac32c1702b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PITmiVGuG8QuDVX6"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Image created by author</figcaption></figure><p id="274f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Ultimately, the core question may just come down to “are you already using LlamaIndex or LangChain to orchestrate your application?” LangGraph and Workflows are both so entwined with their respective underlying frameworks that the additional benefits of each agent-specific framework might not cause you to switch on merit alone.</p><p id="f6b4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The pure code approach will likely always be an attractive option. If you have the rigor to document and enforce any abstractions created, then ensuring nothing in an external framework slows you down is easy.</p><h1 id="ee6b" class="pj oc fq bf od pk pl gq oh pm pn gt ol po pp pq pr ps pt pu pv pw px py pz qa bk">Key Questions To Help In Choosing An Agent Framework</h1><p id="8ad5" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Of course, “it depends” is never a satisfying answer. These three questions should help you decide which framework to use in your next agent project.</p><p id="733f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr"><em class="nz">Are you already using LlamaIndex or LangChain for significant pieces of your project?</em></strong></p><p id="0c7d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If yes, explore that option first.</p><p id="3bc2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr"><em class="nz">Are you familiar with common agent structures, or do you want something telling you how you should structure your agent?</em></strong></p><p id="343a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If you fall into the latter group, try Workflows. If you <em class="nz">really</em> fall into the latter group, try LangGraph.</p><p id="3466" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr"><em class="nz">Has your agent been built before?</em></strong></p><p id="1d16" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">One of the framework benefits is that there are many tutorials and examples built with each. There are far fewer examples of pure code agents to build from.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qn"><img src="../Images/f8250fa7aea13c3785aeb32ecd006a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wF9aSF1db1yaniqO"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Image created by author</figcaption></figure><h1 id="4628" class="pj oc fq bf od pk pl gq oh pm pn gt ol po pp pq pr ps pt pu pv pw px py pz qa bk">Conclusion</h1><p id="d7e4" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Picking an agent framework is just one choice among many that will impact outcomes in production for generative AI systems. As always, it pays to have robust guardrails and <a class="af oa" href="https://docs.arize.com/phoenix/tracing/llm-traces" rel="noopener ugc nofollow" target="_blank">LLM tracing</a> in place — and to be agile as new agent frameworks, research, and models upend established techniques.</p></div></div></div></div>    
</body>
</html>