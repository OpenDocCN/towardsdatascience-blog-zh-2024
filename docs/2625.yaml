- en: 'GSM-Symbolic: Analyzing LLM Limitations in Mathematical Reasoning and Potential
    Solutions'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GSM-Symbolic：分析大语言模型在数学推理中的局限性及潜在解决方案
- en: 原文：[https://towardsdatascience.com/gsm-symbolic-analyzing-llm-limitations-in-mathematical-reasoning-and-potential-solutions-363b82370a26?source=collection_archive---------8-----------------------#2024-10-28](https://towardsdatascience.com/gsm-symbolic-analyzing-llm-limitations-in-mathematical-reasoning-and-potential-solutions-363b82370a26?source=collection_archive---------8-----------------------#2024-10-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/gsm-symbolic-analyzing-llm-limitations-in-mathematical-reasoning-and-potential-solutions-363b82370a26?source=collection_archive---------8-----------------------#2024-10-28](https://towardsdatascience.com/gsm-symbolic-analyzing-llm-limitations-in-mathematical-reasoning-and-potential-solutions-363b82370a26?source=collection_archive---------8-----------------------#2024-10-28)
- en: What The Paper on LLM Reasoning Got Right — And What It Missed.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 《大语言模型推理论文：正确与遗漏的地方》
- en: '[](https://medium.com/@zredlined?source=post_page---byline--363b82370a26--------------------------------)[![Alexander
    Watson](../Images/aea574d9652ea8b1b91d4ec8a9c88ef8.png)](https://medium.com/@zredlined?source=post_page---byline--363b82370a26--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--363b82370a26--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--363b82370a26--------------------------------)
    [Alexander Watson](https://medium.com/@zredlined?source=post_page---byline--363b82370a26--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@zredlined?source=post_page---byline--363b82370a26--------------------------------)[![Alexander
    Watson](../Images/aea574d9652ea8b1b91d4ec8a9c88ef8.png)](https://medium.com/@zredlined?source=post_page---byline--363b82370a26--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--363b82370a26--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--363b82370a26--------------------------------)
    [Alexander Watson](https://medium.com/@zredlined?source=post_page---byline--363b82370a26--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--363b82370a26--------------------------------)
    ·9 min read·Oct 28, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--363b82370a26--------------------------------)
    ·9分钟阅读·2024年10月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'Co-authors: Alex Watson, Yev Meyer, Dane Corneil, Maarten Van Segbroeck (Gretel.ai)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 合著者：Alex Watson, Yev Meyer, Dane Corneil, Maarten Van Segbroeck (Gretel.ai)
- en: '![](../Images/8a06f7b26698ac70c2f8d5922ee6ca19.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a06f7b26698ac70c2f8d5922ee6ca19.png)'
- en: 'Source: Gretel.ai'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Gretel.ai
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: 'Large language models (LLMs) have recently made significant strides in AI reasoning,
    including mathematical problem-solving. However, a recent paper titled “[GSM-Symbolic:
    Understanding the Limitations of Mathematical Reasoning in Large Language Models](https://arxiv.org/pdf/2410.05229)”
    by Mirzadeh et al. raises questions about the true capabilities of these models
    when it comes to mathematical reasoning. We have reviewed the paper and found
    it to be a valuable contribution to the ongoing discussion about AI capabilities
    and limitations, however, our analysis suggests that its conclusions may not fully
    capture the complexity of the issue.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）最近在人工智能推理领域取得了显著进展，包括数学问题解决。然而，Mirzadeh等人最近发表的一篇名为《[GSM-Symbolic：理解大语言模型在数学推理中的局限性](https://arxiv.org/pdf/2410.05229)》的论文提出了关于这些模型在数学推理方面的真正能力的疑问。我们已对该论文进行了审阅，认为它对持续讨论人工智能的能力和局限性做出了宝贵贡献，但我们的分析表明，该论文的结论可能并未完全捕捉到问题的复杂性。
- en: The GSM-Symbolic Benchmark
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GSM-Symbolic基准
- en: The authors introduce GSM-Symbolic, an enhanced benchmark derived from the popular
    GSM8K dataset. This new benchmark allows for the generation of diverse question
    variants, enabling a more nuanced evaluation of LLMs’ performance across various
    setups. The study’s large-scale analysis of 25 state-of-the-art open and closed
    models provides significant insights into how these models behave when faced with
    mathematical reasoning tasks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们介绍了GSM-Symbolic，这是一个从流行的GSM8K数据集中派生的增强基准。这个新基准允许生成多样化的问题变体，从而能够对大语言模型（LLM）在不同设置下的表现进行更加细致的评估。研究对25个最先进的开源和闭源模型的大规模分析提供了重要的见解，揭示了这些模型在面对数学推理任务时的表现。
- en: '![](../Images/c6e00b2fb8155010c499955f50509297.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6e00b2fb8155010c499955f50509297.png)'
- en: 'Figure 1: GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning
    in Large Language Models (Source: [Mirzadeh et al., GSM-Symbolic Paper](https://arxiv.org/abs/2410.05229))'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：GSM-Symbolic：理解大语言模型在数学推理中的局限性（来源：[Mirzadeh等人，GSM-Symbolic论文](https://arxiv.org/abs/2410.05229))
- en: Performance Variability and Model Comparisons
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能变异性与模型比较
- en: One of the most surprising findings is the high variability in model performance
    across different instantiations of the same question. All models exhibit “significant
    variability in accuracy” when tested on GSM-Symbolic. This variability raises
    concerns about the reliability of currently reported metrics on the [GSM8K](https://huggingface.co/datasets/openai/gsm8k)
    benchmark, which relies on single point-accuracy responses.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最令人惊讶的发现是，同一问题的不同实例在模型表现上的高度变异性。所有模型在GSM-Symbolic上测试时都表现出“准确性上的显著变异性”。这种变异性引发了对当前报告的[
    GSM8K](https://huggingface.co/datasets/openai/gsm8k)基准上单点准确度响应可靠性的担忧。
- en: '![](../Images/51313010f4883f6faa35b8d5b355484b.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51313010f4883f6faa35b8d5b355484b.png)'
- en: 'Figure 3: GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning
    in Large Language Models (Source: [Mirzadeh et al., GSM-Symbolic Paper](https://arxiv.org/abs/2410.05229))'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：GSM-Symbolic：理解大型语言模型中数学推理的局限性（来源：[Mirzadeh等人，GSM-Symbolic论文](https://arxiv.org/abs/2410.05229)）
- en: '**Not all models are created equal.** `Llama-3–8b` and `GPT-4o` are clear outliers
    in that they don’t exhibit as significant of a drop on the new benchmark as other
    models like `gemma-2–9b`, `phi-3`, `phi-3.5` and `mathstral-7b`. This observations
    suggests two important points:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**并非所有模型都是一样的。** `Llama-3–8b`和`GPT-4o`在新基准上表现突出，不像其他模型（如`gemma-2–9b`、`phi-3`、`phi-3.5`和`mathstral-7b`）那样表现出显著的下降。这一观察结果表明了两个重要的观点：'
- en: '`Llama-3–8b` and `GPT-4o` generally demonstrate a more robust understanding
    of mathematical concepts, although they are still not immune to performance variations.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Llama-3–8b`和`GPT-4o`通常能更好地理解数学概念，尽管它们仍然不能免于性能变异。'
- en: The training data for `Llama-3–8b` and `GPT-4o` likely has not been contaminated
    (or at least not to the same extent) with GSM8K data. In this context, data contamination
    refers to the unintentional inclusion of test or benchmark data in a model’s training
    set, leading to artificially inflated model performance during evaluation. If
    contamination had occurred, as the authors hypothesize for some models, we would
    expect to see very high performance on GSM8K but significantly lower performance
    on even slight variations of these problems.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Llama-3–8b`和`GPT-4o`的训练数据可能没有受到GSM8K数据的污染（或至少没有像其他模型那样受到污染）。在这种情况下，数据污染是指在模型训练集中无意中包含了测试或基准数据，导致模型在评估时性能被人为抬高。如果发生了污染，正如作者对某些模型的假设那样，我们会期望在GSM8K上看到非常高的表现，但在这些问题的稍微变化版本上，表现会显著下降。'
- en: 'These findings highlight a opportunity for improvement through the use of synthetic
    data, where properly designed synthetic datasets can address both of these points
    for anyone training models:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些发现突显了通过使用合成数据改进模型的机会，经过合理设计的合成数据集能够解决这两点问题，适用于任何进行模型训练的人：
- en: To mitigate potential data contamination issues, there’s no need to use the
    original GSM8K data in training when high-quality synthetic versions can be generated
    ([blog link](https://gretel.ai/blog/teaching-ai-to-think-a-new-approach-with-synthetic-data-and-reflection)).
    These synthetic datasets retain the mathematical reasoning challenges of GSM8K
    without reusing the exact problems or solutions, thus preserving the integrity
    of the model’s evaluation.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了减少潜在的数据污染问题，当高质量的合成版本可以生成时，训练时无需使用原始的GSM8K数据（[博客链接](https://gretel.ai/blog/teaching-ai-to-think-a-new-approach-with-synthetic-data-and-reflection)）。这些合成数据集保留了GSM8K中的数学推理挑战，而不重复使用相同的问题或解决方案，从而保持模型评估的完整性。
- en: Even more importantly, it’s possible to generate synthetic data that surpass
    the quality of both the OpenAI GSM8K and Apple GSM-Symbolic datasets. This approach
    can lead to a more robust understanding of mathematical concepts, addressing the
    performance variability observed in current models.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更重要的是，生成的合成数据有可能超越OpenAI的GSM8K和Apple的GSM-Symbolic数据集的质量。这种方法可以更坚实地理解数学概念，并解决当前模型中观察到的性能变异。
- en: Sensitivity to Changes and Complexity
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对变化和复杂性的敏感性
- en: The authors show that LLMs are more sensitive to changes in numerical values
    than to changes in proper names within problems, suggesting that the models’ understanding
    of the underlying mathematical concepts may not be as robust as previously thought.
    As the complexity of questions increases (measured by the number of clauses),
    the performance of all models degrades, and the variance in their performance
    increases. This highlights the importance of using diverse data in training, and
    this is something that synthetics can help with. As the authors demonstrate, there
    is logically no reason why a AI model should perform worse on a given set of problems,
    with just a simple change in numbers or a slight variation in the number of clauses.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们表明，LLM（大规模语言模型）对数值变化的敏感度比对问题中专有名词变化的敏感度更高，这表明这些模型对潜在数学概念的理解可能并不像之前认为的那样稳固。当问题的复杂性增加时（通过子句数量来衡量），所有模型的表现都会下降，并且它们的表现方差也会增加。这凸显了在训练中使用多样化数据的重要性，而这正是合成数据能够提供帮助的地方。正如作者所展示的那样，从逻辑上讲，AI模型在一组特定问题上表现更差，单纯地改变数字或轻微变化子句数量并没有理由发生。
- en: '![](../Images/b953ae222b4dcb1370c9695ed3b319d3.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b953ae222b4dcb1370c9695ed3b319d3.png)'
- en: 'Figure 4: GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning
    in Large Language Models (Source: [Mirzadeh et al., GSM-Symbolic Paper](https://arxiv.org/abs/2410.05229))'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: GSM-Symbolic：理解大规模语言模型中数学推理的局限性（来源：[Mirzadeh 等，GSM-Symbolic 论文](https://arxiv.org/abs/2410.05229)）'
- en: The GSM-NoOp Challenge
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GSM-NoOp挑战
- en: Perhaps the most concerning finding is the introduction of GSM-NoOp, a dataset
    designed to challenge the reasoning capabilities of LLMs. By adding seemingly
    relevant but ultimately inconsequential information to problems, the authors observed
    substantial performance drops across all models — up to 65% for some. The authors
    propose that this points to current LLMs relying more on a type of pattern matching
    than true logical reasoning
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 也许最令人担忧的发现是引入了GSM-NoOp，一个旨在挑战LLM推理能力的数据集。通过向问题中添加表面相关但最终无关紧要的信息，作者观察到所有模型的表现大幅下降——某些模型下降幅度高达65%。作者提出，这表明当前的LLM在某种程度上更依赖于模式匹配而非真正的逻辑推理。
- en: '![](../Images/a1b1f43f0cd7b8ca1a64325f5456e1a8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1b1f43f0cd7b8ca1a64325f5456e1a8.png)'
- en: 'Figure 6: GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning
    in Large Language Models (Source: [Mirzadeh et al., GSM-Symbolic Paper](https://arxiv.org/abs/2410.05229))'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: GSM-Symbolic：理解大规模语言模型中数学推理的局限性（来源：[Mirzadeh 等，GSM-Symbolic 论文](https://arxiv.org/abs/2410.05229)）'
- en: A Critical Perspective on the Paper’s Conclusions
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对论文结论的批判性观点
- en: While the GSM-Symbolic study provides valuable insights into the performance
    of LLMs on mathematical reasoning tasks, it’s important to critically examine
    the paper’s conclusions. The authors argue that the observed limitations suggest
    LLMs are not capable of true logical reasoning. However, this interpretation may
    be oversimplifying a complex issue.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管GSM-Symbolic研究提供了关于LLM在数学推理任务中表现的宝贵见解，但重要的是要对论文的结论进行批判性审视。作者认为，观察到的局限性表明LLM无法进行真正的逻辑推理。然而，这种解释可能过于简化了一个复杂的问题。
- en: The paper’s argument for LLMs relying on pattern matching rather than reasoning
    seems less definitive when examined closely. It’s clear that these models are
    not perfect reasoners — if they were, they would achieve 100% accuracy on GSM8K.
    But the leap from imperfect performance to a lack of reasoning capability is not
    necessarily justified.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中关于LLM依赖模式匹配而非推理的论点，在仔细审视后似乎没有那么确凿。很明显，这些模型并不是完美的推理者——如果是，它们在GSM8K上将达到100%的准确率。但从不完美的表现推断出缺乏推理能力并不一定是有根据的。
- en: '**There are at least two potential explanations for why LLMs, like humans,
    sometimes get questions wrong**:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**至少有两种可能的解释可以说明为什么LLM像人类一样，有时会答错问题**：'
- en: The model tries to strictly pattern match a problem to something it has seen
    before, and fails if it can’t.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型尝试严格地将一个问题与它曾经见过的某个问题进行模式匹配，如果不能匹配，则失败。
- en: The model tries to follow a logical program but has a certain (compounding)
    probability of making an error at each step, as expected based on the fact that
    it literally samples tokens.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型尝试遵循一个逻辑程序，但在每一步都有一定的（累积）出错概率，这可以通过它实际生成词汇的过程来解释。
- en: The paper seems to lean towards explanation (1), but doesn’t make a convincing
    case for why this should be preferred over explanation (2). In fact, (2) is more
    akin to human-like reasoning and potentially more interesting from a research
    perspective.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 论文似乎倾向于解释（1），但并没有充分论证为什么解释（1）应该优于解释（2）。事实上，（2）更类似于人类的推理方式，并且从研究角度来看可能更有趣。
- en: '**Let’s examine each main finding of the paper through this critical lens:**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**让我们通过这种批判性视角来审视论文中的每一个主要发现：**'
- en: '*GSM-Symbolic Performance*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*GSM-符号性能*'
- en: The GSM-Symbolic approach is a valuable method for dataset expansion, validating
    the potential of synthetic data generation techniques like those used by Gretel.
    However, it’s worth noting that model performance doesn’t completely fall apart
    on these new variants — it just gets somewhat worse. If the models were strictly
    pattern matching, we might expect performance to drop to near zero on these new
    variants. The observed behavior seems more consistent with a model that can generalize
    to some degree but makes more errors on unfamiliar problem structures.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: GSM-符号方法是数据集扩展的有价值方法，验证了像Gretel使用的合成数据生成技术的潜力。然而，值得注意的是，模型在这些新变种上的表现并没有完全崩溃——只是表现有所下降。如果这些模型仅仅是进行模式匹配，我们可能会预期它们在这些新变种上的表现几乎接近零。观察到的行为似乎更符合这样一种模型：它能在一定程度上进行泛化，但在面对陌生问题结构时犯更多错误。
- en: Even human experts are not infallible. On the MATH benchmark, for instance,
    former math olympians typically scored 18/20 or 19/20, making small arithmetic
    errors. This suggests that error-prone reasoning, rather than a lack of reasoning
    capability, might be a more accurate description of both human and LLM performance.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是人类专家也不是全知全能的。例如，在MATH基准测试中，前数学奥林匹克选手通常能得18/20或19/20，偶尔犯些小算术错误。这表明，错误易发生的推理，而非缺乏推理能力，可能更准确地描述了人类和LLM的表现。
- en: '*Varying Difficulty*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*变化的难度*'
- en: The paper’s findings on performance degradation with increasing question complexity
    are consistent with the idea of compounding errors in a multi-step reasoning process.
    As the number of steps increases, so does the probability of making an error at
    some point in the chain. This behavior is observed in human problem-solving as
    well and doesn’t necessarily indicate a lack of reasoning ability.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中关于问题复杂性增加导致性能下降的发现与多步骤推理过程中的错误累积理论相一致。随着步骤数的增加，出现错误的概率也随之增加。这种现象在人类解决问题时也会出现，并不一定表示缺乏推理能力。
- en: '*GSM-NoOp Challenge*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*GSM-NoOp挑战*'
- en: The GSM-NoOp results, may not be as directly related to reasoning capability
    as the paper suggests. In real-world scenarios, we typically assume that all information
    provided in a problem statement is relevant. For instance, in the example question
    in Figure 7, a reasonable human might infer (like the LLMs did) that the size
    of the kiwis was only mentioned because they were discarded.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: GSM-NoOp的结果，可能不像论文所暗示的那样与推理能力直接相关。在现实世界的场景中，我们通常假设问题陈述中提供的所有信息都是相关的。例如，在图7中的示例问题中，一位理性的人的推理可能（就像LLMs所做的那样）是，猕猴桃的大小之所以被提及，仅仅是因为它们被丢弃了。
- en: '![](../Images/b20402670fc477c1e3f36a39ecb5f8db.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b20402670fc477c1e3f36a39ecb5f8db.png)'
- en: 'Figure 7: GSM-Symbolic: Example GSM No-Op question. (Source: [Mirzadeh et al.,
    GSM-Symbolic Paper](https://arxiv.org/abs/2410.05229))'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：GSM-符号：GSM No-Op问题示例。（来源：[Mirzadeh等人，GSM-符号论文](https://arxiv.org/abs/2410.05229)）
- en: The ability to discern relevant information from irrelevant information, especially
    when the irrelevant information is inserted with the intent to be misleading (i.e.
    *seemingly* relevant), is a separate skill from pure mathematical reasoning.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 从相关信息和无关信息中辨别出重要内容，尤其是当无关信息被有意插入并带有误导性（即*看似*相关）时，是一种独立于纯粹数学推理的技能。
- en: 'The authors include a follow-up experiment (NoOp-NoOp) in which the models
    are implicitly “warned” of the misleading intent: they use few-shot examples that
    also contain irrelevant information. The subset of models illustrated with this
    experiment still show a drop in performance. **Several follow-up experiments could
    serve to better understand the phenomenon**:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 作者进行了一项后续实验（NoOp-NoOp），在该实验中，模型在某种程度上“被警告”可能存在误导性意图：他们使用了包含无关信息的少量示例。参与该实验的模型子集仍然表现出性能下降的趋势。**若干后续实验可能有助于更好地理解这一现象**：
- en: Expand the NoOp-NoOp experiment to more models;
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将NoOp-NoOp实验扩展到更多模型；
- en: Measure how well models perform when *explicitly* warned that some information
    may be irrelevant in the prompt;
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量当模型在提示中*明确*被警告某些信息可能是无关时的表现；
- en: Fine-tune models on synthetic training examples that include irrelevant information
    in addition to examples that contain entirely relevant information.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在合成训练示例上微调模型，这些示例不仅包含完全相关的信息，还包括一些无关的信息。
- en: 'Opportunities for Improvement: The Promise of Synthetic Data'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进机会：合成数据的前景
- en: 'While the paper by Mirzadeh et al. highlights important limitations in current
    LLMs, at Gretel we have developed datasets that address many of the challenges
    identified in the paper:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Mirzadeh等人的论文突出了当前LLM的主要局限性，但在Gretel，我们已经开发了针对论文中识别的许多挑战的数据集：
- en: '**Synthetic GSM8K** Dataset: Available on HuggingFace at [gretelai/synthetic-gsm8k-reflection-405b](https://huggingface.co/datasets/gretelai/synthetic-gsm8k-reflection-405b),
    this dataset focuses on generating more complex, multi-step reasoning versions
    of problems than what existed in the original human generated dataset from OpenAI.
    It incorporates advanced prompting techniques, including Reflection and other
    cognitive models, to capture detailed reasoning processes. This approach has shown
    significant improvements, particularly for very hard problems, demonstrating its
    potential to enhance AI’s ability to handle complex, multi-step reasoning tasks.
    As covered in our blog, Gretel’s synthetic data created using these techniques
    achieved a [92.3% win-rate on problem complexity and an 82.7% win-rate for educational
    value over the standard Llama 3.1 405B parameter model outputs](https://gretel.ai/blog/teaching-ai-to-think-a-new-approach-with-synthetic-data-and-reflection),
    using these advanced techniques as judged by `GPT-4o`- demonstrating that LLM
    reasoning can further be unlocked with more sophisticated training data examples
    and prompting techniques than the basic Chain-of-Thought used in the paper.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**合成GSM8K** 数据集：可在HuggingFace上访问 [gretelai/synthetic-gsm8k-reflection-405b](https://huggingface.co/datasets/gretelai/synthetic-gsm8k-reflection-405b)，该数据集侧重于生成比OpenAI原始人工生成数据集中更复杂的、多步骤推理版本的问题。它结合了先进的提示技术，包括反思和其他认知模型，以捕捉详细的推理过程。该方法已显示出显著的改进，特别是在非常难的问题上，展示了其增强AI处理复杂多步骤推理任务能力的潜力。正如我们博客中所述，Gretel使用这些技术创建的合成数据，在问题复杂性上取得了[92.3%的胜率，在教育价值上取得了82.7%的胜率，超过了标准Llama
    3.1 405B参数模型的输出](https://gretel.ai/blog/teaching-ai-to-think-a-new-approach-with-synthetic-data-and-reflection)，这些技术通过`GPT-4o`判断——证明了LLM的推理能力可以通过比论文中使用的基本思维链更复杂的训练数据示例和提示技术进一步解锁。'
- en: '![](../Images/a28512feacedaced6552c69262035702.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a28512feacedaced6552c69262035702.png)'
- en: 'Source: [https://gretel.ai/blog/teaching-ai-to-think-a-new-approach-with-synthetic-data-and-reflection](https://gretel.ai/blog/teaching-ai-to-think-a-new-approach-with-synthetic-data-and-reflection)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://gretel.ai/blog/teaching-ai-to-think-a-new-approach-with-synthetic-data-and-reflection](https://gretel.ai/blog/teaching-ai-to-think-a-new-approach-with-synthetic-data-and-reflection)'
- en: '**2\. Synthetic Text-to-SQL** Dataset: Generated by Gretel to help improve
    LLMs ability to interact with SQL-based databases/warehouses & lakes, available
    at [gretelai/synthetic_text_to_sql](https://huggingface.co/datasets/gretelai/synthetic_text_to_sql),
    has proven highly effective in improving model performance on Text-to-SQL tasks.
    When used to fine-tune CodeLlama models, [it led to 36%+ improvements on the BIRD
    benchmark](https://gretel.ai/blog/fine-tuning-codellama-on-gretel-aws-sagemaker-jumpstart),
    a challenging cross-domain Text-to-SQL evaluation platform. Further supporting
    the theory about today’s LLMs being trained on data that is too simple and leading
    to memorization, a single epoch of fine-tuning the [Phi-3 and Llama 3.1 models
    on this dataset yielded a 300%+ improvement](https://youtu.be/jn6FuG4WA1c?feature=shared&t=2420)
    on BIRD benchmark problems labeled as “very hard”.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 合成文本到SQL** 数据集：由Gretel生成，旨在帮助提高LLM与基于SQL的数据库/仓库和湖泊的交互能力，数据集可在 [gretelai/synthetic_text_to_sql](https://huggingface.co/datasets/gretelai/synthetic_text_to_sql)
    获取，已证明在提高模型在文本到SQL任务上的表现方面非常有效。在用于微调CodeLlama模型时， [它在BIRD基准测试中提高了36%以上](https://gretel.ai/blog/fine-tuning-codellama-on-gretel-aws-sagemaker-jumpstart)，这是一个具有挑战性的跨领域文本到SQL评估平台。进一步支持关于当前LLM训练数据过于简单，导致记忆化的理论，对[Phi-3和Llama
    3.1模型在此数据集上的单个epoch微调，带来了超过300%的提升](https://youtu.be/jn6FuG4WA1c?feature=shared&t=2420)，特别是在BIRD基准测试中被标记为“非常难”的问题上。'
- en: These results demonstratethat high-quality synthetic data can be a powerful
    tool in addressing the limitations of current LLMs in complex reasoning tasks.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，高质量的合成数据可以成为解决当前 LLMs 在复杂推理任务中局限性的重要工具。
- en: Future Directions
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来方向
- en: In conclusion, the GSM-Symbolic paper provides valuable insights into the current
    limitations of LLMs in mathematical reasoning tasks. However, its conclusions
    should be approached critically. The observed behavior of LLMs could be interpreted
    in multiple ways, and it’s possible that the paper’s emphasis on pattern matching
    over reasoning may be oversimplifying a more complex issue.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，GSM-Symbolic 论文提供了对当前大语言模型（LLMs）在数学推理任务中的局限性的重要见解。然而，其结论应以批判的眼光来看待。观察到的
    LLM 行为可以有多种解释，论文强调模式匹配而非推理，可能在某种程度上简化了更复杂的问题。
- en: The limitations identified by the study are real and significant. The variability
    in performance, sensitivity to numerical changes, and struggles with irrelevant
    information all point to areas where current LLMs can be improved.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 研究所识别的局限性是现实且显著的。表现的差异性、对数值变化的敏感性以及对无关信息的处理困难，都指向当前 LLMs 需要改进的领域。
- en: However, as demonstrated by more advanced models such as GPT-4o and Llama 3.1
    above- by synthesizing diverse, challenging problem sets that push the boundaries
    of what AI models can tackle, we can develop LLMs that exhibit more robust, human-like
    reasoning capabilities.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如更先进的模型（如 GPT-4o 和 Llama 3.1 所展示的那样）所表明的，通过合成多样化且具有挑战性的问题集，推动 AI 模型能够应对的边界，我们可以开发出具备更强大、更类似人类推理能力的
    LLMs。
- en: References
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'I. Mirzadeh, K. Alizadeh, H. Shahrokhi, O. Tuzel, S. Bengio, and M. Farajtabar.
    [GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large
    Language Models.](https://arxiv.org/pdf/2410.05229) 2024.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'I. Mirzadeh, K. Alizadeh, H. Shahrokhi, O. Tuzel, S. Bengio, 和 M. Farajtabar。[GSM-Symbolic:
    了解大语言模型在数学推理中的局限性](https://arxiv.org/pdf/2410.05229) 2024。'
