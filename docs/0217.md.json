["```py\nimport os, torch, time\nimport torch.distributed as dist\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom timm.models.vision_transformer import VisionTransformer\n\nbatch_size = 128\nlog_interval = 10\n\n# use random data\nclass FakeDataset(Dataset):\n    def __len__(self):\n        return 1000000\n\n    def __getitem__(self, index):\n        rand_image = torch.randn([3, 224, 224], dtype=torch.float32)\n        label = torch.tensor(data=[index % 1000], dtype=torch.int64)\n        return rand_image, label\n\ndef mp_fn():\n    local_rank = int(os.environ['LOCAL_RANK'])\n    dist.init_process_group(\"nccl\")\n    torch.cuda.set_device(local_rank)\n\n    # model definition\n    model = VisionTransformer()\n    loss_fn = torch.nn.CrossEntropyLoss()\n    model.to(torch.cuda.current_device())\n    model = DDP(model)\n    optimizer = torch.optim.Adam(params=model.parameters())\n\n    # dataset definition\n    num_workers = os.cpu_count()//int(os.environ['LOCAL_WORLD_SIZE'])\n    dl = DataLoader(FakeDataset(), batch_size=batch_size, num_workers=num_workers)\n\n    model.train()\n    t0 = time.perf_counter()\n    for batch_idx, (x, y) in enumerate(dl, start=1):\n        optimizer.zero_grad(set_to_none=True)\n        x = x.to(torch.cuda.current_device())\n        y = torch.squeeze(y.to(torch.cuda.current_device()), -1)\n        with autocast(enabled=True, dtype=torch.bfloat16):\n            outputs = model(x)\n            loss = loss_fn(outputs, y)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % log_interval == 0 and local_rank == 0:\n            time_passed = time.perf_counter() - t0\n            samples_processed = dist.get_world_size() * batch_size * log_interval\n            print(f'{samples_processed / time_passed} samples/second')\n            t0 = time.perf_counter()\n\nif __name__ == '__main__':\n    mp_fn()\n```", "```py\nfrom sagemaker.pytorch import PyTorch\n\n# Toggle flag to switch between multiple single-GPU nodes and\n# single multi-GPU node\nmulti_inst = False\n\ninst_count=1\ninst_type='ml.g5.12xlarge'\nuse_spot_instances=False\nmax_wait=None #max seconds to wait for Spot job to complete\nsubnets=None\nsecurity_group_ids=None\n\nif multi_inst:\n    inst_count=4\n    inst_type='ml.g5.4xlarge' #  optinally change to ml.g5.2xlarge\n    use_spot_instances=True\n    max_wait=24*60*60 #24 hours\n    # configure vpc settings\n    subnets=['<VPC subnet>']\n    security_group_ids=['<Security Group>']\n\nestimator = PyTorch(\n    role='<sagemaker role>',\n    entry_point='train.py',\n    source_dir='<path to source dir>',\n    instance_type=inst_type,\n    instance_count=inst_count,\n    framework_version='2.1.0',\n    py_version='py310',\n    distribution={'torch_distributed': {'enabled': True}},\n    subnets=subnets,\n    security_group_ids=security_group_ids,\n    use_spot_instances=use_spot_instances,\n    max_wait=max_wait\n)\n\n# start job\nestimator.fit()\n```", "```py\nimport boto3\n\nec2 = boto3.client('ec2')\nec2.create_placement_group(\n    GroupName='cluster-placement-group',\n    Strategy='cluster'\n) \n```", "```py\nimport boto3\n\nec2 = boto3.resource('ec2')\ninstances = ec2.create_instances(\n    MaxCount=4,\n    MinCount=4,\n    ImageId='ami-0240b7264c1c9e6a9', # replace with image of choice\n    InstanceType='g5.4xlarge',\n    Placement={'GroupName':'cluster-placement-group'},\n    InstanceMarketOptions={\n        'MarketType': 'spot',\n        'SpotOptions': {\n            \"SpotInstanceType\": \"one-time\",\n            \"InstanceInterruptionBehavior\": \"terminate\"\n        }\n    },\n)\n```"]