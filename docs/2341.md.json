["```py\ndummy_model = MMM(\n    date_column=\"\",\n    channel_columns=[\"\"],\n    adstock=GeometricAdstock(l_max=4),\n    saturation=LogisticSaturation(),\n)\ndummy_model.default_model_config\n```", "```py\nalpha = 1\nbeta_param = 3\n\nx1 = np.linspace(0, 1, 100)\ny1 = beta.pdf(x1, alpha, beta_param)\n\nplt.figure(figsize=(8, 5))\nplt.plot(x1, y1, color='blue')\nplt.fill_between(x1, y1, color='blue', alpha=0.3)\nplt.title('Geometric Adstock: Beta distribution (alpha=1, beta=3)')\nplt.xlabel('Adstock alpha')\nplt.ylabel('Probability density')\nplt.grid(True)\nplt.show()\n```", "```py\nraw_spend = np.array([1000, 900, 800, 700, 600, 500, 400, 300, 200, 100, 0, 0, 0, 0, 0, 0])\n\nadstock_spend_1 = geometric_adstock(x=raw_spend, alpha=0.20, l_max=8, normalize=True).eval().flatten()\nadstock_spend_2 = geometric_adstock(x=raw_spend, alpha=0.50, l_max=8, normalize=True).eval().flatten()\nadstock_spend_3 = geometric_adstock(x=raw_spend, alpha=0.80, l_max=8, normalize=True).eval().flatten()\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(raw_spend, marker='o', label='Raw Spend', color='blue')\nplt.fill_between(range(len(raw_spend)), 0, raw_spend, color='blue', alpha=0.2)\n\nplt.plot(adstock_spend_1, marker='o', label='Adstock (alpha=0.20)', color='orange')\nplt.fill_between(range(len(adstock_spend_1)), 0, adstock_spend_1, color='orange', alpha=0.2)\n\nplt.plot(adstock_spend_2, marker='o', label='Adstock (alpha=0.50)', color='red')\nplt.fill_between(range(len(adstock_spend_2)), 0, adstock_spend_2, color='red', alpha=0.2)\n\nplt.plot(adstock_spend_3, marker='o', label='Adstock (alpha=0.80)', color='purple')\nplt.fill_between(range(len(adstock_spend_3)), 0, adstock_spend_3, color='purple', alpha=0.2)\n\nplt.xlabel('Weeks')\nplt.ylabel('Spend')\nplt.title('Geometric Adstock')\nplt.legend()\nplt.grid(True)\nplt.show()\n```", "```py\nalpha = 3\nbeta = 1\n\nx2 = np.linspace(0, 10, 1000)\ny2 = gamma.pdf(x2, alpha, scale=1/beta)\n\nplt.figure(figsize=(8, 6))\nplt.plot(x2, y2, 'b-')\nplt.fill_between(x2, y2, alpha=0.2, color='blue')\nplt.title('Logistic Saturation: Gamma Distribution (alpha=3, beta=1)')\nplt.xlabel('Saturation lamda')\nplt.ylabel('Probability density')\nplt.grid(True)\nplt.show()\n```", "```py\nscaled_spend = np.linspace(start=0.0, stop=1.0, num=100)\n\nsaturated_spend_1 = logistic_saturation(x=scaled_spend, lam=1).eval()\nsaturated_spend_2 = logistic_saturation(x=scaled_spend, lam=2).eval()\nsaturated_spend_4 = logistic_saturation(x=scaled_spend, lam=4).eval()\nsaturated_spend_8 = logistic_saturation(x=scaled_spend, lam=8).eval()\n\nplt.figure(figsize=(8, 6))\nsns.lineplot(x=scaled_spend, y=saturated_spend_1, label=\"1\")\nsns.lineplot(x=scaled_spend, y=saturated_spend_2, label=\"2\")\nsns.lineplot(x=scaled_spend, y=saturated_spend_4, label=\"4\")\nsns.lineplot(x=scaled_spend, y=saturated_spend_8, label=\"8\")\n\nplt.title('Logistic Saturation')\nplt.xlabel('Scaled Marketing Spend')\nplt.ylabel('Saturated Marketing Spend')\nplt.legend(title='Lambda')\nplt.grid(True)\nplt.show()\n```", "```py\nsigma = 2\n\nx3 = np.linspace(0, 10, 1000)\ny3 = halfnorm.pdf(x3, scale=sigma)\n\nplt.figure(figsize=(8, 6))\nplt.plot(x3, y3, 'b-')\nplt.fill_between(x3, y3, alpha=0.2, color='blue')\nplt.title('Saturation beta prior: HalfNormal Distribution (sigma=2)')\nplt.xlabel('Saturation beta')\nplt.ylabel('Probability Density')\nplt.grid(True)\nplt.show()\n```", "```py\nmu = 0\nsigma = 2\n\nx = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\ny = norm.pdf(x, mu, sigma)\n\nplt.figure(figsize=(8, 5))\nplt.plot(x, y, color='blue')\nplt.fill_between(x, y, color='blue', alpha=0.3)\nplt.title('Control: Normal distribution (mu=0, sigma=2)')\nplt.xlabel('Control value')\nplt.ylabel('Probability density')\nplt.grid(True)\nplt.show()\n```", "```py\nimport pandas as pd\nimport numpy as np\nfrom pymc_marketing.mmm.transformers import geometric_adstock, logistic_saturation\nfrom sklearn.preprocessing import MaxAbsScaler\n\ndef data_generator(start_date, periods, channels, spend_scalar, adstock_alphas, saturation_lamdas, betas, freq=\"W\"):\n    '''\n    Generates a synthetic dataset for a MMM with trend, seasonality, and channel-specific contributions.\n\n    Args:\n        start_date (str or pd.Timestamp): The start date for the generated time series data.\n        periods (int): The number of time periods (e.g., days, weeks) to generate data for.\n        channels (list of str): A list of channel names for which the model will generate spend and sales data.\n        spend_scalar (list of float): Scalars that adjust the raw spend for each channel to a desired scale.\n        adstock_alphas (list of float): The adstock decay factors for each channel, determining how much past spend influences the current period.\n        saturation_lamdas (list of float): Lambda values for the logistic saturation function, controlling the saturation effect on each channel.\n        betas (list of float): The coefficients for each channel, representing the contribution of each channel's impact on sales.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the generated time series data, including demand, sales, and channel-specific metrics.\n    '''\n\n    # 0\\. Create time dimension\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    df = pd.DataFrame({'date': date_range})\n\n    # 1\\. Add trend component with some growth\n    df[\"trend\"]= (np.linspace(start=0.0, stop=20, num=periods) + 5) ** (1 / 8) - 1\n\n    # 2\\. Add seasonal component with oscillation around 0\n    df[\"seasonality\"] = df[\"seasonality\"] = 0.1 * np.sin(2 * np.pi * df.index / 52)\n\n    # 3\\. Multiply trend and seasonality to create overall demand with noise\n    df[\"demand\"] = df[\"trend\"] * (1 + df[\"seasonality\"]) + np.random.normal(loc=0, scale=0.10, size=periods)\n    df[\"demand\"] = df[\"demand\"] * 1000\n\n    # 4\\. Create proxy for demand, which is able to follow demand but has some noise added\n    df[\"demand_proxy\"] = np.abs(df[\"demand\"]* np.random.normal(loc=1, scale=0.10, size=periods))\n\n    # 5\\. Initialize sales based on demand\n    df[\"sales\"] = df[\"demand\"]\n\n    # 6\\. Loop through each channel and add channel-specific contribution\n    for i, channel in enumerate(channels):\n\n        # Create raw channel spend, following demand with some random noise added\n        df[f\"{channel}_spend_raw\"] = df[\"demand\"] * spend_scalar[i]\n        df[f\"{channel}_spend_raw\"] = np.abs(df[f\"{channel}_spend_raw\"] * np.random.normal(loc=1, scale=0.30, size=periods))\n\n        # Scale channel spend\n        channel_transformer = MaxAbsScaler().fit(df[f\"{channel}_spend_raw\"].values.reshape(-1, 1))\n        df[f\"{channel}_spend\"] = channel_transformer .transform(df[f\"{channel}_spend_raw\"].values.reshape(-1, 1))\n\n        # Apply adstock transformation\n        df[f\"{channel}_adstock\"] = geometric_adstock(\n            x=df[f\"{channel}_spend\"].to_numpy(),\n            alpha=adstock_alphas[i],\n            l_max=8, normalize=True\n        ).eval().flatten()\n\n        # Apply saturation transformation\n        df[f\"{channel}_saturated\"] = logistic_saturation(\n            x=df[f\"{channel}_adstock\"].to_numpy(),\n            lam=saturation_lamdas[i]\n        ).eval()\n\n        # Calculate contribution to sales\n        df[f\"{channel}_sales\"] = df[f\"{channel}_saturated\"] * betas[i]\n\n        # Add the channel-specific contribution to sales\n        df[\"sales\"] += df[f\"{channel}_sales\"]\n\n    return df\n```", "```py\nnp.random.seed(10)\n\n# Set parameters for data generator\nstart_date = \"2021-01-01\"\nperiods = 52 * 3\nchannels = [\"tv\", \"social\", \"search\"]\nadstock_alphas = [0.50, 0.25, 0.05]\nsaturation_lamdas = [1.5, 2.5, 3.5]\nbetas = [350, 150, 50]\nspend_scalars = [10, 15, 20]\n\ndf = dg.data_generator(start_date, periods, channels, spend_scalars, adstock_alphas, saturation_lamdas, betas)\n\n# Scale betas using maximum sales value - this is so it is comparable to the fitted beta from pymc (pymc does feature and target scaling using MaxAbsScaler from sklearn)\nbetas_scaled = [\n    ((df[\"tv_sales\"] / df[\"sales\"].max()) / df[\"tv_saturated\"]).mean(),\n    ((df[\"social_sales\"] / df[\"sales\"].max()) / df[\"social_saturated\"]).mean(),\n    ((df[\"search_sales\"] / df[\"sales\"].max()) / df[\"search_saturated\"]).mean()\n]\n\n# Calculate contributions - these will be used later on to see how accurate the contributions from our model are\ncontributions = np.asarray([\n    round((df[\"tv_sales\"].sum() / df[\"sales\"].sum()), 2),\n    round((df[\"social_sales\"].sum() / df[\"sales\"].sum()), 2),\n    round((df[\"search_sales\"].sum() / df[\"sales\"].sum()), 2),\n    round((df[\"demand\"].sum() / df[\"sales\"].sum()), 2)\n])\n\ndf[[\"date\", \"demand\", \"demand_proxy\", \"tv_spend_raw\", \"social_spend_raw\", \"search_spend_raw\", \"sales\"]]\n```", "```py\nplt.figure(figsize=(8, 5))\n\nsns.lineplot(x=df['date'], y=df['trend']*1000, label=\"Trend\", color=\"green\")\nsns.lineplot(x=df['date'], y=df['seasonality']*1000, label=\"Seasonality\", color=\"orange\")\nsns.lineplot(x=df['date'], y=df['demand'], label=\"Demand\", color=\"blue\")\n\nplt.title('Components', fontsize=16)\nplt.xlabel('Date', fontsize=12)\nplt.ylabel('Value', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.legend()\nplt.show()\n```", "```py\nplt.figure(figsize=(8, 5))\n\nsns.scatterplot(x=df['demand_proxy'], y=df['demand'], color=\"blue\")\n\nplt.title('Demand proxy vs demand', fontsize=16)\nplt.xlabel('Demand proxy', fontsize=12)\nplt.ylabel('Demand', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.show()\n```", "```py\nplt.figure(figsize=(8, 5))\n\nsns.lineplot(x=df['date'], y=df['tv_spend_raw'], label=channels[0], color=\"orange\")\nsns.lineplot(x=df['date'], y=df['social_spend_raw'], label=channels[1], color=\"blue\")\nsns.lineplot(x=df['date'], y=df['search_spend_raw'], label=channels[2], color=\"green\")\nplt.title('Marketing Channel Spend', fontsize=16)\nplt.xlabel('Date', fontsize=12)\nplt.ylabel('Value', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.legend()\nplt.show()\n```", "```py\nplt.figure(figsize=(8, 5))\n\nsns.lineplot(x=df['tv_adstock'], y=df['tv_saturated'], label=channels[0], color=\"orange\")\nsns.lineplot(x=df['social_adstock'], y=df['social_saturated'], label=channels[1], color=\"blue\")\nsns.lineplot(x=df['search_adstock'], y=df['search_saturated'], label=channels[2], color=\"green\")\n\nplt.title('Marketing Spend Saturation', fontsize=16)\nplt.xlabel('Adstocked spend', fontsize=12)\nplt.ylabel('Saturated spend', fontsize=12)\nplt.legend()\nplt.show()\n```", "```py\nplt.figure(figsize=(8, 8))\nsns.heatmap(df[[\"demand\", \"demand_proxy\", \"tv_spend_raw\", \"social_spend_raw\", \"search_spend_raw\", \"sales\"]].corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Correlation Heatmap')\nplt.show()\n```", "```py\nplt.figure(figsize=(8, 5))\n\nsns.lineplot(x=df['date'], y=df['sales'], label=\"sales\", color=\"green\")\n\nplt.title('Sales', fontsize=16)\nplt.xlabel('Date', fontsize=12)\nplt.ylabel('Value', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.legend()\nplt.show()\n```", "```py\n# set date column\ndate_col = \"date\"\n\n# set outcome column\ny_col = \"sales\"\n\n# set marketing variables\nchannel_cols = [\"tv_spend_raw\",\n                \"social_spend_raw\",\n                \"search_spend_raw\"]\n\n# set control variables\ncontrol_cols = [\"demand_proxy\"]\n\n# split data into features and target\nX = df[[date_col] + channel_cols + control_cols]\ny = df[y_col]\n\n# set test (out-of-sample) length\ntest_len = 8\n\n# create train and test indices\ntrain_idx = slice(0, len(df) - test_len)\nout_of_time_idx = slice(len(df) - test_len, len(df))\n```", "```py\nmmm_default = MMM(\n    adstock=GeometricAdstock(l_max=8),\n    saturation=LogisticSaturation(),\n    date_column=date_col,\n    channel_columns=channel_cols,\n    control_columns=control_cols,\n)\n\nmmm_default.default_model_config\n```", "```py\nfit_kwargs = {\n    \"tune\": 1_000,\n    \"chains\": 4,\n    \"draws\": 1_000,\n    \"target_accept\": 0.9,\n}\n\nmmm_default.fit(X[train_idx], y[train_idx], **fit_kwargs)\n```", "```py\nmmm_default.idata[\"sample_stats\"][\"diverging\"].sum().item()\n```", "```py\naz.summary(\n    data=mmm_default.fit_result,\n    var_names=[\n        \"intercept\",\n        \"y_sigma\",\n        \"saturation_beta\",\n        \"saturation_lam\",\n        \"adstock_alpha\",\n        \"gamma_control\",\n    ],\n)\n```", "```py\n_ = az.plot_trace(\n    data=mmm_default.fit_result,\n    var_names=[\n        \"intercept\",\n        \"y_sigma\",\n        \"saturation_beta\",\n        \"saturation_lam\",\n        \"adstock_alpha\",\n        \"gamma_control\",\n    ],\n    compact=True,\n    backend_kwargs={\"figsize\": (12, 10), \"layout\": \"constrained\"},\n)\nplt.gcf().suptitle(\"Model Trace\", fontsize=16);\n```", "```py\nmmm_default.sample_posterior_predictive(X[train_idx], extend_idata=True, combined=True)\n```", "```py\nmmm_default.plot_posterior_predictive(original_scale=True);\n```", "```py\nmmm_default.plot_errors(original_scale=True);\n```", "```py\nerrors = mmm_default.get_errors(original_scale=True)\n\nfig, ax = plt.subplots(figsize=(8, 6))\naz.plot_dist(\n    errors, quantiles=[0.25, 0.5, 0.75], color=\"C3\", fill_kwargs={\"alpha\": 0.7}, ax=ax\n)\nax.axvline(x=0, color=\"black\", linestyle=\"--\", linewidth=1, label=\"zero\")\nax.legend()\nax.set(title=\"Errors Posterior Distribution\");\n```", "```py\ny_out_of_sample = mmm_default.sample_posterior_predictive(\n    X_pred=X[out_of_time_idx], extend_idata=False, include_last_observations=True\n)\n\ndef plot_in_sample(X, y, ax, n_points: int = 15):\n    (\n        y.to_frame()\n        .set_index(X[date_col])\n        .iloc[-n_points:]\n        .plot(ax=ax, marker=\"o\", color=\"black\", label=\"actuals\")\n    )\n    return ax\n\ndef plot_out_of_sample(X_out_of_sample, y_out_of_sample, ax, color, label):\n    y_out_of_sample_groupby = y_out_of_sample[\"y\"].to_series().groupby(\"date\")\n\n    lower, upper = quantiles = [0.025, 0.975]\n    conf = y_out_of_sample_groupby.quantile(quantiles).unstack()\n    ax.fill_between(\n        X_out_of_sample[date_col].dt.to_pydatetime(),\n        conf[lower],\n        conf[upper],\n        alpha=0.25,\n        color=color,\n        label=f\"{label} interval\",\n    )\n\n    mean = y_out_of_sample_groupby.mean()\n    mean.plot(ax=ax, marker=\"o\", label=label, color=color, linestyle=\"--\")\n    ax.set(ylabel=\"Original Target Scale\", title=\"Out of sample predictions for MMM\")\n    return ax\n\n_, ax = plt.subplots()\nplot_in_sample(X, y, ax=ax, n_points=len(X[out_of_time_idx])*3)\nplot_out_of_sample(\n    X[out_of_time_idx], y_out_of_sample, ax=ax, label=\"out of sample\", color=\"C0\"\n)\nax.legend(loc=\"upper left\");\n```", "```py\nfig = mmm_default.plot_channel_parameter(param_name=\"adstock_alpha\", figsize=(9, 5))\nax = fig.axes[0]\nax.axvline(x=adstock_alphas[0], color=\"C0\", linestyle=\"--\", label=r\"$\\alpha_1$\")\nax.axvline(x=adstock_alphas[1], color=\"C1\", linestyle=\"--\", label=r\"$\\alpha_2$\")\nax.axvline(x=adstock_alphas[2], color=\"C2\", linestyle=\"--\", label=r\"$\\alpha_3$\")\nax.legend(loc=\"upper right\");\n```", "```py\nfig = mmm_default.plot_channel_parameter(param_name=\"saturation_lam\", figsize=(9, 5))\nax = fig.axes[0]\nax.axvline(x=saturation_lamdas[0], color=\"C0\", linestyle=\"--\", label=r\"$\\lambda_1$\")\nax.axvline(x=saturation_lamdas[1], color=\"C1\", linestyle=\"--\", label=r\"$\\lambda_2$\")\nax.axvline(x=saturation_lamdas[2], color=\"C2\", linestyle=\"--\", label=r\"$\\lambda_3$\")\nax.legend(loc=\"upper right\");\n```", "```py\nfig = mmm_default.plot_channel_parameter(param_name=\"saturation_beta\", figsize=(9, 5))\nax = fig.axes[0]\nax.axvline(x=betas_scaled[0], color=\"C0\", linestyle=\"--\", label=r\"$\\beta_1$\")\nax.axvline(x=betas_scaled[1], color=\"C1\", linestyle=\"--\", label=r\"$\\beta_2$\")\nax.axvline(x=betas_scaled[2], color=\"C2\", linestyle=\"--\", label=r\"$\\beta_3$\")\nax.legend(loc=\"upper right\");\n```", "```py\nchannels = np.array([\"tv\", \"social\", \"search\", \"demand\"])\n\ntrue_contributions = pd.DataFrame({'Channels': channels, 'Contributions': contributions})\ntrue_contributions= true_contributions.sort_values(by='Contributions', ascending=False).reset_index(drop=True)\ntrue_contributions = true_contributions.style.bar(subset=['Contributions'], color='lightblue')\n\ntrue_contributions\n```", "```py\nmmm_default.plot_waterfall_components_decomposition(figsize=(10,6));\n```"]