["```py\n// Create an empty model.\nlet model = DRESS.randomForst([], outcome, numericals, categoricals);\n// Train the existing model using new samples. Repeat this step whenever a sufficient number of new training samples is accumulated. \nmodel.train(samples);\n```", "```py\n// Split a sample dataset into training/vadilation dataset\nconst [trainings, validations] = DRESS.split(samples);\n// Create a model using a training dataset.\nlet model = DRESS.gradientBoosting(trainings, outcome, numericals, categoricals);\n// Compute the permutation feature importances using a validation dataset.\nDRESS.print(\n DRESS.importances(model, validations)\n);\n```", "```py\n// Training parameters\nconst trainParams = [outcomes, features];\n// Validation parameters\nconst validateParams = [0.5];\n// Perform cross validation on sample dataset using the logistic regression algorithm. Note that the training parameters and validations parameters MUST be passed as arrays.\nDRESS.print(\n DRESS.crossValidate(DRESS.logistic, samples, trainParams, validateParams)\n);\n```", "```py\n// Specify the initial hyperparameter values. Hyperparameters that are not defined will be set to the default values by the multilayer perceptron algorithm itself.\nconst initial = {\n alpha: 0.001,\n epoch: 100,\n dilution: 0.1,\n layout: [20, 10]\n}\n// Specify the end values of the search space. Only hyperparameters that are being optimized are included.\nconst eventual = {\n dilution: 0.6, // the dilution hyperparameter will be searched first.\n epoch: 1000 // the epoch hyperparameter will be searched second.\n // the alpha hyperparameter will not be optimized.\n // the layout hyperparameter cannot be optimized since it is not strictly a numerical value.\n}\n// Specify the performace metric.\nconst metric = 'f1',\n// Training parameters\nconst trainParams = [outcome, features];\nDRESS.print(\n DRESS.hyperparameters(initial, eventual, metric, DRESS.multilayerPerceptron, samples, trainParams)\n)\n```", "```py\n// To export a model in JSON format.\nDRESS.save(DRESS.deflate(model), 'model.json');\n// To import a model from a JSON file.\nDRESS.local('model.json').then(json => {\n const model = DRESS.inflate(json)\n})\n```", "```py\n// Print a concise summary of the specified dataset.\nDRESS.print(\n DRESS.summary(samples)\n);\n```", "```py\n{\n ID: number, // Unique identifier\n Etiology: string, // Etiology of liver disease (ASH, NASH, HCV, AIH, PBC)\n Grade: number, // Degree of steatotsis (1, 2, 3, 4)\n Stage: number, // Stage of fibrosis (1, 2, 3, 4)\n Admissions: number[], // List of numerical IDs representing hospital admissions\nDemographics: {\n Age: number, // Age of subject\n Barriers: string[], // List of psychosocial barriers\n Ethnicity: string, // Ethnicity (white, latino, black, asian, other)\n Gender: string // M or F\n },\nExams: {\n BMI: number // Body mass index\n Ascites: string // Ascites on exam (none, small, large)\n Encephalopathy: string // West Haven encephalopathy grade (0, 1, 2, 3, 4)\n Varices: string // Varices on endoscopy (none, small, large)\n },\nLabs: {\n WBC: number, // WBC count (1000/uL)\n Hemoglobin: number, // Hemoglobin (g/dL)\n MCV: number, // MCV (fL)\n Platelet: number, // Platelet count (1000/uL)\n AST: number, // AST (U/L)\n ALT: number, // ALT (U/L)\n ALP: number, // Alkaline Phosphatase (IU/L)\n Bilirubin: number, // Total bilirubin (mg/dL)\n INR: number // INR \n }\n}\n```", "```py\n6000 row(s) 23 feature(s)\nAdmissions : categoric null: 4193 unique: 1806 [1274533, 631455, 969679, …]\nDemographics.Age : numeric null: 0 unique: 51 [45, 48, 50, …]\nDemographics.Barriers : categoric null: 3378 unique: 139 [insurance, substance use, mental health, …]\nDemographics.Ethnicity: categoric null: 0 unique: 5 [white, latino, black, …]\nDemographics.Gender : categoric null: 0 unique: 2 [M, F]\nEtiology : categoric null: 0 unique: 5 [NASH, ASH, HCV, …]\nExams.Ascites : categoric null: 0 unique: 3 [large, small, none]\nExams.BMI : numeric null: 0 unique: 346 [33.8, 23, 31.3, …]\nExams.Encephalopathy : numeric null: 0 unique: 5 [1, 4, 0, …]\nExams.Varices : categoric null: 0 unique: 3 [none, large, small]\nGrade : numeric null: 0 unique: 4 [2, 4, 1, …]\nID : numeric null: 0 unique: 6000 [1, 2, 3, …]\nLabs.ALP : numeric null: 0 unique: 236 [120, 100, 93, …]\nLabs.ALT : numeric null: 0 unique: 373 [31, 87, 86, …]\nLabs.AST : numeric null: 0 unique: 370 [31, 166, 80, …]\nLabs.Bilirubin : numeric null: 0 unique: 103 [1.5, 3.9, 2.6, …]\nLabs.Hemoglobin : numeric null: 0 unique: 88 [14.9, 13.4, 11, …]\nLabs.INR : numeric null: 0 unique: 175 [1, 2.72, 1.47, …]\nLabs.MCV : numeric null: 0 unique: 395 [97.9, 91, 96.7, …]\nLabs.Platelet : numeric null: 0 unique: 205 [268, 170, 183, …]\nLabs.WBC : numeric null: 0 unique: 105 [7.3, 10.5, 5.5, …]\nMELD : numeric null: 0 unique: 33 [17, 32, 21, …]\nStage : numeric null: 0 unique: 4 [3, 4, 2, …]\n```", "```py\n// Split samples to controls and subjects.\nconst [controls, subjects] = DRESS.split(samples);\n// If only numerical features are specified, then the method will build a logistic regression model.\nlet numerical_matches = DRESS.propensity(subjects, controls, numericals);\n// If only categorical features (or both categorical and numberical features) are specified, then the method will build a gradient boosting regression model.\nlet categorical_matches = DRESS.propensity(subjects, controls, numericals, categoricals);\n```", "```py\n// Define boundaries.\nconst boundaries = [3, 6, 9];\n// Categorize any feature value less than 3 as 0, values between 3 and 6 as 1, values between 6 and 9 as 2, and values greater than 9 as 3.\nDRESS.categorize(samples, [feature], boundaries);\n// Define categories.\nconst categories = [A, [B, C], D];\n// Numericize any feature value A to 0, B or C to 1, and D to 2\\. \nDRESS.numericize(samples, [feature], categories);\n```", "```py\n// Generate a receiver-operating characteristic (roc) curve.\nlet roc = DRESS.roc(samples, outcomes, classifiers);\n// Generate a precision-recall (pr) curve.\nlet pr = DRESS.pr(samples, outcomes, classifiers);\n```", "```py\nDRESS.local('data.json').then(subjects => {\n // Do something with the subjects.\n})\n```"]