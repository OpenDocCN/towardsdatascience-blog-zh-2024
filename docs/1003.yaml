- en: 'Decoding Time: Unraveling the Power of LSTM vs. N-BEATS for Accurate Time Series
    Forecasting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解码时间：揭开LSTM与N-BEATS在精确时间序列预测中的力量
- en: 原文：[https://towardsdatascience.com/decoding-time-unraveling-the-power-of-lstm-vs-n-beats-for-accurate-time-series-forecasting-ca5fdd20dbc?source=collection_archive---------11-----------------------#2024-04-19](https://towardsdatascience.com/decoding-time-unraveling-the-power-of-lstm-vs-n-beats-for-accurate-time-series-forecasting-ca5fdd20dbc?source=collection_archive---------11-----------------------#2024-04-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/decoding-time-unraveling-the-power-of-lstm-vs-n-beats-for-accurate-time-series-forecasting-ca5fdd20dbc?source=collection_archive---------11-----------------------#2024-04-19](https://towardsdatascience.com/decoding-time-unraveling-the-power-of-lstm-vs-n-beats-for-accurate-time-series-forecasting-ca5fdd20dbc?source=collection_archive---------11-----------------------#2024-04-19)
- en: '![](../Images/7f89a7d4b8fac9fdb276d5798b65164e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f89a7d4b8fac9fdb276d5798b65164e.png)'
- en: Photo by [Aron Visuals](https://unsplash.com/@aronvisuals?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/selective-focus-photo-of-brown-and-blue-hourglass-on-stones-BXOXnQ26B7o?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Aron Visuals](https://unsplash.com/@aronvisuals?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    在 [Unsplash](https://unsplash.com/photos/selective-focus-photo-of-brown-and-blue-hourglass-on-stones-BXOXnQ26B7o?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: Comparing how two deep learning models perform short-term and long-term
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较两个深度学习模型在短期和长期的表现
- en: '[](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)[![Frida
    Karvouni](../Images/49aad19f6bdd7ffdc68c212722079c6f.png)](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)
    [Frida Karvouni](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)[![Frida
    Karvouni](../Images/49aad19f6bdd7ffdc68c212722079c6f.png)](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)
    [Frida Karvouni](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)
    ·6 min read·Apr 19, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)
    ·6分钟阅读·2024年4月19日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Time series forecasting plays a pivotal role across various domains by facilitating
    predictions of future trends. This exploration focuses on two prominent deep learning
    models, delving into their respective strengths and weaknesses.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列预测在各个领域中扮演着至关重要的角色，通过预测未来的趋势提供了重要的决策支持。本次探索聚焦于两个著名的深度学习模型，深入分析它们各自的优势与局限。
- en: '**LSTM** (Long Short-Term Memory) stands out as a specialised variant of RNN,
    adept at capturing patterns characterised by long-term dependencies in sequential
    data. It enhances traditional RNNs by effectively addressing the vanishing gradient
    problem, allowing for the modelling of extended dependencies. LSTM achieves this
    by selectively retaining or forgetting information over time through the incorporation
    of memory cells and gating mechanisms, including input, output, and forget gates.
    An inherent limitation of LSTM models is that the forecasting horizon must align
    with the length of the input sequences utilised during training.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**LSTM**（长短期记忆）作为RNN的一个特殊变种，在捕捉具有长期依赖关系的序列数据模式方面表现突出。它通过有效地解决梯度消失问题，增强了传统的RNN，能够建模更长时间的依赖关系。LSTM通过引入记忆单元和门控机制（包括输入门、输出门和遗忘门）来实现这一点，能够选择性地保留或遗忘信息。LSTM模型的一个固有限制是，预测的时间范围必须与训练时使用的输入序列的长度相匹配。'
- en: '![](../Images/c70ad5ef5d4fc304d3824aaa7beb19b1.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c70ad5ef5d4fc304d3824aaa7beb19b1.png)'
- en: LSTM architecture is built on RNNs **[1]**
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM架构基于RNN，**[1]**
- en: '**N-BEATS** (Neural Basis Expansion Analysis for Time Series) represents a
    non-recurrent architecture renowned for its ability to accurately forecast multiple
    time series. Constructed with distinct building blocks, it adopts a hierarchical
    structure wherein each block specialises in forecasting a specific horizon. The
    “backcast” block delves into the historical horizon, while the “forecast” block
    focuses on predicting future periods, which might vary in size.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**N-BEATS**（时间序列的神经基础扩展分析）代表了一种非递归架构，以其准确预测多个时间序列的能力而闻名。该模型由不同的构建模块组成，采用层次化结构，其中每个模块专门负责预测特定的时间范围。
    “回溯”模块深入历史时间范围，而“预测”模块则专注于预测未来的时间段，这些时间段的长度可能不同。'
- en: '![](../Images/111c8a4dd4deeb5c0524e170e7a55906.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/111c8a4dd4deeb5c0524e170e7a55906.png)'
- en: N-BEATS look-back and forecast horizons may differ in size **[2]**
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS的回溯窗口和预测时间范围可能具有不同的大小**[2]**
- en: '![](../Images/2bbb57d8b26c59c0414a6df3c507d82e.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2bbb57d8b26c59c0414a6df3c507d82e.png)'
- en: N-BEATS architecture **[2]**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS架构**[2]**
- en: '![](../Images/dd8de56ec473f89ccbec96981f92f6fb.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd8de56ec473f89ccbec96981f92f6fb.png)'
- en: N-BEATS architecture of each stack (left) and each block within each stack (right)
    **[2]**
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS架构中的每个堆栈（左）和每个堆栈内的每个块（右）**[2]**
- en: N-BEATS excels in modelling seasonality by decomposing the series into trend
    and seasonality, akin to the approach taken by STL (Seasonal-Trend decomposition
    using LOESS). This decomposition allows the model to capture both short-term fluctuations
    (seasonality) and long-term trends separately. It utilises Fast Fourier transform
    to effectively model seasonality, a pivotal component in time series analysis.
    N-BEATS is designed to be robust to different types of seasonality patterns, including
    regular and irregular patterns.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS在建模季节性方面表现突出，它通过将时间序列分解为趋势和季节性，类似于STL（基于LOESS的季节性趋势分解）方法。这种分解方法使得模型能够分别捕捉短期波动（季节性）和长期趋势。它利用快速傅里叶变换（Fast
    Fourier Transform）有效建模季节性，这是时间序列分析中的一个关键组成部分。N-BEATS被设计为能够适应不同类型的季节性模式，包括规律性和不规律性模式。
- en: Practical example
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际示例
- en: To better understand the theoretical concepts discussed above, let’s delve into
    a practical example by applying both models. Initially, we’ll generate synthetic
    data at a daily frequency, featuring an ascending trend and seasonality patterns.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解上述理论概念，让我们通过应用两种模型来深入探讨一个实际的例子。首先，我们将生成具有上升趋势和季节性模式的每日频率合成数据。
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The simulated data appears as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟数据如下所示：
- en: '![](../Images/918cbd7e9a9a1c60336653338cc19873.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/918cbd7e9a9a1c60336653338cc19873.png)'
- en: Synthetic time-series data
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 合成时间序列数据
- en: The dataset exhibits seasonality, an ascending trend, and noise, making accurate
    forecasting challenging for most models. This difficulty arises because many models
    specialise in identifying either long-term or short-term patterns individually.
    Consequently, accurately predicting this data requires a model capable of capturing
    both types of patterns simultaneously. To facilitate this, the data has been scaled
    to ensure compatibility with an LSTM model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集展示了季节性、上升趋势和噪声，使得大多数模型很难进行准确的预测。这一难点源于许多模型专门识别长期或短期的模式，通常是各自独立的。因此，准确预测这类数据需要一个能够同时捕捉这两种模式的模型。为此，数据已被缩放，以确保与LSTM模型兼容。
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The model for this dataset was trained in 23 seconds. The test set and predictions
    cover the period after January 1st, 2022\. Here are the forecasted values:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的模型训练用了23秒。测试集和预测覆盖了2022年1月1日之后的时间段。以下是预测的值：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/2fc38115dc852fb4ab1814b60fe30c4a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2fc38115dc852fb4ab1814b60fe30c4a.png)'
- en: LSTM predictions within the test set
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM模型对测试集的预测
- en: '![](../Images/5349877e2859c072600d8185b0a7aad9.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5349877e2859c072600d8185b0a7aad9.png)'
- en: LSTM predictions within the entire dataset
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM模型对整个数据集的预测
- en: The forecasts appear to capture the ascending trend and seasonality effectively,
    which is promising. However, there seems to be a significant amount of noise in
    the predictions. Moreover, as the forecast horizon extends further, deviations
    from the test data become noticeable.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 预测结果似乎有效地捕捉到了上升趋势和季节性，这令人乐观。然而，预测中似乎存在相当大的噪声。此外，随着预测范围的延长，预测值与测试数据之间的偏差变得明显。
- en: 'Now, let’s assess the Weighted Absolute Percentage Error (WAPE):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们评估加权绝对百分比误差（WAPE）：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The results are indeed promising.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 结果确实很有前景。
- en: Next, let’s explore fitting an N-BEATS model to the same dataset and examine
    its performance.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探索如何将N-BEATS模型拟合到相同的数据集，并检查其性能。
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The N-BEATS model was trained in 83 seconds, which, although fast, is slower
    than the LSTM model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS模型在83秒内完成了训练，虽然速度较快，但仍然比LSTM模型慢。
- en: Now, let’s examine the predictions generated by the N-BEATS model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看N-BEATS模型生成的预测。
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/5793207e79e22f0a125334e38873eef2.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5793207e79e22f0a125334e38873eef2.png)'
- en: N-BEATS predictions within the test set
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS在测试集中的预测
- en: '![](../Images/d8f833e2eee729cefde99d30afc8e5d8.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8f833e2eee729cefde99d30afc8e5d8.png)'
- en: N-BEATS predictions within the entire dataset
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS在整个数据集中的预测
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Both models demonstrate high accuracy according to the chosen metric. Interestingly,
    the forecasts generated by N-BEATS do not seem to deteriorate as we approach the
    end of the forecasting horizon. This suggests that N-BEATS could be particularly
    suitable for projects requiring long-term forecasts.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 两个模型根据所选指标展示了高准确性。有趣的是，N-BEATS生成的预测似乎并不会随着预测时间段的结束而恶化。这表明N-BEATS可能特别适合需要长期预测的项目。
- en: Summary
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: N-BEATS and LSTM bring unique strengths to the forecasting domain. N-BEATS excels
    in its ability to capture diverse patterns for longer horizons, while being highly
    interpretable. On the other hand, LSTM is a fast, stable and complex neural network
    mechanism which achieves accurate predictions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS和LSTM为预测领域带来了独特的优势。N-BEATS在捕捉长期预测中的多样模式方面表现突出，同时具有较高的可解释性。而LSTM则是一个快速、稳定且复杂的神经网络机制，能够实现准确的预测。
- en: References
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Unless otherwise noted, all images have been generated by the author'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图像均由作者生成'
- en: '**[1]** Van Houdt, Greg & Mosquera, Carlos & Nápoles, Gonzalo. (2020). A Review
    on the Long Short-Term Memory Model. Artificial Intelligence Review. 53\. 10.1007/s10462–020–09838–1.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**[1]** Van Houdt, Greg & Mosquera, Carlos & Nápoles, Gonzalo. (2020). 长短期记忆模型综述。人工智能评论。53。10.1007/s10462–020–09838–1.'
- en: '**[2]** Binte Habib, Adria. (2022). A Detailed Explanation of the workflow
    of N-BEATS Architecture. 10.13140/RG.2.2.36379.34083.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**[2]** Binte Habib, Adria. (2022). N-BEATS架构工作流程的详细解释。10.13140/RG.2.2.36379.34083.'
- en: '[](https://medium.com/mlearning-ai/building-a-neural-network-zoo-from-scratch-the-long-short-term-memory-network-1cec5cf31b7?source=post_page-----ca5fdd20dbc--------------------------------)
    [## Building a Neural Network Zoo From Scratch: The Long Short-Term Memory Network'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/mlearning-ai/building-a-neural-network-zoo-from-scratch-the-long-short-term-memory-network-1cec5cf31b7?source=post_page-----ca5fdd20dbc--------------------------------)
    [## 从零开始构建神经网络动物园：长短期记忆网络'
- en: Long Short-Term Memory (LSTM) networks are one of the most well known types
    of recurrent neural networks. Originally…
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 长短期记忆（LSTM）网络是最著名的递归神经网络类型之一。最初…
- en: medium.com](https://medium.com/mlearning-ai/building-a-neural-network-zoo-from-scratch-the-long-short-term-memory-network-1cec5cf31b7?source=post_page-----ca5fdd20dbc--------------------------------)
    [](https://forecastegy.com/posts/multiple-time-series-forecasting-nbeats-python/?source=post_page-----ca5fdd20dbc--------------------------------)
    [## Multiple Time Series Forecasting With N-BEATS In Python
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/mlearning-ai/building-a-neural-network-zoo-from-scratch-the-long-short-term-memory-network-1cec5cf31b7?source=post_page-----ca5fdd20dbc--------------------------------)
    [](https://forecastegy.com/posts/multiple-time-series-forecasting-nbeats-python/?source=post_page-----ca5fdd20dbc--------------------------------)
    [## 使用N-BEATS进行Python中的多时间序列预测
- en: Imagine having a robust forecasting solution capable of handling multiple time
    series data without relying on complex…
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想象一下拥有一个强大的预测解决方案，能够处理多时间序列数据，而不依赖于复杂的…
- en: forecastegy.com](https://forecastegy.com/posts/multiple-time-series-forecasting-nbeats-python/?source=post_page-----ca5fdd20dbc--------------------------------)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[forecastegy.com](https://forecastegy.com/posts/multiple-time-series-forecasting-nbeats-python/?source=post_page-----ca5fdd20dbc--------------------------------)'
- en: '[Neural forecast — Nixtla](https://nixtlaverse.nixtla.io/neuralforecast/index.html)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[Neural forecast — Nixtla](https://nixtlaverse.nixtla.io/neuralforecast/index.html)'
- en: '[How to scale data for LSTM](https://machinelearningmastery.com/how-to-scale-data-for-long-short-term-memory-networks-in-python/)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何为LSTM缩放数据](https://machinelearningmastery.com/how-to-scale-data-for-long-short-term-memory-networks-in-python/)'
