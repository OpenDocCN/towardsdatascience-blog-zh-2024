- en: 'Decoding Time: Unraveling the Power of LSTM vs. N-BEATS for Accurate Time Series
    Forecasting'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/decoding-time-unraveling-the-power-of-lstm-vs-n-beats-for-accurate-time-series-forecasting-ca5fdd20dbc?source=collection_archive---------11-----------------------#2024-04-19](https://towardsdatascience.com/decoding-time-unraveling-the-power-of-lstm-vs-n-beats-for-accurate-time-series-forecasting-ca5fdd20dbc?source=collection_archive---------11-----------------------#2024-04-19)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/7f89a7d4b8fac9fdb276d5798b65164e.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aron Visuals](https://unsplash.com/@aronvisuals?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/selective-focus-photo-of-brown-and-blue-hourglass-on-stones-BXOXnQ26B7o?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: Comparing how two deep learning models perform short-term and long-term
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)[![Frida
    Karvouni](../Images/49aad19f6bdd7ffdc68c212722079c6f.png)](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)
    [Frida Karvouni](https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------)
    ·6 min read·Apr 19, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Time series forecasting plays a pivotal role across various domains by facilitating
    predictions of future trends. This exploration focuses on two prominent deep learning
    models, delving into their respective strengths and weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: '**LSTM** (Long Short-Term Memory) stands out as a specialised variant of RNN,
    adept at capturing patterns characterised by long-term dependencies in sequential
    data. It enhances traditional RNNs by effectively addressing the vanishing gradient
    problem, allowing for the modelling of extended dependencies. LSTM achieves this
    by selectively retaining or forgetting information over time through the incorporation
    of memory cells and gating mechanisms, including input, output, and forget gates.
    An inherent limitation of LSTM models is that the forecasting horizon must align
    with the length of the input sequences utilised during training.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c70ad5ef5d4fc304d3824aaa7beb19b1.png)'
  prefs: []
  type: TYPE_IMG
- en: LSTM architecture is built on RNNs **[1]**
  prefs: []
  type: TYPE_NORMAL
- en: '**N-BEATS** (Neural Basis Expansion Analysis for Time Series) represents a
    non-recurrent architecture renowned for its ability to accurately forecast multiple
    time series. Constructed with distinct building blocks, it adopts a hierarchical
    structure wherein each block specialises in forecasting a specific horizon. The
    “backcast” block delves into the historical horizon, while the “forecast” block
    focuses on predicting future periods, which might vary in size.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/111c8a4dd4deeb5c0524e170e7a55906.png)'
  prefs: []
  type: TYPE_IMG
- en: N-BEATS look-back and forecast horizons may differ in size **[2]**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2bbb57d8b26c59c0414a6df3c507d82e.png)'
  prefs: []
  type: TYPE_IMG
- en: N-BEATS architecture **[2]**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dd8de56ec473f89ccbec96981f92f6fb.png)'
  prefs: []
  type: TYPE_IMG
- en: N-BEATS architecture of each stack (left) and each block within each stack (right)
    **[2]**
  prefs: []
  type: TYPE_NORMAL
- en: N-BEATS excels in modelling seasonality by decomposing the series into trend
    and seasonality, akin to the approach taken by STL (Seasonal-Trend decomposition
    using LOESS). This decomposition allows the model to capture both short-term fluctuations
    (seasonality) and long-term trends separately. It utilises Fast Fourier transform
    to effectively model seasonality, a pivotal component in time series analysis.
    N-BEATS is designed to be robust to different types of seasonality patterns, including
    regular and irregular patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Practical example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To better understand the theoretical concepts discussed above, let’s delve into
    a practical example by applying both models. Initially, we’ll generate synthetic
    data at a daily frequency, featuring an ascending trend and seasonality patterns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The simulated data appears as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/918cbd7e9a9a1c60336653338cc19873.png)'
  prefs: []
  type: TYPE_IMG
- en: Synthetic time-series data
  prefs: []
  type: TYPE_NORMAL
- en: The dataset exhibits seasonality, an ascending trend, and noise, making accurate
    forecasting challenging for most models. This difficulty arises because many models
    specialise in identifying either long-term or short-term patterns individually.
    Consequently, accurately predicting this data requires a model capable of capturing
    both types of patterns simultaneously. To facilitate this, the data has been scaled
    to ensure compatibility with an LSTM model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The model for this dataset was trained in 23 seconds. The test set and predictions
    cover the period after January 1st, 2022\. Here are the forecasted values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2fc38115dc852fb4ab1814b60fe30c4a.png)'
  prefs: []
  type: TYPE_IMG
- en: LSTM predictions within the test set
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5349877e2859c072600d8185b0a7aad9.png)'
  prefs: []
  type: TYPE_IMG
- en: LSTM predictions within the entire dataset
  prefs: []
  type: TYPE_NORMAL
- en: The forecasts appear to capture the ascending trend and seasonality effectively,
    which is promising. However, there seems to be a significant amount of noise in
    the predictions. Moreover, as the forecast horizon extends further, deviations
    from the test data become noticeable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s assess the Weighted Absolute Percentage Error (WAPE):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The results are indeed promising.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s explore fitting an N-BEATS model to the same dataset and examine
    its performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The N-BEATS model was trained in 83 seconds, which, although fast, is slower
    than the LSTM model.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s examine the predictions generated by the N-BEATS model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5793207e79e22f0a125334e38873eef2.png)'
  prefs: []
  type: TYPE_IMG
- en: N-BEATS predictions within the test set
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d8f833e2eee729cefde99d30afc8e5d8.png)'
  prefs: []
  type: TYPE_IMG
- en: N-BEATS predictions within the entire dataset
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Both models demonstrate high accuracy according to the chosen metric. Interestingly,
    the forecasts generated by N-BEATS do not seem to deteriorate as we approach the
    end of the forecasting horizon. This suggests that N-BEATS could be particularly
    suitable for projects requiring long-term forecasts.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: N-BEATS and LSTM bring unique strengths to the forecasting domain. N-BEATS excels
    in its ability to capture diverse patterns for longer horizons, while being highly
    interpretable. On the other hand, LSTM is a fast, stable and complex neural network
    mechanism which achieves accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Unless otherwise noted, all images have been generated by the author'
  prefs: []
  type: TYPE_NORMAL
- en: '**[1]** Van Houdt, Greg & Mosquera, Carlos & Nápoles, Gonzalo. (2020). A Review
    on the Long Short-Term Memory Model. Artificial Intelligence Review. 53\. 10.1007/s10462–020–09838–1.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[2]** Binte Habib, Adria. (2022). A Detailed Explanation of the workflow
    of N-BEATS Architecture. 10.13140/RG.2.2.36379.34083.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/mlearning-ai/building-a-neural-network-zoo-from-scratch-the-long-short-term-memory-network-1cec5cf31b7?source=post_page-----ca5fdd20dbc--------------------------------)
    [## Building a Neural Network Zoo From Scratch: The Long Short-Term Memory Network'
  prefs: []
  type: TYPE_NORMAL
- en: Long Short-Term Memory (LSTM) networks are one of the most well known types
    of recurrent neural networks. Originally…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/mlearning-ai/building-a-neural-network-zoo-from-scratch-the-long-short-term-memory-network-1cec5cf31b7?source=post_page-----ca5fdd20dbc--------------------------------)
    [](https://forecastegy.com/posts/multiple-time-series-forecasting-nbeats-python/?source=post_page-----ca5fdd20dbc--------------------------------)
    [## Multiple Time Series Forecasting With N-BEATS In Python
  prefs: []
  type: TYPE_NORMAL
- en: Imagine having a robust forecasting solution capable of handling multiple time
    series data without relying on complex…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: forecastegy.com](https://forecastegy.com/posts/multiple-time-series-forecasting-nbeats-python/?source=post_page-----ca5fdd20dbc--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[Neural forecast — Nixtla](https://nixtlaverse.nixtla.io/neuralforecast/index.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to scale data for LSTM](https://machinelearningmastery.com/how-to-scale-data-for-long-short-term-memory-networks-in-python/)'
  prefs: []
  type: TYPE_NORMAL
