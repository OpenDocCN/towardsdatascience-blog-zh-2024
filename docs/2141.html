<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Diving Deeper with Structured Outputs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Diving Deeper with Structured Outputs</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://towardsdatascience.com/diving-deeper-with-structured-outputs-b4a5d280c208?source=collection_archive---------1-----------------------#2024-09-03">https://towardsdatascience.com/diving-deeper-with-structured-outputs-b4a5d280c208?source=collection_archive---------1-----------------------#2024-09-03</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="90d4" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Helping enhance your understanding and optimal usage of structured outputs and LLMs</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@armin.catovic?source=post_page---byline--b4a5d280c208--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Armin Catovic" class="l ep by dd de cx" src="../Images/046042098f3fec885e756f7f8ee94e6a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*mbpGpAHB8ZUfLAYgsZpR_Q.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--b4a5d280c208--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@armin.catovic?source=post_page---byline--b4a5d280c208--------------------------------" rel="noopener follow">Armin Catovic</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--b4a5d280c208--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div><span data-testid="storyPublishDate">Sep 3, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ml"><img src="../Images/2d1b5f51320c152d86373c947974ac13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FqIcJfcTCAxBpHlTC10tdw.png"/></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Figure 1 ‚Äî steps that are executed both explicitly, as well as implicitly, from the user‚Äôs perspective, when applying structured outputs; image by the author</figcaption></figure><p id="c642" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">In the <a class="af nu" href="https://medium.com/towards-data-science/structured-outputs-and-how-to-use-them-40bd86881d39" rel="noopener">previous article</a>, we were introduced to <strong class="na fr">structured outputs</strong> using OpenAI. Since the general availability release in ChatCompletions API (<a class="af nu" href="https://github.com/openai/openai-python/releases/tag/v1.40.0" rel="noopener ugc nofollow" target="_blank">v1.40.0</a>), structured outputs have been applied across dozens of use cases, and spawned numerous threads on <a class="af nu" href="https://community.openai.com/" rel="noopener ugc nofollow" target="_blank">OpenAI forums</a>.</p><p id="4f5a" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">In this article, our aim is to provide you with an even deeper understanding, dispel some misconceptions, and give you some tips on how to apply them in the most optimal manner possible, across different scenarios.</p><h1 id="d5bb" class="nv nw fq bf nx ny nz gq oa ob oc gt od oe of og oh oi oj ok ol om on oo op oq bk">Structured outputs overview</h1><p id="40fe" class="pw-post-body-paragraph my mz fq na b go or nc nd gr os nf ng nh ot nj nk nl ou nn no np ov nr ns nt fj bk">Structured outputs are a way of enforcing the output of an LLM to follow a pre-defined schema ‚Äî usually a JSON schema. This works by transforming the schema into a <a class="af nu" href="https://en.wikipedia.org/wiki/Context-free_grammar" rel="noopener ugc nofollow" target="_blank">context free grammar (CFG)</a>, which during the token sampling step, is used together with the previously generated tokens, to inform which subsequent tokens are valid. It‚Äôs helpful to think of it as creating a <a class="af nu" href="https://en.wikipedia.org/wiki/Regular_expression" rel="noopener ugc nofollow" target="_blank">regex</a> for token generation.</p><p id="1f84" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">OpenAI API implementation actually tracks a limited subset of JSON schema features. With more general structured output solutions, such as <a class="af nu" href="https://github.com/outlines-dev/outlines" rel="noopener ugc nofollow" target="_blank">Outlines</a>, it is possible to use a somewhat larger subset of the JSON schema, and even define completely custom non-JSON schemas ‚Äî as long as one has access to an open weight model. For the purpose of this article, we will assume the OpenAI API implementation.</p><h1 id="0d71" class="nv nw fq bf nx ny nz gq oa ob oc gt od oe of og oh oi oj ok ol om on oo op oq bk">JSON Schema and Pydantic</h1><p id="4645" class="pw-post-body-paragraph my mz fq na b go or nc nd gr os nf ng nh ot nj nk nl ou nn no np ov nr ns nt fj bk">According to <a class="af nu" href="https://json-schema.org/draft/2020-12/json-schema-core" rel="noopener ugc nofollow" target="_blank">JSON Schema Core Specification</a>, <em class="ow">‚ÄúJSON Schema asserts what a JSON document must look like, ways to extract information from it, and how to interact with it‚Äù</em>. JSON schema defines six primitive types ‚Äî null, boolean, object, array, number and string. It also defines certain keywords, annotations, and specific behaviours. For example, we can specify in our schema that we expect an <code class="cx ox oy oz pa b">array</code> and add an annotation that <code class="cx ox oy oz pa b">minItems</code> shall be <code class="cx ox oy oz pa b">5</code> .</p><p id="f6e0" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">Pydantic is a Python library that implements the JSON schema specification. We use Pydantic to build robust and maintainable software in Python. Since Python is a dynamically typed language, data scientists do not necessarily think in terms of <strong class="na fr">variable types</strong> ‚Äî these are often <strong class="na fr">implied</strong> in their code. For example, a fruit would be specified as:</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="933a" class="pe nw fq pa b bg pf pg l ph pi">fruit = dict(<br/>  name="apple",<br/>  color="red",<br/>  weight=4.2<br/>)</span></pre><p id="c983" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">‚Ä¶while a function declaration that returns ‚Äúfruit‚Äù from some piece of data would often be specified as:</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="0475" class="pe nw fq pa b bg pf pg l ph pi">def extract_fruit(s):<br/>  ...<br/>  return fruit</span></pre><p id="aa3d" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">Pydantic on the other hand allows us to generate a JSON-schema compliant class, with properly annotated variables and <strong class="na fr">type hints</strong>, making our code more readable/maintainable and in general more robust, i.e.</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="5ea4" class="pe nw fq pa b bg pf pg l ph pi">class Fruit(BaseModel):<br/>    name: str<br/>    color: Literal['red', 'green']<br/>    weight: Annotated[float, Gt(0)]<br/><br/><br/>def extract_fruit(s: str) -&gt; Fruit:<br/>  ...<br/>  return fruit</span></pre><p id="f884" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">OpenAI actually <a class="af nu" href="https://platform.openai.com/docs/guides/structured-outputs/avoid-json-schema-divergence" rel="noopener ugc nofollow" target="_blank">strongly recommends</a> the use of Pydantic for specifying schemas, as opposed to specifying the ‚Äúraw‚Äù JSON schema directly. There are several reasons for this. Firstly, Pydantic is guaranteed to adhere to the JSON schema specification, so it saves you extra pre-validation steps. Secondly, for larger schemas, it is less verbose, allowing you to write cleaner code, faster. Finally, the <code class="cx ox oy oz pa b">openai</code> Python package actually does some housekeeping, like setting <code class="cx ox oy oz pa b">additionalProperties</code> to <code class="cx ox oy oz pa b">False</code> for you, whereas when defining your schema ‚Äúby-hand‚Äù using JSON, you would need to <a class="af nu" href="https://platform.openai.com/docs/guides/structured-outputs/additionalproperties-false-must-always-be-set-in-objects" rel="noopener ugc nofollow" target="_blank">set these manually</a>, for every object in your schema (failing to do so results in a rather annoying API error).</p><h1 id="71e7" class="nv nw fq bf nx ny nz gq oa ob oc gt od oe of og oh oi oj ok ol om on oo op oq bk">Limitations</h1><p id="4b42" class="pw-post-body-paragraph my mz fq na b go or nc nd gr os nf ng nh ot nj nk nl ou nn no np ov nr ns nt fj bk">As we alluded to previously, the ChatCompletions API provides a limited subset of the full JSON schema specification. There are numerous <a class="af nu" href="https://platform.openai.com/docs/guides/structured-outputs/some-type-specific-keywords-are-not-yet-supported" rel="noopener ugc nofollow" target="_blank">keywords that are not yet supported</a>, such as <code class="cx ox oy oz pa b">minimum</code> and <code class="cx ox oy oz pa b">maximum</code> for numbers, and <code class="cx ox oy oz pa b">minItems</code> and <code class="cx ox oy oz pa b">maxItems</code> for arrays ‚Äî annotations that would be otherwise very useful in reducing hallucinations, or constraining the output size.</p><p id="b0fa" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">Certain formatting features are also unavailable. For example, the following Pydantic schema would result in API error when passed to <code class="cx ox oy oz pa b">response_format</code> in ChatCompletions:</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="3e47" class="pe nw fq pa b bg pf pg l ph pi">class NewsArticle(BaseModel):<br/>  headline: str<br/>  subheading: str<br/>  authors: List[str]<br/>  date_published: datetime = Field(None, description="Date when article was published. Use ISO 8601 date format.")</span></pre><p id="39e6" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">It would fail because <code class="cx ox oy oz pa b">openai</code> package has no format handling for <code class="cx ox oy oz pa b">datetime</code> , so instead you would need to set <code class="cx ox oy oz pa b">date_published</code> as a <code class="cx ox oy oz pa b">str</code> and perform format validation (e.g. ISO 8601 compliance) post-hoc.</p><p id="402e" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">Other key limitations include the following:</p><ul class=""><li id="c4de" class="my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt pj pk pl bk"><strong class="na fr">Hallucinations are still possible </strong>‚Äî for example, when extracting product IDs, you would define in your response schema the following: <code class="cx ox oy oz pa b">product_ids: List[str]</code> ; while the output is guaranteed to produce a list of strings (product IDs), the strings themselves may be hallucinated, so in this use case, you may want to validate the output against some pre-defined set of product IDs.</li><li id="4516" class="my mz fq na b go pm nc nd gr pn nf ng nh po nj nk nl pp nn no np pq nr ns nt pj pk pl bk"><strong class="na fr">The output is capped</strong> at 16,384 tokens (<strong class="na fr">NOTE:</strong> thanks Peter Edmonds for the correction!), or the lesser number you set within the <code class="cx ox oy oz pa b">max_tokens</code> parameter ‚Äî so even though the schema will be followed precisely, if the output is too large, it will be truncated and produce an invalid JSON ‚Äî especially annoying on very large <a class="af nu" href="https://platform.openai.com/docs/guides/batch" rel="noopener ugc nofollow" target="_blank">Batch API</a> jobs!</li><li id="b265" class="my mz fq na b go pm nc nd gr pn nf ng nh po nj nk nl pp nn no np pq nr ns nt pj pk pl bk"><strong class="na fr">Deeply nested schemas with many object properties</strong> may yield API errors ‚Äî there is a <a class="af nu" href="https://platform.openai.com/docs/guides/structured-outputs/objects-have-limitations-on-nesting-depth-and-size" rel="noopener ugc nofollow" target="_blank">limitation on the depth and breadth</a> of your schema, but in general it is best to stick to flat and simple structures‚Äî not just to avoid API errors but also to squeeze out as much performance from the LLMs as possible (LLMs in general have trouble attending to deeply nested structures).</li><li id="5de3" class="my mz fq na b go pm nc nd gr pn nf ng nh po nj nk nl pp nn no np pq nr ns nt pj pk pl bk"><strong class="na fr">Highly dynamic or arbitrary schemas are not possible</strong> ‚Äî even though <a class="af nu" href="https://platform.openai.com/docs/guides/structured-outputs/recursive-schemas-are-supported" rel="noopener ugc nofollow" target="_blank">recursion is supported</a>, it is not possible to create a highly dynamic schema of let‚Äôs say, a list of arbitrary key-value objects, i.e. <code class="cx ox oy oz pa b">[{"key1": "val1"}, {"key2": "val2"}, ..., {"keyN": "valN"}]</code> , since the ‚Äúkeys‚Äù in this case <strong class="na fr">must</strong> be pre-defined; in such a scenario, the best option is not to use structured outputs at all, but instead opt for standard JSON mode, and provide the instructions on the output structure within the system prompt.</li></ul><h1 id="3a2e" class="nv nw fq bf nx ny nz gq oa ob oc gt od oe of og oh oi oj ok ol om on oo op oq bk">Tips and tricks</h1><p id="7643" class="pw-post-body-paragraph my mz fq na b go or nc nd gr os nf ng nh ot nj nk nl ou nn no np ov nr ns nt fj bk">With all this in mind, we can now go through a couple of use cases with tips and tricks on how to enhance the performance when using structured outputs.</p><h2 id="1bd0" class="pr nw fq bf nx ps pt pu oa pv pw px od nh py pz qa nl qb qc qd np qe qf qg qh bk">Creating flexibility using optional parameters</h2><p id="e26e" class="pw-post-body-paragraph my mz fq na b go or nc nd gr os nf ng nh ot nj nk nl ou nn no np ov nr ns nt fj bk">Let‚Äôs say we are building a web scraping application where our goal is to collect specific components from the web pages. For each web page, we supply the raw HTML in the user prompt, give specific scraping instructions in the system prompt, and define the following Pydantic model:</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="e77c" class="pe nw fq pa b bg pf pg l ph pi">class Webpage(BaseModel):<br/>    title: str<br/>    paragraphs: Optional[List[str]] = Field(None, description="Text contents enclosed within &lt;p&gt;&lt;/p&gt; tags.")<br/>    links: Optional[List[str]] = Field(None, description="URLs specified by `href` field within &lt;a&gt;&lt;/a&gt; tags.")<br/>    images: Optional[List[str]] = Field(None, description="URLs specified by the `src` field within the &lt;img&gt;&lt;/img&gt; tags.")</span></pre><p id="97a4" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">We would then call the API as follows‚Ä¶</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="bd98" class="pe nw fq pa b bg pf pg l ph pi">response = client.beta.chat.completions.parse(<br/>    model="gpt-4o-2024-08-06",<br/>    messages=[<br/>        {<br/>            "role": "system",<br/>            "content": "You are to parse HTML and return the parsed page components."<br/>        },<br/>        {<br/>            "role": "user",<br/>            "content": """<br/>            &lt;html&gt;<br/>            &lt;title&gt;Structured Outputs Demo&lt;/title&gt;<br/>            &lt;body&gt;<br/>            &lt;img src="test.gif"&gt;&lt;/image&gt;<br/>            &lt;p&gt;Hello world!&lt;/p&gt;<br/>            &lt;/body&gt;<br/>            &lt;/html&gt;<br/>            """<br/>        }<br/>    ],<br/>    response_format=Webpage<br/>)</span></pre><p id="9a47" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">‚Ä¶with the following response:</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="e13a" class="pe nw fq pa b bg pf pg l ph pi">{<br/>  'images': ['test.gif'],<br/>  'links': None,<br/>  'paragraphs': ['Hello world!'],<br/>  'title': 'Structured Outputs Demo'<br/>}</span></pre><p id="3add" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">Response schema supplied to the API using structured outputs <strong class="na fr">must</strong> return all the specified fields. However, we can ‚Äúemulate‚Äù optional fields and add more flexibility using the <code class="cx ox oy oz pa b">Optional</code> type annotation. We could actually also use <code class="cx ox oy oz pa b">Union[List[str], None]</code> ‚Äî they are syntactically exactly the same. In both cases, we get a conversion to <code class="cx ox oy oz pa b">anyOf</code> keyword as per the JSON schema spec. In the example above, since there are no <code class="cx ox oy oz pa b">&lt;a&gt;&lt;/a&gt;</code> tags present on the web page, the API still returns the <code class="cx ox oy oz pa b">links</code> field, but it is set to <code class="cx ox oy oz pa b">None</code> .</p><h2 id="6d6f" class="pr nw fq bf nx ps pt pu oa pv pw px od nh py pz qa nl qb qc qd np qe qf qg qh bk">Reducing hallucinations using enums and a two-phased approach</h2><p id="b8cd" class="pw-post-body-paragraph my mz fq na b go or nc nd gr os nf ng nh ot nj nk nl ou nn no np ov nr ns nt fj bk">We mentioned previously that even if the LLM is guaranteed to follow the provided response schema, it may still hallucinate the actual values. Adding to this, a <a class="af nu" href="https://arxiv.org/pdf/2408.02442v1" rel="noopener ugc nofollow" target="_blank">recent paper</a> found that enforcing a fixed schema on the outputs, actually causes the LLM to hallucinate, or degrade in terms of its reasoning capabilities (interestingly enough, classification performance improves ü§î).</p><p id="9528" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">One way to overcome these limitations, is to try and utilize enums as much as possible. Enums constrain the output to a very specific set of tokens, placing a probability of zero on everything else. For example, let‚Äôs assume you are trying to re-rank product similarity results between a <strong class="na fr">target product</strong> that contains a <code class="cx ox oy oz pa b">description</code> and a unique <code class="cx ox oy oz pa b">product_id</code> , and <strong class="na fr">top-5 products</strong> that were obtained using some vector similarity search (e.g. using a cosine distance metric). Each one of those top-5 products also contain the corresponding textual description and a unique ID. In your response you simply wish to obtain the re-ranking 1‚Äì5 as a list (e.g. <code class="cx ox oy oz pa b">[1, 4, 3, 5, 2]</code> ), instead of getting a list of re-ranked product ID strings, which may be hallucinated or invalid. We setup our Pydantic model as follows‚Ä¶</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="8b80" class="pe nw fq pa b bg pf pg l ph pi">class Rank(IntEnum):<br/>    RANK_1 = 1<br/>    RANK_2 = 2<br/>    RANK_3 = 3<br/>    RANK_4 = 4<br/>    RANK_5 = 5<br/><br/>class RerankingResult(BaseModel):<br/>    ordered_ranking: List[Rank] = Field(description="Provides ordered ranking 1-5.")</span></pre><p id="eaaf" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">‚Ä¶and run the API like so:</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="6855" class="pe nw fq pa b bg pf pg l ph pi">response = client.beta.chat.completions.parse(<br/>    model="gpt-4o-2024-08-06",<br/>    messages=[<br/>        {<br/>            "role": "system",<br/>            "content": """<br/>            You are to rank the similarity of the candidate products against the target product.<br/>            Ranking should be orderly, from the most similar, to the least similar.<br/>            """<br/>        },<br/>        {<br/>            "role": "user",<br/>            "content": """<br/>            ## Target Product<br/>            Product ID: X56HHGHH<br/>            Product Description: 80" Samsung LED TV<br/><br/>            ## Candidate Products<br/>            Product ID: 125GHJJJGH<br/>            Product Description: NVIDIA RTX 4060 GPU<br/><br/>            Product ID: 76876876GHJ<br/>            Product Description: Sony Walkman<br/><br/>            Product ID: 433FGHHGG<br/>            Product Description: Sony LED TV 56"<br/><br/>            Product ID: 777888887888<br/>            Product Description: Blueray Sony Player<br/><br/>            Product ID: JGHHJGJ56<br/>            Product Description: BenQ PC Monitor 37" 4K UHD<br/>            """<br/>        }<br/>    ],<br/>    response_format=RerankingResult<br/>)</span></pre><p id="6648" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">The final result is simply:</p><pre class="mm mn mo mp mq pb pa pc bp pd bb bk"><span id="3c46" class="pe nw fq pa b bg pf pg l ph pi">{'ordered_ranking': [3, 5, 1, 4, 2]}</span></pre><p id="2ba7" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">So the LLM ranked the Sony LED TV (i.e. item number ‚Äú3‚Äù in the list), and the BenQ PC Monitor (i.e. item number ‚Äú5‚Äù), as the two most similar product candidates, i.e. the first two elements of the <code class="cx ox oy oz pa b">ordered_ranking</code> list!</p><p id="0439" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">In theory, enums should completely eliminate hallucinations across those specific fields, since only the tokens specified in the enum set will pass through the token mask, i.e. all other tokens will have a probability of zero. However, users have also <a class="af nu" href="https://community.openai.com/t/structured-outputs-deep-dive/930169/18" rel="noopener ugc nofollow" target="_blank">reported seeing hallucinations even across enums</a>, particularly on the ‚Äúmini‚Äù models.</p><p id="256f" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">So another approach is a <strong class="na fr">two-phased approach</strong>, which is in line with the findings of the <a class="af nu" href="https://arxiv.org/pdf/2408.02442v1" rel="noopener ugc nofollow" target="_blank">aforementioned paper</a>:</p><ol class=""><li id="cbea" class="my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt qi pk pl bk">Send a reasoning/extraction task to the mini model <strong class="na fr">without</strong> enforcing structure, i.e. the response will be a flat string.</li><li id="d548" class="my mz fq na b go pm nc nd gr pn nf ng nh po nj nk nl pp nn no np pq nr ns nt qi pk pl bk">Create a 2nd request to the mini model, this time sending the output of the previous step, together with the response schema</li></ol><p id="9fe9" class="pw-post-body-paragraph my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt fj bk">Using this approach we separate out the task into a reasoning step, and a structuring step.</p><h1 id="ff68" class="nv nw fq bf nx ny nz gq oa ob oc gt od oe of og oh oi oj ok ol om on oo op oq bk">Conclusion</h1><p id="9f51" class="pw-post-body-paragraph my mz fq na b go or nc nd gr os nf ng nh ot nj nk nl ou nn no np ov nr ns nt fj bk">In this article we gave a thorough deep-dive into structured outputs. We introduced the JSON schema and Pydantic models, and connected these to OpenAI‚Äôs ChatCompletions API. We walked through a number of examples and showcased some optimal ways of resolving those using structured outputs. To summarize some key takeaways:</p><ul class=""><li id="b516" class="my mz fq na b go nb nc nd gr ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt pj pk pl bk">Structured outputs as supported by OpenAI API, and other 3rd party frameworks, implement only a <strong class="na fr">subset of the JSON schema specification </strong>‚Äî getting better informed in terms of its features and limitations will help you make the right design decisions.</li><li id="e665" class="my mz fq na b go pm nc nd gr pn nf ng nh po nj nk nl pp nn no np pq nr ns nt pj pk pl bk">Using <strong class="na fr">Pydantic</strong> or similar frameworks that track JSON schema specification faithfully, is highly recommended, as it allows you to create valid and cleaner code.</li><li id="e07e" class="my mz fq na b go pm nc nd gr pn nf ng nh po nj nk nl pp nn no np pq nr ns nt pj pk pl bk">Whilst hallucinations are still expected, there are different ways of mitigating those, either by a choice of response schema design; for example, by <strong class="na fr">utilizing enums</strong> where appropriate; or by creating a <strong class="na fr">two-phased approach</strong> where we send two API requests ‚Äî one for reasoning, and the 2nd one simply for output re-structuring.</li></ul><h2 id="0e4d" class="pr nw fq bf nx ps pt pu oa pv pw px od nh py pz qa nl qb qc qd np qe qf qg qh bk">About the Author</h2><p id="7dfd" class="pw-post-body-paragraph my mz fq na b go or nc nd gr os nf ng nh ot nj nk nl ou nn no np ov nr ns nt fj bk"><a class="af nu" href="https://medium.com/@armin.catovic" rel="noopener"><strong class="na fr">Armin Catovic</strong></a> is a Secretary of the Board at <a class="af nu" href="https://www.stockholm.ai/" rel="noopener ugc nofollow" target="_blank">Stockholm AI</a>, and a Vice President and a Senior ML/AI Engineer at the <a class="af nu" href="https://eqtgroup.com/" rel="noopener ugc nofollow" target="_blank">EQT Group</a>, with 18 years of engineering experience across Australia, South-East Asia, Europe and the US, and a number of patents and top-tier peer-reviewed AI publications.</p></div></div></div></div>    
</body>
</html>