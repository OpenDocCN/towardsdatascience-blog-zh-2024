- en: 'PySpark Explained: The explode and collect_list Functions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/pyspark-explained-the-explode-and-collect-list-functions-834f45ff5ac5?source=collection_archive---------11-----------------------#2024-06-18](https://towardsdatascience.com/pyspark-explained-the-explode-and-collect-list-functions-834f45ff5ac5?source=collection_archive---------11-----------------------#2024-06-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/fd0d72b6315cad72a4bb2149198bcb30.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by AI (Dalle-3)
  prefs: []
  type: TYPE_NORMAL
- en: Two useful functions to nest and un-nest data sets in PySpark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@thomas_reid?source=post_page---byline--834f45ff5ac5--------------------------------)[![Thomas
    Reid](../Images/c1b4e5f577272633ba07e5dbfd21c02d.png)](https://medium.com/@thomas_reid?source=post_page---byline--834f45ff5ac5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--834f45ff5ac5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--834f45ff5ac5--------------------------------)
    [Thomas Reid](https://medium.com/@thomas_reid?source=post_page---byline--834f45ff5ac5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--834f45ff5ac5--------------------------------)
    ·9 min read·Jun 18, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: PySpark SQL, the Python interface for SQL in Apache PySpark, is a powerful set
    of tools for data transformation and analysis. Built to emulate the most common
    types of operations that are available in database SQL systems, Pyspark SQL is
    also able to leverage the dataframe paradigm available in Spark to offer additional
    functionality.
  prefs: []
  type: TYPE_NORMAL
- en: In short, Pyspark SQL provides a rich set of functions that enable developers
    to manipulate and process data efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Among these functions, two of the less well-known ones that I want to highlight
    are particularly noteworthy for their ability to transform and aggregate data
    in unique ways. These are the `explode` and `collect_list` operators.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I’ll explain exactly what each of these does and show some
    use cases and sample PySpark code for each.
  prefs: []
  type: TYPE_NORMAL
- en: Explode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The explode function in PySpark SQL is a versatile tool for transforming and
    flattening nested data structures, such as arrays or maps, into individual rows.
    This function is particularly useful when working with complex datasets that contain
    nested collections, as it allows you to analyze and manipulate individual…
  prefs: []
  type: TYPE_NORMAL
