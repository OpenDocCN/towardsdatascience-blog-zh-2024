<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>What Is a Latent Space?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>What Is a Latent Space?</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-a-latent-space-065eb8e3f859?source=collection_archive---------8-----------------------#2024-05-08">https://towardsdatascience.com/what-is-a-latent-space-065eb8e3f859?source=collection_archive---------8-----------------------#2024-05-08</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="14a2" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A Concise explanation for the general reader</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@jaroslaw.drapala?source=post_page---byline--065eb8e3f859--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Jaroslaw Drapala" class="l ep by dd de cx" src="../Images/34de3c52fc32005e36930135254ae45e.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*UOcQjVU5X3yqZH0NoxpOpA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--065eb8e3f859--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@jaroslaw.drapala?source=post_page---byline--065eb8e3f859--------------------------------" rel="noopener follow">Jaroslaw Drapala</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--065eb8e3f859--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 8, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/6459ac32968bd8e1cdb2a456efdfb382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oQbB-rgIHeYThr2u"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Photo by <a class="af nb" href="https://unsplash.com/@lennonzf?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Lennon Cheng</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1a44" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk ny"><span class="l nz oa ob bo oc od oe of og ed">H</span>ave you ever wondered how <strong class="ne fr">generative AI</strong> gets its work done? How does it create images, manage text, and perform other tasks?</p><p id="573b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The crucial concept you really need to understand is <strong class="ne fr">latent space</strong>. Understanding what the latent space is paves the way for comprehending generative AI.</p><p id="54c4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let me walk you through few examples to explain the essence of a latent space.</p><h2 id="3af6" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk"><strong class="al">Example 1.</strong> <em class="pc">Finding a better way to represent heights and weights data.</em></h2><p id="d86d" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Throughout my numerous medical data research projects, I gathered a lot of measurements of patients’ <em class="pi">weights </em>and <em class="pi">heights</em>. The figure below shows the distribution of measurements.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pj"><img src="../Images/cc14590d30b7dffb78a3fb47cca64b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BQO2L5VfyfD-RNaMmD_wqg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Measurements of heights and weights of 11808 cardiac patients.</figcaption></figure><p id="5c6a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can consider each point as a compressed version of information about a real person. All details such as facial features, hairstyle, skin tone, and gender are no longer available, leaving only <em class="pi">weight </em>and <em class="pi">height </em>values.</p><p id="8c9c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Is it possible to reconstruct the original data using only these two values? Sure, if your expectations aren’t too high. You simply need to replace all the discarded information with a standard template object to fill in the gaps. The template object is customized based on the preserved information, which in this case includes only <em class="pi">height </em>and <em class="pi">weight</em>.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pk"><img src="../Images/91a360dbe30c2cfb6da55e9892529b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HvcqMOIGxQg2eaQkIr7RYA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx pl pm pn po b">[Photograph of the author taken by <a class="af nb" href="http://linkedin.com/in/kamilwiniarz" rel="noopener ugc nofollow" target="_blank">Kamil Winiarz</a>]</code></figcaption></figure><p id="db3d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s delve into the space defined by the <em class="pi">height </em>and <em class="pi">weight </em>axes. Consider a point with coordinates of 170 cm for height and 70 kg for weight. Let this point serve as a reference figure and position it at the origin of the axes.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pj"><img src="../Images/0c9587ccaf54e1e9544da41f6f9d78c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZxlLIhjAz5kXs8T_hCoSA.png"/></div></div></figure><p id="7378" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Moving horizontally keeps your <em class="pi">weight </em>constant while altering your <em class="pi">height</em>. Likewise, moving up and down keeps your <em class="pi">height </em>the same but changes your <em class="pi">weight</em>.</p><p id="0cfb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It might seem tricky because when you move in one direction, you have to think about two things simultaneously. Is there a way to improve this?</p><p id="f61a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Take a look at the same dataset colour-coded by <em class="pi">BMI</em>.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pp"><img src="../Images/1fc0ed91cc20c930949c59292c480b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4696P0RBZVyQ4re56BKlSQ.png"/></div></div></figure><p id="0ac0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The colors nearly align with the lines. This suggests that we could consider other axes that might be more convenient for generating human figures.</p><p id="9831" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We might name one of these axes ‘<em class="pi">Zoom</em>’ because it maintains a constant <em class="pi">BMI</em>, with the only change being the scale of the figure. Likewise, the second axis could be labeled <em class="pi">BMI</em>.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pj"><img src="../Images/da371892311df874797e63aa25bb0b33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6mrHP3ZIimtnXgMcVCFPzw.png"/></div></div></figure><p id="3464" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The new axes offer <strong class="ne fr">a more convenient perspective on the data</strong>, making it easier to explore. You can specify a target BMI value and then simply adjust the size of the figure along the ‘<em class="pi">Zoom</em>’ axis.</p><p id="1231" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Looking to add more detail and realism to your figures? Consider additional features, such as <em class="pi">gender</em>, for instance. But from now on, I can’t offer similar visualizations that encompass all aspects of the data due to the lack of dimensions. I’m only able to display the distribution of three selected features: two features are depicted by the positions of points on the axes, with the third being indicated by color.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pj"><img src="../Images/5d32175fb2803768c1d4d1b7ddd3b6f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EDTPVougmR5txZlKuHEBcw.png"/></div></div></figure><p id="4f10" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To improve the previous human figure generator, you can create separate templates for males and females. Then generate a female in yellow-dominant areas and a male where blue prevails.</p><p id="c62a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As more features are taken into account, the figures become increasingly realistic. Notice also that a figure can be generated for every point, even those not present in the dataset.</p><p id="4617" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This is what I would call <em class="pi">a top-down approach</em> to generate synthetic human figures. It involves selecting measurable features and identifying the optimal axes (directions) for exploring the data space. In the machine learning community, the first is called <strong class="ne fr">feature selection</strong>, and the second is termed <strong class="ne fr">feature extraction</strong>. Feature extraction can be carried out using specialized algorithms, e.g., PCA¹ (<strong class="ne fr"><em class="pi">P</em></strong><em class="pi">rincipal </em><strong class="ne fr"><em class="pi">C</em></strong><em class="pi">omponent </em><strong class="ne fr"><em class="pi">A</em></strong><em class="pi">nalysis</em>), allowing the identification of directions that represent the data more naturally.</p><p id="5594" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The mathematical space from which we generate synthetic objects is termed the <strong class="ne fr">latent space</strong> for two reasons. At first, the points (vectors) in this space are simply compressed, imperfect numerical <strong class="ne fr">representations of the original objects</strong>, much like shadows. Secondly, the axes defining the latent space often bear little resemblance to the originally measured features. The second reason will be better demonstrated in the next examples.</p><h2 id="524d" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk"><strong class="al">Example 2.</strong> <em class="pc">Aging of human faces.</em></h2><p id="58c5" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Twoday’s generative AI follows <em class="pi">a bottom-up approach</em>, where both feature selection and extraction are performed automatically from the raw data. Consider a vast dataset comprising images of faces, where the raw features consist of the colors of all pixels in each image, represented as numbers ranging from 0 to 255. A generative model like GAN² (<strong class="ne fr"><em class="pi">G</em></strong><em class="pi">enerative </em><strong class="ne fr"><em class="pi">A</em></strong><em class="pi">dversarial </em><strong class="ne fr"><em class="pi">N</em></strong><em class="pi">etwork</em>) can identify (learn) a low-dimensional set of features where we can find the directions that interest us the most.</p><p id="35e7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Imagine you want to develop an app that takes your image and shows you a younger or older version of yourself. To achieve this, you need to sort all latent space representations of images (latent space vectors) according to age. Then, for each age group, you have to determine the average vector.</p><p id="966e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If all goes well, the average vectors would align along a curve, which you can consider to approximate the age value axis.</p><p id="af0b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, you can determine the latent space representation of your image (<strong class="ne fr">encoding</strong> step) and then move it along the age direction as you wish. Finally, you <strong class="ne fr">decode </strong>it to generate a synthetic image portraying the older (or younger) version of yourself. The idea of the <strong class="ne fr">decoding </strong>step here is similar to what I showed you in Example 1, but theoretically and computationally much more advanced.</p><p id="1309" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The latent space allows exploration into other interesting dimensions, such as <em class="pi">hair length</em>, <em class="pi">smile</em>, <em class="pi">gender</em>, and more.</p><h2 id="6109" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">Example 3. Arranging words and phrases based on their meanings.</h2><p id="46f2" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Let’s say you’re doing a study on predatory behavior in nature and society and you’ve got a ton of text material to analyze. For automating the filtering of relevant articles, you can encode words and phrases into the latent space. Following the top-down approach, let this latent space be based on two dimensions: <em class="pi">Predatoriness</em> and <em class="pi">Size</em>. In a real-world scenario, you’d need more dimensions. I only took two so you could see the latent space for yourself.</p><p id="a0ed" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Below, you can see some words and phrases represented (embedded) in the introduced latent space. Using an analogy to physics: you can think of each word or phrase as being loaded with two types of charges: <em class="pi">predatoriness</em> and <em class="pi">size</em>. Words/phrases with similar charges are located close to each other in the latent space.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pq"><img src="../Images/6815730634ec6a9a7faea2cc1f148d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fCZmNVfgn_n67zrnmxSqeA.png"/></div></div></figure><p id="15a1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Every word/phrase is assigned numerical coordinates in the latent space.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pr"><img src="../Images/dc0b39c528888f17c6e3b055a0b1c879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_gS7QaZ4wT-74OiT3xE48Q.png"/></div></div></figure><p id="bc6a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">These vectors are <strong class="ne fr">latent space representations</strong> of words/phrases and are referred to as <strong class="ne fr">embeddings</strong>. One of the great things about embeddings is that you can perform algebraic operations on them. For example, if you add the vectors representing ‘sheep’ and ‘spider’, you’ll end up close to the vector representing ‘politician’. This justifies the following elegant algebraic expression:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ps"><img src="../Images/025153092b42930f014549c33c32c83c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WPy1zHwwJ24MxRbB5XIssg.png"/></div></div></figure><p id="5700" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Do you think this equation makes sense?</p><p id="8d6a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Try out the latent space representation used by ChatGPT. This could be really entertaining.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pt"><img src="../Images/7ec7262d772fb4bdda6bcbcc04bc1ba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lTPjq0I5AP0-QyKKn4faOQ.png"/></div></div></figure><h2 id="dec0" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">Final words</h2><p id="610e" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">The latent space represents data in a manner that highlights properties essential for the current task. Many AI methods, especially generative models and deep neural networks, operate on the latent space representation of data.</p><p id="f421" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">An AI model learns the latent space from data, projects the original data into this space (encoding step), performs operations within it, and finally reconstructs the result into the original data format (decoding step).</p></div></div></div><div class="ab cb pu pv pw px" role="separator"><span class="py by bm pz qa qb"/><span class="py by bm pz qa qb"/><span class="py by bm pz qa"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="9b41" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">My intention was to help you understand the concept of the latent space. To delve deeper into the subject, I suggest exploring more mathematically advanced sources. If you have good mathematical skills, I recommend following <a class="af nb" href="https://jmtomczak.github.io/" rel="noopener ugc nofollow" target="_blank">the blog of Jakub Tomczak</a>, where he discusses hot topics in the field of generative AI and offers thorough explanations of <strong class="ne fr">generative models</strong>.</p></div></div></div><div class="ab cb pu pv pw px" role="separator"><span class="py by bm pz qa qb"/><span class="py by bm pz qa qb"/><span class="py by bm pz qa"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="3b21" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pi">Unless otherwise noted, all images are by the author.</em></p></div></div></div><div class="ab cb pu pv pw px" role="separator"><span class="py by bm pz qa qb"/><span class="py by bm pz qa qb"/><span class="py by bm pz qa"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="eee1" class="qc oi fq bf oj qd qe gq on qf qg gt or qh qi qj qk ql qm qn qo qp qq qr qs qt bk">References</h1><p id="7e4c" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">[1] Deisenroth, Marc Peter, A. Aldo Faisal, Cheng Soon Ong. <a class="af nb" href="https://www.google.com/url?sa=t&amp;rct=j&amp;opi=89978449&amp;url=https%3A%2F%2Fmml-book.github.io%2Fbook%2Fmml-book.pdf&amp;ved=2ahUKEwjy8PaJ7PiFAxUHLRAIHXMpCWMQFnoECBUQAQ&amp;usg=AOvVaw17xiHCSrqWJgf-0E-XLdOq" rel="noopener ugc nofollow" target="_blank">Mathematics for machine learning</a>. Cambridge University Press, 2020.</p><p id="649a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[2] Jakub M. Tomczak. <a class="af nb" href="https://link.springer.com/book/10.1007/978-3-030-93158-2" rel="noopener ugc nofollow" target="_blank">Deep Generative Modeling</a>. Springer, 2022</p></div></div></div></div>    
</body>
</html>