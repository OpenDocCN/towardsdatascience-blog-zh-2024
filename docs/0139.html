<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Generative AI: Synthetic Data Generation with GANs using Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Generative AI: Synthetic Data Generation with GANs using Pytorch</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-ai-synthetic-data-generation-with-gans-using-pytorch-2e4dde8a17dd?source=collection_archive---------1-----------------------#2024-01-15">https://towardsdatascience.com/generative-ai-synthetic-data-generation-with-gans-using-pytorch-2e4dde8a17dd?source=collection_archive---------1-----------------------#2024-01-15</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="acee" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><strong class="al">Demystifying complexity: beyond images and language models</strong></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@ns650?source=post_page---byline--2e4dde8a17dd--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Najib Sharifi, Ph.D." class="l ep by dd de cx" src="../Images/d94932c5e3633e32247d98a3c221b181.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*gpeo9aVzjcetgo_8deQcBw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--2e4dde8a17dd--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@ns650?source=post_page---byline--2e4dde8a17dd--------------------------------" rel="noopener follow">Najib Sharifi, Ph.D.</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--2e4dde8a17dd--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="c16f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Generative models have become hugely popular for their abilities to generate both beautiful and realistic images, and language models (e.g. ChatGPT) that are increasingly rising in their use across every sector. These generative models models are arguably the reason AI/Machine learning have gotten the excitement (or fear) the world holds for the field right now; because it has shown everyone (especially those outside the field) the immense potential that machine learning holds. There are already a lot of resources on GANs models online but most of these focus on image generation. These image generation and language models require complex spatial or temporal intricacies which adds additional complexities that make it more challenging for readers to understand the true essence of GANs.</p><p id="6429" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In an effort to remedy this and make GANs more accessible to a broader audience, in this short discussion and GAN model example, we’ll take a different and more practical approach that focuses on generating synthetic data of mathematical functions. Beyond being a simplification for learning purposes, synthetic data generation is becoming increasingly more important in its own right. Data is not only playing a central role in business decision-making but also there are an increasing number of uses where a data driven approach is becoming more popular than first principle models. An exciting example of this is weather forecast, the first principle model included simplified versions of the Navier-Stokes equation that was solved numerically (with significant computational costs I should add). However, recent attempts of weather forecast with deep learning (e.g. check out Nvidia’s FourCastNet [1]) have been very successful in capture weather patterns and once trained, it is easier and much faster to run.</p><p id="fdf8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Generative Models vs. Discriminative Models</strong></p><p id="8f6c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In machine learning, it is important to understand the distinction between discriminative and generative models as they are the key components in a GAN. Let’s unravel these terms (very briefly):</p><p id="8308" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Discriminative Models:</p><p id="d1a6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Discriminative models focus on classifying data into predefined classes for example classing images of dogs and cats into their respective classes. Rather than capturing the entire distribution, these models discern the boundaries that separate different classes. They output P(y|x) (probability of class, y given the input data, x) i.e. they answer the question of what category a given data point belongs to?</p><p id="6e01" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Generative Models:</p><p id="cefb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Generative models aim to understand the underlying structure of the data. Unlike discriminative models that discern between classes, generative models learn the entire distribution of the data. These models output p(x|y) i.e. they answer the question of what is the likelihood of generating this specific data point given specified the class?</p><p id="0573" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The interplay between these two models forms the very foundation of GANs.</p><p id="7a5e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">GANs — Structure and Components</strong></p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nh"><img src="../Images/1fa83d74ad0c8fcc4dcca0381c8f8226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tQBszpBwvLD2WwxkPf4dZw.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">A schematic of the anatomy of GANs. Image credit: <a class="af ny" href="https://www.researchgate.net/publication/376301143_A_Survey_of_Generative_Adversarial_Networks_for_Synthesizing_Structured_Electronic_Health_Records" rel="noopener ugc nofollow" target="_blank">Tingting Zhu</a> [2]</figcaption></figure><p id="0279" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let’s now explore how these concepts come together in a GAN model. The key components of a GAN include the noise vector, the generator, and the discriminator.</p><p id="79c3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The Generator: Generating Realistic Data</p><p id="fe6d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To generate synthetic data the generator uses a random noise vector as an input. In it’s bid to fool the discriminator, the generator aims to learn the distribution of the real data and produce synthetic data that cannot be distinguished from the real data. A problem here is that for the same input, it would always produce the same output (imagine an image generator that produced a realistic image but always the same image, that is not very useful). The random noise vector injects randomness into the process, providing diversity in the generated output.</p><p id="7701" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The Discriminator: Discerning Real from Fake</p><p id="ab56" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The discriminator is like an art critic trained to differentiate between real and fake data. It’s role is to scrutinize the data it receives and assign a probability score of the work being real. If the synthetic data seems similar to the real data, the discriminator assigns a high probability, otherwise assign a low probability score.</p><p id="84f8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Adversarial Training: A Dynamic Duel</p><p id="6d0c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The generator strives to learn to produce synthetic data that the discriminator can not differentiate from the real data. Simultaneously, the discriminator also learning and improving its ability to differentiate the real from the synthetic. This dynamic training process pushes both models to refine their skills. The two models are always competing with one another (hence why it is called Adversarial) and through this competition both models become excellent at their roles.</p><p id="82c4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Implementing a GAN with Pytorch</strong></p><p id="51b3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let’s move forward by looking at an example of creating a GAN. In this example, we implement a model in pytorch that can generate synthetic data. For the training, we have a 6-parameters dataset with the following shapes (all parameters are plotted as a function of parameter 1). Each parameter has been deliberately chosen with a significantly different distribution and shape to increase the complexity of the dataset and mimic real-world data. However, it is worth mentioning that there is significant room for optimising both the discriminator and generator architectures but we won’t focus for this tutorial.</p><p id="3b1a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this tutorial, I am assuming you already have an understanding normal ANN model architectures and python. I have provided comments in the code to help you follow the code.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nz"><img src="../Images/9dca607323f861b859fe959578580dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sHiYZCHlZq9qmn8YWZNTAQ.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">The training data — all 6 parameters are plotted as function of parameter 1</figcaption></figure><p id="84a6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Defining the GAN model components (Generator and Discriminator)</p><pre class="ni nj nk nl nm oa ob oc bp od bb bk"><span id="8b57" class="oe of fq ob b bg og oh l oi oj">import torch<br/>from torch import nn<br/>from tqdm.auto import tqdm<br/>from torch.utils.data import DataLoader<br/>import matplotlib.pyplot as plt<br/>import torch.nn.init as init<br/>import pandas as pd<br/>import numpy as np<br/>from torch.utils.data import Dataset<br/><br/><br/># defining a single generation block function<br/>def FC_Layer_blockGen(input_dim, output_dim):<br/>    single_block = nn.Sequential(<br/>        nn.Linear(input_dim, output_dim),<br/><br/>        nn.ReLU()<br/>    )<br/>    return single_block<br/>    <br/># DEFINING THE GENERATOR<br/>class Generator(nn.Module):<br/>    def __init__(self, latent_dim, output_dim):<br/>        super(Generator, self).__init__()<br/>        self.model = nn.Sequential(<br/>            nn.Linear(latent_dim, 256),<br/>            nn.ReLU(),<br/>            nn.Linear(256, 512),<br/>            nn.ReLU(),<br/>            nn.Linear(512, 512),<br/>            nn.ReLU(),<br/>            nn.Linear(512, output_dim),<br/>            nn.Tanh()  <br/>        )<br/><br/>    def forward(self, x):<br/>        return self.model(x)<br/>        <br/>#defining a single discriminattor block       <br/>def FC_Layer_BlockDisc(input_dim, output_dim):<br/>    return nn.Sequential(<br/>        nn.Linear(input_dim, output_dim),<br/>        nn.ReLU(),<br/>        nn.Dropout(0.4)<br/>    )<br/>    <br/># Defining the discriminator<br/><br/>class Discriminator(nn.Module):<br/>    def __init__(self, input_dim):<br/>        super(Discriminator, self).__init__()<br/>        self.model = nn.Sequential(<br/>            nn.Linear(input_dim, 512),<br/>            nn.ReLU(),<br/>            nn.Dropout(0.4),<br/>            nn.Linear(512, 512),<br/>            nn.ReLU(),<br/>            nn.Dropout(0.4),<br/>            nn.Linear(512, 256),<br/>            nn.ReLU(),<br/>            nn.Dropout(0.4),<br/>            nn.Linear(256, 1),<br/>            nn.Sigmoid()<br/>        )<br/><br/>    def forward(self, x):<br/>        return self.model(x)<br/>        <br/>        <br/>#Defining training parameters<br/>batch_size = 128<br/>num_epochs = 500<br/>lr = 0.0002<br/>num_features = 6<br/>latent_dim = 20<br/><br/># MODEL INITIALIZATION<br/>generator = Generator(noise_dim, num_features)<br/>discriminator = Discriminator(num_features)<br/><br/># LOSS FUNCTION AND OPTIMIZERS<br/>criterion = nn.BCELoss()<br/>gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)<br/>disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)</span></pre><p id="329b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Model Initialisation and Data Processing</p><pre class="ni nj nk nl nm oa ob oc bp od bb bk"><span id="acd7" class="oe of fq ob b bg og oh l oi oj"># IMPORTING DATA<br/>file_path = 'SamplingData7.xlsx'<br/>data = pd.read_excel(file_path)<br/>X = data.values<br/>X_normalized = torch.FloatTensor((X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) * 2 - 1)<br/>real_data = X_normalized<br/><br/>#Creating a dataset<br/><br/>class MyDataset(Dataset):<br/>    def __init__(self, dataframe):<br/>        self.data = dataframe.values.astype(float)<br/>        self.labels = dataframe.values.astype(float)<br/><br/>    def __len__(self):<br/>        return len(self.data)<br/><br/>    def __getitem__(self, idx):<br/>        sample = {<br/>            'input': torch.tensor(self.data[idx]),<br/>            'label': torch.tensor(self.labels[idx])<br/>        }<br/>        return sample<br/><br/># Create an instance of the dataset<br/>dataset = MyDataset(data)<br/><br/># Create DataLoader<br/>dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)<br/><br/>def weights_init(m):<br/>    if isinstance(m, nn.Linear):<br/>        init.xavier_uniform_(m.weight)<br/>        if m.bias is not None:<br/>            init.constant_(m.bias, 0)<br/><br/>pretrained = False<br/>if pretrained:<br/>    pre_dict = torch.load('pretrained_model.pth')<br/>    generator.load_state_dict(pre_dict['generator'])<br/>    discriminator.load_state_dict(pre_dict['discriminator'])<br/>else:<br/>    # Apply weight initialization<br/>    generator = generator.apply(weights_init)<br/>    discriminator = discriminator.apply(weights_init)</span></pre><p id="34d1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Model Training</p><pre class="ni nj nk nl nm oa ob oc bp od bb bk"><span id="5e9c" class="oe of fq ob b bg og oh l oi oj">model_save_freq = 100<br/><br/>latent_dim =20<br/>for epoch in range(num_epochs):<br/>    for batch in dataloader:<br/>        real_data_batch = batch['input']<br/>        # Train discriminator on real data<br/>        real_labels = torch.FloatTensor(np.random.uniform(0.9, 1.0, (batch_size, 1)))<br/>        disc_optimizer.zero_grad()<br/>        output_real = discriminator(real_data_batch)<br/>        loss_real = criterion(output_real, real_labels)<br/>        loss_real.backward()<br/><br/>        # Train discriminator on generated data<br/>        fake_labels = torch.FloatTensor(np.random.uniform(0, 0.1, (batch_size, 1)))<br/>        noise = torch.FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim)))<br/>        generated_data = generator(noise)<br/>        output_fake = discriminator(generated_data.detach())<br/>        loss_fake = criterion(output_fake, fake_labels)<br/>        loss_fake.backward()<br/><br/>        disc_optimizer.step()<br/><br/>        # Train generator <br/>        valid_labels = torch.FloatTensor(np.random.uniform(0.9, 1.0, (batch_size, 1)))<br/>        gen_optimizer.zero_grad()<br/>        output_g = discriminator(generated_data)<br/>        loss_g = criterion(output_g, valid_labels)<br/>        loss_g.backward()<br/>        gen_optimizer.step()<br/><br/>    # Print progress<br/>    print(f"Epoch {epoch}, D Loss Real: {loss_real.item()}, D Loss Fake: {loss_fake.item()}, G Loss: {loss_g.item()}")</span></pre><p id="702f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Evaluating and visualising the results</p><pre class="ni nj nk nl nm oa ob oc bp od bb bk"><span id="2f82" class="oe of fq ob b bg og oh l oi oj">import seaborn as sns<br/><br/># Generate synthetic data <br/>synthetic_data = generator(torch.FloatTensor(np.random.normal(0, 1, (real_data.shape[0], noise_dim))))<br/><br/># Plot the results<br/>fig, axs = plt.subplots(2, 3, figsize=(12, 8))<br/>fig.suptitle('Real and Synthetic Data Distributions', fontsize=16)<br/><br/>for i in range(2):<br/>    for j in range(3):<br/>        sns.histplot(synthetic_data[:, i * 3 + j].detach().numpy(), bins=50, alpha=0.5, label='Synthetic Data', ax=axs[i, j], color='blue')<br/>        sns.histplot(real_data[:, i * 3 + j].numpy(), bins=50, alpha=0.5, label='Real Data', ax=axs[i, j], color='orange')<br/>        axs[i, j].set_title(f'Parameter {i * 3 + j + 1}', fontsize=12)<br/>        axs[i, j].set_xlabel('Value')<br/>        axs[i, j].set_ylabel('Frequency')<br/>        axs[i, j].legend()<br/><br/>plt.tight_layout(rect=[0, 0.03, 1, 0.95])<br/>plt.show()<br/><br/><br/># Create a 2x3 grid of subplots<br/>fig, axs = plt.subplots(2, 3, figsize=(15, 10))<br/>fig.suptitle('Comparison of Real and Synthetic Data', fontsize=16)<br/><br/># Define parameter names<br/>param_names = ['Parameter 1', 'Parameter 2', 'Parameter 3', 'Parameter 4', 'Parameter 5', 'Parameter 6']<br/><br/># Scatter plots for each parameter<br/>for i in range(2):<br/>    for j in range(3):<br/>        param_index = i * 3 + j<br/>        sns.scatterplot(real_data[:, 0].numpy(), real_data[:, param_index].numpy(), label='Real Data', alpha=0.5, ax=axs[i, j])<br/>        sns.scatterplot(synthetic_data[:, 0].detach().numpy(), synthetic_data[:, param_index].detach().numpy(), label='Generated Data', alpha=0.5, ax=axs[i, j])<br/>        axs[i, j].set_title(param_names[param_index], fontsize=12)<br/>        axs[i, j].set_xlabel(f'Real Data - {param_names[param_index]}')<br/>        axs[i, j].set_ylabel(f'Real Data - {param_names[param_index]}')<br/>        axs[i, j].legend()<br/><br/>plt.tight_layout(rect=[0, 0.03, 1, 0.95])<br/>plt.show()</span></pre><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nz"><img src="../Images/dc6dbaad057f7434bcbb3812ed77ae2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P0dZDzTDZXp8kWa-OP_-rw.png"/></div></div></figure><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng ok"><img src="../Images/66571da2455b2846c32dd5a59fda6ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xc72a2okaJlcvkZRTkVJAg.png"/></div></div></figure><p id="34b9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Despite the simplicity of our model, the distribution and mathematical shape of the synthetic data and real data look very similar! The training process and model architecture could be changed for improved accuracy, something we didn’t focus on here. This model could very easily be adjusted to produce synthetic data for other applications with larger number parameters and more complexity for real phyical systems. Thank you for taking the time to read, I hope you found this an informative read. There are so much one can do with GANs, it is a very exciting topic at the moment, definitely play around with this code to get the overall idea of GANs and then start experimenting with other ideas! best of luck!</p><p id="1eb2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><em class="ol">Unless otherwise noted, all images are by the author</em></p><p id="2c6e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">References</strong></p><p id="361d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[1] Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, Ashesh Chattopadhyay, Morteza Mardani, Thorsten Kurth, David Hall, Zongyi Li, Kamyar Azizzadenesheli, Pedram Hassanzadeh, Karthik Kashinath, Animashree Anandkumar. (2022). FourCastNet: A Global Data-driven High-resolution Weather Model using Adaptive Fourier Neural Operators. arXiv:2202.11214. <a class="af ny" href="https://doi.org/10.48550/arXiv.2202.11214" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2202.11214</a></p><p id="158f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">[2] Ghosheh, Ghadeer &amp; Jin, Li &amp; Zhu, Tingting. (2023). A Survey of Generative Adversarial Networks for Synthesizing Structured Electronic Health Records. ACM Computing Surveys. 10.1145/3636424.</p></div></div></div></div>    
</body>
</html>