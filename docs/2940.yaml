- en: 'DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs
    of Large Language Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'DRAGIN: 基于大型语言模型信息需求的动态检索增强生成'
- en: 原文：[https://towardsdatascience.com/dragin-dynamic-retrieval-augmented-generation-based-on-the-information-needs-of-large-language-dbdb9aabc1ef?source=collection_archive---------2-----------------------#2024-12-05](https://towardsdatascience.com/dragin-dynamic-retrieval-augmented-generation-based-on-the-information-needs-of-large-language-dbdb9aabc1ef?source=collection_archive---------2-----------------------#2024-12-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/dragin-dynamic-retrieval-augmented-generation-based-on-the-information-needs-of-large-language-dbdb9aabc1ef?source=collection_archive---------2-----------------------#2024-12-05](https://towardsdatascience.com/dragin-dynamic-retrieval-augmented-generation-based-on-the-information-needs-of-large-language-dbdb9aabc1ef?source=collection_archive---------2-----------------------#2024-12-05)
- en: '*Traditional RAG vs. dynamic RAG*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*传统RAG与动态RAG*'
- en: '[](https://medium.com/@atisharajpurohit?source=post_page---byline--dbdb9aabc1ef--------------------------------)[![Atisha
    Rajpurohit](../Images/4a546a800ef8bf9b17684dd00cde0c40.png)](https://medium.com/@atisharajpurohit?source=post_page---byline--dbdb9aabc1ef--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dbdb9aabc1ef--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dbdb9aabc1ef--------------------------------)
    [Atisha Rajpurohit](https://medium.com/@atisharajpurohit?source=post_page---byline--dbdb9aabc1ef--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@atisharajpurohit?source=post_page---byline--dbdb9aabc1ef--------------------------------)[![Atisha
    Rajpurohit](../Images/4a546a800ef8bf9b17684dd00cde0c40.png)](https://medium.com/@atisharajpurohit?source=post_page---byline--dbdb9aabc1ef--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dbdb9aabc1ef--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dbdb9aabc1ef--------------------------------)
    [Atisha Rajpurohit](https://medium.com/@atisharajpurohit?source=post_page---byline--dbdb9aabc1ef--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dbdb9aabc1ef--------------------------------)
    ·9 min read·Dec 5, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dbdb9aabc1ef--------------------------------)
    ·阅读时间 9 分钟·2024年12月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*In this article, I explore the fundamental concepts explained in the research
    paper titled “****DRAGIN : Dynamic Retrieval Augmented Generation based on the
    Information Needs of Large Language Models” by*** *Weihang Su, Yichen Tang, Qingyao
    Ai, Zhijing Wu, and Yiqun Liu. This paper can be accessed* [*here*](https://arxiv.org/abs/2403.10081)*.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*在本文中，我探讨了研究论文《****DRAGIN：基于大型语言模型信息需求的动态检索增强生成****》中解释的基本概念，作者是*** *Weihang
    Su、Yichen Tang、Qingyao Ai、Zhijing Wu 和 Yiqun Liu。这篇论文可以在* [*这里*](https://arxiv.org/abs/2403.10081)*
    访问。*'
- en: '**Introduction — Lets look at a short story!**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**引言 — 让我们来看一个短故事！**'
- en: '*Imagine you’re working on a problem. At the very beginning, you get* ***only
    one chance*** *to ask your professor for guidance. This means it’s important to
    understand the entire scope of the problem upfront. If it’s a simple problem,
    that might be fine — you ask your question, get clarity, and move forward.*'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*假设你正在解决一个问题。刚开始时，你* ***只有一次机会*** *向你的教授请教。这意味着在开始时理解问题的整体范围非常重要。如果是一个简单的问题，可能没问题——你提问、获得清晰的答案，然后继续前进。*'
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Now, imagine that the problem is* ***much more complex****. The more you dive
    into it, the* ***more questions*** *you have! Unfortunately, you can’t go back
    to your professor because all your questions had to be asked at the start. This
    makes solving the problem much harder.*'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*现在，假设这个问题* ***变得更加复杂***。你越深入探讨，*就会有* ***更多问题*** *！不幸的是，你不能再回去问你的教授，因为所有问题都必须在一开始就提出来。这使得问题的解决变得更加困难。*'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*But what if, instead,* ***you were allowed*** *to go back to your professor
    every time you discovered a new question that expanded the scope of the problem?
    This approach lets you navigate the complexity iteratively, asking for guidance
    whenever the problem evolves.* ***That is the essence of DRAGIN (Dynamic RAG)
    over Traditional RAG.***'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*但如果，假设，* ***你被允许*** *每当发现一个扩展问题范围的新问题时都可以回去请教教授呢？这种方法允许你在问题发展时迭代地导航复杂性，每当问题有新发展时都可以请求指导。*
    ***这就是DRAGIN（动态RAG）与传统RAG的本质区别。***'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*And given how complex and multi-dimensional our tasks, problems, and worlds
    have become,* ***the need for this dynamic approach is greater than ever!***'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*考虑到我们的任务、问题和世界变得如此复杂且多维，* ***这种动态方法的需求比以往任何时候都更为迫切！***'
- en: '![](../Images/7924a1b2e6c2c88c65926dbc4ca8f2ea.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7924a1b2e6c2c88c65926dbc4ca8f2ea.png)'
- en: Image taken from [Unsplash](https://unsplash.com/)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[Unsplash](https://unsplash.com/)
- en: Large Language models have changed the way we all access information. We are
    at that point where the way we search has forever changed. Now, instead of finding
    multiple links and processing the information to answer our questions, we can
    directly ask the LLM!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型改变了我们获取信息的方式。我们正处于一个阶段，在这个阶段，我们搜索信息的方式已经永远改变。现在，我们不需要再寻找多个链接并处理信息来回答问题，我们可以直接向LLM提问！
- en: 'However, there are still a number of issues :'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仍然存在一些问题：
- en: 'Hallucinations : Generating fabricated information'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 幻觉：生成虚假信息
- en: 'Datedness/Staleness : Inability to incorporate up to date information'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过时/陈旧：无法获取最新的信息
- en: 'Proprietary Information : Inaccessibility to specialised knowledge'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 专有信息：无法访问专门知识
- en: To overcome the above issues, **Retrieval Augmented Generation (RAG)** emerged
    as a promising solution. The way it works, is by accessing and incorporating the
    relevant external information needed for the LLM to generate accurate responses.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述问题，**检索增强生成（RAG）**作为一种有前景的解决方案应运而生。它的工作原理是通过访问并结合LLM生成准确回答所需的相关外部信息。
- en: However with traditional RAG methods, they rely on single-round retrieval, which
    would mean retrieving external information once, at the start of the information
    generation. This works well for straightforward tasks, however our needs and requirements
    from LLMs are getting more complex, multi-step and requiring longer responses.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，传统的RAG方法依赖于单轮检索，这意味着信息生成开始时只进行一次外部信息检索。这对于简单的任务来说效果很好，但我们对LLM的需求和要求正变得越来越复杂、多步骤，并且需要更长的回答。
- en: 'In these cases, a single-round of retrieval will not work well and mutiple
    rounds of retrieval need to be conducted. Now when, we talk about retrieving information
    more than once, the two next questions are :'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，单轮检索效果不好，需要进行多轮检索。当我们谈到多次检索时，接下来的两个问题是：
- en: '***When*** *to retrieve and* ***What*** *to retrieve?* To solve these, a number
    of RAG methods have been devised :'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '***何时*** *进行检索，* ***检索什么*** *？为了解决这些问题，已经设计了多种RAG方法：*'
- en: '**Fixed Retrieval Methods :**'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**固定检索方法：**'
- en: '**IRCoT (Fixed Sentence RAG)** **[1]** : Retrieval is conducted for each generated
    query and the latest sentence is used as a query.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**IRCoT（固定句子RAG）** **[1]**：为每个生成的查询进行检索，最新的句子用作查询。'
- en: '**RETRO [2] and IC-RALM [3]** **(Fixed Length RAG)** : A sliding window is
    defined and the retrieval module is triggered every *n* tokens.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**RETRO [2] 和 IC-RALM [3]** **（固定长度RAG）**：定义一个滑动窗口，每生成*n*个token就触发一次检索模块。'
- en: '*But aren’t we retrieving* ***too often*** *and hence retrieving information
    that may be unnecessary ? This would introduce noise and could jeopardize the
    quality of the LLM’s outputs, which defeats the original purpose of improving
    accuracy. These rules are still* ***static*** *and we need to think of* ***dynamic***
    *ways of retrieval.*'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*但我们不是在检索* ***太频繁*** *了吗？这会导致检索到可能不必要的信息吗？这会引入噪声，并可能危及LLM输出的质量，违背了提高准确性的初衷。这些规则仍然是*
    ***静态*** *的，我们需要思考* ***动态*** *的检索方式。*'
- en: '**Dynamic Retrieval Methods :**'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**动态检索方法：**'
- en: '**FLARE [4]** **(Low Confidence RAG)** : Retrieval is conducted dynamically,
    when the LLM’s confidence (the generation probability) on the next token is lower
    than certain thresholds. So FLARE, is triggering retrieval based on **uncertainty**.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**FLARE [4]** **（低置信度RAG）**：当LLM对下一个token的置信度（生成概率）低于某个阈值时，会动态进行检索。所以，FLARE是基于**不确定性**触发检索的。'
- en: For determining what to retrieve, the LLMs often restrict themselves to queries
    based on the last few generated tokens or sentences. These methods of query formulation
    for retrieval may not work, when the tasks get more complex and the LLM’s information
    needs span over the entire context!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定检索什么，LLM通常会限制自己基于最近生成的几个token或句子来形成查询。这些查询生成方法在任务变得更加复杂且LLM的信息需求涵盖整个上下文时可能无法奏效！
- en: '*Finally, moving on to the star of the show : DRAGIN!*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*最后，让我们来看看本次的明星：DRAGIN！*'
- en: '**DRAGIN (Dynamic Retrieval Augmented Generation based on Information Needs)
    :**'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**DRAGIN（基于信息需求的动态检索增强生成）：**'
- en: 'This method is specifically designed to make decisions about when and what
    to retrieve to cater to the LLM’s information needs. So, it optimizes the process
    of information retrieval using two frameworks. As the authors explain in their
    paper, DRAGIN has two key frameworks :'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法专门用于决定何时以及检索什么信息，以满足LLM的信息需求。因此，它通过两个框架优化了信息检索的过程。正如作者在论文中所解释的，DRAGIN有两个关键框架：
- en: '***I. RIND (Real-time Information Needs Detection) : When to retrieve ?***'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '***I. RIND（实时信息需求检测）：什么时候检索？***'
- en: It considers the LLM’s **uncertainty** about its own content, the **influence**
    of each token and the **semantics** of each token.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 它会考虑LLM对自身内容的**不确定性**、每个标记的**影响**以及每个标记的**语义**。
- en: '***II. QFS (Query Formulation based on Self-Attention) : What to retrieve?***'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '***II. QFS（基于自注意力的查询构建）：要检索什么？***'
- en: Query formulation leverages the LLM’s **self-attention** across the entire context,
    rather than not just the last few tokens or sentences.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 查询构建利用了LLM在整个上下文中的**自注意力**，而不仅仅是最后几个标记或句子。
- en: '**Illustration of the DRAGIN framework**'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**DRAGIN框架的示意图**'
- en: To illustrate the above frameworks, the paper uses an example query about the
    ‘**brief introduction to Einstein’.**
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明上述框架，论文使用了一个关于‘**爱因斯坦简要介绍**’的查询示例。
- en: '![](../Images/4a52907f87cb4494167079dfde05162d.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a52907f87cb4494167079dfde05162d.png)'
- en: 'Figure 1 : An illustration of the DRAGIN framework, taken from the [research
    paper](https://arxiv.org/abs/2403.10081)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：DRAGIN框架的示意图，摘自[研究论文](https://arxiv.org/abs/2403.10081)
- en: '***Explanation :***'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '***解释：***'
- en: '***Input is Provided:*** *The system is queried to provide some introduction
    about Einstein.*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '***提供输入：*** *系统被查询提供一些关于爱因斯坦的介绍。*'
- en: '***Processing Starts:*** *The system begins generating a response based on
    what it knows. It uses the RIND module to decide if it has enough information
    or if it needs to look things up.*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '***处理开始：*** *系统根据它已知的信息开始生成响应。它使用RIND模块来决定是否有足够的信息，或者是否需要查找更多信息。*'
- en: '***Checking for Required Information (RIND):*** *The system breaks down the
    query into smaller parts (tokens), like “position,” “at,” “University,” etc. It
    checks which parts (tokens) need more information. For example, “university” might
    need additional data because it’s not specific enough.*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '***检查所需信息（RIND）：*** *系统将查询分解成更小的部分（标记），例如“职位”、“在”、“大学”等。它检查哪些部分（标记）需要更多信息。例如，“大学”可能需要额外的数据，因为它不够具体。*'
- en: '***Triggering Retrieval:*** *If a token like “university” is considered to
    be important and unclear, the system triggers retrieval to gather external information
    about it. In this case, it looks up relevant data about Einstein and universities.*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '***触发检索：*** *如果像“大学”这样的标记被认为重要且不明确，系统会触发检索以收集关于它的外部信息。在这种情况下，它会查找有关爱因斯坦和大学的相关数据。*'
- en: '***Formulating the Query (QFS):*** *The system uses its self attention mechanism
    to determine which words are most relevant for forming a precise query. For example,
    it might pick “Einstein,” “1903,” and “secured a job” as the key parts.*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '***制定查询（QFS）：*** *系统使用自注意力机制来确定哪些词语在形成精确查询时最为相关。例如，它可能会选择“爱因斯坦”、“1903”和“找到工作”作为关键部分。*'
- en: '*These keywords are used to craft a query, such as “Einstein 1903 secured a
    job,” which is sent to an external source for information.*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*这些关键词用于构建查询，例如“爱因斯坦 1903 找到一份工作”，该查询将发送给外部源获取信息。*'
- en: '***Retrieving and Adding Information:*** *The external source provides the
    required details. For example, it might return, “In 1903, Einstein secured a job
    at the Swiss Patent Office.” The system incorporates this new information into
    the response.*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '***获取和添加信息：*** *外部源提供所需的详细信息。例如，它可能返回：“在1903年，爱因斯坦在瑞士专利局找到了一份工作。”系统将这些新信息融入到回答中。*'
- en: '***Continuing Generation:*** *With the new details, the system continues generating
    a more complete and accurate response.For example, it might now say, “In 1903,
    Einstein secured a job at the Swiss Patent Office. This allowed him to have a
    stable income.”*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '***继续生成：*** *根据新信息，系统继续生成更完整、更准确的回答。例如，它现在可能会说：“在1903年，爱因斯坦在瑞士专利局找到了一份工作。这使他能够有稳定的收入。”*'
- en: '***Repeating the Process:*** *If more requirements are identified, the process
    repeats:* ***checking, retrieving, and integrating information*** *until the response
    is complete and accurate. This process ensures that the system can dynamically
    fill in gaps in its knowledge and provide detailed, accurate answers by combining
    what it knows with retrieved external information.*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '***重复过程:*** *如果识别到更多需求，过程将重复：* ***检查、检索和整合信息*** *直到响应完整且准确。这个过程确保系统能够动态地填补知识空白，并通过结合已知信息和检索到的外部信息，提供详细且准确的答案。*'
- en: Detailed Methodology about RAG
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG的详细方法
- en: 'The frameworks mentioned in the paper are:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 文中提到的框架有：
- en: '**A. Real-time Information Needs Detection** **(RIND)** : Retrieval is triggered
    based on uncertainty of tokens, influence on other tokens and semantic significance
    of each token.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**A. 实时信息需求检测** **(RIND)** : 检索是基于令牌的不确定性、对其他令牌的影响以及每个令牌的语义重要性来触发的。'
- en: 'i. The **uncertainty** of each token generated by the LLM, is quantified. This
    is done by calculating the **entropy** of the token’s probability distribution
    across the vocabulary. Consider an output sequence *T = {t1,t2,…tn},* with each
    ti representing an individual token at the position *i*. For any token *ti*, the
    entropy is calculated as follows :'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: i. 定量化每个LLM生成的令牌的**不确定性**。通过计算令牌在词汇表中的概率分布的**熵**来实现这一点。考虑输出序列 *T = {t1,t2,…tn}*，其中每个
    *ti* 表示位置 *i* 的一个单独令牌。对于任何令牌 *ti*，熵的计算公式如下：
- en: '![](../Images/c2d74a24d50aa33f9bf4cd886114bf7c.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2d74a24d50aa33f9bf4cd886114bf7c.png)'
- en: where *pi(v)* denotes the probability of generating the token *v* over all the
    tokens in the vocabulary.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *pi(v)* 表示生成令牌 *v* 在词汇表中所有令牌中的概率。
- en: ii. The **influence** of each token on subsequent tokens, is done by leveraging
    the self-attention scores. For a token t, the max attention value is identified
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ii. 通过利用自注意力分数来计算每个令牌对后续令牌的**影响**。对于令牌 t，识别最大注意力值
- en: '![](../Images/0dd60c04c99fd38b31718ece5d1fe3ed.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0dd60c04c99fd38b31718ece5d1fe3ed.png)'
- en: iii. The **semantic contribution** of each token ti, a binary indicator is employed.
    This filters out stop words.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: iii. 每个令牌 *ti* 的**语义贡献**，采用二进制指示器。这会过滤掉停用词。
- en: '![](../Images/83700fa2c321943eb4530d4cb99dffd4.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83700fa2c321943eb4530d4cb99dffd4.png)'
- en: Combining the **uncertainty, significance and semantics,** RIND computes a score
    and if this is greater than a pre-defined threshold then retrieval is triggered.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 结合**不确定性、重要性和语义**，RIND计算一个分数，如果这个分数大于预定义的阈值，则触发检索。
- en: '![](../Images/7029f1628a5da2ff0d470da41943d9ef.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7029f1628a5da2ff0d470da41943d9ef.png)'
- en: '**B**. **Query Formulation based on Self-Attention (QFS)**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**B**. **基于自注意力的查询制定（QFS）**'
- en: Once retrieval is triggered, the next step is to formulate an efficient query
    from external databases for the continued generation of LLMs. In the existing
    dynamic RAG frameworks, queries are formulated using the last sentence or last
    tokens generated by the LLM. This narrow scope doesn’t capture the need for real-time
    information needs. It examines the full context.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦触发检索，下一步是从外部数据库中制定高效的查询，以继续生成LLM。在现有的动态RAG框架中，查询是使用LLM生成的最后一句话或最后一个令牌来制定的。这种狭窄的范围没有捕捉到实时信息需求的必要性。它检查的是完整的上下文。
- en: Suppose RIND identifies the token *ti* at position *i,* requires external knowledge
    and triggers retrieval.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 假设RIND识别到位置 *i* 的令牌 *ti*，需要外部知识并触发检索。
- en: 'Since the token ti was generated based on based on the knowledge of all the
    preceding tokens, it only makes sense to look at the entire content generated,
    until now, to formulate a query. It uses the following steps:'
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于令牌 *ti* 是基于所有前置令牌的知识生成的，因此从现在起查看已生成的完整内容来制定查询是有意义的。它使用以下步骤：
- en: '**Step 1**: Extracts the attention scores of the last transformer layer for
    each token *ti*.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤1**：提取最后一个Transformer层中每个令牌 *ti* 的注意力分数。'
- en: '**Step 2**: Sorts the attention scores in descending order, to identify the
    top ***n*** scores. *(This is basically, identifying the most important tokens).*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤2**：按降序排列注意力分数，以识别前***n***个分数。*(这基本上是识别最重要的令牌)。*'
- en: '**Step 3**: Finds the words corresponding to these tokens from the vocabulary
    and arranges them in their original order. *(This brings back the structure of
    the language form the attention scores and tokens).*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤3**：从词汇表中找到这些令牌对应的词，并按照原始顺序排列。*(这通过注意力分数和令牌恢复了语言结构)。*'
- en: '**Step 4** : Construct the query *Qi* using the words associated with these
    top ***n*** tokens.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**第4步**：使用与这些顶部***n***个标记相关的词构造查询*Qi*。'
- en: '**C. Continue Generation after Retrieval**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**C. 检索后继续生成**'
- en: Once RIND has identified the position *i*, at which external knowledge is needed
    and QFS creates the query, Qi to extract the information using an off-the-shelf
    retrieval model (e.g. BM25).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦RIND识别出需要外部知识的位置*i*，并且QFS生成查询Qi以使用现成的检索模型（例如，BM25）提取信息。
- en: It finds the relevant information in documents *Di1*, *Di2* and *Di3*. It integrates
    the relevant information at position *i,* by truncating the LLM’s output. This
    retrieved knowledge is integrated using the following designed prompt template.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 它从文档*Di1*、*Di2*和*Di3*中找到了相关信息。通过截断LLM的输出，它整合了位置*i*上的相关信息。然后，使用以下设计的提示模板整合这些检索到的知识。
- en: '![](../Images/56da182d3b34f09b8a8c32282f39938d.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56da182d3b34f09b8a8c32282f39938d.png)'
- en: Designed prompt template used to integrate externally retrieved information.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 用于整合外部检索信息的设计提示模板。
- en: '**Limitations**'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**局限性**'
- en: As the paper states, the primary limitations of this paper is the reliance on
    the self-attention mechanisms for both the Real-time Information Needs Detection
    (RIND) and Query Formulation based on Self-Attention (QFS). While self-attention
    scores are available for all source LLMs, it is not applicable for certain APIs
    that do not provide access to self-attention scores.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本文所述，本文的主要局限性在于它依赖自注意力机制来处理实时信息需求检测（RIND）和基于自注意力的查询生成（QFS）。虽然所有源LLM都可以获得自注意力分数，但对于某些不提供自注意力分数的API，这种方法不可行。
- en: '*A point worth considering is the impact on inference time latency and cost:
    in the paper, the authors point out that these are only marginally more since
    an imperfect token sub-sequence is rapidly detected, and further generation is
    interrupted until remediation.*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*值得考虑的一点是对推理时间延迟和成本的影响：在论文中，作者指出这些影响仅仅是微乎其微，因为不完美的标记子序列会迅速被检测到，进一步的生成会被中断，直到进行修正。*'
- en: Conclusion
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: The DRAGIN framework allows us to look to move a few steps ahead of the traditional
    RAG framework. It allows us to perform multiple retrievals, based on the information
    needs of generation. It is an optimized framework for multiple retrievals!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: DRAGIN框架使我们能够比传统的RAG框架走得更远。它允许我们根据生成的信息需求执行多次检索。它是一个优化的多次检索框架！
- en: Our needs and requirements from LLMs are becoming larger and more complex, and
    in such cases where we want to retrieve information accurately, with just the
    right number of retrievals.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对LLM的需求和要求变得越来越大且复杂，在我们希望准确检索信息且仅需适量检索的情况下，DRAGIN框架提供了解决方案。
- en: 'To conclude, DRAGIN :'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 总结，DRAGIN：
- en: ''
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Strikes the perfect balance for the number of retrievals.
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为检索的数量找到了完美的平衡。
- en: Produces highly context-aware queries for retrievals.
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 生成高度上下文感知的检索查询。
- en: Generates content from the LLMs with better accuracy!
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 生成来自LLM的内容，准确度更高！
- en: '*Thank you so much for reading and for a more detailed explanation of the research
    paper, please watch my video!*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*非常感谢您的阅读，若想更详细了解本研究论文，请观看我的视频！*'
- en: '**References :**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献：**'
- en: '*[1] Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal.
    2022\. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive
    multi-step questions. arXiv preprint arXiv:2212.10509.*'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*[1] Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal.
    2022\. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive
    multi-step questions. arXiv preprint arXiv:2212.10509.*'
- en: '*[2] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza
    Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau,
    Bogdan Damoc, Aidan Clark, et al. 2022.*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*[2] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza
    Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau,
    Bogdan Damoc, Aidan Clark, et al. 2022.*'
- en: '*[3] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin
    Leyton-Brown, and Yoav Shoham. 2023\. In-context retrieval-augmented language
    models. arXiv preprint arXiv:2302.00083.*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*[3] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin
    Leyton-Brown, and Yoav Shoham. 2023\. In-context retrieval-augmented language
    models. arXiv preprint arXiv:2302.00083.*'
- en: '*[4] Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu,
    Yiming Yang, Jamie Callan, and Graham Neubig. 2023\. Active retrieval augmented
    generation. arXiv preprint arXiv:2305.06983.*'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*[4] Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu,
    Yiming Yang, Jamie Callan, and Graham Neubig. 2023\. Active retrieval augmented
    generation. arXiv preprint arXiv:2305.06983.*'
