- en: Sora — Intuitively and Exhaustively Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sora — 直观且详尽的解释
- en: 原文：[https://towardsdatascience.com/sora-intuitively-and-exhaustively-explained-a54f83ea9c21?source=collection_archive---------4-----------------------#2024-03-22](https://towardsdatascience.com/sora-intuitively-and-exhaustively-explained-a54f83ea9c21?source=collection_archive---------4-----------------------#2024-03-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/sora-intuitively-and-exhaustively-explained-a54f83ea9c21?source=collection_archive---------4-----------------------#2024-03-22](https://towardsdatascience.com/sora-intuitively-and-exhaustively-explained-a54f83ea9c21?source=collection_archive---------4-----------------------#2024-03-22)
- en: Video Generation | Multimodal Modeling | OpenAI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频生成 | 多模态建模 | OpenAI
- en: A new era of cutting-edge video generation
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新时代的前沿视频生成
- en: '[](https://medium.com/@danielwarfield1?source=post_page---byline--a54f83ea9c21--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page---byline--a54f83ea9c21--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a54f83ea9c21--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a54f83ea9c21--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page---byline--a54f83ea9c21--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danielwarfield1?source=post_page---byline--a54f83ea9c21--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page---byline--a54f83ea9c21--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a54f83ea9c21--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a54f83ea9c21--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page---byline--a54f83ea9c21--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a54f83ea9c21--------------------------------)
    ·18 min read·Mar 22, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a54f83ea9c21--------------------------------)
    ·阅读时间 18 分钟·2024年3月22日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b8b55cdca39f043f3cc252fb5d12d437.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8b55cdca39f043f3cc252fb5d12d437.png)'
- en: “Patchmaster” By Daniel Warfield using MidJourney. All images by the author
    unless otherwise stated.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: “Patchmaster” 由 Daniel Warfield 使用 MidJourney 创建。所有图片均为作者提供，除非另有说明。
- en: In this post we’ll discuss Sora, OpenAI’s new cutting edge video generation
    model. We’ll start by describing the fundamental machine learning technologies
    Sora builds off of, then we’ll discuss information available on Sora itself, including
    OpenAI’s technical report and speculation around it. By the end of this article
    you’ll have a solid understanding of how Sora (probably) works.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将讨论 Sora，OpenAI 最新的前沿视频生成模型。我们将从描述 Sora 所依赖的基本机器学习技术开始，然后讨论关于 Sora
    本身的信息，包括 OpenAI 的技术报告和相关的推测。阅读完这篇文章后，你将对 Sora（可能）是如何工作的有一个扎实的理解。
- en: '![](../Images/0dfa9fdbe68099d615a68bd5904a05f3.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0dfa9fdbe68099d615a68bd5904a05f3.png)'
- en: An example of the video quality Sora is capable of producing. Unfortunately,
    due to copyright issues, I can’t include actual Sora generated videos. Also, because
    of Medium’s file size limits I can’t include high quality video anyway. As a result,
    I’ll be providing links to videos on the OpenAI website. This video is from [here](https://www.pexels.com/video/drone-footage-of-isola-del-garda-8441006/),
    and the actual Sora video it represents can be found [here](https://openai.com/sora?video=amalfi-coast).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Sora 能够生成的视频质量示例。不幸的是，由于版权问题，我不能在这里包括实际的 Sora 生成视频。同时，由于 Medium 的文件大小限制，我也不能上传高质量的视频。因此，我将提供链接到
    OpenAI 网站上的视频。此视频来自 [这里](https://www.pexels.com/video/drone-footage-of-isola-del-garda-8441006/)，而实际的
    Sora 视频可以在 [这里](https://openai.com/sora?video=amalfi-coast) 找到。
- en: '**Who is this useful for?** Anyone interested in generative AI.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**这对谁有用？** 任何对生成式 AI 感兴趣的人。'
- en: '**How advanced is this post?** This is not a complex post, but there are a
    lot of concepts, so this article might be daunting to less experienced data scientists.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**这篇文章有多复杂？** 这篇文章并不复杂，但有很多概念，可能会让经验较少的数据科学家感到有些吃力。'
- en: '**Pre-requisites:** Nothing, but some machine learning experience might be
    helpful. Feel free to refer to linked articles throughout, or the recommended
    reading at the end of the article, if you find yourself confused.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**前提条件：** 无需任何前提，但一些机器学习经验可能会有所帮助。如果你感到困惑，可以参考文中提到的相关文章，或文章末尾的推荐阅读。'
- en: Defining Sora
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义 Sora
