["```py\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MaxAbsScaler\n\n# Load dataset of 8x8 pixel handwritten digits numbered zero to nine.\ndigits = load_digits()\nX = MaxAbsScaler().fit_transform(digits.data)  # Scale to interval [0, 1].\nX_train, X_test = train_test_split(X)\n```", "```py\nfrom sklearn.neural_network import BernoulliRBM\n\nharmonium = BernoulliRBM(n_components=32, learning_rate=0.05)\nharmonium.fit(X_train)\nreceptive_fields = -harmonium.components_  # Energy sign convention.\n```", "```py\nH_test = harmonium.transform(X_test)\n```", "```py\nimport numpy as np\n\nmask = np.ones(shape=[8,8])  # Mask: erase pixel values where zero.\nmask[-4:, :4] = 0  # Zero out 25% pixels: lower left corner.\nmask = mask.ravel()\nx_six_missing = X_test[0] * mask  # Digit six, partly erased.\n```", "```py\n# Impute the data by running 100 parallel Gibbs chains for 1000 steps:\nX_reconstr = np.tile(x_six_missing, reps=(100, 1))  # Initialise 100 chains.\nfor _ in range(1_000):\n    # Advance Markov chains by one Gibbs step.\n    X_reconstr = harmonium.gibbs(X_reconstr)\n    # Clamp the masked pixels.\n    X_reconstr = X_reconstr * (1 - mask) + x_six_missing * mask\n# Final result: average over samples from the 100 Markov chains.\nx_imputed = X_reconstr.mean(axis=0)\n```"]