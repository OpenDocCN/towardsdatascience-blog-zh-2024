- en: How to Reduce Embedding Size and Increase RAG Retrieval Speed
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-reduce-embedding-size-and-increase-rag-retrieval-speed-7f903d3cecf7?source=collection_archive---------2-----------------------#2024-05-26](https://towardsdatascience.com/how-to-reduce-embedding-size-and-increase-rag-retrieval-speed-7f903d3cecf7?source=collection_archive---------2-----------------------#2024-05-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Flexible text embedding with Matryoshka Representation Learning (MRL)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@leoneversberg?source=post_page---byline--7f903d3cecf7--------------------------------)[![Dr.
    Leon Eversberg](../Images/56dc3579a29933f7047a9ce60be4697a.png)](https://medium.com/@leoneversberg?source=post_page---byline--7f903d3cecf7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7f903d3cecf7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7f903d3cecf7--------------------------------)
    [Dr. Leon Eversberg](https://medium.com/@leoneversberg?source=post_page---byline--7f903d3cecf7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7f903d3cecf7--------------------------------)
    ·7 min read·May 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aa83fbe893c96ba83d3975653ab8dbbd.png)'
  prefs: []
  type: TYPE_IMG
- en: Matryoshka dolls are nesting dolls of decreasing size. Photo by [Sandy Millar](https://unsplash.com/@sandym10?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Text embeddings are **high-dimensional vector representations** of single words
    or entire sentences.
  prefs: []
  type: TYPE_NORMAL
- en: These vectors (arrays) of numbers capture rich information about the underlying
    text that can be used for many **downstream tasks**, such as semantic understanding,
    classification, clustering, information retrieval (RAG), reranking, and more.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usually, the dimension *d* of the embedding vector is fixed**. The embedding
    dimension is typically a power of two, ranging from 64 up to 4096.'
  prefs: []
  type: TYPE_NORMAL
- en: With Matryoshka embeddings, you can **change the dimension of your embeddings
    depending on your application**. This can reduce storage space, save costs, and
    increase retrieval speed.
  prefs: []
  type: TYPE_NORMAL
- en: What Are Text Embeddings?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We start by defining a **vocabulary** that maps all possible input characters
    to integer values. The vocabulary includes not only characters from the alphabet,
    but also special characters, short words, and subwords:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
