- en: I Spent My Money on Benchmarking LLMs on Dutch Exams So You Don’t Have To
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我花钱对荷兰语考试进行LLM基准测试，这样你就不必花钱了。
- en: 原文：[https://towardsdatascience.com/i-spent-my-money-on-benchmarking-llms-on-dutch-exams-so-you-dont-have-to-57a4a35ff3d1?source=collection_archive---------4-----------------------#2024-09-25](https://towardsdatascience.com/i-spent-my-money-on-benchmarking-llms-on-dutch-exams-so-you-dont-have-to-57a4a35ff3d1?source=collection_archive---------4-----------------------#2024-09-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/i-spent-my-money-on-benchmarking-llms-on-dutch-exams-so-you-dont-have-to-57a4a35ff3d1?source=collection_archive---------4-----------------------#2024-09-25](https://towardsdatascience.com/i-spent-my-money-on-benchmarking-llms-on-dutch-exams-so-you-dont-have-to-57a4a35ff3d1?source=collection_archive---------4-----------------------#2024-09-25)
- en: OpenAI’s new o1-preview is way too expensive for how it performs on the results
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI的新o1-preview在结果上的表现，价格却过于昂贵。
- en: '[](https://medium.com/@maartensukel?source=post_page---byline--57a4a35ff3d1--------------------------------)[![Maarten
    Sukel](../Images/5e0ca61edbf14129a2359d5890dc0e47.png)](https://medium.com/@maartensukel?source=post_page---byline--57a4a35ff3d1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--57a4a35ff3d1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--57a4a35ff3d1--------------------------------)
    [Maarten Sukel](https://medium.com/@maartensukel?source=post_page---byline--57a4a35ff3d1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maartensukel?source=post_page---byline--57a4a35ff3d1--------------------------------)[![Maarten
    Sukel](../Images/5e0ca61edbf14129a2359d5890dc0e47.png)](https://medium.com/@maartensukel?source=post_page---byline--57a4a35ff3d1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--57a4a35ff3d1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--57a4a35ff3d1--------------------------------)
    [Maarten Sukel](https://medium.com/@maartensukel?source=post_page---byline--57a4a35ff3d1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--57a4a35ff3d1--------------------------------)
    ·10 min read·Sep 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--57a4a35ff3d1--------------------------------)
    ·阅读时间10分钟·2024年9月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Many of my customers ask for advice on which LLM (Large Language Model) to use
    for building products tailored to Dutch-speaking users. However, most available
    benchmarks are multilingual and don’t specifically focus on Dutch. As a machine
    learning engineer and PhD researcher into machine learning at the University of
    Amsterdam, I know how crucial benchmarks have been to the advancement of AI —
    but I also understand the risks when benchmarks are trusted blindly. This is why
    I decided to experiment and run some Dutch-specific benchmarking of my own.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我的许多客户会询问，应该使用哪种LLM（大语言模型）来构建针对荷兰语用户的产品。然而，大多数现有的基准测试都是多语言的，并没有特别关注荷兰语。作为一名机器学习工程师，并且在阿姆斯特丹大学从事机器学习博士研究的研究员，我知道基准测试在人工智能发展中的关键作用——但我也理解盲目依赖基准测试的风险。这就是为什么我决定亲自进行一些荷兰语特定的基准测试。
- en: In this post, you’ll find an in-depth look at my first attempt at benchmarking
    several large language models (LLMs) on real Dutch exam questions. I’ll guide
    you through the entire process, from gathering over 12,000 exam PDFs to extracting
    question-answer pairs and grading the models’ performance automatically using
    LLMs. You’ll see how models like o1-preview, o1-mini, GPT-4o, GPT-4o-mini, and
    Claude-3 performed across different Dutch educational levels, from VMBO to VWO,
    and whether the higher costs of certain models lead to better results. This is
    just a first go at the problem, and I may dive deeper with more posts like this
    in the future, exploring other models and tasks. I’ll also talk about the challenges
    and costs involved and share some insights on which models offer the best value
    for Dutch-language tasks. If you’re building or scaling LLM-based products for
    the Dutch market, this post will provide valuable insights to help guide your
    choices as of September 2024.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你将深入了解我首次尝试对多个大型语言模型（LLM）进行真实荷兰语考试题目的基准测试。我将引导你完成整个过程，从收集超过12,000个考试PDF文件，到提取问题-答案对，再到使用LLM自动评估模型的表现。你将看到像o1-preview、o1-mini、GPT-4o、GPT-4o-mini和Claude-3等模型在不同荷兰教育水平（从VMBO到VWO）上的表现，以及某些模型的更高成本是否能带来更好的结果。这只是我对这个问题的初步尝试，将来我可能会深入探讨，发布更多类似的文章，探索其他模型和任务。我还将讨论过程中遇到的挑战与成本，并分享一些关于哪些模型在荷兰语任务中提供最佳价值的见解。如果你正在为荷兰市场构建或扩展基于LLM的产品，那么这篇文章将为你提供有价值的见解，帮助你在2024年9月做出决策。
- en: It’s becoming more common for companies like OpenAI to make bold, almost extravagant
    claims about the capabilities of their models, often without enough real-world
    validation to back them up. That’s why benchmarking these models is so important
    — especially when they’re marketed as solving everything from complex reasoning
    to nuanced language understanding. With such grand claims, it’s vital to run objective
    tests to see how well they truly perform, and more specifically, how they handle
    the unique challenges of the Dutch language.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 像OpenAI这样的公司越来越常见大胆甚至奢侈的声明，关于他们模型的能力，然而这些声明往往缺乏足够的现实验证作为支持。这就是为什么基准测试这些模型如此重要——尤其是在它们被宣传为解决从复杂推理到细致语言理解的所有问题时。面对如此宏大的宣称，进行客观测试是至关重要的，看看它们的实际表现如何，特别是它们如何应对荷兰语的独特挑战。
- en: I was surprised to find that there hasn’t been extensive research into benchmarking
    LLMs for Dutch, which is what led me to take matters into my own hands on a rainy
    afternoon. With so many institutions and companies relying on these models more
    and more, it felt like the right time to dive in and start validating these models.
    So, here’s my first attempt to start filling that gap, and I hope it offers valuable
    insights for anyone working with the Dutch-language.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我很惊讶地发现，关于荷兰语大规模语言模型（LLM）基准测试的研究并不广泛，这也促使我在一个雨天的下午亲自动手。随着越来越多的机构和公司依赖这些模型，我觉得现在是时候深入研究并开始验证这些模型了。所以，这是我首次尝试填补这一空白，希望能为任何从事荷兰语工作的人员提供有价值的见解。
- en: Why Dutch-Specific Benchmarks Matter
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么荷兰语特定基准测试很重要
- en: Many of my customers work with Dutch-language products, and they need AI models
    that are both cost-effective and highly performant in understanding and processing
    Dutch. Although large language models (LLMs) have made impressive strides, most
    of the available benchmarks focus on English or multilingual capabilities, often
    neglecting the nuances of smaller languages like Dutch. This lack of focus on
    Dutch is significant because linguistic differences can lead to large performance
    gaps when a model is asked to understand non-English texts.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我的许多客户都在使用荷兰语产品，他们需要既具成本效益又能高效理解和处理荷兰语的AI模型。尽管大规模语言模型（LLMs）取得了显著进展，但大多数现有的基准测试侧重于英语或多语言能力，常常忽略了像荷兰语这样较小语言的细微差别。对荷兰语的忽视是非常重要的，因为语言差异可能导致当模型需要理解非英语文本时，出现巨大的性能差距。
- en: Five years ago, NLP — deep learning models for Dutch were far from mature (Like
    the first versions of BERT). At the time, traditional methods like TF-IDF paired
    with logistic regression often outperformed early deep-learning models on Dutch
    language tasks I worked on. While models (and datasets) have since improved tremendously,
    especially with the rise of transformers and multilingual pre-trained LLMs, it’s
    still critical to verify how well these advances translate to specific languages
    like Dutch. The assumption that performance gains in English carry over to other
    languages isn’t always valid, especially for complex tasks like reading comprehension.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 五年前，荷兰语的自然语言处理（NLP）——深度学习模型远未成熟（比如BERT的早期版本）。当时，像TF-IDF配合逻辑回归等传统方法在我从事的荷兰语任务中常常优于早期的深度学习模型。尽管自那时以来，模型（和数据集）得到了极大的改进，特别是随着变换器（transformers）和多语言预训练LLM的崛起，但仍然至关重要的是验证这些进展如何在荷兰语等特定语言中转化。假设英语中的性能提升可以迁移到其他语言并非总是有效，尤其是在复杂的任务如阅读理解时。
- en: That’s why I focused on creating a custom benchmark for Dutch, using real exam
    data from the Dutch “Nederlands” exams (These exams enter the public domain after
    they have been published). These exams don’t just involve simple language processing;
    they test “begrijpend lezen” (reading comprehension), requiring students to understand
    the intent behind various texts and answer nuanced questions about them. This
    type of task is particularly important because it’s reflective of real-world applications,
    like processing and summarizing legal documents, news articles, or customer queries
    written in Dutch.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是为什么我专注于为荷兰语创建一个定制基准，使用荷兰语“荷兰语”（Nederlands）考试中的真实考试数据（这些考试在发布后会进入公共领域）。这些考试不仅仅涉及简单的语言处理；它们还测试“begrijpend
    lezen”（阅读理解），要求学生理解各种文本背后的意图，并回答有关它们的细致问题。这种类型的任务尤其重要，因为它反映了现实世界的应用，如处理和总结荷兰语的法律文件、新闻文章或客户查询。
- en: By benchmarking LLMs on this specific task, I wanted to gain deeper insights
    into how models handle the complexity of the Dutch language, especially when asked
    to interpret intent, draw conclusions, and respond with accurate answers. This
    is crucial for businesses building products tailored to Dutch-speaking users.
    My goal was to create a more targeted, relevant benchmark to help identify which
    models offer the best performance for Dutch, rather than relying on general multilingual
    benchmarks that don’t fully capture the intricacies of the language.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在这个特定任务上对大语言模型（LLMs）进行基准测试，我希望能深入了解模型如何处理荷兰语的复杂性，特别是在被要求解释意图、得出结论并给出准确答案时。这对于为荷兰语用户量身定制产品的企业至关重要。我的目标是创建一个更具针对性和相关性的基准，以帮助识别哪些模型在荷兰语任务中表现最佳，而不是依赖那些无法完全捕捉荷兰语复杂性的通用多语言基准。
- en: '![](../Images/06cb926cc5629a8a1c2058503421f313.png)![](../Images/3e56fcdb2bed82b97159ea446bc3dd94.png)![](../Images/c0a96ab6170e2c975eb7be27e7808c54.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06cb926cc5629a8a1c2058503421f313.png)![](../Images/3e56fcdb2bed82b97159ea446bc3dd94.png)![](../Images/c0a96ab6170e2c975eb7be27e7808c54.png)'
- en: Examples of Dutch exams in the Netherlands, these exams enter the public domain
    after they have been published.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 荷兰考试的示例，这些考试在发布后进入公共领域。
- en: How the Benchmarking Works
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试如何运作
- en: 'Let me walk you through how I built and executed this benchmark:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我为您详细讲解一下我是如何构建和执行这个基准测试的：
- en: '**PDF Collection**: I began by collecting over 12,000 PDFs from Dutch state
    exams. These exams include reading passages and questions that test a student’s
    ability to comprehend and interpret written Dutch.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**PDF收集**：我首先收集了超过12,000份荷兰国家考试的PDF文件。这些考试包含阅读理解段落和问题，用于测试学生理解和解读书面荷兰语的能力。'
- en: '**Data Extraction**: Next, I extracted the relevant information from the PDFs
    using LLMs, turning the text into structured question-answer (Q&A) pairs. For
    example, a typical question from a PDF might look like this: *“Wat is de hoofdgedachte
    van de schrijver in alinea 3 van tekst 2?”* After extraction, this question becomes
    a structured Q&A pair like this: **Question**: What is the main idea of the author
    in paragraph 3?'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据提取**：接下来，我使用LLMs从PDF中提取相关信息，将文本转化为结构化的问答（Q&A）对。例如，来自PDF中的一个典型问题可能是：“Wat
    is de hoofdgedachte van de schrijver in alinea 3 van tekst 2?” 提取后，这个问题变成了一个结构化的问答对，如下所示：**问题**：作者在文本2的第3段中的主要观点是什么？'
- en: '**Correct Answer**: The author argues that technological advancements bring
    both positive and negative consequences (2 points)'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**正确答案**：作者认为，技术进步带来了积极和消极的后果（2分）'
- en: '**Model selection:** The selection of models in this benchmark includes a mix
    of well-known LLMs, ranging from smaller, more cost-efficient models like **o1-mini**
    and **gpt-4o-mini**, to more expensive options like **o1-preview**. These models
    were tested on Dutch-language tasks to assess their ability to handle reading
    comprehension (“begrijpend lezen”) tasks from the Dutch “Nederlands” exam. Notably,
    **Claude-3–5-sonnet** and **Claude-3-haiku** were also included, providing insight
    into how AI models from Anthropic stack up against the GPT family. I selected
    several models to do this initial benchmark with, definitely not extensive enough
    yet. Let me know if you would want me to add more in the future!'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型选择**：这个基准测试中选择的模型包括一系列知名的大语言模型（LLMs），从像**o1-mini**和**gpt-4o-mini**这样的小型、成本效益较高的模型，到像**o1-preview**这样更昂贵的选项。这些模型在荷兰语任务上进行了测试，评估它们处理荷兰语“阅读理解”（“begrijpend
    lezen”）任务的能力，这些任务来自荷兰的“荷兰语”考试。值得注意的是，**Claude-3–5-sonnet**和**Claude-3-haiku**也被包括在内，提供了对Anthropic的AI模型与GPT系列模型对比的洞察。我选择了几个模型进行这个初步的基准测试，虽然还不够全面。如果你希望我在未来加入更多模型，请告诉我！'
- en: '**Question answering:** The fun part! I hooked up the APIs of the LLMs and
    gave them a question with corresponding texts and let them answer the questions.
    It became less fun when the more expensive models kicked in and my credit card
    started informing me it was not very excited about these endeavors. The lengths
    I go through for my readers!'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**问答**：最有趣的部分！我将大语言模型（LLM）的API连接起来，给它们提供问题和相应的文本，并让它们回答问题。当更昂贵的模型参与测试时，过程就不那么有趣了，我的信用卡也开始告诉我，它并不很兴奋参与这些尝试。我为读者所做的努力可见一斑！'
- en: '**Automated Grading**: Using a prompt that knows the correct answer I ask for
    an objective decision if the required answer is in the answer given by the LLM.
    With this method, the LLM-generated answers are compared to the correct answers
    from the official answer sheets. Each question is scored based on how closely
    the model’s answer matches the correct one.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自动评分**：使用已知正确答案的提示，我要求模型对其给出的答案进行客观判断，检查答案中是否包含正确答案。通过这种方法，LLM生成的答案与官方答案进行比较，每个问题的得分取决于模型的答案与正确答案的匹配程度。  '
- en: '**Scoring & Reporting**: After grading, the models are evaluated on how many
    points they earned relative to the maximum possible points for each exam. This
    scoring gives a clear idea of which models perform well and which struggle with
    Dutch reading comprehension tasks.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评分与报告**：在评分之后，模型根据每个考试的最大可能得分与实际得分的比值进行评估。通过这一评分，可以清晰地了解哪些模型在荷兰语阅读理解任务中表现优异，哪些则存在困难。  '
- en: It’s a bit surreal when you think about it — LLMs benchmarking other LLMs, graded
    by LLMs, without a human in sight (except me, writing the code to let them do
    this on a rainy afternoon). This method allows for scalable and automated comparisons,
    but it’s not without limitations. While this approach gives a strong basis for
    comparing models, it’s not the final word. Still, I wanted to put together something
    to gain insight into how these models perform in the context of the Dutch language
    specifically.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '当你想到这一点时，感觉有些超现实——LLM基准测试其他LLM，由LLM评分，没有人类参与（除了我在一个雨天下午编写代码让它们执行这个任务）。这种方法允许可扩展和自动化的比较，但也并非没有局限性。虽然这种方法为比较模型提供了坚实的基础，但它并非最终结论。不过，我还是想整理一些内容，以便专门了解这些模型在荷兰语环境中的表现。  '
- en: The API Cost Dilemma
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'API费用困境  '
- en: Running these benchmarks came at a significant cost. Processing full-text exam
    questions with every request quickly consumed tokens, and I ended up spending
    over €100 in API fees just for this initial round of testing. This forced some
    limitations on how many questions I could process with the different models, but
    it was still enough to uncover some valuable insights.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '进行这些基准测试需要付出相当大的成本。每次请求时处理完整的考试问题会迅速消耗代币，我在这轮初步测试中仅API费用就花费了超过100欧元。这迫使我对能够处理的问题数量进行了限制，虽然如此，仍然足以发现一些有价值的见解。  '
- en: If any Dutch institutions are interested in collaborating on more extensive
    benchmarking efforts, I’d be eager to work together to scale this project. By
    expanding the scope, we could dive deeper into a wider range of exams, significantly
    increase the number of questions answered, and benchmark a broader selection of
    models. This would provide even more comprehensive insights into model performance
    help refine our understanding of how various LLMs handle Dutch-language tasks
    across different educational levels and complexities and help companies pick the
    best LLM and not the best marketing.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有任何荷兰机构有兴趣合作进行更广泛的基准测试工作，我非常愿意一起合作以扩大该项目的规模。通过扩大范围，我们可以深入研究更广泛的考试，显著增加回答的问题数量，并基准测试更多的模型。这将为我们提供更全面的模型性能洞察，帮助我们更加准确地了解各种LLM在处理荷兰语任务时的表现，跨越不同的教育水平和复杂度，并帮助公司选择最佳的LLM，而不是被营销所迷惑。
- en: 'I conducted two separate benchmarks: one with smaller, cheaper models, and
    another with larger, more expensive models until I hit my daily API limits. The
    number of exam questions used was 329 for the cheaper models and 104 for the more
    expensive “titans.” To put this in perspective, this would be equivalent to a
    human taking approximately 4 to 13 full exams.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '我进行了两次独立的基准测试：一次使用较小、较便宜的模型，另一次使用较大、较昂贵的模型，直到达到每日API限制。便宜模型使用了329个考试问题，而更昂贵的“巨人”模型使用了104个考试问题。为了更直观地理解，这相当于一个人完成大约4到13场完整的考试。  '
- en: 'Here’s a breakdown of the model pricing (as of September 25th, via [LLM Price
    Check](https://llmpricecheck.com/)):'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '以下是模型定价的详细信息（截至9月25日，通过[LLM价格检查](https://llmpricecheck.com/)提供）：  '
- en: '![](../Images/68d29300c0c03c63172696f40be5b99e.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68d29300c0c03c63172696f40be5b99e.png)  '
- en: From [https://llmpricecheck.com/](https://llmpricecheck.com/) (Checked September
    25th) Image by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '来自[https://llmpricecheck.com/](https://llmpricecheck.com/)（检查日期：9月25日） 图片由作者提供  '
- en: “o1-preview” costs $10 per million tokens for input and $30 for output.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '“o1-preview”每百万个代币的输入费用为10美元，输出费用为30美元。  '
- en: “o1-mini,” on the other hand, costs only $0.10 per million tokens for input
    and $0.25 for output.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '“o1-mini”则每百万个代币的输入费用仅为0.10美元，输出费用为0.25美元。  '
- en: This means “o1-preview” is approximately 114 times more expensive than “o1-mini.”
    The key question, then, is whether the extra cost translates into better performance,
    and if so, by how much. So, is it worth the extra cost?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着“o1-preview”比“o1-mini”贵大约114倍。那么，关键问题是额外的成本是否能够带来更好的性能，如果有的话，提升的幅度有多大。那么，它值得这额外的费用吗？
- en: 'Benchmarking the Models: Fast, Cheap, and… Better?'
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型基准测试：快速、便宜，且……更好？
- en: Since the launch of **o1-preview**, I’ve been skeptical about its performance,
    as it seemed slower and significantly more expensive compared to other models.
    So, I was eager to see how it would perform in this benchmark.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 自从**o1-preview**发布以来，我对它的性能一直持怀疑态度，因为它似乎比其他模型更慢，且显著更贵。因此，我迫切想知道它在这次基准测试中的表现如何。
- en: Interestingly, the **o1-mini** model actually outperformed more expensive options
    like **GPT-4o** and **o1-preview**. Specifically, **o1-mini** earned **66.75%**
    of the possible points, compared to **62.32%** for **GPT-4O** and **61.91%** for
    **o1-preview**. Based on these results, I’m now considering shifting from **GPT-4O-mini**,
    which earned **61.36%**, to **o1-mini** for Dutch language tasks, as it offers
    better performance at a significantly lower cost.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，**o1-mini**模型实际上超越了更昂贵的选项，如**GPT-4o**和**o1-preview**。具体来说，**o1-mini**获得了可能得分的**66.75%**，而**GPT-4O**为**62.32%**，**o1-preview**为**61.91%**。根据这些结果，我现在考虑将荷兰语任务的工作从**GPT-4O-mini**（得分为**61.36%**）转向**o1-mini**，因为它在提供更好的性能的同时，成本明显更低。
- en: 'Here’s how the other models fared:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 其他模型的表现如下：
- en: '**Claude-3–5-sonnet** earned **61.28%**, while'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude-3–5-sonnet**得分为**61.28%**，而'
- en: '**Claude-3-haiku** lagged behind, with only **42.91%**.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude-3-haiku**的表现较差，仅为**42.91%**。'
- en: Seems like going for the Claude models will cause less performant products that
    are also more expensive.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 看来选择Claude模型会导致性能较差且更昂贵的产品。
- en: The performance breakdown also showed that all of these models handled **VMBO-level**
    exams more easily but struggled with the more complex **VWO-level** questions
    — something expected given the increasing difficulty of the exams. This highlights
    the value of using a more cost-effective model like **o1-mini**, which not only
    performs well across a variety of tasks but also delivers strong results on more
    advanced educational content.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 性能分析还显示，所有这些模型在处理**VMBO级别**的考试时较为轻松，但在处理更复杂的**VWO级别**问题时表现较差——考虑到考试难度的逐步增加，这是预期中的情况。这突出了像**o1-mini**这样更具成本效益的模型的价值，它不仅在各种任务中表现良好，而且在更高难度的教育内容上也能取得出色的成绩。
- en: '![](../Images/af865fd8fce331d3df1ade3266656372.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af865fd8fce331d3df1ade3266656372.png)'
- en: Results of 6 LLM‘s competing on answering 104 Dutch exam questions. Image by
    author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 6个LLM在回答104道荷兰语考试题目的竞争结果。图片由作者提供
- en: '![](../Images/7c5a4f83a0560679ca70e96c395e3233.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c5a4f83a0560679ca70e96c395e3233.png)'
- en: Results of 3 LLM’s competing on answering 329 Dutch exam questions. Image by
    author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 3个大型语言模型（LLM）在回答329道荷兰语考试题目的竞争结果。图片由作者提供
- en: '**Handling Different Exam Levels**: The exams are divided into different educational
    levels, such as VMBO, HAVO, and VWO. My system tracks how well models perform
    across these different levels. Unsurprisingly, the models did better on simpler
    VMBO-level questions and struggled more with complex VWO-level questions.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**应对不同考试等级**：这些考试被分为不同的教育等级，如VMBO、HAVO和VWO。我的系统会跟踪模型在这些不同等级中的表现。毫不奇怪，模型在较简单的VMBO级别问题上表现较好，而在复杂的VWO级别问题上则显得较为吃力。'
- en: '![](../Images/72bace1ec5311995e729a98d260da708.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72bace1ec5311995e729a98d260da708.png)'
- en: Comparison of eductional level and model performance between the six models.
    Image by author
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 六个模型在不同教育水平和模型表现之间的对比。图片由作者提供
- en: '![](../Images/e5c36caf01aeee1513f9b26f9a28f087.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5c36caf01aeee1513f9b26f9a28f087.png)'
- en: The percentage of points scored over all the different educational levels for
    the tree cheaper models. Image by author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 三个更便宜模型在不同教育水平上的得分百分比。图片由作者提供
- en: Limitations and Next Steps
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 局限性与下一步
- en: It’s important to mention that it’s possible some of these Dutch exam texts
    may have been part of the training data for certain LLMs, which could have impacted
    the results. However, these benchmarks still offer valuable insights for developers
    working on Dutch-language products.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 需要提到的是，这些荷兰语考试题目中的某些文本可能已作为某些LLM的训练数据，这可能会影响结果。然而，这些基准测试仍然为从事荷兰语产品开发的开发者提供了宝贵的见解。
- en: That said, the number of questions processed so far is relatively low. In future
    iterations, I plan to run more comprehensive benchmarks to generate even deeper
    insights into the models’ performance.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，到目前为止处理的问题数量相对较少。在未来的版本中，我计划运行更全面的基准测试，以便对模型的表现产生更深入的洞察。
- en: This approach to benchmarking can be extended to other subjects, and I also
    filtered out pure-text questions. Setting up a benchmark for multimodal models,
    which can analyze images alongside text, would be particularly interesting since
    many exams, such as history and geography, involve visual elements like charts,
    maps, or diagrams.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这种基准测试方法可以扩展到其他科目，我还筛选出了纯文本问题。为多模态模型（可以同时分析图像和文本）设置基准测试将特别有趣，因为许多考试（如历史和地理）涉及到诸如图表、地图或图示等视觉元素。
- en: In the future, this method could easily be applied to other Dutch courses such
    as **Biologie**, **Natuurkunde**, **Scheikunde**, **Wiskunde A/B/C**, **Aardrijkskunde**,
    **Bedrijfseconomie**, **Economie**, **Filosofie**, **Geschiedenis**, **Maatschappijwetenschappen**,
    **Kunst**, **Muziek**, **Tehatex**, and languages like **Arabisch**, **Duits**,
    **Engels**, **Frans**, **Fries**, **Grieks**, **Latijn**, **Russisch**, **Spaans**,
    and **Turks**. Extending this to subjects like **Natuur- en scheikunde 1 & 2**,
    **Wiskunde**, **Maatschappijleer**, and even the arts (e.g., **Dans**, **Drama**,
    **Beeldende vakken**) would provide a broad view of model performance across diverse
    disciplines.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，这种方法可以轻松应用于其他荷兰语课程，例如**生物学**、**自然科学**、**化学**、**数学 A/B/C**、**地理学**、**企业经济学**、**经济学**、**哲学**、**历史**、**社会科学**、**艺术**、**音乐**、**技术应用**，以及像**阿拉伯语**、**德语**、**英语**、**法语**、**弗里斯兰语**、**希腊语**、**拉丁语**、**俄语**、**西班牙语**和**土耳其语**等语言。将其扩展到如**自然与化学
    1 & 2**、**数学**、**社会学**，甚至艺术（例如**舞蹈**、**戏剧**、**视觉艺术**）等科目，可以提供一个跨学科的模型性能广泛视角。
- en: If you’re interested in supporting this project, feel free to reach out or [buy
    me a coffee](https://buymeacoffee.com/maartensukel)! The code I’ve developed is
    scalable and can handle a much larger range of Dutch exams and topics with the
    right resources. Collaborating to explore these additional subjects and multimodal
    benchmarks would open up even deeper insights into how AI models can perform in
    Dutch education.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣支持这个项目，请随时联系我或[请我喝杯咖啡](https://buymeacoffee.com/maartensukel)! 我开发的代码是可扩展的，能够在有足够资源的情况下处理更多荷兰语考试和课题。与我合作，探索这些额外的科目和多模态基准，将为我们提供关于AI模型在荷兰教育中表现的更深入的见解。
- en: Final Thoughts
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的思考
- en: If you want help with building or scaling AI or machine learning products responsibly,
    or if you’re curious about which LLMs perform best in specific languages like
    Dutch, I’d be happy to help through my company, **The AI Factory**. Feel free
    to reach out! Feel free to contact [me](http://contact@maartensukel.nl), and if
    you found this benchmarking useful, follow me on [LinkedIn](https://www.linkedin.com/in/maartensukel/)
    for updates on future AI and performance insights.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要帮助，负责地构建或扩展AI或机器学习产品，或者你对哪些LLM在荷兰语等特定语言中的表现最好感兴趣，我很乐意通过我的公司**The AI Factory**为你提供帮助。随时联系我！如果你觉得这个基准测试有用，可以通过[LinkedIn](https://www.linkedin.com/in/maartensukel/)关注我，获取关于未来AI和性能的更新。
