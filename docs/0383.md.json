["```py\nimport openai\nimport os\nimport re\nimport pandas as pd\nimport spacy\nfrom ipywidgets import FloatProgress\nfrom tqdm import tqdm\n\n# Load English tokenizer, tagger, parser and NER\nnlp = spacy.load(\"en_core_web_sm\")\n```", "```py\nos.environ[\"OPENAI_API_KEY\"] = \"XXXXXX\"  # replace with yours\n```", "```py\nmovies = pd.read_csv(\"netflix_titles.csv\")\nmovies = movies.sample(n=1000) #I just used 1000 rows of data to reduce the runtime\n```", "```py\ndef predict_genres(movie_description):\n    prompt = f\"Predict the top three genres (only genres, not descriptions) for a movie with the following description: {movie_description}\"\n    response = openai.completions.create(\n      model=\"gpt-3.5-turbo-instruct\",  # You can use the GPT-3 model for this task\n      prompt=prompt,\n      max_tokens=50,\n      n=1,\n      stop=None,\n      temperature=0.2\n    )\n    predicted_genres = response.choices[0].text.strip()\n    return predicted_genres\n```", "```py\n# Create an empty list to store the predicted genres\nall_predicted_genres = []\n\n# Create an empty set to store unique genres\nunique_genres_set = set()\n\n# Iterate through the movie descriptions\nfor index, row in tqdm(movies.iterrows(), total=movies.shape[0]):\n\n        # Get the movie description\n        movie_description = row['description']\n\n        # Predict the genres for the movie description\n        predicted_genres = predict_genres(movie_description)\n\n        # Extract genres from the text\n        predicted_genres_tokens = nlp(predicted_genres)\n        predicted_genres_tokens = predicted_genres_tokens.text\n\n        # Use regular expression to extract genres\n        genres_with_numbers = re.findall(r'\\d+\\.\\s*([^\\n]+)', predicted_genres_tokens)\n\n        # Remove leading/trailing whitespaces from each genre\n        predicted_genres = [genre.strip().lower() for genre in genres_with_numbers]\n\n        # Update the set of unique genres\n        unique_genres_set.update(predicted_genres)\n\n# Convert the set of unique genres back to a list\nall_unique_genres = list(unique_genres_set)\n```", "```py\nall_unique_genres = pd.DataFrame(all_unique_genres,columns=['genre'])\nall_unique_genres.to_csv(\"genres_taxonomy_quick.csv\")\n```", "```py\n#Read in our genre list\ngenres = pd.read_csv('genres_taxonomy_quick.csv')  # Replace 'genres_taxonomy_quick.csv' with the actual file name\ngenres = genres['genre']\n\n#Read in our movie data\nmovies = pd.read_csv(\"netflix_titles.csv\")\nmovies = movies.sample(n=1000) #This takes a while to run so I didn't do it for the entire dataset at once\n```", "```py\n#Function to filter predicted genres\ndef filter_predicted_genres(predicted_genres, predefined_genres):\n    # Use word embeddings to calculate semantic similarity between predicted and predefined genres\n    predicted_genres_tokens = nlp(predicted_genres)\n    predicted_genres_tokens = predicted_genres_tokens.text\n    # Use regular expression to extract genres\n    genres_with_numbers = re.findall(r'\\d+\\.\\s*([^\\n]+)', predicted_genres_tokens)\n    # Remove leading/trailing whitespaces from each genre\n    predicted_genres = [genre.strip().lower() for genre in genres_with_numbers]\n\n    filtered_genres = []\n    similarity_scores = []\n\n    for predicted_genre in predicted_genres:\n        max_similarity = 0\n        best_match = None\n        for predefined_genre in predefined_genres:\n            similarity_score = nlp(predicted_genre).similarity(nlp(predefined_genre))\n            if similarity_score > max_similarity:  # Adjust the threshold as needed\n                max_similarity = similarity_score\n                best_match = predefined_genre\n        filtered_genres.append(best_match)\n        similarity_scores.append(max_similarity)\n\n    # Sort the filtered genres based on the similarity scores\n    filtered_genres = [x for _, x in sorted(zip(similarity_scores, filtered_genres), reverse=True)]\n\n    return filtered_genres\n\n#Function to add filtered predictions to DataFrame\ndef add_predicted_genres_to_df(df, predefined_genres):   \n    # Iterate through the dataframe\n    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n        # Apply the predict_genres function to the movie description\n        predicted_genres = predict_genres(row['description'])\n        # Prioritize the predicted genres\n        filtered_genres = filter_predicted_genres(predicted_genres, predefined_genres)\n        # Add the prioritized genres to the dataframe\n        df.at[index, 'predicted_genres'] = filtered_genres\n```", "```py\nadd_predicted_genres_to_df(movies, genres)\n```", "```py\n# Split the lists into separate columns with specific names\nmovies[['genre1', 'genre2', 'genre3']] = movies['predicted_genres'].apply(lambda x: pd.Series((x + [None, None, None])[:3]))\n\n#Keep only the columns we need for similarity\nmovies = movies[['title','genre1','genre2','genre3']]\n\n#Drop duplicates\nmovies = movies.drop_duplicates()\n\n#Set the 'title' column as our index\nmovies = movies.set_index('title')\n```", "```py\n# Combine genre columns into a single column\nmovies['all_genres'] = movies[['genre1', 'genre2', 'genre3']].astype(str).agg(','.join, axis=1)\n\n# Split the genres and create dummy variables for each genre\ngenres = movies['all_genres'].str.get_dummies(sep=',')\n\n# Concatenate the dummy variables with the original DataFrame\nmovies = pd.concat([movies, genres], axis=1)\n\n# Drop unnecessary columns\nmovies.drop(['all_genres', 'genre1', 'genre2', 'genre3'], axis=1, inplace=True)\n```", "```py\n# If there are duplicate columns due to the one-hot encoding, you can sum them up\nmovie_genre_matrix = movies.groupby(level=0, axis=1).sum()\n\n# Calculate cosine similarity \nsimilarity_matrix = cosine_similarity(movie_genre_matrix, movie_genre_matrix)\n```", "```py\ndef find_similar_movies(movie_name, movie_genre_matrix, num_similar_movies=3):\n    # Calculate cosine similarity\n    similarity_matrix = cosine_similarity(movie_genre_matrix, movie_genre_matrix)\n\n    # Find the index of the given movie\n    movie_index = movie_genre_matrix.index.get_loc(movie_name)\n\n    # Sort and get indices of most similar movies (excluding the movie itself)\n    most_similar_indices = np.argsort(similarity_matrix[movie_index])[:-num_similar_movies-1:-1]\n\n    # Return the most similar movies\n    return movie_genre_matrix.index[most_similar_indices].tolist()\n```", "```py\n# Example usage\nsimilar_movies = find_similar_movies(\"Eat Pray Love\", movie_genre_matrix, num_similar_movies=4)\nprint(similar_movies)\n```", "```py\n# Melt the dataframe to unpivot genre columns\nmelted_df = pd.melt(movies, id_vars=['title'], value_vars=['genre1', 'genre2', 'genre3'], var_name='Genre', value_name='GenreValue')\n\ngenre_links = pd.crosstab(index=melted_df['title'], columns=melted_df['GenreValue'])\n\n# Create combinations of genres for each title\ncombinations_list = []\n\nfor title, group in melted_df.groupby('title')['GenreValue']:\n    genre_combinations = list(combinations(group, 2))\n    combinations_list.extend([(title, combo[0], combo[1]) for combo in genre_combinations])\n\n# Create a new dataframe from the combinations list\ncombinations_df = pd.DataFrame(combinations_list, columns=['title', 'Genre1', 'Genre2'])\n\ncombinations_df = combinations_df[['Genre1','Genre2']]\n\ncombinations_df = combinations_df.rename(columns={\"Genre1\": \"source\", \"Genre2\": \"target\"}, errors=\"raise\")\n\ncombinations_df = combinations_df.set_index('source')\n\ncombinations_df.to_csv(\"genreCombos.csv\")\n```"]