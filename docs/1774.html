<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Let’s reproduce NanoGPT with JAX!(Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Let’s reproduce NanoGPT with JAX!(Part 1)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lets-reproduce-nanogpt-with-jax-part-1-95bec4630eb4?source=collection_archive---------2-----------------------#2024-07-21">https://towardsdatascience.com/lets-reproduce-nanogpt-with-jax-part-1-95bec4630eb4?source=collection_archive---------2-----------------------#2024-07-21</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="a49b" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><a class="af hd" href="https://medium.com/@lou1swang/lets-reproduce-nanogpt-with-jax-part-1-95bec4630eb4" rel="noopener">Part 1: Build 124M GPT2 with JAX. </a><br/><a class="af hd" href="https://medium.com/@lou1swang/lets-reproduce-nanogpt-with-jax-part-2-175k-1350k-tokens-sec-in-single-gpu-ff2664ef18d3" rel="noopener">Part 2: Optimize the training speed in Single GPU. </a><br/>Part 3: Multi-GPU Training in Jax.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://lou1swang.medium.com/?source=post_page---byline--95bec4630eb4--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Louis Wang" class="l ep by dd de cx" src="../Images/259879ae7cd20b7843936d1f4cdbec52.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*SO8c_peyUW8OCa8SDAUpQw.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--95bec4630eb4--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://lou1swang.medium.com/?source=post_page---byline--95bec4630eb4--------------------------------" rel="noopener follow">Louis Wang</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--95bec4630eb4--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 21, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk lb lc ab q ee ld le" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lf"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap ie li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="0334" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Inspired by Andrej Karpathy’s recent youtube video on <a class="af hd" href="https://www.youtube.com/watch?v=l8pRSuU81PU&amp;t=1646s" rel="noopener ugc nofollow" target="_blank">Let’s reproduce GPT-2 (124M)</a>, I’d like to rebuild it with most of the training optimizations in Jax. Jax is built for highly efficient computation speed, and it is quite interesting to compare Pytorch with its recent training optimization, and Jax with its related libraries like Flax (Layers API for neural network training for Jax)and Optax (a gradient processing and optimization library for JAX). We will quickly learn what is Jax, and rebuild the GPT with Jax. In the end, we will compare the token/sec with multiGPU training between Pytorch and Jax!</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nh"><img src="../Images/327bdd2b1dfc0479960467df61f2d5da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OyoM_vjG1Dl28NmiEJFasA.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">AI generated GPT</figcaption></figure><h2 id="1222" class="ny nz fq bf oa ob oc od oe of og oh oi ms oj ok ol mw om on oo na op oq or os bk">What is Jax?</h2><p id="a655" class="pw-post-body-paragraph mj mk fq ml b go ot mn mo gr ou mq mr ms ov mu mv mw ow my mz na ox nc nd ne fj bk">Based on its <a class="af hd" href="https://jax.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">readthedoc</a>, JAX is a Python library for accelerator-oriented array computation and program transformation, designed for high-performance numerical computing and large-scale machine learning. I would like to introduce JAX with its name. While someone calls it Just Another <a class="af hd" href="https://github.com/openxla/xla" rel="noopener ugc nofollow" target="_blank">XLA</a> (Accelerated Linear Algibra), I prefer to call it J(it) A(utograd) X(LA) to demonstrate its capability of high efficiency.</p><p id="c0b2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">J — Just-in-time (JIT) Compilation. When you run your python function, Jax converts it into a primitive set of operation called Jaxpr. Then the Jaxpr expression will be converted into an input for XLA, which compiles the lower-level scripts to produce an optimized exutable for target device (CPU, GPU or TPU).</p><p id="7bc3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A — Autograd. Computing gradients is a critical part of modern machine learning methods, and you can just call <code class="cx oy oz pa pb b">jax.grad()</code> to get gradients which enables you to optimize the models.</p><p id="208b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">X — XLA. This is a open-source machine learning compiler for CPU, GPU and ML accelerators. In general, XLA performs several built-in optimization and analysis passes on the <a class="af hd" href="https://github.com/openxla/stablehlo" rel="noopener ugc nofollow" target="_blank">StableHLO</a> graph, then sends the HLO computation to a backend for further HLO-level optimizations. The backend then performs target-specific code generation.</p><p id="43e4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Those are just some key features of JAX, but it also has many user friendly numpy-like APIs in <code class="cx oy oz pa pb b">jax.numpy</code> , and automatic vectorization with <code class="cx oy oz pa pb b">jax.vmap</code> , and parallize your codes into multiple devices via <code class="cx oy oz pa pb b">jax.pmap</code> . We will cover more Jax concepts nd applications in the futher blogs, but now let’s reproduct the NanoGPT with Jax!</p><h2 id="076e" class="ny nz fq bf oa ob oc od oe of og oh oi ms oj ok ol mw om on oo na op oq or os bk">From Attention to Transformer</h2><p id="c3d3" class="pw-post-body-paragraph mj mk fq ml b go ot mn mo gr ou mq mr ms ov mu mv mw ow my mz na ox nc nd ne fj bk">GPT is a decoder-only transformer model, and the key building block is Attention module. We can first define a model config dataclass to save the model hyperparameters of the model, so that the model module can consume it efficiently to initialize the model architecture. Similar to the 124M GPT model, here we initialize a 12-layer transformer decoder with 12 heads and vocab size as 50257 tokens, each of which has 768 embedding dimension. The block size for the attention calculation is 1024.</p><pre class="ni nj nk nl nm pc pb pd bp pe bb bk"><span id="919f" class="pf nz fq pb b bg pg ph l pi pj">from dataclasses import dataclass<br/><br/>@dataclass<br/>class ModelConfig:<br/>  vocab_size: int = 50257<br/>  n_head: int = 12<br/>  n_embd: int = 768<br/>  block_size: int = 1024<br/>  n_layer: int = 12<br/>  dropout_rate: float = 0.1</span></pre><p id="a5ba" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Next comes to the key building block of the transformer model — Attention. The idea is to process the inputs into three weight matrics: Key, Query, and Value. Here we rely on the <code class="cx oy oz pa pb b">flax</code> , a the Jax Layer and training API library to initialize the 3 weight matrix, by just call the <code class="cx oy oz pa pb b"><a class="af hd" href="https://flax.readthedocs.io/en/v0.5.3/_autosummary/flax.linen.Dense.html" rel="noopener ugc nofollow" target="_blank">flax.linen.Dense</a></code> . As mentioned, Jax has many numpy-like APIs, so we reshape the outputs after the weight matrix with <code class="cx oy oz pa pb b"><a class="af hd" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.reshape.html" rel="noopener ugc nofollow" target="_blank">jax.numpy.reshape</a></code> from [batch_size, sequence_length, embedding_dim] to [batch_size, sequence_length, num_head, embedding_dim / num_head]. Since we need to do matrix multiplication on the key and value matrics, jax also has <code class="cx oy oz pa pb b"><a class="af hd" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.matmul.html" rel="noopener ugc nofollow" target="_blank">jax.numpy.matmul</a></code> API and <code class="cx oy oz pa pb b"><a class="af hd" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.transpose.html" rel="noopener ugc nofollow" target="_blank">jax.numpy.transpose</a></code> (transpose the key matrix for multiplication).</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div class="nf ng pk"><img src="../Images/8f2916bfb42338ef17e1526a677e4f85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/0*TLHNAqg081AFom4Y.png"/></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Multihead Attention</figcaption></figure><p id="514a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Note that we need to put a mask on the attention matrix to avoid information leakage (prevent the previous tokens to have access to the later tokens), <code class="cx oy oz pa pb b"><a class="af hd" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.tril.html" rel="noopener ugc nofollow" target="_blank">jax.numpy.tril</a></code> helps build a lower triangle array, and <code class="cx oy oz pa pb b"><a class="af hd" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.where.html" rel="noopener ugc nofollow" target="_blank">jax.numpy.where</a></code> can fill the infinite number for us to get 0 after softmax <code class="cx oy oz pa pb b"><a class="af hd" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.nn.softmax.html" rel="noopener ugc nofollow" target="_blank">jax.nn.softmax</a></code> . The full codes of multihead attention can be found below.</p><pre class="ni nj nk nl nm pc pb pd bp pe bb bk"><span id="2570" class="pf nz fq pb b bg pg ph l pi pj">from flax import linen as nn<br/>import jax.numpy as jnp<br/><br/>class CausalSelfAttention(nn.Module):<br/><br/>  config: ModelConfig<br/><br/>  @nn.compact<br/>  def __call__(self, x, deterministic=True):<br/><br/>    assert len(x.shape) == 3<br/><br/>    b, l, d = x.shape<br/><br/>    q     = nn.Dense(self.config.n_embd)(x)<br/>    k     = nn.Dense(self.config.n_embd)(x)<br/>    v     = nn.Dense(self.config.n_embd)(x)<br/>    # q*k / sqrt(dim) -&gt; softmax -&gt; @v<br/>    q     = jnp.reshape(q, (b, l, d//self.config.n_head , self.config.n_head))<br/>    k     = jnp.reshape(k, (b, l, d//self.config.n_head , self.config.n_head))<br/>    v     = jnp.reshape(v, (b, l, d//self.config.n_head , self.config.n_head))<br/>    norm  = jnp.sqrt(list(jnp.shape(k))[-1])<br/>    attn  = jnp.matmul(q,jnp.transpose(k, (0,1,3,2))) / norm<br/>    mask  = jnp.tril(attn)<br/>    attn  = jnp.where(mask[:,:,:l,:l], attn, float("-inf"))<br/>    probs = jax.nn.softmax(attn, axis=-1)<br/>    y     = jnp.matmul(probs, v)<br/>    y     = jnp.reshape(y, (b,l,d))<br/>    y     = nn.Dense(self.config.n_embd)(y)<br/>    return y</span></pre><p id="3238" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">You may notice that there is no <code class="cx oy oz pa pb b">__init__</code> or <code class="cx oy oz pa pb b">forward</code> methods as you can see in the pytorch. This is the special thing for jax, where you can explicitly define the layers with <code class="cx oy oz pa pb b">setup</code> methods, or implicitly define them withn the forward pass by adding <code class="cx oy oz pa pb b">nn.compact</code> on top of <code class="cx oy oz pa pb b">__call__</code> method. [<a class="af hd" href="https://flax.readthedocs.io/en/latest/guides/flax_fundamentals/setup_or_nncompact.html" rel="noopener ugc nofollow" target="_blank">ref</a>]</p><p id="f4f4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Next let’s build the MLP and Block layer, which includes Dense layer, Gelu activation function, LayerNorm and Dropout. Again flax.linen has the layer APIs to help us build the module. Note that we will pass a <code class="cx oy oz pa pb b">deterministic</code> boolean variable to control different behaviors during training or evaluation for some layers like Dropout.</p><pre class="ni nj nk nl nm pc pb pd bp pe bb bk"><span id="a90d" class="pf nz fq pb b bg pg ph l pi pj">class MLP(nn.Module):<br/><br/>  config: ModelConfig<br/><br/>  @nn.compact<br/>  def __call__(self, x, deterministic=True):<br/>    x = nn.Dense(self.config.n_embd*4)(x)<br/>    x = nn.gelu(x, approximate=True)<br/>    x = nn.Dropout(rate=self.config.dropout_rate)(x, deterministic=deterministic)<br/>    x = nn.Dense(self.config.n_embd)(x)<br/>    x = nn.Dropout(rate=self.config.dropout_rate)(x, deterministic=deterministic)<br/>    return x<br/><br/>class Block(nn.Module):<br/><br/>  config: ModelConfig<br/><br/>  @nn.compact<br/>  def __call__(self, x):<br/>    x = nn.LayerNorm()(x)<br/>    x = x + CausalSelfAttention(self.config)(x)<br/>    x = nn.LayerNorm()(x)<br/>    x = x + MLP(self.config)(x)<br/>    return x</span></pre><p id="e49e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now Let’s use the above blocks to build the NanoGPT:</p><p id="24ee" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Given the inputs of a sequence token ids, we use the <code class="cx oy oz pa pb b"><a class="af hd" href="https://flax.readthedocs.io/en/v0.5.3/_autosummary/flax.linen.Embed.html" rel="noopener ugc nofollow" target="_blank">flax.linen.Embed</a></code> layer to get position embeddings and token embeddings. Them we pass them into the Block module N times, where N is number of the layers defined in the Model Config. In the end, we map the outputs from the last Block into the probabilities for each token in the vocab to predict the next token. Besides the forward <code class="cx oy oz pa pb b">__call__</code> method, let’s also create a <code class="cx oy oz pa pb b">init </code>methods to get the dummy inputs to get the model’s parameters.</p><pre class="ni nj nk nl nm pc pb pd bp pe bb bk"><span id="ae41" class="pf nz fq pb b bg pg ph l pi pj">class GPT(nn.Module):<br/><br/>  config: ModelConfig<br/><br/>  @nn.compact<br/>  def __call__(self, x, deterministic=False):<br/>    <br/>    B, T = x.shape<br/>    assert T &lt;= self.config.block_size<br/><br/>    pos     = jnp.arange(0, T)[None]<br/>    pos_emb = nn.Embed(self.config.block_size, self.config.n_embd)(pos)<br/>    wte     = nn.Embed(self.config.vocab_size, self.config.n_embd)<br/>    tok_emb = wte(x)<br/>    x       = tok_emb + pos_emb<br/><br/>    for _ in range(self.config.n_layer):<br/>      x = Block(self.config)(x)<br/>    x = nn.LayerNorm()(x)<br/>    logits = nn.Dense(config.n_embd, config.vocab_size)(x)<br/>    # logits = wte.attend(x) # parameter sharing<br/>    return logits<br/>  <br/>  def init(self, rng):<br/>    tokens = jnp.zeros((1, self.config.block_size), dtype=jnp.uint16)<br/>    params = jax.jit(super().init, static_argnums=(2,))(rng, tokens, True)<br/>    return params<br/></span></pre><p id="9799" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now let’s varify the number of parameters: We first initialize the model config dataclass and the random key, then create a dummy inputs and feed in into the GPT model. Then we utilize the <code class="cx oy oz pa pb b">jax.util.treemap</code> API to create a count parameter function. We got <strong class="ml fr">124439808</strong> (124M) parameters, same amount as Huggingface’s GPT2, BOOM!</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pl"><img src="../Images/513bfdf90096dcb03e3cd4a76910d2d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xc5GcyykraLcZIHx95qsjQ.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Colab Result: number of parameters</figcaption></figure><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng pm"><img src="../Images/576fc03b5cb1912c0ba770b510de7b73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a16nrcpaAWa0qVs4BKzbOQ.png"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Verify number of params in huggingface’s GPT2</figcaption></figure><h2 id="c9c4" class="ny nz fq bf oa ob oc od oe of og oh oi ms oj ok ol mw om on oo na op oq or os bk"><strong class="al">DataLoader and Training Loop</strong></h2><p id="3806" class="pw-post-body-paragraph mj mk fq ml b go ot mn mo gr ou mq mr ms ov mu mv mw ow my mz na ox nc nd ne fj bk">Let’s now overfit a small dataset. To make it comparable inAndrej’s video on Pytorch NanoGPT, let’s use the toy <a class="af hd" href="https://github.com/karpathy/build-nanogpt/blob/master/input.txt" rel="noopener ugc nofollow" target="_blank">dataset</a> that he shared in his video. We use the GPT2' tokenizer from <code class="cx oy oz pa pb b">tiktoken</code> library to tokenize all the texts from the input file, and convert the tokens into <code class="cx oy oz pa pb b">jax.numpy.array</code> for Jax’s model training.</p><pre class="ni nj nk nl nm pc pb pd bp pe bb bk"><span id="256b" class="pf nz fq pb b bg pg ph l pi pj">class DataLoader:<br/>  def __init__(self, B, T):<br/>    self.current_position = 0<br/>    self.B = B<br/>    self.T = T<br/><br/>    with open("input.txt","r") as f:<br/>      text = f.read()<br/>    enc = tiktoken.get_encoding("gpt2")<br/>    self.tokens = jnp.array(enc.encode(text))<br/>    print(f"loaded {len(self.tokens)} tokens in the datasets" )<br/>    print(f" 1 epoch = {len(self.tokens)//(B*T)} batches")<br/><br/>  def next_batch(self):<br/>    B,T = self.B, self.T<br/>    buf = self.tokens[self.current_position:self.current_position+B*T+1]<br/>    x,y = jnp.reshape(buf[:-1],(B,T)), jnp.reshape(buf[1:],(B,T))<br/>    self.current_position += B*T<br/>    if self.current_position + B*T+1 &gt; len(self.tokens):<br/>      self.current_position = 0<br/>    return x,y</span></pre><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div class="nf ng pn"><img src="../Images/da59795faf894d9f4bd6f4d1ed782ece.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*fKn0AcOjBnwwTp-Ru9MdLw.png"/></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Colab Result: Simple dataloader with 4 batch size and 128 sequence length</figcaption></figure><p id="e1d6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Next, let’s forget distributed training and optimization first, and just create a naive training loop for a sanity check. The first thing after intialize the model is to create a <a class="af hd" href="https://flax.readthedocs.io/en/latest/api_reference/flax.training.html#flax.training.train_state.TrainState" rel="noopener ugc nofollow" target="_blank">TrainState</a>, a model state where we can update the parameters and gradients. The TrainState takes three important inputs: apply_fn (model forward function), params (model parameters from the init method), and tx (an Optax gradient transformation).</p><p id="9a8f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Then we use the train_step function to update the model state (gradients and parameters) to proceed the model training. <code class="cx oy oz pa pb b">Optax</code> provide the softmax cross entropy as the loss function for the next token prediction task, and <code class="cx oy oz pa pb b">jax.value_and_grad</code> calculates the gradients and the loss value for the loss function. Finally, we update the model’s state with the new parameters using the <code class="cx oy oz pa pb b">apply_gradients</code> API. [<a class="af hd" href="https://flax.readthedocs.io/en/latest/_modules/flax/training/train_state.html" rel="noopener ugc nofollow" target="_blank">ref</a>] Don’t forget to jit the train_step function to reduce the computation overhead!</p><pre class="ni nj nk nl nm pc pb pd bp pe bb bk"><span id="70f8" class="pf nz fq pb b bg pg ph l pi pj">def init_train_state(key, config) -&gt; TrainState:<br/>  model = GPT(config)<br/>  params = model.init(key)<br/>  optimizer = optax.adamw(3e-4, b1=0.9, b2=0.98, eps=1e-9, weight_decay=1e-1)<br/>  train_state = TrainState.create(<br/>        apply_fn=model.apply,<br/>        params=params,<br/>        tx=optimizer)<br/>  return train_state<br/><br/>@jax.jit<br/>def train_step(state: TrainState, x: jnp.ndarray, y: jnp.ndarray) -&gt; Tuple[jnp.ndarray, TrainState]:<br/><br/>  def loss_fn(params: FrozenDict) -&gt; jnp.ndarray:<br/><br/>      logits = state.apply_fn(params, x, False)<br/>      loss = optax.softmax_cross_entropy_with_integer_labels(logits, y).mean()<br/>      return loss<br/><br/>  loss, grads = jax.value_and_grad(loss_fn, has_aux=False)(state.params)<br/>  new_state = state.apply_gradients(grads=grads)<br/>  return loss, new_state</span></pre><p id="9609" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now everything is ready for the poorman’s training loop.. Let’s check the loss value. The model’s prediction should be better than the random guess, so the loss should be lower than -ln(1/50257)≈10.825. What we expect from the overfitting a single batch is that: in the beginning the loss is close to 10.825, then it goes down to close to 0. Let’s take a batch of (x, y) and run the training loop for 50 times. I also add similar log to calculate the training speed.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng po"><img src="../Images/add7d951685406ff5cfce20cccb41414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6nADfll00Ehm-pLKKkUEgw.png"/></div></div></figure><p id="ac63" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">As we can see, the loss value is exactly what we expect, and the training throughput is around 400–500 k token/sec. Which is already 40x faster than Pytorch’s initial version without any optimization in Andrej’s video. Note that we run the Jax scripts in 1 A100 GPU which should remove the hardware difference for the speed comparison. There is no <code class="cx oy oz pa pb b">.to(device)</code> stuff to move your model or data from host CPU to device GPU, which is one of the benefits from Jax!</p><p id="7b1e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">So that’s it and we made it. We will make the training 10x more faster in Part 2 with more optimizations…</p><p id="5b62" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><a class="af hd" href="https://lou1swang.medium.com/lets-reproduce-nanogpt-with-jax-part-2-175k-1350k-tokens-sec-in-single-gpu-ff2664ef18d3" rel="noopener">Part 2</a>: The journey of training optimization to 1350k tokens/sec in a single GPU!</p><p id="ac02" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">“Unless otherwise noted, all images are by the author”</p></div></div></div></div>    
</body>
</html>