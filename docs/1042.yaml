- en: DuckDB and AWS — How to Aggregate 100 Million Rows in 1 Minute
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/duckdb-and-aws-how-to-aggregate-100-million-rows-in-1-minute-3634eef06b79?source=collection_archive---------1-----------------------#2024-04-25](https://towardsdatascience.com/duckdb-and-aws-how-to-aggregate-100-million-rows-in-1-minute-3634eef06b79?source=collection_archive---------1-----------------------#2024-04-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Process huge volumes of data with Python and DuckDB — An AWS S3 example.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@radecicdario?source=post_page---byline--3634eef06b79--------------------------------)[![Dario
    Radečić](../Images/41882a3b30bab9da43d66a59f1df366b.png)](https://medium.com/@radecicdario?source=post_page---byline--3634eef06b79--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3634eef06b79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3634eef06b79--------------------------------)
    [Dario Radečić](https://medium.com/@radecicdario?source=post_page---byline--3634eef06b79--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3634eef06b79--------------------------------)
    ·4 min read·Apr 25, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a7174c3f10ec72b94d874017fabb6bb.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Growtika](https://unsplash.com/@growtika?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: When companies need a secure, performant, and scalable storage solution, they
    tend to gravitate toward the cloud. One of the most popular platforms in the game
    is AWS S3 — and for a good reason — it’s an industry-leading object storage solution
    that can serve as a data lake.
  prefs: []
  type: TYPE_NORMAL
- en: The question is — **Can you aggregate S3 bucket data without downloading it?
    And can you do it fast?**
  prefs: []
  type: TYPE_NORMAL
- en: The answer is **yes** to both questions. DuckDB allows you to connect to your
    S3 bucket directly via the `httpfs` extension. You’ll learn how to use it today
    by aggregating around 111 million rows split between 37 [Parquet](/csv-files-for-storage-no-thanks-theres-a-better-option-72c78a414d1d)
    files.
  prefs: []
  type: TYPE_NORMAL
- en: '**Spoiler alert:** It will take you around a minute.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Note:* I wrote this post because I was searching for a more performant Pandas
    alternative. My goal was to perform analysis on large datasets locally instead
    of opting for cloud solutions. I have no affiliations with DuckDB or AWS.'
  prefs: []
  type: TYPE_NORMAL
- en: AWS S3 Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First things first, you’ll need an AWS account and an S3 bucket. You’ll also
    want to create an IAM user for which you can generate an access key.
  prefs: []
  type: TYPE_NORMAL
