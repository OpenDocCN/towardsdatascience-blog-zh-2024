- en: How to Encode Constraints to the Output of Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-encode-constraints-to-the-output-of-neural-networks-9bce302b9687?source=collection_archive---------2-----------------------#2024-04-14](https://towardsdatascience.com/how-to-encode-constraints-to-the-output-of-neural-networks-9bce302b9687?source=collection_archive---------2-----------------------#2024-04-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A summary of available approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@runzhong.wang1?source=post_page---byline--9bce302b9687--------------------------------)[![Runzhong
    Wang](../Images/964d8ff22734d69fea6bb7256fe5d84d.png)](https://medium.com/@runzhong.wang1?source=post_page---byline--9bce302b9687--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9bce302b9687--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9bce302b9687--------------------------------)
    [Runzhong Wang](https://medium.com/@runzhong.wang1?source=post_page---byline--9bce302b9687--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9bce302b9687--------------------------------)
    ·12 min read·Apr 14, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5e6583bd3bcbd023d68ee777d90bee66.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by ChatGPT based on this article’s content.
  prefs: []
  type: TYPE_NORMAL
- en: 'Neural networks are indeed powerful. However, as the application scope of neural
    networks moves from “standard” classification and regression tasks to more complex
    decision-making and AI for Science, one drawback is becoming increasingly apparent:
    the output of neural networks is usually unconstrained, or more precisely, constrained
    only by simple 0–1 bounds (Sigmoid activation function), non-negative constraints
    (ReLU activation function), or constraints that sum to one (Softmax activation
    function). These “standard” activation layers have been used to handle classification
    and regression problems and have witnessed the vigorous development of deep learning.
    However, as neural networks started to be widely used for decision-making, optimization
    solving, and other complex scientific problems, these “standard” activation layers
    are clearly no longer sufficient. This article will briefly discuss the current
    methodologies available that can add constraints to the output of neural networks,
    with some personal insights included. Feel free to critique and discuss any related
    topics.'
  prefs: []
  type: TYPE_NORMAL
- en: '[[中文版本(知乎)]](https://zhuanlan.zhihu.com/p/667124121)'
  prefs: []
  type: TYPE_NORMAL
- en: If one shot doesn’t work, try multiple shots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you are familiar with reinforcement learning, you may already know what
    I am talking about. Applying constraints to an n-dimensional vector seems difficult,
    but you can break an n-dimensional vector into n outputs. Each time an output
    is generated, you can manually write the code to restrict the action space for
    the next variable to ensure its value stays within a feasible domain. This so-called
    “autoregressive” method has obvious advantages: it is simple and can handle a
    rich variety of constraints (as long as you can write the code). However, its
    disadvantages are also clear: an n-dimensional vector requires n calls to the
    network’s forward computation, which is inefficient; moreover, this method usually
    needs to be modeled as a Markov Decision Process (MDP) and trained through reinforcement
    learning, so common challenges in reinforcement learning such as large action
    spaces, sparse reward functions, and long training times are also unavoidable.'
  prefs: []
  type: TYPE_NORMAL
- en: In the domain of solving combinatorial optimization problems with neural networks,
    the autoregressive method coupled with reinforcement learning was once mainstream,
    but it is currently being replaced by more efficient methods.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps… Let’s learn the constraints?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During training, a penalty term can be added to the objective function, representing
    the degree to which the current neural network output violates constraints. In
    the traditional optimization field, the Lagrangian dual method also offers a similar
    trick. Unfortunately, when applied to neural networks, these methods have so far
    only been proven on some simple constraints, and it is still unclear whether they
    are applicable to more complex constraints. One shortcoming is that inevitably
    some of the model’s capacity is used to learn how to meet corresponding constraints,
    thereby limiting the model’s ability in other directions (such as optimization
    solving).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, [*Karalias and Loukas, NeurIPS’21 “Erdo˝s Goes Neural: an Unsupervised
    Learning Framework for Combinatorial Optimization on Graphs”*](https://proceedings.neurips.cc/paper/2020/file/49f85a9ed090b20c8bed85a5923c669f-Paper.pdf)
    demonstrated that the so-called “box constraints”, where variable values lie between
    [a, b], can be learned through a penalty term, and the network can solve some
    relatively simple combinatorial optimization problems. However, our further study
    found that this methodology lacks generalization ability. In the training set,
    the neural network can maintain constraints well; but in the testing set, the
    constraints are almost completely lost. Moreover, although adding a penalty term
    in principle can apply to any constraint, it cannot handle more difficult constraints.
    Our paper [*Wang et al, ICLR’23 “Towards One-Shot Neural Combinatorial Optimization
    Solvers: Theoretical and Empirical Notes on the Cardinality-Constrained Case”*](https://openreview.net/pdf?id=h21yJhdzbwz)
    discusses the above phenomena and presents the theoretical analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the design philosophy of generative models, where outputs
    need to conform to a specific distribution, seems more suited to the “learning
    constraints” approach. [*Sun and Yang, NeurIPS’23 “DIFUSCO: Graph-based Diffusion
    Solvers for Combinatorial Optimization”*](https://proceedings.neurips.cc/paper_files/paper/2023/file/0ba520d93c3df592c83a611961314c98-Paper-Conference.pdf)
    showed that Diffusion models can output solutions that meet the constraints of
    the Traveling Salesman Problem (i.e., can output a complete route). We further
    presented [*Li et al, NeurIPS’23 “T2T: From Distribution Learning in Training
    to Gradient Search in Testing for Combinatorial Optimization”*](https://proceedings.neurips.cc/paper_files/paper/2023/file/0ba520d93c3df592c83a611961314c98-Paper-Conference.pdf),
    where the generative model (Diffusion) is responsible for meeting constraints,
    with another optimizer providing optimization guidance during the gradual denoising
    process of Diffusion. This strategy performed pretty well in experiments, surpassing
    all previous neural network solvers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yet another interesting perspective: Solving a convex optimization problem'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Maybe you are concerned that autoregressive is too inefficient, and generative
    models may not solve your problem. You might be thinking about a neural network
    that does only one forward pass, and the output needs to meet the given constraints
    — is that possible?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is yes. We can solve a convex optimization problem to project the
    neural network’s output into a feasible domain bounded by convex constraints.
    This methodology utilizes the property that a convex optimization problem is differentiable
    at its KKT conditions so that this projection step can be regarded as an activation
    layer, embeddable in an end-to-end neural network. This methodology was proposed
    and promoted by Zico Kolter’s group at CMU, and they currently offer the [cvxpylayers
    package](https://github.com/cvxgrp/cvxpylayers) to ease the implementation steps.
    The corresponding convex optimization problem is
  prefs: []
  type: TYPE_NORMAL
- en: where **y** is the unconstrained neural network output, **x** is the constrained
    neural network output. Because the purpose of this step is just a projection,
    a linear objective function can achieve this (adding an entropy regularizer is
    also reasonable). **Ax** ≤ **b** are the linear constraints you need to apply,
    which can also be quadratic or other convex constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is a personal note: there seem to be some [known issues](https://github.com/cvxgrp/cvxpylayers/issues/147),
    and it seems that this repository has not been updated/maintained for a long time
    (04/2024). I would truly appreciate it if anyone is willing to investigate what
    is going on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For non-convex problems: Which gradient approximation do you prefer?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deriving gradients using KKT conditions is theoretically sound, but it cannot
    tackle non-convex or non-continuous problems. In fact, for non-continuous problems,
    when changes in problem parameters cause solution jumps, the real gradient becomes
    a delta function (i.e., infinite at the jump), which obviously can’t be used in
    training neural networks. Fortunately, there are some gradient approximation methods
    that can tackle this problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Georg Martius group at Max Planck Institute introduced a black-box approximation
    method [*Vlastelica et al, ICLR’2020 “Differentiation of Blackbox Combinatorial
    Solvers”*](https://openreview.net/pdf?id=BkevoJSYPB), which views the solver as
    a black box. It first calls the solver once, then perturbs the problem parameters
    in a specific direction, and then calls the solver again. The residual between
    the outputs of the two solver calls serves as the approximate gradient. If this
    methodology is applied to the output of neural networks to enforce constraints,
    we can define an optimization problem with a linear objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: where **y** is the unconstrained neural network output, and **x** is the constrained
    neural network output. Your next step is to implement an algorithm to solve the
    above problem (not necessarily to be optimal), and then it can be integrated into
    the black-box approximation framework. A drawback of the black-box approximation
    method is that it can only handle linear objective functions, but a linear objective
    function just happens to work if you are looking for some methods to enforce constraints;
    moreover, since it is just a gradient approximation method if the hyperparameters
    are not well-tuned, it might encounter sparse gradients and convergence issues.
  prefs: []
  type: TYPE_NORMAL
- en: Another method for approximating gradients involves using a large amount of
    random noise perturbation, repeatedly calling the solver to estimate a gradient,
    as discussed in [*Berthet et al, NeurIPS’2020 “Learning with Differentiable Perturbed
    Optimizers”*](https://papers.nips.cc/paper/2020/file/6bb56208f672af0dd65451f869fedfd9-Paper.pdf).
    Theoretically, the gradient obtained this way should be similar to the gradient
    obtained through the LinSAT method (which will be discussed in the next section),
    being the gradient of an entropy-regularized linear objective function; however,
    in practice, this method requires a large number of random samples, which is kind
    of impractical (at least on my use cases).
  prefs: []
  type: TYPE_NORMAL
- en: 'Self-promotion time: Projection without solving optimization'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whether it’s deriving gradients from KKT conditions for convex problems or approximating
    gradients for non-convex methods, both require calling/writing a solver, whereby
    the CPU-GPU communication could be a bottleneck because most solvers are usually
    designed and implemented for CPUs. Is there a way to project specific constraints
    directly on the GPU like an activation layer, without solving optimization problems
    explicitly?
  prefs: []
  type: TYPE_NORMAL
- en: 'The answer is yes, and our [*Wang et al, ICML’2023 “LinSATNet: The Positive
    Linear Satisfiability Neural Networks”*](https://proceedings.mlr.press/v202/wang23at/wang23at.pdf)
    presents a viable path and derives the convergence property of the algorithm.
    LinSAT stands for **Lin**ear **SAT**isfiability Network.'
  prefs: []
  type: TYPE_NORMAL
- en: LinSAT can be seen as an activation layer, allowing you to apply general positive
    linear constraints to the output of a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/103e965ed6105a4a11aafc4e1a58ac6c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The LinSAT layer is fully differentiable, and the real gradients are computed
    by autograd, just like other activation layers. Our implementation now supports
    PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: You can install it by
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: And get started with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A quick example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you download and run the source code, you will find a simple example. In
    this example, we apply doubly stochastic constraints to a 3×3 matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the example, first clone the repo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Go into the repo, and run the example code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we try to enforce doubly-stochastic constraints to a 3×3 matrix.
    The doubly stochastic constraint means that all rows and columns of the matrix
    should sum to 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'The 3x3 matrix is flattened into a vector, and the following positive linear
    constraints are considered (for **Ex**=**f**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We randomly init **w** and regard it as the output of some neural networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We also have a “ground-truth target” for the output of linsat_layer, which
    is a diagonal matrix in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The forward/backward passes of LinSAT follow the standard PyTorch style and
    are readily integrated into existing deep learning pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'The forward pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The backward pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also set E as a sparse matrix to improve the time & memory efficiency
    (especially for large-sized input). Here is a dumb example (consider to construct
    E in sparse for the best efficiency):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We can also do gradient-based optimization over w to make the output of linsat_layer
    closer to x_gt. This is what happens when you train a
  prefs: []
  type: TYPE_NORMAL
- en: neural network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: And you are likely to see the loss decreasing during the training steps.
  prefs: []
  type: TYPE_NORMAL
- en: For full API references, please check out [the GitHub repository](https://github.com/Thinklab-SJTU/LinSATNet?tab=readme-ov-file#api-reference).
  prefs: []
  type: TYPE_NORMAL
- en: How does LinSAT work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Warning, tons of math ahead! You can safely skip this part if you are just using
    LinSAT.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to learn more details and proofs, please refer to [the main paper](https://proceedings.mlr.press/v202/wang23at/wang23at.pdf).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here we introduce the mechanism inside LinSAT. It works by extending the Sinkhorn
    algorithm to multiple sets of marginals (to our best knowledge, we are the first
    to study Sinkhorn with multi-sets of marginals). The positive linear constraints
    are then enforced by transforming the constraints into marginals.
  prefs: []
  type: TYPE_NORMAL
- en: Classic Sinkhorn with single-set marginals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start with the classic Sinkhorn algorithm. Given non-negative score matrix
    **S** with size *m×n*, and a set of marginal distributions on rows (non-negative
    vector **v** with size *m*) and columns (non-negative vector **u** with size *n*),
    where
  prefs: []
  type: TYPE_NORMAL
- en: the Sinkhorn algorithm outputs a normalized matrix Γ with size *m×n* and values
    in [0,1] so that
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, Γᵢ ⱼ means the **proportion** of *u*ⱼ moved to *v*ᵢ.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm steps are:'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the above formulation is modified from the conventional Sinkhorn formulation.
    Γᵢ ⱼ uⱼ is equivalent to the elements in the “transport” matrix in papers such
    as [(Cuturi 2013](https://arxiv.org/pdf/1306.0895v1.pdf)). We prefer this new
    formulation as it generalizes smoothly to Sinkhorn with multi-set marginals in
    the following.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To make a clearer comparison, the transportation matrix in [(Cuturi 2013)](https://arxiv.org/pdf/1306.0895v1.pdf)
    is **P** with size m×n, and the constraints are
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Pᵢ ⱼ means the **exact mass** moved from uⱼ to vᵢ.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The algorithm steps are:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Extended Sinkhorn with multi-set marginals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discover that the Sinkhorn algorithm can generalize to multiple sets of marginals.
    Recall that Γᵢ ⱼ ∈ [0,1] means the proportion of *u*ⱼ moved to *v*ᵢ. Interestingly,
    it yields the same formulation if we simply replace **u**, **v** with another
    set of marginal distributions, suggesting the potential of extending the Sinkhorn
    algorithm to multiple sets of marginal distributions. Denote that there are *k*
    sets of marginal distributions that are jointly enforced to fit more complicated
    real-world scenarios. The sets of marginal distributions are
  prefs: []
  type: TYPE_NORMAL
- en: 'and we have:'
  prefs: []
  type: TYPE_NORMAL
- en: It assumes the existence of a normalized **Z** ∈ [0,1] with size *m×n*, s.t.
  prefs: []
  type: TYPE_NORMAL
- en: 'i.e., the multiple sets of marginal distributions have a non-empty feasible
    region (you may understand the meaning of “non-empty feasible region” after reading
    the next section about how to handle positive linear constraints). Multiple sets
    of marginal distributions could be jointly enforced by traversing the Sinkhorn
    iterations over *k* sets of marginal distributions. The algorithm steps are:'
  prefs: []
  type: TYPE_NORMAL
- en: In [our paper](https://proceedings.mlr.press/v202/wang23at/wang23at.pdf), we
    prove that the Sinkhorn algorithm for multi-set marginals shares the same convergence
    pattern with the classic Sinkhorn, and its underlying formulation is also similar
    to the classic Sinkhorn.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming positive linear constraints into marginals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Then we show how to transform the positive linear constraints into marginals,
    which are handled by our proposed multi-set Sinkhorn.
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoding neural network’s output** For an *l*-length vector denoted as **y**
    (which can be the output of a neural network, also it is the input to **linsat_layer**),
    the following matrix is built'
  prefs: []
  type: TYPE_NORMAL
- en: 'where **W** is of size 2 × (*l* + 1), and β is the dummy variable, the default
    is β = 0\. **y** is put at the upper-left region of **W**. The entropic regularizer
    is then enforced to control discreteness and handle potential negative inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: The score matrix **S** is taken as the input of Sinkhorn for multi-set marginals.
  prefs: []
  type: TYPE_NORMAL
- en: '**From linear constraints to marginals**'
  prefs: []
  type: TYPE_NORMAL
- en: '**1) Packing constraint** **Ax** ≤ **b**. Assuming that there is only one constraint,
    we rewrite the constraint as'
  prefs: []
  type: TYPE_NORMAL
- en: Following the “transportation” view of Sinkhorn, the output **x** *moves* at
    most *b* unit of mass from *a*₁*, a*₂*, …, aₗ*, and the dummy dimension allows
    the inequality by *moving* mass from the dummy dimension. It is also ensured that
    the sum of **u***ₚ*equals the sum of **v***ₚ*. The marginal distributions are
    defined as
  prefs: []
  type: TYPE_NORMAL
- en: '**2 ) Covering constraint** **Cx** ≥ **d**. Assuming that there is only one
    constraint, we rewrite the constraint as'
  prefs: []
  type: TYPE_NORMAL
- en: We introduce the multiplier
  prefs: []
  type: TYPE_NORMAL
- en: because we always have
  prefs: []
  type: TYPE_NORMAL
- en: (else the constraint is infeasible), and we cannot reach a feasible solution
    where all elements in **x** are 1s without this multiplier. Our formulation ensures
    that at least *d* unit of mass is *moved* from c₁*, c*₂*, …, cₗ* by **x**, thus
    representing the covering constraint of “greater than”. It is also ensured that
    the sum of **u_**c equals the sum of **v**_c. The marginal distributions are defined
    as
  prefs: []
  type: TYPE_NORMAL
- en: '**3) Equality constraint** **Ex** = **f**. Representing the equality constraint
    is more straightforward. Assuming that there is only one constraint, we rewrite
    the constraint as'
  prefs: []
  type: TYPE_NORMAL
- en: The output **x** *moves* e₁*, e*₂*, …, eₗ* to *f*, and we need no dummy element
    in **u**ₑ because it is an equality constraint. It is also ensured that the sum
    of **u**ₑ equals the sum of **v**ₑ. The marginal distributions are defined as
  prefs: []
  type: TYPE_NORMAL
- en: After encoding all constraints and stacking them as multiple sets of marginals,
    we can call the Sinkhorn algorithm for multi-set marginals to encode the constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Experimental Validation of LinSAT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our ICML paper, we validated the LinSATNet method for routing constraints
    beyond the general case (used for solving variants of the Traveling Salesman Problem),
    partial graph matching constraints (used in graph matching where only subsets
    of graphs match each other), and general linear constraints (used in specific
    preference with portfolio optimization). All these problems can be represented
    with positive linear constraints and handled using the LinSATNet method. In experiments,
    neural networks are capable of learning how to solve all three problems.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that the LinSATNet method can only handle **positive linear
    constraints**, meaning that it is unable to handle constraints like *x*₁ — *x*₂
    ≤ 0 which contain negative terms. However, positive linear constraints already
    cover a vast array of scenarios. For each specific problem, the mathematical modeling
    is often not unique, and in many cases, a reasonable positive linear formulation
    could be found. In addition to the examples mentioned above, let the network output
    organic molecules (represented as graphs, ignoring hydrogen atoms, considering
    only the skeleton) can consider constraints such as C atoms having no more than
    4 bonds, O atoms having no more than 2 bonds.
  prefs: []
  type: TYPE_NORMAL
- en: Afterword
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adding constraints to neural networks has a wide range of application scenarios,
    and so far, several methods are available. It’s important to note that there is
    no golden standard to judge their superiority over each other — the best method
    is usually relevant to a certain scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, I recommend trying out LinSATNet! Anyway, it is as simple as an activation
    layer in your network.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you found this article helpful, please feel free to cite:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: All aforementioned content has been discussed in this paper.
  prefs: []
  type: TYPE_NORMAL
