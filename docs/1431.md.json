["```py\nlibrary(MASS)\nlibrary(mice)\n\nset.seed(10)\nn<-3000\n\nXstar <- mvrnorm(n=n, mu=c(0,0), Sigma=matrix( c(1,0.7,0.7,1), nrow=2, byrow=T   ))\n\ncolnames(Xstar) <- paste0(\"X\",1:2)\n\n## Introduce missing mechanisms\nM<-matrix(0, ncol=ncol(Xstar), nrow=nrow(Xstar))\nM[Xstar[,2] > 0, 1]<- sample(c(0,1), size=sum(Xstar[,2] > 0), replace=T, prob = c(1-0.8,0.8) )\n\n## This gives rise to the observed dataset by masking X^* with M:\nX<-Xstar\nX[M==1] <- NA\n\n## Plot the distribution shift\npar(mfrow=c(2,1))\nplot(Xstar[!is.na(X[,1]),1:2], xlab=\"\", main=\"\", ylab=\"\", cex=0.8, col=\"darkblue\", xlim=c(-4,4), ylim=c(-3,3))\nplot(Xstar[is.na(X[,1]),1:2], xlab=\"\", main=\"\", ylab=\"\", cex=0.8, col=\"darkblue\", xlim=c(-4,4), ylim=c(-3,3))\n```", "```py\n## (0) Mean Imputation: This would correspond to \"mean\" in the mice R package ##\n\n# 1\\. Estimate the mean\nmeanX<-mean(X[!is.na(X[,1]),1])\n\n## 2\\. Impute\nmeanimp<-X\nmeanimp[is.na(X[,1]),1] <-meanX\n\n## (1) Regression Imputation: This would correspond to \"norm.predict\" in the mice R package ##\n\n# 1\\. Estimate Regression\nlmodelX1X2<-lm(X1~X2, data=as.data.frame(X[!is.na(X[,1]),])   )\n\n## 2\\. Impute\nimpnormpredict<-X\nimpnormpredict[is.na(X[,1]),1] <-predict(lmodelX1X2, newdata= as.data.frame(X[is.na(X[,1]),])  )\n\n## (2) Gaussian Imputation: This would correspond to \"norm.nob\" in the mice R package ##\n\n# 1\\. Estimate Regression\n#lmodelX1X2<-lm(X1~X2, X=as.data.frame(X[!is.na(X[,1]),])   )\n# (same as before)\n\n## 2\\. Impute\nimpnorm<-X\nmeanx<-predict(lmodelX1X2, newdata= as.data.frame(X[is.na(X[,1]),])  )\nvar <- var(lmodelX1X2$residuals)\nimpnorm[is.na(X[,1]),1] <-rnorm(n=length(meanx), mean = meanx, sd=sqrt(var) )\n\n## Plot the different imputations\n\npar(mfrow=c(2,2))\n\nplot(meanimp[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"Mean Imputation\"), cex=0.8, col=\"darkblue\", cex.main=1.5)\npoints(meanimp[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n\nplot(impnormpredict[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"Regression Imputation\"), cex=0.8, col=\"darkblue\", cex.main=1.5)\npoints(impnormpredict[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n\nplot(impnorm[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"Gaussian Imputation\"), col=\"darkblue\", cex.main=1.5)\npoints(impnorm[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n\n#plot(Xstar[,c(\"X2\",\"X1\")], main=\"Truth\", col=\"darkblue\", cex.main=1.5)\nplot(Xstar[!is.na(X[,1]),c(\"X2\",\"X1\")], main=\"Truth\", col=\"darkblue\", cex.main=1.5)\npoints(Xstar[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkgreen\", cex=0.8 ) \n```", "```py\n## Regressing X_2 onto X_1\n\n## mean imputation estimate\nlm(X2~X1, data=data.frame(meanimp))$coefficients[\"X1\"]\n## beta= 0.61\n\n## regression imputation estimate\nround(lm(X2~X1, data=data.frame(impnormpredict))$coefficients[\"X1\"],2)\n## beta= 0.90\n\n## Gaussian imputation estimate\nround(lm(X2~X1, data=data.frame(impnorm))$coefficients[\"X1\"],2)\n## beta= 0.71\n\n## Truth imputation estimate\nround(lm(X2~X1, data=data.frame(Xstar))$coefficients[\"X1\"],2)\n## beta= 0.71\n```", "```py\n## Function to calculate the RMSE:\n# impX is the imputed data set\n# Xstar is the fully observed data set\n\nRMSEcalc<-function(impX, Xstar){\n\n  round(mean(apply(Xstar - impX,1,function(x) norm(as.matrix(x), type=\"F\"  ) )),2)\n\n}\n```", "```py\nlibrary(energy)\n\n## Function to calculate the energy distance:\n# impX is the imputed data set\n# Xstar is the fully observed data set\n\n## Calculating the energy distance using the eqdist.e function of the energy package\nenergycalc <- function(impX, Xstar){\n\n  # Note: eqdist.e calculates the energy statistics for a test, which is actually\n  # = n^2/(2n)*energydistance(impX,Xstar), but we we are only interested in relative values\n  round(eqdist.e( rbind(Xstar,impX), c(nrow(Xstar), nrow(impX))  ),2)\n\n}\n```", "```py\npar(mfrow=c(2,2))\n\n## Same plots as before, but now with RMSE and energy distance \n## added\n\nplot(meanimp[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"Mean Imputation\", \"\\nRMSE\", RMSEcalc(meanimp, Xstar), \"\\nEnergy\", energycalc(meanimp, Xstar)), cex=0.8, col=\"darkblue\", cex.main=1.5)\npoints(meanimp[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n\nplot(impnormpredict[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"Regression Imputation\",\"\\nRMSE\", RMSEcalc(impnormpredict, Xstar), \"\\nEnergy\", energycalc(impnormpredict, Xstar)), cex=0.8, col=\"darkblue\", cex.main=1.5)\npoints(impnormpredict[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n\nplot(impnorm[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"Gaussian Imputation\",\"\\nRMSE\", RMSEcalc(impnorm, Xstar), \"\\nEnergy\", energycalc(impnorm, Xstar)), col=\"darkblue\", cex.main=1.5)\npoints(impnorm[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n\nplot(Xstar[!is.na(X[,1]),c(\"X2\",\"X1\")], main=\"Truth\", col=\"darkblue\", cex.main=1.5)\npoints(Xstar[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkgreen\", cex=0.8 ) \n```", "```py\n library(mice)\nsource(\"Iscore.R\")\n\nmethods<-c(\"mean\",       #mice-mean\n           \"norm.predict\",   #mice-sample\n           \"norm.nob\") # Gaussian Imputation\n\n## We first define functions that allow for imputation of the three methods:\n\nimputationfuncs<-list()\n\nimputationfuncs[[\"mean\"]] <- function(X,m){ \n# 1\\. Estimate the mean\n  meanX<-mean(X[!is.na(X[,1]),1])\n## 2\\. Impute\n  meanimp<-X\n  meanimp[is.na(X[,1]),1] <-meanX\n\n  res<-list()\n\n  for (l in 1:m){\n    res[[l]] <- meanimp\n  }\n\n  return(res)\n\n}\n\nimputationfuncs[[\"norm.predict\"]] <- function(X,m){ \n # 1\\. Estimate Regression\n  lmodelX1X2<-lm(X1~., data=as.data.frame(X[!is.na(X[,1]),])   )\n ## 2\\. Impute\n  impnormpredict<-X\n  impnormpredict[is.na(X[,1]),1] <-predict(lmodelX1X2, newdata= as.data.frame(X[is.na(X[,1]),])  )\n\nres<-list()\n\nfor (l in 1:m){\n  res[[l]] <- impnormpredict\n}\n\nreturn(res)\n\n  }\n\nimputationfuncs[[\"norm.nob\"]] <- function(X,m){ \n # 1\\. Estimate Regression\n  lmodelX1X2<-lm(X1~., data=as.data.frame(X[!is.na(X[,1]),])   )\n ## 2\\. Impute\n  impnorm<-X\n  meanx<-predict(lmodelX1X2, newdata= as.data.frame(X[is.na(X[,1]),])  )\n  var <- var(lmodelX1X2$residuals)\n\n  res<-list()\n\n  for (l in 1:m){\n    impnorm[is.na(X[,1]),1] <-rnorm(n=length(meanx), mean = meanx, sd=sqrt(var) )\n    res[[l]] <- impnorm\n  }\n\n  return(res)\n\n}\n\nscoreslist <- Iscores_new(X,imputations=NULL, imputationfuncs=imputationfuncs, N=30)  \n\nscores<-do.call(cbind,lapply(scoreslist, function(x) x$score ))\nnames(scores)<-methods\nscores[order(scores)]\n\n#    mean       norm.predict     norm.nob \n#  -0.7455304   -0.5702136   -0.4220387 \n```", "```py\nlibrary(drf)\n\n## mice-DRF ##\npar(mfrow=c(2,2))\n\n#Fit DRF\nDRF <- drf(X=X[!is.na(X[,1]),2, drop=F], Y=X[!is.na(X[,1]),1, drop=F], num.trees=100)\nimpDRF<-X\n# Predict weights for unobserved points\nwx<-predict(DRF, newdata= X[is.na(X[,1]),2, drop=F]  )$weights\nimpDRF[is.na(X[,1]),1] <-apply(wx,1,function(wxi) sample(X[!is.na(X[,1]),1, drop=F], size=1, replace=T, prob=wxi))\n\nplot(impDRF[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"DRF Imputation\", \"\\nRMSE\", RMSEcalc(impDRF, Xstar), \"\\nEnergy\", energycalc(impDRF, Xstar)), cex=0.8, col=\"darkblue\", cex.main=1.5)\npoints(impDRF[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n\n## mice-cart##\nimpcart<-X\nimpcart[is.na(X[,1]),1] <-mice.impute.cart(X[,1], ry=!is.na(X[,1]), X[,2, drop=F], wy = NULL)\n\nplot(impDRF[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"cart Imputation\", \"\\nRMSE\", RMSEcalc(impcart, Xstar), \"\\nEnergy\", energycalc(impcart, Xstar)), cex=0.8, col=\"darkblue\", cex.main=1.5)\npoints(impDRF[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n\nplot(impnorm[!is.na(X[,1]),c(\"X2\",\"X1\")], main=paste(\"Gaussian Imputation\",\"\\nRMSE\", RMSEcalc(impnorm, Xstar), \"\\nEnergy\", energycalc(impnorm, Xstar)), col=\"darkblue\", cex.main=1.5)\npoints(impnorm[is.na(X[,1]),c(\"X2\",\"X1\")], col=\"darkred\", cex=0.8 )\n```", "```py\nIscores_new<-function(X, N=50,  imputationfuncs=NULL, imputations=NULL, maxlength=NULL,...){\n\n  ## X: Data with NAs\n  ## N: Number of samples from imputation distribution H\n  ## imputationfuncs: A list of functions, whereby each imputationfuncs[[method]] is a function that takes the arguments\n  ## X,m and imputes X m times using method: imputations= imputationfuncs[[method]](X,m).\n  ## imputations: Either NULL or a list of imputations for the methods considered, each imputed X saved as \n  ##              imputations[[method]], whereby method is a string\n  ## maxlength: Maximum number of variables X_j to consider, can speed up the code\n\n  require(Matrix)\n  require(scoringRules)\n\n  numberofmissingbyj<-sapply(1:ncol(X), function(j)  sum(is.na(X[,j]))  )\n  print(\"Number of missing values per dimension:\")\n  print(paste0(numberofmissingbyj, collapse=\",\")  )\n\n  methods<-names(imputationfuncs)\n\n  score_all<-list()\n\n  for (method in methods) {\n    print(paste0(\"Evaluating method \", method))\n\n    # }\n    if (is.null(imputations)){\n      # If there is no prior imputation\n      tmp<-Iscores_new_perimp(X, Ximp=NULL, N=N, imputationfunc=imputationfuncs[[method]], maxlength=maxlength,...)\n      score_all[[method]] <- tmp  \n\n    }else{\n\n      tmp<-Iscores_new_perimp(X, Ximp=imputations[[method]][[1]], N=N, imputationfunc=imputationfuncs[[method]], maxlength=maxlength, ...)\n      score_all[[method]] <- tmp  \n\n    }\n\n  }\n\n  return(score_all)\n\n}\n\nIscores_new_perimp <- function(X, Ximp, N=50, imputationfunc, maxlength=NULL,...){\n\n  if (is.null(Ximp)){\n    # Impute, maxit should not be 1 here!\n    Ximp<-imputationfunc(X=X  , m=1)[[1]]\n  }\n\n  colnames(X) <- colnames(Ximp) <- paste0(\"X\", 1:ncol(X))\n\n  args<-list(...)\n\n  X<-as.matrix(X)\n  Ximp<-as.matrix(Ximp)\n\n  n<-nrow(X)\n  p<-ncol(X)\n\n  ##Step 1: Reoder the data according to the number of missing values\n  ## (least missing first)\n  numberofmissingbyj<-sapply(1:p, function(j)  sum(is.na(X[,j]))  )\n\n  ## Done in the function\n  M<-1*is.na(X)\n  colnames(M) <- colnames(X)\n\n  indexfull<-colnames(X)\n\n  # Order first according to most missing values\n\n  # Get dimensions with missing values (all other are not important)\n  dimwithNA<-(colSums(M) > 0)\n  dimwithNA <- dimwithNA[order(numberofmissingbyj, decreasing=T)]\n  dimwithNA<-dimwithNA[dimwithNA==TRUE]\n\n  if (is.null(maxlength)){maxlength<-sum(dimwithNA) }\n\n  if (sum(dimwithNA) < maxlength){\n    warning(\"maxlength was set smaller than sum(dimwithNA)\")\n    maxlength<-sum(dimwithNA)\n  }\n\n  index<-1:ncol(X)\n  scorej<-matrix(NA, nrow= min(sum(dimwithNA), maxlength), ncol=1)\n  weight<-matrix(NA, nrow= min(sum(dimwithNA), maxlength), ncol=1)\n  i<-0\n\n  for (j in names(dimwithNA)[1:maxlength]){\n\n    i<-i+1\n\n    print( paste0(\"Dimension \", i, \" out of \", maxlength )   ) \n\n    # H for all missing values of X_j\n    Ximp1<-Ximp[M[,j]==1, ]\n\n    # H for all observed values of X_j\n    Ximp0<-Ximp[M[,j]==0, ]\n\n    X0 <-X[M[,j]==0, ]\n\n    n1<-nrow(Ximp1)\n    n0<-nrow(Ximp0)\n\n    if (n1 < 10){\n      scorej[i]<-NA\n\n      warning('Sample size of missing and nonmissing too small for nonparametric distributional regression, setting to NA')\n\n    }else{\n\n      # Evaluate on observed data\n      Xtest <- Ximp0[,!(colnames(Ximp0) %in% j) &  (colnames(Ximp0) %in% indexfull), drop=F]\n      Oj<-apply(X0[,!(colnames(Ximp0) %in% j) &  (colnames(Ximp0) %in% indexfull), drop=F],2,function(x) !any(is.na(x)) )\n      # Only take those that are fully observed\n      Xtest<-Xtest[,Oj, drop=F]\n\n      Ytest <-Ximp0[,j, drop=F]\n\n      if (is.null(Xtest)){\n        scorej[i]<-NA\n        #weighted\n        weight[i]<-(n1/n)*(n0/n)\n        warning(\"Oj was empty\")\n        next\n      }\n\n      ###Test 1:\n      # Train DRF on imputed data\n      Xtrain<-Ximp1[,!(colnames(Ximp1) %in% j) & (colnames(Ximp1) %in% indexfull), drop=F]\n      # Only take those that are fully observed\n      Xtrain<-Xtrain[,Oj, drop=F]\n\n      Ytrain<-Ximp1[,j, drop=F]\n\n      Xartificial<-cbind(c(rep(NA,nrow(Ytest)),c(Ytrain)),rbind(Xtest, Xtrain)   )\n      colnames(Xartificial)<-c(colnames(Ytrain), colnames(Xtrain))\n\n      Imputationlist<-imputationfunc(X=Xartificial  , m=N)\n\n      Ymatrix<-do.call(cbind, lapply(Imputationlist, function(x)  x[1:nrow(Ytest),1]  ))\n\n      scorej[i] <- -mean(sapply(1:nrow(Ytest), function(l)  { crps_sample(y = Ytest[l,], dat = Ymatrix[l,]) }))\n\n    }\n\n    #weighted\n    weight[i]<-(n1/n)*(n0/n)\n\n  }\n\n  scorelist<-c(scorej)\n  names(scorelist) <- names(dimwithNA)[1:maxlength]\n  weightlist<-c(weight)\n  names(weightlist) <- names(dimwithNA)[1:maxlength]\n\n  weightedscore<-scorej*weight/(sum(weight, na.rm=T))\n\n  ## Weight the score according to n0/n * n1/n!!\n  return( list(score= sum(weightedscore, na.rm=T), scorelist=scorelist, weightlist=weightlist)  )\n}\n```"]