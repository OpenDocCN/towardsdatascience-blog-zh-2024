- en: Structured LLM Output Using Ollama
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/structured-llm-output-using-ollama-73422889c7ad?source=collection_archive---------2-----------------------#2024-12-17](https://towardsdatascience.com/structured-llm-output-using-ollama-73422889c7ad?source=collection_archive---------2-----------------------#2024-12-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Control your model responses effectively
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@thomas_reid?source=post_page---byline--73422889c7ad--------------------------------)[![Thomas
    Reid](../Images/c1b4e5f577272633ba07e5dbfd21c02d.png)](https://medium.com/@thomas_reid?source=post_page---byline--73422889c7ad--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--73422889c7ad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--73422889c7ad--------------------------------)
    [Thomas Reid](https://medium.com/@thomas_reid?source=post_page---byline--73422889c7ad--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--73422889c7ad--------------------------------)
    ·9 min read·Dec 17, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: With version 0.5, Ollama released a significant enhancement to its LLM API.
    By introducing structured outputs, Ollama now makes it possible to constrain a
    model’s output to a specific format defined by a JSON schema. Under the hood,
    most systems use Pydantic’s capabilities to enable this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e73944428fb10a700832454a6feffeab.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author (Dalle-3)
  prefs: []
  type: TYPE_NORMAL
- en: Structured output solves a nagging problem many developers face when a system
    or process takes the output from an LLM for further processing. It’s important
    for that system to “know” what to expect as its input to process it accurately
    with repeatable results each time.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, you want to display model output in the same format each time you
    display it to a user to avoid confusion and errors
  prefs: []
  type: TYPE_NORMAL
- en: Until now, ensuring consistent output formats from most models has been a pain,
    but the new functionality from Ollama makes doing so quite easy, as I hope to
    show in my example code snippets.
  prefs: []
  type: TYPE_NORMAL
- en: Before that, though, you need to install the latest version of Ollama. This
    isn’t a tutorial on Ollama or how to run it. If you want that information, click
    my article below, where I go through all that good stuff.
  prefs: []
  type: TYPE_NORMAL
