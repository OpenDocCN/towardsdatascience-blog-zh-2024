["```py\ndata_config = DataConfig(\n    target=[target_col],\n    continuous_cols=features,\n    num_workers=0,\n)\ntrainer_config = TrainerConfig(\n    batch_size=1024, \n    max_epochs=20, \n    accelerator=\"gpu\")\n\noptimizer_config = OptimizerConfig()\n\nhead_config = LinearHeadConfig(\n    layers=\"\",  # No additional layer in head, just a mapping layer to output_dim\n    dropout=0.0,\n    initialization=\"kaiming\", \n).__dict__  # model config requires dict\n\nmodel_config = CategoryEmbeddingModelConfig(\n    task=\"classification\",\n    layers=\"1024-512-512\",  \n    activation=\"LeakyReLU\", \n    head=\"LinearHead\",\n    head_config=head_config,\n    learning_rate=1e-3,\n[METRICS ARGUMENTS COME NEXT]\n```", "```py\nmetrics=[\"f1_score\", \"average_precision\", \"accuracy\", \"auroc\"],\nmetrics_params=[\n    {\"task\": \"multiclass\", \"num_classes\": num_classes},\n    {\"task\": \"multiclass\", \"num_classes\": num_classes},\n    {},\n    {},\n],  # f1_score and avg prec need num_classes and task identifier\nmetrics_prob_input=[\n    True,\n    True,\n    False,\n    True,\n],  # f1_score, avg prec, auroc need probability scores, while accuracy doesn't\n```", "```py\ntabular_model = TabularModel(\n    data_config=data_config,\n    model_config=model_config,\n    optimizer_config=optimizer_config,\n    trainer_config=trainer_config,\n    verbose=True,\n)\n```", "```py\ntabular_model.fit(train=train_split_df, validation=val_split_df)\nresult = tabular_model.evaluate(test_split_df)\n```", "```py\ntabular_model.save_model(\n  f\"data/models/tabular_version_{model_name}\"\n ) # The PyTorch Tabular version\n\ntabular_model.save_model_for_inference(\n  f\"data/models/{model_name}\", kind=\"pytorch\"\n ) # The base PyTorch version\n```", "```py\nmodel_obj = torch.load(\"classifier_pytorch\")\ndatamodule = joblib.load(\"datamodule.sav\")\n\n...\n\ninference_dataloader = datamodule.prepare_inference_dataloader(\n  self.processed_event[pytorch_feature_list], batch_size=256\n)\n\ntask = \"classification\"\n\npoint_predictions = []\nfor batch in tqdm(inference_dataloader, desc=\"Generating Predictions...\"):\n    for k, v in batch.items():\n        print(\"New Batch\")\n        if isinstance(v, list) and (len(v) == 0):\n            continue\n        batch[k] = v.to(pytorch_model.device)\n    y_hat, ret_value = pytorch_model.predict(batch, ret_model_output=True)\n    point_predictions.append(y_hat.detach().cpu())\n```"]