- en: 'Reinforcement Learning for Physics: ODEs and Hyperparameter Tuning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 物理中的强化学习：常微分方程和超参数调整
- en: 原文：[https://towardsdatascience.com/reinforcement-learning-for-physics-odes-and-hyperparameter-tuning-2c0a29752a67?source=collection_archive---------6-----------------------#2024-10-17](https://towardsdatascience.com/reinforcement-learning-for-physics-odes-and-hyperparameter-tuning-2c0a29752a67?source=collection_archive---------6-----------------------#2024-10-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/reinforcement-learning-for-physics-odes-and-hyperparameter-tuning-2c0a29752a67?source=collection_archive---------6-----------------------#2024-10-17](https://towardsdatascience.com/reinforcement-learning-for-physics-odes-and-hyperparameter-tuning-2c0a29752a67?source=collection_archive---------6-----------------------#2024-10-17)
- en: Controlling differential equations with gymnasium and optimizing algorithm hyperparameters
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Gymnasium 控制常微分方程并优化算法的超参数
- en: '[](https://medium.com/@retter_42511?source=post_page---byline--2c0a29752a67--------------------------------)[![Robert
    Etter](../Images/8193c0477b2a7df1177779ca5937854a.png)](https://medium.com/@retter_42511?source=post_page---byline--2c0a29752a67--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2c0a29752a67--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2c0a29752a67--------------------------------)
    [Robert Etter](https://medium.com/@retter_42511?source=post_page---byline--2c0a29752a67--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@retter_42511?source=post_page---byline--2c0a29752a67--------------------------------)[![罗伯特·埃特](../Images/8193c0477b2a7df1177779ca5937854a.png)](https://medium.com/@retter_42511?source=post_page---byline--2c0a29752a67--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2c0a29752a67--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2c0a29752a67--------------------------------)
    [罗伯特·埃特](https://medium.com/@retter_42511?source=post_page---byline--2c0a29752a67--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2c0a29752a67--------------------------------)
    ·11 min read·Oct 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2c0a29752a67--------------------------------)
    ·阅读时间：11分钟·2024年10月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/5bdaba3d9f8ca4ef508967b454f1b5f7.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5bdaba3d9f8ca4ef508967b454f1b5f7.png)'
- en: Photo by [Brice Cooper](https://unsplash.com/@brice_cooper18?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [布莱斯·库珀](https://unsplash.com/@brice_cooper18?utm_source=medium&utm_medium=referral)
    拍摄，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'As [discussed previously](/rl-for-physical-dynamical-systems-an-alternative-approach-8e2269dc1e79),
    Reinforcement Learning (RL) provides a powerful new tool for approaching the challenges
    of controlling nonlinear physical systems. Nonlinear physical systems are characterized
    by complex behavior, where small changes in input can lead to dramatic changes
    in output, or only small output changes may result from large inputs. Solutions
    can split, where the same conditions can produce different outputs, or even have
    “memory” in the form of path dependence. We introduced two different approaches
    to applying RL to a nonlinear physical system: the traditional, neural-network
    based Soft Actor Critic (SAC) and an uncommon genetic-algorithm based Genetic
    Programming (GP) approach.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如[之前讨论的](/rl-for-physical-dynamical-systems-an-alternative-approach-8e2269dc1e79)，强化学习（RL）为解决控制非线性物理系统的挑战提供了一个强大的新工具。非线性物理系统的特点是行为复杂，其中输入的微小变化可能导致输出的剧烈变化，或者大输入可能只带来微小的输出变化。解决方案可能会分裂，相同的条件可能会产生不同的输出，甚至可能具有“记忆”，以路径依赖的形式存在。我们介绍了两种将强化学习应用于非线性物理系统的不同方法：传统的基于神经网络的软演员评论家（SAC）方法和一种不常见的基于遗传算法的遗传编程（GP）方法。
- en: Briefly, SAC uses two neural networks, one to learn how the environment behaves
    and one to determine an optimal policy. As the model trains, the networks update
    and the environment learning “critic” network helps evaluate and improve the policy
    determining “actor” network. GP is based on generating a “forest” of random mathematical
    equations, evaluation how well they perform in the environment, and then mutating,
    combining, or making new random equations to improve performance. Applied to gymnasium’s
    [pendulum classic control](https://gymnasium.farama.org/environments/classic_control/pendulum/)
    environment, the GP approach showed faster convergence. Now we expand upon that
    study by (1) introducing more complex physical systems based on ordinary differential
    equations and (2) exploring impact of hyperparameter tuning on algorithm performance
    for both SAC and GP.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，SAC 使用两个神经网络，一个用于学习环境的行为，一个用于确定最优策略。在模型训练过程中，网络不断更新，环境学习“批评者”网络帮助评估和改进决策“行动者”网络的策略。遗传编程（GP）基于生成一组“森林”随机数学方程，评估它们在环境中的表现，然后通过变异、组合或创建新的随机方程来提高表现。应用到
    Gymnasium 的 [摆经典控制](https://gymnasium.farama.org/environments/classic_control/pendulum/)
    环境，GP 方法显示出更快的收敛速度。现在我们扩展这项研究，(1) 引入更复杂的基于常微分方程的物理系统，(2) 探讨超参数调优对 SAC 和 GP 算法表现的影响。
- en: Working with ODEs
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理常微分方程（ODE）
- en: 'Physical systems can typically be modeled through differential equations, or
    equations including derivatives. Forces, hence Newton’s Laws, can be expressed
    as derivatives, as can Maxwell’s Equations, so differential equations can describe
    most physics problems. A differential equation describes how a system changes
    based on the system’s current state, in effect defining state transition. Systems
    of differential equations can be written in matrix/vector form:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 物理系统通常可以通过微分方程来建模，或是包含导数的方程。力，因此也包括牛顿定律，可以通过导数来表示，麦克斯韦方程也是如此，因此微分方程可以描述大多数物理问题。微分方程描述了一个系统如何根据当前状态变化，实际上定义了状态转换。微分方程系统可以写成矩阵/向量形式：
- en: '![](../Images/67005a64883b71ddad1b9b7c045caecb.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67005a64883b71ddad1b9b7c045caecb.png)'
- en: where x is the state vector, A is the state transition matrix determined from
    the physical dynamics, and x dot (or dx/dt) is the change in the state with a
    change in time. Essentially, matrix A acts on state x to advance it a small step
    in time. This formulation is typically used for linear equations (where elements
    of A do not contain any state vector) but can be used for nonlinear equations
    where the elements of A may have state vectors which can lead to the complex behavior
    described above. This equation describes how an environment or system develops
    in time, starting from a particular initial condition. In mathematics, these are
    referred to as initial value problems since evaluating how the system will develop
    requires specification of a starting state.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，x 是状态向量，A 是由物理动态决定的状态转换矩阵，x 点（或 dx/dt）是状态随时间变化的变化量。本质上，矩阵 A 对状态 x 进行作用，使其在时间上向前推进一个小步。这种表述通常用于线性方程（其中
    A 的元素不包含任何状态向量），但也可以用于非线性方程，在这种情况下，A 的元素可能包含状态向量，这会导致上述复杂行为。这方程描述了一个环境或系统如何随时间发展，从特定的初始条件开始。在数学中，这些被称为初值问题，因为评估系统如何发展需要指定一个起始状态。
- en: The expression above describes a particular class of differential equations,
    ordinary differential equations (ODE) where the derivatives are all of one variable,
    usually time but occasionally space. The dot denotes dx/dt, or change in state
    with incremental change in time. ODEs are well studied and linear systems of ODEs
    have a wide range of analytic solution approaches available. Analytic solutions
    allow solutions to be express in terms of variables, making them more flexible
    for exploring the whole system behavior. Nonlinear have fewer approaches, but
    certain classes of systems do have analytic solutions available. For the most
    part though, nonlinear (and some linear) ODEs are best solved through simulation,
    where the solution is determined as numeric values at each time-step.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 上述表达式描述了一类特殊的微分方程，常微分方程（ODE），其中所有导数都是一个变量的函数，通常是时间，但有时也可以是空间。点表示 dx/dt，即状态随时间增量变化的变化量。常微分方程（ODE）已被广泛研究，线性常微分方程系统有许多现成的解析解方法。解析解可以将解表示为变量的函数，使其在探索整个系统行为时更加灵活。非线性常微分方程的解法较少，但某些类别的系统仍然可以找到解析解。大多数情况下，非线性（以及某些线性）常微分方程最好通过仿真来求解，在这种方法中，解作为每个时间步的数值值被确定。
- en: Simulation is based around finding an approximation to the differential equation,
    often through [transformation to an algebraic equation](https://en.wikipedia.org/wiki/Finite_difference_method),
    that is accurate to a known degree over a small change in time. Computers can
    then step through many small changes in time to show how the system develops.
    There are many algorithms available to calculate this will such as Matlab’s ODE45
    or Python SciPy’s solve_ivp functions. These algorithms take an ODE and a starting
    point/initial condition, automatically determine optimal step size, and advance
    through the system to the specified ending time.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟是通过寻找微分方程的近似解来进行的，通常是通过[转化为代数方程](https://en.wikipedia.org/wiki/Finite_difference_method)，在一小段时间变化内，保持已知精度。然后，计算机可以通过许多小的时间变化步骤，展示系统的发展过程。有很多算法可以计算这个过程，例如Matlab的ODE45或Python
    SciPy的solve_ivp函数。这些算法接受一个ODE和一个起始点/初始条件，自动确定最佳步长，并在系统中推进到指定的结束时间。
- en: If we can apply the correct control inputs to an ODE system, we can often drive
    it to a desired state. As discussed last time, RL provides an approach to determine
    the correct inputs for nonlinear systems. To develop RLs, we will again use the
    gymnasium environment, but this time we will create a custom gymnasium environment
    based on our own ODE. Following [Gymnasium documentation](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/),
    we create an observation space that will cover our state space, and an action
    space for the control space. We initialize/reset the gymnasium to an arbitrary
    point within the state space (though here we must be cautious, not all desired
    end states [are always reachable](https://en.wikipedia.org/wiki/Controllability)
    from any initial state for some systems). In the gymnasium’s step function, we
    take a step over a short time horizon in our ODE applying the algorithm estimated
    input using Python SciPy solve_ivp function. Solve_ivp calls a function which
    holds the particular ODE we are working with. Code is available on [git](https://github.com/retter-berkeley/PhysicsGyms).
    The init and reset functions are straightforward; init creates and observation
    space for every state in the system and reset sets a random starting point for
    each of those variables within the domain at a minimum distance from the origin.
    In the step function, note the solve_ivp line that calls the actual dynamics,
    solves the dynamics ODE over a short time step, passing the applied control K.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能够对ODE系统应用正确的控制输入，我们通常可以将其驱动到期望的状态。如上次所讨论的，强化学习（RL）提供了一种确定非线性系统正确输入的方法。为了开发RL，我们将再次使用健身环境，但这一次我们将基于自己的ODE创建一个自定义的健身环境。按照[Gymnasium文档](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/)，我们创建一个观察空间来覆盖我们的状态空间，并为控制空间创建一个动作空间。我们初始化/重置健身环境到状态空间中的一个任意点（但在这里我们必须小心，并非所有期望的最终状态[都能从任何初始状态到达](https://en.wikipedia.org/wiki/Controllability)某些系统）。在健身环境的步进函数中，我们在ODE的短时间范围内执行一步，使用Python
    SciPy的solve_ivp函数应用算法估算的输入。Solve_ivp调用一个函数，解决我们正在处理的特定ODE。代码可在[git](https://github.com/retter-berkeley/PhysicsGyms)上找到。init和reset函数是直接的；init为系统中的每个状态创建观察空间，reset为这些变量在域内设置一个距离原点最小的随机起始点。在步进函数中，注意solve_ivp行，它调用实际的动态方程，在短时间步长内求解动态ODE，传递应用的控制K。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Below are the dynamics of the Moore-Greitzer Mode (MGM) function. This implementation
    is based on solve_ivp documentation . Limits are placed to avoid solution divergence;
    if system hits limits reward will be low to cause algorithm to revise control
    approach. Creating ODE gymnasiums based on the template discussed here should
    be straightforward: change the observation space size to match the dimensions
    of the ODE system and update the dynamics equation as needed.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是摩尔-格雷策模式（MGM）函数的动态特性。此实现基于solve_ivp文档。设置了限制以避免解发散；如果系统触及限制，奖励将较低，促使算法修正控制方法。基于此处讨论的模板创建ODE健身环境应该很简单：只需调整观测空间大小以匹配ODE系统的维度，并根据需要更新动态方程。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For this example, we are using an ODE based on the Moore-Greitzer Model (MGM)
    describe gas turbine engine surge-stall dynamics¹. This equation describes coupled
    damped oscillations between engine mass flow and pressure. The goal of the controller
    is to quickly dampen oscillations to 0 by controlling pressure on the engine.
    MGM has “motivated substantial development of nonlinear control design” making
    it an interesting test case for the SAC and GP approaches. Code describing the
    equation can be found on [Github](https://github.com/retter-berkeley/PhysicsGyms/blob/main/dynamics/dynamics.py).
    Also listed are three other nonlinear ODEs. The Van Der Pol oscillator is a classic
    nonlinear oscillating system based on dynamics of electronic systems. The Lorenz
    Attractor is a seemingly simple system of ODEs that can product chaotic behavior,
    or results highly sensitive to initial conditions such that any infinitely small
    different in starting point will, in an uncontrolled system, soon lead to widely
    divergent state. The third is a mean-field ODE system provided by Duriez/Brunton/Noack
    that describes development of complex interactions of stable and unstable waves
    as an approximation to turbulent fluid flow.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用的是基于Moore-Greitzer模型（MGM）的常微分方程，描述了燃气涡轮发动机的喘振-失速动态¹。这个方程描述了发动机质量流量与压力之间的耦合阻尼振荡。控制器的目标是通过控制发动机的压力，迅速将振荡衰减到0。MGM“推动了非线性控制设计的重大进展”，使其成为SAC和GP方法的有趣测试案例。描述该方程的代码可以在[Github](https://github.com/retter-berkeley/PhysicsGyms/blob/main/dynamics/dynamics.py)上找到。此处还列出了另外三个非线性ODE。Van
    Der Pol振荡器是一个经典的非线性振荡系统，基于电子系统的动力学。Lorenz吸引子是一个看似简单的常微分方程系统，可以产生混沌行为，或者结果对初始条件高度敏感，以至于在一个不受控制的系统中，任何极小的起始点差异都将导致状态迅速发生广泛分化。第三个是Duriez/Brunton/Noack提供的平均场ODE系统，描述了稳定与不稳定波的复杂相互作用发展，作为湍流流体流动的近似。
- en: To avoid repeating analysis of the last article, we simply present results here,
    noting that again the GP approach produced a better controller in lower computational
    time than the SAC/neural network approach. The figures below show the oscillations
    of an uncontrolled system, under the GP controller, and under the SAC controller.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免重复上一篇文章的分析，我们这里只展示结果，指出再次证明GP方法在较低的计算时间内，生成了比SAC/神经网络方法更好的控制器。下面的图形展示了在不受控制系统下、GP控制器下以及SAC控制器下的振荡情况。
- en: '![](../Images/9adf352ac359cb46b0832728877e77a4.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9adf352ac359cb46b0832728877e77a4.png)'
- en: Uncontrolled dynamics, provided by author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 不受控制的动力学，由作者提供
- en: '![](../Images/0467c825dd42857bf017466caa603ccc.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0467c825dd42857bf017466caa603ccc.png)'
- en: GP controller results, provided by author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GP 控制器结果，由作者提供
- en: '![](../Images/333e71d00fdd8f1abe4e2d4e40965bcd.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/333e71d00fdd8f1abe4e2d4e40965bcd.png)'
- en: SAC controlled dynamics, provided by author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: SAC控制的动力学，由作者提供
- en: Both algorithms improve on uncontrolled dynamics. We see that while the SAC
    controller acts more quickly (at about 20 time steps), it is low accuracy. The
    GP controller takes a bit longer to act, but provides smooth behavior for both
    states. Also, as [before](/rl-for-physical-dynamical-systems-an-alternative-approach-8e2269dc1e79),
    GP converged in fewer iterations than SAC.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 两个算法都改善了不受控制的动力学。我们看到，虽然SAC控制器的反应更快（大约20个时间步长），但其准确性较低。GP控制器的反应稍慢，但对两种状态都提供了平滑的行为。此外，正如[之前](/rl-for-physical-dynamical-systems-an-alternative-approach-8e2269dc1e79)所述，GP在迭代次数上比SAC收敛得更快。
- en: We have seen that gymnasiums can be easily adopted to allow training RL algorithms
    on ODE systems, briefly discussed how powerful ODEs can be for describing and
    so exploring RL control of physical dynamics, and seen again the GP producing
    better outcome. However, we have not yet tried to optimize either algorithm, instead
    just setting up with, essentially, a guess at basic algorithm parameters. We will
    address that shortcoming now by expanding the MGM study.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，体育馆可以轻松地适应用于在常微分方程（ODE）系统上训练强化学习（RL）算法，简要讨论了常微分方程在描述和探索物理动力学的RL控制方面的强大功能，并再次看到GP产生了更好的结果。然而，我们还没有尝试优化任何一个算法，而只是基本设置了算法参数，基本上是通过猜测来进行的。现在我们将通过扩展MGM研究来解决这一不足。
- en: Sagemaker Hyperparmeter Tuning with Custom Models
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sagemaker 超参数调优与自定义模型
- en: 'As discussed previously, both GP and SAC have a set of hyperparameters that
    define the model. These parameters are constant during model training, but can
    be changed to try to improve model performance (such as accuracy or convergence
    speed). As a quick review, the following table describes the hyperparameters used
    in the GP algorithm:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，GP 和 SAC 都有一组定义模型的超参数。这些参数在模型训练过程中是固定的，但可以通过调整来尝试提高模型性能（如准确性或收敛速度）。以下表格简要回顾了
    GP 算法中使用的超参数：
- en: '![](../Images/37ab70b8aef4a33f8925f40abf2477cb.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37ab70b8aef4a33f8925f40abf2477cb.png)'
- en: Ni, Ne, Nn, Pr, Pm, Pc all affect exploration vs exploitation, or how much the
    algorithm spends time trying to find new possible solutions against refining the
    best solutions it already has. N batches trades increased computation time for
    increased accuracy and generalizability.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Ni、Ne、Nn、Pr、Pm、Pc 都影响探索与利用的平衡，即算法在尝试找到新的可能解决方案和优化已有最佳解决方案之间的时间分配。N 批次通过增加计算时间来换取更高的准确性和泛化能力。
- en: 'SAC as implemented here has the following hyperparameters:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这里实现的 SAC 有以下超参数：
- en: '![](../Images/2a06834318773b3865861046d00a8ba8.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a06834318773b3865861046d00a8ba8.png)'
- en: To simplify coding and tuning hyperparameters, several ground rules have been
    imposed. Each hidden layer will have the same number of neurons, and each neural
    network (actor and critic) will have the same dimensions (other than input and
    output layer) and batch/buffer for update. Also, each neural network will use
    the same activation functions and optimizer. These parameters, especially neural
    network shape/dimensions, are valid hyperparameters but omitted from tuning here
    to reduce code complexity and computation time.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化编码和调优超参数，已设定了一些基本规则。每个隐藏层将具有相同数量的神经元，且每个神经网络（包括演员和评论员）将具有相同的维度（输入层和输出层除外），并有相同的批次/缓冲区用于更新。此外，每个神经网络将使用相同的激活函数和优化器。这些参数，尤其是神经网络的形状/维度，虽然是有效的超参数，但为了简化代码复杂性和减少计算时间，这里不进行调优。
- en: The goal with tuning hyperparameters is to determine which ones will product
    the most accurate model with the least computational cost. However, tuning hyperparameters
    requires training the model for each set of hyperparameters. Exploring the entire
    hyperparameter space, even for a modest number of hyperparameters, can lead to
    geometrically large test matrices if we wish to test a wide range of values for
    those parameters. This problem is complicated as parameters parameters can be
    coupled (i.e. the optimal value of one parameter may change depending on the setting
    of another). There are several ways to tune hyperparameters. A grid search will
    test every combination of an entire grid, requiring careful selection of which
    parameters and their values to test. A random search tries random parameters from
    a grid. Finally, some mathematical optimization approach could be used, such as
    Bayesian optimization or another ML algorithm. In any case, the best approach
    requires careful consideration (and maybe hyper-hyper-parameter optimization…)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 调优超参数的目标是确定哪些超参数能够在最小的计算成本下生成最准确的模型。然而，调优超参数需要对每一组超参数进行模型训练。即使是对于适量数量的超参数，如果我们希望测试这些参数的广泛值，探索整个超参数空间也可能会导致几何级数增长的测试矩阵。这个问题更加复杂，因为参数可能是耦合的（即一个参数的最优值可能会根据另一个参数的设置而变化）。有几种方法可以调优超参数。网格搜索会测试整个网格的每种组合，因此需要仔细选择要测试的参数及其值。随机搜索则从网格中随机选择参数。最后，也可以使用一些数学优化方法，如贝叶斯优化或其他机器学习算法。无论如何，最佳的方法需要仔细考虑（也许还需要超超参数优化……）。
- en: AWS Sagemaker offers built in hyperparameter optimization for Sagemaker’s included
    or custom algorithms. Sagemaker’s tuning options are random, grid, Bayesian, or
    hyperband (which favors well performing sets of hyperparameters and can prematurely
    stop underperforming sets). To use Sagemaker’s hyperparameter tuning, we must
    provide the algorithms as Docker containers in Sagemaker, and pass the container
    image and training script into a hyperparameter tuning object.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Sagemaker 提供了内置的超参数优化功能，适用于 Sagemaker 包含的或自定义的算法。Sagemaker 的调优选项包括随机、网格、贝叶斯优化或超带（该方法倾向于选择表现较好的超参数集，并且可以在表现较差的超参数集下提前停止）。要使用
    Sagemaker 的超参数调优，我们必须将算法作为 Docker 容器提供给 Sagemaker，并将容器镜像和训练脚本传入超参数调优对象中。
- en: As neither GP nor the specific SAC implementation use an existing Sagemaker
    algorithm or framework (the SAC used here is based on Jax and Haiku, rather than
    tensorflow, pytorch, or mxnet), we will need to create custom RL frameworks. After
    exploring several tutorials and much trial and error, I was able to build properly
    working containers and training scripts for hyperparamter tuning. There were several
    tricky parts; for example, I found I had to zip my traing file, upload it to S3,
    and then pass the path of the zip file in S3 in order to successfully use the
    hyperparameter argument of Sagemaker’s “estimator” ML object. Dockerfile, container
    files, training scripts, and Jupyter notebooks used in Sagemaker are available
    on git for [SAC](https://github.com/retter-berkeley/DockerSAC) and [GP](https://github.com/retter-berkeley/DockerMLC).
    Links to some of the sources used are available in the notbeooks on Git.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GP和特定的SAC实现都没有使用现有的SageMaker算法或框架（这里使用的SAC基于Jax和Haiku，而不是tensorflow、pytorch或mxnet），我们需要创建自定义的RL框架。在探索了多个教程并经过多次试错之后，我成功地构建了能够正常工作的容器和用于超参数调优的训练脚本。过程中有几个难点；例如，我发现必须将训练文件压缩成zip文件，上传到S3，然后在S3中传递该zip文件的路径，以便成功使用SageMaker“估算器”ML对象的超参数参数。用于SageMaker的Dockerfile、容器文件、训练脚本和Jupyter笔记本可以在Git上找到，分别对应[SAC](https://github.com/retter-berkeley/DockerSAC)和[GP](https://github.com/retter-berkeley/DockerMLC)。部分使用的源代码链接可以在Git的笔记本中找到。
- en: This approach could be refined; for example the app.py file probably doesn’t
    need to be in the container. Also, I put my custom ODE gymnasiums inside of the
    “Classical Control” gymnasium and loaded it locally to reduce the time spent building
    my own gymnasium from scratch.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可以进一步优化；例如，app.py文件可能不需要包含在容器中。此外，我将自定义的ODE gymnasium放在了“经典控制”gymnasium中，并将其本地加载，以减少从头开始构建自己gymnasium的时间。
- en: Once the containers were working, I roughly followed an [AWS blog](https://aws.amazon.com/blogs/machine-learning/optimize-hyperparameters-with-amazon-sagemaker-automatic-model-tuning/)
    to set up the hyperparameter tuning job. To make the hyperparameters work in the
    training scripts (app.py for GP, sacapp.py for SAC) I set up an argparse for the
    parameters as guided by [Sagemaker github examples](https://github.com/aws/amazon-sagemaker-examples/blob/0efd885ef2a5c04929d10c5272681f4ca17dac17/advanced_functionality/custom-training-containers/framework-container/notebook/source_dir/train.py).
    To limit the number of runs (and personal cost) of the tuning jobs, I selected
    a limited set of hyperparameters to focus on exploring the concept and evaluating
    how much effect tuning would have.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦容器正常工作，我大致按照[AWS博客](https://aws.amazon.com/blogs/machine-learning/optimize-hyperparameters-with-amazon-sagemaker-automatic-model-tuning/)设置了超参数调优任务。为了使超参数在训练脚本中生效（GP使用的是app.py，SAC使用的是sacapp.py），我根据[SageMaker
    GitHub示例](https://github.com/aws/amazon-sagemaker-examples/blob/0efd885ef2a5c04929d10c5272681f4ca17dac17/advanced_functionality/custom-training-containers/framework-container/notebook/source_dir/train.py)设置了一个argparse来处理这些参数。为了限制调优任务的运行次数（以及个人成本），我选择了一个有限的超参数集，专注于探索这个概念并评估调优效果。
- en: '![](../Images/447fbcebcbf201ea4693cadaa3c8231e.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/447fbcebcbf201ea4693cadaa3c8231e.png)'
- en: 'Running the hyperparameter tuning job was quick; results are given below:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 运行超参数调优任务非常快；结果如下所示：
- en: '![](../Images/2ec8be1c3257e5b20402e08dd0805a60.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ec8be1c3257e5b20402e08dd0805a60.png)'
- en: Only Probability of Mutation (Pm) has an optimal value near the boundary of
    the range.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 只有变异概率（Pm）在范围边界附近有一个最佳值。
- en: Sagemaker’s examples provide [hyperparmeter visualization](https://github.com/aws-samples/amazon-sagemaker-amt-visualize)
    scripts that allow us to review how the tuning jobs went. We review them for SAC
    below (results for GP hyperparameter tuning are omitted for brevity). First, we
    see an overview of the different tuning jobs (squares were stopped prematurely,
    circles completed) over time against the reward.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker的示例提供了[超参数可视化](https://github.com/aws-samples/amazon-sagemaker-amt-visualize)脚本，允许我们查看调优任务的进展。下面我们回顾SAC的调优过程（GP的超参数调优结果为了简洁省略）。首先，我们看到不同调优任务的概览（方形表示任务提前停止，圆形表示任务已完成），并查看了奖励随时间的变化。
- en: '![](../Images/0d51ce81b1b9b2c67dd7004efb3375b3.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d51ce81b1b9b2c67dd7004efb3375b3.png)'
- en: The visualizations also provide a breakdown by parameter of performance, providing
    insight into impact of different parameters on algorithm performance. Below we
    look at number of neurons per hidden layer and see a trend optimizing around 8.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化还提供了按参数划分的性能细分，帮助我们深入了解不同参数对算法性能的影响。下面我们看看每个隐藏层的神经元数量，发现优化趋势集中在8左右。
- en: '![](../Images/4d58dc6c39539b6a7807af3811412ed9.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d58dc6c39539b6a7807af3811412ed9.png)'
- en: We’ve only scratched the surface of ODEs and hyperparmeters. Specifically, the
    exploration of SAC tuning has been rudimentary; neural network design is a science
    (or perhaps art) unto itself. However, hopefully this article has provided an
    insight into and starting point for applying and optimizing RL for physical dynamics!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅仅触及了常微分方程（ODE）和超参数的表面。具体而言，SAC调优的探索仍然是初步的；神经网络设计本身就是一门科学（或者说艺术）。然而，本文希望能够为物理动态中的强化学习应用和优化提供一些见解和起点！
- en: '[1] Manchester, Ian R., and Jean-Jacques E. Slotine. “Output-Feedback Control
    of Nonlinear Systems Using Control Contraction Metrics and Convex Optimization.”
    2014 4th Australian Control Conference (AUCC) (November 2014).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Manchester, Ian R., 和 Jean-Jacques E. Slotine. “使用控制收缩度量和凸优化进行非线性系统的输出反馈控制。”
    2014年第4届澳大利亚控制会议（AUCC）（2014年11月）。'
