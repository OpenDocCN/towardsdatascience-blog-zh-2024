<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Unlocking Insights: Building a Scorecard with Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Unlocking Insights: Building a Scorecard with Logistic Regression</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unlocking-insights-building-a-scorecard-with-logistic-regression-d05cd5eb0927?source=collection_archive---------2-----------------------#2024-02-15">https://towardsdatascience.com/unlocking-insights-building-a-scorecard-with-logistic-regression-d05cd5eb0927?source=collection_archive---------2-----------------------#2024-02-15</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="eb47" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><em class="hd">After a credit card? An insurance policy? Ever wondered about the three-digit number that shapes these decisions?</em></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@morozov6?source=post_page---byline--d05cd5eb0927--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Vassily Morozov" class="l ep by dd de cx" src="../Images/ad68147fa291f1e1e2c03ec958232717.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*cVPDjh8x6KqEplcca2jrrA.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d05cd5eb0927--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@morozov6?source=post_page---byline--d05cd5eb0927--------------------------------" rel="noopener follow">Vassily Morozov</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d05cd5eb0927--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk lb lc ab q ee ld le" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lf"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap ie li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><h2 id="8f74" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Introduction</strong></h2><p id="1ac8" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Scores are used by a large number of industries to make decisions. Financial institutions and insurance providers are using scores to determine whether someone is right for credit or a policy. Some nations are even using social scoring to determine an individual’s trustworthiness and judge their behaviour<em class="oa">.</em></p><p id="92ae" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">For example, before a score was used to make an automatic decision, a customer would go into a bank and speak to a person regarding how much they want to borrow and why they need a loan. The bank employee may impose their own thoughts and biases into their decision-making process. Where is this person from? What are they wearing? Even, how do I feel today?</p><p id="b733" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk"><em class="oa">A score levels the playing field and allows everyone to be assessed on the same basis.</em></p><figure class="oj ok ol om on oo og oh paragraph-image"><div role="button" tabindex="0" class="op oq ed or bh os"><div class="og oh oi"><img src="../Images/e0e5b113e73d07b45653694be961b5c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EKBruMDrZk0g-_W4xgLfaA.jpeg"/></div></div><figcaption class="ou ov ow og oh ox oy bf b bg z dx">Generated by <a class="af oz" href="https://deepai.org/machine-learning-model/text2img" rel="noopener ugc nofollow" target="_blank">DeepAI</a> image generator</figcaption></figure><p id="3f91" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Recently, I have been taking part in several <a class="af oz" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"><em class="oa">Kaggle</em></a> competitions and analyses of featured datasets. The first playground competition of 2024 aimed to determine the likelihood of a customer leaving a bank. This is a common task that is useful for marketing departments. For this competition, I thought I would put aside the tree-based and ensemble modelling techniques normally required to be competitive in these tasks, and go back to the basics: a <strong class="nj fr">logistic regression</strong>.</p><p id="a9f0" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Here, I will guide you through the development of the logistic regression model, its conversion into a score, and its presentation as a scorecard. The aim of doing this is to show how this can reveal insights about your data and its relationship to a binary target. The advantage of this type of model is that it is simpler and easier to explain, even to non-technical audiences.</p><p id="ea70" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">My Kaggle notebook with all my code and maths can be found <a class="af oz" href="https://www.kaggle.com/code/vassyesboy/scorecard-logistic-regression-s4e1" rel="noopener ugc nofollow" target="_blank"><em class="oa">here</em></a><em class="oa">. </em>This article will focus on the highlights.</p><h2 id="9242" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk">What is a Score?</h2><p id="9b8c" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">The score we are describing here is based on a logistic regression model. The model assigns weights to our input features and will output a probability that we can convert through a calibration step into a score. Once we have this, we can represent it with a scorecard: showing how an individual is scoring based on their available data.</p><p id="7c02" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Let’s go through a simple example.</p><p id="e03a" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Mr X walks into a bank looking for loan for a new business. The bank uses a simple score based on income and age to determine whether the individual should be approved.</p><figure class="oj ok ol om on oo"><div class="pa ip l ed"><div class="pb pc l"/></div></figure><p id="95ef" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Mr X is a young individual with a relatively low income. He is penalised for his age, but scores well (second best) in the income band. In total, he scores 24 points in this scorecard, which is a mid-range score (the maximum number of points being 52).</p><p id="957b" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">A score cut-off would often be used by the bank to say how many points are needed to be accepted based on internal policy. A score is based on a logistic regression which is built on some binary definition, using a set of features to predict the log odds.</p><figure class="oj ok ol om on oo"><div class="pa ip l ed"><div class="pd pc l"/></div></figure><p id="0f3b" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">In the case of a bank, the logistic regression may be trying to predict those that have missed payments. For an insurance provider, those who have made a claim before. For a social score, those that have ever attended an anarchist gathering (not really sure what these scores would be predicting but I would be fascinated to know!).</p><p id="d759" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">We will not go through everything required for a full model development, but some of the key steps that will be explored are:</p><ul class=""><li id="6b58" class="nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz pe pf pg bk"><strong class="nj fr">Weights of Evidence Transformation: </strong>Making our continuous features discrete by banding them up as with the Mr X example.</li><li id="67f3" class="nh ni fq nj b go ph nl nm gr pi no np mu pj nr ns my pk nu nv nc pl nx ny nz pe pf pg bk"><strong class="nj fr">Calibrating our Logistic Regression Outputs to Generate a Score: </strong>Making our probability into a more user-friendly number by converting it into a score.</li><li id="17c1" class="nh ni fq nj b go ph nl nm gr pi no np mu pj nr ns my pk nu nv nc pl nx ny nz pe pf pg bk"><strong class="nj fr">Representing Our Score as a Scorecard</strong>: Showing how each feature contributes to the final score.</li></ul><h2 id="9433" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Weights of Evidence Transformation</strong></h2><p id="3a51" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">In the Mr X example, we saw that the model had two features which were based on numeric values: the age and income of Mr X. These variables were banded into groups to make it easier to understand the model and what drives an individual’s score. Using these continuous variables directly (as oppose to within a group) could mean significantly different scores for small differences in values. In the context of credit or insurance risk, this makes a decision harder to justify and explain.</p><p id="a66d" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">There are a variety of ways to approach the banding, but normally an initial automated approach is taken, before fine-tuning the groupings manually to make qualitative sense. Here, I fed each continuous feature individually into a decision tree to get an initial set of groupings.</p><p id="631f" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Once the groupings were available, I calculated the weights of evidence for each band. The formula for this is shown below:</p><figure class="oj ok ol om on oo"><div class="pa ip l ed"><div class="pm pc l"/></div><figcaption class="ou ov ow og oh ox oy bf b bg z dx">Formula for Weights of Evidence (WoE). The distributions can be flipped to reverse the relationship in your features.</figcaption></figure><p id="51cb" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">This is a commonly used transformation technique in scorecard modelling where a logistic regression is used given its linear relationship to the log odds, the thing that the logistic regression is aimed to predict. I will not go into the maths of this here as this is covered in full detail in my <a class="af oz" href="https://www.kaggle.com/code/vassyesboy/scorecard-logistic-regression-s4e1" rel="noopener ugc nofollow" target="_blank">Kaggle notebook</a>.</p><p id="1330" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Once we have the weights of evidence for each banded feature, we can visualise the trend. From the Kaggle data used for bank churn prediction, I have included a couple of features to illustrate the transformations.</p><figure class="oj ok ol om on oo og oh paragraph-image"><div role="button" tabindex="0" class="op oq ed or bh os"><div class="og oh pn"><img src="../Images/d0d573064f4101b1fe9758b8b7cdf117.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iuz6rjl7DP2JYysM6i3h6w.png"/></div></div><figcaption class="ou ov ow og oh ox oy bf b bg z dx"><em class="hd">Image by author</em></figcaption></figure><p id="a99c" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">The red bars surrounding each weights of evidence show a 95% confidence interval, implying we are 95% sure that the weights of evidence would fall within this range. Narrow intervals are associated with robust groups that have sufficient volume to be confident in the weights of evidence.</p><p id="efce" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">For example, categories 16 and 22 of the grouped balance have low volumes of customers leaving the bank (19 and 53 cases in each group respectively) and have the widest confidence intervals.</p><p id="1f0c" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">The patterns reveal insights about the feature relationship and the chance of a customer leaving the bank. The age feature is slightly simpler to understand so we will tackle that first.</p><p id="52b3" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk"><strong class="nj fr">As a customer gets older they are more likely to leave the bank.</strong></p><p id="7323" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">The trend is fairly clear and mostly monotonic except some groups, for example 25–34 year old individuals are less likely to leave than 18–24 year old cases. Unless there is a strong argument to support why this is the case (domain knowledge comes into play!), we may consider grouping these two categories to ensure a monotonic trend.</p><p id="952b" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">A monotonic trend is important when making decisions to grant credit or an insurance policy as this is often a regulatory requirement to make the models interpretable and not just accurate.</p><p id="c984" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">This brings us on to the balance feature. The pattern is not clear and we don’t have a real argument to make here. It does seem that customers with lower balances have less chance to leave the bank but you would need to band several of the groups to make this trend make any sense.</p><p id="938e" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">By grouping categories 2–9, 13–21 and leaving 22 on its own (into bins 1, 2 and 3 respectively) we can start to see the trend. However, the down side of this is losing granularity in our features and likely impacting downstream model performance.</p><figure class="oj ok ol om on oo og oh paragraph-image"><div role="button" tabindex="0" class="op oq ed or bh os"><div class="og oh po"><img src="../Images/9c845ebff89e82b494838188fd785703.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*soyzM3zm1ONE2M0npOj5SA.png"/></div></div><figcaption class="ou ov ow og oh ox oy bf b bg z dx"><em class="hd">Image by author</em></figcaption></figure><p id="99e2" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">For the Kaggle competition, my model did not need to be explainable, so I did not regroup any of the features and just focused on producing the most predictive score based on the automatic groupings I applied. In an industry setting, I may think twice about doing this.</p><p id="2e73" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">It is worth noting that our insights are limited to the features we have available and there may be other underlying causes for the observed behaviour. For example, the age trend may have been driven by policy changes over time such as the move to online banking, but there is no feasible way to capture this in the model without additional data being available.</p><p id="d1d1" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">If you want to perform auto groupings to numeric features, apply this transformation and make these associated graphs for yourselves, they can be created for any binary classification task using the Python repository I put together <a class="af oz" href="https://github.com/VassMorozov/Weights-of-Evidence" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="74a3" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Once these features are available, we can fit a logistic regression. The fitted logistic regression will have an intercept and each feature in the model will have a coefficient assigned to it. From this, we can output the probability that someone is going to leave the bank. I won’t spend time here discussing how I fit the regression, but as before, all the details are available in my <a class="af oz" href="https://www.kaggle.com/code/vassyesboy/scorecard-logistic-regression-s4e1" rel="noopener ugc nofollow" target="_blank">Kaggle notebook</a>.</p><h1 id="64ed" class="pp mk fq bf ml pq pr gq mp ps pt gt mt pu pv pw px py pz qa qb qc qd qe qf qg bk"><strong class="al">Calibrating our Logistic Regression Outputs to Generate a Score</strong></h1><p id="1e8c" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">The fitted logistic regression can output a probability, however this is not particularly useful for non-technical users of the score. As such, we need to calibrate these probabilities and transform them into something neater and more interpretable.</p><p id="b4c0" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Remember that the logistic regression is aimed at predicting the log odds. We can create the score by performing a linear transformation to these odds in the following way:</p><figure class="oj ok ol om on oo"><div class="pa ip l ed"><div class="qh pc l"/></div></figure><p id="ef54" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">In credit risk, the points to double the odds and 1:1 odds are typically set to 20 and 500 respectively, however this is not always the case and the values may differ. For the purposes of my analysis, I stuck to these values.</p><p id="42ff" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">We can visualise the calibrated score by plotting its distribution.</p><figure class="oj ok ol om on oo og oh paragraph-image"><div role="button" tabindex="0" class="op oq ed or bh os"><div class="og oh qi"><img src="../Images/f966b0f3b1b52776a11f1152698f8921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iwj1CixHeYc0m8bqjwWRJw.png"/></div></div><figcaption class="ou ov ow og oh ox oy bf b bg z dx"><em class="hd">Image by author</em></figcaption></figure><p id="3e6d" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">I split the distribution by the target variable (whether a customer leaves the bank), this provides a useful validation that all the previous steps have been done correctly. Those more likely to leave the bank score lower and those who stay score higher. There is an overlap, but a score is rarely perfect!</p><p id="dc94" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Based on this score, a marketing department may set a score cut-off to determine which customers should be targeted with a particular marketing campaign. This cut-off can be set by looking at this distribution and converting a score back to a probability.</p><p id="ac72" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Translating a score of 500 would give a probability of 50% (remember that our 1:1 odds are equal to 500 for the calibration step). This would imply that half of our customers below a score of 500 would leave the bank. If we want to target more of these customers, we would just need to raise the score cut-off.</p><h2 id="7b44" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk">Representing Our Score as a Scorecard</h2><p id="9772" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">We already know that the logistic regression is made up of an intercept and a set of weights for each of the used features. We also know that the weights of evidence have a direct linear relationship with the log odds. Knowing this, we can convert the weights of evidence for each feature to understand its contribution to the overall score.</p><figure class="oj ok ol om on oo"><div class="pa ip l ed"><div class="qj pc l"/></div></figure><p id="0c46" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">I have displayed this for all features in the model in my <a class="af oz" href="https://www.kaggle.com/code/vassyesboy/scorecard-logistic-regression-s4e1" rel="noopener ugc nofollow" target="_blank">Kaggle notebook</a>, but below are examples we have already seen when transforming the variables into their weights of evidence form.</p><p id="e153" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk"><strong class="nj fr">Age</strong></p><figure class="oj ok ol om on oo"><div class="pa ip l ed"><div class="pb pc l"/></div></figure><p id="0aa0" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk"><strong class="nj fr">Balance</strong></p><figure class="oj ok ol om on oo"><div class="pa ip l ed"><div class="pb pc l"/></div></figure><p id="04fd" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">The advantage of this representation, as opposed to the weights of evidence form, is it should make sense to anyone without needing to understand the underlying maths. I can tell a marketing colleague that customers age 48 to 63 years old are scoring lower than other customers. A customer with no balance in their account is more likely to leave than someone with a high balance.</p><p id="e75f" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">You may have noticed that in the scorecard the balance trend is the opposite to what was observed at the weights of evidence stage. Now, low balances are scoring lower. This is due to the coefficient attached to this feature in the model. It is negative and so is flipping the initial trend. This can happen as there are various interactions happening between the features during the fitting of the model. A decision must be made whether these sorts of interactions are acceptable or whether you would want to drop the feature if the trend becomes unintuitive.</p><p id="5a52" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">Supporting documentation can explain the full detail of any score and how it is developed (or at least should!), but with just the scorecard, anyone should be able to get immediate insights!</p><h2 id="1fe1" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk">Conclusion</h2><p id="d108" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">We have explored some of the key steps in developing a score based on a logistic regression and the insights that it can bring. The simplicity of the final output is why this type of score is still used to this day in the face of more advanced classification techniques.</p><p id="d2b5" class="pw-post-body-paragraph nh ni fq nj b go ob nl nm gr oc no np mu od nr ns my oe nu nv nc of nx ny nz fj bk">The score I developed for this competition had an area under the curve of 87.4%, while the top solutions based on ensemble techniques were around 90%. This shows that the simple model is still competitive, although not perfect if you are just looking for accuracy. However, if for your next classification task you are looking for something simple and easily explainable, what about considering a scorecard to gain insights into your data?</p><h2 id="88f8" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk">Reference</h2><p id="def8" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">[1] Walter Reade, Ashley Chow, <a class="af oz" href="https://kaggle.com/competitions/playground-series-s4e1" rel="noopener ugc nofollow" target="_blank">Binary Classification with a Bank Churn Dataset</a> (2024), Kaggle.</p></div></div></div></div>    
</body>
</html>