<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Bias-Variance Tradeoff, Explained: A Visual Guide with Code Examples for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Bias-Variance Tradeoff, Explained: A Visual Guide with Code Examples for Beginners</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bias-variance-tradeoff-explained-a-visual-guide-with-code-examples-for-beginners-9521871f728a?source=collection_archive---------4-----------------------#2024-11-25">https://towardsdatascience.com/bias-variance-tradeoff-explained-a-visual-guide-with-code-examples-for-beginners-9521871f728a?source=collection_archive---------4-----------------------#2024-11-25</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="1352" class="fo fp fq bf b dy fr fs ft fu fv fw dx fx" aria-label="kicker paragraph">MODEL EVALUATION &amp; OPTIMIZATION</h2><div/><div><h2 id="78cb" class="pw-subtitle-paragraph gs fz fq bf b gt gu gv gw gx gy gz ha hb hc hd he hf hg hh cq dx">How underfitting and overfitting fight over your models</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hi hj hk hl hm ab"><div><div class="ab hn"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@samybaladram?source=post_page---byline--9521871f728a--------------------------------" rel="noopener follow"><div class="l ho hp by hq hr"><div class="l ed"><img alt="Samy Baladram" class="l ep by dd de cx" src="../Images/715cb7af97c57601966c5d2f9edd0066.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="hs by l dd de em n ht eo"/></div></div></a></div></div><div class="hu ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--9521871f728a--------------------------------" rel="noopener follow"><div class="l hv hw by hq hx"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hy cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hs by l br hy em n ht eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hz ab q"><div class="ab q ia"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ib ic bk"><a class="af ag ah ai aj ak al am an ao ap aq ar id" data-testid="authorName" href="https://medium.com/@samybaladram?source=post_page---byline--9521871f728a--------------------------------" rel="noopener follow">Samy Baladram</a></p></div></div></div><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ib ic dx"><button class="ig ih ah ai aj ak al am an ao ap aq ar ii ij ik" disabled="">Follow</button></p></div></div></span></div></div><div class="l il"><span class="bf b bg z dx"><div class="ab cn im in io"><div class="ip iq ab"><div class="bf b bg z dx ab ir"><span class="is l il">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar id ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--9521871f728a--------------------------------" rel="noopener follow"><p class="bf b bg z it iu iv iw ix iy iz ja bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">20 min read</span><div class="jb jc l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 25, 2024</span></div></span></div></span></div></div></div><div class="ab cp jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js"><div class="h k w ea eb q"><div class="ki l"><div class="ab q kj kk"><div class="pw-multi-vote-icon ed is kl km kn"><div class=""><div class="ko kp kq kr ks kt ku am kv kw kx kn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ky kz la lb lc ld le"><p class="bf b dy z dx"><span class="kp">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ko lh li ab q ee lj lk" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lg"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lf lg">1</span></p></button></div></div></div><div class="ab q jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="ll k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lm an ao ap ii ln lo lp" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lq cn"><div class="l ae"><div class="ab cb"><div class="lr ls lt lu lv lw ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="2149" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Every time someone builds a prediction model, they face these classic problems: underfitting and overfitting. The model cannot be too simple, yet it also cannot be too complex. The interaction between these two forces is known as the bias-variance tradeoff, and it affects every predictive model out there.</p><p id="34bc" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">The thing about this topic of “bias-variance tradeoff” is that whenever you try to look up these terms online, you’ll find lots of articles with these perfect curves on graphs. Yes, they explain the basic idea — but they miss something important: they focus too much on theory, not enough on real-world problems, and rarely show what happens when you work with actual data.</p><p id="333a" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Here, instead of theoretical examples, we’ll work with a real dataset and build actual models. Step by step, we’ll see exactly how models fail, what underfitting and overfitting look like in practice, and why finding the right balance matters. Let’s stop this fight between bias and variance, and find a fair middle ground.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/bf28840b0f2c53d90e3c33fda840385f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7iilm-b4uavyJU4RGTwmXA.png"/></div></div><figcaption class="ny nz oa nk nl ob oc bf b bg z dx">All visuals: Author-created using Canva Pro. Optimized for mobile; may appear oversized on desktop.</figcaption></figure><h1 id="9844" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">What is Bias-Variance Tradeoff?</h1><p id="2b7e" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Before we start, to avoid confusion, let’s make things clear about the terms <strong class="mq ga">bias</strong> and <strong class="mq ga">variance</strong> that we are using here in machine learning. These words get used differently in many places in math and data science.</p><p id="2190" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Bias can mean several things. <a class="af pe" href="https://en.wikipedia.org/wiki/Bias_(statistics)" rel="noopener ugc nofollow" target="_blank">In statistics</a>, it means how far off our calculations are from the true answer, and <a class="af pe" href="https://en.wikipedia.org/wiki/Selection_bias" rel="noopener ugc nofollow" target="_blank">in data science</a>, it can mean unfair treatment of certain groups. Even in the for other part of machine learning which <a class="af pe" href="https://www.turing.com/kb/necessity-of-bias-in-neural-networks" rel="noopener ugc nofollow" target="_blank">in neural networks</a>, it’s a special number that helps the network learn</p><p id="298a" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Variance also has different meanings. <a class="af pe" href="https://en.wikipedia.org/wiki/Variance" rel="noopener ugc nofollow" target="_blank">In statistics</a>, it tells us how spread out numbers are from their average and <a class="af pe" href="https://www.creative-wisdom.com/teaching/WBI/variance_control.shtml" rel="noopener ugc nofollow" target="_blank">in scientific experiments</a>, it shows how much results change each time we repeat them.</p><p id="d060" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">But in machine learning’s “bias-variance tradeoff,” these words have special meanings.</p><p id="c43f" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk"><strong class="mq ga">Bias</strong> means how well a model can learn patterns. When we say a model has high bias, we mean it’s too simple and keeps making the same mistakes over and over.</p><p id="a9b2" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk"><strong class="mq ga">Variance</strong> here means how much your model’s answers change when you give it different training data. When we say high variance, we mean the model<strong class="mq ga"> </strong>changes its answers too much when we show it new data.</p><p id="b19d" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">The “<strong class="mq ga">bias-variance tradeoff</strong>” is not something we can measure exactly with numbers. Instead, it helps us understand how our model is working: If a model has high bias, it does poorly on both training data and test data, an if a model has high variance, it does very well on training data but poorly on test data.</p><p id="2991" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This helps us fix our models when they’re not working well. Let’s set up our problem and data set to see how to apply this concept.</p><h1 id="9b2d" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">⛳️ Setting Up Our Problem</h1><h2 id="8593" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">Training and Test Dataset</h2><p id="553b" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Say, you own a golf course and now you’re trying to predict how many players will show up on a given day. You have collected the data about the weather: starting from the general outlook until the details of temperature and humidity. You want to use these weather conditions to predict how many players will come.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/62b6715e07ff01c02029294d84cd18f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dCDfe6wpEq9dEsNQHtSPRQ.png"/></div></div><figcaption class="ny nz oa nk nl ob oc bf b bg z dx">Columns: ‘Outlook (sunny, overcast, rain)’, ’Temperature’ (in Fahrenheit), ‘Humidity’ (in %), ‘Windy’ (Yes/No) and ‘Number of Players’ (target feature)</figcaption></figure><pre class="nn no np nq nr pv pw px bp py bb bk"><span id="0c6f" class="pz oe fq pw b bg qa qb l qc qd">import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/><br/># Data preparation<br/>dataset_dict = {<br/>    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'overcast', 'sunny', 'overcast', 'rain', 'sunny', 'overcast', 'rain', 'sunny', 'rain',<br/>                'sunny', 'overcast', 'rain', 'sunny', 'rain', 'overcast', 'sunny', 'rain', 'overcast', 'sunny', 'overcast', 'rain', 'sunny', 'rain'],<br/>    'Temp.': [92.0, 78.0, 75.0, 70.0, 62.0, 68.0, 85.0, 73.0, 65.0, 88.0, 76.0, 63.0, 83.0, 66.0,<br/>              91.0, 77.0, 64.0, 79.0, 61.0, 72.0, 86.0, 67.0, 74.0, 89.0, 75.0, 65.0, 82.0, 63.0],<br/>    'Humid.': [95.0, 65.0, 82.0, 90.0, 75.0, 70.0, 88.0, 78.0, 95.0, 72.0, 80.0, 85.0, 68.0, 92.0,<br/>               93.0, 80.0, 88.0, 70.0, 78.0, 75.0, 85.0, 92.0, 77.0, 68.0, 83.0, 90.0, 65.0, 87.0],<br/>    'Wind': [False, False, False, True, False, False, False, True, False, False, True, True, False, True,<br/>             True, True, False, False, True, False, True, True, False, False, True, False, False, True],<br/>    'Num_Players': [25, 85, 80, 30, 17, 82, 45, 78, 32, 65, 70, 20, 87, 24,<br/>                   28, 68, 35, 75, 25, 72, 55, 32, 70, 80, 65, 24, 85, 25]<br/>}<br/><br/># Data preprocessing<br/>df = pd.DataFrame(dataset_dict)<br/>df = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)<br/>df['Wind'] = df['Wind'].astype(int)</span></pre><p id="01ce" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This might sound simple, but there’s a catch. We only have information from 28 different days — that’s not a lot! And to make things even trickier, we need to split this data into two parts: 14 days to help our model learn (we call this training data), and 14 days to test if our model actually works (test data).</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/385ccc5503447fe191d0d6c2e3a5fc50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MC3gqf6bMcsnqpuLXRjzew.png"/></div></div><figcaption class="ny nz oa nk nl ob oc bf b bg z dx">The first 14 dataset will be used to train the model, while the final 14 will be used to test the model.</figcaption></figure><pre class="nn no np nq nr pv pw px bp py bb bk"><span id="9512" class="pz oe fq pw b bg qa qb l qc qd"># Split features and target<br/>X, y = df.drop('Num_Players', axis=1), df['Num_Players']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)</span></pre><p id="3ffe" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Think about how hard this is. There are so many possible combination of weather conditions. It can be sunny &amp; humid, sunny &amp; cool, rainy &amp; windy, overcast &amp; cool, or other combinations. With only 14 days of training data, we definitely won’t see every possible weather combination. But our model still needs to make good predictions for any weather condition it might encounter.</p><p id="2b63" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This is where our challenge begins. If we make our model too simple — like only looking at temperature — it will miss important details like wind and rain. That’s not good enough. But if we make it too complex — trying to account for every tiny weather change — it might think that one random quiet day during a rainy week means rain actually brings more players. With only 14 training examples, it’s easy for our model to get confused.</p><p id="90d5" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">And here’s the thing: unlike many examples you see online, our data isn’t perfect. Some days might have similar weather but different player counts. Maybe there was a local event that day, or maybe it was a holiday — but our weather data can’t tell us that. This is exactly what makes real-world prediction problems tricky.</p><p id="d059" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">So before we get into building models, take a moment to appreciate what we’re trying to do:</p><blockquote class="qe"><p id="89e0" class="qf qg fq bf qh qi qj qk ql qm qn nj dx">Using just 14 examples to create a model that can predict player counts for ANY weather condition, even ones it hasn’t seen before.</p></blockquote><p id="6354" class="pw-post-body-paragraph mo mp fq mq b gt qo ms mt gw qp mv mw mx qq mz na nb qr nd ne nf qs nh ni nj fj bk">This is the kind of real challenge that makes the bias-variance trade-off so important to understand.</p><h2 id="1736" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">Model Complexity</h2><p id="3b42" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">For our predictions, we’ll use decision tree regressors with varying depth (if you want to learn how this works, check out my article on <a class="af pe" rel="noopener" target="_blank" href="/decision-tree-regressor-explained-a-visual-guide-with-code-examples-fbd2836c3bef">decision tree basics</a>). What matters for our discussion is how complex we let this model become.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/bf5db4005f606e72d8e76bceb6b6a41b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aimaprh5g_K2j1HB7LE1CA.png"/></div></div><figcaption class="ny nz oa nk nl ob oc bf b bg z dx">We will train the decision trees using the whole training dataset. The depth of the tree is set first to stop the tree from growing up to a certain depth.</figcaption></figure><pre class="nn no np nq nr pv pw px bp py bb bk"><span id="dd50" class="pz oe fq pw b bg qa qb l qc qd">from sklearn.tree import DecisionTreeRegressor<br/><br/># Define constants<br/>RANDOM_STATE = 3 # As regression tree can be sensitive, setting this parameter assures that we always get the same tree<br/>MAX_DEPTH = 5<br/><br/># Initialize models<br/>trees = {depth: DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_STATE).fit(X_train, y_train) <br/>         for depth in range(1, MAX_DEPTH + 1)}</span></pre><p id="1869" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">We’ll control the model’s complexity using its depth — from depth 1 (simplest) to depth 5 (most complex).</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/a67bdc7fd280e92d694e0663903f4123.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9vpZy_9BuLWBnAyAHOb_uA.png"/></div></div></figure><pre class="nn no np nq nr pv pw px bp py bb bk"><span id="eb59" class="pz oe fq pw b bg qa qb l qc qd"><br/>import matplotlib.pyplot as plt<br/>from sklearn.tree import plot_tree<br/><br/># Plot trees<br/>for depth in range(1, MAX_DEPTH + 1):<br/>    plt.figure(figsize=(12, 0.5*depth+1.5), dpi=300)<br/>    plot_tree(trees[depth], feature_names=X_train.columns.tolist(), <br/>              filled=True, rounded=True, impurity=False, precision=1, fontsize=8)<br/>    plt.title(f'Depth {depth}')<br/>    plt.show()</span></pre><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl qt"><img src="../Images/01f44ef4c0388791ef9aacbfd5b7082c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MXTxaacj2b2GZWVmiweysg.png"/></div></div></figure><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl qt"><img src="../Images/8fa8694a1819b9ef1a4b11f46a4ab28d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPSfKGN3lhz5rN6hX8ADaA.png"/></div></div></figure><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl qt"><img src="../Images/7a3031d067133f5aee51d4887838a3fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7-84FOFhoN5ZVh3ds-q0-A.png"/></div></div></figure><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl qt"><img src="../Images/708ba80f3954ee07c52c534e06007255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eRHwgi-GwUtdj5q5l-oziQ.png"/></div></div></figure><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl qt"><img src="../Images/9d4c754e23142f5685ea75c0ef9cc311.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzNzZ_rxRt6DbWJd3GKqUw.png"/></div></div></figure><p id="7780" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Why these complexity levels matter:</p><ul class=""><li id="d4a3" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qu qv qw bk">Depth 1: Extremely simple — creates just a few different predictions</li><li id="793c" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Depth 2: Slightly more flexible — can create more varied predictions</li><li id="0830" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Depth 3: Moderate complexity — getting close to too many rules</li><li id="0f8e" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Depth 4–5: Highest complexity — nearly one rule per training example</li></ul><p id="61c0" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Notice something interesting? Our most complex model (depth 5) creates almost as many different prediction rules as we have training examples. When a model starts making unique rules for almost every training example, it’s a clear sign we’ve made it too complex for our small dataset.</p><p id="637e" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Throughout the next sections, we’ll see how these different complexity levels perform on our golf course data, and why finding the right complexity is crucial for making reliable predictions.</p><h1 id="56c7" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">What Makes a Model “Good”?</h1><h2 id="acf3" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">Prediction Errors</h2><p id="d340" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">The main goal in prediction is to make guesses as close to the truth as possible. We need a way to measure errors that sees guessing too high or too low as equally bad. A prediction 10 units above the real answer is just as wrong as one 10 units below it.</p><p id="9ec1" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This is why we use<strong class="mq ga"> Root Mean Square Error (RMSE)</strong> as our measurement. RMSE gives us the typical size of our prediction errors. If RMSE is 7, our predictions are usually off by about 7 units. If it’s 3, we’re usually off by about 3 units. A lower RMSE means better predictions.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl rc"><img src="../Images/4b69f4c62599ba2ba173037469adb4b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*e42MG9Ryhr5w_vjFu0n6Gw.png"/></div></div><figcaption class="ny nz oa nk nl ob oc bf b bg z dx">In the simple 5-point dataset above, we can say our prediction is roughly off by 3 people.</figcaption></figure><p id="d181" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">When measuring model performance, we always calculate two different errors. First is the training error — how well the model performs on the data it learned from. Second is the test error — how well it performs on new data it has never seen. This test error is crucial because it tells us how well our model will work in real-world situations where it faces new data.</p><h2 id="b1fc" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">⛳️ Looking at Our Golf Course Predictions</h2><p id="86a1" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">In our golf course case, we’re trying to predict daily player counts based on weather conditions. We have data from 28 different days, which we split into two equal parts:</p><ul class=""><li id="1afa" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qu qv qw bk">Training data: Records from 14 days that our model uses to learn patterns</li><li id="609e" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Test data: Records from 14 different days that we keep hidden from our model</li></ul><p id="4471" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Using the models we made, let’s test both the training data and the test data, and also calculating their RMSE.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/dc2e2893ad9d5e16348b6abb679078ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1-h7-QeZzGzeDnWeV1ZtnQ.png"/></div></div></figure><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/4c345cc4d52de24c83c3d9d4c1759c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d9KPaFTkq2Jq-m-gjeYu4g.png"/></div></div></figure><pre class="nn no np nq nr pv pw px bp py bb bk"><span id="7133" class="pz oe fq pw b bg qa qb l qc qd"># Create training predictions DataFrame<br/>train_predictions = pd.DataFrame({<br/>    f'Depth_{i}': trees[i].predict(X_train) for i in range(1, MAX_DEPTH + 1)<br/>})<br/>#train_predictions['Actual'] = y_train.values<br/>train_predictions.index = X_train.index<br/><br/># Create test predictions DataFrame<br/>test_predictions = pd.DataFrame({<br/>    f'Depth_{i}': trees[i].predict(X_test) for i in range(1, MAX_DEPTH + 1)<br/>})<br/>#test_predictions['Actual'] = y_test.values<br/>test_predictions.index = X_test.index<br/><br/>print("\nTraining Predictions:")<br/>print(train_predictions.round(1))<br/>print("\nTest Predictions:")<br/>print(test_predictions.round(1))</span></pre><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl rd"><img src="../Images/413369456a72d5c176d6baa2f6a16e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6v9KqaZB0vUjJh4eikQxYw.png"/></div></div></figure><pre class="nn no np nq nr pv pw px bp py bb bk"><span id="b17e" class="pz oe fq pw b bg qa qb l qc qd">from sklearn.metrics import root_mean_squared_error<br/><br/># Calculate RMSE values<br/>train_rmse = {depth: root_mean_squared_error(y_train, tree.predict(X_train))<br/>              for depth, tree in trees.items()}<br/>test_rmse = {depth: root_mean_squared_error(y_test, tree.predict(X_test))<br/>             for depth, tree in trees.items()}<br/><br/># Print RMSE summary as DataFrame<br/>summary_df = pd.DataFrame({<br/>    'Train RMSE': train_rmse.values(),<br/>    'Test RMSE': test_rmse.values()<br/>}, index=range(1, MAX_DEPTH + 1))<br/>summary_df.index.name = 'max_depth'<br/><br/>print("\nSummary of RMSE values:")<br/>print(summary_df.round(2))</span></pre><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl re"><img src="../Images/857cc086116969099a9091f30891f2db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vd6I5SeA1wVWdQkv0abm8w.png"/></div></div></figure><p id="326e" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Looking at these numbers, we can already see some interesting patterns: As we make our models more complex, they get better and better at predicting player counts for days they’ve seen before — to the point where our most complex model makes perfect predictions on training data.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl rf"><img src="../Images/e92e88824480d1a8c42c20133d07f189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HDea3xMPpvGesD541NslQg.png"/></div></div></figure><p id="edd5" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">But the real test is how well they predict player counts for new days. Here, we see something different. While adding some complexity helps (the test error keeps getting better from depth 1 to depth 3), making the model too complex (depth 4–5) actually starts making things worse again.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl rg"><img src="../Images/d91133e82e8ea3802cc41540d83ca708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bhprnh_8p-BrqQSKv8dfRA.png"/></div></div></figure><p id="c910" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This difference between training and test performance (from being off by 3–4 players to being off by 9 players) shows a fundamental challenge in prediction: performing well on new, unseen situations is much harder than performing well on familiar ones. Even with our best performing model, we see this gap between training and test performance.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl rf"><img src="../Images/d18915b0493f91277de71fb1301381f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aPftwLac33K9SE22XCPucw.png"/></div></div></figure><pre class="nn no np nq nr pv pw px bp py bb bk"><span id="a4fc" class="pz oe fq pw b bg qa qb l qc qd"># Create figure<br/>plt.figure(figsize=(4, 3), dpi=300)<br/>ax = plt.gca()<br/><br/># Plot main lines<br/>plt.plot(summary_df.index, summary_df['Train RMSE'], marker='o', label='Train RMSE', <br/>         linestyle='-', color='crimson', alpha=0.1)<br/>plt.plot(summary_df.index, summary_df['Test RMSE'], marker='o', label='Test RMSE', <br/>         linestyle='-', color='crimson', alpha=0.6)<br/><br/># Add vertical lines and difference labels<br/>for depth in summary_df.index:<br/>    train_val = summary_df.loc[depth, 'Train RMSE']<br/>    test_val = summary_df.loc[depth, 'Test RMSE']<br/>    diff = abs(test_val - train_val)<br/>    <br/>    # Draw vertical line<br/>    plt.vlines(x=depth, ymin=min(train_val, test_val), ymax=max(train_val, test_val), <br/>               colors='black', linestyles='-', lw=0.5)<br/>    <br/>    # Add white box behind text<br/>    bbox_props = dict(boxstyle="round,pad=0.1", fc="white", ec="white")<br/>    plt.text(depth - 0.15, (train_val + test_val) / 2, f'{diff:.1f}', <br/>             verticalalignment='center', fontsize=9, fontweight='bold',<br/>             bbox=bbox_props)<br/><br/># Customize plot<br/>plt.xlabel('Max Depth')<br/>plt.ylabel('RMSE')<br/>plt.title('Train vs Test RMSE by Tree Depth')<br/>plt.grid(True, linestyle='--', alpha=0.2)<br/>plt.legend()<br/><br/># Remove spines<br/>ax.spines['top'].set_visible(False)<br/>ax.spines['right'].set_visible(False)<br/><br/># Set limits<br/>plt.xlim(0.8, 5.2)<br/>plt.ylim(0, summary_df['Train RMSE'].max() * 1.1)<br/><br/>plt.tight_layout()<br/>plt.show()</span></pre><p id="a328" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Next, we’ll explore the two main ways models can fail: through consistently inaccurate predictions (bias) or through wildly inconsistent predictions (variance).</p><h1 id="fc43" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">Understanding Bias (When Models Underfit)</h1><h2 id="1b34" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">What is Bias?</h2><p id="5d56" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Bias happens when a model underfits the data by being too simple to capture important patterns. A model with high bias consistently makes large errors because it’s missing key relationships. Think of it as being consistently wrong in a predictable way.</p><p id="6a13" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">When a model underfits, it shows specific behaviors:</p><ul class=""><li id="2509" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qu qv qw bk">Similar sized errors across different predictions</li><li id="08ae" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Training error is high</li><li id="f069" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Test error is also high</li><li id="eb6d" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Training and test errors are close to each other</li></ul><p id="fa74" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">High bias and underfitting are signs that our model needs to be more complex — it needs to pay attention to more patterns in the data. But how do we spot this problem? We look at both training and test errors. If both errors are high and similar to each other, we likely have a bias problem.</p><h2 id="f7cc" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">⛳️ Looking at Our Simple Golf Course Model</h2><p id="61e8" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Let’s examine our simplest model’s performance (depth 1):</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/a60afb362ddeb2e1d3f7d3170c422b45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_D77Apd3c7dFngAJorYpGw.png"/></div></div></figure><ul class=""><li id="d19c" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qu qv qw bk">Training RMSE: 16.13<br/>On average, it’s off by about 16 players even for days it trained on</li><li id="5140" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Test RMSE: 13.26<br/>For new days, it’s off by about 13 players</li></ul><p id="fde0" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">These numbers tell an important story. First, notice how high both errors are. Being off by 13–16 players is a lot when many days see between 20–80 players. Second, while the test error is higher (as we’d expect), both errors are notably large.</p><p id="cbe8" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Looking deeper at what’s happening:</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/4fb3f69c9d775e008d7a9fe5365f1556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zPzOTbdAm6pE_mSxjsOFbg.png"/></div></div></figure><ol class=""><li id="7e1e" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj rh qv qw bk">With depth 1, our model can only make one split decision. It might just split days based on whether it is raining or not, creating only two possible predictions for player counts. This means many different weather conditions get lumped together with the same prediction.</li><li id="e10d" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">The errors follow clear patterns:<br/>- On hot, humid days: The model predicts too many players because it only sees whether it is raining or not<br/>- On cool, perfect days: The model predicts too few players because it ignores great playing conditions</li><li id="8315" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">Most telling is how similar the training and test errors are. Both are high, which means even when predicting days it trained on, the model does poorly. This is the clearest sign of high bias — the model is too simple to even capture the patterns in its training data.</li></ol><p id="521f" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This is the key problem with underfitting: the model lacks the complexity needed to capture important combinations of weather conditions that affect player turnout. Each prediction is wrong in predictable ways because the model simply can’t account for more than one weather factor at a time.</p><p id="fe8a" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">The solution seems obvious: make the model more complex so it can look at multiple weather conditions together. But as we’ll see in the next section, this creates its own problems.</p><h1 id="beb8" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">Understanding Variance (When Models Overfit)</h1><h2 id="5d9d" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">What is Variance?</h2><p id="af19" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Variance occurs when a model overfits by becoming too complex and overly sensitive to small changes in the data. While an underfit model ignores important patterns, an overfit model does the opposite — it treats every tiny detail as if it were an important pattern.</p><p id="44eb" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">A model that’s overfitting shows these behaviors:</p><ul class=""><li id="1459" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qu qv qw bk">Very small errors on training data</li><li id="f1a6" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Much larger errors on test data</li><li id="eb5d" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">A big gap between training and test errors</li><li id="dfcf" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Predictions that change dramatically with small data changes</li></ul><p id="05bd" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This problem is especially dangerous with small datasets. When we only have a few examples to learn from, an overfit model might perfectly memorize all of them without learning the true patterns that matter.</p><h2 id="bc15" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">⛳️ Looking at Our Complex Golf Course Model</h2><p id="6b94" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Let’s examine our most complex model’s performance (depth 5):</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/29cbb043dbe43ddb37a06a163e20d381.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uzouockcENVxzXXuflNuog.png"/></div></div></figure><ul class=""><li id="db96" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qu qv qw bk">Training RMSE: 0.00<br/>Perfect predictions! Not a single error on training data</li><li id="630f" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Test RMSE: 9.14<br/>But on new days, it’s off by about 9–10 players</li></ul><p id="8d04" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">These numbers reveal a classic case of overfitting. The training error of zero means our model learned to predict the exact number of players for every single day it trained on. Sounds great, right? But look at the test error — it’s much higher. This huge gap between training and test performance (from 0 to 9–10 players) is a red flag.</p><p id="8634" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Looking deeper at what’s happening:</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/47825e3568da33adba6f9cacd2f9844d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*csA3MjU4xgio6VHrgTT36w.png"/></div></div></figure><ol class=""><li id="7e89" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj rh qv qw bk">With depth 5, our model creates extremely specific rules. For example:<br/>- If it’s not rainy AND temperature is 76°F AND humidity is 80% AND it’s windy → predict exactly 70 players<br/>Each rule is based on just one or two days from our training data.</li><li id="eba5" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">When the model sees slightly different conditions in the test data, it gets confused.<br/>This is very similar to our first rule above, but the model might predict a completely different number</li><li id="0929" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">With only 14 training examples, each training day gets its own highly specific set of rules. The model isn’t learning general patterns about how weather affects player counts — it’s just memorizing what happened on each specific day.</li></ol><p id="8a80" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">What’s particularly interesting is that while this overfit model does much better than our underfit model (test error 9.15), it’s actually worse than our moderately complex model. This shows how adding too much complexity can start hurting our predictions, even if the training performance looks perfect.</p><p id="e0cd" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This is the fundamental challenge of overfitting: the model becomes so focused on making perfect predictions for the training data that it fails to learn the general patterns that would help it predict new situations well. It’s especially problematic when working with small datasets like ours, where creating a unique rule for each training example leaves us with no way to handle new situations reliably.</p><h1 id="b3c4" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">Finding the Balance</h1><h2 id="e1cc" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">The Core Problem</h2><p id="33b9" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Now we’ve seen both problems — underfitting and overfitting — let’s look at what happens when we try to fix them. This is where the real challenge of the bias-variance trade-off becomes clear.</p><p id="17ca" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Looking at our models’ performance as we made them more complex:</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl rf"><img src="../Images/5ab580aa2868077d0063910ba7fe1884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VB5r7DVKQFubTNNrdUnIHw.png"/></div></div></figure><p id="8eeb" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">These numbers tell an important story. As we made our model more complex:</p><ol class=""><li id="a5c7" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj rh qv qw bk">Training error kept getting better (16.3 → 6.7 → 3.6 → 1.1 → 0.0)</li><li id="080f" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">Test error improved significantly at first (13.3 → 10.1 → 7.3)</li><li id="710f" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">But then test error got slightly worse (7.3 → 8.8 → 9.1)</li></ol><h2 id="e5d2" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">Why This Happens</h2><p id="374d" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">This pattern isn’t a coincidence — it’s the fundamental nature of the bias-variance trade-off.</p><p id="287b" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">When we make a model more complex:</p><ul class=""><li id="610d" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qu qv qw bk">It becomes less likely to underfit the training data (bias decreases)</li><li id="71da" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">But it becomes more likely to overfit to small changes (variance increases)</li></ul><p id="7164" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Our golf course data shows this clearly:</p><ol class=""><li id="eb39" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj rh qv qw bk">The depth 1 model underfit badly — it could only split days into two groups, leading to large errors everywhere</li><li id="c86b" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">Adding complexity helped — depth 2 could consider more weather combinations, and depth 3 found even better patterns</li><li id="c568" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">But depth 4 started to overfit — creating unique rules for nearly every training day</li></ol><p id="30d1" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">The sweet spot came with our depth 3 model:</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/65d6d8150cad95ca942bb23e71884aa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S2cZKl4d3jQKL_YKmwOolQ.png"/></div></div></figure><p id="12c1" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This model is complex enough to avoid underfitting while simple enough to avoid overfitting. It has the best test performance (RMSE 7.13) of all our models.</p><h2 id="0695" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">The Real-World Impact</h2><p id="1555" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">With our golf course predictions, this trade-off has real consequences:</p><ul class=""><li id="7fd0" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qu qv qw bk">Depth 1: Underfits by only looking at temperature, missing crucial information about rain or wind</li><li id="2f10" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Depth 2: Can combine two factors, like temperature AND rain</li><li id="6c95" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Depth 3: Can find patterns like “warm, low humidity, and not rainy means high turnout”</li><li id="04e6" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj qu qv qw bk">Depth 4–5: Overfits with unreliable rules like “exactly 76°F with 80% humidity on a windy day means exactly 70 players”</li></ul><p id="9604" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This is why finding the right balance matters. With just 14 training examples, every decision about model complexity has big impacts. Our depth 3 model isn’t perfect — being off by 7 players on average isn’t ideal. But it’s much better than underfitting with depth 1 (off by 13 players) or overfitting with depth 4 (giving wildly different predictions for very similar weather conditions).</p><h1 id="ba98" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">How to Choose the Right Balance</h1><h2 id="f55a" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">The Basic Approach</h2><p id="7490" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">When picking the best model, looking at training and test errors isn’t enough. Why? Because our test data is limited — with only 14 test examples, we might get lucky or unlucky with how well our model performs on those specific days.</p><p id="81d6" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">A better way to test our models is called <strong class="mq ga">cross-validation</strong>. Instead of using just one split of training and test data, we try different splits. Each time we:</p><ol class=""><li id="8519" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj rh qv qw bk">Pick different samples as training data</li><li id="d2e0" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">Train our model</li><li id="bb62" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">Test on the samples we didn’t use for training</li><li id="c5e2" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk">Record the errors</li></ol><p id="cf22" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">By doing this multiple times, we can understand better how well our model really works.</p><h2 id="f51f" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">⛳️ What We Found With Our Golf Course Data</h2><p id="7d51" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Let’s look at how our different models performed across multiple training splits using cross-validation. Given our small dataset of just 14 training examples, we used K-fold cross-validation with k=7, meaning each validation fold had 2 samples.</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/e385c08896e206e43fcd8e9de12d97f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5avex0gB_o8yW8xduCcrPg.png"/></div></div></figure><p id="52f4" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">While this is a small validation size, it allows us to maximize our training data while still getting meaningful cross-validation estimates:</p><pre class="nn no np nq nr pv pw px bp py bb bk"><span id="07ee" class="pz oe fq pw b bg qa qb l qc qd">from sklearn.model_selection import KFold<br/><br/>def evaluate_model(X_train, y_train, X_test, y_test, n_splits=7, random_state=42):<br/>   kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)<br/>   depths = range(1, 6)<br/>   results = []<br/>   <br/>   for depth in depths:<br/>       # Cross-validation scores<br/>       cv_scores = []<br/>       for train_idx, val_idx in kf.split(X_train):<br/>           # Split data<br/>           X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]<br/>           y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]<br/>           <br/>           # Train and evaluate<br/>           model = DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_STATE)<br/>           model.fit(X_tr, y_tr)<br/>           val_pred = model.predict(X_val)<br/>           cv_scores.append(np.sqrt(mean_squared_error(y_val, val_pred)))<br/>       <br/>       # Test set performance<br/>       model = DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_STATE)<br/>       model.fit(X_train, y_train)<br/>       test_pred = model.predict(X_test)<br/>       test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))<br/>       <br/>       # Store results<br/>       results.append({<br/>           'CV Mean RMSE': np.mean(cv_scores),<br/>           'CV Std': np.std(cv_scores),<br/>           'Test RMSE': test_rmse<br/>       })<br/>   <br/>   return pd.DataFrame(results, index=pd.Index(depths, name='Depth')).round(2)<br/><br/># Usage:<br/>cv_df = evaluate_model(X_train, y_train, X_test, y_test)<br/>print(cv_df)</span></pre><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl ri"><img src="../Images/457b97b29c2a97b2dbc1c62c05b5f659.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ulSoLSWs08VDlZkP_C4JEA.png"/></div></div></figure><p id="3c5d" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Simple Model (depth 1):<br/>- CV Mean RMSE: 20.28 (±12.90)<br/>- Shows high variation in cross-validation (±12.90)<br/>- Consistently poor performance across different data splits</p><p id="3bc1" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Slightly Flexible Model (depth 2):<br/>- CV Mean RMSE: 17.35 (±11.00)<br/>- Lower average error than depth 1<br/>- Still shows considerable variation in cross-validation<br/>- Some improvement in predictive power</p><p id="603e" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Moderate Complexity Model (depth 3):<br/>- CV Mean RMSE: 16.16 (±9.26)<br/>- More stable cross-validation performance<br/>- Shows good improvement over simpler models<br/>- Best balance of stability and accuracy</p><p id="3f75" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Complex Model (depth 4):<br/>- CV Mean RMSE: 16.10 (±12.33)<br/>- Very similar mean to depth 3<br/>- Larger variation in CV suggests less stable predictions<br/>- Starting to show signs of overfitting</p><p id="41c8" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Very Complex Model (depth 5):<br/>- CV Mean RMSE: 16.59 (±11.73)<br/>- CV performance starts to worsen<br/>- High variation continues<br/>- Clear sign of overfitting beginning to occur</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl rj"><img src="../Images/853f4e7f0dd7ac08f000f411fc7c5d4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oD2Q9ktfEth2oYER3aAQoA.png"/></div></div></figure><p id="6819" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">This cross-validation shows us something important: while our depth 3 model achieved the best test performance in our earlier analysis, the cross-validation results reveal that model performance can vary significantly. The high standard deviations (ranging from ±9.26 to ±12.90 players) across all models show that with such a small dataset, any single split of the data might give us misleading results. This is why cross-validation is so important — it helps us see the true performance of our models beyond just one lucky or unlucky split.</p><h2 id="8ae8" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">How to Make This Decision in Practice</h2><p id="5067" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Based on our results, here’s how we can find the right model balance:</p><ol class=""><li id="94d6" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj rh qv qw bk"><strong class="mq ga">Start Simple</strong><br/>Start with the most basic model you can build. Check how well it works on both your training data and test data. If it performs poorly on both, that’s okay! It just means your model needs to be a bit more complex to capture the important patterns.</li><li id="20c9" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk"><strong class="mq ga">Gradually Add Complexity</strong><br/>Now slowly make your model more sophisticated, one step at a time. Watch how the performance changes with each adjustment. When you see it starting to do worse on new data, that’s your signal to stop — you’ve found the right balance of complexity.</li><li id="6687" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk"><strong class="mq ga">Watch for Warning Signs</strong><br/>Keep an eye out for problems: If your model does extremely well on training data but poorly on new data, it’s too complex. If it does badly on all data, it’s too simple. If its performance changes a lot between different data splits, you’ve probably made it too complex.</li><li id="3095" class="mo mp fq mq b gt qx ms mt gw qy mv mw mx qz mz na nb ra nd ne nf rb nh ni nj rh qv qw bk"><strong class="mq ga">Consider Your Data Size</strong><br/>When you don’t have much data (like our 14 examples), keep your model simple. You can’t expect a model to make perfect predictions with very few examples to learn from. With small datasets, it’s better to have a simple model that works consistently than a complex one that’s unreliable.</li></ol><p id="a05a" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">Whenever we make prediction model, our goal isn’t to get perfect predictions — it’s to get reliable, useful predictions that will work well on new data. With our golf course dataset, being off by 6–7 players on average isn’t perfect, but it’s much better than being off by 11–12 players (too simple) or having wildly unreliable predictions (too complex).</p><h1 id="ae14" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">Key Takeaways</h1><h2 id="edd7" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">Quick Ways to Spot Problems</h2><p id="673e" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Let’s wrap up what we’ve learned about building prediction models that actually work. Here are the key signs that tell you if your model is underfitting or overfitting:</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/ed6d8ea301f30aa4d80257ec7e1326fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AnT6rPj88VwJNJMhZYjoqw.png"/></div></div></figure><p id="c5a3" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk"><strong class="mq ga">Signs of Underfitting (Too Simple):</strong> <br/>When a model underfits, the training error will be high (like our depth 1 model’s 16.13 RMSE). Similarly, the test error will be high (13.26 RMSE). The gap between these errors is small (16.13 vs 13.26), which tells us that the model is always performing poorly. This kind of model is too simple to capture existing real relationships.</p><p id="96ef" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk"><strong class="mq ga">Signs of Overfitting (Too Complex): </strong><br/>An overfit model shows a very different pattern. You’ll see very low training error (like our depth 5 model’s 0.00 RMSE) but much higher test error (9.15 RMSE). This large gap between training and test performance (0.00 vs 9.15) is a sign that the model is easily distracted by noise in the training data and it is just memorizing the specific examples it was trained on.</p><p id="448a" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk"><strong class="mq ga">Signs of a Good Balance (Like our depth 3 model): </strong><br/>A well-balanced model shows more promising characteristics. The training error is reasonably low (3.16 RMSE) and while the test error is higher (7.33 RMSE), it’s our best overall performance. The gap between training and test error exists but isn’t extreme (3.16 vs 7.33). This tells us the model has found the sweet spot: it’s complex enough to capture real patterns in the data while being simple enough to avoid getting distracted by noise. This balance between underfitting and overfitting is exactly what we’re looking for in a reliable model.</p><h1 id="30e5" class="od oe fq bf of og oh gv oi oj ok gy ol om on oo op oq or os ot ou ov ow ox oy bk">Final Remarks</h1><p id="2803" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">The bias-variance trade-off isn’t just theory. It has real impacts on real predictions including in our golf course example before. The goal here isn’t to eliminate either underfitting or overfitting completely, because that’s impossible. What we want is to find the sweet spot where your model is complex enough to avoid underfitting and catch real patterns while being simple enough to avoid overfitting to random noise.</p><p id="7a1e" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">At the end, a model that’s consistently off by a little is often more useful than one that overfits — occasionally perfect but usually way off.</p><blockquote class="qe"><p id="be57" class="qf qg fq bf qh qi qj qk ql qm qn nj dx">In the real world, reliability matters more than perfection.</p></blockquote></div></div></div><div class="ab cb rk rl rm rn" role="separator"><span class="ro by bm rp rq rr"/><span class="ro by bm rp rq rr"/><span class="ro by bm rp rq"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="4d80" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">Technical Environment</h2><p id="8026" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">This article uses Python 3.7 and scikit-learn 1.6. While the concepts discussed are generally applicable, specific code implementations may vary slightly with different versions.</p><h2 id="d217" class="pf oe fq bf of pg ph pi oi pj pk pl ol mx pm pn po nb pp pq pr nf ps pt pu fw bk">About the Illustrations</h2><p id="a516" class="pw-post-body-paragraph mo mp fq mq b gt oz ms mt gw pa mv mw mx pb mz na nb pc nd ne nf pd nh ni nj fj bk">Unless otherwise noted, all images are created by the author, incorporating licensed design elements from Canva Pro.</p><p id="6ac5" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝙈𝙤𝙙𝙚𝙡 𝙀𝙫𝙖𝙡𝙪𝙖𝙩𝙞𝙤𝙣 &amp; 𝙊𝙥𝙩𝙞𝙢𝙞𝙯𝙖𝙩𝙞𝙤𝙣 𝙝𝙚𝙧𝙚:</p><div class="rs rt ru rv rw"><div role="button" tabindex="0" class="ab bx cp kj it rx ry bp rz lw ao"><div class="sa l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by sb sc cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l sb sc em n ay un"/></div><div class="sd l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----9521871f728a--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq sg hp l"><h2 class="bf ga xl ic it xm iv iw xn iy ja fz bk">Model Evaluation &amp; Optimization</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk xo wn wo wp wq lj wr ws uy ii wt wu wv vc vd ve ep bm vf nz" href="https://medium.com/@samybaladram/list/model-evaluation-optimization-331287896864?source=post_page-----9521871f728a--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xp l il"><span class="bf b dy z dx">3 stories</span></div></div></div><div class="sp dz sq it ab sr il ed"><div class="ed sj bx sk sl"><div class="dz l"><img alt="" class="dz" src="../Images/18fa82b1435fa7d5571ee54ae93a6c62.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*7iilm-b4uavyJU4RGTwmXA.png"/></div></div><div class="ed sj bx kk sm sn"><div class="dz l"><img alt="" class="dz" src="../Images/c95e89d05d1de700c631c342cd008de0.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*IouZGTjmruanqsZ2o_--JQ.png"/></div></div><div class="ed bx hx so sn"><div class="dz l"><img alt="" class="dz" src="../Images/30e20e1a8ba3ced1e77644b706acd18d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*XQDe622Tw9GCKJ8N4b0QeQ.png"/></div></div></div></div></div><p id="2999" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:</p><div class="rs rt ru rv rw"><div role="button" tabindex="0" class="ab bx cp kj it rx ry bp rz lw ao"><div class="sa l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by sb sc cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l sb sc em n ay un"/></div><div class="sd l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----9521871f728a--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq sg hp l"><h2 class="bf ga xl ic it xm iv iw xn iy ja fz bk">Classification Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk xo wn wo wp wq lj wr ws uy ii wt wu wv vc vd ve ep bm vf nz" href="https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----9521871f728a--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xp l il"><span class="bf b dy z dx">8 stories</span></div></div></div><div class="sp dz sq it ab sr il ed"><div class="ed sj bx sk sl"><div class="dz l"><img alt="" class="dz" src="../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*eVxxKT4DKvRVuAHBGknJ7w.png"/></div></div><div class="ed sj bx kk sm sn"><div class="dz l"><img alt="" class="dz" src="../Images/6ea70d9d2d9456e0c221388dbb253be8.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uFvDKl3iA2_G961vw5QFpg.png"/></div></div><div class="ed bx hx so sn"><div class="dz l"><img alt="" class="dz" src="../Images/7221f0777228e7bcf08c1adb44a8eb76.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*1TbEIdTs_Z8V_TPD9MXxJw.png"/></div></div></div></div></div></div></div></div></div>    
</body>
</html>