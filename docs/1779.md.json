["```py\n# This text splitter is used to create the parent documents\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n# This text splitter is used to create the child documents\n# It should create documents smaller than the parent\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(\n    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n)\n# The storage layer for the parent documents\nstore = InMemoryStore()\nretriever = ParentDocumentRetriever(\n    vectorstore=vectorstore,\n    docstore=store,\n    child_splitter=child_splitter,\n    parent_splitter=parent_splitter,\n)\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```", "```py\n{document_id: \"example.pdf\", sequence_number: 20}\n```", "```py\nchromadb==0.4.24\nlangchain==0.2.8\npymilvus==2.4.4\nlangchain-community==0.2.7\nlangchain-milvus==0.1.2\n```", "```py\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain_core.documents import Document\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\ndocument_id = \"example.pdf\"\n\ndef preprocess_file(file_path: str) -> list[Document]:\n    \"\"\"Load pdf file, chunk and build appropriate metadata\"\"\"\n    loader = PyPDFLoader(file_path=file_path)\n    pdf_docs = loader.load()\n\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=0,\n    )\n\n    docs = text_splitter.split_documents(documents=pdf_docs)\n    chunks_metadata = [\n        {\"document_id\": file_path, \"sequence_number\": i} for i, _ in enumerate(docs)\n    ]\n    for chunk, metadata in zip(docs, chunks_metadata):\n        chunk.metadata = metadata\n\n    return docs\n```", "```py\nfrom langchain_community.vectorstores import Milvus, Chroma\nfrom langchain_community.embeddings import DeterministicFakeEmbedding\n\nembedding = DeterministicFakeEmbedding(size=384) # Just for the demo :)\n\ndef parent_document_retrieval(\n    query: str, client: Milvus | Chroma, window_size: int = 4\n):\n    top_1 = client.similarity_search(query=query, k=1)[0]\n    doc_id = top_1.metadata[\"document_id\"]\n    seq_num = top_1.metadata[\"sequence_number\"]\n    ids_window = [seq_num + i for i in range(-window_size, window_size, 1)]\n    # ...\n```", "```py\n if isinstance(client, Milvus):\n        expr = f\"document_id LIKE '{doc_id}' && sequence_number in {ids_window}\"\n        res = client.col.query(\n            expr=expr, output_fields=[\"sequence_number\", \"text\"], limit=len(ids_window)\n        )  # This is Milvus specific\n        docs_to_return = [\n            Document(\n                page_content=d[\"text\"],\n                metadata={\n                    \"sequence_number\": d[\"sequence_number\"],\n                    \"document_id\": doc_id,\n                },\n            )\n            for d in res\n        ]\n    # ...\n```", "```py\n elif isinstance(client, Chroma):\n        expr = {\n            \"$and\": [\n                {\"document_id\": {\"$eq\": doc_id}},\n                {\"sequence_number\": {\"$gte\": ids_window[0]}},\n                {\"sequence_number\": {\"$lte\": ids_window[-1]}},\n            ]\n        }\n        res = client.get(where=expr)  # This is Chroma specific\n        texts, metadatas = res[\"documents\"], res[\"metadatas\"]\n        docs_to_return = [\n            Document(\n                page_content=t,\n                metadata={\n                    \"sequence_number\": m[\"sequence_number\"],\n                    \"document_id\": doc_id,\n                },\n            )\n            for t, m in zip(texts, metadatas)\n        ]\n```", "```py\n docs_to_return.sort(key=lambda x: x.metadata[\"sequence_number\"])\n    return docs_to_return\n```"]