["```py\nfrom sagemaker.pytorch import PyTorch\n\n# define job\nestimator = PyTorch(\n    role='<sagemaker role>',\n    entry_point='train.py',\n    instance_type='ml.p5.48xlarge',\n    instance_count=1,\n    framework_version='2.0.1',\n    py_version='py310',\n    tags=[{'Key': 'priority', 'Value': '100'}\n)\n\n# start job\nestimator.fit()\n```", "```py\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n  InternalAPI:\n    Type: AWS::Serverless::Api\n      # Auth: # Add access control to API\n      EndpointConfiguration:\n        Type: PRIVATE\n        # VPCEndpointIds: # Specify VPC Endpoint(s)\n      Name: training-job-queue\n      StageName: prod\n```", "```py\n DynamoSMQueue:\n    Type: AWS::Serverless::SimpleTable\n    Properties:\n      PrimaryKey:\n        Name: jobName\n        Type: String\n      TableName: sagemaker-queue\n```", "```py\nimport json, boto3, datetime\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('sagemaker-queue')\n\ndef add_job_entry(job_json):\n    job_details = json.loads(job_json)\n\n    # extract job_name\n    job_name = job_details['TrainingJobName']\n    print(f'add entry {job_name}')\n\n    # get current time\n    entry_time = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n\n    # default priority is 0\n    priority = 0\n\n    # update priority based on tags\n    tags = job_details['Tags']\n    for tag in tags:\n        if tag['Key'] == 'priority':\n            priority = int(tag['Value'])\n            break\n\n    # create entry\n    entry = {\n       'jobName': job_name,\n       'entryTime': entry_time,\n       'jobState': 'pending',\n       'priority': priority,\n       'jobDetails': job_json\n    }\n    table.put_item(Item=entry) #TODO handle errors\n    print(f'Added job {job_name} to queue')\n```", "```py\nfrom boto3.dynamodb.conditions import Attr\n\n# Get a list of all pending jobs sorted by priority\ndef get_pending_jobs():\n    response = table.scan(\n        ProjectionExpression='jobName, priority, entryTime',\n        FilterExpression=Attr('jobState').ne('running')\n    )\n    jobs = response.get('Items', [])\n\n    # sort jobs, first by priority (descending) and then by entryTime\n    sorted_jobs = sorted(jobs,\n                         key=lambda x: (-x['priority'], x['entryTime']))\n\n    return sorted_jobs\n```", "```py\n# Get a jobName -> priority mapping of all running jobs\ndef get_running_jobs_dict():\n    # Get all running jobs\n    response = table.scan(\n        ProjectionExpression=\"jobName, priority\",\n        FilterExpression=Attr('jobState').eq('running')\n    )\n    jobs = response.get('Items', [])\n\n    running_jobs = {job['jobName']: job['priority'] for job in jobs}\n\n    return running_jobs\n\n# Print the queue state\ndef print_queue_state():\n    response = table.scan(\n        ProjectionExpression='jobName, jobState, priority'\n    )\n    jobs = response.get('Items', [])\n\n    print_table = []\n    for job in jobs:\n        print_table.append([job['jobName'], job['jobState'], job['priority']])\n\n    # sort by priority\n    sorted_table = sorted(print_table,\n                         key=lambda x: -x[2])\n    # Print the table\n    from tabulate import tabulate\n    print(tabulate(sorted_table, headers=['Job Name', 'State', 'Priority']))\n\n# get job details\ndef get_job_details(job_name):\n    response = table.get_item(\n        Key={'jobName': job_name},\n        ProjectionExpression='jobDetails'\n    )\n    return json.loads(response.get('Item').get('jobDetails'))\n\n# get job state or None if the job does not exist\ndef get_job_state(job_name):\n    response = table.get_item(\n        Key={'jobName': job_name},\n        ProjectionExpression='jobState'\n    )\n    job = response.get('Item')\n    return job.get('jobState') if job else None\n\n# update the job state\ndef update_job_state(job_name, new_state):\n    table.update_item(\n        Key={'jobName': job_name},\n        UpdateExpression=\"SET jobState = :new_state\",\n        ExpressionAttributeValues={\":new_state\": new_state}\n    )\n    print(f'Update job {job_name} to {new_state}')\n\n# remove a job entry\ndef remove_job(job_name):\n    table.delete_item(\n        Key={'jobName': job_name}\n    )\n    print(f'Removed job {job_name} from queue')\n```", "```py\n# set the limit on total number of instances/jobs\nMAX_CAPACITY = 2\n\nsagemaker = boto3.client('sagemaker')\n\n# apply a queue stamp to identify that the job came from the queue\ndef apply_qstamp(job_name):\n    return f'{job_name}-qstamp-{datetime.now().strftime(\"%d%H%M\")}'\n\n# strip the queue stamp\ndef strip_qstamp(job_name):\n    return job_name.split('-qstamp-')[0]\n\n# start a SageMaker job and update job entry in queue\ndef start_job(job_name):\n    print(f'start job {job_name}')\n    job_details = get_job_details(job_name)\n    job_details['TrainingJobName'] = apply_qstamp(job_name)\n    if(job_details):\n        # start job with detail from queue\n        # (you may optinally overwrite fields such as the iam role)\n        response = sagemaker.create_training_job(**job_details)\n        if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n            print(f'started job {job_name}')\n            update_job_state(job_name, 'running')\n\n# preempt a SageMaker job and update job entry in queue\ndef preempt_job(job_name):\n    print(f'preempt job {job_name}')\n    response = sagemaker.stop_training_job(TrainingJobName=job_name)\n    if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n        print(f'preempted job {job_name}')\n        update_job_state(strip_qstamp(job_name), 'preempted')\n\n# get SageMaker jobs\ndef get_sagemaker_jobs(status):\n    running = sagemaker.list_training_jobs(StatusEquals=status)\n    return running.get('TrainingJobSummaries', [])\n\n# queue manager\ndef manage_queue():\n    # extract pending jobs to run\n    pending = get_pending_jobs()\n\n    if not pending:\n        return\n\n    if len(pending) > MAX_CAPACITY:\n        pending = pending[:MAX_CAPACITY]\n\n    # get running sagemaker jobs\n    running = get_sagemaker_jobs('InProgress')\n    total_running = len(running)\n\n    # get stopping sagemaker jobs\n    stopping = get_sagemaker_jobs('Stopping')\n    total_stopping = len(stopping)\n\n    # calculate the number of free instances    \n    free_slots = MAX_CAPACITY - total_running - total_stopping\n\n    jobs_to_start = min(len(pending), free_slots)\n\n    # for each free instance, start a job\n    for i in range(jobs_to_start):\n        start_job(pending[i].get('jobName'))\n\n    still_pending = pending[jobs_to_start:]\n\n    if not still_pending:\n        return\n\n    # assume that 'total_stopping' number of jobs will start soon\n    test_for_preemption = len(still_pending) - total_stopping\n    if test_for_preemption <= 0:\n        return\n\n    # check if preemption is required\n    test_priority = still_pending[total_stopping:]\n\n    running_jobs = get_running_jobs_dict()\n    priority_dict = {}\n    for job in running:\n        job_name = job['TrainingJobName']\n        priority_dict[job_name] = running_jobs[strip_qstamp(job_name)]\n\n    # sort running jobs from lowest to highest priority\n    sorted_running = sorted(priority_dict.items(), key=lambda item: item[1])\n\n    index = 0\n    while index < test_for_preemption and \\\n          test_priority[index].get('priority') > sorted_running[index][1]:\n        preempt_job(sorted_running[index][0])\n        index = index + 1\n```", "```py\n ManagedTrainingJobQueue:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: job-queue/ # the directory containing our index.py file\n      Handler: index.lambda_handler\n      Runtime: python3.12\n      Architectures:\n        - arm64 # use graviton\n      Policies: # allow access to SageMaker and DynamoDB\n        - !Sub \"arn:${AWS::Partition}:iam::aws:policy/AmazonSageMakerFullAccess\"\n        - DynamoDBCrudPolicy:\n            TableName: !Ref DynamoSMQueue\n      Events:\n        CreateTraining:\n          Type: Api\n          Properties:\n            Path: /add-job\n            Method: post\n            RestApiId: !Ref InternalAPI\n        SageMakerEvent:\n          Type: EventBridgeRule\n          Properties:\n            Pattern:\n              source:\n                - aws.sagemaker\n              detail-type:\n                - SageMaker Training Job State Change\n              detail:\n                TrainingJobStatus:\n                  - \"Completed\"\n                  - \"Failed\"\n                  - \"Stopped\"\n```", "```py\ndef lambda_handler(event, context):\n    # identify source of event and take appropriate action\n    if 'requestContext' in event and 'apiId' in event['requestContext']:\n        print('Lambda triggerred by API Gateway')\n        job_details = json.loads(event.get('body'))\n        add_job_entry(job_details)\n    elif 'source' in event and event['source'] == 'aws.sagemaker':\n        print('Lambda triggerred by SageMaker job state change')\n        job_name = event['detail']['TrainingJobName']\n        job_status = event['detail']['TrainingJobStatus']\n        print(f'{job_name} status changed to {job_status}')\n\n        # strip qstamp from job_name\n        job_name = strip_qstamp(job_name)\n\n        if job_status in ['Completed' , 'Failed']:\n            remove_job(job_name)\n        elif job_status == 'Stopped':\n            # check if it was manually stopped or preempted by queue manager\n            if get_job_state(job_name) == 'preempted':\n                print(f'job {job_name} preemption completed')\n            else:\n                print(f'job {job_name} {job_status}, remove from queue')\n                remove_job(job_name)\n\n    # in all cases invoke queue manager\n    manage_queue()\n```", "```py\nfrom sagemaker.pytorch import PyTorch\nfrom sagemaker.session import Session\nimport requests, logging\nlogger = logging.getLogger('sagemaker')\n\ndef submit_to_training_queue(job):\n    logger.info(f'Adding training-job {job['TrainingJobName']} to queue')\n    logger.debug('train request: {json.dumps(job, indent=4)}')\n\n    vpce='<vpc endpoint>' # insert id of vpc endpoint\n    region='us-east-1' # specify region\n    url=f'https://{vpce}.execute-api.{region}.vpce.amazonaws.com/prod/add-job'\n    headers = {'x-apigw-api-id': '<api-id>'} # insert api gateway id\n\n    # submit job\n    response = requests.post(url, headers=headers, json=job)\n\nclass QueueTrainingJobSession(Session):\n    def _intercept_create_request(self, request, create, func_name = None):\n        \"\"\"This function intercepts the create job request\n\n        Args:\n          request (dict): the create job request\n          create (functor): a functor calls the sagemaker client create method\n          func_name (str): the name of the function needed intercepting\n        \"\"\"\n        if func_name == 'train':\n            submit_to_training_queue(request)\n        else:\n            super()._intercept_create_request(request,create,func_name)\n\n# define job\nestimator = PyTorch(\n    role='<sagemaker role>',\n    entry_point='train.py',\n    instance_type='ml.p5.48xlarge',\n    instance_count=1,\n    framework_version='2.0.1',\n    py_version='py310',\n    tags=[{'Key': 'priority', 'Value': '100'},\n    keep_alive_period_in_seconds=60, # keep warm for 1 minute\n    # use our custom Session class\n    sagemaker_session=QueueTrainingJobSession()\n)\n\nestimator.fit(wait=False)\n```", "```py\nJob Name    State      Priority\n----------  -------  ----------\njob2        running           2\njob1        running           1\njob3        pending           1\n```", "```py\nJob Name    State        Priority\n----------  ---------  ----------\njob4        running             3\njob2        running             2\njob1        preempted           1\njob3        pending             1\n```", "```py\nJob Name    State      Priority\n----------  -------  ----------\njob4        running           3\njob1        running           1\njob3        pending           1\n```"]