- en: Metrics to Evaluate a Classification Machine Learning Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估分类机器学习模型的指标
- en: 原文：[https://towardsdatascience.com/metrics-to-evaluate-a-classification-machine-learning-model-f05f1facd569?source=collection_archive---------7-----------------------#2024-07-31](https://towardsdatascience.com/metrics-to-evaluate-a-classification-machine-learning-model-f05f1facd569?source=collection_archive---------7-----------------------#2024-07-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/metrics-to-evaluate-a-classification-machine-learning-model-f05f1facd569?source=collection_archive---------7-----------------------#2024-07-31](https://towardsdatascience.com/metrics-to-evaluate-a-classification-machine-learning-model-f05f1facd569?source=collection_archive---------7-----------------------#2024-07-31)
- en: '*A study case of credit card fraud*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*信用卡欺诈的案例研究*'
- en: '[](https://medium.com/@lucasbraga461?source=post_page---byline--f05f1facd569--------------------------------)[![Lucas
    Braga](../Images/a652476cfec8d4f129d2d47a64c3e8c3.png)](https://medium.com/@lucasbraga461?source=post_page---byline--f05f1facd569--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f05f1facd569--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f05f1facd569--------------------------------)
    [Lucas Braga](https://medium.com/@lucasbraga461?source=post_page---byline--f05f1facd569--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@lucasbraga461?source=post_page---byline--f05f1facd569--------------------------------)[![Lucas
    Braga](../Images/a652476cfec8d4f129d2d47a64c3e8c3.png)](https://medium.com/@lucasbraga461?source=post_page---byline--f05f1facd569--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f05f1facd569--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f05f1facd569--------------------------------)
    [Lucas Braga](https://medium.com/@lucasbraga461?source=post_page---byline--f05f1facd569--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f05f1facd569--------------------------------)
    ·7 min read·Jul 31, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f05f1facd569--------------------------------)
    ·7分钟阅读·2024年7月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**1\. Introduction**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 引言**'
- en: 'Once we trained a supervised machine learning model to solve a classification
    problem, we’d be happy if this was the end of our work, and we could just throw
    them new data. We hope it will classify everything correctly. However, in reality,
    not all predictions that a model makes are correct. There is a famous quote well
    known in Data Science, created by a British Statistician that says:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们训练了一个监督式机器学习模型来解决分类问题，我们会希望如果这就是我们的工作结束，我们可以直接丢给它新的数据。我们希望它能正确地对所有数据进行分类。然而，实际上，模型做出的并非所有预测都是正确的。在数据科学中有一句名言，由英国统计学家提出：“
- en: “All models are wrong; some are useful.” CLEAR, James, 1976.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “所有模型都是错误的；有些模型是有用的。”——CLEAR, James, 1976
- en: So, how do we know how good the model we have is? The short answer is that we
    do that by evaluating how correct the model’s predictions are. For that, there
    are several metrics that we could use.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何知道我们所拥有的模型有多好呢？简短的回答是，我们通过评估模型预测的准确性来判断。为此，我们可以使用多种指标。
- en: '**2\. How does a model make predictions? i.e., How does a model classify data?**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 模型是如何进行预测的？即，模型是如何对数据进行分类的？**'
- en: '![](../Images/d4a1e2df439a5ffc27a6d116314a8674.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4a1e2df439a5ffc27a6d116314a8674.png)'
- en: 'Image 1: Model making prediction'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图片1：模型进行预测
- en: Let’s say we’ve trained a Machine Learning model to classify a credit card transaction
    and decide whether that particular transaction is Fraud or not Fraud. The model
    will consume the transaction data and give back a score that could be any number
    within the range of 0 to 1, e.g., 0.05, 0.24, 0.56, 0.9875\. For this article,
    we’ll define a default threshold of 0.5, which means if the model gave a score
    lower than 0.5, then the model has classified that transaction as not Fraud (**that’s
    a model prediction**!). If the model gave a score greater or equal to 0.5, then
    the model classified that transaction as Fraud (that’s also a model prediction!).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经训练了一个机器学习模型，用来对信用卡交易进行分类，并决定该交易是否为欺诈交易。该模型将处理交易数据，并返回一个分数，这个分数可能是0到1之间的任意数字，例如：0.05、0.24、0.56、0.9875。对于本文，我们将默认阈值设为0.5，这意味着如果模型给出的分数低于0.5，则模型将该交易分类为非欺诈（**这是模型的预测**！）。如果模型给出的分数大于或等于0.5，则模型将该交易分类为欺诈（这也是模型的预测！）。
- en: In practice, we don’t work with the default of 0.5\. We look into different
    thresholds to see what is more appropriate to optimize the model’s performance,
    but that discussion is for another day.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 实际操作中，我们并不会使用默认的0.5阈值。我们会尝试不同的阈值，以找出最适合优化模型性能的值，但这个讨论留到以后再进行。
- en: '**3\. Confusion Matrix**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 混淆矩阵**'
- en: 'The confusion matrix is a fundamental tool for visualizing the performance
    of a classification model. It helps in understanding the various outcomes of the
    predictions, which include:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是可视化分类模型性能的基本工具。它有助于理解预测的各种结果，包括：
- en: '**True Positive (TP)**'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正阳性 (TP)**'
- en: '**False Positive (FP)**'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性 (FP)**'
- en: '**False Negative (FN)**'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性 (FN)**'
- en: '**True Negative (TN)**'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正阴性 (TN)**'
- en: Let’s break it down!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解一下！
- en: To evaluate a model’s effectiveness, we need to compare its predictions against
    actual outcomes. Actual outcomes are also known as “the reality.” So, a model
    could have classified a transaction as Fraud, and in fact, the customer asked
    for his money back on that same transaction, claiming that his credit card was
    stolen.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估一个模型的有效性，我们需要将其预测与实际结果进行比较。实际结果也被称为“现实”。因此，模型可能将一笔交易分类为欺诈，而实际上，客户在同一笔交易中要求退款，声称他的信用卡被盗。
- en: In that scenario, the model correctly predicted the transaction as Fraud, a
    **True Positive (TP)**.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型正确地将交易预测为欺诈，属于**真正阳性 (TP)**。
- en: In Fraud detection contexts, the “positive” class is labeled as Fraud, and the
    “negative” class is labeled Non-Fraud.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在欺诈检测的背景下，“阳性”类被标记为欺诈，而“阴性”类被标记为非欺诈。
- en: A **False Positive (FP)**, on the other hand, occurs when the model also classifies
    a transaction as Fraud, but in that case, the customer did not report any fraudulent
    activity on their credit card usage. So, in this transaction, the Machine Learning
    model made a mistake.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**假阳性 (FP)** 发生在模型也将一笔交易分类为欺诈，但在这种情况下，客户并未报告其信用卡有任何欺诈活动。因此，在这笔交易中，机器学习模型犯了一个错误。
- en: A **True Negative (TN)** is when the model classified the transaction as Not
    Fraud, and in fact, it was not Fraud. So, the model has made the correct classification.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**真正阴性 (TN)** 是当模型将交易分类为非欺诈，而实际上它确实不是欺诈。因此，模型做出了正确的分类。'
- en: A **False Negative (FN)** was when the model classified the transaction as Not
    Fraud. Still, it was Fraud (the customer reported fraudulent activity on their
    credit card related to that transaction). In this case, the Machine Learning model
    also made a mistake, but it’s a different type of error than a False Positive.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阴性 (FN)** 是当模型将交易分类为非欺诈时，但实际上它是欺诈（客户报告了与该交易相关的信用卡欺诈活动）。在这种情况下，机器学习模型也犯了一个错误，但这是与假阳性不同类型的错误。'
- en: Let’s have a look at image 2
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下图 2
- en: '![](../Images/2c4a16c6c43ec99bb1ad30bfb9b2644a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c4a16c6c43ec99bb1ad30bfb9b2644a.png)'
- en: 'Image 2: Confusion Matrix classifying a Machine Learning Model for Fraud'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：为欺诈分类的机器学习模型的混淆矩阵
- en: Let’s see a different case, maybe more relatable. A test was designed to tell
    whether a patient has COVID. See image 3.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个不同的案例，可能更容易理解。设计了一项测试来判断病人是否感染了 COVID。见图 3。
- en: '![](../Images/437092ea96fac940202c77c8082f29e7.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/437092ea96fac940202c77c8082f29e7.png)'
- en: 'Image 3: Confusion Matrix for a COVID test'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：COVID 测试的混淆矩阵
- en: So, for every transaction, you could check whether it’s TP, FP, TN, or FN. And
    you could do this for thousands of millions of transactions and write the results
    down on a 2x2 table with all the counts of TP, FP, TN and FN. This table is also
    known as a **Confusion Matrix**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于每一笔交易，你可以检查它是 TP、FP、TN 还是 FN。你可以对数百万笔交易进行这种检查，并将 TP、FP、TN 和 FN 的计数写在一个
    2x2 的表格中。这个表格也被称为**混淆矩阵**。
- en: Let’s say you compared the model predictions of 100,000 transactions against
    their actual outcomes and came up with the following Confusion Matrix (see image
    4).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你将模型对 100,000 笔交易的预测与其实际结果进行了比较，并得出了以下混淆矩阵（见图 4）。
- en: '![](../Images/4edc6fa1e484c3ab5934edb51059843b.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4edc6fa1e484c3ab5934edb51059843b.png)'
- en: 'Image 4: Confusion Matrix'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：混淆矩阵
- en: '**4\. Metrics to Evaluate Model Performance**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 评估模型性能的指标**'
- en: and what a confusion matrix is, we are ready to explore the metrics used to
    evaluate a classification model’s performance.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 了解混淆矩阵后，我们就可以开始探索用于评估分类模型性能的指标。
- en: '**Precision = TP / (TP + FP)**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度 = TP / (TP + FP)**'
- en: 'It answers the question: What’s the proportion of correct predictions among
    all predictions? It reflects the proportion of predicted fraud cases that were
    Fraud.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 它回答了这个问题：在所有预测中，正确预测的比例是多少？它反映了模型预测的欺诈案例中实际为欺诈的比例。
- en: 'In simple language: What’s the proportion of when the model called it Fraud,
    and it was Fraud?'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 用简单的话来说：模型将其判定为欺诈时，实际是欺诈的比例是多少？
- en: Looking at the Confusion Matrix from image 4, we compute the Precision = 76.09%
    since Precision = 350 / (350 + 110).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 查看图像4中的混淆矩阵，我们计算精确度 = 76.09%，因为精确度 = 350 / (350 + 110)。
- en: '**Recall = TP / (TP + FN)**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率 = TP / (TP + FN)**'
- en: 'Recall is also known as True Positive Rate (TPR). It answers the question:
    What’s the proportion of correct predictions among all positive actual outcomes?'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率也称为真正率（TPR）。它回答了这个问题：在所有实际的正类结果中，正确预测的比例是多少？
- en: In simple language, what’s the proportion of times that the model caught the
    fraudster correctly in all actual fraud cases?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，模型在所有实际欺诈案件中，正确识别欺诈者的比例是多少？
- en: Using the Confusion Matrix from image 4, the Recall = 74.47%, since Recall =
    350 / (350 + 120).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图像4中的混淆矩阵，召回率 = 74.47%，因为召回率 = 350 / (350 + 120)。
- en: '**Alert Rate = (TP + FP) / (TP + FP + TN + FN)**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**警报率 = (TP + FP) / (TP + FP + TN + FN)**'
- en: 'Also known as Block Rate, this metric helps answer the question: What’s the
    proportion of positive predictions over all predictions?'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为阻塞率，该指标帮助回答问题：在所有预测中，正类预测占比是多少？
- en: 'In simple language: What proportion of times the model predicted something
    was Fraud?'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说：模型预测为欺诈的情况占多少比例？
- en: Using the Confusion Matrix from image 4, the Alert Rate = 0.46%, since Alert
    Rate = (350 + 110) / (350 + 110 + 120 + 99420).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图像4中的混淆矩阵，警报率 = 0.46%，因为警报率 = (350 + 110) / (350 + 110 + 120 + 99420)。
- en: '**F1 Score = 2x (Precision x Recall) / (Precision + Recall)**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**F1 分数 = 2 x (精确度 x 召回率) / (精确度 + 召回率)**'
- en: The F1 Score is a harmonic mean of Precision and Recall. It is a balanced measure
    between Precision and Recall, providing a single score to assess the model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数是精确度和召回率的调和平均值。它是精确度和召回率之间的平衡度量，提供了一个综合评分来评估模型。
- en: Using the Confusion Matrix from image 4, the F1-Score = 75.27%, since F1-Score
    = 2*(76.09% * 74.47%) / (76.09% + 74.47%).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图像4中的混淆矩阵，F1分数 = 75.27%，因为F1分数 = 2 * (76.09% * 74.47%) / (76.09% + 74.47%)。
- en: '**Accuracy = TP + TN / (TP + TN + FP + FN)**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确率 = TP + TN / (TP + TN + FP + FN)**'
- en: 'Accuracy helps answer this question: What’s the proportion of correctly classified
    transactions over all transactions?'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率帮助回答这个问题：在所有交易中，正确分类的交易占比是多少？
- en: Using the Confusion Matrix from image 4, the Accuracy = 99.77%, since Accuracy
    = (350 + 120) / (350 + 110 + 120 + 99420).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图像4中的混淆矩阵，准确率 = 99.77%，因为准确率 = (350 + 120) / (350 + 110 + 120 + 99420)。
- en: '![](../Images/82f2916f4a4144a638bce48a97268c0e.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82f2916f4a4144a638bce48a97268c0e.png)'
- en: 'Image 5: Confusion Matrix with Evaluation Metrics'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图像5：包含评估指标的混淆矩阵
- en: '**5\. When to use what metric**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**5. 何时使用哪些指标**'
- en: Accuracy is a go-to metric for evaluating many classification machine learning
    models. However, accuracy does not work well for cases where the target variable
    is imbalanced. In the case of Fraud detection, there is usually a tiny percentage
    of the data that is fraudulent; for example, in credit card fraud, it’s usually
    less than 1% of fraudulent transactions. So even if the model says that all transactions
    are fraudulent, which would be very incorrect, or that all transactions are not
    fraudulent, which would also be very wrong, the model’s accuracy would still be
    above 99%.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是评估许多分类机器学习模型的常用指标。然而，准确率在目标变量不平衡的情况下效果不好。在欺诈检测的情况下，通常只有极小比例的数据是欺诈的；例如，在信用卡欺诈中，通常不到1%的交易是欺诈交易。因此，即使模型说所有交易都是欺诈的（这将是非常错误的），或者说所有交易都不是欺诈的（这同样也是非常错误的），模型的准确率仍然可能超过99%。
- en: So what to do in those cases? Precision, Recall, and Alert Rate. Those are usually
    the metrics that give a good perspective on the model performance, even if the
    data is imbalanced. Which one exactly to use might depend on your stakeholders.
    I worked with stakeholders that said, whatever you do, please keep a Precision
    of at least 80%. So in that case, the stakeholder was very concerned about the
    user experience because if the Precision is very low, that means there will be
    a lot of False Positives, meaning that the model would incorrectly block good
    customers thinking they are placing fraudulent credit card transactions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在这些情况下该怎么做呢？精确度、召回率和警报率。这些通常是能提供模型性能良好视角的指标，即使数据不平衡。具体使用哪个指标可能取决于你的利益相关者。我曾与一些利益相关者合作，他们表示，无论做什么，请保持至少80%的精确度。因此，在这种情况下，利益相关者非常关注用户体验，因为如果精确度很低，意味着会有大量的假阳性，即模型会错误地屏蔽真正的客户，认为他们进行的是欺诈性的信用卡交易。
- en: 'On the other hand, there is a trade-off between Precision and Recall: the higher
    the Precision, the lower the Recall. So, if the model has a very high Precision,
    it won’t be great at finding all the fraud cases. In some sense, it also depends
    on how much a fraud case costs the business (financial loss, compliance problems,
    fines, etc.) vs. how many false positive cases cost the business (customer lifetime,
    which impacts business profitability).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，精确率和召回率之间存在一个权衡：精确率越高，召回率越低。因此，如果模型的精确率非常高，它在发现所有欺诈案件方面就不够出色。从某种意义上讲，这也取决于欺诈案件对业务的成本（财务损失、合规问题、罚款等）与虚假正例对业务的成本（客户生命周期，进而影响业务盈利能力）。
- en: So, in cases where the financial decision between Precision and Recall is unclear,
    a good metric to use is F1-Score, which helps provide a balance between Precision
    and Recall and optimizes for both of them.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在精确率与召回率之间的财务决策不明确时，一个好的指标是F1-Score，它有助于在精确率和召回率之间提供平衡，并优化两者。
- en: Last but not least, the Alert Rate is also a critical metric to consider because
    it gives an intuition about the number of transactions the Machine Learning model
    is planning to block. If the Alert Rate is very high, like 15%, that means that
    from all the orders placed by customers, 15% will be blocked, and only 85% will
    be accepted. So if you have a business with 1,000,000 orders daily, the machine
    learning model would block 150,000 of them thinking they’re fraudulent transactions.
    That’s a massive amount of orders blocked, and it’s important to have an instinct
    about the percentage of fraud cases. If fraud cases are about 1% or less, then
    a model blocking 15% is not only making a lot of mistakes but also blocking a
    big part of the business revenue.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，警报率也是一个关键的指标，因为它能直观地反映机器学习模型计划阻止的交易数量。如果警报率非常高，比如15%，那么意味着在客户下的所有订单中，15%会被阻止，只有85%会被接受。所以，如果你的业务每天有1,000,000个订单，机器学习模型会认为其中的150,000个是欺诈交易并加以阻止。这是一个巨大的订单量被阻止，因此了解欺诈案件的比例非常重要。如果欺诈案件的比例约为1%或更低，那么一个阻止15%的模型不仅会犯很多错误，还会阻碍大部分的业务收入。
- en: '**6\. Conclusion**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**6\. 结论**'
- en: Understanding these metrics allows data scientists and analysts to interpret
    the results of classification models better and enhance their performance. Precision
    and Recall offer more insights into the effectiveness of a model than mere accuracy,
    not only, but especially in fields like fraud detection where the class distribution
    is heavily skewed.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这些指标可以帮助数据科学家和分析师更好地解读分类模型的结果，并提升模型的表现。精确率和召回率比单纯的准确率提供了更多关于模型有效性的洞见，尤其是在像欺诈检测这样的领域，类分布严重偏斜的情况下。
- en: '**Images: Unless otherwise noted, all images are by the author. Image 1’s robot
    face was created by DALL-E, and it''s for public use.*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**图片：除非另有说明，所有图片均由作者提供。图像1中的机器人面孔是由DALL-E创建的，并且是公开使用的。**'
