- en: 'Image-to-Image Translation with FLUX.1: Intuition and Tutorial'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/image-to-image-translation-with-flux-1-intuition-and-tutorial-001fc521ebe6?source=collection_archive---------6-----------------------#2024-10-14](https://towardsdatascience.com/image-to-image-translation-with-flux-1-intuition-and-tutorial-001fc521ebe6?source=collection_archive---------6-----------------------#2024-10-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Generate new images based on existing images using diffusion models.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--001fc521ebe6--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--001fc521ebe6--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--001fc521ebe6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--001fc521ebe6--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--001fc521ebe6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--001fc521ebe6--------------------------------)
    ·6 min read·Oct 14, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf188237fee67ca01548444336f0e896.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Original image source: Photo by [Sven Mieke](https://unsplash.com/@sxoxm?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/brown-tabby-cat-lying-on-white-textile-G-8B32scqMc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    / Transformed image: Flux.1 with prompt “A picture of a Tiger”'
  prefs: []
  type: TYPE_NORMAL
- en: 'This post guides you through generating new images based on existing ones and
    textual prompts. This technique, presented in a paper called [**SDEdit: Guided
    Image Synthesis and Editing with Stochastic Differential Equations**](https://arxiv.org/abs/2108.01073)
    is applied here to FLUX.1.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we’ll briefly explain how latent diffusion models work. Then, we’ll see
    how SDEdit modifies the backward diffusion process to edit images based on text
    prompts. Finally, we’ll provide the code to run the entire pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Background: Latent Diffusion'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Latent diffusion performs the diffusion process in a lower-dimensional latent
    space. Let’s define latent space:'
  prefs: []
  type: TYPE_NORMAL
- en: A variational autoencoder (VAE) projects the image from pixel space (the RGB-height-width
    representation humans understand) to a smaller latent space. This compression
    retains enough information to reconstruct the image later. The diffusion process
    operates in this latent space because it’s computationally cheaper and less sensitive
    to irrelevant pixel-space details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, lets explain latent diffusion:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
