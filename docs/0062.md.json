["```py\nimport torch\n\ndigits = torch.tensor([0,1,2,3])\ntorch.nn.functional.one_hot(digits, 10)\n```", "```py\ntensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as functional\nimport torch.utils\nimport torch.distributions\nimport torchvision\nimport lightning.pytorch as pl\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# If you don't have access to a GPU use device='cpu'\ndevice = 'cuda'\n```", "```py\ndata = torch.utils.data.DataLoader(\n        torchvision.datasets.MNIST('.', # Choose a path\n               transform=torchvision.transforms.ToTensor(),\n               download=True),\n        batch_size=128,\n        shuffle=True)\n```", "```py\nclass CondVariationalEncoder(nn.Module):\n\n    # The encoder gets the label as a one-hot encoding\n    def __init__(self, latent_dims, n_classes):\n        super(CondVariationalEncoder, self).__init__()\n        # The dimensions of the one-hot encoding are concatenated to the input\n        self.linear1 = nn.Linear(784 + n_classes, 512)\n        self.linear2 = nn.Linear(512, latent_dims)\n        self.linear3 = nn.Linear(512, latent_dims)\n\n        self.N = torch.distributions.Normal(0, 1)\n        # Get sampling working on GPU\n        self.N.loc = self.N.loc.cuda()\n        self.N.scale = self.N.scale.cuda()\n        self.kl = 0\n\n    # The labels are provided as variable `y`\n    def forward(self, x, y):\n        x = torch.flatten(x, start_dim=1)\n        x = x.view(-1, 1*28*28)\n        # Here the label one-hot encoding is concatenated to the image\n        x = functional.relu(self.linear1(torch.cat((x,y),dim=1)))\n        # Mean\n        mu =  self.linear2(x)\n        # Variance\n        sigma = torch.exp(self.linear3(x))\n\n        # Sample latent vector for images\n        z = mu + sigma*self.N.sample(mu.shape)\n        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n        return z\n```", "```py\nclass CondVariationalDecoder(nn.Module):\n\n    # The decoder gets the label as a one-hot encoding\n    def __init__(self, latent_dims, n_classes):\n        super(CondVariationalDecoder, self).__init__()\n        # The dimensions of the one-hot encoding are concatenated to the input\n        self.linear1 = nn.Linear(latent_dims + n_classes, 512)\n        self.linear2 = nn.Linear(512, 784)\n\n    # Labels are provided as variable `y`\n    def forward(self, z, y):\n        # Here the label one-hot encoding is concatenated to the image\n        z = functional.relu(self.linear1(torch.cat((z,y),dim=1)))\n        z = torch.sigmoid(self.linear2(z))\n        return z.reshape((-1, 1, 28, 28))\n```", "```py\nclass CondVariationalAutoencoder(nn.Module):\n    def __init__(self, latent_dims, n_classes):\n        super(CondVariationalAutoencoder, self).__init__()\n        self.encoder = CondVariationalEncoder(latent_dims, n_classes)\n        self.decoder = CondVariationalDecoder(latent_dims, n_classes)\n\n    def forward(self, x, y):\n        z = self.encoder(x, y)\n        return self.decoder(z, y)\n```", "```py\nclass CVAEModel(pl.LightningModule):\n    def __init__(self, latent_dims, n_classes):\n        super().__init__()\n        self.cvae = CondVariationalAutoencoder(latent_dims, n_classes)\n        self.n_classes = n_classes\n\n    # Lightning requires a training step function in which the forward \n    # step is executed and loss calculated\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_oh = torch.nn.functional.one_hot(y, num_classes=self.n_classes)\n\n        x_hat = self.cvae(x, y_oh)\n        loss = loss = ((x - x_hat)**2).sum() + self.cvae.encoder.kl\n\n        self.log('Training loss', loss, on_step=False, on_epoch=True,\n                 logger=False, prog_bar=True)\n\n        return loss\n\n    # Defining the optimizer\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=0.02)\n```", "```py\nlatent_dims=2\nmodel = CVAEModel(latent_dims=latent_dims, n_classes=10)\n\ntrainer = pl.Trainer(devices=1, accelerator='gpu', max_epochs=10)\ntrainer.fit(model, data)\n```", "```py\ndef plot_reconstructed(autoencoder, r0=(-3, 3), r1=(-3, 3),\n                       n=8, number=2, device='cuda'):\n    # Define plot array:\n    fig, axs = plt.subplots(n, n)\n\n    # Loop over a grid in the latent space\n    for i, a in enumerate(np.linspace(*r1, n)):\n        for j, b in enumerate(np.linspace(*r0, n)):\n\n            z = torch.Tensor([[a, b]]).to(device)\n            # One-hot encoding of the integer\n            y = functional.one_hot(torch.tensor([number]),\n                                   num_classes=10).to(device)\n            # Forwarding the data through the decoder\n            x_hat = autoencoder.decoder(z, y)\n\n            x_hat = x_hat.reshape(28, 28).detach().cpu().numpy()\n            axs[i, j].imshow(x_hat)\n            axs[i, j].axis('off')\n    plt.show()\n```", "```py\nmodel = model.to(device)\nplot_reconstructed(model.cvae, number=8, device=device)\n```", "```py\ndef plot_latent_cvae(autoencoder, data, num_batches=100, device='cpu'):\n    for i, (x, y) in enumerate(data):\n        z = autoencoder.encoder(x.to(device),\n                                torch.nn.functional.one_hot(torch.tensor(y),\n                                                            num_classes=10).to(device))\n        z = z.detach().cpu().numpy()\n        plt.scatter(z[:, 0], z[:, 1], c=y, cmap='tab10')\n        if i > num_batches:\n            plt.colorbar()\n            break\nmodel = model.to(device)\nplot_latent_cvae(model.cvae, data, device=device)\n```", "```py\nclass eCVAEModel(pl.LightningModule):\n    # Here we need to define the number of classes and embedding dimensions\n    def __init__(self, latent_dims, n_classes, embedding_dims):\n        super().__init__()\n        # We can use the CVAE model from the previous notebook,\n        # but instead of using the number of classes for a one-hot encoding,\n        # we use the embedding dimensions\n        self.cvae = CondVariationalAutoencoder(latent_dims, embedding_dims)\n        self.n_classes = n_classes\n        self.embedding_dims = embedding_dims\n        self.embed_cond = nn.Embedding(num_embeddings=n_classes,\n                                       embedding_dim=embedding_dims,\n                                       max_norm=True)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n\n        # Instead of a one-hot encoding,\n        # the embeddings are used as conditional variables\n        x_hat = self.cvae(x, self.embed_cond(y))\n        loss = loss = ((x - x_hat)**2).sum() + self.cvae.encoder.kl\n\n        self.log('Training loss', loss, on_step=False, on_epoch=True,\n                 logger=False, prog_bar=True)\n\n        return loss\n\n    # Defining the optimizer\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=0.02)\n```", "```py\nemodel = eCVAEModel(latent_dims=latent_dims, n_classes=10, embedding_dims=5)\n\ntrainer = pl.Trainer(devices=1, accelerator='gpu', max_epochs=10)\ntrainer.fit(emodel, data)\n```", "```py\ndef plot_reconstructed_ecvae(model, r0=(-3, 3), r1=(-3, 3),\n                             n=8, number=2, device='cuda'):\n    # Define plot array:\n    fig, axs = plt.subplots(n, n)\n\n    # Loop over a grid in the latent space\n    for i, a in enumerate(np.linspace(*r1, n)):\n        for j, b in enumerate(np.linspace(*r0, n)):\n\n            z = torch.Tensor([[a, b]]).to(device)\n            # One-hot encoding of the integer\n            y = model.embed_cond(torch.tensor([number]).to(device))\n            # Forwarding the data through the decoder\n            x_hat = model.cvae.decoder(z, y)\n\n            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n            axs[i, j].imshow(x_hat)\n            axs[i, j].axis('off')\n    plt.show()\n```", "```py\nemodel = emodel.to(device)\nplot_reconstructed_ecvae(emodel, number=8, device=device)\n```", "```py\ndef plot_latent_ecvae(model, data, num_batches=100, device='cpu'):\n    for i, (x, y) in enumerate(data):\n        y_embed = model.embed_cond(torch.tensor(y, device=device))\n        z = model.cvae.encoder(x.to(device), y_embed)\n        z = z.detach().cpu().numpy()\n        plt.scatter(z[:, 0], z[:, 1], c=y, cmap='tab10')\n        if i > num_batches:\n            plt.colorbar()\n            break\n\nmodel = model.to(device)\nplot_latent_ecvae(emodel, data, device=device)\n```", "```py\n# Creating dataloaders excluding 8 & 9 digits\n# Code adapted from:\n# https://stackoverflow.com/questions/75034387/remove-digit-from-mnist-pytorch\ndstrain = torchvision.datasets.MNIST('/scratch/trose/mnist',\n                                transform=torchvision.transforms.ToTensor(),\n                                download=True)\nidxn9 = dstrain.targets!=9\nidxn8 = dstrain.targets!=8\nidx = idxn9 & idxn8\n\ndstrain.targets = dstrain.targets[idx]\ndstrain.data = dstrain.data[idx]\n\n# Data containing only 8 & 9 digits\nds89 = torchvision.datasets.MNIST('/scratch/trose/mnist',\n                                transform=torchvision.transforms.ToTensor(),\n                                download=True)\nidx9 = ds89.targets==9\nidx8 = ds89.targets==8\nidx89 = idx9 | idx8\nds89.targets = ds89.targets[idx89]\nds89.data = ds89.data[idx89]\n\ndatatrain = torch.utils.data.DataLoader(dstrain, batch_size=128, shuffle=True)\ndata89 = torch.utils.data.DataLoader(ds89, batch_size=128, shuffle=True)\n```", "```py\nemodel89 = eCVAEModel(latent_dims=latent_dims, n_classes=10, embedding_dims=5)\n\ntrainer = pl.Trainer(devices=1, accelerator='gpu', max_epochs=10)\ntrainer.fit(emodel89, datatrain)\n```", "```py\n# Freeze model parameters\nfor name, param in emodel89.named_parameters():\n    if name == 'embed_cond.weight':\n        param.requires_grad = True\n    else:\n        param.requires_grad = False\n\n# Training just on 8 & 9 digits on frozen weights\n# The model is using the previously created embedding vectors in the model\n# that were not updated for 8 & 9 in the previous training.\ntrainer89 = pl.Trainer(devices=1, accelerator='gpu', max_epochs=10)\ntrainer89.fit(emodel89, data89)\n```", "```py\nemodel89 = emodel.to(device)\nplot_reconstructed_ecvae(emodel89, number=8, device=device)\n```", "```py\nemodel89 = emodel89.to(device)\nplot_latent_ecvae(emodel89, data, device=device)\n```"]