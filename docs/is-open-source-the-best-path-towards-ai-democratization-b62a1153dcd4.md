# 开源是实现AI民主化的最佳途径吗？

> 原文：[https://towardsdatascience.com/is-open-source-the-best-path-towards-ai-democratization-b62a1153dcd4?source=collection_archive---------11-----------------------#2024-06-25](https://towardsdatascience.com/is-open-source-the-best-path-towards-ai-democratization-b62a1153dcd4?source=collection_archive---------11-----------------------#2024-06-25)

## *尽管开源模型已经使软件民主化，但将其应用于AI时会引发法律和伦理问题。开源AI运动的最终目标是什么？*

[](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[![Julius Cerniauskas](../Images/fdff5669f0b16936af3cb59bb4c14526.png)](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------) [Julius Cerniauskas](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------) ·阅读时间：6分钟·2024年6月25日

--

![](../Images/df87b28e8d652e618b3f9b5e4d88156b.png)

AI未来的竞争刚刚遇到了一点小障碍——“开源”的定义。公众第一次听到这个术语有争议是在春初，当时OpenAI的联合创始人埃隆·马斯克[起诉OpenAI](https://www.reuters.com/legal/elon-musk-sues-openai-ceo-sam-altman-breach-contract-2024-03-01/)违反了其最初的非盈利使命（尽管几个月后他决定撤回诉讼）。

确实，OpenAI曾长期宣传开源社区的理念。然而，这一说法受到了广泛批评，最近的一份[报告](https://pure.mpg.de/rest/items/item_3526897_1/component/file_3526898/content)显示，底层的ChatGPT模型是一个封闭系统，只有API在某种程度上保持开放。OpenAI并非唯一一个试图加入“开源洗白”行列的科技公司——Meta的LLaMA和谷歌的BERT也都被宣传为“开源AI”。

不幸的是，将一个系统标榜为“开源”而实际上并非如此的问题，不仅仅是营销问题：有些情况下，标榜为“开源人工智能”可以带来法律豁免，因此企业滥用这一术语的风险是真实存在的。为了解决这一问题，开源倡议（OSI）——一个帮助创造开源软件定义的独立非营利组织——宣布将举办一系列[全球研讨会](https://opensource.org/blog/the-open-source-ai-definition-gets-closer-to-reality-with-a-global-workshop-series)，以收集各方意见，并推动开源人工智能定义达成最终一致。

尽管技术专家和开发人员在争论这一术语的范围，但现在是提出一个可能略显不舒服的问题的时候——开源运动是否是民主化人工智能、让这项技术更加透明的最佳途径？

# 开源软件与开源人工智能

开源软件通常指的是一种去中心化的开发过程，在这个过程中，代码公开供不同的同行进行协作和修改。OSI（开源倡议）制定了一套明确的[开源定义规则](https://opensource.org/osd)，从自由再分发和非歧视到不受限制的许可。然而，有几个合理的原因说明这些原则无法轻易地移植到人工智能领域。

首先，大多数人工智能系统都是建立在庞大的训练数据集之上的，而这些数据受到不同法律体系的约束，包括版权、隐私保护、商业机密和各种保密措施。因此，开放训练数据存在法律风险。如[Meta公司人工智能研究副总裁Joëlle Pineau](https://news.itsfoss.com/open-source-definition-ai/)所指出，目前的许可方案并不是为处理利用来自多个来源的大量数据的软件而设计的。然而，将数据保持封闭，使得人工智能系统可以公开访问，但并非开源，因为没有看到训练数据，任何人都无法利用算法架构。

第二，参与开发和部署人工智能系统的贡献者数量远远大于软件开发中的贡献者数量，后者可能只有一家企业。在人工智能的情况下，不同的贡献者可能会对人工智能系统的不同部分和输出承担责任。然而，要确定如何在不同的开源贡献者之间分配责任将是困难的。我们假设一个场景：如果基于开源模型的人工智能系统产生了误导性的输出，促使情绪困扰的人伤害自己，那么谁将为此负责？

# 开放性的风险

OSI的努力基于这样的论点：要对人工智能模型进行一些修改，必须访问其底层架构、训练代码、文档、加权因子、数据预处理逻辑，以及当然，数据本身。因此，一个真正开放的系统应该允许完全自由地使用和修改系统，这意味着任何人都可以参与技术的发展。在理想的世界里，这一论点是完全正当的。然而，世界并不理想。

最近，[OpenAI已承认](https://www.technologyreview.com/2024/03/25/1090111/tech-industry-open-source-ai-definition-problem/)除非经过仔细评估所有风险，包括滥用和加速，否则他们不愿意将强大的生成性人工智能系统作为开源发布。人们可能会争论这是否是真诚的考虑，还是一项公关举措，但风险确实存在。加速是我们甚至不知道如何应对的风险——这一点在过去两年的快速人工智能发展中得到了清晰体现，令法律和政治界在众多监管问题和挑战面前感到困惑。

滥用——无论是用于犯罪还是其他目的——甚至更难以遏制。正如[RAND资助的研究](https://www.rand.org/pubs/research_reports/RR3139-1.html)所显示的那样，未来的大多数人工智能系统可能会是双重用途的，这意味着军方将会采用并改进商业开发的技术，而不是从零开始开发军事人工智能。因此，开源系统落入非民主国家和激进非国家行为者之手的风险不容忽视。

此外，还存在一些更为无形的风险，比如偏见和虚假信息的增加，这些都必须在发布开源人工智能系统时予以考虑。如果该系统可以自由修改和操作，包括更改训练数据和训练代码的可能性，那么原始的人工智能提供者几乎无法做任何事情来确保系统保持道德、值得信赖和负责任。可能正是出于这个原因，OSI在定义其使命时明确将这些问题称为“超出范围”。因此，尽管开源可能平衡竞争环境，让小型参与者也能从人工智能创新中受益并推动其发展，但它也固有地带来了使人工智能输出变得不公平和不准确的风险。

# 开源模型的使用与滥用

总结来说，目前仍不清楚如何将广泛定义的开源模型应用于主要由数据构成的人工智能领域，而不会带来严重风险。开放人工智能系统将需要新的法律框架，例如[负责任的人工智能许可证](https://www.licenses.ai/)（RAIL），以便允许开发者防止他们的工作被不道德或不负责任地使用。

然而，这并不是说OSI统一定义的使命对于AI创新的未来不重要，而是这种重要性主要不在于推动创新和民主化，而在于确保法律的清晰性并减少潜在的操控风险。

让我们以刚刚发布的[欧盟AI法案](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206&amp%3Bqid=1716811772119)为例——这是首部全面的AI发展法规。AI法案为开源通用人工智能（GPAI）模型提供了明确的例外，放宽了透明度和文档要求。这些模型驱动着大多数当前面向消费者的生成式AI产品，比如ChatGPT。只有当模型具有“系统性风险”或是以盈利为目的时，这些豁免才不适用。

在这种情况下，更加宽松（或更加严格）的开源许可证实际上可能成为一种规避透明度和文档要求的手段，这种行为很可能是考虑到AI公司在不违反版权和数据隐私法的情况下，获取多维度训练数据的持续斗争。行业必须就“开源”达成一致的定义并强制执行；否则，大型公司将根据自身利益来决定“开源”的含义。

# 民主化数据，而非系统

尽管出于法律目的需要明确的定义，但是否广义定义的开源方法能够带来预期的技术进步并平衡竞争环境，仍然存疑。AI系统主要建立在数据之上，获取大规模数据的难度是大科技公司的最强竞争优势之一，此外还有计算能力。

使AI开源并不能消除小型企业所面临的所有结构性障碍——仍然需要不断流入的数据、适当的计算能力以及高度熟练的开发人员和数据科学家来修改系统并进一步训练它。

在追求AI民主化的过程中，保护开放互联网和所有人都能访问的开放网络数据可能比推动开源议程更为重要。由于法律制度的冲突或过时，今天的互联网数据是碎片化的，阻碍了创新。因此，政府和监管机构必须寻找方法，重新平衡诸如版权保护等领域，使公共数据更容易获取。
