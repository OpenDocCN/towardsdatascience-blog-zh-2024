<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Classification Loss Functions: Intuition and Applications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Classification Loss Functions: Intuition and Applications</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classification-loss-functions-intuition-and-applications-cb75a3b03237?source=collection_archive---------3-----------------------#2024-06-27">https://towardsdatascience.com/classification-loss-functions-intuition-and-applications-cb75a3b03237?source=collection_archive---------3-----------------------#2024-06-27</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="629d" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A simpler way to understand derivations of loss functions for classification and when/how to apply them in PyTorch</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@rtdcunha?source=post_page---byline--cb75a3b03237--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ryan D'Cunha" class="l ep by dd de cx" src="../Images/7a39859e2b5e5b09ef2c60aaf6bb75ac.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*NhxQFjIuOQ0Xh_bfwEk4vQ@2x.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--cb75a3b03237--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@rtdcunha?source=post_page---byline--cb75a3b03237--------------------------------" rel="noopener follow">Ryan D'Cunha</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--cb75a3b03237--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 27, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/8799dde9d8c2ba105f0d95e98464eb61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i6pDKVsATeeyTDkCDn3CrQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Source: GPT4o Generated</figcaption></figure><p id="e0b6" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Whether you are new to exploring neural networks or a seasoned pro, this should be a beneficial read to gain more intuition about loss functions. As someone testing many different loss functions during model training, I would get tripped up on small details between functions. I spent hours researching an intuitive depiction of loss functions from textbooks, research papers, and videos. I wanted to share not only the <strong class="nd fr">derivations</strong> that helped me grasp the concepts, but common pitfalls and use cases for <strong class="nd fr">classification</strong> in PyTorch.</p><h1 id="92a3" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">Terminology</h1><p id="52b9" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Before we get started, we need to define some basic terms I will be using.</p><ul class=""><li id="8df2" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw oy oz pa bk">Training dataset: <em class="pb">{xᵢ, yᵢ}</em></li><li id="3691" class="nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw oy oz pa bk">Loss function: <em class="pb">L[φ]</em></li><li id="3376" class="nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw oy oz pa bk">Model prediction output <em class="pb">f[xᵢ, φ] </em>with parameters<em class="pb"> φ</em></li><li id="a7af" class="nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw oy oz pa bk">Conditional probability: <em class="pb">Pr(y|x)</em></li><li id="95fc" class="nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw oy oz pa bk">Parametric distribution:<em class="pb"> Pr(y|ω) </em>with<em class="pb"> ω</em> representing network parameters for distribution over <em class="pb">y</em></li></ul><h1 id="2e76" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">Introduction</h1><p id="603d" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Let’s first go back to the basics. A common thought is that neural networks compute a scalar output from the model <em class="pb">f[xᵢ, φ]. </em>However, most neural networks these days are trained to predict parameters of a distribution <em class="pb">y. </em>(as oppose to to predicted the value of <em class="pb">y</em>).</p><p id="b4a7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In reality, a network will output a conditional probability distribution <em class="pb">Pr(y|x) </em>over possible outputs <em class="pb">y. </em>In other words, every input data point will lead to a probability distribution generated for each output. The network wants to learn the parameters for the probability distribution and then use the parameters and distribution to predict the output.</p><p id="d213" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The traditional definition of a loss function is a function that compares target and predicted outputs. But we just said a network raw output is a distribution instead of a scalar output, so how is this possible?</p><p id="f3bb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Thinking about this from the view we just defined, a loss function pushes each <em class="pb">yᵢ </em>to have a higher probability in the distribution <em class="pb">Pr(yᵢ|xᵢ)</em>. The key part to remember is that our distribution is being used to predict the true output based on parameters from our model output. Instead of using our input <em class="pb">xᵢ </em>for the distribution<em class="pb">, </em>we can think of a parametric distribution <em class="pb">Pr(y|ω) </em>where<em class="pb"> ω</em> represents probability distribution parameters. We are still considering the input, but there will be a different <em class="pb">ωᵢ = f[xᵢ, φ] </em>for each<em class="pb"> xᵢ.</em></p><blockquote class="ph pi pj"><p id="3c8b" class="nb nc pb nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Note:</strong> To clarify a confusing concept, φ<em class="fq"> </em>represents the model parameters and ω represents the probability distribution parameters</p></blockquote><h1 id="8d3a" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">Deriving Negative Log-Likelihood Loss</h1><p id="05d6" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk"><em class="pb">G</em>oing back to the traditional definition of a loss function, we need to get an output we can use from the model. From our probability distribution, it seems logical to take <em class="pb">φ </em>that produces the greatest probability for each <em class="pb">xᵢ. </em>Thus, we need the overall <em class="pb">φ</em> that produces the greatest probability across all training points <em class="pb">I </em>(all derivations are adapted from Understanding Deep Learning [1]):</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pk"><img src="../Images/522fceb7fdc7af4df7531a2c5537250e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jl_v25YGo6-12lLCvY5ZCw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Maximizing parameters from output model probability distributions [1]</figcaption></figure><p id="d10b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We multiply the generated probabilities from each distribution to find <em class="pb">φ</em> that produces the maximum probability (called <strong class="nd fr">max likelihood</strong>). In order to do this, we must assume the data is independent and identically distributed. But now we run into a problem: what if the probabilities are very small? Our multiplication output will approach 0 (similar to a vanishing gradient issue). Furthermore, our program may not be able to process such small numbers.</p><p id="fa60" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To fix this, we bring in a logarithmic<em class="pb"> </em>function! Utilizing the properties of logs, we can add together our probabilities instead of multiplying them. We know that the logarithm is a monotonically increasing function, so our original output is preserved and scaled by the log.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pl"><img src="../Images/e9d290f8114504d063ca077dce4382fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CV6JRmUbqwNE-0aN-8FGJA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Using logarithms to add probabilities [1]</figcaption></figure><p id="2dfe" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The last thing we need to get our traditional negative log-likelihood is to minimize the output. We are currently maximizing the output, so simply multiply by a negative and take the minimum argument (think about some graphical examples to convince yourself of this):</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pm"><img src="../Images/fc1c7cee0ae2ea2d49a9ef2760b133ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8agwFLtkVAkehZlCtadpzA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Negative Log-Likelihood [1]</figcaption></figure><p id="2dba" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Just by visualizing the model output as a probability distribution, attempting to maximize <em class="pb">φ </em>that creates the max probability, and applying a log, we have derived negative log-likelihood loss! This can be applied to many tasks by choosing a logical probability distribution. Common classification examples are shown below.</p><p id="667b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">If you are wondering how a scalar output is generated from the model during <strong class="nd fr">inference</strong>, it’s just the max of the distribution:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pn"><img src="../Images/77d8057be79a86e22f7758dac179cbec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VQCJOrBa_hIIT_ZktwgtBQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Generating an output from inference [1]</figcaption></figure><blockquote class="ph pi pj"><p id="5b3c" class="nb nc pb nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Note:</strong> This is just a derivation of negative log-likelihood. In practice, there will most likely be regularization present in the loss function too.</p></blockquote><h1 id="4e78" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">Loss for Classification</h1><p id="3ca0" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Up to this point, we derived negative log-likelihood. Important to know, but it can be found in most textbooks or online resources. Now, let’s apply this to classification to understand it’s application.</p><blockquote class="ph pi pj"><p id="7e07" class="nb nc pb nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Side note:</strong> If you are interested in seeing this applied to regression, Understanding Deep Learning [1] has great examples with univariate regression and a Gaussian Distribution to derive Mean Squared Error</p></blockquote><h2 id="4534" class="po ny fq bf nz pp pq pr oc ps pt pu of nk pv pw px no py pz qa ns qb qc qd qe bk">Binary Classification</h2><p id="53ba" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">The goal of binary classification is to assign an input <em class="pb">x</em> to one of two class labels <em class="pb">y</em> ∈ {0, 1}. We are going to use the Bernoulli distribution as our probability distribution of choice.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qf"><img src="../Images/64d8d4c8478ea774fceb1a8d84d5c783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XxhOO9b_GkT-HvnqcFX1TA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Mathematical Representation of Bernoulli Distribution. Image by Author</figcaption></figure><p id="a464" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This is just a fancy way of saying the probability that the output is true, but the equation is necessary to derive our loss function. We need the model <em class="pb">f[x, φ] </em>to output <em class="pb">p </em>to generate the predicted output probability<em class="pb">. </em>However, before we can input <em class="pb">p </em>into Bernoulli, we need it to be between 0 and 1 (so it’s a probability). The function of choice for this is a sigmoid: σ(<em class="pb">z</em>)</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qg"><img src="../Images/9716980d8305f8ba0fce144f11ee2f0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wTx-scwK5W4s5HrB.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Source: <a class="af qh" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Sigmoid_function</a></figcaption></figure><p id="d69f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">A sigmoid will compress the output <em class="pb">p </em>to between 0 and 1. Therefore our input to Bernoulli will be <em class="pb">p = </em>σ(<em class="pb">f[x, φ]). </em>This makes our probability distribution:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qi"><img src="../Images/32e05e638cc53e6838db0a7dcaeeb77c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D9tl4b3GGJHFgLSJTsX8ZA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">New Probability Distribution with Sigmoid and Bernoulli. Image by Author</figcaption></figure><p id="90a7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Going back to negative log-likehood, we get the following:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qj"><img src="../Images/f2e36bf555c46b78ee8cac481211a9c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x2ozw9Fl63GZsskqzzQ5hg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Binary Cross Entropy. Image by Author</figcaption></figure><p id="6b4c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Look familiar? This is the binary cross entropy (BCE) loss function! The main intuition with this is understanding why a sigmoid is used. We have a scalar output and it needs to be scaled to between 0 and 1. There are other functions capable of this, but the sigmoid is the most commonly used.</p><h2 id="e05f" class="po ny fq bf nz pp pq pr oc ps pt pu of nk pv pw px no py pz qa ns qb qc qd qe bk">BCE in PyTorch</h2><p id="c60b" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">When implementing BCE in PyTorch, there are a few tricks to watch out for. There are two different BCE functions in PyTorch: <em class="pb">BCELoss()</em> and <em class="pb">BCEWithLogitsLoss()</em>. A common mistake (that I have made) is incorrectly swapping the use cases.</p><p id="ed76" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">BCELoss():</strong> This torch function outputs the loss WITH THE SIGMOID APPLIED. The output will be a <strong class="nd fr">probability</strong>.</p><p id="618d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">BCEWithLogitsLoss():</strong> The torch function outputs logits which are the <strong class="nd fr">raw outputs</strong> of the model. There is NO SIGMOID APPLIED. When using this, you will need to apply a <em class="pb">torch.sigmoid()</em> to the output.</p><blockquote class="ph pi pj"><p id="ad64" class="nb nc pb nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This is especially important for Transfer Learning as the model even if you know the model is trained with BCE, make sure to use the right one. If not, you make accidentally apply a sigmoid after BCELoss() causing the network to not learn…</p></blockquote><p id="a9ef" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Once a probability is calculated using either function, it needs to be interpreted during inference. The probability is the model’s prediction of the likelihood of being true (class label of 1). Thresholding is needed to determine the cutoff probability of a true label. <em class="pb">p = 0.5 </em>is commonly used, but it’s important to test out and optimize different threshold probabilities. A good idea is to plot a histogram of output probabilities to see the confidence of outputs before deciding on a threshold.</p><h2 id="0cd0" class="po ny fq bf nz pp pq pr oc ps pt pu of nk pv pw px no py pz qa ns qb qc qd qe bk">Multiclass Classification</h2><p id="2764" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">The goal of multiclass classification is to assign an input <em class="pb">x</em> to one of <em class="pb">K</em> &gt; 2 class labels <em class="pb">y</em> ∈ {1, 2, …, <em class="pb">K</em>}. We are going to use the categorical distribution as our probability distribution of choice.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qk"><img src="../Images/0a232fbe9bf6255a4b73db74c8d240e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MOdJOLYJIjxalsllkOk2sw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Categorical Distribution. Image by Author</figcaption></figure><p id="fcd1" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This is just assigning a probability for each class for a given output and all probabilities must sum to 1. We need the model <em class="pb">f[x, φ] </em>to output <em class="pb">p </em>to generate the predicted output probability<em class="pb">. </em>The sum issue arises as in binary classification. Before we can input <em class="pb">p </em>into Bernoulli, we need it to be a probability between 0 and 1. A sigmoid will no longer work as it will scale each class score to a probability, but there is no guarantee all probabilities will sum to 1. This may not immediately be apparent, but an example is shown:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ql"><img src="../Images/83affdb6b334591ba290ca2a040054c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LCvZ93hRne34jIiAbrNlA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Sigmoid does not generate probability distribution in multiclass classification. Image by Author</figcaption></figure><p id="0645" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We need a function that can ensure both constraints. For this, a softmax is chosen. A softmax is an extension of a sigmoid, but it will ensure all the probabilities sum to 1.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qm"><img src="../Images/94e889be5ace748c47a8fb0ce491f38a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fuF6-XzPpyUl4Z_P8LW1xw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Softmax Function. Image by Author</figcaption></figure><p id="7d10" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This means the probability distribution is a softmax applied to the model output. The likelihood of calculating a label <em class="pb">k</em>: <em class="pb">Pr</em>(<em class="pb">y = k|x</em>) = <em class="pb">S</em>ₖ(<em class="pb">f[x, φ]</em>).</p><p id="ecb1" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To derive the loss function for multiclass classification, we can plug the softmax and model output into the negative log-likelihood loss:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qn"><img src="../Images/bfcc77f988d2af066f4750c5d37ad78d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-bAHJNHz69tSLfaIbEzifw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Multiclass Cross Entropy. Image by Author</figcaption></figure><p id="452c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This is the derivation for multiclass cross entropy. It is important to remember the only term contributing to the loss function is the probability of the true class. If you have seen cross entropy, you are more familiar with a function with a <em class="pb">p(x) </em>and <em class="pb">q(x). </em>This is identical to the cross entropy loss equation shown where <em class="pb">p(x) = 1</em> for the true class and 0 for all other classes. <em class="pb">q(x) </em>is the softmax of the model output. The other derivation of cross entropy comes from using KL Divergence, and you can reach the same loss function by treating one term as a Dirac-delta function where true outputs exist and the other term as the model output with softmax. It is important to note that both routes lead to the same loss function.</p><h2 id="f23b" class="po ny fq bf nz pp pq pr oc ps pt pu of nk pv pw px no py pz qa ns qb qc qd qe bk">Cross Entropy in PyTorch</h2><p id="e9fe" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Unlike binary cross entropy, there is only one loss function for cross entropy in PyTorch. <em class="pb">nn.CrossEntropyLoss</em> returns the model output with the softmax already applied. Inference can be performed by taking the largest probability softmax model output (taking the highest probability as would be expected).</p><h1 id="5467" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">Applications</h1><p id="e5b1" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">These were two well studied classification examples. For a more complex task, it may take some time to decide on a loss function and probability distribution. There are a lot of charts matching probability distributions with intended tasks, but there is always room to explore.</p><p id="edc3" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For certain tasks, it may be helpful to combine loss functions. A common use case for this is in a classification task where it maybe helpful to combine a [binary] cross entropy loss with a modified Dice coefficient loss. Most of the time, the loss functions will be added together and scaled by some hyperparameter to control each individual functions contribution to loss.</p></div></div></div><div class="ab cb qo qp qq qr" role="separator"><span class="qs by bm qt qu qv"/><span class="qs by bm qt qu qv"/><span class="qs by bm qt qu"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="653e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Hopefully this derivation of negative log-likelihood loss and its applications proved to be useful!</p><h1 id="a46c" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">References</h1><p id="4e52" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">[1] Prince, Simon J.D., <a class="af qh" href="https://mitpress.mit.edu/9780262048644/understanding-deep-learning/" rel="noopener ugc nofollow" target="_blank">Understanding Deep Learning</a>.</p><p id="b7b4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[2] <a class="af qh" href="https://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank">Stanford CS231n</a>.</p><p id="a06f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[3] P. Bosman, D. Thierens, <a class="af qh" href="https://homepages.cwi.nl/~bosman/publications/2000_negativeloglikelihood.pdf" rel="noopener ugc nofollow" target="_blank">Negative Log–Likelihood And Statistical Hypothesis Testing As The Basis Of Model Selection In IDEAs</a> (2000).</p></div></div></div></div>    
</body>
</html>