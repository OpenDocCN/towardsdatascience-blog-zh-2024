["```py\nbaseline BIC: 34570.166173470934\n```", "```py\nimport statsmodels.api as sm\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.base import BaseEstimator\n\nclass DummyEstimator(BaseEstimator):\n    # mlxtend wants to use an sklearn estimator, which is not needed here\n    # (statsmodels OLS is used instead)\n    # create a dummy estimator to pacify mlxtend\n    def fit(self, X, y=None, **kwargs):\n        return self\n\ndef neg_bic(m, X, y):\n    # objective function\n    lin_mod_res = sm.OLS(y, X, hasconst=True).fit()\n    return -lin_mod_res.bic\n\nseq_selector = SFS(\n    DummyEstimator(),\n    k_features=(1, X.shape[1]),\n    forward=True,\n    floating=False,\n    scoring=neg_bic,\n    cv=None,\n    n_jobs=-1,\n    verbose=0,\n    # make sure the intercept is not dropped\n    fixed_features=['const'],\n)\n\nn_features = X.shape[1] - 1\nobjective_runs_sfs = round(n_features * (n_features + 1) / 2)\nt_start_seq = time.time()\n# mlxtend will mess with your dataframes if you don't .copy()\nseq_res = seq_selector.fit(X.copy(), y.copy())\nt_end_seq = time.time()\nrun_time_seq = t_end_seq - t_start_seq\nseq_metrics = seq_res.get_metric_dict()\n```", "```py\nbest k:         36\nbest objective: 33708.98602877906\nR2 @ best k:    0.9075677543649224\nobjective runs: 22791\ntotal run time: 42.448 sec\n```", "```py\ndef cma_objective(fs):\n    features_use = ['const'] + [\n        f for i, f in enumerate(features_select) if fs[i,] == 1\n    ]\n    lin_mod = sm.OLS(y_cmaes, X_cmaes[features_use], hasconst=True).fit()\n    return lin_mod.bic\n\nX_cmaes = X.copy()\ny_cmaes = y.copy()\nfeatures_select = [f for f in X_cmaes.columns if f != 'const']\n\ndim = len(features_select)\nbounds = np.tile([0, 1], (dim, 1))\nsteps = np.ones(dim)\noptimizer = CMAwM(\n    mean=np.full(dim, 0.5),\n    sigma=1 / 6,\n    bounds=bounds,\n    steps=steps,\n    n_max_resampling=10 * dim,\n    seed=0,\n)\n\nmax_gen = 100\nbest_objective_cmaes_small = np.inf\nbest_sol_raw_cmaes_small = None\nfor gen in tqdm(range(max_gen)):\n    solutions = []\n    for _ in range(optimizer.population_size):\n        x_for_eval, x_for_tell = optimizer.ask()\n        value = cma_objective(x_for_eval)\n        solutions.append((x_for_tell, value))\n        if value < best_objective_cmaes_small:\n            best_objective_cmaes_small = value\n            best_sol_raw_cmaes_small = x_for_eval\n    optimizer.tell(solutions)\n\nbest_features_cmaes_small = [\n    features_select[i]\n    for i, val in enumerate(best_sol_raw_cmaes_small.tolist())\n    if val == 1.0\n]\nprint(f'best objective: {best_objective_cmaes_small}')\nprint(f'best features:  {best_features_cmaes_small}')\n```", "```py\nbest objective:  33703.070530508514\nbest generation: 921\nobjective runs:  20000\ntime to best:    48.326 sec\n```", "```py\nbaseline BIC: 34570.166173470934\n```"]