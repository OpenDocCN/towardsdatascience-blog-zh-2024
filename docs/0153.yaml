- en: 'Detecting Concept Shift: Impact on Machine Learning Performance'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测概念漂移：对机器学习性能的影响
- en: 原文：[https://towardsdatascience.com/detecting-concept-shift-impact-on-machine-learning-performance-16923261cda8?source=collection_archive---------9-----------------------#2024-01-16](https://towardsdatascience.com/detecting-concept-shift-impact-on-machine-learning-performance-16923261cda8?source=collection_archive---------9-----------------------#2024-01-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/detecting-concept-shift-impact-on-machine-learning-performance-16923261cda8?source=collection_archive---------9-----------------------#2024-01-16](https://towardsdatascience.com/detecting-concept-shift-impact-on-machine-learning-performance-16923261cda8?source=collection_archive---------9-----------------------#2024-01-16)
- en: MLOps
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps
- en: When should I retrain my model?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我什么时候应该重新训练我的模型？
- en: '[](https://michaloleszak.medium.com/?source=post_page---byline--16923261cda8--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page---byline--16923261cda8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--16923261cda8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--16923261cda8--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page---byline--16923261cda8--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michaloleszak.medium.com/?source=post_page---byline--16923261cda8--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page---byline--16923261cda8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--16923261cda8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--16923261cda8--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page---byline--16923261cda8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16923261cda8--------------------------------)
    ·14 min read·Jan 16, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16923261cda8--------------------------------)
    ·阅读时间：14分钟·2024年1月16日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/df5c3efdf2b6711c8bebfeb66348eb3a.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df5c3efdf2b6711c8bebfeb66348eb3a.png)'
- en: 'Have you heard of lifelong learning? You might be familiar with the story:
    with today’s rapid technology advancements, what we learned at school will not
    set us up for professional success for our whole career. To stay useful in the
    job market, one needs to learn how to learn continuously. In this aspect of life,
    AI is not so different from us humans. Machine learning models’ knowledge becomes
    obsolete, too, and they need to relearn stuff just like we do. But when does a
    model become obsolete?'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你听说过终身学习吗？你可能熟悉这样的故事：随着今天科技的快速发展，我们在学校学到的东西不能保证我们整个职业生涯都能取得成功。为了在就业市场中保持竞争力，我们需要学会如何持续学习。在这一方面，人工智能和我们人类并没有太大的不同。机器学习模型的知识也会过时，它们需要像我们一样重新学习。那么，模型何时会变得过时呢？
- en: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
- en: What is concept shift, and can we detect it?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是概念漂移，我们能检测到它吗？
- en: 'The phenomenon responsible for ML models’ knowledge going stale is known as
    *concept shift*. However, before we dive into the details, let’s take a quick
    high-level overview of the broader problem: data shifts.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型知识过时的现象被称为*概念漂移*。然而，在深入细节之前，我们先快速回顾一下更广泛的问题：数据漂移。
- en: Data shifts primer
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据漂移概述
- en: The world changes. Consumer behaviors and tastes evolve over time; your users
    might change their preferences as they grow older; data-collecting devices tend
    to break or malfunction in unexpected ways. Whatever industry you are working
    in, and whatever problem you’re solving with machine learning, you can be sure
    that at some point, the data your production model receives will be different
    from the data it has seen during training. As a consequence of this, machine learning
    models tend to deteriorate over time after being deployed to production.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 世界在变化。消费者行为和口味随着时间的推移而演变；随着年龄的增长，你的用户可能会改变他们的偏好；数据收集设备也可能会以意想不到的方式发生故障或损坏。无论你所在的行业是什么，或者你用机器学习解决什么问题，你可以肯定的是，在某个时刻，你的生产模型接收到的数据将会与它在训练时看到的数据不同。因此，机器学习模型在投入生产后往往会随着时间的推移而退化。
- en: Types of data shift
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据漂移的类型
- en: The changes in the world can translate to the changes in your data in different
    ways. To better understand this, it’s useful to introduce a bit of notation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 世界的变化可以以不同的方式转化为数据的变化。为了更好地理解这一点，引入一些符号是非常有用的。
- en: 'Machine learning models, in general, operate on two kinds of input data: features,
    *X*, and targets, *y*. The data shift in its most generic form is described as
    a change in the joint distribution of features and targets, *P(X, Y)*. There are
    four potential causes for *P(X, Y)* to change*.*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，机器学习模型处理两种类型的输入数据：特征，*X*，和目标，*y*。数据偏移在其最一般的形式下是描述特征和目标的联合分布变化，*P(X, Y)*。有四种可能的原因导致*P(X,
    Y)*的变化*。
- en: To list all four, we need to use the so-called product rule, a mathematical
    formula stating that P(X, Y) = P(Y, X) = P(X|Y)P(Y) = P(Y|X)P(X).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了列出所有四种方式，我们需要使用所谓的乘积法则，这是一个数学公式，表示 P(X, Y) = P(Y, X) = P(X|Y)P(Y) = P(Y|X)P(X)。
- en: 'From there, it follows that the joint distribution of features and targets
    (which can be equivalently written as P(X, Y) or P(Y, X) can be decomposed in
    two alternative and equivalent ways:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里可以得出，特征和目标的联合分布（可以等效地写作 P(X, Y) 或 P(Y, X)）可以通过两种不同但等效的方式进行分解：
- en: P(X|Y) * P(Y)
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: P(X|Y) * P(Y)
- en: P(Y|X) * P(X)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: P(Y|X) * P(X)
- en: This means that if any of the four elements above changes, P(X, Y) will also
    change, resulting in a data shift. The change of each of the four elements has
    its own name, its own causes, and its own solutions. Let’s take a look at them
    briefly.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果上述四个元素中的任何一个发生变化，P(X, Y) 也会发生变化，从而导致数据偏移。每个元素的变化都有其自己的名称、原因和解决方案。让我们简要看一下它们。
- en: 'Side note: I said that each of the four elements can change, leading to a data
    shift. But of course, there is no rule forbidding multiple of the four elements
    to change at the same time. In fact, they often do, causing the resulting data
    shift to be a multifaceted and complex phenomenon. In this article, however, let’s
    assume only one of the four changes at any given time.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 旁注：我说过四个元素中的每一个都可能发生变化，从而导致数据偏移。但当然，并没有规则禁止四个元素中的多个同时发生变化。事实上，它们经常同时变化，导致数据偏移变成一个多面且复杂的现象。然而，在本文中，我们假设在任何给定时刻，四个元素中只有一个发生变化。
- en: So, back to the four types of data shift.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，回到四种数据偏移类型。
- en: If P(X) changes (and P(Y|X) remains unchanged), we are talking about *covariate
    shift*. The name makes a lot of sense once we realize that covariate is just another
    term for the feature or the independent variable in a model. Covariate shift is
    when the distribution of the model inputs changes.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 P(X) 发生变化（且 P(Y|X) 不变），我们就谈论*协变量偏移*。一旦我们意识到协变量只是模型中的特征或自变量的另一种说法，这个名称就非常合理。协变量偏移是指模型输入的分布发生变化。
- en: If P(Y) changes (but P(X|Y) remains unchanged), we are talking about a *label
    shift*. It means the output distribution changed, but for any given output, the
    input distribution stays the same.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 P(Y) 发生变化（但 P(X|Y) 不变），我们就谈论*标签偏移*。这意味着输出分布发生了变化，但对于任何给定的输出，输入分布保持不变。
- en: If P(Y|X) changes (but P(X) remains unchanged), that’s the *concept shift*,
    the topic of this article. We will explore it in detail soon.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 P(Y|X) 发生变化（但 P(X) 不变），那就是*概念偏移*，本文的主题。我们将很快详细探讨它。
- en: Finally, the situation in which P(X|Y) changes while P(Y) remains the same is
    known as *manifestation shift*. It means that the same target values manifest
    themselves differently in the input distribution. We won’t cover manifestation
    shifts here, leaving it for a separate article.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，P(X|Y) 发生变化，而 P(Y) 保持不变的情况被称为*表现偏移*。这意味着相同的目标值在输入分布中以不同的方式表现出来。我们在这里不会讨论表现偏移，将它留到另一个单独的文章中。
- en: Out of the four types of data shift, covariate shift and concept shift are the
    most widely discussed and are arguably the major concerns for most companies having
    ML models serving predictions in production. Let’s discuss detecting the two to
    see how concept shift detection introduces new challenges compared to covariate
    shift detection.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在四种数据偏移类型中，协变量偏移和概念偏移是讨论最多的，也是大多数公司在生产环境中使用机器学习模型进行预测时最为关注的问题。让我们讨论如何检测这两种偏移，看看概念偏移检测相比协变量偏移检测带来了哪些新的挑战。
- en: Detecting data shifts
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测数据偏移
- en: 'Covariate shift is arguably easier to both understand and detect. Let’s revisit:
    it’s a situation in which P(X) changes. In other words, the distribution of the
    model’s input features at serving time is different from the one it has seen in
    training.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 协变量偏移无疑更容易理解和检测。让我们再回顾一下：这是指 P(X) 发生变化。换句话说，模型在服务时输入特征的分布与其在训练时所见的不同。
- en: 'In the vast majority of cases, one has access to both training features and
    serving features. It’s enough to compare their distributions: if they differ,
    a covariate shift has happened.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在绝大多数情况下，既有训练特征也有服务特征。只需比较它们的分布：如果它们不同，则发生了协变量漂移。
- en: Alright, that’s an oversimplification. In reality, there are two approaches
    to measuring covariate shift. We can look at it in a univariate way by checking
    if the distribution of one or more of the features has changed, or in a multivariate
    way where we focus on the joint distribution of all features.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这个例子有些过于简化。实际上，测量协变量漂移有两种方法。我们可以通过检查一个或多个特征的分布是否发生变化，从单变量角度进行分析，或者从多变量角度，关注所有特征的联合分布。
- en: In the univariate approach, one can [compare training and serving distributions
    using statistical tests and distance measures](/how-to-detect-data-drift-with-hypothesis-testing-1a3be3f8e625),
    feature by feature. In the multivariate approach, [a more nuanced approach based
    on PCA is a good way to go](/detecting-covariate-shift-a-guide-to-the-multivariate-approach-c099bd1891b9).
    But in either case, the task is to compare two observed quantities and decide
    whether they are truly different or not.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在单变量方法中，可以通过[使用统计检验和距离度量比较训练分布和服务分布](/how-to-detect-data-drift-with-hypothesis-testing-1a3be3f8e625)，逐个特征地进行比较。在多变量方法中，[基于PCA的更细致方法是一个不错的选择](/detecting-covariate-shift-a-guide-to-the-multivariate-approach-c099bd1891b9)。但无论哪种方法，任务都是比较两个观察到的量，并决定它们是否真的不同。
- en: 'In the case of concept shift, the challenge of shift detection is more involved.
    Let’s revisit: concept shift is when P(Y|X) changes, that is, for given feature
    values, the target distribution changes.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在概念漂移的情况下，漂移检测的挑战更加复杂。我们再来看一下：概念漂移是当P(Y|X)发生变化时，也就是说，对于给定的特征值，目标分布发生了变化。
- en: The tricky part is in measuring and comparing P(Y|X), often referred to as the
    *concept.* It’s not a single quantity that can be easily calculated. It’s the
    true mapping, or relation, between inputs and outputs. We know it for the training
    data (to the best of our model’s ability), but how can we know when it changes
    in the real world? Let’s see!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 难点在于如何衡量和比较P(Y|X)，通常称之为*概念*。它不是一个可以轻松计算的单一量。它是输入和输出之间的真实映射或关系。我们知道训练数据的P(Y|X)（根据我们模型的能力），但是我们如何知道它在现实世界中何时发生了变化呢？让我们来看一下！
- en: Concept shift detection in the wild
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 野外中的概念漂移检测
- en: Thanks for bearing with me through this rather lengthy introduction! Now that
    we know what concept shift is and why it’s challenging to detect, let’s discuss
    it in greater detail, following a practical example.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你耐心阅读这段较长的引言！现在我们知道了什么是概念漂移以及为什么它很难检测，让我们通过一个实际的例子进一步讨论这个问题。
- en: Concept shift in time & space
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间与空间中的概念漂移
- en: 'Concept shift means that for specific inputs, the distribution of the output
    has changed (P(Y|X) has changed, remember?). This change can occur in either of
    the two dimensions: in time or space.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移意味着对于特定的输入，输出的分布发生了变化（P(Y|X)发生了变化，记住了吗？）。这种变化可以发生在时间或空间的两个维度中的任何一个。
- en: Concept shift in time means that the concept the model has learned during training
    has since then changed in the real world. In other words, the model’s knowledge
    is not up-to-date anymore.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 时间上的概念漂移意味着模型在训练期间学到的概念在现实世界中发生了变化。换句话说，模型的知识已经不再是最新的了。
- en: 'Let me borrow an example from Chip Huyen’s fantastic book “*Designing Machine
    Learning Systems*”: imagine you’re building a model to predict housing prices
    in San Francisco. Before the coronavirus pandemic, a three-bedroom apartment might
    have cost $2m, but because of the virus, many people have left the city, and as
    a result of declining demand, the same apartment could now cost $1.5m. The feature
    distributions P(X) have not changed: the houses still have the same number of
    bedrooms, square footage, etc. It’s just that the same set of inputs now maps
    to a different output.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我借用Chip Huyen在他的精彩著作《*设计机器学习系统*》中的一个例子：假设你正在构建一个预测旧金山房价的模型。在新冠疫情爆发之前，一套三居室公寓的价格可能是200万美元，但由于疫情，很多人离开了城市，需求下降，导致同样的公寓现在的价格可能是150万美元。特征分布P(X)没有变化：房子仍然有相同数量的卧室、相同的面积等。只是相同的一组输入现在映射到一个不同的输出。
- en: Concept shift in space when a concept learned from data from a particular geography
    or a particular set of users is not relevant for different regions or user bases.
    For example, adding 50 square feet to a San Francisco apartment can result in
    a significant price increase. However, the same addition to a house in rural Wyoming,
    where the housing market is much less competitive, might not translate to an equally
    large price increase.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 空间上的概念漂移发生在从特定地理位置或特定用户集数据中学习到的概念不适用于其他地区或用户群体。例如，给旧金山的公寓增加50平方英尺的面积可能导致价格大幅上涨。然而，向怀俄明州的乡村房屋添加相同的面积，因当地住房市场竞争较少，可能不会导致同样的价格上涨。
- en: Alright, so what we know so far is that concept shift might be a problem when
    either some time has passed since model deployment, or when the model starts serving
    different users or geographies. But how do we go about detecting it?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么到目前为止，我们知道概念漂移可能是一个问题，无论是在模型部署后经过了一段时间，还是当模型开始为不同的用户或地理区域提供服务时。那么，我们该如何检测它呢？
- en: Detecting concept shift
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测概念漂移
- en: 'Imagine this: you train your San Francisco house pricing model on all available
    data and deploy it to production. Afterward, you collect the features that the
    model receives for inference and store them in daily batches.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下：你用所有可用数据训练你的旧金山房价预测模型并投入生产。之后，你收集模型用于推理时接收的特征，并按日存储这些特征批次。
- en: '![](../Images/6bef8a3560f8092a63ddaee52ef3f3f8.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6bef8a3560f8092a63ddaee52ef3f3f8.png)'
- en: Training and serving data sets. Image by the author.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和服务数据集。图像由作者提供。
- en: Here, *X-serve-0* are the features from the day of deployment, *X-serve-1* are
    the features from the following day, and so on, while *y-serve-** denotes the
    corresponding targets.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*X-serve-0* 是部署当天的特征，*X-serve-1* 是次日的特征，依此类推，而 *y-serve-0* 表示相应的目标值。
- en: 'It’s day 0 today: the model trained on data up until yesterday is now in production.
    Are today’s data (*X-serve-0* and *y-serve-0*) subject to concept shift?'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 今天是零日：模型已基于昨天的数据进行训练并投入生产。那么，今天的数据（*X-serve-0* 和 *y-serve-0*）是否发生了概念漂移呢？
- en: Let’s assume for a moment that this is a binary question. In practice, of course,
    concept shift can be large or small and impact model performance heavily or not
    very much. But for now, let’s say that concept shift has either happened on day
    0 or not.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设这是一个二元问题。当然，实际上，概念漂移可能是大规模的，也可能是小规模的，而且对模型性能的影响也可能很大或很小。但现在，让我们假设概念漂移在零日时已经发生或没有发生。
- en: 'Here’s an idea: let’s train a model on day 0 data. If there was no concept
    shift, it should learn the same features-to-target mapping that our production
    model has learned. If concept shift occurred, the learned mapping will be different.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个思路：我们在零日数据上训练一个模型。如果没有发生概念漂移，它应该学会与生产模型相同的特征到目标的映射。如果发生了概念漂移，学习到的映射将会不同。
- en: '![](../Images/1b3750236f177775215c26c9456b7fea.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b3750236f177775215c26c9456b7fea.png)'
- en: Concept shift detection mechanism. Image by the author.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移检测机制。图像由作者提供。
- en: 'Next, let’s use this day-0 model to make predictions for test data: we just
    feed it *X-test*. If the outputs are close to the test-set predictions from the
    production model*,* it means that our day-0 model has learned the same P(Y|X),
    or the same concept, as our production model. Therefore, we proclaim no concept
    shift. If the outputs are different, however, then concept shift must have happened.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用这个零日模型来对测试数据进行预测：我们只需输入*X-test*。如果输出结果与生产模型的测试集预测值接近，*这意味着我们的零日模型已经学会了与生产模型相同的P(Y|X)，或者说学会了相同的概念*。因此，我们可以宣告没有概念漂移。如果输出结果不同，那么概念漂移肯定已经发生。
- en: We can detect concept shift by training a model on serving data and comparing
    it to the production model.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们可以通过在服务数据上训练一个模型并与生产模型进行比较，从而检测概念漂移。
- en: We can repeat this process daily with every new batch of data we receive in
    serving to keep refreshing our knowledge of whether a concept shift has happened
    or not.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以每天重复这一过程，每当收到新的数据批次时，就刷新对概念漂移是否发生的了解。
- en: 'Concept shift: detection vs. impact on performance'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概念漂移：检测与对性能的影响
- en: 'This is all nice, but there is one caveat to it, which a watchful reader might
    have spotted already. The outputs from the *day-** models will never be exactly
    the same as the ones from the production model: even in the absence of any shift,
    the sampling error (different sample of training data) will lead to slightly different
    results. How large differences do actually signal concept shift? Or, to rephrase
    this question more practically: when do we need to retrain the model?'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都很好，但有一个警告，警觉的读者可能已经注意到了。*日常模型*的输出永远不会和生产模型的输出完全相同：即使没有任何漂移，抽样误差（不同的训练数据样本）也会导致稍微不同的结果。那么，实际上多大的差异才意味着概念漂移呢？或者更实际地说，什么时候我们需要重新训练模型？
- en: Indeed, not every difference should call for retraining, which could be a costly
    or complex procedure. As mentioned above, the difference might sometimes be the
    result of random sampling, in which case no retraining is necessary. On other
    occasions, the difference might actually be caused by the concept shift, but one
    that’s not impacting the model in a meaningful way. In this case, retraining is
    not needed either.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，并不是每个差异都需要重新训练模型，因为重新训练可能是一个昂贵或复杂的过程。如上所述，差异有时可能是随机抽样的结果，这种情况下不需要重新训练。在其他情况下，差异可能确实是由概念漂移引起的，但这种漂移对模型的影响不大。在这种情况下，也不需要重新训练。
- en: The key observation to take away here is that one should only retrain the model
    when the concept shift is meaningfully impacting the model’s performance.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键观察是，只有当概念漂移显著影响模型性能时，才应该重新训练模型。
- en: One should only retrain the model when the concept shift is meaningfully impacting
    the model’s performance.
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 只有当概念漂移显著影响模型性能时，才应重新训练模型。
- en: 'So how do we tell how much is the performance impacted by concept shift? Let’s
    flip this question: are there situations where concept shift occurs but does not
    hurt the model’s performance?'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何判断概念漂移对性能的影响有多大呢？我们换个角度来看这个问题：是否有一些情况，概念漂移发生了，但并没有影响模型的性能？
- en: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
- en: Harmless concept shift
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无害的概念漂移
- en: Imagine that your San Francisco house pricing model is now a classification
    model in which you are predicting whether a house costs more or less than $1m
    given its features. You have followed the steps described above to find large
    differences between the outputs of the production model and the current-day model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你的旧金山房价预测模型现在是一个分类模型，你正在预测一栋房子的价格是否超过100万美元，基于其特征。你已经按照上述步骤，发现生产模型和当前模型之间有很大的差异。
- en: Unchanged predicted labels
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测标签没有变化
- en: Here is the plot showing the differences in the probability of the house costing
    more than $1m from the two models for a subset of 10 data points.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个图表，显示了两个模型在一个包含10个数据点的子集上，预测房子价格超过100万美元的概率差异。
- en: '![](../Images/baa635b782a882e366827284c4ea5be7.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/baa635b782a882e366827284c4ea5be7.png)'
- en: Concept shift is harmless if final predictions don’t change. Image by the author.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果最终的预测结果没有变化，概念漂移是无害的。图片来自作者。
- en: There are three important observations to be made here. First, the two models
    predict completely different probabilities. The difference is large for each data
    point and can be as significant as close to 50 percentage points. We can be almost
    certain that a significant concept shift has occurred.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有三个重要的观察结果。首先，两个模型预测的概率完全不同。对于每个数据点，差异都很大，可能接近50个百分点。我们几乎可以确定已经发生了显著的概念漂移。
- en: Second, there is no consistency in the two models’ relative outputs. Sometimes
    one produces a much higher probability than the other, sometimes the other way
    round.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，两个模型的相对输出不一致。有时一个模型的概率远高于另一个模型，有时则相反。
- en: Third, the concept shift we are experiencing is completely harmless for the
    model. Wait, what? That’s right! Although significant, the concept shift we’re
    dealing with will not impact the model performance at all!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，我们遇到的概念漂移对模型是完全无害的。等等，什么？没错！尽管概念漂移显著，但我们所面对的概念漂移对模型性能没有任何影响！
- en: Concept shift does not always impact model performance.
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 概念漂移并不总是影响模型性能。
- en: 'Recall we’re looking at a binary classification task. Given a customary decision
    threshold at 50%, for each data point, both models will yield the same prediction:
    data points 2, 3, 4, 5, and 8 correspond to positive predictions (price above
    $1m), and the remaining ones — to negative predictions. Performance metrics such
    as accuracy, precision, recall, or f1-score will be the same for both models (ROC
    AUC will be impacted, though, since it uses the model scores rather than just
    class assignments).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们正在处理一个二分类任务。假设使用常见的50%的决策阈值，对于每个数据点，两个模型将得出相同的预测：数据点2、3、4、5和8对应于正预测（价格超过100万美元），其余的对应于负预测。像准确率、精确度、召回率或F1得分这样的性能指标在两个模型中是相同的（不过ROC
    AUC会受到影响，因为它使用模型分数而不仅仅是类别标签）。
- en: 'I admit that this example is artificial and has been deliberately drafted to
    show what I’m trying to convey: that concept shift need not impact performance.
    But fair enough — in reality, one would rarely ever just use the predicted labels
    while disregarding certainty scores. Let’s look at another, arguably more realistic
    scenario in which concept shift will not hurt you.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我承认这个例子是人为构造的，故意设计来展示我想表达的内容：即概念漂移不一定会影响性能。但也可以理解——实际上，人们很少只使用预测标签而忽略置信度分数。让我们来看另一个可能更现实的场景，在这种情况下，概念漂移不会对你造成伤害。
- en: Shift in sparse regions
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稀疏区域的漂移
- en: Model features constitute a multidimensional space, and each training example
    is a point in this space. If you only had two features, x1 and x2, you could plot
    each example as a point on a two-dimensional plane — the feature space. With three
    features, each example will be a point inside a cube. In the more common situations
    of using four features or more, our brains fail to imagine the scene, but still,
    each example is a point in the feature space.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 模型特征构成了一个多维空间，每个训练样本都是这个空间中的一个点。如果只有两个特征，x1和x2，你可以在二维平面上绘制每个样本作为一个点——特征空间。如果有三个特征，每个样本将是一个立方体中的一个点。在更常见的使用四个特征或更多特征的情况下，我们的大脑无法想象这种场景，但每个样本依然是特征空间中的一个点。
- en: The training examples are not uniformly distributed across the feature space.
    Some areas within the feature space will be densely packed by data points, while
    elsewhere they will be quite sparse. Another way to think about it is that in
    your data, some combinations of feature values are frequent and others very rare.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 训练样本在特征空间中的分布并不均匀。特征空间中的某些区域数据点密集，而其他区域则非常稀疏。换句话说，在你的数据中，某些特征值的组合是常见的，而其他的则非常罕见。
- en: 'Now, here’s the thing: concept shift might occur in any region within the feature
    space. If it happens to be in a sparse region, its impact on the model’s performance
    will be minor. This is because there is not much training nor serving data in
    this region. Thus, the model will hardly ever get to predict in this region. Any
    misclassifications caused by the concept shift in a sparse region will be rare
    events, not contributing much to the model’s overall performance.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，问题是：概念漂移可能发生在特征空间的任何区域。如果它发生在一个稀疏区域，对模型性能的影响将会很小。这是因为在该区域内没有多少训练数据或服务数据。因此，模型几乎不会在该区域进行预测。由于概念漂移导致的稀疏区域的误分类将是罕见事件，对模型的整体性能贡献不大。
- en: Misclassifications caused by the concept shift in a sparse region will be rare
    events, not contributing much to the model’s overall performance.
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于概念漂移导致的稀疏区域的误分类将是罕见事件，对模型的整体性能贡献不大。
- en: The takeaway from the two stories above is that some concept shifts are harmless,
    and only a meaningfully negative impact on performance calls for model retraining.
    Once you have detected a concept shift, estimate its impact on your model first
    before taking unnecessary action!
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 上面两个故事的启示是，某些概念漂移是无害的，只有对性能有实质性负面影响时才需要重新训练模型。一旦你检测到概念漂移，首先评估它对模型的影响，然后再采取不必要的行动！
- en: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
- en: Tools for concept shift detection
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念漂移检测工具
- en: 'We could summarize our whole discussion up to this point as: don’t focus on
    the shift’s presence. Detect its impact on performance instead.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将到目前为止的整个讨论总结为：不要关注漂移的存在，而要检测其对性能的影响。
- en: 'However, this is not how people typically do it. A quick web search reveals
    that most approaches to concept shift detection (such as [this one from DeepChecks
    blog](https://deepchecks.com/how-to-detect-concept-drift-with-machine-learning-monitoring/)
    or [this one from Evidently AI](https://www.evidentlyai.com/ml-in-production/concept-drift#how-to-detect-concept-drift))
    work indirectly: they are typically based on detecting the prediction drift, label
    drift, or data drift.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是人们通常的做法。快速的网络搜索显示，大多数概念漂移检测方法（例如[DeepChecks博客中的这个方法](https://deepchecks.com/how-to-detect-concept-drift-with-machine-learning-monitoring/)或[Evidently
    AI中的这个方法](https://www.evidentlyai.com/ml-in-production/concept-drift#how-to-detect-concept-drift)）通常是间接的：它们通常基于检测预测漂移、标签漂移或数据漂移。
- en: The only tool I found that claims to be able to directly detect the magnitude
    of concept shift, and more importantly to quantify its impact on model performance
    as we have just discussed, is NannyML. I contacted the team and was told that
    besides being available as a standalone algorithm on [AWS](https://aws.amazon.com/marketplace/pp/prodview-64nptz3lrs4gc)
    (which had appeared in my search), it is also available as an [Azure managed app](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/nannyml1682590100745.nannyml-managed?tab=Overview).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现的唯一一个声称能够直接检测概念漂移的幅度，并且更重要的是量化其对模型性能影响的工具是NannyML。我联系了该团队，他们告诉我，除了可以作为独立算法在[AWS](https://aws.amazon.com/marketplace/pp/prodview-64nptz3lrs4gc)上使用（这也是我搜索时看到的），它还可以作为[Azure托管应用](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/nannyml1682590100745.nannyml-managed?tab=Overview)使用。
- en: This approach follows the previously discussed workflow. Every day after deployment,
    a day-model is trained on serving data collected on this particular day. Next,
    we look at the predicted probabilities that our day-model produced for the training
    data and compare them with the ones from the production model. These differences
    let us estimate the shift’s impact on performance metrics such as ROC AUC, accuracy,
    and others.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法遵循之前讨论的工作流程。每次部署后，我们都会使用当天收集的服务数据训练一个日模型。接下来，我们查看日模型对训练数据预测的概率，并将其与生产模型的预测结果进行比较。这些差异使我们能够估计变化对性能指标（如ROC
    AUC、准确率等）的影响。
- en: I used the free trial to see how to estimate the performance implications of
    a concept shift in practice for a classification task. And no, it won’t be about
    San Francisco housing again.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了免费试用来看看如何在实际中估算概念漂移对分类任务性能的影响。不，这次不会再讨论旧金山的住房问题了。
- en: Consider flight cancellations. They are primarily driven by operational factors
    like weather conditions or airline-specific problems. We can use these features
    to quite reliably predict whether a given flight will be canceled or not.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑航班取消问题。它们主要受天气状况或航空公司特定问题等运营因素的驱动。我们可以利用这些特征来相当可靠地预测某个航班是否会被取消。
- en: Or at least that was the case until the end of the year 2019\. With the onset
    of the COVID-19 pandemic, travel restrictions, lockdowns, and a sharp decrease
    in travel demand led to a significant increase in flight cancellations, fundamentally
    changing the relationship between factors such as weather and cancellations. For
    example, good weather did not guarantee fewer cancellations anymore.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 或者至少在2019年底之前是这样。随着COVID-19大流行的爆发，旅行限制、封锁措施以及旅行需求的急剧下降导致航班取消数量显著增加，彻底改变了天气等因素与取消之间的关系。例如，良好的天气再也不能保证航班取消数量减少了。
- en: Let’s train a model to predict cancellations on data up to the year 2018, and
    treat years 2019 through 2023 as our serving data based on the [data from the
    Bureau of Transportation Statistics](https://www.transtats.bts.gov/homedrillchart.asp).
    Here’s what NannyML’s concept shift detection algorithm outputs.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们训练一个模型，预测2018年之前的数据的航班取消情况，并将2019年至2023年作为我们的服务数据，数据来源于[运输统计局的数据](https://www.transtats.bts.gov/homedrillchart.asp)。这是NannyML的概念漂移检测算法输出的结果。
- en: '![](../Images/ac91e608bb1d4382a93e0e06171639a1.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac91e608bb1d4382a93e0e06171639a1.png)'
- en: NannyML’s concept shift detection. Image by the author.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: NannyML的概念漂移检测。图像来源：作者。
- en: During the first year after deployment, 2019, no significant concept shift seems
    to have happened. Our thresholds for meaningful performance change were not crossed.
    The following year, however, as the pandemic broke out, our cancellation classifier
    lost 6 accuracy percentage points! Interestingly, the following year, things roughly
    got back to their pre-pandemic state.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署后的第一年，即2019年，似乎没有发生显著的概念变化。我们设定的有意义的性能变化阈值并未突破。然而，第二年，当疫情爆发时，我们的取消分类器准确率下降了6个百分点！有趣的是，第三年，情况大致恢复到了疫情前的状态。
- en: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
- en: Considerations & Conclusion
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑与结论
- en: 'A Concept shift is a change in the mapping between features and targets, while
    the features themselves remain unchanged. Think of it as: the same inputs, different
    outputs. It’s arguably harder to detect than its evil twin, covariate shift, in
    which the features’ distributions change.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移是特征与目标之间映射的变化，而特征本身保持不变。可以理解为：相同的输入，不同的输出。与其“邪恶双胞胎”协变量漂移相比，概念漂移更难以检测，后者是特征的分布发生变化。
- en: A clever way of detecting concept shift is to regularly train models on incoming
    serving data and compare the concept they learn to the concept learned by the
    production model. If they are different, concept shift must have happened. This
    approach has some limitations, though. It assumes that the targets for the serving
    data are available, which is not the case in many applications.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 检测概念漂移的一个巧妙方法是定期在传入的服务数据上训练模型，并将其学习到的概念与生产模型所学习到的概念进行比较。如果它们不同，说明概念漂移已经发生。然而，这种方法也有一些局限性。它假设服务数据的目标是可用的，而在许多应用中并非如此。
- en: Finally, not all concept shift is bad. In some situations, however, it can negatively
    impact the performance of your models in production, and by extension, the business
    value delivered by these models. By following the approach outlined above, you
    can quantify your concept shift’s impact and ensure your ML models continue to
    provide value.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，并不是所有的概念漂移都是坏事。然而，在某些情况下，它可能会对你的生产模型性能产生负面影响，从而影响这些模型所带来的商业价值。通过遵循上面概述的方法，你可以量化概念漂移的影响，并确保你的机器学习模型继续提供价值。
- en: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc5b3128f07866fbee190bbda8a97d94.png)'
- en: Thanks for reading!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: If you liked this post, why don’t you [**subscribe for email updates**](https://michaloleszak.medium.com/subscribe)
    on my new articles? By [**becoming a Medium member**](https://michaloleszak.medium.com/membership),
    you can support my writing and get unlimited access to all stories by other authors
    and yours truly. Need consulting? You can ask me anything or book me for a 1:1
    [**here**](https://topmate.io/michaloleszak).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，为什么不[**订阅电子邮件更新**](https://michaloleszak.medium.com/subscribe)获取我的新文章？通过[**成为
    Medium 会员**](https://michaloleszak.medium.com/membership)，你可以支持我的写作，并且获得其他作者及我本人的所有故事的无限访问权限。需要咨询？你可以随时问我问题，或者[**在这里预约一对一咨询**](https://topmate.io/michaloleszak)。
- en: 'You can also try one of [my other articles](https://michaloleszak.github.io/blog/).
    Can’t choose? Pick one of these:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以尝试阅读[我的其他文章](https://michaloleszak.github.io/blog/)。无法选择？试试以下这些：
- en: '[](/how-to-detect-data-drift-with-hypothesis-testing-1a3be3f8e625?source=post_page-----16923261cda8--------------------------------)
    [## How to Detect Data Drift with Hypothesis Testing'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-detect-data-drift-with-hypothesis-testing-1a3be3f8e625?source=post_page-----16923261cda8--------------------------------)
    [## 如何通过假设检验检测数据漂移'
- en: 'Hint: forget about the p-values'
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示：忘记 p 值吧
- en: towardsdatascience.com](/how-to-detect-data-drift-with-hypothesis-testing-1a3be3f8e625?source=post_page-----16923261cda8--------------------------------)
    [](/organizing-a-machine-learning-monorepo-with-pants-8e0570de0c4c?source=post_page-----16923261cda8--------------------------------)
    [## Organizing a Machine Learning Monorepo with Pants
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-detect-data-drift-with-hypothesis-testing-1a3be3f8e625?source=post_page-----16923261cda8--------------------------------)
    [](/organizing-a-machine-learning-monorepo-with-pants-8e0570de0c4c?source=post_page-----16923261cda8--------------------------------)
    [## 使用 Pants 组织机器学习单一代码库
- en: Streamline your ML workflow management
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简化你的机器学习工作流管理
- en: towardsdatascience.com](/organizing-a-machine-learning-monorepo-with-pants-8e0570de0c4c?source=post_page-----16923261cda8--------------------------------)
    [](/self-supervised-learning-in-computer-vision-fd43719b1625?source=post_page-----16923261cda8--------------------------------)
    [## Self-Supervised Learning in Computer Vision
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/organizing-a-machine-learning-monorepo-with-pants-8e0570de0c4c?source=post_page-----16923261cda8--------------------------------)
    [](/self-supervised-learning-in-computer-vision-fd43719b1625?source=post_page-----16923261cda8--------------------------------)
    [## 计算机视觉中的自监督学习'
- en: How to train models with only a few labeled examples
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何仅通过少量标记样本训练模型
- en: towardsdatascience.com](/self-supervised-learning-in-computer-vision-fd43719b1625?source=post_page-----16923261cda8--------------------------------)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/self-supervised-learning-in-computer-vision-fd43719b1625?source=post_page-----16923261cda8--------------------------------)
