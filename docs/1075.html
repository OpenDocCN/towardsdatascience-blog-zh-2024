<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Transform Data with Hyperbolic Sine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Transform Data with Hyperbolic Sine</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transform-data-with-hyperbolic-sine-e39e9275b6ba?source=collection_archive---------3-----------------------#2024-04-29">https://towardsdatascience.com/transform-data-with-hyperbolic-sine-e39e9275b6ba?source=collection_archive---------3-----------------------#2024-04-29</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="7b09" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><em class="hd">Why handling negative values should be a cinch</em></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@david.kyle_13073?source=post_page---byline--e39e9275b6ba--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="David Kyle" class="l ep by dd de cx" src="../Images/536175491ed7f89d03a4e528a986bf8a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*jSqt6z57gywmvh3b3x6zUA.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e39e9275b6ba--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@david.kyle_13073?source=post_page---byline--e39e9275b6ba--------------------------------" rel="noopener follow">David Kyle</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e39e9275b6ba--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 29, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk ld le ab q ee lf lg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lb lc">1</span></p></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lh k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al li an ao ap ie lj lk ll" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lm cn"><div class="l ae"><div class="ab cb"><div class="ln lo lp lq lr ls ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml mm"><img src="../Images/f9953f39cfbd1e188cffa967e1745689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*epRv9ArHlvR-Awz8"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Photo by <a class="af nd" href="https://unsplash.com/@osmanrana?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Osman Rana</a> on <a class="af nd" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2708" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Many models are sensitive to outliers, such as <a class="af nd" href="https://medium.com/swlh/how-outliers-can-pose-a-problem-in-linear-regression-1431c50a8e0" rel="noopener">linear regression</a>, <a class="af nd" rel="noopener" target="_blank" href="/k-nearest-neighbors-knn-algorithm-23832490e3f4">k-nearest neighbor</a>, and <a class="af nd" rel="noopener" target="_blank" href="/limitations-of-arima-dealing-with-outliers-30cc0c6ddf33">ARIMA</a>. Machine learning algorithms suffer from over-fitting and may not generalize well in the presence of outliers.¹ However, the right transformation can shrink these extreme values and improve your model’s performance.</p><p id="1e5d" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Transformations for data with negative values include:</p><ol class=""><li id="c7ab" class="ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk"><strong class="ng fr">Shifted Log</strong></li><li id="fcfb" class="ne nf fq ng b go od ni nj gr oe nl nm nn of np nq nr og nt nu nv oh nx ny nz oa ob oc bk"><strong class="ng fr">Shifted Box-Cox</strong></li><li id="e405" class="ne nf fq ng b go od ni nj gr oe nl nm nn of np nq nr og nt nu nv oh nx ny nz oa ob oc bk"><strong class="ng fr">Inverse Hyperbolic Sine</strong></li><li id="6475" class="ne nf fq ng b go od ni nj gr oe nl nm nn of np nq nr og nt nu nv oh nx ny nz oa ob oc bk"><strong class="ng fr">Sinh-arcsinh</strong></li></ol><p id="ae27" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Log and Box-Cox are effective tools when working with positive data, but inverse hyperbolic sine (arcsinh) is much more effective on negative values.</p><p id="ac6a" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Sinh-arcsinh is even more powerful. It has two parameters that can adjust the <em class="oi">skew</em> and <em class="oi">kurtosis </em>of your data to make it close to normal. These parameters can be derived using gradient descent. See an implementation in python at the end of this post.</p><h1 id="fc9a" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">Shifted Log</h1><p id="b816" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">The log transformation can be adapted to handle negative values with a shifting term <em class="oi">α</em>.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/99c6c190ddd6505638f2678eb47efe0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i1Lkjr_D-aq2n7opxNDFzw.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Throughout the article, I use log to mean natural log.</figcaption></figure><p id="bd0d" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Visually, this is moving the log’s vertical asymptote from 0 to <em class="oi">α.</em></p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pl"><img src="../Images/b23b4614a839d9a61ce842cc05f28bee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjYY70j7IH6eMgLn4meU4w.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Plot of shifted log transformation with offset of <em class="hd">-5, made with </em><a class="af nd" href="https://www.desmos.com/calculator" rel="noopener ugc nofollow" target="_blank"><em class="hd">Desmos</em></a><em class="hd"> available under </em><a class="af nd" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a>. Equation text added to image.</figcaption></figure><h2 id="4665" class="pm ok fq bf ol pn po pp oo pq pr ps or nn pt pu pv nr pw px py nv pz qa qb qc bk">Forecasting Stock Prices</h2><p id="1df8" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">Imagine you are a building a model to predict the stock market. Hosenzade and Haratizadeh tackle this problem with a convolutional neural network using a large set of feature variables that I have pulled from <a class="af nd" href="https://archive.ics.uci.edu/" rel="noopener ugc nofollow" target="_blank">UCI Irvine Machine Learning Repository</a>². Below is distribution of the change of volume feature — an important technical indicator for stock market forecasts.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qd"><img src="../Images/cb8996afed994306181c18ac2606825b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xBOoW29TGGlfFsxopyW8hA.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">made with Matplotlib</figcaption></figure><p id="4217" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The <a class="af nd" rel="noopener" target="_blank" href="/significance-of-q-q-plots-6f0c6e31c626">quantile-quantile (QQ) plot</a> reveals heavy right and left tails. The goal of our transformation will be to bring the tails closer to normal (the red line) so that it has no outliers.</p><p id="afb9" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Using a shift value of -250, I get this log distribution.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qe"><img src="../Images/9762e83d81f0bcc42223528b8d72e848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AJ4JxYhROzhCmJry9hYrpQ.png"/></div></div></figure><p id="3dcb" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The right tail looks a little better, but the left tail still shows deviation from the red line. Log works by applying a concave function to the data which skews the data left by compressing the high values and stretching out the low values.</p><blockquote class="qf qg qh"><p id="9668" class="ne nf oi ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk"><strong class="ng fr">The log transformation only makes the right tail lighter.</strong></p></blockquote><p id="c7aa" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">While this works well for positively skewed data, it is less effective for data with negative outliers.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qi"><img src="../Images/c022841ba714b40e16e78b07f5e0bfae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cl-qVrcXij6c3M1hBxSjqg.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx"><em class="hd">made with </em><a class="af nd" href="https://www.desmos.com/calculator" rel="noopener ugc nofollow" target="_blank"><em class="hd">Desmos</em></a><em class="hd"> available under </em><a class="af nd" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a>. Text and arrows added to image.</figcaption></figure><p id="d46d" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">In the stock data, skewness is not the issue. The extreme values are on both left and right sides. The <em class="oi">kurtosis </em>is high, meaning that both tails are heavy. A simple concave function is not equipped for this situation.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qj"><img src="../Images/dd5ccbccc9db1cd0fcfc02d79bddc6b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vB-kWraUzSwcLM7D8o7BXA.png"/></div></div></figure><h1 id="0fc2" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">Shifted Box-Cox</h1><p id="9069" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">Box-Cox is a generalized version of log, which can also be shifted to include negative values, written as</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/35718e7af8786adef4b75da40dd17dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pOiAHX74Hgyx4xiut5wiJA.png"/></div></div></figure><p id="3d01" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The <em class="oi">λ</em> parameter controls the concavity of the transformation allowing it to take on a variety of forms. Box-cox is quadratic when <em class="oi">λ</em> = 2. It’s linear when <em class="oi">λ</em> = 1, and log as <em class="oi">λ</em> approaches 0. This can be verified by using L’Hôpital’s rule.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/0cbf359a4587fca43a715f1fa106fbdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VXmQQ-82oAo7H4VPgiBXkw.png"/></div></div></figure><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qk"><img src="../Images/672b9b7574cb3fc0e11b5d3c5d1cfd53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mW_7fcLK41jpOBTLESbEdA.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Plot of shifted box-cox transformation with shift <em class="hd">-5 and five different values for λ, made with </em><a class="af nd" href="https://www.desmos.com/calculator" rel="noopener ugc nofollow" target="_blank"><em class="hd">Desmos</em></a><em class="hd"> available under </em><a class="af nd" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a>. Text added to image.</figcaption></figure><p id="777d" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">To apply this transformation on our stock price data, I use a shift value -250 and determine <em class="oi">λ </em>with scipy's <code class="cx ql qm qn qo b">boxcox</code> function.</p><pre class="mn mo mp mq mr qp qo qq bp qr bb bk"><span id="4574" class="qs ok fq qo b bg qt qu l qv qw">from scipy.stats import boxcox<br/>y, lambda_ = boxcox(x - (-250))</span></pre><p id="ff4f" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The resulting transformed data looks like this:</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qx"><img src="../Images/4b2fcd3045616c56e3f19c0db0aa3ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G-3P60DjFN4xvXVdAwJjEw.png"/></div></div></figure><p id="2a31" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Despite the flexibility of this transformation, it fails to reduce the tails on the stock price data. Low values of <em class="oi">λ</em> skew the data left, shrinking the right tail. High values of <em class="oi">λ </em>skew the data right, shrinking the left tail, but there isn’t any value that can shrink both simultaneously.</p><h1 id="1c6b" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">Inverse Hyperbolic Sine</h1><p id="fe26" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">The hyperbolic sine function (sinh) is defined as</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/65ef55f997fba3e9932083583db2a288.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d5ju0FHcz4aCXBNk7kMUpQ.png"/></div></div></figure><p id="cb93" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">and its inverse is</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/6be839af43c14014259a6e3e424fee59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uxiyJ1OISzT3vr73ouA8cw.png"/></div></div></figure><p id="6caa" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">In this case, the inverse is a more helpful function because it’s approximately log for large <em class="oi">x</em> (positive or negative) and linear for small values of <em class="oi">x</em>. In effect, this shrinks extremes while keeping the central values, more or less, the same.</p><blockquote class="qf qg qh"><p id="f045" class="ne nf oi ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk"><strong class="ng fr">Arcsinh reduces both positive and negative tails.</strong></p></blockquote><p id="ba02" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">For positive values, arcsinh is concave, and for negative values, it’s convex. This change in curvature is the secret sauce that allows it to handle positive and negative extreme values simultaneously.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qk"><img src="../Images/15d87992438fa114983ffb31af99b23c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*glJtHk1HRZpYHsk79QxgwQ.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">plot of inverse hyperbolic sine (arcsinh) compared to a log function, <em class="hd">made with </em><a class="af nd" href="https://www.desmos.com/calculator" rel="noopener ugc nofollow" target="_blank"><em class="hd">Desmos</em></a><em class="hd"> available under </em><a class="af nd" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a>. Text, arrows, and box shape added to image.</figcaption></figure><p id="c661" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Using this transformation on the stock data results in near normal tails. The new data has no outliers!</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qy"><img src="../Images/aa54a96575ef16c793face51f9fe5557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*84Ej1ybfzWZMGbjNvXesSQ.png"/></div></div></figure><h2 id="4d0e" class="pm ok fq bf ol pn po pp oo pq pr ps or nn pt pu pv nr pw px py nv pz qa qb qc bk">Scale Matters</h2><p id="0e3e" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">Consider how your data is scaled before it’s passed into arcsinh.</p><p id="7e84" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">For log, your choice of units is irrelevant. Dollars or cents, grams or kilograms, miles or feet —it’s all the same to the log function. The scale of your inputs only shifts the transformed values by a constant value.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/3d27470fec2088c8429ee388b40f0239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y6KKSFDpojZ8DpY5wB3HYw.png"/></div></div></figure><p id="f7d8" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The same is not true for arcsinh. Values between -1 and 1 are left almost unchanged while large numbers are log-dominated. You may need to play around with different scales and offsets before feeding your data into arcsinh to get a result you are satisfied with.</p><p id="e3f1" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">At the end of the article, I implement a gradient descent algorithm in python to estimate these transformation parameters more precisely.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qj"><img src="../Images/237220229b36a2e0b15700f261721f04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oC_3h-4nuo7yT0UCa8kcaQ.png"/></div></div></figure><h1 id="c896" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">Sinh-arcsinh</h1><p id="5a6b" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">Proposed by Jones and Pewsey³, the sinh-arcsinh transformation is</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/c9d90b8fa9c77d4eec462f153ed2e90e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vmHA93IBy5WhFe4y7siEuw.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Jones and Pewsey do not include the constant 1/<em class="hd">δ term at the front. However, I include it here because it makes it easier to show arcsinh as a limiting case.</em></figcaption></figure><p id="a18a" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Parameter <em class="oi">ε</em> adjusts the skew of the data and <em class="oi">δ</em> adjusts the kurtosis³, allowing the transformation to take on many forms. For example, the identity transformation <em class="oi">f(x) = x</em> is a special case of sinh-arcsinh when <em class="oi">ε </em>= 0 and <em class="oi">δ </em>= 1. Arcsinh is a limiting case for <em class="oi">ε </em>= 0 and <em class="oi">δ </em>approaching zero, as can be seen using L’Hôpital’s rule again.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/8affeb48e27667cbb459a63d1d4d4e7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V_LUepsZR1Z0Leu94s3mPQ.png"/></div></div></figure></div></div><div class="ms"><div class="ab cb"><div class="ln qz lo ra lp rb cf rc cg rd ci bh"><figure class="mn mo mp mq mr ms rf rg paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml re"><img src="../Images/07826aa87a3306c2ec7bdc9a39ed1f45.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*ipNJuduRZSVZ2UPksEsxNA.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">plots of sinh-arcsinh for different values of <em class="hd">ε </em>and <em class="hd">δ.</em> On the left, <em class="hd">ε </em>is fixed at zero, and on the right, <em class="hd">δ is fixed at 0.5, made with </em><a class="af nd" href="https://www.desmos.com/calculator" rel="noopener ugc nofollow" target="_blank"><em class="hd">Desmos</em></a><em class="hd"> available under </em><a class="af nd" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a>. Text added to image.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="5cc2" class="pm ok fq bf ol pn po pp oo pq pr ps or nn pt pu pv nr pw px py nv pz qa qb qc bk">Scale Still Matters</h2><p id="9b39" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">Just like with arcsinh, there are meaningful differences in the results of the sinh-arcsinh transformation based on how your input data is shifted or scaled, meaning there are not two, but four parameters that can be chosen.</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml qj"><img src="../Images/5b19c8b2798b2c1c7a1525d3ce501935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cpR4cHKsJeKdqBv-dM-gMQ.png"/></div></div></figure><h1 id="4c96" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">Parameter Estimation</h1><p id="6f4b" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">We’ve seen how data transformations can make the tails of your data more Gaussian. Now, let’s take it to the next level by picking the parameters that maximize the normal log likelihood.</p><p id="987c" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Let <em class="oi">T(x)</em> be my transformation, and let <em class="oi">N(x | μ, σ)</em> be the probability density function for a normal distribution with mean <em class="oi">μ</em> and standard deviation <em class="oi">σ</em>. Assuming independence, the likelihood of the entire dataset <em class="oi">X</em> is</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/342cd4d56e6394c8a91767cc4430d2e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r1VzNZ7-H5yPw0Ti5Ij5rw.png"/></div></div></figure><p id="9bff" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">where I’ve made use of the Jacobian of the transformation. The log likelihood is</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pk"><img src="../Images/aaee0bef4e435c9d8366a31fc8c08826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8FdgMLoIvlg9DfTVywEJqQ.png"/></div></div></figure><p id="6bd4" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">where I can drop the absolute value signs because the derivative of the transformation is always positive.</p><h2 id="fd2a" class="pm ok fq bf ol pn po pp oo pq pr ps or nn pt pu pv nr pw px py nv pz qa qb qc bk">Gradient Descent</h2><p id="49f3" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">I estimate my parameters with gradient descent, setting the loss function to the negative mean log likelihood. Tensorflow’s <code class="cx ql qm qn qo b">GradientTape</code> automatically calculates the partial derivatives with respect to the four parameters of sinh-arcsinh as well as <em class="oi">μ </em>and<em class="oi"> σ </em>from the normal probability density function. Parameters β, <em class="oi">δ</em>, and<em class="oi"> σ </em>are represented in log form to ensure they stay positive. You may want to try a few initializations of the variables in case the algorithm gets stuck at a local minimum. I also recommend normalizing your inputs to mean zero and standard deviation one before running the script for the best performance.</p><pre class="mn mo mp mq mr qp qo qq bp qr bb bk"><span id="a7a6" class="qs ok fq qo b bg qt qu l qv qw">import tensorflow as tf<br/>import numpy as np<br/><br/>@tf.function<br/>def log_prob(x, params):<br/>    # extract parameters<br/>    alpha, log_beta = params[0], params[1]  # rescaling params<br/>    beta = tf.math.exp(log_beta)<br/>    epsilon, log_delta = params[2], params[3]  # transformation params<br/>    delta = tf.math.exp(log_delta)<br/>    mu, log_sigma = params[4], params[5]  # normal dist params<br/>    sigma = tf.math.exp(log_sigma)<br/>    # rescale<br/>    x_scaled = (x - alpha)/beta<br/>    # transformation<br/>    sinh_arg = epsilon + delta * tf.math.asinh(x_scaled)<br/>    x_transformed = (1/delta) * tf.math.sinh(sinh_arg)<br/>    # log jacobian of transformation<br/>    d_sinh = tf.math.log(tf.math.cosh(sinh_arg))<br/>    d_arcsinh = - 0.5*tf.math.log(x_scaled**2 + 1)<br/>    d_rescaling = - log_beta<br/>    jacobian =  d_sinh + d_arcsinh + d_rescaling  # chain rule<br/>    # normal likelihood<br/>    z = (x_transformed - mu)/sigma  # standardized<br/>    normal_prob = -0.5*tf.math.log(2*np.pi) - log_sigma -0.5*z**2<br/>    return normal_prob + jacobian<br/><br/># Learning rate and number of epochs<br/>learning_rate = 0.1<br/>epochs = 1000<br/><br/># Initialize variables<br/>tf.random.set_seed(892)<br/>params = tf.Variable(tf.random.normal(shape=(6,), mean=0.0, stddev=1.0), dtype=tf.float32)<br/><br/># Use the Adam optimizer<br/>optimizer = tf.optimizers.Adam(learning_rate=learning_rate)<br/><br/># Perform gradient descent<br/>for epoch in range(epochs):<br/>    with tf.GradientTape() as tape:<br/>        loss = - tf.reduce_mean(log_prob(x_tf, params))<br/><br/>    # Compute gradients<br/>    gradients = tape.gradient(loss, [params])<br/><br/>    # Apply gradients to variables<br/>    optimizer.apply_gradients(zip(gradients, [params]))<br/><br/>    if (epoch % 100) == 0:<br/>        print(-loss.numpy())<br/><br/>print(f"Optimal vals: {params}")</span></pre><p id="b64c" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">This optimized approach resulted in a distribution very close to Gaussian — not only the tails, but the mid-section too!</p><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml rh"><img src="../Images/d06fde39c2703077445fa6b463fb2370.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XeisRDz7UnXHbj56U0xSzA.png"/></div></div></figure><h1 id="b651" class="oj ok fq bf ol om on gq oo op oq gt or os ot ou ov ow ox oy oz pa pb pc pd pe bk">Conclusion</h1><p id="8455" class="pw-post-body-paragraph ne nf fq ng b go pf ni nj gr pg nl nm nn ph np nq nr pi nt nu nv pj nx ny nz fj bk">Log and Box-Cox are powerful transformations when working with positive data, but merely shifting these transformations to include negative values has severe limitations. The arcsinh transformation is much better at handling extreme positive and negative values simultaneously.</p><p id="814d" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">If you are willing to increase the complexity, the sinh-arcsinh transformation is a more powerful function that generalizes arcsinh. When normality is very important, its parameters can also be derived using gradient descent to match a Gaussian distribution.</p><p id="85d3" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Arcsinh doesn’t get much attention, but it’s an essential transformation that should be a part of every data engineer’s tool kit.</p><p id="b245" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">If you’ve found these transformation techniques useful or have any questions about applying them to your own datasets, please share your thoughts and experiences in the comments below.</p></div></div></div><div class="ab cb ri rj rk rl" role="separator"><span class="rm by bm rn ro rp"/><span class="rm by bm rn ro rp"/><span class="rm by bm rn ro"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="bca3" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Unless otherwise noted, all images are by the author.</p><p id="77ad" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk"><strong class="ng fr"><em class="oi">Note from Towards Data Science’s editors:</em></strong><em class="oi"> While we allow independent authors to publish articles in accordance with our </em><a class="af nd" rel="noopener" target="_blank" href="/questions-96667b06af5"><em class="oi">rules and guidelines</em></a><em class="oi">, we do not endorse each author’s contribution. You should not rely on an author’s works without seeking professional advice. See our </em><a class="af nd" rel="noopener" target="_blank" href="/readers-terms-b5d780a700a4"><em class="oi">Reader Terms</em></a><em class="oi"> for details.</em></p><p id="cb43" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">[1] Jabbar, H. K., &amp; Khan, R. Z. (2014). <a class="af nd" href="https://www.researchgate.net/publication/295198699_METHODS_TO_AVOID_OVER-FITTING_AND_UNDER-FITTING_IN_SUPERVISED_MACHINE_LEARNING_COMPARATIVE_STUDY" rel="noopener ugc nofollow" target="_blank">Methods to avoid over-fitting and under-fitting in supervised machine learning (Comparative study)</a>.</p><p id="d35f" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">[2] <a class="af nd" href="https://doi.org/10.48550/arXiv.1810.08923" rel="noopener ugc nofollow" target="_blank">CNNpred: CNN-based stock market prediction using a diverse set of variables</a>. (2019). <a class="af nd" href="https://doi.org/10.24432/C55P70" rel="noopener ugc nofollow" target="_blank">UCI Machine Learning Repository</a>.</p><p id="238b" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">[3] Jones, M &amp; Pewsey, Arthur. (2009). <a class="af nd" href="https://www.researchgate.net/publication/295198699_METHODS_TO_AVOID_OVER-FITTING_AND_UNDER-FITTING_IN_SUPERVISED_MACHINE_LEARNING_COMPARATIVE_STUDY" rel="noopener ugc nofollow" target="_blank">Sinh-arcsinh distributions: a broad family giving rise to powerful tests of normality and symmetry</a>. Biometrika.</p></div></div></div></div>    
</body>
</html>