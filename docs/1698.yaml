- en: Building a Data Science Platform with Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes构建数据科学平台
- en: 原文：[https://towardsdatascience.com/building-a-data-science-tool-stack-with-kubernetes-00c74b491b9d?source=collection_archive---------7-----------------------#2024-07-11](https://towardsdatascience.com/building-a-data-science-tool-stack-with-kubernetes-00c74b491b9d?source=collection_archive---------7-----------------------#2024-07-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-a-data-science-tool-stack-with-kubernetes-00c74b491b9d?source=collection_archive---------7-----------------------#2024-07-11](https://towardsdatascience.com/building-a-data-science-tool-stack-with-kubernetes-00c74b491b9d?source=collection_archive---------7-----------------------#2024-07-11)
- en: How Kubernetes — the back-end tool — powers the data science team with end-to-end
    ML life-cycle from model development to deployment
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes如何作为后端工具，支持数据科学团队实现从模型开发到部署的端到端机器学习生命周期
- en: '[](https://avinashknmr.medium.com/?source=post_page---byline--00c74b491b9d--------------------------------)[![Avinash
    Kanumuru](../Images/7d9f0547542650178297ed04365fb7da.png)](https://avinashknmr.medium.com/?source=post_page---byline--00c74b491b9d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--00c74b491b9d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--00c74b491b9d--------------------------------)
    [Avinash Kanumuru](https://avinashknmr.medium.com/?source=post_page---byline--00c74b491b9d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://avinashknmr.medium.com/?source=post_page---byline--00c74b491b9d--------------------------------)[![Avinash
    Kanumuru](../Images/7d9f0547542650178297ed04365fb7da.png)](https://avinashknmr.medium.com/?source=post_page---byline--00c74b491b9d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--00c74b491b9d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--00c74b491b9d--------------------------------)
    [Avinash Kanumuru](https://avinashknmr.medium.com/?source=post_page---byline--00c74b491b9d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--00c74b491b9d--------------------------------)
    ·6 min read·Jul 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--00c74b491b9d--------------------------------)
    ·阅读时长6分钟·2024年7月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6e99dc373ba82e9468ce30f2575fb1af.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e99dc373ba82e9468ce30f2575fb1af.png)'
- en: Photo by [Growtika](https://unsplash.com/@growtika?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Growtika](https://unsplash.com/@growtika?utm_source=medium&utm_medium=referral)
    于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: When I started in my new role as Manager of Data Science, little did I know
    about setting up a data science platform for the team. In all my previous roles,
    I had worked on building models and to some extent deploying models (or at least
    supporting the team that was deploying models), but I never needed to set up something
    from scratch (infra, I mean). The data science team did not exist then.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始担任数据科学经理的新职位时，我对为团队搭建数据科学平台几乎一无所知。在我之前的所有职位中，我主要工作是构建模型，并在一定程度上进行模型部署（或者至少是支持进行模型部署的团队），但我从未需要从零开始搭建什么（我指的是基础设施）。那时，数据科学团队还不存在。
- en: So first of my objective was to set up a platform, not just for the data science
    team in a silo, but that can be integrated with data engineering and software
    teams. This is when I was introduced to Kubernetes (k8s) directly. I had heard
    of it earlier but hadn’t worked beyond creating docker images and someone else
    would deploy in some infra.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我的第一个目标是搭建一个平台，不仅仅是为数据科学团队单独使用，而是能够与数据工程和软件团队集成。这就是我第一次直接接触Kubernetes（k8s）的时候。我之前听说过它，但没有超出创建docker镜像的范围，其他人会在某些基础设施上进行部署。
- en: Now, why is Kubernetes required for the data science team? What are some of
    the challenges faced by data science teams?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么数据科学团队需要Kubernetes呢？数据科学团队面临哪些挑战？
- en: A scalable computer based on requirement — as a data scientist we work on different
    problems every day and each has different resource requirements. There isn’t a
    one-size-fits-all computer. Even if it exists, it can’t be given to everyone on
    the data science team
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据需求可扩展的计算——作为数据科学家，我们每天处理不同的问题，每个问题的资源需求各不相同。没有一种通用的计算机。即使有，也不能提供给数据科学团队的每个成员。
- en: Version issues — Python and package version issues when working in a team or
    when we deploy to production
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 版本问题——在团队中工作时，或者在我们部署到生产环境时，Python和包的版本问题
- en: Different technologies and platforms — some pre-processing and model building
    require spark, and some can be done in pandas. So again, there isn’t a one-size-fits-all
    in local computer
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的技术和平台 — 有些预处理和模型构建需要使用 Spark，而有些可以通过 Pandas 完成。所以再次强调，本地计算机上并没有适用于所有情况的“一刀切”方案。
- en: Sharing work within the team — Sharing and tracking of model results done in
    an Excel spreadsheet and circulated after each iteration
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队内部的工作共享 — 在 Excel 表格中共享和跟踪模型结果，并在每次迭代后进行分发
- en: And most importantly, Production deployment — how do I get the finished model
    to production? Models don’t get to production for real-time use cases, as we as
    data scientists are not aware of building API/system around a model. Eventually,
    we end up running the model score in batch
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最重要的是，生产部署 —— 我如何将完成的模型部署到生产环境中？模型往往无法用于实时场景，因为我们作为数据科学家不懂得围绕模型构建 API/系统。最终，我们往往只能在批处理模式中运行模型评分。
- en: I’ve explored solutions, including Cloud Platform solutions (AWS SageMaker,
    GCP AI Platform, Azure Machine Learning), but our main factor is cost and next
    is cloud-agnostic. If cost is not a factor, then one can use the above-mentioned
    cloud platform services.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我探讨过包括云平台解决方案（AWS SageMaker、GCP AI Platform、Azure Machine Learning）在内的方案，但我们的主要考虑因素是成本，其次是云无关性。如果成本不是问题，那么可以使用上述提到的云平台服务。
- en: We identified that Kubernetes is an ideal platform that satisfies most of these
    requirements — to scale and serve containerized images. Also this way, we are
    cloud-agnostic. If we have to move to a different vendor, we just lift and shift
    everything with minimal changes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现 Kubernetes 是一个理想的平台，能够满足大多数这些需求 —— 它能扩展并服务容器化的镜像。通过这种方式，我们也保持了云无关性。如果必须迁移到其他供应商，只需最小的修改，便能轻松迁移一切。
- en: Many tools provide complete/similar solutions like KubeFlow, Weights & Biases,
    Kedro, …, but I ended up deploying the below 3 services as the first version of
    the data science platform. Though these don’t provide the complete MLOps framework,
    this gets us started to build the data science platform and team.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 许多工具提供了完整/类似的解决方案，比如 KubeFlow、Weights & Biases、Kedro 等，但我最终部署了以下三项服务作为数据科学平台的第一版。尽管这些工具没有提供完整的
    MLOps 框架，但它们为我们提供了构建数据科学平台和团队的起点。
- en: '**JupyterHub** — Containerized user environments for developing models in interactive
    Jupyter Notebooks'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**JupyterHub** — 为开发模型提供容器化的交互式 Jupyter Notebook 用户环境'
- en: '**MLflow** — Experiment tracking and storing model artifacts'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**MLflow** — 实验跟踪和存储模型工件'
- en: '**Seldon Core** — Simplified way to deploy models in Kubernetes'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Seldon Core** — 简化的 Kubernetes 模型部署方式'
- en: With these 3 services, I get my team to build models including big data processing
    in JupyterHub, track different fine-tuned parameters, and metrics, and store artifacts
    using MLflow and serve the model for production using Seldon-Core.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这三个服务，我可以让我的团队在 JupyterHub 中构建模型，包括大数据处理，跟踪不同的调优参数和指标，并使用 MLflow 存储工件，通过 Seldon-Core
    提供生产环境中的模型。
- en: JupyterHub
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JupyterHub
- en: Deploying this was the trickiest of all. JupyterHub in a standalone setup is
    easy compared to Kubernetes installation. But most of the required configuration
    was available here —
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 部署是最棘手的部分。相比于 Kubernetes 安装，单独的 JupyterHub 安装要简单一些。但这里有许多必需的配置 —
- en: '[](https://z2jh.jupyter.org/?source=post_page-----00c74b491b9d--------------------------------)
    [## Zero to JupyterHub with Kubernetes'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://z2jh.jupyter.org/?source=post_page-----00c74b491b9d--------------------------------)
    [## 使用 Kubernetes 从零开始搭建 JupyterHub'
- en: JupyterHub allows users to interact with a computing environment through a webpage.
    As most devices have access to a…
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: JupyterHub 允许用户通过网页与计算环境进行交互。由于大多数设备都能访问...
- en: z2jh.jupyter.org](https://z2jh.jupyter.org/?source=post_page-----00c74b491b9d--------------------------------)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: z2jh.jupyter.org](https://z2jh.jupyter.org/?source=post_page-----00c74b491b9d--------------------------------)
- en: Since we want to use Spark for some of our data processing, we created 2 docker
    images —
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望使用 Spark 进行一些数据处理，我们创建了 2 个 Docker 镜像 —
- en: Basic Notebook — extended from `jupyter/minimal-notebook:python-3.9`
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基本笔记本 — 扩展自`jupyter/minimal-notebook:python-3.9`
- en: Spark Notebook — extended from above with additional spark setup.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spark 笔记本 — 在上述基础上扩展，增加了 Spark 配置。
- en: Code for these notebook docker images and helm values for installing JupyterHub
    using these docker images are available [here](https://github.com/avinashknmr/data-science-tools).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些笔记本 Docker 镜像的代码和使用这些 Docker 镜像安装 JupyterHub 的 Helm 配置可以在[这里](https://github.com/avinashknmr/data-science-tools)找到。
- en: '[](https://github.com/avinashknmr/data-science-tools?source=post_page-----00c74b491b9d--------------------------------)
    [## GitHub - avinashknmr/data-science-tools'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/avinashknmr/data-science-tools?source=post_page-----00c74b491b9d--------------------------------)
    [## GitHub - avinashknmr/data-science-tools  '
- en: Contribute to avinashknmr/data-science-tools development by creating an account
    on GitHub.
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '通过在GitHub上创建账户，参与开发avinashknmr/data-science-tools项目。  '
- en: github.com](https://github.com/avinashknmr/data-science-tools?source=post_page-----00c74b491b9d--------------------------------)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/avinashknmr/data-science-tools?source=post_page-----00c74b491b9d--------------------------------)  '
- en: There are a lot of tweaks done to enable Google Oauth, starting Notebook as
    a root user, but running them as an individual user, retrieving the username,
    user-level permissions, persistent volume claims, and service accounts, … which
    took me days to get it working, especially with the Auth. But this code in the
    repo, can give you a skeleton to get started.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '为了启用Google Oauth，我做了很多调整，包括将Notebook作为root用户启动，但以个别用户身份运行它们，检索用户名、用户级别的权限、持久卷声明和服务账户等，这些都花费了我几天时间才能让它工作，尤其是身份验证部分。但代码库中的这段代码，可以为你提供一个框架，帮助你开始使用。  '
- en: MLflow
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'MLflow  '
- en: Setting up MLFlow was easy.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '设置MLFlow很简单。  '
- en: '[](https://mlflow.org/docs/latest/introduction/index.html?source=post_page-----00c74b491b9d--------------------------------)
    [## What is MLflow?'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mlflow.org/docs/latest/introduction/index.html?source=post_page-----00c74b491b9d--------------------------------)
    [## 什么是MLflow？  '
- en: Stepping into the world of Machine Learning (ML) is an exciting journey, but
    it often comes with complexities that can…
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '进入机器学习（ML）领域是一次令人兴奋的旅程，但它常常伴随着一些复杂性，这可能…  '
- en: mlflow.org](https://mlflow.org/docs/latest/introduction/index.html?source=post_page-----00c74b491b9d--------------------------------)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[mlflow.org](https://mlflow.org/docs/latest/introduction/index.html?source=post_page-----00c74b491b9d--------------------------------)  '
- en: MLflow offers model tracking, model registry, and model serving capabilities.
    But for model serving, we use the next tool (Seldon-Core).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 'MLflow提供模型追踪、模型注册和模型服务能力。但对于模型服务，我们使用下一个工具（Seldon-Core）。  '
- en: Build a Docker image with the required Python packages.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '构建一个包含所需Python包的Docker镜像。  '
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once the docker image is created and pushed to the container registry of your
    choice, we create a deployment and service file for Kubernetes (similar to any
    other docker image deployment). A snippet of the deployment yaml is given below.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '一旦创建并推送Docker镜像到你选择的容器注册中心，我们会为Kubernetes创建一个部署和服务文件（类似于任何其他Docker镜像部署）。下面给出了部署yaml的一个片段。  '
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: There are 2 main configurations here that took time for me to understand and
    configure —
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个主要的配置，花了我一些时间才理解和配置完成——
- en: artifact’s location
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'artifact的位置  '
- en: backend store
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '后端存储  '
- en: The artifact location will be a blob storage where your model file will be stored
    and can be used for model-serving purposes. But in our case, this is AWS S3 where
    all models are stored, and is a model registry for us. There are a couple of other
    options to store the model locally in the server, but whenever the pod restarts
    the data is done, and PersistentVolume is accessible only via the server. By using
    Cloud Storage, we can integrate with other services — for example, Seldon-Core
    can pick from this location to serve the model. The backend store stores all metadata
    required to run the application including model tracking — parameters and metrics
    of each experiment/run.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 'artifact的位置将是一个Blob存储，你的模型文件将存储在此处，并可用于模型服务。然而，在我们的案例中，这个位置是AWS S3，所有的模型都存储在这里，并且它对我们来说是一个模型注册中心。还有其他几种选择可以在服务器本地存储模型，但每当Pod重启时，数据会丢失，而且PersistentVolume只能通过服务器访问。通过使用云存储，我们可以与其他服务进行集成——例如，Seldon-Core可以从这个位置加载并服务模型。后端存储则保存运行应用所需的所有元数据，包括模型追踪——每次实验/运行的参数和指标。  '
- en: Seldon-Core
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Seldon-Core  '
- en: The second most trickiest of the three is Seldon-Core.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '三者中第二个最棘手的是Seldon-Core。  '
- en: Seldon-Core is like a wrapper to your model that can package, deploy, and monitor
    ML models. This removes the dependency on ML engineers to make the deployment
    pipelines.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 'Seldon-Core就像是你模型的封装器，它可以打包、部署和监控ML模型。这消除了对ML工程师的依赖，避免了需要他们来创建部署流水线。  '
- en: '[](https://github.com/SeldonIO/seldon-core?source=post_page-----00c74b491b9d--------------------------------)
    [## GitHub - SeldonIO/seldon-core: An MLOps framework to package, deploy, monitor
    and manage thousands…'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/SeldonIO/seldon-core?source=post_page-----00c74b491b9d--------------------------------)
    [## GitHub - SeldonIO/seldon-core：一个用于打包、部署、监控和管理成千上万的生产机器学习模型的MLOps框架…  '
- en: An MLOps framework to package, deploy, monitor and manage thousands of production
    machine learning models …
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '一个MLOps框架，用于打包、部署、监控和管理成千上万的生产机器学习模型…  '
- en: github.com](https://github.com/SeldonIO/seldon-core?source=post_page-----00c74b491b9d--------------------------------)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/SeldonIO/seldon-core?source=post_page-----00c74b491b9d--------------------------------)'
- en: We did the installation using a Helm chart and Istio for ingress. There are
    2 options for ingress — Istio & Ambassador. I’m not getting into setting up Istio,
    as the DevOps team did this setup. Seldon is installed with the below Helm and
    Kubectl commands.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 Helm chart 和 Istio 进行安装，以实现 ingress。Ingress 有两种选择 —— Istio 和 Ambassador。我不会深入讲解
    Istio 的设置，因为这是由 DevOps 团队完成的。Seldon 是通过以下 Helm 和 Kubectl 命令安装的。
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: But assuming you have Istio set, below is the Yaml to set up Gateway and VirtualService
    for our Seldon.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经设置好了 Istio，下面是设置我们 Seldon 的 Gateway 和 VirtualService 的 Yaml 配置。
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Below is a sample k8s deployment file to serve the iris model from GCS. If using
    `scikit-learn` package for model development, the model should be exported using
    `joblib` and named as `model.joblib` .
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个示例的 k8s 部署文件，用于从 GCS 提供 iris 模型服务。如果使用 `scikit-learn` 包进行模型开发，模型应通过 `joblib`
    导出，并命名为 `model.joblib`。
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this example, we use SKLEARN_SERVER, but it has integrations for MLFLOW_SERVER,
    and TF_SERVER for MLflow and TensorFlow respectively.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用 SKLEARN_SERVER，但它也支持 MLFLOW_SERVER 和 TF_SERVER，分别用于 MLflow 和 TensorFlow。
- en: Seldon-Core not only supports REST API but also gRPC for seamless server-server
    calls.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Seldon-Core 不仅支持 REST API，还支持 gRPC，能够实现无缝的服务器间调用。
- en: Conclusion
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: These tools are open source and deployable in Kubernetes, so they are cost-effective
    for small teams and also cloud-agnostic. They cover most challenges of a data
    science team like a centralized Jupyter Notebook for collaboration without version
    issues and serving models without dedicated ML engineers.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具是开源的，可以部署在 Kubernetes 上，因此对于小团队来说具有成本效益，并且是云中立的。它们解决了数据科学团队的大部分挑战，比如集中式的
    Jupyter Notebook 用于协作，避免版本问题，同时无需专门的机器学习工程师就能提供模型服务。
- en: JupyterHub and Seldon-Core leverage the Kubernetes capabilities. JupyterHub
    spins up a pod for users when they log in and kills it when idle. Seldon-Core
    wraps the model and serves it as an API in a few minutes. MLflow is the only standalone
    installation that connects model development and model deployment. MLflow acts
    as a model registry to track models and store artifacts for later use.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: JupyterHub 和 Seldon-Core 都利用了 Kubernetes 的能力。JupyterHub 会在用户登录时启动一个 Pod，并在空闲时将其销毁。Seldon-Core
    会将模型封装并在几分钟内作为 API 提供服务。MLflow 是唯一一个独立安装的工具，它连接了模型开发和模型部署。MLflow 作为一个模型注册库，用于追踪模型并存储后续使用的工件。
