- en: N-BEATS — The First Interpretable Deep Learning Model That Worked for Time Series
    Forecasting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: N-BEATS — 第一个在时间序列预测中有效的可解释深度学习模型
- en: 原文：[https://towardsdatascience.com/n-beats-the-first-interpretable-deep-learning-model-that-worked-for-time-series-forecasting-06920daadac2?source=collection_archive---------2-----------------------#2024-05-11](https://towardsdatascience.com/n-beats-the-first-interpretable-deep-learning-model-that-worked-for-time-series-forecasting-06920daadac2?source=collection_archive---------2-----------------------#2024-05-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/n-beats-the-first-interpretable-deep-learning-model-that-worked-for-time-series-forecasting-06920daadac2?source=collection_archive---------2-----------------------#2024-05-11](https://towardsdatascience.com/n-beats-the-first-interpretable-deep-learning-model-that-worked-for-time-series-forecasting-06920daadac2?source=collection_archive---------2-----------------------#2024-05-11)
- en: An easy-to-understand deep dive into how N-BEATS works and how you can use it.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 易于理解的N-BEATS工作原理深度解析，以及你如何使用它。
- en: '[](https://medium.com/@jodancker?source=post_page---byline--06920daadac2--------------------------------)[![Jonte
    Dancker](../Images/29e37a1a1cabc15cfb90a860b2931f03.png)](https://medium.com/@jodancker?source=post_page---byline--06920daadac2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--06920daadac2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--06920daadac2--------------------------------)
    [Jonte Dancker](https://medium.com/@jodancker?source=post_page---byline--06920daadac2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jodancker?source=post_page---byline--06920daadac2--------------------------------)[![Jonte
    Dancker](../Images/29e37a1a1cabc15cfb90a860b2931f03.png)](https://medium.com/@jodancker?source=post_page---byline--06920daadac2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--06920daadac2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--06920daadac2--------------------------------)
    [Jonte Dancker](https://medium.com/@jodancker?source=post_page---byline--06920daadac2--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--06920daadac2--------------------------------)
    ·11 min read·May 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--06920daadac2--------------------------------)
    ·11分钟阅读·2024年5月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/980ff84a5ed71008034c95d433f1ed18.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/980ff84a5ed71008034c95d433f1ed18.png)'
- en: Architecture of N-BEATS (Image taken from [Oreshkin et al.](https://arxiv.org/pdf/1905.10437)).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS架构（图片来自[Oreshkin等人](https://arxiv.org/pdf/1905.10437)）。
- en: Time series forecasting has been the only area in which Deep Learning and Transformers
    did not outperform other models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列预测一直是深度学习和Transformers未能超越其他模型的唯一领域。
- en: Looking at the Makridakis M-competition, the winning solutions always relied
    on statistical models. Until the M4 competition, winning solutions were either
    pure statistical or a hybrid of ML and statistical models. Pure ML approaches
    barely surpassed the competition baseline.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从Makridakis M比赛来看，获胜的解决方案总是依赖于统计模型。直到M4比赛，获胜的解决方案才是纯统计模型或机器学习与统计模型的混合。纯机器学习方法几乎无法超越竞争基准。
- en: This changed with a paper published by [Oreshkin, et al.](https://arxiv.org/pdf/1905.10437)
    in 2020\. The authors published N-BEATS, a promising pure Deep Learning approach.
    The model beat the winning solution of the M4 competition. It was the first pure
    Deep Learning approach that outperformed well-established statistical approaches.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切在2020年由[Oreshkin等人](https://arxiv.org/pdf/1905.10437)发表的一篇论文中发生了变化。作者们发布了N-BEATS，这是一种有前景的纯深度学习方法。该模型超越了M4竞赛的获胜方案。它是第一个超越成熟统计方法的纯深度学习方法。
- en: N-BEATS stands for **N**eural **B**asis **E**xpansion **A**nalysis for Interpretable
    **T**ime **S**eries.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: N-BEATS代表**N**eural **B**asis **E**xpansion **A**nalysis for Interpretable **T**ime
    **S**eries（可解释的时间序列神经基础扩展分析）。
- en: In this article, I will go through the architecture behind N-BEATS. But do not
    be afraid, the deep dive will be easy-to-understand. I also show you how we can
    make the deep learning approach interpretable. However, it is not enough to only
    understand how N-BEATS works. Thus, I will show you how…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将介绍N-BEATS背后的架构。但请不要担心，深入讲解将会易于理解。我还将展示如何使深度学习方法具有可解释性。然而，仅仅理解N-BEATS如何工作是不够的。因此，我将向你展示如何…
