- en: Powering Experiments with CUPED and Double Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/powering-experiments-with-cuped-and-double-machine-learning-34dc2f3d3284?source=collection_archive---------2-----------------------#2024-08-15](https://towardsdatascience.com/powering-experiments-with-cuped-and-double-machine-learning-34dc2f3d3284?source=collection_archive---------2-----------------------#2024-08-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Causal AI, exploring the integration of causal reasoning into machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@raz1470?source=post_page---byline--34dc2f3d3284--------------------------------)[![Ryan
    O''Sullivan](../Images/7cd161d38d67d2c0b7da2d8f3e7d33fe.png)](https://medium.com/@raz1470?source=post_page---byline--34dc2f3d3284--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--34dc2f3d3284--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--34dc2f3d3284--------------------------------)
    [Ryan O''Sullivan](https://medium.com/@raz1470?source=post_page---byline--34dc2f3d3284--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--34dc2f3d3284--------------------------------)
    ·17 min read·Aug 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9853e8cbe533bacb89e3bddd32cb8708.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Karsten Würth](https://unsplash.com/@karsten_wuerth?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: What is this series of articles about?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to my series on Causal AI, where we will explore the integration of
    causal reasoning into machine learning models. Expect to explore a number of practical
    applications across different business contexts.
  prefs: []
  type: TYPE_NORMAL
- en: In the last article we covered *safeguarding demand forecasting with causal
    graphs*. Today, we turn our attention to powering experiments using CUPED and
    double machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you missed the last article on safeguarding demand forecasting, check it
    out here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/safeguarding-demand-forecasting-with-causal-graphs-591511fc8e0e?source=post_page-----34dc2f3d3284--------------------------------)
    [## Safeguarding Demand Forecasting with Causal Graphs'
  prefs: []
  type: TYPE_NORMAL
- en: Causal AI, exploring the integration of causal reasoning into machine learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/safeguarding-demand-forecasting-with-causal-graphs-591511fc8e0e?source=post_page-----34dc2f3d3284--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this article, we evaluate whether CUPED and double machine learning can
    enhance the effectiveness of your experiments. We will use a case study to explore
    the following areas:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The building blocks of experimentation: Hypothesis testing, power analysis,
    bootstrapping.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is CUPED and how can it help power experiments?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the conceptual similarities between CUPED and double machine learning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When should we use double machine learning rather than CUPED?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The full notebook can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/raz1470/causal_ai/blob/main/notebooks/powering%20your%20experiments%20-%20cuped.ipynb?source=post_page-----34dc2f3d3284--------------------------------)
    [## causal_ai/notebooks/powering your experiments - cuped.ipynb at main · raz1470/causal_ai'
  prefs: []
  type: TYPE_NORMAL
- en: This project introduces Causal AI and how it can drive business value. - causal_ai/notebooks/powering
    your experiments…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/raz1470/causal_ai/blob/main/notebooks/powering%20your%20experiments%20-%20cuped.ipynb?source=post_page-----34dc2f3d3284--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You’ve recently joined the experimentation team at a leading online retailer
    known for its vast product catalog and dynamic user base. The data science team
    has deployed an advanced recommender system designed to enhance user experience
    and drive sales. This system integrates in real-time with the retailer’s platform
    and involves significant infrastructure and engineering costs.
  prefs: []
  type: TYPE_NORMAL
- en: The finance team is eager to understand the system’s financial impact, specifically
    how much additional revenue it generates compared to a baseline scenario without
    recommendations. To evaluate the recommender system’s effectiveness, you plan
    to conduct a randomized controlled experiment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data-generating process: Pre-experiment'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We start by creating some pre-experiment data. The data-generating process
    we use has the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: 3 observed covariates related to the recency (x_recency), frequency (x_frequency)
    and value (x_value) of previous sales.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 unobserved covariate, the users monthly income (u_income).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/bac77761d4e1524256fb74b839f98e5c.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'A complex relationship between covariates is used to estimate our target metric,
    sales value:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/34a926a337c172ee066ca3cd38c4ce74.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'The python code below is used to create the pre-experiment data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/69b2bc0d3c5278b6ed231416969a3a30.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'The building blocks of experimentation: Hypothesis testing, power analysis,
    bootstrapping'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we get onto CUPED, I thought it would be worthwhile covering some foundational
    knowledge on experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Hypothesis testing helps determine if observed differences in an experiment
    are statistically significant or just random noise. In our experiment, we divide
    users into two groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Control Group**: Receives no recommendations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Treatment Group**: Receives personalised recommendations from the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We define our hypotheses as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Null Hypothesis (H₀)**: The recommender system does not affect revenue. Any
    observed differences are due to chance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alternative Hypothesis (Hₐ)**: The recommender system increases revenue.
    Users receiving recommendations generate significantly more revenue compared to
    those who do not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To assess the hypotheses you will be comparing the mean revenue in the control
    and treatment group. However, there are a few things to be aware of:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Type I error (False positive)**: If the experiment concludes that the recommender
    system significantly increases revenue when in reality, it has no effect.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Type II error (Beta, False negative)**: If the experiment finds no significant
    increase in revenue from the recommender system when in reality, it does lead
    to a meaningful increase'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Significance Level (Alpha)**: If you set the significance level to 0.05,
    you are accepting a 5% chance of incorrectly concluding that the recommender system
    improves revenue when it does not (false positive).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Power (1 — Beta)**: Achieving a power of 0.80 means you have an 80% chance
    of detecting a significant increase in revenue due to the recommender system if
    it truly has an effect. A higher power reduces the risk of false negatives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you start to think about designing the experiment, you set some initial
    goals:'
  prefs: []
  type: TYPE_NORMAL
- en: '**You want to reliably detect the effect** — Making sure you balance the risks
    of detecting a non-existent effect vs the risk of not detecting a real effect.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**As quickly as possible** — Finance are on your case!'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Keeping the sample size as cost efficient as possible** — The business case
    from the data science team suggests the system is going to drive a large increase
    in revenue so they don’t want the control group being too big.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: But how can you meet these goals? Let’s delve into power analysis next!
  prefs: []
  type: TYPE_NORMAL
- en: Power analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When we talk about powering experiments, we are usually referring to the process
    of determining the minimum sample size needed to detect an effect of a certain
    size with a given confidence. There are 3 components to power analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Effect size** — The difference between the mean value of H₀ and Hₐ. We generally
    need to make sensible assumptions around this based on understanding what matters
    to the business/industry we are operating within.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Significance level** — The probability of incorrectly concluding there is
    an effect when there isn’t, typically set at 0.05.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Power** — The probability of correctly detecting an effect when there is
    one, typically set at 0.80.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I found the intuition behind these quite hard to grasp at first, but visualising
    it can really help. So lets give it a try! The key areas are where H₀ and Hₐ crossover
    — See if you it helps you tie together the components discussed above…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/01eaf60212908ac7aab73804366e2e8d.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: A larger sample size leads to a smaller **standard error**. With a smaller standard
    error, the sampling distributions of H₀ and Hₐ become narrower and less overlapping.
    This decreased overlap makes it easier to detect a difference, leading to higher
    power.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function below shows how we can use the statsmodels python package to carry
    out a power analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: So let’s test it out with our pre-experiment data!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e766581806e322906648a66eb2e665bc.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: We can see that given the distribution of our target metric, we would need a
    sample size of 1,645 to detect an increase of 5%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data-generating process: Experimental data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rather than rush into setting up the experiment, you decide to take the pre-experiment
    data and simulate the experiment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following function randomly selects users to be treated and applies a treatment
    effect. At the end of the function we record the mean difference before and after
    the treatment was applied as well as the true ATE (average treatment effect):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can feed through the minimum sample size we previously calculated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s start by inspecting the data we created for treated users to help you
    understand what the function is doing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d5448f96a7709846f3ac08aad74204b5.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'Next let’s take a look at the results which the function prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e68cb71f6cabe6971c08e46b1d947b0b.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Interesting, we see that after we select users to be treated, but before we
    treat them, there is already a difference in means. This difference is due to
    chance. This means that when we look at the difference after users are treated
    we don’t correctly estimate the ATE (average treatment effect). We will come back
    to this point when we cover CUPED.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/874eed4c5f7388d5a8c7717f0613b3bd.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Next let’s explore a more sophisticated way of making an inference than just
    taking the difference in means…
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bootstrapping is a powerful statistical technique that involves resampling data
    with replacement. These resampled datasets, called bootstrap samples, help us
    estimate the variability of a statistic (like the mean or median) from our original
    data. This is particularly attractive when it comes to experimentation as it enables
    us to calculate confidence intervals. Let’s walk through it step by step using
    a simple example…
  prefs: []
  type: TYPE_NORMAL
- en: You have run an experiment with a control and treatment group each made up of
    1k users.
  prefs: []
  type: TYPE_NORMAL
- en: Create bootstrap samples — Randomly select (with replacement) 1k users from
    the control and then treatment group. This gives us 1 bootstrap sample for control
    and one for treatment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat this process n times (e.g. 10k times).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each pair of bootstrap samples calculate the mean difference between control
    and treatment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We now have a distribution (made up of the mean difference between 10k bootstrap
    samples) which we can use to calculate confidence intervals.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/3346768ff5436682708eccc93ac03db7.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Applying it to our case study
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s use our case study to illustrate how it works. Below we use the sciPy
    stats python package to help calculate bootstrap confidence intervals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run it for our case study data we can see that we now have some confidence
    intervals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/95dea5cf92e093d0a197aec611dafefb.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Our ground truth ATE is 143 (the actual treatment effect from our experiment
    data generator function), which falls within our confidence intervals. However,
    it’s worth noting that the mean difference hasn’t changed (it’s still 93 as before
    when we simply calculated the mean difference of control and treatment), and the
    pre-treatment difference is still there.
  prefs: []
  type: TYPE_NORMAL
- en: So what if we wanted to come up with narrower confidence intervals? And is there
    any way we can deal with the pre-treatment differences? This leads us nicely into
    CUPED…
  prefs: []
  type: TYPE_NORMAL
- en: What is CUPED and how can it help power experiments?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'CUPED (controlled experiments using pre-experiment data) is a powerful technique
    for improving the accuracy of experiments developed by researchers at Microsoft.
    The original paper is an insightful read for anyone interested in experimentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://ai.stanford.edu/~ronnyk/2009controlledExperimentsOnTheWebSurvey.pdf](https://ai.stanford.edu/~ronnyk/2009controlledExperimentsOnTheWebSurvey.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The core idea of CUPED is to use data collected before your experiment begins
    to reduce the variance in your target metric. By doing so, you can make your experiment
    more sensitive, which has two major benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: You can detect smaller effects with the same sample size.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can detect the same effect with a smaller sample size.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Think of it like removing the “background noise” so you can see the “signal”
    more clearly.
  prefs: []
  type: TYPE_NORMAL
- en: Variance, standard deviation, standard error
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you read about CUPED you may hear people talk about it reducing the variance,
    standard deviation or standard error. If you are anything like me, you might find
    yourself forgetting how these are related, so before we go any further let’s recap
    on this!
  prefs: []
  type: TYPE_NORMAL
- en: '**Variance**: Variance measures the average squared deviation of each data
    point from the mean, reflecting the overall spread or dispersion within a dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard Deviation**: Standard deviation is the square root of variance,
    representing the average distance of each data point from the mean, and providing
    a more interpretable measure of spread.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard Error**: Standard error quantifies the precision of the sample mean
    as an estimate of the population mean, calculated as the standard deviation divided
    by the square root of the sample size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does CUPED work?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To understand how CUPED works, let’s break it down…
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-experiment covariate** — In the lightest implementation of CUPED, the
    pre-experiment covariate would be the target metric measured in a time period
    before the experiment. So if your target metric was sales value, your covariate
    could be each customers sales value 4 weeks prior to the experiment.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s important that your covariate is correlated with your target metric and
    that it is unaffected by the treatment. This is why we would typically use pre-treatment
    data from the control group.
  prefs: []
  type: TYPE_NORMAL
- en: '**Regression adjustment** — Linear regression is used to model the relationship
    between the covariate (measured before the experiment) and the target metric (measured
    across the experiment period). We can then calculate the CUPED adjusted target
    metric by removing the influence of the covariate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ee1f5375c1228403ad307b357c55788c.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that taking away the mean of the covariate is done to centre
    the outcome variable around the mean to make it interpretable when compared to
    the original target metric.
  prefs: []
  type: TYPE_NORMAL
- en: '**Variance reduction** — After the regression adjustment the variance in our
    target metric has reduced. Lower variance means that the differences between the
    control and treatment group are easier to detect, thus increasing the statistical
    power of the experiment.'
  prefs: []
  type: TYPE_NORMAL
- en: Applying it to our case study
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s use our case study to illustrate how it works. Below we code CUPED up
    in a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'When we apply it to our case study data and compare the adjusted target metric
    to the original target metric, we see that the variance has reduced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/979220e2d8fa0775cb942bf17a1d1505.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Does it reduce the standard error?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we have applied CUPED and reduced the variance, lets run our bootstrapping
    function to see what impact it has:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7e4f9adbcabe4f1f983b968fa2ced17c.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'If you compare this to our previous result using the original target metric
    you see that the confidence intervals are narrower:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2ca14804954a90f551baa3be1187c7a4.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: The bootstrap difference in means also moves closer to the ground truth treatment
    effect. This is because CUPED is also very effective at dealing with pre-existing
    differences between the control and treatment group.
  prefs: []
  type: TYPE_NORMAL
- en: Does it reduce the minimum sample size?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next question is does it reduce the minimum sample size we need. Well lets
    find out!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5c4826146a3028c94472f710ed1844fa.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: The minimum sample size needed has reduced from 1,645 to 901\. Both Finance
    and the Data Science team are going to be pleased as we can run the experiment
    for a shorter time period with a smaller control sample!
  prefs: []
  type: TYPE_NORMAL
- en: What are the conceptual similarities between CUPED and double machine learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When I first read about CUPED, I thought of double machine learning and the
    similarities. If you aren’t familiar with double machine learning, check out my
    article from earlier in the series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/de-biasing-treatment-effects-with-double-machine-learning-63b16fcb3e97?source=post_page-----34dc2f3d3284--------------------------------)
    [## De-biasing Treatment Effects with Double Machine Learning'
  prefs: []
  type: TYPE_NORMAL
- en: Causal AI, exploring the integration of causal reasoning into machine learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/de-biasing-treatment-effects-with-double-machine-learning-63b16fcb3e97?source=post_page-----34dc2f3d3284--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Pay attention to the first stage outcome model in double machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Outcome model (de-noising):*** Machine learning model used to estimate the
    outcome using just the control features. The outcome model residuals are then
    calculated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is conceptually very similar to what we are doing with CUPED!
  prefs: []
  type: TYPE_NORMAL
- en: How does it compare to CUPED?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s feed through our case study data and see if we get a similar result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/edd156ca7a8178703d554a058002f2aa.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: We get an almost identical result!
  prefs: []
  type: TYPE_NORMAL
- en: 'When we plot the residuals we can see that the variance is reduced like in
    CUPED (although we don’t add the mean to scale for interpretation):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/895d86f01f26912525e039620b535abc.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: “So what?” I hear you ask!
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, I think it’s an interesting observation for anyone using double machine
    learning — The first stage outcome model help reduce the variance and therefore
    we should get similar benefits to CUPED.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, it raises the question when is each method appropriate? Let’s close
    things off by covering off this question…
  prefs: []
  type: TYPE_NORMAL
- en: When should we use double machine learning rather than CUPED?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several reasons why it may make sense to tend towards CUPED:'
  prefs: []
  type: TYPE_NORMAL
- en: It’s easier to understand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s simpler to implement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s one model rather than three, meaning you have less challenges with overfitting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, there are a couple of exceptions where double machine learning outperforms
    CUPED:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Biased treatment assignment** — When the treatment assignment is biased,
    for example when you are using observational data, double machine learning can
    deal with this. My article from earlier in the series builds on this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](/de-biasing-treatment-effects-with-double-machine-learning-63b16fcb3e97?source=post_page-----34dc2f3d3284--------------------------------)
    [## De-biasing Treatment Effects with Double Machine Learning'
  prefs: []
  type: TYPE_NORMAL
- en: Causal AI, exploring the integration of causal reasoning into machine learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/de-biasing-treatment-effects-with-double-machine-learning-63b16fcb3e97?source=post_page-----34dc2f3d3284--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Heterogenous treatment effects** — When you want to understand effects at
    an individual level, for example finding out who it is worth sending discounts
    to, double machine learning can help with this. There is a good case study which
    illustrates this in my previous article on optimising treatment strategies:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](/using-double-machine-learning-and-linear-programming-to-optimise-treatment-strategies-920c20a29553?source=post_page-----34dc2f3d3284--------------------------------)
    [## Using Double Machine Learning and Linear Programming to optimise treatment
    strategies'
  prefs: []
  type: TYPE_NORMAL
- en: Causal AI, exploring the integration of causal reasoning into machine learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/using-double-machine-learning-and-linear-programming-to-optimise-treatment-strategies-920c20a29553?source=post_page-----34dc2f3d3284--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Final thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Today we did a whistle stop tour of experimentation, covering hypothesis testing,
    power analysis and bootstrapping. We then explored how CUPED can reduce the standard
    error and increase the power of our experiments. Finally, we touched on it’s similarities
    to double machine learning and discussed when each method should be used. There
    are a few additional key points which are worth mentioning in terms CUPED:'
  prefs: []
  type: TYPE_NORMAL
- en: We don’t have to use linear regression — If we have multiple covariates, maybe
    some with non-linear relationships, we could use a machine learning technique
    like boosting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we do go down the route of using a machine learning technique, we need to
    make sure not to overfit the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some careful thought should go into when to run CUPED — Are you going to run
    it before you start your experiment and then run a power analysis to determine
    your reduced sample size? Or are you just going to run it after your experiment
    to reduce the standard error?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Follow me if you want to continue this journey into Causal AI – In the next
    article we will investigate whether multi-collinearity is harming your causal
    inferences in marketing mix modelling!
  prefs: []
  type: TYPE_NORMAL
