["```py\npip install -U torch fiftyone diffusers transformers scikit-image\n```", "```py\nfrom glob import glob\nimport numpy as np\nfrom PIL import Image\nimport torch\n\nimport fiftyone as fo\nimport fiftyone.zoo as foz\nimport fiftyone.brain as fob\nfrom fiftyone import ViewField as F\n```", "```py\ncurl -o sunrgbd.zip https://rgbd.cs.princeton.edu/data/SUNRGBD.zip\n```", "```py\nunzip sunrgbd.zip\n```", "```py\n## create, name, and persist the dataset\ndataset = fo.Dataset(name=\"SUNRGBD-20\", persistent=True)\n\n## pick out first 20 scenes\nscene_dirs = glob(\"SUNRGBD/kv1/NYUdata/*\")[:20]\n\nsamples = []\n\nfor scene_dir in scene_dirs:\n    ## Get image file path from scene directory\n    image_path = glob(f\"{scene_dir}/image/*\")[0]\n\n    ## Get depth map file path from scene directory\n    depth_path = glob(f\"{scene_dir}/depth_bfx/*\")[0]\n\n    depth_map = np.array(Image.open(depth_path))\n    depth_map = (depth_map * 255 / np.max(depth_map)).astype(\"uint8\")\n\n    ## Create sample\n    sample = fo.Sample(\n        filepath=image_path,\n        gt_depth=fo.Heatmap(map=depth_map),\n    )\n\n    samples.append(sample)\n\n## Add samples to dataset\ndataset.add_samples(samples);\n```", "```py\nsession = fo.launch_app(dataset, auto=False)\n## then open tab to localhost:5151 in browser\n```", "```py\npip install replicate\n```", "```py\nexport REPLICATE_API_TOKEN=r8_<your_token_here>\n```", "```py\nfrom transformers import AutoImageProcessor, AutoModelForDepthEstimation\n\n## swap for \"Intel/dpt-large\" if you'd like\npretrained = \"Intel/dpt-hybrid-midas\"\n\nimage_processor = AutoImageProcessor.from_pretrained(pretrained)\ndpt_model = AutoModelForDepthEstimation.from_pretrained(pretrained)\n```", "```py\ndef apply_dpt_model(sample, model, label_field):\n    image = Image.open(sample.filepath)\n    inputs = image_processor(images=image, return_tensors=\"pt\")\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predicted_depth = outputs.predicted_depth\n\n    prediction = torch.nn.functional.interpolate(\n        predicted_depth.unsqueeze(1),\n        size=image.size[::-1],\n        mode=\"bicubic\",\n        align_corners=False,\n    )\n\n    output = prediction.squeeze().cpu().numpy()\n    ## flip b/c MiDaS returns inverse depth\n    formatted = (255 - output * 255 / np.max(output)).astype(\"uint8\")\n\n    sample[label_field] = fo.Heatmap(map=formatted)\n    sample.save()\n```", "```py\nfor sample in dataset.iter_samples(autosave=True, progress=True):\n    apply_dpt_model(sample, dpt_model, \"dpt\")\n\nsession = fo.launch_app(dataset)\n```", "```py\nimport replicate\n\n## example application to first sample\nrgb_fp = dataset.first().filepath\n\noutput = replicate.run(\n    \"cjwbw/midas:a6ba5798f04f80d3b314de0f0a62277f21ab3503c60c84d4817de83c5edfdae0\",\n    input={\n        \"model_type\": \"dpt_beit_large_512\",\n        \"image\":open(rgb_fp, \"rb\")\n    }\n)\nprint(output)\n```", "```py\ngit clone https://github.com/prs-eth/Marigold.git\n```", "```py\n## load model\nfrom Marigold.marigold import MarigoldPipeline\npipe = MarigoldPipeline.from_pretrained(\"Bingxin/Marigold\")\n\n## apply to first sample, as example\nrgb_image = Image.open(dataset.first().filepath)\noutput = pipe(rgb_image)\ndepth_image = output['depth_colored']\n```", "```py\nimport replicate\nimport requests\nimport io\n\ndef marigold_model(rgb_image):\n    output = replicate.run(\n        \"adirik/marigold:1a363593bc4882684fc58042d19db5e13a810e44e02f8d4c32afd1eb30464818\",\n        input={\n            \"image\":rgb_image\n        }\n    )\n    ## get the black and white depth map\n    response = requests.get(output[1]).content\n    return response\n\ndef apply_marigold_model(sample, model, label_field):\n    rgb_image = open(sample.filepath, \"rb\")\n    response = model(rgb_image)\n    depth_image = np.array(Image.open(io.BytesIO(response)))[:, :, 0] ## all channels are the same\n    formatted = (255 - depth_image).astype(\"uint8\")\n    sample[label_field] = fo.Heatmap(map=formatted)\n    sample.save()\n\nfor sample in dataset.iter_samples(autosave=True, progress=True):\n    apply_marigold_model(sample, marigold_model, \"marigold\")\n\nsession = fo.launch_app(dataset)\n```", "```py\nfrom skimage.metrics import peak_signal_noise_ratio, mean_squared_error, structural_similarity\n\ndef rmse(gt, pred):\n    \"\"\"Compute root mean squared error between ground truth and prediction\"\"\"\n    return np.sqrt(mean_squared_error(gt, pred))\n\ndef evaluate_depth(dataset, prediction_field, gt_field):\n  \"\"\"Run 3 evaluation metrics for all samples for `prediction_field`\n     with respect to `gt_field`\"\"\"\n    for sample in dataset.iter_samples(autosave=True, progress=True):\n        gt_map = sample[gt_field].map\n        pred = sample[prediction_field]\n        pred_map = pred.map\n        pred[\"rmse\"] = rmse(gt_map, pred_map)\n        pred[\"psnr\"] = peak_signal_noise_ratio(gt_map, pred_map)\n        pred[\"ssim\"] = structural_similarity(gt_map, pred_map)\n        sample[prediction_field] = pred\n\n    ## add dynamic fields to dataset so we can view them in the App\n    dataset.add_dynamic_sample_fields()\n```", "```py\nevaluate_depth(dataset, \"dpt\", \"gt_depth\")\nevaluate_depth(dataset, \"marigold\", \"gt_depth\")\n```", "```py\nprint(\"Mean Error Metrics\")\nfor model in [\"dpt\", \"marigold\"]:\n    print(\"-\"*50)\n    for metric in [\"rmse\", \"psnr\", \"ssim\"]:\n        mean_metric_value = dataset.mean(f\"{model}.{metric}\")\n        print(f\"Mean {metric} for {model}: {mean_metric_value}\")\n```", "```py\nMean Error Metrics\n--------------------------------------------------\nMean rmse for dpt: 49.8915828817003\nMean psnr for dpt: 14.805904629602551\nMean ssim for dpt: 0.8398022368184576\n--------------------------------------------------\nMean rmse for marigold: 104.0061165272178\nMean psnr for marigold: 7.93015537185192\nMean ssim for marigold: 0.42766803372861134\n```"]