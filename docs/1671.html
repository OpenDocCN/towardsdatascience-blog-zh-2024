<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>TensorFlow Transform: Ensuring Seamless Data Preparation in Production</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>TensorFlow Transform: Ensuring Seamless Data Preparation in Production</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-transform-ensuring-seamless-data-preparation-in-production-99ffcf49f535?source=collection_archive---------7-----------------------#2024-07-08">https://towardsdatascience.com/tensorflow-transform-ensuring-seamless-data-preparation-in-production-99ffcf49f535?source=collection_archive---------7-----------------------#2024-07-08</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="2ed4" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Leveraging TensorFlow Transform for scaling data pipelines for production environments</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@akila29?source=post_page---byline--99ffcf49f535--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Akila Somasundaram" class="l ep by dd de cx" src="../Images/5f3c58de8057c9c7ef42f6f5729fb395.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*3X97v4WvKq87j_whKdIwmA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--99ffcf49f535--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@akila29?source=post_page---byline--99ffcf49f535--------------------------------" rel="noopener follow">Akila Somasundaram</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--99ffcf49f535--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 8, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/95b3c8120fb4d55756d5e7eb9f7f8d50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rLFQK7315X-cZpFx"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Photo by <a class="af nb" href="https://unsplash.com/@scw1217?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Suzanne D. Williams</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="04e2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Data pre-processing is one of the major steps in any Machine Learning pipeline. Tensorflow Transform helps us achieve it in a distributed environment over a huge dataset.</p><p id="241c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Before going further into Data Transformation, Data Validation is the first step of the production pipeline process, which has been covered in my article <a class="af nb" href="https://medium.com/towards-data-science/validating-data-in-a-production-pipeline-the-tfx-way-9770311eb7ce" rel="noopener">Validating Data in a Production Pipeline: The TFX Way</a>. Have a look at this article to gain better understanding of this article.</p><p id="d42e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">I have used Colab for this demo, as it is much easier (and faster) to configure the environment. If you are in the exploration phase, I would recommend Colab as well, as it would help you concentrate on the more important things.</p><p id="8335" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">ML Pipeline operations begins with data ingestion and validation, followed by transformation. The transformed data is trained and deployed. I have covered the validation part in my earlier <a class="af nb" href="https://medium.com/towards-data-science/validating-data-in-a-production-pipeline-the-tfx-way-9770311eb7ce" rel="noopener">article</a>, and now we will be covering the transformation section. To get a better understanding of pipelines in Tensorflow, have a look at the below article.</p><div class="ny nz oa ob oc od"><a href="https://www.tensorflow.org/tfx?source=post_page-----99ffcf49f535--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab ig"><div class="of ab co cb og oh"><h2 class="bf fr hw z io oi iq ir oj it iv fp bk">TFX | ML Production Pipelines | TensorFlow</h2><div class="ok l"><h3 class="bf b hw z io oi iq ir oj it iv dx">Build and manage end-to-end production ML pipelines. TFX components enable scalable, high-performance data processing…</h3></div><div class="ol l"><p class="bf b dy z io oi iq ir oj it iv dx">www.tensorflow.org</p></div></div><div class="om l"><div class="on l oo op oq om or lq od"/></div></div></a></div><p id="d3a3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As established earlier, we will be using Colab. So we just need to install the tfx library and we are good to go.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="7a73" class="ow ox fq ot b bg oy oz l pa pb">! pip install tfx</span></pre><blockquote class="pc pd pe"><p id="8a46" class="nc nd pf ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After installation restart the session to proceed.</p></blockquote><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj pg"><img src="../Images/9e7831e0446e0018e3319cf4a224a3cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*XP4tnE_5ohlC4tH1kaG1Rw.png"/></div></figure><p id="89a5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next come the imports.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="2a87" class="ow ox fq ot b bg oy oz l pa pb"># Importing Libraries<br/><br/>import tensorflow as tf<br/><br/>from tfx.components import CsvExampleGen<br/>from tfx.components import ExampleValidator<br/>from tfx.components import SchemaGen<br/>from tfx.v1.components import ImportSchemaGen<br/>from tfx.components import StatisticsGen<br/>from tfx.components import Transform<br/><br/>from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext<br/>from google.protobuf.json_format import MessageToDict<br/><br/>import os</span></pre><p id="ed54" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We will be using the spaceship titanic dataset from Kaggle, as in the data validation article. This dataset is free to use for commercial and non-commercial purposes. You can access it from <a class="af nb" href="https://www.kaggle.com/competitions/spaceship-titanic" rel="noopener ugc nofollow" target="_blank">here</a>. A description of the dataset is shown in the below figure.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj ph"><img src="../Images/b7f72d9f83df9040e86e6d07ea33beac.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/0*sIusxEQr9Anq1hZy.png"/></div></figure><p id="c535" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In order to begin with the data transformation part, it is recommended to create folders where the pipeline components would be placed (else they will be placed in the default directory). I have created two folders, one for the pipeline components and the other for our training data.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="21fc" class="ow ox fq ot b bg oy oz l pa pb"># Path to pipeline folder<br/># All the generated components will be stored here<br/><br/>_pipeline_root = '/content/tfx/pipeline/'<br/><br/># Path to training data<br/># It can even contain multiple training data files<br/>_data_root = '/content/tfx/data/'</span></pre><p id="db55" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, we create the InteractiveContext, and pass the path to the pipeline directory. This process also creates a sqlite database for storing the metadata of the pipeline process.</p><p id="3be3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">InteractiveContext is meant for exploring each stage of the process. At each point, we can have a view of the artifacts that are created. When in a production environment, we will ideally be using a pipeline creation framework like Apache Beam, where this entire process will be executed automatically, without intervention.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="373c" class="ow ox fq ot b bg oy oz l pa pb"># Initializing the InteractiveContext <br/># This will create an sqlite db for storing the metadata<br/><br/>context = InteractiveContext(pipeline_root=_pipeline_root)</span></pre><p id="c15a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, we start with data ingestion. If your data is stored as a csv file, we can use CsvExampleGen, and pass the path to the directory where the data files are stored.</p><blockquote class="pc pd pe"><p id="2948" class="nc nd pf ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Make sure the folder contains only the training data and nothing else. If your training data is divided into multiple files, ensure they have the same header.</p></blockquote><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="9e83" class="ow ox fq ot b bg oy oz l pa pb"># Input CSV files <br/>example_gen = CsvExampleGen(input_base=_data_root)</span></pre><p id="424b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">TFX currently supports csv, tf.Record, BigQuery and some custom executors. More about it in the below link.</p><div class="ny nz oa ob oc od"><a href="https://www.tensorflow.org/tfx/guide/examplegen?source=post_page-----99ffcf49f535--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab ig"><div class="of ab co cb og oh"><h2 class="bf fr hw z io oi iq ir oj it iv fp bk">The ExampleGen TFX Pipeline Component | TensorFlow</h2><div class="ok l"><h3 class="bf b hw z io oi iq ir oj it iv dx">The ExampleGen TFX Pipeline component ingests data into TFX pipelines. It consumes external files/services to generate…</h3></div><div class="ol l"><p class="bf b dy z io oi iq ir oj it iv dx">www.tensorflow.org</p></div></div><div class="om l"><div class="pi l oo op oq om or lq od"/></div></div></a></div><p id="a335" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To execute the ExampleGen component, use context.run.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="dc19" class="ow ox fq ot b bg oy oz l pa pb"># Execute the component<br/><br/>context.run(example_gen)</span></pre><p id="27ea" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After running the component, this will be our output. It provides the execution_id, component details and where the component’s outputs are saved.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pj"><img src="../Images/f0b4d3c3cf0fc4c129d54772f83d7180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gFp1Qn5K5mEmLwfihBHjWQ.png"/></div></div></figure><p id="9974" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">On expanding, we should be able to see these details.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pk"><img src="../Images/49e56a8f1feee2d880ff89ff157e3530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B0w5GUi3P6ZXvgGpRPgC3g.png"/></div></div></figure><p id="eb75" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The directory structure looks like the below image. All these artifacts have been created for us by TFX. They are automatically versioned as well, and the details are stored in metadata.sqlite. The sqlite file helps maintain data provenance or data lineage.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj pl"><img src="../Images/2cb0dfd4007f0e3b58d2557279ec9744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*8I7f-WRbHj-q22yp6VeWVQ.png"/></div></figure><p id="523f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To explore these artifacts programatically, use the below code.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="5a15" class="ow ox fq ot b bg oy oz l pa pb"># View the generated artifacts<br/>artifact = example_gen.outputs['examples'].get()[0]<br/><br/># Display split names and uri<br/>print(f'split names: {artifact.split_names}')<br/>print(f'artifact uri: {artifact.uri}')</span></pre><p id="5b96" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The output would be the name of the files and the uri.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pm"><img src="../Images/26670b069b3c950fdfe9b6c7e8b2bb55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sZZNOGnEQor7FjTnd5mIOg.png"/></div></div></figure><p id="938d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let us copy the train uri and have a look at the details inside the file. The file is stored as a zip file and is stored in TFRecordDataset format.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="2f9f" class="ow ox fq ot b bg oy oz l pa pb"># Get the URI of the output artifact representing the training examples<br/>train_uri = os.path.join(artifact.uri, 'Split-train')<br/><br/># Get the list of files in this directory (all compressed TFRecord files)<br/>tfrecord_filenames = [os.path.join(train_uri, name)<br/>                      for name in os.listdir(train_uri)]<br/><br/># Create a `TFRecordDataset` to read these files<br/>dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type="GZIP")</span></pre><p id="9d1d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The below code is obtained from Tensorflow, it is the standard code that can be used to pick up records from TFRecordDataset and returns the results for us to examine.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="9a17" class="ow ox fq ot b bg oy oz l pa pb"># Helper function to get individual examples<br/>def get_records(dataset, num_records):<br/>    '''Extracts records from the given dataset.<br/>    Args:<br/>        dataset (TFRecordDataset): dataset saved by ExampleGen<br/>        num_records (int): number of records to preview<br/>    '''<br/><br/>    # initialize an empty list<br/>    records = []<br/><br/>    # Use the `take()` method to specify how many records to get<br/>    for tfrecord in dataset.take(num_records):<br/><br/>        # Get the numpy property of the tensor<br/>        serialized_example = tfrecord.numpy()<br/><br/>        # Initialize a `tf.train.Example()` to read the serialized data<br/>        example = tf.train.Example()<br/><br/>        # Read the example data (output is a protocol buffer message)<br/>        example.ParseFromString(serialized_example)<br/><br/>        # convert the protocol bufffer message to a Python dictionary<br/>        example_dict = (MessageToDict(example))<br/><br/>        # append to the records list<br/>        records.append(example_dict)<br/><br/>    return records</span></pre><pre class="pn os ot ou bp ov bb bk"><span id="ad2e" class="ow ox fq ot b bg oy oz l pa pb"># Get 3 records from the dataset<br/>sample_records = get_records(dataset, 3)<br/><br/># Print the output<br/>pp.pprint(sample_records)</span></pre><p id="62e1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We requested for 3 records, and the output looks like this. Every record and its metadata are stored in dictionary format.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj po"><img src="../Images/3e08f502cbd1f52b2f642b0b57efee07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DoFR28LFgZ01KnQbKnGSXA.png"/></div></div></figure><p id="8661" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, we move ahead to the subsequent process, which is to generate the statistics for the data using StatisticsGen. We pass the outputs from the example_gen object as the argument.</p><p id="c69d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We execute the component using statistics.run, with statistics_gen as the argument.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="43be" class="ow ox fq ot b bg oy oz l pa pb"># Generate dataset statistics with StatisticsGen using the example_gen object<br/><br/>statistics_gen = StatisticsGen(<br/>    examples=example_gen.outputs['examples'])<br/><br/># Execute the component<br/>context.run(statistics_gen)</span></pre><p id="8fe3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can use context.show to view the results.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="e8a6" class="ow ox fq ot b bg oy oz l pa pb"># Show the output statistics<br/><br/>context.show(statistics_gen.outputs['statistics'])</span></pre><p id="a5be" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can see that it is very similar to the statistics generation that we have discussed in the TFDV article. The reason is, TFX uses TFDV under the hood to perform these operations. Getting familiar with TFDV will help understand these processes better.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pp"><img src="../Images/ae1ebef42a6b57be00552e36e651e490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zUIh5ltJJ6IJ_qvzY_AWqw.png"/></div></div></figure><p id="ffb4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next step is to create the schema. This is done using the SchemaGen by passing the statistics_gen object. Run the component and visualize it using context.show.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="a539" class="ow ox fq ot b bg oy oz l pa pb"># Generate schema using SchemaGen with the statistics_gen object<br/><br/>schema_gen = SchemaGen(<br/>    statistics=statistics_gen.outputs['statistics'],<br/>    )<br/><br/># Run the component<br/>context.run(schema_gen)<br/><br/># Visualize the schema<br/><br/>context.show(schema_gen.outputs['schema'])</span></pre><p id="6af0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The output shows details about the underlying schema of the data. Again, same as in TFDV.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj pq"><img src="../Images/1f0aa75e2731fff473b691354d3683a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*024x4-I_KkUTgNVCIYzrLw.png"/></div></figure><p id="f497" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If you need to make modifications to the schema presented here, make them using tfdv, and create a schema file. You can pass it using the ImportSchemaGen and ask tfx to use the new file.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="cc56" class="ow ox fq ot b bg oy oz l pa pb"># Adding a schema file manually <br/>schema_gen = ImportSchemaGen(schema_file="path_to_schema_file/schema.pbtxt")</span></pre><p id="2843" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, we validate the examples using the ExampleValidator. We pass the statistics_gen and schema_gen as arguments.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="30ce" class="ow ox fq ot b bg oy oz l pa pb"># Validate the examples using the ExampleValidator<br/># Pass statistics_gen and schema_gen objects<br/><br/>example_validator = ExampleValidator(<br/>    statistics=statistics_gen.outputs['statistics'],<br/>    schema=schema_gen.outputs['schema'])<br/><br/># Run the component.<br/>context.run(example_validator)</span></pre><p id="f64a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This should be your ideal output to show that all is well.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pr"><img src="../Images/c53b89c5ea10cc197c14f557d20ba447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5UmminO7EbBAeArCQzpaxw.png"/></div></div></figure><p id="4940" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">At this point, our directory structure looks like the below image. We can see that for every step in the process, the corresponding artifacts are created.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj ps"><img src="../Images/764a04c84ebe42ad48477cbab52d717c.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*86ubPhAqkKXfjsAX-c3unw.png"/></div></figure><p id="e515" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let us move to the actual transformation part. We will now create the constants.py file to add all the constants that are required for the process.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="8c44" class="ow ox fq ot b bg oy oz l pa pb"># Creating the file containing all constants that are to be used for this project<br/><br/>_constants_module_file = 'constants.py'</span></pre><p id="6722" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We will create all the constants and write it to the constants.py file. See the “%%writefile {_constants_module_file}”, this command does not let the code run, instead, it writes all the code in the given cell into the specified file.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="ccc7" class="ow ox fq ot b bg oy oz l pa pb">%%writefile {_constants_module_file}<br/><br/># Features with string data types that will be converted to indices<br/>CATEGORICAL_FEATURE_KEYS = [ 'CryoSleep','Destination','HomePlanet','VIP']<br/><br/># Numerical features that are marked as continuous<br/>NUMERIC_FEATURE_KEYS = ['Age','FoodCourt','RoomService', 'ShoppingMall','Spa','VRDeck']<br/><br/># Feature that can be grouped into buckets<br/>BUCKET_FEATURE_KEYS = ['Age']<br/><br/># Number of buckets used by tf.transform for encoding each bucket feature.<br/>FEATURE_BUCKET_COUNT = {'Age': 4}<br/><br/># Feature that the model will predict<br/>LABEL_KEY = 'Transported'<br/><br/># Utility function for renaming the feature<br/>def transformed_name(key):<br/>    return key + '_xf'</span></pre><p id="037e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let us create the transform.py file, which will contain the actual code for transforming the data.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="3f5c" class="ow ox fq ot b bg oy oz l pa pb"># Creating a file that contains all preprocessing code for the project<br/><br/>_transform_module_file = 'transform.py'</span></pre><p id="fb9d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here, we will be using the tensorflow_transform library. The code for transformation process will be written under the preprocessing_fn function. It is mandatory we use the same name, as tfx internally searches for it during the transformation process.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="f146" class="ow ox fq ot b bg oy oz l pa pb">%%writefile {_transform_module_file}<br/><br/>import tensorflow as tf<br/>import tensorflow_transform as tft<br/><br/>import constants<br/><br/># Unpack the contents of the constants module<br/>_NUMERIC_FEATURE_KEYS = constants.NUMERIC_FEATURE_KEYS<br/>_CATEGORICAL_FEATURE_KEYS = constants.CATEGORICAL_FEATURE_KEYS<br/>_BUCKET_FEATURE_KEYS = constants.BUCKET_FEATURE_KEYS<br/>_FEATURE_BUCKET_COUNT = constants.FEATURE_BUCKET_COUNT<br/>_LABEL_KEY = constants.LABEL_KEY<br/>_transformed_name = constants.transformed_name<br/><br/><br/># Define the transformations<br/>def preprocessing_fn(inputs):<br/><br/>    outputs = {}<br/><br/>    # Scale these features to the range [0,1]<br/>    for key in _NUMERIC_FEATURE_KEYS:<br/>        outputs[_transformed_name(key)] = tft.scale_to_0_1(<br/>            inputs[key])<br/><br/>    # Bucketize these features<br/>    for key in _BUCKET_FEATURE_KEYS:<br/>        outputs[_transformed_name(key)] = tft.bucketize(<br/>            inputs[key], _FEATURE_BUCKET_COUNT[key])<br/><br/>    # Convert strings to indices in a vocabulary<br/>    for key in _CATEGORICAL_FEATURE_KEYS:<br/>        outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(inputs[key])<br/><br/>    # Convert the label strings to an index<br/>    outputs[_transformed_name(_LABEL_KEY)] = tft.compute_and_apply_vocabulary(inputs[_LABEL_KEY])<br/><br/>    return outputs</span></pre><p id="0996" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We have used a few standard scaling and encoding functions for this demo. The transform library actually hosts a whole lot of functions. Explore them here.</p><div class="ny nz oa ob oc od"><a href="https://www.tensorflow.org/tfx/transform/api_docs/python/tft?source=post_page-----99ffcf49f535--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab ig"><div class="of ab co cb og oh"><h2 class="bf fr hw z io oi iq ir oj it iv fp bk">Module: tft | TFX | TensorFlow</h2><div class="ok l"><h3 class="bf b hw z io oi iq ir oj it iv dx">Init module for TF.Transform.</h3></div><div class="ol l"><p class="bf b dy z io oi iq ir oj it iv dx">www.tensorflow.org</p></div></div><div class="om l"><div class="pt l oo op oq om or lq od"/></div></div></a></div><p id="c4e9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now it is time to see the transformation process in action. We create a Transform object, and pass example_gen and schema_gen objects, along with the path to the transform.py we created.</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="d7ef" class="ow ox fq ot b bg oy oz l pa pb"># Ignore TF warning messages<br/>tf.get_logger().setLevel('ERROR')<br/><br/># Instantiate the Transform component with example_gen and schema_gen objects<br/># Pass the path for transform file<br/><br/>transform = Transform(<br/>    examples=example_gen.outputs['examples'],<br/>    schema=schema_gen.outputs['schema'],<br/>    module_file=os.path.abspath(_transform_module_file))<br/><br/># Run the component<br/>context.run(transform)</span></pre><p id="75e1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Run it and the transformation part is complete!</p><p id="3843" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Take a look at the transformed data shown in the below image.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pu"><img src="../Images/1303ef6e4514391c58823b9c199134b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n7eMzcQMJ2kMj77UIu2q-w.png"/></div></div></figure><h1 id="d5cc" class="pv ox fq bf pw px py gq pz qa qb gt qc qd qe qf qg qh qi qj qk ql qm qn qo qp bk">Why not just use scikit-learn library or pandas to do this?</h1><p id="a871" class="pw-post-body-paragraph nc nd fq ne b go qq ng nh gr qr nj nk nl qs nn no np qt nr ns nt qu nv nw nx fj bk">This is your question now, right?</p><p id="b12a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This process is not meant for an individual wanting to preprocess their data and get going with model training. It is meant to be applied on large amounts of data (data that mandates distributed processing) and an automated production pipeline that can’t afford to break.</p><p id="38a0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After applying the transform, your folder structure looks like this</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj qv"><img src="../Images/605cd1b6d460c9c789304a9f8bd56bc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*PjUOSk0BagiDM4-EAdOPtQ.png"/></div></figure><p id="3f09" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It contains pre and post transform details. Further, a transform graph is also created.</p><p id="c062" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Remember, we scaled our numerical features using tft.scale_to_0_1. Functions like this requires computing details that require analysis of the entire data (like the mean, minimum and maximum values in a feature). Analyzing data distributed over multiple machines, to get these details is performance intensive (especially if done multiple times). Such details are calculated once and maintained in the transform_graph. Any time a function needs them, it is directly fetched from the transform_graph. It also aids in applying transforms created during the training phase directly to serving data, ensuring consistency in the pre-processing phase.</p><p id="8331" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Another major advantage is of using Tensorflow Transform libraries is that every phase is recorded as artifacts, hence data lineage is maintained. Data Versioning is also automatically done when the data changes. Hence it makes experimentation, deployment and rollback easy in a production environment.</p><p id="6982" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">That’s all to it. If you have any questions please jot them down in the comments section.</p><p id="2b08" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can download the notebook and the data files used in this article from my GitHub repository using this <a class="af nb" href="https://github.com/akila29/TF_Transform_Demo" rel="noopener ugc nofollow" target="_blank">link</a></p></div></div></div><div class="ab cb qw qx qy qz" role="separator"><span class="ra by bm rb rc rd"/><span class="ra by bm rb rc rd"/><span class="ra by bm rb rc"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="30da" class="pv ox fq bf pw px re gq pz qa rf gt qc qd rg qf qg qh rh qj qk ql ri qn qo qp bk">What Next?</h1><p id="7cdd" class="pw-post-body-paragraph nc nd fq ne b go qq ng nh gr qr nj nk nl qs nn no np qt nr ns nt qu nv nw nx fj bk">To get a better understanding of the pipeline components, read the below article.</p><div class="ny nz oa ob oc od"><a href="https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines?source=post_page-----99ffcf49f535--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab ig"><div class="of ab co cb og oh"><h2 class="bf fr hw z io oi iq ir oj it iv fp bk">Understanding TFX Pipelines | TensorFlow</h2><div class="ok l"><h3 class="bf b hw z io oi iq ir oj it iv dx">MLOps is the practice of applying DevOps practices to help automate, manage, and audit machine learning (ML) workflows…</h3></div><div class="ol l"><p class="bf b dy z io oi iq ir oj it iv dx">www.tensorflow.org</p></div></div><div class="om l"><div class="rj l oo op oq om or lq od"/></div></div></a></div></div></div></div><div class="ab cb qw qx qy qz" role="separator"><span class="ra by bm rb rc rd"/><span class="ra by bm rb rc rd"/><span class="ra by bm rb rc"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="c8ec" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Thanks for reading my article. If you like it, please encourage by giving me a few claps, and if you are in the other end of the spectrum, let me know what can be improved in the comments. Ciao.</p><p id="7f3a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Unless otherwise noted, all images are by the author.</p></div></div></div></div>    
</body>
</html>