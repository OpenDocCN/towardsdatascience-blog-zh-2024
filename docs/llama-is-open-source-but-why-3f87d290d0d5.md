# Llama 是开源的，但为什么？

> 原文：[https://towardsdatascience.com/llama-is-open-source-but-why-3f87d290d0d5?source=collection_archive---------5-----------------------#2024-06-25](https://towardsdatascience.com/llama-is-open-source-but-why-3f87d290d0d5?source=collection_archive---------5-----------------------#2024-06-25)

## 观点

## Meta 开源大模型战略分析

[](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[![Haifeng Jin](../Images/705d6ecaed975b6376fac19087f2c02c.png)](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------) [Haifeng Jin](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------) ·6分钟阅读·2024年6月25日

--

![](../Images/9f9d46a904ceb1062f3aa0c3d67d63d6.png)

图片由作者使用 DALL-E 创建

训练一个大语言模型可能花费数百万美元。Meta 为什么会花这么多钱训练一个模型，并且让所有人免费使用？

本文分析了 Meta 的 GenAI 和大模型战略，旨在理解开源大模型的考虑因素。我们还讨论了这波开源模型如何与传统开源软件相似，又有何不同。

免责声明：Llama 模型是否真正开源超出了本文的讨论范围。所有信息均来自公开来源。

## 专有模型的幻象

如果 Meta 开源它的模型，难道人们不会选择自己构建服务，而不是付费使用 Meta 提供的服务（例如，基于 Llama 的 [Meta AI](https://www.meta.ai/) 聊天机器人，API，或者帮助你微调模型并高效提供服务）吗？

通过将模型保持为专有，来阻止人们构建自己的解决方案，这不过是一个幻象。无论是否开源你的模型，其他公司，如 [Mistral AI](https://docs.mistral.ai/#open-source)、[阿里巴巴](https://github.com/QwenLM/Qwen2)，甚至 [谷歌](https://blog.google/technology/developers/gemma-open-models/)，都已开源了他们的模型。

目前，OpenAI、Anthropic 和谷歌并没有开源它们最大/最好的模型，因为它们仍然认为自己处于一个开源模型无法企及的领域，无论是能力还是质量。开源这些模型将对他们的业务造成损害。

除非你的模型比其他任何开源模型好几个数量级，否则是否开源你的模型不会影响用户在开源模型上构建应用程序的质量。

你唯一的选择是成为开源模型的首创者和领导者，或者成为一个追随者，在稍后发布你的模型。

## 为什么要成为开源模型的领导者？

成为开源模型的领导者有许多好处，但最重要的就是吸引人才。

GenAI 的战争是被计算能力瓶颈限制的人才竞争。你获得多少计算能力在很大程度上取决于你与 Nvidia 的现金流关系，[除了谷歌](/tpus-are-not-for-sale-but-why-5964f87f7a15)。然而，拥有多少人才则是另一个问题。

根据[埃隆·马斯克](https://youtu.be/2BfMuHDfGJI?t=2748)的说法，谷歌拥有三分之二的 AI 人才，为了对抗谷歌的力量，他们创办了 OpenAI。随后，一些最顶尖的人才离开了 OpenAI，创办了 Anthropic，专注于 AI 安全。因此，目前市场上这三家公司拥有最优秀、最多的 AI 专家。其他公司都急需更多的 AI 专家。

成为开源模型的领导者将帮助 Meta 弥合 AI 专家的差距。开源模型通过两种方式吸引人才。

首先，AI 专家们想为 Meta 工作。让全世界都使用你构建的模型是超级酷的。这会为你的工作带来大量曝光，扩大你的专业影响力，并且对你未来的职业生涯有好处。所以，许多有才华的人愿意为他们工作。

其次，社区中的 AI 专家们为 Meta 做了免费的工作。在 Llama 发布后不久，人们开始对其进行实验。他们帮助你开发新的服务技术以降低成本，微调模型以发现新应用，并仔细审查模型以发现漏洞，提升其安全性。例如，根据[这篇文章](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)，他们在 Llama 最初发布后一个月内进行了指令调优、量化、质量改进、人类评估、多模态和 RLHF。将这项工作交给社区，帮助 Meta 节省了大量的计算和人力资源。

## 与社区快速迭代。

使用开源模型，Meta 可以通过直接将其新开发的方法融入其中，迅速与社区一起进行迭代。

如果谷歌要采用社区的新方法，成本会有多高？这个过程分为两个阶段：实现和评估。首先，他们需要重新实现该方法以适配 Gemini。这涉及到用 JAX 重写代码，需要大量的工程资源。在评估阶段，他们需要对其进行一系列基准测试，这又需要大量的计算能力。最重要的是，这需要时间。当最新技术首次可用时，它们无法立即进行迭代。

相反，如果 Meta 想要采纳社区的一个新方法，对他们来说几乎没有成本。社区已经直接对 Llama 模型做了实验和基准测试，因此不需要进一步评估。代码是用 PyTorch 编写的，他们可以直接复制并粘贴到自己的系统中。

Llama 在 Meta 和社区之间建立了一个飞轮。Meta 从社区引入最新技术，并将其下一代模型推向社区。PyTorch 是他们共同使用的语言。

## 他们还能赚钱吗？

模型是开源的。人们不会直接建立自己的服务吗？为什么他们还要为一个建立在开源模型上的服务付费给 Meta 呢？当然会。即使是开源模型，构建服务依然很困难。

你如何微调和调整模型以适应你的特定应用？你如何平衡服务成本和模型质量？你是否了解所有技巧，能够充分利用你的 GPU？

知道这些问题答案的人很难找到，且招聘成本高。即使有足够的人力，想要获得足够的计算能力来微调和服务模型也很难。试想一下，如何从开源的 Llama 模型构建 [Meta AI](https://www.meta.ai/)。我预计需要数百名员工和大量 GPU 参与其中。

所以，如果将来有任何类似的 Meta GenAI 服务，人们仍然可能会为其付费。

## 这就像开源软件，但又不完全是。

情况与传统的开源软件非常相似。"[免费代码，付费服务](/tensorflow-is-open-source-but-why-512d849f59d2)" 这一框架依然适用。代码或模型是免费的，用来吸引更多用户加入生态系统。随着生态系统的扩大，拥有者能收获更多的利益。建立在免费代码之上的服务则是为了盈利。

然而，它也并不像开源软件。主要的区别可以总结为低用户留存率和一种新型的生态系统。

## 用户留存率低

开源模型的用户留存率较低。迁移到新模型比迁移到新软件要容易得多。

迁移软件很困难。PyTorch 和 HuggingFace 为深度学习框架和模型池建立了强大的生态系统。试想一下，如果你创建一个新的深度学习框架或模型池来与他们竞争，想要稍微改变他们的主导地位有多么困难。

一个很好的例子是 JAX。它对大规模分布式训练提供了更好的支持，但由于生态系统和社区较小，很难吸引用户使用 JAX。它缺乏一个能帮助用户解决问题的有力社区。而且，将整个基础设施迁移到新的框架的工程成本对大多数公司来说太高了。

开源模型没有这些问题。它们易于迁移，几乎不需要用户支持。因此，人们可以轻松转向最新和最好的模型。要在开源模型中保持领导地位，你必须不断发布位于排行榜顶部的新模型。这也是成为开源模型领导者的一大挑战或缺点。

## 一种新型的生态系统

开源模型创造了一种新型的生态系统。与开源软件创造贡献者和新软件生态系统不同，开源模型创造了微调和量化模型的生态系统，这些模型可以看作是原始模型的分支。

因此，一个开源基础模型不必在每个具体任务上都表现得非常优秀，因为用户可以通过领域特定的数据对其进行微调以适应他们的应用需求。基础模型最重要的特点是能够满足用户的部署要求，例如推理时的低延迟，或者足够小以适应终端设备。

这就是为什么 Llama 为每个版本提供多个尺寸的原因。例如，Llama-3 有三个版本：8B、70B 和 400B。他们希望确保涵盖所有的部署场景。

## 总结

即使 Meta 不开源他们的模型，其他公司也会开源。所以，Meta 提前开源并领导开源模型将是明智之举。然后，Meta 可以与社区快速迭代，改进其模型，赶上 OpenAI 和 Google。

在开源你的模型时，不必担心人们不使用你的服务，因为基础模型与构建良好的服务之间仍然存在巨大的差距。

开源模型类似于开源软件，它们都遵循“自由代码付费服务”框架，但在用户留存率和所创建的生态系统类型上有所不同。

未来，我预计会看到更多来自更多公司的开源模型。与已集中在 PyTorch 上的深度学习框架不同，开源模型将在很长一段时间内保持多样性和竞争力。
