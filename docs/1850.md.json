["```py\nfrom bertopic import BERTopic\nfrom umap import UMAP \nfrom hdbscan import HDBSCAN\nfrom sentence_transformers import SentenceTransformer \nfrom bertopic.vectorizers import ClassTfidfTransformer\n\ntopic_size_ = 7\n\n# Sentence Embedding in Hebrew (works well also on English)\nsent_emb_model = \"imvladikon/sentence-transformers-alephbert\"\nsentence_model = SentenceTransformer(sent_emb_model)\n\n# Initialize UMAP model for dimensionality reduction to improve BERTopic\numap_model = UMAP(n_components=128, n_neighbors=4, min_dist=0.0)\n\n# Initialize HDBSCAN model for BERTopic clustering\nhdbscan_model = HDBSCAN(min_cluster_size = topic_size_, \n                        gen_min_span_tree=True, \n                        prediction_data=True, \n                        min_samples=2)\n\n# class-based TF-IDF vectorization for topic representation prior to clustering\nctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n\n# Initialize MaximalMarginalRelevance for enhancing topic representation\nrepresentation_model = MaximalMarginalRelevance(diversity=0.1)\n\n# Configuration for BERTopic\nbert_config = {\n    'embedding_model': sentence_model,  \n    'top_n_words': 20,  # Number of top words to represent each topic\n    'min_topic_size': topic_size_,  \n    'nr_topics': 40, \n    'low_memory': False, \n    'calculate_probabilities': False, \n    'umap_model': umap_model, \n    'hdbscan_model': hdbscan_model, \n    'ctfidf_model': ctfidf_model, \n    'representation_model': representation_model\n}\n\n# Initialize BERTopic model with the specified configuration\ntopic_model = BERTopic(**bert_config)\n```"]