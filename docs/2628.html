<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The Ultimate Guide to RAGs — Each Component Dissected</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>The Ultimate Guide to RAGs — Each Component Dissected</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-ultimate-guide-to-rags-each-component-dissected-3cd51c4c0212?source=collection_archive---------0-----------------------#2024-10-29">https://towardsdatascience.com/the-ultimate-guide-to-rags-each-component-dissected-3cd51c4c0212?source=collection_archive---------0-----------------------#2024-10-29</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="97e0" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A visual tour of what it takes to build production-ready LLM pipelines</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@neural.avb?source=post_page---byline--3cd51c4c0212--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Avishek Biswas" class="l ep by dd de cx" src="../Images/6feb591069f354aa096f6108f1a70ea7.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*7-2CKsevyqzgVs8m"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--3cd51c4c0212--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@neural.avb?source=post_page---byline--3cd51c4c0212--------------------------------" rel="noopener follow">Avishek Biswas</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--3cd51c4c0212--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 29, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/e75abdffaf2c2c493ffd5ea61939f229.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uy-1psIHuGC1uvMuc89o7g.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Let’s learn RAGs! (Image by Author)</figcaption></figure><p id="3b4a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If you have worked with Large Language Models, there is a great chance that you have at least heard the term RAG — Retrieval Augmented Generation. The idea of RAGs are pretty simple — suppose you want to ask a question to a LLM, instead of just relying on the LLM’s pre-trained knowledge, you first retrieve relevant information from an external knowledge base. This retrieved information is then provided to the LLM along with the question, allowing it to generate a more informed and up-to-date response.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/c29b45a46c05f489f1ce51b45fa9711a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u4du9Epf5lCMaAIrOWc5FQ.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Comparing standard LLM calls with RAG (Source: Image by Author)</figcaption></figure><p id="3c42" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">So, why use Retrieval Augmented Generation?</strong></p><p id="4734" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">When providing <strong class="ne fr">accurate and up-to-date information</strong> is key, you cannot rely on the LLM’s inbuilt knowledge. RAGs are a cheap practical way to use LLMs to generate content about recent topics or niche topics <strong class="ne fr">without needing to finetune</strong> them on your own and burn away your life’s savings. Even when LLMs internal knowledge may be enough to answer questions, it might be a good idea to use RAGs anyway, <a class="af ny" href="https://arxiv.org/html/2404.08189v1" rel="noopener ugc nofollow" target="_blank">since recent studies have shown that they could help reduce LLMs hallucinations.</a></p><h1 id="565e" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">The different components of a bare-bones RAG</h1><p id="8645" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Before we dive into the advanced portion of this article, let’s review the basics. Generally RAGs consist of two pipelines — <strong class="ne fr">preprocessing and inferencing</strong>.</p><p id="1cc4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Inferencing</strong> is all about using data from your existing database to answer questions from a user query. <strong class="ne fr">Preprocessing </strong>is the process of setting up the database in the correct way so that retrieval is done correctly later on.</p><p id="57bf" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here is a diagramatic look into the entire basic barebones RAG pipeline.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pa"><img src="../Images/39ef29751baffd2a51ab35e9ebba7411.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dkzpV-Cp-Viwa5kWxbeszA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">The Basic RAG pipeline (Image by Author)</figcaption></figure><h2 id="7420" class="pb oa fq bf ob pc pd pe oe pf pg ph oh nl pi pj pk np pl pm pn nt po pp pq pr bk">The Indexing or Preprocessing Steps</h2><p id="be67" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">This is the offline preprocessing stage, where we would set up our database.</p><ol class=""><li id="5fa0" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ps pt pu bk"><strong class="ne fr">Identify Data Source</strong>: Choose a relevant data source based on the application, such as Wikipedia, books, or manuals. Since this is domain dependent, I am going to skip over this step in this article. Go choose any data you want to use, knock yourself out!</li><li id="da18" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx ps pt pu bk"><strong class="ne fr">Chunking the Data</strong>: Break down the dataset into smaller, manageable documents or chunks.</li><li id="81ad" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx ps pt pu bk"><strong class="ne fr">Convert to Searchable Format</strong>: Transform each chunk into a numerical vector or similar searchable representation.</li><li id="e742" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx ps pt pu bk"><strong class="ne fr">Insert into Database</strong>: Store these searchable chunks in a custom database, though external databases or search engines could also be used.</li></ol><h2 id="33df" class="pb oa fq bf ob pc pd pe oe pf pg ph oh nl pi pj pk np pl pm pn nt po pp pq pr bk">The Inferencing Steps</h2><p id="9af6" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">During the Query Inferencing stage, the following components stand out.</p><ol class=""><li id="7baa" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ps pt pu bk"><strong class="ne fr">Query Processing</strong>: A method to convert the user’s query into a format suitable for search.</li><li id="4971" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx ps pt pu bk"><strong class="ne fr">Retrieval/Search Strategy</strong>: A similarity search mechanism to retrieve the most relevant documents.</li><li id="bc44" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx ps pt pu bk"><strong class="ne fr">Post-Retrieval Answer Generation</strong>: Use retrieved documents as context to generate the answer with an LLM.</li></ol><p id="c733" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Great — so we identified several key modules required to build a RAG. Believe it or not, each of these components have a lot of additional research to make this simple RAG turn into CHAD-rag. Let’s look into each of the major components in this list, starting with chunking.</p><figure class="mm mn mo mp mq mr"><div class="qa io l ed"><div class="qb qc l"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">This article is based on this Youtube video</figcaption></figure><p id="76bd" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr"><em class="qd">By the way, this article is based on this 17-minute Youtube video I made on the same topic, covering all the topics in this article. Feel free to check it out after reading this Medium article!</em></strong></p></div></div></div><div class="ab cb qe qf qg qh" role="separator"><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="9797" class="nz oa fq bf ob oc qm gq oe of qn gt oh oi qo ok ol om qp oo op oq qq os ot ou bk">1. Chunking</h1><p id="5c57" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Chunking is the process of breaking down large documents into smaller, manageable pieces. It might sound simple, but trust me, the way you chunk your data can make or break your RAG pipeline. Whatever chunks you create during preprocessing will eventually get retrieved during inference. If you make the size of chunks too small — like each sentence — then it might be difficult to retrieve them through search because they capture very little information. If the chunk size is too big — like inserting entire Wikipedia articles — the retrieved passages might end up confusing the LLM because you are sending large bodies of texts at once.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/967b63a03b974ae50ac5aabda8f455f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TlSNAqNGGxk8C2NocaNfdQ.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Depending on the different levels of chunking, your results may vary! (Image by author)</figcaption></figure><p id="c011" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Some frameworks use LLMs to do chunking, for example by extracting simple factoids or propositions from the text corpus, and treat them as documents. This could be expensive because the larger your dataset, the more LLM calls you’ll have to make.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/b84d0c25979742b7fa6f815c18b4b9c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9miTeaJPWG_0RMQmtMhpA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Proposition Chunking (Source: <a class="af ny" href="https://arxiv.org/pdf/2312.06648" rel="noopener ugc nofollow" target="_blank">Dense X Retrieval Paper</a>. License: Free)</figcaption></figure><h2 id="c32e" class="pb oa fq bf ob pc pd pe oe pf pg ph oh nl pi pj pk np pl pm pn nt po pp pq pr bk">Structural Chunking</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/ac673609cd4ba4dd7f4e383864696009.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iMOyx8dAvUCH8r3EWmDk6Q.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">If your data has inherent boundaries (like HTML or Code), sometimes it is best to just utilize it. (Image by Author)</figcaption></figure><p id="7292" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Quite often we may also deal with datasets that inherently have a known structure or format. For example, if you want to insert code into your database, you can simply split each script by the function names or class definitions. For HTML pages like Wikipedia articles, you can split by the heading tags — for example, split by the H2 tags to isolate each sub-chapter.</p><h2 id="2c5e" class="pb oa fq bf ob pc pd pe oe pf pg ph oh nl pi pj pk np pl pm pn nt po pp pq pr bk">Contextual Chunking</h2><p id="9174" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">But there are some glaring issues with the types of chunking we have discussed so far. Suppose your dataset consists of tens of thousands of paragraphs extracted from all Sherlock Holmes books. Now the user has queried something general like what was the first crime in Study in Scarlet? What do you think is going to happen?</p><p id="619e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The problem is that since each documented is an isolated piece of information, we don’t know which chunks are from the book Study in Scarlet. Therefore, later on during retrieval, we will end up fetch a bunch of passages about the topic “crime” without knowing if it’s relevant to the book. To resolve this, we can use something known as contextual chunking.</p><p id="7b8d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Enter Contextual Chunking</strong></p><p id="8dd9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><a class="af ny" href="https://anthropic.com/news/contextual-retrieval" rel="noopener ugc nofollow" target="_blank">A recent blogpost</a> from Anthropic describes it as prepending chunk-specific explanatory context to each chunk before embedding. Basically, while we are indexing, we would also include additional information relevant to the chunk — like the name of the book, the chapter, maybe a summary of the events in the book. Adding this context will allow the retriever to find references to Study in Scarlett and crimes when searching, hopefully getting the right documents from the database!</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/094e3126d94897eb876a84b373778c79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8E5VOrmQX01XMpXqyije9A.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Contextual Chunking adds additional information to the chunks than just the text body (Image by author)</figcaption></figure><p id="c6bb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There are other ways to solve the problem of finding the right queries — like metadata filtering, We will talk about this later when we talk about Databases.</p></div></div></div><div class="ab cb qe qf qg qh" role="separator"><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="b49d" class="nz oa fq bf ob oc qm gq oe of qn gt oh oi qo ok ol om qp oo op oq qq os ot ou bk">2. Data Conversion</h1><p id="fa65" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Next, we come to the data-conversion stage. Note that whatever strategy we used to convert the documents during preprocessing, we need to use it to search for similarity later, so these two components are tightly coupled.</p><p id="fa7a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Two of the most common approaches that have emerged in this space are <strong class="ne fr">embedding based methods</strong> and <strong class="ne fr">keyword-frequency based methods</strong> like TF-IDF or BM-25.</p><h2 id="c516" class="pb oa fq bf ob pc pd pe oe pf pg ph oh nl pi pj pk np pl pm pn nt po pp pq pr bk">Embedding Based Methods</h2><p id="c1aa" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">We’ll start with embedding-based methods. Here, we use pretrained transformer models to transform the text into high-dimensional vector representations, capturing semantic meaning about the text. Embeddings are great for capturing semantic relationships, handling synonyms, and understanding context-dependent meanings. However, embedding can be computationally intensive, and can sometimes overlook exact matches that simpler methods would easily catch.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/eea86572fe8b84983f6e3fb254176d90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wbvyG4yT2TKalYMB7i9bhw.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Embeddings (Image by Author)</figcaption></figure><h2 id="d793" class="pb oa fq bf ob pc pd pe oe pf pg ph oh nl pi pj pk np pl pm pn nt po pp pq pr bk">When does Semantic Search fail?</h2><p id="fa55" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">For example, suppose you have a database of manuals containing information about specific refrigerators. When you ask a query mentioning a very specific niche model or a serial number, embeddings will fetch documents that kind of resemble your query, but may fail to exactly match it. This brings us to the alternative of embeddings retrieval — keyword based retrieval.</p><h2 id="63dd" class="pb oa fq bf ob pc pd pe oe pf pg ph oh nl pi pj pk np pl pm pn nt po pp pq pr bk">Keyword Based Methods</h2><p id="ad2b" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Two popular keyword-based methods are TF-IDF and BM25. These algorithms focus on statistical relationships between terms in documents and queries.</p><p id="1d9e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">TF-IDF weighs the importance of a word based on its frequency in a document relative to its frequency in the entire corpus. Every document in our dataset is be represented by a array of TF-IDF scores for each word in the vocabulary. The indices of the high values in this document vector tell us which words that are likely to be most characteristic of that document’s content, because these words appear more frequently in this document and less frequently in others. For example, the documents related to this Godrej A241gX , will have a high TF-IDF score for the phrase Godrej and A241gX, making it more likely for us to retrieve this using TF-IDF.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/030fa185bf92ef2d88efe95f98253679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9e5K9CPt9l1JJOW_WK82nw.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">TF-IDF relies on the ratio of the occurence of terms in a document compared to the entire corpus. (Image by author)</figcaption></figure><p id="7d92" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">BM25, an evolution of TF-IDF, incorporates document length normalization and term saturation. Meaning that it adjusts the TF-IDF score based on if the document itself is longer or shorter than the average document length in the collection. Term saturation means that as a particular word appears too often in the database, it’s importance decreases.</p><p id="0b27" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">TF-IDF and BM-25 are great finding documents with specific keyword occurrences when they exactly occur. And embeddings are great for finding documents with similar semantic meaning.</p><p id="af27" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">A common thing these days is to retrieve using both keyword and embedding based methods, and combine them, giving us the best of both worlds. </strong>Later on when we discuss Reciprocal Rank Fusion and Deduplication, we will look into how to combine these different retrieval methods.</p></div></div></div><div class="ab cb qe qf qg qh" role="separator"><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="aa55" class="nz oa fq bf ob oc qm gq oe of qn gt oh oi qo ok ol om qp oo op oq qq os ot ou bk">3. Databases</h1><p id="098a" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Up next, let’s talk about Databases. The most common type of database that is used in RAGs are <strong class="ne fr">Vector Databases</strong>. Vector databases store documents by indexing them with their vector representation, be in from an embedding, or TF-IDF. Vector databases specialize in fast similarity check with query vectors, making them ideal for RAG. Popular vector databases that you may want to look into are Pinecone, Milvus, ChromaDB, MongoDB, and they all have their pros and cons and pricing model.</p><p id="52af" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">An alternative to vector databases are <strong class="ne fr">graph databases</strong>. Graph databases store information as a network of documents with each document connected to others through relationships.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/cf61de385aadd84baf03ba5bd4f69fa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*36aU1yyTNhLrrMyQzuubLQ.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Modern Vector Databases allow attribute filtering with semantic search (Image by Author)</figcaption></figure><p id="e4a8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Many modern vector and graph database also allow properties from relational databases, most notably metadata or attribute filtering. If you know the question is about the 5th Harry Potter book, it would be really nice to filter your entire database first to only contain documents from the 5th Harry Potter book, and not run embeddings search through the entire dataset. Optimal metadata filtering in Vector Databases is a pretty amazing area in Computer Science research, and a seperate article would be best for a in-depth discussion about this.</p></div></div></div><div class="ab cb qe qf qg qh" role="separator"><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="db2e" class="nz oa fq bf ob oc qm gq oe of qn gt oh oi qo ok ol om qp oo op oq qq os ot ou bk">4. Query transformation</h1><p id="e0e3" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk"><strong class="ne fr">Next, let’s move to inferencing starting with query transformation — which is any preprocessing step we do to the user’s actual query before doing any similarity search. Think of it like improving the user’s question to get better answers.</strong></p><p id="926d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In general, we want to avoid searching directly with the user query. User inputs are usually very noisy and they can type random stuff — we want an additional transformation layer that interprets the user query and turns it into a search query.</p><h2 id="7b48" class="pb oa fq bf ob pc pd pe oe pf pg ph oh nl pi pj pk np pl pm pn nt po pp pq pr bk">A simple example why Query Rewriting is important</h2><p id="c895" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">The most common technique to do this transformation is query rewriting. Imagine someone asks, “<strong class="ne fr">What happened to the artist who painted the Mona Lisa?</strong>” If we do semantic or keyword searches, the retrieved information will be all about the Mona Lisa, not about the artist. A query rewriting system would use an LLM to rewrite this query. The LLM might transform this into “<strong class="ne fr">Leonardo da Vinci Mona Lisa artist</strong>”, which will be a much fruitful search.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/0ef4f1d430fde82b990b925ff0b9bdab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8lCf7gpGTFmEE2yZANQEzg.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Direct Retrieval vs Query Rewriting (Image by Author)</figcaption></figure><p id="e53d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Sometimes we would also use <strong class="ne fr">Contextual Query Writing</strong>, where we might use additional contexts, like using the older conversation transcript from the user, or if we know that our application covers documents from 10 different books, maybe we can have a classifier LLM that classifies the user query to detect which of the 10 books we are working with. If our database is in a different language, we can also translate the query.</p><p id="5aab" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><a class="af ny" href="https://arxiv.org/abs/2212.10496" rel="noopener ugc nofollow" target="_blank">There are also powerful techniques like HYDE</a>, which stands for <strong class="ne fr">Hypothetical Document Embedding</strong>. HYDE uses a language model to generate a hypothetical answer to the query, and do similarity search with this hypothetical answer to retrieve relevant documents.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/89020eaaea924ddb06e90b8dc7705e20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t0RLANA0mtFLdhKGgbDNqA.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Hypothetical Document Embeddings (Image by Author)</figcaption></figure><p id="6ee9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Another technique is <strong class="ne fr">Multi-Query Expansion</strong> where we generate multiple queries from the single user query and perform parallel searches to retrieve multiple sets of documents. The received documents can then later go through a de-duplication step or rank fusion to remove redundant documents.</p><p id="d2cd" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A recent approach called <a class="af ny" href="https://arxiv.org/abs/2410.07176" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">Astute RAG</strong></a><strong class="ne fr"> </strong>tries to consolidate externally input knowledge with the LLM’s own internal knowledge before generating answers. There are also <strong class="ne fr">Multi-Hop techniques like Baleen programs</strong>. They work by performing an initial search, analyzing the top results to find frequently co-occurring terms, and then adding these terms to the original query. This adaptive approach can help bridge the vocabulary gap between user queries and document content, and help retrieve better documents.</p></div></div></div><div class="ab cb qe qf qg qh" role="separator"><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="569c" class="nz oa fq bf ob oc qm gq oe of qn gt oh oi qo ok ol om qp oo op oq qq os ot ou bk">5. Post Retrieval Processing</h1><p id="265d" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Now that we’ve retrieved our potentially relevant documents, we can add another post-retrieval processing step before feeding information to our language model for generating the answer.</p><p id="2db2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For example, we can do information selection and emphasis, where an LLM selects portion of the retrieved documents that could be useful for finding the answer. We might highlight key sentences, or do semantic filtering where we remove unimportant paragraphs, or do context summarization by fusing multiple documents into one. The goal here is to avoid overwhelming our LLM with too much information, which could lead to less focused or accurate responses.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/1afd67da02e55c50540e235d5695a19d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h4MofGlJA4fWMTP9dfU1-w.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">You can use smaller LLMs to flag relevant info from retrieved documents before consolidating the context prompt for the final LLM call (Image by Author)</figcaption></figure><p id="3e79" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Often we do multiple queries with query expansion, or use multiple retrieval algorithms like Embeddings+BM-25 to separately fetch multiple documents. To remove duplicates, we often use reranking methods like Reciprocal Rank Fusion. RRF combines the rankings from all the different approaches, giving higher weight to documents that consistently rank well across multiple methods. In the end, the top K high ranking documents are passed to the LLM.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/e7640eabc4d48854d1a9da9a4ecd3379.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*atRwalhrP2K_na7uUCIEjQ.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Reciprocal Rank Fusion is a classic Search Engine algorithm to combine item ranks obtained from multiple ranking algorithms (Image by author)</figcaption></figure><p id="70b3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><a class="af ny" href="https://arxiv.org/abs/2305.06983" rel="noopener ugc nofollow" target="_blank">FLARE or forward-looking active retrieval augmented generation</a> is an iterative post-retrieval strategy. Starting with the user input and initial retrieval results, an LLM iteratively guesses the next sentence. Then we check if the generated guess contains any low probability tokens indicated here with an underline — if so, we call the retriever to retrieve useful documents from the dataset and make necessary corrections.</p></div></div></div><div class="ab cb qe qf qg qh" role="separator"><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk ql"/><span class="qi by bm qj qk"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="53c8" class="nz oa fq bf ob oc qm gq oe of qn gt oh oi qo ok ol om qp oo op oq qq os ot ou bk">Final Thoughts</h1><figure class="mm mn mo mp mq mr"><div class="qa io l ed"><div class="qb qc l"/></div></figure><p id="1c6e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For a more visual breakdown of the different components of RAGs, do checkout my Youtube video on this topic. The field of LLMs and RAGs are rapidly evolving — a thorough understanding of the RAG framework is incredibly essential to appreciate the pros and cons of each approach and weigh which approaches work best for YOUR use-case. The next time you are thinking of designing a RAG system, do stop and ask yourself these questions —</p><ul class=""><li id="ac67" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx qs pt pu bk">What are my data sources?</li><li id="d3c8" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx qs pt pu bk">How should I chunk my data? Is there inherent structure that comes with my data domain? Do my chunks need additional context (contextual chunking)?</li><li id="91c3" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx qs pt pu bk">Do I need semantic retrieval (embeddings) or more exact-match retrieval (BM-25)? What type of queries am I expecting from the user?</li><li id="435f" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx qs pt pu bk">What database should I use? Is my data a graph? Does it need metadata-filtering? How much money do I want to spend on databases?</li><li id="27cd" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx qs pt pu bk">How can I best rewrite the user query for easy search hits? Can an LLM rewrite the queries? Should I use HYDE? If LLMs already have enough domain knowledge about my target field, can I use Astute?</li><li id="32a4" class="nc nd fq ne b go pv ng nh gr pw nj nk nl px nn no np py nr ns nt pz nv nw nx qs pt pu bk">Can I combine multiple different retrieval algorithms and then do rank fusion? (honestly, just do it if you can afford it cost-wise and latency-wise)</li></ul><h1 id="6f77" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">The Author</h1><p id="d37e" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Check out my Youtube channel where I post content about Deep Learning, Machine Learning, Paper Reviews, Tutorials, and just about anything related to AI (except news, there are WAY too many Youtube channels for AI news). Here are some of my links:</p><p id="68c7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Youtube Channel:</strong> <a class="af ny" href="https://www.youtube.com/@avb_fj" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/@avb_fj</a></p><p id="4a38" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Patreon:</strong> <a class="af ny" href="https://www.patreon.com/c/NeuralBreakdownwithAVB" rel="noopener ugc nofollow" target="_blank">https://www.patreon.com/c/NeuralBreakdownwithAVB</a></p><p id="01c0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Give me a follow on Medium and a clap if you enjoyed this!</p><h1 id="fad9" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">References</h1><p id="b0bf" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Vector Databases: <a class="af ny" href="https://superlinked.com/vector-db-comparison" rel="noopener ugc nofollow" target="_blank">https://superlinked.com/vector-db-comparison</a></p><p id="d24f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Metadata Filtering: <a class="af ny" href="https://www.pinecone.io/learn/vector-search-filtering/" rel="noopener ugc nofollow" target="_blank">https://www.pinecone.io/learn/vector-search-filtering/</a></p><p id="677b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Contextual Chunking: <a class="af ny" href="https://www.anthropic.com/news/contextual-retrieval" rel="noopener ugc nofollow" target="_blank">https://www.anthropic.com/news/contextual-retrieval</a></p><p id="e201" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Propositions / Dense X Retrieval: <a class="af ny" href="https://arxiv.org/pdf/2312.06648" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2312.06648</a></p><p id="26a3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Hypothetical Document Embeddigs (HYDE): <a class="af ny" href="https://arxiv.org/abs/2212.10496" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2212.10496</a></p><p id="f36e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">FLARE: <a class="af ny" href="https://arxiv.org/abs/2305.06983" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2305.06983</a></p></div></div></div></div>    
</body>
</html>