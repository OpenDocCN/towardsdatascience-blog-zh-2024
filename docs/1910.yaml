- en: 'Gemma vs. Llama vs. Mistral: Exploring Smaller AI Models'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/gemma-vs-llama-vs-mistral-exploring-smaller-ai-models-672a95f4b9b7?source=collection_archive---------4-----------------------#2024-08-06](https://towardsdatascience.com/gemma-vs-llama-vs-mistral-exploring-smaller-ai-models-672a95f4b9b7?source=collection_archive---------4-----------------------#2024-08-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'A Comparative Study of Small-Scale Language Models: Evaluating Gemma, Llama
    3, and Mistral in Reading Comprehension Tasks'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@luisroque?source=post_page---byline--672a95f4b9b7--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page---byline--672a95f4b9b7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--672a95f4b9b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--672a95f4b9b7--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page---byline--672a95f4b9b7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--672a95f4b9b7--------------------------------)
    ·14 min read·Aug 6, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*This post was co-authored with Rafael Guedes.*'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have been evolving rapidly. Each month, new models
    are developed to surpass the current top scorers in the market. This healthy competition
    is beneficial for creating new approaches that increase quality and speed. Additionally,
    companies are focused on developing smaller models to make them accessible to
    individuals or organizations without powerful computing resources.
  prefs: []
  type: TYPE_NORMAL
- en: Just a few weeks ago, Apple introduced Apple Intelligence at their Worldwide
    Developers Conference. This is a set of multiple generative models fine-tuned
    to help users write and refine text, prioritize and summarize notifications, create
    images, and take in-app actions. The only foundational and proprietary model developed
    by Apple in that suite was introduced at the same conference. It is a small model
    designed to run on-device, where the hardware becomes a significant constraint.
    In Apple’s case, the model is closed-source. What we know is that it is a ~3 billion
    parameter model on par with the 7b versions of Gemma, Mistral, and Llama 3 (according
    to the results shared by Apple).
  prefs: []
  type: TYPE_NORMAL
