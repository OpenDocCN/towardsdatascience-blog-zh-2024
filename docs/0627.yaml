- en: End to End AI Use Case-Driven System Design
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 端到端AI应用场景驱动的系统设计
- en: 原文：[https://towardsdatascience.com/end-to-end-ai-use-case-driven-system-design-6eb1e9b14944?source=collection_archive---------10-----------------------#2024-03-07](https://towardsdatascience.com/end-to-end-ai-use-case-driven-system-design-6eb1e9b14944?source=collection_archive---------10-----------------------#2024-03-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/end-to-end-ai-use-case-driven-system-design-6eb1e9b14944?source=collection_archive---------10-----------------------#2024-03-07](https://towardsdatascience.com/end-to-end-ai-use-case-driven-system-design-6eb1e9b14944?source=collection_archive---------10-----------------------#2024-03-07)
- en: A thorough list of Technologies for best Performance/Watt
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最佳性能/瓦特的技术全面列表
- en: '[](https://medium.com/@LizLiAI?source=post_page---byline--6eb1e9b14944--------------------------------)[![Liz
    Li](../Images/78846add1618c8c095dd97adeca87f81.png)](https://medium.com/@LizLiAI?source=post_page---byline--6eb1e9b14944--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6eb1e9b14944--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6eb1e9b14944--------------------------------)
    [Liz Li](https://medium.com/@LizLiAI?source=post_page---byline--6eb1e9b14944--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@LizLiAI?source=post_page---byline--6eb1e9b14944--------------------------------)[![Liz
    Li](../Images/78846add1618c8c095dd97adeca87f81.png)](https://medium.com/@LizLiAI?source=post_page---byline--6eb1e9b14944--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6eb1e9b14944--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6eb1e9b14944--------------------------------)
    [Liz Li](https://medium.com/@LizLiAI?source=post_page---byline--6eb1e9b14944--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6eb1e9b14944--------------------------------)
    ·7 min read·Mar 7, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6eb1e9b14944--------------------------------)
    ·阅读时间7分钟·2024年3月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The most commonly used metric to define AI performance is TOPs (Tera Operations
    Per Second), which indicates compute capability but oversimplifies the complexity
    of AI systems. When it comes to real AI use case system design, many other factors
    should also be considered beyond TOPs, including memory/cache size and bandwidth,
    data types, energy efficiency, etc.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 定义AI性能最常用的指标是TOPs（每秒万亿次操作），它表示计算能力，但简化了AI系统的复杂性。在真正的AI应用场景系统设计中，除了TOPs之外，还需要考虑许多其他因素，包括内存/缓存大小和带宽、数据类型、能效等。
- en: Moreover, each AI use case has its characteristics and requires a holistic examination
    of the whole use case pipeline. This examination delves into its impact on system
    components and explores optimization techniques to predict the best pipeline performance.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每个AI应用场景都有其独特性，需要对整个应用场景的流程进行全面审视。这种审视深入分析其对系统组件的影响，并探索优化技术，以预测最佳的流程性能。
- en: '![](../Images/f359afd76118bc72c1cfc8249e68a20a.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f359afd76118bc72c1cfc8249e68a20a.png)'
- en: Image by author
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: In this post, we pick one AI use case — an end-to-end real-time infinite zoom
    feature with a stable diffusion-v2 inpainting model and study how to build a corresponding
    AI system with the best performance/Watt. This can serve as a proposal, with both
    well-established technologies and new research ideas that can lead to potential
    architectural features.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们选择了一个AI应用场景——一个端到端的实时无限缩放功能，使用稳定扩散-v2修复模型，并研究如何构建一个具有最佳性能/瓦特的对应AI系统。这可以作为一个提案，包含了既有的成熟技术和新的研究思路，可能引发潜在的架构特性。
- en: Background on end-to-end video zoom
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 端到端视频缩放背景
- en: As shown in the below diagram, to zoom out video frames (fish image), we resize
    and apply a border mask to the frames before feeding them into the stable diffusion
    inpainting pipeline. Alongside an input text prompt, this pipeline generates frames
    with new content to fill the border-masked region. This process is continuously
    applied to each frame to achieve the continuous zoom-out effect. To conserve compute
    power, we may **sparsely sample video frames to avoid inpainting every frame**(e.g.,
    generating 1 frame every 5 frames) if it still delivers a satisfactory user experience.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如下图所示，为了缩小视频帧（鱼图像），我们先调整帧的大小并应用边框遮罩，然后将其输入稳定扩散修复管道。在输入文本提示的帮助下，该管道生成带有新内容的帧，以填补边框遮罩区域。这个过程不断应用于每一帧，以实现连续的缩放效果。为了节省计算资源，我们可以**稀疏采样视频帧，以避免对每一帧进行修复**（例如，每隔5帧生成1帧），如果这样仍能提供令人满意的用户体验。
- en: '![](../Images/296e2f107c1b9547cdab192a96052340.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/296e2f107c1b9547cdab192a96052340.png)'
- en: 'Frame generation. Source: [Infinite Zoom Stable Diffusion v2 and OpenVINO™](https://docs.openvino.ai/2023.2/notebooks/236-stable-diffusion-v2-infinite-zoom-with-output.html)
    [1]'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 帧生成。来源：[无限缩放稳定扩散v2和OpenVINO™](https://docs.openvino.ai/2023.2/notebooks/236-stable-diffusion-v2-infinite-zoom-with-output.html)
    [1]
- en: '[Stable diffusion-v2 inpainting](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting)
    pipeline is pre-trained on stable diffusion-2 model, which is a text-to-image
    latent diffusion model created by stability AI and LAION. The blue box in below
    diagram displays each function block in the inpainting pipeline'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[稳定扩散-v2 修复](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting)管道在稳定扩散-2模型上进行预训练，该模型是由Stability
    AI和LAION创建的文本到图像潜在扩散模型。下图中的蓝色框显示了修复管道中的每个功能模块。'
- en: '![](../Images/bc53101f16bb0e22374ffa92857fa6d7.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc53101f16bb0e22374ffa92857fa6d7.png)'
- en: 'Inpainting pipeline (inputs include text prompt, masked image and input random
    noise). Source: [Infinite Zoom Stable Diffusion v2 and OpenVINO™](https://docs.openvino.ai/2023.2/notebooks/236-stable-diffusion-v2-infinite-zoom-with-output.html)
    [1]'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 修复管道（输入包括文本提示、遮蔽图像和输入的随机噪声）。来源：[无限缩放稳定扩散v2和OpenVINO™](https://docs.openvino.ai/2023.2/notebooks/236-stable-diffusion-v2-infinite-zoom-with-output.html)
    [1]
- en: Stable diffusion-2 model generates 768*768 resolution images, it is trained
    to denoise random noise iteratively (50 steps) to get a new image. The denoising
    process is implemented by Unet and scheduler which is a very slow process and
    requires lots of compute and memory.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稳定扩散-2模型生成768*768分辨率的图像，经过训练后，通过迭代去噪（50步）从随机噪声中得到新的图像。去噪过程由Unet和调度器实现，这是一个非常缓慢的过程，需要大量的计算和内存。
- en: '![](../Images/91d84efdae6306a1826afd8fe5782b48.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91d84efdae6306a1826afd8fe5782b48.png)'
- en: 'Stable diffusion-2-base model. Source: [The Illustrated Stable Diffusion](https://jalammar.github.io/illustrated-stable-diffusion/)
    [2]'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散-2基础模型。来源：[插图版稳定扩散](https://jalammar.github.io/illustrated-stable-diffusion/)
    [2]
- en: 'There are 4 models used in the pipeline as below:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是管道中使用的4个模型：
- en: '**VAE (image encoder)**. Convert image into low dimensional latent representation
    (64*64)'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**VAE（图像编码器）**。将图像转换为低维潜在表示（64*64）。'
- en: '**CLIP (text encoder)**. Transformer architecture (77*768), 85MP'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**CLIP（文本编码器）**。Transformer架构（77*768），85MP。'
- en: '**UNet (diffusion process)**. Iteratively denoising processing via a schedular
    algorithm, 865M'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**UNet（扩散过程）**。通过调度算法进行迭代去噪处理，865M。'
- en: '**VAE (image decoder).** Transforms the latent representation back into an
    image (512*512)'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**VAE（图像解码器）**。将潜在表示转换回图像（512*512）。'
- en: Most stable Diffusion operations (98% of the autoencoder and text encoder models
    and 84% of the U-Net) are **convolutions**. The bulk of the remaining U-Net operations
    (16%) are dense matrix multiplications due to the self-attention blocks. These
    models can be pretty big (varies with different hyperparameters) which requires
    lots of memory, for mobile devices with limited memory, it is essential to explore
    model compression techniques to reduce the model size, including quantization
    (2–4x mode size reduction and 2-3x speedup from FP16 to INT4), pruning, sparsity,
    etc.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数稳定扩散操作（98%的自动编码器和文本编码器模型，以及84%的U-Net）是**卷积**。剩余的U-Net操作的大部分（16%）是密集矩阵乘法，原因在于自注意力模块。这些模型可能非常庞大（不同超参数会有所不同），因此需要大量内存。对于内存有限的移动设备来说，探索模型压缩技术以减少模型大小是至关重要的，包括量化（2-4倍的模式大小缩减以及从FP16到INT4的2-3倍加速）、剪枝、稀疏性等。
- en: Power efficiency optimization for AI features like end-to-end video zoom
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 针对AI特性（如端到端视频缩放）的电源效率优化。
- en: For AI features like video zoom, power efficiency is one of the top factors
    for successful deployment on edge/mobile devices. These battery-operated edge
    devices store their energy in the battery, with the capacity of mW-H (milliWatt
    Hours, 1200WH means 1200 watts in one hour before it discharge, if an application
    is consuming 2w in one hour, then the battery can power the device for 600h).
    Power efficiency is computed as IPS/Watt where IPS is inferences per second (FPS/Watt
    for image-based applications, TOPS/Watt )
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像视频缩放这样的AI特性，电源效率是成功部署到边缘/移动设备上的关键因素之一。这些电池供电的边缘设备将能量储存在电池中，容量为mW-H（毫瓦时，1200WH意味着在一小时内消耗1200瓦的电能，如果应用程序每小时消耗2瓦，则电池可为设备提供600小时的电力）。电源效率的计算方法是IPS/瓦特，其中IPS是每秒推理次数（对于基于图像的应用是FPS/瓦特，TOPS/瓦特）。
- en: It’s critical to reduce power consumption to get long battery life for mobile
    devices, there are lots of factors contributing to high power usage, including
    large amounts of memory transactions due to big model size, heavy computation
    of matrix multiplications, etc., let’s take a look at how to optimize the use
    case for efficient power usage.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 减少功耗以延长移动设备的电池寿命至关重要，许多因素会导致高功耗，包括由于模型尺寸较大而导致的大量内存事务、矩阵乘法的高计算量等，让我们来看一下如何优化使用场景以实现高效的功耗管理。
- en: '**Model optimization.**'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型优化。**'
- en: Beyond quantization, pruning, and sparsity, there is also weight sharing. There
    are lots of redundant weights in the network while only a small number of weights
    are useful, the number of weights can be reduced by letting multiple connections
    share the same weight shown as below. the original 4*4 weight matrix is reduced
    to 4 shared weights and a 2-bit matrix, total bits are reduced from 512 bits to
    160 bits.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了量化、剪枝和稀疏性之外，还有权重共享。网络中有许多冗余权重，而只有少数权重是有用的，可以通过让多个连接共享相同的权重来减少权重的数量，如下所示。原始的4*4权重矩阵被减少为4个共享权重和一个2位矩阵，总位数从512位减少到160位。
- en: '![](../Images/e68e1d591d59c9b468d5fc6e86a4ad8e.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e68e1d591d59c9b468d5fc6e86a4ad8e.png)'
- en: 'Weight sharing. Source: [A Survey on Optimization Techniques for Edge Artificial
    Intelligence (AI)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9919555/#B79-sensors-23-01279)
    [3]'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 权重共享。来源：[关于边缘人工智能（AI）优化技术的调查](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9919555/#B79-sensors-23-01279)
    [3]
- en: 2\. **Memory optimization.**
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 2. **内存优化。**
- en: Memory is a critical component that consumes more power compared to matrix multiplications.
    For instance, the power consumption of a DRAM operation can be orders of magnitude
    more than that of a multiplication operation. In mobile devices, accommodating
    large models within local device memory is often challenging. This leads to numerous
    memory transactions between local device memory and DRAM, resulting in higher
    latency and increased energy consumption.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 内存是一个关键组件，相比矩阵乘法，它消耗更多的电力。例如，DRAM操作的功耗可能是矩阵乘法操作的几个数量级。对于移动设备来说，将大模型适配到本地设备内存中往往是一个挑战。这导致了本地设备内存和DRAM之间大量的内存事务，从而带来更高的延迟和更大的能量消耗。
- en: Optimizing off-chip memory access is crucial for enhancing energy efficiency.
    The article ([Optimizing Off-Chip Memory Access for Deep Neural Network Accelerator](https://ieeexplore.ieee.org/document/9708433)
    [4]) introduced an adaptive scheduling algorithm designed to minimize DRAM access.
    This approach demonstrated a substantial energy consumption and latency reduction,
    ranging between 34% and 93%.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 优化芯片外内存访问对提高能效至关重要。文章（[优化深度神经网络加速器的芯片外内存访问](https://ieeexplore.ieee.org/document/9708433)
    [4]）介绍了一种自适应调度算法，旨在最小化DRAM访问。该方法显著减少了能量消耗和延迟，减少幅度在34%至93%之间。
- en: A new method ([ROMANet](https://arxiv.org/pdf/1902.10222.pdf) [5]) is proposed
    to minimize memory access for power saving. The core idea is to optimize the right
    block size of CNN layer partition to match DRAM/SRAM resources and maximize data
    reuse, and also optimize the tile access scheduling to minimize the number of
    DRAM access. The data mapping to DRAM focuses on mapping a data tile to different
    columns in the same row to maximize row buffer hits. For larger data tiles, same
    bank in different chips can be utilized for chip-level parallelism. Furthermore,
    if the same row in all chips is filled, data are mapped in the different banks
    in the same chip for bank-level parallelism. For SRAM, a similar concept of bank-level
    parallelism can be applied. The proposed optimization flow can save energy by
    12% for the AlexNet, by 36% for the VGG-16, and by 46% for the MobileNet. A high-level
    flow chart of the proposed method and schematic illustration of DRAM data mapping
    is shown below.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 提出了一种新的方法（[ROMANet](https://arxiv.org/pdf/1902.10222.pdf) [5]），旨在通过减少内存访问来节省功耗。其核心思想是优化CNN层分区的正确块大小，以匹配DRAM/SRAM资源并最大化数据重用，同时还优化了数据块访问调度，以最小化DRAM访问次数。数据映射到DRAM时，重点是将数据块映射到同一行的不同列，以最大化行缓冲区命中率。对于更大的数据块，可以利用不同芯片中相同银行的并行性来实现芯片级并行性。此外，如果所有芯片的同一行已填满，则数据将映射到同一芯片中的不同银行，以实现银行级并行性。对于SRAM，可以应用类似的银行级并行性概念。所提优化流程可以为AlexNet节省12%的能量，为VGG-16节省36%的能量，为MobileNet节省46%的能量。下方展示了所提方法的高级流程图和DRAM数据映射的示意图。
- en: '![](../Images/b8499fe7fd9fbadd851d0ddf635f5ff4.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8499fe7fd9fbadd851d0ddf635f5ff4.png)'
- en: 'Operation flow of proposed method. Source: [ROMANet](https://arxiv.org/pdf/1902.10222.pdf)
    [5]'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 提出方法的操作流程。来源：[ROMANet](https://arxiv.org/pdf/1902.10222.pdf) [5]
- en: '![](../Images/5f26cf64625958c88fa93373ea35ffe1.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f26cf64625958c88fa93373ea35ffe1.png)'
- en: 'DRAM data mapping across banks and chips. Source: [ROMANet](https://arxiv.org/pdf/1902.10222.pdf)
    [5]'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: DRAM数据在不同银行和芯片间的映射。来源：[ROMANet](https://arxiv.org/pdf/1902.10222.pdf) [5]
- en: 3\. **Dynamic power scaling.**
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 3. **动态功率调整。**
- en: The power of a system can be calculated by P=C*F*V², where F is the operating
    frequency and V is the operating voltage. Techniques like DVFS (dynamic voltage
    frequency scaling) was developed to optimize runtime power. It scales voltage
    and frequency depending on workload capacity. In deep learning, layer-wise DVFS
    is not appropriate as voltage scaling has long latency. On the other hand, frequency
    scaling is fast enough to keep up with each layer. A [layer-wise dynamic frequency
    scaling (DFS)](https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2022-0094)[6]
    technique is proposed for NPU, with a power model to predict power consumption
    to determine the highest allowable frequency. It’s demonstrated that DFS improves
    latency by 33%, and saves energy by 14%
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个系统的功率可以通过P=C*F*V²来计算，其中F是工作频率，V是工作电压。像DVFS（动态电压频率调整）这样的技术被开发用来优化运行时功耗。它根据工作负载的容量调整电压和频率。在深度学习中，逐层DVFS并不合适，因为电压调整有较长的延迟。另一方面，频率调整足够快，可以跟上每一层的要求。提出了一种针对NPU的[逐层动态频率调整（DFS）](https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2022-0094)[6]技术，使用功率模型预测功耗以确定最高允许频率。证明DFS可以提高33%的延迟，节省14%的能量。
- en: '![](../Images/cd452c14ae3934e8f58eb7d00d7fcfee.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd452c14ae3934e8f58eb7d00d7fcfee.png)'
- en: 'Frequency changes over layer across 8 different NN applications. Source: [A
    layer-wise frequency scaling for a neural processing unit](https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2022-0094)
    [6]'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 8个不同神经网络应用中，层级间频率变化。来源：[针对神经处理单元的逐层频率调整](https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2022-0094)
    [6]
- en: 4. **Dedicated low-power AI HW accelerator architecture.** To accelerate deep
    learning inference, specialized AI accelerators have shown superior power efficiency,
    achieving similar performance with reduced power consumption. For instance, Google’s
    TPU is tailored for accelerating matrix multiplication by reusing input data multiple
    times for computations, unlike CPUs that fetch data for each computation. This
    approach conserves power and diminishes data transfer latency.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 4. **专用低功耗AI硬件加速器架构。** 为了加速深度学习推理，专门的AI加速器表现出卓越的功率效率，能够在降低功耗的同时实现类似的性能。例如，谷歌的TPU专门为加速矩阵乘法而设计，通过多次重用输入数据进行计算，与每次都需要获取数据的CPU不同。这种方法节省了功率，并减少了数据传输延迟。
- en: At the end
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结束
- en: AI inferencing is only a part of the End-to-end use case flow, there are other
    sub-domains to be considered while optimizing system power and performance, including
    imaging, codec, memory, display, graphics, etc. Breakdown of the process and examine
    the impact on each sub-domain is essential. for example, to look at power consumption
    when we run infinite zoom, we need also to look into the power of camera capturing
    and video processing system, display, memory, etc. make sure the power budget
    for each component is optimized. There are numerous optimization methods and we
    need to prioritize based on the use case and product
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: AI推理仅仅是端到端用例流程的一部分，在优化系统功耗和性能时，还需要考虑其他子领域，包括图像处理、编解码、内存、显示、图形等。对过程进行细分并检查每个子领域的影响至关重要。例如，在运行无限缩放时，我们还需要考虑相机捕捉、视频处理系统、显示、内存等部分的功耗，确保每个组件的功耗预算得到优化。有许多优化方法，我们需要根据具体的用例和产品来确定优先级。
- en: Reference
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] OpenVINO tutorial: [Infinite Zoom Stable Diffusion v2 and OpenVINO™](https://docs.openvino.ai/2023.2/notebooks/236-stable-diffusion-v2-infinite-zoom-with-output.html)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] OpenVINO教程：[无限缩放稳定扩散v2与OpenVINO™](https://docs.openvino.ai/2023.2/notebooks/236-stable-diffusion-v2-infinite-zoom-with-output.html)'
- en: '[2] [J](https://jalammar.github.io/)ay Alammar, [The Illustrated Stable Diffusion](https://jalammar.github.io/illustrated-stable-diffusion/)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [J](https://jalammar.github.io/)ay Alammar，[图解稳定扩散](https://jalammar.github.io/illustrated-stable-diffusion/)'
- en: '[3] Chellammal Surianarayanan et al., [A Survey on Optimization Techniques
    for Edge Artificial Intelligence (AI)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9919555/#B79-sensors-23-01279),
    Jan 2023'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Chellammal Surianarayanan等人，[边缘人工智能（AI）优化技术综述](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9919555/#B79-sensors-23-01279)，2023年1月'
- en: '[4] Yong Zheng et al., [Optimizing Off-Chip Memory Access for Deep Neural Network
    Accelerator](https://ieeexplore.ieee.org/document/9708433), IEEE Transactions
    on Circuits and Systems II: Express Briefs, Volume: 69, Issue: 4, April 2022'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Yong Zheng 等人，[优化深度神经网络加速器的片外内存访问](https://ieeexplore.ieee.org/document/9708433)，IEEE《电路与系统
    II: 快捷简报》期刊，卷：69，期：4，2022年4月'
- en: '[5] Rachmad Vidya Wicaksana Putra et al., [ROMANet: Fine grained reuse-driven
    off-chip memory access management and data organization for deep neural network
    accelerators](https://arxiv.org/pdf/1902.10222.pdf), arxiv, 2020'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Rachmad Vidya Wicaksana Putra 等人，[ROMANet: 基于细粒度重用驱动的片外内存访问管理与数据组织用于深度神经网络加速器](https://arxiv.org/pdf/1902.10222.pdf)，arxiv，2020年'
- en: '[6] Jaehoon Chung et al., [A layer-wise frequency scaling for a neural processing
    unit](https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2022-0094), ETRI
    Journal, Volume 44, Issue 5, Sept 2022'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Jaehoon Chung 等人，[神经处理单元的层次频率调节](https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2022-0094)，ETRI期刊，卷：44，期：5，2022年9月'
