["```py\ndef michaelis_menten(x, alpha, lam):\n    return alpha * x / (lam + x)\n```", "```py\ndef data_generator(n, tau_weight, alpha, lam):\n\n    # Set number of features\n    p=4\n\n    # Create features\n    X = np.random.uniform(size=n * p).reshape((n, -1))\n\n    # Nuisance parameters\n    b = (\n        np.sin(np.pi * X[:, 0])\n        + 2 * (X[:, 1] - 0.5) ** 2\n        + X[:, 2] * X[:, 3]\n    )\n\n    # Create treatment and treatment effect\n    T = np.linspace(200, 10000, n)\n    T_mm = michaelis_menten(T, alpha, lam) * tau_weight\n    tau = T_mm / T\n\n    # Calculate outcome\n    y = b + T * tau + np.random.normal(size=n) * 0.5\n\n    y_train = y\n    X_train = np.hstack((X, T.reshape(-1, 1)))\n\n    return y_train, X_train, T_mm, tau\n```", "```py\nnp.random.seed(1234)\n\nn=100000\n\ny_train_1, X_train_1, T_mm_1, tau_1 = data_generator(n, 1.00, 2, 5000)\ny_train_2, X_train_2, T_mm_2, tau_2 = data_generator(n, 0.25, 2, 5000)\ny_train_3, X_train_3, T_mm_3, tau_3 = data_generator(n, 2.00, 2, 5000)\n```", "```py\ndef train_slearner(X_train, y_train):\n\n    model = LGBMRegressor(random_state=42)\n    model.fit(X_train, y_train)\n\n    yhat_train = model.predict(X_train)\n\n    mse_train = mean_squared_error(y_train, yhat_train)\n    r2_train = r2_score(y_train, yhat_train)\n\n    print(f'MSE on train set is {round(mse_train)}')\n    print(f'R2 on train set is {round(r2_train, 2)}')\n\n    return model, yhat_train\n```", "```py\nnp.random.seed(1234)\n\nmodel_1, yhat_train_1 = train_slearner(X_train_1, y_train_1)\nmodel_2, yhat_train_2 = train_slearner(X_train_2, y_train_2)\nmodel_3, yhat_train_3 = train_slearner(X_train_3, y_train_3)\n```", "```py\ndef extract_treated_effect(n, X_train, model):\n\n    # Set features to mean value\n    X_mean_mapping = {'X1': [X_train[:, 0].mean()] * n,\n                      'X2': [X_train[:, 1].mean()] * n,\n                      'X3': [X_train[:, 2].mean()] * n,\n                      'X4': [X_train[:, 3].mean()] * n}\n\n    # Create DataFrame\n    df_scoring = pd.DataFrame(X_mean_mapping)\n\n    # Add full range of treatment values\n    df_scoring['T'] = X_train[:, 4].reshape(-1, 1)\n\n    # Calculate outcome prediction for treated\n    treated = model.predict(df_scoring)\n\n    return treated, df_scoring\n```", "```py\ntreated_1, df_scoring_1 = extract_treated_effect(n, X_train_1, model_1)\ntreated_2, df_scoring_2 = extract_treated_effect(n, X_train_2, model_2)\ntreated_3, df_scoring_3 = extract_treated_effect(n, X_train_3, model_3)\n```", "```py\ndef extract_untreated_effect(n, X_train, model):\n\n    # Set features to mean value\n    X_mean_mapping = {'X1': [X_train[:, 0].mean()] * n,\n                      'X2': [X_train[:, 1].mean()] * n,\n                      'X3': [X_train[:, 2].mean()] * n,\n                      'X4': [X_train[:, 3].mean()] * n,\n                      'T': [0] * n}\n\n    # Create DataFrame\n    df_scoring = pd.DataFrame(X_mean_mapping)\n\n    # Add full range of treatment values\n    df_scoring\n\n    # Calculate outcome prediction for treated\n    untreated = model.predict(df_scoring)\n\n    return untreated\n```", "```py\nuntreated_1 = extract_untreated_effect(n, X_train_1, model_1)\nuntreated_2 = extract_untreated_effect(n, X_train_2, model_2)\nuntreated_3 = extract_untreated_effect(n, X_train_3, model_3)\n```", "```py\ntreatment_effect_1 = treated_1 - untreated_1\ntreatment_effect_2 = treated_2 - untreated_2\ntreatment_effect_3 = treated_3 - untreated_3\n```", "```py\ndef michaelis_menten(x, alpha, lam):\n    return alpha * x / (lam + x)\n```", "```py\ndef response_curves(treatment_effect, df_scoring):\n\n    maxfev = 100000\n    lam_initial_estimate = 0.001\n    alpha_initial_estimate = max(treatment_effect)\n    initial_guess = [alpha_initial_estimate, lam_initial_estimate]\n\n    popt, pcov = curve_fit(michaelis_menten, df_scoring['T'], treatment_effect, p0=initial_guess, maxfev=maxfev)\n\n    return popt, pcov\n```", "```py\npopt_1, pcov_1 = response_curves(treatment_effect_1, df_scoring_1)\npopt_2, pcov_2 = response_curves(treatment_effect_2, df_scoring_2)\npopt_3, pcov_3 = response_curves(treatment_effect_3, df_scoring_3)\n```", "```py\ntreatment_effect_curve_1 = michaelis_menten(df_scoring_1['T'], popt_1[0], popt_1[1])\ntreatment_effect_curve_2 = michaelis_menten(df_scoring_2['T'], popt_2[0], popt_2[1])\ntreatment_effect_curve_3 = michaelis_menten(df_scoring_3['T'], popt_3[0], popt_3[1])\n```", "```py\n# List of products\nproducts = [\"product_1\", \"product_2\", \"product_3\"]\n\n# Set total budget to be the sum of the mean of each product reduced by 20%\ntotal_budget = (df_scoring_1['T'].mean() + df_scoring_2['T'].mean() + df_scoring_3['T'].mean()) * 0.80\n\n# Dictionary with min and max bounds for each product - set as +/-20% of max/min discount\nbudget_ranges = {\"product_1\": [df_scoring_1['T'].min() * 0.80, df_scoring_1['T'].max() * 1.2], \n                 \"product_2\": [df_scoring_2['T'].min() * 0.80, df_scoring_2['T'].max() * 1.2], \n                 \"product_3\": [df_scoring_3['T'].min() * 0.80, df_scoring_3['T'].max() * 1.2]}\n\n# Dictionary with response curve parameters\nparameters = {\"product_1\": [popt_1[0], popt_1[1]], \n              \"product_2\": [popt_2[0], popt_2[1]], \n              \"product_3\": [popt_3[0], popt_3[1]]}\n```", "```py\ndef objective_function(x, products, parameters):\n\n    sum_orders = 0.0\n\n    # Unpack parameters for each product and calculate expected orders\n    for product, budget in zip(products, x, strict=False):\n        L, k = parameters[product]\n        sum_orders += michaelis_menten(budget, L, k)\n\n    return -1 * sum_orders\n```", "```py\n# Set initial guess by equally sharing out the total budget\ninitial_guess = [total_budget // len(products)] * len(products)\n\n# Set the lower and upper bounds for each product\nbounds = [budget_ranges[product] for product in products]\n\n# Set the equality constraint - constraining the total budget\nconstraints = {\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - total_budget}\n\n# Run optimisation\nresult = minimize(\n    lambda x: objective_function(x, products, parameters),\n    initial_guess,\n    method=\"SLSQP\",\n    bounds=bounds,\n    constraints=constraints,\n    options={'disp': True, 'maxiter': 1000, 'ftol': 1e-9},\n)\n\n# Extract results\noptimal_treatment = {product: budget for product, budget in zip(products, result.x, strict=False)}\nprint(f'Optimal promo budget allocations: {optimal_treatment}')\nprint(f'Optimal orders: {round(result.fun * -1, 2)}')\n```"]