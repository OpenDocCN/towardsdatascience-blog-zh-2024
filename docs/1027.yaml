- en: Building an AI-Powered Business Manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-an-ai-powered-business-manager-e2a31a2fe984?source=collection_archive---------3-----------------------#2024-04-23](https://towardsdatascience.com/building-an-ai-powered-business-manager-e2a31a2fe984?source=collection_archive---------3-----------------------#2024-04-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/dc602a5cdef860b9a6b382b91264e95b.png)'
  prefs: []
  type: TYPE_IMG
- en: Created with [DALL·E](https://labs.openai.com/s/1rNDsRujptitO6sPd57aWyZp)
  prefs: []
  type: TYPE_NORMAL
- en: A step-by-step guide to linking your AI agent with a SQL database — Part 2 of
    the series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@lukas.kowejsza?source=post_page---byline--e2a31a2fe984--------------------------------)[![Lukasz
    Kowejsza](../Images/8d920478bee9ad674a6c79462128b0db.png)](https://medium.com/@lukas.kowejsza?source=post_page---byline--e2a31a2fe984--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e2a31a2fe984--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e2a31a2fe984--------------------------------)
    [Lukasz Kowejsza](https://medium.com/@lukas.kowejsza?source=post_page---byline--e2a31a2fe984--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e2a31a2fe984--------------------------------)
    ·29 min read·Apr 23, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Imagine streamlining your entire business management through a single, user-friendly
    interface on your phone. While juggling multiple apps is common practice, the
    future lies in consolidating all your interactions into one chat-based platform,
    powered by the capabilities of Large Language Models (LLMs).
  prefs: []
  type: TYPE_NORMAL
- en: For small businesses, this approach offers significant advantages. By centralizing
    data management tasks within a unified chat interface, owners can save time, reduce
    complexity, and minimize reliance on disparate software tools. The result is a
    more efficient allocation of resources, allowing a greater focus on core business
    growth activities.
  prefs: []
  type: TYPE_NORMAL
- en: However, the potential extends beyond just small businesses. The concepts and
    techniques detailed in this tutorial are adaptable to personal use cases as well.
    From managing to-do lists and tracking expenses to organizing collections, a chat-based
    interface provides an intuitive and efficient way to interact with your data.
  prefs: []
  type: TYPE_NORMAL
- en: 'This article is the second installment in a series that guides you through
    the process of developing such a software project, from initial concept to practical
    implementation. Building upon the components introduced in the previous article,
    we will establish the foundational elements of our application, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the database schema
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining core application functionality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structuring the project repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating Tools capable of interacting with multiple SQL database tables using
    natural language commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this tutorial, you will have a clear understanding of how to architect
    a chat-based interface that leverages LLMs to simplify data management tasks.
    Whether you’re a small business owner looking to streamline operations or an individual
    seeking to optimize personal organization, the principles covered here will provide
    a solid starting point for your own projects.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin by briefly recapping the key takeaways from the previous article
    to set the context for our current objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Recap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[In the first part of this series](/leverage-openai-tool-calling-building-a-reliable-ai-agent-from-scratch-4e21fcd15b62),
    we built a prototype agent workflow capable of interacting with tool objects.
    Our goal was to reduce hallucination in tool arguments generated by the underlying
    language model, in our case `gpt-3.5-turbo`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve this, we implemented two key changes:'
  prefs: []
  type: TYPE_NORMAL
- en: Removed required parameters in the tool schema
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Added a parameter validation step before executing the desired function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By setting all tool parameters to optional and manually checking for missing
    parameters, we eliminated the urge for the Agent/LLM to hallucinate missing values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key objects introduced in the previous article were:'
  prefs: []
  type: TYPE_NORMAL
- en: '`OpenAiAgent`: The main agent workflow class'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tool`: A class representing a tool the agent can use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ToolResult` and `StepResult`: Classes for encapsulating tool execution results'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These components formed the foundation of our agent system, allowing it to process
    user requests, select appropriate tools, and generate responses.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’d like a more detailed explanation or want to know the reasoning behind
    specific design choices, feel free to check out the previous article: [Leverage
    OpenAI Tool Calling: Building a Reliable AI Agent from Scratch](https://medium.com/towards-data-science/leverage-openai-tool-calling-building-a-reliable-ai-agent-from-scratch-4e21fcd15b62)'
  prefs: []
  type: TYPE_NORMAL
- en: With this recap in mind, let’s dive into the next phase of our project — integrating
    database functionality to store and manage business data.
  prefs: []
  type: TYPE_NORMAL
- en: Why Chat Interface for Small Business Data Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Small businesses often face unique challenges when it comes to data maintenance.
    Like larger corporations, they need to regularly update and maintain various types
    of data, such as accounting records, time tracking, invoices, and more. However,
    the complexity and costs associated with modern ERP (Enterprise Resource Planning)
    systems can be prohibitive for small businesses. As a result, many resort to using
    a series of Excel spreadsheets to capture and maintain essential data.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with this approach is that small business owners, who are rarely
    dedicated solely to administrative tasks, cannot afford to invest significant
    time and effort into complex administration and control processes. The key is
    to define lean processes and update data as it arises, minimizing the overhead
    of data management.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging the power of Large Language Models and creating a chat interface,
    we aim to simplify and streamline data management for small businesses. The chatbot
    will act as a unified interface, allowing users to input data, retrieve information,
    and perform various tasks using natural language commands. This eliminates the
    need for navigating multiple spreadsheets or developing complex web applications
    with multiple forms and dashboards.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this series, we will gradually enhance the chatbot’s capabilities,
    adding features such as role-based access control, advanced querying and evaluation,
    multimodal support, and integration with popular communication platforms like
    WhatsApp. By the end of the series, you will have a powerful and flexible tool
    that can adapt to your specific needs, whether you’re running a small business
    or simply looking to organize your personal life more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Project Structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To ensure a well-organized and maintainable project, we’ve structured our repository
    to encapsulate different functionalities and components systematically. Here’s
    an overview of the repository structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This structure allows for a clear separation of concerns, making it easier to
    develop, maintain, and scale our application.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Set up Database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Choosing the right database and ORM (Object-Relational Mapping) library is
    crucial for our application. For this project, we’ve selected the following frameworks:'
  prefs: []
  type: TYPE_NORMAL
- en: 'SQLAlchemy: A powerful SQL toolkit and Object-Relational Mapping (ORM) library
    for Python. It provides a set of tools for interacting with databases using Python
    objects and classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SQLModel: A library that builds on top of SQLAlchemy and Pydantic, offering
    a simple and intuitive way to define database models and perform database operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By leveraging SQLModel, we can seamlessly integrate with Pydantic and SQLAlchemy,
    enabling efficient data validation and database operations while eliminating the
    risk of SQL injection attacks. Moreover, SQLModel allows us to easily build upon
    our previously designed `Tool` class, which uses Pydantic models for creating
    a tool schema.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure the security and robustness of our application, we implement the
    following measures:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Role-based access control: Executable operations are bound to user roles, ensuring
    that users can only perform actions they are authorized to do. This adds an extra
    layer of security and prevents unauthorized access to sensitive data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Prevention of SQL injection attacks: By utilizing ChatGPT’s natural language
    understanding capabilities, we can validate and sanitize user inputs, mitigating
    the risk of SQL injection vulnerabilities. SQLModel’s integration with Pydantic
    helps us enforce strict data validation rules.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With our tech stack decided, let’s dive into setting up the database and defining
    our models.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Database Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To begin building our prototype application, we’ll define the essential database
    tables and their corresponding SQLModel definitions. For this tutorial, we’ll
    focus on three core tables:'
  prefs: []
  type: TYPE_NORMAL
- en: Expense
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revenue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These tables will serve as the foundation for our application, allowing us to
    demonstrate the key functionalities and interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new file named `models.py` in the `database` directory and define
    the tables using SQLModel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to the standard SQLModel fields, we’ve defined three custom type
    annotations: `DateFormat`, `TimeFormat`, and `Numeric`. These annotations leverage
    Pydantic’s `BeforeValidator` to ensure that the input data is correctly formatted
    before being stored in the database. The `validate_date` function handles the
    conversion of string input to the appropriate `datetime`. This approach allows
    us to accept a variety of date formats from the Large Language Model, reducing
    the need for strict format enforcement in the prompts.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Database Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With our models defined, we need a script to set up the database engine and
    create the corresponding tables. Let’s create a `db.py` file in the `database`
    directory to handle this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this script, we import our models and the necessary SQLModel components.
    We define the `DATABASE_URL` to point to a local SQLite database file named `app.db`.
    We create an `engine` using `create_engine` from SQLModel, passing in the `DATABASE_URL`.
    The `echo=True` parameter enables verbose output for debugging purposes.
  prefs: []
  type: TYPE_NORMAL
- en: The `create_db_and_tables` function uses `SQLModel.metadata.create_all` to generate
    the corresponding tables in the database based on our defined models. Finally,
    we call this function to ensure the database and tables are created when the script
    is run.
  prefs: []
  type: TYPE_NORMAL
- en: With our database setup complete, we can now focus on updating our `Tool` class
    to work seamlessly with SQLModel and enhance our tool schema conversion process.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Tool Class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll discuss the updates made to the `Tool` class to handle
    SQLModel instances and improve the validation process. For a more detailed explanation
    of the `Tool` class, visit my previous article.
  prefs: []
  type: TYPE_NORMAL
- en: First, we’ve added `Type[SQLModel]` as a possible type for the `model` field
    using the `Union` type hint. This allows the `Tool` class to accept both Pydantic's
    `BaseModel` and SQLModel's `SQLModel` as valid model types.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ve introduced a new attribute called `exclude_keys` of type `list[str]`
    with a default value of `["id"]`. The purpose of this attribute is to specify
    which keys should be excluded from the validation process and the OpenAI tool
    schema generation. In this case the default excluded key is `id` since for data
    entry creation with `SqlModel` the id is automatically generated during ingestion.
  prefs: []
  type: TYPE_NORMAL
- en: On top of that we introduced `parse_model` boolean attribute to our Tool class.
    Where we can basically decided if the tool function is called with our pydantic/SQLModel
    or with keyword arguments.
  prefs: []
  type: TYPE_NORMAL
- en: In the `validate_input()` method, we've added a check to ensure that the keys
    specified in `exclude_keys` are not considered as missing keys during the validation
    process. This is particularly useful for fields like `id`, which are automatically
    generated by SQLModel and should not be required in the input.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, in the `openai_tool_schema` property, we've added a loop to remove
    the excluded keys from the generated schema. This ensures that the excluded keys
    are not included in the schema sent to the OpenAI API. For recap we use the `openai_tool_schema`
    property to remove `required` arguments from our tool schema. This is done to
    elimenate hallucination by our language model.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, we changed the import from `from pydantic.v1 import BaseModel` to
    `from pydantic import BaseModel`. Since `SQLModel` is based on Pydantic v2, we
    want to be consistent and use Pydantic v2 at this point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the updated code for the `Tool` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: These updates to the `Tool` class provide more flexibility and control over
    the validation process and schema generation when working with SQLModel instances.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Custom Tool Schema Conversion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our `Tool` class, we create a schema from a Pydantic model using the `convert_to_openai_tool`
    function from Langchain. However, this function is based on Pydantic v1, while
    SQLModel uses Pydantic v2\. To make the conversion function compatible, we need
    to adapt it. Let''s create a new script called `convert.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This adapted conversion function handles the differences between Pydantic v1
    and v2, ensuring that our `Tool` class can generate compatible schemas for the
    OpenAI API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, update the import statement in `tools/base.py` to use the new `convert_to_openai_tool`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: With these changes in place, our `Tool` class can now handle SQLModel instances
    and generate schemas that are compatible with the OpenAI API.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: If you encounter dependency issues, you may consider removing the Langchain
    dependency entirely and including the* `*_rm_titles*` *and* `*dereference_refs*`
    *functions directly in the* `*convert.py*` *file.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By adapting the tool schema conversion process, we’ve ensured that our application
    can seamlessly work with SQLModel and Pydantic v2, enabling us to leverage the
    benefits of these libraries while maintaining compatibility with the OpenAI API.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Defining SQL Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will create functions and tools to interact with our database
    tables using SQL.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Add Data Tool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let’s define a generic function `add_row_to_table` that takes a SQLModel
    instance and adds it to the corresponding table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we’ll create a model-specific function `add_expense_to_table` that takes
    input arguments for an Expense entry and adds it to the table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In `add_expense_to_table`, we use the `model_validate()` method to trigger the
    execution of the previously defined BeforeValidator and ensure data validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid writing separate functions for each table or SQLModel, we can dynamically
    generate the functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This approach produces the same result and can be used to dynamically generate
    functions for all other models.
  prefs: []
  type: TYPE_NORMAL
- en: 'With these functions in place, we can create tools using our `Tool` class to
    add entries to our database tables via the OpenAIAgent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 4.2 Query Tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we need to create an add_xxx_tool for each table due to varying input
    schemas, we only need one query tool for querying all tables. To eliminate the
    risk of SQL injection, we will use the SQL sanitization provided by SQLAlchemy
    and SQLModel. This means we will query the database through standard Python classes
    and objects instead of parsing SQL statements directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the queries we want to perform on our tables, we will need the following
    logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '**select statement** -> `SELECT * FROM table_name` Arguments: `columns`, `table_name`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**where statement** -> `WHERE column_name = value`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Arguments: `column`, `operator`, `value`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In SQLModel, this corresponds to the following sanitized code when we want
    to find all expenses for coffee in the `Expense` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'To abstract this into a pydantic model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `QueryConfig` model allows us to set a `table_name`, `columns`, and `where`
    statements. The `where` property accepts a list of `WhereStatement` models or
    an empty list (when we want to return all values with no further filtering). A
    `WhereStatement` is a submodel defining a column, operator, and value. The `Literal`
    type is used to restrict the allowed operators to a predefined set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define a function that executes a query based on the `QueryConfig`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `query_data_function` serves as a high-level abstraction for selecting our
    table model from the `TABLES` dictionary, while `sql_query_from_config` is the
    underlying function for executing the `QueryConfig` on a table (SQLModel).
  prefs: []
  type: TYPE_NORMAL
- en: In `QueryConfig` you can choose to also define table_names as Literal type,
    where you hard code the available table names into it. You can even dynamically
    define the Literal using our TABLES dictionary. By doing so you can reduce false
    arguments for table_name. For now I have choosen to not use an enum object, because
    I will provide the agent prompt with context about the currently available tables
    and there underling ORM schema. I plan to add a tool for our future agent to create
    new tables on it’s own.While I can dynamically change the agent’s prompt, it won’t
    be straightforward to change the enum object within `QueryConfig` on our running
    server.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Finally, we can define our query tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: With these tools in place, our OpenAIAgent is now capable of adding and querying
    data in our database tables using natural language commands.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Configure Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To enable successful tool usage for our previously defined tools, the Agent
    from the previous article will need more context information, especially for using
    the query tool. The Agent prompt will need to include information about available
    tables and their schemas. Since we only use two tables at this point, we can include
    the ORM schema and table names in the system prompt or user prompt. Both options
    might work well, but I prefer to include variable information like this in the
    user prompt. By doing so, we can create few-shot examples that demonstrate context-aware
    tool usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make our Agent capable of handling variable context in the system prompt
    and user prompt, we can update our Agent class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The main changes compared to our previous version:'
  prefs: []
  type: TYPE_NORMAL
- en: We placed a “{context}” placeholder in the default system prompt.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We added `context` and `user_context` as input arguments to `__init__()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We added `context` to the `run()` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In `run()`, we add `context` to the user message if defined.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also added an `examples` attribute to `__init__()` that, if set, will be
    passed between the system and user messages in `run()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can define a system context and a user context while initializing our
    agent. Additionally, we can pass a user context when calling the run method. If
    `context` is passed to the run method, it will overwrite the `user_context` from
    initialization for that run.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Providing Context to the Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we can run our Agent, let’s define a function that generates context
    information. We want to automatically generate `user_context`, which we can then
    pass to the Agent''s run function as implemented above. To keep it simple, we
    want a single line for each table as context information that should include:'
  prefs: []
  type: TYPE_NORMAL
- en: Table name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Column_name: `<type>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After a few attempts with trial and error, the following function will do the
    job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If we pass `Expense` and `Revenue` to `generate_context()`, we should get the
    following context string:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We want the Agent to know the current date and day of the week, so we can reference
    the correct date. So let’s add some date parsing functions to our utils class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s create the context for a query agent
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 5.2 Routing Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we add more tools, the complexity of our setup may start to limit the usability
    of cheaper models like “gpt-3.5-turbo”. In the next article, we might consider
    switching to Anthropic Claude, since their newly released tool-use API feature
    seems promising, even for the more affordable HAIKU model, in handling multiple
    tools simultaneously. However, for now, we will continue using OpenAI’s GPT models.
  prefs: []
  type: TYPE_NORMAL
- en: When developing for personal use and before creating production-ready applications,
    I find it useful to optimize the workflow for smaller models, such as `gpt-3.5-turbo`
    in this case. This approach forces us to create a streamlined processing logic
    and prompting system. While we may not achieve 100% reliability without using
    the most powerful model, we will be able to catch flaws and identify unclear instructions.
    If your application works in 9 out of 10 cases with a smaller model, you will
    have a production-ready logic that will perform even better with a stronger model.
  prefs: []
  type: TYPE_NORMAL
- en: To make multi-tool handling reliable with `gpt-3.5-turbo` we will implement
    a routing agent whose sole purpose is to route the user query to the appropriate
    task agent. This allows us to separate execution logic and reduce complexity.
    Each agent will have a limited scope, enabling us to separate access roles and
    operations in the future. I have observed that even with gpt-4, there are instances
    where the agent does not know when its task is finished.
  prefs: []
  type: TYPE_NORMAL
- en: By introducing a routing agent, we can break down the problem into smaller,
    more manageable parts. The routing agent will be responsible for understanding
    the user’s intent and directing the query to the relevant task agent. This approach
    not only simplifies the individual agents’ responsibilities but also makes the
    system more modular and easier to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, separating the execution logic and complexity will pave the way
    for implementing role-based access control in the future. Each task agent can
    be assigned specific permissions and access levels, ensuring that sensitive operations
    are only performed by authorized agents.
  prefs: []
  type: TYPE_NORMAL
- en: While the routing agent adds an extra step in the process, it ultimately leads
    to a more robust and scalable system. By optimizing for smaller models and focusing
    on clear, concise prompts, we can create a solid foundation that will perform
    even better when we switch to more powerful models like Claude Opus or GPT-4.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s have a look on the implementation of the routing agent
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The biggest differences to our `OpenAIAgent` are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**No open loop:** we want the routing agent to route user’s queries to the
    appropriate agent. So instead of creating an open loop we select the desired agent
    via tool calling and pass the user query to it. The routing Agent should not do
    any other task or follow-up question.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agents as Tools**: Instead of calling a tool the routing agent setup a subagent.
    So our previously defined `OpenAIAgent`is now a tool within our routing agent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5.3 Agent as a Tool — Task Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use our `OpenAIAgent`as a tool, we need to introduce some sort of tool class
    dedicated for Agents. We want to define a name and description for each agent
    and automate the initialization process. Therefore, we define our last class for
    this tutorial the`TaskAgent`.
  prefs: []
  type: TYPE_NORMAL
- en: The `TaskAgent` class serves similar functionality as the `Tool` class. We define
    a name a description and an input model which we call `arg_model`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, we added all relevant attributes to our `TaskAgent` class, which
    we need for an underlying specialized `OpenAIAgent` :'
  prefs: []
  type: TYPE_NORMAL
- en: '`create_context` / `create_user_context`: Here we can pass a function to create
    the context or user context like in section 5.1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tool_loader` is another callable function which we may need for setting up
    the underlying agent. As in our dynamic tool building previously explained, we
    may need tools that are dynamically built based on the user input/routing agent
    input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`system_message` is the agent’s system prompt. In our example, it will be the
    default system prompt for every agent, but it can be an optimized version for
    each specialized agent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tools`: Predefined tools the agent should use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`examples`: Examples to include in subagent’s message history'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`routing_example`: Examples to include in routing agent’s message history'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moreover, we have an emty BaseModel called `EmptyArgModel` which is default
    `arg_model` in our TaskAgent
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/296be241ea21139c029a09fa600081de.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by the author [mermaid](https://mermaid.live/)
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see if it all plays together!
  prefs: []
  type: TYPE_NORMAL
- en: Run Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, it’s time to test if our routing and subagents work well together. As we
    introduced examples as a paremeter we can use several test runs to inspect major
    flaws in the execution and define example usage for each sub agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s define our subagents first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: As you can see we added some remarks as string to `create_user_context` for
    revenue and expense agents. We want the sub agent to handle tax rates and calculate
    the net or gross amount automatically to test the reasoning capabilites of our
    sub agent.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s add a revenue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'And for the last test let’s try to query the revenue that created from database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: All tools worked as expected. The Routing Agent worked perfectly. For theTask
    Agent I had to update the prompt several times.
  prefs: []
  type: TYPE_NORMAL
- en: I would recommend to add some example tool calls to each task agent when not
    working with state-of-the-art models like gpt-4\. In general I would recommend
    to tackle flaws with examples and more intuitive designs instead of prompt engineering.
    Reapting flaws are indicators for not straightforward designs. For example when
    the agent struggles with calculating the gross or net amount just add a ‘calculate_gross_amount_tool’
    or ‘calculate_net_amount_tool’. GPT-4 on the other hand would handle use cases
    like that without hestitating.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we’ve taken a significant step forward in our journey to create
    a comprehensive chat-based interface for managing small businesses using Large
    Language Models.
  prefs: []
  type: TYPE_NORMAL
- en: By setting up our database schema, defining core functionalities, and structuring
    our project repository, we’ve laid a solid foundation for the development of our
    application.
  prefs: []
  type: TYPE_NORMAL
- en: We started by designing our database models using SQLModel, which allowed us
    to seamlessly integrate with Pydantic and SQLAlchemy. This approach ensures efficient
    data validation and database operations while minimizing the risk of SQL injection
    attacks.
  prefs: []
  type: TYPE_NORMAL
- en: We then proceeded to update our `Tool` class to handle SQLModel instances and
    improve the validation process. Next, we implemented SQL tools for adding data
    to our database tables and querying data using natural language commands. By leveraging
    the power of SQLModel and Pydantic, we were able to create a robust and flexible
    system that can handle a wide range of user inputs and generate accurate SQL queries.
  prefs: []
  type: TYPE_NORMAL
- en: We configured our OpenAIAgent to provide context-aware tool usage by updating
    the agent class to handle variable context in the system prompt and user prompt.
    This allows our agent to understand the available tables and their schemas, enabling
    more accurate and efficient tool usage. While we’ve made significant progress,
    there’s still much more to explore and implement.
  prefs: []
  type: TYPE_NORMAL
- en: To further enhance our chatbot, we introduced the TaskAgent class, which serves
    a similar functionality as the Tool class. The TaskAgent allows us to define a
    name, description, and input model for each agent, automating the initialization
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we tested our routing and subagents by defining subagents for querying
    data, adding expenses, adding revenue. We demonstrated how the agents handle tax
    rates and calculate net or gross amounts automatically, showcasing the reasoning
    capabilities of our subagents.
  prefs: []
  type: TYPE_NORMAL
- en: Next steps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the next part of this series, we’ll focus on enhancing our agent’s capabilities
    by adding support for more tools and potentially testing Claude as a new default
    language model. We’ll also explore integrating our application with popular communication
    platforms (WhatsApp) to make it even more accessible and user-friendly.
  prefs: []
  type: TYPE_NORMAL
- en: As we continue to refine and expand our application, the possibilities are endless.
    By leveraging the power of Large Language Models and creating intuitive chat-based
    interfaces, we can revolutionize the way small businesses manage their data and
    streamline their operations. Stay tuned for the next installment in this exciting
    series!
  prefs: []
  type: TYPE_NORMAL
- en: Source Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Additionally, the entire source code for the projects covered is available on
    GitHub. You can access it at [https://github.com/elokus/ArticleDemo2](https://github.com/elokus/ArticleDemo2)
  prefs: []
  type: TYPE_NORMAL
