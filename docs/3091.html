<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Deep Dive into Multithreading, Multiprocessing, and Asyncio</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Deep Dive into Multithreading, Multiprocessing, and Asyncio</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-dive-into-multithreading-multiprocessing-and-asyncio-94fdbe0c91f0?source=collection_archive---------0-----------------------#2024-12-28">https://towardsdatascience.com/deep-dive-into-multithreading-multiprocessing-and-asyncio-94fdbe0c91f0?source=collection_archive---------0-----------------------#2024-12-28</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="6522" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How to choose the right concurrency model</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@clarachong13?source=post_page---byline--94fdbe0c91f0--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Clara Chong" class="l ep by dd de cx" src="../Images/94c482bc7e35135f104fbfd08a45eef1.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*MCNQhAnU9ozuJZNFH3f7UQ.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--94fdbe0c91f0--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@clarachong13?source=post_page---byline--94fdbe0c91f0--------------------------------" rel="noopener follow">Clara Chong</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--94fdbe0c91f0--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 28, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">9</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/7c7943e9ffec1c0fd533c4ffcb697285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hwsMbtR0kWWcej8AYWOwYA.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://unsplash.com/@pinjasaur" rel="noopener ugc nofollow" target="_blank">Paul Esch-Laurent</a> from <a class="af nc" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="dbda" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Python provides three main approaches to handle multiple tasks simultaneously: multithreading, multiprocessing, and asyncio.</p><p id="a91a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Choosing the right model is crucial for maximising your program’s performance and efficiently using system resources. (P.S. It is also a common interview question!)</p><p id="12a0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Without concurrency, a program processes only one task at a time. During operations like file loading, network requests, or user input, it stays idle, wasting valuable CPU cycles. Concurrency solves this by enabling multiple tasks to run efficiently.</p><p id="f094" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">But which model should you use? Let’s dive in!</p><h1 id="0f29" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Contents</h1><ol class=""><li id="02c7" class="nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny pa pb pc bk">Fundamentals of concurrency<br/>- Concurrency vs parallelism<br/>- Programs<br/>- Processes<br/>- Threads<br/>- How does the OS manage threads and processes?</li><li id="97a6" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk">Python’s concurrency models<br/>- Multithreading<br/>- Python’s Global Interpreter Lock (GIL)<br/>- Multiprocessing<br/>- Asyncio</li><li id="d0a2" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk">When should I use which concurrency model?</li></ol><h1 id="1d96" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Fundamentals of concurrency</h1><p id="6f93" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Before jumping into Python’s concurrency models, let’s recap some foundational concepts.</p><h2 id="3811" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk">1. Concurrency vs Parallelism</h2></div></div><div class="mr"><div class="ab cb"><div class="lm pz ln qa lo qb cf qc cg qd ci bh"><figure class="mm mn mo mp mq mr qf qg paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qe"><img src="../Images/c82f7d13c46396775ef98ce15aa559c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*5zUHBzNkzOZYPu1uvuLcSQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Visual representation of concurrency vs parallelism (drawn by me)</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="e3dd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Concurrency is all about managing multiple tasks at the same time, not necessarily simultaneously. Tasks may take turns, creating the illusion of multitasking.</p><p id="0ffc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Parallelism is about running multiple tasks simultaneously, typically by leveraging multiple CPU cores.</p><h2 id="c289" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk">2. Programs</h2><p id="e7f1" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Now let’s move on to some fundamental OS concepts — programs, processes and threads.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qh"><img src="../Images/c3aa191a728825dae828926b5c384a45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7oO4wA3pvsqXgx6Gwc7twg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Multiple threads can exist simultaneously within the a single process — known as multithreading (drawn by me)</figcaption></figure><blockquote class="qi qj qk"><p id="ae06" class="nd ne ql nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A program is simply a static file, like a Python script or an executable.</p></blockquote><p id="71a2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A program sits on disk, and is passive until the operating system (OS) loads it into memory to run. Once this happens, the program becomes a <strong class="nf fr">process</strong>.</p><h2 id="2501" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk">3. Processes</h2><blockquote class="qi qj qk"><p id="d2a2" class="nd ne ql nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A process is an independent instance of a running program.</p></blockquote><p id="5d2a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A process has its own memory space, resources, and execution state. Processes are isolated from each other, meaning one process cannot interfere with another unless explicitly designed to do so via mechanisms like <strong class="nf fr"><em class="ql">inter-process communication (IPC)</em></strong>.</p><p id="b157" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Processes can generally be categorised into two types:</p><ol class=""><li id="df0d" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pa pb pc bk"><strong class="nf fr">I/O-bound processes:</strong><br/>Spend most of it’s time <strong class="nf fr"><em class="ql">waiting</em></strong> for input/output operations to complete, such as file access, network communication, or user input. While waiting, the CPU sits idle.</li><li id="2b66" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk"><strong class="nf fr">CPU-bound processes:</strong><br/>Spend most of their time <strong class="nf fr"><em class="ql">doing computations</em></strong> (e.g video encoding, numerical analysis). These tasks require a lot of CPU time.</li></ol><p id="ec9b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Lifecycle of a process:</strong></p><ul class=""><li id="9a3c" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qm pb pc bk">A process starts in a <em class="ql">new</em> state when created.</li><li id="e0e3" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny qm pb pc bk">It moves to the <em class="ql">ready</em> state, waiting for CPU time.</li><li id="2a41" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny qm pb pc bk">If the process waits for an event like I/O, it enters the <em class="ql">waiting</em> state.</li><li id="f556" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny qm pb pc bk">Finally, it <em class="ql">terminates</em> after completing its task.</li></ul><h2 id="4850" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk">4. Threads</h2><blockquote class="qi qj qk"><p id="303d" class="nd ne ql nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A thread is the smallest unit of execution within a process.<br/>A process acts as a “container” for threads, and multiple threads can be created and destroyed over the process’s lifetime.</p></blockquote><p id="97ec" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Every process has at least one thread — the <strong class="nf fr"><em class="ql">main thread</em></strong><em class="ql"> </em>— but it can also create additional threads.</p><p id="78cb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Threads share memory and resources within the same process, enabling efficient communication. However, this sharing can lead to synchronisation issues like race conditions or deadlocks if not managed carefully. Unlike processes, multiple threads in a single process are not isolated — one misbehaving thread can crash the entire process.</p><h2 id="55f6" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk">5. How does the OS manage threads and processes?</h2><p id="6200" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">The CPU can execute <strong class="nf fr"><em class="ql">only one task per core at a time</em></strong>. To handle multiple tasks, the operating system uses <strong class="nf fr"><em class="ql">preemptive context switching</em></strong>.</p><p id="0cb1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">During a context switch, the OS pauses the current task, saves its state and loads the state of the next task to be executed.</p><p id="810a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This rapid switching creates the illusion of simultaneous execution on a single CPU core.</p><p id="75d6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For processes, context switching is more resource-intensive because the OS must save and load separate memory spaces. For threads, switching is faster because threads share the same memory within a process. However, frequent switching introduces overhead, which can slow down performance.</p><p id="77fd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">True parallel execution of processes can only occur if there are multiple CPU cores available. Each core handles a separate process simultaneously.</p><h1 id="cdf1" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Python’s concurrency models</h1><p id="b7c9" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Let’s now explore Python’s specific concurrency models.</p></div></div><div class="mr"><div class="ab cb"><div class="lm pz ln qa lo qb cf qc cg qd ci bh"><figure class="mm mn mo mp mq mr qf qg paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qn"><img src="../Images/4aa327a57c30f849fea84547f3f53fb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*YrsrPOh5y4EL_7UOFJ08yg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Summary of the different concurrency models (drawn by me)</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="dee9" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">1. Multithreading</h1><p id="f432" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Multithreading allows a process to execute multiple threads concurrently, with threads sharing the same memory and resources (see diagrams 2 and 4).</p><p id="bffa" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">However, Python’s Global Interpreter Lock (GIL) limits multithreading’s effectiveness for CPU-bound tasks.</p><h2 id="a48a" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk">Python’s Global Interpreter Lock (GIL)</h2><blockquote class="qi qj qk"><p id="2a8b" class="nd ne ql nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The GIL is a lock that allows only one thread to hold control of the Python interpreter at any time, meaning only one thread can execute Python bytecode at once.</p></blockquote><p id="578f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The GIL was introduced to simplify memory management in Python as many internal operations, such as object creation, are not thread safe by default. Without a GIL, multiple threads trying to access the shared resources will require complex locks or synchronisation mechanisms to prevent race conditions and data corruption.</p><p id="ada5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr"><em class="ql">When is GIL a bottleneck?</em></strong></p><ul class=""><li id="cf28" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qm pb pc bk">For single threaded programs, the GIL is irrelevant as the thread has exclusive access to the Python interpreter.</li><li id="851e" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny qm pb pc bk">For multithreaded I/O-bound programs, the GIL is less problematic as threads release the GIL when waiting for I/O operations.</li><li id="f139" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny qm pb pc bk">For multithreaded CPU-bound operations, the GIL becomes a significant bottleneck. Multiple threads competing for the GIL must take turns executing Python bytecode.</li></ul><p id="f5c2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">An interesting case worth noting is the use of <code class="cx qo qp qq qr b">time.sleep</code>, which Python effectively treats as an I/O operation. The <code class="cx qo qp qq qr b">time.sleep</code> function is not CPU-bound because it does not involve active computation or the execution of Python bytecode during the sleep period. Instead, the responsibility of tracking the elapsed time is delegated to the OS. During this time, the thread releases the GIL, allowing other threads to run and utilise the interpreter.</p><h1 id="59fd" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">2. Multiprocessing</h1><p id="e53d" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Multiprocessing enables a system to run multiple processes in parallel, each with its own memory, GIL and resources. Within each process, there may be one or more threads (see diagrams 3 and 4).</p><p id="58fa" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Multiprocessing bypasses the limitations of the GIL. This makes it suitable for CPU bound tasks that require heavy computation.</p><p id="1653" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">However, multiprocessing is more resource intensive due to separate memory and process overheads.</p><h1 id="ffe0" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">3. Asyncio</h1><blockquote class="qi qj qk"><p id="1c21" class="nd ne ql nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Unlike threads or processes, asyncio uses a single thread to handle multiple tasks.</p></blockquote><p id="2ad3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When writing asynchronous code with the <code class="cx qo qp qq qr b">asyncio</code> library, you'll use the <code class="cx qo qp qq qr b">async/await</code> keywords to manage tasks.</p><h2 id="fd8f" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk"><strong class="al"><em class="qs">Key concepts</em></strong></h2><ol class=""><li id="30ea" class="nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny pa pb pc bk"><strong class="nf fr">Coroutines:</strong> These are functions defined with <code class="cx qo qp qq qr b">async def</code> . They are the core of asyncio and represent tasks that can be paused and resumed later.</li><li id="02ad" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk"><strong class="nf fr">Event loop:</strong> It manages the execution of tasks.</li><li id="b49a" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk"><strong class="nf fr">Tasks:</strong> Wrappers around coroutines. When you want a coroutine to actually start running, you turn it into a task — eg. using <code class="cx qo qp qq qr b">asyncio.create_task()</code></li><li id="2783" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk"><code class="cx qo qp qq qr b"><strong class="nf fr">await</strong></code> : Pauses execution of a coroutine, giving control back to the event loop.</li></ol><h2 id="607c" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk"><strong class="al"><em class="qs">How it works</em></strong></h2><p id="12d4" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Asyncio runs an event loop that schedules tasks. Tasks voluntarily “pause” themselves when waiting for something, like a network response or a file read. While the task is paused, the event loop switches to another task, ensuring no time is wasted waiting.</p><p id="7530" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This makes asyncio ideal for scenarios involving <strong class="nf fr">many small tasks that spend a lot of time waiting</strong>, such as handling thousands of web requests or managing database queries. Since everything runs on a single thread, asyncio avoids the overhead and complexity of thread switching.</p><blockquote class="qi qj qk"><p id="4d64" class="nd ne ql nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">The key difference between asyncio and multithreading lies in how they handle waiting tasks.</strong></p></blockquote><ul class=""><li id="9282" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qm pb pc bk">Multithreading relies on the OS to switch between threads when one thread is waiting (<strong class="nf fr"><em class="ql">preemptive context switching</em></strong>).<br/>When a thread is waiting, the OS switches to another thread automatically.</li><li id="7b30" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny qm pb pc bk">Asyncio uses a single thread and depends on tasks to “cooperate” by pausing when they need to wait (<strong class="nf fr"><em class="ql">cooperative multitasking</em></strong>).</li></ul><h2 id="91fe" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk">2 ways to write async code:</h2><p id="4a4b" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk"><code class="cx qo qp qq qr b"><strong class="nf fr">method 1: await coroutine</strong></code></p><p id="726c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When you directly <code class="cx qo qp qq qr b">await</code> a coroutine, the execution of the <strong class="nf fr"><em class="ql">current coroutine pauses</em></strong> at the <code class="cx qo qp qq qr b">await</code> statement until the awaited coroutine finishes. Tasks are executed <strong class="nf fr"><em class="ql">sequentially </em></strong>within the current coroutine<strong class="nf fr"><em class="ql">.</em></strong></p><p id="e4c1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Use this approach when you need the result of the coroutine<em class="ql"> </em><strong class="nf fr"><em class="ql">immediately</em></strong> to proceed with the next steps.</p><p id="8564" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Although this might sound like synchronous code, it’s not. In synchronous code, the entire program would block during a pause.</p><blockquote class="qi qj qk"><p id="c5f3" class="nd ne ql nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">With asyncio, only the current coroutine pauses, while the rest of the program can continue running. This makes asyncio non-blocking at the program level.</p></blockquote><p id="b879" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Example:</strong></p><p id="070c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The event loop pauses the current coroutine until <code class="cx qo qp qq qr b">fetch_data</code> is complete.</p><pre class="mm mn mo mp mq qt qr qu bp qv bb bk"><span id="013c" class="qw oa fq qr b bg qx qy l qz ra">async def fetch_data():<br/>    print("Fetching data...")<br/>    await asyncio.sleep(1)  # Simulate a network call<br/>    print("Data fetched")<br/>    return "data"<br/><br/>async def main():<br/>    result = await fetch_data()  # Current coroutine pauses here<br/>    print(f"Result: {result}")<br/><br/>asyncio.run(main())</span></pre><p id="13d1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><code class="cx qo qp qq qr b"><strong class="nf fr">method 2: asyncio.create_task(coroutine)</strong></code></p><p id="bf63" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The coroutine is scheduled to <strong class="nf fr"><em class="ql">run concurrently in the background</em></strong>. Unlike <code class="cx qo qp qq qr b">await</code>, the current coroutine continues executing immediately without waiting for the scheduled task to finish.</p><p id="ca2a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr"><em class="ql">The scheduled coroutine starts running as soon as the event loop finds an opportunity</em></strong>, without needing to wait for an explicit <code class="cx qo qp qq qr b">await</code>.</p><blockquote class="qi qj qk"><p id="8865" class="nd ne ql nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">No new threads are created; instead, the coroutine runs within the same thread as the event loop, which manages when each task gets execution time.</p></blockquote><p id="23eb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This approach enables concurrency within the program, allowing multiple tasks to overlap their execution efficiently. You will later need to <code class="cx qo qp qq qr b">await</code> the task to get it’s result and ensure it’s done.</p><p id="3590" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Use this approach when you want to run tasks concurrently and don’t need the results immediately.</p><p id="f942" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Example:</strong></p><p id="3a9c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When the line <code class="cx qo qp qq qr b">asyncio.create_task()</code> is reached, the coroutine <code class="cx qo qp qq qr b">fetch_data()</code> is scheduled to start running <strong class="nf fr"><em class="ql">immediately when the event loop is available</em></strong>. This can happen even <strong class="nf fr"><em class="ql">before</em></strong> you explicitly <code class="cx qo qp qq qr b">await</code> the task. In contrast, in the first <code class="cx qo qp qq qr b">await</code> method, the coroutine only starts executing when the <code class="cx qo qp qq qr b">await</code> statement is reached.</p><p id="1966" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Overall, this makes the program more efficient by overlapping the execution of multiple tasks.</p><pre class="mm mn mo mp mq qt qr qu bp qv bb bk"><span id="846b" class="qw oa fq qr b bg qx qy l qz ra">async def fetch_data():<br/>    # Simulate a network call<br/>    await asyncio.sleep(1)<br/>    return "data"<br/><br/>async def main():<br/>    # Schedule fetch_data<br/>    task = asyncio.create_task(fetch_data())  <br/>    # Simulate doing other work<br/>    await asyncio.sleep(5)  <br/>    # Now, await task to get the result<br/>    result = await task  <br/>    print(result)<br/><br/>asyncio.run(main())</span></pre><h2 id="59de" class="pi oa fq bf ob pj pk pl oe pm pn po oh nm pp pq pr nq ps pt pu nu pv pw px py bk">Other important points</h2><ul class=""><li id="28fc" class="nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny qm pb pc bk"><strong class="nf fr">You can mix synchronous and asynchronous code. </strong><br/>Since synchronous code is blocking, it can be offloaded to a separate thread using <code class="cx qo qp qq qr b">asyncio.to_thread()</code>. This makes your program effectively multithreaded.<br/>In the example below, the asyncio event loop runs on the main thread, while a separate background thread is used to execute the <code class="cx qo qp qq qr b">sync_task</code>.</li></ul><pre class="mm mn mo mp mq qt qr qu bp qv bb bk"><span id="f3b5" class="qw oa fq qr b bg qx qy l qz ra">import asyncio<br/>import time<br/><br/>def sync_task():<br/>    time.sleep(2)<br/>    return "Completed"<br/><br/>async def main():<br/>    result = await asyncio.to_thread(sync_task)<br/>    print(result)<br/><br/>asyncio.run(main())</span></pre><ul class=""><li id="046f" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qm pb pc bk">You should offload CPU-bound tasks which are computationally intensive to a separate process.</li></ul><h1 id="16cf" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">When should I use which concurrency model?</h1><p id="288c" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">This flow is a good way to decide when to use what.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rb"><img src="../Images/1cbf5604feb451093217df351ec93878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Das-hY02tbJbHPxCmMvXA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Flowchart (drawn by me), referencing this <a class="af nc" href="https://stackoverflow.com/questions/27435284/multiprocessing-vs-multithreading-vs-asyncio/52498068#52498068" rel="noopener ugc nofollow" target="_blank">stackoverflow</a> discussion</figcaption></figure><ol class=""><li id="5419" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pa pb pc bk"><strong class="nf fr">Multiprocessing</strong><br/>- Best for CPU-bound tasks which are computationally intensive.<br/>- When you need to bypass the GIL — Each process has it’s own Python interpreter, allowing for true parallelism.</li><li id="bd60" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk"><strong class="nf fr">Multithreading</strong><br/>- Best for fast I/O-bound tasks as the frequency of context switching is reduced and the Python interpreter sticks to a single thread for longer<br/>- Not ideal for CPU-bound tasks due to GIL.</li><li id="7c51" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk"><strong class="nf fr">Asyncio</strong><br/>- Ideal for slow I/O-bound tasks such as long network requests or database queries because it efficiently handles waiting, making it scalable. <br/>- Not suitable for CPU-bound tasks without offloading work to other processes.</li></ol><h1 id="15b7" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Wrapping up</h1><p id="a7db" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">That’s it folks. There’s a lot more that this topic has to cover but I hope I’ve introduced to you the various concepts, and when to use each method.</p><p id="6799" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Thanks for reading! I write regularly on Python, software development and the projects I build, so give me a follow to not miss out. See you in the next article :)</p></div></div></div></div>    
</body>
</html>