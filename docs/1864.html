<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Metrics to Evaluate a Classification Machine Learning Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Metrics to Evaluate a Classification Machine Learning Model</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/metrics-to-evaluate-a-classification-machine-learning-model-f05f1facd569?source=collection_archive---------7-----------------------#2024-07-31">https://towardsdatascience.com/metrics-to-evaluate-a-classification-machine-learning-model-f05f1facd569?source=collection_archive---------7-----------------------#2024-07-31</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="b1bd" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><em class="hd">A study case of credit card fraud</em></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@lucasbraga461?source=post_page---byline--f05f1facd569--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Lucas Braga" class="l ep by dd de cx" src="../Images/a652476cfec8d4f129d2d47a64c3e8c3.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*3H1gxVegE0mWYl3nw5xXAg.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f05f1facd569--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@lucasbraga461?source=post_page---byline--f05f1facd569--------------------------------" rel="noopener follow">Lucas Braga</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f05f1facd569--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 31, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk ld le ab q ee lf lg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lb lc">1</span></p></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lh k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al li an ao ap ie lj lk ll" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lm cn"><div class="l ae"><div class="ab cb"><div class="ln lo lp lq lr ls ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><pre class="mk ml mm mn mo mp mq mr bp ms bb bk"><span id="aa3d" class="mt mu fq mq b bg mv mw l mx my">1. Introduction<br/>2. How does a model make predictions<br/>3. Confusion Matrix<br/>4. Metrics to Evaluate Model Performance<br/>5. When to use what metrics</span></pre><p id="2706" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">1. Introduction</strong></p><p id="bf19" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Once we trained a supervised machine learning model to solve a classification problem, we’d be happy if this was the end of our work, and we could just throw them new data. We hope it will classify everything correctly. However, in reality, not all predictions that a model makes are correct. There is a famous quote well known in Data Science, created by a British Statistician that says:</p><blockquote class="nv nw nx"><p id="51da" class="mz na ny nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">“All models are wrong; some are useful.” CLEAR, James, 1976.</p></blockquote><p id="5cb1" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">So, how do we know how good the model we have is? The short answer is that we do that by evaluating how correct the model’s predictions are. For that, there are several metrics that we could use.</p><p id="ac9c" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">2. How does a model make predictions? i.e., How does a model classify data?</strong></p><figure class="mk ml mm mn mo oc nz oa paragraph-image"><div role="button" tabindex="0" class="od oe ed of bh og"><div class="nz oa ob"><img src="../Images/d4a1e2df439a5ffc27a6d116314a8674.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_p3Ix8qkUjk-kc1coTgSTQ.png"/></div></div><figcaption class="oi oj ok nz oa ol om bf b bg z dx">Image 1: Model making prediction</figcaption></figure><p id="f818" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Let’s say we’ve trained a Machine Learning model to classify a credit card transaction and decide whether that particular transaction is Fraud or not Fraud. The model will consume the transaction data and give back a score that could be any number within the range of 0 to 1, e.g., 0.05, 0.24, 0.56, 0.9875. For this article, we’ll define a default threshold of 0.5, which means if the model gave a score lower than 0.5, then the model has classified that transaction as not Fraud (<strong class="nb fr">that’s a model prediction</strong>!). If the model gave a score greater or equal to 0.5, then the model classified that transaction as Fraud (that’s also a model prediction!).</p><p id="0759" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">In practice, we don’t work with the default of 0.5. We look into different thresholds to see what is more appropriate to optimize the model’s performance, but that discussion is for another day.</p><p id="3787" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">3. Confusion Matrix</strong></p><p id="a3dc" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">The confusion matrix is a fundamental tool for visualizing the performance of a classification model. It helps in understanding the various outcomes of the predictions, which include:</p><ul class=""><li id="dc50" class="mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu on oo op bk"><strong class="nb fr">True Positive (TP)</strong></li><li id="629b" class="mz na fq nb b go oq nd ne gr or ng nh ni os nk nl nm ot no np nq ou ns nt nu on oo op bk"><strong class="nb fr">False Positive (FP)</strong></li><li id="9fbb" class="mz na fq nb b go oq nd ne gr or ng nh ni os nk nl nm ot no np nq ou ns nt nu on oo op bk"><strong class="nb fr">False Negative (FN)</strong></li><li id="3c35" class="mz na fq nb b go oq nd ne gr or ng nh ni os nk nl nm ot no np nq ou ns nt nu on oo op bk"><strong class="nb fr">True Negative (TN)</strong></li></ul><p id="0847" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Let’s break it down!</p><p id="69c1" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">To evaluate a model’s effectiveness, we need to compare its predictions against actual outcomes. Actual outcomes are also known as “the reality.” So, a model could have classified a transaction as Fraud, and in fact, the customer asked for his money back on that same transaction, claiming that his credit card was stolen.</p><p id="deb3" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">In that scenario, the model correctly predicted the transaction as Fraud, a <strong class="nb fr">True Positive (TP)</strong>.</p><p id="662d" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">In Fraud detection contexts, the “positive” class is labeled as Fraud, and the “negative” class is labeled Non-Fraud.</p><p id="3025" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">A <strong class="nb fr">False Positive (FP)</strong>, on the other hand, occurs when the model also classifies a transaction as Fraud, but in that case, the customer did not report any fraudulent activity on their credit card usage. So, in this transaction, the Machine Learning model made a mistake.</p><p id="5304" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">A <strong class="nb fr">True Negative (TN) </strong>is when the model classified the transaction as Not Fraud, and in fact, it was not Fraud. So, the model has made the correct classification.</p><p id="f72c" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">A <strong class="nb fr">False Negative (FN) </strong>was when the model classified the transaction as Not Fraud. Still, it was Fraud (the customer reported fraudulent activity on their credit card related to that transaction). In this case, the Machine Learning model also made a mistake, but it’s a different type of error than a False Positive.</p><p id="1ce3" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Let’s have a look at image 2</p><figure class="mk ml mm mn mo oc nz oa paragraph-image"><div role="button" tabindex="0" class="od oe ed of bh og"><div class="nz oa ov"><img src="../Images/2c4a16c6c43ec99bb1ad30bfb9b2644a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SOQXZKrZy-2IyIjh_DkkCg.png"/></div></div><figcaption class="oi oj ok nz oa ol om bf b bg z dx">Image 2: Confusion Matrix classifying a Machine Learning Model for Fraud</figcaption></figure><p id="503a" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Let’s see a different case, maybe more relatable. A test was designed to tell whether a patient has COVID. See image 3.</p><figure class="mk ml mm mn mo oc nz oa paragraph-image"><div role="button" tabindex="0" class="od oe ed of bh og"><div class="nz oa ow"><img src="../Images/437092ea96fac940202c77c8082f29e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zi2H0fpSvwYE8y5VoP_Ysg.png"/></div></div><figcaption class="oi oj ok nz oa ol om bf b bg z dx">Image 3: Confusion Matrix for a COVID test</figcaption></figure><p id="55ae" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">So, for every transaction, you could check whether it’s TP, FP, TN, or FN. And you could do this for thousands of millions of transactions and write the results down on a 2x2 table with all the counts of TP, FP, TN and FN. This table is also known as a <strong class="nb fr">Confusion Matrix</strong>.</p><p id="59e6" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Let’s say you compared the model predictions of 100,000 transactions against their actual outcomes and came up with the following Confusion Matrix (see image 4).</p><figure class="mk ml mm mn mo oc nz oa paragraph-image"><div role="button" tabindex="0" class="od oe ed of bh og"><div class="nz oa ox"><img src="../Images/4edc6fa1e484c3ab5934edb51059843b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*imZ9limdAHWJ1Yg4lP6pOA.png"/></div></div><figcaption class="oi oj ok nz oa ol om bf b bg z dx">Image 4: Confusion Matrix</figcaption></figure><p id="8717" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">4. Metrics to Evaluate Model Performance</strong></p><p id="a49e" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">and what a confusion matrix is, we are ready to explore the metrics used to evaluate a classification model’s performance.</p><p id="e95e" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">Precision = TP / (TP + FP)</strong></p><p id="407b" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">It answers the question: What’s the proportion of correct predictions among all predictions? It reflects the proportion of predicted fraud cases that were Fraud.</p><p id="8d69" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">In simple language: What’s the proportion of when the model called it Fraud, and it was Fraud?</p><p id="6189" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Looking at the Confusion Matrix from image 4, we compute the Precision = 76.09% since Precision = 350 / (350 + 110).</p><p id="e876" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">Recall = TP / (TP + FN)</strong></p><p id="06ae" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Recall is also known as True Positive Rate (TPR). It answers the question: What’s the proportion of correct predictions among all positive actual outcomes?</p><p id="6a34" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">In simple language, what’s the proportion of times that the model caught the fraudster correctly in all actual fraud cases?</p><p id="e0d8" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Using the Confusion Matrix from image 4, the Recall = 74.47%, since Recall = 350 / (350 + 120).</p><p id="7dda" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">Alert Rate = (TP + FP) / (TP + FP + TN + FN)</strong></p><p id="8456" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Also known as Block Rate, this metric helps answer the question: What’s the proportion of positive predictions over all predictions?</p><p id="018d" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">In simple language: What proportion of times the model predicted something was Fraud?</p><p id="c586" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Using the Confusion Matrix from image 4, the Alert Rate = 0.46%, since Alert Rate = (350 + 110) / (350 + 110 + 120 + 99420).</p><p id="c5c9" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">F1 Score = 2x (Precision x Recall) / (Precision + Recall)</strong></p><p id="9d82" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">The F1 Score is a harmonic mean of Precision and Recall. It is a balanced measure between Precision and Recall, providing a single score to assess the model.</p><p id="74c0" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Using the Confusion Matrix from image 4, the F1-Score = 75.27%, since F1-Score = 2*(76.09% * 74.47%) / (76.09% + 74.47%).</p><p id="9533" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">Accuracy = TP + TN / (TP + TN + FP + FN)</strong></p><p id="fbbd" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Accuracy helps answer this question: What’s the proportion of correctly classified transactions over all transactions?</p><p id="952a" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Using the Confusion Matrix from image 4, the Accuracy = 99.77%, since Accuracy = (350 + 120) / (350 + 110 + 120 + 99420).</p><figure class="mk ml mm mn mo oc nz oa paragraph-image"><div role="button" tabindex="0" class="od oe ed of bh og"><div class="nz oa oy"><img src="../Images/82f2916f4a4144a638bce48a97268c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BRIjkEondhDrWTXGuZyGvw.png"/></div></div><figcaption class="oi oj ok nz oa ol om bf b bg z dx">Image 5: Confusion Matrix with Evaluation Metrics</figcaption></figure><p id="7c43" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">5. When to use what metric</strong></p><p id="be83" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Accuracy is a go-to metric for evaluating many classification machine learning models. However, accuracy does not work well for cases where the target variable is imbalanced. In the case of Fraud detection, there is usually a tiny percentage of the data that is fraudulent; for example, in credit card fraud, it’s usually less than 1% of fraudulent transactions. So even if the model says that all transactions are fraudulent, which would be very incorrect, or that all transactions are not fraudulent, which would also be very wrong, the model’s accuracy would still be above 99%.</p><p id="732a" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">So what to do in those cases? Precision, Recall, and Alert Rate. Those are usually the metrics that give a good perspective on the model performance, even if the data is imbalanced. Which one exactly to use might depend on your stakeholders. I worked with stakeholders that said, whatever you do, please keep a Precision of at least 80%. So in that case, the stakeholder was very concerned about the user experience because if the Precision is very low, that means there will be a lot of False Positives, meaning that the model would incorrectly block good customers thinking they are placing fraudulent credit card transactions.</p><p id="eadb" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">On the other hand, there is a trade-off between Precision and Recall: the higher the Precision, the lower the Recall. So, if the model has a very high Precision, it won’t be great at finding all the fraud cases. In some sense, it also depends on how much a fraud case costs the business (financial loss, compliance problems, fines, etc.) vs. how many false positive cases cost the business (customer lifetime, which impacts business profitability).</p><p id="708f" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">So, in cases where the financial decision between Precision and Recall is unclear, a good metric to use is F1-Score, which helps provide a balance between Precision and Recall and optimizes for both of them.</p><p id="b135" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Last but not least, the Alert Rate is also a critical metric to consider because it gives an intuition about the number of transactions the Machine Learning model is planning to block. If the Alert Rate is very high, like 15%, that means that from all the orders placed by customers, 15% will be blocked, and only 85% will be accepted. So if you have a business with 1,000,000 orders daily, the machine learning model would block 150,000 of them thinking they’re fraudulent transactions. That’s a massive amount of orders blocked, and it’s important to have an instinct about the percentage of fraud cases. If fraud cases are about 1% or less, then a model blocking 15% is not only making a lot of mistakes but also blocking a big part of the business revenue.</p><p id="eb64" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">6. Conclusion</strong></p><p id="b04d" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Understanding these metrics allows data scientists and analysts to interpret the results of classification models better and enhance their performance. Precision and Recall offer more insights into the effectiveness of a model than mere accuracy, not only, but especially in fields like fraud detection where the class distribution is heavily skewed.</p><p id="eee1" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><em class="ny">*Images: Unless otherwise noted, all images are by the author. Image 1’s robot face was created by DALL-E, and it's for public use.</em></p></div></div></div></div>    
</body>
</html>