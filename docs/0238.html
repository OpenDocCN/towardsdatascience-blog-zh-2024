<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Adapted Prediction Intervals by Means of Conformal Predictions and a Custom Non-Conformity Score</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Adapted Prediction Intervals by Means of Conformal Predictions and a Custom Non-Conformity Score</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/use-case-adapted-prediction-intervals-by-means-of-conformal-predictions-and-a-custom-non-conformity-b4fb28d2a4f7?source=collection_archive---------3-----------------------#2024-01-24">https://towardsdatascience.com/use-case-adapted-prediction-intervals-by-means-of-conformal-predictions-and-a-custom-non-conformity-b4fb28d2a4f7?source=collection_archive---------3-----------------------#2024-01-24</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="3386" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How confident should I be in a machine learning model’s prediction for a new data point? Could I get a range of likely values?</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@arnaud.gc.capitaine?source=post_page---byline--b4fb28d2a4f7--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Arnaud Capitaine" class="l ep by dd de cx" src="../Images/3d2ef4ffd67289732c79b59c37771b70.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*fg4vf_G_kPTu66M974CBZw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--b4fb28d2a4f7--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@arnaud.gc.capitaine?source=post_page---byline--b4fb28d2a4f7--------------------------------" rel="noopener follow">Arnaud Capitaine</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--b4fb28d2a4f7--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 24, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/4a98c53a6c2c214aed040c14db0e4ced.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KeaesoeNyizcb7abRtnfaw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by author</figcaption></figure><p id="087b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk nx"><span class="l ny nz oa bo ob oc od oe of ed">W</span>hen working on a supervised task, machine learning models can be used to predict the outcome for new samples. However, it is likely that <strong class="nd fr">the prediction from a new data point is incorrect</strong>. This is particularly true for a regression task where the outcome may take an infinite number of values.</p><p id="809e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In order to get a more insightful prediction, we may be interested in (or even need) a prediction interval instead of a single point. <strong class="nd fr">Well informed decisions should be made by taking into account uncertainty.</strong> For instance, as a property investor, I would not offer the same amount if the prediction interval is [100000–10000 ; 100000+10000] as if it is [100000–1000 ; 100000+1000] (even though the single point predictions are the same, i.e. 100000). I may trust the single prediction for the second interval but I would probably take a deep dive into the first case because the interval is quite wide, so is the profitability, and the final price may significantly differs from the single point prediction.</p><h1 id="ff7c" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Prediction interval vs confidence interval</h1><p id="9711" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">Before continuing, I first would like to clarify the difference between these two definitions. It was not obvious for me when I started to learn conformal prediction. Since I may not be the only one being confused, this is why I would like to give additional explanation.</p><ul class=""><li id="1fc1" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ph pi pj bk">A (1-α) <strong class="nd fr">confidence interval </strong>[<a class="af pk" href="https://en.wikipedia.org/wiki/Confidence_interval" rel="noopener ugc nofollow" target="_blank">1</a>] is an interval based on 2 statistics, ŝ_{lb} and ŝ_{ub}, which has a probability greater than (1-α) to contain the actual parameter that we try to estimate. Here θ is a parameter (not a random variable).</li></ul><blockquote class="pl"><p id="1498" class="pm pn fq bf po pp pq pr ps pt pu nw dx">ℙ([ŝ_{lb} ; ŝ_{ub}] ∋ θ) ≥ 1-α</p></blockquote><ul class=""><li id="4e65" class="nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw ph pi pj bk">A (1-α) <strong class="nd fr">prediction interval</strong> [<a class="af pk" href="https://en.wikipedia.org/wiki/Prediction_interval" rel="noopener ugc nofollow" target="_blank">2</a>] is an interval based on 2 statistics, ŝ_{lb} and ŝ_{ub}, which has the following property: the target random variable has a probability greater than (1-α) of being inside this prediction interval. Here Y is a random variable (not a parameter).</li></ul><blockquote class="pl"><p id="4c62" class="pm pn fq bf po pp pq pr ps pt pu nw dx">ℙ(Y∈[ŝ_{lb} ; ŝ_{ub}]) ≥ (1-α)</p></blockquote><p id="21eb" class="pw-post-body-paragraph nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw fj bk">Let’s consider an example to illustrate the difference. Let’s consider a n-sample of parent distribution N(μ, σ²). ŝ is the unbiased estimator of σ. &lt;Xn&gt; is the mean of the n-sample. I noted q the 1-α/2 quantile of the Student distribution of n-1 degree of freedom (to limit the length of the formula).</p><ul class=""><li id="8d03" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ph pi pj bk">The symmetric<strong class="nd fr"> confidence interval</strong> for μ is:</li></ul><blockquote class="pl"><p id="ee6b" class="pm pn fq bf po pp pq pr ps pt pu nw dx">[&lt;Xn&gt;-q*ŝ/√(n) ; &lt;Xn&gt;+q*ŝ/√(n)]</p></blockquote><ul class=""><li id="4fd3" class="nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw ph pi pj bk">The symmetric <strong class="nd fr">prediction interval</strong> for X(n+1), a (n+1)th random variable from the same distribution N(μ, σ²), is:</li></ul><blockquote class="pl"><p id="2100" class="pm pn fq bf po pp pq pr ps pt pu nw dx">[&lt;Xn&gt;-q*ŝ*√(1+1/n)) ; &lt;Xn&gt;+q*ŝ*√(1+1/n)]</p></blockquote><p id="3418" class="pw-post-body-paragraph nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw fj bk">Now that we have clarified these definitions, let’s come back to our goal: design insightful prediction intervals to make well informed decisions. There are many ways to design prediction intervals [<a class="af pk" href="https://en.wikipedia.org/wiki/Prediction_interval" rel="noopener ugc nofollow" target="_blank">2</a>] [<a class="af pk" href="https://medium.com/@heinrichpeters/prediction-intervals-in-machine-learning-a2faa36b320c" rel="noopener">3</a>]. We are going to focus on conformal predictions [<a class="af pk" href="https://en.wikipedia.org/wiki/Conformal_prediction" rel="noopener ugc nofollow" target="_blank">4</a>].</p><h1 id="a2ee" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Conformal predictions</h1><p id="f5c3" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">Conformal prediction has been introduced to generate prediction intervals with weak theoretical guarantees. It only requires that the points are exchangeable, which is weaker than i.i.d. assumption (independent and identically distributed random variables). There is no assumption on the data distribution nor on the model. By splitting the data between a training and a calibration set, it is possible to get a trained model and some non-conformity scores that we could use to build a prediction interval on a new data point (with theoretical coverage guarantee provided that the exchangeability assumption is true).</p><p id="690f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Let’s now consider an example. I would like to get some prediction intervals for house prices. I have considered the house_price dataset from OpenML [<a class="af pk" href="https://www.openml.org/search?type=data&amp;sort=runs&amp;id=42165&amp;status=active" rel="noopener ugc nofollow" target="_blank">5</a>]. I have used the library MAPIE [<a class="af pk" href="https://github.com/scikit-learn-contrib/MAPIE" rel="noopener ugc nofollow" target="_blank">6</a>] that implements conformal predictions. I have trained a model (I did not spend some time optimizing it since it is not the purpose of the post). I have displayed below the prediction points and intervals for the test set as well as the actual price.</p><p id="a25b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">There are 3 subplots:</p><p id="6aa4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">- The 1st one displays the single point predictions (blue points) as well as the predictions intervals (vertical blue lines) against the true value (on abscissa). The red diagonal is the identity line. If a vertical line crosses the red line, the prediction interval does contain the actual value, otherwise it does not.<br/>- The 2nd one displays the prediction interval widths.<br/>- The 3rd one displays the global and local coverages. The coverage is the ratio between the number of samples falling inside the prediction intervals divided by the total number of samples. The global coverage is the ratio over all the points of the test set. The local coverages are the ratios over subsets of points of the test set. The buckets are created by means of quantiles of the actual prices.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qa"><img src="../Images/a40e31c43df8e167081d1baea69df2e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*jITlWdfGjX1XAu0GrPnK6g.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by author</figcaption></figure><p id="b21b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We can see that prediction width is almost the same for all the predictions. The coverage is 94%, close to the chosen value 95%. However, even though the global coverage is (close to) the desired one, if we look at (what I call) the local coverages (coverage for a subset of data points with almost the same price) we can see that <strong class="nd fr">coverage is bad for expensive houses</strong> (expensive regarding my dataset). Conversely, it is good for cheap ones (cheap regarding my dataset). However, <strong class="nd fr">the insights for cheap houses are really poor</strong>. For instance, the prediction interval may be [0 ; 180000] for a cheap house, which is not really helpful to make a decision.</p><p id="0718" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Instinctively, I would like to get prediction intervals which width is proportional to the prediction value so that the prediction widths scale to the predictions. This is why I have looked at other non conformity scores, more adapted to my use case.</p><h1 id="4478" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Conformal predictions with custom non conformity score</h1><p id="3912" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">Even though I am not a real estate expert, I have some expectations regarding the prediction intervals. As said previously, I would like them to be, kind of, proportional to the predicted value. I would like a small prediction interval when the price is low and I expect a bigger one when the price is high.</p><p id="edcf" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Consequently, for this use case I am going to implement two non conformity scores that respect the conditions that a non conformity score must fulfill [<a class="af pk" href="https://proceedings.mlr.press/v204/cordier23a/cordier23a.pdf" rel="noopener ugc nofollow" target="_blank">7</a>] (3.1 and Appendix C.). I have created two classes from the interface <em class="qb">ConformityScore</em> which requires to implement at least two methods <em class="qb">get_signed_conformity_scores</em> and <em class="qb">get_estimation_distribution</em>. <em class="qb">get_signed_conformity_scores</em> computes the non conformity scores from the predictions and the observed values. <em class="qb">get_estimation_distribution </em>computes the estimated distribution that is then used to get the prediction interval (after providing a chosen coverage). I decided to name my first non conformity score <em class="qb">PoissonConformityScore</em> because it is intuitively linked to the Poisson regression. When considering a Poisson regression, (Y-μ)/√μ has 0 mean and a variance of 1. Similarly, for the <em class="qb">TweedieConformityScore</em> class, when considering a Tweedie regression, (Y-μ)/(μ^(p/2)) has 0 mean and a variance of σ² (which is assumed to be the same for all observations). In both classes, <em class="qb">sym=False</em> because the non conformity scores are not expected to be symmetrical. Besides, <em class="qb">consistency_check=False</em> because I know that the two methods are consistent and fulfill the necessary requirements.</p><pre class="ml mm mn mo mp qc qd qe bp qf bb bk"><span id="14b7" class="qg oh fq qd b bg qh qi l qj qk">import numpy as np<br/><br/>from mapie._machine_precision import EPSILON<br/>from mapie.conformity_scores import ConformityScore<br/>from mapie._typing import ArrayLike, NDArray<br/><br/>class PoissonConformityScore(ConformityScore):<br/>    """<br/>    Poisson conformity score.<br/><br/>    The signed conformity score = (y - y_pred) / y_pred**(1/2).<br/>    The conformity score is not symmetrical.<br/>    y must be positive<br/>    y_pred must be strictly positive<br/><br/>    This is appropriate when the confidence interval is not symmetrical and<br/>    its range depends on the predicted values.<br/>    """<br/><br/>    def __init__(<br/>        self,<br/>    ) -&gt; None:<br/>        super().__init__(sym=False, consistency_check=False, eps=EPSILON)<br/><br/>    def _check_observed_data(<br/>        self,<br/>        y: ArrayLike,<br/>    ) -&gt; None:<br/>        if not self._all_positive(y):<br/>            raise ValueError(<br/>                f"At least one of the observed target is strictly negative "<br/>                f"which is incompatible with {self.__class__.__name__}. "<br/>                "All values must be positive."<br/>            )<br/><br/>    def _check_predicted_data(<br/>        self,<br/>        y_pred: ArrayLike,<br/>    ) -&gt; None:<br/>        if not self._all_strictly_positive(y_pred):<br/>            raise ValueError(<br/>                f"At least one of the predicted target is negative "<br/>                f"which is incompatible with {self.__class__.__name__}. "<br/>                "All values must be strictly positive."<br/>            )<br/><br/>    @staticmethod<br/>    def _all_positive(<br/>        y: ArrayLike,<br/>    ) -&gt; bool:<br/>        return np.all(np.greater_equal(y, 0))<br/><br/>    @staticmethod<br/>    def _all_strictly_positive(<br/>        y: ArrayLike,<br/>    ) -&gt; bool:<br/>        return np.all(np.greater(y, 0))<br/><br/>    def get_signed_conformity_scores(<br/>        self,<br/>        X: ArrayLike,<br/>        y: ArrayLike,<br/>        y_pred: ArrayLike,<br/>    ) -&gt; NDArray:<br/>        """<br/>        Compute the signed conformity scores from the observed values<br/>        and the predicted ones, from the following formula:<br/>        signed conformity score = (y - y_pred) / y_pred**(1/2)<br/>        """<br/>        self._check_observed_data(y)<br/>        self._check_predicted_data(y_pred)<br/>        return np.divide(np.subtract(y, y_pred), np.power(y_pred, 1 / 2))<br/><br/>    def get_estimation_distribution(<br/>        self, X: ArrayLike, y_pred: ArrayLike, conformity_scores: ArrayLike<br/>    ) -&gt; NDArray:<br/>        """<br/>        Compute samples of the estimation distribution from the predicted<br/>        values and the conformity scores, from the following formula:<br/>        signed conformity score = (y - y_pred) / y_pred**(1/2)<br/>        &lt;=&gt; y = y_pred + y_pred**(1/2) * signed conformity score<br/><br/>        ``conformity_scores`` can be either the conformity scores or<br/>        the quantile of the conformity scores.<br/>        """<br/>        self._check_predicted_data(y_pred)<br/>        return np.add(y_pred, np.multiply(np.power(y_pred, 1 / 2), conformity_scores))</span></pre><pre class="ql qc qd qe bp qf bb bk"><span id="2f2f" class="qg oh fq qd b bg qh qi l qj qk">class TweedieConformityScore(ConformityScore):<br/>    """<br/>    Tweedie conformity score.<br/><br/>    The signed conformity score = (y - y_pred) / y_pred**(p/2).<br/>    The conformity score is not symmetrical.<br/>    y must be positive<br/>    y_pred must be strictly positive<br/><br/>    This is appropriate when the confidence interval is not symmetrical and<br/>    its range depends on the predicted values.<br/>    """<br/><br/>    def __init__(self, p) -&gt; None:<br/>        self.p = p<br/>        super().__init__(sym=False, consistency_check=False, eps=EPSILON)<br/><br/>    def _check_observed_data(<br/>        self,<br/>        y: ArrayLike,<br/>    ) -&gt; None:<br/>        if not self._all_positive(y):<br/>            raise ValueError(<br/>                f"At least one of the observed target is strictly negative "<br/>                f"which is incompatible with {self.__class__.__name__}. "<br/>                "All values must be positive."<br/>            )<br/><br/>    def _check_predicted_data(<br/>        self,<br/>        y_pred: ArrayLike,<br/>    ) -&gt; None:<br/>        if not self._all_strictly_positive(y_pred):<br/>            raise ValueError(<br/>                f"At least one of the predicted target is negative "<br/>                f"which is incompatible with {self.__class__.__name__}. "<br/>                "All values must be strictly positive."<br/>            )<br/><br/>    @staticmethod<br/>    def _all_positive(<br/>        y: ArrayLike,<br/>    ) -&gt; bool:<br/>        return np.all(np.greater_equal(y, 0))<br/><br/>    @staticmethod<br/>    def _all_strictly_positive(<br/>        y: ArrayLike,<br/>    ) -&gt; bool:<br/>        return np.all(np.greater(y, 0))<br/><br/>    def get_signed_conformity_scores(<br/>        self,<br/>        X: ArrayLike,<br/>        y: ArrayLike,<br/>        y_pred: ArrayLike,<br/>    ) -&gt; NDArray:<br/>        """<br/>        Compute the signed conformity scores from the observed values<br/>        and the predicted ones, from the following formula:<br/>        signed conformity score = (y - y_pred) / y_pred**(1/2)<br/>        """<br/>        self._check_observed_data(y)<br/>        self._check_predicted_data(y_pred)<br/>        return np.divide(np.subtract(y, y_pred), np.power(y_pred, self.p / 2))<br/><br/>    def get_estimation_distribution(<br/>        self, X: ArrayLike, y_pred: ArrayLike, conformity_scores: ArrayLike<br/>    ) -&gt; NDArray:<br/>        """<br/>        Compute samples of the estimation distribution from the predicted<br/>        values and the conformity scores, from the following formula:<br/>        signed conformity score = (y - y_pred) / y_pred**(1/2)<br/>        &lt;=&gt; y = y_pred + y_pred**(1/2) * signed conformity score<br/><br/>        ``conformity_scores`` can be either the conformity scores or<br/>        the quantile of the conformity scores.<br/>        """<br/>        self._check_predicted_data(y_pred)<br/>        return np.add(<br/>            y_pred, np.multiply(np.power(y_pred, self.p / 2), conformity_scores)<br/>        )</span></pre><p id="6c6e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">I have then taken the same example as previously. In addition to the default non conformity scores, that I named <em class="qb">AbsoluteConformityScore</em> in my plot, I have also considered these two additional non conformity scores.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qm"><img src="../Images/e4221fa85633ecfec2a22305d8c4bb59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rb0CY2pruSsrkTMhu3HEfA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by author</figcaption></figure><p id="1470" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As we can see, the global coverages are all close to the chosen one, 95%. I think the small variations are due to luck during the random split between the training set and test one. However, the prediction interval widths differ significantly from an approach to another, as well as the local coverages. Once again, I am not a real estate expert, but I think the prediction intervals are more realistic for the last non conformity score (3rd column in the figure). For the new two non conformity scores, the prediction intervals are quite narrow (with a good coverage, even if slightly below 95%) for cheap houses and they are quite wide for expensive houses. This is necessary to (almost) reach the chosen coverage (95%). <strong class="nd fr">Our new prediction intervals from the <em class="qb">TweedieConformityScore </em>non conformity socre have good local coverages over the entire range of prices and are more insightful since prediction intervals are not unnecessarily wide.</strong></p><h1 id="9ff3" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Conclusion</h1><p id="72ed" class="pw-post-body-paragraph nb nc fq nd b go pc nf ng gr pd ni nj nk pe nm nn no pf nq nr ns pg nu nv nw fj bk">Prediction intervals may be useful to make well informed decisions. Conformal prediction is a tool, among others, to build predictions intervals with theoretical coverage guarantee and only a weak assumption (data exchangeability). When considering the commonly used non conformity score, even though the global coverage is the desired one, local coverages may significantly differ from the chosen one, depending on the use case. This is why I finally considered other non conformity scores, adapted to the considered use case. I showed how to implement it in the conformal prediction library MAPIE and the benefits of doing so. An appropriate non conformity score helps to get more insightful prediction intervals (with good local coverages over the range of target values).</p><h1 id="a35c" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">References</h1><div class="qn qo qp qq qr qs"><a href="https://en.wikipedia.org/wiki/Confidence_interval?source=post_page-----b4fb28d2a4f7--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qt ab ig"><div class="qu ab co cb qv qw"><h2 class="bf fr hw z io qx iq ir qy it iv fp bk">Confidence interval - Wikipedia</h2><div class="qz l"><h3 class="bf b hw z io qx iq ir qy it iv dx">In frequentist statistics, a confidence interval ( CI) is a range of estimates for an unknown parameter. A confidence…</h3></div><div class="ra l"><p class="bf b dy z io qx iq ir qy it iv dx">en.wikipedia.org</p></div></div><div class="rb l"><div class="rc l rd re rf rb rg lq qs"/></div></div></a></div><div class="qn qo qp qq qr qs"><a href="https://en.wikipedia.org/wiki/Prediction_interval?source=post_page-----b4fb28d2a4f7--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qt ab ig"><div class="qu ab co cb qv qw"><h2 class="bf fr hw z io qx iq ir qy it iv fp bk">Prediction interval - Wikipedia</h2><div class="qz l"><h3 class="bf b hw z io qx iq ir qy it iv dx">In statistical inference, specifically predictive inference, a prediction interval is an estimate of an interval in…</h3></div><div class="ra l"><p class="bf b dy z io qx iq ir qy it iv dx">en.wikipedia.org</p></div></div><div class="rb l"><div class="rh l rd re rf rb rg lq qs"/></div></div></a></div><div class="qn qo qp qq qr qs"><a href="https://medium.com/@heinrichpeters/prediction-intervals-in-machine-learning-a2faa36b320c?source=post_page-----b4fb28d2a4f7--------------------------------" rel="noopener follow" target="_blank"><div class="qt ab ig"><div class="qu ab co cb qv qw"><h2 class="bf fr hw z io qx iq ir qy it iv fp bk">Prediction Intervals in Machine Learning</h2><div class="qz l"><h3 class="bf b hw z io qx iq ir qy it iv dx">Machine learning models are powerful tools — but how can we quantify the uncertainty that is associated with their…</h3></div><div class="ra l"><p class="bf b dy z io qx iq ir qy it iv dx">medium.com</p></div></div><div class="rb l"><div class="ri l rd re rf rb rg lq qs"/></div></div></a></div><div class="qn qo qp qq qr qs"><a href="https://en.wikipedia.org/wiki/Conformal_prediction?source=post_page-----b4fb28d2a4f7--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qt ab ig"><div class="qu ab co cb qv qw"><h2 class="bf fr hw z io qx iq ir qy it iv fp bk">Conformal prediction - Wikipedia</h2><div class="qz l"><h3 class="bf b hw z io qx iq ir qy it iv dx">Conformal prediction (CP) is a machine learning framework for uncertainty quantification that can produce prediction…</h3></div><div class="ra l"><p class="bf b dy z io qx iq ir qy it iv dx">en.wikipedia.org</p></div></div><div class="rb l"><div class="rj l rd re rf rb rg lq qs"/></div></div></a></div><div class="qn qo qp qq qr qs"><a href="https://www.openml.org/search?type=data&amp;sort=runs&amp;id=42165&amp;status=active&amp;source=post_page-----b4fb28d2a4f7--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qt ab ig"><div class="qu ab co cb qv qw"><h2 class="bf fr hw z io qx iq ir qy it iv fp bk">OpenML</h2><div class="qz l"><h3 class="bf b hw z io qx iq ir qy it iv dx">OpenML is an open platform for sharing datasets, algorithms, and experiments - to learn how to learn better, together.</h3></div><div class="ra l"><p class="bf b dy z io qx iq ir qy it iv dx">www.openml.org</p></div></div></div></a></div><div class="qn qo qp qq qr qs"><a href="https://github.com/scikit-learn-contrib/MAPIE?source=post_page-----b4fb28d2a4f7--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qt ab ig"><div class="qu ab co cb qv qw"><h2 class="bf fr hw z io qx iq ir qy it iv fp bk">GitHub - scikit-learn-contrib/MAPIE: A scikit-learn-compatible module for estimating prediction…</h2><div class="qz l"><h3 class="bf b hw z io qx iq ir qy it iv dx">A scikit-learn-compatible module for estimating prediction intervals. - GitHub - scikit-learn-contrib/MAPIE: A…</h3></div><div class="ra l"><p class="bf b dy z io qx iq ir qy it iv dx">github.com</p></div></div><div class="rb l"><div class="rk l rd re rf rb rg lq qs"/></div></div></a></div><figure class="ml mm mn mo mp mq"><div class="rl io l ed"><div class="rm rn l"/></div></figure></div></div></div></div>    
</body>
</html>