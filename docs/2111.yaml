- en: 'Causal Machine Learning for Customer Retention: a Practical Guide with Python'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/causal-machine-learning-for-customer-retention-a-practical-guide-with-python-6bd959b25741?source=collection_archive---------1-----------------------#2024-08-30](https://towardsdatascience.com/causal-machine-learning-for-customer-retention-a-practical-guide-with-python-6bd959b25741?source=collection_archive---------1-----------------------#2024-08-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/4444080567c58b7b2c0d88100cc89dd9.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Claudio Schwarz](https://unsplash.com/@purzlbaum?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: An accessible guide to leveraging causal machine learning for optimizing client
    retention strategies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)[![Arthur
    Cruiziat](../Images/32ae05f184523057a5a2e81184f9bc67.png)](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)
    [Arthur Cruiziat](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)
    ·20 min read·Aug 30, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Details of this series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This article is the second in a series on uplift modeling and causal machine
    learning. The idea is to dive deep into these methodologies both from a business
    and a technical perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Before jumping into this one, I highly recommend reading the previous episode
    which explains what uplift modeling is and how it can help your company in general.
  prefs: []
  type: TYPE_NORMAL
- en: Link can be found below.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/from-insights-to-impact-leveraging-data-science-to-maximize-customer-value-9c9af354e192?source=post_page-----6bd959b25741--------------------------------)
    [## From insights to impact: leveraging data science to maximize customer value'
  prefs: []
  type: TYPE_NORMAL
- en: 'Uplift modeling: how causal machine learning transforms customer relationships
    and revenue'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/from-insights-to-impact-leveraging-data-science-to-maximize-customer-value-9c9af354e192?source=post_page-----6bd959b25741--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Picture this: you’ve been a client of a bank for a couple years. However, for
    a month or two, you’ve been considering leaving because their application has
    become too complicated. Suddenly, an employee of the bank calls you. He asks about
    your experience and ends up quickly explaining to you how to use the app. In the
    meantime, your daughter, who’s a client of the same bank also thinks about leaving
    them because of their trading fees; she thinks they’re too expensive. While about
    to unsubscribe, out of the blue, she receives a voucher allowing her to trade
    for free for a month! How is that even possible?'
  prefs: []
  type: TYPE_NORMAL
- en: 'In my previous article, I introduced the mysterious technique behind this level
    of personalisation: uplift modeling. When traditional approaches usually predict
    an outcome — e.g. the probability of churn of a customer— , uplift modeling predicts
    the potential result of an action taken on a customer. The likelihood of a customer
    staying if called or if offered a voucher, for example!'
  prefs: []
  type: TYPE_NORMAL
- en: This approach allows us to target the right customers — as we’ll be removing
    customers who wouldn’t react positively to our approach — but also to increase
    our chance of success by tailoring our approach to each customer. Thanks to uplift
    modeling, not only do we focus our resources toward the right population, we also
    maximise their impact!
  prefs: []
  type: TYPE_NORMAL
- en: 'Sounds interesting, wouldn’t you agree? Well this is your lucky day as in this
    article we’ll dive deep into the implementation of this approach by solving a
    concrete example: improving our retention. We’ll go through every step, from defining
    our precise use case to evaluating our models results. Our goal today is to provide
    you with the right knowledge and tools to be able to apply this technique within
    your own organisation, adapted to your own data and use case, of course.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what we’ll cover:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ll start by **clearly defining our use case.** What is churn? Who do we target?
    What actions will we set up to try and retain our clients with?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, **we’ll look into getting the right data for the job.** What data do we
    need to implement uplift modeling and how to get it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After that, we’ll look into the actual modeling,focusing on u**nderstanding
    the various models behind uplift modeling**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, we’ll apply our newly acquired knowledge to a **first case with a single
    retention action: an email campaign.**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we’ll deep dive into a **more complicated implementation with** **many
    treatments, approaching user-level personalisation**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Our use case: improving customer retention'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can apply uplift modeling to improve customer retention, we need to
    clearly define the context. What constitutes “churn” in our business context?
    Do we want to target specific users? If yes, why? Which actions do we plan on
    setting up to retain them? Do we have budget constraints? Let’s try answering
    these questions.
  prefs: []
  type: TYPE_NORMAL
- en: Defining Churn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is our first step. By precisely and quantitatively defining churn, we’ll
    be able to define retention and understand where we stand, how it has evolved
    and, if needed, take action. The churn definition you’ll choose will 100% depend
    on your business model and sector. Here are some factors to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: If you’re in a transaction-based company, you can look at transaction frequency,
    or transaction volumes evolution. You could also look at the time since the last
    transaction occured or a drop in account activity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you’re in a subscription based company, it can be as simple as looking at
    users who have unsubscribed, or subscribed users who have stopped using the product.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you’re working in a transaction based tech company, churn could be defined
    as “*customer who has not done a transaction in 90 days”*, whereas if you’re working
    for a mobile app you may prefer to define it as *“customer who has not logged
    in in 30 days*”. Both the time frame and the nature of churn has to be defined
    beforehand as flagging churned user will be our first step.
  prefs: []
  type: TYPE_NORMAL
- en: The complexity of your definition will depend on your company’s specificities
    as well as the number of metrics you want to consider. However, the idea is to
    set up definitions that provide thresholds that are easy to understand and that
    enable us identify churners.
  prefs: []
  type: TYPE_NORMAL
- en: Churn Prediction Window
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we know what churn is, we need to define exactly what we want to avoid.
    What I mean is, do we want to prevent customers from churning within the next
    15 days or 30 days? Based on the answer here, you’ll have to organise your data
    in a specific manner, and define different retention actions. I would recommend
    not to be too optimistic here for 2 reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: The longer the time horizon the harder it is for a model to have good performances.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The longer we wait after the treatment, the harder it will be to capture its
    effect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So let’s be reasonable here. If our definition of churn encompasses a 30-day
    timeframe, let’s go with a 30 days horizon and let’s try to limit churn within
    the next 30 days.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is that our timeframe must give us enough time to implement our retention
    strategies and observe their impact on user behavior, while maintaining our models’
    performances.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Selecting Target Users [Optional]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another question we need to answer is: are we targeting a specific population
    with our retention actions? Multiple reasons could motivate such an idea.'
  prefs: []
  type: TYPE_NORMAL
- en: We noticed an increase in churn in a specific segment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to target highly valuable customers to maximize our ROI with those actions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to target new customers to ensure a durable activation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to target customers that are likely to churn soon.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on your own use case, you may want to select only a subset of your
    customers.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we’ll choose to target clients with a higher probability of churn,
    so that we target customers that need us most.
  prefs: []
  type: TYPE_NORMAL
- en: Defining retention Actions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we have to select the actual retention actions we want to use on our
    clients. This is not an easy one, and working alongside your business stakeholders
    here is probably a good idea. In our case, we’ll select 4 different actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Personalized email
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In-app notifications highlighting new features or opportunities
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Directly calling our customer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Special offers or discounts — *another uplift model could help us identify the
    best voucher amount, should we explore that next?*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our uplift model will help us determine which of these actions (if any) is most
    likely to be effective for each individual user.
  prefs: []
  type: TYPE_NORMAL
- en: We’re ready! We defined churn, picked a prediction window, and selected the
    actions we want to retain our customers with. Now, the fun part begins, let’s
    gather some data and build a causal machine learning model!
  prefs: []
  type: TYPE_NORMAL
- en: 'Data gathering: the foundation of our uplift model'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building an effective uplift model requires a good dataset combining both existing
    user information with experimental data.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging existing user data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let’s look at our available data. Tech companies usually have access
    to a lot of those! In our case, we need customer level data such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer information (like age, geography, gender, acquisition channel etc.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Product specifics (creation or subscription date, subscription tier etc.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Transactions information ( frequency of transactions, average transaction value,
    total spend, types of products/services purchased, time since last transaction
    etc.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Engagement (e.g., login frequency, time spent on platform, feature usage statistics,
    etc.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can look at this data raw, but what brings even more value is to understand
    how it evolves over time. It enables us to identify behavioral patterns that will
    likely improve our models’ performances. Lucky for us, it’s quite simple to do,
    we just have to look at our data from a different perspective; here are a few
    transformations that can help:'
  prefs: []
  type: TYPE_NORMAL
- en: Taking moving averages (7, 30 days…) of our main usage metrics — transactions
    for instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at the percentage changes over time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregating our data at different time scales such as daily, weekly etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Or even adding seasonality indicators such as the day of week or week of year.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These features bring “dynamic information” that could be valuable when it comes
    to detect future changes! Understanding more precisely which features we should
    select is beyond the scope of this article, however those approaches are best
    practices when it comes to work with temporal data.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, our goal is to create a comprehensive user profile that evolves over
    time. This temporal data will serve as the foundation of our uplift model, **enabling
    us to predict not who might churn, but who is most likely to respond positively
    to our retention efforts.**
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Gathering Experimental Data for Uplift Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second part of our data gathering journey is about collecting data related
    to our retention actions. Now, uplift modeling does not require experimental data.
    If you have historical data because of past events — you may already have sent
    emails to customers or offered vouchers — you can leverage those. However, the
    more recent and unbiased your data is, the better your results will be. Debiasing
    observational or non randomized data requires extra steps that we will not discuss
    here.
  prefs: []
  type: TYPE_NORMAL
- en: So what exactly do we need? Well, we need to have an idea of the impact of the
    actions you plan to take. We need to set up a randomized experiment where we test
    these actions. A lot of extremely good articles already discuss how to set those
    up, and I will not dive into it here. I just want to add that the better the setup,
    and the bigger the training set, the better it is us!
  prefs: []
  type: TYPE_NORMAL
- en: After the experiment, we’ll obviously analyse the results. And while those are
    not helping us directly in our quest, it will provide us with additional understanding
    of the expected impact of our treatments as well as a good effect baseline we’ll
    try to outperform with our models. Not to bore you too much with definitions and
    acronyms, but the result of a randomized experiment is called “Average treatment
    effect” or ATE. On our side, we’re looking to estimate the **Conditional Average
    Treatment Effect** (CATE), also known as **Individual Treatment Effect** (ITE).
  prefs: []
  type: TYPE_NORMAL
- en: '*While experimental data is ideal, uplift modeling can still provide insights
    with observational data if an experiment isn’t feasible. If not randomized, several
    techniques exists to debias our dataset, such as propensity score matching. The
    key is to have a rich dataset that captures user characteristics, behaviors, and
    outcomes in relation to our retention efforts.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Generating synthetic data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the purpose of this example, we’ll be generating synthetic data using the
    **causalml package from Uber**. Uber has communicated a lot on uplift modeling
    and even created an easy to use and well documented Python package.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s how we can generate our synthetic data if you’re curious about it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Ouf final data should be organized like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8940c6f65a748c68ab51d0be26a39b51.png)'
  prefs: []
  type: TYPE_IMG
- en: dataset description
  prefs: []
  type: TYPE_NORMAL
- en: In a “real life use case”, this data would be aggregated at time level, for
    instance this would be for each user a daily or weekly aggregation of data gathered
    before we reached out to them.
  prefs: []
  type: TYPE_NORMAL
- en: X_1 to X_n would be our user level features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: T would be the actual treatment (1 or 0, treatment or control, treatment 1,
    treatment 2, control depending on your use case)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And Y is the actual outcome: did the user stay or not?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our case, in order to analyse both our use cases, we need further preparation.
    Let’s create 2 distinct datasets — training and a testing set — for each use case:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First use case: a single treatment case, where we’ll focus on a single retention
    strategy: sending email to our customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Second use case: a multi treatment case, where we’ll compare the effectiveness
    of different treatments and most importantly find the best one for each customer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now that our data is ready, let’s go through a bit of theory and investigate
    the different approaches available to us!
  prefs: []
  type: TYPE_NORMAL
- en: Understanding uplift modeling approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we now know, uplift modeling uses machine learning algorithms to estimate
    th**e heterogeneous treatment effect** of an intervention on a population. This
    modelling approach focuses on the **Conditional Average Treatment Effect** (CATE),
    which quantifies the expected difference in outcome with and without the intervention
    for our customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the main models we can use to estimate it:'
  prefs: []
  type: TYPE_NORMAL
- en: Direct uplift modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This approach is the simplest one. We simply use a specific algorithm, such
    as an uplift decision tree, which loss function is optimized to solve this problem.
    **These models are designed to maximize the difference in outcomes between treated
    and untreated groups within the same model.**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll be using an **Uplift Random ForestClassifier** as an example of this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meta-learners
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Meta-learners use known machine learning models to estimate the CATE. They can
    combine multiple models used in different ways, or be trained on the predictions
    of other models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While many exist, we’ll focus on two types : the **S-Learner and the T-Learner**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s quickly understand what those are!
  prefs: []
  type: TYPE_NORMAL
- en: 1\. S-Learner (Single-Model)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/408c1ab77023700f4a98eab8514625c4.png)'
  prefs: []
  type: TYPE_IMG
- en: S Learner — source causalml documentation
  prefs: []
  type: TYPE_NORMAL
- en: The S-Learner is the simplest meta-learner of all. Why? Because it only consists
    of using a traditional machine learning model that includes the treatment feature
    as input. While simple to implement, it may struggle if the importance of the
    treatment variable is low.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. T-Learner (Two-Model)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/ec3f45f29794d0b392b3229a0d4e9a68.png)'
  prefs: []
  type: TYPE_IMG
- en: “The T-Learner tries to solve the problem of discarding the treatment entirely
    by forcing the learner to first split on it. Instead of using a single model,
    we will use one model per treatment variable.
  prefs: []
  type: TYPE_NORMAL
- en: In the binary case, there are only two models that we need to estimate (hence
    the name T)” *Source [3]*
  prefs: []
  type: TYPE_NORMAL
- en: '*Each of these approaches has its pros and cons. How well they work will depend
    on your data and what you’re trying to achieve.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this article we’ll try out all three: an Uplift Random Forest Classifier,
    a S-Learner, and a T-Learner, and compare their performances when it comes to
    improving our company’s retention.'
  prefs: []
  type: TYPE_NORMAL
- en: Single treatment uplift model implementation with causal ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Model Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let’s train our models. We’ll start with our direct uplift model, the uplift
    random forest classifier. Then we’ll train our meta models using an XGBoost regressor.
    Two things to note here:'
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm choice behind your meta-models will obviously impact the final
    model performances, thus you may want to select it carefully.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yes, we’re selecting regressors as meta models rather than classifiers, mainly
    because they provide more flexibility, outputting a precise effect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are the different steps you’ll find in the below code:'
  prefs: []
  type: TYPE_NORMAL
- en: We initialize our result dataframe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we train each model on our training set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally we predict our treatment effects on the test sets before saving the
    results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that we’re still using causalml here, and that the API is extremely simple
    to use, very close to a sklearn-like implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How to evaluate and compare our models’ performances? That is a great question!
    As we’re predicting something we do not know — *we don’t know the effect of our
    treatment on our customers as each customer either received the treatment or was
    in the control group*. **We cannot use classic evaluation metrics.** Hopefully,
    there are other ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Gain curve**: The gain curve offers an easy way to visualise our model’s
    performance. The idea behind gain is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: We compute the estimated effect of each of our customers, order them from the
    biggest effect to the lesser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From here, we move point by point. At each point, we calculate the average treatment
    effect meaning, both the average effect — for control and treatment — and we take
    the difference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We do that for both our models ordering and a random ordering, simulating random
    selection, and compare both curves!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It helps us understand which improvement our model would have brought versus
    a random selection.
  prefs: []
  type: TYPE_NORMAL
- en: '**The AAUC score**: the AAUC score is very close to the actual gain curve as
    it measures the Area under the curve of the gain curve of our model, enabling
    us to compare it with the one of the random model. It summarizes the gain curve
    in an easy to compare number.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following code, we calculate these metrics
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here are the results we got. Higher scores are better of course.
  prefs: []
  type: TYPE_NORMAL
- en: 'T-Learner: ~6.4 (best performer)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'S-Learner: ~6.3 (very close second)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Random Forest: ~5.7 (good, but not as good as the others)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Random targeting: ~0.5 (baseline)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What do these results mean?
  prefs: []
  type: TYPE_NORMAL
- en: Well, all our models are performing way better than random targeting. This is
    reassuring. They’re about 12 times more effective! We’ll understand what it means
    in terms of impact just after.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also understand from these AAUC score that, while all models are performing
    quite well, the T-Leaner is the best performer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s take a look at the gain curve.
  prefs: []
  type: TYPE_NORMAL
- en: Gain Curve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How to read a gain curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '**X-Axis (Population)**: This represents the size of the population you’re
    targeting, starting from the most responsive individuals (on the left) to the
    least responsive (on the right).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Y-Axis (Gain)**: This shows the cumulative gain, which is the improvement
    in your outcome (e.g., increased retention).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/a3e9e18fe560758b686e9a4cca91aded.png)'
  prefs: []
  type: TYPE_IMG
- en: Gain curve Interpretation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The gain curve shows us the benefit — in our initial unit hence “people retained”
    — of targeting the population using our uplif model or randomly targeting.
  prefs: []
  type: TYPE_NORMAL
- en: In that case it seems that if we reach out to the whole population with our
    emails, we would retain approximately 100 additional users. This is our baseline
    scenario. Note that every curve ends by this result which is expected considering
    our gain definition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So how to interpret this? Well, looking at the curve we can say that using our
    model, **by reaching out to only 50% of the population, we can save 600 additional
    users!** Six times more than by reaching out to everyone. How is that possible?
    By targeting only users that are likely to react positively to our outreach, while
    ignoring those who would leverage this email to actually churn for instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*It is time for a small disclaimer: we’re using synthetic data here, our results
    are extremely unlikely in the real world, but it is good to illustrate.*'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, our models enable us to do more with less. This is a good example
    on how we can optimize our resources using uplift modeling and targeting a lower
    share of the population, hence limiting the operation costs, to obtain a good
    share of the results. A kind of Pareto effect if you’d like.
  prefs: []
  type: TYPE_NORMAL
- en: 'But let’s head over to the really cool stuff : how can we personalize our approach
    to every customer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Multi treatment model: let’s move to Personalization'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s now restart our analysis, considering all our retention strategies described
    above:'
  prefs: []
  type: TYPE_NORMAL
- en: Email campaign
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call campaign
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In-app notification
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vouchers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In order to achieve this, we need experimentation results of either a multi-treatment
    experimentation of all those actions, or to aggregate the results of multiple
    experimentation. the better the experimental data, the better predictive output
    we’ll get. However, setting up such experiments can take time and resources.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use our previously generated data, keeping in mind that obtaining this
    data in the first place is probably the biggest challenge of this approach!
  prefs: []
  type: TYPE_NORMAL
- en: Model Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by training our models. We’ll keep the same model type as before,
    a Random Forest, S-Learner, and T-Learner.
  prefs: []
  type: TYPE_NORMAL
- en: However, these models will now learn to differentiate between the effects of
    our four distinct treatments.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Predictions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that our models are trained, let’s generate our predictions for each treatment.
    For each user, we’ll get the uplift of each treatment. This will enable us to
    choose the most effective treatment by user, if any treatment has a positive uplift.
    Otherwise, we just won’t reach out to this person!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the kind of data we’ll obtain from this, for each model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fd2ce4069ee2507a9add63ae305b450a.png)'
  prefs: []
  type: TYPE_IMG
- en: We’ll be able, for each model, to pick the best treatment for each user!
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let’s look at our approach evaluation. As we have multiple treatments,
    it is slightly different:'
  prefs: []
  type: TYPE_NORMAL
- en: For each user we select the best treatment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we order our user based on their best treatment effect
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And look at what really happened : either the user really stayed or left.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Following this rationale, we easily understand how we can outperform random
    targeting by only targeting a small share of our whole population.
  prefs: []
  type: TYPE_NORMAL
- en: From here, we’re able to plot our gain curve and compute our AAUC. Easy right?
    The code below does exactly that, still leveraging causalML.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Results interpretation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'T-Learner: ~1.45 (best performer)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'S-Learner: ~1.42 (very close second)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Random Forest: ~1.20 (good, but not as good as the others)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Random targeting: ~0.52 (baseline)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'What this means:'
  prefs: []
  type: TYPE_NORMAL
- en: Once again, all our models outperform random targeting, and once again the T-Learner
    is the best performer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However we note that the difference is lower than in our first case. Different
    reasons could explain that, one being the actual set-up. We’re considering a bigger
    population here, which we did not consider in our first experiment. It also could
    mean that our models do not perform as well when it comes to multi-treatment and
    we would need to iterate and try to improve their performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But let’s look at our gain curve to understand better our performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eefc212c1cd99fe14ac130ba467534db.png)'
  prefs: []
  type: TYPE_IMG
- en: Interpretation of the Multi-Treatment Gain Curve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we can see, if we were to target 100% of our population — 30,000 users —
    we would retain an additional 850 users (approximately)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: however, using our models, we are able to retain 1,600 users while only contacting
    33% of the total population
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we notice that past 40% of the population all curves start to decrease
    indicating that there is no value contacting those customers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We made it. We successfully built a model that enables us to personalize effectively
    our retention actions to maximize our ROI. Based on this model, our company decided
    to put this model to production and saved millions not wasting resources reaching
    out to everyone, but also focusing the right type of effort on the right customer!
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting such a model to production is another challenge in itself because we
    need to ensure its performance in the long term, and keep retraining it when possible.
    The framework to do that would be to:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate inference with your model on 80% of your target population
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keep 10% of your target population intact : Control'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep an additional 10% of your population to keep experimenting to train your
    model for the next time period (month/quarter/year depending on your capabilities)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We might look into this later on!
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you made it this far, thank you! I hope this was interesting and that you
    learned how to create an uplift model and how to evaluate its performance.
  prefs: []
  type: TYPE_NORMAL
- en: If I did a good job, you may now know that uplift models are an incredible tool
    to understand and that it can lead to great, direct and measurable impact. You
    also may have understood that uplift models enable us to target the right population
    with the right treatment, but require a strong and exploitable experimental data
    to be trained on. Getting this data up to date is often the big challenge of such
    projects. It is applicable on historical/observational data, one would need to
    add specific cleaning and treating steps to ensure that the data is unbiased.
  prefs: []
  type: TYPE_NORMAL
- en: So what’s next? While we’re deep-diving in the world of causal machine learning,
    I want to make sure you are heard. So if you want to look into specific topics
    that you think you could apply in your own company and would like to learn more
    about it, let me know, I’ll do my best. Let’s keep all learning from each other!
    Until next time, happy modeling!
  prefs: []
  type: TYPE_NORMAL
- en: Source
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Unless otherwise noted, all images are by the author*'
  prefs: []
  type: TYPE_NORMAL
- en: '[1] [https://en.wikipedia.org/wiki/Uplift_modelling](https://en.wikipedia.org/wiki/Uplift_modelling)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [https://causalml.readthedocs.io/en/latest/index.html](https://causalml.readthedocs.io/en/latest/index.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [https://matheusfacure.github.io/python-causality-handbook/landing-page.html](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)'
  prefs: []
  type: TYPE_NORMAL
