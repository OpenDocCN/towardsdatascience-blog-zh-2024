- en: Efficient Large Dimensional Self-Organising Maps with PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/efficient-large-dimensional-self-organising-maps-with-pytorch-8f5c2b4c66e2?source=collection_archive---------4-----------------------#2024-12-13](https://towardsdatascience.com/efficient-large-dimensional-self-organising-maps-with-pytorch-8f5c2b4c66e2?source=collection_archive---------4-----------------------#2024-12-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Because it’s fun to self-organise
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mathieu.daquin.x?source=post_page---byline--8f5c2b4c66e2--------------------------------)[![Mathieu
    d''Aquin](../Images/b91a2457db6910010311758d21e2794a.png)](https://medium.com/@mathieu.daquin.x?source=post_page---byline--8f5c2b4c66e2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8f5c2b4c66e2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8f5c2b4c66e2--------------------------------)
    [Mathieu d''Aquin](https://medium.com/@mathieu.daquin.x?source=post_page---byline--8f5c2b4c66e2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8f5c2b4c66e2--------------------------------)
    ·5 min read·Dec 13, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[Self-organising maps](https://en.wikipedia.org/wiki/Self-organizing_map) (or
    Kohonen maps) are an interesting kind of neural networks: they don’t follow the
    same kind of architecture and are definitely trained differently from the usual
    [backpropagation](https://en.wikipedia.org/wiki/Backpropagation) methods. There
    is a good reason for this: they are meant to be used for [unsupervised learning](https://en.wikipedia.org/wiki/Unsupervised_learning).
    They are to the usual multi-layer neural networks what K-Means is to SVM. They
    create clusters; they discretise the data space. But they have one thing that
    makes them different from other clustering methods: The clusters that they create
    form a map of the data (a grid of clusters) where the distance between clusters
    in that map represents the distance that exists between the average members of
    those clusters in the data space.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because they are slightly atypical, there has not been as much work done on
    creating efficient implementations of self-organising maps (SOMs) as for other
    forms of neural networks, in particular with respect to enabling them to handle
    highly dimensional data on GPUs (i.e., they are typically used on data with not
    more than a few dozen features). Too bad, since that is exactly what I needed
    for a [project](https://arxiv.org/abs/2312.05864): fast SOM training on data with
    thousands of features. I had tried existing libraries, including those based on
    PyTorch, and was not quite satisfied, so I made my own: [ksom](https://pypi.org/project/ksom/)
    (admittedly also because it is fun to do, especially as a way to get better at
    using PyTorch).'
  prefs: []
  type: TYPE_NORMAL
