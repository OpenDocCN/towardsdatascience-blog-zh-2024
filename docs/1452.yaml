- en: 'Deep Learning Illustrated, Part 4: Recurrent Neural Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/deep-learning-illustrated-part-4-recurrent-neural-networks-d0121f27bc74?source=collection_archive---------3-----------------------#2024-06-11](https://towardsdatascience.com/deep-learning-illustrated-part-4-recurrent-neural-networks-d0121f27bc74?source=collection_archive---------3-----------------------#2024-06-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An illustrated and intuitive guide on the inner workings of an RNN and the Softmax
    Activation Function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@shreya.rao?source=post_page---byline--d0121f27bc74--------------------------------)[![Shreya
    Rao](../Images/03f13be6f5f67783d32f0798f09a4f86.png)](https://medium.com/@shreya.rao?source=post_page---byline--d0121f27bc74--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d0121f27bc74--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d0121f27bc74--------------------------------)
    [Shreya Rao](https://medium.com/@shreya.rao?source=post_page---byline--d0121f27bc74--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d0121f27bc74--------------------------------)
    ·17 min read·Jun 11, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to Part 4 of our illustrated Deep Learning journey! Today, we’re diving
    into Recurrent Neural Networks. We’ll be talking about concepts that will feel
    familiar, such as inputs, outputs, and activation functions, but with a twist.
    And if this is your first stop on this journey, definitely read the previous articles,
    particularly Parts [1](https://medium.com/towards-data-science/neural-networks-illustrated-part-1-how-does-a-neural-network-work-c3f92ce3b462)
    and [2](https://medium.com/towards-data-science/deep-learning-illustrated-part-2-how-does-a-neural-network-learn-481f70c1b474),
    before this one.
  prefs: []
  type: TYPE_NORMAL
- en: '![Shreya Rao](../Images/45d3d481fab74a720c78346bc47e95fd.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Shreya Rao](https://medium.com/@shreya.rao?source=post_page-----d0121f27bc74--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning, Illustrated
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@shreya.rao/list/deep-learning-illustrated-ae6c27de1640?source=post_page-----d0121f27bc74--------------------------------)5
    stories![](../Images/9668eeb3fd221bb26c2341a0ec0bfeab.png)![](../Images/1c261ce54b80b877b7737964ba5bf3f2.png)![](../Images/10364c8fdf64c9c6fb8300ce74259d00.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent Neural Networks (RNN) are unique models explicitly designed to handle
    **sequence-based problems**, where the next position relies on the previous state.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s unpack what a sequence-based problem is with a simple example from this
    [MIT course](https://www.youtube.com/watch?v=dqoEU9Ac3ek&t=2126s). Picture a ball
    at a specific point in time, tn.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2be63abd09a78f20f6f1c85c251cf444.png)'
  prefs: []
  type: TYPE_IMG
- en: If we’re asked to predict the ball’s direction, without further information,
    it’s a guessing game — it could be moving in any direction.
  prefs: []
  type: TYPE_NORMAL
