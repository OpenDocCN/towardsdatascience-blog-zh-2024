- en: Structured Outputs and How to Use Them
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化输出及其使用方法
- en: 原文：[https://towardsdatascience.com/structured-outputs-and-how-to-use-them-40bd86881d39?source=collection_archive---------3-----------------------#2024-08-09](https://towardsdatascience.com/structured-outputs-and-how-to-use-them-40bd86881d39?source=collection_archive---------3-----------------------#2024-08-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/structured-outputs-and-how-to-use-them-40bd86881d39?source=collection_archive---------3-----------------------#2024-08-09](https://towardsdatascience.com/structured-outputs-and-how-to-use-them-40bd86881d39?source=collection_archive---------3-----------------------#2024-08-09)
- en: Building robustness and determinism in LLM applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在LLM应用中构建鲁棒性和确定性
- en: '[](https://medium.com/@armin.catovic?source=post_page---byline--40bd86881d39--------------------------------)[![Armin
    Catovic](../Images/046042098f3fec885e756f7f8ee94e6a.png)](https://medium.com/@armin.catovic?source=post_page---byline--40bd86881d39--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--40bd86881d39--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--40bd86881d39--------------------------------)
    [Armin Catovic](https://medium.com/@armin.catovic?source=post_page---byline--40bd86881d39--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@armin.catovic?source=post_page---byline--40bd86881d39--------------------------------)[![Armin
    Catovic](../Images/046042098f3fec885e756f7f8ee94e6a.png)](https://medium.com/@armin.catovic?source=post_page---byline--40bd86881d39--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--40bd86881d39--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--40bd86881d39--------------------------------)
    [Armin Catovic](https://medium.com/@armin.catovic?source=post_page---byline--40bd86881d39--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--40bd86881d39--------------------------------)
    ·5 min read·Aug 9, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--40bd86881d39--------------------------------)
    ·阅读时间：5分钟·2024年8月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3c27ad73265f5ca5be36e8041289d13e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c27ad73265f5ca5be36e8041289d13e.png)'
- en: Image by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: OpenAI [recently announced](https://openai.com/index/introducing-structured-outputs-in-the-api/)
    support for **Structured Outputs** in its latest *gpt-4o-2024–08–06* models. Structured
    outputs in relation to large language models (LLMs) are nothing new — developers
    have either used various prompt engineering techniques, or 3rd party tools.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI [最近宣布](https://openai.com/index/introducing-structured-outputs-in-the-api/)支持其最新的**gpt-4o-2024–08–06**模型中的*结构化输出*。对于大型语言模型（LLM）而言，结构化输出并不是什么新鲜事——开发者们通常使用各种提示工程技术，或者第三方工具。
- en: 'In this article we will explain what structured outputs are, how they work,
    and how you can apply them in your own LLM based applications. Although OpenAI’s
    announcement makes it quite easy to implement using their APIs (as we will demonstrate
    here), you may want to instead opt for the open source [Outlines](https://github.com/outlines-dev/outlines)
    package (maintained by the lovely folks over at [dottxt](https://dottxt.co/)),
    since it can be applied to both the self-hosted open-weight models (e.g. Mistral
    and LLaMA), as well as the proprietary APIs (**Disclaimer**: due to [this issue](https://github.com/outlines-dev/outlines/issues/637)
    Outlines does not as of this writing support structured JSON generation via OpenAI
    APIs; but that will change soon!).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将解释什么是结构化输出，它是如何工作的，以及如何在你自己的基于LLM的应用中应用它们。虽然OpenAI的公告使得通过其API实现结构化输出变得相当简单（如我们在此演示的），你可能更倾向于选择开源的[Outlines](https://github.com/outlines-dev/outlines)包（由[dotxt](https://dottxt.co/)的可爱团队维护），因为它既可以应用于自托管的开源模型（如Mistral和LLaMA），也可以应用于专有API。（**免责声明**：由于[这个问题](https://github.com/outlines-dev/outlines/issues/637)，截至本文写作时，Outlines尚不支持通过OpenAI
    API生成结构化JSON；但这一点很快就会有所改变！）
- en: What are Structured Outputs?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是结构化输出？
- en: If [RedPajama dataset](https://www.together.ai/blog/redpajama-data-v2) is any
    indication, the overwhelming majority of pre-training data is human text. Therefore
    “natural language” is the native domain of LLMs — both in the input, as well as
    the output. When we build applications however, we would like to use machine-readable
    formal structures or schemas to encapsulate our data input/output. This way we
    build robustness and determinism into our applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果[RedPajama数据集](https://www.together.ai/blog/redpajama-data-v2)可以作为参考，那么压倒性的预训练数据来自人类文本。因此，“自然语言”是LLM的本土领域——无论是在输入端，还是输出端。然而，当我们构建应用程序时，我们希望使用机器可读的正式结构或模式来封装我们的数据输入/输出。通过这种方式，我们在应用程序中构建了鲁棒性和确定性。
- en: '**Structured Outputs** is a mechanism by which we enforce a pre-defined schema
    on the LLM output. This typically means that we enforce a JSON schema, however
    it is not limited to JSON only — we could in principle enforce XML, Markdown,
    or a completely custom-made schema. The benefits of Structured Outputs are two-fold:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**结构化输出**是一种强制执行预定义模式的机制，作用于LLM的输出。这通常意味着我们强制执行一个JSON模式，然而它不限于JSON—我们原则上可以强制执行XML、Markdown或完全自定义的模式。结构化输出的好处有两个方面：'
- en: '**Simpler prompt design** — we need **not** be overly verbose when specifying
    how the output should look like'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更简单的提示设计**—我们在指定输出的格式时，**不需要**过于冗长。'
- en: '**Deterministic names and types** — we can **guarantee** to obtain for example,
    an attribute `age` with a `Number` [JSON type](https://json-schema.org/) in the
    LLM response'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**确定性的名称和类型**—我们可以**保证**例如在LLM的响应中获得一个具有`Number` [JSON类型](https://json-schema.org/)的`age`属性。'
- en: Implementing a JSON schema
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现一个JSON模式
- en: For this example, we will use the first sentence from [Sam Altman’s Wikipedia
    entry](https://en.wikipedia.org/wiki/Sam_Altman)…
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们将使用[Sam Altman的维基百科条目](https://en.wikipedia.org/wiki/Sam_Altman)中的第一句话…
- en: Samuel Harris Altman (born April 22, 1985) is an American entrepreneur and investor
    best known as the CEO of OpenAI since 2019 (he was briefly fired and reinstated
    in November 2023).
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Samuel Harris Altman（1985年4月22日出生）是美国企业家和投资者，最著名的是自2019年起担任OpenAI的首席执行官（他在2023年11月被短暂解雇并恢复职务）。
- en: '…and we are going to use the latest GPT-4o checkpoint as a named-entity recognition
    (NER) system. We will enforce the following JSON schema:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: …并且我们将使用最新的GPT-4o检查点作为命名实体识别（NER）系统。我们将强制执行以下JSON模式：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In essence, our LLM response should contain a `NamedEntities` object, which
    consists of an array of `entities`, each one containing a `name` and `type`. There
    are a few things to note here. We can for example enforce *Enum* type, which is
    very useful in NER since we can constrain the output to a fixed set of entity
    types. We must specify all the fields in the `required` array: however, we can
    also emulate “optional” fields by setting the type to e.g. `["string", null]`
    .'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，我们的LLM响应应该包含一个`NamedEntities`对象，其中包含一个`entities`数组，每个数组元素都包含一个`name`和`type`。这里有几点需要注意。例如，我们可以强制使用*Enum*类型，这在NER中非常有用，因为我们可以将输出限制为一组固定的实体类型。我们必须在`required`数组中指定所有字段；然而，我们也可以通过将类型设置为例如`["string",
    null]`来模拟“可选”字段。
- en: We can now pass our schema, together with the data and the instructions to the
    API. We need to populate the `response_format` argument with a *dict* where we
    set `type` to `"json_schema”` and then supply the corresponding schema.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将我们的模式、数据和指令传递给API。我们需要用*dict*填充`response_format`参数，在其中将`type`设置为`"json_schema"`，然后提供相应的模式。
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output should look something like this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该看起来像这样：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The full source code used in this article is available [here](https://github.com/acatovic/structured-outputs-demo).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的完整源代码可以在[这里](https://github.com/acatovic/structured-outputs-demo)找到。
- en: How it works
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: The magic is in the combination of **constrained sampling**, and **context free
    grammar (CFG)**. We mentioned previously that the overwhelming majority of pre-training
    data is “natural language”. Statistically this means that for every decoding/sampling
    step, there is a non-negligible probability of sampling some arbitrary token from
    the learned vocabulary (and in modern LLMs, vocabularies typically stretch across
    40 000+ tokens). However, when dealing with formal schemas, we would really like
    to rapidly eliminate all improbable tokens.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 魔力在于**约束采样**和**无上下文语法（CFG）**的结合。我们之前提到过，大多数预训练数据是“自然语言”。从统计学角度来看，这意味着在每一个解码/采样步骤中，从已学习的词汇表中采样某个任意令牌的概率是不可忽略的（在现代LLM中，词汇表通常包含超过40,000个令牌）。然而，在处理正式模式时，我们确实希望快速排除所有不太可能的令牌。
- en: In the previous example, if we have already generated…
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，如果我们已经生成了…
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: …then ideally we would like to place a very high logit bias on the `'typ` token
    in the next decoding step, and very low probability on all the other tokens in
    the vocabulary.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: …那么理想情况下，我们希望在下一步解码时对`'typ`令牌施加一个非常高的logit偏置，并对词汇表中的所有其他令牌施加非常低的概率。
- en: This is in essence what happens. When we supply the schema, it gets converted
    into a formal grammar, or CFG, which serves to guide the logit bias values during
    the decoding step. CFG is one of those old-school computer science and natural
    language processing (NLP) mechanisms that is making a comeback. A very nice introduction
    to CFG was actually presented in [this StackOverflow answer](https://stackoverflow.com/questions/6713240/what-is-a-context-free-grammar/6713333#6713333),
    but essentially it is a way of describing transformation rules for a collection
    of symbols.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，发生的就是这个过程。当我们提供模式时，它会被转换成一种形式化的文法，或称上下文无关文法（CFG），该文法在解码步骤中用于引导logit偏置值。CFG是一种经典的计算机科学和自然语言处理（NLP）机制，现在正重新崛起。实际上，[这个StackOverflow回答](https://stackoverflow.com/questions/6713240/what-is-a-context-free-grammar/6713333#6713333)对CFG做了一个非常好的介绍，但本质上，它是一种描述符号集合转换规则的方式。
- en: Conclusion
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Structured Outputs are nothing new, but are certainly becoming top-of-mind with
    proprietary APIs and LLM services. They provide a bridge between the erratic and
    unpredictable “natural language” domain of LLMs, and the deterministic and structured
    domain of software engineering. Structured Outputs are essentially a **must**
    for anyone designing complex LLM applications where LLM outputs must be shared
    or “presented” in various components. While API-native support has finally arrived,
    builders should also consider using libraries such as Outlines, as they provide
    a LLM/API-agnostic way of dealing with structured output.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化输出并不是什么新鲜事物，但随着专有API和大型语言模型（LLM）服务的发展，它们无疑已成为关注的重点。结构化输出在LLM的“不稳定”和“不可预测”的“自然语言”领域与软件工程的确定性和结构化领域之间架起了一座桥梁。对于任何设计复杂LLM应用程序的人来说，结构化输出本质上是**必须的**，尤其是在LLM输出必须以各种组件共享或“展示”的情况下。尽管API本地支持终于到来，但构建者仍应考虑使用如Outlines等库，因为它们提供了一种与LLM/API无关的方式来处理结构化输出。
