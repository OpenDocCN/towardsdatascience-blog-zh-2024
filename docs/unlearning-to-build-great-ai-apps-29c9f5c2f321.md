# 摆脱旧思维，构建优秀的AI应用

> 原文：[https://towardsdatascience.com/unlearning-to-build-great-ai-apps-29c9f5c2f321?source=collection_archive---------4-----------------------#2024-01-08](https://towardsdatascience.com/unlearning-to-build-great-ai-apps-29c9f5c2f321?source=collection_archive---------4-----------------------#2024-01-08)

## 从经典机器学习到适应（或抛弃）生成式AI世界的产品策略

[](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)[![Sam Stone](../Images/c241f50c3904ef8ee56c826f813fa8e1.png)](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------) [Sam Stone](https://medium.com/@sjstone1987?source=post_page---byline--29c9f5c2f321--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--29c9f5c2f321--------------------------------) ·9分钟阅读·2024年1月8日

--

![](../Images/0cc2e5bbc15b261108b01f07c19c5442.png)

图片来源：Tome

多年前，我在Opendoor的老板给我的第一条建议简洁而深刻：*“投资回测。AI产品团队的成败取决于回测的质量。”* 当时，这条建议是经过实践验证的；它通过搜索、推荐、生命科学、金融等多个高风险领域的团队艰难获得的经验。这也是我珍视了近十年的建议。

但我逐渐相信，这并不是构建*生成式*AI产品的公理。大约一年前，我从经典机器学习产品（输出简单结果：数字、类别、有序列表）转向了生成式AI产品。在这个过程中，我发现许多经典机器学习的原则不再适用于我和我的团队。

通过我在Tome的工作（我担任产品负责人），以及与生成式AI初创公司领导者的对话，我意识到有三种行为特征，区分了那些推出最强大、最有用的生成式AI功能的团队。这些团队：

1.  同时从用户问题（向后工作）和技术机会（向前工作）两个方向进行探索

1.  从一开始就设计低摩擦的反馈循环

1.  重新思考经典机器学习中的研发工具

这些行为需要“摆脱”许多仍然是经典机器学习最佳实践的内容。乍看之下，其中一些可能显得违反直觉。然而，这些原则广泛适用于生成式AI应用，从横向到纵向的软件产品，从初创公司到行业巨头。让我们深入探讨吧！

*(想知道为什么自动化回测不再是生成式AI应用团队的基本原则了吗？该用什么替代它？继续阅读原则3)*

*(更关心生成式 AI 应用的 UI/UX 应该如何与经典机器学习产品有所不同，而不是关心过程？* [*查看这篇博客文章。*](/the-design-of-everyday-ai-things-26516d928566)*)*

# 原则 1：同时从用户问题出发（倒推）和从技术机会出发（正推）

“从用户问题倒推”是许多产品和设计圈中的信条，[由亚马逊所闻名](https://www.nytimes.com/2021/02/13/business/dealbook/amazon-working-backwards.html)。研究用户，找出他们的痛点，编写用户体验需求以缓解最严重的痛点，识别最合适的技术进行实施，然后不断重复。换句话说，弄清楚“这是我们要解决的最重要的问题，然后选择哪个工具来解决它。”

当启用技术发展得非常迅速时，这种方法的意义就不大了。ChatGPT 不是通过从用户痛点倒推来构建的。它之所以成功，是因为它通过一个简单、开放式的用户界面提供了一个强大而全新的启用技术。换句话说：“我们发明了一把新锤子，看看用户会用它敲哪些钉子。”

最优秀的生成式人工智能应用团队会同时进行正推和倒推。他们做用户研究，理解痛点的广度和深度。但他们不仅仅是按顺序处理一个排序列表。团队中的每个人，包括产品经理和设计师，都深度沉浸在最新的人工智能进展中。他们将这些不断发展的技术机会与用户痛点联系起来，这种联系往往比一对一的映射更为复杂。例如，某个团队可能会发现，用户痛点 #2、#3 和 #6 都可以通过模型突破 X 来缓解。那么，下一个项目可能会选择“正推”——通过结合模型突破 X，而不是“倒推”用户痛点 #1。

深度沉浸在近期人工智能的进展中，意味着要理解这些进展如何应用于你的实际应用，而不仅仅是阅读研究论文。这需要原型设计。只有在你的应用环境中亲自尝试新技术，用户收益的估算才不只是猜测。原型设计的重要性提升要求颠覆传统的 ***规格 → 原型 → 构建*** 过程，变成 ***原型 → 规格 → 构建***。更多的原型会被舍弃，但这是唯一能够持续精确匹配广泛且深刻的用户需求与有用新技术的方式。

# 原则 2：从一开始就设计低摩擦反馈回路

## **系统改进反馈**

经典的机器学习产品输出相对简单：数字、类别、排序列表。用户通常会接受或拒绝这些输出：你点击谷歌搜索结果页面上的一个链接，或者将邮件标记为垃圾邮件。每一次用户互动都会生成数据，直接反馈到模型的再训练中，因此实际使用和模型改进之间的联系是强大的（而且是机械的）。

不幸的是，大多数生成式AI产品往往不会随着每次用户互动产生新的、真实的训练数据。这个挑战与生成式模型的强大之处息息相关：它们能够生成复杂的产物，这些产物融合了文本、图像、视频、音频、代码等。对于复杂的产物，用户很少会“接受或拒绝”。相反，大多数用户会对模型输出进行精细化调整，无论是通过更多/不同的AI，还是手动调整。例如，用户可能会将ChatGPT的输出复制到Word中，编辑后再发送给同事。这种行为使得应用程序（ChatGPT）无法“看到”产物的最终、期望形式。

一个含义是允许用户在你的应用程序中对输出进行迭代。但这并不解决问题：当用户没有对输出进行迭代时，这意味着“哇”还是“哀愁”？你可以为每个AI响应添加一个情感指示器（例如，点赞/点踩），但互动级别的反馈响应率往往是*非常*低的。而提交的反馈通常偏向极端。用户大多将情感收集工作视为额外的障碍，因为它们大多不能帮助用户立即获得更好的输出。

更好的策略是识别用户工作流程中的某一步，标志着“这个输出现在足够好”。将这一步构建到你的应用中，并确保记录此时输出的样子。对于Tome，我们帮助用户使用AI制作演示文稿，关键步骤是将演示文稿分享给另一个人。为了在我们的应用中实现这一点，我们在共享功能上进行了大量投资。然后，我们评估哪些AI输出是“可共享的”，哪些则需要大量手动编辑才能共享。

## **用户协助反馈**

自由文本已经成为用户希望与生成式AI应用交互的主要方式。但自由文本是一个潘多拉的盒子：给用户自由文本输入AI，他们会要求产品做一些它无法完成的事情。自由文本是一种 notoriously 难以传达产品限制的输入机制；相比之下，老式的网页表单能清晰地表明可以和必须提交哪些信息，以及必须以什么格式提交。

但是，用户在进行创意或复杂工作时并不想要表单。他们需要自由文本——并且需要关于如何根据当前任务编写优秀提示的指导。帮助用户的策略包括示例提示或模板，关于最优提示长度和格式的指导（他们是否应该包括[少量示例](https://www.promptingguide.ai/techniques/fewshot)？）。人类可读的错误信息也是关键（例如：“该提示使用了X语言，但我们仅支持Y和Z语言。”）

自由文本输入的一个好处是，未被支持的请求可以成为下一个开发灵感的绝佳来源。诀窍在于能够识别和聚类用户在自由文本中试图做的事情。关于这一点将在下一节中详细讨论…

# 原则三：重新考虑经典机器学习中的研发工具

*构建一些，保留一些，舍弃一些*

## **Build: 自然语言分析**

许多生成性 AI 应用程序允许用户从同一个入口点执行非常不同的工作流：一个开放式、自由文本的界面。用户并不是从下拉菜单中选择“我在头脑风暴”或“我想解决一个数学问题”——他们期望的工作流隐含在他们的文本输入中。因此，理解用户期望的工作流需要对这些自由文本输入进行切分。一些切分方法可能会长期有效——在 Tome，我们一直关注所需的语言和目标受众类型。也有一些临时的切分方法，用于回答产品路线图上的特定问题——例如，多少个提示请求视觉元素，如图像、视频、表格或图表，因此我们应该在这些视觉元素上进行投资？

自然语言分析应该是对传统研究方法的补充，而不是取而代之。自然语言处理（NLP）与结构化数据（例如传统的 SQL）结合时尤其强大。许多关键数据不是自由文本：用户何时注册、用户的属性（如组织、职位、地理位置等）。在 Tome，我们倾向于根据职位功能、地理位置和自由/付费用户状态来查看语言聚类——所有这些都需要传统的 SQL。

定量分析的洞察永远不应单独依赖于定性分析。我发现，观察用户实时使用我们的产品*现场*演示，有时能获得是用户访谈（用户事后讨论其产品印象）十倍的洞察力。而且我也遇到过某个优秀的用户访谈，解锁了定量分析十倍的洞察。

## **Keep: 低代码原型设计工具**

两种工具类型能促进高速度、高质量的生成性 AI 应用开发：原型设计工具和输出质量评估工具。

有许多不同的方式可以改进机器学习应用，但有一种既快速又易于接触的策略是[提示工程](https://platform.openai.com/docs/guides/prompt-engineering)。它之所以快速，是因为它不需要重新训练模型；之所以易于接触，是因为它涉及的是自然语言，而不是代码。允许非工程师在开发环境或本地环境中操作提示工程方法，可以显著提高开发速度和质量。通常，这可以通过笔记本实现。笔记本中可能包含大量代码，但非工程师也可以在不接触代码的情况下，通过迭代自然语言提示取得显著进展。

评估原型输出质量通常相当困难，尤其是在构建全新特性时。与其投资于自动化质量测量，我发现通过“beta 测试程序”向同事或用户征求 10–100 次结构化评估（评分 + 注释）要快得多且更有用。“投票方法”的启用技术可以很轻便：一个生成输入/输出示例的小规模笔记本，并将其传输到 Google 表格中。这使得手动评估能够并行进行，通常在不到一天的时间内，通过少数几个人就能评估大约 100 个示例。评估者的注释可以提供关于失败模式或优秀模式的见解，这也是一个额外的好处；注释通常比数值评分更有助于识别下一步需要修复或构建的内容。

## **丢弃：自动化、回测的质量测量**

经典机器学习工程的一个原则是投资于强健的回测。团队频繁地重新训练经典模型（每周或每天），而一个好的回测确保只有优秀的新候选模型被发布到生产环境中。对于输出数字或类别的模型来说，这种方式是合理的，因为它们可以轻松与真实情况进行比对评分。

但在面对复杂（或许是多模态）输出时，评分准确性变得更难。你可能有一段你认为很好的文本，因此倾向于将其称为“真实情况”，但是如果模型输出与其相差 1 个词，这有意义吗？相差 1 句话呢？如果事实都相同，但结构不同呢？如果是文本和图像的结合呢？

但并非一切都已失去。人类通常能轻松评估生成式 AI 输出是否达到了他们的质量标准。这并不意味着将差的输出转化为好的输出是容易的，只是用户通常能够在几秒钟内判断文本、图像、音频等是否“好”或“不好”。此外，应用层的大多数生成式 AI 系统并不会每天、每周甚至每月进行重新训练，原因是计算成本和/或获取足够的用户信号来证明重训练的长时间周期。因此，我们不需要每天运行的质量评估流程（除非你是 Google、Meta 或 OpenAI）。

考虑到人类能够轻松评估生成式 AI 输出，而且重训练的频率较低，通常情况下，根据内部手动测试（例如上文提到的投票方法）而非自动化回测来评估新模型候选者是更合适的。

开发出色的生成式 AI 应用不仅仅需要创新的工程技术，还需要产品和设计以不同于传统机器学习（ML）或非 ML 产品的方式来协作。有些模式需要被遗忘（“投资于你的回测！”），有些需要重新定义（“从后向前和前向后工作”），还有一些是全新的（“从一开始就为反馈循环构建”）。

这可能需要大量的流程和人员重组，但好处是巨大的——如果你不这么做，革命将会与你擦肩而过。
