- en: The Definitive Guide to Structured Data Parsing with OpenAI GPT3.5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-definitive-guide-to-structured-data-parsing-with-openai-gpt3-5-0e5ea0e52637?source=collection_archive---------9-----------------------#2024-04-16](https://towardsdatascience.com/the-definitive-guide-to-structured-data-parsing-with-openai-gpt3-5-0e5ea0e52637?source=collection_archive---------9-----------------------#2024-04-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Systematically comparing Instructor, Fructose, Mirascope, and Langchain for
    three complex real-world structured data parsing tasks.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://stephen-leo.medium.com/?source=post_page---byline--0e5ea0e52637--------------------------------)[![Marie
    Stephen Leo](../Images/c5669d884da5ff5c965f98904257d379.png)](https://stephen-leo.medium.com/?source=post_page---byline--0e5ea0e52637--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0e5ea0e52637--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0e5ea0e52637--------------------------------)
    [Marie Stephen Leo](https://stephen-leo.medium.com/?source=post_page---byline--0e5ea0e52637--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0e5ea0e52637--------------------------------)
    ·8 min read·Apr 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d3a404445478a2d6bebbaf07d3f18b61.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by Author using ChatGPT
  prefs: []
  type: TYPE_NORMAL
- en: Parsing structured data from Large Language Models (LLMs) can be frustrating
    for anything beyond toy problems. Yet, reliably parsing LLM outputs into pre-defined
    structures is crucial to integrating LLMs into other software systems and generative
    AI apps. OpenAI has taken the lead by releasing the GPT function calling ([Link](https://platform.openai.com/docs/guides/function-calling))
    and JSON mode ([Link](https://platform.openai.com/docs/guides/text-generation/json-mode)).
    Still, these require intensive prompt engineering, robust parsing, retry, and
    graceful error handling to work reliably for production real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: Below are some problems I’ve faced parsing structured data with LLMs. This article
    was written entirely by a human with help from Grammarly’s grammar checker, which
    has been my writing method since 2019.
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification:** The LLM must strictly adhere to a list of allowed classes,
    which can be as many as tens to hundreds in real-world problems. LLMs start hallucinating
    about disallowed classes in tasks with more than a handful of classes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Named Entity Recognition (NER):** The LLM should only pick entities explicitly
    present in the text. These entities…'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
