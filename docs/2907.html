<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Modeling DAU with Markov Chain</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Modeling DAU with Markov Chain</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/modeling-dau-with-markov-chain-640ea4fddeb4?source=collection_archive---------1-----------------------#2024-12-02">https://towardsdatascience.com/modeling-dau-with-markov-chain-640ea4fddeb4?source=collection_archive---------1-----------------------#2024-12-02</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="2b02" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How to predict DAU using Duolingo’s growth model and control the prediction</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@wowone?source=post_page---byline--640ea4fddeb4--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Vladimir Kukushkin" class="l ep by dd de cx" src="../Images/e41265ea2c2079723f327ca02db3f67f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*hyf8Gr_LFBv4yTsAk9h-uQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--640ea4fddeb4--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@wowone?source=post_page---byline--640ea4fddeb4--------------------------------" rel="noopener follow">Vladimir Kukushkin</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--640ea4fddeb4--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">21 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 2, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">4</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><h1 id="efcd" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">1. Introduction</h1><p id="50eb" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Doubtlessly, DAU, WAU, and MAU — daily, weekly, and monthly <a class="af ob" href="https://en.wikipedia.org/wiki/Active_users" rel="noopener ugc nofollow" target="_blank">active users</a> — are critical business metrics. An article <a class="af ob" href="https://www.lennysnewsletter.com/p/how-duolingo-reignited-user-growth" rel="noopener ugc nofollow" target="_blank">“How Duolingo reignited user growth”</a> by <a class="af ob" href="https://www.linkedin.com/in/jorgemazal/" rel="noopener ugc nofollow" target="_blank">Jorge Mazal</a>, former CPO of Duolingo, is #1 in the Growth section of Lenny’s Newsletter blog. In this article, Jorge paid special attention to the methodology Duolingo used to model the DAU metric (see another article <a class="af ob" href="https://blog.duolingo.com/growth-model-duolingo/" rel="noopener ugc nofollow" target="_blank">“Meaningful metrics: how data sharpened the focus of product teams”</a> by <a class="af ob" href="https://blog.duolingo.com/author/erin/" rel="noopener ugc nofollow" target="_blank">Erin Gustafson</a>). This methodology has multiple strengths, but I’d like to focus on how one can use this approach for DAU forecasting.</p><p id="7439" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The new year is coming soon, so many companies are planning their budgets for the next year these days. Cost estimations often require DAU forecasts. In this article, I’ll show how you can get this prediction using Duolingo’s growth model. I’ll explain why this approach is better compared to standard time-series forecasting methods and how you can adjust the prediction according to your teams’ plans (e.g., marketing, activation, product teams).</p><p id="d3c1" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The article text goes along with the code, and a simulated dataset is attached so the research is fully reproducible. The Jupyter notebook version is available <a class="af ob" href="https://github.com/wowone/wowone.github.io/blob/master/posts/2024-12-02_dau_prediction/dau_prediction.ipynb" rel="noopener ugc nofollow" target="_blank">here</a>. In the end, I’ll share a DAU “calculator” designed in Google Spreadsheet format.</p><p id="6f0c" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">I’ll be narrating on behalf of the collective “we” as if we’re talking together.</p><h1 id="5a15" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">2. Methodology</h1><p id="5271" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">A quick recap on how the <a class="af ob" href="https://blog.duolingo.com/growth-model-duolingo/" rel="noopener ugc nofollow" target="_blank">Duolingo’s growth model</a> works. At day d (d = 1, 2, … ) of a user’s lifetime, the user can be in one of the following 7 (mutually-exclusive) states: <code class="cx oh oi oj ok b">new</code>, <code class="cx oh oi oj ok b">current</code>, <code class="cx oh oi oj ok b">reactivated</code>, <code class="cx oh oi oj ok b">resurrected</code>, <code class="cx oh oi oj ok b">at_risk_wau</code>, <code class="cx oh oi oj ok b">at_risk_mau</code>, <code class="cx oh oi oj ok b">dormant</code>. The states are defined according to indicators of whether a user was active today, in the last 7 days, or in the last 30 days. The definition summary is given in the table below:</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om on"><img src="../Images/310a0c6eba807c18e6ad05ec8ab9aa67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tAPSb4Syw4hFteuao0T7PA.png"/></div></div></figure><p id="fb9d" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Having these states defined (as a set S), we can consider user behavior as a <a class="af ob" href="https://en.wikipedia.org/wiki/Markov_chain" rel="noopener ugc nofollow" target="_blank">Markov chain</a>. Here’s an example of a user’s trajectory: <code class="cx oh oi oj ok b">new</code>→ <code class="cx oh oi oj ok b">current</code>→ <code class="cx oh oi oj ok b">current</code>→ <code class="cx oh oi oj ok b">at_risk_wau</code>→...→ <code class="cx oh oi oj ok b">at_risk_mau</code>→...→ <code class="cx oh oi oj ok b">dormant</code>. Let M be a transition matrix associated with this Markov process: m_{i, j} = P(s_j | s_i) are the probabilities that a user moves to state s_j right after being at state s_i, where s_i, s_j ∈ S. Such a matrix is inferred from the historical data.</p><p id="acc3" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">If we assume that user behavior is stationary (independent of time), the matrix M fully describes the states of all users in the future. Suppose that the vector u_0 of length 7 contains the counts of users in certain states on a given day, denoted as day 0. According to the Markov model, on the next day 1, we expect to have the following number of users states u_1:</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om oz"><img src="../Images/cd5c149c2584d7449578ec794b6c820c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cv3xYnXplDXsDIno6MPrFw.png"/></div></div></figure><p id="ed23" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Applying this formula recursively, we derive the number of users in certain states on any arbitrary day t &gt; 0 in the future.</p><p id="8762" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Besides the initial distribution u_0, we need to provide the number of new users that will appear in the product each day in the future. We’ll address this problem as a general time-series forecasting.</p><p id="93c3" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Now, having u_t calculated, we can determine DAU values on day t:</p><p id="e056" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">DAU_t = #New_t + #Current_t + #Reactivated_t + #Resurrected_t</p><p id="718d" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Additionally, we can easily calculate WAU and MAU metrics:</p><p id="6034" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">WAU_t = DAU_t + #AtRiskWau_t,<br/>MAU_t = DAU_t + #AtRiskWau_t + #AtRiskMau_t.</p><p id="3abb" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Finally, here’s the algorithm outline:</p><ol class=""><li id="4061" class="nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa pa pb pc bk">For each prediction day t = 1, …, T, calculate the expected number of new users #New_1, …, #New_T.</li><li id="0e5d" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa pa pb pc bk">For each lifetime day of each user, assign one of the 7 states.</li><li id="c3d9" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa pa pb pc bk">Calculate the transition matrix M from the historical data.</li><li id="844b" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa pa pb pc bk">Calculate initial state counts u_0 corresponding to day t=0.</li><li id="2f95" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa pa pb pc bk">Recursively calculate u_{t+1} = M^T * u_t.</li><li id="7087" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa pa pb pc bk">Calculate DAU, WAU, and MAU for each prediction day t = 1, …, T.</li></ol><h1 id="3231" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">3. Implementation</h1><p id="7aee" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">This section is devoted to technical aspects of the implementation. If you’re interested in studying the model properties rather than code, you may skip this section and go to the <a class="af ob" href="#1375" rel="noopener ugc nofollow">Section 4</a>.</p><h2 id="38a3" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">3.1 Dataset</h2><p id="f3e5" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">We use a simulated dataset based on historical data of a SaaS app. The data is stored in the <a class="af ob" href="https://drive.google.com/file/d/16kd8rJBvcgmw95jY42MedRfIxcO4LpPd/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">dau_data.csv.gz</a> file and contains three columns: <code class="cx oh oi oj ok b">user_id</code>, <code class="cx oh oi oj ok b">date</code>, and <code class="cx oh oi oj ok b">registration_date</code>. Each record indicates a day when a user was active. The dataset includes activity indicators for 51480 users from <code class="cx oh oi oj ok b">2020-11-01</code> to <code class="cx oh oi oj ok b">2023-10-31</code>. Additionally, data from October 2020 is included to calculate user states properly, as the <code class="cx oh oi oj ok b">at_risk_mau</code> and <code class="cx oh oi oj ok b">dormant</code> states require data from one month prior.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="f3a0" class="qc mk fq ok b bg qd qe l qf qg">import pandas as pd<br/><br/>df = pd.read_csv('dau_data.csv.gz', compression='gzip')<br/>df['date'] = pd.to_datetime(df['date'])<br/>df['registration_date'] = pd.to_datetime(df['registration_date'])<br/><br/>print(f'Shape: {df.shape}')<br/>print(f'Total users: {df['user_id'].nunique()}')<br/>print(f'Data range: [{df['date'].min()}, {df['date'].max()}]')<br/>df.head()</span></pre><pre class="qh pz ok qa bp qb bb bk"><span id="6125" class="qc mk fq ok b bg qd qe l qf qg">Shape: (667236, 3)<br/>Total users: 51480<br/>Data range: [2020-10-01 00:00:00, 2023-10-31 00:00:00]</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om on"><img src="../Images/3248afffd2cb0a590beb957b9a2eaed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*boptDIHcT3KVLhNdbNNnQw.png"/></div></div></figure><p id="2735" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">This is how the DAU time-series looks like.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="c67f" class="qc mk fq ok b bg qd qe l qf qg">df.groupby('date').size()\<br/>    .plot(title='DAU, historical')</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qi"><img src="../Images/f3da1f5416d7f6c96d1ffe7d01f34913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B88Nd_1uVTA3SYy4Xh2xgg.png"/></div></div></figure><p id="c8a4" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Suppose that today is 2023–10–31 and we want to predict the DAU metric for the next 2024 year. We define a couple of global constants <code class="cx oh oi oj ok b">PREDICTION_START</code> and <code class="cx oh oi oj ok b">PREDICTION_END</code> which encompass the prediction period.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="d9ac" class="qc mk fq ok b bg qd qe l qf qg">PREDICTION_START = '2023-11-01'<br/>PREDICTION_END = '2024-12-31'</span></pre><h2 id="baf6" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">3.2 Predicting new users amount</h2><p id="af97" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Let’s start from the new users prediction. We use the <a class="af ob" href="http://facebook.github.io/prophet/" rel="noopener ugc nofollow" target="_blank">prophet</a> library as one of the easiest ways to forecast time-series data. The <code class="cx oh oi oj ok b">new_users</code> Series contains such data. We extract it from the original <code class="cx oh oi oj ok b">df</code> dataset selecting the rows where the <code class="cx oh oi oj ok b">registration date</code> is equal to the <code class="cx oh oi oj ok b">date</code>.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="33d9" class="qc mk fq ok b bg qd qe l qf qg">new_users = df[df['date'] == df['registration_date']]\<br/>    .groupby('date').size()<br/>new_users.head()</span></pre><pre class="qh pz ok qa bp qb bb bk"><span id="e174" class="qc mk fq ok b bg qd qe l qf qg">date<br/>2020-10-01    4<br/>2020-10-02    4<br/>2020-10-03    3<br/>2020-10-04    4<br/>2020-10-05    8<br/>dtype: int64</span></pre><p id="a57e" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk"><code class="cx oh oi oj ok b">prophet</code> requires a time-series as a DataFrame containing two columns <code class="cx oh oi oj ok b">ds</code> and <code class="cx oh oi oj ok b">y</code>, so we reformat the <code class="cx oh oi oj ok b">new_users</code> Series to the <code class="cx oh oi oj ok b">new_users_prophet</code> DataFrame. Another thing we need to prepare is to create the <code class="cx oh oi oj ok b">future</code> variable containing certain days for prediction: from <code class="cx oh oi oj ok b">prediction_start</code> to <code class="cx oh oi oj ok b">prediction_end</code>. This logic is implemented in the <code class="cx oh oi oj ok b">predict_new_users</code> function. The plot below illustrates predictions for both past and future periods.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="8e86" class="qc mk fq ok b bg qd qe l qf qg">import logging<br/>import matplotlib.pyplot as plt<br/>from prophet import Prophet<br/><br/># suppress prophet logs<br/>logging.getLogger('prophet').setLevel(logging.WARNING)<br/>logging.getLogger('cmdstanpy').disabled=True<br/><br/>def predict_new_users(prediction_start, prediction_end, new_users_train, show_plot=True):<br/>    """<br/>    Forecasts a time-seires for new users<br/><br/>    Parameters<br/>    ----------<br/>    prediction_start : str<br/>        Date in YYYY-MM-DD format.<br/>    prediction_end : str<br/>        Date in YYYY-MM-DD format.<br/>    new_users_train : pandas.Series<br/>        Historical data for the time-series preceding the prediction period.<br/>    show_plot : boolean, default=True<br/>        If True, a chart with the train and predicted time-series values is displayed.<br/>    Returns<br/>    -------<br/>    pandas.Series<br/>        Series containing the predicted values.<br/>    """<br/>    m = Prophet()<br/><br/>    new_users_train = new_users_train\<br/>        .loc[new_users_train.index &lt; prediction_start]<br/>    new_users_prophet = pd.DataFrame({<br/>        'ds': new_users_train.index,<br/>        'y': new_users_train.values<br/>    })<br/><br/>    m.fit(new_users_prophet)<br/><br/>    periods = len(pd.date_range(prediction_start, prediction_end))<br/>    future = m.make_future_dataframe(periods=periods)<br/>    new_users_pred = m.predict(future)<br/>    if show_plot:<br/>        m.plot(new_users_pred)<br/>        plt.title('New users prediction');<br/><br/>    new_users_pred = new_users_pred\<br/>        .assign(yhat=lambda _df: _df['yhat'].astype(int))\<br/>        .rename(columns={'ds': 'date', 'yhat': 'count'})\<br/>        .set_index('date')\<br/>        .clip(lower=0)\<br/>        ['count']<br/><br/>    return new_users_pred</span></pre><pre class="qh pz ok qa bp qb bb bk"><span id="9bac" class="qc mk fq ok b bg qd qe l qf qg">new_users_pred = predict_new_users(PREDICTION_START, PREDICTION_END, new_users)</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qj"><img src="../Images/e2d4082a52ad9a60f38efb68bc7141e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PrxCj-BJmr7rgc7VyNkIlw.png"/></div></div></figure><p id="8a0f" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The <code class="cx oh oi oj ok b">new_users_pred</code> Series stores the predicted users amount.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="a0f0" class="qc mk fq ok b bg qd qe l qf qg">new_users_pred.tail(5)</span></pre><pre class="qh pz ok qa bp qb bb bk"><span id="affb" class="qc mk fq ok b bg qd qe l qf qg">date<br/>2024-12-27    52<br/>2024-12-28    56<br/>2024-12-29    71<br/>2024-12-30    79<br/>2024-12-31    74<br/>Name: count, dtype: int64</span></pre><h2 id="b2e5" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">3.3 Getting the states</h2><p id="4492" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">In practice, the most calculations are reasonable to execute as SQL queries to a database where the data is stored. Hereafter, we will simulate such querying using the <a class="af ob" href="https://duckdb.org" rel="noopener ugc nofollow" target="_blank">duckdb</a> library.</p><p id="2156" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">We want to assign one of the 7 states to each day of a user’s lifetime within the app. According to the definition, for each day, we need to consider at least the past 30 days. This is where SQL window functions come in. However, since the <code class="cx oh oi oj ok b">df</code> data contains only records of <em class="qk">active days</em>, we need to explicitly extend them and include the days when a user was not active. In other words, instead of this list of records:</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="010d" class="qc mk fq ok b bg qd qe l qf qg">user_id    date          registration_date<br/>1234567    2023-01-01    2023-01-01<br/>1234567    2023-01-03    2023-01-01</span></pre><p id="6393" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">we’d like to get a list like this:</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="432a" class="qc mk fq ok b bg qd qe l qf qg">user_id    date          is_active    registration_date<br/>1234567    2023-01-01    TRUE         2023-01-01<br/>1234567    2023-01-02    FALSE        2023-01-01<br/>1234567    2023-01-03    TRUE         2023-01-01<br/>1234567    2023-01-04    FALSE        2023-01-01<br/>1234567    2023-01-05    FALSE        2023-01-01<br/>...        ...           ...          ...<br/>1234567    2023-10-31    FALSE        2023-01-01</span></pre><p id="8a89" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">For readability purposes we split the following SQL query into multiple subqueries.</p><ul class=""><li id="016c" class="nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa ql pb pc bk"><code class="cx oh oi oj ok b">full_range</code>: Create a full sequence of dates for each user.</li><li id="7573" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk"><code class="cx oh oi oj ok b">dau_full</code>: Get the full list of both active and inactive records.</li><li id="3cff" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk"><code class="cx oh oi oj ok b">states</code>: Assign one of the 7 states for each day of a user's lifetime.</li></ul><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="67e7" class="qc mk fq ok b bg qd qe l qf qg">import duckdb<br/><br/>DATASET_START = '2020-11-01'<br/>DATASET_END = '2023-10-31'<br/>OBSERVATION_START = '2020-10-01'<br/><br/>query = f"""<br/>WITH<br/>full_range AS (<br/>    SELECT<br/>        user_id, UNNEST(generate_series(greatest(registration_date, '{OBSERVATION_START}'), date '{DATASET_END}', INTERVAL 1 DAY))::date AS date<br/>    FROM (<br/>        SELECT DISTINCT user_id, registration_date FROM df<br/>    )<br/>),<br/>dau_full AS (<br/>    SELECT<br/>        fr.user_id,<br/>        fr.date,<br/>        df.date IS NOT NULL AS is_active,<br/>        registration_date<br/>    FROM full_range AS fr<br/>    LEFT JOIN df USING(user_id, date)<br/>),<br/>states AS (<br/>    SELECT<br/>        user_id,<br/>        date,<br/>        is_active,<br/>        first_value(registration_date IGNORE NULLS) OVER (PARTITION BY user_id ORDER BY date) AS registration_date,<br/>        SUM(is_active::int) OVER (PARTITION BY user_id ORDER BY date ROWS BETWEEN 6 PRECEDING and 1 PRECEDING) AS active_days_back_6d,<br/>        SUM(is_active::int) OVER (PARTITION BY user_id ORDER BY date ROWS BETWEEN 29 PRECEDING and 1 PRECEDING) AS active_days_back_29d,<br/>        CASE<br/>            WHEN date = registration_date THEN 'new'<br/>            WHEN is_active = TRUE AND active_days_back_6d BETWEEN 1 and 6 THEN 'current'<br/>            WHEN is_active = TRUE AND active_days_back_6d = 0 AND IFNULL(active_days_back_29d, 0) &gt; 0 THEN 'reactivated'<br/>            WHEN is_active = TRUE AND active_days_back_6d = 0 AND IFNULL(active_days_back_29d, 0) = 0 THEN 'resurrected'<br/>            WHEN is_active = FALSE AND active_days_back_6d &gt; 0 THEN 'at_risk_wau'<br/>            WHEN is_active = FALSE AND active_days_back_6d = 0 AND ifnull(active_days_back_29d, 0) &gt; 0 THEN 'at_risk_mau'<br/>            ELSE 'dormant'<br/>        END AS state<br/>    FROM dau_full<br/>)<br/>SELECT user_id, date, state FROM states<br/>WHERE date BETWEEN '{DATASET_START}' AND '{DATASET_END}'<br/>ORDER BY user_id, date<br/>"""<br/>states = duckdb.sql(query).df()</span></pre><p id="7fc3" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The query results are kept in the <code class="cx oh oi oj ok b">states</code> DataFrame:</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qm"><img src="../Images/53ea15d70dd68eaa0f5c26683a10eaf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CKrex2_FcRmfmFMOtT-_yw.png"/></div></div></figure><h2 id="8810" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">3.4 Calculating the transition matrix</h2><p id="32d6" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Having obtained these states, we can calculate state transition frequencies. In the <a class="af ob" href="#0637" rel="noopener ugc nofollow">Section 4.3</a> we’ll study how the prediction depends on a period in which transitions are considered, so it’s reasonable to pre-aggregate this data on daily basis. The resulting <code class="cx oh oi oj ok b">transitions</code> DataFrame contains <code class="cx oh oi oj ok b">date</code>, <code class="cx oh oi oj ok b">state_from</code>, <code class="cx oh oi oj ok b">state_to</code>, and <code class="cx oh oi oj ok b">cnt</code> columns.</p><p id="6655" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Now, we can calculate the transition matrix M. We implement the <code class="cx oh oi oj ok b">get_transition_matrix</code> function, which accepts the <code class="cx oh oi oj ok b">transitions</code> DataFrame and a pair of dates that encompass the transitions period to be considered.</p><p id="e81d" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">As a baseline, let’s calculate the transition matrix for the whole year from <code class="cx oh oi oj ok b">2022-11-01</code> to <code class="cx oh oi oj ok b">2023-10-31</code>.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="363d" class="qc mk fq ok b bg qd qe l qf qg">M = get_transition_matrix(transitions, '2022-11-01', '2023-10-31')<br/>M</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qn"><img src="../Images/3a953164c81ba1b76230eb9fa6cc70de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CEK1ieeHcLT4-0XtXUAiHg.png"/></div></div></figure><p id="b4c5" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The sum of each row of any transition matrix equals 1 since it represents the probabilities of moving from one state to any other state.</p><h2 id="1c8c" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">3.5 Getting the initial state counts</h2><p id="9c05" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">An initial state is retrieved from the <code class="cx oh oi oj ok b">states</code> DataFrame by the <code class="cx oh oi oj ok b">get_state0</code> function and the corresponding SQL query. The only argument of the function is the date for which we want to get the initial state. We assign the result to the <code class="cx oh oi oj ok b">state0</code> variable.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="1c15" class="qc mk fq ok b bg qd qe l qf qg">def get_state0(date):<br/>    query = f"""<br/>    SELECT state, count(*) AS cnt<br/>    FROM states<br/>    WHERE date = '{date}'<br/>    GROUP BY state<br/>    """<br/><br/>    state0 = duckdb.sql(query).df()<br/>    state0 = state0.set_index('state').reindex(states_order)['cnt']<br/>    <br/>    return state0</span></pre><pre class="qh pz ok qa bp qb bb bk"><span id="16fc" class="qc mk fq ok b bg qd qe l qf qg">state0 = get_state0(DATASET_END)<br/>state0</span></pre><pre class="qh pz ok qa bp qb bb bk"><span id="1d03" class="qc mk fq ok b bg qd qe l qf qg">state<br/>new               20<br/>current          475<br/>reactivated       15<br/>resurrected       19<br/>at_risk_wau      404<br/>at_risk_mau     1024<br/>dormant        49523<br/>Name: cnt, dtype: int64</span></pre><h2 id="5dc8" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">3.6 Predicting DAU</h2><p id="84e4" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">The <code class="cx oh oi oj ok b">predict_dau</code> function below accepts all the previous variables required for the DAU prediction and makes this prediction for a date range defined by the <code class="cx oh oi oj ok b">start_date</code> and <code class="cx oh oi oj ok b">end_date</code> arguments.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="7505" class="qc mk fq ok b bg qd qe l qf qg">def predict_dau(M, state0, start_date, end_date, new_users):<br/>    """<br/>    Predicts DAU over a given date range.<br/><br/>    Parameters<br/>    ----------<br/>    M : pandas.DataFrame<br/>        Transition matrix representing user state changes.<br/>    state0 : pandas.Series<br/>        counts of initial state of users.<br/>    start_date : str<br/>        Start date of the prediction period in 'YYYY-MM-DD' format.<br/>    end_date : str<br/>        End date of the prediction period in 'YYYY-MM-DD' format.<br/>    new_users : int or pandas.Series<br/>        The expected amount of new users for each day between `start_date` and `end_date`.<br/>        If a Series, it should have dates as the index.<br/>        If an int, the same number is used for each day.<br/>        <br/>    Returns<br/>    -------<br/>    pandas.DataFrame<br/>        DataFrame containing the predicted DAU, WAU, and MAU for each day in the date range,<br/>        with columns for different user states and tot.<br/>    """<br/>    <br/>    dates = pd.date_range(start_date, end_date)<br/>    dates.name = 'date'<br/>    dau_pred = []<br/>    new_dau = state0.copy()<br/>    for date in dates:<br/>        new_dau = (M.transpose() @ new_dau).astype(int)<br/>        if isinstance(new_users, int):<br/>            new_users_today = new_users<br/>        else:<br/>            new_users_today = new_users.astype(int).loc[date] <br/>        new_dau.loc['new'] = new_users_today<br/>        dau_pred.append(new_dau.tolist())<br/><br/>    dau_pred = pd.DataFrame(dau_pred, index=dates, columns=states_order)<br/>    dau_pred['dau'] = dau_pred['new'] + dau_pred['current'] + dau_pred['reactivated'] + dau_pred['resurrected']<br/>    dau_pred['wau'] = dau_pred['dau'] + dau_pred['at_risk_wau']<br/>    dau_pred['mau'] = dau_pred['dau'] + dau_pred['at_risk_wau'] + dau_pred['at_risk_mau']<br/>    <br/>    return dau_pred</span></pre><pre class="qh pz ok qa bp qb bb bk"><span id="e218" class="qc mk fq ok b bg qd qe l qf qg">dau_pred = predict_dau(M, state0, PREDICTION_START, PREDICTION_END, new_users_pred)<br/>dau_pred</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qo"><img src="../Images/70dcf535319cb880014b98b0a1834a4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*onivsmmuFBTDt0qZhlrQXA.png"/></div></div></figure><p id="0b03" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">This is how the DAU prediction <code class="cx oh oi oj ok b">dau_pred</code> looks like for the <code class="cx oh oi oj ok b">PREDICTION_START</code> - <code class="cx oh oi oj ok b">PREDICTION_END</code> period. Besides the expected <code class="cx oh oi oj ok b">dau</code>, <code class="cx oh oi oj ok b">wau</code>, and <code class="cx oh oi oj ok b">mau</code> columns, the output contains the number of users in each state for each prediction date.</p><p id="e901" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Finally, we calculate the ground-truth values of DAU, WAU, and MAU (along with the user state counts), keep them in the <code class="cx oh oi oj ok b">dau_true</code> DataFrame, and plot the predicted and true values altogether.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="efb5" class="qc mk fq ok b bg qd qe l qf qg">query = f"""<br/>SELECT date, state, COUNT(*) AS cnt<br/>FROM states<br/>GROUP BY date, state<br/>ORDER BY date, state;<br/>"""<br/><br/>dau_true = duckdb.sql(query).df()<br/>dau_true['date'] = pd.to_datetime(dau_true['date'])<br/>dau_true = dau_true.pivot(index='date', columns='state', values='cnt')<br/>dau_true['dau'] = dau_true['new'] + dau_true['current'] + dau_true['reactivated'] + dau_true['resurrected']<br/>dau_true['wau'] = dau_true['dau'] + dau_true['at_risk_wau']<br/>dau_true['mau'] = dau_true['dau'] + dau_true['at_risk_wau'] + dau_true['at_risk_mau']</span></pre><pre class="qh pz ok qa bp qb bb bk"><span id="93b6" class="qc mk fq ok b bg qd qe l qf qg">dau_true.head()</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qm"><img src="../Images/09d316078e58553d6b7050786090ae89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ToJZNPI8Bd4oxJm5tMts5w.png"/></div></div></figure><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="e176" class="qc mk fq ok b bg qd qe l qf qg">pd.concat([dau_true['dau'], dau_pred['dau']])\<br/>    .plot(title='DAU, historical &amp; predicted');<br/>plt.axvline(PREDICTION_START, color='k', linestyle='--');</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qp"><img src="../Images/cabd39f402f83dcda0f85360a2c50474.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b9opg5Z4MkcNvx0RvWJEjA.png"/></div></div></figure><p id="d003" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">We’ve obtained the prediction but so far it’s not clear whether it’s fair or not. In the next section, we’ll evaluate the model.</p><h1 id="1375" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">4. Model evaluation</h1><h2 id="0e38" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">4.1 Baseline model</h2><p id="634f" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">First of all, let’s check whether we really need to build a complex model to predict DAU. Wouldn’t it be better to predict DAU as a general time-series using the mentioned <code class="cx oh oi oj ok b">prophet</code> library? The function <code class="cx oh oi oj ok b">predict_dau_prophet</code> below implements this. We try to use some tweaks available in the library in order to make the prediction more accurate. In particular:</p><ul class=""><li id="05d0" class="nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa ql pb pc bk">we use logistic model instead of linear to avoid negative values;</li><li id="166a" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">we add explicitly monthly and yearly seasonality;</li><li id="28bf" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">we remove the outliers;</li><li id="83e4" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">we explicitly define a peak period in January and February as “holidays”.</li></ul><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="9b0a" class="qc mk fq ok b bg qd qe l qf qg">def predict_dau_prophet(prediction_start, prediction_end, dau_true, show_plot=True):<br/>    # assigning peak days for the new year<br/>    holidays = pd.DataFrame({<br/>        'holiday': 'january_spike',<br/>        'ds': pd.date_range('2022-01-01', '2022-01-31', freq='D').tolist() + \<br/>              pd.date_range('2023-01-01', '2023-01-31', freq='D').tolist(),<br/>        'lower_window': 0,<br/>        'upper_window': 40<br/>    })<br/><br/>    m = Prophet(growth='logistic', holidays=holidays)<br/>    m.add_seasonality(name='monthly', period=30.5, fourier_order=3)<br/>    m.add_seasonality(name='yearly', period=365, fourier_order=3)<br/><br/>    train = dau_true.loc[(dau_true.index &lt; prediction_start) &amp; (dau_true.index &gt;= '2021-08-01')]<br/>    train_prophet = pd.DataFrame({'ds': train.index, 'y': train.values})<br/>    # removining outliers<br/>    train_prophet.loc[train_prophet['ds'].between('2022-06-07', '2022-06-09'), 'y'] = None<br/>    train_prophet['new_year_peak'] = (train_prophet['ds'] &gt;= '2022-01-01') &amp;\<br/>                                     (train_prophet['ds'] &lt;= '2022-02-14')<br/>    m.add_regressor('new_year_peak')<br/>    # setting logistic upper and lower bounds<br/>    train_prophet['cap'] = dau_true.max() * 1.1<br/>    train_prophet['floor'] = 0<br/><br/>    m.fit(train_prophet)<br/><br/>    periods = len(pd.date_range(prediction_start, prediction_end))<br/>    future = m.make_future_dataframe(periods=periods)<br/>    future['new_year_peak'] = (future['ds'] &gt;= '2022-01-01') &amp; (future['ds'] &lt;= '2022-02-14')<br/>    future['cap'] = dau_true.max() * 1.1<br/>    future['floor'] = 0<br/>    pred = m.predict(future)<br/><br/>    if show_plot:<br/>        m.plot(pred);<br/><br/>    # converting the predictions to an appropriate format<br/>    pred = pred\<br/>        .assign(yhat=lambda _df: _df['yhat'].astype(int))\<br/>        .rename(columns={'ds': 'date', 'yhat': 'count'})\<br/>        .set_index('date')\<br/>        .clip(lower=0)\<br/>        ['count']\<br/>        .loc[lambda s: (s.index &gt;= prediction_start) &amp; (s.index &lt;= prediction_end)]<br/><br/>    return pred</span></pre><p id="2386" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The fact that the code turns out to be quite sophisticated indicates that one can’t simply apply <code class="cx oh oi oj ok b">prophet</code> to the DAU time-series.</p><p id="7e19" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Hereafter we test a prediction for multiple predicting horizons: 3, 6, and 12 months. As a result, we get 3 test sets:</p><ul class=""><li id="b25f" class="nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa ql pb pc bk">3-months horizon: <code class="cx oh oi oj ok b">2023-08-01</code> - <code class="cx oh oi oj ok b">2023-10-31</code>,</li><li id="3784" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">6-months horizon: <code class="cx oh oi oj ok b">2023-05-01</code> - <code class="cx oh oi oj ok b">2023-10-31</code>,</li><li id="d322" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">1-year horizon: <code class="cx oh oi oj ok b">2022-11-01</code> - <code class="cx oh oi oj ok b">2023-10-31</code>.</li></ul><p id="d048" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">For each test set we calculate the <a class="af ob" href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error" rel="noopener ugc nofollow" target="_blank">MAPE</a> loss function.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="54d8" class="qc mk fq ok b bg qd qe l qf qg">from sklearn.metrics import mean_absolute_percentage_error<br/><br/>mapes = []<br/>prediction_end = '2023-10-31'<br/>prediction_horizon = [3, 6, 12]<br/><br/>for offset in prediction_horizon:<br/>    prediction_start = pd.to_datetime(prediction_end) - pd.DateOffset(months=offset - 1)<br/>    prediction_start = prediction_start.replace(day=1)<br/>    prediction_end = '2023-10-31'<br/>    pred = predict_dau_prophet(prediction_start, prediction_end, dau_true['dau'], show_plot=False)<br/>    mape = mean_absolute_percentage_error(dau_true['dau'].reindex(pred.index), pred)<br/>    mapes.append(mape)<br/><br/>mapes = pd.DataFrame({'horizon': prediction_horizon, 'MAPE': mapes})<br/>mapes</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qq"><img src="../Images/fde884739a1ba0e70bd009db56aaeda1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IDKv5izzXgCIIEO2BNRO6Q.png"/></div></div></figure><p id="d9e4" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The MAPE error turns out to be high: 18% — 35%. The fact that the shortest horizon has the highest error means that the model is tuned for the long-term predictions. This is another inconvenience of such an approach: we have to tune the model for each prediction horizon. Anyway, this is our baseline. In the next section we’ll compare it with more advanced models.</p><h2 id="767a" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">4.2 General evaluation</h2><p id="f595" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">In this section we evaluate the model implemented in the <a class="af ob" href="#5dc8" rel="noopener ugc nofollow">Section 3.6</a>. So far we set the transition period as 1 year before the prediction start. We’ll study how the prediction depends on the transition period in the <a class="af ob" href="#0637" rel="noopener ugc nofollow">Section 4.3</a>. As for the new users, we run the model using two options: the real values and the predicted ones. Similarly, we fix the same 3 prediction horizons and test the model on them.</p><p id="20fa" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The <code class="cx oh oi oj ok b">make_predicion</code> helper function below implements the described options. It accepts <code class="cx oh oi oj ok b">prediction_start</code>, <code class="cx oh oi oj ok b">prediction_end</code> arguments defining the prediction period for a given horizon, <code class="cx oh oi oj ok b">new_users_mode</code> which can be either <code class="cx oh oi oj ok b">true</code> or <code class="cx oh oi oj ok b">predict</code>, and <code class="cx oh oi oj ok b">transition_period</code>. The options of the latter argument will be explained further.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="c022" class="qc mk fq ok b bg qd qe l qf qg">import re<br/><br/><br/>def make_prediction(prediction_start, prediction_end, new_users_mode='predict', transition_period='last_30d'):<br/>    prediction_start_minus_1d = pd.to_datetime(prediction_start) - pd.Timedelta('1d')<br/>    state0 = get_state0(prediction_start_minus_1d)<br/>    <br/>    if new_users_mode == 'predict':<br/>        new_users_pred = predict_new_users(prediction_start, prediction_end, new_users, show_plot=False)<br/>    elif new_users_mode == 'true':<br/>        new_users_pred = new_users.copy()<br/><br/>    if transition_period.startswith('last_'):<br/>        shift = int(re.search(r'last_(\d+)d', transition_period).group(1))<br/>        transitions_start = pd.to_datetime(prediction_start) - pd.Timedelta(shift, 'd')<br/>        M = get_transition_matrix(transitions, transitions_start, prediction_start_minus_1d)<br/>        dau_pred = predict_dau(M, state0, prediction_start, prediction_end, new_users_pred)<br/>    else:<br/>        transitions_start = pd.to_datetime(prediction_start) - pd.Timedelta(240, 'd')<br/>        M_base = get_transition_matrix(transitions, transitions_start, prediction_start_minus_1d)<br/>        dau_pred = pd.DataFrame()<br/><br/>        month_starts = pd.date_range(prediction_start, prediction_end, freq='1MS')<br/>        N = len(month_starts)<br/><br/>        for i, prediction_month_start in enumerate(month_starts):<br/>            prediction_month_end = pd.offsets.MonthEnd().rollforward(prediction_month_start)<br/>            transitions_month_start = prediction_month_start - pd.Timedelta('365D')<br/>            transitions_month_end = prediction_month_end - pd.Timedelta('365D')<br/><br/>            M_seasonal = get_transition_matrix(transitions, transitions_month_start, transitions_month_end)<br/>            if transition_period == 'smoothing':<br/>                i = min(i, 12)<br/>                M = M_seasonal * i / (N - 1)  + (1 - i / (N - 1)) * M_base<br/>            elif transition_period.startswith('seasonal_'):<br/>                seasonal_coef = float(re.search(r'seasonal_(0\.\d+)', transition_period).group(1))<br/>                M = seasonal_coef * M_seasonal + (1 - seasonal_coef) * M_base<br/>            <br/>            dau_tmp = predict_dau(M, state0, prediction_month_start, prediction_month_end, new_users_pred)<br/>            dau_pred = pd.concat([dau_pred, dau_tmp])<br/><br/>            state0 = dau_tmp.loc[prediction_month_end][states_order]<br/><br/>    return dau_pred<br/><br/>def prediction_details(dau_true, dau_pred, show_plot=True, ax=None):<br/>    y_true = dau_true.reindex(dau_pred.index)['dau']<br/>    y_pred = dau_pred['dau']<br/>    mape = mean_absolute_percentage_error(y_true, y_pred) <br/><br/>    if show_plot:<br/>        prediction_start = str(y_true.index.min().date())<br/>        prediction_end = str(y_true.index.max().date())<br/>        if ax is None:<br/>            y_true.plot(label='DAU true')<br/>            y_pred.plot(label='DAU pred')<br/>            plt.title(f'DAU prediction, {prediction_start} - {prediction_end}')<br/>            plt.legend()<br/>        else:<br/>            y_true.plot(label='DAU true', ax=ax)<br/>            y_pred.plot(label='DAU pred', ax=ax)<br/>            ax.set_title(f'DAU prediction, {prediction_start} - {prediction_end}')<br/>            ax.legend()<br/>    return mape</span></pre><p id="1795" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">In total, we have 6 prediction scenarios: 2 options for new users and 3 prediction horizons. The diagram below illustrates the results. The charts on the left relate to the <code class="cx oh oi oj ok b">new_users_mode = 'predict'</code> option, while the right ones relate to the <code class="cx oh oi oj ok b">new_users_mode = 'true'</code> option.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="f921" class="qc mk fq ok b bg qd qe l qf qg">fig, axs = plt.subplots(3, 2, figsize=(15, 6))<br/>mapes = []<br/>prediction_end = '2023-10-31'<br/>prediction_horizon = [3, 6, 12]<br/><br/>for i, offset in enumerate(prediction_horizon):<br/>    prediction_start = pd.to_datetime(prediction_end) - pd.DateOffset(months=offset - 1)<br/>    prediction_start = prediction_start.replace(day=1)<br/>    args = {<br/>        'prediction_start': prediction_start,<br/>        'prediction_end': prediction_end,<br/>        'transition_period': 'last_365d'<br/>    }<br/>    for j, new_users_mode in enumerate(['predict', 'true']):<br/>        args['new_users_mode'] = new_users_mode<br/>        dau_pred = make_prediction(**args)<br/>        mape = prediction_details(dau_true, dau_pred, ax=axs[i, j])<br/>        mapes.append([offset, new_users_mode, mape])<br/><br/>mapes = pd.DataFrame(mapes, columns=['horizon', 'new_users', 'MAPE'])<br/>plt.tight_layout()</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qr"><img src="../Images/d4b663fdf3b9e441c5f502857f49d6b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2tlgRVrGc_aDjRNdYii_9g.png"/></div></div></figure><p id="8ba0" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">And here are the MAPE values summarizing the prediction quality:</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="0059" class="qc mk fq ok b bg qd qe l qf qg">mapes.pivot(index='horizon', columns='new_users', values='MAPE')</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om on"><img src="../Images/67d12d573e59424179102793f145476a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GX0FfctDtEPiQvBey-IPaQ.png"/></div></div></figure><p id="b315" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">We notice multiple things.</p><ul class=""><li id="2326" class="nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa ql pb pc bk">In general, the model demonstrates much better results than the baseline. Indeed, the baseline is based on the historical DAU data only, while the model uses the user states information.</li><li id="91df" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">However, for the 1-year horizon and <code class="cx oh oi oj ok b">new_users_mode='predict'</code> the MAPE error is huge: 65%. This is 3 times higher than the corresponding baseline error (21%). On the other hand, <code class="cx oh oi oj ok b">new_users_mode='true'</code> option gives a much better result: 8%. It means that the new users prediction has a huge impact on the model, especially for long-term predictions. For the shorter periods the difference is less dramatic. The major reason for such a difference is that 1-year period includes Christmas with its extreme values. As a result, i) it's hard to predict such high new user values, ii) the period heavily impacts user behavior, the transition matrix and, consequently, DAU values. Hence, we strongly recommend to implement the new user prediction carefully. The baseline model was specially tuned for this Christmas period, so it's not surprising that it outperforms the Markov model.</li><li id="ac5c" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">When the new users prediction is accurate, the model captures trends well. It means that using last 365 days for the transition matrix calculation is a reasonable choice.</li><li id="8c5d" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">Interestingly, the true new users data provides worse results for the 3-months prediction. This is nothing but a coincidence. The wrong new users prediction in October 2023 reversed the predicted DAU trend and made MAPE a bit lower.</li></ul><p id="7ecc" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Now, let’s decompose the prediction error and see which states contribure the most. By error we mean here <code class="cx oh oi oj ok b">dau_pred</code> - <code class="cx oh oi oj ok b">dau_true</code> values, by relative error - ( <code class="cx oh oi oj ok b">dau_pred</code> - <code class="cx oh oi oj ok b">dau_true</code>) / <code class="cx oh oi oj ok b">dau_true</code> - see left and right diagrams below correspondingly. In order to focus on this aspect, we'll narrow the configuration to the 3-months prediction horizon and the <code class="cx oh oi oj ok b">new_users_mode='true'</code> option.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="07cd" class="qc mk fq ok b bg qd qe l qf qg">dau_component_cols = ['new', 'current', 'reactivated', 'resurrected']<br/><br/>dau_pred = make_prediction('2023-08-01', '2023-10-31', new_users_mode='true', transition_period='last_365d')<br/>figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))<br/><br/>dau_pred[dau_component_cols]\<br/>    .subtract(dau_true[dau_component_cols])\<br/>    .reindex(dau_pred.index)\<br/>    .plot(title='Prediction error by state', ax=ax1)<br/><br/>dau_pred[['current']]\<br/>    .subtract(dau_true[['current']])\<br/>    .div(dau_true[['current']])\<br/>    .reindex(dau_pred.index)\<br/>    .plot(title='Relative prediction error (current state)', ax=ax2);</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qs"><img src="../Images/bf9cbc3945f5e93adb2b3bd873e2df2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jGx4NxaaMzY8cW27xCuehg.png"/></div></div></figure><p id="f862" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">From the left chart we notice that the error is basically contributed by the <code class="cx oh oi oj ok b">current</code> state. It's not surprising since this state contributes to DAU the most. The error for the <code class="cx oh oi oj ok b">reactivated</code>, and <code class="cx oh oi oj ok b">resurrected</code> states is quite low. Another interesting thing is that this error is mostly negative for the <code class="cx oh oi oj ok b">current</code> state and mostly positive for the <code class="cx oh oi oj ok b">resurrected</code> state. The former might be explained by the fact that the new users who appeared in the prediction period are more engaged that the users from the past. The latter indicates that the <code class="cx oh oi oj ok b">resurrected</code> users in reality contribute to DAU less than the transition matrix expects, so the <code class="cx oh oi oj ok b">dormant</code>→ <code class="cx oh oi oj ok b">resurrected</code> conversion rate is overestimated.</p><p id="9779" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">As for the relative error, it makes sense to analyze it for the <code class="cx oh oi oj ok b">current</code> state only. This is because the daily amount of the reactivated and resurrected states are low so the relative error is high and noisy. The relative error for the <code class="cx oh oi oj ok b">current</code> state varies between -25% and 4% which is quite high. And since we've fixed the new users prediction, this error is explained by the transition matrix inaccuracy only. In particular, the <code class="cx oh oi oj ok b">current</code>→ <code class="cx oh oi oj ok b">current</code> conversion rate is roughly 0.8 which is high and, as a result, it contributes to the error a lot. So if we want to improve the prediction we need to consider tuning this conversion rate foremost.</p><h2 id="0637" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">4.3 Transitions period impact</h2><p id="5a1b" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">In the previous section we kept the transitions period fixed: 1 year before a prediction start. Now we’re going to study how long this period should be to get more accurate prediction. We consider the same prediction horizons of 3, 6, and 12 months. In order to mitigate the noise from the new users prediction, we use the real values of the new users amount: <code class="cx oh oi oj ok b">new_users_mode='true'</code>.</p><p id="2a90" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Here comes varying of the <code class="cx oh oi oj ok b">transition_period</code> argument. Its values are masked with the <code class="cx oh oi oj ok b">last_&lt;N&gt;d</code> pattern where <code class="cx oh oi oj ok b">N</code> stands for the number of days in a transitions period. For each prediction horizon we calculate 12 different transition periods of 1, 2, ..., 12 months. Then we calculate the MAPE error for each of the options and plot the results.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="64df" class="qc mk fq ok b bg qd qe l qf qg">result = []<br/><br/>for prediction_offset in prediction_horizon:<br/>    prediction_start = pd.to_datetime(prediction_end) - pd.DateOffset(months=prediction_offset - 1)<br/>    prediction_start = prediction_start.replace(day=1)<br/><br/>    for transition_offset in range(1, 13):<br/>        dau_pred = make_prediction(<br/>            prediction_start, prediction_end, new_users_mode='true',<br/>            transition_period=f'last_{transition_offset*30}d'<br/>        )<br/>        mape = prediction_details(dau_true, dau_pred, show_plot=False)<br/>        result.append([prediction_offset, transition_offset, mape])<br/>result = pd.DataFrame(result, columns=['prediction_period', 'transition_period', 'mape'])<br/><br/>result.pivot(index='transition_period', columns='prediction_period', values='mape')\<br/>    .plot(title='MAPE by prediction and transition period');</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qt"><img src="../Images/011526da7ab75ad565b95a1720864d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qeC8RXnYtfF74NpBIUfUOQ.png"/></div></div></figure><p id="8ed0" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">It turns out that the optimal transitions period depends on the prediction horizon. Shorter horizons require shorter transitions periods: the minimal MAPE error is achieved at 1, 4, and 8 transition periods for the 3, 6, and 12 months correspondingly. Apparently, this is because the longer horizons contain some seasonal effects that could be captured only by the longer transitions periods. Also, it seems that for the longer prediction horizons the MAPE curve is U-shaped meaning that too long and too short transitions periods are both not good for the prediction. We’ll develop this idea in the next section.</p><h2 id="c8fc" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">4.4 Obsolence and seasonality</h2><p id="72aa" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Nevertheless, fixing a single transition matrix for predicting the whole year ahead doesn’t seem to be a good idea: such a model would be too rigid. Usually, user behavior varies depending on a season. For example, users who appear after Christmas might have some shifts in behavior. Another typical situation is when users change their behavior in summer. In this section, we’ll try to take into account these seasonal effects.</p><p id="3618" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">So we want to predict DAU for 1 year ahead starting from November 2022. Instead of using a single transition matrix <code class="cx oh oi oj ok b">M_base</code> which is calculated for the last 8 months before the prediction start, according to the previous subsection results (and labeled as the <code class="cx oh oi oj ok b">last_240d</code> option below), we'll consider a mixture of this matrix and a seasonal one <code class="cx oh oi oj ok b">M_seasonal</code>. The latter is calculated on monthly basis lagging 1 year behind. For example, to predict DAU for November 2022 we define <code class="cx oh oi oj ok b">M_seasonal</code> as the transition matrix for November 2021. Then we shift the prediction horizon to December 2022 and calculate <code class="cx oh oi oj ok b">M_seasonal</code> for December 2021, etc.</p><p id="079f" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">In order to mix <code class="cx oh oi oj ok b">M_base</code> and <code class="cx oh oi oj ok b">M_seasonal</code> we define the following two options.</p><ul class=""><li id="1e70" class="nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa ql pb pc bk"><code class="cx oh oi oj ok b">seasonal_0.3</code>: M = 0.3 * <code class="cx oh oi oj ok b">M_seasonal</code> + 0.7 * <code class="cx oh oi oj ok b">M_base</code>. 0.3 is a weight that was chosen as a local minimum after some experiments.</li><li id="ed14" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk"><code class="cx oh oi oj ok b">smoothing</code>: M = i/(N-1) * <code class="cx oh oi oj ok b">M_seasonal</code> + (1 - i/(N - 1)) * <code class="cx oh oi oj ok b">M_base</code> where N is the number of months within the predicting period, i = 0, …, N - 1 - the month index. The idea of this configuration is to gradually switch from the most recent transition matrix <code class="cx oh oi oj ok b">M_base</code> to seasonal ones as the prediction month moves forward from the prediction start.</li></ul><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="0494" class="qc mk fq ok b bg qd qe l qf qg">result = pd.DataFrame()<br/>for transition_period in ['last_240d', 'seasonal_0.3', 'smoothing']:<br/>    result[transition_period] = make_prediction(<br/>        '2022-11-01', '2023-10-31',<br/>        'true',<br/>        transition_period<br/>    )['dau']<br/>result['true'] = dau_true['dau']<br/>result['true'] = result['true'].astype(int)<br/>result.plot(title='DAU prediction by different transition matrices');</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qu"><img src="../Images/6fda5e3857f98bc9a778ca757cc1d48d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZrRv71gr3_36ssoFlWhE3g.png"/></div></div></figure><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="53f3" class="qc mk fq ok b bg qd qe l qf qg">mape = pd.DataFrame()<br/>for col in result.columns:<br/>    if col != 'true':<br/>        mape.loc[col, 'mape'] = mean_absolute_percentage_error(result['true'], result[col])<br/>mape</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qo"><img src="../Images/e4f9865ed7eb29fbb478d7f4fd129e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_cwTRpOtAlKpqDMr75IlOw.png"/></div></div></figure><p id="3dc2" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">According to the MAPE errors, <code class="cx oh oi oj ok b">seasonal_0.3</code> configuration provides the best results. Interestingly, <code class="cx oh oi oj ok b">smoothing</code> approach has appeared to be even worse than the <code class="cx oh oi oj ok b">last_240d</code>. From the diagram above we see that all three models start to underestimate the DAU values in July 2023, especially the <code class="cx oh oi oj ok b">smoothing</code> model. It seems that the new users who started appearing in July 2023 are more engaged than the users from 2022. Probably, the app was improved sufficiently or the marketing team did a great job. As a result, the <code class="cx oh oi oj ok b">smoothing</code> model that much relies on the outdated transitions data from July 2022 - October 2022 fails more than the other models.</p><h2 id="8d96" class="pi mk fq bf ml pj pk pl mo pm pn po mr no pp pq pr ns ps pt pu nw pv pw px py bk">4.5 Final solution</h2><p id="7a9e" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">To sum things up, let’s make a final prediction for the 2024 year. We use the <code class="cx oh oi oj ok b">seasonal_0.3</code> configuration and the predicted values for new users.</p><pre class="oo op oq or os pz ok qa bp qb bb bk"><span id="f2cf" class="qc mk fq ok b bg qd qe l qf qg">dau_pred = make_prediction(<br/>    PREDICTION_START, PREDICTION_END,<br/>    new_users_mode='predict',<br/>    transition_period='seasonal_0.3'<br/>)<br/>dau_true['dau'].plot(label='true')<br/>dau_pred['dau'].plot(label='seasonal_0.3')<br/>plt.title('DAU, historical &amp; predicted')<br/>plt.axvline(PREDICTION_START, color='k', linestyle='--')<br/>plt.legend();</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qv"><img src="../Images/3a5bc393283104377c72bb28ccdbc8d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZLm5RMB7E7qN_3UWlJZJw.png"/></div></div></figure><h1 id="8273" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">5. Discussion</h1><p id="0804" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">In the <a class="af ob" href="#1375" rel="noopener ugc nofollow">Section 4</a> we studied the model performance from the prediction accuracy perspective. Now let’s discuss the model from the practical point of view.</p><p id="62a7" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Besides poor accuracy, predicting DAU as a time-series (see the <a class="af ob" href="#0e38" rel="noopener ugc nofollow">Section 4.1</a>) makes this approach very stiff. Essentially, it makes a prediction in such a manner so it would fit <em class="qk">historical</em> data best. In practice, when making plans for a next year we usually have some certain expectations about the future. For example,</p><ul class=""><li id="fc18" class="nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa ql pb pc bk">the marketing team is going to launch some new more effective campaings,</li><li id="cb16" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">the activation team is planning to improve the onboarding process,</li><li id="36e1" class="nf ng fq nh b go pd nj nk gr pe nm nn no pf nq nr ns pg nu nv nw ph ny nz oa ql pb pc bk">the product team will release some new features that would engage and retain users more.</li></ul><p id="77f9" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Our model can take into account such expectations. For the examples above we can adjust the new users prediction, the <code class="cx oh oi oj ok b">new</code>→ <code class="cx oh oi oj ok b">current</code> and the <code class="cx oh oi oj ok b">current</code>→ <code class="cx oh oi oj ok b">current</code> conversion rates respectively. As a result, we can get a prediction that doesn't match with the historical data but nevertheless would be more realistic. This model's property is not just flexible - it's interpretable. You can easily discuss all these adjustments with the stakeholders, and they can understand how the prediction works.</p><p id="5984" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Another advantage of the model is that it doesn’t require predicting whether a certain user will be active on a certain day. Sometimes binary classifiers are used for this purpose. The downside of this approach is that we need to apply such a classifier to each user including all the dormant users and each day from a prediction horizon. This is a tremedous computational cost. In contrast, the Markov model requires only the initial amount of states ( <code class="cx oh oi oj ok b">state0</code>). Moreover, such classiffiers are often black-box models: they are poorly interpretable and hard to adjust.</p><p id="bfc9" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">The Markov model also has some limitations. As we already have seen, it’s sensitive to the new users prediction. It’s easy to totally ruin the prediction by a wrong new users amount. Another problem is that the Markov model is memoryless meaning that it doesn’t take into account the user’s history. For example, it doesn’t distinguish whether a <code class="cx oh oi oj ok b">current</code> user is a newbie, experienced, or <code class="cx oh oi oj ok b">reactivated</code>/ <code class="cx oh oi oj ok b">resurrected</code> one. The retention rate of these user types should be certainly different. Also, as we discussed earlier, the user behavior might be of different nature depending on the season, marketing sources, countries, etc. So far our model is not able to capture these differences. However, this might be a subject for further research: we could extend the model by fitting more transition matrices for different user segments.</p><p id="3208" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">Finally, as we promised in the introduction, we provide a <a class="af ob" href="https://docs.google.com/spreadsheets/d/1DxbjrkSy_wvU1lzlNWhrEfWO-Kq1tJrQw0izEHu5ULU/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">DAU spreadsheet calculator</a>. In the <code class="cx oh oi oj ok b">Prediction</code> sheet you'll need to fill the initial states distribution row (marked with blue) and the new users prediction column (marked with purple). In the <code class="cx oh oi oj ok b">Conversions</code> sheet you can adjust the transition matrix values. Remember that the sum of each row of the matrix should be equal to 1.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qw"><img src="../Images/2cf0749a67ff0865d79889e8e41789ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nH670_3JC8_4uul1.png"/></div></div></figure></div></div></div><div class="ab cb qx qy qz ra" role="separator"><span class="rb by bm rc rd re"/><span class="rb by bm rc rd re"/><span class="rb by bm rc rd"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="2354" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">That’s all for now. I hope that this article was useful for you. In case of any questions or suggestions, feel free to ask in the comments below or contact me directly on <a class="af ob" href="https://www.linkedin.com/in/vladimir-kukushkin-95b6487/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>.</p></div></div></div><div class="ab cb qx qy qz ra" role="separator"><span class="rb by bm rc rd re"/><span class="rb by bm rc rd re"/><span class="rb by bm rc rd"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="b8fe" class="pw-post-body-paragraph nf ng fq nh b go oc nj nk gr od nm nn no oe nq nr ns of nu nv nw og ny nz oa fj bk">All the images in the post are generated by the author.</p></div></div></div></div>    
</body>
</html>