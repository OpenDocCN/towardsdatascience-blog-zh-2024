<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Structured Generative AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Structured Generative AI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/structured-generative-ai-e772123428e4?source=collection_archive---------3-----------------------#2024-04-18">https://towardsdatascience.com/structured-generative-ai-e772123428e4?source=collection_archive---------3-----------------------#2024-04-18</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="80f9" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How to constrain your model to output defined formats</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@orenmatar?source=post_page---byline--e772123428e4--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Oren Matar" class="l ep by dd de cx" src="../Images/8b1fa6aa3585fc283d51828b53a0754c.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*oq69-9-IJCBKnNzJYPqnXA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e772123428e4--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@orenmatar?source=post_page---byline--e772123428e4--------------------------------" rel="noopener follow">Oren Matar</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e772123428e4--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 18, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="a3e0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this post I will explain and demonstrate the concept of “structured generative AI”: generative AI constrained to defined formats. By the end of the post, you will understand where and when it can be used and how to implement it whether you’re crafting a transformer model from scratch or utilizing Hugging Face’s models. Additionally, we will cover an important tip for tokenization that is especially relevant for structured languages.</p><p id="dfa3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">One of the many uses of generative AI is as a translation tool. This often involves translating between two human languages but can also include computer languages or formats. For example, your application may need to translate natural (human) language to SQL:</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="5c34" class="no np fq nl b bg nq nr l ns nt"><strong class="nl fr">Natural language</strong>: “Get customer names and emails of customers from the US”<br/><br/><strong class="nl fr">SQL</strong>: "SELECT name, email FROM customers WHERE country = 'USA'"</span></pre><p id="6978" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Or to convert text data into a JSON format:</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="1863" class="no np fq nl b bg nq nr l ns nt"><strong class="nl fr">Natural language</strong>: “I am John Doe, phone number is 555–123–4567,<br/>                   my friends are Anna and Sara”<br/><br/><strong class="nl fr">JSON</strong>: {name: "John Doe",<br/>       phone_number: "555–123–5678",<br/>       friends: {<br/>          name: [["Anna", "Sara"]]}<br/>      }</span></pre><p id="d401" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Naturally, many more applications are possible, for other structured languages. The training process for such tasks involves feeding examples of natural language alongside structured formats to an encoder-decoder model. Alternatively, leveraging a pre-trained Language Model (LLM) can suffice.</p><p id="9183" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">While achieving 100% accuracy is unattainable, there is one class of errors that we can eliminate: syntax errors. These are violations of the format of the language, like replacing commas with dots, using table names that are not present in the SQL schema, or omitting bracket closures, which render SQL or JSON non-executable.</p><p id="af01" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The fact that we’re translating into a structured language means that the list of legitimate tokens at every generation step is limited, and pre-determined. If we could insert this knowledge into the generative AI process we can avoid a wide range of incorrect results. This is the idea behind structured generative AI: constrain it to a list of legitimate tokens.</p><h2 id="0f7a" class="nu np fq bf nv nw nx ny nz oa ob oc od ms oe of og mw oh oi oj na ok ol om on bk"><strong class="al">A quick reminder on how tokens are generated</strong></h2><p id="dbbc" class="pw-post-body-paragraph mj mk fq ml b go oo mn mo gr op mq mr ms oq mu mv mw or my mz na os nc nd ne fj bk">Whether employing an encoder-decoder or GPT architecture, token generation operates sequentially. Each token’s selection relies on both the input and previously generated tokens, continuing until a &lt;end&gt; token is generated, signifying the completion of the sequence. At each step, a classifier assigns logit values to all tokens in the vocabulary, representing the probability of each token as the next selection. The next token is sampled based on those logits.</p><figure class="nf ng nh ni nj ow ot ou paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ot ou ov"><img src="../Images/cad3a2ae8eae2f7150a70bacdecbaa82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2guusXsUQWJ1tq_DhGCNA.png"/></div></div><figcaption class="pc pd pe ot ou pf pg bf b bg z dx">The decoder classifier assigns a logit to every token in the vocabulary (Image by author)</figcaption></figure><h2 id="9de6" class="nu np fq bf nv nw nx ny nz oa ob oc od ms oe of og mw oh oi oj na ok ol om on bk"><strong class="al">Limiting token generation</strong></h2><p id="757b" class="pw-post-body-paragraph mj mk fq ml b go oo mn mo gr op mq mr ms oq mu mv mw or my mz na os nc nd ne fj bk">To constrain token generation, we incorporate knowledge of the output language’s structure. Illegitimate tokens have their logits set to -inf, ensuring their exclusion from selection. For instance, if only a comma or “FROM” is valid after “Select name,” all other token logits are set to -inf.</p><p id="b2d2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If you’re using Hugging Face, this can be implemented using a “logits processor”. To use it you need to implement a class with a __call__ method, which will be called after the logits are calculated, but before the sampling. This method receives all token logits and generated input IDs, returning modified logits for all tokens.</p><figure class="nf ng nh ni nj ow ot ou paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ot ou ph"><img src="../Images/e92f5fbfb0e5b222e3b5b4571ae33971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MTnqJISDdRrB7VV7fdD3pA.png"/></div></div><figcaption class="pc pd pe ot ou pf pg bf b bg z dx">The logits returned from the logits processor: all illegitimate tokens get a value of -inf (Image by author)</figcaption></figure><p id="d5c4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">I’ll demonstrate the code with a simplified example. First, we initialize the model, we will use Bart in this case, but this can work with any model.</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="1a72" class="no np fq nl b bg nq nr l ns nt">from transformers import BartForConditionalGeneration, BartTokenizerFast, PreTrainedTokenizer<br/>from transformers.generation.logits_process import LogitsProcessorList, LogitsProcessor<br/>import torch<br/><br/>name = 'facebook/bart-large'<br/>tokenizer = BartTokenizerFast.from_pretrained(name, add_prefix_space=True)<br/>pretrained_model = BartForConditionalGeneration.from_pretrained(name)</span></pre><p id="3e15" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If we want to generate a translation from the natural language to SQL, we can run:</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="4d19" class="no np fq nl b bg nq nr l ns nt">to_translate = 'customers emails from the us'<br/>words = to_translate.split()<br/>tokenized_text = tokenizer([words], is_split_into_words=True)<br/><br/>out = pretrained_model.generate(<br/>    torch.tensor(tokenized_text["input_ids"]),<br/>    max_new_tokens=20,<br/>)<br/>print(tokenizer.convert_tokens_to_string(<br/>    tokenizer.convert_ids_to_tokens(<br/>        out[0], skip_special_tokens=True)))</span></pre><p id="9807" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Returning</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="29a5" class="no np fq nl b bg nq nr l ns nt">'More emails from the us'</span></pre><p id="12b1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Since we did not fine-tune the model for text-to-SQL tasks, the output does not resemble SQL. We will not train the model in this tutorial, but we will guide it to generate an SQL query. We will achieve this by employing a function that maps each generated token to a list of permissible next tokens. For simplicity, we’ll focus only on the immediate preceding token, but more complicated mechanisms are easy to implement. We will use a dictionary defining for each token, which tokens are allowed to follow it. E.g. The query must begin with “SELECT” or “DELETE”, and after “SELECT” only “name”, “email”, or ”id” are allowed since those are the columns in our schema.</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="3a17" class="no np fq nl b bg nq nr l ns nt">rules = {'&lt;s&gt;': ['SELECT', 'DELETE'], # beginning of the generation<br/> 'SELECT': ['name', 'email', 'id'],  # names of columns in our schema<br/> 'DELETE': ['name', 'email', 'id'],<br/> 'name': [',', 'FROM'],<br/> 'email': [',', 'FROM'],<br/> 'id': [',', 'FROM'],<br/> ',': ['name', 'email', 'id'],<br/> 'FROM': ['customers', 'vendors'],  # names of tables in our schema<br/> 'customers': ['&lt;/s&gt;'],<br/> 'vendors': ['&lt;/s&gt;'],  # end of the generation<br/>}</span></pre><p id="8181" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now we need to convert these tokens to the IDs used by the model. This will happen inside a class inheriting from LogitsProcessor.</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="711c" class="no np fq nl b bg nq nr l ns nt">def convert_token_to_id(token):<br/>    return tokenizer(token, add_special_tokens=False)['input_ids'][0]<br/><br/>class SQLLogitsProcessor(LogitsProcessor):<br/>    def __init__(self, tokenizer: PreTrainedTokenizer):<br/>        self.tokenizer = tokenizer<br/>        self.rules = {convert_token_to_id(k): [convert_token_to_id(v0) for v0 in v] for k,v in rules.items()}</span></pre><p id="e1e9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Finally, we will implement the __call__ function, which is called after the logits are calculated. The function creates a new tensor of -infs, checks which IDs are legitimate according to the rules (the dictionary), and places their scores in the new tensor. The result is a tensor that only has valid values for the valid tokens.</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="c5b3" class="no np fq nl b bg nq nr l ns nt">class SQLLogitsProcessor(LogitsProcessor):<br/>    def __init__(self, tokenizer: PreTrainedTokenizer):<br/>        self.tokenizer = tokenizer<br/>        self.rules = {convert_token_to_id(k): [convert_token_to_id(v0) for v0 in v] for k,v in rules.items()}<br/><br/>    def __call__(self, input_ids: torch.LongTensor, scores: torch.LongTensor):<br/>        if not (input_ids == self.tokenizer.bos_token_id).any():<br/>        # we must allow the start token to appear before we start processing<br/>            return scores<br/>        # create a new tensor of -inf<br/>        new_scores = torch.full((1, self.tokenizer.vocab_size), float('-inf'))<br/>        # ids of legitimate tokens<br/>        legit_ids = self.rules[int(input_ids[0, -1])]<br/>        # place their values in the new tensor<br/>        new_scores[:, legit_ids] = scores[0, legit_ids]<br/>        return new_scores</span></pre><p id="d14a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">And that’s it! We can now run a generation with the logits-processor:</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="3692" class="no np fq nl b bg nq nr l ns nt">to_translate = 'customers emails from the us'<br/>words = to_translate.split()<br/>tokenized_text = tokenizer([words], is_split_into_words=True, return_offsets_mapping=True)<br/><br/>logits_processor = LogitsProcessorList([SQLLogitsProcessor(tokenizer)])<br/><br/>out = pretrained_model.generate(<br/>    torch.tensor(tokenized_text["input_ids"]),<br/>    max_new_tokens=20,<br/>    logits_processor=logits_processor<br/>)<br/>print(tokenizer.convert_tokens_to_string(<br/>    tokenizer.convert_ids_to_tokens(<br/>        out[0], skip_special_tokens=True)))</span></pre><p id="87b2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Returning</p><pre class="nf ng nh ni nj nk nl nm bp nn bb bk"><span id="f91c" class="no np fq nl b bg nq nr l ns nt"> SELECT email , email , id , email FROM customers</span></pre><p id="f6df" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The outcome is a little strange, but remember: <strong class="ml fr">we didn’t even train the model!</strong> We only enforced token generation based on specific rules. Notably, constraining generation doesn’t interfere with training; constraints only apply during generation post-training. Thus, when appropriately implemented, these constraints can only enhance generation accuracy.</p><p id="44d9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Our simplistic implementation falls short of covering all the SQL syntax. A real implementation must support more syntax, potentially considering not just the last token but several, and enable batch generation. Once these enhancements are in place, our trained model can reliably generate executable SQL queries, constrained to valid table and column names from the schema. A Similar approach can enforce constraints in generating JSON, ensuring key presence and bracket closure.</p><h2 id="44ac" class="nu np fq bf nv nw nx ny nz oa ob oc od ms oe of og mw oh oi oj na ok ol om on bk"><strong class="al">Be careful of tokenization</strong></h2><p id="3eae" class="pw-post-body-paragraph mj mk fq ml b go oo mn mo gr op mq mr ms oq mu mv mw or my mz na os nc nd ne fj bk">Tokenization is often overlooked but correct tokenization is crucial when using generative AI for structured output. However, under the hood, tokenization can make an impact on the training of your model. For example, you may fine-tune a model to translate text into a JSON. As part of the fine-tuning process, you provide the model with examples of text-JSON pairs, which it tokenizes. What will this tokenization look like?</p><figure class="nf ng nh ni nj ow ot ou paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ot ou pi"><img src="../Images/dc9052660570390852112c1180650f1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pF9BczoClFTLQMGuKJI-Lg.png"/></div></div><figcaption class="pc pd pe ot ou pf pg bf b bg z dx">(Image by author)</figcaption></figure><p id="416b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">While you read “[[“ as two square brackets, the tokenizer converts them into a single ID, which will be treated as a completely distinct class from the single bracket by the token classifier. This makes the entire logic that the model must learn — more complicated (for example, remembering how many brackets to close). Similarly, adding a space before words may change their tokenization and their class ID. For instance:</p><figure class="nf ng nh ni nj ow ot ou paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ot ou pj"><img src="../Images/756198370ecbaaf8710bcdb24c8ccf3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q6o1RoGZJmjlp36DARMNEQ.png"/></div></div><figcaption class="pc pd pe ot ou pf pg bf b bg z dx">(Image by author)</figcaption></figure><p id="fc5c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Again, this complicates the logic the model will have to learn since the weights connected to each of these IDs will have to be learned separately, for slightly different cases.</p><p id="9abd" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For simpler learning, ensure each concept and punctuation is consistently converted to the same token, by adding spaces before words and characters.</p><figure class="nf ng nh ni nj ow ot ou paragraph-image"><div role="button" tabindex="0" class="ox oy ed oz bh pa"><div class="ot ou pk"><img src="../Images/ce09edd397c68277a6d2ddf93b2cb378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hDxFwqWAH585-b5WaYY_bw.png"/></div></div><figcaption class="pc pd pe ot ou pf pg bf b bg z dx">Spaced-out words lead to more consistent tokenization (Image by author)</figcaption></figure><p id="50f9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Inputting spaced examples during fine-tuning simplifies the patterns the model has to learn, enhancing model accuracy. During prediction, the model will output the JSON with spaces, which you can then remove before parsing.</p><h2 id="e13b" class="nu np fq bf nv nw nx ny nz oa ob oc od ms oe of og mw oh oi oj na ok ol om on bk"><strong class="al">Summary</strong></h2><p id="0b72" class="pw-post-body-paragraph mj mk fq ml b go oo mn mo gr op mq mr ms oq mu mv mw or my mz na os nc nd ne fj bk">Generative AI offers a valuable approach for translating into a formatted language. By leveraging the knowledge of the output structure, we can constrain the generative process, eliminating a class of errors and ensuring the executability of queries and parse-ability of data structures.</p><p id="8949" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Additionally, these formats may use punctuation and keywords to signify certain meanings. Making sure that the tokenization of these keywords is consistent can dramatically reduce the complexity of the patterns that the model has to learn, thus reducing the required size of the model and its training time, while increasing its accuracy.</p><p id="a0bd" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Structured generative AI can effectively translate natural language into any structured format. These translations enable information extraction from text or query generation, which is a powerful tool for numerous applications.</p></div></div></div></div>    
</body>
</html>