- en: How to Find Yourself in a Digital World
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-find-yourself-in-a-digital-world-f58580a69c6a?source=collection_archive---------5-----------------------#2024-03-04](https://towardsdatascience.com/how-to-find-yourself-in-a-digital-world-f58580a69c6a?source=collection_archive---------5-----------------------#2024-03-04)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**The probabilistic approach to self-locate under uncertainty**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@edenoosh15?source=post_page---byline--f58580a69c6a--------------------------------)[![Eden
    B.](../Images/058b30695c237ec5f19bd7177d2f17d3.png)](https://medium.com/@edenoosh15?source=post_page---byline--f58580a69c6a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f58580a69c6a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f58580a69c6a--------------------------------)
    [Eden B.](https://medium.com/@edenoosh15?source=post_page---byline--f58580a69c6a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f58580a69c6a--------------------------------)
    ·8 min read·Mar 4, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '**Table of contents:**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is localization and why does a robot need it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are probabilistic tools used to compute localization?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'End-to-end example: how to use bayesian algorithms to determine a robot’s position
    under uncertainty?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can autonomous cars stay within a single lane at 60mph? How can an i-robot
    avoid falling down the stairs? How can delivery robots know if they are going
    to the right hungry customer? These are just a few of the questions autonomous
    vehicles must answer without human intervention.
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. What is localization? And why does a robot need it?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you might imagine, accurate vehicle location is critical to whether the autonomous
    vehicle effectively and safely completes its tasks. **The process to estimate
    the vehicle’s position from sensor data is called localization**. Localization
    accuracy increases with sensors that add information and decreases with the vehicle’s
    movement which adds noise.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Why are probabilistic tools used to compute localization?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Probabilistic tools can be leveraged to improve location accuracy where neither
    the sensors nor the movement is 100% accurate.
  prefs: []
  type: TYPE_NORMAL
- en: '**What is probability?**'
  prefs: []
  type: TYPE_NORMAL
- en: According to the dictionary definition, probability is a “numerical description
    of how likely an event is to occur” (wikipedia). However, when it comes to the
    meaning of probability, the answer is not that simple. There are rivaling interpretations
    to probability from two major camps, the frequentists and bayesians.
  prefs: []
  type: TYPE_NORMAL
- en: The **Frequentist** approach interprets probability as the relative frequency
    over time; how many times will I get my desired outcome if I repeat an experiment
    many times?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This approach is objective because anyone who runs the experiments (e.g. flipping
    a coin) will get the same result in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: The **Bayesian** approach interprets probability as the degree of certainty
    that an event will happen. How certain am I that I will get my desired outcome
    given expert knowledge and the available data? This approach is subjective, as
    it represents the current state of belief by combining (subjective) previous knowledge
    and experimental data known to date. It allows estimating the probability of a
    singular event that we can’t run many times, where the frequentist meaning doesn’t
    apply.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For example, if the probability that a date texts you back after your first
    meetup is 0.8, then we are 80% certain that you had a great time and the person
    will text you back; we *don’t* mean they will text 80% of the time if you repeat
    the first date over and over again.
  prefs: []
  type: TYPE_NORMAL
- en: '**What are the benefits of bayesian probability?**'
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian probability allows us to both quantify our degree of belief and to
    update it in light of new evidence.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ae54596cd348be3dfdc294acfd1e8e91.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Bayes’ theorem: update the robot’s position hypothesis P(H), also known as
    the prior, according to evidence E from the sensors, to return P(H|E), also known
    as the posterior'
  prefs: []
  type: TYPE_NORMAL
- en: In our context, P(H) is our initial guess of the robot‘s position, and P(H|E)
    is our updated guess after measuring the sensors’ evidence E.
  prefs: []
  type: TYPE_NORMAL
- en: The hypothesis probability distribution quantifies our certainty in the robot’s
    position.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/9070aa5cb63d64ee8dd17e1b12309777.png)'
  prefs: []
  type: TYPE_IMG
- en: '(1) uniform distribution: if we have no idea where the robot is, all locations
    are equally probable (2) normal distribution with mean= best guess and the spread
    = uncertainty'
  prefs: []
  type: TYPE_NORMAL
- en: The hypothesis can change according to evidence
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The more informative and accurate the sensors data, the bigger effect it will
    have. If the sensor is perfect, the robot’s position will align with the sensor’s
    reading, otherwise if the sensor data is very noisy or non-informative, the robot’s
    position will stay the same.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1f79d7cd3d4cbba353f4876123e123e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Updating our hypothesis: How different is the hypothesis after evidence P(H|E)
    from our initial belief P(H)?'
  prefs: []
  type: TYPE_NORMAL
- en: Updates can combine multiple sources of evidence
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We can formulate Bayes’ law to combine multiple data sources by using the chain
    rule, also known as the general product rule. It permits simplifying a joint distribution
    of multiple evidence to a product of conditional probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b1d0bdec6431340a5e1bed974efd5c8.png)'
  prefs: []
  type: TYPE_IMG
- en: Bayes’ theorem generalizes to cases with multiple evidence, E1 and E2, by applying
    the chain rule
  prefs: []
  type: TYPE_NORMAL
- en: For example, we often use GPS to navigate from our current location but GPS
    works best in clear skies and its accuracy is limited to a few meters. Autonomous
    cars can not solely rely on GPS to remain in a lane that is a few meters wide
    and to navigate in tunnels or underground parking lots. Autonomous vehicles can
    compensate for GPS deficiencies by adding more sources of information such as
    cameras.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. End-to-end example: how to use bayesian algorithms to determine the robot’s
    position under uncertainty?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s take a deep dive into a bayesian filter that recursively improves localization
    probability estimates using bayesian inference. The recursive nature means that
    the output of the filter at time t_0, P(H|E), serves as the hypothesis input for
    the next timestamp t_1, P(H).
  prefs: []
  type: TYPE_NORMAL
- en: Suppose a delivery robot is looping a circular path within a space station to
    transport supplies. The robot has a map detailing the lay of the land and the
    location of sensors.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7fc41faac9101fd4f240f2e3134af2a0.png)'
  prefs: []
  type: TYPE_IMG
- en: The robot’s map shows the route and the presence of sensors, beacon 1 with orange
    and beacon 2 with blue. The circular nature of the route leads the robot back
    to the beginning when it reaches the last bin. (Robot image generated with Dall-E)
  prefs: []
  type: TYPE_NORMAL
- en: '**- Problem definition:**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We refer to the estimated robot location as the **robot’s state space**. For
    example, a two-dimensional vector (i.e. an ordered pair of numbers) tracing x-axis
    position and x-axis velocity can track a robot location and changing speed in
    one-dimension. It is possible to extend the robot’s state space to additional
    dimensions to track multiple position dimensions (y, z), orientation, etc.
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we can assume our robot is moving with constant speed. The movement
    adds uncertainty to the computation, since it is not 100% reliable. The engine
    might fail to run at a specific velocity or the robot might encounter obstacles,
    which will cause the robot to overshoot or undershoot its expected movement.
  prefs: []
  type: TYPE_NORMAL
- en: Our robot will sense its location by measuring the presence of a beacon. The
    sensor readings, also called **measurement space**, are not 100% accurate. Sensors
    might confuse noise with a beacon signal that can lead to false alarms or fail
    to detect a signal at all.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cb2d0acb8d2ece708ebc85cc33829374.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The robot’s vectors: (1) state space vector showing the x position at time
    t (2) measurement space vector denoting the beacons’ presence at time t'
  prefs: []
  type: TYPE_NORMAL
- en: '**- The algorithm: histogram filter**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this bayesian filter the robot state space is represented by a histogram
    through a finite number of bins or regions. It is a discrete filter, meaning the
    robot can only be in one of these regions, and we compute the probability that
    the robot is in each. Additionally, within each bin, such as a 5 square meter
    area, the probability of being at any specific point is the same. If we want to
    increase the granularity, we must add more bins.
  prefs: []
  type: TYPE_NORMAL
- en: This filter is non parametric, meaning it does not make any strong assumptions
    on the robot’s state representation, and is not restricted to one type of distribution
    such as a Gaussian. It is able to represent complex location estimates, such as
    a multimodal hypothesis that keeps multiple best guesses, but it comes with a
    computational cost — an exponential complexity. In order to add an additional
    dimension, from 1-D to 2-D while keeping the same granularity, we will need 10x10
    bins, to move to 3-D we will need 10x10x10 bins, and so on. This is a significant
    limitation for robots that track multiple dimensions and are limited in memory
    and compute power.
  prefs: []
  type: TYPE_NORMAL
- en: '- Calculation:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Initial guess:** We start from an unknown location equipped with a map. At
    the beginning every region is equally probable, as represented by a uniform distribution
    across all bins.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/5227197166cefb9f14eb9484fb741664.png)'
  prefs: []
  type: TYPE_IMG
- en: The x position is divided into 10 discrete regions that represent the robot’s
    state. Initially, we have no information on where the robot is, so each region
    is equally likely with a probability of 1/10
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Movement function:** simulates the robot movement. The robot’s motion
    is stochastic, meaning it is not guaranteed to move to the desired bin at each
    time step. To update the robot’s location after each move, we calculate the probability
    of the robot being in each region at the next time step. This calculation considers
    both the probability of the robot to stay in the same region and the probability
    of it to move to a different region.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7014d8aedf1b50046e7671755e0d85de.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Movement function: assuming the robot moves one step at a time, what is the
    chance of a successful one-step move? There is a 95% chance the robot moved to
    the next bin, and a 5% chance it remained stationary'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the equation below, the robot’s one-step movement will not change
    the location estimate because of the uniform distribution, where each region has
    equal probability to stay and move.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3072ca7cb5b0ca70c20c58329d79e4fd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'What is the probability that the robot is in bin #2 after the robot moved one-step?'
  prefs: []
  type: TYPE_NORMAL
- en: Even if we initially begin at a bin with complete certainty (100%), the inherent
    randomness in movement will gradually add noise, leading us towards a uniform
    distribution over time. We need to add information!
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Sense function:** incorporates measurements that add information using
    Bayes’ theorem.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The sensors reliability is represented with probabilities, since they are not
    100% accurate. The equations below demonstrate that when the sensor detects the
    color orange, there is a 90% probability that the robot is located in an orange
    bin, and a 10% probability that the sensor is wrong and the robot is actually
    in a blue bin.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17df2383c508fc904bee9f774abb0239.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Sense function: what is the probability that the robot sensed “orange” given
    it’s in an orange bin?'
  prefs: []
  type: TYPE_NORMAL
- en: The calculation presented below illustrates that, in contrast to movement, sensors
    contribute information and improve our understanding of the robot’s location.
    For instance, because bin 2 is not orange, the probability of the robot being
    in it diminishes from 0.1 to 0.02.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88fd3b1c7ab4461b0249b3d7f6883326.png)'
  prefs: []
  type: TYPE_IMG
- en: What is the probability that the robot is in the second bin, given that the
    robot sensed “orange” ?
  prefs: []
  type: TYPE_NORMAL
- en: The image below shows the updated location hypothesis after incorporating movement
    and sensors’ data to our initial guess.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/32d397f92077cfbcf16f2ac87b69b351.png)'
  prefs: []
  type: TYPE_IMG
- en: Thanks to the sense function after one step we have a bit more certainty of
    where the robot is. We need more steps to increase the certainty among the orange
    bins.
  prefs: []
  type: TYPE_NORMAL
- en: '**Final thoughts**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Where is the robot? We can continuously refine our answer to this question by
    using recursive bayesian filters, starting from a uniform distribution that keeps
    all guesses equally probable until settling on the most likely one.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian filters help us measure our confidence in the robot’s whereabouts,
    updating this belief by integrating (noisy) sensor data with prior information
    (the estimated robot’s position after movement).
  prefs: []
  type: TYPE_NORMAL
- en: 'Sources:'
  prefs: []
  type: TYPE_NORMAL
- en: These are my summary notes from the first lectures of the highly recommend edX
    course “[Bayesian algorithms for Self-Driving Vehicles](https://learning.edx.org/course/course-v1:IsraelX+ACD_RFP4_ARIEL_Nivut+2T2023/home)”
    by [Dr.Roi Yozevitch](https://www.yozevitch.com/yozevitch-homepage-1).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Probabilistic Robotics](https://calvinfeng.gitbook.io/probabilistic-robotics/basics/nonparametric-filters)
    GitBook: Non parametric filter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wikipedia [probability](https://en.wikipedia.org/wiki/Probability), [probability
    theory](https://en.wikipedia.org/wiki/Probability_theory) and [bayes theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Daniel Sabinasz’s personal [blog on histogram filters](https://www.sabinasz.net/robot-localization-histogram-filter/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online converter from [latex to png](https://latex2png.com/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Images: the robot avatar was created with [Dall-E](https://openai.com/dall-e-3).
    All other images used in this article were created by the author.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
