- en: 'BiTCN: Multivariate Time Series Forecasting with Convolutional Networks'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BiTCN：基于卷积网络的多变量时间序列预测
- en: 原文：[https://towardsdatascience.com/bitcn-multivariate-time-series-forecasting-with-convolutional-networks-1471347c1bcc?source=collection_archive---------6-----------------------#2024-05-01](https://towardsdatascience.com/bitcn-multivariate-time-series-forecasting-with-convolutional-networks-1471347c1bcc?source=collection_archive---------6-----------------------#2024-05-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/bitcn-multivariate-time-series-forecasting-with-convolutional-networks-1471347c1bcc?source=collection_archive---------6-----------------------#2024-05-01](https://towardsdatascience.com/bitcn-multivariate-time-series-forecasting-with-convolutional-networks-1471347c1bcc?source=collection_archive---------6-----------------------#2024-05-01)
- en: Discover the BiTCN model for multivariate time series forecasting, explore its
    architecture, and implement it in Python.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解BiTCN模型在多变量时间序列预测中的应用，探索其架构，并在Python中实现它。
- en: '[](https://medium.com/@marcopeixeiro?source=post_page---byline--1471347c1bcc--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page---byline--1471347c1bcc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1471347c1bcc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1471347c1bcc--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page---byline--1471347c1bcc--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcopeixeiro?source=post_page---byline--1471347c1bcc--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page---byline--1471347c1bcc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1471347c1bcc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1471347c1bcc--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page---byline--1471347c1bcc--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1471347c1bcc--------------------------------)
    ·10 min read·May 1, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1471347c1bcc--------------------------------)
    ·10分钟阅读·2024年5月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b6f29593a7a517847ba11694535f6380.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6f29593a7a517847ba11694535f6380.png)'
- en: Photo by [Timothy Dykes](https://unsplash.com/@timothycdykes?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 摄影：由[Timothy Dykes](https://unsplash.com/@timothycdykes?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In the field of time series forecasting, the architectures of models often rely
    on either the multi-layer perceptron (MLP) or the Transformer architecture.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列预测领域，模型的架构通常依赖于多层感知机（MLP）或Transformer架构。
- en: MLP-based models, like [N-HiTS](/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5),
    [TiDE](/time-series-forecasting-with-tide-b043acc60f79) and [TSMixer](/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb),
    can achieve very good forecasting performances while remaining fast to train.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基于多层感知机（MLP）的模型，如[N-HiTS](/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5)、[TiDE](/time-series-forecasting-with-tide-b043acc60f79)和[TSMixer](/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb)，可以在保持快速训练的同时，取得非常好的预测性能。
- en: On the other hand, Transformer-based models like [PatchTST](https://medium.com/towards-data-science/patchtst-a-breakthrough-in-time-series-forecasting-e02d48869ccc)
    and [iTransformer](/itransformer-the-latest-breakthrough-in-time-series-forecasting-d538ddc6c5d1)
    also achieve good performances, but are more memory intensive and require more
    time to train.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，基于Transformer的模型，如[PatchTST](https://medium.com/towards-data-science/patchtst-a-breakthrough-in-time-series-forecasting-e02d48869ccc)和[iTransformer](/itransformer-the-latest-breakthrough-in-time-series-forecasting-d538ddc6c5d1)也能取得良好的预测效果，但它们在内存使用上更加密集，且训练时间较长。
- en: 'Still, one architecture remains largely underutilized in forecasting: the convolutional
    neural network (CNN).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在预测领域，卷积神经网络（CNN）这一架构仍然在很大程度上未被充分利用。
- en: Traditionally, CNNs have been applied in computer vision, but their applications
    in forecasting remains scarce, with only [TimesNet](https://medium.com/towards-data-science/timesnet-the-latest-advance-in-time-series-forecasting-745b69068c9c)
    being the most recent example.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，卷积神经网络（CNN）主要应用于计算机视觉领域，但在预测中的应用仍然稀缺，只有[TimesNet](https://medium.com/towards-data-science/timesnet-the-latest-advance-in-time-series-forecasting-745b69068c9c)是最近的一个例子。
- en: However, CNNs have been shown to be effective in treating sequential data, and
    their architecture allow for parallel computation, which can greatly speed up
    training.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，已证明卷积神经网络（CNN）在处理序列数据方面是有效的，并且其架构允许并行计算，这可以大大加快训练速度。
- en: In this article, we thus explore BiTCN, a model proposed in March 2023 in the
    paper…
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将探讨BiTCN，这是2023年3月在论文中提出的一个模型…
