<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Efficient Document Chunking Using LLMs: Unlocking Knowledge One Block at a Time</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Efficient Document Chunking Using LLMs: Unlocking Knowledge One Block at a Time</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/efficient-document-chunking-using-llms-unlocking-knowledge-one-block-at-a-time-355717a88c5c?source=collection_archive---------0-----------------------#2024-10-21">https://towardsdatascience.com/efficient-document-chunking-using-llms-unlocking-knowledge-one-block-at-a-time-355717a88c5c?source=collection_archive---------0-----------------------#2024-10-21</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="gr gs gt gu gv ab"><div><div class="ab gw"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@peronc79?source=post_page---byline--355717a88c5c--------------------------------" rel="noopener follow"><div class="l gx gy by gz ha"><div class="l ed"><img alt="Carlo Peron" class="l ep by dd de cx" src="../Images/e6db9521113aa6a2dd43b0b2aa6687b5.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*uDXGuejWzRpj54GywWxenw.jpeg"/><div class="hb by l dd de em n hc eo"/></div></div></a></div></div><div class="hd ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--355717a88c5c--------------------------------" rel="noopener follow"><div class="l he hf by gz hg"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hh cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hb by l br hh em n hc eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hi ab q"><div class="ab q hj"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hk hl bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hm" data-testid="authorName" href="https://medium.com/@peronc79?source=post_page---byline--355717a88c5c--------------------------------" rel="noopener follow">Carlo Peron</a></p></div></div></div><span class="hn ho" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hk hl dx"><button class="hp hq ah ai aj ak al am an ao ap aq ar hr hs ht" disabled="">Follow</button></p></div></div></span></div></div><div class="l hu"><span class="bf b bg z dx"><div class="ab cn hv hw hx"><div class="hy hz ab"><div class="bf b bg z dx ab ia"><span class="ib l hu">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hm ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--355717a88c5c--------------------------------" rel="noopener follow"><p class="bf b bg z ic id ie if ig ih ii ij bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hn ho" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="ik il l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 21, 2024</span></div></span></div></span></div></div></div><div class="ab cp im in io ip iq ir is it iu iv iw ix iy iz ja jb"><div class="h k w ea eb q"><div class="jr l"><div class="ab q js jt"><div class="pw-multi-vote-icon ed ib ju jv jw"><div class=""><div class="jx jy jz ka kb kc kd am ke kf kg jw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kh ki kj kk kl km kn"><p class="bf b dy z dx"><span class="jy">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao jx kq kr ab q ee ks kt" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="kp"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count ko kp">3</span></p></button></div></div></div><div class="ab q jc jd je jf jg jh ji jj jk jl jm jn jo jp jq"><div class="ku k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al kv an ao ap hr kw kx ky" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep kz cn"><div class="l ae"><div class="ab cb"><div class="la lb lc ld le lf ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al kv an ao ap hr lg lh kt li lj lk ll lm s ln lo lp lq lr ls lt u lu lv lw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al kv an ao ap hr lg lh kt li lj lk ll lm s ln lo lp lq lr ls lt u lu lv lw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al kv an ao ap hr lg lh kt li lj lk ll lm s ln lo lp lq lr ls lt u lu lv lw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ma mb mc md me mf lx ly paragraph-image"><div role="button" tabindex="0" class="mg mh ed mi bh mj"><div class="lx ly lz"><img src="../Images/8d39f802c75bb432d069186938148b8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eScvr-xRy9FeWL8AP9zPDQ.png"/></div></div><figcaption class="ml mm mn lx ly mo mp bf b bg z dx">The process of splitting two blocks — Image by the author</figcaption></figure><p id="922f" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This article explains how to use an LLM (Large Language Model) to perform the chunking of a document based on concept of “idea”.</p><p id="feac" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">I use OpenAI’s gpt-4o model for this example, but the same approach can be applied with any other LLM, such as those from Hugging Face, Mistral, and others.</p><p id="0bf2" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Everyone can access this <a class="af no" href="https://medium.com/@peronc79/355717a88c5c?sk=1cc4e46c40708d5057d54da391035cfa" rel="noopener">article</a> for free.</p><p id="8939" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Considerations on Document Chunking</strong></p><p id="03e5" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">In cognitive psychology, a chunk represents a “unit of information.”</p><p id="9ec7" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This concept can be applied to computing as well: using an LLM, we can analyze a document and produce a set of chunks, typically of variable length, with each chunk expressing a complete “idea.”</p><p id="0c82" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This means that the system divides a document into “pieces of text” such that each expresses a unified concept, without mixing different ideas in the same chunk.</p><p id="47af" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The goal is to create a knowledge base composed of independent elements that can be related to one another without overlapping different concepts within the same chunk.</p><p id="c8f8" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Of course, during analysis and division, there may be multiple chunks expressing the same idea if that idea is repeated in different sections or expressed differently within the same document.</p><p id="7181" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Getting Started</strong></p><p id="d110" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The first step is identifying a document that will be part of our knowledge base.</p><p id="3458" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This is typically a PDF or Word document, read either page by page or by paragraphs and converted into text.</p><p id="dce8" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">For simplicity, let’s assume we already have a list of text paragraphs like the following, extracted from <strong class="ms fr"><em class="np">Around the World in Eighty Days</em></strong>:</p><pre class="nq nr ns nt nu nv nw nx bp ny bb bk"><span id="cfb0" class="nz oa fq nw b bg ob oc l od oe">documents = [<br/>    """On October 2, 1872, Phileas Fogg, an English gentleman, left London for an extraordinary journey. <br/>    He had wagered that he could circumnavigate the globe in just eighty days. <br/>    Fogg was a man of strict habits and a very methodical life; everything was planned down to the smallest detail, and nothing was left to chance.<br/>    He departed London on a train to Dover, then crossed the Channel by ship. His journey took him through many countries, <br/>    including France, India, Japan, and America. At each stop, he encountered various people and faced countless adventures, but his determination never wavered.""",<br/><br/>    """However, time was his enemy, and any delay risked losing the bet. With the help of his faithful servant Passepartout, Fogg had to face <br/>    unexpected obstacles and dangerous situations.""",<br/><br/>    """Yet, each time, his cunning and indomitable spirit guided him to victory, while the world watched in disbelief.""",<br/><br/>    """With one final effort, Fogg and Passepartout reached London just in time to prove that they had completed their journey in less than eighty days. <br/>    This extraordinary adventurer not only won the bet but also discovered that the true treasure was the friendship and experiences he had accumulated along the way."""<br/>]</span></pre><p id="2e5c" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Let’s also assume we are using an LLM that accepts a limited number of tokens for input and output, which we’ll call <em class="np">input_token_nr</em> and <em class="np">output_token_nr</em>.</p><p id="28e7" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">For this example, we’ll set <em class="np">input_token_nr </em>= 300 and <em class="np">output_token_nr</em> = 250.</p><p id="fd98" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This means that for successful splitting, the number of tokens for both the prompt and the document to be analyzed must be less than 300, while the result produced by the LLM must consume no more than 250 tokens.</p><p id="4b70" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Using the <a class="af no" href="https://platform.openai.com/tokenizer" rel="noopener ugc nofollow" target="_blank">tokenizer</a> provided by OpenAI we see that our knowledge base documents is composed of 254 tokens.</p><p id="a629" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Therefore, analyzing the entire document at once isn’t possible, as even though the input can be processed in a single call, it can’t fit in the output.</p><p id="4786" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">So, as a preparatory step, we need to divide the original document into blocks no larger than 250 tokens.</p><p id="2b75" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">These blocks will then be passed to the LLM, which will further split them into chunks.</p><p id="faeb" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">To be cautious, let’s set the maximum block size to 200 tokens.</p><p id="0683" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Generating Blocks</strong></p><p id="8e8f" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The process of generating blocks is as follows:</p><ol class=""><li id="aaf5" class="mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn of og oh bk">Consider the first paragraph in the knowledge base (KB), determine the number of tokens it requires, and if it’s less than 200, it becomes the first element of the block.</li><li id="ebc4" class="mq mr fq ms b mt oi mv mw mx oj mz na nb ok nd ne nf ol nh ni nj om nl nm nn of og oh bk">Analyze the size of the next paragraph, and if the combined size with the current block is less than 200 tokens, add it to the block and continue with the remaining paragraphs.</li><li id="99f1" class="mq mr fq ms b mt oi mv mw mx oj mz na nb ok nd ne nf ol nh ni nj om nl nm nn of og oh bk">A block reaches its maximum size when attempting to add another paragraph causes the block size to exceed the limit.</li><li id="e2bb" class="mq mr fq ms b mt oi mv mw mx oj mz na nb ok nd ne nf ol nh ni nj om nl nm nn of og oh bk">Repeat from step one until all paragraphs have been processed.</li></ol><p id="87c3" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The blocks generation process assumes, for simplicity, that each paragraph is smaller than the maximum allowed size (otherwise, the paragraph itself must be split into smaller elements).</p><p id="375c" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">To perform this task, we use the <em class="np">llm_chunkizer.split_document_into_blocks</em> function from the LLMChunkizerLib/chunkizer.py library, which can be found in the following repository — <a class="af no" href="https://github.com/peronc/LLMChunkizer/" rel="noopener ugc nofollow" target="_blank">LLMChunkizer</a>.</p><p id="f315" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Visually, the result looks like Figure 1.</p><figure class="nq nr ns nt nu mf lx ly paragraph-image"><div class="lx ly on"><img src="../Images/366d6fb7dc3c658b31fa9d0481492dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*5w2tacJGeloqaJbmDfcqzw.png"/></div><figcaption class="ml mm mn lx ly mo mp bf b bg z dx">Figure 1 — Split document into blocks of maximum size of 200 tokens — Image by the author</figcaption></figure><p id="739f" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">When generating blocks, the only rule to follow is not to exceed the maximum allowed size.</p><p id="7e5c" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">No analysis or assumptions are made about the meaning of the text.</p><p id="7864" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Generating Chunks</strong></p><p id="115f" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The next step is to split the block into chunks that each express the same idea.</p><p id="933a" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">For this task, we use the <em class="np">llm_chunkizer.chunk_text_with_llm</em> function from the <em class="np">LLMChunkizerLib/chunkizer.py</em> library, also found in the same repository.</p><p id="8fa7" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The result can be seen in Figure 2.</p><figure class="nq nr ns nt nu mf lx ly paragraph-image"><div role="button" tabindex="0" class="mg mh ed mi bh mj"><div class="lx ly oo"><img src="../Images/d38ce011f33c722eaeb5e5dea015397a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FD5lBxglxQK2O0HwwcMXOw.png"/></div></div><figcaption class="ml mm mn lx ly mo mp bf b bg z dx">Figure 2 — Split block into chunks — Image by the author</figcaption></figure><p id="07e2" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This process works linearly, allowing the LLM to freely decide how to form the chunks.</p><p id="f497" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Handling the Overlap Between Two Blocks</strong></p><p id="457e" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">As previously mentioned, during block splitting, only the length limit is considered, with no regard for whether adjacent paragraphs expressing the same idea are split across different blocks.</p><p id="680c" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This is evident in Figure 1, where the concept “bla bla bla” (representing a unified idea) is split between two adjacent blocks.</p><p id="7ca2" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">As you can see In Figure 2, the chunkizer processes only one block at a time, meaning the LLM cannot correlate this information with the following block (it doesn’t even know a next block exists), and thus, places it in the last split chunk.</p><p id="95c5" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This problem occurs frequently during ingestion, particularly when importing a long document whose text cannot all fit within a single LLM prompt.</p><p id="1077" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">To address it, <em class="np">llm_chunkizer.chunk_text_with_llm</em> works as shown in Figure 3:</p><ol class=""><li id="32fa" class="mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn of og oh bk">The last chunk (or the last N chunks) produced from the previous block is removed from the “valid” chunks list, and its content is added to the next block to be split.</li><li id="a726" class="mq mr fq ms b mt oi mv mw mx oj mz na nb ok nd ne nf ol nh ni nj om nl nm nn of og oh bk">The <em class="np">New Block2 </em>is passed to the chunking function again.</li></ol><figure class="nq nr ns nt nu mf lx ly paragraph-image"><div role="button" tabindex="0" class="mg mh ed mi bh mj"><div class="lx ly op"><img src="../Images/17201eb773dba1ba31362002dc138ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tk4Xz8tD0i6wkWpNEQMiIg.png"/></div></div><figcaption class="ml mm mn lx ly mo mp bf b bg z dx">Figure 3 — Handling the overlap — Image by the author</figcaption></figure><p id="7678" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">As shown in Figure 3, the content of chunk M is split more effectively into two chunks, keeping the concept “bla bla bla” together</p><p id="e1c2" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The idea behind this solution is that the last N chunks of the previous block represent independent ideas, not just unrelated paragraphs.</p><p id="e76a" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Therefore, adding them to the new block allows the LLM to generate similar chunks while also creating a new chunk that unites paragraphs that were previously split without regard for their meaning.</p><p id="96cb" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Result of Chunking</strong></p><p id="1a96" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">At the end, the system produces the following 6 chunks:</p><pre class="nq nr ns nt nu nv nw nx bp ny bb bk"><span id="132b" class="nz oa fq nw b bg ob oc l od oe">0: On October 2, 1872, Phileas Fogg, an English gentleman, left London for an extraordinary journey. He had wagered that he could circumnavigate the globe in just eighty days. Fogg was a man of strict habits and a very methodical life; everything was planned down to the smallest detail, and nothing was left to chance.  <br/>1: He departed London on a train to Dover, then crossed the Channel by ship. His journey took him through many countries, including France, India, Japan, and America. At each stop, he encountered various people and faced countless adventures, but his determination never wavered.  <br/>2: However, time was his enemy, and any delay risked losing the bet. With the help of his faithful servant Passepartout, Fogg had to face unexpected obstacles and dangerous situations.  <br/>3: Yet, each time, his cunning and indomitable spirit guided him to victory, while the world watched in disbelief.  <br/>4: With one final effort, Fogg and Passepartout reached London just in time to prove that they had completed their journey in less than eighty days.  <br/>5: This extraordinary adventurer not only won the bet but also discovered that the true treasure was the friendship and experiences he had accumulated along the way.</span></pre><p id="1370" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Considerations on Block Size</strong></p><p id="7534" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Let’s see what happens when the original document is split into larger blocks with a maximum size of 1000 tokens.</p><p id="2558" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">With larger block sizes, the system generates 4 chunks instead of 6.</p><p id="5f77" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This behavior is expected because the LLM could analyzed a larger portion of content at once and was able to use more text to represent a single concept.</p><p id="24c5" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Here are the chunks in this case:</p><pre class="nq nr ns nt nu nv nw nx bp ny bb bk"><span id="b5e0" class="nz oa fq nw b bg ob oc l od oe">0: On October 2, 1872, Phileas Fogg, an English gentleman, left London for an extraordinary journey. He had wagered that he could circumnavigate the globe in just eighty days. Fogg was a man of strict habits and a very methodical life; everything was planned down to the smallest detail, and nothing was left to chance.  <br/>1: He departed London on a train to Dover, then crossed the Channel by ship. His journey took him through many countries, including France, India, Japan, and America. At each stop, he encountered various people and faced countless adventures, but his determination never wavered.  <br/>2: However, time was his enemy, and any delay risked losing the bet. With the help of his faithful servant Passepartout, Fogg had to face unexpected obstacles and dangerous situations. Yet, each time, his cunning and indomitable spirit guided him to victory, while the world watched in disbelief.  <br/>3: With one final effort, Fogg and Passepartout reached London just in time to prove that they had completed their journey in less than eighty days. This extraordinary adventurer not only won the bet but also discovered that the true treasure was the friendship and experiences he had accumulated along the way.</span></pre><p id="e5df" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Conclusions</strong></p><p id="979e" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">It’s important to attempt multiple chunking runs, varying the block size passed to the chunkizer each time.</p><p id="3b06" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">After each attempt, the results should be reviewed to determine which approach best fits the desired outcome.</p><p id="26ba" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Coming Up</strong></p><p id="f0b7" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">In the next article, I will show how to use an LLM to retrieve chunks — <a class="af no" href="https://github.com/peronc/LLMRetriever" rel="noopener ugc nofollow" target="_blank">LLMRetriever </a>.</p><p id="fa12" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">You could find all the code and more example in my repository — <a class="af no" href="https://github.com/peronc/LLMChunkizer/" rel="noopener ugc nofollow" target="_blank">LLMChunkizer</a>.</p></div></div></div><div class="ab cb oq or os ot" role="separator"><span class="ou by bm ov ow ox"/><span class="ou by bm ov ow ox"/><span class="ou by bm ov ow"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="47e3" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">If you’d like to discuss this further, feel free to connect with me on <a class="af no" href="https://www.linkedin.com/in/carlo-peron" rel="noopener ugc nofollow" target="_blank">LinkedIn</a></p></div></div></div></div>    
</body>
</html>