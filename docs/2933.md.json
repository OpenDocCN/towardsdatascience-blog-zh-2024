["```py\nfrom google.colab import drive\ndrive.mount('/content/drive') \n```", "```py\n!ls /content/drive/MyDrive/data\n!ls /content/drive/MyDrive/checkpoint\n```", "```py\ndef save_checkpoint(epoch, model, optimizer, scheduler, loss, model_name, overwrite=True):\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'loss': loss\n    }\n    direc = get_checkpoint_dir(model_name)\n    if overwrite:\n        file_path = direc + '/checkpoint.pth'\n    else:\n        file_path = direc + '/epoch_'+str(epoch) + '_checkpoint.pth'\n    if not os.path.isdir(direc):\n       try:\n          os.mkdir(direc)\n       except:\n          print(\"Error: directory does not exist and cannot be created\")\n          file_path = direc +'_epoch_'+str(epoch) + '_checkpoint.pth'\n    torch.save(checkpoint, file_path)\n    print(f\"Checkpoint saved at epoch {epoch}\")\n```", "```py\ndef load_checkpoint(model_name, model, optimizer, scheduler):\n    direc = get_checkpoint_dir(model_name)\n    if os.path.exists(direc):\n        file_path = get_path_with_max_epochs(direc)\n        checkpoint = torch.load(file_path, map_location=torch.device('cpu'))\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        epoch = checkpoint['epoch']\n        loss = checkpoint['loss']\n        print(f\"Checkpoint loaded from {epoch} epoch\")\n        return epoch, loss\n    else:\n        print(f\"No checkpoint found, starting from epoch 1.\")\n        return 0, None\n```", "```py\n EPOCHS = 10\nfor exp in experiments: \n    model, optimizer, scheduler = initialise_model_components(exp)\n    train_loader, val_loader = generate_data_loaders(exp)\n    start_epoch, prev_loss = load_checkpoint(exp, model, optimizer, scheduler)\n    for epoch in range(start_epoch, EPOCHS):\n        print(f'Epoch {epoch + 1}/{EPOCHS}')\n        # ALL YOUR TRAINING CODE HERE\n        save_checkpoint(epoch + 1, model, optimizer, scheduler, train_loss, exp) \n```"]