<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Building a Multilingual Multi-Agent Chat Application Using LangGraph — Part I</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Building a Multilingual Multi-Agent Chat Application Using LangGraph — Part I</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-multilingual-multi-agent-chat-application-using-langgraph-i-262d40df6b4f?source=collection_archive---------6-----------------------#2024-09-06">https://towardsdatascience.com/building-a-multilingual-multi-agent-chat-application-using-langgraph-i-262d40df6b4f?source=collection_archive---------6-----------------------#2024-09-06</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="74b6" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">In this 3 part series, learn how to build a RAG-based, multilingual, agentic chat application along with an integrated AI assistant to streamline tasks at workplaces</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@RSK2327?source=post_page---byline--262d40df6b4f--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Roshan Santhosh" class="l ep by dd de cx" src="../Images/2509f38bf7d5a40c453fa54575293f06.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/2*WZ0oPku8QDRZpZp9zdfjnQ.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--262d40df6b4f--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@RSK2327?source=post_page---byline--262d40df6b4f--------------------------------" rel="noopener follow">Roshan Santhosh</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--262d40df6b4f--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 6, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><h1 id="a3f4" class="mi mj fq bf mk ml mm gq mn mo mp gt mq mr ms mt mu mv mw mx my mz na nb nc nd bk"><strong class="al">Background</strong></h1><p id="3a00" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Despite the advancements in technology, language barriers still exist in today’s world. Whether it’s at work or while you are outside, there are always situations where differences in languages can create awkward situations. This is especially true for large enterprises that have teams spread across different geographies, speaking different languages. As part of the recently concluded Aya Expedition organized by the Cohere for AI research community, I was able to work on a project that aimed to address this language barrier along with other workplace-related inefficiencies by developing a multilingual agentic chat application for workplaces.</p><p id="9775" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">Instead of talking more about the product, I think the best way to introduce the product and what we will be building through this series is to actually watch it in action.</p><figure class="of og oh oi oj ok"><div class="ol io l ed"><div class="om on l"/></div><figcaption class="oo op oq or os ot ou bf b bg z dx">Final demo of chat application</figcaption></figure><p id="ad4e" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">The following tutorial series covers the development of this application which includes :</p><ol class=""><li id="3f33" class="ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz ov ow ox bk">An agentic workflow for translating to the user’s preferred language</li><li id="bccb" class="ne nf fq ng b go oy ni nj gr oz nl nm nn pa np nq nr pb nt nu nv pc nx ny nz ov ow ox bk">Building features for the AI assistant: RAG-based question answering, Documentation-on-the-Go, and Smart Summarize features</li><li id="389a" class="ne nf fq ng b go oy ni nj gr oz nl nm nn pa np nq nr pb nt nu nv pc nx ny nz ov ow ox bk">Deploying the agentic workflow through FastAPI and developing a web UI to interface with it</li></ol></div></div></div><div class="ab cb pd pe pf pg" role="separator"><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="13cd" class="mi mj fq bf mk ml pl gq mn mo pm gt mq mr pn mt mu mv po mx my mz pp nb nc nd bk">High-level framework</h1><p id="6831" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Given the popularity of LangChain and its graph based counterpart, LangGraph, I don’t want this to be another tutorial that explains the basics of these packages and their methods. Instead I want to <strong class="ng fr">focus more on the design choices and challenges faced</strong> while implementing our solution through these packages as I feel that would be more useful in the long run.</p><h2 id="ede8" class="pq mj fq bf mk pr ps pt mn pu pv pw mq nn px py pz nr qa qb qc nv qd qe qf qg bk"><strong class="al">LangChain vs LangGraph</strong></h2><p id="7faf" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The first design choice we faced was selecting between LangChain and LangGraph.</p><p id="3778" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">In a simple scenario (as pictured below), where every message provided by a user is sent to all other users and translated to their preferred language, then LangChain would have been a sufficient choice. This is a <strong class="ng fr">unidirectional flow</strong> that starts from the user sending the message and ends with the users receiving the messages:</p><figure class="of og oh oi oj ok or os paragraph-image"><div role="button" tabindex="0" class="qi qj ed qk bh ql"><div class="or os qh"><img src="../Images/00fb860bd624ca99a1d9135b608687fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OeKHWpfKqbZFzMKaNC3Jyg.png"/></div></div><figcaption class="oo op oq or os ot ou bf b bg z dx">Unidirectional information flow without Aya</figcaption></figure><p id="6048" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">However, the primary constraint in our scenario was the <strong class="ng fr">inclusion of an AI assistant, which we shall be referring to as Aya</strong> (named after the Expedition). Aya was planned to be a significant component of this chat application and added a new layer of complexity to our system. With Aya, messages from the sending user needed to be analyzed and depending on the nature of the message (if it was a command addressed to Aya), the system needed to send back a message, which in turn needed to be sent again to the receiving users.</p></div></div><div class="ok"><div class="ab cb"><div class="ll qn lm qo ln qp cf qq cg qr ci bh"><figure class="of og oh oi oj ok qt qu paragraph-image"><div role="button" tabindex="0" class="qi qj ed qk bh ql"><div class="or os qs"><img src="../Images/711ed7a611f3f03fa23f97dd86f1f322.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*tiqq5dCoqvD4vVUcfTSNsw.png"/></div></div><figcaption class="oo op oq or os ot ou bf b bg z dx">Information flow with Aya</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="c5c2" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk"><strong class="ng fr">Defining a Run: </strong>Another design choice thats relevant here is the definition of one ‘run’ or one ‘iteration’ of the messaging cycle.</p><p id="2f92" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">In the definition we chose, we considered each run to be initiated by any user sending a message and it being terminated when all messages related to that initial message reach the receiving users.</p><p id="3b03" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">So if it’s a message that doesn’t address Aya and is just a direct message to other users, the run is considered to be terminated when the initial translated message is received by all users. And if it’s a message that addresses Aya, then it’s considered terminated when the initial message along with the response from Aya, BOTH, reach all users.</p><p id="e927" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">So with this design choice/definition of a run, we wanted a flow where we wait for the responses from Aya to be generated and pushed to the users before terminating the run. And for implementing such a flow, we used LangGraph, as it was specifically built to solve for such cases.</p></div></div></div><div class="ab cb pd pe pf pg" role="separator"><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="8316" class="mi mj fq bf mk ml pl gq mn mo pm gt mq mr pn mt mu mv po mx my mz pp nb nc nd bk">Building the Agents</h1><p id="6044" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The backbone of this application are the agents and their interactions. Overall, we had two different types of agents :</p><ol class=""><li id="563e" class="ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz ov ow ox bk">User Agents: Agents attached to each user. Primarily tasked with translating incoming messages into the user’s preferred language</li><li id="91af" class="ne nf fq ng b go oy ni nj gr oz nl nm nn pa np nq nr pb nt nu nv pc nx ny nz ov ow ox bk">Aya Agents: Various agents associated with Aya, each with its own specific role/job</li></ol><h2 id="d958" class="pq mj fq bf mk pr ps pt mn pu pv pw mq nn px py pz nr qa qb qc nv qd qe qf qg bk">User Agents</h2><p id="d135" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The UserAgent class is used to define an agent that will be associated with every user part of the chat room. Some of the functions implemented by the UserAgent class:</p><p id="b0a6" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">1. Translate incoming messages into the user’s preferred language</p><p id="8439" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">2. Activate/Invoke graph when a user sends a message</p><p id="d7a5" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">3. Maintain a chat history to help provide context to the translation task to allow for ‘context-aware’ translation</p><pre class="of og oh oi oj qv qw qx bp qy bb bk"><span id="f77a" class="qz mj fq qw b bg ra rb l rc rd">class UserAgent(object):<br/><br/>    def __init__(self, llm, userid, user_language):<br/>        self.llm = llm<br/>        self.userid = userid<br/>        self.user_language = user_language<br/>        self.chat_history = []<br/><br/>        prompt = ChatPromptTemplate.from_template(USER_SYSTEM_PROMPT2)<br/><br/>        self.chain = prompt | llm<br/><br/><br/>    def set_graph(self, graph):<br/>        self.graph = graph<br/><br/>    def send_text(self,text:str, debug = False):<br/><br/>        message = ChatMessage(message = HumanMessage(content=text), sender = self.userid)<br/>        inputs = {"messages": [message]}<br/>        output = self.graph.invoke(inputs, debug = debug)<br/>        return output<br/><br/>    def display_chat_history(self, content_only = False):<br/><br/>        for i in self.chat_history:<br/>            if content_only == True:<br/>                print(f"{i.sender} : {i.content}")<br/>            else:<br/>                print(i)<br/><br/>    <br/>    def invoke(self, message:BaseMessage) -&gt; AIMessage:<br/>        <br/>        output = self.chain.invoke({'message':message.content, 'user_language':self.user_language})<br/><br/>        return output</span></pre><p id="919b" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">For the most part, the implementation of UserAgent is pretty standard LangChain/LangGraph code:</p><ul class=""><li id="9b62" class="ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz re ow ox bk">Define a LangChain chain ( a prompt template + LLM) that is responsible for doing the actual translation.</li><li id="4ee1" class="ne nf fq ng b go oy ni nj gr oz nl nm nn pa np nq nr pb nt nu nv pc nx ny nz re ow ox bk">Define a send_text function thats used to invoke the graph whenever a user wants to send a new message</li></ul><p id="8098" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">For the most part, the performance of this agent is dependent on the translation quality of the LLM, as translation is the primary objective of this agent. And LLM performance can vary significantly for translation, especially depending on the languages involved. Certain low resource languages don’t have good representation in the training data of some models and this does affect the translation quality for those languages.</p><h2 id="f7e1" class="pq mj fq bf mk pr ps pt mn pu pv pw mq nn px py pz nr qa qb qc nv qd qe qf qg bk">Aya Agents</h2><p id="7a30" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">For Aya, we actually have a system of separate agents that all contributes towards the overall assistant. Specifically, we have</p><ol class=""><li id="e9aa" class="ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz ov ow ox bk">AyaSupervisor : Control agent that supervises the operation of the other Aya agents.</li><li id="9af9" class="ne nf fq ng b go oy ni nj gr oz nl nm nn pa np nq nr pb nt nu nv pc nx ny nz ov ow ox bk">AyaQuery : Agent for running RAG based question answering</li><li id="11d4" class="ne nf fq ng b go oy ni nj gr oz nl nm nn pa np nq nr pb nt nu nv pc nx ny nz ov ow ox bk">AyaSummarizer : Agent for generating chat summaries and doing task identification</li><li id="560a" class="ne nf fq ng b go oy ni nj gr oz nl nm nn pa np nq nr pb nt nu nv pc nx ny nz ov ow ox bk">AyaTranslator: Agent for translating messages to English</li></ol><pre class="of og oh oi oj qv qw qx bp qy bb bk"><span id="c0bd" class="qz mj fq qw b bg ra rb l rc rd">class AyaTranslator(object):<br/><br/>    def __init__(self, llm) -&gt; None:<br/>        self.llm = llm <br/>        prompt = ChatPromptTemplate.from_template(AYA_TRANSLATE_PROMPT)<br/>        self.chain = prompt | llm <br/>        <br/>    def invoke (self, message: str) -&gt; AIMessage:<br/>        output = self.chain.invoke({'message':message})<br/>        return output<br/><br/>class AyaQuery(object):<br/><br/>    def __init__(self, llm, store, retriever) -&gt; None:<br/>        self.llm = llm<br/>        self.retriever = retriever<br/>        self.store = store<br/>        qa_prompt = ChatPromptTemplate.from_template(AYA_AGENT_PROMPT)<br/>        self.chain = qa_prompt | llm<br/><br/>    def invoke(self, question : str) -&gt; AIMessage:<br/><br/>        context = format_docs(self.retriever.invoke(question))<br/>        rag_output = self.chain.invoke({'question':question, 'context':context})<br/>        return rag_output<br/><br/>class AyaSupervisor(object):<br/><br/>    def __init__(self, llm):<br/>        <br/>        prompt = ChatPromptTemplate.from_template(AYA_SUPERVISOR_PROMPT)<br/>        self.chain = prompt | llm<br/><br/>    def invoke(self, message : str) -&gt; str:<br/>        output = self.chain.invoke(message)<br/>        return output.content<br/><br/>class AyaSummarizer(object):<br/><br/>    def __init__(self, llm):<br/>        <br/>        message_length_prompt = ChatPromptTemplate.from_template(AYA_SUMMARIZE_LENGTH_PROMPT)<br/>        self.length_chain = message_length_prompt | llm <br/>        <br/>        prompt = ChatPromptTemplate.from_template(AYA_SUMMARIZER_PROMPT)<br/>        self.chain = prompt | llm<br/><br/><br/><br/>    def invoke(self, message : str, agent : UserAgent) -&gt; str:<br/><br/>        length = self.length_chain.invoke(message)<br/><br/>        try:<br/>            length = int(length.content.strip())<br/>        except:<br/>            length = 0<br/><br/>        chat_history = agent.chat_history<br/><br/>        if length == 0:<br/>            messages_to_summarize = [chat_history[i].content for i in range(len(chat_history))]<br/>        else:<br/>            messages_to_summarize = [chat_history[i].content for i in range(min(len(chat_history), length))]<br/>        <br/>        print(length)<br/>        print(messages_to_summarize)<br/><br/>        messages_to_summarize = "\n ".join(messages_to_summarize)<br/>        <br/>        output = self.chain.invoke(messages_to_summarize)<br/>        output_content = output.content <br/><br/>        print(output_content)<br/><br/>        return output_content</span></pre><p id="c745" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">Most of these agents have a similar structure, primarily consisting of a LangChain chain consisting of a custom prompt and a LLM. Exceptions include the AyaQuery agent which has an additional vector database retriever to implement RAG and AyaSummarizer which has multiple LLM functions being implemented within it.</p><h2 id="a09a" class="pq mj fq bf mk pr ps pt mn pu pv pw mq nn px py pz nr qa qb qc nv qd qe qf qg bk"><strong class="al">Design considerations</strong></h2><p id="7787" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk"><strong class="ng fr">Role of AyaSupervisor Agent</strong>: In the design of the graph, we had a fixed edge going from the Supervisor node to the user nodes. Which meant that all messages that reached the Supervisor node were pushed to the user nodes itself. Therefore, in cases where Aya was being addressed, <strong class="ng fr">we had to ensure that only a single final output from Aya was being pushed to the users</strong>. We didn’t want intermediate messages, if any, to reach the users. Therefore, we had the AyaSupervisor agent that acted as the single point of contact for the Aya agent. This agent was primarily responsible for interpreting the intent of the incoming message, direct the message to the appropriate task-specific agent, and then outputting the final message to be shared with the users.</p><p id="bc1d" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk"><strong class="ng fr">Design of AyaSummarizer: </strong>The AyaSummarizer agent is slightly more complex compared to the other Aya agents as it carries out a two-step process. In the first step, the agent first determines the number of messages that needs to be summarized, which is a LLM call with its own prompt. In the second step, once we know the number of messages to summarize, we collate the required messages and pass it to the LLM to generate the actual summary. In addition to the summary, in this step itself, the LLM also identifies any action items that were present in the messages and lists it out separately.</p><p id="02cc" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">So broadly there were three tasks: determining the length of the messages to be summarized, summarizing messages, identifying action items. However, given that the first task was proving a bit difficult for the LLM without any explicit examples, I made the choice to have this be a separate LLM call and then combine the two last two tasks as their own LLM call.</p><p id="e26c" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">It may be possible to eliminate the additional LLM call and combine all three tasks in one call. Potential options include :</p><ol class=""><li id="28d0" class="ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz ov ow ox bk">Providing very detailed examples that cover all three tasks in one step</li><li id="41f9" class="ne nf fq ng b go oy ni nj gr oz nl nm nn pa np nq nr pb nt nu nv pc nx ny nz ov ow ox bk">Generating lot of examples to actually finetune a LLM to be able to perform well in this task</li></ol><p id="03b1" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk"><strong class="ng fr">Role of AyaTranslator: </strong>One of the goals with respect to Aya was to make it a multilingual AI assistant which can communicate in the user’s preferred language. However, it would be difficult to handle different languages internally within the Aya agents. Specifically, if the Aya agents prompt is in English and the user message is in a different language, it could potentially create issues. So in order to avoid such situations, as a filtering step, <strong class="ng fr">we translated any incoming user messages to Aya into English</strong>. As a result, all of the internal work within the Aya group of agents was done in English, including the output. We didnt have to translate the Aya output back to the original language because when the message reaches the users, the User agents will take care of translating the message to their respective assigned language.</p></div></div></div><div class="ab cb pd pe pf pg" role="separator"><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="a0f1" class="mi mj fq bf mk ml pl gq mn mo pm gt mq mr pn mt mu mv po mx my mz pp nb nc nd bk"><strong class="al">Prompt Design</strong></h1><p id="7729" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">With respect to prompt designs, the majority of the work was focused on getting the LLM to output responses in a particular format in a consistent manner. For most cases, I was able to achieve this by providing explicit instructions. In some cases, instructions alone was not enough and I had to provide examples for the agent to behave consistently.</p><p id="1a82" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">For the most part, the prompt template had the following structure :</p><pre class="of og oh oi oj qv qw qx bp qy bb bk"><span id="b6cf" class="qz mj fq qw b bg ra rb l rc rd">[High level task definition] You are an AI assistant that answers user's questions... <br/><br/>[List of specific constraints related to the response]<br/>Obey the following rules : <br/>1. ....<br/><br/>[Providing context/user input]<br/>Message : <br/></span></pre><p id="45d2" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">To take a specific example, we take a look at the prompt used by the User Agent:</p><pre class="of og oh oi oj qv qw qx bp qy bb bk"><span id="08ff" class="qz mj fq qw b bg ra rb l rc rd">You are a {user_language} translator, translating a conversation between work colleagues. Translate the message provided by the user into {user_language}. <br/><br/>Obey the following rules : <br/>1. Only translate the text thats written after 'Message:' and nothing else<br/>2. If the text is already in {user_language} then return the message as it is.<br/>3. Return only the translated text<br/>4. Ensure that your translation uses formal language<br/><br/>Message:<br/>{message}</span></pre><p id="1ba4" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">With regards to this agent, an important constraint was to ensure that the model only outputted the translated text and no supporting text like “Here’s the translated text” or “Sure, the following is a translation for the provided text”. In this case, adding a specific rule to obey (rule #3) was enough to ensure that the models were only outputting the translated text and nothing else.</p><p id="8781" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">An example of an instance that required examples in the prompt were the prompts related to the summarizer agent. Specifically for the agent responsible for identifying the number of messages to summarize over. I found it difficult to get the agent to consistently extract the number of messages listed, if any, and output it in a specific format. Therefore, it became necessary to provide examples to better explain what I was expecting as a response from the agent.</p><h1 id="8af2" class="mi mj fq bf mk ml mm gq mn mo mp gt mq mr ms mt mu mv mw mx my mz na nb nc nd bk">Other implementation details</h1><h2 id="bbaf" class="pq mj fq bf mk pr ps pt mn pu pv pw mq nn px py pz nr qa qb qc nv qd qe qf qg bk">ChatMessage</h2><p id="03f3" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Those familiar with LangChain should already be aware of AIMessage, HumanMessage classes that are used to hold AI and human messages. For our use case, <strong class="ng fr">we needed to be able to store the ID of the sender for downstream tasks</strong>. Therefore to address this, we created a new derived class called ChatMessage that stores a message along with the sender’s ID</p><pre class="of og oh oi oj qv qw qx bp qy bb bk"><span id="6f70" class="qz mj fq qw b bg ra rb l rc rd">class ChatMessage(object):<br/><br/>    def __init__(self, message : BaseMessage, sender : str = None):<br/>        self.message = message<br/>        self.sender = sender<br/>        self.content = message.content<br/><br/>    def __repr__(self) -&gt; str:<br/>        return f"{self.sender} | {self.content}"</span></pre><h2 id="e81b" class="pq mj fq bf mk pr ps pt mn pu pv pw mq nn px py pz nr qa qb qc nv qd qe qf qg bk">Graph State</h2><p id="cd8e" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">In LangGraph, one of key elements of the graph is the graph state. The state variable/object is crucial for proper communication between the agents as well as for keeping track of the progress through the graph workflow.</p><pre class="of og oh oi oj qv qw qx bp qy bb bk"><span id="d963" class="qz mj fq qw b bg ra rb l rc rd">def reducer(a : list, b : list | str ) -&gt; list:<br/><br/>    if type(b) == list: <br/>        return a + b<br/>    else:<br/>        return a<br/><br/>    <br/>class AgentState(TypedDict):<br/>    messages: Annotated[Sequence[ChatMessage], reducer]</span></pre><p id="b21e" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">In most LangGraph examples, the state variable is a list of strings that keeps getting appended to after passing through every agent. In our use case, <strong class="ng fr">I wanted to exclude the outputs from certain nodes from affecting the state of the graph</strong>, despite the workflow having passed through that node. To accommodate such cases, I differentiated between the two types of state changes by having one as a list and the other as a string. In cases where the state update is in the form of a list, it gets appended to the overall state object. In cases, where the state update is a string, we ignore that update and propagate the existing state. This is achieved using the custom <strong class="ng fr"><em class="rf">reducer</em></strong> function defined above.</p></div></div></div><div class="ab cb pd pe pf pg" role="separator"><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj pk"/><span class="ph by bm pi pj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="75db" class="mi mj fq bf mk ml pl gq mn mo pm gt mq mr pn mt mu mv po mx my mz pp nb nc nd bk">Conclusion</h1><p id="a9d1" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">At this stage, we have covered the design choices of one of the key components of the agentic workflow : the agents. In the next tutorial, we will cover more details about the actual LangGraph graph and its implementation, along with some more details about the features associated with Aya.</p><h2 id="cca3" class="pq mj fq bf mk pr ps pt mn pu pv pw mq nn px py pz nr qa qb qc nv qd qe qf qg bk">Resources</h2><p id="1bfd" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">For the code, you can refer to the repo here : <a class="af rg" href="https://github.com/rsk2327/Multilingual-Chatbot" rel="noopener ugc nofollow" target="_blank">Multilingual Chatbot</a>.</p><p id="10bb" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk">Unless specified otherwise, all images are created by the author.</p><p id="007f" class="pw-post-body-paragraph ne nf fq ng b go oa ni nj gr ob nl nm nn oc np nq nr od nt nu nv oe nx ny nz fj bk"><em class="rf">In addition to Medium, I share my thoughts, ideas and other updates on </em><a class="af rg" href="https://www.linkedin.com/in/roshan-santhosh/" rel="noopener ugc nofollow" target="_blank"><em class="rf">LinkedIn</em></a><em class="rf">.</em></p></div></div></div></div>    
</body>
</html>