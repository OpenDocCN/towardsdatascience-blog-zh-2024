- en: Building a User Insights-Gathering Tool for Product Managers from Scratch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零开始构建产品经理的用户洞察收集工具
- en: 原文：[https://towardsdatascience.com/building-a-user-insights-gathering-tool-for-product-managers-from-scratch-a6459dc1c3f6?source=collection_archive---------8-----------------------#2024-08-12](https://towardsdatascience.com/building-a-user-insights-gathering-tool-for-product-managers-from-scratch-a6459dc1c3f6?source=collection_archive---------8-----------------------#2024-08-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-a-user-insights-gathering-tool-for-product-managers-from-scratch-a6459dc1c3f6?source=collection_archive---------8-----------------------#2024-08-12](https://towardsdatascience.com/building-a-user-insights-gathering-tool-for-product-managers-from-scratch-a6459dc1c3f6?source=collection_archive---------8-----------------------#2024-08-12)
- en: Say goodbye to paid customer insights hubs! Learn how to combine five open-source
    AI models to automate insights gathering from your user interviews.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向付费的客户洞察中心告别吧！学习如何将五个开源AI模型结合起来，自动化从用户访谈中收集洞察。
- en: '[](https://medium.com/@zaninihugo?source=post_page---byline--a6459dc1c3f6--------------------------------)[![Hugo
    Zanini](../Images/cbda793f1cf82f34b29c6e136556361d.png)](https://medium.com/@zaninihugo?source=post_page---byline--a6459dc1c3f6--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a6459dc1c3f6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a6459dc1c3f6--------------------------------)
    [Hugo Zanini](https://medium.com/@zaninihugo?source=post_page---byline--a6459dc1c3f6--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@zaninihugo?source=post_page---byline--a6459dc1c3f6--------------------------------)[![Hugo
    Zanini](../Images/cbda793f1cf82f34b29c6e136556361d.png)](https://medium.com/@zaninihugo?source=post_page---byline--a6459dc1c3f6--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a6459dc1c3f6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a6459dc1c3f6--------------------------------)
    [Hugo Zanini](https://medium.com/@zaninihugo?source=post_page---byline--a6459dc1c3f6--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a6459dc1c3f6--------------------------------)
    ·11 min read·Aug 12, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a6459dc1c3f6--------------------------------)
    ·阅读时间 11 分钟 ·2024年8月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6094d50facdc92f35218923622bab796.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6094d50facdc92f35218923622bab796.png)'
- en: Photo by [Daria Nepriakhina](https://unsplash.com/@epicantus?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/printed-sticky-notes-glued-on-board-zoCDWPuiRuA?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Daria Nepriakhina](https://unsplash.com/@epicantus?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    于 [Unsplash](https://unsplash.com/photos/printed-sticky-notes-glued-on-board-zoCDWPuiRuA?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: As a technical product manager for a data platform, I frequently run user interviews
    to identify challenges associated with data development processes.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个数据平台的技术产品经理，我经常进行用户访谈，以识别与数据开发过程相关的挑战。
- en: However, when exploring a new problem area with users, I can easily become overwhelmed
    by the numerous conversations I have with various individuals across the organization.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我与用户一起探索一个新的问题领域时，我很容易被与组织内各个个体的众多对话所压倒。
- en: Over time, I have adopted a systematic approach to address this challenge. I
    focus on taking comprehensive notes during each interview and then revisit them.
    This allows me to consolidate my understanding and identify user discussion patterns.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，我采用了一种系统化的方法来应对这一挑战。我专注于在每次访谈中做详细的笔记，然后再回顾这些笔记。这让我能够巩固理解并识别出用户讨论的模式。
- en: However, dividing my attention between note-taking and active listening often
    compromised the quality of my conversations. I noticed that when someone else
    took notes for me, my interviews significantly improved. This allowed me to fully
    engage with the interviewees, concentrate solely on what they were saying, and
    have more meaningful and productive interactions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在做笔记和积极倾听之间分心往往会影响我对话的质量。我注意到，当别人为我做笔记时，我的访谈效果显著提升。这使我能够完全投入到与受访者的交流中，专注于他们所说的内容，从而进行更有意义和富有成效的互动。
- en: To be more efficient, I transitioned from taking notes during meetings to recording
    and transcribing them whenever the functionality was available. This significantly
    reduced the number of interviews I needed to conduct, as I could gain more insights
    from fewer conversations. However, this change required me to invest time reviewing
    transcriptions and watching videos. The figure below shows what became a simplified
    flow of the process I follow for mapping a new product development opportunity.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高效率，我从在会议中做笔记转变为每当有功能时，就进行录音并转录。这大大减少了我需要进行的访谈数量，因为我可以从较少的对话中获得更多的洞察。然而，这一变化要求我花时间回顾转录内容并观看视频。下图展示了我在绘制新的产品开发机会时所遵循的简化流程。
- en: '![](../Images/98af683776e7bdb22a3114f9e803ed9d.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98af683776e7bdb22a3114f9e803ed9d.png)'
- en: Image by author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '**Due to the size of the meeting transcriptions and difficulties in categorizing
    user insights, consolidation and analysis became challenging.**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**由于会议转录的体积和分类用户洞察的困难，整合与分析变得具有挑战性。**'
- en: Furthermore, the meeting transcription tools available to me were limited to
    English, while most of my conversations were in Portuguese. As a result, I decided
    to look to the market for a solution that could help me with those challenges.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，现有的会议转录工具仅限于英语，而我大多数的对话是葡萄牙语。因此，我决定在市场上寻找一个能够帮助我应对这些挑战的解决方案。
- en: The solutions I found that solved most of my pain points were [Dovetail](https://dovetail.com/),
    [Marvin](https://heymarvin.com/), [Condens](https://condens.io/), and [Reduct](https://reduct.video/).
    They position themselves as customer insights hubs, and their main product is
    generally Customer Interview transcriptions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我找到的解决了大多数痛点的工具是 [Dovetail](https://dovetail.com/)、[Marvin](https://heymarvin.com/)、[Condens](https://condens.io/)
    和 [Reduct](https://reduct.video/)。它们定位自己为客户洞察中心，主要产品通常是客户访谈的转录。
- en: Basically, you can upload an interview video there, and you are going to receive
    a transcription indicating who is speaking with hyperlinks to the original video
    on every phrase. Over the text, you can add highlights, tags, and comments and
    ask for a summary of the conversation. **These features would solve my problem;
    however, these tools are expensive, especially considering that I live in Brazil
    and they charge in dollars.**
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，你可以在这里上传访谈视频，并获得一份转录，指明每一句话的发言人，并在每句话上附有指向原视频的超链接。在文本上，你可以添加高亮、标签和评论，还可以请求对话的总结。**这些功能将解决我的问题；然而，这些工具价格昂贵，特别是考虑到我住在巴西，而他们收取美元费用。**
- en: '**The tools offer nothing revolutionary, so I decided to implement an open-source
    alternative that would run for free on Colab notebooks.**'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**这些工具没有任何革命性创新，所以我决定实现一个开源替代方案，可以在Colab笔记本上免费运行。**'
- en: The requirements
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需求
- en: 'As a good PM, the first thing I did was identify the must-haves for my product
    based on the user''s (my) needs. Here are the high-level requirements I mapped:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名优秀的产品经理，我做的第一件事是根据用户（我的）需求识别产品的必备功能。以下是我所列出的高层次需求：
- en: '**Cost and Accessibility**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**成本与可访问性**'
- en: Free;
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 免费；
- en: No coding experience is required to use;
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无需编程经验即可使用；
- en: '**Data Privacy and Security**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据隐私与安全**'
- en: Keep data private — no connection with external services;
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持数据私密——与外部服务无连接；
- en: '**Performance**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能**'
- en: Execution must be faster than the video duration;
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行速度必须快于视频时长；
- en: High-precision transcription in different languages;
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高精度的多语言转录；
- en: '**Functionality**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**功能**'
- en: Speakers identification;
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发言人识别；
- en: Easy to search over the transcriptions;
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于在转录内容中搜索；
- en: Easy to highlight the transcriptions;
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻松突出显示转录内容；
- en: Easy to create repositories of research being done;
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易创建正在进行的研究的存储库；
- en: '**Integration**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**集成**'
- en: Integrated with my company's existing tools (Google Workspace);
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与我公司现有工具（Google Workspace）集成；
- en: LLM model integrated to receive prompts for tasks on top of the transcriptions;
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成LLM模型以接收任务提示，基于转录内容执行；
- en: The solution
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'With the requirements, I designed what would be the features of my solution:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 根据需求，我设计了我的解决方案应具备的功能：
- en: '![](../Images/92381377517963db8d4c326de1666e2b.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92381377517963db8d4c326de1666e2b.png)'
- en: Image by author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: 'Then, I projected what would be the expected inputs and the user interfaces
    to define them:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我设计了预期的输入和用户界面来定义这些功能：
- en: '![](../Images/2cd00c7a1d251e1fb7d75824b24ef412.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cd00c7a1d251e1fb7d75824b24ef412.png)'
- en: Image by author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Users will upload their interview to YouTube as an unlisted video and create
    a Google Drive folder to store the transcription. They will then access a Google
    Colab notebook to provide basic information about the interview, paste the video
    URL, and optionally define tasks for an LLM model. The output will be Google Docs,
    where they can consolidate insights.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 用户将把他们的面试上传到YouTube，并设置为未列出的视频，然后创建一个Google Drive文件夹来存储转录文件。接着，他们可以访问Google
    Colab笔记本，提供面试的基本信息、粘贴视频网址，并可以选择为大型语言模型（LLM）定义任务。输出结果将是Google Docs，用户可以在其中整合洞察。
- en: Below is the product architecture. The solution required combining five different
    ML models and some Python libraries. The next sections provide overviews of each
    of the building blocks; however, if you are more interested in trying the product,
    please go to the "I got it" section.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是产品架构。这个解决方案结合了五个不同的机器学习模型和一些Python库。接下来的部分将提供每个构建模块的概述；但是，如果你更感兴趣的是尝试这个产品，请跳到“I
    got it”部分。
- en: '![](../Images/96168c1df8b7d3ba902a9a547c92e61f.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96168c1df8b7d3ba902a9a547c92e61f.png)'
- en: Image by author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Interview Setup and Video Upload
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面试设置与视频上传
- en: To create a user-friendly interface for setting up interviews and providing
    video links, I used [Google Colab’s forms functionality](https://colab.research.google.com/notebooks/forms.ipynb?ref=dataschool.io#scrollTo=ig8PIYeLtM8g).
    This allows for the creation of text fields, sliders, dropdowns, and more. The
    code is hidden behind the form, making it very accessible for non-technical users.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一个用户友好的界面，用于设置面试并提供视频链接，我使用了[Google Colab的表单功能](https://colab.research.google.com/notebooks/forms.ipynb?ref=dataschool.io#scrollTo=ig8PIYeLtM8g)。它允许创建文本框、滑动条、下拉框等。代码被隐藏在表单后面，非常适合非技术用户使用。
- en: '![](../Images/89dea50e1e495b9369553a667507f74a.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89dea50e1e495b9369553a667507f74a.png)'
- en: Interview selection form — Image by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 面试选择表格 — 图片由作者提供
- en: Audio download and conversion
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频下载与转换
- en: I used the yt-dlp lib to download only the audio from a YouTube video and convert
    it to the mp3 format. It is very straightforward to use, and you can [check its
    documentation here](https://github.com/yt-dlp/yt-dlp).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了yt-dlp库来仅下载YouTube视频的音频，并将其转换为mp3格式。这个工具非常简单易用，你可以[在这里查看它的文档](https://github.com/yt-dlp/yt-dlp)。
- en: '![](../Images/4c47572c2a50d6190d0dac82e9bbbae7.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c47572c2a50d6190d0dac82e9bbbae7.png)'
- en: Image by [yt-dlp](https://github.com/yt-dlp/yt-dlp)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[yt-dlp](https://github.com/yt-dlp/yt-dlp)提供
- en: Audio transcription
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频转录
- en: To transcribe the meeting, I used [Whisper from Open AI](https://github.com/openai/whisper).
    It is an open-source model for speech recognition trained on more than 680K hours
    of multilingual data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了转录会议内容，我使用了[Open AI的Whisper](https://github.com/openai/whisper)。这是一个开源的语音识别模型，训练数据来自超过68万小时的多语言数据。
- en: The model runs incredibly fast; a one-hour audio clip takes around 6 minutes
    to be transcribed on a 16GB T4 GPU (offered by free on Google Colab), and it supports
    [99 different languages](https://github.com/openai/whisper/blob/ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab/whisper/tokenizer.py#L11-L110).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型运行非常迅速；一段一小时的音频大约需要6分钟就能在16GB T4 GPU（Google Colab提供的免费GPU）上完成转录，并且它支持[99种不同语言](https://github.com/openai/whisper/blob/ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab/whisper/tokenizer.py#L11-L110)。
- en: Since privacy is a requirement for the solution, the model weights are downloaded,
    and all the inference occurs inside the colab instance. I also added a Model Selection
    form in the notebook so the user can choose different models based on the precision
    they are looking for.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于隐私是这个解决方案的一个要求，模型的权重被下载，所有推理操作都在Colab实例内部进行。我还在笔记本中添加了一个模型选择表单，用户可以根据他们所需要的精度选择不同的模型。
- en: '![](../Images/12597ca463c3d2bcaf8f4ae25e6d8dfb.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12597ca463c3d2bcaf8f4ae25e6d8dfb.png)'
- en: Image by author
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Speakers Identification
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讲话者识别
- en: Speaker identification is done through a technique called Speakers Diarization.
    The idea is to identify and segment audio into distinct speech segments, where
    each segment corresponds to a particular speaker. With that, we can identify who
    spoke and when.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 讲话者识别是通过一种叫做讲话者分段技术（Speakers Diarization）来完成的。其原理是将音频划分为不同的语音段，每个段落对应一个特定的讲话者。通过这种方式，我们可以识别出谁在什么时候发言。
- en: Since the videos uploaded from YouTube don't have metadata identifying who is
    speaking, the speakers will be divided into Speaker 1, Speaker 2, etc.… Later,
    the user can find and replace those names in Google Docs to add the speakers’
    identification.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于从YouTube上传的视频没有元数据来标识谁在说话，讲话者将被分为讲话者1、讲话者2等……稍后，用户可以在Google Docs中查找并替换这些名字，以添加讲话者的身份标识。
- en: '![](../Images/f8b66de2615683dd7210b7c4d1be7a3c.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8b66de2615683dd7210b7c4d1be7a3c.png)'
- en: Image by author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: For the diarization, we will use a model called the [Multi-Scale Diarization
    Decoder (MSDD)](https://arxiv.org/pdf/2203.15974), which was developed by Nvidia
    researchers. It is a sophisticated approach to speaker diarization that leverages
    multi-scale analysis and dynamic weighting to achieve high accuracy and flexibility.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于说话者分离，我们将使用一个名为[多尺度说话者分离解码器（MSDD）](https://arxiv.org/pdf/2203.15974)的模型，该模型由Nvidia研究人员开发。这是一种先进的说话者分离方法，利用多尺度分析和动态加权来实现高精度和灵活性。
- en: The model is known for being quite good at identifying and properly categorizing
    moments where multiple speakers are talking—a thing that occurs frequently during
    interviews.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型以在识别并正确分类多个讲者交替发言的时刻而闻名——这是访谈中常见的现象。
- en: The model can be used through the [NVIDIA NeMo framework](https://github.com/NVIDIA/NeMo).
    It allowed me to get MSDD checkpoints and run the diarization directly in the
    colab notebook with just a few lines of code.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型可以通过[NVIDIA NeMo框架](https://github.com/NVIDIA/NeMo)使用。它让我能够获取MSDD检查点，并直接在colab笔记本中运行说话者分离，只需几行代码。
- en: Looking into the Diarization results from MSDD, I noticed that punctuation was
    pretty bad, with long phrases, and some interruptions such as "*hmm*" and "*yeah*"
    were taken into account as a speaker interruption — making the text difficult
    to read.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 查看MSDD的说话者分离结果时，我注意到标点符号很差，长句子中某些像“*嗯*”和“*是的*”的插入语被误认为是说话者的中断——这使得文本难以阅读。
- en: 'So, I decided to add a punctuation model to the pipeline to improve the readability
    of the transcribed text and facilitate human analysis. So I got the [punctuate-all
    model from Hugging Face](https://huggingface.co/kredor/punctuate-all), which is
    a very precise and fast solution and supports the following languages: English,
    German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portuguese,
    Slovak, and Slovenian.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我决定在管道中添加一个标点模型，以提高转录文本的可读性并便于人工分析。于是，我从[Hugging Face获取了punctuate-all模型](https://huggingface.co/kredor/punctuate-all)，这是一个非常精确且快速的解决方案，支持以下语言：英语、德语、法语、西班牙语、保加利亚语、意大利语、波兰语、荷兰语、捷克语、葡萄牙语、斯洛伐克语和斯洛文尼亚语。
- en: Video Synchronization
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频同步
- en: From the industry solutions I benchmarked, a strong requirement was that every
    phrase should be linked to the moment in the interview the speaker was talking.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从我所对比的行业解决方案来看，一个强烈的需求是每个短语都应该与采访中讲述的时刻相关联。
- en: The Whisper transcriptions have metadata indicating the timestamps when the
    phrases were said; however, this metadata is not very precise.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Whisper转录包含指示短语说出时间戳的元数据；然而，这些元数据并不十分精确。
- en: Therefore, I used a model called [Wav2Vec2](https://arxiv.org/abs/2006.11477)
    to do this match in a more accurate way. Basically, the solution is a neural network
    designed to learn representations of audio and perform speech recognition alignment.
    The process involves finding the exact timestamps in the audio signal where each
    segment was spoken and aligning the text accordingly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我使用了一个名为[Wav2Vec2](https://arxiv.org/abs/2006.11477)的模型来更准确地进行这种匹配。基本上，该解决方案是一个神经网络，旨在学习音频表示并执行语音识别对齐。该过程包括在音频信号中找到每个段落说出的确切时间戳，并相应地对齐文本。
- en: With the transcription <> timestamp match properly done, through simple Python
    code, I created hyperlinks pointing to the moment in the video where the phrases
    start to be said.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过准确地匹配转录文本与时间戳，我通过简单的Python代码创建了超链接，指向视频中开始说出短语的时刻。
- en: The LLM Model
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM模型
- en: This step of the pipeline has a large language model ready to run locally and
    analyze the text, providing insights about the interview. By default, I added
    a Gemma Model 1.1b with a prompt to summarize the text. If the users choose to
    have the summarization, it will be in a bullet list at the top of the document.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这个管道步骤有一个准备好在本地运行并分析文本的大型语言模型，提供关于访谈的洞见。默认情况下，我添加了Gemma模型1.1b，并设置了一个提示来总结文本。如果用户选择进行总结，它将以项目符号列表的形式显示在文档顶部。
- en: '![](../Images/1175b705bc66896a25ab9333288fe76a.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1175b705bc66896a25ab9333288fe76a.png)'
- en: Image by author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Also, by clicking on *Show code*, the users can change the prompt and ask the
    model to perform a different task.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过点击*显示代码*，用户可以更改提示并要求模型执行不同的任务。
- en: '![](../Images/f782e28c6df86a0db83ca2f6bb0210bc.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f782e28c6df86a0db83ca2f6bb0210bc.png)'
- en: Document generation for tagging, highlights, and comments
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于标签、重点和评论的文档生成
- en: The last task performed by the solution is to generate Google Docs with the
    transcriptions and hyperlinks to the interviews. This was done through the [Google
    API Python client library](https://googleapis.github.io/google-api-python-client/).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案执行的最后一项任务是生成带有访谈转录和超链接的 Google Docs。这是通过[Google API Python 客户端库](https://googleapis.github.io/google-api-python-client/)完成的。
- en: I got it
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我知道了
- en: Since the product has become incredibly useful in my day-to-day work, I decided
    to give it a name for easier reference. I called it the **I**nsights **G**athering
    **O**pen-source **T**ool, or iGot.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于该产品在我日常工作中变得非常有用，我决定给它起个名字，以便更容易引用。我将它称为**I**nsights **G**athering **O**pen-source
    **T**ool，简称iGot。
- en: '![](../Images/8d4274e8d7769313b98c24f070f4ab62.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d4274e8d7769313b98c24f070f4ab62.png)'
- en: '[Image generated by DALL·E-3](https://openai.com/policies/terms-of-use/)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[由 DALL·E-3 生成的图片](https://openai.com/policies/terms-of-use/)'
- en: When using the solution for the first time, some initial setup is required.
    Let me guide you through a real-world example to help you get started.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在首次使用该解决方案时，需要进行一些初始设置。让我通过一个实际的例子来指导您开始使用。
- en: Open the iGot notebook and install the required libraries
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 打开 iGot 笔记本并安装所需的库
- en: Click on [this link](https://colab.research.google.com/drive/1eMN4-b4kAH4uNTzzgJ-X4J90BYozGl6o?usp=sharing)
    to open the notebook and run the first cell to install the required libraries.
    It is going to take around 5 minutes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 点击[此链接](https://colab.research.google.com/drive/1eMN4-b4kAH4uNTzzgJ-X4J90BYozGl6o?usp=sharing)打开笔记本并运行第一个单元格以安装所需的库。大约需要
    5 分钟。
- en: '![](../Images/dd64fbb094759505bde82f7e4b22e499.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd64fbb094759505bde82f7e4b22e499.png)'
- en: Image by author
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: If you get a prompt asking you to restart the notebook, just cancel it. There
    is no need.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统提示您重启笔记本，请直接取消。无需重启。
- en: '![](../Images/933bc06cfe3b64c5b15ec643472bc6e6.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/933bc06cfe3b64c5b15ec643472bc6e6.png)'
- en: Image by author
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: If everything runs as expected, you are going to get the message "All libraries
    installed!".
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切按预期运行，您将看到“所有库已安装！”的消息。
- en: '![](../Images/1bfd13f827456fe8cd37187bf397eddd.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1bfd13f827456fe8cd37187bf397eddd.png)'
- en: Image by author
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Getting the Hugging User Access Token and model access
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取 Hugging 用户访问令牌和模型访问权限
- en: '*(This step is required just the first time you are executing the notebook)*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*(此步骤仅在首次执行笔记本时需要)*'
- en: For running the Gemma and punctuate-all models, we will download weights from
    hugging face. To do so, you must request a user token and model access.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行 Gemma 和 punctuate-all 模型，我们将从 Hugging Face 下载权重文件。为此，您必须申请一个用户令牌并获得模型访问权限。
- en: To do so, you need to create a hugging face account and follow these steps to
    get a token with reading permissions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，您需要创建一个 Hugging Face 账户，并按照以下步骤获取具有阅读权限的令牌。
- en: '![](../Images/bc3cd784c45aa25cbac192ff56881600.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc3cd784c45aa25cbac192ff56881600.png)'
- en: Image by author
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Once you have the token, copy it and return to the lab notebook. Go to the secrets
    tab and click on "Add new secret."
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您获得了令牌，复制它并返回到实验笔记本。进入“Secrets”选项卡，然后点击“Add new secret”。
- en: '![](../Images/805b3887ad6143ac349b4a479e64bc27.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/805b3887ad6143ac349b4a479e64bc27.png)'
- en: Image by author
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Name your token as *HF_TOKEN* and past the key you got from Hugging Face.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 将您的令牌命名为*HF_TOKEN*，并粘贴您从 Hugging Face 获得的密钥。
- en: '![](../Images/3d133e00fce9e77c3aebe876f80e2051.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d133e00fce9e77c3aebe876f80e2051.png)'
- en: Image by author
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Next, click [this link](https://medium.com/r?url=https%3A%2F%2Fhuggingface.co%2Fgoogle%2Fgemma-1.1-2b-it)
    to open the Gemma model on Hugging Face. Then, click on “Acknowledge license”
    to get access the model.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，点击[此链接](https://medium.com/r?url=https%3A%2F%2Fhuggingface.co%2Fgoogle%2Fgemma-1.1-2b-it)打开
    Hugging Face 上的 Gemma 模型。然后点击“确认许可”以获得模型访问权限。
- en: '![](../Images/2a1a389a054a697d3c52a2aee0a80a2b.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a1a389a054a697d3c52a2aee0a80a2b.png)'
- en: Image by author
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Sending the interview
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发送访谈
- en: To send an interview to iGot, you need to upload it as an unlisted video on
    YouTube previously. For the purpose of this tutorial, I got a piece of the Andrej
    Karpathy interview with Lex Fridman and uploaded it to my account. It is part
    of the conversation where Andrej gave some advice for Machine Learning Beginners.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要将访谈发送到 iGot，您需要先将其作为未列出的 YouTube 视频上传。为了本教程的目的，我从 Andrej Karpathy 与 Lex Fridman
    的访谈中截取了一部分，并将其上传到我的账户。这是 Andrej 给机器学习初学者的一些建议部分。
- en: Then, you need to get the video URL, paste in the *video_url* field of the *Interview
    Selection* notebook cell, define a name for it, and indicate the language spoken
    in the video.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您需要获取视频的 URL，将其粘贴到*Interview Selection*笔记本单元格的*video_url*字段中，定义一个名称，并注明视频中的语言。
- en: Once you run the cell, you are going to receive a message indicating that an
    audio file was generated.t into
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你运行了该单元，你将收到一条消息，指示音频文件已生成。
- en: '![](../Images/7cf4b3fb57c466921b073bc7a0f4af38.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7cf4b3fb57c466921b073bc7a0f4af38.png)'
- en: Image by author
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Model selection and execution
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型选择与执行
- en: In the next cell, you can select the size of the Whisper model you want to use
    for the transcription. The bigger the model, the higher the transcription precision.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个单元中，你可以选择你想要用于转录的 Whisper 模型的大小。模型越大，转录精度越高。
- en: By default, the largest model is selected. Make your choice and run the cell.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，选择的是最大的模型。做出选择后，运行该单元。
- en: '![](../Images/48cd47e34184546ea5fb73b849b06a4e.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48cd47e34184546ea5fb73b849b06a4e.png)'
- en: Image by author
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Then, run the models execution cell to run the pipeline of models showed in
    the previous section. If everything goes as expected, you should receive the message
    "Punctuation done!" by the end.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，运行模型执行单元，执行上一部分中显示的模型流程。如果一切顺利，你应该在最后看到消息“标点符号处理完毕！”。
- en: '![](../Images/85223fc8f974c1c2401713da9585adf9.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85223fc8f974c1c2401713da9585adf9.png)'
- en: Image by author
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: If you get prompted with a message asking for access to the hugging face token,
    grant access to it.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你收到提示消息，询问是否允许访问 Hugging Face 令牌，请授予访问权限。
- en: '![](../Images/6405dfa35e01114692e8732e8ce80f3b.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6405dfa35e01114692e8732e8ce80f3b.png)'
- en: Image by author
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Configuring the transcript output
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置转录输出
- en: The final step is to save the transcription to a Google Docs file. To accomplish
    this, you need to specify the file path, provide the interview name, and indicate
    whether you want Gemma to summarize the meeting.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将转录保存到 Google Docs 文件中。为此，你需要指定文件路径，提供采访名称，并指示是否希望 Gemma 总结会议内容。
- en: When executing the cell for the first time, you can get prompted with a message
    asking for access to your Google Drive. Click in allow.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次执行该单元时，你可能会收到一条提示消息，询问是否允许访问你的 Google Drive。点击“允许”。
- en: '![](../Images/9b8a9c6633be1f95a04f9f472ca7d678.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b8a9c6633be1f95a04f9f472ca7d678.png)'
- en: Image by author
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Then, give Colab full access to your Google Drive workspace.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，给 Colab 完全访问你的 Google Drive 工作区。
- en: '![](../Images/b18e48f3be24d56a6af91e644cd05110.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b18e48f3be24d56a6af91e644cd05110.png)'
- en: Image by author
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: If everything runs as expected, you are going to see a link to the google docs
    file at the end. Just click on it, and you are going to have access to your interview
    transcription.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，你将会看到一个指向 Google Docs 文件的链接。只需点击它，你就可以访问你的采访转录。
- en: '![](../Images/0fb83c207c6df706d2958faf05fdba3f.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0fb83c207c6df706d2958faf05fdba3f.png)'
- en: Image by author
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Gathering insights from the generated document
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从生成的文档中提取见解
- en: The final document will have the transcriptions, with each phrase linked to
    the corresponding moment in the video where it begins. Since YouTube does not
    provide speaker metadata, I recommend using Google Docs’ find and replace tool
    to substitute “Speaker 0,” “Speaker 1,” and so on with the actual names of the
    speakers.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最终文档将包含转录内容，每个短语都与视频中开始的相应时刻相关联。由于 YouTube 不提供讲者元数据，建议使用 Google Docs 的查找和替换工具，将“Speaker
    0”、“Speaker 1”等替换为实际的讲者名字。
- en: '![](../Images/931431f03c01af159f04973515555704.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/931431f03c01af159f04973515555704.png)'
- en: Image by author
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'With that, you can work on highlights, notes, reactions, etc. As envisioned
    in the beginning:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，你可以处理高亮、笔记、反应等内容。如最初设想的那样：
- en: '![](../Images/08bd85c364d8aa7ff383f3237f763ad0.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08bd85c364d8aa7ff383f3237f763ad0.png)'
- en: Image by author
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Final thoughts
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的思考
- en: The tool is just in its first version, and I plan to evolve it into a more user-friendly
    solution. Maybe hosting a website so users don’t need to interact directly with
    the notebook, or creating a plugin for using it in Google Meets and Zoom.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具仍处于第一版本，我计划将其发展为一个更用户友好的解决方案。也许会搭建一个网站，让用户不需要直接与笔记本交互，或者开发一个插件，用于在 Google
    Meets 和 Zoom 中使用。
- en: My main goal with this project was to create a high-quality meeting transcription
    tool that can be beneficial to others while demonstrating how available open-source
    tools can match the capabilities of commercial solutions.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我的这个项目的主要目标是创建一个高质量的会议转录工具，它不仅对他人有益，还能展示现有的开源工具如何与商业解决方案的能力相匹配。
- en: I hope you find it useful! Feel free to [reach out to me on LinkedIn](https://www.linkedin.com/in/hugozanini/)
    if you have any feedback or are interested in collaborating on the evolution of
    iGot :)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你觉得它有用！如果你有任何反馈或对iGot的发展有兴趣，欢迎随时通过[LinkedIn联系我](https://www.linkedin.com/in/hugozanini/)。
