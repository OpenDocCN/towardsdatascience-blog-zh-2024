- en: 'Model Validation Techniques, Explained: A Visual Guide with Code Examples'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¨¡å‹éªŒè¯æŠ€æœ¯è§£æï¼šå¸¦æœ‰ä»£ç ç¤ºä¾‹çš„å¯è§†åŒ–æŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/model-validation-techniques-explained-a-visual-guide-with-code-examples-eb13bbdc8f88?source=collection_archive---------1-----------------------#2024-11-30](https://towardsdatascience.com/model-validation-techniques-explained-a-visual-guide-with-code-examples-eb13bbdc8f88?source=collection_archive---------1-----------------------#2024-11-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/model-validation-techniques-explained-a-visual-guide-with-code-examples-eb13bbdc8f88?source=collection_archive---------1-----------------------#2024-11-30](https://towardsdatascience.com/model-validation-techniques-explained-a-visual-guide-with-code-examples-eb13bbdc8f88?source=collection_archive---------1-----------------------#2024-11-30)
- en: MODEL EVALUATION & OPTIMIZATION
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–
- en: 12 must-know methods to v**alidate your machine learning**
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12ç§å¿…é¡»äº†è§£çš„**æœºå™¨å­¦ä¹ éªŒè¯æ–¹æ³•**
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)
    Â·26 min readÂ·Nov 30, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)
    Â·é˜…è¯»æ—¶é•¿26åˆ†é’ŸÂ·2024å¹´11æœˆ30æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Every day, machines make millions of predictions â€” from detecting objects in
    photos to helping doctors find diseases. But before trusting these predictions,
    we need to know if theyâ€™re any good. After all, no one would want to use a machine
    thatâ€™s wrong most of the time!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯å¤©ï¼Œæœºå™¨éƒ½ä¼šåšå‡ºæ•°ç™¾ä¸‡ä¸ªé¢„æµ‹â€”â€”ä»æ£€æµ‹ç…§ç‰‡ä¸­çš„ç‰©ä½“åˆ°å¸®åŠ©åŒ»ç”Ÿå‘ç°ç–¾ç—…ã€‚ä½†åœ¨ç›¸ä¿¡è¿™äº›é¢„æµ‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å®ƒä»¬æ˜¯å¦å‡†ç¡®ã€‚æ¯•ç«Ÿï¼Œæ²¡æœ‰äººæ„¿æ„ä½¿ç”¨ä¸€ä¸ªå¤§å¤šæ•°æ—¶å€™éƒ½é”™è¯¯çš„æœºå™¨ï¼
- en: This is where validation comes in. Validation methods test machine predictions
    to measure their reliability. While this might sound simple, different validation
    approaches exist, each designed to handle specific challenges in machine learning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ—¶ï¼ŒéªŒè¯å°±æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚éªŒè¯æ–¹æ³•æµ‹è¯•æœºå™¨çš„é¢„æµ‹ç»“æœï¼Œä»¥è¡¡é‡å…¶å¯é æ€§ã€‚è™½ç„¶è¿™å¬èµ·æ¥å¾ˆç®€å•ï¼Œä½†å®é™…ä¸Šå­˜åœ¨å¤šç§éªŒè¯æ–¹æ³•ï¼Œæ¯ç§æ–¹æ³•éƒ½æ˜¯ä¸ºäº†åº”å¯¹æœºå™¨å­¦ä¹ ä¸­çš„ç‰¹å®šæŒ‘æˆ˜è€Œè®¾è®¡çš„ã€‚
- en: Here, Iâ€™ve organized these validation techniques â€” all 12 of them â€” in a tree
    structure, showing how they evolved from basic concepts into more specialized
    ones. And of course, we will use clear visuals and a consistent dataset to show
    what each method does differently and why method selection matters.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘å°†è¿™äº›éªŒè¯æŠ€æœ¯â€”â€”å…¨éƒ¨12ç§â€”â€”ä»¥æ ‘çŠ¶ç»“æ„ç»„ç»‡ï¼Œå±•ç¤ºå®ƒä»¬å¦‚ä½•ä»åŸºæœ¬æ¦‚å¿µå‘å±•æˆæ›´ä¸ºä¸“ä¸šçš„æŠ€æœ¯ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¸…æ™°çš„å¯è§†åŒ–å›¾åƒå’Œä¸€è‡´çš„æ•°æ®é›†ï¼Œå±•ç¤ºæ¯ç§æ–¹æ³•çš„ä¸åŒä¹‹å¤„ä»¥åŠä¸ºä»€ä¹ˆé€‰æ‹©æ–¹æ³•è‡³å…³é‡è¦ã€‚
- en: '![](../Images/b1f5d5ea3c85d86aa30c1a32e4af95d6.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1f5d5ea3c85d86aa30c1a32e4af95d6.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å¯è§†åŒ–å›¾åƒï¼šä½œè€…ä½¿ç”¨Canva Proåˆ›å»ºã€‚å·²ä¼˜åŒ–ä¸ºç§»åŠ¨ç«¯æ˜¾ç¤ºï¼›åœ¨æ¡Œé¢ç«¯å¯èƒ½ä¼šæ˜¾å¾—è¿‡å¤§ã€‚
- en: What is Model Validation?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯æ¨¡å‹éªŒè¯ï¼Ÿ
- en: Model validation is the process of testing how well a machine learning model
    works with data it hasnâ€™t seen or used during training. Basically, we use existing
    data to check the modelâ€™s performance instead of using new data. This helps us
    identify problems before deploying the model for real use.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹éªŒè¯æ˜¯æµ‹è¯•æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æœªè§è¿‡æˆ–æœªåœ¨è®­ç»ƒä¸­ä½¿ç”¨è¿‡çš„æ•°æ®ä¸Šè¡¨ç°å¦‚ä½•çš„è¿‡ç¨‹ã€‚åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨ç°æœ‰æ•°æ®æ¥æ£€æŸ¥æ¨¡å‹çš„è¡¨ç°ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ–°çš„æ•°æ®ã€‚è¿™å¸®åŠ©æˆ‘ä»¬åœ¨å®é™…ä½¿ç”¨æ¨¡å‹ä¹‹å‰è¯†åˆ«é—®é¢˜ã€‚
- en: 'There are several validation methods, and each method has specific strengths
    and addresses different validation challenges:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å¤šç§éªŒè¯æ–¹æ³•ï¼Œæ¯ç§æ–¹æ³•éƒ½æœ‰å…¶ç‰¹å®šçš„ä¼˜åŠ¿ï¼Œå¹¶ä¸”è§£å†³ä¸åŒçš„éªŒè¯æŒ‘æˆ˜ï¼š
- en: Different validation methods can produce different results, so choosing the
    right method matters.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸åŒçš„éªŒè¯æ–¹æ³•å¯èƒ½ä¼šäº§ç”Ÿä¸åŒçš„ç»“æœï¼Œå› æ­¤é€‰æ‹©æ­£ç¡®çš„æ–¹æ³•å¾ˆé‡è¦ã€‚
- en: Some validation techniques work better with specific types of data and models.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸€äº›éªŒè¯æŠ€æœ¯åœ¨ç‰¹å®šç±»å‹çš„æ•°æ®å’Œæ¨¡å‹ä¸­æ•ˆæœæ›´ä½³ã€‚
- en: Using incorrect validation methods can give misleading results about the modelâ€™s
    true performance.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¸æ­£ç¡®çš„éªŒè¯æ–¹æ³•å¯èƒ½ä¼šå¯¼è‡´å…³äºæ¨¡å‹çœŸå®è¡¨ç°çš„è¯¯å¯¼æ€§ç»“æœã€‚
- en: 'Here is a tree diagram showing how these validation methods relate to each
    other:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€æ£µæ ‘å½¢å›¾ï¼Œå±•ç¤ºäº†è¿™äº›éªŒè¯æ–¹æ³•ä¹‹é—´çš„å…³ç³»ï¼š
- en: '![](../Images/ef40a8b199595fb3a2ea907fc7d8c4e7.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef40a8b199595fb3a2ea907fc7d8c4e7.png)'
- en: The tree diagram shows which validation methods are connected to each other.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ£µæ ‘å½¢å›¾å±•ç¤ºäº†å“ªäº›éªŒè¯æ–¹æ³•ç›¸äº’å…³è”ã€‚
- en: Next, weâ€™ll look at each validation method more closely by showing exactly how
    they work. To make everything easier to understand, weâ€™ll walk through clear examples
    that show how these methods work with real data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ›´ä»”ç»†åœ°ç ”ç©¶æ¯ç§éªŒè¯æ–¹æ³•ï¼Œå±•ç¤ºå®ƒä»¬æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ä¸ºäº†æ›´å®¹æ˜“ç†è§£ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ¸…æ™°çš„ç¤ºä¾‹ï¼Œå±•ç¤ºè¿™äº›æ–¹æ³•å¦‚ä½•åœ¨å®é™…æ•°æ®ä¸­è¿ä½œã€‚
- en: ğŸ“Š ğŸ“ˆ Our Running Example
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ“Š ğŸ“ˆ æˆ‘ä»¬çš„è¿è¡Œç¤ºä¾‹
- en: We will use the same example throughout to help you understand each testing
    method. While this dataset may not be appropriate for some validation methods,
    for education purpose, using this one example makes it easier to compare different
    methods and see how each one works.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å§‹ç»ˆä½¿ç”¨ç›¸åŒçš„ç¤ºä¾‹ï¼Œå¸®åŠ©ä½ ç†è§£æ¯ç§éªŒè¯æ–¹æ³•ã€‚è™½ç„¶è¿™ä¸ªæ•°æ®é›†å¯èƒ½ä¸é€‚åˆæŸäº›éªŒè¯æ–¹æ³•ï¼Œä½†ä¸ºäº†æ•™å­¦ç›®çš„ï¼Œä½¿ç”¨è¿™ä¸ªç¤ºä¾‹ä½¿å¾—æ¯”è¾ƒä¸åŒæ–¹æ³•å¹¶è§‚å¯Ÿæ¯ç§æ–¹æ³•å¦‚ä½•å·¥ä½œçš„è¿‡ç¨‹æ›´åŠ å®¹æ˜“ã€‚
- en: ğŸ“Š The Golf Playing Dataset
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ“Š é«˜å°”å¤«æ¸¸æˆæ•°æ®é›†
- en: Weâ€™ll work with this dataset that predicts whether someone will play golf based
    on weather conditions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†ï¼Œå®ƒæ ¹æ®å¤©æ°”æ¡ä»¶é¢„æµ‹æŸäººæ˜¯å¦ä¼šæ‰“é«˜å°”å¤«ã€‚
- en: '![](../Images/a76a1336de0cf6952c9aee515376a7ad.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a76a1336de0cf6952c9aee515376a7ad.png)'
- en: 'Columns: â€˜Overcast (one-hot-encoded into 3 columns)â€™, â€™Temperatureâ€™ (in Fahrenheit),
    â€˜Humidityâ€™ (in %), â€˜Windyâ€™ (Yes/No) and â€˜Playâ€™ (Yes/No, target feature)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—ï¼šâ€˜Overcastï¼ˆç‹¬çƒ­ç¼–ç ä¸º3åˆ—ï¼‰â€™ï¼Œâ€˜Temperatureâ€™ï¼ˆä»¥åæ°åº¦è¡¨ç¤ºï¼‰ï¼Œâ€˜Humidityâ€™ï¼ˆç™¾åˆ†æ¯”ï¼‰ï¼Œâ€˜Windyâ€™ï¼ˆæ˜¯/å¦ï¼‰å’Œâ€˜Playâ€™ï¼ˆæ˜¯/å¦ï¼Œç›®æ ‡ç‰¹å¾ï¼‰
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ğŸ“ˆ Our Model Choice
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ“ˆ æˆ‘ä»¬çš„æ¨¡å‹é€‰æ‹©
- en: 'We will use a [decision tree classifier](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    for all our tests. See the following article if you are not familiar with it:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æ‰€æœ‰æµ‹è¯•ä¸­ä½¿ç”¨[å†³ç­–æ ‘åˆ†ç±»å™¨](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)ã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰å®ƒï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹æ–‡ç« ï¼š
- en: '[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----eb13bbdc8f88--------------------------------)
    [## Decision Tree Classifier, Explained: A Visual Guide with Code Examples for
    Beginners'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----eb13bbdc8f88--------------------------------)
    [## å†³ç­–æ ‘åˆ†ç±»å™¨è§£æï¼šé™„å¸¦ä»£ç ç¤ºä¾‹çš„è§†è§‰æŒ‡å—ï¼ˆé¢å‘åˆå­¦è€…ï¼‰'
- en: A fresh look on our favorite upside-down tree
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¯¹æˆ‘ä»¬æœ€å–œæ¬¢çš„å€’ç«‹æ ‘çš„å…¨æ–°çœ‹æ³•
- en: towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----eb13bbdc8f88--------------------------------)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----eb13bbdc8f88--------------------------------)'
- en: We picked this model because we can easily draw the resulting model as a tree
    structure, with each branch showing different decisions. To keep things simple
    and focus on how we test the model, we will use the default `scikit-learn` parameter
    with a fixed `random_state`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€‰æ‹©è¿™ä¸ªæ¨¡å‹æ˜¯å› ä¸ºæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°å°†ç»“æœæ¨¡å‹ç»˜åˆ¶ä¸ºæ ‘å½¢ç»“æ„ï¼Œæ¯ä¸ªåˆ†æ”¯æ˜¾ç¤ºä¸åŒçš„å†³ç­–ã€‚ä¸ºäº†ç®€åŒ–æ“ä½œå¹¶ä¸“æ³¨äºå¦‚ä½•æµ‹è¯•æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é»˜è®¤çš„`scikit-learn`å‚æ•°ï¼Œå¹¶è®¾ç½®å›ºå®šçš„`random_state`ã€‚
- en: 'Letâ€™s be clear about these two terms weâ€™ll use: The decision tree classifier
    is our **learning algorithm** â€” itâ€™s the method that finds patterns in our data.
    When we feed data into this algorithm, it creates a **model** (in this case, a
    tree with clear branches showing different decisions). This model is what weâ€™ll
    actually use to make predictions.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ˜ç¡®è¿™ä¸¤ä¸ªæœ¯è¯­ï¼šå†³ç­–æ ‘åˆ†ç±»å™¨æ˜¯æˆ‘ä»¬çš„**å­¦ä¹ ç®—æ³•**â€”â€”å®ƒæ˜¯æ‰¾åˆ°æ•°æ®ä¸­æ¨¡å¼çš„æ–¹æ³•ã€‚å½“æˆ‘ä»¬å°†æ•°æ®è¾“å…¥è¯¥ç®—æ³•æ—¶ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ª**æ¨¡å‹**ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ˜¯ä¸€æ£µæ˜¾ç¤ºä¸åŒå†³ç­–çš„æ ‘ï¼‰ã€‚è¿™ä¸ªæ¨¡å‹å°±æ˜¯æˆ‘ä»¬å®é™…ç”¨æ¥è¿›è¡Œé¢„æµ‹çš„æ¨¡å‹ã€‚
- en: '![](../Images/05f04d2e03922330e874044c751e77f9.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05f04d2e03922330e874044c751e77f9.png)'
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Each time we split our data differently for validation, weâ€™ll get different
    models with different decision rules. Once our validation shows that our algorithm
    works reliably, weâ€™ll create one final model using all our data. This final model
    is the one weâ€™ll actually use to predict if someone will play golf or not.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯æ¬¡æˆ‘ä»¬ä»¥ä¸åŒçš„æ–¹å¼æ‹†åˆ†æ•°æ®è¿›è¡ŒéªŒè¯æ—¶ï¼Œéƒ½ä¼šå¾—åˆ°ä¸åŒçš„æ¨¡å‹å’Œä¸åŒçš„å†³ç­–è§„åˆ™ã€‚ä¸€æ—¦æˆ‘ä»¬çš„éªŒè¯è¡¨æ˜ç®—æ³•å¯é åœ°å·¥ä½œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ‰€æœ‰æ•°æ®åˆ›å»ºä¸€ä¸ªæœ€ç»ˆæ¨¡å‹ã€‚è¿™ä¸ªæœ€ç»ˆæ¨¡å‹å°±æ˜¯æˆ‘ä»¬å®é™…ç”¨æ¥é¢„æµ‹æŸäººæ˜¯å¦ä¼šæ‰“é«˜å°”å¤«çš„æ¨¡å‹ã€‚
- en: With this setup ready, we can now focus on understanding how each validation
    method works and how it helps us make better predictions about golf playing based
    on weather conditions. Letâ€™s examine each validation method one at a time.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ç½®å¥½è¿™ä¸€åˆ‡åï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥é›†ä¸­ç²¾åŠ›äº†è§£æ¯ç§éªŒè¯æ–¹æ³•çš„å·¥ä½œåŸç†ï¼Œä»¥åŠå®ƒå¦‚ä½•å¸®åŠ©æˆ‘ä»¬æ ¹æ®å¤©æ°”æ¡ä»¶åšå‡ºæ›´å¥½çš„é«˜å°”å¤«çƒé¢„æµ‹ã€‚æˆ‘ä»¬å°†é€ä¸€æ£€æŸ¥æ¯ç§éªŒè¯æ–¹æ³•ã€‚
- en: Hold-out Methods
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¿ç•™æ³•
- en: Hold-out methods are the most basic way to check how well our model works. In
    these methods, we basically save some of our data just for testing.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿ç•™æ³•æ˜¯æ£€éªŒæˆ‘ä»¬æ¨¡å‹æ•ˆæœçš„æœ€åŸºç¡€æ–¹æ³•ã€‚åœ¨è¿™äº›æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šå°†ä¸€éƒ¨åˆ†æ•°æ®ä¸“é—¨ç”¨äºæµ‹è¯•ã€‚
- en: Train-Test Split
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒ-æµ‹è¯•æ‹†åˆ†
- en: 'This method is simple: we split our data into two parts. We use one part to
    train our model and the other part to test it. Before we split the data, we mix
    it up randomly so the order of our original data doesnâ€™t affect our results.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•å¾ˆç®€å•ï¼šæˆ‘ä»¬å°†æ•°æ®åˆ†æˆä¸¤éƒ¨åˆ†ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€éƒ¨åˆ†æ¥è®­ç»ƒæ¨¡å‹ï¼Œå¦ä¸€éƒ¨åˆ†æ¥æµ‹è¯•æ¨¡å‹ã€‚åœ¨åˆ†å‰²æ•°æ®ä¹‹å‰ï¼Œæˆ‘ä»¬ä¼šéšæœºæ‰“ä¹±æ•°æ®é¡ºåºï¼Œä»¥ç¡®ä¿åŸå§‹æ•°æ®çš„é¡ºåºä¸ä¼šå½±å“ç»“æœã€‚
- en: 'Both the training and test dataset size depends on our total dataset size,
    usually denoted by their ratio. To determine their size, you can follow this guideline:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å¤§å°å–å†³äºæˆ‘ä»¬çš„æ€»æ•°æ®é›†å¤§å°ï¼Œé€šå¸¸ç”¨å®ƒä»¬çš„æ¯”ä¾‹æ¥è¡¨ç¤ºã€‚ä¸ºäº†ç¡®å®šå®ƒä»¬çš„å¤§å°ï¼Œæ‚¨å¯ä»¥éµå¾ªä»¥ä¸‹æŒ‡å¯¼åŸåˆ™ï¼š
- en: For small datasets (around 1,000â€“10,000 samples), use 80:20 ratio.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºå°å‹æ•°æ®é›†ï¼ˆå¤§çº¦1,000â€“10,000ä¸ªæ ·æœ¬ï¼‰ï¼Œä½¿ç”¨80:20çš„æ¯”ä¾‹ã€‚
- en: For medium datasets (around 10,000â€“100,000 samples), use 70:30 ratio.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºä¸­ç­‰è§„æ¨¡çš„æ•°æ®é›†ï¼ˆå¤§çº¦10,000â€“100,000ä¸ªæ ·æœ¬ï¼‰ï¼Œä½¿ç”¨70:30çš„æ¯”ä¾‹ã€‚
- en: Large datasets (over 100,000 samples), use 90:10 ratio.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§å‹æ•°æ®é›†ï¼ˆè¶…è¿‡100,000ä¸ªæ ·æœ¬ï¼‰ï¼Œä½¿ç”¨90:10çš„æ¯”ä¾‹ã€‚
- en: '![](../Images/ea1cda2f5b4ebaf2ac345e82232c49e6.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea1cda2f5b4ebaf2ac345e82232c49e6.png)'
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/9b572acdaf081abe2ed17104646ae2ac.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b572acdaf081abe2ed17104646ae2ac.png)'
- en: This method is easy to use, but it has some limitation â€” the results can change
    a lot depending on how we randomly split the data. This is why we always need
    to try out different `random_state` to make sure that the result is consistent.
    Also, if we donâ€™t have much data to start with, we might not have enough to properly
    train or test our model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•å¾ˆå®¹æ˜“ä½¿ç”¨ï¼Œä½†ä¹Ÿæœ‰ä¸€äº›å±€é™æ€§ â€”â€” ç»“æœå¯èƒ½ä¼šå› ä¸ºæˆ‘ä»¬å¦‚ä½•éšæœºåˆ†å‰²æ•°æ®è€Œæœ‰å¾ˆå¤§å˜åŒ–ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬æ€»æ˜¯éœ€è¦å°è¯•ä¸åŒçš„`random_state`æ¥ç¡®ä¿ç»“æœçš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œå¦‚æœæˆ‘ä»¬èµ·åˆçš„æ•°æ®ä¸å¤šï¼Œå¯èƒ½æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥å……åˆ†è®­ç»ƒæˆ–æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹ã€‚
- en: Train-Validation-Test Split
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒ-éªŒè¯-æµ‹è¯•æ‹†åˆ†
- en: This method split our data into three parts. The middle part, called validation
    data, is being used to tune the parameters of the model and weâ€™re aiming to have
    the least amount of error there.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•å°†æ•°æ®åˆ†ä¸ºä¸‰éƒ¨åˆ†ã€‚ä¸­é—´éƒ¨åˆ†ï¼Œç§°ä¸ºéªŒè¯æ•°æ®ï¼Œç”¨æ¥è°ƒæ•´æ¨¡å‹çš„å‚æ•°ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°½é‡å‡å°‘è¯¥éƒ¨åˆ†çš„è¯¯å·®ã€‚
- en: Since the validation results is considered many times during this tuning process,
    our model might start doing too well on this validation data (which is what we
    want). This is the reason of why we make the separate test set. We are only testing
    it once at the very end â€” it gives us the truth of how well our model works.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåœ¨è°ƒæ•´è¿‡ç¨‹ä¸­ä¼šå¤šæ¬¡è€ƒè™‘éªŒè¯ç»“æœï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯èƒ½ä¼šåœ¨éªŒè¯æ•°æ®ä¸Šè¡¨ç°å¾—å¤ªå¥½ï¼ˆè¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼‰ã€‚è¿™å°±æ˜¯æˆ‘ä»¬ä¸ºä»€ä¹ˆè¦è®¾ç«‹å•ç‹¬çš„æµ‹è¯•é›†çš„åŸå› ã€‚æˆ‘ä»¬åªåœ¨æœ€åä¸€æ¬¡æµ‹è¯•å®ƒ
    â€”â€” å®ƒèƒ½çœŸå®åœ°åæ˜ å‡ºæˆ‘ä»¬çš„æ¨¡å‹æ•ˆæœå¦‚ä½•ã€‚
- en: 'Here are typical ways to split your data:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¸¸è§çš„æ•°æ®æ‹†åˆ†æ–¹å¼ï¼š
- en: For smaller datasets (1,000â€“10,000 samples), use 60:20:20 ratio.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¾ƒå°çš„æ•°æ®é›†ï¼ˆ1,000â€“10,000ä¸ªæ ·æœ¬ï¼‰ï¼Œä½¿ç”¨60:20:20çš„æ¯”ä¾‹ã€‚
- en: For medium datasets (10,000â€“100,000 samples), use 70:15:15 ratio.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºä¸­ç­‰è§„æ¨¡çš„æ•°æ®é›†ï¼ˆ10,000â€“100,000ä¸ªæ ·æœ¬ï¼‰ï¼Œä½¿ç”¨70:15:15çš„æ¯”ä¾‹ã€‚
- en: Large datasets (> 100,000 samples), use 80:10:10 ratio.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§å‹æ•°æ®é›†ï¼ˆ>100,000ä¸ªæ ·æœ¬ï¼‰ï¼Œä½¿ç”¨80:10:10çš„æ¯”ä¾‹ã€‚
- en: '![](../Images/8abee1c3e7b3526152ccf2256108da3f.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8abee1c3e7b3526152ccf2256108da3f.png)'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/4b6cfed209a3227dfc62eaf3f28413a1.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b6cfed209a3227dfc62eaf3f28413a1.png)'
- en: Hold-out methods work differently depending on how much data you have. They
    work really well when you have lots of data (> 100,000). But when you have less
    data (< 1,000) this method is not be the best. With smaller datasets, you might
    need to use more advanced validation methods to get a better understanding of
    how well your model really works.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿ç•™æ³•æ ¹æ®æ•°æ®é‡çš„ä¸åŒä¼šæœ‰ä¸åŒçš„è¡¨ç°ã€‚å½“ä½ æœ‰å¤§é‡æ•°æ®ï¼ˆ>100,000ä¸ªæ ·æœ¬ï¼‰æ—¶ï¼Œå®ƒæ•ˆæœå¾ˆå¥½ã€‚ä½†å½“ä½ æ•°æ®è¾ƒå°‘ï¼ˆ<1,000ä¸ªæ ·æœ¬ï¼‰æ—¶ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¸æ˜¯æœ€ç†æƒ³çš„ã€‚åœ¨æ•°æ®è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½éœ€è¦ä½¿ç”¨æ›´é«˜çº§çš„éªŒè¯æ–¹æ³•ï¼Œä»¥ä¾¿æ›´å¥½åœ°äº†è§£ä½ çš„æ¨¡å‹åˆ°åº•æœ‰å¤šæœ‰æ•ˆã€‚
- en: ğŸ“Š Moving to Cross-validation
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ“Š è½¬å‘äº¤å‰éªŒè¯
- en: We just learned that hold-out methods might not work very well with small datasets.
    This is exactly the challenge we currently faceâ€” we only have 28 days of data.
    Following the hold-out principle, weâ€™ll keep 14 days of data separate for our
    final test. This leaves us with 14 days to work with for trying other validation
    methods.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆšåˆšäº†è§£åˆ°ï¼Œç•™å‡ºæ³•å¯èƒ½åœ¨å°æ•°æ®é›†ä¸Šæ•ˆæœä¸ä½³ã€‚è¿™æ­£æ˜¯æˆ‘ä»¬ç›®å‰é¢ä¸´çš„æŒ‘æˆ˜â€”â€”æˆ‘ä»¬åªæœ‰28å¤©çš„æ•°æ®ã€‚æŒ‰ç…§ç•™å‡ºæ³•åŸåˆ™ï¼Œæˆ‘ä»¬å°†ä¿ç•™14å¤©çš„æ•°æ®ä½œä¸ºæœ€ç»ˆæµ‹è¯•æ•°æ®ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å‰©ä¸‹14å¤©çš„æ•°æ®å¯ä»¥ç”¨äºå°è¯•å…¶ä»–éªŒè¯æ–¹æ³•ã€‚
- en: '![](../Images/81a27f280c9b79b4950ec9a9f00ae731.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81a27f280c9b79b4950ec9a9f00ae731.png)'
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the next part, weâ€™ll see how cross-validation methods can take these 14 days
    and split them up multiple times in different ways. This gives us a better idea
    of how well our model is really working, even with such limited data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°äº¤å‰éªŒè¯æ–¹æ³•å¦‚ä½•å°†è¿™14å¤©çš„æ•°æ®å¤šæ¬¡åˆ’åˆ†ï¼Œå¹¶ä»¥ä¸åŒçš„æ–¹å¼è¿›è¡Œæµ‹è¯•ã€‚è¿™è®©æˆ‘ä»¬å³ä½¿åœ¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æ›´å¥½åœ°äº†è§£æ¨¡å‹çš„å®é™…æ•ˆæœã€‚
- en: Cross Validation
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äº¤å‰éªŒè¯
- en: Cross-validation changes how we think about testing our models. Instead of testing
    our model just once with one split of data, we test it many times using different
    splits of the same data. This helps us understand much better how well our model
    really works.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: äº¤å‰éªŒè¯æ”¹å˜äº†æˆ‘ä»¬æµ‹è¯•æ¨¡å‹çš„æ–¹å¼ã€‚æˆ‘ä»¬ä¸å†ä»…ä»…ç”¨ä¸€ç§æ•°æ®åˆ’åˆ†æ–¹å¼æµ‹è¯•ä¸€æ¬¡æ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡å¤šæ¬¡ä½¿ç”¨ç›¸åŒæ•°æ®çš„ä¸åŒåˆ’åˆ†æ¥è¿›è¡Œæµ‹è¯•ã€‚è¿™æœ‰åŠ©äºæˆ‘ä»¬æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„å®é™…è¡¨ç°ã€‚
- en: The main idea of cross-validation is to test our model multiple times, and each
    time the training and test dataset come from different part of the our data. This
    helps prevent bias by one really good (or really bad) split of the data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: äº¤å‰éªŒè¯çš„ä¸»è¦æ€æƒ³æ˜¯å¤šæ¬¡æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæ¯æ¬¡çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ½æ¥è‡ªæˆ‘ä»¬æ•°æ®çš„ä¸åŒéƒ¨åˆ†ã€‚è¿™æœ‰åŠ©äºé¿å…ç”±äºæ•°æ®åˆ’åˆ†æç«¯ï¼ˆå¦‚ç‰¹åˆ«å¥½æˆ–ç‰¹åˆ«å·®ï¼‰è€Œå¸¦æ¥çš„åå·®ã€‚
- en: 'Hereâ€™s why this matters: say our model gets 95% accuracy when we test it one
    way, but only 75% when we test it another way using the same data. Which number
    shows how good our model really is? Cross-validation helps us answer this question
    by giving us many test results instead of just one. This gives us a clearer picture
    of how well our model actually performs.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ºä»€ä¹ˆå¾ˆé‡è¦å‘¢ï¼Ÿå‡è®¾æˆ‘ä»¬çš„æ¨¡å‹åœ¨æŸæ¬¡æµ‹è¯•ä¸­å¾—åˆ°95%çš„å‡†ç¡®ç‡ï¼Œè€Œåœ¨å¦ä¸€ç§æµ‹è¯•æ–¹æ³•ä¸‹åªå¾—åˆ°75%çš„å‡†ç¡®ç‡ï¼Œå“ªä¸€ä¸ªç»“æœæ‰æ˜¯çœŸæ­£åæ˜ æ¨¡å‹è¡¨ç°çš„å‘¢ï¼Ÿäº¤å‰éªŒè¯é€šè¿‡æä¾›å¤šä¸ªæµ‹è¯•ç»“æœï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªï¼Œå¸®åŠ©æˆ‘ä»¬å›ç­”è¿™ä¸ªé—®é¢˜ã€‚è¿™è®©æˆ‘ä»¬æ›´æ¸…æ¥šåœ°äº†è§£æ¨¡å‹çš„å®é™…è¡¨ç°ã€‚
- en: K-Fold Methods
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KæŠ˜æ³•
- en: '***Basic K-Fold Cross-Validation*** *K*-fold cross-validation fixes a big problem
    with basic splitting: relying too much on just one way of splitting the data.
    Instead of splitting the data once, *K*-fold splits the data into *K* equal parts.
    Then it tests the model multiple times, using a different part for testing each
    time while using all other parts for training.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '***åŸºç¡€KæŠ˜äº¤å‰éªŒè¯*** *K*æŠ˜äº¤å‰éªŒè¯è§£å†³äº†åŸºæœ¬æ•°æ®åˆ’åˆ†æ–¹æ³•çš„ä¸€ä¸ªå¤§é—®é¢˜ï¼šè¿‡äºä¾èµ–å•ä¸€çš„æ•°æ®åˆ’åˆ†æ–¹å¼ã€‚ä¸å…¶åªè¿›è¡Œä¸€æ¬¡æ•°æ®åˆ’åˆ†ï¼Œ*K*æŠ˜å°†æ•°æ®åˆ’åˆ†æˆ*K*ä¸ªç›¸ç­‰çš„éƒ¨åˆ†ã€‚ç„¶åï¼Œå®ƒå¤šæ¬¡æµ‹è¯•æ¨¡å‹ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éƒ¨åˆ†è¿›è¡Œæµ‹è¯•ï¼Œè€Œå…¶ä»–éƒ¨åˆ†åˆ™ç”¨äºè®­ç»ƒã€‚'
- en: The number we pick for *K* changes how we test our model. Most people use 5
    or 10 for *K*, but this can change based on how much data we have and what we
    need for our project. Letâ€™s say we use *K* = 3\. This means we split our data
    into three equal parts. We then train and test our model three different times.
    Each time, 2/3 of the data is used for training and 1/3 for testing, but we rotate
    which part is being used for testing. This way, every piece of data gets used
    for both training and testing.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€‰æ‹©çš„*K*æ•°å€¼ä¼šå½±å“æˆ‘ä»¬å¦‚ä½•æµ‹è¯•æ¨¡å‹ã€‚å¤§å¤šæ•°äººä½¿ç”¨5æˆ–10ä½œä¸º*K*ï¼Œä½†è¿™ä¸ªæ•°å€¼ä¹Ÿå¯ä»¥æ ¹æ®æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®é‡å’Œé¡¹ç›®éœ€æ±‚æ¥è°ƒæ•´ã€‚å‡è®¾æˆ‘ä»¬ä½¿ç”¨*K* =
    3ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å°†æ•°æ®åˆ†æˆä¸‰ç­‰ä»½ã€‚ç„¶åæˆ‘ä»¬å°†æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•ä¸‰æ¬¡ã€‚æ¯æ¬¡ï¼Œ2/3çš„æ•°æ®ç”¨äºè®­ç»ƒï¼Œ1/3çš„æ•°æ®ç”¨äºæµ‹è¯•ï¼Œä½†æ¯æ¬¡æµ‹è¯•æ—¶ï¼Œæ‰€ç”¨çš„æµ‹è¯•éƒ¨åˆ†éƒ½ä¼šä¸åŒã€‚è¿™æ ·ï¼Œæ¯ä¸ªæ•°æ®ç‰‡æ®µéƒ½ä¼šåŒæ—¶ç”¨äºè®­ç»ƒå’Œæµ‹è¯•ã€‚
- en: '![](../Images/06b5298158f9daf8c0fdf2f24ba9d7f9.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06b5298158f9daf8c0fdf2f24ba9d7f9.png)'
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`Validation accuracy: 0.433 Â± 0.047`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡: 0.433 Â± 0.047`'
- en: '![](../Images/3597efd5b0c424bb9ef27f510ef42907.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3597efd5b0c424bb9ef27f510ef42907.png)'
- en: When weâ€™re done with all the rounds, we calculate the average performance from
    all *K* tests. This average gives us a more trustworthy measure of how well our
    model works. We can also learn about how stable our model is by looking at how
    much the results change between different rounds of testing.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å®Œæˆæ‰€æœ‰è½®æ¬¡åï¼Œæˆ‘ä»¬ä¼šè®¡ç®—æ‰€æœ‰*K*æµ‹è¯•çš„å¹³å‡è¡¨ç°ã€‚è¿™ä¸ªå¹³å‡å€¼ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæ›´å¯é çš„è¡¡é‡æ ‡å‡†ï¼Œæ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹è¡¨ç°å¦‚ä½•ã€‚æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡è§‚å¯Ÿä¸åŒæµ‹è¯•è½®æ¬¡ä¹‹é—´ç»“æœçš„å˜åŒ–ï¼Œæ¥äº†è§£æˆ‘ä»¬çš„æ¨¡å‹æœ‰å¤šç¨³å®šã€‚
- en: '***Stratified K-Fold*** Basic K-fold cross-validation usually works well, but
    it can run into problems when our data is unbalanced â€” meaning we have a lot more
    of one type than others. For example, if we have 100 data points and 90 of them
    are type A while only 10 are type B, randomly splitting this data might give us
    pieces that donâ€™t have enough type B to test properly.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '***åˆ†å±‚ K æŠ˜*** åŸºæœ¬çš„ K æŠ˜äº¤å‰éªŒè¯é€šå¸¸æ•ˆæœä¸é”™ï¼Œä½†å½“æˆ‘ä»¬çš„æ•°æ®ä¸å¹³è¡¡æ—¶â€”â€”å³æŸäº›ç±»å‹çš„æ•°æ®æ¯”å…¶ä»–ç±»å‹å¤šå¾—å¤šâ€”â€”å®ƒå¯èƒ½ä¼šé‡åˆ°é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰
    100 ä¸ªæ•°æ®ç‚¹ï¼Œå…¶ä¸­ 90 ä¸ªæ˜¯ A ç±»å‹ï¼Œè€Œåªæœ‰ 10 ä¸ªæ˜¯ B ç±»å‹ï¼Œéšæœºåˆ’åˆ†è¿™äº›æ•°æ®å¯èƒ½ä¼šå¯¼è‡´æŸäº›åˆ’åˆ†ä¸­æ²¡æœ‰è¶³å¤Ÿçš„ B ç±»å‹æ•°æ®æ¥è¿›è¡Œåˆç†çš„æµ‹è¯•ã€‚'
- en: Stratified K-fold fixes this by making sure each split has the same mix as our
    original data. If our full dataset has 10% type B, each split will also have about
    10% type B. This makes our testing more reliable, especially when some types of
    data are much rarer than others.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†å±‚ K æŠ˜äº¤å‰éªŒè¯é€šè¿‡ç¡®ä¿æ¯ä¸ªæ•°æ®åˆ’åˆ†ä¸åŸå§‹æ•°æ®çš„åˆ†å¸ƒç›¸åŒæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœæˆ‘ä»¬çš„å®Œæ•´æ•°æ®é›†ä¸­æœ‰ 10% æ˜¯ B ç±»å‹ï¼Œé‚£ä¹ˆæ¯ä¸ªåˆ’åˆ†ä¹Ÿå°†åŒ…å«å¤§çº¦ 10%
    çš„ B ç±»å‹æ•°æ®ã€‚è¿™ä½¿å¾—æˆ‘ä»¬çš„æµ‹è¯•æ›´åŠ å¯é ï¼Œç‰¹åˆ«æ˜¯åœ¨æŸäº›æ•°æ®ç±»å‹æ¯”å…¶ä»–ç±»å‹ç¨€å°‘æ—¶ã€‚
- en: '![](../Images/6410d2ca1a0a1801423584f4ee9c30dd.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6410d2ca1a0a1801423584f4ee9c30dd.png)'
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`Validation accuracy: 0.650 Â± 0.071`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡ï¼š0.650 Â± 0.071`'
- en: '![](../Images/6a845da93fa64fae2b73609521f534a5.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a845da93fa64fae2b73609521f534a5.png)'
- en: Keeping this balance helps in two ways. First, it makes sure each split properly
    represents what our data looks like. Second, it gives us more consistent test
    results . This means that if we test our model multiple times, weâ€™ll most likely
    get similar results each time.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿æŒè¿™ç§å¹³è¡¡æœ‰ä¸¤ä¸ªå¥½å¤„ã€‚é¦–å…ˆï¼Œå®ƒç¡®ä¿æ¯ä¸ªåˆ’åˆ†èƒ½å¤Ÿæ°å½“åœ°ä»£è¡¨æˆ‘ä»¬æ•°æ®çš„åˆ†å¸ƒã€‚å…¶æ¬¡ï¼Œå®ƒä½¿å¾—æˆ‘ä»¬çš„æµ‹è¯•ç»“æœæ›´åŠ ä¸€è‡´ã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœæˆ‘ä»¬å¤šæ¬¡æµ‹è¯•æ¨¡å‹ï¼Œæˆ‘ä»¬å¾ˆå¯èƒ½æ¯æ¬¡éƒ½ä¼šå¾—åˆ°ç±»ä¼¼çš„ç»“æœã€‚
- en: '***Repeated K-Fold*** Sometimes, even when we use K-fold validation, our test
    results can change a lot between different random splits. Repeated K-fold solves
    this by running the entire K-fold process multiple times, using different random
    splits each time.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '***é‡å¤ K æŠ˜*** æœ‰æ—¶ï¼Œå³ä½¿æˆ‘ä»¬ä½¿ç”¨äº† K æŠ˜éªŒè¯ï¼Œæµ‹è¯•ç»“æœåœ¨ä¸åŒçš„éšæœºåˆ’åˆ†ä¹‹é—´ä¹Ÿå¯èƒ½å‘ç”Ÿè¾ƒå¤§çš„å˜åŒ–ã€‚é‡å¤ K æŠ˜é€šè¿‡å¤šæ¬¡è¿è¡Œæ•´ä¸ª K æŠ˜è¿‡ç¨‹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éšæœºåˆ’åˆ†ã€‚'
- en: For example, letâ€™s say we run 5-fold cross-validation three times. This means
    our model goes through training and testing 15 times in total. By testing so many
    times, we can better tell which differences in results come from random chance
    and which ones show how well our model really performs. The downside is that all
    this extra testing takes more time to complete.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬è¿è¡Œ 5 æŠ˜äº¤å‰éªŒè¯ä¸‰æ¬¡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬çš„æ¨¡å‹æ€»å…±ä¼šè¿›è¡Œ 15 æ¬¡è®­ç»ƒå’Œæµ‹è¯•ã€‚é€šè¿‡å¦‚æ­¤å¤šæ¬¡çš„æµ‹è¯•ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°åˆ¤æ–­ç»“æœä¸­çš„å·®å¼‚æ˜¯æ¥è‡ªéšæœºå› ç´ ï¼Œè¿˜æ˜¯èƒ½çœŸæ­£åæ˜ å‡ºæ¨¡å‹çš„æ€§èƒ½ã€‚ç¼ºç‚¹æ˜¯ï¼Œæ‰€æœ‰è¿™äº›é¢å¤–çš„æµ‹è¯•éœ€è¦æ›´å¤šçš„æ—¶é—´æ¥å®Œæˆã€‚
- en: '![](../Images/f2b033a8e6b90cc1bad5a07059d1457a.png)![](../Images/53d8b614cdb52f63a8289ec002c7dce5.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2b033a8e6b90cc1bad5a07059d1457a.png)![](../Images/53d8b614cdb52f63a8289ec002c7dce5.png)'
- en: '[PRE7]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`Validation accuracy: 0.425 Â± 0.107`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡ï¼š0.425 Â± 0.107`'
- en: '![](../Images/e94bb4e17347fd027be23da900507dd9.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e94bb4e17347fd027be23da900507dd9.png)'
- en: When we look at repeated K-fold results, since we have many sets of test results,
    we can do more than just calculate the average â€” we can also figure out how confident
    we are in our results. This gives us a better understanding of how reliable our
    model really is.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬æŸ¥çœ‹é‡å¤ K æŠ˜ç»“æœæ—¶ï¼Œç”±äºæˆ‘ä»¬æœ‰å¾ˆå¤šç»„æµ‹è¯•ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥åšçš„ä¸ä»…ä»…æ˜¯è®¡ç®—å¹³å‡å€¼â€”â€”æˆ‘ä»¬è¿˜å¯ä»¥äº†è§£æˆ‘ä»¬å¯¹ç»“æœçš„ä¿¡å¿ƒã€‚è¿™ä½¿æˆ‘ä»¬æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„å¯é æ€§ã€‚
- en: '***Repeated Stratified K-Fold*** This method combines two things we just learned
    about: keeping class balance (stratification) and running multiple rounds of testing
    (repetition). It keeps the right mix of different types of data while testing
    many times. This works especially well when we have a small dataset thatâ€™s uneven
    â€” where we have a lot more of one type of data than others.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '***é‡å¤åˆ†å±‚ K æŠ˜*** è¿™ç§æ–¹æ³•ç»“åˆäº†æˆ‘ä»¬åˆšåˆšå­¦ä¹ çš„ä¸¤ä»¶äº‹ï¼šä¿æŒç±»åˆ«å¹³è¡¡ï¼ˆåˆ†å±‚ï¼‰å’Œè¿›è¡Œå¤šè½®æµ‹è¯•ï¼ˆé‡å¤ï¼‰ã€‚å®ƒåœ¨æµ‹è¯•å¤šæ¬¡çš„åŒæ—¶ä¿æŒäº†ä¸åŒç±»å‹æ•°æ®çš„æ­£ç¡®æ¯”ä¾‹ã€‚è¿™åœ¨æˆ‘ä»¬çš„æ•°æ®é›†è¾ƒå°ä¸”ä¸å¹³è¡¡æ—¶å°¤å…¶æœ‰æ•ˆâ€”â€”ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬æœ‰å¤§é‡ä¸€ç§ç±»å‹çš„æ•°æ®ï¼Œè€Œå…¶ä»–ç±»å‹çš„æ•°æ®è¾ƒå°‘æ—¶ã€‚'
- en: '![](../Images/f9084cb48d717d1a53b287556171438e.png)![](../Images/9736bf44bf4d82ce511033183bcb338a.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9084cb48d717d1a53b287556171438e.png)![](../Images/9736bf44bf4d82ce511033183bcb338a.png)'
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`Validation accuracy: 0.542 Â± 0.167`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡ï¼š0.542 Â± 0.167`'
- en: '![](../Images/61517576ff80c26f2c20ca066afe43fd.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61517576ff80c26f2c20ca066afe43fd.png)'
- en: 'However, thereâ€™s a trade-off: this method takes more time for our computer
    to run. Each time we repeat the whole process, it multiplies how long it takes
    to train our model. When deciding whether to use this method, we need to think
    about whether having more reliable results is worth the extra time it takes to
    run all these tests.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•æœ‰ä¸€ä¸ªæƒè¡¡ï¼šå®ƒéœ€è¦æ›´å¤šçš„æ—¶é—´æ¥è¿è¡Œã€‚æ¯æ¬¡æˆ‘ä»¬é‡å¤æ•´ä¸ªè¿‡ç¨‹æ—¶ï¼Œè®­ç»ƒæ¨¡å‹æ‰€éœ€çš„æ—¶é—´ä¼šæˆå€å¢åŠ ã€‚åœ¨å†³å®šæ˜¯å¦ä½¿ç”¨è¿™ç§æ–¹æ³•æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘ï¼Œæ˜¯å¦å€¼å¾—èŠ±è´¹é¢å¤–çš„æ—¶é—´æ¥è·å¾—æ›´å¯é çš„ç»“æœã€‚
- en: '***Group K-Fold*** Sometimes our data naturally comes in groups that should
    stay together. Think about golf data where we have many measurements from the
    same golf course throughout the year. If we put some measurements from one golf
    course in training data and others in test data, we create a problem: our model
    would indirectly learn about the test data during training because it saw other
    measurements from the same course.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '***åˆ†ç»„ K æŠ˜äº¤å‰éªŒè¯*** æœ‰æ—¶ï¼Œæˆ‘ä»¬çš„æ•°æ®è‡ªç„¶åˆ†ä¸ºä¸€äº›åº”è¯¥ä¿æŒåœ¨ä¸€èµ·çš„ç»„ã€‚ä¾‹å¦‚ï¼Œé«˜å°”å¤«æ•°æ®ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½æœ‰æ¥è‡ªåŒä¸€ä¸ªé«˜å°”å¤«çƒåœºçš„å¤šæ¬¡æµ‹é‡æ•°æ®ã€‚å¦‚æœæˆ‘ä»¬å°†æ¥è‡ªä¸€ä¸ªé«˜å°”å¤«çƒåœºçš„éƒ¨åˆ†æµ‹é‡æ•°æ®æ”¾å…¥è®­ç»ƒæ•°æ®ï¼Œè€Œå…¶ä»–çš„æ”¾å…¥æµ‹è¯•æ•°æ®ï¼Œå°±ä¼šå‡ºç°é—®é¢˜ï¼šæˆ‘ä»¬çš„æ¨¡å‹å¯èƒ½ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é—´æ¥äº†è§£æµ‹è¯•æ•°æ®ï¼Œå› ä¸ºå®ƒçœ‹åˆ°äº†æ¥è‡ªåŒä¸€çƒåœºçš„å…¶ä»–æµ‹é‡æ•°æ®ã€‚'
- en: Group K-fold fixes this by keeping all data from the same group (like all measurements
    from one golf course) together in the same part when we split the data. This prevents
    our model from accidentally seeing information it shouldnâ€™t, which could make
    us think it performs better than it really does.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç»„ K æŠ˜äº¤å‰éªŒè¯é€šè¿‡ä¿æŒæ¥è‡ªåŒä¸€ç»„çš„æ•°æ®ï¼ˆä¾‹å¦‚æ¥è‡ªåŒä¸€é«˜å°”å¤«çƒåœºçš„æ‰€æœ‰æµ‹é‡æ•°æ®ï¼‰ä¸€èµ·åˆ’åˆ†ï¼Œæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚è¿™å¯ä»¥é˜²æ­¢æˆ‘ä»¬çš„æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ— æ„ä¸­çœ‹åˆ°ä¸åº”è¯¥çœ‹åˆ°çš„ä¿¡æ¯ï¼Œä»è€Œè®©æˆ‘ä»¬è¯¯ä»¥ä¸ºå®ƒè¡¨ç°å¾—æ¯”å®é™…æƒ…å†µæ›´å¥½ã€‚
- en: '![](../Images/cde7db87459ae48728b9dd87dd26ac88.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cde7db87459ae48728b9dd87dd26ac88.png)'
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`Validation accuracy: 0.417 Â± 0.143`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®åº¦: 0.417 Â± 0.143`'
- en: '![](../Images/616c266d6ae7d923873b81a26b0df5de.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/616c266d6ae7d923873b81a26b0df5de.png)'
- en: This method can be important when working with data that naturally comes in
    groups, like multiple weather readings from the same golf course or data that
    was collected over time from the same location.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å¤„ç†è‡ªç„¶åˆ†ç»„çš„æ•°æ®æ—¶ï¼Œè¿™ç§æ–¹æ³•å°¤å…¶é‡è¦ï¼Œæ¯”å¦‚æ¥è‡ªåŒä¸€ä¸ªé«˜å°”å¤«çƒåœºçš„å¤šæ¬¡å¤©æ°”æ•°æ®ï¼Œæˆ–è€…åŒä¸€åœ°ç‚¹åœ¨ä¸åŒæ—¶é—´æ”¶é›†çš„æ•°æ®ã€‚
- en: '***Time Series Split*** When we split data randomly in regular K-fold, we assume
    each piece of data doesnâ€™t affect the others. But this doesnâ€™t work well with
    data that changes over time, where what happened before affects what happens next.
    Time series split changes K-fold to work better with this kind of time-ordered
    data.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '***æ—¶é—´åºåˆ—åˆ’åˆ†*** å½“æˆ‘ä»¬åœ¨å¸¸è§„çš„ K æŠ˜äº¤å‰éªŒè¯ä¸­éšæœºåˆ’åˆ†æ•°æ®æ—¶ï¼Œæˆ‘ä»¬å‡è®¾æ¯ä¸ªæ•°æ®ç‚¹ä¸ä¼šå½±å“å…¶ä»–æ•°æ®ç‚¹ã€‚ä½†è¿™å¯¹äºéšæ—¶é—´å˜åŒ–çš„æ•°æ®å¹¶ä¸é€‚ç”¨ï¼Œå› ä¸ºè¿‡å»å‘ç”Ÿçš„äº‹æƒ…ä¼šå½±å“æœªæ¥çš„ç»“æœã€‚æ—¶é—´åºåˆ—åˆ’åˆ†é€šè¿‡è°ƒæ•´
    K æŠ˜äº¤å‰éªŒè¯ï¼Œæ›´å¥½åœ°å¤„ç†è¿™ç§æ—¶é—´é¡ºåºæ•°æ®ã€‚'
- en: Instead of splitting data randomly, time series split uses data in order, from
    past to future. The training data only includes information from times before
    the testing data. This matches how we use models in real life, where we use past
    data to predict what will happen next.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—åˆ’åˆ†å¹¶ééšæœºåˆ†å‰²æ•°æ®ï¼Œè€Œæ˜¯æŒ‰é¡ºåºä½¿ç”¨æ•°æ®ï¼Œä»è¿‡å»åˆ°æœªæ¥ã€‚è®­ç»ƒæ•°æ®ä»…åŒ…æ‹¬æµ‹è¯•æ•°æ®ä¹‹å‰çš„æ—¶é—´æ®µçš„ä¿¡æ¯ã€‚è¿™ä¸æˆ‘ä»¬åœ¨ç°å®ç”Ÿæ´»ä¸­ä½¿ç”¨æ¨¡å‹çš„æ–¹å¼ä¸€è‡´ï¼Œå³æˆ‘ä»¬åˆ©ç”¨è¿‡å»çš„æ•°æ®æ¥é¢„æµ‹æœªæ¥çš„äº‹ä»¶ã€‚
- en: '![](../Images/81146fa4c70beaca8801445fd200d3fb.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81146fa4c70beaca8801445fd200d3fb.png)'
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`Validation accuracy: 0.556 Â± 0.157`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®åº¦: 0.556 Â± 0.157`'
- en: '![](../Images/4d881beb9b6d1811302457256067f38f.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d881beb9b6d1811302457256067f38f.png)'
- en: For example, with *K*=3 and our golf data, we might train using weather data
    from January and February to predict Marchâ€™s golf playing patterns. Then weâ€™d
    train using January through March to predict April, and so on. By only going forward
    in time, this method gives us a more realistic idea of how well our model will
    work when predicting future golf playing patterns based on weather.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå‡è®¾*K*=3ï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰é«˜å°”å¤«æ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€æœˆå’ŒäºŒæœˆçš„å¤©æ°”æ•°æ®è®­ç»ƒï¼Œæ¥é¢„æµ‹ä¸‰æœˆçš„é«˜å°”å¤«æ‰“çƒæ¨¡å¼ã€‚æ¥ç€ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€æœˆåˆ°ä¸‰æœˆçš„æ•°æ®æ¥é¢„æµ‹å››æœˆï¼Œä¾æ­¤ç±»æ¨ã€‚é€šè¿‡åªå‘å‰æ¨è¿›æ—¶é—´ï¼Œè¿™ç§æ–¹æ³•èƒ½æ›´çœŸå®åœ°åæ˜ æˆ‘ä»¬çš„æ¨¡å‹åœ¨é¢„æµ‹åŸºäºå¤©æ°”çš„æœªæ¥é«˜å°”å¤«æ‰“çƒæ¨¡å¼æ—¶çš„è¡¨ç°ã€‚
- en: Leave-Out Methods
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç•™å‡ºæ³•
- en: '***Leave-One-Out Cross-Validation (LOOCV)*** Leave-One-Out Cross-Validation
    (LOOCV) is the most thorough validation method. It uses just *one* sample for
    testing and all other samples for training. The validation is repeated until every
    single piece of data has been used for testing.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '***ç•™ä¸€äº¤å‰éªŒè¯ (LOOCV)*** ç•™ä¸€äº¤å‰éªŒè¯ (LOOCV) æ˜¯æœ€å½»åº•çš„éªŒè¯æ–¹æ³•ã€‚å®ƒä»…ä½¿ç”¨*ä¸€ä¸ª*æ ·æœ¬è¿›è¡Œæµ‹è¯•ï¼Œå…¶ä»–æ‰€æœ‰æ ·æœ¬ç”¨äºè®­ç»ƒã€‚éªŒè¯ä¼šé‡å¤è¿›è¡Œï¼Œç›´åˆ°æ¯ä¸€æ¡æ•°æ®éƒ½è¢«ç”¨ä½œæµ‹è¯•ã€‚'
- en: Letâ€™s say we have 100 days of golf weather data. LOOCV would train and test
    the model 100 times. Each time, it uses 99 days for training and 1 day for testing.
    This method removes any randomness in testing â€” if you run LOOCV on the same data
    multiple times, youâ€™ll always get the same results.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰100å¤©çš„é«˜å°”å¤«å¤©æ°”æ•°æ®ã€‚LOOCVä¼šè®­ç»ƒå¹¶æµ‹è¯•æ¨¡å‹100æ¬¡ã€‚æ¯æ¬¡ï¼Œå®ƒä½¿ç”¨99å¤©çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œ1å¤©çš„æ•°æ®è¿›è¡Œæµ‹è¯•ã€‚è¿™ç§æ–¹æ³•æ¶ˆé™¤äº†æµ‹è¯•ä¸­çš„ä»»ä½•éšæœºæ€§â€”â€”å¦‚æœä½ å¤šæ¬¡åœ¨ç›¸åŒçš„æ•°æ®ä¸Šè¿è¡ŒLOOCVï¼Œä½ å°†å§‹ç»ˆå¾—åˆ°ç›¸åŒçš„ç»“æœã€‚
- en: However, LOOCV takes a lot of computing time. If you have *N* pieces of data,
    you need to train your model *N* times. With large datasets or complex models,
    this might take too long to be practical. Some simpler models, like linear ones,
    have shortcuts that make LOOCV faster, but this isnâ€™t true for all models.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼ŒLOOCVéœ€è¦å¾ˆé•¿çš„è®¡ç®—æ—¶é—´ã€‚å¦‚æœä½ æœ‰*N*ä¸ªæ•°æ®ç‚¹ï¼Œä½ éœ€è¦è®­ç»ƒæ¨¡å‹*N*æ¬¡ã€‚å¯¹äºå¤§å‹æ•°æ®é›†æˆ–å¤æ‚æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦çš„æ—¶é—´å¤ªé•¿ï¼Œæ— æ³•å®é™…ä½¿ç”¨ã€‚ä¸€äº›ç®€å•çš„æ¨¡å‹ï¼Œå¦‚çº¿æ€§æ¨¡å‹ï¼Œæœ‰ä¸€äº›æ·å¾„ä½¿å¾—LOOCVå˜å¾—æ›´å¿«ï¼Œä½†å¹¶ä¸æ˜¯æ‰€æœ‰æ¨¡å‹éƒ½é€‚ç”¨ã€‚
- en: '![](../Images/52e0f4b1c42428101fe15f6f81637446.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52e0f4b1c42428101fe15f6f81637446.png)'
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`Validation accuracy: 0.429 Â± 0.495`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡ï¼š0.429 Â± 0.495`'
- en: '![](../Images/40709bb360f71992f6218297c2d2242e.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40709bb360f71992f6218297c2d2242e.png)'
- en: LOOCV works really well when we donâ€™t have much data and need to make the most
    of every piece we have. Since the result depend on every single data, the results
    can change a lot if our data has noise or unusual values in it.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: LOOCVåœ¨æ•°æ®é‡ä¸å¤šï¼Œéœ€è¦æœ€å¤§é™åº¦åˆ©ç”¨æ¯ä¸€ä»½æ•°æ®æ—¶è¡¨ç°å¾—éå¸¸å¥½ã€‚ç”±äºç»“æœä¾èµ–äºæ¯ä¸€æ¡æ•°æ®ï¼Œå¦‚æœæ•°æ®ä¸­æœ‰å™ªå£°æˆ–å¼‚å¸¸å€¼ï¼Œç»“æœå¯èƒ½ä¼šæœ‰å¾ˆå¤§å˜åŒ–ã€‚
- en: '***Leave-P-Out Cross-Validation*** Leave-P-Out builds on the idea of Leave-One-Out,
    but instead of testing with just one piece of data, it tests with P pieces at
    a time. This creates a balance between Leave-One-Out and K-fold validation. The
    number we choose for P changes how we test the model and how long it takes.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '***Leave-P-Outäº¤å‰éªŒè¯*** Leave-P-OutåŸºäºLeave-One-Outçš„æ€æƒ³ï¼Œä½†å®ƒæ¯æ¬¡æµ‹è¯•æ—¶ä½¿ç”¨Pä¸ªæ•°æ®ç‚¹ï¼Œè€Œä¸æ˜¯ä»…æµ‹è¯•ä¸€ä¸ªæ•°æ®ç‚¹ã€‚è¿™åœ¨Leave-One-Outå’ŒK-foldéªŒè¯ä¹‹é—´åˆ›é€ äº†å¹³è¡¡ã€‚æˆ‘ä»¬é€‰æ‹©çš„På€¼ä¼šæ”¹å˜æ¨¡å‹çš„æµ‹è¯•æ–¹å¼ä»¥åŠæ‰€éœ€çš„æ—¶é—´ã€‚'
- en: The main problem with Leave-P-Out is how quickly the number of possible test
    combinations grows. For example, if we have 100 days of golf weather data and
    we want to test with 5 days at a time (P=5), there are millions of different possible
    ways to choose those 5 days. Testing all these combinations takes too much time
    when we have lots of data or when we use a larger number for P.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Leave-P-Outçš„ä¸»è¦é—®é¢˜æ˜¯å¯èƒ½çš„æµ‹è¯•ç»„åˆæ•°é‡å¢é•¿å¾—éå¸¸å¿«ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰100å¤©çš„é«˜å°”å¤«å¤©æ°”æ•°æ®ï¼Œå¹¶ä¸”æ¯æ¬¡æµ‹è¯•5å¤©ï¼ˆP=5ï¼‰ï¼Œé‚£ä¹ˆé€‰æ‹©è¿™5å¤©çš„æ–¹å¼æœ‰æ•°ç™¾ä¸‡ç§ä¸åŒçš„ç»„åˆã€‚å½“æ•°æ®é‡å¾ˆå¤§æˆ–På€¼è¾ƒå¤§æ—¶ï¼Œæµ‹è¯•æ‰€æœ‰è¿™äº›ç»„åˆä¼šè€—è´¹å¤§é‡æ—¶é—´ã€‚
- en: '![](../Images/b08884b049867b549153b90e059cd20b.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b08884b049867b549153b90e059cd20b.png)'
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`Validation accuracy: 0.441 Â± 0.254`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡ï¼š0.441 Â± 0.254`'
- en: '![](../Images/b285dc37f93b1968c4e62df28fba57d7.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b285dc37f93b1968c4e62df28fba57d7.png)'
- en: Because of these practical limits, Leave-P-Out is mostly used in special cases
    where we need very thorough testing and have a small enough dataset to make it
    work. Itâ€™s especially useful in research projects where getting the most accurate
    test results matters more than how long the testing takes.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè¿™äº›å®é™…é™åˆ¶ï¼ŒLeave-P-Outé€šå¸¸ç”¨äºéœ€è¦éå¸¸å½»åº•æµ‹è¯•ä¸”æ•°æ®é›†è¶³å¤Ÿå°ä»¥ä½¿å…¶å¯è¡Œçš„ç‰¹æ®Šæƒ…å†µã€‚å®ƒåœ¨ç ”ç©¶é¡¹ç›®ä¸­å°¤å…¶æœ‰ç”¨ï¼Œåœ¨è¿™äº›é¡¹ç›®ä¸­ï¼Œè·å–æœ€å‡†ç¡®çš„æµ‹è¯•ç»“æœæ¯”æµ‹è¯•æ‰€éœ€çš„æ—¶é—´æ›´ä¸ºé‡è¦ã€‚
- en: Random Methods
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éšæœºæ–¹æ³•
- en: '***ShuffleSplit Cross-Validation*** ShuffleSplit works differently from other
    validation methods by using completely random splits. Instead of splitting data
    in an organized way like K-fold, or testing every possible combination like Leave-P-Out,
    ShuffleSplit creates random training and testing splits each time.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '***ShuffleSplitäº¤å‰éªŒè¯*** ShuffleSplitä¸å…¶ä»–éªŒè¯æ–¹æ³•ä¸åŒï¼Œå®ƒé‡‡ç”¨å®Œå…¨éšæœºçš„åˆ†å‰²æ–¹å¼ã€‚ä¸K-foldæŒ‰æœ‰åºæ–¹å¼åˆ’åˆ†æ•°æ®ï¼Œæˆ–åƒLeave-P-Outé‚£æ ·æµ‹è¯•æ‰€æœ‰å¯èƒ½çš„ç»„åˆä¸åŒï¼ŒShuffleSplitæ¯æ¬¡éƒ½ä¼šåˆ›å»ºéšæœºçš„è®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²ã€‚'
- en: What makes ShuffleSplit different from K-fold is that the splits donâ€™t follow
    any pattern. In K-fold, each piece of data gets used exactly once for testing.
    But in ShuffleSplit, a single day of golf weather data might be used for testing
    several times, or might not be used for testing at all. This randomness gives
    us a different way to understand how well our model performs.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ShuffleSplitä¸K-foldçš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œåˆ†å‰²ä¸éµå¾ªä»»ä½•å›ºå®šæ¨¡å¼ã€‚åœ¨K-foldä¸­ï¼Œæ¯æ¡æ•°æ®éƒ½æ°å¥½ç”¨äºä¸€æ¬¡æµ‹è¯•ã€‚ä½†åœ¨ShuffleSplitä¸­ï¼Œä¸€å¤©çš„é«˜å°”å¤«å¤©æ°”æ•°æ®å¯èƒ½è¢«ç”¨äºå¤šæ¬¡æµ‹è¯•ï¼Œä¹Ÿå¯èƒ½æ ¹æœ¬ä¸è¢«ç”¨äºæµ‹è¯•ã€‚è¿™ç§éšæœºæ€§ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§ä¸åŒçš„æ–¹å¼æ¥ç†è§£æ¨¡å‹çš„è¡¨ç°ã€‚
- en: ShuffleSplit works especially well with large datasets where K-fold might take
    too long to run. We can choose how many times we want to test, no matter how much
    data we have. We can also control how big each split should be. This lets us find
    a good balance between thorough testing and the time it takes to run.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ShuffleSplit åœ¨å¤§æ•°æ®é›†ä¸Šç‰¹åˆ«æœ‰æ•ˆï¼Œè€Œ K-æŠ˜äº¤å‰éªŒè¯å¯èƒ½éœ€è¦èŠ±è´¹è¿‡å¤šæ—¶é—´æ¥è¿è¡Œã€‚æˆ‘ä»¬å¯ä»¥é€‰æ‹©æµ‹è¯•å¤šå°‘æ¬¡ï¼Œæ— è®ºæ•°æ®é‡å¤šå¤§ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æ§åˆ¶æ¯æ¬¡åˆ’åˆ†çš„å¤§å°ã€‚è¿™è®©æˆ‘ä»¬èƒ½å¤Ÿåœ¨å…¨é¢æµ‹è¯•å’Œè¿è¡Œæ—¶é—´ä¹‹é—´æ‰¾åˆ°ä¸€ä¸ªè‰¯å¥½çš„å¹³è¡¡ã€‚
- en: '![](../Images/923156cc72cc526aae6376b4a83d7b24.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/923156cc72cc526aae6376b4a83d7b24.png)'
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`Validation accuracy: 0.333 Â± 0.272`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡ï¼š0.333 Â± 0.272`'
- en: '![](../Images/8c1642d4aa7fd19870eddc81316dddfa.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c1642d4aa7fd19870eddc81316dddfa.png)'
- en: Since ShuffleSplit can create as many random splits as we want, itâ€™s useful
    when we want to see how our modelâ€™s performance changes with different random
    splits, or when we need more tests to be confident about our results.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº ShuffleSplit å¯ä»¥åˆ›å»ºä»»æ„æ•°é‡çš„éšæœºåˆ’åˆ†ï¼Œå®ƒåœ¨æˆ‘ä»¬å¸Œæœ›æŸ¥çœ‹æ¨¡å‹æ€§èƒ½å¦‚ä½•éšä¸åŒçš„éšæœºåˆ’åˆ†è€Œå˜åŒ–ï¼Œæˆ–åœ¨æˆ‘ä»¬éœ€è¦æ›´å¤šçš„æµ‹è¯•ä»¥ç¡®ä¿ç»“æœçš„å¯é æ€§æ—¶éå¸¸æœ‰ç”¨ã€‚
- en: '***Stratified ShuffleSplit*** Stratified ShuffleSplit combines random splitting
    with keeping the right mix of different types of data. Like Stratified K-fold,
    it makes sure each split has about the same percentage of each type of data as
    the full dataset.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '***åˆ†å±‚ ShuffleSplit*** åˆ†å±‚ ShuffleSplit ç»“åˆäº†éšæœºåˆ’åˆ†å’Œä¿æŒä¸åŒç±»å‹æ•°æ®çš„æ­£ç¡®æ··åˆã€‚åƒåˆ†å±‚ K-æŠ˜äº¤å‰éªŒè¯ä¸€æ ·ï¼Œå®ƒç¡®ä¿æ¯ä¸ªåˆ’åˆ†çš„æ¯ç§ç±»å‹çš„æ•°æ®å æ¯”ä¸æ•´ä¸ªæ•°æ®é›†ç›¸åŒã€‚'
- en: 'This method gives us the best of both worlds: the freedom of random splitting
    and the fairness of keeping data balanced. For example, if our golf dataset has
    70% â€œyesâ€ days and 30% â€œnoâ€ days for playing golf, each random split will try
    to keep this same 70â€“30 mix. This is especially useful when we have uneven data,
    where random splitting might accidentally create test sets that donâ€™t represent
    our data well.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ–¹æ³•ä¸ºæˆ‘ä»¬æä¾›äº†åŒèµ¢çš„å±€é¢ï¼šæ—¢æœ‰éšæœºåˆ’åˆ†çš„è‡ªç”±ï¼Œåˆæœ‰ä¿æŒæ•°æ®å¹³è¡¡çš„å…¬å¹³æ€§ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬çš„é«˜å°”å¤«æ•°æ®é›†æœ‰ 70% çš„â€œæ˜¯â€å¤©å’Œ 30% çš„â€œå¦â€å¤©ï¼Œæ¯ä¸ªéšæœºåˆ’åˆ†éƒ½ä¼šå°½é‡ä¿æŒè¿™ä¸€
    70-30 çš„æ¯”ä¾‹ã€‚è¿™åœ¨æ•°æ®ä¸å‡è¡¡æ—¶å°¤å…¶æœ‰ç”¨ï¼Œå› ä¸ºéšæœºåˆ’åˆ†å¯èƒ½ä¼šæ— æ„ä¸­åˆ›å»ºä¸ä»£è¡¨æˆ‘ä»¬æ•°æ®çš„æµ‹è¯•é›†ã€‚
- en: '![](../Images/c6f0a11a4d547374bf57dafa1869e61c.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6f0a11a4d547374bf57dafa1869e61c.png)'
- en: '[PRE14]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`Validation accuracy: 0.556 Â± 0.157`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡ï¼š0.556 Â± 0.157`'
- en: '![](../Images/96409b67fddbc5e5715ea4f0bed7f347.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96409b67fddbc5e5715ea4f0bed7f347.png)'
- en: However, trying to keep both the random nature of the splits and the right mix
    of data types can be tricky. The method sometimes has to make small compromises
    between being perfectly random and keeping perfect proportions. In real use, these
    small trade-offs rarely cause problems, and having balanced test sets is usually
    matters more than having perfectly random splits.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä¿æŒåˆ’åˆ†çš„éšæœºæ€§ä»¥åŠæ•°æ®ç±»å‹çš„æ­£ç¡®æ··åˆå¯èƒ½ä¼šå¾ˆæ£˜æ‰‹ã€‚è¯¥æ–¹æ³•æœ‰æ—¶éœ€è¦åœ¨å®Œå…¨éšæœºå’Œä¿æŒå®Œç¾æ¯”ä¾‹ä¹‹é—´åšå‡ºä¸€äº›å°çš„å¦¥åã€‚åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™äº›å°çš„æŠ˜è¡·å¾ˆå°‘ä¼šå¼•èµ·é—®é¢˜ï¼Œä¸”é€šå¸¸ä¿æŒæµ‹è¯•é›†çš„å¹³è¡¡æ¯”æ‹¥æœ‰å®Œå…¨éšæœºçš„åˆ’åˆ†æ›´ä¸ºé‡è¦ã€‚
- en: ğŸŒŸ Validation Techniques Summarized & Code Summary
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸŒŸ éªŒè¯æŠ€æœ¯æ€»ç»“ä¸ä»£ç æ€»ç»“
- en: 'To summarize, model validation methods fall into two main categories: hold-out
    methods and cross-validation methods:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“æ¥è¯´ï¼Œæ¨¡å‹éªŒè¯æ–¹æ³•åˆ†ä¸ºä¸¤å¤§ç±»ï¼šç•™å‡ºæ³•å’Œäº¤å‰éªŒè¯æ³•ï¼š
- en: '**Hold-out Methods** Â· Train-Test Split: The simplest approach, dividing data
    into two parts'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç•™å‡ºæ³•** Â· è®­ç»ƒ-æµ‹è¯•åˆ†å‰²ï¼šæœ€ç®€å•çš„æ–¹æ³•ï¼Œå°†æ•°æ®åˆ†æˆä¸¤éƒ¨åˆ†'
- en: 'Â· Train-Validation-Test Split: A three-way split for more complex model development'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Â· è®­ç»ƒ-éªŒè¯-æµ‹è¯•åˆ†å‰²ï¼šä¸€ç§ä¸‰åˆ†æ³•ç”¨äºæ›´å¤æ‚çš„æ¨¡å‹å¼€å‘
- en: '**Cross-validation Methods** Cross-validation methods make better use of available
    data through multiple rounds of validation:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**äº¤å‰éªŒè¯æ³•** äº¤å‰éªŒè¯æ³•é€šè¿‡å¤šè½®éªŒè¯æ›´å¥½åœ°åˆ©ç”¨å¯ç”¨æ•°æ®ï¼š'
- en: '*K-Fold Methods* Rather than a single split, these methods divide data into
    K parts:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '*K-æŠ˜äº¤å‰éªŒè¯æ³•* è¿™äº›æ–¹æ³•å°†æ•°æ®åˆ†ä¸º K ä¸ªéƒ¨åˆ†ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå•ç‹¬çš„åˆ’åˆ†ï¼š'
- en: 'Â· Basic K-Fold: Rotates through different test sets'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Â· åŸºæœ¬ K-æŠ˜äº¤å‰éªŒè¯ï¼šè½®æµä½¿ç”¨ä¸åŒçš„æµ‹è¯•é›†
- en: 'Â· Stratified K-Fold: Maintains class balance across splits'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Â· åˆ†å±‚ K-æŠ˜äº¤å‰éªŒè¯ï¼šä¿æŒå„ä¸ªåˆ’åˆ†ä¸­çš„ç±»åˆ«å¹³è¡¡
- en: 'Â· Group K-Fold: Preserves data grouping'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Â· åˆ†ç»„ K-æŠ˜äº¤å‰éªŒè¯ï¼šä¿ç•™æ•°æ®åˆ†ç»„
- en: 'Â· Time Series Split: Respects temporal order'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Â· æ—¶é—´åºåˆ—åˆ†å‰²ï¼šå°Šé‡æ—¶é—´é¡ºåº
- en: Â· Repeated K-Fold
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Â· é‡å¤ K-æŠ˜äº¤å‰éªŒè¯
- en: Â· Repeated Stratified K-Fold
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Â· é‡å¤åˆ†å±‚ K-æŠ˜äº¤å‰éªŒè¯
- en: '*Leave-Out Methods* These methods take validation to the extreme:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç•™å‡ºæ³•* è¿™äº›æ–¹æ³•å°†éªŒè¯æ¨å‘æé™ï¼š'
- en: 'Â· Leave-P-Out: Tests on P data points at a time'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Â· ç•™ P æ³•ï¼šä¸€æ¬¡å¯¹ P ä¸ªæ•°æ®ç‚¹è¿›è¡Œæµ‹è¯•
- en: 'Â· Leave-One-Out: Tests on single data points'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Â· ç•™ä¸€æ³•ï¼šå¯¹å•ä¸ªæ•°æ®ç‚¹è¿›è¡Œæµ‹è¯•
- en: '*Random Methods* These introduce controlled randomness:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*éšæœºæ–¹æ³•* è¿™äº›æ–¹æ³•å¼•å…¥äº†å—æ§çš„éšæœºæ€§ï¼š'
- en: 'Â· ShuffleSplit: Creates random splits repeatedly'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Â· ShuffleSplitï¼šé‡å¤åˆ›å»ºéšæœºåˆ’åˆ†
- en: 'Â· Stratified ShuffleSplit: Random splits with balanced classes'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Â· åˆ†å±‚ ShuffleSplitï¼šéšæœºåˆ’åˆ†ä¸”ä¿æŒç±»åˆ«å¹³è¡¡
- en: '[PRE15]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '`Validation accuracy: 0.429 Â± 0.495`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`éªŒè¯å‡†ç¡®ç‡: 0.429 Â± 0.495`'
- en: '`Test accuracy: 0.714`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`æµ‹è¯•å‡†ç¡®ç‡: 0.714`'
- en: '***Comment on the result above:*** The large gap between validation and test
    accuracy, along with the very high standard deviation in validation scores, suggests
    our modelâ€™s performance is unstable. This inconsistency likely comes from using
    LeaveOneOut validation on our small weather dataset â€” testing on single data points
    causes performance to vary dramatically. A different validation method using larger
    validation sets might give us more reliable results.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '***å¯¹ä¸Šè¿°ç»“æœçš„è¯„è®º:*** éªŒè¯å‡†ç¡®ç‡å’Œæµ‹è¯•å‡†ç¡®ç‡ä¹‹é—´çš„å·¨å¤§å·®è·ï¼Œä»¥åŠéªŒè¯åˆ†æ•°ä¸­éå¸¸é«˜çš„æ ‡å‡†å·®ï¼Œè¡¨æ˜æˆ‘ä»¬çš„æ¨¡å‹è¡¨ç°ä¸ç¨³å®šã€‚è¿™ç§ä¸ä¸€è‡´æ€§å¾ˆå¯èƒ½æ¥æºäºåœ¨æˆ‘ä»¬çš„å°å‹å¤©æ°”æ•°æ®é›†ä¸Šä½¿ç”¨
    LeaveOneOut éªŒè¯â€”â€”åœ¨å•ä¸ªæ•°æ®ç‚¹ä¸Šè¿›è¡Œæµ‹è¯•å¯¼è‡´æ€§èƒ½å‰§çƒˆæ³¢åŠ¨ã€‚ä½¿ç”¨è¾ƒå¤§çš„éªŒè¯é›†çš„ä¸åŒéªŒè¯æ–¹æ³•å¯èƒ½ä¼šç»™æˆ‘ä»¬å¸¦æ¥æ›´å¯é çš„ç»“æœã€‚'
- en: Choosing the Right Validation Method
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é€‰æ‹©æ­£ç¡®çš„éªŒè¯æ–¹æ³•
- en: 'Choosing how to validate your model isnâ€™t simple â€” different situations need
    different approaches. Understanding which method to use can mean the difference
    between getting reliable or misleading results. Here are some aspect that you
    should consider when choosing the validation method:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©å¦‚ä½•éªŒè¯æ¨¡å‹å¹¶ä¸ç®€å•â€”â€”ä¸åŒçš„æƒ…å†µéœ€è¦ä¸åŒçš„æ–¹æ³•ã€‚ç†è§£ä½¿ç”¨å“ªç§æ–¹æ³•å¯èƒ½æ„å‘³ç€è·å¾—å¯é ç»“æœæˆ–è¯¯å¯¼æ€§ç»“æœä¹‹é—´çš„å·®å¼‚ã€‚ä»¥ä¸‹æ˜¯é€‰æ‹©éªŒè¯æ–¹æ³•æ—¶åº”è¯¥è€ƒè™‘çš„ä¸€äº›æ–¹é¢ï¼š
- en: 1\. Dataset Size
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. æ•°æ®é›†å¤§å°
- en: 'The size of your dataset strongly influences which validation method works
    best. Letâ€™s look at different sizes:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†çš„å¤§å°å¯¹é€‰æ‹©å“ªç§éªŒè¯æ–¹æ³•æœ€æœ‰æ•ˆæœ‰å¾ˆå¤§çš„å½±å“ã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ä¸åŒå¤§å°çš„æ•°æ®é›†ï¼š
- en: '**Large Datasets (More than 100,000 samples)**'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¤§æ•°æ®é›†ï¼ˆè¶…è¿‡ 100,000 ä¸ªæ ·æœ¬ï¼‰**'
- en: When you have large datasets, the amount of time to test becomes one of the
    main consideration. Simple hold-out validation (splitting data once into training
    and testing) often works well because you have enough data for reliable testing.
    If you need to use cross-validation, using just 3 folds or using ShuffleSplit
    with fewer rounds can give good results without taking too long to run.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ æœ‰å¤§é‡æ•°æ®é›†æ—¶ï¼Œæµ‹è¯•æ‰€éœ€çš„æ—¶é—´æˆä¸ºä¸»è¦è€ƒè™‘å› ç´ ä¹‹ä¸€ã€‚ç®€å•çš„ä¿ç•™éªŒè¯ï¼ˆå°†æ•°æ®ä¸€æ¬¡æ€§åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼‰é€šå¸¸æ•ˆæœä¸é”™ï¼Œå› ä¸ºä½ æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œå¯é çš„æµ‹è¯•ã€‚å¦‚æœéœ€è¦ä½¿ç”¨äº¤å‰éªŒè¯ï¼Œä½¿ç”¨
    3 æŠ˜æˆ–ä½¿ç”¨ ShuffleSplit è¿›è¡Œè¾ƒå°‘è½®æ¬¡çš„éªŒè¯å¯ä»¥åœ¨ä¸èŠ±è´¹å¤ªå¤šæ—¶é—´çš„æƒ…å†µä¸‹è·å¾—è‰¯å¥½çš„ç»“æœã€‚
- en: '***Medium Datasets (1,000 to 100,000 samples)***'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '***ä¸­ç­‰æ•°æ®é›†ï¼ˆ1,000 åˆ° 100,000 ä¸ªæ ·æœ¬ï¼‰***'
- en: For medium-sized datasets, regular K-fold cross-validation works best. Using
    5 or 10 folds gives a good balance between reliable results and reasonable computing
    time. This amount of data is usually enough to create representative splits but
    not so much that testing takes too long.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸­ç­‰å¤§å°çš„æ•°æ®é›†ï¼Œå¸¸è§„çš„ K æŠ˜äº¤å‰éªŒè¯æ•ˆæœæœ€ä½³ã€‚ä½¿ç”¨ 5 æŠ˜æˆ– 10 æŠ˜å¯ä»¥åœ¨å¯é ç»“æœå’Œåˆç†çš„è®¡ç®—æ—¶é—´ä¹‹é—´å–å¾—è‰¯å¥½çš„å¹³è¡¡ã€‚è¿™ç§æ•°æ®é‡é€šå¸¸è¶³ä»¥åˆ›å»ºå…·æœ‰ä»£è¡¨æ€§çš„åˆ’åˆ†ï¼Œè€Œä¸ä¼šä½¿å¾—æµ‹è¯•æ—¶é—´è¿‡é•¿ã€‚
- en: '***Small Datasets (Less than 1,000 samples)***'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '***å°å‹æ•°æ®é›†ï¼ˆå°‘äº 1,000 ä¸ªæ ·æœ¬ï¼‰***'
- en: Small datasets, like our example of 28 days of golf records, need more careful
    testing. Leave-One-Out Cross-Validation or Repeated K-fold with more folds can
    actually work well in this case. Even though these methods take longer to run,
    they help us get the most reliable results when we donâ€™t have much data to work
    with.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: å°å‹æ•°æ®é›†ï¼Œä¾‹å¦‚æˆ‘ä»¬28å¤©é«˜å°”å¤«è®°å½•çš„ä¾‹å­ï¼Œéœ€è¦æ›´ä»”ç»†çš„æµ‹è¯•ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒLeave-One-Out äº¤å‰éªŒè¯æˆ–é‡å¤ K æŠ˜äº¤å‰éªŒè¯ï¼ˆä½¿ç”¨æ›´å¤šæŠ˜æ•°ï¼‰å®é™…ä¸Šå¯ä»¥å¾ˆå¥½åœ°å·¥ä½œã€‚å°½ç®¡è¿™äº›æ–¹æ³•çš„è¿è¡Œæ—¶é—´è¾ƒé•¿ï¼Œä½†åœ¨æ•°æ®é‡ä¸å¤§çš„æƒ…å†µä¸‹ï¼Œå®ƒä»¬å¸®åŠ©æˆ‘ä»¬è·å¾—æœ€å¯é çš„ç»“æœã€‚
- en: 2\. Computational Resource
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. è®¡ç®—èµ„æº
- en: 'When choosing a validation method, we need to think about our computing resources.
    Thereâ€™s a three-way balance between dataset size, how complex our model is, and
    which validation method we use:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é€‰æ‹©éªŒè¯æ–¹æ³•æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘è®¡ç®—èµ„æºã€‚åœ¨æ•°æ®é›†å¤§å°ã€æ¨¡å‹å¤æ‚åº¦å’Œæ‰€ä½¿ç”¨çš„éªŒè¯æ–¹æ³•ä¹‹é—´å­˜åœ¨ä¸‰æ–¹é¢çš„å¹³è¡¡ï¼š
- en: '**Fast Training Models**'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¿«é€Ÿè®­ç»ƒæ¨¡å‹**'
- en: Simple models like decision trees, logistic regression, and linear SVM can use
    more thorough validation methods like Leave-One-Out Cross-Validation or Repeated
    Stratified K-fold because they train quickly. Since each training round takes
    just seconds or minutes, we can afford to run many validation iterations. Even
    running LOOCV with its N training rounds might be practical for these algorithms.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: åƒå†³ç­–æ ‘ã€é€»è¾‘å›å½’å’Œçº¿æ€§ SVM è¿™æ ·çš„ç®€å•æ¨¡å‹å¯ä»¥ä½¿ç”¨æ›´å½»åº•çš„éªŒè¯æ–¹æ³•ï¼Œå¦‚ Leave-One-Out äº¤å‰éªŒè¯æˆ–é‡å¤åˆ†å±‚ K æŠ˜äº¤å‰éªŒè¯ï¼Œå› ä¸ºå®ƒä»¬è®­ç»ƒé€Ÿåº¦è¾ƒå¿«ã€‚ç”±äºæ¯è½®è®­ç»ƒåªéœ€å‡ ç§’é’Ÿæˆ–å‡ åˆ†é’Ÿï¼Œæˆ‘ä»¬å¯ä»¥æ‰¿å—å¤šæ¬¡éªŒè¯è¿­ä»£ã€‚å³ä½¿æ˜¯ä½¿ç”¨
    N è½®è®­ç»ƒçš„ LOOCVï¼Œä¹Ÿå¯èƒ½å¯¹è¿™äº›ç®—æ³•æ¥è¯´æ˜¯å¯è¡Œçš„ã€‚
- en: '**Resource-Heavy Models**'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æºå¯†é›†å‹æ¨¡å‹**'
- en: Deep neural networks, random forests with many trees, or gradient boosting models
    take much longer to train. When using these models, more intensive validation
    methods like Repeated K-fold or Leave-P-Out might not be practical. We might need
    to choose simpler methods like basic K-fold or ShuffleSplit to keep testing time
    reasonable.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦ç¥ç»ç½‘ç»œã€æ‹¥æœ‰å¤§é‡æ ‘çš„éšæœºæ£®æ—æˆ–æ¢¯åº¦æå‡æ¨¡å‹çš„è®­ç»ƒæ—¶é—´è¾ƒé•¿ã€‚åœ¨ä½¿ç”¨è¿™äº›æ¨¡å‹æ—¶ï¼Œæ›´åŠ å¯†é›†çš„éªŒè¯æ–¹æ³•ï¼Œå¦‚é‡å¤KæŠ˜äº¤å‰éªŒè¯æˆ–Leave-P-Outï¼Œå¯èƒ½ä¸å¤ªå®é™…ã€‚æˆ‘ä»¬å¯èƒ½éœ€è¦é€‰æ‹©æ›´ç®€å•çš„æ–¹æ³•ï¼Œå¦‚åŸºæœ¬çš„KæŠ˜äº¤å‰éªŒè¯æˆ–ShuffleSplitï¼Œä»¥ä¿æŒåˆç†çš„æµ‹è¯•æ—¶é—´ã€‚
- en: '**Memory Considerations**'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**å†…å­˜è€ƒè™‘å› ç´ **'
- en: Some methods like K-fold need to track multiple splits of data at once. ShuffleSplit
    can help with memory limitations since it handles one random split at a time.
    For large datasets with complex models (like deep neural networks that need lots
    of memory), simpler hold-out methods might be necessary. If we still need thorough
    validation with limited memory, we could use Time Series Split since it naturally
    processes data in sequence rather than needing all splits in memory at once.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›æ–¹æ³•ï¼Œå¦‚KæŠ˜äº¤å‰éªŒè¯ï¼Œéœ€è¦åŒæ—¶è·Ÿè¸ªå¤šä¸ªæ•°æ®åˆ’åˆ†ã€‚ShuffleSplitå¯ä»¥å¸®åŠ©è§£å†³å†…å­˜é™åˆ¶é—®é¢˜ï¼Œå› ä¸ºå®ƒä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªéšæœºåˆ’åˆ†ã€‚å¯¹äºå…·æœ‰å¤æ‚æ¨¡å‹ï¼ˆå¦‚éœ€è¦å¤§é‡å†…å­˜çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼‰çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨æ›´ç®€å•çš„ä¿ç•™æ–¹æ³•ã€‚å¦‚æœæˆ‘ä»¬åœ¨å†…å­˜æœ‰é™çš„æƒ…å†µä¸‹ä»éœ€è¦å½»åº•çš„éªŒè¯ï¼Œå¯ä»¥ä½¿ç”¨æ—¶é—´åºåˆ—åˆ’åˆ†ï¼Œå› ä¸ºå®ƒè‡ªç„¶åœ°æŒ‰é¡ºåºå¤„ç†æ•°æ®ï¼Œè€Œä¸éœ€è¦ä¸€æ¬¡æ€§å°†æ‰€æœ‰åˆ’åˆ†å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚
- en: When resources are limited, using a simpler validation method that we can run
    properly (like basic K-fold) is better than trying to run a more complex method
    (like Leave-P-Out) that we canâ€™t complete properly.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: å½“èµ„æºæœ‰é™æ—¶ï¼Œä½¿ç”¨ä¸€ä¸ªæˆ‘ä»¬å¯ä»¥é¡ºåˆ©è¿è¡Œçš„æ›´ç®€å•çš„éªŒè¯æ–¹æ³•ï¼ˆä¾‹å¦‚åŸºæœ¬çš„KæŠ˜äº¤å‰éªŒè¯ï¼‰æ¯”å°è¯•è¿è¡Œä¸€ä¸ªæˆ‘ä»¬æ— æ³•å®Œæˆçš„æ›´å¤æ‚æ–¹æ³•ï¼ˆä¾‹å¦‚Leave-P-Outï¼‰è¦å¥½ã€‚
- en: 3\. Class Distribution
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. ç±»åˆ«åˆ†å¸ƒ
- en: Class imbalance strongly affects how we should validate our model. With unbalanced
    data, stratified validation methods become essential. Methods like Stratified
    K-fold and Stratified ShuffleSplit make sure each testing split has about the
    same mix of classes as our full dataset. Without using these stratified methods,
    some test sets might end up with no particular class at all, making it impossible
    to properly test how well our model makes prediction.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ä¸å¹³è¡¡ä¼šå¼ºçƒˆå½±å“æˆ‘ä»¬åº”è¯¥å¦‚ä½•éªŒè¯æ¨¡å‹ã€‚å¯¹äºä¸å¹³è¡¡æ•°æ®ï¼Œåˆ†å±‚éªŒè¯æ–¹æ³•å˜å¾—è‡³å…³é‡è¦ã€‚åƒåˆ†å±‚KæŠ˜äº¤å‰éªŒè¯å’Œåˆ†å±‚ShuffleSplitè¿™æ ·çš„æ–¹å¼ç¡®ä¿æ¯ä¸ªæµ‹è¯•åˆ’åˆ†ä¸å®Œæ•´æ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒå¤§è‡´ç›¸åŒã€‚å¦‚æœä¸ä½¿ç”¨è¿™äº›åˆ†å±‚æ–¹æ³•ï¼Œä¸€äº›æµ‹è¯•é›†å¯èƒ½å®Œå…¨æ²¡æœ‰æŸä¸ªç±»åˆ«ï¼Œè¿™æ ·å°±æ— æ³•æ­£ç¡®æµ‹è¯•æ¨¡å‹çš„é¢„æµ‹æ•ˆæœã€‚
- en: 4\. Time Series
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. æ—¶é—´åºåˆ—
- en: When working with data that changes over time, we need special validation approaches.
    Regular random splitting methods donâ€™t work well because time order matters.With
    time series data, we must use methods like Time Series Split that respect time
    order.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å¤„ç†éšæ—¶é—´å˜åŒ–çš„æ•°æ®æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ç‰¹æ®Šçš„éªŒè¯æ–¹æ³•ã€‚å¸¸è§„çš„éšæœºåˆ’åˆ†æ–¹æ³•æ•ˆæœä¸ä½³ï¼Œå› ä¸ºæ—¶é—´é¡ºåºå¾ˆé‡è¦ã€‚å¯¹äºæ—¶é—´åºåˆ—æ•°æ®ï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨åƒæ—¶é—´åºåˆ—åˆ’åˆ†ï¼ˆTime
    Series Splitï¼‰è¿™æ ·çš„æ–¹å¼ï¼Œå°Šé‡æ—¶é—´é¡ºåºã€‚
- en: 5\. Group Dependencies
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. ç¾¤ç»„ä¾èµ–
- en: Many datasets contain natural groups of related data. These connections in our
    data need special handling when we validate our models. When data points are related,
    we need to use methods like Group K-fold to prevent our model from accidentally
    learning things it shouldnâ€™t.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šæ•°æ®é›†åŒ…å«è‡ªç„¶çš„ç›¸å…³æ•°æ®ç»„ã€‚åœ¨éªŒè¯æ¨¡å‹æ—¶ï¼Œè¿™äº›æ•°æ®ä¸­çš„è¿æ¥éœ€è¦ç‰¹æ®Šå¤„ç†ã€‚å½“æ•°æ®ç‚¹ç›¸å…³æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨åƒGroup K-foldè¿™æ ·çš„æ–¹å¼ï¼Œä»¥é˜²æ­¢æˆ‘ä»¬çš„æ¨¡å‹é”™è¯¯åœ°å­¦ä¹ åˆ°ä¸è¯¥å­¦ä¹ çš„ä¸œè¥¿ã€‚
- en: Practical Guidelines
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®ç”¨æŒ‡å—
- en: This flowchart will help you select the most appropriate validation method for
    your data. The steps below outline a clear process for choosing the best validation
    approach, assuming you have sufficient computing resources.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¼ æµç¨‹å›¾å°†å¸®åŠ©ä½ ä¸ºä½ çš„æ•°æ®é€‰æ‹©æœ€åˆé€‚çš„éªŒè¯æ–¹æ³•ã€‚ä¸‹é¢çš„æ­¥éª¤æ¦‚è¿°äº†ä¸€ä¸ªæ¸…æ™°çš„é€‰æ‹©æœ€ä½³éªŒè¯æ–¹æ³•çš„è¿‡ç¨‹ï¼Œå‰ææ˜¯ä½ æœ‰è¶³å¤Ÿçš„è®¡ç®—èµ„æºã€‚
- en: '![](../Images/3c111d0da670ace01dcf36fc6effc876.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c111d0da670ace01dcf36fc6effc876.png)'
- en: Final Remarks
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ€åçš„å¤‡æ³¨
- en: Model validation is essential for building reliable machine learning models.
    After exploring many validation methods, from simple train-test splits to complex
    cross-validation approaches, weâ€™ve learned that there is always a suitable validation
    method for whatever data you have.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹éªŒè¯å¯¹äºæ„å»ºå¯é çš„æœºå™¨å­¦ä¹ æ¨¡å‹è‡³å…³é‡è¦ã€‚åœ¨æ¢ç´¢äº†è®¸å¤šéªŒè¯æ–¹æ³•ï¼Œä»ç®€å•çš„è®­ç»ƒ-æµ‹è¯•åˆ’åˆ†åˆ°å¤æ‚çš„äº¤å‰éªŒè¯æ–¹æ³•åï¼Œæˆ‘ä»¬å‘ç°ï¼Œæ€»æœ‰ä¸€ç§é€‚åˆä½ çš„æ•°æ®çš„éªŒè¯æ–¹æ³•ã€‚
- en: While machine learning keeps changing with new methods and tools, these basic
    rules of validation stay the same. When you understand these principles well,
    I believe youâ€™ll build models that people can trust and rely on.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æœºå™¨å­¦ä¹ åœ¨ä¸æ–­å˜åŒ–ï¼Œå‡ºç°äº†æ–°çš„æ–¹æ³•å’Œå·¥å…·ï¼Œä½†è¿™äº›åŸºæœ¬çš„éªŒè¯è§„åˆ™å§‹ç»ˆä¸å˜ã€‚å½“ä½ å¾ˆå¥½åœ°ç†è§£è¿™äº›åŸåˆ™æ—¶ï¼Œæˆ‘ç›¸ä¿¡ä½ ä¼šå»ºç«‹èµ·äººä»¬å¯ä»¥ä¿¡ä»»å’Œä¾èµ–çš„æ¨¡å‹ã€‚
- en: Further Reading
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ·±å…¥é˜…è¯»
- en: For a detailed explanation of the [validation methods in](https://scikit-learn.org/stable/api/sklearn.model_selection.html)
    `[scikit-learn](https://scikit-learn.org/stable/api/sklearn.model_selection.html)`,
    readers can refer to the official documentation, which provides comprehensive
    information on its usage and parameters.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äº[éªŒè¯æ–¹æ³•](https://scikit-learn.org/stable/api/sklearn.model_selection.html)çš„è¯¦ç»†è§£é‡Šï¼Œè¯»è€…å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼Œé‡Œé¢æä¾›äº†å…¨é¢çš„ä½¿ç”¨å’Œå‚æ•°è¯´æ˜ã€‚
- en: Technical Environment
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æŠ€æœ¯ç¯å¢ƒ
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä½¿ç”¨çš„æ˜¯Python 3.7å’Œscikit-learn 1.5ã€‚å°½ç®¡æ‰€è®¨è®ºçš„æ¦‚å¿µé€šå¸¸é€‚ç”¨ï¼Œä½†å…·ä½“çš„ä»£ç å®ç°å¯èƒ½ä¼šå› ç‰ˆæœ¬ä¸åŒè€Œæœ‰æ‰€å˜åŒ–ã€‚
- en: About the Illustrations
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºæ’å›¾
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤éå¦æœ‰è¯´æ˜ï¼Œå¦åˆ™æ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…åˆ›ä½œï¼Œå¹¶ç»“åˆäº†Canva Proçš„æˆæƒè®¾è®¡å…ƒç´ ã€‚
- en: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ™ˆğ™¤ğ™™ğ™šğ™¡ ğ™€ğ™«ğ™–ğ™¡ğ™ªğ™–ğ™©ğ™ğ™¤ğ™£ & ğ™Šğ™¥ğ™©ğ™ğ™¢ğ™ğ™¯ğ™–ğ™©ğ™ğ™¤ğ™£ ğ™¢ğ™šğ™©ğ™ğ™¤ğ™™ğ™¨ ğ™ğ™šğ™§ğ™š:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ™ˆğ™¤ğ™™ğ™šğ™¡ ğ™€ğ™«ğ™–ğ™¡ğ™ªğ™–ğ™©ğ™ğ™¤ğ™£ & ğ™Šğ™¥ğ™©ğ™ğ™¢ğ™ğ™¯ğ™–ğ™©ğ™ğ™¤ğ™£ ğ™¢ğ™šğ™©ğ™ğ™¤ğ™™ğ™¨ ğ™ğ™šğ™§ğ™š:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
- en: Model Evaluation & Optimization
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–
- en: '[View list](https://medium.com/@samybaladram/list/model-evaluation-optimization-331287896864?source=post_page-----eb13bbdc8f88--------------------------------)3
    stories![](../Images/18fa82b1435fa7d5571ee54ae93a6c62.png)![](../Images/c95e89d05d1de700c631c342cd008de0.png)![](../Images/30e20e1a8ba3ced1e77644b706acd18d.png)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/model-evaluation-optimization-331287896864?source=post_page-----eb13bbdc8f88--------------------------------)3ä¸ªæ•…äº‹![](../Images/18fa82b1435fa7d5571ee54ae93a6c62.png)![](../Images/c95e89d05d1de700c631c342cd008de0.png)![](../Images/30e20e1a8ba3ced1e77644b706acd18d.png)'
- en: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
- en: Classification Algorithms
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ†ç±»ç®—æ³•
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----eb13bbdc8f88--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----eb13bbdc8f88--------------------------------)8ä¸ªæ•…äº‹![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
- en: Ensemble Learning
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›†æˆå­¦ä¹ 
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----eb13bbdc8f88--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----eb13bbdc8f88--------------------------------)4ä¸ªæ•…äº‹![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
