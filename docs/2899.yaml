- en: 'Model Validation Techniques, Explained: A Visual Guide with Code Examples'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型验证技术解析：带有代码示例的可视化指南
- en: 原文：[https://towardsdatascience.com/model-validation-techniques-explained-a-visual-guide-with-code-examples-eb13bbdc8f88?source=collection_archive---------1-----------------------#2024-11-30](https://towardsdatascience.com/model-validation-techniques-explained-a-visual-guide-with-code-examples-eb13bbdc8f88?source=collection_archive---------1-----------------------#2024-11-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/model-validation-techniques-explained-a-visual-guide-with-code-examples-eb13bbdc8f88?source=collection_archive---------1-----------------------#2024-11-30](https://towardsdatascience.com/model-validation-techniques-explained-a-visual-guide-with-code-examples-eb13bbdc8f88?source=collection_archive---------1-----------------------#2024-11-30)
- en: MODEL EVALUATION & OPTIMIZATION
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估与优化
- en: 12 must-know methods to v**alidate your machine learning**
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12种必须了解的**机器学习验证方法**
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--eb13bbdc8f88--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)
    ·26 min read·Nov 30, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--eb13bbdc8f88--------------------------------)
    ·阅读时长26分钟·2024年11月30日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Every day, machines make millions of predictions — from detecting objects in
    photos to helping doctors find diseases. But before trusting these predictions,
    we need to know if they’re any good. After all, no one would want to use a machine
    that’s wrong most of the time!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 每天，机器都会做出数百万个预测——从检测照片中的物体到帮助医生发现疾病。但在相信这些预测之前，我们需要知道它们是否准确。毕竟，没有人愿意使用一个大多数时候都错误的机器！
- en: This is where validation comes in. Validation methods test machine predictions
    to measure their reliability. While this might sound simple, different validation
    approaches exist, each designed to handle specific challenges in machine learning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，验证就显得尤为重要。验证方法测试机器的预测结果，以衡量其可靠性。虽然这听起来很简单，但实际上存在多种验证方法，每种方法都是为了应对机器学习中的特定挑战而设计的。
- en: Here, I’ve organized these validation techniques — all 12 of them — in a tree
    structure, showing how they evolved from basic concepts into more specialized
    ones. And of course, we will use clear visuals and a consistent dataset to show
    what each method does differently and why method selection matters.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我将这些验证技术——全部12种——以树状结构组织，展示它们如何从基本概念发展成更为专业的技术。当然，我们将使用清晰的可视化图像和一致的数据集，展示每种方法的不同之处以及为什么选择方法至关重要。
- en: '![](../Images/b1f5d5ea3c85d86aa30c1a32e4af95d6.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1f5d5ea3c85d86aa30c1a32e4af95d6.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可视化图像：作者使用Canva Pro创建。已优化为移动端显示；在桌面端可能会显得过大。
- en: What is Model Validation?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是模型验证？
- en: Model validation is the process of testing how well a machine learning model
    works with data it hasn’t seen or used during training. Basically, we use existing
    data to check the model’s performance instead of using new data. This helps us
    identify problems before deploying the model for real use.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 模型验证是测试机器学习模型在未见过或未在训练中使用过的数据上表现如何的过程。基本上，我们使用现有数据来检查模型的表现，而不是使用新的数据。这帮助我们在实际使用模型之前识别问题。
- en: 'There are several validation methods, and each method has specific strengths
    and addresses different validation challenges:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种验证方法，每种方法都有其特定的优势，并且解决不同的验证挑战：
- en: Different validation methods can produce different results, so choosing the
    right method matters.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不同的验证方法可能会产生不同的结果，因此选择正确的方法很重要。
- en: Some validation techniques work better with specific types of data and models.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些验证技术在特定类型的数据和模型中效果更佳。
- en: Using incorrect validation methods can give misleading results about the model’s
    true performance.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用不正确的验证方法可能会导致关于模型真实表现的误导性结果。
- en: 'Here is a tree diagram showing how these validation methods relate to each
    other:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一棵树形图，展示了这些验证方法之间的关系：
- en: '![](../Images/ef40a8b199595fb3a2ea907fc7d8c4e7.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef40a8b199595fb3a2ea907fc7d8c4e7.png)'
- en: The tree diagram shows which validation methods are connected to each other.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这棵树形图展示了哪些验证方法相互关联。
- en: Next, we’ll look at each validation method more closely by showing exactly how
    they work. To make everything easier to understand, we’ll walk through clear examples
    that show how these methods work with real data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将更仔细地研究每种验证方法，展示它们是如何工作的。为了更容易理解，我们将通过清晰的示例，展示这些方法如何在实际数据中运作。
- en: 📊 📈 Our Running Example
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 📊 📈 我们的运行示例
- en: We will use the same example throughout to help you understand each testing
    method. While this dataset may not be appropriate for some validation methods,
    for education purpose, using this one example makes it easier to compare different
    methods and see how each one works.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将始终使用相同的示例，帮助你理解每种验证方法。虽然这个数据集可能不适合某些验证方法，但为了教学目的，使用这个示例使得比较不同方法并观察每种方法如何工作的过程更加容易。
- en: 📊 The Golf Playing Dataset
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 📊 高尔夫游戏数据集
- en: We’ll work with this dataset that predicts whether someone will play golf based
    on weather conditions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个数据集，它根据天气条件预测某人是否会打高尔夫。
- en: '![](../Images/a76a1336de0cf6952c9aee515376a7ad.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a76a1336de0cf6952c9aee515376a7ad.png)'
- en: 'Columns: ‘Overcast (one-hot-encoded into 3 columns)’, ’Temperature’ (in Fahrenheit),
    ‘Humidity’ (in %), ‘Windy’ (Yes/No) and ‘Play’ (Yes/No, target feature)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 列：‘Overcast（独热编码为3列）’，‘Temperature’（以华氏度表示），‘Humidity’（百分比），‘Windy’（是/否）和‘Play’（是/否，目标特征）
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 📈 Our Model Choice
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 📈 我们的模型选择
- en: 'We will use a [decision tree classifier](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    for all our tests. See the following article if you are not familiar with it:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在所有测试中使用[决策树分类器](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)。如果你不熟悉它，可以参考以下文章：
- en: '[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----eb13bbdc8f88--------------------------------)
    [## Decision Tree Classifier, Explained: A Visual Guide with Code Examples for
    Beginners'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----eb13bbdc8f88--------------------------------)
    [## 决策树分类器解析：附带代码示例的视觉指南（面向初学者）'
- en: A fresh look on our favorite upside-down tree
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对我们最喜欢的倒立树的全新看法
- en: towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----eb13bbdc8f88--------------------------------)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----eb13bbdc8f88--------------------------------)'
- en: We picked this model because we can easily draw the resulting model as a tree
    structure, with each branch showing different decisions. To keep things simple
    and focus on how we test the model, we will use the default `scikit-learn` parameter
    with a fixed `random_state`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择这个模型是因为我们可以很容易地将结果模型绘制为树形结构，每个分支显示不同的决策。为了简化操作并专注于如何测试模型，我们将使用默认的`scikit-learn`参数，并设置固定的`random_state`。
- en: 'Let’s be clear about these two terms we’ll use: The decision tree classifier
    is our **learning algorithm** — it’s the method that finds patterns in our data.
    When we feed data into this algorithm, it creates a **model** (in this case, a
    tree with clear branches showing different decisions). This model is what we’ll
    actually use to make predictions.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们明确这两个术语：决策树分类器是我们的**学习算法**——它是找到数据中模式的方法。当我们将数据输入该算法时，它会创建一个**模型**（在这种情况下，是一棵显示不同决策的树）。这个模型就是我们实际用来进行预测的模型。
- en: '![](../Images/05f04d2e03922330e874044c751e77f9.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05f04d2e03922330e874044c751e77f9.png)'
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Each time we split our data differently for validation, we’ll get different
    models with different decision rules. Once our validation shows that our algorithm
    works reliably, we’ll create one final model using all our data. This final model
    is the one we’ll actually use to predict if someone will play golf or not.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们以不同的方式拆分数据进行验证时，都会得到不同的模型和不同的决策规则。一旦我们的验证表明算法可靠地工作，我们将使用所有数据创建一个最终模型。这个最终模型就是我们实际用来预测某人是否会打高尔夫的模型。
- en: With this setup ready, we can now focus on understanding how each validation
    method works and how it helps us make better predictions about golf playing based
    on weather conditions. Let’s examine each validation method one at a time.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 设置好这一切后，我们现在可以集中精力了解每种验证方法的工作原理，以及它如何帮助我们根据天气条件做出更好的高尔夫球预测。我们将逐一检查每种验证方法。
- en: Hold-out Methods
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保留法
- en: Hold-out methods are the most basic way to check how well our model works. In
    these methods, we basically save some of our data just for testing.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 保留法是检验我们模型效果的最基础方法。在这些方法中，我们基本上将一部分数据专门用于测试。
- en: Train-Test Split
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练-测试拆分
- en: 'This method is simple: we split our data into two parts. We use one part to
    train our model and the other part to test it. Before we split the data, we mix
    it up randomly so the order of our original data doesn’t affect our results.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法很简单：我们将数据分成两部分。我们使用一部分来训练模型，另一部分来测试模型。在分割数据之前，我们会随机打乱数据顺序，以确保原始数据的顺序不会影响结果。
- en: 'Both the training and test dataset size depends on our total dataset size,
    usually denoted by their ratio. To determine their size, you can follow this guideline:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集和测试集的大小取决于我们的总数据集大小，通常用它们的比例来表示。为了确定它们的大小，您可以遵循以下指导原则：
- en: For small datasets (around 1,000–10,000 samples), use 80:20 ratio.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于小型数据集（大约1,000–10,000个样本），使用80:20的比例。
- en: For medium datasets (around 10,000–100,000 samples), use 70:30 ratio.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于中等规模的数据集（大约10,000–100,000个样本），使用70:30的比例。
- en: Large datasets (over 100,000 samples), use 90:10 ratio.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型数据集（超过100,000个样本），使用90:10的比例。
- en: '![](../Images/ea1cda2f5b4ebaf2ac345e82232c49e6.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea1cda2f5b4ebaf2ac345e82232c49e6.png)'
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/9b572acdaf081abe2ed17104646ae2ac.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b572acdaf081abe2ed17104646ae2ac.png)'
- en: This method is easy to use, but it has some limitation — the results can change
    a lot depending on how we randomly split the data. This is why we always need
    to try out different `random_state` to make sure that the result is consistent.
    Also, if we don’t have much data to start with, we might not have enough to properly
    train or test our model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法很容易使用，但也有一些局限性 —— 结果可能会因为我们如何随机分割数据而有很大变化。这就是为什么我们总是需要尝试不同的`random_state`来确保结果的一致性。此外，如果我们起初的数据不多，可能没有足够的数据来充分训练或测试我们的模型。
- en: Train-Validation-Test Split
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练-验证-测试拆分
- en: This method split our data into three parts. The middle part, called validation
    data, is being used to tune the parameters of the model and we’re aiming to have
    the least amount of error there.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将数据分为三部分。中间部分，称为验证数据，用来调整模型的参数，我们的目标是尽量减少该部分的误差。
- en: Since the validation results is considered many times during this tuning process,
    our model might start doing too well on this validation data (which is what we
    want). This is the reason of why we make the separate test set. We are only testing
    it once at the very end — it gives us the truth of how well our model works.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在调整过程中会多次考虑验证结果，我们的模型可能会在验证数据上表现得太好（这正是我们想要的）。这就是我们为什么要设立单独的测试集的原因。我们只在最后一次测试它
    —— 它能真实地反映出我们的模型效果如何。
- en: 'Here are typical ways to split your data:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是常见的数据拆分方式：
- en: For smaller datasets (1,000–10,000 samples), use 60:20:20 ratio.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于较小的数据集（1,000–10,000个样本），使用60:20:20的比例。
- en: For medium datasets (10,000–100,000 samples), use 70:15:15 ratio.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于中等规模的数据集（10,000–100,000个样本），使用70:15:15的比例。
- en: Large datasets (> 100,000 samples), use 80:10:10 ratio.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型数据集（>100,000个样本），使用80:10:10的比例。
- en: '![](../Images/8abee1c3e7b3526152ccf2256108da3f.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8abee1c3e7b3526152ccf2256108da3f.png)'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/4b6cfed209a3227dfc62eaf3f28413a1.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b6cfed209a3227dfc62eaf3f28413a1.png)'
- en: Hold-out methods work differently depending on how much data you have. They
    work really well when you have lots of data (> 100,000). But when you have less
    data (< 1,000) this method is not be the best. With smaller datasets, you might
    need to use more advanced validation methods to get a better understanding of
    how well your model really works.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 保留法根据数据量的不同会有不同的表现。当你有大量数据（>100,000个样本）时，它效果很好。但当你数据较少（<1,000个样本）时，这种方法可能不是最理想的。在数据较少的情况下，你可能需要使用更高级的验证方法，以便更好地了解你的模型到底有多有效。
- en: 📊 Moving to Cross-validation
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 📊 转向交叉验证
- en: We just learned that hold-out methods might not work very well with small datasets.
    This is exactly the challenge we currently face— we only have 28 days of data.
    Following the hold-out principle, we’ll keep 14 days of data separate for our
    final test. This leaves us with 14 days to work with for trying other validation
    methods.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚了解到，留出法可能在小数据集上效果不佳。这正是我们目前面临的挑战——我们只有28天的数据。按照留出法原则，我们将保留14天的数据作为最终测试数据。这样，我们剩下14天的数据可以用于尝试其他验证方法。
- en: '![](../Images/81a27f280c9b79b4950ec9a9f00ae731.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81a27f280c9b79b4950ec9a9f00ae731.png)'
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the next part, we’ll see how cross-validation methods can take these 14 days
    and split them up multiple times in different ways. This gives us a better idea
    of how well our model is really working, even with such limited data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将看到交叉验证方法如何将这14天的数据多次划分，并以不同的方式进行测试。这让我们即使在数据有限的情况下，也能更好地了解模型的实际效果。
- en: Cross Validation
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Cross-validation changes how we think about testing our models. Instead of testing
    our model just once with one split of data, we test it many times using different
    splits of the same data. This helps us understand much better how well our model
    really works.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证改变了我们测试模型的方式。我们不再仅仅用一种数据划分方式测试一次模型，而是通过多次使用相同数据的不同划分来进行测试。这有助于我们更好地理解模型的实际表现。
- en: The main idea of cross-validation is to test our model multiple times, and each
    time the training and test dataset come from different part of the our data. This
    helps prevent bias by one really good (or really bad) split of the data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的主要思想是多次测试我们的模型，每次的训练集和测试集都来自我们数据的不同部分。这有助于避免由于数据划分极端（如特别好或特别差）而带来的偏差。
- en: 'Here’s why this matters: say our model gets 95% accuracy when we test it one
    way, but only 75% when we test it another way using the same data. Which number
    shows how good our model really is? Cross-validation helps us answer this question
    by giving us many test results instead of just one. This gives us a clearer picture
    of how well our model actually performs.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这为什么很重要呢？假设我们的模型在某次测试中得到95%的准确率，而在另一种测试方法下只得到75%的准确率，哪一个结果才是真正反映模型表现的呢？交叉验证通过提供多个测试结果，而不仅仅是一个，帮助我们回答这个问题。这让我们更清楚地了解模型的实际表现。
- en: K-Fold Methods
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K折法
- en: '***Basic K-Fold Cross-Validation*** *K*-fold cross-validation fixes a big problem
    with basic splitting: relying too much on just one way of splitting the data.
    Instead of splitting the data once, *K*-fold splits the data into *K* equal parts.
    Then it tests the model multiple times, using a different part for testing each
    time while using all other parts for training.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '***基础K折交叉验证*** *K*折交叉验证解决了基本数据划分方法的一个大问题：过于依赖单一的数据划分方式。与其只进行一次数据划分，*K*折将数据划分成*K*个相等的部分。然后，它多次测试模型，每次使用不同的部分进行测试，而其他部分则用于训练。'
- en: The number we pick for *K* changes how we test our model. Most people use 5
    or 10 for *K*, but this can change based on how much data we have and what we
    need for our project. Let’s say we use *K* = 3\. This means we split our data
    into three equal parts. We then train and test our model three different times.
    Each time, 2/3 of the data is used for training and 1/3 for testing, but we rotate
    which part is being used for testing. This way, every piece of data gets used
    for both training and testing.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择的*K*数值会影响我们如何测试模型。大多数人使用5或10作为*K*，但这个数值也可以根据我们拥有的数据量和项目需求来调整。假设我们使用*K* =
    3。这意味着我们将数据分成三等份。然后我们将模型训练和测试三次。每次，2/3的数据用于训练，1/3的数据用于测试，但每次测试时，所用的测试部分都会不同。这样，每个数据片段都会同时用于训练和测试。
- en: '![](../Images/06b5298158f9daf8c0fdf2f24ba9d7f9.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06b5298158f9daf8c0fdf2f24ba9d7f9.png)'
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`Validation accuracy: 0.433 ± 0.047`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率: 0.433 ± 0.047`'
- en: '![](../Images/3597efd5b0c424bb9ef27f510ef42907.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3597efd5b0c424bb9ef27f510ef42907.png)'
- en: When we’re done with all the rounds, we calculate the average performance from
    all *K* tests. This average gives us a more trustworthy measure of how well our
    model works. We can also learn about how stable our model is by looking at how
    much the results change between different rounds of testing.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们完成所有轮次后，我们会计算所有*K*测试的平均表现。这个平均值为我们提供了一个更可靠的衡量标准，来评估我们的模型表现如何。我们还可以通过观察不同测试轮次之间结果的变化，来了解我们的模型有多稳定。
- en: '***Stratified K-Fold*** Basic K-fold cross-validation usually works well, but
    it can run into problems when our data is unbalanced — meaning we have a lot more
    of one type than others. For example, if we have 100 data points and 90 of them
    are type A while only 10 are type B, randomly splitting this data might give us
    pieces that don’t have enough type B to test properly.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '***分层 K 折*** 基本的 K 折交叉验证通常效果不错，但当我们的数据不平衡时——即某些类型的数据比其他类型多得多——它可能会遇到问题。例如，如果我们有
    100 个数据点，其中 90 个是 A 类型，而只有 10 个是 B 类型，随机划分这些数据可能会导致某些划分中没有足够的 B 类型数据来进行合理的测试。'
- en: Stratified K-fold fixes this by making sure each split has the same mix as our
    original data. If our full dataset has 10% type B, each split will also have about
    10% type B. This makes our testing more reliable, especially when some types of
    data are much rarer than others.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 分层 K 折交叉验证通过确保每个数据划分与原始数据的分布相同来解决这个问题。如果我们的完整数据集中有 10% 是 B 类型，那么每个划分也将包含大约 10%
    的 B 类型数据。这使得我们的测试更加可靠，特别是在某些数据类型比其他类型稀少时。
- en: '![](../Images/6410d2ca1a0a1801423584f4ee9c30dd.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6410d2ca1a0a1801423584f4ee9c30dd.png)'
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`Validation accuracy: 0.650 ± 0.071`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率：0.650 ± 0.071`'
- en: '![](../Images/6a845da93fa64fae2b73609521f534a5.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a845da93fa64fae2b73609521f534a5.png)'
- en: Keeping this balance helps in two ways. First, it makes sure each split properly
    represents what our data looks like. Second, it gives us more consistent test
    results . This means that if we test our model multiple times, we’ll most likely
    get similar results each time.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 保持这种平衡有两个好处。首先，它确保每个划分能够恰当地代表我们数据的分布。其次，它使得我们的测试结果更加一致。这意味着，如果我们多次测试模型，我们很可能每次都会得到类似的结果。
- en: '***Repeated K-Fold*** Sometimes, even when we use K-fold validation, our test
    results can change a lot between different random splits. Repeated K-fold solves
    this by running the entire K-fold process multiple times, using different random
    splits each time.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '***重复 K 折*** 有时，即使我们使用了 K 折验证，测试结果在不同的随机划分之间也可能发生较大的变化。重复 K 折通过多次运行整个 K 折过程来解决这个问题，每次使用不同的随机划分。'
- en: For example, let’s say we run 5-fold cross-validation three times. This means
    our model goes through training and testing 15 times in total. By testing so many
    times, we can better tell which differences in results come from random chance
    and which ones show how well our model really performs. The downside is that all
    this extra testing takes more time to complete.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们运行 5 折交叉验证三次。这意味着我们的模型总共会进行 15 次训练和测试。通过如此多次的测试，我们可以更好地判断结果中的差异是来自随机因素，还是能真正反映出模型的性能。缺点是，所有这些额外的测试需要更多的时间来完成。
- en: '![](../Images/f2b033a8e6b90cc1bad5a07059d1457a.png)![](../Images/53d8b614cdb52f63a8289ec002c7dce5.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2b033a8e6b90cc1bad5a07059d1457a.png)![](../Images/53d8b614cdb52f63a8289ec002c7dce5.png)'
- en: '[PRE7]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`Validation accuracy: 0.425 ± 0.107`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率：0.425 ± 0.107`'
- en: '![](../Images/e94bb4e17347fd027be23da900507dd9.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e94bb4e17347fd027be23da900507dd9.png)'
- en: When we look at repeated K-fold results, since we have many sets of test results,
    we can do more than just calculate the average — we can also figure out how confident
    we are in our results. This gives us a better understanding of how reliable our
    model really is.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看重复 K 折结果时，由于我们有很多组测试结果，我们可以做的不仅仅是计算平均值——我们还可以了解我们对结果的信心。这使我们更好地理解模型的可靠性。
- en: '***Repeated Stratified K-Fold*** This method combines two things we just learned
    about: keeping class balance (stratification) and running multiple rounds of testing
    (repetition). It keeps the right mix of different types of data while testing
    many times. This works especially well when we have a small dataset that’s uneven
    — where we have a lot more of one type of data than others.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '***重复分层 K 折*** 这种方法结合了我们刚刚学习的两件事：保持类别平衡（分层）和进行多轮测试（重复）。它在测试多次的同时保持了不同类型数据的正确比例。这在我们的数据集较小且不平衡时尤其有效——例如，当我们有大量一种类型的数据，而其他类型的数据较少时。'
- en: '![](../Images/f9084cb48d717d1a53b287556171438e.png)![](../Images/9736bf44bf4d82ce511033183bcb338a.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9084cb48d717d1a53b287556171438e.png)![](../Images/9736bf44bf4d82ce511033183bcb338a.png)'
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`Validation accuracy: 0.542 ± 0.167`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率：0.542 ± 0.167`'
- en: '![](../Images/61517576ff80c26f2c20ca066afe43fd.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61517576ff80c26f2c20ca066afe43fd.png)'
- en: 'However, there’s a trade-off: this method takes more time for our computer
    to run. Each time we repeat the whole process, it multiplies how long it takes
    to train our model. When deciding whether to use this method, we need to think
    about whether having more reliable results is worth the extra time it takes to
    run all these tests.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法有一个权衡：它需要更多的时间来运行。每次我们重复整个过程时，训练模型所需的时间会成倍增加。在决定是否使用这种方法时，我们需要考虑，是否值得花费额外的时间来获得更可靠的结果。
- en: '***Group K-Fold*** Sometimes our data naturally comes in groups that should
    stay together. Think about golf data where we have many measurements from the
    same golf course throughout the year. If we put some measurements from one golf
    course in training data and others in test data, we create a problem: our model
    would indirectly learn about the test data during training because it saw other
    measurements from the same course.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '***分组 K 折交叉验证*** 有时，我们的数据自然分为一些应该保持在一起的组。例如，高尔夫数据中，我们可能有来自同一个高尔夫球场的多次测量数据。如果我们将来自一个高尔夫球场的部分测量数据放入训练数据，而其他的放入测试数据，就会出现问题：我们的模型可能会在训练过程中间接了解测试数据，因为它看到了来自同一球场的其他测量数据。'
- en: Group K-fold fixes this by keeping all data from the same group (like all measurements
    from one golf course) together in the same part when we split the data. This prevents
    our model from accidentally seeing information it shouldn’t, which could make
    us think it performs better than it really does.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 分组 K 折交叉验证通过保持来自同一组的数据（例如来自同一高尔夫球场的所有测量数据）一起划分，来解决这一问题。这可以防止我们的模型在训练过程中无意中看到不应该看到的信息，从而让我们误以为它表现得比实际情况更好。
- en: '![](../Images/cde7db87459ae48728b9dd87dd26ac88.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cde7db87459ae48728b9dd87dd26ac88.png)'
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`Validation accuracy: 0.417 ± 0.143`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确度: 0.417 ± 0.143`'
- en: '![](../Images/616c266d6ae7d923873b81a26b0df5de.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/616c266d6ae7d923873b81a26b0df5de.png)'
- en: This method can be important when working with data that naturally comes in
    groups, like multiple weather readings from the same golf course or data that
    was collected over time from the same location.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理自然分组的数据时，这种方法尤其重要，比如来自同一个高尔夫球场的多次天气数据，或者同一地点在不同时间收集的数据。
- en: '***Time Series Split*** When we split data randomly in regular K-fold, we assume
    each piece of data doesn’t affect the others. But this doesn’t work well with
    data that changes over time, where what happened before affects what happens next.
    Time series split changes K-fold to work better with this kind of time-ordered
    data.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '***时间序列划分*** 当我们在常规的 K 折交叉验证中随机划分数据时，我们假设每个数据点不会影响其他数据点。但这对于随时间变化的数据并不适用，因为过去发生的事情会影响未来的结果。时间序列划分通过调整
    K 折交叉验证，更好地处理这种时间顺序数据。'
- en: Instead of splitting data randomly, time series split uses data in order, from
    past to future. The training data only includes information from times before
    the testing data. This matches how we use models in real life, where we use past
    data to predict what will happen next.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列划分并非随机分割数据，而是按顺序使用数据，从过去到未来。训练数据仅包括测试数据之前的时间段的信息。这与我们在现实生活中使用模型的方式一致，即我们利用过去的数据来预测未来的事件。
- en: '![](../Images/81146fa4c70beaca8801445fd200d3fb.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81146fa4c70beaca8801445fd200d3fb.png)'
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`Validation accuracy: 0.556 ± 0.157`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确度: 0.556 ± 0.157`'
- en: '![](../Images/4d881beb9b6d1811302457256067f38f.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d881beb9b6d1811302457256067f38f.png)'
- en: For example, with *K*=3 and our golf data, we might train using weather data
    from January and February to predict March’s golf playing patterns. Then we’d
    train using January through March to predict April, and so on. By only going forward
    in time, this method gives us a more realistic idea of how well our model will
    work when predicting future golf playing patterns based on weather.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设*K*=3，并且我们有高尔夫数据。我们可以使用一月和二月的天气数据训练，来预测三月的高尔夫打球模式。接着，我们使用一月到三月的数据来预测四月，依此类推。通过只向前推进时间，这种方法能更真实地反映我们的模型在预测基于天气的未来高尔夫打球模式时的表现。
- en: Leave-Out Methods
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 留出法
- en: '***Leave-One-Out Cross-Validation (LOOCV)*** Leave-One-Out Cross-Validation
    (LOOCV) is the most thorough validation method. It uses just *one* sample for
    testing and all other samples for training. The validation is repeated until every
    single piece of data has been used for testing.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '***留一交叉验证 (LOOCV)*** 留一交叉验证 (LOOCV) 是最彻底的验证方法。它仅使用*一个*样本进行测试，其他所有样本用于训练。验证会重复进行，直到每一条数据都被用作测试。'
- en: Let’s say we have 100 days of golf weather data. LOOCV would train and test
    the model 100 times. Each time, it uses 99 days for training and 1 day for testing.
    This method removes any randomness in testing — if you run LOOCV on the same data
    multiple times, you’ll always get the same results.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有100天的高尔夫天气数据。LOOCV会训练并测试模型100次。每次，它使用99天的数据进行训练，1天的数据进行测试。这种方法消除了测试中的任何随机性——如果你多次在相同的数据上运行LOOCV，你将始终得到相同的结果。
- en: However, LOOCV takes a lot of computing time. If you have *N* pieces of data,
    you need to train your model *N* times. With large datasets or complex models,
    this might take too long to be practical. Some simpler models, like linear ones,
    have shortcuts that make LOOCV faster, but this isn’t true for all models.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，LOOCV需要很长的计算时间。如果你有*N*个数据点，你需要训练模型*N*次。对于大型数据集或复杂模型，这可能需要的时间太长，无法实际使用。一些简单的模型，如线性模型，有一些捷径使得LOOCV变得更快，但并不是所有模型都适用。
- en: '![](../Images/52e0f4b1c42428101fe15f6f81637446.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52e0f4b1c42428101fe15f6f81637446.png)'
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`Validation accuracy: 0.429 ± 0.495`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率：0.429 ± 0.495`'
- en: '![](../Images/40709bb360f71992f6218297c2d2242e.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40709bb360f71992f6218297c2d2242e.png)'
- en: LOOCV works really well when we don’t have much data and need to make the most
    of every piece we have. Since the result depend on every single data, the results
    can change a lot if our data has noise or unusual values in it.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: LOOCV在数据量不多，需要最大限度利用每一份数据时表现得非常好。由于结果依赖于每一条数据，如果数据中有噪声或异常值，结果可能会有很大变化。
- en: '***Leave-P-Out Cross-Validation*** Leave-P-Out builds on the idea of Leave-One-Out,
    but instead of testing with just one piece of data, it tests with P pieces at
    a time. This creates a balance between Leave-One-Out and K-fold validation. The
    number we choose for P changes how we test the model and how long it takes.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '***Leave-P-Out交叉验证*** Leave-P-Out基于Leave-One-Out的思想，但它每次测试时使用P个数据点，而不是仅测试一个数据点。这在Leave-One-Out和K-fold验证之间创造了平衡。我们选择的P值会改变模型的测试方式以及所需的时间。'
- en: The main problem with Leave-P-Out is how quickly the number of possible test
    combinations grows. For example, if we have 100 days of golf weather data and
    we want to test with 5 days at a time (P=5), there are millions of different possible
    ways to choose those 5 days. Testing all these combinations takes too much time
    when we have lots of data or when we use a larger number for P.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Leave-P-Out的主要问题是可能的测试组合数量增长得非常快。例如，如果我们有100天的高尔夫天气数据，并且每次测试5天（P=5），那么选择这5天的方式有数百万种不同的组合。当数据量很大或P值较大时，测试所有这些组合会耗费大量时间。
- en: '![](../Images/b08884b049867b549153b90e059cd20b.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b08884b049867b549153b90e059cd20b.png)'
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`Validation accuracy: 0.441 ± 0.254`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率：0.441 ± 0.254`'
- en: '![](../Images/b285dc37f93b1968c4e62df28fba57d7.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b285dc37f93b1968c4e62df28fba57d7.png)'
- en: Because of these practical limits, Leave-P-Out is mostly used in special cases
    where we need very thorough testing and have a small enough dataset to make it
    work. It’s especially useful in research projects where getting the most accurate
    test results matters more than how long the testing takes.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些实际限制，Leave-P-Out通常用于需要非常彻底测试且数据集足够小以使其可行的特殊情况。它在研究项目中尤其有用，在这些项目中，获取最准确的测试结果比测试所需的时间更为重要。
- en: Random Methods
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机方法
- en: '***ShuffleSplit Cross-Validation*** ShuffleSplit works differently from other
    validation methods by using completely random splits. Instead of splitting data
    in an organized way like K-fold, or testing every possible combination like Leave-P-Out,
    ShuffleSplit creates random training and testing splits each time.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '***ShuffleSplit交叉验证*** ShuffleSplit与其他验证方法不同，它采用完全随机的分割方式。与K-fold按有序方式划分数据，或像Leave-P-Out那样测试所有可能的组合不同，ShuffleSplit每次都会创建随机的训练和测试分割。'
- en: What makes ShuffleSplit different from K-fold is that the splits don’t follow
    any pattern. In K-fold, each piece of data gets used exactly once for testing.
    But in ShuffleSplit, a single day of golf weather data might be used for testing
    several times, or might not be used for testing at all. This randomness gives
    us a different way to understand how well our model performs.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ShuffleSplit与K-fold的不同之处在于，分割不遵循任何固定模式。在K-fold中，每条数据都恰好用于一次测试。但在ShuffleSplit中，一天的高尔夫天气数据可能被用于多次测试，也可能根本不被用于测试。这种随机性为我们提供了一种不同的方式来理解模型的表现。
- en: ShuffleSplit works especially well with large datasets where K-fold might take
    too long to run. We can choose how many times we want to test, no matter how much
    data we have. We can also control how big each split should be. This lets us find
    a good balance between thorough testing and the time it takes to run.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ShuffleSplit 在大数据集上特别有效，而 K-折交叉验证可能需要花费过多时间来运行。我们可以选择测试多少次，无论数据量多大。同时，我们还可以控制每次划分的大小。这让我们能够在全面测试和运行时间之间找到一个良好的平衡。
- en: '![](../Images/923156cc72cc526aae6376b4a83d7b24.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/923156cc72cc526aae6376b4a83d7b24.png)'
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`Validation accuracy: 0.333 ± 0.272`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率：0.333 ± 0.272`'
- en: '![](../Images/8c1642d4aa7fd19870eddc81316dddfa.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c1642d4aa7fd19870eddc81316dddfa.png)'
- en: Since ShuffleSplit can create as many random splits as we want, it’s useful
    when we want to see how our model’s performance changes with different random
    splits, or when we need more tests to be confident about our results.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 ShuffleSplit 可以创建任意数量的随机划分，它在我们希望查看模型性能如何随不同的随机划分而变化，或在我们需要更多的测试以确保结果的可靠性时非常有用。
- en: '***Stratified ShuffleSplit*** Stratified ShuffleSplit combines random splitting
    with keeping the right mix of different types of data. Like Stratified K-fold,
    it makes sure each split has about the same percentage of each type of data as
    the full dataset.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '***分层 ShuffleSplit*** 分层 ShuffleSplit 结合了随机划分和保持不同类型数据的正确混合。像分层 K-折交叉验证一样，它确保每个划分的每种类型的数据占比与整个数据集相同。'
- en: 'This method gives us the best of both worlds: the freedom of random splitting
    and the fairness of keeping data balanced. For example, if our golf dataset has
    70% “yes” days and 30% “no” days for playing golf, each random split will try
    to keep this same 70–30 mix. This is especially useful when we have uneven data,
    where random splitting might accidentally create test sets that don’t represent
    our data well.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法为我们提供了双赢的局面：既有随机划分的自由，又有保持数据平衡的公平性。例如，如果我们的高尔夫数据集有 70% 的“是”天和 30% 的“否”天，每个随机划分都会尽量保持这一
    70-30 的比例。这在数据不均衡时尤其有用，因为随机划分可能会无意中创建不代表我们数据的测试集。
- en: '![](../Images/c6f0a11a4d547374bf57dafa1869e61c.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6f0a11a4d547374bf57dafa1869e61c.png)'
- en: '[PRE14]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`Validation accuracy: 0.556 ± 0.157`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率：0.556 ± 0.157`'
- en: '![](../Images/96409b67fddbc5e5715ea4f0bed7f347.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96409b67fddbc5e5715ea4f0bed7f347.png)'
- en: However, trying to keep both the random nature of the splits and the right mix
    of data types can be tricky. The method sometimes has to make small compromises
    between being perfectly random and keeping perfect proportions. In real use, these
    small trade-offs rarely cause problems, and having balanced test sets is usually
    matters more than having perfectly random splits.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，保持划分的随机性以及数据类型的正确混合可能会很棘手。该方法有时需要在完全随机和保持完美比例之间做出一些小的妥协。在实际使用中，这些小的折衷很少会引起问题，且通常保持测试集的平衡比拥有完全随机的划分更为重要。
- en: 🌟 Validation Techniques Summarized & Code Summary
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 🌟 验证技术总结与代码总结
- en: 'To summarize, model validation methods fall into two main categories: hold-out
    methods and cross-validation methods:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，模型验证方法分为两大类：留出法和交叉验证法：
- en: '**Hold-out Methods** · Train-Test Split: The simplest approach, dividing data
    into two parts'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**留出法** · 训练-测试分割：最简单的方法，将数据分成两部分'
- en: '· Train-Validation-Test Split: A three-way split for more complex model development'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: · 训练-验证-测试分割：一种三分法用于更复杂的模型开发
- en: '**Cross-validation Methods** Cross-validation methods make better use of available
    data through multiple rounds of validation:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**交叉验证法** 交叉验证法通过多轮验证更好地利用可用数据：'
- en: '*K-Fold Methods* Rather than a single split, these methods divide data into
    K parts:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '*K-折交叉验证法* 这些方法将数据分为 K 个部分，而不是一个单独的划分：'
- en: '· Basic K-Fold: Rotates through different test sets'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: · 基本 K-折交叉验证：轮流使用不同的测试集
- en: '· Stratified K-Fold: Maintains class balance across splits'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: · 分层 K-折交叉验证：保持各个划分中的类别平衡
- en: '· Group K-Fold: Preserves data grouping'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: · 分组 K-折交叉验证：保留数据分组
- en: '· Time Series Split: Respects temporal order'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: · 时间序列分割：尊重时间顺序
- en: · Repeated K-Fold
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: · 重复 K-折交叉验证
- en: · Repeated Stratified K-Fold
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: · 重复分层 K-折交叉验证
- en: '*Leave-Out Methods* These methods take validation to the extreme:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*留出法* 这些方法将验证推向极限：'
- en: '· Leave-P-Out: Tests on P data points at a time'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: · 留 P 法：一次对 P 个数据点进行测试
- en: '· Leave-One-Out: Tests on single data points'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: · 留一法：对单个数据点进行测试
- en: '*Random Methods* These introduce controlled randomness:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*随机方法* 这些方法引入了受控的随机性：'
- en: '· ShuffleSplit: Creates random splits repeatedly'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: · ShuffleSplit：重复创建随机划分
- en: '· Stratified ShuffleSplit: Random splits with balanced classes'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: · 分层 ShuffleSplit：随机划分且保持类别平衡
- en: '[PRE15]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '`Validation accuracy: 0.429 ± 0.495`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`验证准确率: 0.429 ± 0.495`'
- en: '`Test accuracy: 0.714`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`测试准确率: 0.714`'
- en: '***Comment on the result above:*** The large gap between validation and test
    accuracy, along with the very high standard deviation in validation scores, suggests
    our model’s performance is unstable. This inconsistency likely comes from using
    LeaveOneOut validation on our small weather dataset — testing on single data points
    causes performance to vary dramatically. A different validation method using larger
    validation sets might give us more reliable results.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '***对上述结果的评论:*** 验证准确率和测试准确率之间的巨大差距，以及验证分数中非常高的标准差，表明我们的模型表现不稳定。这种不一致性很可能来源于在我们的小型天气数据集上使用
    LeaveOneOut 验证——在单个数据点上进行测试导致性能剧烈波动。使用较大的验证集的不同验证方法可能会给我们带来更可靠的结果。'
- en: Choosing the Right Validation Method
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择正确的验证方法
- en: 'Choosing how to validate your model isn’t simple — different situations need
    different approaches. Understanding which method to use can mean the difference
    between getting reliable or misleading results. Here are some aspect that you
    should consider when choosing the validation method:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 选择如何验证模型并不简单——不同的情况需要不同的方法。理解使用哪种方法可能意味着获得可靠结果或误导性结果之间的差异。以下是选择验证方法时应该考虑的一些方面：
- en: 1\. Dataset Size
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 数据集大小
- en: 'The size of your dataset strongly influences which validation method works
    best. Let’s look at different sizes:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的大小对选择哪种验证方法最有效有很大的影响。让我们来看一下不同大小的数据集：
- en: '**Large Datasets (More than 100,000 samples)**'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**大数据集（超过 100,000 个样本）**'
- en: When you have large datasets, the amount of time to test becomes one of the
    main consideration. Simple hold-out validation (splitting data once into training
    and testing) often works well because you have enough data for reliable testing.
    If you need to use cross-validation, using just 3 folds or using ShuffleSplit
    with fewer rounds can give good results without taking too long to run.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有大量数据集时，测试所需的时间成为主要考虑因素之一。简单的保留验证（将数据一次性分为训练集和测试集）通常效果不错，因为你有足够的数据进行可靠的测试。如果需要使用交叉验证，使用
    3 折或使用 ShuffleSplit 进行较少轮次的验证可以在不花费太多时间的情况下获得良好的结果。
- en: '***Medium Datasets (1,000 to 100,000 samples)***'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '***中等数据集（1,000 到 100,000 个样本）***'
- en: For medium-sized datasets, regular K-fold cross-validation works best. Using
    5 or 10 folds gives a good balance between reliable results and reasonable computing
    time. This amount of data is usually enough to create representative splits but
    not so much that testing takes too long.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 对于中等大小的数据集，常规的 K 折交叉验证效果最佳。使用 5 折或 10 折可以在可靠结果和合理的计算时间之间取得良好的平衡。这种数据量通常足以创建具有代表性的划分，而不会使得测试时间过长。
- en: '***Small Datasets (Less than 1,000 samples)***'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '***小型数据集（少于 1,000 个样本）***'
- en: Small datasets, like our example of 28 days of golf records, need more careful
    testing. Leave-One-Out Cross-Validation or Repeated K-fold with more folds can
    actually work well in this case. Even though these methods take longer to run,
    they help us get the most reliable results when we don’t have much data to work
    with.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 小型数据集，例如我们28天高尔夫记录的例子，需要更仔细的测试。在这种情况下，Leave-One-Out 交叉验证或重复 K 折交叉验证（使用更多折数）实际上可以很好地工作。尽管这些方法的运行时间较长，但在数据量不大的情况下，它们帮助我们获得最可靠的结果。
- en: 2\. Computational Resource
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 计算资源
- en: 'When choosing a validation method, we need to think about our computing resources.
    There’s a three-way balance between dataset size, how complex our model is, and
    which validation method we use:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择验证方法时，我们需要考虑计算资源。在数据集大小、模型复杂度和所使用的验证方法之间存在三方面的平衡：
- en: '**Fast Training Models**'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**快速训练模型**'
- en: Simple models like decision trees, logistic regression, and linear SVM can use
    more thorough validation methods like Leave-One-Out Cross-Validation or Repeated
    Stratified K-fold because they train quickly. Since each training round takes
    just seconds or minutes, we can afford to run many validation iterations. Even
    running LOOCV with its N training rounds might be practical for these algorithms.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 像决策树、逻辑回归和线性 SVM 这样的简单模型可以使用更彻底的验证方法，如 Leave-One-Out 交叉验证或重复分层 K 折交叉验证，因为它们训练速度较快。由于每轮训练只需几秒钟或几分钟，我们可以承受多次验证迭代。即使是使用
    N 轮训练的 LOOCV，也可能对这些算法来说是可行的。
- en: '**Resource-Heavy Models**'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源密集型模型**'
- en: Deep neural networks, random forests with many trees, or gradient boosting models
    take much longer to train. When using these models, more intensive validation
    methods like Repeated K-fold or Leave-P-Out might not be practical. We might need
    to choose simpler methods like basic K-fold or ShuffleSplit to keep testing time
    reasonable.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络、拥有大量树的随机森林或梯度提升模型的训练时间较长。在使用这些模型时，更加密集的验证方法，如重复K折交叉验证或Leave-P-Out，可能不太实际。我们可能需要选择更简单的方法，如基本的K折交叉验证或ShuffleSplit，以保持合理的测试时间。
- en: '**Memory Considerations**'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存考虑因素**'
- en: Some methods like K-fold need to track multiple splits of data at once. ShuffleSplit
    can help with memory limitations since it handles one random split at a time.
    For large datasets with complex models (like deep neural networks that need lots
    of memory), simpler hold-out methods might be necessary. If we still need thorough
    validation with limited memory, we could use Time Series Split since it naturally
    processes data in sequence rather than needing all splits in memory at once.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法，如K折交叉验证，需要同时跟踪多个数据划分。ShuffleSplit可以帮助解决内存限制问题，因为它一次只处理一个随机划分。对于具有复杂模型（如需要大量内存的深度神经网络）的大规模数据集，可能需要使用更简单的保留方法。如果我们在内存有限的情况下仍需要彻底的验证，可以使用时间序列划分，因为它自然地按顺序处理数据，而不需要一次性将所有划分存储在内存中。
- en: When resources are limited, using a simpler validation method that we can run
    properly (like basic K-fold) is better than trying to run a more complex method
    (like Leave-P-Out) that we can’t complete properly.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当资源有限时，使用一个我们可以顺利运行的更简单的验证方法（例如基本的K折交叉验证）比尝试运行一个我们无法完成的更复杂方法（例如Leave-P-Out）要好。
- en: 3\. Class Distribution
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 类别分布
- en: Class imbalance strongly affects how we should validate our model. With unbalanced
    data, stratified validation methods become essential. Methods like Stratified
    K-fold and Stratified ShuffleSplit make sure each testing split has about the
    same mix of classes as our full dataset. Without using these stratified methods,
    some test sets might end up with no particular class at all, making it impossible
    to properly test how well our model makes prediction.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 类别不平衡会强烈影响我们应该如何验证模型。对于不平衡数据，分层验证方法变得至关重要。像分层K折交叉验证和分层ShuffleSplit这样的方式确保每个测试划分与完整数据集的类别分布大致相同。如果不使用这些分层方法，一些测试集可能完全没有某个类别，这样就无法正确测试模型的预测效果。
- en: 4\. Time Series
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 时间序列
- en: When working with data that changes over time, we need special validation approaches.
    Regular random splitting methods don’t work well because time order matters.With
    time series data, we must use methods like Time Series Split that respect time
    order.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理随时间变化的数据时，我们需要特殊的验证方法。常规的随机划分方法效果不佳，因为时间顺序很重要。对于时间序列数据，我们必须使用像时间序列划分（Time
    Series Split）这样的方式，尊重时间顺序。
- en: 5\. Group Dependencies
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 群组依赖
- en: Many datasets contain natural groups of related data. These connections in our
    data need special handling when we validate our models. When data points are related,
    we need to use methods like Group K-fold to prevent our model from accidentally
    learning things it shouldn’t.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据集包含自然的相关数据组。在验证模型时，这些数据中的连接需要特殊处理。当数据点相关时，我们需要使用像Group K-fold这样的方式，以防止我们的模型错误地学习到不该学习的东西。
- en: Practical Guidelines
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实用指南
- en: This flowchart will help you select the most appropriate validation method for
    your data. The steps below outline a clear process for choosing the best validation
    approach, assuming you have sufficient computing resources.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这张流程图将帮助你为你的数据选择最合适的验证方法。下面的步骤概述了一个清晰的选择最佳验证方法的过程，前提是你有足够的计算资源。
- en: '![](../Images/3c111d0da670ace01dcf36fc6effc876.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c111d0da670ace01dcf36fc6effc876.png)'
- en: Final Remarks
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的备注
- en: Model validation is essential for building reliable machine learning models.
    After exploring many validation methods, from simple train-test splits to complex
    cross-validation approaches, we’ve learned that there is always a suitable validation
    method for whatever data you have.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 模型验证对于构建可靠的机器学习模型至关重要。在探索了许多验证方法，从简单的训练-测试划分到复杂的交叉验证方法后，我们发现，总有一种适合你的数据的验证方法。
- en: While machine learning keeps changing with new methods and tools, these basic
    rules of validation stay the same. When you understand these principles well,
    I believe you’ll build models that people can trust and rely on.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然机器学习在不断变化，出现了新的方法和工具，但这些基本的验证规则始终不变。当你很好地理解这些原则时，我相信你会建立起人们可以信任和依赖的模型。
- en: Further Reading
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入阅读
- en: For a detailed explanation of the [validation methods in](https://scikit-learn.org/stable/api/sklearn.model_selection.html)
    `[scikit-learn](https://scikit-learn.org/stable/api/sklearn.model_selection.html)`,
    readers can refer to the official documentation, which provides comprehensive
    information on its usage and parameters.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 关于[验证方法](https://scikit-learn.org/stable/api/sklearn.model_selection.html)的详细解释，读者可以参考官方文档，里面提供了全面的使用和参数说明。
- en: Technical Environment
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术环境
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用的是Python 3.7和scikit-learn 1.5。尽管所讨论的概念通常适用，但具体的代码实现可能会因版本不同而有所变化。
- en: About the Illustrations
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于插图
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，否则所有图片均由作者创作，并结合了Canva Pro的授权设计元素。
- en: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝙈𝙤𝙙𝙚𝙡 𝙀𝙫𝙖𝙡𝙪𝙖𝙩𝙞𝙤𝙣 & 𝙊𝙥𝙩𝙞𝙢𝙞𝙯𝙖𝙩𝙞𝙤𝙣 𝙢𝙚𝙩𝙝𝙤𝙙𝙨 𝙝𝙚𝙧𝙚:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝙈𝙤𝙙𝙚𝙡 𝙀𝙫𝙖𝙡𝙪𝙖𝙩𝙞𝙤𝙣 & 𝙊𝙥𝙩𝙞𝙢𝙞𝙯𝙖𝙩𝙞𝙤𝙣 𝙢𝙚𝙩𝙝𝙤𝙙𝙨 𝙝𝙚𝙧𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
- en: Model Evaluation & Optimization
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估与优化
- en: '[View list](https://medium.com/@samybaladram/list/model-evaluation-optimization-331287896864?source=post_page-----eb13bbdc8f88--------------------------------)3
    stories![](../Images/18fa82b1435fa7d5571ee54ae93a6c62.png)![](../Images/c95e89d05d1de700c631c342cd008de0.png)![](../Images/30e20e1a8ba3ced1e77644b706acd18d.png)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/model-evaluation-optimization-331287896864?source=post_page-----eb13bbdc8f88--------------------------------)3个故事![](../Images/18fa82b1435fa7d5571ee54ae93a6c62.png)![](../Images/c95e89d05d1de700c631c342cd008de0.png)![](../Images/30e20e1a8ba3ced1e77644b706acd18d.png)'
- en: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
- en: Classification Algorithms
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----eb13bbdc8f88--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----eb13bbdc8f88--------------------------------)8个故事![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----eb13bbdc8f88--------------------------------)'
- en: Ensemble Learning
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成学习
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----eb13bbdc8f88--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----eb13bbdc8f88--------------------------------)4个故事![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
