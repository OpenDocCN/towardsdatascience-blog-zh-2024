["```py\nfrom langchain import hub\nfrom langchain.chains import SequentialChain\n\ncot_step1 = hub.pull(\"rachnogstyle/nlw_jan24_cot_step1\")\ncot_step2 = hub.pull(\"rachnogstyle/nlw_jan24_cot_step2\")\ncot_step3 = hub.pull(\"rachnogstyle/nlw_jan24_cot_step3\")\ncot_step4 = hub.pull(\"rachnogstyle/nlw_jan24_cot_step4\")\n\nmodel = \"gpt-3.5-turbo\"\n\nchain1 = LLMChain(\n    llm=ChatOpenAI(temperature=0, model=model),\n    prompt=cot_step1,\n    output_key=\"solutions\"\n)\n\nchain2 = LLMChain(\n    llm=ChatOpenAI(temperature=0, model=model),\n    prompt=cot_step2,\n    output_key=\"review\"\n)\n\nchain3 = LLMChain(\n    llm=ChatOpenAI(temperature=0, model=model),\n    prompt=cot_step3,\n    output_key=\"deepen_thought_process\"\n)\n\nchain4 = LLMChain(\n    llm=ChatOpenAI(temperature=0, model=model),\n    prompt=cot_step4,\n    output_key=\"ranked_solutions\"\n)\n\noverall_chain = SequentialChain(\n    chains=[chain1, chain2, chain3, chain4],\n    input_variables=[\"input\", \"perfect_factors\"],\n    output_variables=[\"ranked_solutions\"],\n    verbose=True\n)\n```", "```py\nprompt = hub.pull(\"hwchase17/react\")\nprompt = hub.pull(\"hwchase17/self-ask-with-search\")\n```", "```py\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain.agents import AgentExecutor\nfrom langchain.agents import create_openai_functions_agent\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\ntools = [retriever_tool]\nagent = create_openai_functions_agent(\n    llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n\nmessage_history = ChatMessageHistory()\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor,\n    lambda session_id: message_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n)\n```", "```py\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\n\nloader = WebBaseLoader(\"https://neurons-lab.com/\")\ndocs = loader.load()\ndocuments = RecursiveCharacterTextSplitter(\n    chunk_size=1000, chunk_overlap=200\n).split_documents(docs)\nvector = FAISS.from_documents(documents, OpenAIEmbeddings())\nretriever = vector.as_retriever()\n```", "```py\nfrom langchain.utilities.tavily_search import TavilySearchAPIWrapper\nfrom langchain.tools.tavily_search import TavilySearchResults\n\nsearch = TavilySearchAPIWrapper()\ntavily_tool = TavilySearchResults(api_wrapper=search)\n\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)\nagent_chain = initialize_agent(\n    [retriever_tool, tavily_tool],\n    llm,\n    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True,\n)\n```", "```py\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import BaseTool, StructuredTool, tool\n\n@tool\ndef calculate_length_tool(a: str) -> int:\n    \"\"\"The function calculates the length of the input string.\"\"\"\n    return len(a)\n\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)\nagent_chain = initialize_agent(\n    [retriever_tool, tavily_tool, calculate_length_tool],\n    llm,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True,\n)\n```", "```py\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\nagent = create_openai_functions_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor,\n    lambda session_id: message_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n)\n```"]