- en: 'LoRA: Revolutionizing Large Language Model Adaptation without Fine-Tuning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/lora-revolutionizing-large-language-model-adaptation-without-fine-tuning-3279d909f5af?source=collection_archive---------8-----------------------#2024-04-23](https://towardsdatascience.com/lora-revolutionizing-large-language-model-adaptation-without-fine-tuning-3279d909f5af?source=collection_archive---------8-----------------------#2024-04-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploiting the low-rank nature of weight updates during fine-tuning results
    in orders of magnitude reduction in learnable parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samuel.flender?source=post_page---byline--3279d909f5af--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page---byline--3279d909f5af--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3279d909f5af--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3279d909f5af--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page---byline--3279d909f5af--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3279d909f5af--------------------------------)
    ·8 min read·Apr 23, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0fdea0772d1307bd66eb057e35a2c984.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated with ChatGPT
  prefs: []
  type: TYPE_NORMAL
- en: Ever since the introduction of BERT in 2019, [fine-tuning](https://mlfrontiers.substack.com/p/what-exactly-happens-when-we-fine)
    has been the standard approach to adapt large language models (LLMs) to downstream
    tasks. This changed with the introduction of LoRA ([Hu et al 2021](https://arxiv.org/abs/2106.09685))
    which showed for the first time that the weight update matrix during fine-tuning
    can be drastically simplified using low-rank factorization, often with orders
    of magnitude fewer trainable parameters!
  prefs: []
  type: TYPE_NORMAL
- en: LoRA has become very popular in the NLP community because it allows us to adapt
    LLMs to downstream tasks faster, more robustly, and with smaller model footprints
    than ever before.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at how it works.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with fine-tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Google’s BERT ([Devlin et al 2019](https://arxiv.org/pdf/1810.04805.pdf)) was
    a paradigm shift in NLP, in particular because of its introduction of the pre-training
    / fine-tuning paradigm: after unsupervised pre-training on a massive amount of
    text data, the model can be rapidly fine-tuned on a specific downstream task with
    relatively few labels because generic linguistic patterns have…'
  prefs: []
  type: TYPE_NORMAL
