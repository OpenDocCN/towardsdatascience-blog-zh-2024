["```py\n# IMPORTING DATASET #\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport numpy as np\n\ndataset_dict = {\n    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain', 'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast', 'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'],\n    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],\n    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],\n    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']\n}\ndf = pd.DataFrame(dataset_dict)\n\n# ONE-HOT ENCODE 'Outlook' COLUMN\ndf = pd.get_dummies(df, columns=['Outlook'],  prefix='', prefix_sep='', dtype=int)\n\n# CONVERT 'Windy' (bool) and 'Play' (binary) COLUMNS TO BINARY INDICATORS\ndf['Wind'] = df['Wind'].astype(int)\ndf['Play'] = (df['Play'] == 'Yes').astype(int)\n\n# Set feature matrix X and target vector y\nX, y = df.drop(columns='Play'), df['Play']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\n\nprint(pd.concat([X_train, y_train], axis=1), end='\\n\\n')\nprint(pd.concat([X_test, y_test], axis=1))\n```", "```py\n# One-hot encode the categorized columns and drop them after, but do it separately for training and test sets\n# Define categories for 'Temperature' and 'Humidity' for training set\nX_train['Temperature'] = pd.cut(X_train['Temperature'], bins=[0, 80, 100], labels=['Warm', 'Hot'])\nX_train['Humidity'] = pd.cut(X_train['Humidity'], bins=[0, 75, 100], labels=['Dry', 'Humid'])\n\n# Similarly, define for the test set\nX_test['Temperature'] = pd.cut(X_test['Temperature'], bins=[0, 80, 100], labels=['Warm', 'Hot'])\nX_test['Humidity'] = pd.cut(X_test['Humidity'], bins=[0, 75, 100], labels=['Dry', 'Humid'])\n\n# One-hot encode the categorized columns\none_hot_columns_train = pd.get_dummies(X_train[['Temperature', 'Humidity']], drop_first=True, dtype=int)\none_hot_columns_test = pd.get_dummies(X_test[['Temperature', 'Humidity']], drop_first=True, dtype=int)\n\n# Drop the categorized columns from training and test sets\nX_train = X_train.drop(['Temperature', 'Humidity'], axis=1)\nX_test = X_test.drop(['Temperature', 'Humidity'], axis=1)\n\n# Concatenate the one-hot encoded columns with the original DataFrames\nX_train = pd.concat([one_hot_columns_train, X_train], axis=1)\nX_test = pd.concat([one_hot_columns_test, X_test], axis=1)\n\nprint(pd.concat([X_train, y_train], axis=1), '\\n')\nprint(pd.concat([X_test, y_test], axis=1))\n```", "```py\nfrom fractions import Fraction\n\ndef calc_target_prob(attr):\n    total_counts = attr.value_counts().sum()\n    prob_series = attr.value_counts().apply(lambda x: Fraction(x, total_counts).limit_denominator())\n    return prob_series\n\nprint(calc_target_prob(y_train))\n```", "```py\nfrom fractions import Fraction\n\ndef sort_attr_label(attr, lbl):\n    return (pd.concat([attr, lbl], axis=1)\n            .sort_values([attr.name, lbl.name])\n            .reset_index()\n            .rename(columns={'index': 'ID'})\n            .set_index('ID'))\n\ndef calc_feature_prob(attr, lbl):\n    total_classes = lbl.value_counts()\n    counts = pd.crosstab(attr, lbl)\n    prob_df = counts.apply(lambda x: [Fraction(c, total_classes[x.name]).limit_denominator() for c in x])\n\n    return prob_df\n\nprint(sort_attr_label(y_train, X_train['sunny']))\nprint(calc_feature_prob(X_train['sunny'], y_train))\n```", "```py\nfor col in X_train.columns:\n  print(calc_feature_prob(X_train[col], y_train), \"\\n\")\n```", "```py\n# In sklearn, all processes above is summarized in this 'fit' method:\nfrom sklearn.naive_bayes import BernoulliNB\nnb_clf = BernoulliNB(alpha=1)\nnb_clf.fit(X_train, y_train)\n```", "```py\ny_pred = nb_clf.predict(X_test)\nprint(y_pred)\n```", "```py\n# Evaluate the classifier\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\n# Import needed libraries\nimport pandas as pd\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndataset_dict = {\n    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy', 'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast', 'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],\n    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],\n    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],\n    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']\n}\ndf = pd.DataFrame(dataset_dict)\n\n# Prepare data for model\ndf = pd.get_dummies(df, columns=['Outlook'],  prefix='', prefix_sep='', dtype=int)\ndf['Wind'] = df['Wind'].astype(int)\ndf['Play'] = (df['Play'] == 'Yes').astype(int)\n\n# Split data into training and testing sets\nX, y = df.drop(columns='Play'), df['Play']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\n\n# Scale numerical features (for automatic binarization)\nscaler = StandardScaler()\nfloat_cols = X_train.select_dtypes(include=['float64']).columns\nX_train[float_cols] = scaler.fit_transform(X_train[float_cols])\nX_test[float_cols] = scaler.transform(X_test[float_cols])\n\n# Train the model\nnb_clf = BernoulliNB()\nnb_clf.fit(X_train, y_train)\n\n# Make predictions\ny_pred = nb_clf.predict(X_test)\n\n# Check accuracy\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```"]