- en: 'Quantum Mechanics Meets PCA: An (Un)expected Convergence'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量子力学与PCA相遇：一种（不）意外的融合
- en: 原文：[https://towardsdatascience.com/quantum-mechanics-meets-pca-an-un-expected-convergence-5e04bcb16376?source=collection_archive---------1-----------------------#2024-05-22](https://towardsdatascience.com/quantum-mechanics-meets-pca-an-un-expected-convergence-5e04bcb16376?source=collection_archive---------1-----------------------#2024-05-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/quantum-mechanics-meets-pca-an-un-expected-convergence-5e04bcb16376?source=collection_archive---------1-----------------------#2024-05-22](https://towardsdatascience.com/quantum-mechanics-meets-pca-an-un-expected-convergence-5e04bcb16376?source=collection_archive---------1-----------------------#2024-05-22)
- en: How quantum states and PCA components connect
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量子态与PCA组件的联系
- en: '[](https://medium.com/@rodrigopesilva?source=post_page---byline--5e04bcb16376--------------------------------)[![Rodrigo
    Silva](../Images/d260f05ed9887c5072e0590db1481be2.png)](https://medium.com/@rodrigopesilva?source=post_page---byline--5e04bcb16376--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5e04bcb16376--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5e04bcb16376--------------------------------)
    [Rodrigo Silva](https://medium.com/@rodrigopesilva?source=post_page---byline--5e04bcb16376--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@rodrigopesilva?source=post_page---byline--5e04bcb16376--------------------------------)[![Rodrigo
    Silva](../Images/d260f05ed9887c5072e0590db1481be2.png)](https://medium.com/@rodrigopesilva?source=post_page---byline--5e04bcb16376--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5e04bcb16376--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5e04bcb16376--------------------------------)
    [Rodrigo Silva](https://medium.com/@rodrigopesilva?source=post_page---byline--5e04bcb16376--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5e04bcb16376--------------------------------)
    ·8 min read·May 22, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5e04bcb16376--------------------------------)
    ·阅读时长8分钟·2024年5月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c54c6270dff8c1bf03529adba4ce1195.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c54c6270dff8c1bf03529adba4ce1195.png)'
- en: Photo by [Dynamic Wang](https://unsplash.com/@dynamicwang)on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[动态王](https://unsplash.com/@dynamicwang)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: One of the greatest gifts of maths is its weird ability to be as general as
    our creativity allows. An important consequence of this generalizability is that
    we can use the same set of tools to create formalisms for vastly different topics.
    A side effect of when we do this is that some unexpected analogies will appear
    between these different areas. To illustrate what I'm saying, I will try to convince
    you, through this article, that the principal values in PCA coordinates and the
    energies of a quantum system are the same (mathematical) thing.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数学的最伟大礼物之一就是它奇特的能力，能够像我们的创造力一样广泛。这个广泛性的重要后果是，我们可以使用相同的工具集为截然不同的主题创建形式化方法。当我们这么做时，一个副作用是，某些不同领域之间会出现一些意想不到的类比。为了说明我所说的，我将通过这篇文章说服你，主成分分析（PCA）坐标中的主值和量子系统的能量是相同（数学上的）东西。
- en: The linear algebra of PCA
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PCA的线性代数
- en: For those unfamiliar with Principal Component Analysis (or PCA), I will formulate
    it on the bare minimum. The main idea of PCA is, based on your data, to obtain
    a new set of coordinates such that when our original data is rewritten in this
    new coordinate system, the axes point in the direction of the highest variance.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不熟悉主成分分析（PCA）的人，我将简要介绍它的基本概念。PCA的主要思想是，基于你的数据，获得一组新的坐标系，这样当我们的原始数据被重写到这个新的坐标系中时，坐标轴将指向方差最大的方向。
- en: Suppose you have a set of *n* data samples (which I shall refer from now on
    as *individuals*), where each individual consists of *m* features. For instance,
    if I ask for the weight, height, and salary of 10 different people, *n=*10 and
    *m=3*. In this example, we expect some relation between weight and height, but
    there is no relation between these variables and salary, at least not in principle.
    PCA will help us better visualize these relations. For us to understand how and
    why this happens, I'll go through each step of the PCA algorithm.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一组*n*数据样本（我将从现在开始称它们为*个体*），其中每个个体包含*m*个特征。例如，如果我询问10个不同人的体重、身高和工资，那么*n=10*，*m=3*。在这个例子中，我们预计体重和身高之间有某种关系，但这些变量和工资之间没有关系，至少从原理上讲是没有的。PCA将帮助我们更好地可视化这些关系。为了让我们理解这种情况是如何发生的以及为什么会发生，我将逐步讲解PCA算法的每个步骤。
- en: 'To begin the formalism, each individual will be represented by a vector **x**,
    where each component of this vector is a feature. This means that we will have
    *n* vectors living in an *m*-dimensional space. Our dataset can be regarded as
    a big matrix *X*, *m* x *n*, where we essentially place the individuals side-by-side
    (a.k.a. each individual is represented as a column vector):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始正式的推导，每个个体将由向量**x**表示，其中该向量的每个分量是一个特征。这意味着我们将有 *n* 个向量，它们存在于 *m* 维空间中。我们的数据集可以看作一个大的矩阵
    *X*，*m* x *n*，其中我们本质上将个体并排放置（即每个个体用列向量表示）：
- en: '![](../Images/7eeb01ff584ab418e7618165d50bfcfb.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7eeb01ff584ab418e7618165d50bfcfb.png)'
- en: With this in mind, we can properly begin the PCA algorithm.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些前提，我们可以正式开始PCA算法。
- en: Centralize the data
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据中心化
- en: 'Centralizing our data means shifting the data points in a way that it becomes
    distributed around the origin of our coordinate system. To do this, we calculate
    the mean for each feature and subtract it from the data points. We can express
    the mean for each feature as a vector **µ**:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化意味着以某种方式平移数据点，使其分布在坐标系的原点周围。为了实现这一点，我们计算每个特征的均值，并将其从数据点中减去。我们可以将每个特征的均值表示为向量**µ**：
- en: '![](../Images/1522c66363cbc2430708a55432568541.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1522c66363cbc2430708a55432568541.png)'
- en: 'where *µ_i* is the mean taken for the *i*-th feature. By centralizing our data
    we get a new matrix *B* given by:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *µ_i* 是对第 *i* 个特征求得的均值。通过数据中心化，我们得到一个新的矩阵 *B*，表示为：
- en: '![](../Images/dd96356b4b24dba6ffbbb7e03045c426.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd96356b4b24dba6ffbbb7e03045c426.png)'
- en: This matrix *B* represents our data set centered around the origin. Notice that,
    since I'm defining the mean vector as a row matrix, I have to use its *transpose*
    to calculate *B* (where each individual is represented by a column matrix), but
    this is just a minor detail.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵 *B* 表示我们围绕原点中心化的数据集。注意，由于我将均值向量定义为行矩阵，因此在计算 *B* 时需要使用其*转置*（其中每个个体用列矩阵表示），但这只是一个小细节。
- en: Compute the covariance matrix
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算协方差矩阵
- en: 'We can compute the covariance matrix, *S*, by multiplying the matrix *B* and
    its transpose *B^T* as shown below:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将矩阵 *B* 和其转置 *B^T* 相乘来计算协方差矩阵 *S*，如下所示：
- en: '![](../Images/c826739ce5c5dbfeb89e5e59a234535b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c826739ce5c5dbfeb89e5e59a234535b.png)'
- en: The 1*/(n-*1*)* factor in front is just to make the definition equal to the
    statistical definition. One can easily show that elements *S_ij* of the above
    matrix are the covariances of the feature *i* with the feature *j*, and its diagonal
    entry *S_ii* is the variance of the *i-*th feature.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的1*/(n-*1*)*因子只是为了使定义与统计学定义一致。可以很容易地证明，上述矩阵的元素 *S_ij* 是特征 *i* 与特征 *j* 的协方差，其对角线元素
    *S_ii* 是 *i* 维特征的方差。
- en: Find the eigenvalues and eigenvectors of the covariance matrix
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 找到协方差矩阵的特征值和特征向量
- en: 'I will list three important facts from linear algebra (that I will not prove
    here) about the covariance matrix *S* that we have constructed so far:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我将列出三个关于我们到目前为止构建的协方差矩阵 *S* 的重要线性代数事实（我将在这里不进行证明）：
- en: 'The matrix *S* is symmetric: the mirrored entries with respect to the diagonal
    are equal (i.e. *S_ij = S_ji*);'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 矩阵 *S* 是对称的：关于对角线的镜像条目是相等的（即 *S_ij = S_ji*）；
- en: 'The matrix *S* is orthogonally diagonalizable: there is a set of numbers (λ_1,
    λ_2, …, λ_m) called *eigenvalues*, and a set of vectors (**v_**1, **v_**2 …, **v_**m)
    called *eigenvectors*, such that, when *S* is written using the eigenvectors as
    a basis, it has a diagonal form with diagonal elements being its eigenvalues;'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 矩阵 *S* 是正交对角化的：存在一组数字（λ_1, λ_2, …, λ_m）称为*特征值*，以及一组向量（**v_**1, **v_**2 …, **v_**m）称为*特征向量*，使得，当
    *S* 使用特征向量作为基底表示时，它具有对角形式，且对角线元素是其特征值；
- en: The matrix *S* has only real, non-negative eigenvalues.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 矩阵 *S* 只有实数的非负特征值。
- en: In PCA formalism, the eigenvectors of the covariance matrix are called the principal
    components, and the eigenvalues are called the principal values.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在主成分分析（PCA）公式中，协方差矩阵的特征向量称为主成分，特征值称为主值。
- en: 'At first glance, it seems just a bunch of mathematical operations on a data
    set. But I will give you a last linear algebra fact and we are done with maths
    for today:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，这似乎只是对一个数据集进行一系列数学运算。但我会给你提供最后一个线性代数的事实，今天的数学部分就到这里：
- en: 4\. The trace of a matrix (i.e. the sum of its diagonal terms) is independent
    of the basis in which the matrix is represented.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 矩阵的迹（即对角线元素的总和）与矩阵所表示的基底无关。
- en: This means that, if the sum of the diagonal terms in matrix *S* is the total
    variance of that data set, then the sum of the *eigenvalues* of matrix *S* is
    also the total variance of the data set. Let's call this total variance *L.*
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果矩阵*S*中对角线元素的和是数据集的总方差，那么矩阵*S*的*特征值*的和也应该是数据集的总方差。我们将这个总方差称为*L*。
- en: 'Having this mechanism in mind, we can order the eigenvalues (λ_1, λ_2, …, λ_m)
    in descending order: λ_1 > λ_2 > … > λ_m in a way that λ_1/*L* > λ_2/*L* > … >
    λ_m/*L*. We have ordered our eigenvalues using the total variance of our data
    set as the importance metric. The first principal component, **v_**1, points towards
    the direction of the largest variance because its eigenvalue, λ_1, accounts for
    the largest contribution to the total variance.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这一机制，我们可以按降序排列特征值（λ_1，λ_2，…，λ_m）：λ_1 > λ_2 > … > λ_m，使得λ_1/*L* > λ_2/*L* >
    … > λ_m/*L*。我们使用数据集的总方差作为重要性度量来对特征值进行排序。第一个主成分**v_1**指向方差最大的方向，因为它的特征值λ_1占据了总方差的最大贡献。
- en: This is PCA in a nutshell. Now… what about quantum mechanics?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是PCA的核心概念。那么…量子力学呢？
- en: The linear algebra of quantum mechanics
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量子力学的线性代数
- en: 'Maybe the most important aspect of quantum mechanics for our discussion here
    is one of its postulates:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 也许量子力学中对我们讨论最重要的一个方面是它的一个公设：
- en: The states of a quantum system are represented as vectors (usually called state
    vectors) that live in a vector space, called the Hilbert space.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 量子系统的状态用向量表示（通常称为态向量），这些向量存在于一个向量空间中，这个空间称为希尔伯特空间。
- en: As I'm writing this, I noticed that I find this postulate to be very natural
    because I see this everyday, and I have got used to it. But it's kinda absurd,
    so take your time to absorb this. Bear in mind that *state* is a generic term
    that we use in physics that means "the configuration of something at a certain
    time."
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当我写到这里时，我注意到我发现这个公设非常自然，因为我每天都见到它，并且已经习惯了。但它有点荒谬，所以请花时间消化一下。请记住，*态*是我们在物理学中使用的一个通用术语，指的是“某个事物在某一时刻的配置”。
- en: This postulate implies that when we representour physical system as a vector,
    all the rules from linear algebra apply here, and there should be no surprise
    that some connections between PCA (which also relies on linear algebra) and quantum
    mechanics arise.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公设意味着，当我们将物理系统表示为一个向量时，线性代数中的所有规则都适用，因此不会感到惊讶的是，PCA（也依赖于线性代数）和量子力学之间会有一些联系。
- en: 'Since physics is the science interested in how physical systems change, we
    should be able to represent *changes* in the formalism of quantum mechanics. To
    *change* a vector, we must apply some kind of operation on it using a mathematical
    entity called (not surprisingly) operator. A class of operators of particular
    interest is the class of linear operators; in fact, they are so important that
    we usually omit the term "linear" because it is implied that when we are talking
    about operators, these are linear operators. Hence, if you want to impress people
    at a bar table, just drop this bomb:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于物理学是研究物理系统如何变化的科学，我们应该能够在量子力学的形式主义中表示*变化*。要*改变*一个向量，我们必须对其应用某种操作，使用一个被称为（毫不奇怪的）算符的数学实体。一类特别重要的算符是线性算符；事实上，它们非常重要，以至于我们通常省略“线性”这个词，因为在讨论算符时，通常默认它们是线性算符。因此，如果你想在酒吧桌上给人留下深刻印象，尽管说出这个爆炸性的事实：
- en: In quantum mechanics, it's all about (state) vectors and (linear) operators.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在量子力学中，一切都围绕着（态）向量和（线性）算符展开。
- en: Measurements in quantum mechanics
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量子力学中的测量
- en: If in the context of quantum mechanics, vectors represent physical states, what
    does operators represent? Well, they represent physical *measurements*. For instance,
    if I want to measure the position of a quantum particle, it is modeled in quantum
    mechanics as applying a position operator on the state vector associated with
    the particle. Similarly, if I want to measure the energy of a quantum particle,
    I must apply the energy operator to it. The final catch here to connect quantum
    mechanics and PCA is to remember that a linear operator, when you choose a basis,
    can be represented as a matrix.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在量子力学的背景下，向量表示物理状态，那么算符表示什么呢？嗯，它们表示物理*测量*。例如，如果我想测量一个量子粒子的位置，在量子力学中，它是通过对与粒子关联的态向量应用位置算符来建模的。同样，如果我想测量一个量子粒子的能量，我必须对其应用能量算符。将量子力学和PCA联系起来的关键是记住，当你选择一个基底时，线性算符可以表示为一个矩阵。
- en: 'A very common basis used to represent our quantum systems is the basis made
    by the eigenvectors of the energy operator. In this basis, the energy operator
    matrix is diagonal, and its diagonal terms are the energies of the system for
    different energy (eigen)states. The sum of these energy values corresponds to
    the trace of your energy operator, and if you stop and think about it, of course
    this cannot change under a change of basis, as said earlier in this text. If it
    did change, it would imply that it should be possible to change the energy of
    a system by writing its components differently, which is absurd. Your measuring
    apparatus in the lab does not care if you use basis A or B to represent your system:
    if you measure the energy, you measure the energy and that''s it.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 表示我们量子系统的一种非常常见的基是由能量算符的特征向量构成的基。在这个基中，能量算符矩阵是对角的，且其对角线上的项是系统在不同能量（本征）态下的能量。这些能量值的总和对应于能量算符的迹，如果你停下来仔细思考，显然这个总和在基变换下不会改变，正如本文早些时候所说的那样。如果它发生了变化，那就意味着应该有可能通过改变组件的表示方式来改变系统的能量，这显然是荒谬的。你在实验室中的测量仪器并不关心你是使用基A还是基B来表示你的系统：如果你测量的是能量，那你测量的就是能量，仅此而已。
- en: Energies and PCA
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 能量与主成分分析（PCA）
- en: With all being said, a nice interpretation of the principal values of a PCA
    decomposition is that they correspond to the "energy" of your system. When you
    write down your principal values (and principal components) in descending order,
    you are giving priority to the "states" that carry the largest "energies" of your
    system.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 综上所述，对PCA分解的主值的一个很好的解释是，它们对应于你系统的“能量”。当你按降序排列主值（和主成分）时，你实际上是优先考虑了那些携带你系统最大“能量”的“状态”。
- en: This interpretation may be somewhat more insightful than trying to interpret
    a statistical quantity such as variance. I believe that we have a better intuition
    about energy since it is a fundamental physical concept.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种解释可能比试图解释诸如方差之类的统计量更具洞察力。我相信我们对能量有更好的直觉，因为它是一个基础的物理概念。
- en: Conclusion
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: '"All of this is pretty obvious." This was a provocation made by my dearest
    friend [Rodrigo da Motta](https://medium.com/@rodrigodamottacc), referring to
    the article you''ve just read.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: “这一切其实是显而易见的。”这是我最亲爱的朋友[罗德里戈·达·莫塔](https://medium.com/@rodrigodamottacc)对你刚刚阅读的文章做出的挑衅。
- en: When I write posts like this, I try to explain things having in mind the reader
    with minimum context. This exercise led me to the conclusion that, with the right
    background, pretty much anything can be potentially obvious. Rodrigo and I are
    physicists who also happen to be data scientists, so this relationship between
    quantum mechanics and PCA must be pretty obvious *to us*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我写这样的文章时，我会尽量考虑到读者只有最基本的背景知识。这一练习使我得出结论：只要具备正确的背景，几乎任何事情都可以变得显而易见。罗德里戈和我都是物理学家，同时也恰好是数据科学家，所以量子力学和主成分分析（PCA）之间的关系对我们来说一定是相当显而易见的*。
- en: Writing posts like this gives me more reasons to believe that we should expose
    ourselves to all kinds of knowledge because that's when interesting connections
    arise. The same human brain that thinks about and creates the understanding of
    physics is the one that creates the understanding of biology, and history, and
    cinema. If the possibilities of language and the connections of our brains are
    finite, it means that contiously or not, we eventually recycle concepts from one
    field into another, and this creates underlying shared structures accross the
    domains of knowledge.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 写这样的文章让我更坚信我们应该接触所有种类的知识，因为只有在那个时候，才会有有趣的联系出现。思考并创造物理理解的那个人脑，正是创造生物学、历史和电影理解的那个脑。如果语言的可能性和我们大脑的连接是有限的，那么无论是否有意识地，我们最终会将一个领域的概念回收并应用到另一个领域，这就创造了跨领域的共享结构。
- en: We, as scientists, should take advantage of this.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作为科学家，我们应该利用这一点。
- en: References
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Linear algebra of PCA: [https://www.math.union.edu/~jaureguj/PCA.pdf](https://www.math.union.edu/~jaureguj/PCA.pdf)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] PCA的线性代数：[https://www.math.union.edu/~jaureguj/PCA.pdf](https://www.math.union.edu/~jaureguj/PCA.pdf)'
- en: '[2] The postulates of quantum mechanics: [https://web.mit.edu/8.05/handouts/jaffe1.pdf](https://web.mit.edu/8.05/handouts/jaffe1.pdf)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] 量子力学的公设：[https://web.mit.edu/8.05/handouts/jaffe1.pdf](https://web.mit.edu/8.05/handouts/jaffe1.pdf)'
