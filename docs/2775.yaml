- en: Ontology Reasoning in Knowledge Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ontology-reasoning-in-knowledge-graphs-7e563cc5b62a?source=collection_archive---------0-----------------------#2024-11-15](https://towardsdatascience.com/ontology-reasoning-in-knowledge-graphs-7e563cc5b62a?source=collection_archive---------0-----------------------#2024-11-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[KGs Insights](https://towardsdatascience.com/tagged/kgs-insights)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Python hands-on guide to understanding the principles of generating new knowledge
    by following logical processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@giuseppefutia?source=post_page---byline--7e563cc5b62a--------------------------------)[![Giuseppe
    Futia](../Images/4d1d3b3766eca9ae8220dc5eb480a4cf.png)](https://medium.com/@giuseppefutia?source=post_page---byline--7e563cc5b62a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7e563cc5b62a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7e563cc5b62a--------------------------------)
    [Giuseppe Futia](https://medium.com/@giuseppefutia?source=post_page---byline--7e563cc5b62a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7e563cc5b62a--------------------------------)
    ·9 min read·Nov 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a3ae55dfa91d8d9a9818fc612db9031d.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1 — An end-to-end process illustrating how starting statements lead to
    inferred ones through ontology reasoning
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reasoning capabilities are a widely discussed topic in the context of AI systems.
    These capabilities are often associated with Large Language Models (LLMs), which
    are particularly effective in extracting patterns learned from a vast amount of
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The knowledge captured during this learning process enables LLMs to perform
    various language tasks, such as question answering and text summarization, showing
    skills that resemble human reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: It’s not helpful to just say “LLMs can’t reason”, since clearly they do some
    things which humans would use reasoning for. — *Jeremy Howard |
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Co-Founder Fast.AI — Digital Fellow at Stanford*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Despite their ability to identify and match patterns within data, LLMs show
    limitations in tasks that require structured and formal reasoning, especially
    in fields that demand rigorous logical processes.
  prefs: []
  type: TYPE_NORMAL
- en: These limitations highlight the distinction between pattern recognition and
    proper logical reasoning, a difference humans do not always discern.
  prefs: []
  type: TYPE_NORMAL
