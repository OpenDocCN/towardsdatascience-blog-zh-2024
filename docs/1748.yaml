- en: Semantic Search Engine for Emojis in 50+ Languages Using AI ğŸ˜ŠğŸŒğŸš€
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/semantic-search-for-emojis-in-50-languages-using-ai-f85a36a86f21?source=collection_archive---------7-----------------------#2024-07-17](https://towardsdatascience.com/semantic-search-for-emojis-in-50-languages-using-ai-f85a36a86f21?source=collection_archive---------7-----------------------#2024-07-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Develop an AI-powered semantic search for emojis using Python and open-source
    NLP libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@badr.alabsi?source=post_page---byline--f85a36a86f21--------------------------------)[![Badr
    Alabsi, PhD](../Images/1e509109fb24dec154cd155859273903.png)](https://medium.com/@badr.alabsi?source=post_page---byline--f85a36a86f21--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f85a36a86f21--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f85a36a86f21--------------------------------)
    [Badr Alabsi, PhD](https://medium.com/@badr.alabsi?source=post_page---byline--f85a36a86f21--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f85a36a86f21--------------------------------)
    Â·12 min readÂ·Jul 17, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4e4b22aa4d5eedea4c9699b59de728b5.png)'
  prefs: []
  type: TYPE_IMG
- en: If you are on social media like Twitter or LinkedIn, you have probably noticed
    that emojis are creatively used in both informal and professional text-based communication.
    For example, the *Rocket* emoji ğŸš€ is often used on LinkedIn to symbolize high
    aspirations and ambitious goals, while the *Bullseye* ğŸ¯ emoji is used in the context
    of achieving goals. Despite this growth of creative emoji use, most social media
    platforms lack a utility that assists users in choosing the right emoji to effectively
    communicate their message. I therefore decided to invest some time to work on
    a project I called Emojeez ğŸ’, an AI-powered engine for emoji search and retrieval.
    You can experience Emojeez ğŸ’ live using this fun interactive [demo](https://emojeez.streamlit.app/).
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will discuss my experience and explain how I employed advanced
    **natural language processing** (NLP) technologies to develop a **semantic search
    engine** for emojis. Concretely, I will present a case study on embedding-based
    semantic search with the following steps
  prefs: []
  type: TYPE_NORMAL
- en: How to use **LLMs** ğŸ¦œto generate semantically rich emoji descriptions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to use Hugging Face ğŸ¤— **Transformers** for multilingual embeddings
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to integrate **Qdrant** ğŸ§‘ğŸ»â€ğŸš€ vector database to perform efficient semantic
    search
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I made the full code for this project available on [GitHub](https://github.com/badrex/emojeez).
  prefs: []
  type: TYPE_NORMAL
- en: InspirationğŸ’¡
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Every new idea often begins with a spark of inspiration. For me, the spark
    came from Luciano Ramalhoâ€™s book *Fluent Python*. It is a fantastic read that
    I highly recommend for anyone who likes to write truly Pythonic code. In chapter
    4 of his book, Luciano shows how to search over Unicode characters by querying
    their names in the Unicode standards. He created a Python utility that takes a
    query like â€œcat smilingâ€ and retrieves all Unicode characters that have both â€œcatâ€
    and â€œsmilingâ€ in their names. Given the query â€œcat smilingâ€, the utility retrieves
    three emojis: ğŸ˜», ğŸ˜º, and ğŸ˜¸. Pretty cool, right?'
  prefs: []
  type: TYPE_NORMAL
- en: From there, I started thinking how modern AI technology could be used to build
    an even better emoji search utility. By â€œbetter,â€ I envisioned a search engine
    that not only has better emoji coverage but also supports user queries in multiple
    languages beyond English.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of Keyword Search ğŸ˜“
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are an emoji enthusiast, you know that ğŸ˜», ğŸ˜º, and ğŸ˜¸ arenâ€™t the only smiley
    cat emojis out there. Some cat emojis are missing, notably ğŸ˜¸ and ğŸ˜¹. This is a
    known limitation of keyword search algorithms, which rely on string matching to
    retrieve relevant items. Keyword, or **lexical search** algorithms, are known
    among information retrieval practitioners to have **high precision** but **low
    recall**. High precision means the retrieved items usually match the user query
    well. One the other hand, low recall means the algorithm might not retrieve all
    relevant items. In many cases, the lower recall is due to string matching. For
    example, the emoji ğŸ˜¹ does not have â€œsmilingâ€ in its name â€” *cat with tears of
    joy*. Therefore, it cannot be retrieved with the query â€œcat smilingâ€ if we search
    for both terms *cat* and *smiling* in its name.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue with lexical search is that it is usually **language-specific**.
    In Lucianoâ€™s Fluent Python example, you canâ€™t find emojis using a query in another
    language because all Unicode characters, including emojis, have English names.
    To support other languages, we would need to translate each query into English
    first using machine translation. This will add more complexity and might not work
    well for all languages.
  prefs: []
  type: TYPE_NORMAL
- en: But hey, itâ€™s 2024 and AI has come a long way. We now have solutions to address
    these limitations. In the rest of this article, I will show you how.
  prefs: []
  type: TYPE_NORMAL
- en: Embedding-based Semantic Search âœ¨
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recent years, a new search paradigm has emerged with the popularity of deep
    neural networks for NLP. In this paradigm, the search algorithm does not look
    at the strings that make up the items in the search database or the query. Instead,
    it operates on numerical representations of text, known as **vector embeddings**.
    In embedding-based search algorithms, the search items, whether text documents
    or visual images, are first converted into data points in a vector space such
    that **semantically relevant** items are nearby. Embeddings enable us to perform
    similarity search based on the meaning of the emoji description rather than the
    keywords in its name. Because they retrieve items based on **semantic similarity**
    rather than keyword similarity, embedding-based search algorithms are known as
    semantic search.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using semantic search for emoji retrieval solves two problems:'
  prefs: []
  type: TYPE_NORMAL
- en: We can go beyond keyword matching and use semantic similarity between emoji
    descriptions and user queries. This improves the coverage of the retrieved emojis,
    leading to higher recall.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we represent emojis as data points in a **multilingual embedding** space,
    we can enable user queries written in languages other than English, without needing
    translation into English. That is very cool, isnâ€™t it? Letâ€™s see how ğŸ‘€
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Step 1: Generating Rich Emoji Descriptions using LLMs ğŸ¦œ'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you use social media, you probably know that many emojis are almost never
    used literally. For example, ğŸ† and ğŸ‘ rarely denote an *eggplant* and *peach*.
    Social media users are very creative in assigning meanings to emojis that go beyond
    their literal interpretation. This creativity limits the expressiveness of emoji
    names in the Unicode standards. A notable example is the ğŸŒˆ emoji, which is described
    in the Unicode name simply as *rainbow*, yet it is commonly used in contexts related
    to diversity, peace, and LGBTQ+ community.
  prefs: []
  type: TYPE_NORMAL
- en: To build a useful search engine, we need a rich semantic description for each
    emoji that defines what the emoji represents and what it symbolizes. Given that
    there are more than 5000 emojis in the current Unicode standards, doing this manually
    is not feasible. Luckily, we can employ **Large Language Models** (LLMs) to assist
    us in generating metadata for each emoji. Since LLMs are trained on the entire
    web, they have likely seen how each emoji is used in context.
  prefs: []
  type: TYPE_NORMAL
- en: For this task, I used the ğŸ¦™ [**Llama 3**](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
    LLM to generate metadata for each emoji. I wrote a prompt to define the task and
    what the LLM is expected to do. As illustrated in the figure below, the LLM generated
    a rich semantic description for the *Bullseye* ğŸ¯ emoji. These descriptions are
    more suitable for semantic search compared to Unicode names. I released the LLM-generated
    descriptions as a Hugging Face [dataset](https://huggingface.co/datasets/badrex/llm-emoji-dataset).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ceeef194babbfb0bcd16d0b4f158e06c.png)'
  prefs: []
  type: TYPE_IMG
- en: Using Llama 3 LLM for generating enriched semantic descriptions for emojis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Representing Emojis as Embeddings using Sentence Transformers ğŸ”„'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a rich semantic description for each emoji in the Unicode standard,
    the next step is to represent each emoji as a vector embedding in a multidimensional
    space that captures the meaning of the emoji description. For this task, I used
    a multilingual transformer based on the **BERT** architecture, fine-tuned for
    sentence similarity across 50 languages. You can see the supported languages in
    the model [card](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)
    in the Hugging Face ğŸ¤— library.
  prefs: []
  type: TYPE_NORMAL
- en: So far, I have only discussed the embedding of emoji descriptions generated
    by the LLM, which are in English. But how can we support languages other than
    English?
  prefs: []
  type: TYPE_NORMAL
- en: Well, hereâ€™s where the magic of multilingual transformers comes in. The multilingual
    support is enabled through the embedding space itself. This means we can take
    user queries in any of the 50 supported languages and match them to emojis based
    on their English descriptions. The multilingual sentence encoder (or embedding
    model) maps semantically similar text phrases to nearby points in its embedding
    space. Let me show you what I mean with the following illustration.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c4f1cb844d59ebb3ee7160335f3365e3.png)'
  prefs: []
  type: TYPE_IMG
- en: A visual illustration of the multilingual embedding space where sentences and
    phrases are geometrically organized based on their semantic similarity regardless
    of the text language. The Arabic and Chinese texts in this figure are the literal
    translation of the phrase â€œCat smilingâ€.
  prefs: []
  type: TYPE_NORMAL
- en: In the figure above, we see that semantically similar phrases end up being data
    points that are nearby in the embedding space, even if they are expressed in different
    languages. Multilingual sentence Transformers enable **cross-lingual search**
    applications, therefore user queries and indexed search items do not have to be
    expressed in the same language.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Integrating Qdrantâ€™s Vector Database ğŸ§‘ğŸ»â€ğŸš€'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have our emojis represented as vector embeddings, the next step is to
    build an index over these embeddings in a way that allows for efficient search
    operations. For this purpose, I chose to use **Qdrant**, an open-source vector
    similarity search engine that provides high-performance search capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Qdrant for this task is a simple as the code snippet below (you can
    also check out this Jupyter [Notebook](https://github.com/badrex/emojeez/blob/main/notebooks/emoji_search_notebook.ipynb)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now the search index *vector_DB_client* is ready to take queries. All we need
    to do is to transform the coming user query into a vector embedding using the
    same embedding model we used to embed the emoji descriptions. This can be done
    through the function below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To further show the retrieved emojis, their similarity score with the query,
    and their Unicode names, I wrote the following helper function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now everything is set up, and we can look at a few examples. Remember the â€œcat
    smilingâ€ query from Lucianoâ€™s book? Letâ€™s see how semantic search is different
    from keyword search.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Awesome! Not only did we get the expected cat emojis like ğŸ˜¸, ğŸ˜º, and ğŸ˜», which
    the keyword search retrieved, but it also the smiley cats ğŸ˜¼, ğŸ˜¹, ğŸ±, and ğŸ˜½. This
    showcases the higher recall, or higher coverage of the retrieved items, I mentioned
    earlier. Indeed, more cats is always better!
  prefs: []
  type: TYPE_NORMAL
- en: The Real Power of Semantic Search ğŸª„
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous â€œcat smilingâ€ example shows how embedding-based semantic search
    can retrieve a broader and more meaningful set of items, improving the overall
    search experience. However, I donâ€™t think this example truly shows the power of
    semantic search.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine looking for something but not knowing its name. For example, take the
    ğŸ§¿ object. Do you know what itâ€™s called in English? I sure didnâ€™t. But I know a
    bit about it. In Middle Eastern and Central Asian cultures, the ğŸ§¿ is believed
    to protect against the evil eye. So, I knew what it does but not what itâ€™s called.
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s see if we can find the emoji ğŸ§¿ with our search engine by describing it
    using the query â€œprotect from evil eyeâ€.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: And Viola! It turns out that the ğŸ§¿ is actually called *Nazar Amulet*. I learned
    something new ğŸ˜„
  prefs: []
  type: TYPE_NORMAL
- en: Going Beyond English ğŸŒ ğŸŒ ğŸŒ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the features I really wanted for this search engine to have is for it
    to support as many languages besides English as possible. So far, we have not
    tested that. Letâ€™s test the multilingual capabilities using the description of
    the *Nazar Amulet* ğŸ§¿ emoji by translating the phrase â€œprotection from evil eyesâ€
    into other languages and using them as queries one language at a time. Here are
    the result below for some languages.
  prefs: []
  type: TYPE_NORMAL
- en: Arabic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: German
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Greek
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Bulgarian
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Chinese
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Japanese
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: For languages as diverse as Arabic, German, Greek, Bulgarian, Chinese, and Japanese,
    the ğŸ§¿ emoji always appears in the top 10! This is pretty fascinating since these
    languages have different linguistic features and writing scripts, thanks to the
    massive multilinguality of our ğŸ¤— sentence Transformer.
  prefs: []
  type: TYPE_NORMAL
- en: Limits of AI ğŸ™ˆ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last thing I want to mention is that no technology, no matter how advanced,
    is perfect. Semantic search is great for improving the recall of information retrieval
    systems. This means we can retrieve more relevant items even if there is no keyword
    overlap between the query and the items in the search index. However, this comes
    at the expense of precision. Remember from the ğŸ§¿ emoji example that in some languages,
    the emoji we were looking for didnâ€™t show up in the top 5 results. For this application,
    this is not a big problem since itâ€™s not cognitively demanding to quickly scan
    through emojis to find the one we desire, even if itâ€™s ranked at the 50th position.
    But in other cases such as searching through long documents, users may not have
    the patience nor the resources to skim through dozens of documents. Developers
    need to keep in mind user cognitive as well as resource constraints when building
    search engines. Some of the design choices I made for the Emojeez ğŸ’ search engine
    may not be work as well for other applications.
  prefs: []
  type: TYPE_NORMAL
- en: Another thing to mention is that AI models are known to learn s**ocio-cultural
    biases** from their training data. There is a large volume of documented research
    showing how modern language technology can amplify **gender stereotypes** and
    be unfair to **minorities**. So, we need to be aware of these issues and do our
    best to tackle them when deploying AI in the real world. If you notice such unwanted
    biases and unfair behaviors in Emojeez ğŸ’, please let me know and I will do my
    best to address them.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working on the Emojeez ğŸ’ project was a fascinating journey that taught me a
    lot about how modern AI and NLP technologies can be employed to address the limitations
    of traditional keyword search. By harnessing the power of Large Language Models
    for enriching emoji metadata, multilingual transformers for creating semantic
    embeddings, and Qdrant for efficient vector search, I was able to create a search
    engine that makes emoji search more fun and accessible across 50+ languages. Although
    this project focuses on emoji search, the underlying technology has potential
    applications in multimodal search and recommendation systems.
  prefs: []
  type: TYPE_NORMAL
- en: For readers who are proficient in languages other than English, I am particularly
    interested in your feedback. Does Emojeez ğŸ’ perform equally well in English and
    your native language? Did you notice any differences in quality or accuracy? Please
    give it a try and let me what you think. Your insights are quite invaluable.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading, and I hope you enjoy exploring Emojeez ğŸ’ as much as I
    enjoyed building it.
  prefs: []
  type: TYPE_NORMAL
- en: Happy Emoji search! ğŸ“†ğŸ˜ŠğŸŒğŸš€
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Unless otherwise noted, all images are created by the author.*'
  prefs: []
  type: TYPE_NORMAL
