- en: Data Quality Error Detection powered by LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据质量错误检测由LLM驱动
- en: 原文：[https://towardsdatascience.com/automated-detection-of-data-quality-issues-54a3cb283a91?source=collection_archive---------0-----------------------#2024-03-22](https://towardsdatascience.com/automated-detection-of-data-quality-issues-54a3cb283a91?source=collection_archive---------0-----------------------#2024-03-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/automated-detection-of-data-quality-issues-54a3cb283a91?source=collection_archive---------0-----------------------#2024-03-22](https://towardsdatascience.com/automated-detection-of-data-quality-issues-54a3cb283a91?source=collection_archive---------0-----------------------#2024-03-22)
- en: '[](https://medium.com/@simon.grah?source=post_page---byline--54a3cb283a91--------------------------------)[![Simon
    Grah](../Images/f8fd00600db79bc910ff51e9f64503d0.png)](https://medium.com/@simon.grah?source=post_page---byline--54a3cb283a91--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--54a3cb283a91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--54a3cb283a91--------------------------------)
    [Simon Grah](https://medium.com/@simon.grah?source=post_page---byline--54a3cb283a91--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@simon.grah?source=post_page---byline--54a3cb283a91--------------------------------)[![Simon
    Grah](../Images/f8fd00600db79bc910ff51e9f64503d0.png)](https://medium.com/@simon.grah?source=post_page---byline--54a3cb283a91--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--54a3cb283a91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--54a3cb283a91--------------------------------)
    [Simon Grah](https://medium.com/@simon.grah?source=post_page---byline--54a3cb283a91--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--54a3cb283a91--------------------------------)
    ·17 min read·Mar 22, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--54a3cb283a91--------------------------------)
    ·阅读时间17分钟·2024年3月22日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This article is the second in a series about cleaning data using Large Language
    Models (LLMs), with a focus on identifying errors in tabular data sets.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是关于使用大型语言模型（LLM）清理数据系列文章的第二篇，重点介绍在表格数据集中识别错误。
- en: '![](../Images/7ad60ce10b812d10c4d79cec6c7b7cce.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ad60ce10b812d10c4d79cec6c7b7cce.png)'
- en: The sketch outlines the methodology we’ll explore in this article, which focuses
    on evaluating the Data Dirtiness Score of a tabular data set with minimal human
    involvement.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本文概述了我们将要探索的方法论，重点是评估表格数据集的脏污分数，且几乎不需要人工干预。
- en: The Data Dirtiness Score
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据脏污分数
- en: Readers are encouraged to first review the introductory article on the [Data
    Dirtiness Score](https://medium.com/p/fe2ca5678d40), which explains the key assumptions
    and demonstrates how to calculate this score.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励读者首先阅读关于[数据脏污分数](https://medium.com/p/fe2ca5678d40)的介绍性文章，文章解释了关键假设，并演示了如何计算该分数。
- en: 'As a quick refresher, the *Data Dirtiness Score* estimates the expected proportion
    of cells in a data set that contain errors. Here are the key hypotheses behind
    this metric:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 简单回顾一下，*数据脏污分数*估算数据集中包含错误的单元格的预期比例。这个指标背后的主要假设如下：
- en: '**Data errors are related to violated constraints.**'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据错误与违反的约束有关。**'
- en: If there are **no expectations**, there is **no effect on the score**.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果**没有预期**，则**不会影响分数**。
- en: '**Data problems** can be **pinpointed to specific cell**s.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据问题**可以**精确定位到特定单元格**。'
- en: Each **data error** is assigned a **confidence score**.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个**数据错误**都会被分配一个**置信度分数**。
- en: '**Every cell has an equal impact** on the overall score.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每个单元格对整体得分有相同的影响。**'
- en: The initial step in this process involves identifying and cataloguing data inaccuracies
    present within the data set.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程的第一步是识别和分类数据集中的数据不准确性。
- en: The Importance of Detecting Data Quality Issues Automatically
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动检测数据质量问题的重要性
- en: 'Detecting data issues is crucial in the process but challenging due to several
    factors:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 检测数据问题在这个过程中至关重要，但由于多个因素，通常具有挑战性：
- en: '**High Human Labelling Cost**: Identifying data errors often needs significant
    input from data professionals (like scientists, engineers, and analysts) or subject
    matter experts (SMEs). This requires a lot of time and is expensive.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高人工标注成本**：识别数据错误通常需要大量来自数据专业人员（如科学家、工程师和分析师）或主题专家（SME）的投入。这需要大量时间且成本昂贵。'
- en: '**Lack of Enthusiasm Among Data Practitioners for this Grunt Wor**k: It’s no
    secret that many in the field view data cleaning as a less appealing aspect of
    their work. Seen as a precursor to more engaging activities such as modelling,
    building modern data stacks or answering business queries, data cleaning often
    falls lower on the priority list, leading to procrastination or, in some cases,
    completely ignored until critical issues arise.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据从业者对这项繁琐工作的热情缺乏**：数据清洗被许多业内人士视为工作中不太吸引人的部分，这并不是什么秘密。数据清洗通常被视为比建模、构建现代数据架构或回答业务查询等更具吸引力活动的前奏，因此它常常排在优先级较低的位置，导致拖延，甚至在某些情况下，直到出现重大问题才被完全忽视。'
- en: '**SME Limitations**: SMEs have valuable knowledge but might lack technical
    skills like SQL or programming. While no-code and low-code tools help to some
    extent, they haven’t been fully adopted and might not cover all data management
    aspects, such as version control.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域专家的局限性**：领域专家（SMEs）拥有宝贵的知识，但可能缺乏像SQL或编程这样的技术技能。虽然无代码和低代码工具在某种程度上有所帮助，但它们尚未被完全采用，且可能无法覆盖所有数据管理方面，比如版本控制。'
- en: '**The Expertise Gap**: Effective data cleaning transcends basic skill sets,
    requiring specialised expertise. The lack of training and the general disinterest
    in data preparation mean that many practitioners may only identify superficial
    errors, missing more complex issues that require a deeper understanding of data
    cleaning.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专业知识差距**：有效的数据清洗超越了基本技能，要求具备专门的专业知识。缺乏培训和数据准备方面的普遍冷漠意味着许多从业者只能识别表面错误，忽视了需要更深层次理解的数据清洗中更复杂的问题。'
- en: Despite the inherent challenges, advancements in the field of Large Language
    Models (LLMs) offer promising solutions for automating the identification of straightforward
    data issues and uncovering more intricate data quality problems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在固有的挑战，**大语言模型（LLM）**领域的进展为自动识别简单数据问题并揭示更复杂的数据质量问题提供了有前景的解决方案。
- en: Data Error Detection powered by LLMs
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大语言模型驱动的数据错误检测
- en: 'Large language models are becoming invaluable tools in automating the detection
    of data quality issues, serving as an efficient starting point for a productive
    human-in-the-loop iterative process. Models, such as those discussed in papers
    like [Jellyfish: A Large Language Model for Data Preprocessing](https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10),
    [Can language models automate data wrangling?](http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf)
    and [Large Language Models as Data Preprocessors](https://arxiv.org/abs/2308.16361),
    demonstrate their potential to automate constraint generation and data error detection.
    This automation doesn’t replace human intervention but rather enhances it, allowing
    for the review and adjustment of automated constraints by either addressing issues
    directly or modifying confidence scores to reflect the uncertainty inherent in
    data error detection.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '大语言模型正成为自动化检测数据质量问题的宝贵工具，作为高效的起点，推动富有成效的人机协作迭代过程。诸如[Jellyfish: A Large Language
    Model for Data Preprocessing](https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10)、[Can
    language models automate data wrangling?](http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf)
    和[Large Language Models as Data Preprocessors](https://arxiv.org/abs/2308.16361)等论文中讨论的模型，展示了它们在自动化约束生成和数据错误检测方面的潜力。这种自动化并不取代人工干预，而是增强了它，使得人们可以审查和调整自动化约束，通过直接处理问题或调整置信度分数来反映数据错误检测中的不确定性。'
- en: LLMs are particularly well-suited for detecting data quality issues due to their
    extensive training on a diverse range of internet content, including a vast array
    of domain knowledge and numerous examples of code reviews related to data quality
    issues. This training enables LLMs to identify data errors based on textual content
    without the need for explicitly defined rules. By converting tabular data sets
    into plain text (called *serialisation*), LLMs can scrutinise data much like a
    team of experienced humans, leveraging their “compressed” internet knowledge to
    pinpoint errors. This extensive training allows them to identify potential errors
    in human-readable data sets, such as CSV files, with a level of intuition that
    mimics human expertise. Moreover, any gaps in domain-specific knowledge can be
    bridged through techniques like Retrieval-Augmented Generation (RAG) or by tailoring
    the model’s prompts to the specific nature of the data set.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（大语言模型）特别适用于检测数据质量问题，因为它们在多样化的互联网内容上进行了广泛的训练，涵盖了大量领域知识和与数据质量问题相关的代码审查示例。这种训练使得LLM能够基于文本内容识别数据错误，而无需显式定义规则。通过将表格数据集转换为纯文本（称为*序列化*），LLM能够像一支经验丰富的团队一样仔细审查数据，利用其“压缩”的互联网知识来定位错误。这种广泛的训练使得它们能够以类似人类专家的直觉水平，识别出CSV文件等人类可读数据集中的潜在错误。此外，任何领域特定知识的空白都可以通过检索增强生成（RAG）等技术，或者通过根据数据集的特定性质调整模型的提示来弥补。
- en: Another key advantage of employing LLMs in data error detection is their ability
    to handle the inherent uncertainty associated with data quality issues. Not all
    errors are straightforward, and even experts can sometimes disagree on what constitutes
    a data issue. LLMs can assign confidence scores to their findings, like a human
    does based on a mix of intuition and experience, reflecting the estimated likelihood
    of an error.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据错误检测中使用LLM的另一个关键优势是它们能够处理与数据质量问题相关的固有不确定性。并非所有错误都是直观的，甚至专家有时也会对什么构成数据问题产生分歧。LLM能够像人类一样，根据直觉和经验的结合，为其发现的错误分配置信度分数，从而反映错误发生的可能性。
- en: The challenge of generalising error detection across diverse data sets and potential
    issues is considerable. Traditional methods often resort to an extensive set of
    decision rules or a combination of specialised machine learning models to address
    various scenarios, such as checking the validity of addresses and phone numbers
    or anomaly detection. This is where LLMs shine, offering a more adaptable and
    less labour-intensive alternative. Their ability to understand and identify a
    wide range of data quality issues without extensive rule-based systems or domain-specific
    models makes them an invaluable tool. The analogy with the advantages of Machine
    Learning approaches over traditional business rules or statistical methods is
    quite intriguing. The adoption of machine learning has been driven by its relative
    ease of use and adaptability across different use cases, requiring less domain-specific
    knowledge and time to implement.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同数据集和潜在问题中推广错误检测的挑战相当巨大。传统方法通常依赖一套广泛的决策规则或结合专门的机器学习模型来处理各种场景，比如检查地址和电话号码的有效性或进行异常检测。这正是LLM的优势所在，它们提供了一种更具适应性且劳动强度更低的替代方案。LLM能够理解并识别各种数据质量问题，而无需庞大的基于规则的系统或领域特定的模型，这使得它们成为一种无价的工具。与传统商业规则或统计方法相比，机器学习方法的优势相当引人注目。机器学习的采用是由于其相对易用性和在不同用例中的适应性，不需要过多的领域特定知识，也无需花费大量时间进行实施。
- en: Next, we will demonstrate this approach through a practical example.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过一个实际示例演示这种方法。
- en: A Case Study
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个案例研究
- en: 'In the previous article, we explored the concept of the [Data Dirtiness Score](https://medium.com/p/fe2ca5678d40)
    using a data set example from the book [Cleaning Data for Effective Data Science](https://github.com/PacktPublishing/Cleaning-Data-for-Effective-Data-Science).
    The data set in question is as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一篇文章中，我们通过使用来自《[Cleaning Data for Effective Data Science](https://github.com/PacktPublishing/Cleaning-Data-for-Effective-Data-Science)》一书的数据集示例，探讨了[数据脏污评分](https://medium.com/p/fe2ca5678d40)的概念。相关的数据集如下：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Data errors were already pointed out. Now, we want to explore how we can use
    a Large Language Model, specifically `GPT-4`, to automatically find these errors.
    This new method offers a modern way to spot issues in data sets but comes with
    possible risks such as privacy concerns when using external APIs. However, this
    can work with any LLMs, not just `GPT-4`, although the effectiveness might vary
    depending on the model's capabilities.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据错误已经被指出。现在，我们想探索如何使用大型语言模型，特别是`GPT-4`，自动发现这些错误。这种新方法提供了一种现代化的方式来发现数据集中的问题，但也带来了可能的风险，如使用外部API时的隐私问题。然而，这种方法不仅适用于`GPT-4`，还可以与任何LLM配合使用，尽管效果可能会因模型的能力而有所不同。
- en: 'Preliminary Step: Retrieve Table Annotation'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初步步骤：检索表格注释
- en: To assist the model in identifying data inconsistencies, it’s beneficial to
    provide additional context about the data frame. This is precisely the role of
    a [data catalog](https://www.datagalaxy.com/en/blog/what-is-a-data-catalog/),
    which, although a broad topic, we will simplify to focus solely on the essential
    context information that a LLM requires to detect data errors when examining batches
    of data set rows.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助模型识别数据不一致性，提供有关数据框的额外上下文信息是很有帮助的。这正是[data catalog](https://www.datagalaxy.com/en/blog/what-is-a-data-catalog/)（数据目录）的作用，尽管这个话题非常广泛，我们将简化为仅关注LLM在检查数据集行批次时识别数据错误所需的基本上下文信息。
- en: 'The key metadata needed includes:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的关键元数据包括：
- en: An overview of the **table**, including its **description and purpose**.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对**表格**的概述，包括其**描述和用途**。
- en: A clear **understanding** of each **column’s meaning and type**.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对每个**列的含义和类型**有清晰的**理解**。
- en: 'Given the frequent absence of data catalogs or reliable documentation in organisations,
    we’ll explore how to use LLMs to speed up this process. This process is known
    as *Table Annotation*, which involves identifying semantic information about table
    elements, including columns, their relationships, and the entities within the
    cells. For further details, refer to sources such as [Column Type Annotation using
    ChatGPT](https://arxiv.org/abs/2306.00745), [Annotating Columns with Pre-trained
    Language Models](https://paperswithcode.com/paper/annotating-columns-with-pre-trained-language),
    or [SOTAB: The WDC Schema.org Table Annotation Benchmark](https://paperswithcode.com/paper/sotab-the-wdc-schema-org-table-annotation).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于在组织中常常缺乏数据目录或可靠的文档，我们将探讨如何使用LLM加速这一过程。这个过程被称为*表格注释*，它涉及识别表格元素的语义信息，包括列、列之间的关系以及单元格中的实体。欲了解更多详细信息，请参考以下资源：[使用ChatGPT进行列类型注释](https://arxiv.org/abs/2306.00745)、[使用预训练语言模型进行列注释](https://paperswithcode.com/paper/annotating-columns-with-pre-trained-language)或[SOTAB：WDC
    Schema.org表格注释基准](https://paperswithcode.com/paper/sotab-the-wdc-schema-org-table-annotation)。
- en: 'Here’s the prompt I use:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我使用的提示：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the prompt instructions, I direct the model to analyse the provided table
    (or an overview of the table) and to suggest annotations following the [Schema.org](https://schema.org/)
    standards. Specifically, the output should include:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示指令中，我要求模型分析提供的表格（或表格概述），并建议按照[Schema.org](https://schema.org/)标准进行注释。具体来说，输出应包括：
- en: The **table’s semantic type**
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**表格的语义类型**'
- en: A brief **description** of each **column**
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个**列**的简要**描述**
- en: The **column’s annotation type** from Schema.org, where applicable
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自Schema.org的**列注释类型**，如适用
- en: The ideal or best-suited **data types for each column**, regardless of data
    issues in the provided text serialisation
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每列的理想或最佳匹配的**数据类型**，无论提供的文本序列化中是否存在数据问题
- en: 'The response is then formatted to provide a clear and structured summary that
    can be reused as context in subsequent prompts:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，响应会被格式化为提供清晰和结构化的摘要，可以作为后续提示中的上下文重用：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The table is incorporated using a `{table}` placeholder in the prompt. The
    typical method involves converting tabular data into text through serialisation,
    as discussed in [Large Language Models(LLMs) on Tabular Data: Prediction, Generation,
    and Understanding -- A Survey](https://arxiv.org/abs/2402.17944?utm_campaign=Data_Elixir&utm_source=Data_Elixir_475).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表格通过`{table}`占位符插入提示中。典型的方法是通过序列化将表格数据转换为文本，如在[大型语言模型（LLMs）在表格数据上的应用：预测、生成和理解——综述](https://arxiv.org/abs/2402.17944?utm_campaign=Data_Elixir&utm_source=Data_Elixir_475)中所讨论的那样。
- en: 'Here is a sample response from `GPT-4`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`GPT-4`的示例响应：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Responses may vary slightly but are generally consistent for such a straightforward
    example. The aim here is to accelerate the initial process rather than fully automate
    it. Thus, this can be seen as a preliminary draft, which can then be refined with
    insights from our knowledge and external context from subject matter experts (SMEs).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 回复可能会略有不同，但对于这样一个简单的示例通常是一致的。这里的目的是加速初步过程，而不是完全自动化。因此，这可以视为一个初步草稿，之后可以根据我们知识的见解和来自领域专家（SMEs）的外部上下文进行完善。
- en: Now, with some context about the table, let’s explore how to automatically identify
    data quality issues.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，了解了一些表格的上下文后，让我们探讨如何自动识别数据质量问题。
- en: Sniffing Data Errors with LLMs
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLMs检测数据错误
- en: To start, I suggest a prompt that will help identify data quality issues in
    a given table.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我建议使用一个提示，帮助识别给定表格中的数据质量问题。
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The initial part of the prompt sets the task’s objective and lists examples
    of common data issues, such as ingestion errors, duplicates, and privacy concerns,
    among others. **This list is not exhaustive, and you’re encouraged to add more
    relevant types based on your table’s context to guide the analysis.**
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的初始部分设置了任务目标，并列出了常见的数据问题示例，如数据摄取错误、重复数据和隐私问题等。**此列表并不详尽，鼓励您根据表格的上下文添加更多相关类型，以指导分析。**
- en: Next, the prompt details step-by-step instructions following a [Chain-of-Thoughts](https://learnprompting.org/docs/intermediate/chain_of_thought)
    approach, ensuring the model methodically analyses the table and its metadata
    before identifying data issues line by line, mirroring human analysis. This process
    is meant to be conducted without coding, to maintain simplicity and broad applicability.
    This is crucial because, although models like `GPT-4` with analytics capabilities
    can perform useful iterative coding sessions, relying solely on textual analysis
    promotes generalisation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，提示详细说明了逐步指令，采用[Chain-of-Thoughts](https://learnprompting.org/docs/intermediate/chain_of_thought)方法，确保模型有条不紊地分析表格及其元数据，在逐行识别数据问题时模拟人工分析。这个过程应在没有编码的情况下进行，以保持简洁性和广泛适用性。这个步骤非常重要，因为尽管像`GPT-4`这样的模型具有分析能力，可以进行有用的迭代编码会话，但仅依赖于文本分析有助于推广通用性。
- en: 'Upon detecting a potential data issue, the prompt instructs documenting the
    following details:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测到潜在的数据问题时，提示会指导记录以下详细信息：
- en: The **nature and description of the issue**
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题的性质和描述**'
- en: The **expected correct state**
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**期望的正确状态**'
- en: The **violated constraint**
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**违反的约束**'
- en: 'A **confidence level** in the assessment using ordinal categories: `low`, `medium`,
    `high` and `certain`.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用序数类别的**置信度等级**进行评估：`low`（低）、`medium`（中）、`high`（高）和`certain`（确定）。
- en: The **specific location of the issue** in the table, using ‘None’ for table-wide
    issues, with Index and Column names for reference.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据问题的**具体位置**，如果是全表问题，则使用‘None’，并附上索引和列名以供参考。
- en: The table and its metadata are provided within the prompt, with an index added
    to each row to aid the model in pinpointing the exact locations of errors.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 提示中提供了表格及其元数据，并为每一行添加了索引，帮助模型精确定位错误位置。
- en: '*For large tables, this prompt can be applied in batches to cover the entire
    data set, with findings aggregated to identify all data quality issues.*'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*对于大规模表格，可以分批应用此提示以涵盖整个数据集，并将结果汇总以识别所有数据质量问题。*'
- en: Here is an example of the output this prompt can generate, formatted as a report
    detailing identified data issues, each with a description, expected state, violated
    constraint, confidence level, and location.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是该提示生成的输出示例，格式为报告，详细列出了已识别的数据问题，每个问题包括描述、期望状态、违反的约束、置信度等级和位置。
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The next step is converting these identified issues into a Python object for
    easier calculation of the *Data Dirtiness Score*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将这些识别出的问题转换为Python对象，以便更容易计算*数据脏度评分*。
- en: Converting Identified Data Issues into the Correct Format
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将识别的数据问题转换为正确格式
- en: 'This section focuses on transforming the previously identified data issues
    from plain text descriptions into Python objects. These objects should adhere
    to the structure defined by the `DataIssue` class:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本节重点讲解如何将先前识别的数据问题从简单文本描述转换为Python对象。这些对象应遵循`DataIssue`类定义的结构：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here is the prompt I use:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我使用的提示：
- en: '[PRE7]python'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE7]python'
- en: from dataclasses import dataclass
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: from dataclasses import dataclass
- en: from typing import List, Tuple
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: from typing import List, Tuple
- en: '@dataclass'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '@dataclass'
- en: 'class DataIssue:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 'class DataIssue:'
- en: 'type_of_issue: str'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'type_of_issue: str'
- en: 'expectation: str'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'expectation: str'
- en: 'constraint_violated: str'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'constraint_violated: str'
- en: 'confidence_score: str # `low`, `medium`, `high` or `certain`'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'confidence_score: str # `低`，`中`，`高` 或 `确定`'
- en: 'location: List[Tuple]  # Cell positions as (Index, Column). Use None for row/column-wide
    issues.'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'location: List[Tuple]  # 单元格位置以（索引，列）表示。使用 None 表示整行或整列的问题。'
- en: 'Instructions:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 'Instructions:'
- en: 1\. Review all identified issues provided and their descriptions silently.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 静默检查所有识别出的问题及其描述。
- en: 2\. For each issue, instantiate it using the provided `DataIssue` class structure.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 对于每个问题，使用提供的`DataIssue`类结构实例化它。
- en: 3\. Return only the code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 仅返回代码。
- en: 4\. Once the code has been validated, stop generation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 一旦代码验证完成，停止生成。
- en: 'Identified issues:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 识别的问题：
- en: '{issues_found}'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '{issues_found}'
- en: 'Your code here:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 'Your code here:'
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: issue1 = DataIssue(
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: issue1 = DataIssue(
- en: type_of_issue="Incorrect value format",
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: type_of_issue="格式不正确",
- en: expectation="Each cell under 'Favorite Color' should contain only one color",
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: expectation="‘喜欢的颜色’列下的每个单元格应只包含一个颜色",
- en: constraint_violated="Single value constraint",
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: constraint_violated="单值约束",
- en: confidence_score="high",
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: confidence_score="高",
- en: location=[(1, "Favorite Color")]
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: location=[(1, "喜欢的颜色")]
- en: )
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: issue2 = DataIssue(
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: issue2 = DataIssue(
- en: type_of_issue="Missing value",
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: type_of_issue="缺失值"
- en: expectation="No missing values in any columns",
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: expectation="任何列中都不应有缺失值",
- en: constraint_violated="Non-null constraint",
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: constraint_violated="非空约束",
- en: confidence_score="certain",
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: confidence_score="确定",
- en: location=[(2, "Favorite Color"), (5, "Last Name"), (5, "Favorite Color")]
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: location=[(2, "喜欢的颜色"), (5, "姓氏"), (5, "喜欢的颜色")]
- en: )
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: issue3 = DataIssue(
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: issue3 = DataIssue(
- en: type_of_issue="Negative value",
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: type_of_issue="负值",
- en: expectation="Age values should be positive integers",
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: expectation="年龄值应为正整数",
- en: constraint_violated="Age value range (greater than 0)",
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: constraint_violated="年龄值范围（大于 0）",
- en: confidence_score="certain",
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: confidence_score="确定",
- en: location=[(3, "Age")]
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: location=[(3, "年龄")]
- en: )
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: issue4 = DataIssue(
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: issue4 = DataIssue(
- en: type_of_issue="Misplaced values",
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: type_of_issue="值错位",
- en: expectation="Age should be a reasonable positive integer, and favorite color
    should be a string denoting a color",
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: expectation="年龄应该是一个合理的正整数，喜欢的颜色应该是表示颜色的字符串",
- en: constraint_violated="Data type and value range constraint",
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: constraint_violated="数据类型和数值范围约束",
- en: confidence_score="high",
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: confidence_score="高",
- en: location=[(4, "Favorite Color"), (4, "Age")]
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: location=[(4, "喜欢的颜色"), (4, "年龄")]
- en: )
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: issue5 = DataIssue(
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: issue5 = DataIssue(
- en: type_of_issue="Inconsistent formatting",
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: type_of_issue="格式不一致",
- en: expectation="Each row should consistently follow the format defined by the column
    headers without extra delimiters",
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: expectation="每一行应该始终遵循由列标题定义的格式，且不应有额外的分隔符",
- en: constraint_violated="Data format and consistency constraint",
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: constraint_violated="数据格式和一致性约束",
- en: confidence_score="high",
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: confidence_score="高",
- en: 'location=[(5, None)]  # None indicates entire row issue'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'location=[(5, None)]  # None 表示整个行的问题'
- en: )
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: compute_data_dirtiness_score(data_issues)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: compute_data_dirtiness_score(data_issues)
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Student#  Last Name  First Name  Favorite Color   Age
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 学生编号  姓氏  名字  喜欢的颜色  年龄
- en: 0      0.00        0.0        0.00            0.00  0.00
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 0      0.00        0.0        0.00            0.00  0.00
- en: 1      0.00        0.0        0.00            0.75  0.00
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 1      0.00        0.0        0.00            0.75  0.00
- en: 2      0.00        0.0        0.00            1.00  0.00
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 2      0.00        0.0        0.00            1.00  0.00
- en: 3      0.00        0.0        0.00            0.00  1.00
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 3      0.00        0.0        0.00            0.00  1.00
- en: 4      0.00        0.0        0.00            0.75  0.75
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 4      0.00        0.0        0.00            0.75  0.75
- en: 5      0.75        1.0        0.75            1.00  0.75
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 5      0.75        1.0        0.75            1.00  0.75
- en: '[PRE11]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Student#  Last Name  First Name  Favorite Color   Age
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 学生编号  姓氏  名字  喜欢的颜色  年龄
- en: 0       0.0        0.0        0.00          0.0000  0.00
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 0       0.0        0.0        0.00          0.0000  0.00
- en: 1       0.0        0.0        0.00          0.7500  0.00
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 1       0.0        0.0        0.00          0.7500  0.00
- en: 2       0.0        0.0        0.00          1.0000  0.00
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 2       0.0        0.0        0.00          1.0000  0.00
- en: 3       0.0        0.0        0.00          0.0000  1.00
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 3       0.0        0.0        0.00          0.0000  1.00
- en: 4       0.0        0.0        0.25          0.8125  0.75
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 4       0.0        0.0        0.25          0.8125  0.75
- en: 5       1.0        1.0        1.00          1.0000  1.00
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 5       1.0        1.0        1.00          1.0000  1.00
- en: '[PRE12]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: create_mask_from_list_of_cell_positions(
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: create_mask_from_list_of_cell_positions(
- en: shape=dataset_shape,
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: shape=dataset_shape,
- en: list_of_cell_positions=[(4, 'Favorite Color'), (4, 'Age')],
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: list_of_cell_positions=[(4, '喜欢的颜色'), (4, '年龄')],
- en: columns=columns
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: columns=columns
- en: )
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE13]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: array([[0, 0, 0, 0, 0],
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: array([[0, 0, 0, 0, 0],
- en: '[0, 0, 0, 0, 0],'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[0, 0, 0, 0, 0],'
- en: '[0, 0, 0, 0, 0],'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[0, 0, 0, 0, 0],'
- en: '[0, 0, 0, 0, 0],'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[0, 0, 0, 0, 0],'
- en: '[0, 0, 0, 1, 1],'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[0, 0, 0, 1, 1],'
- en: '[0, 0, 0, 0, 0]], dtype=int8)'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[0, 0, 0, 0, 0]], dtype=int8)'
- en: '[PRE14]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: def validate_cell_position(
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: def validate_cell_position(
- en: 'cell_position: Union['
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'cell_position: Union['
- en: Tuple[int, int], Tuple[None, int], Tuple[int, None], Tuple[None, None]
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: Tuple[int, int], Tuple[None, int], Tuple[int, None], Tuple[None, None]
- en: '],'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '],'
- en: 'columns: List[str] = None,'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'columns: List[str] = None,'
- en: ') -> Tuple[int, int]:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ') -> Tuple[int, int]:'
- en: '"""'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: Validate the cell position and convert column names to indices if necessary.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 验证单元格位置并在必要时将列名转换为索引。
- en: '"""'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: 'if not isinstance(cell_position, tuple):'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if not isinstance(cell_position, tuple):'
- en: raise ValueError("Cell position must be a tuple")
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise ValueError("单元格位置必须是元组")
- en: Convert column name to index if columns are provided
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如果提供了列名，则将列名转换为索引
- en: 'if isinstance(cell_position[1], str):'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if isinstance(cell_position[1], str):'
- en: 'if columns is None:'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if columns is None:'
- en: raise ValueError(
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise ValueError(
- en: '"Column names must be provided to create a mask based on column names"'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"必须提供列名，以便根据列名创建掩码"'
- en: )
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: )
- en: column_index = columns.index(cell_position[1])
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: column_index = columns.index(cell_position[1])
- en: return (cell_position[0], column_index)
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: return (cell_position[0], column_index)
- en: return cell_position
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return cell_position
- en: 'def set_mask_values(mask: np.ndarray, cell_position: Tuple[int, int]):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 'def set_mask_values(mask: np.ndarray, cell_position: Tuple[int, int]):'
- en: '"""'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: Set values in the mask based on the cell position.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据单元格位置设置掩码中的值。
- en: '"""'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: row_index, col_index = cell_position
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: row_index, col_index = cell_position
- en: 'if row_index is None:'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if row_index is None:'
- en: mask[:, col_index] = 1
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: mask[:, col_index] = 1
- en: 'elif col_index is None:'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'elif col_index is None:'
- en: mask[row_index, :] = 1
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: mask[row_index, :] = 1
- en: 'else:'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'else:'
- en: mask[row_index, col_index] = 1
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: mask[row_index, col_index] = 1
- en: def create_mask_from_list_of_cell_positions(
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: def create_mask_from_list_of_cell_positions(
- en: 'shape: Tuple[int, int],'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'shape: Tuple[int, int],'
- en: 'list_of_cell_positions: List[Tuple],'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'list_of_cell_positions: List[Tuple],'
- en: 'columns: List[str] = None,'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'columns: List[str] = None,'
- en: ') -> np.ndarray:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ') -> np.ndarray:'
- en: '"""'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: Create a mask array based on a list of cell positions.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据单元格位置列表创建掩码数组。
- en: '"""'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: mask = np.zeros(shape=shape, dtype=np.int8)
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: mask = np.zeros(shape=shape, dtype=np.int8)
- en: 'for cell_position in list_of_cell_positions:'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'for cell_position in list_of_cell_positions:'
- en: validated_position = validate_cell_position(cell_position, columns)
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: validated_position = validate_cell_position(cell_position, columns)
- en: set_mask_values(mask, validated_position)
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: set_mask_values(mask, validated_position)
- en: return mask
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return mask
- en: '```'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '```'
