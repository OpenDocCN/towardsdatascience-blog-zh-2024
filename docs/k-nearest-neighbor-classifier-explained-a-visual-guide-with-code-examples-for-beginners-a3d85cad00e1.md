# K æœ€è¿‘é‚»åˆ†ç±»å™¨è§£æï¼šåˆå­¦è€…çš„å¯è§†åŒ–æŒ‡å—ä¸ä»£ç ç¤ºä¾‹

> åŸæ–‡ï¼š[`towardsdatascience.com/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=collection_archive---------2-----------------------#2024-08-20`](https://towardsdatascience.com/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=collection_archive---------2-----------------------#2024-08-20)

## åˆ†ç±»ç®—æ³•

## æœºå™¨å­¦ä¹ ä¸­çš„å‹å¥½é‚»å±…æ–¹æ³•

[](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)![Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------) [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--a3d85cad00e1--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a3d85cad00e1--------------------------------) Â·é˜…è¯»æ—¶é—´ï¼š8 åˆ†é’ŸÂ·2024 å¹´ 8 æœˆ 20 æ—¥

--

![](img/31276134251efc679092597eaa9db567.png)

`â›³ï¸ æ›´å¤šåˆ†ç±»ç®—æ³•è§£æï¼šÂ· è™šæ‹Ÿåˆ†ç±»å™¨ â–¶ K æœ€è¿‘é‚»åˆ†ç±»å™¨ Â· ä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯ Â· é«˜æ–¯æœ´ç´ è´å¶æ–¯ Â· å†³ç­–æ ‘åˆ†ç±»å™¨ Â· é€»è¾‘å›å½’ Â· æ”¯æŒå‘é‡åˆ†ç±»å™¨ Â· å¤šå±‚æ„ŸçŸ¥æœº`

æƒ³è±¡ä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡æŸ¥çœ‹ä¹‹å‰è§è¿‡çš„æœ€ç›¸ä¼¼çš„ä¾‹å­æ¥åšå‡ºé¢„æµ‹ã€‚è¿™å°±æ˜¯æœ€è¿‘é‚»åˆ†ç±»å™¨çš„æœ¬è´¨â€”â€”ä¸€ä¸ªç®€å•è€Œç›´è§‚çš„ç®—æ³•ï¼Œå®ƒä¸ºæœºå™¨å­¦ä¹ å¸¦æ¥äº†ä¸€ä¸ç°å®ä¸–ç•Œçš„é€»è¾‘ã€‚

è™½ç„¶ [è™šæ‹Ÿåˆ†ç±»å™¨](https://medium.com/towards-data-science/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)è®¾å®šäº†æœ€ä½çš„æ€§èƒ½æ ‡å‡†ï¼Œä½†æœ€è¿‘é‚»æ–¹æ³•æ¨¡ä»¿äº†æˆ‘ä»¬åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­åšå†³ç­–çš„æ–¹å¼ï¼šé€šè¿‡å›å¿†ç±»ä¼¼çš„è¿‡å»ç»å†ã€‚è¿™å°±åƒæ˜¯é—®ä½ çš„é‚»å±…ä»Šå¤©æ ¹æ®å¤©æ°”å¦‚ä½•ç©¿è¡£ï¼Œä»è€Œå†³å®šä½ åº”è¯¥ç©¿ä»€ä¹ˆã€‚åœ¨æ•°æ®ç§‘å­¦é¢†åŸŸï¼Œè¿™ä¸ªåˆ†ç±»å™¨é€šè¿‡æ£€æŸ¥æœ€æ¥è¿‘çš„æ•°æ®ç‚¹æ¥åšå‡ºé¢„æµ‹ã€‚

![](img/b075e06729583b9a5f90a9ee64a83e9d.png)

æ‰€æœ‰è§†è§‰å…ƒç´ ï¼šä½œè€…ä½¿ç”¨ Canva Pro åˆ›å»ºã€‚å·²ä¼˜åŒ–ä¸ºé€‚åˆç§»åŠ¨è®¾å¤‡ï¼›åœ¨æ¡Œé¢ä¸Šå¯èƒ½ä¼šæ˜¾å¾—è¿‡å¤§ã€‚

# å®šä¹‰

K æœ€è¿‘é‚»åˆ†ç±»å™¨æ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå®ƒæ ¹æ®ç‰¹å¾ç©ºé—´ä¸­ K ä¸ªæœ€è¿‘æ•°æ®ç‚¹çš„å¤šæ•°ç±»åˆ«æ¥åšå‡ºé¢„æµ‹ã€‚KNN ç®—æ³•å‡è®¾ç›¸ä¼¼çš„äº‹ç‰©ä¼šå­˜åœ¨äºè¿‘è·ç¦»å†…ï¼Œè¿™ä½¿å¾—å®ƒç›´è§‚ä¸”æ˜“äºç†è§£ã€‚

![](img/9ac3c976bc1cc4b51aa375372d697de8.png)

æœ€è¿‘é‚»æ–¹æ³•æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€ç®€å•çš„ç®—æ³•ä¹‹ä¸€ã€‚

# ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªç®€å•çš„äººå·¥é«˜å°”å¤«æ•°æ®é›†ï¼ˆçµæ„Ÿæ¥è‡ª [1]ï¼‰ä½œä¸ºä¾‹å­ã€‚è¿™ä¸ªæ•°æ®é›†é¢„æµ‹ä¸€ä¸ªäººæ˜¯å¦ä¼šæ ¹æ®å¤©æ°”æ¡ä»¶æ‰“é«˜å°”å¤«ã€‚å®ƒåŒ…æ‹¬å¤©æ°”ã€æ¸©åº¦ã€æ¹¿åº¦å’Œé£ç­‰ç‰¹å¾ï¼Œç›®æ ‡å˜é‡æ˜¯æ˜¯å¦æ‰“é«˜å°”å¤«ã€‚

![](img/e0709936f67841828da150d4160270fd.png)

åˆ—ï¼šâ€˜Outlookâ€™ï¼ˆå¤©æ°”ï¼‰ã€â€˜Temperatureâ€™ï¼ˆæ¸©åº¦ï¼‰ã€â€˜Humidityâ€™ï¼ˆæ¹¿åº¦ï¼‰ã€â€˜Windâ€™ï¼ˆé£ï¼‰å’Œâ€˜Playâ€™ï¼ˆç›®æ ‡ç‰¹å¾ï¼‰

```py
# Import libraries
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pandas as pd
import numpy as np

# Make the dataset
dataset_dict = {
    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy', 'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast', 'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],
    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],
    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],
    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],
    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']
}
original_df = pd.DataFrame(dataset_dict)

print(original_df)
```

KNN ç®—æ³•è¦æ±‚é¦–å…ˆå¯¹æ•°æ®è¿›è¡Œç¼©æ”¾ã€‚[å°†ç±»åˆ«åˆ—è½¬æ¢](https://encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)ä¸º 0 å’Œ 1ï¼Œå¹¶ä¸” [ç¼©æ”¾æ•°å€¼ç‰¹å¾](https://scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)ï¼Œä»¥ç¡®ä¿æ²¡æœ‰å•ä¸ªç‰¹å¾ä¸»å¯¼è·ç¦»åº¦é‡ã€‚

![](img/2e13dc4bed27647caca187226dffff37.png)

ç±»åˆ«åˆ—ï¼ˆå¤©æ°”å’Œé£ï¼‰ä½¿ç”¨ç‹¬çƒ­ç¼–ç è¿›è¡Œç¼–ç ï¼Œè€Œæ•°å€¼åˆ—åˆ™ä½¿ç”¨æ ‡å‡†åŒ–ç¼©æ”¾ï¼ˆz æ ‡å‡†åŒ–ï¼‰ã€‚æ­¤è¿‡ç¨‹åˆ†åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šè¿›è¡Œã€‚

```py
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Preprocess data
df = pd.get_dummies(original_df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)
df['Wind'] = df['Wind'].astype(int)
df['Play'] = (df['Play'] == 'Yes').astype(int)
df = df[['sunny','rainy','overcast','Temperature','Humidity','Wind','Play']]

# Split data and standardize features
X, y = df.drop(columns='Play'), df['Play']
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)

scaler = StandardScaler()
float_cols = X_train.select_dtypes(include=['float64']).columns
X_train[float_cols] = scaler.fit_transform(X_train[float_cols])
X_test[float_cols] = scaler.transform(X_test[float_cols])

# Print results
print(pd.concat([X_train, y_train], axis=1).round(2), '\n')
print(pd.concat([X_test, y_test], axis=1).round(2), '\n')
```

# ä¸»è¦æœºåˆ¶

KNN åˆ†ç±»å™¨é€šè¿‡æ‰¾åˆ°ç¦»æ–°æ•°æ®ç‚¹æœ€è¿‘çš„ K ä¸ªé‚»å±…ï¼Œç„¶åå¯¹è¿™äº›é‚»å±…ä¸­æœ€å¸¸è§çš„ç±»åˆ«è¿›è¡ŒæŠ•ç¥¨æ¥è¿›è¡Œå·¥ä½œã€‚ä»¥ä¸‹æ˜¯å…¶å·¥ä½œåŸç†ï¼š

1.  è®¡ç®—æ–°æ•°æ®ç‚¹ä¸è®­ç»ƒé›†ä¸­çš„æ‰€æœ‰ç‚¹ä¹‹é—´çš„è·ç¦»ã€‚

1.  æ ¹æ®è¿™äº›è·ç¦»é€‰æ‹© K ä¸ªæœ€è¿‘çš„é‚»å±…ã€‚

1.  å¯¹è¿™ K ä¸ªé‚»å±…çš„ç±»åˆ«è¿›è¡Œå¤šæ•°æŠ•ç¥¨ã€‚

1.  å°†å¤šæ•°ç±»åˆ«åˆ†é…ç»™æ–°æ•°æ®ç‚¹ã€‚

![](img/72b63fbec5470322fed4ac538be8259b.png)

å¯¹äºæˆ‘ä»¬çš„é«˜å°”å¤«æ•°æ®é›†ï¼ŒKNN åˆ†ç±»å™¨å¯èƒ½ä¼šæŸ¥çœ‹è¿‡å» 5 ä¸ªæœ€ç›¸ä¼¼çš„å¤©æ°”æ¡ä»¶ï¼Œä»¥é¢„æµ‹æŸäººä»Šå¤©æ˜¯å¦ä¼šæ‰“é«˜å°”å¤«ã€‚

# è®­ç»ƒæ­¥éª¤

ä¸è®¸å¤šå…¶ä»–ç®—æ³•ä¸åŒï¼ŒKNN æ²¡æœ‰æ˜ç¡®çš„è®­ç»ƒé˜¶æ®µã€‚ç›¸åï¼Œå®ƒè®°ä½æ•´ä¸ªè®­ç»ƒæ•°æ®é›†ã€‚ä»¥ä¸‹æ˜¯å…¶è¿‡ç¨‹ï¼š

1.  é€‰æ‹©ä¸€ä¸ª K å€¼ï¼ˆè¦è€ƒè™‘çš„é‚»å±…æ•°é‡ï¼‰ã€‚

![](img/7bc23cbaf9d209db5e3ecfcb5ecf63f3.png)

åœ¨ 2D è®¾ç½®ä¸­ï¼Œå°±åƒæ˜¯æ‰¾å‡ºæœ€æ¥è¿‘çš„é¢œè‰²çš„å¤šæ•°ã€‚

```py
from sklearn.neighbors import KNeighborsClassifier

# Select the Number of Neighbors ('k')
k = 5
```

2\. é€‰æ‹©ä¸€ä¸ªè·ç¦»åº¦é‡ï¼ˆä¾‹å¦‚ï¼Œæ¬§å‡ é‡Œå¾—è·ç¦»ã€æ›¼å“ˆé¡¿è·ç¦»ï¼‰ã€‚

![](img/d2a1cd84b7e89aeac60d229ee175f395.png)

æœ€å¸¸è§çš„è·ç¦»åº¦é‡æ˜¯æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚è¿™å°±åƒæ˜¯æ‰¾å‡ºä¸¤ä¸ªç‚¹ä¹‹é—´çš„ç›´çº¿è·ç¦»ã€‚

```py
import numpy as np

# Choose a Distance Metric
distance_metric = 'euclidean'

# Trying to calculate distance between ID 0 and ID 1
print(np.linalg.norm(X_train.loc[0].values - X_train.loc[1].values))
```

3\. å­˜å‚¨/è®°ä½æ‰€æœ‰è®­ç»ƒæ•°æ®ç‚¹åŠå…¶å¯¹åº”çš„æ ‡ç­¾ã€‚

```py
# Initialize the k-NN Classifier
knn_clf = KNeighborsClassifier(n_neighbors=k, metric=distance_metric)

# "Train" the kNN (although no real training happens)
knn_clf.fit(X_train, y_train)
```

# åˆ†ç±»æ­¥éª¤

ä¸€æ—¦æœ€è¿‘é‚»åˆ†ç±»å™¨è¢«â€œè®­ç»ƒâ€ï¼ˆå³è®­ç»ƒæ•°æ®å·²å­˜å‚¨ï¼‰ï¼Œå®ƒå°†å¦‚ä½•ä¸ºæ–°å®ä¾‹åšå‡ºé¢„æµ‹ï¼š

1.  **è·ç¦»è®¡ç®—**ï¼šå¯¹äºæ–°çš„å®ä¾‹ï¼Œä½¿ç”¨é€‰æ‹©çš„è·ç¦»åº¦é‡è®¡ç®—å…¶ä¸æ‰€æœ‰å­˜å‚¨çš„è®­ç»ƒå®ä¾‹ä¹‹é—´çš„è·ç¦»ã€‚

![](img/0fe732ea0723d899d9d69b95fabffd38.png)

å¯¹äº ID 14ï¼Œæˆ‘ä»¬è®¡ç®—å…¶ä¸è®­ç»ƒé›†æ¯ä¸ªæˆå‘˜ï¼ˆID 0 â€” ID 13ï¼‰ä¹‹é—´çš„è·ç¦»ã€‚

```py
from scipy.spatial import distance

# Compute the distances from the first row of X_test to all rows in X_train
distances = distance.cdist(X_test.iloc[0:1], X_train, metric='euclidean')

# Create a DataFrame to display the distances
distance_df = pd.DataFrame({
    'Train_ID': X_train.index,
    'Distance': distances[0].round(2),
    'Label': y_train
}).set_index('Train_ID')

print(distance_df.sort_values(by='Distance'))
```

2\. **é‚»å±…é€‰æ‹©ä¸é¢„æµ‹**ï¼šåŸºäºè®¡ç®—çš„è·ç¦»ï¼Œè¯†åˆ« K ä¸ªæœ€è¿‘çš„é‚»å±…ï¼Œç„¶åå°†è¿™äº›é‚»å±…ä¸­æœ€å¸¸è§çš„ç±»ä½œä¸ºæ–°å®ä¾‹çš„é¢„æµ‹ç±»ã€‚

![](img/544c2bf36d8672ed8b43a4cb302c1946.png)

åœ¨è®¡ç®—äº†å®ƒä¸æ‰€æœ‰å­˜å‚¨æ•°æ®ç‚¹çš„è·ç¦»ï¼Œå¹¶æŒ‰ä»ä½åˆ°é«˜æ’åºåï¼Œæˆ‘ä»¬è¯†åˆ«å‡º 5 ä¸ªæœ€è¿‘çš„é‚»å±…ï¼ˆå‰ 5ï¼‰ã€‚å¦‚æœè¿™äº›é‚»å±…ä¸­å¤§å¤šæ•°ï¼ˆ3 ä¸ªæˆ–æ›´å¤šï¼‰æ ‡è®°ä¸ºâ€œNOâ€ï¼Œæˆ‘ä»¬ä¸º ID 14 é¢„æµ‹â€œNOâ€ã€‚

```py
# Use the k-NN Classifier to make predictions
y_pred = knn_clf.predict(X_test)
print("Label     :",list(y_test))
print("Prediction:",list(y_pred))
```

# è¯„ä¼°æ­¥éª¤

![](img/0b41962fcacac9d33decd7f1a5c31a3a.png)

é€šè¿‡è¿™ä¸ªç®€å•çš„æ¨¡å‹ï¼Œæˆ‘ä»¬èƒ½è·å¾—è¶³å¤Ÿå¥½çš„å‡†ç¡®æ€§ï¼Œè¿œè¿œä¼˜äº[éšæœºçŒœæµ‹](https://medium.com/towards-data-science/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)!

```py
from sklearn.metrics import accuracy_score

# Evaluation Phase
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy.round(4)*100}%')
```

# å…³é”®å‚æ•°

è™½ç„¶ KNN åœ¨æ¦‚å¿µä¸Šç®€å•ï¼Œä½†å®ƒç¡®å®æœ‰ä¸€äº›é‡è¦çš„å‚æ•°ï¼š

1.  **K**ï¼šè¦è€ƒè™‘çš„é‚»å±…æ•°é‡ã€‚è¾ƒå°çš„ K å€¼å¯èƒ½å¯¼è‡´å¯¹å™ªå£°æ•æ„Ÿçš„ç»“æœï¼Œè€Œè¾ƒå¤§çš„ K å€¼å¯èƒ½ä¼šå¹³æ»‘å†³ç­–è¾¹ç•Œã€‚

![](img/f6a1c3b887adfb52913295c5fc34fc61.png)

k å€¼è¶Šå¤§ï¼Œè¶Šæœ‰å¯èƒ½é€‰æ‹©å¤§å¤šæ•°ç±»ï¼ˆâ€œYESâ€ï¼‰ã€‚

```py
labels, predictions, accuracies = list(y_test), [], []

k_list = [3, 5, 7]
for k in k_list:
    knn_clf = KNeighborsClassifier(n_neighbors=k)
    knn_clf.fit(X_train, y_train)
    y_pred = knn_clf.predict(X_test)
    predictions.append(list(y_pred))
    accuracies.append(accuracy_score(y_test, y_pred).round(4)*100)

df_predictions = pd.DataFrame({'Label': labels})
for k, pred in zip(k_list, predictions):
    df_predictions[f'k = {k}'] = pred

df_accuracies = pd.DataFrame({'Accuracy ': accuracies}, index=[f'k = {k}' for k in k_list]).T

print(df_predictions)
print(df_accuracies)
```

2\. **è·ç¦»åº¦é‡**ï¼šè¿™å†³å®šäº†ç‚¹ä¸ç‚¹ä¹‹é—´ç›¸ä¼¼åº¦çš„è®¡ç®—æ–¹å¼ã€‚å¸¸è§é€‰é¡¹åŒ…æ‹¬ï¼š

+   æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆç›´çº¿è·ç¦»ï¼‰

+   æ›¼å“ˆé¡¿è·ç¦»ï¼ˆç»å¯¹å·®å€¼ä¹‹å’Œï¼‰

+   é—µå¯å¤«æ–¯åŸºè·ç¦»ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»å’Œæ›¼å“ˆé¡¿è·ç¦»çš„æ³›åŒ–ï¼‰

3\. **æƒé‡å‡½æ•°**ï¼šè¿™å†³å®šäº†å¦‚ä½•å¯¹æ¯ä¸ªé‚»å±…çš„è´¡çŒ®è¿›è¡ŒåŠ æƒã€‚é€‰é¡¹åŒ…æ‹¬ï¼š

+   â€˜uniformâ€™ï¼šæ‰€æœ‰é‚»å±…çš„æƒé‡ç›¸ç­‰ã€‚

+   â€˜distanceâ€™ï¼šè¾ƒè¿‘çš„é‚»å±…æ¯”è¾ƒè¿œçš„é‚»å±…å¯¹ç»“æœæœ‰æ›´å¤§çš„å½±å“ã€‚

# ä¼˜ç¼ºç‚¹

å°±åƒæœºå™¨å­¦ä¹ ä¸­çš„ä»»ä½•ç®—æ³•ä¸€æ ·ï¼ŒKNN ä¹Ÿæœ‰å…¶ä¼˜ç‚¹å’Œå±€é™æ€§ã€‚

## ä¼˜ç‚¹ï¼š

1.  **ç®€æ´æ€§**ï¼šå®¹æ˜“ç†è§£å’Œå®ç°ã€‚

1.  **æ— å‡è®¾**ï¼šä¸å¯¹æ•°æ®åˆ†å¸ƒåšä»»ä½•å‡è®¾ã€‚

1.  **å¤šåŠŸèƒ½æ€§**ï¼šå¯ä»¥ç”¨äºåˆ†ç±»å’Œå›å½’ä»»åŠ¡ã€‚

1.  **æ— éœ€è®­ç»ƒé˜¶æ®µ**ï¼šå¯ä»¥å¿«é€Ÿæ•´åˆæ–°æ•°æ®ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

## ç¼ºç‚¹ï¼š

1.  **è®¡ç®—å¼€é”€å¤§**ï¼šæ¯æ¬¡é¢„æµ‹æ—¶éœ€è¦è®¡ç®—æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„è·ç¦»ã€‚

1.  **å†…å­˜å¯†é›†å‹**ï¼šéœ€è¦å­˜å‚¨æ‰€æœ‰è®­ç»ƒæ•°æ®ã€‚

1.  **å¯¹æ— å…³ç‰¹å¾æ•æ„Ÿ**ï¼šå¯èƒ½ä¼šå—åˆ°ä¸åˆ†ç±»æ— å…³çš„ç‰¹å¾çš„å¹²æ‰°ã€‚

1.  **ç»´åº¦ç¾éš¾**ï¼šåœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæ€§èƒ½ä¼šä¸‹é™ã€‚

# æœ€åå¤‡æ³¨

K æœ€è¿‘é‚»ï¼ˆKNNï¼‰åˆ†ç±»å™¨ä½œä¸ºæœºå™¨å­¦ä¹ ä¸­çš„åŸºç¡€ç®—æ³•ï¼Œå› å…¶ç›´è§‚ä¸”é«˜æ•ˆçš„åˆ†ç±»æ–¹æ³•è€Œè„±é¢–è€Œå‡ºã€‚å…¶ç®€å•æ€§ä½¿å…¶æˆä¸ºåˆå­¦è€…çš„ç†æƒ³èµ·ç‚¹ï¼Œè€Œå…¶å¤šåŠŸèƒ½æ€§ç¡®ä¿äº†å¯¹ç»éªŒä¸°å¯Œçš„æ•°æ®ç§‘å­¦å®¶çš„ä»·å€¼ã€‚KNN çš„å¼ºå¤§ä¹‹å¤„åœ¨äºï¼Œå®ƒèƒ½å¤Ÿæ ¹æ®æ•°æ®ç‚¹çš„æ¥è¿‘åº¦è¿›è¡Œé¢„æµ‹ï¼Œæ— éœ€å¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ã€‚

ç„¶è€Œï¼Œå¿…é¡»è®°ä½ï¼ŒKNN åªæ˜¯åºå¤§æœºå™¨å­¦ä¹ å·¥å…·ç®±ä¸­çš„ä¸€ä¸ªå·¥å…·ã€‚åœ¨æ•°æ®ç§‘å­¦æ—…ç¨‹ä¸­å‰è¿›æ—¶ï¼Œå¯ä»¥å°† KNN ä½œä¸ºç†è§£æ›´å¤æ‚ç®—æ³•çš„å«è„šçŸ³ï¼Œåœ¨é€‰æ‹©æ¨¡å‹æ—¶å§‹ç»ˆè€ƒè™‘ä½ çš„æ•°æ®ç‰¹æ€§å’Œé—®é¢˜éœ€æ±‚ã€‚é€šè¿‡æŒæ¡ KNNï¼Œä½ å°†è·å¾—å¯¹åˆ†ç±»æŠ€æœ¯çš„å®è´µè§è§£ï¼Œä¸ºåº”å¯¹æ›´å¤æ‚çš„æœºå™¨å­¦ä¹ æŒ‘æˆ˜å¥ å®šåšå®çš„åŸºç¡€ã€‚

# ğŸŒŸ k æœ€è¿‘é‚»åˆ†ç±»å™¨ä»£ç æ€»ç»“

```py
# Import libraries
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Load data
dataset_dict = {
    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy', 'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast', 'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],
    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],
    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],
    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],
    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']
}
df = pd.DataFrame(dataset_dict)

# Preprocess data
df = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)
df['Wind'] = df['Wind'].astype(int)
df['Play'] = (df['Play'] == 'Yes').astype(int)

# Split data
X, y = df.drop(columns='Play'), df['Play']
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)

# Standardize features
scaler = StandardScaler()
float_cols = X_train.select_dtypes(include=['float64']).columns
X_train[float_cols] = scaler.fit_transform(X_train[float_cols])
X_test[float_cols] = scaler.transform(X_test[float_cols])

# Train model
knn_clf = KNeighborsClassifier(n_neighbors=3, metric='euclidean')
knn_clf.fit(X_train, y_train)

# Predict and evaluate
y_pred = knn_clf.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
```

## è¿›ä¸€æ­¥é˜…è¯»

è‹¥æƒ³è¯¦ç»†äº†è§£ [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) åŠå…¶åœ¨ scikit-learn ä¸­çš„å®ç°ï¼Œè¯»è€…å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ [2]ï¼Œè¯¥æ–‡æ¡£æä¾›äº†å…³äºå…¶ç”¨æ³•å’Œå‚æ•°çš„è¯¦ç»†ä¿¡æ¯ã€‚

## æŠ€æœ¯ç¯å¢ƒ

æœ¬æ–‡ä½¿ç”¨ Python 3.7 å’Œ scikit-learn 1.5ã€‚è™½ç„¶æ‰€è®¨è®ºçš„æ¦‚å¿µé€šå¸¸é€‚ç”¨ï¼Œä½†ä¸åŒç‰ˆæœ¬ä¹‹é—´çš„å…·ä½“ä»£ç å®ç°å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚

## æ’å›¾è¯´æ˜

é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…åˆ›ä½œï¼Œèåˆäº† Canva Pro çš„æˆæƒè®¾è®¡å…ƒç´ ã€‚

![](img/ec10b257f55a9fa724d5f1978f5b3572.png)

å¦‚éœ€ç®€æ˜çš„ K æœ€è¿‘é‚»è§†è§‰æ€»ç»“ï¼Œè¯·æŸ¥çœ‹ [é…å¥— Instagram å¸–å­ã€‚](https://www.instagram.com/p/C-ssgsAyFSI)

## å‚è€ƒæ–‡çŒ®

[1] T. M. Mitchell, [æœºå™¨å­¦ä¹ ](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)ï¼ˆ1997ï¼‰ï¼Œéº¦æ ¼åŠ³-å¸Œå°”ç§‘å­¦/å·¥ç¨‹/æ•°å­¦ï¼Œ ç¬¬ 59 é¡µ

ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ˜¾ğ™¡ğ™–ğ™¨ğ™¨ğ™ğ™›ğ™ğ™˜ğ™–ğ™©ğ™ğ™¤ğ™£ ğ˜¼ğ™¡ğ™œğ™¤ğ™§ğ™ğ™©ğ™ğ™¢ğ™¨ ğ™ğ™šğ™§ğ™š:

![Samy Baladram](img/835013c69e08fec04ad9ca465c2adf6c.png)

[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)

## åˆ†ç±»ç®—æ³•

[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----a3d85cad00e1--------------------------------)8 ä¸ªæ•…äº‹![](img/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](img/6ea70d9d2d9456e0c221388dbb253be8.png)![](img/7221f0777228e7bcf08c1adb44a8eb76.png)

ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:

![Samy Baladram](img/835013c69e08fec04ad9ca465c2adf6c.png)

[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)

## å›å½’ç®—æ³•

[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----a3d85cad00e1--------------------------------)5 ä¸ªæ•…äº‹![ä¸€ä¸ªå¸¦ç€è¾«å­å’Œç²‰è‰²å¸½å­çš„å¡é€šç©å¶ã€‚è¿™ä¸ªâ€œå‡äººâ€ç©å¶ï¼Œé€šè¿‡å…¶ç®€å•çš„è®¾è®¡å’Œå¿ƒå½¢è£…é¥°çš„è¡£æœï¼Œå½¢è±¡åœ°ä»£è¡¨äº†æœºå™¨å­¦ä¹ ä¸­å‡å›å½’å™¨çš„æ¦‚å¿µã€‚å°±åƒè¿™ä¸ªç©å…·èˆ¬çš„å½¢è±¡æ˜¯å¯¹äººçš„ç®€åŒ–é™æ€è¡¨ç°ï¼Œå‡å›å½’å™¨åˆ™æ˜¯ä½œä¸ºåŸºå‡†æ¨¡å‹ï¼Œä¾›æ›´å¤æ‚çš„åˆ†æä½¿ç”¨ã€‚](img/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](img/44e6d84e61c895757ff31e27943ee597.png)![](img/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy Baladram](img/835013c69e08fec04ad9ca465c2adf6c.png)

[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----a3d85cad00e1--------------------------------)

## é›†æˆå­¦ä¹ 

[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----a3d85cad00e1--------------------------------)4 ä¸ªæ•…äº‹![](img/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](img/22a5d43568e70222eb89fd36789a9333.png)![](img/8ea1a2f29053080a5feffc709f5b8669.png)
