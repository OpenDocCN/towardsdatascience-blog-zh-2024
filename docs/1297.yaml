- en: 6 Real-World Uses of Microsoft’s Newest Phi-3 Vision-Language Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=collection_archive---------0-----------------------#2024-05-24](https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=collection_archive---------0-----------------------#2024-05-24)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploring possible use cases of Phi-3-Vision, a small yet powerful MLLM that
    can be run locally (with code examples)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)
    ·7 min read·May 24, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b74137bffcdef5766be32f53b015f9fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [RoonZ nl](https://unsplash.com/@roonz_nl?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft recently released Phi-3, a powerful language model, with a new Vision-Language
    variant called Phi-3-vision-128k-instruct. This 4B parameter model achieved impressive
    results on public benchmarks, even surpassing GPT-4V in some cases and outperforming
    Gemini 1.0 Pro V in all but MMMU.
  prefs: []
  type: TYPE_NORMAL
- en: 'This blog post will explore how you can utilize Phi-3-vision-128k-instruct
    as a robust vision and text model in your data science toolkit. We’ll demonstrate
    its capabilities through various use cases, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Optical Character Recognition (OCR)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image Captioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table Parsing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure Understanding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading Comprehension on Scanned Documents
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set-of-Mark Prompting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll begin by providing a simple code snippet to run this model locally using
    transformers and bitsandbytes. Then, we’ll showcase an example for each of the
    use cases listed above.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the model locally:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
