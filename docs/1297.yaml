- en: 6 Real-World Uses of Microsoft’s Newest Phi-3 Vision-Language Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微软最新Phi-3视觉语言模型的6种实际应用
- en: 原文：[https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=collection_archive---------0-----------------------#2024-05-24](https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=collection_archive---------0-----------------------#2024-05-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=collection_archive---------0-----------------------#2024-05-24](https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=collection_archive---------0-----------------------#2024-05-24)
- en: Exploring possible use cases of Phi-3-Vision, a small yet powerful MLLM that
    can be run locally (with code examples)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索Phi-3-Vision的可能应用场景，这是一款小巧却强大的MLLM，可以在本地运行（附带代码示例）
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--8ebbfa317fe8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)
    ·7 min read·May 24, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8ebbfa317fe8--------------------------------)
    ·阅读时间7分钟·2024年5月24日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b74137bffcdef5766be32f53b015f9fa.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b74137bffcdef5766be32f53b015f9fa.png)'
- en: Photo by [RoonZ nl](https://unsplash.com/@roonz_nl?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[RoonZ nl](https://unsplash.com/@roonz_nl?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Microsoft recently released Phi-3, a powerful language model, with a new Vision-Language
    variant called Phi-3-vision-128k-instruct. This 4B parameter model achieved impressive
    results on public benchmarks, even surpassing GPT-4V in some cases and outperforming
    Gemini 1.0 Pro V in all but MMMU.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 微软最近发布了Phi-3，一款强大的语言模型，并推出了一种新的视觉-语言变体——Phi-3-vision-128k-instruct。这款拥有40亿参数的模型在公开基准测试中取得了令人印象深刻的成绩，在某些情况下甚至超越了GPT-4V，并且在除了MMMU之外的所有领域都优于Gemini
    1.0 Pro V。
- en: 'This blog post will explore how you can utilize Phi-3-vision-128k-instruct
    as a robust vision and text model in your data science toolkit. We’ll demonstrate
    its capabilities through various use cases, including:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将探讨如何将Phi-3-vision-128k-instruct作为您数据科学工具包中的强大视觉和文本模型。我们将通过各种应用场景展示其能力，包括：
- en: Optical Character Recognition (OCR)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光学字符识别（OCR）
- en: Image Captioning
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像描述
- en: Table Parsing
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表格解析
- en: Figure Understanding
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像理解
- en: Reading Comprehension on Scanned Documents
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扫描文档的阅读理解
- en: Set-of-Mark Prompting
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集合标记提示
- en: We’ll begin by providing a simple code snippet to run this model locally using
    transformers and bitsandbytes. Then, we’ll showcase an example for each of the
    use cases listed above.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先提供一个简单的代码片段，用于通过transformers和bitsandbytes在本地运行该模型。然后，我们将展示上述每个应用场景的示例。
- en: 'Running the model locally:'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在本地运行模型：
