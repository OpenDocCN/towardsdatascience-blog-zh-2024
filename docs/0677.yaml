- en: An Intuitive View on Mutual Information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/an-intuitive-view-on-mutual-information-db0655535f84?source=collection_archive---------6-----------------------#2024-03-13](https://towardsdatascience.com/an-intuitive-view-on-mutual-information-db0655535f84?source=collection_archive---------6-----------------------#2024-03-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Layman’s guide to appreciating the concept of association
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@markchangg?source=post_page---byline--db0655535f84--------------------------------)[![Mark
    Chang](../Images/149afb7a61e175743da6c36f05bc6318.png)](https://medium.com/@markchangg?source=post_page---byline--db0655535f84--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--db0655535f84--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--db0655535f84--------------------------------)
    [Mark Chang](https://medium.com/@markchangg?source=post_page---byline--db0655535f84--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--db0655535f84--------------------------------)
    ·8 min read·Mar 13, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/119a293dadb7e3a97d7b8666de767d74.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ben White](https://unsplash.com/@benwhitephotography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Recently I’ve been working on a project that aims to screen **pairs of variables**
    in the stock market, and **see how they show enough correlation potential** for
    us to deep-dive and research further.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout my research, I’ve chanced upon many different methodologies; from
    the humble Spearman’s/Pearson linear correlation, to the more advanced non-linear
    methods using Time-Delay Embeddings and even Machine Learning techniques.
  prefs: []
  type: TYPE_NORMAL
- en: And that was when I chanced upon this robust and probabilistic concept known
    as **Mutual Information** that helps one to measure the level of association/dependence
    between two variables. This serves as a good Step 0 tool for model development
    or associative studies.
  prefs: []
  type: TYPE_NORMAL
- en: Scouring the web to understand further, I’ve realized that while there were
    excellent mathematical and statistical explanations, **there weren’t many traces
    of intuitive insights on how and why Mutual Information works**.
  prefs: []
  type: TYPE_NORMAL
- en: And therefore, here we are,
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to my attempt at helping you break down and appreciate this statistical
    concept!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**The Textbook Definition**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mutual Information is a measure of how much “information” you can get of one
    variable by observing another variable
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I’m sure you’ve seen the above statement, or variants of it, throughout your
    own research. But what exactly is this “information” that they are talking about?
    How does it tell me that two variables are associated/dependent?
  prefs: []
  type: TYPE_NORMAL
- en: 'The definition becomes even more daunting when you look at the formulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/78bbaebed9d998ae8de882ead9c34c67.png)'
  prefs: []
  type: TYPE_IMG
- en: Formula for Mutual Information for Discrete Observations
  prefs: []
  type: TYPE_NORMAL
- en: Fret not! Let’s get into breaking down this concept into digestible chunks using
    a case study.
  prefs: []
  type: TYPE_NORMAL
- en: “Do people really use umbrellas only when it rains?”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/23262ac9ac78fbd879c736b941f5b590.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [zhang dayong](https://unsplash.com/@dayongzhang?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: said Bob, your drunk friend during a night out of festivities.
  prefs: []
  type: TYPE_NORMAL
- en: He insists that people carry umbrella only when they feel like it, and not because
    they need it to shelter them from the rain.
  prefs: []
  type: TYPE_NORMAL
- en: You think that that statement is ludicrous! It challenged every observation
    you made growing up; every notion of logic within your bones.
  prefs: []
  type: TYPE_NORMAL
- en: You decided to stalk Bob and observe him over the next 5 days during his vacation
    in tropical Singapore. You want to see if he really walks the talk and lives true
    to his bodacious claims.
  prefs: []
  type: TYPE_NORMAL
- en: You decide to do so using the concept of **Mutual Information**.
  prefs: []
  type: TYPE_NORMAL
- en: Bob vs Mutual Information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can break down the Mutual Information formula into the following parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The *x, X* and *y, Y***'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*x* and *y* are the individual observations/values that we see in our data.
    *X* and *Y* are just the set of these individual values. A good example would
    be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a4f6e7a5ead25c261663a5081fbb6a6f.png)'
  prefs: []
  type: TYPE_IMG
- en: Discrete/Binary observation of umbrella-wielding and weather
  prefs: []
  type: TYPE_NORMAL
- en: 'And assuming we have 5 days of observations of Bob in this exact sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a5f8f1a57846c491c3a4f19ac00c51ad.png)'
  prefs: []
  type: TYPE_IMG
- en: Discrete/Binary observation of umbrella-wielding and weather over 5 days
  prefs: []
  type: TYPE_NORMAL
- en: '**Individual/Marginal Probability**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/383c1c8c07fb4779e277865282fe9c24.png)'
  prefs: []
  type: TYPE_IMG
- en: These are just the simple probability of observing a particular *x* or *y* in
    their respective sets of possible *X* and *Y* values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take *x = 1* as an example: the probability is simply *0.4* (Bob carried an
    umbrella 2 out of 5 days of his vacation).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Joint Probability**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/cc6114a1cdc620ee8e98e97fbdbe1177.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the probability of observing a particular *x* and *y* from the joint
    probability of (*X, Y)*. The joint probability (*X, Y)* is simply just the set
    of paired observations. We pair them up according to their index.
  prefs: []
  type: TYPE_NORMAL
- en: In our case with Bob, we pair the observations up based on which day they occurred.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a881e1dbacfa805bf74e041ddc5a140b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You may be tempted to jump to a conclusion after looking at the pairs:'
  prefs: []
  type: TYPE_NORMAL
- en: Since there are equal-value pairs occurring 80% of the time, it clearly means
    that people carry umbrellas BECAUSE it is raining!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Well I’m here to play the devil’s advocate and say that that may just be a
    freakish coincidence:'
  prefs: []
  type: TYPE_NORMAL
- en: If the chance of rain is very low in Singapore, and, independently, the likelihood
    of Bob carrying umbrella is also equally low (because he hates holding extra stuff),
    can you see that the odds of having *(0,0)* paired observations will be very high
    **naturally**?
  prefs: []
  type: TYPE_NORMAL
- en: So what can we do to prove that these paired observations are not by coincidence?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Joint Versus Individual Probabilities**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/5be386e3384c40df59a7e23635daadee.png)'
  prefs: []
  type: TYPE_IMG
- en: We can take the ratio of both probabilities to give us a clue on the **“extent
    of coincidence”**.
  prefs: []
  type: TYPE_NORMAL
- en: In the denominator, we take the product of both individual probabilities of
    a particular *x* and particular *y* occurring. Why did we do so?
  prefs: []
  type: TYPE_NORMAL
- en: '**Peering into the humble coin toss**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall the first lesson you took in statistics class: calculating the probability
    of getting 2 heads in 2 tosses of a fair coin.'
  prefs: []
  type: TYPE_NORMAL
- en: '1st Toss [ *p(x*) ]: There’s a 50% chance of getting heads'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2nd Toss [ *p(y*) ]: There’s still a 50% chance of getting heads, since the
    outcome is **independent** of what happened in the 1st toss'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The above 2 tosses make up your individual probabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, the **theoretical** probability of getting both heads in 2 independent
    tosses is *0.5* * 0.5 *= 0.25* ( [*p(x).p(y)*](#0073))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/8499b8db31a00ac5b3cb3b6f52277fbd.png)'
  prefs: []
  type: TYPE_IMG
- en: And if you actually do maybe 100 sets of that double-coin-toss experiment, you’ll
    likely see that you get the *(heads, heads)* result 25% of the time. The 100 sets
    of experiment is actually your [(*X, Y)* joint probability set](#807d)!
  prefs: []
  type: TYPE_NORMAL
- en: Hence, when you take the ratio of joint versus combined-individual probabilities,
    you get a value of *1.*
  prefs: []
  type: TYPE_NORMAL
- en: 'This is actually the real **expectation for independent events**: the joint
    probability of a specific pair of values occurring is exactly equal to the product
    of their individual probabilities! Just like what you were taught in fundamental
    statistics.'
  prefs: []
  type: TYPE_NORMAL
- en: Now imagine that your 100-set experiment yielded *(heads, heads)* 90% of the
    time. **Surely that can’t be a coincidence…**
  prefs: []
  type: TYPE_NORMAL
- en: You expected 25% since you know that they are independent events, yet what was
    observed is an extreme skew of this expectation.
  prefs: []
  type: TYPE_NORMAL
- en: To put this qualitative feeling into numbers, the ratio of probabilities is
    now a whopping *3.6 (0.9 / 0.25)*, essentially 3.6x more frequent than we expected.
  prefs: []
  type: TYPE_NORMAL
- en: As such, we start to think that **maybe the coin tosses were** **not independent.**
    Maybe the result of the 1st toss might actually have some unexplained effect on
    the 2nd toss. **Maybe** **there is some level of association/dependence between
    1st and 2nd toss**.
  prefs: []
  type: TYPE_NORMAL
- en: That is what **Mutual Information tries to tells** us!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Expected Value of Observations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/25e9be68a91424b51e5245c580c56a0e.png)'
  prefs: []
  type: TYPE_IMG
- en: For us to be fair to Bob, we should not just look at the times where his claims
    are wrong, i.e. calculate the ratio of probabilities of *(0,0)* and *(1,1)*.
  prefs: []
  type: TYPE_NORMAL
- en: We should also calculate the ratio of probabilities for when his claims are
    correct, i.e. *(0,1)* and *(1,0).*
  prefs: []
  type: TYPE_NORMAL
- en: 'Thereafter, we can **aggregate all 4 scenarios** in an expected value method,
    which just means “taking the average”: aggregate up all ratio of probabilities
    for each observed pair in (*X, Y)*, then divide it by the number of observations.'
  prefs: []
  type: TYPE_NORMAL
- en: That is the purpose of these two summation terms. For continuous variables like
    my stock market example, we will then use integrals instead.
  prefs: []
  type: TYPE_NORMAL
- en: Logarithm of Ratios
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/a273e4b9b4ea16ede7fbcbbd37c09dbd.png)'
  prefs: []
  type: TYPE_IMG
- en: Similar to how we calculate the probability of getting 2 consecutive heads for
    the coin toss, we are also now calculating the additional probability of seeing
    the 5 pairs that we observed.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the coin toss, we calculate by **multiplying** the probabilities of each
    toss. For Bob, it’s the same: the **probabilities have multiplicative effect**
    on each other to give us the sequence that we observed in the joint set.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With logarithms, we **turn multiplicative effects into additive** ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e40d4d458dde7c2f139bf9b2e10df7b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Converting the ratio of probabilities to their logarithmic variants, we can
    now simply just calculate the expected value as [described above](#776f) using
    **summation of their logarithms**.
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to use log-base 2, *e*, or 10, it does not matter for the purposes
    of this article.
  prefs: []
  type: TYPE_NORMAL
- en: Putting It All Together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/78bbaebed9d998ae8de882ead9c34c67.png)'
  prefs: []
  type: TYPE_IMG
- en: Formula for Mutual Information for Discrete Observations
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now prove Bob wrong by calculating the Mutual Information. I will use
    log-base *e* (natural logarithm) for my calculations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c07fbe0d1451d05fa071d7d2555cf854.png)'
  prefs: []
  type: TYPE_IMG
- en: So what does the value of ***0.223***tell us?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first assume Bob is right, and that the use of umbrellas are **independent**
    from presence of rain:'
  prefs: []
  type: TYPE_NORMAL
- en: We know that the joint probability will exactly equal the product of the individual
    probabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, for every *x* and *y* permutation, the ratio of probabilities *=
    1*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking the logarithm, that equates to 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus, the expected value of all permutations (i.e. Mutual Information) is therefore
    ***0***.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But since the Mutual Information score that we calculated is **non-zero**, we
    can therefore prove to Bob that he is wrong!
  prefs: []
  type: TYPE_NORMAL
- en: Beyond Linear Correlation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Because Mutual Information is a probabilistic measure of association/dependence,
    it can work for **non-linear correlation** studies as well!
  prefs: []
  type: TYPE_NORMAL
- en: Take for example two variables *X* and *Y:*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70abc9232eefbc36d9c44dcb55bc713f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Calculating their Mutual Information score, Spearman’s correlation score, and
    plotting, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c73cfb29d55e9f31e7b62c88a438361.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Y vs X: Y is a deterministic, non-linear scaling of X'
  prefs: []
  type: TYPE_NORMAL
- en: Relying on Spearman’s correlation alone, we would think that these 2 variables
    have nothing to do with each other, but we know for a fact that they are deterministically
    related (based on my formula above)!
  prefs: []
  type: TYPE_NORMAL
- en: The non-zero Mutual Information score hints us to look deeper, **albeit not
    giving us the explicit form of relation**.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also robust enough to work on strictly linear correlations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f8a77486dbd30f736b568c22677154e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Y vs X: Y is a deterministic, linear translation of X'
  prefs: []
  type: TYPE_NORMAL
- en: So, if you are ever unsure what kind of correlation you are expecting going
    into an X-vs-Y analysis, you can try out Mutual Information as a step zero!
  prefs: []
  type: TYPE_NORMAL
- en: My “Layman” Definition of Mutual Information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/792fe745d9888281b96376019e26e4a4.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Albert](https://unsplash.com/@picturesbyalbert?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: With the [above examples and breakdown](#7bae), I hope I managed to help you
    guys get an intuitive understanding what Mutual Information is and how it works.
  prefs: []
  type: TYPE_NORMAL
- en: 'If it helps you further, I prefer to summarize Mutual Information as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Mutual Information gives us the additional probability of x and y happening
    at the same time due to other factors above just their chance of co-occurring.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Mutual Information is very useful in areas such as Feature Selection before
    building your Machine Learning models, and even text association analyses when
    used with text embeddings. Therefore, it is paramount that we truly know how it
    works before adopting it for its myriad of uses.
  prefs: []
  type: TYPE_NORMAL
- en: With your newfound intuition and understanding, I believe you will be able to
    find other pockets of opportunities to apply this versatile concept as I will
    with my stock market ventures!
  prefs: []
  type: TYPE_NORMAL
