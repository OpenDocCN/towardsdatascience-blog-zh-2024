<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Denoising Radar Satellite Images with Python Has Never Been So Easy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Denoising Radar Satellite Images with Python Has Never Been So Easy</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/denoising-radar-satellite-images-with-python-has-never-been-so-easy-f445241002a5?source=collection_archive---------5-----------------------#2024-04-23">https://towardsdatascience.com/denoising-radar-satellite-images-with-python-has-never-been-so-easy-f445241002a5?source=collection_archive---------5-----------------------#2024-04-23</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="1877" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Presentation of the latest release of deepdespeckling</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@brash6?source=post_page---byline--f445241002a5--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Hadrien Mariaccia" class="l ep by dd de cx" src="../Images/7417df68fbdaaeb0846feea7dbee1966.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*DtTVgX_qKpqHTo5LDaUNrg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f445241002a5--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@brash6?source=post_page---byline--f445241002a5--------------------------------" rel="noopener follow">Hadrien Mariaccia</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f445241002a5--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 23, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/74c66f5f0dd45fc2b38e514fc9da75f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cw0v6NAPh0E-Zx18kGr0yQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Optical and radar image of an agricultural area near Nîmes, France</figcaption></figure><p id="529c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Synthetic aperture radar (SAR) images are widely use in a large variety of sectors (aerospace, military, meteorology, etc.). The problem is this kind of images <strong class="ne fr">suffer from noise</strong> in their raw format. While these images are also usually heavy files, the task of denoising it efficiently appears to be both challenging from a scientific perspective and very useful in the real world.</p><p id="0bac" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this <a class="af ny" rel="noopener" target="_blank" href="/denoising-radar-satellite-images-using-deep-learning-in-python-946daad31022">Towards Data Science article</a>, we presented <a class="af ny" href="https://github.com/hi-paris/deepdespeckling" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">deepdespeckling</strong></a>, an open-source python package enabling to despeckle synthetic aperture radar (SAR) images using a <strong class="ne fr">novel deep learning based method</strong>.</p><p id="cdb6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We are happy to announce that we have released a <strong class="ne fr">new version of</strong> <strong class="ne fr">deepdespeckling,</strong> enabling to use both <a class="af ny" href="https://arxiv.org/pdf/2110.13148.pdf" rel="noopener ugc nofollow" target="_blank">MERLIN</a> and <a class="af ny" href="https://arxiv.org/pdf/2006.15037.pdf" rel="noopener ugc nofollow" target="_blank">SAR2SAR</a> methods for despeckling radar satellite images.</p><h2 id="e15e" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">A quick reminder on satellite images</h2><p id="d833" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk">There are <strong class="ne fr">two</strong> big categories of satellite images :</p><ul class=""><li id="b105" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oz pa pb bk"><strong class="ne fr">Optical images : </strong>the ones we are used to see when we watch a weather forecast for example. These images are taken by optical sensors. <br/>While these images generally provide a high level of detail, they encounter at least <strong class="ne fr">two significant challenges</strong> in capturing Earth’s intricacies: the limitations posed by <strong class="ne fr">nighttime conditions</strong> and <strong class="ne fr">adverse weather</strong>.</li><li id="290f" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><strong class="ne fr">Radar images : </strong>while optical systems rely on the sunlight (the sensor is passive), radars send an electromagnetic wave and measure the component backscattered by the objects on the ground (the sensor is active). radar sensors can acquire data at any time of the day and with any meteorological conditions, as the wavelength of the transmitted wave allows it to penetrate clouds. They however encounter an intrinsic issue : <strong class="ne fr">speckle noise</strong>.</li></ul><h2 id="aade" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">What is speckle noise ?</h2><p id="d2ef" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk"><strong class="ne fr">Speckle</strong> is a granular interference due to bouncing properties of emitted radio waves that degrades the quality of images and therefore their interpretability with a human eye.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ph"><img src="../Images/641150276bb02312e2e20f126a4158c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*-JAAgVmgsk_7IKJ8Ibo1Rg.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of an image respectively without and with speckle noise</figcaption></figure><h2 id="e1f1" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">How to get rid of it</h2><p id="9b0f" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk">Several methods exist, but deep learning has brought significant improvements for this task. <a class="af ny" href="https://emanueledalsasso.github.io/" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">Emanuele Dalsasso</strong></a><strong class="ne fr">, Loïc Denis and Florence Tupin</strong> developed two deep learning based methods for despeckling SAR images :</p><ul class=""><li id="bc9b" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oz pa pb bk"><a class="af ny" href="https://arxiv.org/pdf/2110.13148.pdf" rel="noopener ugc nofollow" target="_blank">MERLIN</a> (coMplex sElf-supeRvised despeckLINg) : a self-supervised strategy based on the separation of the real and imaginary parts of single-look complex SAR images that we presented in the previous <a class="af ny" rel="noopener" target="_blank" href="/denoising-radar-satellite-images-using-deep-learning-in-python-946daad31022">Towards Data Science article</a></li><li id="75a1" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><a class="af ny" href="https://arxiv.org/pdf/2006.15037.pdf" rel="noopener ugc nofollow" target="_blank">SAR2SAR</a> : Multi-temporal time series are leveraged in order to train neural network to restore SAR images by only looking at noisy acquisitions. <strong class="ne fr">This method is part of the new features of the latest release of </strong><a class="af ny" href="https://github.com/hi-paris/deepdespeckling" rel="noopener ugc nofollow" target="_blank"><strong class="ne fr">deepdespeckling</strong></a><strong class="ne fr">. Hence, we will focus on this method in this article</strong></li></ul><h1 id="5f7d" class="pi oa fq bf ob pj pk gq of pl pm gt oj pn po pp pq pr ps pt pu pv pw px py pz bk">SAR2SAR</h1><p id="f907" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk">Just as MERLIN, SAR2SAR also draws inspiration from the noise2noise algorithm, which showed that it is possible to train a model to denoise without looking at noise-free examples. This feature is of particular importance in SAR despeckling, as speckle-free acquisition does not exist.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qa"><img src="../Images/789609d9fa99f86557d1a37a7c1fe09d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*_EmVbI1Em7HDFRB8bmS0RA.png"/></div></figure><p id="1416" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">SAR2SAR builds on the assumption that two images acquired over the same area at different times are corrupted by <strong class="ne fr">two uncorrelated speckle realizations</strong>, matching with the hypothesis allowing the application of the noise2noise principle. This allows to develop a model to remove speckle from Ground Range Detected (GRD) SAR images, which are only available in amplitude (the phase is suppressed during the detection step) and thus MERLIN cannot be used on such data. Temporal acquisitions are leveraged to generate a dataset containing independent speckle realisations of the same scene (a change compensations strategy relying on a pre-trained model is used to ensure that the temporal acquisitions only differ for the speckle component).</p><p id="771e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Once the model is trained, during inference SAR2SAR requires a single GRD image and can be effectively deployed to suppress speckle from Sentinel-1 GRD SAR images.</p><h1 id="3d4b" class="pi oa fq bf ob pj pk gq of pl pm gt oj pn po pp pq pr ps pt pu pv pw px py pz bk">SAR images acquisition</h1><p id="a75d" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk">Different acquisition modes exist depending on the compromise between the illuminated scene (the swath) and and the image resolution. Each acquisition mode thus produces images having a different resolution, thus the appearance of objects is specific to each acquisition mode.</p><p id="544e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For this reason, a model specific for each modality must be developed. Given the simplicity of application of MERLIN, which requires single SAR images, datasets for each specific modality can be seamlessly collected. We have trained MERLIN on the following images:</p><ul class=""><li id="fd17" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oz pa pb bk">TerraSAR-X images acquired in Stripmap mode</li><li id="6aeb" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk">TerraSAR-X images acquired in HighResolution SpotLight mode</li><li id="2e3c" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk">Sentinel-1 images acquired in TOPS mode</li></ul><h1 id="af44" class="pi oa fq bf ob pj pk gq of pl pm gt oj pn po pp pq pr ps pt pu pv pw px py pz bk">deepdespeckling package usage</h1><h2 id="0828" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">Package installation</h2><p id="dd18" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk">Before installing deepdespeckling, make sure to install gdal dependancies, it can be done using conda with the following command :</p><pre class="mm mn mo mp mq qb qc qd bp qe bb bk"><span id="194e" class="qf oa fq qc b bg qg qh l qi qj">conda install -c conda-forge gdal</span></pre><p id="5cce" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then you can install the package this way :</p><pre class="mm mn mo mp mq qb qc qd bp qe bb bk"><span id="0b39" class="qf oa fq qc b bg qg qh l qi qj">pip install deepdespeckling</span></pre><h2 id="e302" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">Despeckle one image with MERLIN</h2><blockquote class="qk ql qm"><p id="7781" class="nc nd qn ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To despeckle SAR images using MERLIN, images need to be in .cos or .npy format.</p></blockquote><p id="7871" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Two parameters have to be set:</p><ul class=""><li id="5a24" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">model_name</code><em class="qn"> : </em><code class="cx qo qp qq qc b">"spotlight"</code> for SAR images retrieved with spotlight mode, <code class="cx qo qp qq qc b">"stripmap"</code> for SAR images retrieved with stripmap mode or <code class="cx qo qp qq qc b">"Sentinel-TOPS"</code> for images retrieved with TOPS mode</li><li id="1913" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">symetrise</code><em class="qn">: d</em>uring the preprocessing steps of the noisy image for MERLIN, the real and the imaginary parts are “<strong class="ne fr">symetrised</strong>” (to match the theoretical assumptions of MERLIN). To skip this step, the <code class="cx qo qp qq qc b">symetrise</code> parameter can be set to <code class="cx qo qp qq qc b">False</code></li></ul><pre class="mm mn mo mp mq qb qc qd bp qe bb bk"><span id="553f" class="qf oa fq qc b bg qg qh l qi qj">from deepdespeckling.utils.load_cosar import cos2mat<br/>from deepdespeckling.utils.constants import PATCH_SIZE, STRIDE_SIZE<br/>from deepdespeckling.merlin.merlin_denoiser import MerlinDenoiser<br/><br/># Path to one image (cos or npy file)<br/>image_path="path/to/cosar/image"<br/># Model name, can be "spotlight", "stripmap" or "Sentinel-TOPS"<br/>model_name = "spotlight"<br/>symetrise = True<br/><br/>image = cos2mat(image_path).astype(np.float32)<br/><br/>denoiser = MerlinDenoiser(model_name=model_name, symetrise=symetrise)<br/>denoised_image = denoiser.denoise_image(image, patch_size=PATCH_SIZE, stride_size=STRIDE_SIZE)</span></pre><p id="8ad4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This snippet of code will store the despeckled image in a <strong class="ne fr">numpy array</strong> in the <code class="cx qo qp qq qc b">denoised_image</code><em class="qn"> </em>variable.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/7aed8495ae99a2995eacd13a728ca195.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*233W6ZZ7JtPSMJTPicNv1w.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of a full size noisy SAR image</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/df6544db6a81595f6124872d8094f2e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5v8kyY2K5tKi9N4CefvyaQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">The same image denoised using MERLIN</figcaption></figure><h2 id="8559" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">Despeckle one image with SAR2SAR</h2><blockquote class="qk ql qm"><p id="985e" class="nc nd qn ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To despeckle SAR images using SAR2SAR, images need to be in .tiff or .npy format.</p></blockquote><pre class="mm mn mo mp mq qb qc qd bp qe bb bk"><span id="8718" class="qf oa fq qc b bg qg qh l qi qj">from deepdespeckling.utils.load_cosar import cos2mat<br/>from deepdespeckling.utils.constants import PATCH_SIZE, STRIDE_SIZE<br/>from deepdespeckling.sar2sar.sar2sar_denoiser import Sar2SarDenoiser<br/><br/># Path to one image (tiff or npy file)<br/>image_path="path/to/cosar/image"<br/><br/># Works exactly the same as with MERLIN<br/>image = cos2mat(image_path).astype(np.float32)<br/><br/># Denoise the image with SAR2SAR<br/>denoiser = Sar2SarDenoiser()<br/>denoised_image = denoiser.denoise_image(image, patch_size=PATCH_SIZE, stride_size=STRIDE_SIZE)</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qs"><img src="../Images/8d34d7f9f6e2bd548031a2f6a4be6fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O6aOJAm306K8g0PNoBcqXA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of result using SAR2SAR (displayed after a conversion to png)</figcaption></figure><h2 id="f5fb" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">Despeckle a set of images using MERLIN or SAR2SAR</h2><p id="32b0" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk">For both MERLIN and SAR2SAR, you can choose between <strong class="ne fr">3 different functions</strong> to despeckle a set of SAR images contained in a folder :</p><ul class=""><li id="1fa1" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">despeckle</code> to despeckle full size images</li><li id="06a0" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">despeckle_from_coordinates</code> to despeckle a sub-part of the images defined by some coordinates</li><li id="429e" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">despeckle_from_crop</code> to despeckle a sub-part of the images defined using a crop tool</li></ul><p id="80d1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Despeckle fullsize images</strong></p><pre class="mm mn mo mp mq qb qc qd bp qe bb bk"><span id="bdae" class="qf oa fq qc b bg qg qh l qi qj">from deepdespeckling.despeckling import despeckle<br/><br/># Path to a folder of several images <br/># images have to be in .tiff or .npy formats if using sar2sar <br/># images have to be in .cos or .npy formats is using merlin ("spotlight", "stripmap" or "Sentinel-TOPS")<br/>image_path="path/to/cosar/image"<br/># Folder where results are stored<br/>destination_directory="path/where/to/save/results"<br/><br/># Can be "sar2sar", "spotlight' or "stripmap"<br/>model_name = "spotlight"<br/># symetrise parameter if using "spotlight", "stripmap" or "Sentinel-TOPS" (harmless if using "sar2sar")<br/>symetrise = True<br/><br/>despeckle(image_path, destination_directory, model_name=model_name, symetrise=symetrise)</span></pre><p id="4fab" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The <code class="cx qo qp qq qc b">despeckle</code> function will create several folders in the <code class="cx qo qp qq qc b">destination_directory</code> :</p><ul class=""><li id="de30" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">processed_images:</code> the <em class="qn">npy</em> files (numpy array conversion) of the raw images stored in the folder defined in <code class="cx qo qp qq qc b">image_path.</code></li><li id="cc87" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">noisy:</code>the preprocessed noisy images in both <em class="qn">.npy</em> and <em class="qn">.png</em> formats</li><li id="bd7f" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">denoised:</code> the denoised images in both <em class="qn">.npy</em> and <em class="qn">.png</em> formats</li></ul><p id="5ceb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Despeckle parts of images using custom coordinates</strong></p><pre class="mm mn mo mp mq qb qc qd bp qe bb bk"><span id="2ecd" class="qf oa fq qc b bg qg qh l qi qj">from deepdespeckling.despeckling import despeckle_from_coordinates<br/><br/># Path to a folder of several images <br/># images have to be in .tiff or .npy formats if using sar2sar <br/># images have to be in .cos or .npy formats is using merlin ("spotlight", "stripmap" or "Sentinel-TOPS")<br/>image_path="path/to/cosar/image"<br/># Folder where results are stored<br/>destination_directory="path/where/to/save/results"<br/># Example of coordinates of the subparts of the images to be despeckled<br/>coordinates_dictionnary = {'x_start':2600,'y_start':1000,'x_end':3000,'y_end':1200}<br/><br/># Can be "sar2sar", "spotlight", "stripmap" or "Sentinel-TOPS"<br/>model_name = "spotlight"<br/># symetrise parameter if using "spotlight", "stripmap" or "Sentinel-TOPS" (harmless if using "sar2sar")<br/>symetrise = True<br/><br/>despeckle_from_coordinates(image_path, coordinates_dict, destination_directory, <br/>                            model_name=model_name, symetrise=symetrise)</span></pre><p id="88d9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The<code class="cx qo qp qq qc b">despeckle_from_coordinates</code> function will create the same folders as the<code class="cx qo qp qq qc b">despeckle</code> function, with images croped with the specified coordinates.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qs"><img src="../Images/eb9ded1de8eb64f4fd9ad9ea3ec3b8bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ub19eEnhx8-iM_Oi6xkNng.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of image denoised using custom coordinates (displayed after a conversion to png)</figcaption></figure><p id="4378" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Despeckle parts of images using a crop tool</strong></p><pre class="mm mn mo mp mq qb qc qd bp qe bb bk"><span id="60bd" class="qf oa fq qc b bg qg qh l qi qj">from deepdespeckling.merlin.inference.despeckling import despeckle_from_crop<br/><br/># Path to a folder of several images <br/># images have to be in .tiff or .npy formats if using sar2sar <br/># images have to be in .cos or .npy formats is using merlin ("spotlight", "stripmap" or "Sentinel-TOPS")<br/>image_path="path/to/cosar/image"<br/># Folder where results are stored<br/>destination_directory="path/where/to/save/results"<br/><br/># If True it will crop a 256*256 image from the position of your click<br/># If False you will draw free-handly the area of your interest<br/>fixed = True<br/># Can be "sar2sar", "spotlight", "stripmap" or "Sentinel-TOPS"<br/>model_name = "spotlight"<br/># symetrise parameter if using "spotlight""stripmap" or "Sentinel-TOPS" (harmless if using "sar2sar")<br/>symetrise = True<br/><br/>despeckle_from_crop(image_path, destination_directory, model_name=model_name, fixed=fixed, symetrise=symetrise)</span></pre><blockquote class="qk ql qm"><p id="e24a" class="nc nd qn ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The<code class="cx qo qp qq qc b">despeckle_from_crop</code> function will first launch the crop tool : just select an area and press “q” when you are satisfied with the crop</p></blockquote><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qt"><img src="../Images/d4a013a93efe6ded94edd91bb94c65ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IozCehttDmdGuQx3f0pwCw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">the cropping tool in action</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qu"><img src="../Images/b0d7d2f8f8c3def0ae533fe741767c40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZufWqdvCOOyKU8bFuMKQjA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Results of the denoising using the crop tool</figcaption></figure><p id="3e14" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then, the <code class="cx qo qp qq qc b">despeckle_from_crop</code> function will create :</p><ul class=""><li id="fcd8" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oz pa pb bk">The same folders as the<code class="cx qo qp qq qc b">despeckle</code> function, with images cropped using the crop tool</li><li id="d632" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><code class="cx qo qp qq qc b">cropping_coordinates.txt</code> file containing the coordinates of the selected crop</li></ul><h2 id="768e" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">Going further</h2><p id="dbec" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk">Now you know to use deepdespeckling, to understand further more how it works, you can check <a class="af ny" href="https://github.com/hi-paris/deepdespeckling" rel="noopener ugc nofollow" target="_blank">the github repository</a>. We also provide a sphinx documentation <a class="af ny" href="https://hi-paris.github.io/deepdespeckling/" rel="noopener ugc nofollow" target="_blank">available here</a>.</p><p id="b438" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Feel free to contact me for any questions and feedback !</p><h2 id="e068" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk">Authors</h2><ul class=""><li id="13d4" class="nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx oz pa pb bk"><a class="af ny" href="https://www.linkedin.com/in/hadrien-mar/" rel="noopener ugc nofollow" target="_blank">Hadrien Mariaccia</a></li><li id="bee4" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><a class="af ny" href="https://emanueledalsasso.github.io/" rel="noopener ugc nofollow" target="_blank">Emanuele Dalsasso</a></li></ul><blockquote class="qk ql qm"><p id="a211" class="nc nd qn ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Unless otherwise noted, all images are by the authors</p></blockquote><h2 id="f810" class="nz oa fq bf ob oc od oe of og oh oi oj nl ok ol om np on oo op nt oq or os ot bk"><strong class="al">Contact</strong></h2><p id="ff2a" class="pw-post-body-paragraph nc nd fq ne b go ou ng nh gr ov nj nk nl ow nn no np ox nr ns nt oy nv nw nx fj bk">Don’t hesitate to contact me if you have any questions.</p><p id="c05d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To know more about Hi! PARIS and its Engineering Team:</p><ul class=""><li id="e1d8" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx oz pa pb bk"><a class="af ny" href="https://www.hi-paris.fr/" rel="noopener ugc nofollow" target="_blank">Hi! PARIS</a></li><li id="0172" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx oz pa pb bk"><a class="af ny" href="https://engineeringteam.hi-paris.fr/" rel="noopener ugc nofollow" target="_blank">Hi! PARIS Engineering Team</a></li></ul></div></div></div></div>    
</body>
</html>