<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>What’s Inside a Neural Network?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>What’s Inside a Neural Network?</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/whats-inside-a-neural-network-799daf235463?source=collection_archive---------1-----------------------#2024-09-29">https://towardsdatascience.com/whats-inside-a-neural-network-799daf235463?source=collection_archive---------1-----------------------#2024-09-29</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="37fb" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Plotting surface of error in 3D using PyTorch🔥</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@alexroz?source=post_page---byline--799daf235463--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Aleksei Rozanov" class="l ep by dd de cx" src="../Images/748b69bfaccf39c9aa568a9e6f41eec3.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*JISS93SvFnwE3NMNTl8HAQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--799daf235463--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@alexroz?source=post_page---byline--799daf235463--------------------------------" rel="noopener follow">Aleksei Rozanov</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--799daf235463--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 29, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">3</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ml"><img src="../Images/e665c5a7cca94323cffcd6c08b98fb71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*VtLefFL2ewkxRx1U0NegCw.png"/></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="2adb" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk nv"><span class="l nw nx ny bo nz oa ob oc od ed">In</span> my senior year of undergrad, like many other students, I had to choose a topic for my bachelor’s thesis. My major was hydrometeorology, so I initially considered researching a problem related to climate modeling. Fortunately, my advisor, <a class="af my" href="https://scholar.google.com/citations?user=RpUAogkAAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank">Dr. Gribanov</a>, suggested exploring a completely new direction I knew nothing about at the time — applying Neural Networks to upscale terrestrial carbon fluxes. Back then, the word “neural” made me think of surgery, and “network” of transportation. However, he gave me one of the clearest and most intuitive explanations of neural networks I’ve ever heard. One of the highlights was his description of the optimization process.</p><p id="67f6" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Imagine a piece of blank paper like this:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="of og ed oh bh oi"><div class="mj mk oe"><img src="../Images/fb7b70e385d3498cef464408e64daf4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H9lnIBIfYjnf891Yp8eVCw.png"/></div></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://openai.com/index/gpt-4/" rel="noopener ugc nofollow" target="_blank">GPT</a>.</figcaption></figure><p id="5a8f" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Now I ask you to aggressively (it’s important) crumple it to a ball:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="of og ed oh bh oi"><div class="mj mk oe"><img src="../Images/8955b8b7d4f32cb203fc145d0dc32176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ijCmW3NqKcNRYKYi6gvNYA.png"/></div></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://openai.com/index/gpt-4/" rel="noopener ugc nofollow" target="_blank">GPT</a>.</figcaption></figure><p id="9717" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">After straightening it back you’ll see something like an earth surface or some kind of a landscape with its peaks and depressions:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="of og ed oh bh oi"><div class="mj mk oe"><img src="../Images/7f6aa185047f64bbca138a6b0fc969b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xxehq_m5PNjAUzSiuhjnQw.png"/></div></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://openai.com/index/gpt-4/" rel="noopener ugc nofollow" target="_blank">GPT</a>.</figcaption></figure><p id="5f1e" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Now, if we introduce three dimensions — weight 1 , weight 2, and mean squared error (MSE) instead of latitude, longitude and elevation — we can think of this image as representing the error surface of a neural network. The goal of optimization is<strong class="nb fr"> to find the lowest point on this surface</strong>, which corresponds to the minimum error. As you can see from the image there is a multitude of local minima and maxima, that’s why it’s always a challenging task.</p><p id="72cd" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">So in this article, we will create such a surface in <strong class="nb fr">3D </strong>and use the <a class="af my" href="https://plotly.com/" rel="noopener ugc nofollow" target="_blank"><em class="oj">plotly</em></a> Python library to interactively illustrate it, along with the steps of Stochastic Gradient Descent (SGD).</p><blockquote class="ok ol om"><p id="6db4" class="mz na oj nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><em class="fq">As always the code of this article you can find on my </em><a class="af my" href="https://github.com/alexxxroz/Medium/blob/main/Error_surface_NN.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="nb fr"><em class="fq">GitHub</em></strong></a><em class="fq">.</em></p></blockquote></div></div></div><div class="ab cb on oo op oq" role="separator"><span class="or by bm os ot ou"/><span class="or by bm os ot ou"/><span class="or by bm os ot"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="832a" class="ov ow fq bf ox oy oz gq pa pb pc gt pd pe pf pg ph pi pj pk pl pm pn po pp pq bk"><strong class="al">Data</strong></h1><p id="1ba9" class="pw-post-body-paragraph mz na fq nb b go pr nd ne gr ps ng nh ni pt nk nl nm pu no np nq pv ns nt nu fj bk">First and foremost, we need synthetic data to work with. The data should exhibit some non-linear dependency. Let’s define it like this:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pw"><img src="../Images/23ffa0073c771ab4cb5e68fa80e69d85.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/0*gEKWWEWIEP3EH8oI"/></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="0f8e" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">In python it will have the following shape:</p><pre class="mm mn mo mp mq px py pz bp qa bb bk"><span id="33cc" class="qb ow fq py b bg qc qd l qe qf">np.random.seed(42)<br/>X = np.random.normal(1, 4.5, 10000)<br/>y = np.piecewise(X, [X &lt; -2,(X &gt;= -2) &amp; (X &lt; 2), X &gt;= 2], [lambda X: 2*X + 5, lambda X: 7.3*np.sin(X), lambda X: -0.03*X**3 + 2]) + np.random.normal(0, 1, X.shape)</span></pre><p id="bddf" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">After visualization:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qg"><img src="../Images/f9e827e1f4c93a3196111a509687adb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*ElpotEPBsaUjGiTSILVu4g.png"/></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><h1 id="7d98" class="ov ow fq bf ox oy qh gq pa pb qi gt pd pe qj pg ph pi qk pk pl pm ql po pp pq bk">Neural Net</h1><p id="c406" class="pw-post-body-paragraph mz na fq nb b go pr nd ne gr ps ng nh ni pt nk nl nm pu no np nq pv ns nt nu fj bk">Since we are visualizing a 3D space, our neural network will only have 2 weights. This means the ANN will consist of a single hidden neuron. Implementing this in PyTorch is quite intuitive:</p><pre class="mm mn mo mp mq px py pz bp qa bb bk"><span id="a2cd" class="qb ow fq py b bg qc qd l qe qf">class ANN(nn.Module):<br/>    def __init__(self, input_size, N, output_size):<br/>        super().__init__()<br/>        self.net = nn.Sequential()<br/>        self.net.add_module(name='Layer_1', module=nn.Linear(input_size, N, bias=False))<br/>        self.net.add_module(name='Tanh',module=nn.Tanh())<br/>        self.net.add_module(name='Layer_2',module=nn.Linear(N, output_size, bias=False))<br/><br/><br/>    def forward(self, x):<br/>        return self.net(x)</span></pre><blockquote class="ok ol om"><p id="f873" class="mz na oj nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><strong class="nb fr">Important!</strong> Don’t forget to turn off the biases in your layers, otherwise you’ll end up having <strong class="nb fr">x2</strong> more parameters.</p></blockquote><h1 id="2d46" class="ov ow fq bf ox oy qh gq pa pb qi gt pd pe qj pg ph pi qk pk pl pm ql po pp pq bk"><strong class="al">Changing weights</strong></h1><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qm"><img src="../Images/cf88d0421295fcd318f41797d5f15671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*TxPgxkjKxVfD_eqhWTMr6A.png"/></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="e621" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">To build the error surface, we first need to create a grid of possible values for W1 and W2. Then, for each weight combination, we will update the parameters of the network and calculate the error:</p><pre class="mm mn mo mp mq px py pz bp qa bb bk"><span id="51bd" class="qb ow fq py b bg qc qd l qe qf">W1, W2 = np.arange(-2, 2, 0.05), np.arange(-2, 2, 0.05)<br/>LOSS = np.zeros((len(W1), len(W2)))<br/>for i, w1 in enumerate(W1):<br/>    model.net._modules['Layer_1'].weight.data = torch.tensor([[w1]], dtype=torch.float32)<br/><br/>    for j, w2 in enumerate(W2):<br/>        model.net._modules['Layer_2'].weight.data = torch.tensor([[w2]], dtype=torch.float32)<br/><br/>        model.eval()<br/>        total_loss = 0<br/>        with torch.no_grad():<br/>            for x, y in test_loader:<br/>                preds = model(x.reshape(-1, 1))<br/>                total_loss += loss(preds, y).item()<br/><br/>        LOSS[i, j] = total_loss / len(test_loader)</span></pre><p id="aad2" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">It may take some time. If you make the resolution of this grid too coarse (i.e., the step size between possible weight values), you might miss local minima and maxima. Remember how the learning rate is often schedule to decrease over time? When we do this, the absolute change in weight values can be as small as 1e-3 or less. A grid with a 0.5 step simply won’t capture these fine details of the error surface!</p><h1 id="b0bf" class="ov ow fq bf ox oy qh gq pa pb qi gt pd pe qj pg ph pi qk pk pl pm ql po pp pq bk"><strong class="al">Training the model</strong></h1><p id="159b" class="pw-post-body-paragraph mz na fq nb b go pr nd ne gr ps ng nh ni pt nk nl nm pu no np nq pv ns nt nu fj bk">At this point, we don’t care at all about the quality of the trained model. However, we do want to pay attention to the learning rate, so let’s keep it between 1e-1 and 1e-2. We’ll simply collect the weight values and errors during the training process and store them in separate lists:</p><pre class="mm mn mo mp mq px py pz bp qa bb bk"><span id="0e31" class="qb ow fq py b bg qc qd l qe qf">model = ANN(1,1,1)<br/>epochs = 25<br/>lr = 1e-2<br/><br/>optimizer = optim.SGD(model.parameters(),lr =lr)<br/><br/>model.net._modules['Layer_1'].weight.data = torch.tensor([[-1]], dtype=torch.float32)<br/>model.net._modules['Layer_2'].weight.data = torch.tensor([[-1]], dtype=torch.float32)<br/><br/>errors, weights_1, weights_2 = [], [], []<br/><br/>model.eval()<br/>with torch.no_grad():<br/>    total_loss = 0<br/>    for x, y in test_loader:<br/>        preds = model(x.reshape(-1,1))<br/>        error = loss(preds, y)<br/>        total_loss += error.item()<br/>weights_1.append(model.net._modules['Layer_1'].weight.data.item())<br/>weights_2.append(model.net._modules['Layer_2'].weight.data.item())<br/>errors.append(total_loss / len(test_loader))<br/><br/>for epoch in tqdm(range(epochs)):<br/>    model.train()<br/><br/>    for x, y in train_loader:<br/>        pred = model(x.reshape(-1,1))<br/>        error = loss(pred, y)<br/>        optimizer.zero_grad()<br/>        error.backward()<br/>        optimizer.step()<br/><br/>    model.eval()<br/>    test_preds, true = [], []<br/>    with torch.no_grad():<br/>        total_loss = 0<br/>        for x, y in test_loader:<br/>            preds = model(x.reshape(-1,1))<br/>            error = loss(preds, y)<br/>            test_preds.append(preds)<br/>            true.append(y)<br/><br/>            total_loss += error.item()<br/>    weights_1.append(model.net._modules['Layer_1'].weight.data.item())<br/>    weights_2.append(model.net._modules['Layer_2'].weight.data.item())<br/>    errors.append(total_loss / len(test_loader))</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="of og ed oh bh oi"><div class="mj mk qn"><img src="../Images/c29a4134d350c741b87e453875476377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cjUtMXKRYi6jD0IZLC9SGw.png"/></div></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><h1 id="8d10" class="ov ow fq bf ox oy qh gq pa pb qi gt pd pe qj pg ph pi qk pk pl pm ql po pp pq bk"><strong class="al">Visualization</strong></h1><p id="cc4c" class="pw-post-body-paragraph mz na fq nb b go pr nd ne gr ps ng nh ni pt nk nl nm pu no np nq pv ns nt nu fj bk">Finally, we can visualize the data we have collected using plotly. The plot will have two scenes: surface and SGD trajectory. One of the ways to do the first part is to create a figure with a plotly <em class="oj">surface</em>. After that we will style it a little by updating a layout.</p><p id="19d7" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">The second part is as simple as it is — just use <em class="oj">Scatter3d</em> function and specify all three axes.</p><pre class="mm mn mo mp mq px py pz bp qa bb bk"><span id="41a7" class="qb ow fq py b bg qc qd l qe qf">import plotly.graph_objects as go<br/>import plotly.io as pio<br/><br/>plotly_template = pio.templates["plotly_dark"]<br/>fig = go.Figure(data=[go.Surface(z=LOSS, x=W1, y=W2)])<br/><br/>fig.update_layout(<br/>    title='Loss Surface',<br/>    scene=dict(<br/>        xaxis_title='w1',<br/>        yaxis_title='w2',<br/>        zaxis_title='Loss',<br/>        aspectmode='manual',<br/>        aspectratio=dict(x=1, y=1, z=0.5),<br/>        xaxis=dict(showgrid=False), <br/>        yaxis=dict(showgrid=False), <br/>        zaxis=dict(showgrid=False), <br/>    ),<br/>    width=800,<br/>    height=800<br/>)<br/><br/>fig.add_trace(go.Scatter3d(x=weights_2, y=weights_1, z=errors,<br/>                               mode='lines+markers',<br/>                              line=dict(color='red', width=2),<br/>                              marker=dict(size=4, color='yellow') ))<br/>fig.show()</span></pre><p id="a09e" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">Running it in Google Colab or locally in Jupyter Notebook will allow you to investigate the error surface more closely. Honestly, I spent a buch of time just looking at this figure:)</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="of og ed oh bh oi"><div class="mj mk qo"><img src="../Images/7722d9fedc5d08bfd935f0ab7f62996f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Up6PYomclMhRMpfLE5AaaA.gif"/></div></div><figcaption class="mt mu mv mj mk mw mx bf b bg z dx">Image by <a class="af my" href="https://medium.com/@alexroz" rel="noopener">author</a>.</figcaption></figure><p id="72d7" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">I’d love to see you surfaces, so please feel free to share it in comments. I strongly believe that the more imperfect the surface is the more interesting it is to investigate it!</p><p id="fde3" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">===========================================</p><p id="75a9" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk"><em class="oj">All my publications on Medium are free and open-access, that’s why I’d really appreciate if you followed me here!</em></p><p id="2fcc" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">P.s. I’m extremely passionate about (Geo)Data Science, ML/AI and Climate Change. So if you want to work together on some project pls contact me in <a class="af my" href="https://www.linkedin.com/in/alexxxroz/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> and check out <a class="af my" href="https://alexxxroz.github.io/" rel="noopener ugc nofollow" target="_blank">my website</a>!</p><p id="68b3" class="pw-post-body-paragraph mz na fq nb b go nc nd ne gr nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu fj bk">🛰️Follow for more🛰️</p></div></div></div></div>    
</body>
</html>