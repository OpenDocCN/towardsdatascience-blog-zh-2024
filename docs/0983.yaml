- en: Structured Generative AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化生成式 AI
- en: 原文：[https://towardsdatascience.com/structured-generative-ai-e772123428e4?source=collection_archive---------3-----------------------#2024-04-18](https://towardsdatascience.com/structured-generative-ai-e772123428e4?source=collection_archive---------3-----------------------#2024-04-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/structured-generative-ai-e772123428e4?source=collection_archive---------3-----------------------#2024-04-18](https://towardsdatascience.com/structured-generative-ai-e772123428e4?source=collection_archive---------3-----------------------#2024-04-18)
- en: How to constrain your model to output defined formats
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何限制你的模型输出定义的格式
- en: '[](https://medium.com/@orenmatar?source=post_page---byline--e772123428e4--------------------------------)[![Oren
    Matar](../Images/8b1fa6aa3585fc283d51828b53a0754c.png)](https://medium.com/@orenmatar?source=post_page---byline--e772123428e4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e772123428e4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e772123428e4--------------------------------)
    [Oren Matar](https://medium.com/@orenmatar?source=post_page---byline--e772123428e4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@orenmatar?source=post_page---byline--e772123428e4--------------------------------)[![Oren
    Matar](../Images/8b1fa6aa3585fc283d51828b53a0754c.png)](https://medium.com/@orenmatar?source=post_page---byline--e772123428e4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e772123428e4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e772123428e4--------------------------------)
    [Oren Matar](https://medium.com/@orenmatar?source=post_page---byline--e772123428e4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e772123428e4--------------------------------)
    ·7 min read·Apr 18, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e772123428e4--------------------------------)
    ·阅读时间 7 分钟·2024 年 4 月 18 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'In this post I will explain and demonstrate the concept of “structured generative
    AI”: generative AI constrained to defined formats. By the end of the post, you
    will understand where and when it can be used and how to implement it whether
    you’re crafting a transformer model from scratch or utilizing Hugging Face’s models.
    Additionally, we will cover an important tip for tokenization that is especially
    relevant for structured languages.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将解释并演示“结构化生成式 AI”的概念：即将生成式 AI 限制在定义的格式内。文章结束时，你将理解它的应用场景以及如何实现它，无论是从零开始构建一个变换器模型，还是使用
    Hugging Face 的模型。此外，我们还将介绍一个与分词相关的重要技巧，特别适用于结构化语言。
- en: 'One of the many uses of generative AI is as a translation tool. This often
    involves translating between two human languages but can also include computer
    languages or formats. For example, your application may need to translate natural
    (human) language to SQL:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 的许多用途之一是作为翻译工具。这通常涉及在人类语言之间的翻译，但也可以包括计算机语言或格式。例如，你的应用程序可能需要将自然语言（人类语言）翻译成
    SQL：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Or to convert text data into a JSON format:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 或者将文本数据转换为 JSON 格式：
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Naturally, many more applications are possible, for other structured languages.
    The training process for such tasks involves feeding examples of natural language
    alongside structured formats to an encoder-decoder model. Alternatively, leveraging
    a pre-trained Language Model (LLM) can suffice.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，其他结构化语言也可以有更多的应用。此类任务的训练过程包括将自然语言与结构化格式的示例输入到编码器-解码器模型中。或者，利用预训练的语言模型（LLM）也可以满足需求。
- en: 'While achieving 100% accuracy is unattainable, there is one class of errors
    that we can eliminate: syntax errors. These are violations of the format of the
    language, like replacing commas with dots, using table names that are not present
    in the SQL schema, or omitting bracket closures, which render SQL or JSON non-executable.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然实现 100% 准确率是不可能的，但有一类错误我们是可以消除的：语法错误。这些错误是对语言格式的违反，比如用点替代逗号，使用 SQL 模式中没有的表名，或者遗漏括号闭合，这些都会导致
    SQL 或 JSON 无法执行。
- en: 'The fact that we’re translating into a structured language means that the list
    of legitimate tokens at every generation step is limited, and pre-determined.
    If we could insert this knowledge into the generative AI process we can avoid
    a wide range of incorrect results. This is the idea behind structured generative
    AI: constrain it to a list of legitimate tokens.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在翻译成结构化语言，这意味着在每一步生成过程中，合法令牌的列表是有限的并且是预定的。如果我们能够将这一知识注入到生成式 AI 过程中，就能避免许多不正确的结果。这就是结构化生成式
    AI 的理念：将其限制为一组合法的令牌。
- en: '**A quick reminder on how tokens are generated**'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**关于令牌生成的快速提醒**'
- en: Whether employing an encoder-decoder or GPT architecture, token generation operates
    sequentially. Each token’s selection relies on both the input and previously generated
    tokens, continuing until a <end> token is generated, signifying the completion
    of the sequence. At each step, a classifier assigns logit values to all tokens
    in the vocabulary, representing the probability of each token as the next selection.
    The next token is sampled based on those logits.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是使用编码器-解码器架构还是GPT架构，令牌生成都是按顺序进行的。每个令牌的选择依赖于输入和之前生成的令牌，直到生成<end>令牌，标志着序列的完成。在每一步，分类器会为词汇表中的所有令牌分配logit值，表示每个令牌作为下一个选择的概率。接下来的令牌是基于这些logits进行采样的。
- en: '![](../Images/cad3a2ae8eae2f7150a70bacdecbaa82.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cad3a2ae8eae2f7150a70bacdecbaa82.png)'
- en: The decoder classifier assigns a logit to every token in the vocabulary (Image
    by author)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器分类器为词汇表中的每个令牌分配一个logit（图片由作者提供）
- en: '**Limiting token generation**'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**限制令牌生成**'
- en: To constrain token generation, we incorporate knowledge of the output language’s
    structure. Illegitimate tokens have their logits set to -inf, ensuring their exclusion
    from selection. For instance, if only a comma or “FROM” is valid after “Select
    name,” all other token logits are set to -inf.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了约束令牌生成，我们结合了对输出语言结构的理解。不合法的令牌将其logits设置为-inf，确保它们不会被选中。例如，如果在“Select name”后只有逗号或“FROM”是合法的，那么所有其他令牌的logits都会被设置为-inf。
- en: If you’re using Hugging Face, this can be implemented using a “logits processor”.
    To use it you need to implement a class with a __call__ method, which will be
    called after the logits are calculated, but before the sampling. This method receives
    all token logits and generated input IDs, returning modified logits for all tokens.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用Hugging Face，可以通过“logits处理器”实现这一点。要使用它，你需要实现一个包含__call__方法的类，该方法在计算logits后被调用，但在采样之前。此方法接收所有令牌logits和生成的输入ID，并返回所有令牌的修改后的logits。
- en: '![](../Images/e92f5fbfb0e5b222e3b5b4571ae33971.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e92f5fbfb0e5b222e3b5b4571ae33971.png)'
- en: 'The logits returned from the logits processor: all illegitimate tokens get
    a value of -inf (Image by author)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从logits处理器返回的logits：所有不合法的令牌都会得到-inf的值（图片由作者提供）
- en: I’ll demonstrate the code with a simplified example. First, we initialize the
    model, we will use Bart in this case, but this can work with any model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我将通过一个简化的示例演示代码。首先，我们初始化模型，这里我们使用Bart模型，但任何模型都可以使用。
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If we want to generate a translation from the natural language to SQL, we can
    run:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要生成从自然语言到SQL的翻译，可以运行：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Returning
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Since we did not fine-tune the model for text-to-SQL tasks, the output does
    not resemble SQL. We will not train the model in this tutorial, but we will guide
    it to generate an SQL query. We will achieve this by employing a function that
    maps each generated token to a list of permissible next tokens. For simplicity,
    we’ll focus only on the immediate preceding token, but more complicated mechanisms
    are easy to implement. We will use a dictionary defining for each token, which
    tokens are allowed to follow it. E.g. The query must begin with “SELECT” or “DELETE”,
    and after “SELECT” only “name”, “email”, or ”id” are allowed since those are the
    columns in our schema.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有针对文本到SQL任务对模型进行微调，因此输出不类似于SQL。在本教程中，我们不会训练模型，但我们会引导它生成SQL查询。我们将通过使用一个函数来实现这一点，该函数将每个生成的令牌映射到允许的下一个令牌列表。为了简化，我们仅关注紧接着的前一个令牌，但更复杂的机制也容易实现。我们将使用一个字典来定义每个令牌允许的后续令牌。例如，查询必须以“SELECT”或“DELETE”开始，在“SELECT”之后，仅允许“name”、“email”或“id”，因为这些是我们架构中的列。
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now we need to convert these tokens to the IDs used by the model. This will
    happen inside a class inheriting from LogitsProcessor.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将这些令牌转换为模型使用的ID。这将在一个继承自LogitsProcessor的类中完成。
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Finally, we will implement the __call__ function, which is called after the
    logits are calculated. The function creates a new tensor of -infs, checks which
    IDs are legitimate according to the rules (the dictionary), and places their scores
    in the new tensor. The result is a tensor that only has valid values for the valid
    tokens.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将实现__call__函数，该函数在计算logits后被调用。此函数创建一个包含-infs的新张量，检查哪些ID符合规则（字典中的规则），并将其分数放入新张量中。结果是一个仅包含有效令牌的有效值的张量。
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'And that’s it! We can now run a generation with the logits-processor:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们现在可以使用logits处理器进行生成：
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Returning
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The outcome is a little strange, but remember: **we didn’t even train the model!**
    We only enforced token generation based on specific rules. Notably, constraining
    generation doesn’t interfere with training; constraints only apply during generation
    post-training. Thus, when appropriately implemented, these constraints can only
    enhance generation accuracy.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 结果有点奇怪，但请记住：**我们甚至没有训练模型！** 我们只是根据特定规则强制生成标记。值得注意的是，约束生成不会干扰训练；约束只在训练后生成过程中起作用。因此，当这些约束得当实施时，它们只会提高生成准确性。
- en: Our simplistic implementation falls short of covering all the SQL syntax. A
    real implementation must support more syntax, potentially considering not just
    the last token but several, and enable batch generation. Once these enhancements
    are in place, our trained model can reliably generate executable SQL queries,
    constrained to valid table and column names from the schema. A Similar approach
    can enforce constraints in generating JSON, ensuring key presence and bracket
    closure.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的简化实现未能涵盖所有 SQL 语法。一个真正的实现必须支持更多的语法，可能不仅考虑最后一个标记，还要考虑多个标记，并且支持批量生成。一旦这些改进到位，我们训练好的模型可以可靠地生成可执行的
    SQL 查询，且仅限于模式中有效的表名和列名。类似的方法也可以在生成 JSON 时强制执行约束，确保键存在和括号闭合。
- en: '**Be careful of tokenization**'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**注意分词问题**'
- en: Tokenization is often overlooked but correct tokenization is crucial when using
    generative AI for structured output. However, under the hood, tokenization can
    make an impact on the training of your model. For example, you may fine-tune a
    model to translate text into a JSON. As part of the fine-tuning process, you provide
    the model with examples of text-JSON pairs, which it tokenizes. What will this
    tokenization look like?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 分词通常被忽视，但在使用生成性 AI 进行结构化输出时，正确的分词至关重要。然而，在后台，分词可能对模型的训练产生影响。例如，您可能会微调一个模型，将文本翻译为
    JSON。在微调过程中，您向模型提供文本-JSON 对，模型会对其进行分词。那么这种分词会是什么样子呢？
- en: '![](../Images/dc9052660570390852112c1180650f1e.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc9052660570390852112c1180650f1e.png)'
- en: (Image by author)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: (图像来源：作者)
- en: 'While you read “[[“ as two square brackets, the tokenizer converts them into
    a single ID, which will be treated as a completely distinct class from the single
    bracket by the token classifier. This makes the entire logic that the model must
    learn — more complicated (for example, remembering how many brackets to close).
    Similarly, adding a space before words may change their tokenization and their
    class ID. For instance:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当您阅读“[[”时，它是两个方括号，但分词器将其转换为单一的 ID，这将被分词分类器视为与单一括号完全不同的类别。这使得模型必须学习的整个逻辑更加复杂（例如，记住需要关闭多少个括号）。类似地，在单词前添加空格可能会改变它们的分词和类别
    ID。例如：
- en: '![](../Images/756198370ecbaaf8710bcdb24c8ccf3a.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/756198370ecbaaf8710bcdb24c8ccf3a.png)'
- en: (Image by author)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: (图像来源：作者)
- en: Again, this complicates the logic the model will have to learn since the weights
    connected to each of these IDs will have to be learned separately, for slightly
    different cases.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这再次增加了模型需要学习的逻辑复杂性，因为与这些 ID 相关的权重将需要单独学习，以适应稍微不同的情况。
- en: For simpler learning, ensure each concept and punctuation is consistently converted
    to the same token, by adding spaces before words and characters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化学习，确保每个概念和标点符号始终转换为相同的标记，方法是为单词和字符前添加空格。
- en: '![](../Images/ce09edd397c68277a6d2ddf93b2cb378.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce09edd397c68277a6d2ddf93b2cb378.png)'
- en: Spaced-out words lead to more consistent tokenization (Image by author)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 分开写的单词有助于更一致的分词（图像来源：作者）
- en: Inputting spaced examples during fine-tuning simplifies the patterns the model
    has to learn, enhancing model accuracy. During prediction, the model will output
    the JSON with spaces, which you can then remove before parsing.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调过程中输入带空格的示例可以简化模型需要学习的模式，从而提高模型的准确性。在预测时，模型将输出带空格的 JSON，您可以在解析之前去除这些空格。
- en: '**Summary**'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**总结**'
- en: Generative AI offers a valuable approach for translating into a formatted language.
    By leveraging the knowledge of the output structure, we can constrain the generative
    process, eliminating a class of errors and ensuring the executability of queries
    and parse-ability of data structures.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性 AI 提供了一种有价值的方法，用于翻译成格式化语言。通过利用输出结构的知识，我们可以约束生成过程，消除一类错误，并确保查询的可执行性和数据结构的可解析性。
- en: Additionally, these formats may use punctuation and keywords to signify certain
    meanings. Making sure that the tokenization of these keywords is consistent can
    dramatically reduce the complexity of the patterns that the model has to learn,
    thus reducing the required size of the model and its training time, while increasing
    its accuracy.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些格式可能会使用标点符号和关键词来表示某些意义。确保这些关键词的标记化一致性，可以显著降低模型需要学习的模式复杂度，从而减少模型的所需规模和训练时间，同时提高其准确性。
- en: Structured generative AI can effectively translate natural language into any
    structured format. These translations enable information extraction from text
    or query generation, which is a powerful tool for numerous applications.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化生成式人工智能可以有效地将自然语言转换为任何结构化格式。这些翻译能够从文本中提取信息或生成查询，这是许多应用的强大工具。
