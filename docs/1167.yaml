- en: 'Time Series Forecasting: A Practical Guide to Exploratory Data Analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/time-series-forecasting-a-practical-guide-to-exploratory-data-analysis-a101dc5f85b1?source=collection_archive---------0-----------------------#2024-05-09](https://towardsdatascience.com/time-series-forecasting-a-practical-guide-to-exploratory-data-analysis-a101dc5f85b1?source=collection_archive---------0-----------------------#2024-05-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to use Exploratory Data Analysis to drive information from time series data
    and enhance feature engineering using Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@maicolnicolini96?source=post_page---byline--a101dc5f85b1--------------------------------)[![Maicol
    Nicolini](../Images/97e78725ba70c95e340b76527c358498.png)](https://medium.com/@maicolnicolini96?source=post_page---byline--a101dc5f85b1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a101dc5f85b1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a101dc5f85b1--------------------------------)
    [Maicol Nicolini](https://medium.com/@maicolnicolini96?source=post_page---byline--a101dc5f85b1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a101dc5f85b1--------------------------------)
    ·15 min read·May 9, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/32bbea6cf3c9513a36265783549ae925.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ales Krivec](https://unsplash.com/@aleskrivec?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Time series analysis certainly represents one of the most widespread topics
    in the field of data science and machine learning: whether predicting financial
    events, energy consumption, product sales or stock market trends, this field has
    always been of great interest to businesses.'
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, the great increase in data availability, combined with the constant
    progress in machine learning models, has made this topic even more interesting
    today. Alongside traditional forecasting methods derived from statistics (e.g.
    regressive models, ARIMA models, exponential smoothing), techniques relating to
    machine learning (e.g. tree-based models) and deep learning (e.g. LSTM Networks,
    CNNs, Transformer-based Models) have emerged for some time now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite the huge differences between these techniques, there is a preliminary
    step that must be done, no matter what the model is: *Exploratory Data Analysis.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In statistics, **Exploratory Data Analysis** (EDA) is a discipline consisting
    in analyzing and visualizing data in order to summarize their main characteristics
    and gain relevant information from them. This is of considerable importance in
    the data science field because it allows to lay the foundations to another important
    step: *feature engineering*. That is, the practice that consists on creating,
    transforming and extracting features from the dataset so that the model can work
    to the best of its possibilities.'
  prefs: []
  type: TYPE_NORMAL
- en: The objective of this article is therefore to define a clear exploratory data
    analysis template, focused on time series, which can summarize and highlight the
    most important characteristics of the dataset. To do this, we will use some common
    Python libraries such as *Pandas*, *Seaborn* and S*tatsmodel*.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s first define the dataset: for the purposes of this article, we will take
    Kaggle’s [**Hourly Energy Consumption**](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption)data.
    This dataset relates to PJM Hourly Energy Consumption data, a regional transmission
    organization in the United States, that serves electricity to Delaware, Illinois,
    Indiana, Kentucky, Maryland, Michigan, New Jersey, North Carolina, Ohio, Pennsylvania,
    Tennessee, Virginia, West Virginia, and the District of Columbia.'
  prefs: []
  type: TYPE_NORMAL
- en: The hourly power consumption data comes from PJM’s website and are in megawatts
    (MW).
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s now define which are the most significant analyses to be performed when
    dealing with time series.
  prefs: []
  type: TYPE_NORMAL
- en: 'For sure, one of the most important thing is to plot the data: graphs can highlight
    many features, such as patterns, unusual observations, changes over time, and
    relationships between variables. As already said, the insight that emerge from
    these plots must then be taken into consideration, as much as possible, into the
    forecasting model. Moreover, some mathematical tools such as descriptive statistics
    and time series decomposition, will also be very useful.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Said that, the EDA I’m proposing in this article consists on six steps: Descriptive
    Statistics, Time Plot, Seasonal Plots, Box Plots, Time Series Decomposition, Lag
    Analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Descriptive Statistics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Descriptive statistic is a summary statistic that quantitatively describes or
    summarizes features from a collection of structured data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some metrics that are commonly used to describe a dataset are: measures of
    central tendency (e.g. *mean*, *median*), measures of dispersion (e.g. *range*,
    *standard deviation*), and measure of position (e.g. *percentiles*, *quartile*).
    All of them can be summarized by the so called **five number summary**, which
    include: minimum, first quartile (Q1), median or second quartile (Q2), third quartile
    (Q3) and maximum of a distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, these information can be easily retrieved using the well know `describe`
    method from Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/569c28931bca7ee75e4366dbbd6b91db.png)'
  prefs: []
  type: TYPE_IMG
- en: 1\. PJME statistic summary.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Time plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The obvious graph to start with is the time plot. That is, the observations
    are plotted against the time they were observed, with consecutive observations
    joined by lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python , we can use Pandas and Matplotlib:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d9bd55add95ba151a92842566151524f.png)'
  prefs: []
  type: TYPE_IMG
- en: 2.1 PJME Consumption Time Plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'This plot already provides several information:'
  prefs: []
  type: TYPE_NORMAL
- en: As we could expect, the pattern shows yearly seasonality.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Focusing on a single year, it seems that more pattern emerges. Likely, the consumptions
    will have a peak in winter and one another in summer, due to the greater electricity
    consumption.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The series does not exhibit a clear increasing/decreasing trend over the years,
    the average consumptions remains stationary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is an anomalous value around 2023, probably it should be imputed when
    implementing the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 3\. Seasonal Plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A seasonal plot is fundamentally a time plot where data are plotted against
    the individual “seasons” of the series they belong.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regarding energy consumption, we usually have hourly data available, so there
    could be several seasonality: *yearly*, *weekly*, *daily*. Before going deep into
    these plots, let’s first set up some variables in our Pandas dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 3.1 Seasonal plot — Yearly consumption
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A very interesting plot is the one referring to the energy consumption grouped
    by year over months, this highlights yearly seasonality and can inform us about
    ascending/descending trends over the years.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d81109dc87e66d8794e60ec39136e05a.png)'
  prefs: []
  type: TYPE_IMG
- en: 3.1 PJME Yearly Seasonal Plot
  prefs: []
  type: TYPE_NORMAL
- en: 'This plot shows every year has actually a very predefined pattern: the consumption
    increases significantly during winter and has a peak in summer (due to heating/cooling
    systems), while has a minima in spring and in autumn when no heating or cooling
    is usually required.'
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, this plot tells us that’s not a clear increasing/decreasing pattern
    in the overall consumptions across years.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Seasonal plot — Weekly consumption
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another useful plot is the weekly plot, it depicts the consumptions during the
    week over months and can also suggest if and how weekly consumptions are changing
    over a single year.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how to figure it out with Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/072c928e8b54ab3ce70e7607a0e5f7f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 3.2 PJME Weekly Seasonal Plot
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Seasonal plot — Daily consumption
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, the last seasonal plot I want to show is the daily consumption plot.
    As you can guess, it represents how consumption change over the day. In this case,
    data are first grouped by day of week and then aggregated taking the mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9e0cc04edfadccf0216f2b1c90e5e291.png)'
  prefs: []
  type: TYPE_IMG
- en: 3.3 PJME Daily Seasonal Plot
  prefs: []
  type: TYPE_NORMAL
- en: Often, this plot show a very typical pattern, someone calls it “M profile” since
    consumptions seems to depict an “M” during the day. Sometimes this pattern is
    clear, others not (like in this case).
  prefs: []
  type: TYPE_NORMAL
- en: However, this plots usually shows a relative peak in the middle of the day (from
    10 am to 2 pm), then a relative minima (from 2 pm to 6 pm) and another peak (from
    6 pm to 8 pm). Finally, it also shows the difference in consumptions from weekends
    and other days.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Seasonal plot — Feature Engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s now see how to use this information for feature engineering. Let’s suppose
    we are using some ML model that requires good quality features (e.g. ARIMA models
    or tree-based models).
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the main evidences coming from seasonal plots:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yearly consumptions do not change a lot over years: this suggests the possibility
    to use, when available, yearly seasonality features coming from lag or exogenous
    variables.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Weekly consumptions follow the same pattern across months: this suggests to
    use weekly features coming from lag or exogenous variables.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Daily consumption differs from normal days and weekends: this suggest to use
    categorical features able to identify when a day is a normal day and when it is
    not.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 4\. Box Plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Boxplot are a useful way to identify how data are distributed. Briefly, boxplots
    depict percentiles, which represent 1st (Q1), 2nd (Q2/median) and 3rd (Q3) quartile
    of a distribution and whiskers, which represent the range of the data. Every value
    beyond the whiskers can be thought as an *outlier*, more in depth, whiskers are
    often computed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/06e5f1fe1b65dbcd7f018e268cf2ba24.png)'
  prefs: []
  type: TYPE_IMG
- en: 4\. Whiskers Formula
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Box Plots — Total consumption
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s first compute the box plot regarding the total consumption, this can
    be easily done with *Seaborn*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/bcb675b3d2364e13ed03d36cc3cbc140.png)'
  prefs: []
  type: TYPE_IMG
- en: 4.1 PJME Boxplot
  prefs: []
  type: TYPE_NORMAL
- en: Even if this plot seems not to be much informative, it tells us we are dealing
    with a Gaussian-like distribution, with a tail more accentuated towards the right.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Box Plots — Day month distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A very interesting plot is the day/month box plot. It is obtained creating
    a “day month” variable and grouping consumptions by it. Here is the code, referring
    only from year 2017:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6ebf1b885874f81ddd75c7a79a975425.png)'
  prefs: []
  type: TYPE_IMG
- en: 4.2 PJME Year/Month Boxplot
  prefs: []
  type: TYPE_NORMAL
- en: It can be seen that consumption are less uncertain in summer/winter months (i.e.
    when we have peaks) while are more dispersed in spring/autumn (i.e. when temperatures
    are more variable). Finally, consumption in summer 2018 are higher than 2017,
    maybe due to a warmer summer. When feature engineering, remember to include (if
    available) the temperature curve, probably it can be used as an exogenous variable.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Box Plots — Day distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another useful plot is the one referring consumption distribution over the week,
    this is similar to the weekly consumption seasonal plot.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ad9f40a6f45d4957e36315b08229a7a7.png)'
  prefs: []
  type: TYPE_IMG
- en: 4.3 PJME Day Boxplot
  prefs: []
  type: TYPE_NORMAL
- en: As seen before, consumptions are noticeably lower on weekends. Anyway, there
    are several outliers pointing out that calendar features like “day of week” for
    sure are useful but could not fully explain the series.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Box Plots — Hour distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s finally see hour distribution box plot. It is similar to the daily consumption
    seasonal plot since it provides how consumptions are distributed over the day.
    Following, the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/807ad6d26cec4a5520a05176ff392043.png)'
  prefs: []
  type: TYPE_IMG
- en: 4.4 PJME Hour Boxplot
  prefs: []
  type: TYPE_NORMAL
- en: Note that the “M” shape seen before is now much more crushed. Furthermore there
    are a lot of outliers, this tells us data not only relies on daily seasonality
    (e.g. the consumption on today’s 12 am is similar to the consumption of yesterday
    12 am) but also on something else, probably some exogenous climatic feature like
    temperature or humidity.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Time Series Decomposition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As already said, time series data can exhibit a variety of patterns. Often,
    it is helpful to split a time series into several components, each representing
    an underlying pattern category.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can think of a time series as comprising three components: a *trend* component,
    a *seasonal* component and a *remainder* component (containing anything else in
    the time series). For some time series (e.g., energy consumption series), there
    can be more than one seasonal component, corresponding to different seasonal periods
    (daily, weekly, monthly, yearly).'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main type of decomposition: *additive* and *multiplicative*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the additive decomposition, we represent a series (𝑦) as the sum of a seasonal
    component (𝑆), a trend (𝑇) and a remainder (𝑅):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e17ee10b8116c19d217f65fd55260dfd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, a multiplicative decomposition can be written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e242c6a97fc1dad2ad2fc5598e1b1ea4.png)'
  prefs: []
  type: TYPE_IMG
- en: Generally speaking, additive decomposition best represent series with constant
    variance while multiplicative decomposition best suits time series with non-stationary
    variances.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, time series decomposition can be easily fulfilled with *Statsmodel*
    library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1e6aac354ac11d476f1aa4d7b27c75ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 5.1 PJME Series Decomposition — Additive Decompose.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ce50a9bfc23a07acefea8bb56927df5f.png)'
  prefs: []
  type: TYPE_IMG
- en: 5.2 PJME Series Decomposition — Multiplicative Decompose.
  prefs: []
  type: TYPE_NORMAL
- en: 'The above plots refers to 2017\. In both cases, we see the trend has several
    local peaks, with higher values in summer. From the seasonal component, we can
    see the series actually has several periodicities, this plot highlights more the
    weekly one, but if we focus on a particular month (January) of the same year,
    daily seasonality emerges too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/38852e4d20f443b471e67673aa590562.png)'
  prefs: []
  type: TYPE_IMG
- en: 5.3 PJME Series Decomposition — Additive Decompose, focus on January 2017.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c81aba4ff062cc4f588cb56dc5a7fe2f.png)'
  prefs: []
  type: TYPE_IMG
- en: 5.4 PJME Series Decomposition — Multiplicative Decompose, focus on January 2017.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Lag Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In time series forecasting, a lag is simply a past value of the series. For
    example, for daily series, the first lag refers to the value the series had the
    previous day, the second to the value of the day before and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lag analysis is based on computing correlations between the series and a lagged
    version of the series itself, this is also called *autocorrelation.* For a k-lagged
    version of a series, we define the autocorrelation coefficient as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/012a2b1804fb4a04bed04ce8fa487838.png)'
  prefs: []
  type: TYPE_IMG
- en: Where *y* bar represent the mean value of the series and *k* the lag.
  prefs: []
  type: TYPE_NORMAL
- en: The autocorrelation coefficients make up the *autocorrelation function* (ACF)
    for the series, this is simply a plot depicting the auto-correlation coefficient
    versus the number of lags taken into consideration.
  prefs: []
  type: TYPE_NORMAL
- en: When data has a trend, the autocorrelations for small lags are usually large
    and positive because observations close in time are also nearby in value. When
    data show seasonality, autocorrelation values will be larger in correspondence
    of seasonal lags (and multiples of the seasonal period) than for other lags. Data
    with both trend and seasonality will show a combination of these effects.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, a more useful function is the *partial autocorrelation function*
    (PACF). It is similar to the ACF, except that it shows only the direct autocorrelation
    between two lags. For example, the partial autocorrelation for lag 3 refers to
    the only correlation lag 1 and 2 do not explain. In other words, the partial correlation
    refers to the direct effect a certain lag has on the current time value.
  prefs: []
  type: TYPE_NORMAL
- en: Before moving to the Python code, it is important to highlight that autocorrelation
    coefficient emerges more clearly if the series is *stationary,* so often is better
    to first differentiate the series to stabilize the signal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Said that, here is the code to plot PACF for different hours of the day:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/44dbff41f17b2e610d813960ecfb0c5b.png)'
  prefs: []
  type: TYPE_IMG
- en: 6.1 PJME Lag Analysis — Partial Auto Correlation Function (h=0).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d7d2d2e6976b720b7bff2e0a9c82c8e8.png)'
  prefs: []
  type: TYPE_IMG
- en: 6.2 PJME Lag Analysis — Partial Auto Correlation Function (h=4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a32acfd15df172f5e3ace8d54843d633.png)'
  prefs: []
  type: TYPE_IMG
- en: 6.3 PJME Lag Analysis — Partial Auto Correlation Function (h=8).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/30eaf2c891649106e9ec2e6a1ce93aa4.png)'
  prefs: []
  type: TYPE_IMG
- en: 6.4 PJME Lag Analysis — Partial Auto Correlation Function (h=12).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9337dca06ee8f7ca5b4ff221128e89f9.png)'
  prefs: []
  type: TYPE_IMG
- en: 6.5 PJME Lag Analysis — Partial Auto Correlation Function (h=16).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9f5f6bfa3c2cba4da0413c467eac4548.png)'
  prefs: []
  type: TYPE_IMG
- en: 6.6 PJME Lag Analysis — Partial Auto Correlation Function (h=20).
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the PACF simply consists on plotting Pearson partial auto-correlation
    coefficients for different lags. Of course, the non-lagged series shows a perfect
    auto-correlation with itself, so lag 0 will always be 1\. The blue band represent
    the *confidence interval:* if a lag exceed that band, then it is statistically
    significant and we can assert it is has great importance.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Lag analysis — Feature Engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lag analysis is one of the most impactful study on time series feature engineering.
    As already said, a lag with high correlation is an important lag for the series,
    then it should be taken into consideration.
  prefs: []
  type: TYPE_NORMAL
- en: A widely used feature engineering technique consists on making an **hourly division**
    of the dataset. That is, splitting data in 24 subset, each one referring to an
    hour of the day. This has the effect to regularize and smooth the signal, making
    it more simple to forecast.
  prefs: []
  type: TYPE_NORMAL
- en: Each subset should then be feature engineered, trained and fine-tuned. The final
    forecast will be achieved combining the results of these 24 models. Said that,
    every hourly model will have its peculiarities, most of them will regard important
    lags.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving on, let’s define two types of lag we can deal with when doing
    lag analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Auto-regressive lags**: lags close to lag 0, for which we expect high values
    (recent lags are more likely to predict the present value). They are a representation
    on how much trend the series shows.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Seasonal lags**: lags referring to seasonal periods. When hourly splitting
    the data, they usually represent weekly seasonality.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that auto-regressive lag 1 can also be taught as a *daily seasonal lag*
    for the series.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now discuss about the PACF plots printed above.
  prefs: []
  type: TYPE_NORMAL
- en: Night Hours
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consumption on night hours (0, 4) relies more on auto-regressive than on weekly
    lags, since the most important are all localized on the first five. Seasonal periods
    such as 7, 14, 21, 28 seems not to be too much important, this advises us to pay
    particular attention on lag 1 to 5 when feature engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Day Hours
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consumption on day hours (8, 12, 16, 20) exhibit both auto-regressive and seasonal
    lags. This particularly true for hours 8 and 12 - when consumption is particularly
    high — while seasonal lags become less important approaching the night. For these
    subsets we should also include seasonal lag as well as auto-regressive ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, here are some tips when feature engineering lags:'
  prefs: []
  type: TYPE_NORMAL
- en: Do not to take into consideration too many lags since this will probably lead
    to over fitting. Generally, auto-regressive lags goes from 1 to 7, while weekly
    lags should be 7, 14, 21 and 28\. But it’s not mandatory to take each of them
    as features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking into consideration lags that are not auto-regressive or seasonal is usually
    a bad idea since they could bring to overfitting as well. Rather, try to understand
    while a certain lag is important.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transforming lags can often lead to more powerful features. For example, seasonal
    lags can be aggregated using a weighted mean to create a single feature representing
    the seasonality of the series.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Free Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, I would like to mention a very useful (and free) book explaining time
    series, which I have personally used a lot: [Forecasting: Principles and Practice](https://otexts.com/fpp3/).'
  prefs: []
  type: TYPE_NORMAL
- en: Even though it is meant to use R instead of Python, this textbook provides a
    great introduction to forecasting methods, covering the most important aspects
    of time series analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim of this article was to present a comprehensive Exploratory Data Analysis
    template for time series forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: EDA is a fundamental step in any type of data science study since it allows
    to understand the nature and the peculiarities of the data and lays the foundation
    to feature engineering, which in turn can dramatically improve model performance.
  prefs: []
  type: TYPE_NORMAL
- en: We have then described some of the most used analysis for time series EDA, these
    can be both statistical/mathematical and graphical. Obviously, the intention of
    this work was only to give a practical framework to start with, subsequent investigations
    need to be carried out based on the type of historical series being examined and
    the business context.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for having followed me until the end.
  prefs: []
  type: TYPE_NORMAL
- en: '*Unless otherwise noted, all images are by the author.*'
  prefs: []
  type: TYPE_NORMAL
