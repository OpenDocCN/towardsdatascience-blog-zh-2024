<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Navigating the Latest GenAI Announcements — July 2024</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Navigating the Latest GenAI Announcements — July 2024</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/navigating-the-latest-genai-model-announcements-july-2024-461f227f588f?source=collection_archive---------7-----------------------#2024-07-26">https://towardsdatascience.com/navigating-the-latest-genai-model-announcements-july-2024-461f227f588f?source=collection_archive---------7-----------------------#2024-07-26</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="e2c7" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><em class="hd">A guide to new models GPT-4o mini, Llama 3.1, Mistral NeMo 12B and other GenAI trends</em></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@tula.masterman?source=post_page---byline--461f227f588f--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Tula Masterman" class="l ep by dd de cx" src="../Images/c36b3740befd5dfdb8719dc6596f1a99.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/2*Fn6lzAzI489IDlnO-QI8_A.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--461f227f588f--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@tula.masterman?source=post_page---byline--461f227f588f--------------------------------" rel="noopener follow">Tula Masterman</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--461f227f588f--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 26, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk lb lc ab q ee ld le" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lf"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap ie li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/2c1a54aec97e06bbaf4652cc58890eb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lghnKSBoAXmBq4U9kUwCfA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image Created by Author with GPT-4o to represent different models</figcaption></figure><h1 id="83bd" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Introduction</h1><p id="2143" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Since the launch of ChatGPT in November 2022, it feels like almost every week there’s a new model, novel prompting approach, innovative agent framework, or other exciting GenAI breakthrough. July 2024 is no different: this month alone we’ve seen the release of <a class="af ou" href="https://mistral.ai/news/codestral-mamba/" rel="noopener ugc nofollow" target="_blank">Mistral Codestral Mamba</a>, <a class="af ou" href="https://mistral.ai/news/mistral-nemo/" rel="noopener ugc nofollow" target="_blank">Mistral NeMo 12B</a>, <a class="af ou" href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/" rel="noopener ugc nofollow" target="_blank">GPT-4o mini</a>, and <a class="af ou" href="https://ai.meta.com/blog/meta-llama-3-1/" rel="noopener ugc nofollow" target="_blank">Llama 3.1</a> amongst others. These models bring significant enhancements to areas like inference speed, reasoning ability, coding ability, and tool calling performance making them a compelling choice for business use.</p><p id="b035" class="pw-post-body-paragraph ny nz fq oa b go ov oc od gr ow of og oh ox oj ok ol oy on oo op oz or os ot fj bk">In this article we’ll cover the highlights of recently released models and discuss some of the major trends in GenAI today, including increasing context window sizes and improving performance across languages and modalities.</p><h1 id="76a1" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Overview of July Release Models</h1><h2 id="e2cf" class="pa nd fq bf ne pb pc pd nh pe pf pg nk oh ph pi pj ol pk pl pm op pn po pp pq bk"><strong class="al">Mistral Codestral Mamba</strong></h2><ul class=""><li id="de4d" class="ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot pr ps pt bk"><strong class="oa fr">Overview</strong>: Codestral Mamba 7B is designed for <strong class="oa fr">enhanced reasoning and coding capabilities </strong>using the <a class="af ou" href="https://arxiv.org/abs/2312.00752" rel="noopener ugc nofollow" target="_blank">Mamba architecture</a> instead of the Transformer architecture used by most Language Models. This architecture enables in context retrieval for much longer sequences and has been tested for sequences up to 256K tokens. By comparison, most Transformer based models allow between 8-128K token context windows. The Mamba architecture also enables faster inference speeds than Transformer based models.</li><li id="ab0c" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Availability</strong>: Codestral Mamba is an open source model under the Apache 2.0 License.</li><li id="d089" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Performance</strong>: Codestral Mamba 7B outperforms CodeGemma-1.1 7B, CodeLlama 7B, and DeepSeekv1.5 7B on the HumanEval, MBPP, CruxE, HumanEval C++, and Human Eval JavaScript benchmarks. It performs similarly to Codestral 22B across these benchmarks despite it’s smaller size.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pz"><img src="../Images/9ccaedb9551dbc596082350afb2a639e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tBn1CrugxnxdykZL8HWXNw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author based on results from Mistral AI <a class="af ou" href="https://mistral.ai/news/codestral-mamba/" rel="noopener ugc nofollow" target="_blank">Codestral Mamba announcement</a></figcaption></figure><h2 id="95e9" class="pa nd fq bf ne pb pc pd nh pe pf pg nk oh ph pi pj ol pk pl pm op pn po pp pq bk"><strong class="al">Mistral NeMo 12B</strong></h2><ul class=""><li id="c8cd" class="ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot pr ps pt bk"><strong class="oa fr">Overview</strong>: Mistral NeMo 12B was produced by Mistral and Nvidia to offer a competitive language model in the 12B parameter range with a far larger context window than most models of this size. Nemo 12B has a <strong class="oa fr">128K token context window</strong> while similarly sized models Gemma 2 9B and Llama 3 8B offer only 8K token context windows. NeMo is <strong class="oa fr">designed for multilingual use cases and provides a new tokenizer</strong>, Tekken, which outperforms the Llama 3 tokenizer for compressing text across 85% of languages. The HuggingFace model card indicates <strong class="oa fr">NeMo should be used with lower temperatures</strong> than earlier Mistral models, they recommend setting the temperature to 0.3.</li><li id="be36" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Availability</strong>: NeMo 12B is an open source model (offering both base and instruction-tuned checkpoints) under the Apache 2.0 License.</li><li id="4bec" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Performance</strong>: Mistral NeMo 12B outperforms Gemma 2 9B and Llama 3 8B across multiple zero and five shot benchmarks by as much as 10%. It also performs almost 2x better than Mistral 7B on WildBench which is designed to measure model’s performance on real world tasks requiring complex reasoning and multiple conversation turns.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qa"><img src="../Images/bff3c9eb1e34c83135461162a628694c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iYZFWVDl99tO4-ohCYSPyg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author based on results from <a class="af ou" href="https://mistral.ai/news/mistral-nemo/" rel="noopener ugc nofollow" target="_blank">Mistral AI NeMo announcement</a></figcaption></figure><h2 id="23fe" class="pa nd fq bf ne pb pc pd nh pe pf pg nk oh ph pi pj ol pk pl pm op pn po pp pq bk"><strong class="al">Mistral Large 2</strong></h2><ul class=""><li id="cba8" class="ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot pr ps pt bk"><strong class="oa fr">Overview</strong>: <a class="af ou" href="https://mistral.ai/news/mistral-large-2407/" rel="noopener ugc nofollow" target="_blank">Mistral Large 2 </a>provides a <strong class="oa fr">128K token context window</strong>, improved function calling, support for numerous languages and 8<strong class="oa fr">0+ coding languages</strong>. Like Codestral Mamba and NeMo, Mistral Large 2 was trained on a large volume of code allowing it to perform competitively with GPT-4o, Claude 3 Opus, and Llama 3.1 405B. During training, the Mistral team <strong class="oa fr">focused on reducing the model’s likelihood of hallucinations </strong>making Mistral Large 2 more likely to respond that it cannot find an answer or lacks the information needed to provide a response.</li><li id="68e4" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Availability</strong>: Mistral Large 2 is available under the <a class="af ou" href="https://mistral.ai/licenses/MRL-0.1.md" rel="noopener ugc nofollow" target="_blank">Mistral Research License</a>. This allows experimentation and modification for research and non-commercial use cases. For those interested in using Mistral Large 2 commercially, you can <a class="af ou" href="https://mistral.ai/contact/" rel="noopener ugc nofollow" target="_blank">contact Mistral AI directly</a> and request a Mistral Commercial License.</li><li id="1785" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Performance</strong>: Mistral Large 2 outperforms GPT-4o, and Claude 3 Opus on function calling tasks and performs similarly to these models on instruction following and alignment based tasks evaluated by the Wild Bench and Arena Hard benchmarks.</li></ul><h2 id="3faf" class="pa nd fq bf ne pb pc pd nh pe pf pg nk oh ph pi pj ol pk pl pm op pn po pp pq bk"><strong class="al">GPT-4o mini</strong></h2><ul class=""><li id="52f4" class="ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot pr ps pt bk"><strong class="oa fr">Overview</strong>: GPT-4o mini is a small, cost effective model that supports text and vision and offers competitive reasoning and tool calling performance. It has a <strong class="oa fr">128K token context window </strong>with an impressive <strong class="oa fr">16K token output length</strong>. It is the most cost effective model from OpenAI at 15 cents per million input tokens and 60 cents per million output tokens. OpenAI notes that this price is 99% cheaper than their text-davinci-003 model from 2022 indicating a trend towards cheaper, smaller, more capable models in a relatively short time frame. While GPT-4o mini does not support image, video, and audio inputs like GPT-4o does, OpenAI reports these features are coming soon. Like GPT-4o, GPT-4o mini has been trained with built-in safety measures and is the first OpenAI model that applies the <a class="af ou" href="https://arxiv.org/abs/2404.13208" rel="noopener ugc nofollow" target="_blank"><strong class="oa fr">instruction hierarchy</strong></a><strong class="oa fr"> method</strong> designed to make the model <strong class="oa fr">more resistant to prompt injections and jailbreaks</strong>. GPT-4o mini leverages the same tokenizer as GPT-4o which enables <strong class="oa fr">improved performance on non-English text</strong>. Shortly after the GPT-4o mini announcement, OpenAI also announced an e<a class="af ou" href="https://openai.com/gpt-4o-long-output/" rel="noopener ugc nofollow" target="_blank">xperimental 64K token output for GPT-4o</a> available through their alpha program.</li><li id="eb36" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Availability</strong>: GPT-4o mini is a closed source model available through OpenAI’s Assistants API, Chat Completions API, and Batch API. It is also available through <a class="af ou" href="https://azure.microsoft.com/en-us/blog/openais-fastest-model-gpt-4o-mini-is-now-available-on-azure-ai/" rel="noopener ugc nofollow" target="_blank">Azure AI</a>.</li><li id="1599" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Performance</strong>: GPT-4o mini outperforms Gemini Flash and Claude Haiku, models of similar size, on multiple benchmarks including <a class="af ou" href="https://arxiv.org/abs/2009.03300" rel="noopener ugc nofollow" target="_blank">MMLU </a>(Massive Multitask Language Understanding) which is designed to measure reasoning ability, <a class="af ou" href="https://arxiv.org/abs/2210.03057" rel="noopener ugc nofollow" target="_blank">MGSM </a>(Multilingual Grade School Math) which measures mathematical reasoning, <a class="af ou" href="https://arxiv.org/abs/2107.03374" rel="noopener ugc nofollow" target="_blank">HumanEval</a> which measures coding ability, and <a class="af ou" href="https://arxiv.org/abs/2311.16502" rel="noopener ugc nofollow" target="_blank">MMMU </a>(Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark) which measures multimodal reasoning.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qb"><img src="../Images/c9a13e62a7becc06958538e36a815f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iekK7DURlOwEhx-8iq0oWw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by author based on results from <a class="af ou" href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/" rel="noopener ugc nofollow" target="_blank">GPT-4o mini announcement</a></figcaption></figure><h2 id="93e7" class="pa nd fq bf ne pb pc pd nh pe pf pg nk oh ph pi pj ol pk pl pm op pn po pp pq bk"><strong class="al">Llama 3.1</strong></h2><ul class=""><li id="8468" class="ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot pr ps pt bk"><strong class="oa fr">Overview</strong>: Llama 3.1 introduces a <strong class="oa fr">128K token context window</strong>, a significant jump from the 8K token context window for Llama 3, which was released only three months ago in April. Llama 3.1 is <strong class="oa fr">available in three sizes: 405B, 70B, and 8B.</strong> It offers improved reasoning, tool-calling, and multilingual performance. Meta’s Llama 3.1 announcement calls <strong class="oa fr">Llama 3.1 405B the “first frontier-level open source AI model”. </strong>This demonstrates a huge stride forward for the open source community and demonstrates Meta’s commitment to making AI accessible, Mark Zuckerberg discusses this in more detail in his article “<a class="af ou" href="https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/" rel="noopener ugc nofollow" target="_blank">Open Source AI is the Path Forward</a>”. The Llama 3.1 announcement also includes guidance on enabling common use cases like real-time and batch inference, fine-tuning, RAG, continued pre-training, synthetic data generation, and distillation. Meta also released the <a class="af ou" href="https://github.com/meta-llama/llama-agentic-system" rel="noopener ugc nofollow" target="_blank">Llama Reference System</a> to support developers working on agentic based use cases with Llama 3.1 and additional <a class="af ou" href="https://ai.meta.com/blog/meta-llama-3-1-ai-responsibility/" rel="noopener ugc nofollow" target="_blank">AI safety tools</a> including Llama Guard 3 to moderate inputs and outputs in multiple languages, Prompt Guard to mitigate prompt injections, and CyberSecEval 3 to reduce GenAI security risks.</li><li id="a432" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Availability</strong>: Llama 3.1 is an open source model. Meta has changed their license to allow developers to use the outputs from Llama models to train and improve other models. Models are available through HuggingFace, llama.meta.com, and through other partner platforms like Azure AI.</li><li id="f1cf" class="ny nz fq oa b go pu oc od gr pv of og oh pw oj ok ol px on oo op py or os ot pr ps pt bk"><strong class="oa fr">Performance</strong>: Each of the Llama 3.1 models outperform other models in their size class across nearly all the common language model benchmarks for reasoning, coding, math, tool use, long context, and multilingual performance.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qc"><img src="../Images/450cbf33dfabb38a07c3b2ce3a1466a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rAxQzW8whBalwn5VH700YA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by author based on results from <a class="af ou" href="https://ai.meta.com/blog/meta-llama-3-1/" rel="noopener ugc nofollow" target="_blank">Meta Llama 3.1 announcement</a></figcaption></figure><h1 id="1e2e" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Trends in GenAI Models</h1><p id="733e" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Overall, there is a trend towards increasingly capable models of all sizes with longer context windows, longer token output lengths, and lower price points. The push towards improved reasoning, tool calling, and coding abilities reflect the increasing demand for agentic systems capable of taking complex actions on behalf of users. To create effective agent systems, models need to understand how to break down a problem, how to use the tools available to them, and how to reconcile lots of information at one time.</p><p id="367f" class="pw-post-body-paragraph ny nz fq oa b go ov oc od gr ow of og oh ox oj ok ol oy on oo op oz or os ot fj bk">The recent announcements from OpenAI and Meta reflect the growing discussion around AI safety with both companies demonstrating different ways to approach the same challenge. OpenAI has taken a closed source approach and improved model safety through applying feedback from experts in social psychology and misinformation and implementing new training methods. In contrast, Meta has doubled down on their open source initiatives and released new tools focused on helping developers mitigate AI safety concerns.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qd"><img src="../Images/323d506da8b3ee322752fc81dd3cf6d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-BHgkfVo_qcypoMm5bYfQA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author with GPT-4o depicting an arena with closed and open source models competing.</figcaption></figure><h1 id="b8d8" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Conclusion</h1><p id="688e" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">In the future, I think we’ll continue to see advancements in generalist and specialist models with frontier models like GPT-4o and Llama 3.1 getting better and better at breaking down problems and performing a variety of tasks across modalities, while specialist models like Codestral Mamba will excel in their domain and become more adept at handling longer contexts and nuanced tasks within their area of expertise. Additionally, I expect we’ll see new benchmarks focused on models’ ability to follow multiple directions at once within a single turn and a proliferation of AI systems that leverage generalist and specialist models to perform tasks as a team.</p><p id="0214" class="pw-post-body-paragraph ny nz fq oa b go ov oc od gr ow of og oh ox oj ok ol oy on oo op oz or os ot fj bk">Furthermore, while model performance is typically measured based on standard benchmarks, what ultimately matters is how humans perceive the performance and how effectively models can further human goals. The Llama 3.1 announcement includes an interesting graphic demonstrating how people rated responses from Llama 3.1 compared to GPT-4o, GPT-4, and Claude 3.5. The results show that Llama 3.1 received a tie from humans in over 50% of the examples with the remaining win rates roughly split between Llama 3.1 and it’s challenger. This is significant because it suggests that open source models can now readily compete in a league that was previously dominated by closed source models.</p><p id="fc8a" class="pw-post-body-paragraph ny nz fq oa b go ov oc od gr ow of og oh ox oj ok ol oy on oo op oz or os ot fj bk"><em class="qe">Interested in discussing further or collaborating? Reach out on </em><a class="af ou" href="https://www.linkedin.com/in/tula-masterman/" rel="noopener ugc nofollow" target="_blank"><em class="qe">LinkedIn</em></a><em class="qe">!</em></p></div></div></div></div>    
</body>
</html>