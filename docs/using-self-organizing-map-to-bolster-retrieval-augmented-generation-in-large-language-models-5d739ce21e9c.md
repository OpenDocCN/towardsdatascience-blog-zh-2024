# ä½¿ç”¨è‡ªç»„ç»‡æ˜ å°„å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ

> åŸæ–‡ï¼š[`towardsdatascience.com/using-self-organizing-map-to-bolster-retrieval-augmented-generation-in-large-language-models-5d739ce21e9c?source=collection_archive---------3-----------------------#2024-03-16`](https://towardsdatascience.com/using-self-organizing-map-to-bolster-retrieval-augmented-generation-in-large-language-models-5d739ce21e9c?source=collection_archive---------3-----------------------#2024-03-16)

## *SOM è¢«æè®®ç”¨æ¥å¢å¼º LLM ä¸Šä¸‹æ–‡çš„é«˜æ•ˆæ£€ç´¢ï¼Œä»¥æ”¯æŒ RAGâ€¦â€¦*

[](https://murali-kashaboina.medium.com/?source=post_page---byline--5d739ce21e9c--------------------------------)![Murali Kashaboina](https://murali-kashaboina.medium.com/?source=post_page---byline--5d739ce21e9c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5d739ce21e9c--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5d739ce21e9c--------------------------------) [Murali Kashaboina](https://murali-kashaboina.medium.com/?source=post_page---byline--5d739ce21e9c--------------------------------)

Â·å‘å¸ƒäº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5d739ce21e9c--------------------------------) Â·17 åˆ†é’Ÿé˜…è¯»Â·2024 å¹´ 3 æœˆ 16 æ—¥

--

![](img/77f2ba7f54a07f0a727c5ac6340c1a4e.png)

å›¾ç‰‡æ¥æºï¼š[Werclive ğŸ‘¹](https://unsplash.com/@werclive?utm_source=medium&utm_medium=referral)æ¥è‡ª[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

## èƒŒæ™¯

å¤§é‡æ•°æ®è¢«ç”¨äºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè¿™äº›æ¨¡å‹åŒ…å«æ•°ç™¾ä¸‡ã€æ•°åäº¿ä¸ªå‚æ•°ï¼Œç›®çš„æ˜¯è¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œå¦‚æ–‡æœ¬è¡¥å…¨ã€æ–‡æœ¬æ‘˜è¦ã€è¯­è¨€ç¿»è¯‘å’Œé—®é¢˜å›ç­”ã€‚è™½ç„¶ LLM ä»è®­ç»ƒæ•°æ®ä¸­è‡ªç„¶è€Œç„¶åœ°å»ºç«‹äº†ä¸€ä¸ªçŸ¥è¯†åº“ï¼Œä½†è®­ç»ƒæ•°æ®æœ‰ä¸€ä¸ªæˆªæ­¢æ—¥æœŸï¼Œæˆªæ­¢æ—¥æœŸä¹‹åï¼ŒLLM å°†æ— æ³•äº†è§£ä»»ä½•æ–°ç”Ÿæˆçš„æ•°æ®ã€‚ä¾‹å¦‚ï¼ŒOpenAI çš„ GPT-3.5-turbo-instruct LLM çš„è®­ç»ƒæˆªæ­¢æ—¥æœŸæ˜¯ 2021 å¹´ 9 æœˆï¼ˆå‚è€ƒï¼š[`platform.openai.com/docs/models/gpt-3-5-turbo`](https://platform.openai.com/docs/models/gpt-3-5-turbo)ï¼‰ï¼Œå› æ­¤ï¼ŒGPT-3.5-turbo-instruct LLM å¯èƒ½æ— æ³•å‡†ç¡®å›ç­” 2022 å¹´ã€2023 å¹´æˆ– 2024 å¹´çš„äº‹ä»¶ã€‚è¿™ç±»ä¸å±äº LLM åŸå§‹è®­ç»ƒæ•°æ®çš„æ•°æ®ç§°ä¸ºå¤–éƒ¨æ•°æ®ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡ä»æˆæƒçš„å¤–éƒ¨æ¥æºæ£€ç´¢ä¸è¾“å…¥æç¤ºç›¸å…³çš„é€‚å½“ä¿¡æ¯ï¼Œå¹¶å¢å¼ºè¾“å…¥ï¼Œä»¥ä¾¿ LLM èƒ½å¤Ÿç”Ÿæˆå‡†ç¡®ä¸”ç›¸å…³çš„å“åº”ã€‚å®é™…ä¸Šï¼ŒRAG æ„æˆäº† LLM ä¸å¤–éƒ¨æ•°æ®ä¹‹é—´çš„æ¡¥æ¢ã€‚è¿™ç§å¢å¼ºé¿å…äº†é‡æ–°è®­ç»ƒæˆ–è¿›ä¸€æ­¥å¾®è°ƒ LLM æ¨¡å‹çš„éœ€è¦ã€‚

## LLM çš„å…¸å‹æ“ä½œæ¨¡å¼

LLM æ˜¯è‡ªå›å½’çš„ï¼Œæ ¹æ®è¾“å…¥æç¤ºå°† token åŒ–çš„åºåˆ—ç”Ÿæˆä¸€ä¸ªæ–°çš„ tokenã€‚ä¸‹ä¸€ä¸ªæœ€ä½³ token çš„ç”Ÿæˆæ˜¯åŸºäºæ¦‚ç‡çš„ï¼Œå¯ä»¥è¡¨è¾¾ä¸ºä»¥ä¸‹å½¢å¼ï¼š

```py
P( Yn âˆ£ X0, X1, ... Xn-1, Î¸ )
```

æœ¬è´¨ä¸Šï¼Œæ–°ç”Ÿæˆçš„ç¬¬ n ä¸ª token Yn çš„æ¦‚ç‡æ˜¯åŸºäº n-1 ä¸ªå‰åº tokens X ä»¥åŠå­¦ä¹ åˆ°çš„æ¨¡å‹å‚æ•°Î¸çš„æ¦‚ç‡ã€‚è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtoken åŒ–çš„è¾“å…¥åºåˆ— X åœ¨ç”Ÿæˆä¸‹ä¸€ä¸ª token æ—¶èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚æ­¤å¤–ï¼Œè‡ªæ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆåœ°è¡¥å……äº†è‡ªå›å½’ï¼Œåœ¨è¿™ç§æœºåˆ¶ä¸‹ï¼Œåºåˆ—ä¸­çš„æ¯ä¸ªè¾“å…¥ token é€šè¿‡å…³æ³¨å¹¶åŠ æƒåºåˆ—ä¸­å…¶ä»– token çš„é‡è¦æ€§æ¥è®¡ç®—å…¶è¡¨ç¤ºã€‚è¿™ç§ token ä¹‹é—´å¤æ‚çš„å…³ç³»å’Œä¾èµ–æ€§ä½¿å¾— LLM èƒ½å¤Ÿè§£ç å‡ºä¸è¾“å…¥åºåˆ—ä¸­çš„ tokensâ€œå¥‘åˆâ€çš„ä¸‹ä¸€ä¸ªæœ€ä½³ tokenã€‚LLM å°†æ–°ç”Ÿæˆçš„ token é™„åŠ åˆ°ä¹‹å‰çš„ tokens ä¸Šï¼Œå½¢æˆæ–°çš„è¾“å…¥åºåˆ—ï¼Œå¹¶é‡å¤è‡ªå›å½’è¿‡ç¨‹ï¼Œç›´åˆ°æ»¡è¶³ç»“æŸæ¡ä»¶ï¼Œä¾‹å¦‚è¾¾åˆ°æœ€å¤§ token æ•°é‡ã€‚

è¿™ç§è‡ªæ³¨æ„åŠ›é©±åŠ¨çš„è‡ªå›å½’æ¨¡å‹æ„å‘³ç€ï¼ŒLLM ä¸»è¦ä¾èµ–äºè¾“å…¥åºåˆ—æ¥ç”Ÿæˆä¸‹ä¸€ä¸ªæœ€ä½³çš„ tokenã€‚åªè¦è¾“å…¥åºåˆ—é€šè¿‡è‡ªæ³¨æ„åŠ›å¸®åŠ©ç¡®å®šä¸‹ä¸€ä¸ªæœ€ä½³ tokenï¼ŒLLM å°±ä¼šç»§ç»­åœ¨ä¸€ä¸ªâ€œè‰¯æ€§â€å¾ªç¯ä¸­ç”Ÿæˆè¿è´¯ã€æ˜“ç†è§£ä¸”ç›¸å…³çš„è¾“å‡ºã€‚ç›¸åï¼Œå¦‚æœæç¤ºè¾“å…¥æ— æ³•å¸®åŠ©ç¡®å®šä¸‹ä¸€ä¸ªæœ€ä½³ tokenï¼ŒLLM å°†å¼€å§‹ä¾èµ–æ¨¡å‹å‚æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœæ¨¡å‹å·²ç»ç»è¿‡è¶³å¤Ÿçš„è®­ç»ƒï¼Œèƒ½å¤ŸåŒ…å«ä¸è¾“å…¥æç¤ºç›¸å…³çš„â€˜çŸ¥è¯†â€™ï¼Œå®ƒå¯èƒ½æˆåŠŸç”Ÿæˆä¸‹ä¸€ä¸ªæœ€ä½³ tokenã€‚ç›¸åï¼Œå¦‚æœæç¤ºè¾“å…¥æ¶‰åŠ LLM ä»æœªè®­ç»ƒè¿‡çš„â€˜å¤–éƒ¨æ•°æ®â€™ï¼Œæ¨¡å‹å¯èƒ½ä¼šè¿›å…¥ä¸€ä¸ªâ€˜æ¶æ€§â€™å¾ªç¯ï¼Œç”Ÿæˆä¸è¿è´¯ã€éš¾ä»¥ç†è§£ä¸”å¯èƒ½æ— å…³çš„è¾“å‡ºã€‚

æœ‰å¤šç§æŠ€æœ¯æ¥åº”å¯¹è¿™ä¸ªé—®é¢˜ã€‚æç¤ºå·¥ç¨‹å°±æ˜¯å…¶ä¸­ä¹‹ä¸€ï¼Œå…¶ç›®æ ‡æ˜¯é€šè¿‡è°ƒæ•´æç¤ºæ¥è§£å†³â€˜ç¼ºå¤±çš„ä¸Šä¸‹æ–‡â€™ï¼Œä»¥å¢å¼ºä¸Šä¸‹æ–‡ï¼Œä½¿å¾— LLM å¯ä»¥ç”Ÿæˆç›¸å…³çš„è¾“å‡ºã€‚RAG æ˜¯å¦ä¸€ç§æŠ€æœ¯ï¼Œå…¶ç›®æ ‡æ˜¯é€šè¿‡ä»å¤–éƒ¨æ•°æ®æºè‡ªåŠ¨æ£€ç´¢ä¸è¾“å…¥æç¤ºç›¸å…³çš„æœ€åˆé€‚ä¿¡æ¯ï¼Œå¹¶å¢å¼ºæç¤ºï¼Œä¸“é—¨è§£å†³ç”±äºâ€˜å¤–éƒ¨æ•°æ®â€™ç¼ºå¤±çš„ä¸Šä¸‹æ–‡ã€‚

## RAG çš„æŒ‘æˆ˜

RAG çš„ä¸»è¦èŒè´£æ˜¯ä»å¤–éƒ¨æ•°æ®æºï¼ˆå¦‚ä¿¡æ¯æ•°æ®åº“ã€API å’Œå…¶ä»–æ–‡æ¡£åº“ï¼Œå¦‚ç»´åŸºç™¾ç§‘ï¼‰ä¸­æœç´¢å¹¶æ£€ç´¢ä¸è¾“å…¥æç¤ºç›¸å…³çš„ä¸Šä¸‹æ–‡æ•°æ®ã€‚ç®€å•çš„å…³é”®è¯æœç´¢æ˜¯ä¸å¤Ÿçš„ï¼Œè€Œæ˜¯éœ€è¦è¿›è¡Œè¯­ä¹‰æœç´¢ã€‚ä¸ºäº†ä¿ƒè¿›è¯­ä¹‰æœç´¢ï¼Œä»å¤–éƒ¨æºæ£€ç´¢çš„æ–‡æœ¬ä¿¡æ¯ä¼šè¢«è½¬åŒ–ä¸ºæ•°å€¼è¡¨ç¤ºæˆ–å‘é‡ï¼Œé€šå¸¸ç§°ä¸ºæ–‡æœ¬åµŒå…¥ï¼Œå¹¶å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ã€‚å­˜åœ¨å¤šç§æ¨¡å‹æˆ–ç®—æ³•ç”¨äºä»æ–‡æœ¬ä¸­åˆ›å»ºè¿™äº›åµŒå…¥ã€‚é¦–å…ˆå°†æç¤ºè½¬åŒ–ä¸ºå…¶å‘é‡è¡¨ç¤ºï¼Œä»¥ä¾¿æœç´¢å’Œæ£€ç´¢æœ€æ¥è¿‘çš„å¤–éƒ¨æ•°æ®å‘é‡ã€‚ç„¶åè®¡ç®—æç¤ºå‘é‡ä¸å…ˆå‰å­˜å‚¨çš„å¤–éƒ¨æ•°æ®å‘é‡ä¹‹é—´çš„å‘é‡ç›¸ä¼¼åº¦ï¼ˆæˆ–å‘é‡è·ç¦»ï¼‰ã€‚æ ¹æ®ç›¸ä¼¼åº¦æ’åºå¹¶ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤æœ€ç›¸ä¼¼æˆ–æœ€è¿‘çš„å‘é‡ï¼Œæœ€ç»ˆæ£€ç´¢ç›¸åº”çš„æ–‡æœ¬ä¿¡æ¯ä»¥å¢å¼ºæç¤ºçš„ä¸Šä¸‹æ–‡ã€‚ä»¥ä¸‹æ¦‚å¿µå›¾å±•ç¤ºäº†å¯ç”¨ RAG æ—¶ä¸åŒç»„ä»¶ä¹‹é—´çš„å…¸å‹äº¤äº’ï¼š

![](img/b2ae4ffe86cb15e19dafd2de1bbfbf70.png)

å¯ç”¨ RAG çš„ä¸»è¦ç³»ç»Ÿç»„ä»¶äº¤äº’çš„æ¦‚å¿µè§†å›¾ â€” ä½œè€…æä¾›çš„å›¾ç‰‡

RAG é¢ä¸´çš„æŒ‘æˆ˜æ˜¯ï¼Œè¿›è¡ŒåŸºäºå‘é‡çš„è¯­ä¹‰æœç´¢å¹¶éç®€å•ä»»åŠ¡ï¼Œä¸”éœ€è¦å¤§é‡è®¡ç®—èµ„æºï¼Œå› ä¸ºå®ƒæ¶‰åŠåˆ°å¯¹å¯èƒ½æ˜¯åºå¤§æ•°æ®åº“ä¸­å¤§é‡å‘é‡è¿›è¡Œç›¸ä¼¼åº¦æˆ–è·ç¦»è®¡ç®—ã€‚å¯¹äºæ¯ä¸€ä¸ªè¾“å…¥æç¤ºï¼Œä»åºå¤§çš„å‘é‡æ•°æ®åº“ä¸­è®¡ç®—æ¯ä¸ªå­˜å‚¨å‘é‡çš„ç›¸ä¼¼åº¦æˆ–è·ç¦»å°†å˜å¾—ä¸å¯è¡Œã€‚è€Œä¸”ï¼Œè¯­ä¹‰åŒ¹é…è´¨é‡è¶Šä½ï¼ŒLLM çš„ç”Ÿæˆè¾“å‡ºè´¨é‡ä¹Ÿè¶Šä½ã€‚å› æ­¤ï¼Œæ‰¾åˆ°ä¸€ç§é«˜æ•ˆè¿›è¡Œè¯­ä¹‰æœç´¢çš„æ–¹æ³•å˜å¾—è‡³å…³é‡è¦ã€‚

## è§£å†³æ–¹æ¡ˆ

ä¸ºäº†è¿›è¡Œé«˜æ•ˆçš„è¯­ä¹‰æœç´¢ï¼Œé‡‡ç”¨äº†å‡ ç§ç®—æ³•è§£å†³æ–¹æ¡ˆã€‚è¿™äº›ç®—æ³•çš„å…¸å‹æ–¹æ³•æ˜¯å°†å¤–éƒ¨æ•°æ®å‘é‡æŒ‰æœ€è¿‘é‚»è¿›è¡Œåˆ†ç»„æˆ–èšç±»ï¼Œå¹¶é€šè¿‡æ˜ å°„åˆ°è¿™äº›èšç±»æ¥è¿›è¡Œç´¢å¼•ã€‚å¤§å¤šæ•°å‘é‡æ•°æ®åº“æä¾›äº†è¿™ç§å†…å»ºçš„ç´¢å¼•åŠŸèƒ½ã€‚åœ¨è¯­ä¹‰æœç´¢è¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆä¼šè¯„ä¼°è¾“å…¥æç¤ºå‘é‡ä¸åŒ¹é…åˆ°çš„èšç±»ã€‚å¯¹äºæ¯ä¸ªè¯„ä¼°è¿‡çš„èšç±»ï¼Œé€‰æ‹©ç›¸åº”çš„ç´¢å¼•å‘é‡ã€‚ç„¶åè®¡ç®—è¾“å…¥æç¤ºå‘é‡ä¸æ‰€é€‰å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚æ­¤å¤„çš„é¢„æœŸæ˜¯ï¼Œé€šè¿‡æ‰¾åˆ°â€œæœ€è¿‘é‚»â€ä½œä¸ºä¸€ä¸ªä¸­é—´æ­¥éª¤ï¼Œæ˜¾è‘—å‡å°‘äº†ç›¸ä¼¼åº¦è®¡ç®—çš„æ¬¡æ•°ã€‚æœ€åï¼Œä¾æ®é˜ˆå€¼è¿‡æ»¤ï¼Œé€šè¿‡ç›¸ä¼¼åº¦æœ€é«˜æˆ–æœ€è¿‘çš„å‘é‡æ¥æ£€ç´¢ç›¸åº”çš„æ–‡æœ¬ä¿¡æ¯ã€‚åƒ k-æœ€è¿‘é‚»ã€åŠå¾„çƒä½“ Rã€å±€éƒ¨æ•æ„Ÿå“ˆå¸Œã€DBSCAN èšç±»ã€æ ‘çŠ¶å±‚æ¬¡ç»“æ„å’Œå›¾çŠ¶å±‚æ¬¡ç»“æ„ç­‰ç®—æ³•ï¼Œé€šå¸¸ç”±å‘é‡æ•°æ®åº“å®ç°ï¼Œç”¨ä»¥ä¿ƒè¿›è¯­ä¹‰æœç´¢ã€‚

æ²¡æœ‰ä¸€ç§é€‚ç”¨äºæ‰€æœ‰æƒ…å†µçš„è§£å†³æ–¹æ¡ˆï¼Œå› ä¸ºä¸åŒç±»å‹çš„ç®—æ³•åœ¨å†…å­˜æ•ˆç‡ã€è®¡ç®—æ•ˆç‡ã€å»¶è¿Ÿã€å‡†ç¡®æ€§ã€å‘é‡ç»´åº¦ã€æ•°æ®é›†å¤§å°ç­‰æ–¹é¢æœ‰ä¸åŒçš„æƒè¡¡ã€‚ä¾‹å¦‚ï¼Œèšç±»æ–¹æ³•é€šè¿‡ç¼©å°è¯­ä¹‰æœç´¢çš„å‘é‡ç©ºé—´æ¥æé«˜é€Ÿåº¦ï¼Œè€Œç±»ä¼¼æ ‘å½¢æˆ–å›¾å½¢çš„æ–¹æ³•åˆ™ä¸ºä½ç»´å‘é‡æ•°æ®æä¾›æ›´é«˜çš„å‡†ç¡®æ€§ã€‚

## è‡ªç»„ç»‡æ˜ å°„

è‡ªç»„ç»‡æ˜ å°„ï¼ˆSOMï¼‰æ˜¯ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„é™ç»´ç®—æ³•ï¼Œç”± Teuvo Kohonen åœ¨ 1980 å¹´ä»£å¼€å‘ã€‚å®ƒé€šå¸¸ç”¨äºå°†é«˜ç»´ç‰¹å¾å‘é‡é™è‡³ä½ç»´ï¼ˆé€šå¸¸æ˜¯äºŒç»´ï¼‰ç‰¹å¾å‘é‡ã€‚SOM çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†é«˜ç»´æ•°æ®å‘é‡è¡¨ç¤ºä¸ºä½ç»´ç©ºé—´ä¸­çš„ç‰¹å®šèŠ‚ç‚¹ï¼ŒåŒæ—¶ä¿ç•™å‘é‡åœ¨åŸå§‹ç©ºé—´ä¸­çš„æ‹“æ‰‘ç»“æ„ã€‚ä½ç»´ç©ºé—´ä¸­çš„èŠ‚ç‚¹æ•°é‡ï¼ˆSOM èŠ‚ç‚¹ï¼‰æ˜¯å›ºå®šçš„ï¼ˆè¶…å‚æ•°ï¼‰ã€‚SOM èŠ‚ç‚¹çš„ç²¾ç¡®ä½ç½®é€šè¿‡å¤šä¸ªè®­ç»ƒå‘¨æœŸæ¥è¯„ä¼°ã€‚è¿­ä»£è®­ç»ƒçš„ç›®æ ‡æ˜¯è°ƒæ•´ SOM èŠ‚ç‚¹åœ¨ä½ç»´ç©ºé—´ä¸­çš„ä½ç½®ï¼Œä½¿å…¶æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´ä¸­æœ€é‚»è¿‘çš„å‘é‡ã€‚æ¢å¥è¯è¯´ï¼Œç›®æ ‡æ˜¯å°†é«˜ç»´ç©ºé—´ä¸­æœ€è¿‘é‚»çš„å‘é‡æ˜ å°„åˆ°ä½ç»´ç©ºé—´ä¸­ä¹Ÿä¸ºæœ€è¿‘é‚»çš„ SOM èŠ‚ç‚¹ã€‚

## SOM ç”¨äº RAG

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æƒ³åˆ†äº«æˆ‘åœ¨å®éªŒä¸­å¯¹ SOM çš„ç¬”è®°å’Œå‘ç°ï¼Œä½œä¸ºä¸€ç§æ¨åŠ¨ RAG è¯­ä¹‰æœç´¢çš„å¯èƒ½ç®—æ³•ã€‚SOM ç›¸æ¯”å…¶ä»–ç®—æ³•å¯èƒ½ç†æƒ³çš„ä¸‰ä¸ªå…³é”®åŸå› æ˜¯ï¼š

1.  å‘é‡çš„é«˜ç»´åº¦å¯èƒ½æˆä¸ºå¤§å¤šæ•°å…¶ä»–ç®—æ³•çš„ç“¶é¢ˆï¼Œä¾‹å¦‚æ ‘å’Œå›¾â€”â€”è¿™å°±æ˜¯æ‰€è°“çš„ç»´åº¦ç¾éš¾ã€‚ç›¸åï¼ŒSOM æ˜¯ä¸ºé™ç»´è€Œè®¾è®¡çš„ï¼Œå› æ­¤å®ƒå¯ä»¥åœ¨é«˜ç»´å’Œä½ç»´åœºæ™¯ä¸­æœ‰æ•ˆåº”ç”¨ã€‚

1.  SOM å¯¹å¯èƒ½æ¸—å…¥åŸå§‹é«˜ç»´å‘é‡ç©ºé—´çš„éšæœºå˜åŒ–ä¸å¤ªæ•æ„Ÿï¼Œä»è€Œé¿å…äº†å™ªéŸ³çš„å½±å“ã€‚å…¶ä»–ç®—æ³•å¯èƒ½å¯¹è¿™äº›å™ªéŸ³æ•æ„Ÿï¼Œä»è€Œå½±å“å®ƒä»¬å°†é«˜ç»´å‘é‡èšç±»æˆ–åˆ†ç»„ä¸ºæœ€è¿‘é‚»çš„æ–¹å¼ã€‚ç”±äº SOM åœ¨ä½ç»´å‘é‡ç©ºé—´ä¸­ä½¿ç”¨ä¸­é—´çš„ SOM èŠ‚ç‚¹ï¼Œè¿™äº›èŠ‚ç‚¹è¢«è¯„ä¼°ä¸ºæ˜ å°„è‡ªé«˜ç»´ç©ºé—´å‘é‡çš„å±€éƒ¨å¹³å‡å€¼ï¼Œå› æ­¤å®ƒæœ‰æ•ˆåœ°å‡å°‘äº†å™ªéŸ³ã€‚

1.  å¤–éƒ¨æ•°æ®é›†çš„åºå¤§è§„æ¨¡å¯èƒ½ä¼šé™åˆ¶å…¶ä»–ç®—æ³•åœ¨åˆ›å»ºè¯­ä¹‰å‘é‡ç©ºé—´æ—¶çš„è¡¨ç°ï¼Œè¿™å¯èƒ½ä¼šå½±å“è¯­ä¹‰åŒ¹é…çš„å»¶è¿Ÿå’Œå‡†ç¡®æ€§ã€‚å¦ä¸€æ–¹é¢ï¼ŒSOM èƒ½å¤Ÿå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå› ä¸ºä½ç»´ç©ºé—´ä¸­çš„ SOM èŠ‚ç‚¹æ•°é‡å¯ä»¥é€šè¿‡ä¸åº•å±‚æ•°æ®é›†å¤§å°æˆæ¯”ä¾‹çš„è¶…å‚æ•°æ¥ç²¾ç»†è°ƒæ•´ã€‚å°½ç®¡ä½¿ç”¨å¤§æ•°æ®é›†è®­ç»ƒ SOM å¯èƒ½éœ€è¦æ›´é•¿çš„æ—¶é—´ï¼Œä½†è®­ç»ƒå®Œæˆåï¼ŒæŸ¥è¯¢æ˜ å°„ä»ç„¶ä¼šæ›´å¿«ã€‚

æˆ‘å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œä½¿ç”¨ SOM æ¥è¿›è¡Œ RAG çš„è¯­ä¹‰æœç´¢ï¼Œä»¥å¢å¼ºåŸºäº OpenAI GPT-3.5-turbo-instruct LLM çš„é—®ç­”ä¸Šä¸‹æ–‡ã€‚ä½¿ç”¨ OpenAI GPT-3.5-turbo-instruct LLM çš„ä¸»è¦åŸå› æ˜¯å› ä¸º OpenAI GPT-3.5-turbo-instruct LLM çš„è®­ç»ƒæˆªæ­¢æ—¥æœŸä¸º 2021 å¹´ 9 æœˆï¼ˆå‚è€ƒï¼š[`platform.openai.com/docs/models/gpt-3-5-turbo`](https://platform.openai.com/docs/models/gpt-3-5-turbo)ï¼‰ï¼Œå› æ­¤ï¼ŒGPT-3.5-turbo-instruct LLM å¯èƒ½æ— æ³•å‡†ç¡®å›ç­” 2022 å¹´ã€2023 å¹´æˆ– 2024 å¹´çš„äº‹ä»¶é—®é¢˜ã€‚å› æ­¤ï¼Œå…³äº 2022 å¹´ã€2023 å¹´æˆ– 2024 å¹´çš„äº‹ä»¶ä¿¡æ¯å¯èƒ½æˆä¸º OpenAI GPT-3.5-turbo-instruct LLM çš„â€œå¤–éƒ¨æ•°æ®â€ã€‚æˆ‘ä½¿ç”¨äº† Wikipedia API ä½œä¸ºè¿™ç§â€œå¤–éƒ¨æ•°æ®â€çš„æ¥æºï¼Œæ¥è·å–äº‹ä»¶ä¿¡æ¯ã€‚ä»¥ä¸‹æ˜¯æˆ‘ç”¨æ¥å¼€å‘å’Œè®­ç»ƒç¤ºä¾‹çš„æ­¥éª¤ï¼Œä»¥åŠç¤ºä¾‹ä»£ç ã€‚

## ç¬¬ä¸€æ­¥ï¼šåŸºäº PyTorch çš„ Kohonen SOM å®ç°

æˆ‘ä½¿ç”¨äº† PyTorch å¼ é‡æ¥è¡¨ç¤ºå‘é‡ï¼Œå¹¶ä½¿ç”¨ PyTorch å®ç°äº† Kohonen çš„ SOMã€‚è¯¥ç®—æ³•ä½¿ç”¨ä¸€ä¸ªäºŒç»´æ ¼å­ï¼Œå…¶å¤§å°æˆä¸ºä¸€ä¸ªè¶…å‚æ•°ã€‚ç®—æ³•çš„æ•°å­¦æ–¹é¢æ¥æºäºä»¥ä¸‹æ–‡ç« ä¸­çš„æ¸…æ™°è§£é‡Šï¼š

[](http://www.ai-junkie.com/ann/som/som1.html?source=post_page-----5d739ce21e9c--------------------------------) [## SOM æ•™ç¨‹ç¬¬ä¸€éƒ¨åˆ†

### ç¥ç»ç½‘ç»œæ•™ç¨‹ï¼ˆé€šä¿—æ˜“æ‡‚ï¼‰

www.ai-junkie.com](http://www.ai-junkie.com/ann/som/som1.html?source=post_page-----5d739ce21e9c--------------------------------)

ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº† Kohonen SOM çš„ Python ç±»ã€‚å®Œæ•´ä»£ç å¯åœ¨[è¿™ä¸ª GitHub é“¾æ¥](https://github.com/kbmurali/som-driven-qa-rag/blob/main/kohonen_som.py)æ‰¾åˆ°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªå®ç°æ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤å¯ä»¥åœ¨ RAG ç¤ºä¾‹ä¹‹å¤–ä½¿ç”¨ã€‚

```py
class KohonenSOM():
    """
    The code is developed based on the following article:
    http://www.ai-junkie.com/ann/som/som1.html

    The vector and matrix operations are developed using PyTorch Tensors.
    """
    def __init__( ... )
    ...
    def find_topk_best_matching_units( self, data_points : torch.Tensor, topk : int = 1 ) -> List[ List[ int ] ] :
        if len( data_points.size() ) == 1:
            #batching 
            data_points = data_points.view( 1, data_points.shape[0] )

        topk = int( topk )

        distances = self.dist_evaluator( data_points, self.lattice_node_weights )

        topk_best_matching_unit_indexes = torch.topk( distances, topk, dim=1, largest=False ).indices
        topk_best_matching_units = []

        for i in range( data_points.shape[0] ):
            best_matching_unit_indexes = topk_best_matching_unit_indexes[i]
            best_matching_units = [ self.lattice_coordinates[ bmu_index.item() ].tolist() for bmu_index in best_matching_unit_indexes ]
            topk_best_matching_units.append( best_matching_units )

        return topk_best_matching_units
```

## ç¬¬äºŒæ­¥ï¼šåŸºäº SOM çš„å‘é‡ç´¢å¼•å™¨å®ç°

å‘é‡ç´¢å¼•å™¨æ˜¯ä¸€ä¸ªå·¥å…·ï¼Œåˆ©ç”¨ Kohonen çš„ SOM æ¥è®­ç»ƒ SOM èŠ‚ç‚¹ï¼Œä½¿ç”¨æ¥è‡ªå¤–éƒ¨æ•°æ®é›†çš„æ•°æ®å‘é‡ã€‚å…¶ä¸»è¦ç›®çš„æ˜¯å°†æ¯ä¸ªæ•°æ®å‘é‡æ˜ å°„åˆ°æœ€æ¥è¿‘çš„ top-k SOM èŠ‚ç‚¹ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æ•°æ®å‘é‡ç´¢å¼•ã€‚ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†å‘é‡ç´¢å¼•å™¨ Python ç±»çš„è®­ç»ƒå’Œç´¢å¼•åŠŸèƒ½ã€‚å…¶å®Œæ•´ä»£ç å¯åœ¨[è¿™ä¸ª GitHub é“¾æ¥](https://github.com/kbmurali/som-driven-qa-rag/blob/main/vector_indexer.py)æ‰¾åˆ°ã€‚å°½ç®¡å…¶å®ç°ç›®å‰ä»…é™äºç¤ºä¾‹çš„éœ€æ±‚ï¼Œä½†å¯ä»¥æ‰©å±•ä»¥æ»¡è¶³å…¶ä»–éœ€æ±‚ã€‚

```py
class SOMBasedVectorIndexer():
    ...

    def train_n_gen_indexes( 
                                self, input_vectors : torch.Tensor, 
                                train_epochs : int = 100 
                           ):
        if self.generated_indexes:
            print( "WARNING: Indexes were already generated. Ignoring the request..." )
            return

        self.som.train( input_vectors, train_epochs )

        topk_bmu_indexes = self.som.find_topk_best_matching_units( input_vectors, topk = self.topk_bmu_for_indexing )

        for idx in tqdm( range( len( topk_bmu_indexes ) ), desc="SOM-Based Indexed Vectors"  ):
            bmu_indexes = topk_bmu_indexes[ idx ]

            for bmu_index in bmu_indexes:
                bmu_index_key = tuple( bmu_index )
                idx_set = self.som_node_idx_map.get( bmu_index_key, set() )
                idx_set.add( idx )
                self.som_node_idx_map[ bmu_index_key ] = idx_set

        self.generated_indexes = True
```

## ç¬¬ä¸‰æ­¥ï¼šåŸºäº OpenAI åµŒå…¥çš„æ–‡æœ¬åˆ°å‘é‡ç¼–ç å™¨

ç¼–ç å™¨çš„ä¸»è¦åŠŸèƒ½æ˜¯ä½¿ç”¨ OpenAI çš„æ–‡æœ¬åµŒå…¥ API å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨åµŒå…¥ API éœ€è¦ä¸€ä¸ª OpenAI å¸æˆ·å’Œ API å¯†é’¥ã€‚åœ¨é¦–æ¬¡å¼€é€šè´¦æˆ·æ—¶ï¼ŒOpenAI ä¼šæä¾›å…è´¹çš„ä¿¡ç”¨é¢åº¦ï¼Œè¶³ä»¥ç”¨äº API æµ‹è¯•ã€‚ä»¥ä¸‹æ˜¯å±•ç¤º OpenAI ç¼–ç å™¨ Python ç±»çš„æ‰¹é‡ç¼–ç åŠŸèƒ½çš„ä»£ç ç‰‡æ®µï¼Œå®Œæ•´ä»£ç å¯åœ¨[è¿™ä¸ª GitHub ä½ç½®](https://github.com/kbmurali/som-driven-qa-rag/blob/main/openai_vector_encoder.py)æ‰¾åˆ°ã€‚

```py
import openai
from openai.embeddings_utils import get_embedding
...
from vector_encoder_parent import VectorEncoder
...

class OpenAIEmbeddingsVectorEncoder( VectorEncoder ):
    def __init__( ... )
    ...
    def encode_batch( self, list_of_text : List[ str ] ) -> torch.Tensor :
        if list_of_text == None or len( list_of_text ) == 0:
            raise ValueError( "ERROR: Required list_of_text is None or empty" )

        list_of_text = [ str( text ) for text in list_of_text ]

        openai.api_key = self.openai_key
        response = openai.Embedding.create(
                                            input = list_of_text,
                                            engine = self.vector_encoder_id
                                          )

        embeddings = [ data["embedding"] for data in response["data"] ] 
        vectors = torch.tensor( embeddings, dtype=torch.float )
        return vectors
```

è¯·æ³¨æ„ï¼ŒOpenAI å‘é‡ç¼–ç å™¨ç±»æ‰©å±•äº†ä¸€ä¸ªé€šç”¨çš„çˆ¶ç±»â€˜VectorEncoderâ€™ï¼Œè¯¥çˆ¶ç±»å®šä¹‰äº†æŠ½è±¡çš„ç¼–ç å‡½æ•°ï¼Œéœ€é€šè¿‡ç»§æ‰¿æ¥å®ç°ã€‚å¯ä»¥é€šè¿‡ç»§æ‰¿è¯¥çˆ¶ç±»å®ç°å…¶ä»–ç±»å‹çš„å‘é‡ç¼–ç å™¨ï¼Œä»è€Œå®ç°å…¶ä»–ç¼–ç æ–¹æ¡ˆçš„æ’ä»¶åŒ–ã€‚çˆ¶å‘é‡ç¼–ç å™¨ç±»çš„å®Œæ•´ä»£ç å¯ä»¥åœ¨[è¿™ä¸ª GitHub ä½ç½®](https://github.com/kbmurali/som-driven-qa-rag/blob/main/vector_encoder_parent.py)æ‰¾åˆ°ã€‚

## æ­¥éª¤ 4ï¼šåŸºäº Wikipedia API çš„æ•°æ®æºå®ç°

è¿™ä¸ªå·¥å…·ç±»æ—¨åœ¨å°è£…ä¸ Wikipedia API é›†æˆçš„æ•°æ®æ£€ç´¢é€»è¾‘ã€‚å®ƒçš„ä¸»è¦åŠŸèƒ½æ˜¯è·å–æŒ‡å®šæ—¥å†å¹´ä»½èŒƒå›´å†…çš„äº‹ä»¶ï¼Œæ ¼å¼åŒ–æ£€ç´¢åˆ°çš„äº‹ä»¶ï¼Œå¹¶å°†å®ƒä»¬åŠ è½½åˆ° Pandas æ•°æ®æ¡†ä¸­ã€‚ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†è¯¥å·¥å…·ç±»çš„ä¸»è¦åŠŸèƒ½ï¼Œå®Œæ•´ä»£ç å¯ä»¥åœ¨[è¿™ä¸ª GitHub ä½ç½®](https://github.com/kbmurali/som-driven-qa-rag/blob/main/wiki_datasource.py)æ‰¾åˆ°ã€‚

```py
import requests
import pandas as pd
from dateutil.parser import parse
...
class WikiEventsDataSource():
    ...
    def fetch_n_prepare_data( self ):
        if self.fetched:
            print( "WARNING: Wiki events for the specified years already fetched. Ignoring the request..." )
            return

        main_df = pd.DataFrame()

        for year in self.event_years_to_fetch:
            wiki_api_params = {
                                "action": "query", 
                                "prop": "extracts",
                                "exlimit": 1,
                                "titles": year,
                                "explaintext": 1,
                                "formatversion": 2,
                                "format": "json"
                              }

            response = requests.get( "https://en.wikipedia.org/w/api.php", params=wiki_api_params )
            response_dict = response.json()

            df = pd.DataFrame()
            df[ "text" ] = response_dict["query"]["pages"][0]["extract"].split("\n")
            df = self.__clean_df__( df, year )

            main_df = pd.concat( [ main_df, df ] )

        self.df = main_df.reset_index(drop=True)
        self.fetched = True
```

## æ­¥éª¤ 5ï¼šåŸºäº SOM çš„ RAG å·¥å…·å®ç°

åŸºäº SOM çš„ RAG å·¥å…·æ˜¯ç¤ºä¾‹å®ç°ä¸­çš„ä¸€ä¸ªå…³é”®å…ƒç´ ã€‚å®ƒåˆ©ç”¨å‘é‡ç¼–ç å™¨ã€ç´¢å¼•å™¨å’Œæ•°æ®æºå®ç°åº•å±‚è¯­ä¹‰æœç´¢çš„æ ¸å¿ƒé€»è¾‘ã€‚åŸºäº SOM çš„ RAG å·¥å…·çš„å®Œæ•´ä»£ç å¯ä»¥åœ¨[è¿™ä¸ª GitHub ä½ç½®](https://github.com/kbmurali/som-driven-qa-rag/blob/main/som_based_rag.py)æ‰¾åˆ°ã€‚

è¯¥å·¥å…·å®ç°äº†ä¸‰ä¸ªä¸»è¦åŠŸèƒ½ã€‚ç¬¬ä¸€ä¸ªåŠŸèƒ½æ˜¯ä»å¤–éƒ¨æ•°æ®æºåŠ è½½æ•°æ®å¹¶å°†å…¶ç¼–ç ä¸ºå‘é‡ï¼Œå¦‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µæ‰€ç¤ºã€‚

```py
...
from vector_encoder_parent import VectorEncoder
from vector_indexer import SOMBasedVectorIndexer

class SOM_Based_RAG_Util():
    ...
    def load_n_vectorize_data( self, data_source ):
        if self.data_loaded_n_vectorized:
            print( "WARNING: Data already loaded and vectorized. Ignoring the request..." )
            return

        data_source.fetch_n_prepare_data()
        self.df = data_source.get_data()

        vectors = None

        for i in tqdm( range(0, len(self.df), self.vectorize_batch_size ), desc="Vectorized Data Batch" ):
            list_of_text = self.df.iloc[ i:i+self.vectorize_batch_size ]["text"].tolist()
            batch_encoded_vectors = self.vector_encoder.encode_batch( list_of_text )

            if vectors == None:
                vectors = batch_encoded_vectors
            else:
                vectors = torch.cat( [ vectors, batch_encoded_vectors], dim=0 )

        self.vectors = vectors.to( self.device )
        self.data_loaded_n_vectorized = True
```

ç¬¬äºŒä¸ªåŠŸèƒ½æ˜¯è®­ç»ƒåŸºäº SOM çš„ç´¢å¼•å™¨ï¼Œæ„å»º Kohonen çš„ SOM èŠ‚ç‚¹ï¼Œç„¶åå¯¹æ•°æ®å‘é‡è¿›è¡Œç´¢å¼•ï¼Œå¦‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µæ‰€ç¤ºã€‚

```py
def train_n_index_data_vectors( self, train_epochs : int = 100  ):
        if not self.data_loaded_n_vectorized:
            raise ValueError( "ERROR: Data not loaded and vectorized." )

        if self.data_vectors_indexed:
            print( "WARNING: Data vectors already indexed. Ignoring the request..." )
            return

        self.vector_indexer.train_n_gen_indexes( self.vectors, train_epochs )
        self.data_vectors_indexed = True
```

ç¬¬ä¸‰ä¸ªåŠŸèƒ½æ˜¯åŸºäºæŸ¥è¯¢æ–‡æœ¬ä»å…ˆå‰å­˜å‚¨çš„å¤–éƒ¨æ•°æ®é›†æ‰¾åˆ°ç›¸ä¼¼çš„ä¿¡æ¯ã€‚è¯¥åŠŸèƒ½ä½¿ç”¨ç¼–ç å™¨å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œç„¶åé€šè¿‡åŸºäº SOM çš„ç´¢å¼•å™¨æœç´¢æœ€å¯èƒ½çš„åŒ¹é…é¡¹ã€‚æ¥ç€ï¼Œä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æˆ–å…¶ä»–æŒ‡å®šçš„ç›¸ä¼¼åº¦è¯„ä¼°å™¨è®¡ç®—æŸ¥è¯¢å‘é‡ä¸å‘ç°çš„æ•°æ®å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚æœ€åï¼Œè¯¥åŠŸèƒ½ç­›é€‰å‡ºä¸æŒ‡å®šç›¸ä¼¼åº¦é˜ˆå€¼å¤§äºæˆ–ç­‰äºçš„ç›¸ä¼¼åº¦çš„æ•°æ®å‘é‡ã€‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µå±•ç¤ºäº†è¯¥åŠŸèƒ½çš„å®ç°ã€‚

```py
def find_semantically_similar_data( self, query: str, sim_evaluator = None, sim_threshold : float = 0.8  ):
        if not self.data_vectors_indexed:
            raise ValueError( "ERROR: Data vectors not indexed." )

        if query == None or len( query.strip() ) == 0:
            raise ValueError( "ERROR: Required query text is not specified." )

        sim_threshold = float( sim_threshold )

        if sim_evaluator == None:
            sim_evaluator = nn.CosineSimilarity(dim=0, eps=1e-6)

        query_vector = self.vector_encoder.encode( query )
        query_vector = query_vector.view( self.vector_encoder.get_encoded_vector_dimensions() )
        query_vector = query_vector.to( self.device )

        nearest_indexes = self.vector_indexer.find_nearest_indexes( query_vector )
        nearest_indexes = nearest_indexes[0]

        sim_scores = []

        for idx in nearest_indexes:
            data_vector = self.vectors[ idx ]
            data_vector = data_vector.view( self.vector_encoder.get_encoded_vector_dimensions() )

            sim_score = sim_evaluator( query_vector, data_vector )

            if sim_score >= sim_threshold:
                sim_score_tuple = (idx, sim_score.item() )
                sim_scores.append( sim_score_tuple )

        sim_scores.sort( key = lambda x: x[1], reverse=True )

        semantically_similar_data = [ 
                                        { 
                                            'text': self.df[ 'text' ][ idx ],
                                            'sim_score' : sim_score
                                        } for idx, sim_score in sim_scores
                                    ]

        return semantically_similar_data
```

ä»¥ä¸‹æ˜¯é€šè¿‡åŸºäº SOM çš„ RAG å®ç”¨å‡½æ•°è¿›è¡Œè¯­ä¹‰æœç´¢çš„ç¤ºä¾‹è¾“å‡ºï¼š

![](img/0495dc8a7325e42a26216f4edea1b957.png)

ä¸€ä¸ªç¤ºä¾‹çš„è¯­ä¹‰æœç´¢è¾“å‡ºâ€”â€”ä½œè€…æä¾›çš„å›¾åƒ

## ç¬¬ 6 æ­¥ï¼šæŠ½è±¡é—®é¢˜/å›ç­”èŠå¤©æœºå™¨äººåŠå…¶åŸºäº OpenAI çš„å®ç°

ä¸€ä¸ªæŠ½è±¡çš„â€˜QuestionAnswerChatBotâ€™ Python ç±»è¢«å¼€å‘å‡ºæ¥ï¼Œä»¥ä¾¿äºç±»ä¼¼èŠå¤©æœºå™¨äººçš„å®ç°ã€‚å®ƒé€šè¿‡ä½¿ç”¨æ ‡å‡†çš„æŒ‡ä»¤æ¨¡æ¿ï¼Œå¹¶ç”¨ä» RAG å®ç”¨å·¥å…·ä¸­æ£€ç´¢åˆ°çš„è¯­å¢ƒç›¸ä¼¼ä¿¡æ¯å¡«å……å®ƒï¼Œæ¥å¢å¼ºé—®é¢˜æç¤ºã€‚

æŒ‡å®šçš„æœ€å¤§æ–°æ ‡è®°æ•°é™åˆ¶äº†ä¸Šä¸‹æ–‡å¢å¼ºçš„æ–‡æœ¬å¤§å°ï¼Œè€Œæ ‡è®°è®¡æ•°åˆ™æ¨è¿Ÿåˆ°åº•å±‚å®ç°ã€‚åœ¨ LLM ç»æµå­¦ä¸­ï¼Œæ ‡è®°å°±åƒè´§å¸ä¸€æ ·ã€‚æ¨¡å‹å¤„ç†çš„æ¯ä¸€ä¸ªæ ‡è®°éƒ½éœ€è¦è®¡ç®—èµ„æºâ€”â€”å†…å­˜ã€å¤„ç†èƒ½åŠ›å’Œæ—¶é—´ã€‚å› æ­¤ï¼ŒLLM éœ€è¦å¤„ç†çš„æ ‡è®°è¶Šå¤šï¼Œè®¡ç®—æˆæœ¬å°±è¶Šé«˜ã€‚

æœ€åï¼Œä¸€æ—¦é—®ç­”æŒ‡ä»¤è¢«å¡«å……ï¼Œè¯¥ç±»ä¼šå°† LLM æ¨¡å‹çš„æç¤ºå·¥ä½œå§”æ‰˜ç»™åº•å±‚å®ç°ã€‚ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†ä¸»è¦åŠŸèƒ½ï¼›å®Œæ•´ä»£ç å¯ä»¥åœ¨[è¿™ä¸ª GitHub ä½ç½®](https://github.com/kbmurali/som-driven-qa-rag/blob/main/qa_chatbot.py)æ‰¾åˆ°ã€‚

```py
from abc import ABC, abstractmethod
import torch
import math

class QuestionAnswerChatBot( ABC ):
    ...
    def find_answer_to_question( self, question : str, sim_threshold = 0.68, max_new_tokens : int = 5 ):
        if question == None or len( question.strip() ) == 0:
            raise ValueError( "ERROR: Required question is not specified" )

        sim_threshold = float( sim_threshold )
        max_new_tokens = int( max_new_tokens )

        qa_instruction = self.get_qa_instruction( question, sim_threshold = sim_threshold )

        answer_text = self.__get_answer_text__( qa_instruction, max_new_tokens = max_new_tokens )
        answer_text = self.__clean_answer_text__( qa_instruction, answer_text )

        return answer_text
    ...
    def __qa_template__( self ):
        qa_template = """Context: 

    {}

    ---

    Question: {}
    Answer:"""
        return qa_template
```

Python ç±»â€˜OpenAIQuestionAnswerChatBotâ€™æ‰©å±•äº†æŠ½è±¡ç±»â€˜QuestionAnswerChatBotâ€™ï¼Œå¹¶ä½¿ç”¨ OpenAI LLM API å®ç°äº†èŠå¤©æœºå™¨äººåŠŸèƒ½ã€‚ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†è¯¥ç±»çš„ä¸»è¦åŠŸèƒ½ã€‚å®Œæ•´ä»£ç å¯ä»¥åœ¨[è¿™ä¸ª GitHub ä½ç½®](https://github.com/kbmurali/som-driven-qa-rag/blob/main/openai_qa_chatbot.py)æ‰¾åˆ°ã€‚

```py
import openai
import tiktoken
from qa_chatbot import QuestionAnswerChatBot

class OpenAIQuestionAnswerChatBot( QuestionAnswerChatBot ):
    ...
    def __get_answer_text__( self, qa_instruction : str, max_new_tokens : int = 5 ) -> str :
        openai.api_key = self.openai_key

        basic_answer = openai.Completion.create(
                                                    model = self.openai_model_name,
                                                    prompt = qa_instruction, 

                                               )

        answer_text = basic_answer[ "choices" ][0][ "text" ]
        return answer_text

    def __token_count__( self, text : str ):    
        return len( self.tokenizer.encode( text ) )
```

ä»¥ä¸‹æ˜¯å¦‚ä½•é€šè¿‡è¯­ä¹‰æœç´¢æ£€ç´¢åˆ°çš„ç±»ä¼¼ä¿¡æ¯æ¥å¢å¼ºé—®é¢˜æç¤ºçš„ç¤ºä¾‹ï¼š

![](img/77dd0ecb2e734bb5bb300ed137e03cf6.png)

ä¸€ä¸ªç¤ºä¾‹çš„ä¸Šä¸‹æ–‡å¢å¼ºé—®é¢˜æç¤ºâ€”â€”ä½œè€…æä¾›çš„å›¾åƒ

## ç¬¬ 7 æ­¥ï¼šç”¨äºæµ‹è¯•çš„ç¤ºä¾‹é—®é¢˜

ä»¥ä¸‹æ˜¯ç”¨äºæµ‹è¯• RAG çš„ç¤ºä¾‹é—®é¢˜ï¼Œä½¿ç”¨çš„æ˜¯ OpenAI çš„ GPT-3.5-turbo-instruct LLMã€‚è¿™äº›é—®é¢˜æ˜¯ä¸ºäº†ç¡®ä¿å®ƒä»¬çš„ç­”æ¡ˆä¸ 2022 å¹´ã€2023 å¹´å’Œ 2024 å¹´å‘ç”Ÿçš„äº‹ä»¶ç›¸å…³ã€‚

```py
sample_questions = [
                        "Who won the 2022 soccer world cup?",
                        "When did Sweden join NATO?",
                        "Who joined NATO in 2023?",
                        "Who joined NATO in 2024?",
                        "Which is the 31st member of NATO?",
                        "Which is the 32nd member of NATO?",
                        "Who won the Cricket World Cup in 2023?",
                        "Who defeated India in Cricket World Cup final in 2023?",
                        "Name the former prime minister of Japan that was assassinated in 2022?",
                        "When did Chandrayaan-3 land near the south pole of the Moon?",
                        "Where did Chandrayaan-3 land on the Moon?",
                        "Who acquired Twitter in 2022?",
                        "Who owns Twitter?",
                        "Who acquired Activision Blizzard in 2023?"
                   ]
```

## ç¬¬ 8 æ­¥ï¼šå°†æ‰€æœ‰å†…å®¹æ•´åˆåœ¨ä¸€èµ·

æ•´åˆæ‰€æœ‰ç»„ä»¶çš„å®Œæ•´ Jupyter ç¬”è®°æœ¬å¯ä»¥åœ¨[è¿™ä¸ª GitHub ä½ç½®](https://github.com/kbmurali/som-driven-qa-rag/blob/main/OpenAI_Based_SOM_GPT2_Bot.ipynb)æ‰¾åˆ°ã€‚ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†åŸºäº OpenAI çš„ä¸»è¦é—®ç­”èŠå¤©æœºå™¨äººçš„åˆå§‹åŒ–è¿‡ç¨‹ã€‚è¯·æ³¨æ„ï¼ŒOpenAI çš„æ–‡æœ¬åµŒå…¥ç®—æ³•â€œtext-embedding-ada-002â€ç”¨äºå‘é‡ç¼–ç ã€‚åŒæ ·ï¼ŒèŠå¤©æœºå™¨äººä½¿ç”¨ OpenAI çš„åˆ†è¯å™¨â€œcl100k_baseâ€æ¥è®¡ç®—æ ‡è®°æ•°ï¼Œä»¥é™åˆ¶ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼Œå¹¶é€šè¿‡åˆ©ç”¨ TikToken Python åº“çš„å†…ç½®å‡½æ•°å¢å¼ºé—®é¢˜æç¤ºã€‚

```py
openai_vector_encoder_id = "text-embedding-ada-002"
openai_encoded_vector_dimensions = 1536
openai_tokenizer_name = "cl100k_base" 
openai_model_name = "gpt-3.5-turbo-instruct"

vector_encoder = OpenAIEmbeddingsVectorEncoder( openai_encoded_vector_dimensions, openai_vector_encoder_id, openai_key )

event_years_to_fetch = [ 2022, 2023, 2024 ]
data_source = WikiEventsDataSource( event_years_to_fetch  )
...
som_driven_rag_util = SOM_Based_RAG_Util( 
                                            vector_encoder = vector_encoder,
                                            som_lattice_height = 20,
                                            som_lattice_width = 30,
                                            learning_rate = 0.3,
                                            topk_bmu_for_indexing = 10,
                                            device = device
                                        )
...
openai_chatbot = OpenAIQuestionAnswerChatBot( 
                                                vector_db_util = som_driven_rag_util,
                                                openai_tokenizer_name = openai_tokenizer_name,
                                                openai_model_name = openai_model_name,
                                                openai_key = openai_key,
                                                question_input_max_token_count = 100,
                                                context_trim_percent = 0.1,
                                                device = device
                                            )
```

ä»¥ä¸‹åºåˆ—å›¾æœ‰åŠ©äºå¯è§†åŒ–åˆå§‹åŒ–å’Œå®é™…é—®ç­”é˜¶æ®µä¸­æ‰€æœ‰ç»„ä»¶çš„äº¤äº’ã€‚

![](img/acffe90601416d6f17621a9d2d29cddb.png)

åˆå§‹åŒ–è¿‡ç¨‹ä¸­çš„å„ç»„ä»¶äº¤äº’â€”â€”ä½œè€…æä¾›çš„å›¾åƒ

![](img/320862ead248a3bb9360d7ac2eea63bc.png)

é—®ç­”è¿‡ç¨‹ä¸­å„ä¸ªç»„ä»¶çš„äº¤äº’ â€”â€” å›¾ç‰‡ç”±ä½œè€…æä¾›

## ç ”ç©¶å‘ç°

ä»¥ä¸‹å›¾åƒå±•ç¤ºäº†åœ¨æœ‰æ— ä¸Šä¸‹æ–‡å¢å¼ºçš„æƒ…å†µä¸‹ï¼ŒOpenAI çš„ GPT-3.5-turbo-instruct LLM çš„é—®ç­”ã€‚

![](img/e55fe942772a20c25c4906ad9d6d3a5b.png)

OpenAI çš„ GPT-3.5-turbo-instruct LLM çš„æœ‰æ— ä¸Šä¸‹æ–‡å¢å¼ºå›ç­” â€”â€” å›¾ç‰‡ç”±ä½œè€…æä¾›

å¯ä»¥ç†è§£çš„æ˜¯ï¼ŒLLM å‘ç°å›ç­” 2021 å¹´ 9 æœˆä¹‹åå‘ç”Ÿçš„äº‹ä»¶ç›¸å…³é—®é¢˜æ—¶å­˜åœ¨å›°éš¾ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå®ƒæ˜ç¡®å›åº”è¯´è¿™äº›é—®é¢˜ç›¸å¯¹äºå…¶è®­ç»ƒæˆªæ­¢æ—¥æœŸè€Œè¨€æ¥è‡ªæœªæ¥ã€‚ç›¸åï¼Œå½“é€šè¿‡ä»ç»´åŸºç™¾ç§‘ä¸­æ£€ç´¢åˆ°çš„ 2022ã€2023 å’Œ 2024 å¹´çš„ç›¸å…³ä¿¡æ¯å¢å¼ºé—®é¢˜ä¸Šä¸‹æ–‡æ—¶ï¼ŒåŒä¸€ LLM èƒ½å¤Ÿå‡†ç¡®æ— è¯¯åœ°å›ç­”æ‰€æœ‰é—®é¢˜ã€‚çœŸæ­£çš„åŠŸåŠ³åœ¨äºä¸º RAG çš„è¯­ä¹‰æœç´¢æä¾›åŸºç¡€çš„ SOMï¼Œå®ƒä½¿å¾—èƒ½å¤Ÿé€šè¿‡æ£€ç´¢å¹¶å¢å¼ºé—®é¢˜çš„ä¸Šä¸‹æ–‡ï¼Œæä¾›ç›¸å…³ä¿¡æ¯ã€‚

## å»ºè®®çš„ä¸‹ä¸€æ­¥

è™½ç„¶ä¸Šè¿°ç¤ºä¾‹ä½œä¸ºæ¦‚å¿µéªŒè¯ï¼Œè¯„ä¼°äº†è‡ªç»„ç»‡æ˜ å°„ï¼ˆSelf-Organizing Mapï¼ŒSOMï¼‰æ˜¯å¦é€‚åˆç”¨äºä½¿ LLM é€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–‡æœ¬ï¼Œä½†å»ºè®®è¿›è¡Œæ›´å…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œä»¥è¯„ä¼°å…¶ä¸å…¶ä»–ç®—æ³•çš„æ€§èƒ½å¯¹æ¯”ï¼Œä½¿ç”¨æ›´å¤§è§„æ¨¡çš„å¤–éƒ¨æ•°æ®é›†ï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæ€§èƒ½å°†é€šè¿‡ LLM è¾“å‡ºçš„è´¨é‡æ¥è¡¡é‡ï¼ˆç±»ä¼¼å›°æƒ‘åº¦+å‡†ç¡®åº¦ï¼‰ã€‚æ­¤å¤–ï¼Œç”±äºå½“å‰ç¤ºä¾‹å¯ç”¨äº†å¯æ’æ‹”æ¡†æ¶ï¼Œå»ºè®®ä½¿ç”¨å…¶ä»–å¼€æºä¸”å…è´¹çš„ QA LLM è¿›è¡Œæ­¤ç±»åŸºå‡†æµ‹è¯•ï¼Œä»¥å‡å°‘ LLM çš„ä½¿ç”¨è´¹ç”¨ã€‚

ä¸ºäº†å¸®åŠ©åœ¨æœ¬åœ°ç¯å¢ƒä¸­è¿è¡Œç¤ºä¾‹ï¼Œæˆ‘é™„ä¸Šäº†â€˜requirements.txtâ€™æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«æˆ‘åœ¨ç¯å¢ƒä¸­ç”¨äºè¿è¡Œå’Œæµ‹è¯•ä¸Šè¿°ç¤ºä¾‹çš„å„ç§ç‰ˆæœ¬çš„ Python åº“ã€‚è¯¥æ–‡ä»¶å¯åœ¨[æ­¤ GitHub ä½ç½®](https://github.com/kbmurali/som-driven-qa-rag/blob/main/requirements.txt)æ‰¾åˆ°ã€‚

æˆ‘æœ€åæ‰¿è¯ºï¼Œå¦‚æœæˆ‘è¿›è¡Œä»»ä½•æ­¤ç±»åŸºå‡†æµ‹è¯•ï¼Œå°†ä¼šåœ¨å•ç‹¬çš„æ–‡ç« ä¸­åˆ†äº«æˆ‘çš„å‘ç°ã€‚è¯·ç»§ç»­å…³æ³¨ï¼ï¼

## å‚è€ƒæ–‡çŒ®

[](http://www.ai-junkie.com/ann/som/som1.html?source=post_page-----5d739ce21e9c--------------------------------) [## SOM æ•™ç¨‹ç¬¬ä¸€éƒ¨åˆ†

### ç¥ç»ç½‘ç»œæ•™ç¨‹ï¼ˆç®€æ˜è‹±è¯­ç‰ˆï¼‰

[www.ai-junkie.com](http://www.ai-junkie.com/ann/som/som1.html?source=post_page-----5d739ce21e9c--------------------------------) [](/understanding-self-organising-map-neural-network-with-python-code-7a77f501e985?source=post_page-----5d739ce21e9c--------------------------------) ## é€šè¿‡ Python ä»£ç ç†è§£è‡ªç»„ç»‡æ˜ å°„ç¥ç»ç½‘ç»œ

### é€šè¿‡ç«äº‰ã€åˆä½œå’Œé€‚åº”è¿›è¡Œçš„è„‘å¯å‘å¼æ— ç›‘ç£æœºå™¨å­¦ä¹ 

[towardsdatascience.com [](https://arxiv.org/abs/2005.11401?source=post_page-----5d739ce21e9c--------------------------------) [## é¢å‘çŸ¥è¯†å¯†é›†å‹è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ

### å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å·²è¢«è¯æ˜èƒ½å¤Ÿåœ¨å…¶å‚æ•°ä¸­å­˜å‚¨äº‹å®çŸ¥è¯†ï¼Œå¹¶å®ç°â€¦

arxiv.org](https://arxiv.org/abs/2005.11401?source=post_page-----5d739ce21e9c--------------------------------) [](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/?source=post_page-----5d739ce21e9c--------------------------------) [## ä»€ä¹ˆæ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ï¼Ÿ

### æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ˜¯ä¸€ç§å¢å¼ºç”Ÿæˆå‹äººå·¥æ™ºèƒ½æ¨¡å‹å‡†ç¡®æ€§å’Œå¯é æ€§çš„æŠ€æœ¯â€¦

blogs.nvidia.com](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/?source=post_page-----5d739ce21e9c--------------------------------)

[`www.sciencedirect.com/topics/engineering/self-organizing-map`](https://www.sciencedirect.com/topics/engineering/self-organizing-map)

[`platform.openai.com/docs/models/gpt-3-5-turbo`](https://platform.openai.com/docs/models/gpt-3-5-turbo)

[`platform.openai.com/docs/guides/text-generation/chat-completions-api`](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)
