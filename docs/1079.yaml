- en: Models, MLFlow, and Microsoft Fabric
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/models-mlflow-and-microsoft-fabric-8faacaa90814?source=collection_archive---------7-----------------------#2024-04-29](https://towardsdatascience.com/models-mlflow-and-microsoft-fabric-8faacaa90814?source=collection_archive---------7-----------------------#2024-04-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fabric Madness part 5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@roger_noble?source=post_page---byline--8faacaa90814--------------------------------)[![Roger
    Noble](../Images/869b5b0f237f24b119ca6c41c2e31162.png)](https://medium.com/@roger_noble?source=post_page---byline--8faacaa90814--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8faacaa90814--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8faacaa90814--------------------------------)
    [Roger Noble](https://medium.com/@roger_noble?source=post_page---byline--8faacaa90814--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8faacaa90814--------------------------------)
    ·6 min read·Apr 29, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd8a2c9a78a66c843fc0e9dcee09acce.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author and ChatGPT. “Design an illustration, with imagery representing
    multiple machine learning models, focusing on basketball data” prompt. ChatGPT,
    4, OpenAI, 25th April. 2024\. [https://chat.openai.com.](https://chat.openai.com./)
  prefs: []
  type: TYPE_NORMAL
- en: '*A Huge thanks to* [*Martim Chaves*](https://medium.com/@mgrc99) *who co-authored
    this post and developed the example scripts.*'
  prefs: []
  type: TYPE_NORMAL
- en: So far in this series, we’ve looked at how to use Fabric for collecting data,
    feature engineering, and training models.
  prefs: []
  type: TYPE_NORMAL
- en: But now that we have our shiny new models, what do we do with them? How do we
    keep track of them, and how do we use them to make predictions? This is where
    MLFlow’s Model Registry comes in, or what Fabric calls an **ML Model**.
  prefs: []
  type: TYPE_NORMAL
- en: A model registry allows us to keep track of different versions of a model and
    their respective performances. This is especially useful in production scenarios,
    where we need to deploy a specific version of a model for inference.
  prefs: []
  type: TYPE_NORMAL
- en: A Model Registry can be seen as source control for ML Models. Fundamentally,
    each version represents a distinct set of model files. These files contain the
    model’s architecture, its trained weights, as well as any other files necessary
    to load the model and use it.
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we’ll discuss how to log models and how to use the model registry
    to keep track of different versions of a model. We’ll also discuss how to load
    a model from the registry and use it to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Registering a Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two ways to register a model in Fabric: via code or via the UI. Let’s
    look at both.'
  prefs: []
  type: TYPE_NORMAL
- en: Registering a Model using code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [previous post](https://medium.com/towards-data-science/experimenting-with-mlflow-and-microsoft-fabric-68f43043ff34)
    we looked at creating experiments and logging runs with different configurations.
    Logging or registering a model can be done using code within a run. To do that,
    we just have to add a couple of lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this code snippet, we first calculate the predictions for the training set.
    Then create a signature, which is essentially the input and output shape of the
    model. This is necessary to ensure that the model can be loaded later on.
  prefs: []
  type: TYPE_NORMAL
- en: MLFlow has functions to log models made with different commonly used packages,
    such as [TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/),
    and [scikit-learn](https://scikit-learn.org/). When `mlflow.tensorflow.log_model`
    is used, a folder is saved, as an artifact, attached to the run, containing the
    files needed to load and run the model. In these files, the architecture along
    with with trained weights of the model and any other configuration necessary for
    reconstruction are found. This makes it possible to load the model later, either
    to do inference, fine-tune it, or any other regular model operations without having
    to re-run the original code that created it.
  prefs: []
  type: TYPE_NORMAL
- en: The model’s URI is used as a “path” to the model file, and is made up of the
    run ID and the name of the file used for the model. Once we have the model’s URI,
    we can register a ML Model, using the model’s URI.
  prefs: []
  type: TYPE_NORMAL
- en: What’s neat about this is that if a model with the same name already exists,
    a new version is added. That way we can keep track of different versions of the
    same model, and see how they perform without having overly complex code to manage
    this.
  prefs: []
  type: TYPE_NORMAL
- en: In our [previous post](https://medium.com/towards-data-science/experimenting-with-mlflow-and-microsoft-fabric-68f43043ff34),
    we ran three experiments, one for each model architecture being tested with three
    different learning rates. For each model architecture, an ML Model was created,
    and for each learning rate, a version was saved. In total we now have 9 versions
    to choose from, each with a different architecture and learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: Registering a Model using the UI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An **ML Model** can also be registered via Fabric’s UI. Model versions can be
    imported from the experiments that have been created.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d47fd08d8ffde05970072caa90913ab2.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 1 — Creating a ML Model using the UI. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: After creating an ML Model, we can import a model from an existing experiment.
    To do that, in a run, we have to select `Save` in the `Save run as an ML Model`
    section.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/21455e93691763f2cd58ffa22dd3fecd.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 2 — Creating a new version of the created ML Model from a run. Image by
    author.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting Best Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have registered all of the models, we can select the best one. This
    can be done either via the UI or code. This can be done by opening each experiment,
    selecting the `list view`, and selecting all of the available runs. After finding
    the best run, we would have to check which model and version that would be.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cb6393da3ecff62cba4ab6a74ce2394.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig. 3 — Inspecting Experiment. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, it can also be done via code, by getting all of the versions
    of all of the ML Models performance, and selecting the version with the best score.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this code snippet, we get a list of all of the available ML Models. Then,
    we iterate over this list and get all of the available versions of each ML Model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Getting a list of the versions of an ML Model can be done using the following
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, for each version, we simply have to get its metric history. That can
    be done with the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: After that, we simply have to keep track of the best performing version. At
    the end of this, we had found the best performing model overall, regardless of
    architecture and hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the Best Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After finding the best model, using it to get the final predictions can be
    done using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Loading the model can be done using `mlflow.pyfunc.load_model()`, and the only
    argument that is needed is the model's path. The path of the model is made up
    of its name and version, in a `models:/[model name]/[version]` format. After that,
    we just have to make sure that the input is the same shape and the features are
    in the same order as when it was trained - and that's it!
  prefs: []
  type: TYPE_NORMAL
- en: Using the test set, we calculated the final Brier Score, **0.20**.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this post we discussed the ideas behind a model registry, and why it’s beneficial
    to use one. We showed how Fabric’s model registry can be used, through the ML
    Model tool, either via the UI or code. Finally, we looked at loading a model from
    the registry, to do inference.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our Fabric series. We hope you enjoyed it and that you learned
    something new. If you have any questions or comments, feel free to reach out to
    us. We’d love to hear from you! 👋
  prefs: []
  type: TYPE_NORMAL
- en: '*Originally published at* [*https://nobledynamic.com*](https://nobledynamic.com/posts/fabric-madness-5/)
    *on April 29, 2024.*'
  prefs: []
  type: TYPE_NORMAL
