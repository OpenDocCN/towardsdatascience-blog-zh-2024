<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Find Unusual Segments in Your Data with Subgroup Discovery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Find Unusual Segments in Your Data with Subgroup Discovery</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/find-unusual-segments-in-your-data-with-subgroup-discovery-2661a586e60c?source=collection_archive---------8-----------------------#2024-02-02">https://towardsdatascience.com/find-unusual-segments-in-your-data-with-subgroup-discovery-2661a586e60c?source=collection_archive---------8-----------------------#2024-02-02</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="9deb" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Patient rule induction method finds 35% better segments than previously reported</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vadim.arzamasov?source=post_page---byline--2661a586e60c--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Vadim Arzamasov" class="l ep by dd de cx" src="../Images/70ced2eafa6fc926052979875a0a4265.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*sLla8xXL0qQuaiNDqAnTiw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--2661a586e60c--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@vadim.arzamasov?source=post_page---byline--2661a586e60c--------------------------------" rel="noopener follow">Vadim Arzamasov</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--2661a586e60c--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 2, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/5c58998cb8355e53823acdd3947bda6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rug-eFCXvFKLKd6wiDy-xw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by author with recraft.ai</figcaption></figure><p id="becb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Inspired by an in-depth <a class="af ny" href="https://medium.com/towards-data-science/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2" rel="noopener">Medium article</a> [1] with a case study on identifying bank customer segments with high churn reduction potential, this story explores a similar challenge through the lens of subgroup discovery methods [2]. Intrigued by the parallels, I applied a subgroup discovery approach to the same dataset and uncovered a segment with a 35% higher churn reduction potential — a significant improvement over what was previously reported. This story will take you through each step of the process, including building the methodology from the ground up. At the end of this journey, you’ll gain:</p><ul class=""><li id="af79" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx nz oa ob bk">A clear understanding of the Patient Rule Induction Method (PRIM), a mature yet powerful subgroup discovery technique.</li><li id="0cb7" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">The skills to apply PRIM to your datasets and tailor it to your specific needs.</li></ul><p id="44dd" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The complete code for PRIM and the experiment is on <a class="af ny" href="https://github.com/Arzik1987/medium/tree/main/prim_segments" rel="noopener ugc nofollow" target="_blank">GitHub</a> [3].</p><h2 id="6e78" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">Patient Rule Induction Method</h2><p id="9413" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">For the experiment, I’ve chosen my favorite subgroup discovery method: PRIM [4]. Despite its long presence in the field, PRIM has a unique mix of properties that make it very versatile:</p><ul class=""><li id="ed0c" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx nz oa ob bk"><strong class="ne fr">Numerical data handling</strong>: PRIM easily handles numerical data without the need for binning. Unlike typical methods that discretize variables (e.g., categorizing age into predefined groups such as <code class="cx ph pi pj pk b">45–54 years</code>), PRIM overcomes this limitation. For example, it can identify more nuanced criteria such as <code class="cx ph pi pj pk b">age &gt; 37</code>.</li><li id="3ab9" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk"><strong class="ne fr">Intelligent categorical data processing</strong>: PRIM can discover complex segments within categorical data. It can go beyond simple classifications such as <code class="cx ph pi pj pk b">country = Germany</code> to more complex definitions such as <code class="cx ph pi pj pk b">country not in {France}</code>.</li><li id="f897" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk"><strong class="ne fr">Simplicity</strong>: While traditional subgroup discovery methods are often burdened with multiple parameters, PRIM is refreshingly simple. It relies primarily on a single, unambiguous <code class="cx ph pi pj pk b">peeling parameter</code>: the proportion of points removed from a candidate segment in each iteration.</li><li id="08ca" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk"><strong class="ne fr">Efficiency</strong>: Being a heuristic approach, PRIM is remarkably fast. Despite its large search space, segment identification is typically resolved in milliseconds.</li><li id="12b6" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk"><strong class="ne fr">Interactivity and control</strong>: PRIM enables interactive analysis. Users can balance segment size against potential impact by examining a series of “nested” segments and selecting the most appropriate one. It also supports incremental segment discovery by removing already segmented data.</li><li id="9506" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk"><strong class="ne fr">Flexibility</strong>: The flexibility of the method extends to the optimization function it is designed to enhance. This function isn’t limited to a single variable. For example, PRIM can identify segments where the correlation between two variables is significantly different from their correlation in the entire data set.</li></ul><p id="3c6f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In summary, PRIM’s straightforward logic not only makes it easy to implement, but also allows for customization.</p><h2 id="51d6" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">PRIM algorithm</h2><p id="0858" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">PRIM works through two distinct phases: peeling and pasting. Peeling starts from a segment encompassing the entire dataset and gradually shrinks it while optimizing its quality. Pasting works similarly, but in the opposite direction — it tries to expand the selected candidate segment without quality loss. In our previous experiments [5], we observed that the pasting phase typically contributes minimally to the output quality. Therefore, I will focus on the peeling phase. The underlying logic of the peeling phase is as follows:</p><pre class="mm mn mo mp mq pl pk pm bp pn bb bk"><span id="9cea" class="po oi fq pk b bg pp pq l pr ps">1. Initialize:<br/>   - Set the peeling parameter (usually 0.05)<br/>   - Set the initial box (segment) to encompass the entire data space.<br/>   - Define the target quality function (e.g., a potential churn reduction).<br/><br/>2. While the stopping criterion is not met:<br/>   - For each dimension of the data space:<br/>     * Identify a small portion (defined by a peeling parameter) <br/>       of the data to remove that maximizes quality of remaining data<br/>   - Update the box by removing the identified portion from <br/>     the current box.<br/>   - Update the dataset by removing the data points that fall outside <br/>     the new box.<br/><br/>3. End when the stopping criterion is met <br/>   (e.g., after a certain number of iterations <br/>   or minimum number of data points remaining).<br/><br/>4. Return the final box and all the preceding boxes as candidate segments.</span></pre><p id="0df9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this pseudo-code:</p><ul class=""><li id="15e8" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx nz oa ob bk"><code class="cx ph pi pj pk b">box</code> refers to the current segment of the data.</li><li id="498e" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">The <code class="cx ph pi pj pk b">target quality function</code> is typically some statistic of the response variable (mean, median, etc) that we want to maximize or minimize.</li><li id="514d" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">The <code class="cx ph pi pj pk b">peeling parameter</code> determines the proportion of data points to be removed in each iteration. It is usually set to a small value, such as 0.05, hence the word “patient” in the method’s name.</li><li id="7da3" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">The <code class="cx ph pi pj pk b">stopping criterion </code>ensures that enough data points remain for analysis.</li></ul><p id="dbca" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Consider simple examples of how PRIM handles numeric and categorical variables:</p><p id="6b1b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Numeric variables:<br/></strong>Imagine you have a numeric variable such as age. In each step of the peeling phase, PRIM looks at the range of that variable (say, age from 18 to 80). PRIM then “peels off” a portion of that range from either end, as defined by the <code class="cx ph pi pj pk b">peeling parameter</code>. For example, it might remove ages 75 to 80 because doing so improves the <code class="cx ph pi pj pk b">target quality function</code> in the remaining data (e.g., increasing the churn reduction potential). The animation below shows PRIM finding an interesting segment (with a high proportion of orange squares) in a 2D numeric dataset.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pt"><img src="../Images/b490dcc06d4384cccf544002f220f0f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aPgqYTBm0aWivviCaR03JQ.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">PRIM at work on a 2D numerical data set. Image by the author</figcaption></figure><p id="f2c3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Categorical nominal variables:<br/></strong>Now consider a categorical nominal variable such as country, with categories such as Germany, France, and Spain. In the peeling phase, PRIM evaluates each category based on how well it improves the <code class="cx ph pi pj pk b">target quality function</code>. It then removes the least promising category. For example, if removing “Germany” results in a subset where the <code class="cx ph pi pj pk b">target quality function</code> is improved (such as a higher potential churn reduction), then all data points with “Germany” are “peeled”. Note that the <code class="cx ph pi pj pk b">peeling parameter</code> has no effect on the processing of categorical data, which can cause undesired effects in some cases, as I will discuss and provide a simple remedy (in section “Better segments via enforced ‘patience’”).</p><p id="db95" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Categorical ordinal variables:</strong><br/>For ordinal variables, disjoint intervals in segment descriptions can sometimes be less intuitive. Consider an education variable with levels such as primary, secondary, vocational, bachelor, and graduate. Finding a rule like <code class="cx ph pi pj pk b">education in {primary, bachelor}</code> may not fit well with the ordinal nature of the data because it combines non-adjacent categories. For those looking for a more coherent segmentation, such as <code class="cx ph pi pj pk b">education &gt; secondary</code>, that respects the natural order of the variable, using an ordinal encoding can be a useful workaround. For more insight into categorical encoding, you may find my <a class="af ny" href="https://medium.com/@vadim.arzamasov/navigating-categorical-encoder-maze-c04e49b165fe" rel="noopener">earlier post</a> [6] helpful, as it navigates you to the necessary information.</p><h2 id="4c03" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">Experiment: Churn for bank customers</h2><p id="ab1b" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Now everything is ready to start the experiment. Following the Medium article on identifying unique data segments [1], I will apply the PRIM method to the <a class="af ny" href="https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers" rel="noopener ugc nofollow" target="_blank">Churn for Bank Customers</a> [7] dataset from Kaggle, available under the CC0: Public Domain license. I will also adopt the <code class="cx ph pi pj pk b">target quality function</code> from the article:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pu"><img src="../Images/24f1b331624a6e6cc65d360d7fb1ec59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q5_W4_KDbRwGpAnzkc4VCg.png"/></div></div></figure><p id="d38b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">That is, I will look for the segments with many customers where the churn rate is much higher than the baseline, which is the average churn rate in the entire dataset. So I use PRIM, which gives me a set of nested candidate segments, and plot the <code class="cx ph pi pj pk b">churn_est_reduction</code> against the number of clients.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pv"><img src="../Images/f2f6519be48b38e624fb8716ef89341d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fMeqTuqmqIDKO9L8HUMphg.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by the author</figcaption></figure><p id="684f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The highest quality, <code class="cx ph pi pj pk b">churn_est_reduction = 457</code> is achieved for the 11th candidate segment with the description <code class="cx ph pi pj pk b">num_of_products &lt; 2, is_active_member &lt; 1, age &gt; 37</code>. This is quite an improvement over the previously reported maximum <code class="cx ph pi pj pk b">churn_est_reduction = 410</code> in [1]. Comparing the segment descriptions, I suspect that the main reason for this improvement is PRIM’s ability to handle numeric variables.</p><h2 id="6791" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">Better segments via enforced ‘patience’</h2><p id="d0c4" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Something suspicious is going on in the previous plot. By its nature, PRIM is expected to be “patient”, i.e. to reduce the segment size only a little bit at each iteration. However, the second candidate segment is twice as small as the previous one — PRIM has cut off half the data at once. The reason for this is the low cardinality of some features, which is often the case with categorical or indicator variables. For example, <code class="cx ph pi pj pk b">is_active_member</code> only takes the values 0 or 1. PRIM can only cut off large chunks of data for such variables, giving them an unfair advantage.</p><p id="24ef" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To address this issue, I’ve added an additional parameter called <code class="cx ph pi pj pk b">patience </code>to give more weight to smaller cuts. Specifically, for the task at hand, I prioritize cuts by multiplying the churn rate reduction by the segment size raised to the power of <code class="cx ph pi pj pk b">patience</code>. This approach helps to fine-tune the selection of segments based on their size, making it more tailored to our analysis needs. Applying PRIM with <code class="cx ph pi pj pk b">patience = 2</code> to the data yields the following candidate segments</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pv"><img src="../Images/a1434019563bc9df4066f3424e5c1032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ncw9ThdOUOz2f2KI_40TTQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by the author</figcaption></figure><p id="a45d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now the best candidate segment is <code class="cx ph pi pj pk b">num_of_products &lt; 2, 37 &lt; age &lt; 64</code> with <code class="cx ph pi pj pk b">churn_est_reduction = 548</code>, much better than any previous result!</p><h2 id="a253" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">Finding multiple segments</h2><p id="2847" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Let us say we have selected the just discovered segment and ask one of two responsible teams to focus on it. Can PRIM find a job for another team, i.e., find another group of clients, not in the first segment, with a high potential churn rate reduction? Yes it can, with so-called “covering” approach [4]. This means that one simply drops the clients belonging to the previously selected segment(s) from the dataset and apply PRIM once again. So I removed data with <code class="cx ph pi pj pk b">num_of_products &lt; 2, 37 &lt; age &lt; 64</code> and applied PRIM to the rest:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pv"><img src="../Images/829eaac3357952969256d1bf7521d29d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OvX0sDu2BX7psORZx_AZkw.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by the author</figcaption></figure><p id="1797" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here the best candidate segment is <code class="cx ph pi pj pk b">gender != ‘Male’, num_of_products &gt; 2, balance &gt; 0.0</code> with <code class="cx ph pi pj pk b">chirn_est_reduction = 93.</code></p><h2 id="8100" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">Summary</h2><p id="8f3b" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">To wrap things up, I illustrated PRIM’s strong performance on a Customer Churn Dataset for a task to find unusual segments. Points to note:</p><ul class=""><li id="8b75" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx nz oa ob bk">PRIM has identified highly insightful segments with 35% higher quality than previously reported.</li><li id="6d2b" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">I shared the code [3] for practical application and further experimentation. It is very concise and, unlike to other existing implementations [8–9], allows one to easily replace the target quality function tailored to a specific need.</li><li id="ef47" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">I endorse PRIM for its robust features, such as effective handling of both numeric and categorical data, flexible segment definition, and fast execution, and recommend it for similar analytical challenges.</li></ul><h2 id="ee1c" class="oh oi fq bf oj ok ol om on oo op oq or nl os ot ou np ov ow ox nt oy oz pa pb bk">References</h2><p id="7403" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">[1] <a class="af ny" href="https://medium.com/towards-data-science/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2" rel="noopener">Figuring out the most unusual segments in data</a><br/>[2] Atzmueller, Martin. “<a class="af ny" href="https://www.kde.cs.uni-kassel.de/wp-content/uploads/atzmueller/paper/2005-SDSchlagwortKI_AtzmuellerM.pdf" rel="noopener ugc nofollow" target="_blank">Subgroup discovery</a>.” <em class="pw">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</em> 5.1 (2015): 35–49.<br/>[3] <a class="af ny" href="https://github.com/Arzik1987/medium/tree/main/prim_segments" rel="noopener ugc nofollow" target="_blank">My code for PRIM and the experiment</a><br/>[4] Friedman, Jerome H., and Nicholas I. Fisher. “<a class="af ny" href="https://www.researchgate.net/profile/Nicholas-Fisher-10/publication/283550136_Bump_hunting_in_high-dimensional_data-Discussion/links/5a4350980f7e9ba868a54cd9/Bump-hunting-in-high-dimensional-data-Discussion.pdf" rel="noopener ugc nofollow" target="_blank">Bump hunting in high-dimensional data</a>.” <em class="pw">Statistics and computing</em> 9.2 (1999): 123–143.<br/>[5] Arzamasov, Vadim, and Klemens Böhm. “<a class="af ny" href="https://dl.acm.org/doi/abs/10.1145/3448016.3457301?casa_token=MK5vsUGKNz8AAAAA%3ASdp6s_axuda7ZPTNtz6ajP9_pAIIeMFu4VTPUbbQhuLlGmajVgVBmuIgShjGln2FlwebBuv5JwJS2w" rel="noopener ugc nofollow" target="_blank">REDS: rule extraction for discovering scenarios</a>.” <em class="pw">Proceedings of the 2021 International Conference on Management of Data</em>. 2021.<br/>[6] <a class="af ny" href="https://medium.com/@vadim.arzamasov/navigating-categorical-encoder-maze-c04e49b165fe" rel="noopener">Categorical Encoding: Key Insights</a><br/>[7] <a class="af ny" href="https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers" rel="noopener ugc nofollow" target="_blank">Churn for Bank Customers dataset</a><br/>[8] <a class="af ny" href="https://pypi.org/project/PRIM/" rel="noopener ugc nofollow" target="_blank">Patient Rule Induction Method for Python</a><br/>[9] <a class="af ny" href="https://cran.r-project.org/web/packages/prim/index.html" rel="noopener ugc nofollow" target="_blank">Patient Rule Induction Method for R</a></p></div></div></div></div>    
</body>
</html>