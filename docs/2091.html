<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Enforcing JSON Outputs in Commercial LLMs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Enforcing JSON Outputs in Commercial LLMs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/enforcing-json-outputs-in-commercial-llms-3db590b9b3c8?source=collection_archive---------2-----------------------#2024-08-28">https://towardsdatascience.com/enforcing-json-outputs-in-commercial-llms-3db590b9b3c8?source=collection_archive---------2-----------------------#2024-08-28</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="d0f6" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A comprehensive guide</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@volkot?source=post_page---byline--3db590b9b3c8--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Daniel Kharitonov" class="l ep by dd de cx" src="../Images/7d81129c1f88e4a0700462a342137227.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*oRrar_xIWb-X80KUJQs0mQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--3db590b9b3c8--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@volkot?source=post_page---byline--3db590b9b3c8--------------------------------" rel="noopener follow">Daniel Kharitonov</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--3db590b9b3c8--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 28, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><blockquote class="mj mk ml"><p id="f796" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">TL;DR</strong></p><p id="87a4" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">We tested the structured output capabilities of Google Gemini Pro, Anthropic Claude, and OpenAI GPT. In their best-performing configurations, all three models can generate structured outputs on a scale of thousands of JSON objects. However, the API capabilities vary significantly in the effort required to prompt the models to produce JSONs and in ability to adhere to the data models.</p></blockquote><p id="bb0a" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">More specifically, the only commercial vendor offering consistent structured outputs right out of the box appears to be OpenAI, with their latest <a class="af nj" href="https://openai.com/index/introducing-structured-outputs-in-the-api/" rel="noopener ugc nofollow" target="_blank">Structured Outputs API</a> released on August 6th, 2024. OpenAI’s GPT-4o can directly integrate with Pydantic data models, formatting JSONs based on the required fields and field descriptions.</p><p id="a3e6" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Anthropic’s Claude Sonnet 3.5 takes second place because it requires a ‘tool call’ trick to reliably produce JSONs. While Claude can interpret field descriptions, it does not directly support Pydantic models.</p><p id="3c02" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Finally, Google Gemini 1.5 Pro ranks third due to its cumbersome API, which requires the use of the poorly documented <em class="mo">genai.protos.Schema</em> class as a model for reliable JSON production. Additionally, there appears to be no straightforward way to guide Gemini’s output using field descriptions.</p><p id="e36a" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Here are the test results in a summary table:</p><figure class="nn no np nq nr ns nk nl paragraph-image"><div role="button" tabindex="0" class="nt nu ed nv bh nw"><div class="nk nl nm"><img src="../Images/2eb322369cc005af5499424b8f71545e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1JCh8Qny1AHxgg9vRa-Nbg.png"/></div></div><figcaption class="ny nz oa nk nl ob oc bf b bg z dx">Approximate rates of structured output errors (data source: author’s Jupyter notebook below)</figcaption></figure><p id="2c13" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Here is the link to the testbed notebook:</p><p id="403b" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://github.com/iterative/datachain-examples/blob/main/formats/JSON-outputs.ipynb" rel="noopener ugc nofollow" target="_blank">https://github.com/iterative/datachain-examples/blob/main/formats/JSON-outputs.ipynb</a></p><p id="0e6d" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Introduction to the problem</strong></p><blockquote class="mj mk ml"><p id="bbf8" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">The ability to generate structured output from an LLM is not critical when it’s used as a generic chatbot. However, structured outputs become indispensable in two emerging LLM applications:</p><p id="0aa3" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">• LLM-based analytics (such as AI-driven judgments and unstructured data analysis)</p><p id="d8eb" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">• Building LLM agents</p></blockquote><p id="1d60" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">In both cases, it’s crucial that the communication from an LLM adheres to a well-defined format. Without this consistency, downstream applications risk receiving inconsistent inputs, leading to potential errors.</p><p id="948d" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Unfortunately, while most modern LLMs offer methods designed to produce structured outputs (such as JSON), these methods often encounter two significant issues:</p><p id="3456" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">1. They periodically fail to produce a valid structured object.</p><p id="5574" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">2. They generate a valid object but cannot adhere to the requested data model.</p><p id="5af0" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">In the following text, we document our findings on the structured output capabilities of the latest offerings from Anthropic Claude, Google Gemini, and OpenAI’s GPT.</p><p id="e6c2" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Anthropic Claude Sonnet 3.5</strong></p><p id="3b80" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">At first glance, Anthropic Claude’s API looks straightforward because it features a section titled ‘<a class="af nj" href="https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency#example-daily-sales-report" rel="noopener ugc nofollow" target="_blank">Increasing JSON Output Consistency</a>,’ which opens with an example of a moderately complex structured output:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="1daf" class="oh oi fq oe b bg oj ok l ol om">import os<br/>import anthropic<br/><br/><br/>PROMPT = """<br/>You’re a Customer Insights AI. <br/>Analyze this feedback and output in JSON format with keys: “sentiment” (positive/negative/neutral), <br/>“key_issues” (list), and “action_items” (list of dicts with “team” and “task”).<br/>"""<br/><br/>source_files = "gs://datachain-demo/chatbot-KiT/"<br/>client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))<br/><br/>completion = (<br/>   client.messages.create(                       <br/>        model="claude-3-5-sonnet-20240620", <br/>        max_tokens = 1024,       <br/>        system=PROMPT,                           <br/>        messages=[{"role": "user", "content": "User: Book me a ticket. Bot: I do not know."}]<br/>   )<br/>)<br/>print(completion.content[0].text)</span></pre><p id="93c8" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">However, if we actually run this code a few times, we will notice that conversion to JSON fails because the LLM prepends JSON object with an unwanted text prefix:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="3dd4" class="oh oi fq oe b bg oj ok l ol om">Here's the analysis of that feedback in JSON format:<br/><br/>{<br/>  "sentiment": "negative",<br/>  "key_issues": [<br/>    "Bot unable to perform requested task",<br/>    "Lack of functionality",<br/>    "Poor user experience"<br/>  ],<br/>  "action_items": [<br/>    {<br/>      "team": "Development",<br/>      "task": "Implement ticket booking functionality"<br/>    },<br/>    {<br/>      "team": "Knowledge Base",<br/>      "task": "Create and integrate a database of ticket booking information and procedures"<br/>    },<br/>    {<br/>      "team": "UX/UI",<br/>      "task": "Design a user-friendly interface for ticket booking process"<br/>    },<br/>    {<br/>      "team": "Training",<br/>      "task": "Improve bot's response to provide alternatives or direct users to appropriate resources when unable to perform a task"<br/>    }<br/>  ]<br/>}</span></pre><p id="1b03" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">This issue affects approximately 14–20% of requests, making reliance on Claude’s ‘structured prompt’ feature questionable. The problem is evidently well-known to Anthropic, as their documentation provides two more recommendations:</p><p id="223f" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">1. Provide inline examples of valid output.</p><p id="70cb" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">2. Coerce the LLM to begin its response with a valid preamble.</p><p id="4612" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">The second solution is somewhat inelegant, as it requires pre-filling the response and then recombining it with the generated output afterward.</p><p id="3e34" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Here’s an example of code that implements both techniques and evaluates the validity of a resulting JSON string. This prompt was tested across 50 different dialogs by <a class="af nj" href="https://radar.kit.edu/radar/en/dataset/FdJmclKpjHzLfExE.ExpBot%2B-%2BA%2Bdataset%2Bof%2B79%2Bdialogs%2Bwith%2Ban%2Bexperimental%2Bcustomer%2Bservice%2Bchatbot" rel="noopener ugc nofollow" target="_blank">Karlsruhe Institute of Technology</a> using Iterative’s <a class="af nj" href="https://github.com/iterative/datachain" rel="noopener ugc nofollow" target="_blank">DataChain library</a>:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="9229" class="oh oi fq oe b bg oj ok l ol om">import os<br/>import json<br/>import anthropic<br/>from datachain import File, DataChain, Column<br/><br/>source_files = "gs://datachain-demo/chatbot-KiT/"<br/>client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))<br/><br/>PROMPT = """<br/>You’re a Customer Insights AI. <br/>Analyze this dialog and output in JSON format with keys: “sentiment” (positive/negative/neutral), <br/>“key_issues” (list), and “action_items” (list of dicts with “team” and “task”).<br/><br/>Example:<br/>{<br/>  "sentiment": "negative",<br/>  "key_issues": [<br/>    "Bot unable to perform requested task",<br/>    "Poor user experience"<br/>  ],<br/>  "action_items": [<br/>    {<br/>      "team": "Development",<br/>      "task": "Implement ticket booking functionality"<br/>    },<br/>    {<br/>      "team": "UX/UI",<br/>      "task": "Design a user-friendly interface for ticket booking process"<br/>    }<br/>  ]<br/>}    <br/>"""<br/>prefill='{"sentiment":'<br/><br/>def eval_dialogue(file: File) -&gt; str:    <br/>     completion = (<br/>         client.messages.create(                       <br/>                model="claude-3-5-sonnet-20240620", <br/>                max_tokens = 1024,       <br/>                system=PROMPT,                           <br/>                messages=[{"role": "user", "content": file.read()},<br/>                          {"role": "assistant", "content": f'{prefill}'},<br/>                         ]<br/>         )<br/>     )<br/>     json_string = prefill + completion.content[0].text<br/>     try:<br/>         # Attempt to convert the string to JSON<br/>         json_data = json.loads(json_string)<br/>         return json_string<br/>     except json.JSONDecodeError as e:<br/>         # Catch JSON decoding errors<br/>         print(f"JSONDecodeError: {e}")<br/>         print(json_string)<br/>         return json_string<br/><br/>chain = DataChain.from_storage(source_files, type="text")       \<br/>              .filter(Column("file.path").glob("*.txt"))        \<br/>              .map(claude = eval_dialogue)                      \<br/>              .exec()</span></pre><p id="898a" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">The results have improved, but they are still not perfect. Approximately one out of every 50 calls returns an error:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="c52f" class="oh oi fq oe b bg oj ok l ol om">JSONDecodeError: Expecting value: line 2 column 1 (char 14)<br/>{"sentiment":<br/>Human: I want you to analyze the conversation I just shared</span></pre><p id="f7fd" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">This implies that the Sonnet 3.5 model may fail to follow the instructions and hallucinate unwanted continuations of the dialogue. As a result, the model is still not consistently adhering to desired outputs.</p><p id="cd5a" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Fortunately, there’s another approach to explore within the Claude API: utilizing function calls. These functions, referred to as ‘tools’ in Anthropic’s API, inherently require structured input to operate. To leverage this option, we can create a mock function and configure the call signature identical with our desired JSON object:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="745b" class="oh oi fq oe b bg oj ok l ol om">import os<br/>import json<br/>import anthropic<br/>from datachain import File, DataChain, Column<br/><br/>from pydantic import BaseModel, Field, ValidationError<br/>from typing import List, Optional<br/><br/>class ActionItem(BaseModel):<br/>    team: str <br/>    task: str<br/><br/>class EvalResponse(BaseModel):<br/>    sentiment: str = Field(description="dialog sentiment (positive/negative/neutral)")<br/>    key_issues: list[str] = Field(description="list of five problems discovered in the dialog")<br/>    action_items: list[ActionItem] = Field(description="list of dicts with 'team' and 'task'")<br/><br/><br/>source_files = "gs://datachain-demo/chatbot-KiT/"<br/>client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))<br/><br/>PROMPT = """<br/>You’re assigned to evaluate this chatbot dialog and sending the results to the manager via send_to_manager tool.    <br/>"""<br/><br/>def eval_dialogue(file: File) -&gt; str:    <br/>     completion = (<br/>         client.messages.create(                       <br/>                model="claude-3-5-sonnet-20240620", <br/>                max_tokens = 1024,       <br/>                system=PROMPT, <br/>                tools=[<br/>                    {<br/>                        "name": "send_to_manager",<br/>                        "description": "Send bot evaluation results to a manager",<br/>                        "input_schema": EvalResponse.model_json_schema(),<br/>                    }<br/>                ],<br/>                messages=[{"role": "user", "content": file.read()},<br/>                         ]<br/>         )<br/>     )<br/>     try: # We are only interested in the ToolBlock part<br/>         json_dict = completion.content[1].input<br/>     except IndexError as e:<br/>         # Catch cases where Claude refuses to use tools<br/>         print(f"IndexError: {e}")<br/>         print(completion)<br/>         return str(completion)<br/>     try:<br/>         # Attempt to convert the tool dict to EvalResponse object<br/>         EvalResponse(**json_dict)<br/>         return completion<br/>     except ValidationError as e:<br/>         # Catch Pydantic validation errors<br/>         print(f"Pydantic error: {e}")<br/>         print(completion)<br/>         return str(completion)<br/><br/>tool_chain = DataChain.from_storage(source_files, type="text")          \<br/>              .filter(Column("file.path").glob("*.txt"))                \<br/>              .map(claude = eval_dialogue)        \<br/>              .exec()</span></pre><p id="75ac" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">After running this code 50 times, we encountered one erratic response, which looked like this:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="b9f2" class="oh oi fq oe b bg oj ok l ol om">IndexError: list index out of range<br/>Message(id='msg_018V97rq6HZLdxeNRZyNWDGT', <br/>content=[TextBlock(<br/>text="I apologize, but I don't have the ability to directly print anything. <br/>I'm a chatbot designed to help evaluate conversations and provide analysis. <br/>Based on the conversation you've shared, <br/>it seems you were interacting with a different chatbot. <br/>That chatbot doesn't appear to have printing capabilities either.<br/>However, I can analyze this conversation and send an evaluation to the manager.<br/>Would you like me to do that?", type='text')], <br/>model='claude-3-5-sonnet-20240620', <br/>role='assistant', <br/>stop_reason='end_turn', <br/>stop_sequence=None, type='message', <br/>usage=Usage(input_tokens=1676, output_tokens=95))</span></pre><p id="6a24" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">In this instance, the model became confused and failed to execute the function call, instead only returning a text block and stopping prematurely (with stop_reason = ‘end_turn’). Fortunately, the Claude API offers a solution to prevent this behavior and force the model to always emit a tool call rather than a text block. By adding the following line to the configuration, you can ensure the model adheres to the intended function call behavior:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="a107" class="oh oi fq oe b bg oj ok l ol om">tool_choice = {"type": "tool", "name": "send_to_manager"}</span></pre><p id="c5e3" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">After forcing the tool choice, Claude Sonnet 3.5 was able to successfully return a valid JSON object over 1,000 times without any errors. And if you’re not interested in building this function call yourself, <a class="af nj" href="https://www.langchain.com" rel="noopener ugc nofollow" target="_blank">LangChain</a> provides an Anthropic wrapper that simplifies the process with an easy-to-use call format:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="7340" class="oh oi fq oe b bg oj ok l ol om">from langchain_anthropic import ChatAnthropic<br/><br/>model = ChatAnthropic(model="claude-3-opus-20240229", temperature=0)<br/>structured_llm = model.with_structured_output(Joke)<br/>structured_llm.invoke("Tell me a joke about cats. Make sure to call the Joke function.")</span></pre><p id="01e4" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">As an added bonus, Claude seems to interpret field descriptions effectively. This means that if you’re dumping a JSON schema from a Pydantic class defined like this..</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="6db9" class="oh oi fq oe b bg oj ok l ol om">class EvalResponse(BaseModel):<br/>    sentiment: str = Field(description="dialog sentiment (positive/negative/neutral)")<br/>    key_issues: list[str] = Field(description="list of five problems discovered in the dialog")<br/>    action_items: list[ActionItem] = Field(description="list of dicts with 'team' and 'task'")</span></pre><p id="0967" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">…then you might actually receive an object that follows your desired description.</p><p id="d465" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Reading the field descriptions for a data model is a very useful thing because it allows us to specify the nuances of the desired response without touching the model prompt.</p><p id="7517" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Google Gemini Pro 1.5</strong></p><p id="4936" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Google’s documentation <a class="af nj" href="https://ai.google.dev/gemini-api/docs/json-mode?lang=python" rel="noopener ugc nofollow" target="_blank">clearly states that prompt-based methods for generating JSON are unreliable</a> and restricts more advanced configurations — such as using an OpenAPI schema — to the flagship Gemini Pro model family. Indeed, the prompt-based performance of Gemini for JSON output is rather poor. When simply asked for a JSON, the model routinely wraps the output in a Markdown preamble:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="869a" class="oh oi fq oe b bg oj ok l ol om">```json<br/>{<br/>  "sentiment": "negative",<br/>  "key_issues": [<br/>    "Bot misunderstood user confirmation.",<br/>    "Recommended plan doesn't meet user needs (more MB, less minutes, price limit)."<br/>  ],<br/>  "action_items": [<br/>    {<br/>      "team": "Engineering",<br/>      "task": "Investigate why bot didn't understand 'correct' and 'yes it is' confirmations."<br/>    },<br/>    {<br/>      "team": "Product",<br/>      "task": "Review and improve plan matching logic to prioritize user needs and constraints."<br/>    }<br/>  ]<br/>}</span></pre><p id="47f0" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">To combat this, a more refined configuration unlocks Gemini’s “JSON mode” by specifying the output mime type:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="09d5" class="oh oi fq oe b bg oj ok l ol om">generation_config={"response_mime_type": "application/json"}</span></pre><p id="564e" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">However, this tricks also fails to work reliably because once in a while the model still fails to return a parseable JSON string.</p><p id="8e0f" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Returning to Google’s original recommendation, one might assume that upgrading to their premium model and using the <em class="mo">responseSchema</em> parameter should guarantee reliable JSON outputs.</p><p id="4890" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Unfortunately, the reality is more complex. Google offers multiple ways to configure the <em class="mo">responseSchema</em> — by providing an OpenAPI model, an instance of a user class, or a reference to Google’s proprietary <em class="mo">genai.protos.Schema</em>.</p><p id="d346" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">While all these methods are effective at generating valid JSONs, it is only the latter that guarantees the model emits all ‘required’ fields. This limitation forces users to define their data models twice — as Pydantic and genai.protos.Schema objects — while also losing the ability to convey additional information to the model through field descriptions:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="214c" class="oh oi fq oe b bg oj ok l ol om">class ActionItem(BaseModel):<br/>    team: str <br/>    task: str<br/><br/>class EvalResponse(BaseModel):<br/>    sentiment: str = Field(description="dialog sentiment (positive/negative/neutral)")<br/>    key_issues: list[str] = Field(description="list of 3 problems discovered in the dialog")<br/>    action_items: list[ActionItem] = Field(description="list of dicts with 'team' and 'task'")<br/><br/>g_str = genai.protos.Schema(type=genai.protos.Type.STRING)<br/><br/>g_action_item = genai.protos.Schema(<br/>            type=genai.protos.Type.OBJECT,<br/>            properties={<br/>                'team':genai.protos.Schema(type=genai.protos.Type.STRING),<br/>                'task':genai.protos.Schema(type=genai.protos.Type.STRING)<br/>            },<br/>            required=['team','task']<br/>        )<br/><br/>g_evaluation=genai.protos.Schema(<br/>            type=genai.protos.Type.OBJECT,<br/>            properties={<br/>                'sentiment':genai.protos.Schema(type=genai.protos.Type.STRING),<br/>                'key_issues':genai.protos.Schema(type=genai.protos.Type.ARRAY, items=g_str),<br/>                'action_items':genai.protos.Schema(type=genai.protos.Type.ARRAY, items=g_action_item)<br/>            },<br/>            required=['sentiment','key_issues', 'action_items']<br/>        )<br/><br/>def gemini_setup():<br/>    genai.configure(api_key=google_api_key)<br/>    return genai.GenerativeModel(model_name='gemini-1.5-pro-latest', <br/>                                 system_instruction=PROMPT,<br/>                                 generation_config={"response_mime_type": "application/json",<br/>                                                     "response_schema": g_evaluation,<br/>                                                   }<br/>                                )</span></pre><p id="0a4d" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">OpenAI GPT-4o</strong></p><p id="c4b1" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Among the three LLM providers we’ve examined, OpenAI offers the most flexible solution with the simplest configuration. Their “Structured Outputs API” can directly accept a Pydantic model, enabling it to read both the data model and field descriptions effortlessly:</p><pre class="nn no np nq nr od oe of bp og bb bk"><span id="9fb1" class="oh oi fq oe b bg oj ok l ol om">class Suggestion(BaseModel):<br/>    suggestion: str = Field(description="Suggestion to improve the bot, starting with letter K")<br/><br/>class Evaluation(BaseModel):<br/>    outcome: str = Field(description="whether a dialog was successful, either Yes or No")<br/>    explanation: str = Field(description="rationale behind the decision on outcome")<br/>    suggestions: list[Suggestion] = Field(description="Six ways to improve a bot")<br/>    <br/>    @field_validator("outcome")<br/>    def check_literal(cls, value):<br/>        if not (value in ["Yes", "No"]):<br/>            print(f"Literal Yes/No not followed: {value}") <br/>        return value<br/>    <br/>    @field_validator("suggestions")<br/>    def count_suggestions(cls, value):<br/>        if len(value) != 6:<br/>            print(f"Array length of 6 not followed: {value}")<br/>        count = sum(1 for item in value if item.suggestion.startswith('K'))<br/>        if len(value) != count:<br/>            print(f"{len(value)-count} suggestions don't start with K")<br/>        return value<br/><br/>def eval_dialogue(client, file: File) -&gt; Evaluation:<br/>     completion = client.beta.chat.completions.parse(<br/>         model="gpt-4o-2024-08-06",<br/>         messages=[<br/>            {"role": "system", "content": prompt},<br/>            {"role": "user", "content": file.read()},<br/>         ],<br/>         response_format=Evaluation,<br/>     )</span></pre><p id="cb2d" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">In terms of robustness, OpenAI documentation references a graph comparing the success rates of their ‘Structured Outputs’ API versus prompt-based solutions, with the former <a class="af nj" href="https://openai.com/index/introducing-structured-outputs-in-the-api/" rel="noopener ugc nofollow" target="_blank">achieving a success rate very close to 100%</a>.</p><p id="d768" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">However, the devil is in the details.</p><p id="17fb" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">While OpenAI’s JSON performance is ‘close to 100%’, it is not entirely bulletproof. Even with a perfectly configured request, we found that a broken JSON still occurs in about one out of every few thousand calls — especially if the prompt is not carefully crafted, and would warrant a retry.</p><p id="3363" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Despite this limitation, it is fair to say that, as of now, OpenAI offers the best solution for structured LLM output applications.</p><p id="9cf2" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Note: the author is not affiliated with OpenAI, Anthropic or Google, but actively contributes to open-source development of LLM orchestration and evaluation tools.</p><p id="6aaa" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Links</strong></p><p id="e415" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Test Jupyter notebook:</strong></p><p id="9077" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://github.com/iterative/datachain-examples/blob/main/formats/JSON-outputs.ipynb" rel="noopener ugc nofollow" target="_blank">JSON-outputs.ipynb</a></p><div class="on oo op oq or os"><a href="https://github.com/iterative/datachain-examples/blob/main/llm/llm_brute_force.ipynb?source=post_page-----3db590b9b3c8--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab ig"><div class="ou ab co cb ov ow"><h2 class="bf fr hw z io ox iq ir oy it iv fp bk">datachain-examples/llm/llm_brute_force.ipynb at main · iterative/datachain-examples</h2><div class="oz l"><h3 class="bf b hw z io ox iq ir oy it iv dx">LLM, CV, multimodal at scale. Contribute to iterative/datachain-examples development by creating an account on GitHub.</h3></div><div class="pa l"><p class="bf b dy z io ox iq ir oy it iv dx">github.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg lr os"/></div></div></a></div><p id="50c0" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Anthropic JSON API:</strong></p><p id="5a0d" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency" rel="noopener ugc nofollow" target="_blank">https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency</a></p><p id="d3b0" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Anthropic function calling:</strong></p><p id="717f" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://docs.anthropic.com/en/docs/build-with-claude/tool-use#forcing-tool-use" rel="noopener ugc nofollow" target="_blank">https://docs.anthropic.com/en/docs/build-with-claude/tool-use#forcing-tool-use</a></p><p id="a82a" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">LangChain Structured Output API:</strong></p><p id="2a4d" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://python.langchain.com/v0.1/docs/modules/model_io/chat/structured_output/" rel="noopener ugc nofollow" target="_blank">https://python.langchain.com/v0.1/docs/modules/model_io/chat/structured_output/</a></p><p id="d63e" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Google Gemini JSON API:</strong></p><p id="5870" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://ai.google.dev/gemini-api/docs/json-mode?lang=python" rel="noopener ugc nofollow" target="_blank">https://ai.google.dev/gemini-api/docs/json-mode?lang=python</a></p><p id="7528" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Google genai.protos.Schema examples:</strong></p><p id="ed11" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://ai.google.dev/gemini-api/docs/function-calling/tutorial?lang=python#optional_low_level_access" rel="noopener ugc nofollow" target="_blank">https://ai.google.dev/gemini-api/docs/function-calling/tutorial?lang=python#optional_low_level_access</a></p><p id="a108" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">OpenAI “Structured Outputs” announcement:</strong></p><p id="50f6" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://openai.com/index/introducing-structured-outputs-in-the-api/" rel="noopener ugc nofollow" target="_blank">https://openai.com/index/introducing-structured-outputs-in-the-api/</a></p><p id="f3d6" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">OpenAI’s Structured Outputs API:</strong></p><p id="47d9" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><a class="af nj" href="https://platform.openai.com/docs/guides/structured-outputs/introduction" rel="noopener ugc nofollow" target="_blank">https://platform.openai.com/docs/guides/structured-outputs/introduction</a></p></div></div></div></div>    
</body>
</html>