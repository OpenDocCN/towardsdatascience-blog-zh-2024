- en: LLMOps â€” Serve a Llama-3 model with BentoML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMOps â€” ä½¿ç”¨BentoMLæä¾›Llama-3æ¨¡å‹æœåŠ¡
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09](https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09](https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09)
- en: '![](../Images/338cd1cb8fd84b57aa00595d61685ee8.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/338cd1cb8fd84b57aa00595d61685ee8.png)'
- en: Photo by [Simon Wiedensohler](https://unsplash.com/@simonwiedensohler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±[Simon Wiedensohler](https://unsplash.com/@simonwiedensohler?utm_source=medium&utm_medium=referral)æ‹æ‘„ï¼Œæ¥æºï¼š[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Quickly set up LLM APIs with BentoML and Runpod
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¿«é€Ÿè®¾ç½®LLM APIï¼Œä½¿ç”¨BentoMLå’ŒRunpod
- en: '[](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    Â·6 min readÂ·Aug 9, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    Â·6åˆ†é’Ÿé˜…è¯»Â·2024å¹´8æœˆ9æ—¥
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¼•è¨€
- en: I often see data scientists getting interested in the development of LLMs in
    terms of model architecture, training techniques or data collection. However,
    I have noticed that many times, outside the theoretical aspect, in many people
    have problems in serving these models in a way that they can actually be used
    by users.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç»å¸¸çœ‹åˆ°æ•°æ®ç§‘å­¦å®¶å¯¹LLMçš„æ¨¡å‹æ¶æ„ã€è®­ç»ƒæŠ€æœ¯æˆ–æ•°æ®æ”¶é›†äº§ç”Ÿå…´è¶£ã€‚ç„¶è€Œï¼Œæˆ‘æ³¨æ„åˆ°ï¼Œå¾ˆå¤šæ—¶å€™ï¼Œåœ¨ç†è®ºå±‚é¢ä¹‹å¤–ï¼Œè®¸å¤šäººåœ¨å°†è¿™äº›æ¨¡å‹éƒ¨ç½²ä¸ºå¯ä¾›ç”¨æˆ·ä½¿ç”¨æ—¶é‡åˆ°å›°éš¾ã€‚
- en: In this brief tutorial, I thought I would show in a very simple way how you
    can serve an LLM, specifically llama-3, using [BentoML](https://www.bentoml.com/).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç®€çŸ­çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘å°†ä»¥éå¸¸ç®€å•çš„æ–¹å¼å±•ç¤ºå¦‚ä½•ä½¿ç”¨[BentoML](https://www.bentoml.com/)æä¾›LLMæœåŠ¡ï¼Œç‰¹åˆ«æ˜¯llama-3æ¨¡å‹ã€‚
- en: BentoML is an end-to-end solution for machine learning model serving. It facilitates
    Data Science teams to develop production-ready model serving endpoints, with DevOps
    best practices and performance optimization at every stage.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: BentoMLæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æœºå™¨å­¦ä¹ æ¨¡å‹æœåŠ¡è§£å†³æ–¹æ¡ˆã€‚å®ƒå¸®åŠ©æ•°æ®ç§‘å­¦å›¢é˜Ÿå¼€å‘ç”Ÿäº§å°±ç»ªçš„æ¨¡å‹æœåŠ¡ç«¯ç‚¹ï¼Œåœ¨æ¯ä¸ªé˜¶æ®µéƒ½å®ç°DevOpsæœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–ã€‚
- en: We need GPU
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦GPU
- en: As you know in Deep Learning having the right hardware available is critical.
    Especially for very large models like LLMs, this becomes even more important.
    Unfortunately, I donâ€™t have any GPU ğŸ˜”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€çŸ¥ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ‹¥æœ‰åˆé€‚çš„ç¡¬ä»¶è‡³å…³é‡è¦ã€‚å°¤å…¶å¯¹äºåƒLLMè¿™æ ·çš„å¤§å‹æ¨¡å‹ï¼Œè¿™ä¸€ç‚¹æ›´åŠ é‡è¦ã€‚ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘æ²¡æœ‰GPU ğŸ˜”
- en: Thatâ€™s why I rely on external providers, so I rent one of their machines and
    work there. I chose for this article to work on [Runpod](https://www.runpod.io/)
    because I know their services and I think it is an affordable price to follow
    this tutorial. But if you have GPUs available or want toâ€¦
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä¾èµ–å¤–éƒ¨æä¾›å•†ï¼Œæ‰€ä»¥æˆ‘ç§Ÿç”¨ä»–ä»¬çš„æœºå™¨å¹¶åœ¨é‚£é‡Œå·¥ä½œã€‚ä¸ºäº†è¿™ç¯‡æ–‡ç« ï¼Œæˆ‘é€‰æ‹©äº†[Runpod](https://www.runpod.io/)ï¼Œå› ä¸ºæˆ‘äº†è§£ä»–ä»¬çš„æœåŠ¡ï¼Œå¹¶ä¸”æˆ‘è®¤ä¸ºè¿™ä¸ªä»·æ ¼é€‚åˆè·Ÿéšæœ¬æ•™ç¨‹ã€‚ä½†å¦‚æœä½ æœ‰GPUæˆ–è€…æƒ³è¦â€¦
