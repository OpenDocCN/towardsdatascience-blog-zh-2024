- en: LLMOps â€” Serve a Llama-3 model with BentoML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09](https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/338cd1cb8fd84b57aa00595d61685ee8.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Simon Wiedensohler](https://unsplash.com/@simonwiedensohler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Quickly set up LLM APIs with BentoML and Runpod
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    Â·6 min readÂ·Aug 9, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I often see data scientists getting interested in the development of LLMs in
    terms of model architecture, training techniques or data collection. However,
    I have noticed that many times, outside the theoretical aspect, in many people
    have problems in serving these models in a way that they can actually be used
    by users.
  prefs: []
  type: TYPE_NORMAL
- en: In this brief tutorial, I thought I would show in a very simple way how you
    can serve an LLM, specifically llama-3, using [BentoML](https://www.bentoml.com/).
  prefs: []
  type: TYPE_NORMAL
- en: BentoML is an end-to-end solution for machine learning model serving. It facilitates
    Data Science teams to develop production-ready model serving endpoints, with DevOps
    best practices and performance optimization at every stage.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We need GPU
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you know in Deep Learning having the right hardware available is critical.
    Especially for very large models like LLMs, this becomes even more important.
    Unfortunately, I donâ€™t have any GPU ðŸ˜”
  prefs: []
  type: TYPE_NORMAL
- en: Thatâ€™s why I rely on external providers, so I rent one of their machines and
    work there. I chose for this article to work on [Runpod](https://www.runpod.io/)
    because I know their services and I think it is an affordable price to follow
    this tutorial. But if you have GPUs available or want toâ€¦
  prefs: []
  type: TYPE_NORMAL
