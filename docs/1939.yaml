- en: LLMOps — Serve a Llama-3 model with BentoML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMOps — 使用BentoML提供Llama-3模型服务
- en: 原文：[https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09](https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09](https://towardsdatascience.com/llmops-serve-a-llama-3-model-with-bentoml-4d580a7a007f?source=collection_archive---------6-----------------------#2024-08-09)
- en: '![](../Images/338cd1cb8fd84b57aa00595d61685ee8.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/338cd1cb8fd84b57aa00595d61685ee8.png)'
- en: Photo by [Simon Wiedensohler](https://unsplash.com/@simonwiedensohler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Simon Wiedensohler](https://unsplash.com/@simonwiedensohler?utm_source=medium&utm_medium=referral)拍摄，来源：[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Quickly set up LLM APIs with BentoML and Runpod
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速设置LLM API，使用BentoML和Runpod
- en: '[](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page---byline--4d580a7a007f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    ·6 min read·Aug 9, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4d580a7a007f--------------------------------)
    ·6分钟阅读·2024年8月9日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: I often see data scientists getting interested in the development of LLMs in
    terms of model architecture, training techniques or data collection. However,
    I have noticed that many times, outside the theoretical aspect, in many people
    have problems in serving these models in a way that they can actually be used
    by users.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我经常看到数据科学家对LLM的模型架构、训练技术或数据收集产生兴趣。然而，我注意到，很多时候，在理论层面之外，许多人在将这些模型部署为可供用户使用时遇到困难。
- en: In this brief tutorial, I thought I would show in a very simple way how you
    can serve an LLM, specifically llama-3, using [BentoML](https://www.bentoml.com/).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简短的教程中，我将以非常简单的方式展示如何使用[BentoML](https://www.bentoml.com/)提供LLM服务，特别是llama-3模型。
- en: BentoML is an end-to-end solution for machine learning model serving. It facilitates
    Data Science teams to develop production-ready model serving endpoints, with DevOps
    best practices and performance optimization at every stage.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: BentoML是一个端到端的机器学习模型服务解决方案。它帮助数据科学团队开发生产就绪的模型服务端点，在每个阶段都实现DevOps最佳实践和性能优化。
- en: We need GPU
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们需要GPU
- en: As you know in Deep Learning having the right hardware available is critical.
    Especially for very large models like LLMs, this becomes even more important.
    Unfortunately, I don’t have any GPU 😔
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，在深度学习中，拥有合适的硬件至关重要。尤其对于像LLM这样的大型模型，这一点更加重要。不幸的是，我没有GPU 😔
- en: That’s why I rely on external providers, so I rent one of their machines and
    work there. I chose for this article to work on [Runpod](https://www.runpod.io/)
    because I know their services and I think it is an affordable price to follow
    this tutorial. But if you have GPUs available or want to…
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我依赖外部提供商，所以我租用他们的机器并在那里工作。为了这篇文章，我选择了[Runpod](https://www.runpod.io/)，因为我了解他们的服务，并且我认为这个价格适合跟随本教程。但如果你有GPU或者想要…
