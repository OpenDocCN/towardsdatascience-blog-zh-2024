<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>When Averages Lie: Moving Beyond Single-Point Predictions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>When Averages Lie: Moving Beyond Single-Point Predictions</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/when-averages-lie-moving-beyond-single-point-predictions-23201e8c04c8?source=collection_archive---------1-----------------------#2024-12-17">https://towardsdatascience.com/when-averages-lie-moving-beyond-single-point-predictions-23201e8c04c8?source=collection_archive---------1-----------------------#2024-12-17</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="5642" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">The Case for Predicting Full Probability Distributions in Decision-Making</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@loic.merckel?source=post_page---byline--23201e8c04c8--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Loic Merckel" class="l ep by dd de cx" src="../Images/339b21f1106f13b9326c43d609d3cb77.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*lhhmQaAZIbdrXBVI"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--23201e8c04c8--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@loic.merckel?source=post_page---byline--23201e8c04c8--------------------------------" rel="noopener follow">Loic Merckel</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--23201e8c04c8--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 17, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">3</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/a2f90cfeffa6b0505974eccb78a3b850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fnVEMTmE9ETvdimmXusbfw.jpeg"/></div></div></figure><p id="a1f7" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Some people like hot coffee, some people like iced coffee, but no one likes lukewarm coffee. Yet, a simple model trained on coffee temperatures might predict that the next coffee served should be… lukewarm. This illustrates a fundamental problem in predictive modeling: focusing on single point estimates (e.g., averages) can lead us to meaningless or even misleading conclusions.</p><p id="bdaa" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In “<a class="af nt" href="https://medium.com/@loic.merckel/the-crystal-ball-fallacy-what-perfect-predictive-models-really-mean-aa843067ee30" rel="noopener">The Crystal Ball Fallacy</a>” (Merckel, 2024b), we explored how even a perfect predictive model does not tell us exactly what will happen — it tells us what could happen and how likely each outcome is. In other words, it reveals the true distribution of a random variable. While such a perfect model remains hypothetical, real-world models should still strive to approximate these true distributions.</p><p id="06e6" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Yet many predictive models used in the corporate world do something quite different: they focus solely on point estimates — typically the mean or the mode — rather than attempting to capture the full range of possibilities. This is not just a matter of how the predictions are used; this limitation is inherent in the design of many conventional machine learning algorithms. Random forests, generalized linear models (GLM), artificial neural networks (ANNs), and gradient boosting machines, among others, are all designed to predict the expected value (mean) of a distribution when used for regression tasks. In classification problems, while logistic regression and other GLMs naturally attempt to estimate probabilities of class membership, tree-based methods like random forests and gradient boosting produce raw scores that would require additional calibration steps (like isotonic regression or Platt scaling) to be transformed into meaningful probabilities. Yet in practice, this calibration is rarely performed, and even when uncertainty information is available (i.e., the probabilities), it is typically discarded in favor of the single most likely class, i.e., the mode.</p><p id="2ebc" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This oversimplification is sometimes not just inadequate; it can lead to fundamentally wrong conclusions, much like our lukewarm coffee predictor. A stark example is the Gaussian copula formula used to price collateralized debt obligations (CDOs) before the 2008 financial crisis. By reducing the complex relationships between mortgage defaults to a single correlation number, among other issues, this model catastrophically underestimated the possibility of simultaneous defaults (MacKenzie &amp; Spears, 2014). This systematic underestimation of extreme risks is so pervasive that some investment funds, like Universa Investments advised by Nassim Taleb, incorporate strategies to capitalize on it. They recognize that markets consistently undervalue the probability and impact of extreme events (Patterson, 2023). When we reduce a complex distribution of possible outcomes to a single number, we lose critical information about uncertainty, risk, and potential extreme events that could drastically impact decision-making.</p><p id="e1e2" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">On the other hand, some quantitative trading firms have built their success partly by properly modeling these complex distributions. When asked about Renaissance Technologies’ approach — whose Medallion fund purportedly achieved returns of 66% annually before fees from 1988 to 2018 (Zuckerman, 2019) — founder Jim Simons emphasized that they carefully consider that market risk “is typically not a normal distribution, the tails of a distribution are heavier and the inside is not as heavy” (Simons, 2013, 47:41), highlighting the critical importance of looking beyond simple averages.</p><p id="3db0" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Why, then, do we persist in using point estimates despite their clear limitations? The reasons may be both practical and cultural. Predicting distributions is technically more challenging than predicting single values, requiring more sophisticated models and greater computational resources. But more fundamentally, most business processes and tools are simply not designed to handle distributional thinking. You cannot put a probability distribution in a spreadsheet cell, and many decision-making frameworks demand concrete numbers rather than ranges of possibilities. Moreover, as Kahneman (2011) notes in his analysis of human decision-making, we are naturally inclined to think in terms of specific scenarios rather than statistical distributions — our intuitive thinking prefers simple, concrete answers over probabilistic ones.</p><p id="a064" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Let us examine actual housing market data to illustrate potential issues with single-point valuation and possible modeling techniques to capture the full distribution of possible values.</p><h1 id="bc03" class="nu nv fq bf nw nx ny gq nz oa ob gt oc od oe of og oh oi oj ok ol om on oo op bk">A Deep Dive into Property Pricing</h1><p id="6e04" class="pw-post-body-paragraph mx my fq mz b go oq nb nc gr or ne nf ng os ni nj nk ot nm nn no ou nq nr ns fj bk">In this section, we use the French Real Estate Transactions (DVF) dataset provided by the French government (gouv.fr, 2024), which contains comprehensive records of property transactions across France. For this analysis, we focus on sale prices, property surface areas, and the number of rooms for the years ranging from 2014 to 2024. Notably, we exclude critical information such as geolocation, as our aim is not to predict house prices but to demonstrate the benefits of predicting distributions over relying solely on single-point estimates.</p><p id="f838" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">First, we will go through a fictional — yet most likely à clef — case study where a common machine learning technique is put into action for planning an ambitious real estate operation. Subsequently, we will adopt a critical stance on this case and offer alternatives that many may prefer in order to be better prepared for pulling off the trade.</p><h2 id="1800" class="ov nv fq bf nw ow ox oy nz oz pa pb oc ng pc pd pe nk pf pg ph no pi pj pk pl bk">Case Study: The Homer &amp; Lisa Reliance on AI for Real Estate Trading</h2><p id="c23b" class="pw-post-body-paragraph mx my fq mz b go oq nb nc gr or ne nf ng os ni nj nk ot nm nn no ou nq nr ns fj bk">Homer and Lisa live in Paris. They expect the family to grow and envisage to sell their two-room flat to fund the acquisition of a four-room property. Given the operational and maintenance costs, and the capacity of their newly acquired state-of-the-art Roomba with all options, they reckoned that 90m² is the perfect surface area for them. They want to estimate how much they need to save/borrow to complement the proceeds from the sale. Homer followed a MOOC on machine learning just before graduating in advanced French literature last year, and immediately found — thanks to his network — a data scientist role at a large reputable traditional firm that was heavily investing in expanding (admittedly from scratch, really) its AI capacity to avoid missing out. Now a Principal Senior Lead Data Scientist, after almost a year of experience, he knows quite a bit! (He even <a class="af nt" href="https://medium.com/@loic.merckel/data-driven-or-data-derailed-lessons-from-the-hello-world-classifier-764fdf4dbb60" rel="noopener">works for a zoo as a side hustle</a>, where his performance has not remained unnoticed — Merckel, 2024a.)</p><p id="e264" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Following some googling, he found the real estate dataset freely provided by the government. He did a bit of cleaning, filtering, and aggregating to obtain the perfect ingredients for his ordinary least squares model (OLS for those in the know). He can now confidently predict prices, in the Paris area, from both the number of rooms and the surface. Their 2-room, 40m², flat is worth 365,116€. And a 4-room, 90m², reaches 804,911€. That is a no-brainer; they must calculate the difference, i.e., 439,795€.</p><h2 id="45a7" class="ov nv fq bf nw ow ox oy nz oz pa pb oc ng pc pd pe nk pf pg ph no pi pj pk pl bk">Homer &amp; Lisa: The Ones Playing Darts… Unknowingly!</h2><p id="9cb7" class="pw-post-body-paragraph mx my fq mz b go oq nb nc gr or ne nf ng os ni nj nk ot nm nn no ou nq nr ns fj bk">Do Homer and Lisa need to save/borrow 439,795€? The model certainly suggests so. But is that so?</p><p id="cbac" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Perhaps Homer, if only he knew, could have provided confidence intervals? Using OLS, confidence intervals can either be estimated empirically via bootstrapping or analytically using standard error-based methods.</p><p id="ba40" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Besides, even before that, he could have looked at the price distribution, and realized the default OLS methods may not be the best choice…</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pm"><img src="../Images/6dbab750739cd8068a540a2d81ead474.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wRwQEWuzpNw6TDkensFbxA.jpeg"/></div></div><figcaption class="pn po pp mj mk pq pr bf b bg z dx"><strong class="bf nw">Figure 1: Real Estate Prices Near Paris (2014–2024):</strong> The left plot illustrates the distribution of real estate prices within a 7km radius of central Paris. The right plot shows the distribution of the natural logarithm of those prices. In both histograms, the final bar represents the cumulative count of properties priced above 2,000,000€ (or log(2,000,000) in the logarithmic scale). Image by the author.</figcaption></figure><p id="19fa" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The right-skewed shape with a long tail is hard to miss. For predictive modeling (as opposed to, e.g., explanatory modeling), the primary concern with OLS is not necessarily the normality (and homoscedasticity) of errors but the potential for extreme values in the long tail to disproportionately influence the model — OLS minimizes squared errors, making it sensitive to extreme observations, particularly those that deviate significantly from the Gaussian distribution assumed for the errors.</p><p id="9bfc" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">A Generalized Linear Model (GLM) extends the linear model framework by directly specifying a distribution for the response variable (from the exponential family) and using a “link function” to connect the linear predictor to the mean of that distribution. While linear models assume normally distributed errors and estimate the expected response E(Y) directly through a linear predictor, GLMs allow for different response distributions and transform the relationship between the linear predictor and E(Y) through the link function.</p><p id="ad55" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Let us revisit Homer and Lisa’s situation using a simpler but related approach. Rather than implementing a GLM, we can transform the data by taking the natural logarithm of prices before applying a linear model. This implies we are modeling prices as following a log-normal distribution (Figure 1 presents the distribution of prices and the log version). When transforming predictions back to the original scale, we need to account for the bias introduced by the log transformation using Duan’s smearing estimator (Duan, 1983). Using this bias-corrected log-normal model and fitting it on properties around Paris, their current 2-room, 40m² flat is estimated at 337,844€, while their target 4-room, 90m² property would cost around 751,884€, hence a need for an additional 414,040€.</p><p id="353a" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The log-normal model with smearing correction is particularly suitable for this context because it not only reflects multiplicative relationships, such as price increasing proportionally (by a factor) rather than by a fixed amount when the number of rooms or surface area increases, but also properly accounts for the retransformation bias that would otherwise lead to systematic underestimation of prices.</p><p id="fc10" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">To better understand the uncertainty in these predictions, we can examine their confidence intervals. The 95% bootstrap confidence interval [400,740€ — 418,618€] for the mean price difference means that if we were to repeat this sampling process many times, about 95% of such intervals would contain the true mean price difference. This interval is more reliable in this context than the standard error-based 95% confidence interval because it does not depend on strict parametric assumptions about the model, such as the distribution of errors or the adequacy of the model’s specification. Instead, it captures the observed data’s variability and complexity, accounting for unmodeled factors and potential deviations from idealized assumptions. For instance, our model only considers the number of rooms and surface area, while real estate prices in Paris are influenced by many other factors — proximity to metro stations, architectural style, floor level, building condition, and local neighborhood dynamics, and even broader economic conditions such as prevailing interest rates.</p><p id="b1f4" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In light of this analysis, the log-normal model provides a new and arguably more realistic point estimate of 414,040€ for the price difference. However, the confidence interval, while statistically rigorous, might not be the most useful for Homer and Lisa’s practical planning needs. Instead, to better understand the full range of possible prices and provide more actionable insights for their planning, we might turn to Bayesian modeling. This approach would allow us to estimate the complete probability distribution of potential price differences, rather than just point estimates and confidence intervals.</p><h2 id="ab68" class="ov nv fq bf nw ow ox oy nz oz pa pb oc ng pc pd pe nk pf pg ph no pi pj pk pl bk">The Prior, The Posterior, and The Uncertain</h2><p id="27fe" class="pw-post-body-paragraph mx my fq mz b go oq nb nc gr or ne nf ng os ni nj nk ot nm nn no ou nq nr ns fj bk">Bayesian modeling offers a more comprehensive approach to understanding uncertainty in predictions. Instead of calculating just a single “best guess” price difference or even a confidence interval, Bayesian methods provide the full probability distribution of possible prices.</p><p id="addf" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The process begins with expressing our “prior beliefs” about property prices — what we consider reasonable based on existing knowledge. In practice, this involves defining prior distributions for the parameters of the model (e.g., the weights of the number of rooms and surface area) and specifying how we believe the data is generated through a likelihood function (which gives us the probability of observing prices given our model parameters). We then incorporate actual sales data (our “evidence”) into the model. By combining these through Bayes’ theorem, we derive the “posterior distribution,” which provides an updated view of the parameters and predictions, reflecting the uncertainty in our estimates given the data. This posterior distribution is what Homer and Lisa would truly find valuable.</p><p id="7401" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Given the right-skewed nature of the price data, a log-normal distribution appears to be a reasonable assumption for the likelihood. This choice should be validated with posterior predictive checks to ensure it adequately captures the data’s characteristics. For the parameters, Half-Gaussian distributions constrained to be positive can reflect our assumption that prices increase with the number of rooms and surface area. The width of these priors reflects the range of possible effects, capturing our uncertainty in how much prices increase with additional rooms or surface area.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pm"><img src="../Images/3e9d3f97d80557da7b60af077a501cf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OqdD3TsHmEwr92PkvTsSMA.jpeg"/></div></div><figcaption class="pn po pp mj mk pq pr bf b bg z dx"><strong class="bf nw">Figure 2: Predicted Price Distributions for 2-Room (40m²) and 4-Room (90m²) Properties: </strong>The left plot shows the predicted price distribution for a 2-room, 40m² property, while the right plot illustrates the predicted price distribution for a 4-room, 90m² property. Image by the author.</figcaption></figure><p id="f6d5" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The Bayesian approach provides a stark contrast to our earlier methods. While the OLS and <em class="ps">pseudo</em>-GLM (so called because the log-normal distribution is not a member of the exponential family) gave us single predictions with some uncertainty bounds, the Bayesian model reveals complete probability distributions for both properties. Figure 2 illustrates these predicted price distributions, showing not just point estimates but the full range of likely prices for each property type. The overlapping regions between the two distributions reveal that housing prices are not strictly determined by size and room count — unmodeled factors like location quality, building condition, or market timing can sometimes make smaller properties more expensive than larger ones.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pm"><img src="../Images/a9cd291d769e060fda51d1d20268aedc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*toQuYne2q7uwUXF9uWMCgg.jpeg"/></div></div><figcaption class="pn po pp mj mk pq pr bf b bg z dx"><strong class="bf nw">Figure 3: Distribution of Predicted Price Differences Between 2-Room (40m²) and 4-Room (90m²) Properties:</strong> This plot illustrates the distribution of predicted price differences, obtained via a Monte Carlo simulation, capturing the uncertainty in the model parameters. The mean price difference is approximately 405,697€, while the median is 337,281€, reflecting a slight right skew in the distribution. Key percentiles indicate a wide range of variability: the 10th percentile is -53,318€, the 25th percentile is 126,602€, the 75th percentile is 611,492€, and the 90th percentile is 956,934€. The standard deviation of 448,854€ highlights significant uncertainty in these predictions. Image by the author.</figcaption></figure><p id="e3c8" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">To understand what this means for Homer and Lisa’s situation, we need to estimate the distribution of price differences between the two properties. Using Monte Carlo simulation, we repeatedly draw samples from both predicted distributions and calculate their differences, building up the distribution shown in Figure 3. The results are sobering: while the mean difference suggests they would need to find an additional 405,697€, there is substantial uncertainty around this figure. In fact, approximately 13.4% of the simulated scenarios result in a negative price difference, meaning there is a non-negligible chance they could actually make money on the transaction. However, they should also be prepared for the possibility of needing significantly more money — there is a 25% chance they will need over 611,492€ — and 10% over 956,934€ — extra to make the upgrade.</p><p id="8218" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This more complete picture of uncertainty gives Homer and Lisa a much better foundation for their decision-making than the seemingly precise single numbers provided by our earlier analyses.</p><h2 id="839f" class="ov nv fq bf nw ow ox oy nz oz pa pb oc ng pc pd pe nk pf pg ph no pi pj pk pl bk">Sometimes Less is More: The One With The Raw Data</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pm"><img src="../Images/1a3e331874675df0d1e3bec089087c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VSoeCZnwCIDG7c62vmt2tg.jpeg"/></div></div><figcaption class="pn po pp mj mk pq pr bf b bg z dx"><strong class="bf nw">Figure 4: Distribution of Simulated Price Differences Between 2-Room (40m²) and 4-Room (90m²) Properties:</strong> This distribution is obtained through Monte Carlo simulation by randomly pairing actual transactions of 2-room (35–45m²) and 4-room (85–95m²) properties. The mean price difference is 484,672€ (median: 480,000€), with a substantial spread shown by the 90% percentile interval ranging from -52,810€ to 1,014,325€. The shaded region below zero, representing about 6.6% of scenarios, indicates cases where a 4-room property might be found at a lower price than a 2-room one. The distribution’s right skew suggests that while most price differences cluster around the median, there is a notable chance of encountering much larger differences, with 5% of cases exceeding 1,014,325€. Image by the author.</figcaption></figure><p id="b768" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Rather than relying on sophisticated Bayesian modeling, we can gain clear insights from directly analyzing similar transactions. Looking at properties around Paris, we found 36,265 2-room flats (35–45m²) and 4,145 4-room properties (85–95m²), providing a rich dataset of actual market behavior.</p><p id="b8d8" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The data shows substantial price variation. Two-room properties have a mean price of 329,080€ and a median price of 323,000€, with 90% of prices falling between 150,000€ and 523,650€. Four-room properties show even wider variation, with a mean price of 812,015€, a median price of 802,090€ and a 90% range from 315,200€ to 1,309,227€.</p><p id="dba0" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Using Monte Carlo simulation to randomly pair properties, we can estimate what Homer and Lisa might face. The mean price difference is 484,672€ and the median price difference is 480,000€, with the middle 50% of scenarios requiring between 287,488€ and 673,000€. Moreover, in 6.6% of cases, they might even find a 4-room property cheaper than their 2-room sale and make money.</p><p id="3d7a" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This straightforward approach uses actual transactions rather than model predictions, making no assumptions about price relationships while capturing real market variability. For Homer and Lisa’s planning, the message is clear: while they should prepare for needing around 480,000€, they should be ready for scenarios requiring significantly more or less. Understanding this range of possibilities is crucial for their financial planning.</p><p id="7219" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This simple technique works particularly well here because we have a dense dataset with over 40,000 relevant transactions across our target property categories. However, in many situations relying on predictive modeling, we might face sparse data. In such cases, we would need to interpolate between different data points or extrapolate beyond our available data. This is where Bayesian models are particularly powerful…</p><h1 id="68a3" class="nu nv fq bf nw nx ny gq nz oa ob gt oc od oe of og oh oi oj ok ol om on oo op bk">Final Remarks</h1><p id="5d50" class="pw-post-body-paragraph mx my fq mz b go oq nb nc gr or ne nf ng os ni nj nk ot nm nn no ou nq nr ns fj bk">The journey through these analytical approaches — OLS, log-normal modeling, Bayesian analysis, and Monte Carlo simulation — offers more than a range of price predictions. It highlights how we can handle uncertainty in predictive modeling with increasing sophistication. From the deceptively precise OLS estimate (439,795€) to the nuanced log-normal model (414,040€), and finally, to distributional insights provided by Bayesian and Monte Carlo methods (with means of 405,697€ and 484,672€, respectively), each method provides a unique perspective on the same problem.</p><p id="5636" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This progression demonstrates when distributional thinking becomes beneficial. For high-stakes, one-off decisions like Homer and Lisa’s, understanding the full range of possibilities provides a clear advantage. In contrast, repetitive decisions with low individual stakes, like online ad placements, can often rely on simple point estimates. However, in domains where tail risks carry significant consequences — such as portfolio management or major financial planning — modeling the full distribution is not just beneficial but fundamentally wise.</p><p id="4b21" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">It is important to acknowledge the real-world complexities simplified in this case study. Factors like interest rates, temporal dynamics, transaction costs, and other variables significantly influence real estate pricing. Our objective was not to develop a comprehensive housing price predictor but to illustrate, step-by-step, the progression from a naive single-point estimate to a full distribution.</p><p id="9457" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">It is worth noting that, given our primary aim of illustrating this progression — from point estimates to distributional thinking — we deliberately kept our models simple. The OLS and <em class="ps">pseudo</em>-GLM implementations were used without interaction terms — and thus without regularization or hyperparameter tuning — and minimal preprocessing was applied. While the high correlation between the number of rooms and surface area is not particularly problematic for predictive modeling in general, it can affect the sampling efficiency of the Markov chain Monte Carlo (MCMC) methods used in our Bayesian models by creating ridges in the posterior distribution that are harder to explore efficiently (indeed, we observed a strong ridge structure with correlation of -0.74 between these parameters, though effective sample sizes remained reasonable at about 50% of total samples, suggesting our inference should be sufficiently stable for our illustrative purposes). For the Bayesian approaches specifically, there is substantial room for improvement through defining more informative priors or the inclusion of additional covariates. While such optimizations might yield somewhat different numerical results, they would likely not fundamentally alter the key insights about the importance of considering full distributions rather than point estimates.</p><p id="fa9b" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Finally, we must accept that even our understanding of uncertainty is uncertain. The confidence we place in distributional predictions depends on model assumptions and data quality. This “uncertainty about uncertainty” challenges us not only to refine our models but also to communicate their limitations transparently.</p><p id="3eb9" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Embracing distributional thinking is not merely a technical upgrade — it is a mindset shift. Single-point predictions may feel actionable, but they often provide a false sense of precision, ignoring the inherent variability of outcomes. By considering the full spectrum of possibilities, we equip ourselves to make better-informed decisions and develop strategies that are better prepared for the randomness of the real world.</p><h1 id="f857" class="nu nv fq bf nw nx ny gq nz oa ob gt oc od oe of og oh oi oj ok ol om on oo op bk">Sources</h1><h2 id="9bbe" class="ov nv fq bf nw ow ox oy nz oz pa pb oc ng pc pd pe nk pf pg ph no pi pj pk pl bk">References</h2><p id="255a" class="pw-post-body-paragraph mx my fq mz b go oq nb nc gr or ne nf ng os ni nj nk ot nm nn no ou nq nr ns fj bk">- <strong class="mz fr">Duan, N.</strong> (1983). <em class="ps">Smearing estimate: A nonparametric retransformation method</em>. Journal of the American Statistical Association, 78(383), 605–610. Available from <a class="af nt" href="https://www.jstor.org/stable/2288126" rel="noopener ugc nofollow" target="_blank">https://www.jstor.org/stable/2288126</a>.<br/>- <strong class="mz fr">Kahneman, D.</strong> (2011). <em class="ps">Thinking, Fast and Slow. </em>Kindle edition. ASIN B00555X8OA.<br/>- <strong class="mz fr">MacKenzie, D., &amp; Spears, T.</strong> (2014). <em class="ps">‘The formula that killed Wall Street’: The Gaussian copula and modelling practices in investment banking</em>. Social Studies of Science, 44(3), 393–417. Available from <a class="af nt" href="https://www.jstor.org/stable/43284238" rel="noopener ugc nofollow" target="_blank">https://www.jstor.org/stable/43284238</a>.<br/>- <strong class="mz fr">Patterson, S.</strong> (2023). <em class="ps">Chaos Kings: How Wall Street Traders Make Billions in the New Age of Crisis. </em>Kindle edition. ASIN B0BSB49L11.<br/>- <strong class="mz fr">Zuckerman, G.</strong> (2019). <em class="ps">The Man Who Solved the Market: How Jim Simons Launched the Quant Revolution. </em>Kindle edition. ASIN B07NLFC63Y.</p><h2 id="b39b" class="ov nv fq bf nw ow ox oy nz oz pa pb oc ng pc pd pe nk pf pg ph no pi pj pk pl bk">Notes</h2><p id="0478" class="pw-post-body-paragraph mx my fq mz b go oq nb nc gr or ne nf ng os ni nj nk ot nm nn no ou nq nr ns fj bk">- <strong class="mz fr">gouv.fr</strong> (2024). <em class="ps">Demandes de valeurs foncières (DVF)</em>, Retrieved from <a class="af nt" href="https://www.data.gouv.fr/fr/datasets/5c4ae55a634f4117716d5656/" rel="noopener ugc nofollow" target="_blank">https://www.data.gouv.fr/fr/datasets/5c4ae55a634f4117716d5656/</a>.<br/>- <strong class="mz fr">Merckel, L.</strong> (2024a). <em class="ps">Data-Driven or Data-Derailed? Lessons from the Hello-World Classifier</em>. Retrieved from <a class="af nt" href="https://619.io/blog/2024/11/28/data-driven-or-data-derailed/" rel="noopener ugc nofollow" target="_blank">https://619.io/blog/2024/11/28/data-driven-or-data-derailed/</a>.<br/>- <strong class="mz fr">Merckel, L.</strong> (2024b). <em class="ps">The Crystal Ball Fallacy: What Perfect Predictive Models Really Mean</em>. Retrieved from <a class="af nt" href="https://619.io/blog/2024/12/03/the-crystal-ball-fallacy/" rel="noopener ugc nofollow" target="_blank">https://619.io/blog/2024/12/03/the-crystal-ball-fallacy/</a>.<br/>- <strong class="mz fr">Simons, J. H.</strong> (2013). <em class="ps">Mathematics, Common Sense, and Good Luck: My Life and Careers. </em>Video lecture. YouTube. <a class="af nt" href="https://www.youtube.com/watch?v=SVdTF4_QrTM" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=SVdTF4_QrTM</a>.</p></div></div></div><div class="ab cb pt pu pv pw" role="separator"><span class="px by bm py pz qa"/><span class="px by bm py pz qa"/><span class="px by bm py pz"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="218f" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Art and text by Loic Merckel. Licensed under <a class="af nt" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">CC BY 4.0</a>. Originally published on <a class="af nt" href="https://619.io/" rel="noopener ugc nofollow" target="_blank">619.io</a>. For discussions or engagement, feel free to refer to the <a class="af nt" href="https://www.linkedin.com/pulse/when-averages-lie-moving-beyond-single-point-loic-merckel-jptxe" rel="noopener ugc nofollow" target="_blank">LinkedIn version</a> or <a class="af nt" href="https://medium.com/@loic.merckel/when-averages-lie-moving-beyond-single-point-predictions-23201e8c04c8" rel="noopener">Medium version</a>. Otherwise, attribute the <a class="af nt" href="https://www.619.io/blog/2024/12/17/when-averages-lie/" rel="noopener ugc nofollow" target="_blank">original source</a> when sharing or reusing.</p></div></div></div></div>    
</body>
</html>