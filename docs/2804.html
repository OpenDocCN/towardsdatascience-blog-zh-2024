<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Dance Between Dense and Sparse Embeddings: Enabling Hybrid Search in LangChain-Milvus</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Dance Between Dense and Sparse Embeddings: Enabling Hybrid Search in LangChain-Milvus</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dance-between-dense-and-sparse-embeddings-enabling-hybrid-search-in-langchain-milvus-7c8de54dda24?source=collection_archive---------8-----------------------#2024-11-19">https://towardsdatascience.com/dance-between-dense-and-sparse-embeddings-enabling-hybrid-search-in-langchain-milvus-7c8de54dda24?source=collection_archive---------8-----------------------#2024-11-19</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="96f3" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How to create and search multi-vector-store in langchain-milvus</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://ohadeytan.medium.com/?source=post_page---byline--7c8de54dda24--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ohad Eytan" class="l ep by dd de cx" src="../Images/46074702c9543b68bf761d51d6a6ac2c.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*hyNH3QixmgpTuPC0-Om8QA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--7c8de54dda24--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://ohadeytan.medium.com/?source=post_page---byline--7c8de54dda24--------------------------------" rel="noopener follow">Ohad Eytan</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--7c8de54dda24--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 19, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div></div><div class="ab cb mj mk ml mm" role="separator"><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="8054" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk"><em class="nn">This blog post was co-authored by </em><a class="af no" href="https://www.linkedin.com/in/levyomri/" rel="noopener ugc nofollow" target="_blank"><strong class="mt fr"><em class="nn">Omri Levy</em></strong></a><strong class="mt fr"><em class="nn"> </em></strong><em class="nn">and </em><strong class="mt fr"><em class="nn">Ohad Eytan</em></strong><em class="nn">, as part of the work we have done in </em><a class="af no" href="https://research.ibm.com/labs/israel" rel="noopener ugc nofollow" target="_blank"><em class="nn">IBM Research Israel</em></a><em class="nn">.</em></p></div></div></div><div class="ab cb mj mk ml mm" role="separator"><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="85e0" class="np nq fq bf nr ns nt gq nu nv nw gt nx ny nz oa ob oc od oe of og oh oi oj ok bk">Intro</h1><p id="96fa" class="pw-post-body-paragraph mr ms fq mt b go ol mv mw gr om my mz na on nc nd ne oo ng nh ni op nk nl nm fj bk">Recently, we — at IBM Research — needed to use hybrid search in the <a class="af no" href="https://milvus.io/" rel="noopener ugc nofollow" target="_blank"><em class="nn">Milvus</em></a><em class="nn"> </em>vector store. Since we were already using the <a class="af no" href="https://www.langchain.com/" rel="noopener ugc nofollow" target="_blank"><em class="nn">LangChain</em></a> framework, we decided to roll up our sleeves and contribute what was needed to enable it in <a class="af no" href="https://github.com/langchain-ai/langchain-milvus" rel="noopener ugc nofollow" target="_blank"><em class="nn">langchain-milvus</em></a>. That included support for <strong class="mt fr">sparse embeddings</strong> (<a class="af no" href="https://github.com/langchain-ai/langchain/pull/25284" rel="noopener ugc nofollow" target="_blank">PR</a>) and <strong class="mt fr">multi-vector search</strong> (<a class="af no" href="https://github.com/langchain-ai/langchain-milvus/pull/11" rel="noopener ugc nofollow" target="_blank">PR</a>) through the <em class="nn">langchain</em> interface.</p><p id="c894" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">In this blog post, we will briefly introduce the difference between dense and sparse embeddings, and how you can leverage both using hybrid search. We’ll also provide a code walk-through to demonstrate how to use these new features in <em class="nn">langchain-milvus</em>.</p><p id="18f0" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">To use the code in this blog post, you should install some packages:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="b133" class="oz nq fq ow b bg pa pb l pc pd">pip install langchain_milvus==0.1.6<br/>pip install langchain-huggingface==0.1.0<br/>pip install "pymilvus[model]==2.4.8"</span></pre><p id="354f" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">and import these:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="fd77" class="oz nq fq ow b bg pa pb l pc pd">from langchain_huggingface import HuggingFaceEmbeddings<br/>from langchain_milvus.utils.sparse import BM25SparseEmbedding<br/>from langchain_milvus.vectorstores import Milvus</span></pre><p id="e70e" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">You can also see and clone the whole code in <a class="af no" href="https://gist.github.com/omriel1/3b8ea57cc14b896237c47d5417eaec8f" rel="noopener ugc nofollow" target="_blank">this gist</a>.</p><p id="9bbe" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Let’s go.</p></div></div></div><div class="ab cb mj mk ml mm" role="separator"><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="61c3" class="np nq fq bf nr ns nt gq nu nv nw gt nx ny nz oa ob oc od oe of og oh oi oj ok bk">Dense Embeddings</h1><p id="a44d" class="pw-post-body-paragraph mr ms fq mt b go ol mv mw gr om my mz na on nc nd ne oo ng nh ni op nk nl nm fj bk">The most common way to use vector stores is with dense embeddings. Here we use a pre-trained model to embed the data (usually text, but could be other media like images etc.) into high dimensional vectors, and store it in the vector database. The vectors have a couple of hundred (or even thousands of) dimensions, and each entry is a floating-point number. Typically, all of the entries in the vectors are occupied with non-zero values, hence the term “dense”. Given a query, we embed it using the same model, and the vector store retrieves similar, relevant data based on vector similarity. Using <em class="nn">langchain-milvus</em>, it’s just a couple lines of code. Let’s see how it’s done.</p><p id="622e" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">First, we define the vector store using <a class="af no" href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" rel="noopener ugc nofollow" target="_blank">a model from HuggingFace</a>:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="682b" class="oz nq fq ow b bg pa pb l pc pd">dense_embedding = HuggingFaceEmbeddings(model_name=<br/>    "sentence-transformers/all-MiniLM-L6-v2")<br/>vector_store = Milvus(<br/>    embedding_function=dense_embedding,<br/>    connection_args={"uri": "./milvus_dense.db"}, # Using milvus-lite for simplicity<br/>    auto_id=True,<br/>)</span></pre><p id="bc59" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Second, we insert our data into the vector store:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="7672" class="oz nq fq ow b bg pa pb l pc pd">document = [<br/>    "Today was very warm during the day but cold at night",<br/>    "In Israel, Hot is a TV provider that broadcasts 7 days a week",<br/>]<br/>vector_store.add_texts(documents)</span></pre><p id="cfa2" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Behind the scenes, each document is embedded into a vector using the model we supplied, and is stored alongside the original text.</p><p id="0d45" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Finally, we can search for a query and print the result we got:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="1190" class="oz nq fq ow b bg pa pb l pc pd">query = "What is the weather? is it hot?"<br/>dense_output = vector_store.similarity_search(query=query, k=1)<br/>print(f"Dense embeddings results:\n{dense_output[0].page_content}\n")<br/><br/># output: Dense embeddings results: <br/>#         Today was very warm during the day but cold at night</span></pre><p id="318f" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Here, the query is embedded, and the vector store does the (usually approximated) similarity search and returns the closest content it found.</p><p id="ac91" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Dense embeddings models are trained to capture the <strong class="mt fr">semantic meaning</strong> of the data and represent it in the multidimensional space. The advantage is clear — it enables semantic search, which means the results are based on the query’s meaning. But sometimes that’s not enough. If you look for specific keywords, or even words without broader meaning (like names), the semantic search will misguide you and this approach will fail.</p></div></div></div><div class="ab cb mj mk ml mm" role="separator"><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="4167" class="np nq fq bf nr ns nt gq nu nv nw gt nx ny nz oa ob oc od oe of og oh oi oj ok bk">Sparse embeddings</h1><p id="b2d5" class="pw-post-body-paragraph mr ms fq mt b go ol mv mw gr om my mz na on nc nd ne oo ng nh ni op nk nl nm fj bk">Ages before LLMs became a thing, and learned models weren’t so popular, search engines used traditional methods such as <a class="af no" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank">TF-IDF</a> or its modern enhancement, <a class="af no" href="https://en.wikipedia.org/wiki/Okapi_BM25" rel="noopener ugc nofollow" target="_blank">BM25</a> (known for it’s use in <a class="af no" href="https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch" rel="noopener ugc nofollow" target="_blank">Elastic</a>), to search relevant data. With these methods, the number of dimensions is the vocabulary size (typically tens of thousands, much larger than the dense vector space), and each entry represents the relevance of a keyword to a document, while taking into consideration the frequency of the term and its rarity across the corpus of documents. For each data point, most of the entries are zeros (for words that don’t appear), hence the term “sparse”. Although under the hood the implementation is different, with <em class="nn">langchain-milvus</em> interface it becomes very similar. Let’s see it in action:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="f1d6" class="oz nq fq ow b bg pa pb l pc pd">sparse_embedding = BM25SparseEmbedding(corpus=documents)<br/>vector_store = Milvus(<br/>    embedding_function=sparse_embedding,<br/>    connection_args={"uri": "./milvus_sparse.db"},<br/>    auto_id=True,<br/>)<br/>vector_store.add_texts(documents)<br/><br/>query = "Does Hot cover weather changes during weekends?"<br/>sparse_output = vector_store.similarity_search(query=query, k=1)<br/>print(f"Sparse embeddings results:\n{sparse_output[0].page_content}\n")<br/><br/># output: Sparse embeddings results:<br/>#         In Israel, Hot is a TV provider that broadcast 7 days a week</span></pre><p id="1606" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">BM25 is effective for exact keyword matching, which is useful for terms or names that lack clear semantic meaning. However, it will not capture the intent of the query, and will yield poor results in many cases where semantic understanding is needed.</p><blockquote class="pe pf pg"><p id="cda7" class="mr ms nn mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Note: the term “Sparse embeddings” also refers to advanced methods like SPLADE or Elastic Elser. These methods can also be used with Milvus and can be integrated into hybrid search!</p></blockquote></div></div></div><div class="ab cb mj mk ml mm" role="separator"><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="oq or os ot ou pk ph pi paragraph-image"><div role="button" tabindex="0" class="pl pm ed pn bh po"><div class="ph pi pj"><img src="../Images/1ae4c985d8d5a4981502aa1df9fbc7e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b7XmnGReCmXzSPi1o1h5GQ.png"/></div></div><figcaption class="pq pr ps ph pi pt pu bf b bg z dx">Image by the author</figcaption></figure><h1 id="69bc" class="np nq fq bf nr ns pv gq nu nv pw gt nx ny px oa ob oc py oe of og pz oi oj ok bk">Hybrid Search</h1><p id="194a" class="pw-post-body-paragraph mr ms fq mt b go ol mv mw gr om my mz na on nc nd ne oo ng nh ni op nk nl nm fj bk">If you swap the queries between the two examples above, and use each one with the other’s embedding, both will produce the wrong result. This demonstrates the fact that each method has its strengths but also its weaknesses. Hybrid search combines the two, aiming to leverage the best from both worlds. By indexing data with both dense and sparse embeddings, we can perform searches that consider both semantic relevance and keyword matching, balancing results based on custom weights. Again, the internal implementation is more complicated, but <em class="nn">langchain-milvus</em> makes it pretty simple to use. Let’s look at how this works:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="ab9c" class="oz nq fq ow b bg pa pb l pc pd">vector_store = Milvus(<br/>    embedding_function=[<br/>        sparse_embedding,<br/>        dense_embedding,<br/>    ],<br/>    connection_args={"uri": "./milvus_hybrid.db"}, <br/>    auto_id=True,<br/>)<br/>vector_store.add_texts(documents)</span></pre><p id="01ed" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">In this setup, both sparse and dense embeddings are applied. Let’s test the hybrid search with equal weighting:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="d9eb" class="oz nq fq ow b bg pa pb l pc pd">query = "Does Hot cover weather changes during weekends?"<br/>hybrid_output = vector_store.similarity_search(<br/>    query=query,<br/>    k=1,<br/>    ranker_type="weighted",<br/>    ranker_params={"weights": [0.49, 0.51]},  # Combine both results!<br/>)<br/>print(f"Hybrid search results:\n{hybrid_output[0].page_content}")<br/><br/># output: Hybrid search results:<br/>#         In Israel, Hot is a TV provider that broadcast 7 days a week</span></pre><p id="1fb2" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">This searches for similar results using each embedding function, gives each score a weight, and returns the result with the best weighted score. We can see that with slightly more weight to the dense embeddings, we get the result we desired. This is true for the second query as well.</p><p id="a18b" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">If we give more weight to the dense embeddings, we will once again get non-relevant results, as with the dense embeddings alone:</p><pre class="oq or os ot ou ov ow ox bp oy bb bk"><span id="e38e" class="oz nq fq ow b bg pa pb l pc pd">query = "When and where is Hot active?"<br/>hybrid_output = vector_store.similarity_search(<br/>    query=query,<br/>    k=1,<br/>    ranker_type="weighted",<br/>    ranker_params={"weights": [0.2, 0.8]},  # Note -&gt; the weights changed<br/>)<br/>print(f"Hybrid search results:\n{hybrid_output[0].page_content}")<br/><br/># output: Hybrid search results:<br/>#         Today was very warm during the day but cold at night</span></pre><p id="e686" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Finding the right balance between dense and sparse is not a trivial task, and can be seen as part of a wider hyper-parameter optimization problem. There is an ongoing research and tools that trying to solve such issues in this area, for example <a class="af no" href="https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-programming-rag.html?context=wx&amp;audience=wdp#autorag-implement" rel="noopener ugc nofollow" target="_blank">IBM’s AutoAI for RAG</a>.</p><p id="8b75" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">There are many more ways you can adapt and use the hybrid search approach. For instance, if each document has an associated title, you could use two dense embedding functions (possibly with different models) — one for the title and another for the document content — and perform a hybrid search on both indices. Milvus currently supports up to 10 different vector fields, providing flexibility for complex applications. There are also additional configurations for indexing and reranking methods. You can see <a class="af no" href="https://milvus.io/docs/multi-vector-search.md" rel="noopener ugc nofollow" target="_blank">Milvus documentation</a> about the available params and options.</p></div></div></div><div class="ab cb mj mk ml mm" role="separator"><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="0a8b" class="np nq fq bf nr ns nt gq nu nv nw gt nx ny nz oa ob oc od oe of og oh oi oj ok bk">Closing words</h1><p id="252c" class="pw-post-body-paragraph mr ms fq mt b go ol mv mw gr om my mz na on nc nd ne oo ng nh ni op nk nl nm fj bk">With Milvus’s multi-vector search capabilities now accessible through LangChain, you can integrate hybrid search into your applications easily. This opens up new possibilities to apply different search strategies in your application, making it easy to tailor search logic to fit specific use cases. For us, it was a good opportunity to contribute to an open source project. Many of the libraries and tools we use on a daily basis are open source, and it’s nice to give back to the community. Hopefully it will be useful for others.</p><p id="f42c" class="pw-post-body-paragraph mr ms fq mt b go mu mv mw gr mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Finally, a big shout-out to <a class="af no" href="https://github.com/efriis" rel="noopener ugc nofollow" target="_blank">Erick Friis</a> and <a class="af no" href="https://github.com/zc277584121" rel="noopener ugc nofollow" target="_blank">Cheng Zi</a> for all the effort they put on <em class="nn">langchain-milvus</em>, and in these PRs particularly. This work couldn’t have happened without them.</p></div></div></div></div>    
</body>
</html>