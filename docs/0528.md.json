["```py\ndef torch.optim.SGD(\n  params, lr=0.001, momentum=0, dampening=0,\n  weight_decay=0, nesterov=False, *, maximize=False,\n  foreach=None, differentiable=False):\n  # Implements stochastic gradient descent (optionally with momentum).\n  # ...\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(20240215)\nn = 50\nx = np.array(np.random.randn(n), dtype=np.float32)\ny = np.array(\n  0.75 * x**2 + 1.0 * x + 2.0 + 0.3 * np.random.randn(n),\n  dtype=np.float32)\n\nplt.scatter(x, y, facecolors='none', edgecolors='b')\nplt.scatter(x, y, c='r')\nplt.show()\n```", "```py\nimport torch\n\nmodel = torch.nn.Linear(1, 1)\nmodel.weight.data.fill_(6.0)\nmodel.bias.data.fill_(-3.0)\n\nloss_fn = torch.nn.MSELoss()\nlearning_rate = 0.1\nepochs = 100\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\nfor epoch in range(epochs):\n  inputs = torch.from_numpy(x).requires_grad_().reshape(-1, 1)\n  labels = torch.from_numpy(y).reshape(-1, 1)\n\n  optimizer.zero_grad()\n  outputs = model(inputs)\n  loss = loss_fn(outputs, labels)\n  loss.backward()\n  optimizer.step()\n  print('epoch {}, loss {}'.format(epoch, loss.item()))\n```", "```py\nepoch 0, loss 53.078269958496094\nepoch 1, loss 34.7295036315918\nepoch 2, loss 22.891206741333008\nepoch 3, loss 15.226042747497559\nepoch 4, loss 10.242652893066406\nepoch 5, loss 6.987757682800293\nepoch 6, loss 4.85075569152832\nepoch 7, loss 3.4395809173583984\nepoch 8, loss 2.501774787902832\nepoch 9, loss 1.8742430210113525\n...\nepoch 97, loss 0.4994412660598755\nepoch 98, loss 0.4994412362575531\nepoch 99, loss 0.4994412660598755\n```", "```py\nweight = model.weight.item()\nbias = model.bias.item()\nplt.scatter(x, y, facecolors='none', edgecolors='b')\nplt.plot(\n  [x.min(), x.max()],\n  [weight * x.min() + bias, weight * x.max() + bias],\n  c='r')\nplt.show()\n```", "```py\ndef get_loss_map(loss_fn, x, y):\n  \"\"\"Maps the loss function on a 100-by-100 grid between (-5, -5) and (8, 8).\"\"\"\n  losses = [[0.0] * 101 for _ in range(101)]\n  x = torch.from_numpy(x)\n  y = torch.from_numpy(y)\n  for wi in range(101):\n    for wb in range(101):\n      w = -5.0 + 13.0 * wi / 100.0\n      b = -5.0 + 13.0 * wb / 100.0\n      ywb = x * w + b\n      losses[wi][wb] = loss_fn(ywb, y).item()\n\n  return list(reversed(losses))  # Because y will be reversed.\n\nimport pylab\n\nloss_fn = torch.nn.MSELoss()\nlosses = get_loss_map(loss_fn, x, y)\ncm = pylab.get_cmap('terrain')\n\nfig, ax = plt.subplots()\nplt.xlabel('Bias')\nplt.ylabel('Weight')\ni = ax.imshow(losses, cmap=cm, interpolation='nearest', extent=[-5, 8, -5, 8])\nfig.colorbar(i)\nplt.show()\n```", "```py\nmodel = torch.nn.Linear(1, 1)\n...\nmodels = [[model.weight.item(), model.bias.item()]]\nfor epoch in range(epochs):\n  ...\n  print('epoch {}, loss {}'.format(epoch, loss.item()))\n  models.append([model.weight.item(), model.bias.item()])\n\n# Plot model parameters against the loss map.\ncm = pylab.get_cmap('terrain')\nfig, ax = plt.subplots()\nplt.xlabel('Bias')\nplt.ylabel('Weight')\ni = ax.imshow(losses, cmap=cm, interpolation='nearest', extent=[-5, 8, -5, 8])\n\nmodel_weights, model_biases = zip(*models)\nax.scatter(model_biases, model_weights, c='r', marker='+')\nax.plot(model_biases, model_weights, c='r')\n\nfig.colorbar(i)\nplt.show()\n```", "```py\ndef multi_plot(lr=0.1, epochs=100, momentum=0, weight_decay=0, dampening=0, nesterov=False):\n  fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n  for loss_fn, title, ax in [\n    (torch.nn.MSELoss(), 'MSELoss', ax1),\n    (torch.nn.L1Loss(), 'L1Loss', ax2),\n    (torch.nn.HuberLoss(), 'HuberLoss', ax3),\n    (torch.nn.SmoothL1Loss(), 'SmoothL1Loss', ax4),\n  ]:\n    losses = get_loss_map(loss_fn, x, y)\n    model, models = learn(\n      loss_fn, x, y, lr=lr, epochs=epochs, momentum=momentum,\n      weight_decay=weight_decay, dampening=dampening, nesterov=nesterov)\n\n    cm = pylab.get_cmap('terrain')\n    i = ax.imshow(losses, cmap=cm, interpolation='nearest', extent=[-5, 8, -5, 8])\n    ax.title.set_text(title)\n    loss_w, loss_b = zip(*models)\n    ax.scatter(loss_b, loss_w, c='r', marker='+')\n    ax.plot(loss_b, loss_w, c='r')\n\n  plt.show()\n\nmulti_plot(lr=0.1, epochs=100)\n```", "```py\nmulti_plot(lr=0.1, epochs=100, momentum=0.9)\n```", "```py\nmulti_plot(lr=0.1, epochs=100, momentum=0.9, nesterov=True)\n```", "```py\nmulti_plot(lr=0.1, epochs=100, momentum=0.9, nesterov=True, weight_decay=2.0)\n```", "```py\nmulti_plot(lr=0.1, epochs=100, momentum=0.9, dampening=0.8)\n```"]