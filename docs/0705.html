<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>AI vs. Human Insight in Financial Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>AI vs. Human Insight in Financial Analysis</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-vs-human-insight-in-financial-analysis-89d3408eb6d5?source=collection_archive---------6-----------------------#2024-03-15">https://towardsdatascience.com/ai-vs-human-insight-in-financial-analysis-89d3408eb6d5?source=collection_archive---------6-----------------------#2024-03-15</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="7dcc" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How the Bud Light boycott and SalesForce’s innovation plans confuse the best LLMs</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@mihail.dungarov?source=post_page---byline--89d3408eb6d5--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Misho Dungarov" class="l ep by dd de cx" src="../Images/c65eb57145dada4f02acbb3f145a9b77.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*Dg0KW0iAz3ZooKRUKaq2Pw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--89d3408eb6d5--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@mihail.dungarov?source=post_page---byline--89d3408eb6d5--------------------------------" rel="noopener follow">Misho Dungarov</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--89d3408eb6d5--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/f3d40b0e75e91276eebdb39ec53680c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rgp2a-ihP7kv4PP6za8Sdg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by <a class="af nc" href="https://platform.openai.com/docs/guides/images/" rel="noopener ugc nofollow" target="_blank">Dall-E 3</a></figcaption></figure><p id="710b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Can the best AI models today, accurately pick up the most important message out of a company earnings call? They can certainly pick up SOME points but how do we know if those are the important ones? Can we <em class="nz">prompt</em> them into to doing a better job? To find those answers, we look at what the best journalists in the field have done and try to get as close to that with AI</p><h1 id="24f6" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">The Challenge</h1><p id="183d" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">In this article, I look at 8 recent company earnings calls and ask the current contestants for smartest AIs (<a class="af nc" href="https://www.anthropic.com/news/claude-3-family" rel="noopener ugc nofollow" target="_blank">Claude 3</a>, <a class="af nc" href="https://openai.com/gpt-4" rel="noopener ugc nofollow" target="_blank">GPT-4</a> and <a class="af nc" href="https://mistral.ai/news/mistral-large/" rel="noopener ugc nofollow" target="_blank">Mistral Large</a>) what they think is important. Then compare the results to what some of the best names in Journalism (Reuters, Bloomberg, and Barron’s) have said about those exact reports.</p><h1 id="f2da" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Why care about this?</h1><h2 id="8d03" class="pb ob fq bf oc pc pd pe of pf pg ph oi nm pi pj pk nq pl pm pn nu po pp pq pr bk">The Significance of Earnings Calls</h2><p id="b78a" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Earnings calls are quarterly events where senior management reviews the company’s financial results. They discuss the company’s performance, share commentary, and sometimes preview future plans. These discussions can significantly impact the company’s stock price. Management explains their future expectations and reasons for meeting or surpassing past forecasts. The management team offers invaluable insights into the company’s actual condition and future direction.</p><h2 id="e4a5" class="pb ob fq bf oc pc pd pe of pf pg ph oi nm pi pj pk nq pl pm pn nu po pp pq pr bk">The Power of Automation in Earnings Analysis</h2><p id="3e97" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Statista reports that there are just under <a class="af nc" href="https://www.statista.com/statistics/1330817/nasdaq-number-of-listed-companies-by-domicile/" rel="noopener ugc nofollow" target="_blank">4000 companies listed on the NASDAQ</a> and about <a class="af nc" href="https://focus.world-exchanges.org/articles/number-listed-companies" rel="noopener ugc nofollow" target="_blank">58,000 globally</a> according to one estimate.</p><blockquote class="ps"><p id="1a51" class="pt pu fq bf pv pw px py pz qa qb ny dx">A typical conference call lasts roughly 1 hour. To just listen to all NASDAQ companies, one would need at least 10 people working full-time for the entire quarter. And this doesn’t even include the more time-consuming tasks like analyzing and comparing financial reports.</p></blockquote><p id="855c" class="pw-post-body-paragraph nd ne fq nf b go qc nh ni gr qd nk nl nm qe no np nq qf ns nt nu qg nw nx ny fj bk">Large brokerages might manage this workload, but it’s unrealistic for individual investors. Automation in this area could level the playing field, making it easier for everyone to understand quarterly earnings.</p><p id="486b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">While this may just be within reach of large brokerages, it is not feasible for private investors. Therefore, any reliable automation in this space will be a boon, especially for democratizing the understanding of quarterly earnings.</p><h1 id="3c30" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">The Process of Testing AI as a Financial Analyst</h1><p id="a4e5" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">To test how well the best LLMs of the day can do this job. I decided to compare the main takeaways by humans and see how well AI can mimic that. Here are the steps:</p><ol class=""><li id="92a0" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qh qi qj bk">Pick some companies with recent earnings call transcripts and matching news articles.</li><li id="af1b" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qh qi qj bk">Provide the LLMs with the full transcript as context and ask them to provide <strong class="nf fr">the top three bullet points</strong> that seem most impactful for the value of the company. This is important as, providing a longer summary becomes progressively easier — there are only so many important things to say.</li><li id="8ac6" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qh qi qj bk">To ensure we maximise the quality of the output, I vary the way I phrase the problem to the AI (using different prompts): Ranging from simply asking for a summary, adding more detailed instructions, adding previous transcripts and some combinations of those.</li><li id="b391" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qh qi qj bk">Finally, compare those with the 3 most important points from the respective news article and use the overlap as a measure of success.</li></ol><h1 id="12de" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Summary of Results</h1><p id="102a" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">GPT-4 shows best performance at 80% when providing it the previous quarter’s transcript and using a set of instructions on how to analyse transcripts well (Chain of Thought). Notably, just using correct instructions increases GPT-4 performance from 51% to 75%.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qp"><img src="../Images/64789c98fb1056fbb549b6dbe7a3bd5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*r1vX5ab1vlGxz3A6b82ImQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">GPT-4 shows the best results and responds best to prompting (80%) — i.e. adding previous results and dedicated instructions on how to analyse results. Without sophisticated prompting, Claude 3 Opus works best (67%). Image and data by the author</figcaption></figure><ul class=""><li id="cf85" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qq qi qj bk">Next best performers are: <br/> — Claude 3 Opus (67%) — Without sophisticated prompting, Claude 3 Opus works best.<br/> — Mistral Large (66%) when adding supporting instructions (i.e. Chain of Thought)</li><li id="84af" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Chain-of-thought (CoT) and Think Step by Step (SxS) seem to work well for GPT-4 but are detrimental for other models. </strong>This suggests there is still a lot to be learned about what prompts work for each LLM.</li><li id="b0e3" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Chain-of-Thought (CoT) seems almost always outperforms Step-by-step (SxS)</strong>. This means tailored financial knowledge of priorities for analysis helps. The specific instructions provided are listed at the bottom of the article.</li><li id="84f7" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">More data-less sense: </strong>Adding a previous period transcript to the model context seems to be at least slightly and at worst significantly detrimental to results across the board than just focusing on the latest results (except for GPT-4 + CoT). Potentially, there is much irrelevant information introduced from a previous transcript and a relatively small amount of specific facts to make a quarter-on-quarter comparison. Mistral Large’s performance drops significantly, note that its context window is just 32k tokens vs the significantly larger ones for the others (2 transcripts + prompt actually just barely fit under 32k tokens).</li><li id="8aa3" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Claude-3 Opus and Sonnet perform very closely</strong>, with Sonnet actually outperforming Opus in some cases. However, this tends to be by a few %-age points and can therefore be attributed to the randomness of results.</li><li id="a876" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk">Note that, as mentioned, results show a high degree of variability and the <strong class="nf fr">range of outcomes is within +/-6%</strong>. For that reason, I have <strong class="nf fr">rerun all analysis 3 times </strong>and am showing the averages. However, the +/-6% range is not sufficient to significantly upend any of the above conclusions</li></ul><h1 id="1ff0" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">What do LLMs get right and wrong?</h1><blockquote class="ps"><p id="41a3" class="pt pu fq bf pv pw px py pz qa qb ny dx">How the Bud Light Boycott and Salesforce’s AI plans confused the best AIs</p></blockquote><p id="c0fa" class="pw-post-body-paragraph nd ne fq nf b go qc nh ni gr qd nk nl nm qe no np nq qf ns nt nu qg nw nx ny fj bk">This task offers some easy wins: guessing that results are about the latest revenue numbers and next year’s projections is fairly on the nose. Unsurprisingly, this is where models get things right most of the time.</p><p id="50ae" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The table below gives an overview of what was mentioned in the news and what LLMs chose differently when summarized in just a few words.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/fb1f72934bbfb2a64ec80c3656f2d44f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-zikmVFQ68aB7V29yP7MtA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">“Summarize each bullet with up to 3 words”: The top three themes in the news vs themes the LLMs picked that were not on that list. Each model was asked to provide a 2–3 word summary of the bullet points. A model will have 6 sets of top 3 choices (i.e. 24) and these are the 3 that most often were not relevant when compared to news summaries. Note that in some cases, comparing the top and bottom table may feel like both sound the same, this is mostly because each bullet is actually significantly more detailed and may have a lot of additional / contradictory information missed in the 2–3 word summary</figcaption></figure><p id="1ef0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Next, I tried to look for any trends of what the models consistently miss. Those generally Fall into a few categories:</p><ul class=""><li id="6d53" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qq qi qj bk"><strong class="nf fr">Making sense of changes: </strong>In the above results, LLMs have been able to understand fairly reliably what to look for: earnings, sales, dividend, and guidance, however, making sense of what is significant is still very elusive. For instance, common-sense might suggest that Q4 2023 results will be a key topic for any company and this is what the LLMs pick. However, Nordstrom talks about muted revenue and demand expectations for 2024 which pushes Q4 2023 results aside in terms of importance</li><li id="1669" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Hallucinations: </strong>as is well documented, LLMs tend to make up facts. In this case, despite having instructions to “only include facts and metrics from the context” some metrics and dates end up being made up. The models unfortunately will not be shy about talking about the Q4 2024 earnings by referring to them as already available and using the 2023 numbers for them.</li><li id="d005" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Significant one-off events: </strong>Unexpected one-off events are surprisingly often missed by LLMs. For instance, <strong class="nf fr">the boycott of Bud Light</strong> drove sales of the best-selling beer in the US down by 15.9% for <em class="nz">Anheuser-Busch </em>and is discussed at length in the transcripts. The number alone should appear significant, however it was missed by all models in the sample.</li><li id="c4db" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Actions speak louder than words: </strong>Both GPT and Claude highlight innovation and the commitment to AI as important.<br/> — Salesforce (CRM) talks at length about a heavy focus on AI and Data Cloud<br/> — Snowflake appointed their SVP of AI and former exec of Google Ads as CEO (Sridhar Ramaswamy), similarly signaling a focus on leveraging AI technology.<br/>Both signal a shift to innovation &amp; AI. <strong class="nf fr">However, journalists and analysts are not as easily tricked into mistaking words for actions. </strong>In the article analyzing CRM’s earnings, the subtitle reads Salesforce Outlook Disappoints as AI Fails to Spark Growth. However, Salesforce has been trying to tango with AI for a while and the forward-looking plans to use AI are not even mentioned. Salesforce’s transcript mentions AI 91 times while Snowflake’s less than half of that at 39. However, humans can make the distinction in meaning: Bloomberg’s article [link] on the appointment of a new CEO: His elevation underscores a focus on AI for Snowflake.</li></ul><h1 id="4952" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Experiment design and choices</h1><ol class=""><li id="9cba" class="nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny qh qi qj bk"><strong class="nf fr">Why Earnings call transcripts? </strong>The more intuitive choice may be company filings, however, I find transcripts to present a more natural and less formal discussion of events. I believe transcripts give the LLM as a reasoning engine a better chance to glean more natural commentary of events as opposed to the dry and highly regulated commentary of earnings. The calls are mostly management presentations, which might skew things toward a more positive view. However, my analysis has shown the performance of the LLMs seems similar between positive and negative narratives.</li><li id="c468" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qh qi qj bk"><strong class="nf fr">Choice of Companies: </strong>I chose stocks that have published Q4 2023 earnings reports between 25 Feb and 5 March and have been reported on by one of Reuters, Bloomberg, or Barron’s. This ensures that the results are timely and that the models have not been trained on that data yet. Plus, everyone always talks about AAPL and TSLA, so this is something different. Finally, the reputation of these journalistic houses ensures a meaningful comparison. The 8 stocks we ended up with are: <em class="nz">Autodesk (ADSK), BestBuy (BBY), Anheuser-Busch InBev (BUD), Salesforce (CRM), DocuSign (DOCU), Nordstrom (JWN), Kroger (KR), Snowflake (SNOW)</em></li><li id="f31e" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qh qi qj bk"><strong class="nf fr">Variability of results </strong>LLM results can vary between runs so I have run all experiments 3 times and show an average. All analysis for all models was done using temperature 0 which is commonly used to minimize variation of results. In this case, I have observed different runs have as much as 10% difference in performance. This is due to the small sample (only 24 data points 8 stocks by 3 statements) and the fact that we are basically asking an LLM to choose one of many possible statements for the summary, so when this happens with some randomness it can naturally lead to picking some of them differently.</li><li id="42d3" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qh qi qj bk"><strong class="nf fr">Choice of Prompts: </strong>For each of the 3 LLMs in comparison try out 4 different prompting approaches:</li></ol><ul class=""><li id="1640" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qq qi qj bk"><strong class="nf fr">Naive</strong> — The prompt simply asks the model to determine the most likely impact on the share price.</li><li id="8fd7" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Chain-of-Thought (CoT) </strong>— where I provide a detailed list of steps to follow when choosing a summary. This is inspired and loosely follows<a class="af nc" href="https://arxiv.org/abs/2201.11903" rel="noopener ugc nofollow" target="_blank"> [Wei et. al. 2022]</a> work outlining the Chain of Thought approach, providing reasoning steps as part of the prompt dramatically improves results. These additional instructions, in the context of this experiment, include typical drivers of price movements: changes to expected performance in revenue, costs, earnings, litigation, etc.</li><li id="7f1e" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Step by Step (SxS) </strong>aka Zero-shot CoT, inspired by<a class="af nc" href="https://arxiv.org/abs/2205.11916" rel="noopener ugc nofollow" target="_blank"> Kojima et.al (2022)</a> where they discovered that simply adding the phrase “Let’s think step by step” improves performance. I ask the LLMs to think step-by-step and describe their logic before answering.</li><li id="9468" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Previous transcript</strong> — finally, I run all three of the above prompts once more by including the transcript from the previous quarter (in this case Q3)</li></ul><h1 id="431b" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Conclusion</h1><p id="0676" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">From what we can see above, Journalists’ and Research Analysts’ jobs seem safe for now, as most LLMs struggle to get more than two of three answers correctly. In most cases, this just means guessing that the meeting was about the latest revenue and next year’s projections.</p><p id="1264" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">However, despite all the limitations of this test, we can still see some clear conclusions:</p><ul class=""><li id="9e93" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qq qi qj bk">The accuracy level is fairly low for most models. Even GPT-4’s best performance of 80% will be problematic at scale without human supervision — giving wrong advice one in five times is not convincing.</li><li id="a470" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk">GPT4 seems to still be a clear leader in complex tasks it was not specifically trained for.</li><li id="1db2" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk">There are significant gains when correctly prompt engineering the task</li><li id="0a46" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk">Most models seem easily confused by extra information as adding the previous transcript generally reduces performance.</li></ul><h2 id="d44e" class="pb ob fq bf oc pc pd pe of pf pg ph oi nm pi pj pk nq pl pm pn nu po pp pq pr bk">Where to from here?</h2><p id="7477" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">We have all witnessed that LLM capabilities continuously improve. Will this gap be closed and how? We have observed three types of cognitive issues that have impacted performance: hallucinations, understanding what is important and what isn’t (e.g. really understanding what is <em class="nz">surprising</em> for a company), more complex company causality issues (e.g. like the Bud Light boycott and how important the US sales are relative to an overall business):</p><ul class=""><li id="3bf3" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qq qi qj bk"><strong class="nf fr">Hallucinations </strong>or scenarios where the LLM cannot correctly reproduce factual information are a major stumbling block in applications that require strict adherence to factuality. Advanced RAG approaches, combined with research in the area continue to make progress, <a class="af nc" href="https://arxiv.org/abs/2311.05232" rel="noopener ugc nofollow" target="_blank">[Huang et al 2023]</a> give an overview of current progress</li><li id="8f94" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Understanding what is important </strong>— fine-tuning LLM models for the specific use case should lead to some improvements. However, those come with much bigger requirements on team, cost, data, and infrastructure.</li><li id="3862" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><strong class="nf fr">Complex Causality Links </strong>— this one may be a good direction for AI Agents. For instance, in the Bud Light boycott case, the model might need to: <br/>1. the importance of Bud Light to US sales, which is likely peppered through many presentations and management commentary<br/>2. The importance of US sales ot the overall company, which could be gleaned from company financials<br/>3. Finally stack those impacts to all other impacts mentioned<br/>Such causal logic is more akin to how a ReAct AI Agent might think instead of just a standalone LLM <a class="af nc" href="https://arxiv.org/abs/2210.03629" rel="noopener ugc nofollow" target="_blank">[Yao, et al 2022]</a>. Agent planning is a hot research topic <a class="af nc" href="https://arxiv.org/abs/2402.10890" rel="noopener ugc nofollow" target="_blank">[Chen, et al 2024]</a></li></ul><p id="27d0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><a class="af nc" href="https://linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&amp;followMember=mihail-misho-dungarov-cfa-a0291a88" rel="noopener ugc nofollow" target="_blank">Follow me on LinkedIn</a></p><h2 id="0640" class="pb ob fq bf oc pc pd pe of pf pg ph oi nm pi pj pk nq pl pm pn nu po pp pq pr bk">Disclaimers</h2><p id="8dfe" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk"><em class="nz">The views, opinions, and conclusions expressed in this article are my own and do not reflect the views or positions of any of the entities mentioned or any other entities.</em></p><p id="51c1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="nz">No data was used to model training nor was systematically collected from the sources mentioned, all techniques were limited to prompt engineering.</em></p><h1 id="3bbd" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Resources</h1><h2 id="9905" class="pb ob fq bf oc pc pd pe of pf pg ph oi nm pi pj pk nq pl pm pn nu po pp pq pr bk">Earnings Call Transcripts (Motley Fool)</h2><ul class=""><li id="939f" class="nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny qq qi qj bk"><a class="af nc" href="https://www.fool.com/earnings/call-transcripts/2024/02/29/anheuser-busch-inbevnv-bud-q4-2023-earnings-call-t/" rel="noopener ugc nofollow" target="_blank">Anheuser-Busch InBev (BUD) Q4 2024</a></li><li id="49c3" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.fool.com/earnings/call-transcripts/2024/02/29/autodesk-adsk-q4-2024-earnings-call-transcript/" rel="noopener ugc nofollow" target="_blank">Autodesk (ADSK) Q4 2024</a></li><li id="cfe6" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.fool.com/earnings/call-transcripts/2024/02/29/best-buy-bby-q4-2024-earnings-call-transcript/" rel="noopener ugc nofollow" target="_blank">Best Buy (BBY) Q4 2024</a></li><li id="10b5" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.fool.com/earnings/call-transcripts/2024/03/07/docusign-docu-q4-2024-earnings-call-transcript/" rel="noopener ugc nofollow" target="_blank">DocuSign (DOCU) Q4 2024</a></li><li id="04ee" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.fool.com/earnings/call-transcripts/2024/03/07/kroger-kr-q4-2023-earnings-call-transcript/" rel="noopener ugc nofollow" target="_blank">Kroger (KR) Q4 2024</a></li><li id="306f" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.fool.com/earnings/call-transcripts/2024/03/05/nordstrom-jwn-q4-2023-earnings-call-transcript/" rel="noopener ugc nofollow" target="_blank">Nordstrom (JWN) Q4 2024</a></li><li id="c74e" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.fool.com/earnings/call-transcripts/2024/02/29/salesforce-crm-q4-2024-earnings-call-transcript/" rel="noopener ugc nofollow" target="_blank">Salesforce (CRM) Q4 2024</a></li><li id="b59f" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.fool.com/earnings/call-transcripts/2024/02/29/snowflake-snow-q4-2024-earnings-call-transcript/" rel="noopener ugc nofollow" target="_blank">Snowflake (SNOW) Q4 2024</a></li></ul><h2 id="2801" class="pb ob fq bf oc pc pd pe of pf pg ph oi nm pi pj pk nq pl pm pn nu po pp pq pr bk">News Articles</h2><ul class=""><li id="893c" class="nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny qq qi qj bk"><a class="af nc" href="https://www.reuters.com/business/retail-consumer/brewer-ab-inbev-hikes-annual-dividend-after-q4-sales-estimate-beat-2024-02-29/" rel="noopener ugc nofollow" target="_blank">Anheuser-Busch InBev (Reuters)</a></li><li id="fa3f" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.reuters.com/technology/autodesk-forecasts-annual-revenue-above-estimates-shares-jump-2024-02-29/" rel="noopener ugc nofollow" target="_blank">Autodesk (Reuters)</a></li><li id="eabe" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.bloomberg.com/news/articles/2024-02-29/best-buy-sales-decline-at-slower-pace-as-demand-improves" rel="noopener ugc nofollow" target="_blank">BestBuy (Bloomberg)</a></li><li id="5b89" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.barrons.com/articles/docusign-shares-earnings-20862b9a" rel="noopener ugc nofollow" target="_blank">DocuSign (Barron’s)</a></li><li id="f569" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.barrons.com/articles/kroger-stock-earnings-9b9bebd6" rel="noopener ugc nofollow" target="_blank">Kroger (Barron’s)</a></li><li id="3550" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.bloomberg.com/news/articles/2024-03-05/nordstrom-sees-muted-revenue-comparable-sales-in-current-year" rel="noopener ugc nofollow" target="_blank">Nordstrom (Bloomberg)</a></li><li id="6c6d" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.bloomberg.com/news/articles/2024-02-28/salesforce-outlook-disappoints-as-ai-fails-to-spark-growth" rel="noopener ugc nofollow" target="_blank">Salesforce (Bloomberg)</a></li><li id="3dbc" class="nd ne fq nf b go qk nh ni gr ql nk nl nm qm no np nq qn ns nt nu qo nw nx ny qq qi qj bk"><a class="af nc" href="https://www.bloomberg.com/news/articles/2024-02-28/snowflake-misses-estimates-says-ceo-slootman-to-step-down" rel="noopener ugc nofollow" target="_blank">Snowflake (Bloomberg)</a></li></ul></div></div></div></div>    
</body>
</html>