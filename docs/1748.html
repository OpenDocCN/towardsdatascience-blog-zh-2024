<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Semantic Search Engine for Emojis in 50+ Languages Using AI 😊🌍🚀</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Semantic Search Engine for Emojis in 50+ Languages Using AI 😊🌍🚀</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/semantic-search-for-emojis-in-50-languages-using-ai-f85a36a86f21?source=collection_archive---------7-----------------------#2024-07-17">https://towardsdatascience.com/semantic-search-for-emojis-in-50-languages-using-ai-f85a36a86f21?source=collection_archive---------7-----------------------#2024-07-17</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="2c35" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Develop an AI-powered semantic search for emojis using Python and open-source NLP libraries</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@badr.alabsi?source=post_page---byline--f85a36a86f21--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Badr Alabsi, PhD" class="l ep by dd de cx" src="../Images/1e509109fb24dec154cd155859273903.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*V3xA2Ur-y1MMshWUKY-eYA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f85a36a86f21--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@badr.alabsi?source=post_page---byline--f85a36a86f21--------------------------------" rel="noopener follow">Badr Alabsi, PhD</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f85a36a86f21--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 17, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">3</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/4e4b22aa4d5eedea4c9699b59de728b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G7N_wy3HPArjDdP-tTno-Q.png"/></div></div></figure><p id="0f30" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">If you are on social media like Twitter or LinkedIn, you have probably noticed that emojis are creatively used in both informal and professional text-based communication. For example, the <em class="nt">Rocket</em> emoji 🚀 is often used on LinkedIn to symbolize high aspirations and ambitious goals, while the <em class="nt">Bullseye</em> 🎯 emoji is used in the context of achieving goals. Despite this growth of creative emoji use, most social media platforms lack a utility that assists users in choosing the right emoji to effectively communicate their message. I therefore decided to invest some time to work on a project I called Emojeez 💎, an AI-powered engine for emoji search and retrieval. You can experience Emojeez 💎 live using this fun interactive <a class="af nu" href="https://emojeez.streamlit.app/" rel="noopener ugc nofollow" target="_blank">demo</a>.</p><p id="cadc" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In this article, I will discuss my experience and explain how I employed advanced <strong class="mz fr">natural language processing</strong> (NLP) technologies to develop a <strong class="mz fr">semantic search engine</strong> for emojis. Concretely, I will present a case study on embedding-based semantic search with the following steps</p><ol class=""><li id="9a0f" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nv nw nx bk">How to use <strong class="mz fr">LLMs</strong> 🦜to generate semantically rich emoji descriptions</li><li id="1b52" class="mx my fq mz b go ny nb nc gr nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nv nw nx bk">How to use Hugging Face 🤗 <strong class="mz fr">Transformers</strong> for multilingual embeddings</li><li id="8894" class="mx my fq mz b go ny nb nc gr nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nv nw nx bk">How to integrate <strong class="mz fr">Qdrant</strong> 🧑🏻‍🚀 vector database to perform efficient semantic search</li></ol><p id="f002" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">I made the full code for this project available on <a class="af nu" href="https://github.com/badrex/emojeez" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p><h1 id="8aad" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Inspiration💡</h1><p id="13c5" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">Every new idea often begins with a spark of inspiration. For me, the spark came from Luciano Ramalho’s book <em class="nt">Fluent Python</em>. It is a fantastic read that I highly recommend for anyone who likes to write truly Pythonic code. In chapter 4 of his book, Luciano shows how to search over Unicode characters by querying their names in the Unicode standards. He created a Python utility that takes a query like “cat smiling” and retrieves all Unicode characters that have both “cat” and “smiling” in their names. Given the query “cat smiling”, the utility retrieves three emojis: 😻, 😺, and 😸. Pretty cool, right?</p><p id="a8ed" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">From there, I started thinking how modern AI technology could be used to build an even better emoji search utility. By “better,” I envisioned a search engine that not only has better emoji coverage but also supports user queries in multiple languages beyond English.</p><h1 id="e0e4" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Limitations of Keyword Search 😓</h1><p id="ec90" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">If you are an emoji enthusiast, you know that 😻, 😺, and 😸 aren’t the only smiley cat emojis out there. Some cat emojis are missing, notably 😸 and 😹. This is a known limitation of keyword search algorithms, which rely on string matching to retrieve relevant items. Keyword, or <strong class="mz fr">lexical search</strong> algorithms, are known among information retrieval practitioners to have <strong class="mz fr">high precision</strong> but <strong class="mz fr">low recall</strong>. High precision means the retrieved items usually match the user query well. One the other hand, low recall means the algorithm might not retrieve all relevant items. In many cases, the lower recall is due to string matching. For example, the emoji 😹 does not have “smiling” in its name — <em class="nt">cat with tears of joy</em>. Therefore, it cannot be retrieved with the query “cat smiling” if we search for both terms <em class="nt">cat</em> and <em class="nt">smiling</em> in its name.</p><p id="1ab4" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Another issue with lexical search is that it is usually <strong class="mz fr">language-specific</strong>. In Luciano’s Fluent Python example, you can’t find emojis using a query in another language because all Unicode characters, including emojis, have English names. To support other languages, we would need to translate each query into English first using machine translation. This will add more complexity and might not work well for all languages.</p><p id="73a9" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">But hey, it’s 2024 and AI has come a long way. We now have solutions to address these limitations. In the rest of this article, I will show you how.</p><h1 id="84aa" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Embedding-based Semantic Search ✨</h1><p id="72e4" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">In recent years, a new search paradigm has emerged with the popularity of deep neural networks for NLP. In this paradigm, the search algorithm does not look at the strings that make up the items in the search database or the query. Instead, it operates on numerical representations of text, known as <strong class="mz fr">vector embeddings</strong>. In embedding-based search algorithms, the search items, whether text documents or visual images, are first converted into data points in a vector space such that <strong class="mz fr">semantically relevant</strong> items are nearby. Embeddings enable us to perform similarity search based on the meaning of the emoji description rather than the keywords in its name. Because they retrieve items based on <strong class="mz fr">semantic similarity</strong> rather than keyword similarity, embedding-based search algorithms are known as semantic search.</p><p id="9abd" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Using semantic search for emoji retrieval solves two problems:</p><ol class=""><li id="6376" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nv nw nx bk">We can go beyond keyword matching and use semantic similarity between emoji descriptions and user queries. This improves the coverage of the retrieved emojis, leading to higher recall.</li><li id="0968" class="mx my fq mz b go ny nb nc gr nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nv nw nx bk">If we represent emojis as data points in a <strong class="mz fr">multilingual embedding</strong> space, we can enable user queries written in languages other than English, without needing translation into English. That is very cool, isn’t it? Let’s see how 👀</li></ol><h1 id="20fb" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Step 1: Generating Rich Emoji Descriptions using LLMs 🦜</h1><p id="1b26" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">If you use social media, you probably know that many emojis are almost never used literally. For example, 🍆 and 🍑 rarely denote an <em class="nt">eggplant</em> and <em class="nt">peach</em>. Social media users are very creative in assigning meanings to emojis that go beyond their literal interpretation. This creativity limits the expressiveness of emoji names in the Unicode standards. A notable example is the 🌈 emoji, which is described in the Unicode name simply as <em class="nt">rainbow</em>, yet it is commonly used in contexts related to diversity, peace, and LGBTQ+ community.</p><p id="01c1" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">To build a useful search engine, we need a rich semantic description for each emoji that defines what the emoji represents and what it symbolizes. Given that there are more than 5000 emojis in the current Unicode standards, doing this manually is not feasible. Luckily, we can employ <strong class="mz fr">Large Language Models</strong> (LLMs) to assist us in generating metadata for each emoji. Since LLMs are trained on the entire web, they have likely seen how each emoji is used in context.</p><p id="8d6c" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For this task, I used the 🦙 <a class="af nu" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" rel="noopener ugc nofollow" target="_blank"><strong class="mz fr">Llama 3</strong></a> LLM to generate metadata for each emoji. I wrote a prompt to define the task and what the LLM is expected to do. As illustrated in the figure below, the LLM generated a rich semantic description for the <em class="nt">Bullseye</em> 🎯 emoji. These descriptions are more suitable for semantic search compared to Unicode names. I released the LLM-generated descriptions as a Hugging Face <a class="af nu" href="https://huggingface.co/datasets/badrex/llm-emoji-dataset" rel="noopener ugc nofollow" target="_blank">dataset</a>.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pe"><img src="../Images/ceeef194babbfb0bcd16d0b4f158e06c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RB98fsFcdlAXqqQvYZmZCA.png"/></div></div><figcaption class="pf pg ph mj mk pi pj bf b bg z dx">Using Llama 3 LLM for generating enriched semantic descriptions for emojis.</figcaption></figure><h1 id="1244" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Step 2: Representing Emojis as Embeddings using Sentence Transformers 🔄</h1><p id="84ea" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">Now that we have a rich semantic description for each emoji in the Unicode standard, the next step is to represent each emoji as a vector embedding in a multidimensional space that captures the meaning of the emoji description. For this task, I used a multilingual transformer based on the <strong class="mz fr">BERT</strong> architecture, fine-tuned for sentence similarity across 50 languages. You can see the supported languages in the model <a class="af nu" href="https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2" rel="noopener ugc nofollow" target="_blank">card</a> in the Hugging Face 🤗 library.</p><p id="d2b1" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">So far, I have only discussed the embedding of emoji descriptions generated by the LLM, which are in English. But how can we support languages other than English?</p><p id="b3c9" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Well, here’s where the magic of multilingual transformers comes in. The multilingual support is enabled through the embedding space itself. This means we can take user queries in any of the 50 supported languages and match them to emojis based on their English descriptions. The multilingual sentence encoder (or embedding model) maps semantically similar text phrases to nearby points in its embedding space. Let me show you what I mean with the following illustration.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pk"><img src="../Images/c4f1cb844d59ebb3ee7160335f3365e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bW0-VPzolusp2GKCDCA1wQ.png"/></div></div><figcaption class="pf pg ph mj mk pi pj bf b bg z dx">A visual illustration of the multilingual embedding space where sentences and phrases are geometrically organized based on their semantic similarity regardless of the text language. The Arabic and Chinese texts in this figure are the literal translation of the phrase “Cat smiling”.</figcaption></figure><p id="8a30" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In the figure above, we see that semantically similar phrases end up being data points that are nearby in the embedding space, even if they are expressed in different languages. Multilingual sentence Transformers enable <strong class="mz fr">cross-lingual search</strong> applications, therefore user queries and indexed search items do not have to be expressed in the same language.</p><h1 id="63b0" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Step 3: Integrating Qdrant’s Vector Database 🧑🏻‍🚀</h1><p id="15d6" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">Once we have our emojis represented as vector embeddings, the next step is to build an index over these embeddings in a way that allows for efficient search operations. For this purpose, I chose to use <strong class="mz fr">Qdrant</strong>, an open-source vector similarity search engine that provides high-performance search capabilities.</p><p id="5f24" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Setting up Qdrant for this task is a simple as the code snippet below (you can also check out this Jupyter <a class="af nu" href="https://github.com/badrex/emojeez/blob/main/notebooks/emoji_search_notebook.ipynb" rel="noopener ugc nofollow" target="_blank">Notebook</a>).</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="2aab" class="pp oe fq pm b bg pq pr l ps pt"># Load the emoji dictionary from a pickle file<br/>with open(file_path, 'rb') as file:<br/>    emoji_dict: Dict[str, Dict[str, Any]] = pickle.load(file)<br/>    <br/># Setup the Qdrant client and populate the database<br/>vector_DB_client = QdrantClient(":memory:")<br/><br/>embedding_dict = {<br/>    emoji: np.array(metadata['embedding']) <br/>    for emoji, metadata in emoji_dict.items()<br/>}<br/><br/># Remove the embeddings from the dictionary so it can be used <br/># as payload in Qdrant<br/>for emoji in list(emoji_dict):<br/>    del emoji_dict[emoji]['embedding']<br/><br/>embedding_dim: int = next(iter(embedding_dict.values())).shape[0]<br/><br/># Create a new collection in Qdrant<br/>vector_DB_client.create_collection(<br/>    collection_name="EMOJIS",<br/>    vectors_config=models.VectorParams(<br/>        size=embedding_dim, <br/>        distance=models.Distance.COSINE<br/>    ),<br/>)<br/><br/># Upload vectors to the collection<br/>vector_DB_client.upload_points( <br/>    collection_name="EMOJIS",<br/>    points=[<br/>        models.PointStruct(<br/>            id=idx, <br/>            vector=embedding_dict[emoji].tolist(),<br/>            payload=emoji_dict[emoji]<br/>        )<br/>        for idx, emoji in enumerate(emoji_dict)<br/>    ],<br/>)</span></pre><p id="e1e9" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Now the search index <em class="nt">vector_DB_client</em> is ready to take queries. All we need to do is to transform the coming user query into a vector embedding using the same embedding model we used to embed the emoji descriptions. This can be done through the function below.</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="3bcd" class="pp oe fq pm b bg pq pr l ps pt">def retrieve_relevant_emojis(<br/>        embedding_model: SentenceTransformer,<br/>        vector_DB_client: QdrantClient,<br/>        query: str, <br/>        num_to_retrieve: int) -&gt; List[str]:<br/>    """<br/>    Return emojis relevant to the query using sentence encoder and Qdrant. <br/>    """<br/><br/>    # Embed the query<br/>    query_vector = embedding_model.encode(query).tolist()<br/><br/>    hits = vector_DB_client.search(<br/>        collection_name="EMOJIS",<br/>        query_vector=query_vector,<br/>        limit=num_to_retrieve,<br/>    )<br/><br/>    return hits</span></pre><p id="ce9d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">To further show the retrieved emojis, their similarity score with the query, and their Unicode names, I wrote the following helper function.</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="e277" class="pp oe fq pm b bg pq pr l ps pt">def show_top_10(query: str) -&gt; None:<br/>    """<br/>    Show emojis that are most relevant to the query.<br/>    """<br/>    emojis = retrieve_relevant_emojis(<br/>        sentence_encoder, <br/>        vector_DB_clinet, <br/>        query, <br/>        num_to_retrieve=10<br/>    )<br/><br/><br/>    for i, hit in enumerate(emojis, start=1):<br/>       <br/>        emoji_char = hit.payload['Emoji']<br/>        score = hit.score<br/><br/>        space = len(emoji_char) + 3<br/>        <br/>        unicode_desc = ' '.join(<br/>           em.demojize(emoji_char).split('_')<br/>        ).upper()<br/><br/>        print(f"{i:&lt;3} {emoji_char:&lt;{space}}", end='')<br/>        print(f"{score:&lt;7.3f}", end= '')<br/>        print(f"{unicode_desc[1:-1]:&lt;55}")</span></pre><p id="e9fb" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Now everything is set up, and we can look at a few examples. Remember the “cat smiling” query from Luciano’s book? Let’s see how semantic search is different from keyword search.</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="21cd" class="pp oe fq pm b bg pq pr l ps pt">&gt;&gt;&gt; show_top_10('cat smiling')<br/>1   😼   0.651  CAT WITH WRY SMILE                                     <br/>2   😸   0.643  GRINNING CAT WITH SMILING EYES                         <br/>3   😹   0.611  CAT WITH TEARS OF JOY                                  <br/>4   😻   0.603  SMILING CAT WITH HEART-EYES                            <br/>5   😺   0.596  GRINNING CAT                                           <br/>6   🐱   0.522  CAT FACE                                               <br/>7   🐈   0.513  CAT                                                    <br/>8   🐈‍⬛   0.495  BLACK CAT                                              <br/>9   😽   0.468  KISSING CAT                                            <br/>10  🐆   0.452  LEOPARD</span></pre><p id="cc6b" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Awesome! Not only did we get the expected cat emojis like 😸, 😺, and 😻, which the keyword search retrieved, but it also the smiley cats 😼, 😹, 🐱, and 😽. This showcases the higher recall, or higher coverage of the retrieved items, I mentioned earlier. Indeed, more cats is always better!</p><h1 id="00da" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">The Real Power of Semantic Search 🪄</h1><p id="04bf" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">The previous “cat smiling” example shows how embedding-based semantic search can retrieve a broader and more meaningful set of items, improving the overall search experience. However, I don’t think this example truly shows the power of semantic search.</p><p id="c7f8" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Imagine looking for something but not knowing its name. For example, take the 🧿 object. Do you know what it’s called in English? I sure didn’t. But I know a bit about it. In Middle Eastern and Central Asian cultures, the 🧿 is believed to protect against the evil eye. So, I knew what it does but not what it’s called.</p><p id="ff9c" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Let’s see if we can find the emoji 🧿 with our search engine by describing it using the query “protect from evil eye”.</p><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="c97f" class="pp oe fq pm b bg pq pr l ps pt">&gt;&gt;&gt; show_top_10('protect from evil eye')<br/>1   🧿   0.409  NAZAR AMULET                                           <br/>2   👓   0.405  GLASSES                                                <br/>3   🥽   0.387  GOGGLES                                                <br/>4   👁   0.383  EYE                                                    <br/>5   🦹🏻   0.382  SUPERVILLAIN LIGHT SKIN TONE                           <br/>6   👀   0.374  EYES                                                   <br/>7   🦹🏿   0.370  SUPERVILLAIN DARK SKIN TONE                            <br/>8   🛡️   0.369  SHIELD                                                 <br/>9   🦹🏼   0.366  SUPERVILLAIN MEDIUM-LIGHT SKIN TONE                    <br/>10  🦹🏻‍♂   0.364  MAN SUPERVILLAIN LIGHT SKIN TONE                       </span></pre><p id="745e" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">And Viola! It turns out that the 🧿 is actually called <em class="nt">Nazar Amulet</em>. I learned something new 😄</p><h1 id="b133" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Going Beyond English 🌍 🌏 🌎</h1><p id="3f54" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">One of the features I really wanted for this search engine to have is for it to support as many languages besides English as possible. So far, we have not tested that. Let’s test the multilingual capabilities using the description of the <em class="nt">Nazar Amulet</em> 🧿 emoji by translating the phrase “protection from evil eyes” into other languages and using them as queries one language at a time. Here are the result below for some languages.</p><h1 id="e8d0" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Arabic</h1><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="b326" class="pp oe fq pm b bg pq pr l ps pt">&gt;&gt;&gt; show_top_10('يحمي من العين الشريرة') # Arabic<br/>1   🧿   0.442  NAZAR AMULET                                           <br/>2   👓   0.430  GLASSES                                                <br/>3   👁   0.414  EYE                                                    <br/>4   🥽   0.403  GOGGLES                                                <br/>5   👀   0.403  EYES                                                   <br/>6   🦹🏻   0.398  SUPERVILLAIN LIGHT SKIN TONE                           <br/>7   🙈   0.394  SEE-NO-EVIL MONKEY                                     <br/>8   🫣   0.387  FACE WITH PEEKING EYE                                  <br/>9   🧛🏻   0.385  VAMPIRE LIGHT SKIN TONE                                <br/>10  🦹🏼   0.383  SUPERVILLAIN MEDIUM-LIGHT SKIN TONE</span></pre><h1 id="65f2" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">German</h1><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="5261" class="pp oe fq pm b bg pq pr l ps pt">&gt;&gt;&gt; show_top_10('Vor dem bösen Blick schützen') # Deutsch <br/>1   😷   0.369  FACE WITH MEDICAL MASK                                 <br/>2   🫣   0.364  FACE WITH PEEKING EYE                                  <br/>3   🛡️   0.360  SHIELD                                                 <br/>4   🙈   0.359  SEE-NO-EVIL MONKEY                                     <br/>5   👀   0.353  EYES                                                   <br/>6   🙉   0.350  HEAR-NO-EVIL MONKEY                                    <br/>7   👁   0.346  EYE                                                    <br/>8   🧿   0.345  NAZAR AMULET                                           <br/>9   💂🏿‍♀️   0.345  WOMAN GUARD DARK SKIN TONE                             <br/>10  💂🏿‍♀   0.345  WOMAN GUARD DARK SKIN TONE</span></pre><h1 id="8d10" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Greek</h1><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="3a67" class="pp oe fq pm b bg pq pr l ps pt">&gt;&gt;&gt; show_top_10('Προστατέψτε από το κακό μάτι') #Greek<br/>1   👓   0.497  GLASSES                                                <br/>2   🥽   0.484  GOGGLES                                                <br/>3   👁   0.452  EYE                                                    <br/>4   🕶️   0.430  SUNGLASSES                                             <br/>5   🕶   0.430  SUNGLASSES                                             <br/>6   👀   0.429  EYES                                                   <br/>7   👁️   0.415  EYE                                                    <br/>8   🧿   0.411  NAZAR AMULET                                           <br/>9   🫣   0.404  FACE WITH PEEKING EYE                                  <br/>10  😷   0.391  FACE WITH MEDICAL MASK</span></pre><h1 id="93cf" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Bulgarian</h1><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="f6cc" class="pp oe fq pm b bg pq pr l ps pt">&gt;&gt;&gt; show_top_10('Защитете от лошото око') # Bulgarian<br/>1   👓   0.475  GLASSES                                                <br/>2   🥽   0.452  GOGGLES                                                <br/>3   👁   0.448  EYE                                                    <br/>4   👀   0.418  EYES                                                   <br/>5   👁️   0.412  EYE                                                    <br/>6   🫣   0.397  FACE WITH PEEKING EYE                                  <br/>7   🕶️   0.387  SUNGLASSES                                             <br/>8   🕶   0.387  SUNGLASSES                                             <br/>9   😝   0.375  SQUINTING FACE WITH TONGUE                             <br/>10  🧿   0.373  NAZAR AMULET</span></pre><h1 id="9d8d" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Chinese</h1><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="7125" class="pp oe fq pm b bg pq pr l ps pt">&gt;&gt;&gt; show_top_10('防止邪眼') # Chinese<br/>1   👓   0.425  GLASSES                                                <br/>2   🥽   0.397  GOGGLES                                                <br/>3   👁   0.392  EYE                                                    <br/>4   🧿   0.383  NAZAR AMULET                                           <br/>5   👀   0.380  EYES                                                   <br/>6   🙈   0.370  SEE-NO-EVIL MONKEY                                     <br/>7   😷   0.369  FACE WITH MEDICAL MASK                                 <br/>8   🕶️   0.363  SUNGLASSES                                             <br/>9   🕶   0.363  SUNGLASSES                                             <br/>10  🫣   0.360  FACE WITH PEEKING EYE</span></pre><h1 id="6d2f" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Japanese</h1><pre class="mm mn mo mp mq pl pm pn bp po bb bk"><span id="fa3d" class="pp oe fq pm b bg pq pr l ps pt">&gt;&gt;&gt; show_top_10('邪眼から守る') # Japanese <br/>1   🙈   0.379  SEE-NO-EVIL MONKEY                                     <br/>2   🧿   0.379  NAZAR AMULET                                           <br/>3   🙉   0.370  HEAR-NO-EVIL MONKEY                                    <br/>4   😷   0.363  FACE WITH MEDICAL MASK                                 <br/>5   🙊   0.363  SPEAK-NO-EVIL MONKEY                                   <br/>6   🫣   0.355  FACE WITH PEEKING EYE                                  <br/>7   🛡️   0.355  SHIELD                                                 <br/>8   👁   0.351  EYE                                                    <br/>9   🦹🏼   0.350  SUPERVILLAIN MEDIUM-LIGHT SKIN TONE                    <br/>10  👓   0.350  GLASSES</span></pre><p id="4f6a" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For languages as diverse as Arabic, German, Greek, Bulgarian, Chinese, and Japanese, the 🧿 emoji always appears in the top 10! This is pretty fascinating since these languages have different linguistic features and writing scripts, thanks to the massive multilinguality of our 🤗 sentence Transformer.</p><h1 id="c57c" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Limits of AI 🙈</h1><p id="70bd" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">The last thing I want to mention is that no technology, no matter how advanced, is perfect. Semantic search is great for improving the recall of information retrieval systems. This means we can retrieve more relevant items even if there is no keyword overlap between the query and the items in the search index. However, this comes at the expense of precision. Remember from the 🧿 emoji example that in some languages, the emoji we were looking for didn’t show up in the top 5 results. For this application, this is not a big problem since it’s not cognitively demanding to quickly scan through emojis to find the one we desire, even if it’s ranked at the 50th position. But in other cases such as searching through long documents, users may not have the patience nor the resources to skim through dozens of documents. Developers need to keep in mind user cognitive as well as resource constraints when building search engines. Some of the design choices I made for the Emojeez 💎 search engine may not be work as well for other applications.</p><p id="482a" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Another thing to mention is that AI models are known to learn s<strong class="mz fr">ocio-cultural biases</strong> from their training data. There is a large volume of documented research showing how modern language technology can amplify <strong class="mz fr">gender stereotypes</strong> and be unfair to <strong class="mz fr">minorities</strong>. So, we need to be aware of these issues and do our best to tackle them when deploying AI in the real world. If you notice such unwanted biases and unfair behaviors in Emojeez 💎, please let me know and I will do my best to address them.</p><h1 id="7fb5" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Conclusion</h1><p id="5442" class="pw-post-body-paragraph mx my fq mz b go oz nb nc gr pa ne nf ng pb ni nj nk pc nm nn no pd nq nr ns fj bk">Working on the Emojeez 💎 project was a fascinating journey that taught me a lot about how modern AI and NLP technologies can be employed to address the limitations of traditional keyword search. By harnessing the power of Large Language Models for enriching emoji metadata, multilingual transformers for creating semantic embeddings, and Qdrant for efficient vector search, I was able to create a search engine that makes emoji search more fun and accessible across 50+ languages. Although this project focuses on emoji search, the underlying technology has potential applications in multimodal search and recommendation systems.</p><p id="13da" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For readers who are proficient in languages other than English, I am particularly interested in your feedback. Does Emojeez 💎 perform equally well in English and your native language? Did you notice any differences in quality or accuracy? Please give it a try and let me what you think. Your insights are quite invaluable.</p><p id="43fe" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Thank you for reading, and I hope you enjoy exploring Emojeez 💎 as much as I enjoyed building it.</p><p id="4f52" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Happy Emoji search! 📆😊🌍🚀</p><p id="26ae" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><em class="nt">Note: Unless otherwise noted, all images are created by the author.</em></p></div></div></div></div>    
</body>
</html>