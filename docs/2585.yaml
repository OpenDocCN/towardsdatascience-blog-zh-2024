- en: 'ML Metamorphosis: Chaining ML Models for Optimized Results'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ml-metamorphosis-chaining-ml-models-for-optimized-results-d89d952627a9?source=collection_archive---------2-----------------------#2024-10-23](https://towardsdatascience.com/ml-metamorphosis-chaining-ml-models-for-optimized-results-d89d952627a9?source=collection_archive---------2-----------------------#2024-10-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The universal principle of knowledge distillation, model compression, and rule
    extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@vadim.arzamasov?source=post_page---byline--d89d952627a9--------------------------------)[![Vadim
    Arzamasov](../Images/70ced2eafa6fc926052979875a0a4265.png)](https://medium.com/@vadim.arzamasov?source=post_page---byline--d89d952627a9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d89d952627a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d89d952627a9--------------------------------)
    [Vadim Arzamasov](https://medium.com/@vadim.arzamasov?source=post_page---byline--d89d952627a9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d89d952627a9--------------------------------)
    ·7 min read·Oct 23, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5b5804cb68224d5d689f156155d59eb9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1**. This and other images were created by the author with the help
    of recraft.ai'
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine learning (ML) model training typically follows a familiar pipeline:
    start with data collection, clean and prepare it, then move on to model fitting.
    But what if we could take this process further? Just as some insects undergo dramatic
    transformations before reaching maturity, ML models can evolve in a similar way
    (see Hinton et al. [1]) — what I will call the **ML metamorphosis**. This process
    involves chaining different models together, resulting in a final model that achieves
    significantly better quality than if it had been trained directly from the start.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with some initial knowledge, *Data 1*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train an ML model, *Model A* (say, a neural network), on this data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate new data, *Data 2*, using *Model A*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, use Data 2 to fit your target model, *Model B*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/2645f7d1e0777997a8daebcec3b49575.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2\.** An illustration of the ML metamorphosis'
  prefs: []
  type: TYPE_NORMAL
- en: You may already be familiar with this concept from knowledge distillation, where
    a smaller neural network replaces a larger one. But ML metamorphosis goes beyond
    this, and neither the initial model (*Model A*) nor the final one (*Model B*)
    need be neural networks at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: ML metamorphosis on the MNIST Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Imagine you’re tasked with training a multi-class decision tree on the MNIST
    dataset of handwritten digit images, but only 1,000 images are labelled. You could
    train the tree directly on this limited data, but the accuracy would be capped
    at around 0.67\. Not great, right? Alternatively, you could use ML metamorphosis
    to improve your results.*'
  prefs: []
  type: TYPE_NORMAL
- en: But before we dive into the solution, let’s take a quick look at the techniques
    and research behind this approach.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Knowledge distillation (2015)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even if you haven’t used knowledge distillation, you’ve probably seen it in
    action. For example, Meta suggests distilling its Llama 3.2 model to adapt it
    to specific tasks [2]. Or take DistilBERT — a distilled version of BERT [3]— or
    the DMD framework, which distills Stable Diffusion to speed up image generation
    by a factor of 30 [4].
  prefs: []
  type: TYPE_NORMAL
- en: At its core, knowledge distillation transfers knowledge from a large, complex
    model (the *teacher*) to a smaller, more efficient model (the *student*). The
    process involves creating a *transfer set* that includes both the original training
    data and additional data (either original or synthesized) pseudo-labeled by the
    teacher model. The pseudo-labels are known as *soft labels* — derived from the
    probabilities predicted by the teacher across multiple classes. These soft labels
    provide richer information than *hard labels* (simple class indicators) because
    they reflect the teacher’s confidence and capture subtle similarities between
    classes. For instance, they might show that a particular “1” is more similar to
    a “7” than to a “5.”
  prefs: []
  type: TYPE_NORMAL
- en: By training on this enriched transfer set, the student model can effectively
    mimic the teacher’s performance while being much lighter, faster, and easier to
    use.
  prefs: []
  type: TYPE_NORMAL
- en: The student model obtained in this way is more accurate than it would have been
    if it had been trained solely on the original training set.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 2\. Model compression (2007)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model compression [5] is often seen as a precursor to knowledge distillation,
    but there are important differences. Unlike knowledge distillation, model compression
    doesn’t seem to use soft labels, despite some claims in the literature [1,6].
    I haven’t found any evidence that soft labels are part of the process. In fact,
    the method in the original paper doesn’t even rely on artificial neural networks
    (ANNs) as *Model A*. Instead, it uses an ensemble of models — such as SVMs, decision
    trees, random forests, and others.
  prefs: []
  type: TYPE_NORMAL
- en: Model compression works by approximating the feature distribution *p(x)* to
    create a transfer set. This set is then labelled by *Model A*, which provides
    the conditional distribution *p(y|x)*. The key innovation in the original work
    is a technique called MUNGE to approximate *p(x)*. As with knowledge distillation,
    the goal is to train a smaller, more efficient *Model B* that retains the performance
    of the larger *Model A*.
  prefs: []
  type: TYPE_NORMAL
- en: As in knowledge distillation, the compressed model trained in this way can often
    outperform a similar model trained directly on the original data, thanks to the
    rich information embedded in the transfer set [5].
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Often, “model compression” is used more broadly to refer to any technique that
    reduces the size of *Model A* [7,8]. This includes methods like knowledge distillation
    but also techniques that don’t rely on a transfer set, such as pruning, quantization,
    or low-rank approximation for neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Rule extraction (1995)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When the problem isn’t computational complexity or memory, but the opacity
    of a model’s decision-making, pedagogical rule extraction offers a solution [9].
    In this approach, a simpler, more interpretable model (*Model B*) is trained to
    replicate the behavior of the opaque teacher model (*Model A*), with the goal
    of deriving a set of human-readable rules. The process typically starts by feeding
    unlabelled examples — often randomly generated — into *Model A*, which labels
    them to create a transfer set. This transfer set is then used to train the transparent
    student model. For example, in a classification task, the student model might
    be a decision tree that outputs rules such as: “If feature X1 is above threshold
    T1 and feature X2 is below threshold T2, then classify as positive”.'
  prefs: []
  type: TYPE_NORMAL
- en: The main goal of pedagogical rule extraction is to closely mimic the teacher
    model’s behavior, with *fidelity* — the accuracy of the student model relative
    to the teacher model — serving as the primary quality measure.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, research has shown that transparent models created through this
    method can sometimes reach higher accuracy than similar models trained directly
    on the original data used to build Model A [10,11].
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Pedagogical rule extraction belongs to a broader family of techniques known
    as “global” model explanation methods, which also include decompositional and
    eclectic rule extraction. See [12] for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Simulations as Model A
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Model A* doesn’t have to be an ML model — it could just as easily be a computer
    simulation of an economic or physical process, such as the simulation of airflow
    around an airplane wing. In this case, *Data 1* consists of the differential or
    difference equations that define the process. For any given input, the simulation
    makes predictions by solving these equations numerically. However, when these
    simulations become computationally expensive, a faster alternative is needed:
    a surrogate model (*Model B*), which can accelerate tasks like optimization [13].
    When the goal is to identify important regions in the input space, such as zones
    of system stability, an interpretable *Model B* is developed through a process
    known as scenario discovery [14]. To generate the transfer set (*Data 2*) for
    both surrogate modelling and scenario discovery, *Model A* is run on a diverse
    set of inputs.'
  prefs: []
  type: TYPE_NORMAL
- en: Back to our MNIST example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In an insightful [article](/teaching-your-model-to-learn-from-itself-8b5ef13eb173)
    on TDS [15], [Niklas von Moers](https://medium.com/u/a3ecf86934da?source=post_page---user_mention--d89d952627a9--------------------------------)
    shows how semi-supervised learning can improve the performance of a convolutional
    neural network (CNN) on the same input data. This result fits into the first stage
    of the ML metamorphosis pipeline, where *Model A* is a trained CNN classifier.
    The transfer set, *Data 2*, then contains the originally labelled 1,000 training
    examples plus about 55,000 examples pseudo-labelled by *Model A* with high confidence
    predictions. I now train our target *Model B*, a decision tree classifier, on
    *Data 2* and achieve an accuracy of 0.86 — much higher than 0.67 when training
    on the labelled part of *Data 1* alone. This means that chaining the decision
    tree to the CNN solution reduces error rate of the decision tree from 0.33 to
    0.14\. Quite an improvement, wouldn’t you say?
  prefs: []
  type: TYPE_NORMAL
- en: For the full experimental code, check out the [GitHub](https://github.com/Arzik1987/medium/tree/main/metamorphosis)
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In summary, ML metamorphosis isn’t always necessary — especially if accuracy
    is your only concern and there’s no need for interpretability, faster inference,
    or reduced storage requirements. But in other cases, chaining models may yield
    significantly better results than training the target model directly on the original
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b04e87426dec01924b73226bb1df2ea.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2**: For easy reference, here’s the illustration again'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a classification task, the process involves:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Data 1*: The original, fully or partially labeled data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Model A*: A model trained on *Data 1*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data 2*: A transfer set that includes pseudo-labeled data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Model B*: The final model, designed to meet additional requirements, such
    as interpretability or efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So why don’t we always use ML metamorphosis? The challenge often lies in finding
    the right transfer set, *Data 2* [9]. But that’s a topic for another story.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Hinton, Geoffrey. “[Distilling the Knowledge in a Neural Network](https://arxiv.org/pdf/1503.02531).”
    *arXiv preprint arXiv:1503.02531* (2015).'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [Introducing Llama 3.2](https://llama.meta.com/?ref=engineering.fb.com)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Sanh, Victor, et al. “[DistilBERT, a distilled version of BERT: Smaller,
    faster, cheaper and lighter](https://arxiv.org/abs/1910.01108). ” *arXiv preprint
    arXiv:1910.01108* (2019).'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Yin, Tianwei, et al. “[One-step diffusion with distribution matching distillation](https://tianweiy.github.io/dmd/).”
    *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*.
    2024.'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] Buciluǎ, Cristian, Rich Caruana, and Alexandru Niculescu-Mizil. “[Model
    compression.](https://dl.acm.org/doi/pdf/10.1145/1150402.1150464?casa_token=CY8nr3ZTpi0AAAAA%3A6T9MQ4MKzDCllOBuaurkddgR67bKLt88tc-TtEf0MfzNCdncFzr0Q1ZQZSha2GkBBYdysx78qMxdwA)”
    *Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery
    and data mining*. 2006.'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] [Knowledge distillation](https://en.wikipedia.org/wiki/Knowledge_distillation),
    Wikipedia'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] [An Overview of Model Compression Techniques for Deep Learning in Space](https://medium.com/gsi-technology/an-overview-of-model-compression-techniques-for-deep-learning-in-space-3fd8d4ce84e5),
    on Medium'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] [Distilling BERT Using an Unlabeled Question-Answering Dataset](/distilling-bert-using-unlabeled-qa-dataset-4670085cc18),
    on Towards Data Science'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] Arzamasov, Vadim, Benjamin Jochum, and Klemens Böhm. “[Pedagogical Rule
    Extraction to Learn Interpretable Models — an Empirical Study](https://arxiv.org/pdf/2112.13285).”
    *arXiv preprint arXiv:2112.13285* (2021).'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] Domingos, Pedro. “[Knowledge acquisition from examples via multiple models.](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=1a9a39da9d4fc937bc455705d508674a205620aa)”
    *MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE-*. MORGAN KAUFMANN PUBLISHERS,
    INC., 1997.'
  prefs: []
  type: TYPE_NORMAL
- en: '[11] De Fortuny, Enric Junque, and David Martens. “[Active learning-based pedagogical
    rule extraction](https://ieeexplore.ieee.org/abstract/document/7018925?casa_token=SU8qtZ-ZkGEAAAAA%3A7L_-_Sj-eZ7x0_f4oYQgH4kynTftYbJW4ytvcEQgaq-r4VWyOdmh0lD1jXYN1otMmKzt-dIRcA).”
    *IEEE transactions on neural networks and learning systems* 26.11 (2015): 2664–2677.'
  prefs: []
  type: TYPE_NORMAL
- en: '[12] Guidotti, Riccardo, et al. “[A survey of methods for explaining black
    box models](https://dl.acm.org/doi/abs/10.1145/3236009).” *ACM computing surveys
    (CSUR)* 51.5 (2018): 1–42.'
  prefs: []
  type: TYPE_NORMAL
- en: '[13] [Surrogate model](https://en.wikipedia.org/wiki/Surrogate_model), Wikipedia'
  prefs: []
  type: TYPE_NORMAL
- en: '[14] [Scenario discovery in Python](https://waterprogramming.wordpress.com/2015/08/05/scenario-discovery-in-python/),
    blog post on [Water Programming](https://waterprogramming.wordpress.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[15] [Teaching Your Model to Learn from Itself](/teaching-your-model-to-learn-from-itself-8b5ef13eb173),
    on Towards Data Science'
  prefs: []
  type: TYPE_NORMAL
