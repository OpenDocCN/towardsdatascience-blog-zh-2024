<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Building a Semantic Book Search: Scale an Embedding Pipeline with Apache Spark and AWS EMR Serverless</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Building a Semantic Book Search: Scale an Embedding Pipeline with Apache Spark and AWS EMR Serverless</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-semantic-book-search-part-2-scaling-the-embedding-pipeline-with-apache-spark-and-aws-1d074ee9cb55?source=collection_archive---------8-----------------------#2024-01-31">https://towardsdatascience.com/building-a-semantic-book-search-part-2-scaling-the-embedding-pipeline-with-apache-spark-and-aws-1d074ee9cb55?source=collection_archive---------8-----------------------#2024-01-31</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="fo bh"><figure class="fp fo bh paragraph-image"><img src="../Images/c41e10bbe243304d42ff3cdf276f15b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:4800/format:webp/1*RtOoKEZ6e7Rp_0AeNrQTEg.jpeg"/><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image from Unsplash</figcaption></figure></div><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="81b2" class="pw-subtitle-paragraph gy ga gb bf b gz ha hb hc hd he hf hg hh hi hj hk hl hm hn cq dx">Using OpenAI’s Clip model to support natural language search on a collection of 70k book covers</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="ho hp hq hr hs ab"><div><div class="ab ht"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@erevear?source=post_page---byline--1d074ee9cb55--------------------------------" rel="noopener follow"><div class="l hu hv by hw hx"><div class="l ed"><img alt="Eva Revear" class="l ep by dd de cx" src="../Images/675266fccb503690d50d83b8c92f48b8.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*TDe2GU_aVQijIWwvj7WlXw.jpeg"/><div class="hy by l dd de em n hz eo"/></div></div></a></div></div><div class="ia ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--1d074ee9cb55--------------------------------" rel="noopener follow"><div class="l ib ic by hw id"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ie cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hy by l br ie em n hz eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="if ab q"><div class="ab q ig"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ih ii bk"><a class="af ag ah ai aj ak al am an ao ap aq ar ij" data-testid="authorName" href="https://medium.com/@erevear?source=post_page---byline--1d074ee9cb55--------------------------------" rel="noopener follow">Eva Revear</a></p></div></div></div><span class="ik il" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ih ii dx"><button class="im in ah ai aj ak al am an ao ap aq ar io ip iq" disabled="">Follow</button></p></div></div></span></div></div><div class="l ir"><span class="bf b bg z dx"><div class="ab cn is it iu"><div class="iv iw ab"><div class="bf b bg z dx ab ix"><span class="iy l ir">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar ij ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--1d074ee9cb55--------------------------------" rel="noopener follow"><p class="bf b bg z iz ja jb jc jd je jf jg bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ik il" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="jh ji l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 31, 2024</span></div></span></div></span></div></div></div><div class="ab cp jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy"><div class="h k w ea eb q"><div class="ko l"><div class="ab q kp kq"><div class="pw-multi-vote-icon ed iy kr ks kt"><div class=""><div class="ku kv kw kx ky kz la am lb lc ld kt"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l le lf lg lh li lj lk"><p class="bf b dy z dx"><span class="kv">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ku ll lm ab q ee ln lo" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="fp"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jz ka kb kc kd ke kf kg kh ki kj kk kl km kn"><div class="lp k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lq an ao ap io lr ls lt" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lu cn"><div class="l ae"><div class="ab cb"><div class="lv lw lx ly lz fq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lq an ao ap io ma mb lo mc md me mf mg s mh mi mj mk ml mm mn u mo mp mq"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lq an ao ap io ma mb lo mc md me mf mg s mh mi mj mk ml mm mn u mo mp mq"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lq an ao ap io ma mb lo mc md me mf mg s mh mi mj mk ml mm mn u mo mp mq"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="5b70" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">In a <a class="af nn" href="https://medium.com/@erevear/building-semantic-book-search-with-openais-clip-model-b7c3dafa2bea" rel="noopener">previous post</a> I did a little PoC to see if I could use OpenAI’s Clip model to build a semantic book search. It worked surprisingly well, in my opinion, but I couldn’t help wondering if it would be better with more data. The previous version used only about 3.5k books, but there are millions in the <a class="af nn" href="https://openlibrary.org/data" rel="noopener ugc nofollow" target="_blank">Openlibrary data set</a>, and I thought it was worthwhile to try adding more options to the search space.</p><p id="f4f2" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">However, the full dataset is about 40GB, and trying to handle that much data on my little laptop, or even in a Colab notebook was a bit much, so I had to figure out a pipeline that could manage filtering and embedding a larger data set.</p><p id="22c3" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">TLDR; Did it improve the search? I think it did! We 15x’ed the data, which gives the search much more to work with. Its not perfect, but I thought the results were fairly interesting; although I haven’t done a formal accuracy measure.</p><p id="b12b" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">This was one example I couldn’t get to work no matter how I phrased it in the last iteration, but works fairly well in the version with more data.</p><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw no"><img src="../Images/607d576fe9f3cd3c251f1adee292b71f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wfqc_aKKF9UmvWleabINXA.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image by author</figcaption></figure><p id="c426" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">If you’re curious you can try it out in <a class="af nn" href="https://colab.research.google.com/drive/1QH_ZlDKAJ9I5yEitew6X_ZJWIvcmsqfv?usp=sharing" rel="noopener ugc nofollow" target="_blank">Colab</a>!</p><p id="b281" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Overall, it was an interesting technical journey, with a lot of roadblocks and learning opportunities along the way. The tech stack still includes the OpenAI Clip model, but this time I leverage Apache Spark and AWS EMR to run the embedding pipeline.</p><h1 id="e55b" class="ny nz gb bf oa ob oc hb od oe of he og oh oi oj ok ol om on oo op oq or os ot bk"><strong class="al">Tech Stack</strong></h1><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw ou"><img src="../Images/23511f9399b09dea8df6e74c8f6e841d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ywR6KSzswHDvVWBU3eHkXg.jpeg"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image by author</figcaption></figure><p id="0c43" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">This seemed like a good opportunity to use Spark, as it allows us to parallelize the embedding computation.</p><p id="b469" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">I decided to run the pipeline in EMR Serverless, which is a fairly new AWS offering that provides a serverless environment for EMR and manages scaling resources automatically. I felt it would work well for this use case — as opposed to spinning up an EMR on EC2 cluster — because this is a fairly ad-hoc project, I’m paranoid about cluster costs, and initially I was unsure about what resources the job would require. EMR Serverless makes it pretty easy to experiment with job parameters.</p><p id="80a3" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Below is the full process I went through to get everything up and running. I imagine there are better ways to manage certain steps, this is just what ended up working for me, so if you have thoughts or opinions, please do share!</p><h2 id="cdfc" class="ov nz gb bf oa ow ox oy od oz pa pb og na pc pd pe ne pf pg ph ni pi pj pk pl bk">Building an embedding pipeline job with Spark</h2><p id="d43e" class="pw-post-body-paragraph mr ms gb mt b gz pm mv mw hc pn my mz na po nc nd ne pp ng nh ni pq nk nl nm fj bk">The initial step was writing the Spark job(s). The full pipeline is broken out into two stages, the first takes in the initial data set and filters for recent fiction (within the last 10 years). This resulted in about 250k books, and around 70k with cover images available to download and embed in the second stage.</p><p id="783e" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">First we pull out the relevant columns from the raw data file.</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><p id="5eec" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Then do some general data transformation on data types, and filter out everything but English fiction with more than 100 pages.</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><p id="6215" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">The second stage grabs the first stage’s output dataset, and runs the images through the Clip model, downloaded from Hugging Face. The important step here is turning the various functions that we need to apply to the data into Spark UDFs. The main one of interest is get_image_embedding, which takes in the image and returns the embedding</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><p id="7de6" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">We register it as a UDF:</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><p id="b95a" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">And call that UDF on the dataset:</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><h2 id="699c" class="ov nz gb bf oa ow ox oy od oz pa pb og na pc pd pe ne pf pg ph ni pi pj pk pl bk">Setting up the vector database</h2><p id="99c7" class="pw-post-body-paragraph mr ms gb mt b gz pm mv mw hc pn my mz na po nc nd ne pp ng nh ni pq nk nl nm fj bk">As a last, optional, step in the code, we can setup a vector database, in this case Milvus, to load and query from. Note, I did not do this as part of the cloud job for this project, as I pickled my embeddings to use without having to keep a cluster up and running indefinitely. However, it is fairly simple to setup Milvus and load a Spark Dataframe to a collection.</p><p id="d7c5" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">First, create a collection with an index on the image embedding column that the database can use for the search.</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><p id="87da" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Then we can access the collection in the Spark script, and load the embeddings into it from the final Dataframe.</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><p id="949a" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Finally, we can simply embed the search text with the same method used in the UDF above, and hit the database with the embeddings. The database does the heavy lifting of figuring out the best matches</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><h2 id="da2f" class="ov nz gb bf oa ow ox oy od oz pa pb og na pc pd pe ne pf pg ph ni pi pj pk pl bk">Setting up the pipeline in AWS</h2><p id="e196" class="pw-post-body-paragraph mr ms gb mt b gz pm mv mw hc pn my mz na po nc nd ne pp ng nh ni pq nk nl nm fj bk"><strong class="mt gc">Prerequisites</strong></p><p id="5dfb" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Now there’s a bit of setup to go through in order to run these jobs on EMR Serverless.</p><p id="aec1" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">As prerequisites we need:</p><ul class=""><li id="1639" class="mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm pu pv pw bk">An S3 bucket for job scripts, inputs and outputs, and other artifacts that the job needs</li><li id="fab5" class="mr ms gb mt b gz px mv mw hc py my mz na pz nc nd ne qa ng nh ni qb nk nl nm pu pv pw bk">An IAM role with Read, List, and Write permissions for S3, as well as Read and Write for Glue.</li><li id="80b7" class="mr ms gb mt b gz px mv mw hc py my mz na pz nc nd ne qa ng nh ni qb nk nl nm pu pv pw bk">A trust policy that allows the EMR jobs to access other AWS services.</li></ul><p id="8228" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">There are great descriptions of the roles and permissions policies, as well as a general outline of how to get up and running with EMR Serverless in the AWS docs here: <a class="af nn" href="https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/getting-started.html" rel="noopener ugc nofollow" target="_blank">Getting started with Amazon EMR Serverless</a></p><p id="3413" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Next we have to setup an EMR Studio: <a class="af nn" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-create-studio.html" rel="noopener ugc nofollow" target="_blank">Create an EMR Studio</a></p><p id="9b86" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk"><strong class="mt gc">Accessing the web via an Internet Gateway</strong></p><p id="1b16" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Another bit of setup that’s specific to this particular job is that we have to allow the job to reach out to the Internet, which the EMR application is not able to do by default. As we saw in the script, the job needs to access both the images to embed, as well as Hugging Face to download the model configs and weights.</p><p id="76fb" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Note: There are likely more efficient ways to handle the model than downloading it to each worker (broadcasting it, storing it somewhere locally in the system, etc), but in this case, for a single run through the data, this is sufficient.</p><p id="50e6" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Anyway, allowing the machine the Spark job is running on to reach out to the Internet requires VPC with private subnets that have NAT gateways. All of this setup starts with accessing AWS VPC interface -&gt; Create VPC -&gt; selecting VPC and more -&gt; selecting option for at least on NAT gateway -&gt; clicking Create VPC.</p><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw qc"><img src="../Images/c949e2d8bba19e439972c50c44e0575e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kN_TD4b-yueWZt8MGd6GQA.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image by author</figcaption></figure><p id="2c69" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">The VPC takes a few minutes to set up. Once that is done we also need to create a security group in the security group interface, and attach the VPC we just created.</p><p id="90e3" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk"><strong class="mt gc">Creating the EMR Serverless application</strong></p><p id="5fba" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Now for the EMR Serverless application that will submit the job! Creating and launching an EMR studio should open a UI that offers a few options including creating an application. In the create application UI, select Use Custom settings -&gt; Network settings. Here is where the VPC, the two private subnets, and the security group come into play.</p><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw qd"><img src="../Images/ecdc638917b82e45aa67258591d2a561.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pqgiSTNBlYvU1QC0Sp1UDg.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Image by Author</figcaption></figure><p id="a024" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk"><strong class="mt gc">Building a virtual environment</strong></p><p id="bc50" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Finally, the environment doesn’t come with many libraries, so in order to add additional Python dependencies we can either use native Python or create and package a virtual environment: <a class="af nn" href="https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/using-python-libraries.html" rel="noopener ugc nofollow" target="_blank">Using Python libraries with EMR Serverless</a>.</p><p id="a75c" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">I went the second route, and the easiest way to do this is with Docker, as it allows us to build the virtual environment within the Amazon Linux distribution that’s running the EMR jobs (doing it in any other distribution or OS can become incredibly messy).</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><p id="ddd3" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Another warning: be careful to pick the version of EMR that corresponds to the version of Python that you are using, and choose package versions accordingly as well.</p><p id="4895" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">The Docker process outputs the zipped up virtual environment as pyspark_dependencies.tar.gz, which then goes into the S3 bucket along with the job scripts.</p><p id="57a8" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">We can then send this packaged environment along with the rest of the Spark job configurations</p><figure class="np nq nr ns nt fo"><div class="pr iz l ed"><div class="ps pt l"/></div></figure><p id="ebbc" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Nice! We have the job script, the environmental dependencies, gateways, and an EMR application, we get to submit the job! Not so fast! Now comes the real fun, Spark tuning.</p><p id="fd4b" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">As previously mentioned, EMR Serverless scales automatically to handle our workload, which typically would be great, but I found (obvious in hindsight) that it was unhelpful for this particular use case.</p><p id="a27e" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">A few tens of thousands of records is not at all “big data”; Spark wants terabytes of data to work through, and I was just sending essentially a few thousand image urls (not even the images themselves). Left to its own devices, EMR Serverless will send the job to one node to work through on a single thread, completely defeating the purpose of parallelization.</p><p id="f88b" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">Additionally, while embedding jobs take in a relatively small amount of data, they expand it significantly, as the embeddings are quite large (512 in the case of Clip). Even if you leave that one node to churn away for a few days, it’ll run out of memory long before it finishes working through the full set of data.</p><p id="3d19" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">In order to get it to run, I experimented with a few Spark properties so that I could use large machines in the cluster, but split the data into very small partitions so that each core would have just a bit to work through and output:</p><ul class=""><li id="2c03" class="mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm pu pv pw bk">spark.executor.memory: Amount of memory to use per executor process</li><li id="08a8" class="mr ms gb mt b gz px mv mw hc py my mz na pz nc nd ne qa ng nh ni qb nk nl nm pu pv pw bk">spark.sql.files.maxPartitionBytes: The maximum number of bytes to pack into a single partition when reading files.</li><li id="fae7" class="mr ms gb mt b gz px mv mw hc py my mz na pz nc nd ne qa ng nh ni qb nk nl nm pu pv pw bk">spark.executor.cores: The number of cores to use on each executor.</li></ul><p id="62c4" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">You’ll have to tweak these depending on the particular nature of the your data, and embedding still isn’t a speedy process, but it was able to work through my data.</p><h2 id="17aa" class="ov nz gb bf oa ow ox oy od oz pa pb og na pc pd pe ne pf pg ph ni pi pj pk pl bk"><strong class="al">Conclusion</strong></h2><p id="d97c" class="pw-post-body-paragraph mr ms gb mt b gz pm mv mw hc pn my mz na po nc nd ne pp ng nh ni pq nk nl nm fj bk">As with my <a class="af nn" href="https://medium.com/@erevear/building-semantic-book-search-with-openais-clip-model-b7c3dafa2bea" rel="noopener">previous post</a> the results certainly aren’t perfect, and by no means a replacement for solid book recommendations from other humans! But that being said there were some spot on answers to a number of my searches, which I thought was pretty cool.</p><p id="8b68" class="pw-post-body-paragraph mr ms gb mt b gz mu mv mw hc mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm fj bk">If you want to play around with the app yourself, its in <a class="af nn" href="https://colab.research.google.com/drive/1QH_ZlDKAJ9I5yEitew6X_ZJWIvcmsqfv?usp=sharing" rel="noopener ugc nofollow" target="_blank">Colab</a>, and the full code for the pipeline is in <a class="af nn" href="https://github.com/erevear/book_semantic_search_cloud" rel="noopener ugc nofollow" target="_blank">Github</a>!</p></div></div></div></div>    
</body>
</html>