- en: Choosing Between LLM Agent Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/choosing-between-llm-agent-frameworks-69019493b259?source=collection_archive---------0-----------------------#2024-09-21](https://towardsdatascience.com/choosing-between-llm-agent-frameworks-69019493b259?source=collection_archive---------0-----------------------#2024-09-21)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*The tradeoffs between building bespoke code-based agents and the major agent
    frameworks.*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://aparnadhinak.medium.com/?source=post_page---byline--69019493b259--------------------------------)[![Aparna
    Dhinakaran](../Images/e431ee69563ecb27c86f3428ba53574c.png)](https://aparnadhinak.medium.com/?source=post_page---byline--69019493b259--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--69019493b259--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--69019493b259--------------------------------)
    [Aparna Dhinakaran](https://aparnadhinak.medium.com/?source=post_page---byline--69019493b259--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--69019493b259--------------------------------)
    ·12 min read·Sep 21, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7f41def86bbb86b6e740c349eac8b70e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: '*Thanks to John Gilhuly for his contributions to this piece.*'
  prefs: []
  type: TYPE_NORMAL
- en: Agents are having a moment. With multiple new frameworks and fresh [investment](https://foundationcapital.com/goodbye-aiops-welcome-agentsres-the-next-100b-opportunity/)
    in the space, modern AI agents are overcoming [shaky origins](https://arxiv.org/html/2405.13966v1)
    to rapidly supplant RAG as an implementation priority. So will 2024 finally be
    the year that autonomous AI systems that can take over writing our emails, booking
    flights, talking to our data, or seemingly any other task?
  prefs: []
  type: TYPE_NORMAL
- en: Maybe, but much work remains to get to that point. Any developer building an
    agent must not only choose foundations — which model, use case, and architecture
    to use — but also which framework to leverage. Do you go with the long-standing
    LangGraph, or the newer entrant LlamaIndex Workflows? Or do you go the traditional
    route and code the whole thing yourself?
  prefs: []
  type: TYPE_NORMAL
- en: This post aims to make that choice a bit easier. Over the past few weeks, I
    built the same agent in major frameworks to examine some of the strengths and
    weaknesses of each at a technical level. All of the code for each agent is available
    in [this repo](https://github.com/Arize-ai/phoenix/tree/main/examples/agent_framework_comparison).
  prefs: []
  type: TYPE_NORMAL
- en: Background on the Agent Used for Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The agent used for testing includes function calling, multiple tools or skills,
    connections to outside resources, and shared state or memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The agent has the following capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Answering questions from a knowledge base
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Talking to data: answering questions about telemetry data of an LLM application'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Analyzing data: analyzing higher-level trends and patterns in retrieved telemetry
    data'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to accomplish these, the agent has three starting skills: RAG with
    product documentation, SQL generation on a trace database, and data analysis.
    A simple gradio-powered interface is used for the agent UI, with the agent itself
    structured as a chatbot.'
  prefs: []
  type: TYPE_NORMAL
- en: Code-Based Agent (No Framework)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first option you have when developing an agent is to skip the frameworks
    entirely and build the agent fully yourself. When embarking on this project, this
    was the approach I started with.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d10a779ccc5d91bfa0325de4b2665e86.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Pure Code Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code-based agent below is made up of an OpenAI-powered router that uses
    function calling to select the right skill to use. After that skill completes,
    it returns back to the router to either call another skill or respond to the user.
  prefs: []
  type: TYPE_NORMAL
- en: The agent keeps an ongoing list of messages and responses that is passed fully
    into the router on each call to preserve context through cycles.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The skills themselves are defined in their own classes (e.g. GenerateSQLQuery)
    that are collectively held in a SkillMap. The router itself only interacts with
    the SkillMap, which it uses to load skill names, descriptions, and callable functions.
    This approach means that adding a new skill to the agent is as simple as writing
    that skill as its own class, then adding it to the list of skills in the SkillMap.
    The idea here is to make it easy to add new skills without disturbing the router
    code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Overall, this approach is fairly straightforward to implement but comes with
    a few challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges with Pure Code Agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first difficulty lies in structuring the router system prompt. Often, the
    router in the example above insisted on generating SQL itself instead of delegating
    that to the right skill. If you’ve ever tried to get an LLM *not* to do something,
    you know how frustrating that experience can be; finding a working prompt took
    many rounds of debugging. Accounting for the different output formats from each
    step was also tricky. Since I opted not to use structured outputs, I had to be
    ready for multiple different formats from each of the LLM calls in my router and
    skills.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of a Pure Code Agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A code-based approach provides a good baseline and starting point, offering
    a great way to learn how agents work without relying on canned agent tutorials
    from prevailing frameworks. Although convincing the LLM to behave can be challenging,
    the code structure itself is simple enough to use and might make sense for certain
    use cases (more in the analysis section below).
  prefs: []
  type: TYPE_NORMAL
- en: LangGraph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LangGraph is one of the longest-standing agent frameworks, first releasing in
    January 2024\. The framework is built to address the acyclic nature of existing
    pipelines and chains by adopting a Pregel graph structure instead. LangGraph makes
    it easier to define loops in your agent by adding the concepts of nodes, edges,
    and conditional edges to traverse a graph. LangGraph is built on top of LangChain,
    and uses the objects and types from that framework.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/08d1c12009b7fdd2a59ea76f527eeee7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: LangGraph Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The LangGraph agent looks similar to the code-based agent on paper, but the
    code behind it is drastically different. LangGraph still uses a “router” technically,
    in that it calls OpenAI with functions and uses the response to continue to a
    new step. However the way the program moves between skills is controlled completely
    differently.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The graph defined here has a node for the initial OpenAI call, called “agent”
    above, and one for the tool handling step, called “tools.” LangGraph has a built-in
    object called ToolNode that takes a list of callable tools and triggers them based
    on a ChatMessage response, before returning to the “agent” node again.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After each call of the “agent” node (put another way: the router in the code-based
    agent), the should_continue edge decides whether to return the response to the
    user or pass on to the ToolNode to handle tool calls.'
  prefs: []
  type: TYPE_NORMAL
- en: Throughout each node, the “state” stores the list of messages and responses
    from OpenAI, similar to the code-based agent’s approach.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges with LangGraph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most of the difficulties with LangGraph in the example stem from the need to
    use Langchain objects for things to flow nicely.
  prefs: []
  type: TYPE_NORMAL
- en: '**Challenge #1: Function Call Validation**'
  prefs: []
  type: TYPE_NORMAL
- en: In order to use the ToolNode object, I had to refactor most of my existing Skill
    code. The ToolNode takes a list of callable functions, which originally made me
    think I could use my existing functions, however things broke down due to my function
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: The skills were defined as classes with a callable member function, meaning
    they had “self” as their first parameter. GPT-4o was smart enough to not include
    the “self” parameter in the generated function call, however LangGraph read this
    as a validation error due to a missing parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'This took hours to figure out, because the error message instead marked the
    third parameter in the function (“args” on the data analysis skill) as the missing
    parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: It is worth mentioning that the error message originated from Pydantic, not
    from LangGraph.
  prefs: []
  type: TYPE_NORMAL
- en: I eventually bit the bullet and redefined my skills as basic methods with Langchain’s
    @tool decorator, and was able to get things working.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Challenge #2: Debugging**'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, debugging in a framework is difficult. This primarily comes down
    to confusing error messages and abstracted concepts that make it harder to view
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: The abstracted concepts primarily show up when trying to debug the messages
    being sent around the agent. LangGraph stores these messages in state[“messages”].
    Some nodes within the graph pull from these messages automatically, which can
    make it difficult to understand the value of messages when they are accessed by
    the node.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/14b7cf88b1c2547c64d82b735e16a194.png)'
  prefs: []
  type: TYPE_IMG
- en: '*A sequential view of the agent’s actions (image by author)*'
  prefs: []
  type: TYPE_NORMAL
- en: LangGraph Benefits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the main benefits of LangGraph is that it’s easy to work with. The graph
    structure code is clean and accessible. Especially if you have complex node logic,
    having a single view of the graph makes it easier to understand how the agent
    is connected together. LangGraph also makes it straightforward to convert an existing
    application built in LangChain.
  prefs: []
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you use everything in the framework, LangGraph works cleanly; if you step
    outside of it, prepare for some debugging headaches.
  prefs: []
  type: TYPE_NORMAL
- en: LlamaIndex Workflows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Workflows is a newer entrant into the agent framework space, premiering earlier
    this summer. Like LangGraph, it aims to make looping agents easier to build. Workflows
    also has a particular focus on running asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: Some elements of Workflows seem to be in direct response to LangGraph, specifically
    its use of events instead of edges and conditional edges. Workflows use steps
    (analogous to nodes in LangGraph) to house logic, and emitted and received events
    to move between steps.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/26b9e664d6cce92214a956f0faf4f485.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The structure above looks similar to the LangGraph structure, save for one addition.
    I added a setup step to the Workflow to prepare the agent context, more on this
    below. Despite the similar structure, there is very different code powering it.
  prefs: []
  type: TYPE_NORMAL
- en: Workflows Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code below defines the Workflow structure. Similar to LangGraph, this is
    where I prepared the state and attached the skills to the LLM object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This is also where I define an extra step, “prepare_agent”. This step creates
    a ChatMessage from the user input and adds it to the workflow memory. Splitting
    this out as a separate step means that we do return to it as the agent loops through
    steps, which avoids repeatedly adding the user message to the memory.
  prefs: []
  type: TYPE_NORMAL
- en: In the LangGraph case, I accomplished the same thing with a run_agent method
    that lived outside the graph. This change is mostly stylistic, however it’s cleaner
    in my opinion to house this logic with the Workflow and graph as we’ve done here.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the Workflow set up, I then defined the routing code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'And the tool call handling code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Both of these look more similar to the code-based agent than the LangGraph agent.
    This is mainly because Workflows keeps the conditional routing logic in the steps
    as opposed to in conditional edges — lines 18–24 were a conditional edge in LangGraph,
    whereas now they are just part of the routing step — and the fact that LangGraph
    has a ToolNode object that does just about everything in the tool_call_handler
    method automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Moving past the routing step, one thing I was very happy to see is that I could
    use my SkillMap and existing skills from my code-based agent with Workflows. These
    required no changes to work with Workflows, which made my life much easier.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges with Workflows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Challenge #1: Sync vs Async**'
  prefs: []
  type: TYPE_NORMAL
- en: While asynchronous execution is preferable for a live agent, debugging a synchronous
    agent is much easier. Workflows is designed to work asynchronously, and trying
    to force synchronous execution was very difficult.
  prefs: []
  type: TYPE_NORMAL
- en: I initially thought I would just be able to remove the “async” method designations
    and switch from “achat_with_tools” to “chat_with_tools”. However, since the underlying
    methods within the Workflow class were also marked as asynchronous, it was necessary
    to redefine those in order to run synchronously. I ended up sticking to an asynchronous
    approach, but this didn’t make debugging more difficult.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86bb92ce7e47d92f16d5fb9bdcadc985.png)'
  prefs: []
  type: TYPE_IMG
- en: '*A sequential view of the agent’s actions (image by author)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Challenge #2: Pydantic Validation Errors**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a repeat of the woes with LangGraph, similar problems emerged around confusing
    Pydantic validation errors on skills. Fortunately, these were easier to address
    this time since Workflows was able to handle member functions just fine. I ultimately
    just ended up having to be more prescriptive in creating LlamaIndex FunctionTool
    objects for my skills:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*Excerpt from AgentFlow.__init__ that builds FunctionTools*'
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of Workflows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I had a much easier time building the Workflows agent than I did the LangGraph
    agent, mainly because Workflows still required me to write routing logic and tool
    handling code myself instead of providing built-in functions. This also meant
    that my Workflow agent looked extremely similar to my code-based agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The biggest difference came in the use of events. I used two custom events
    to move between steps in my agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The emitter-receiver, event-based architecture took the place of directly calling
    some of the methods in my agent, like the tool call handler.
  prefs: []
  type: TYPE_NORMAL
- en: If you have more complex systems with multiple steps that are triggering asynchronously
    and might emit multiple events, this architecture becomes very helpful to manage
    that cleanly.
  prefs: []
  type: TYPE_NORMAL
- en: Other benefits of Workflows include the fact that it is very lightweight and
    doesn’t force much structure on you (aside from the use of certain LlamaIndex
    objects) and that its event-based architecture provides a helpful alternative
    to direct function calling — especially for complex, asynchronous applications.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Looking across the three approaches, each one has its benefits.
  prefs: []
  type: TYPE_NORMAL
- en: The no framework approach is the simplest to implement. Because any abstractions
    are defined by the developer (i.e. SkillMap object in the above example), keeping
    various types and objects straight is easy. The readability and accessibility
    of the code entirely comes down to the individual developer however, and it’s
    easy to see how increasingly complex agents could get messy without some enforced
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: LangGraph provides quite a bit of structure, which makes the agent very clearly
    defined. If a broader team is collaborating on an agent, this structure would
    provide a helpful way of enforcing an architecture. LangGraph also might provide
    a good starting point with agents for those not as familiar with the structure.
    There is a tradeoff, however — since LangGraph does quite a bit for you, it can
    lead to headaches if you don’t fully buy into the framework; the code may be very
    clean, but you may pay for it with more debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Workflows falls somewhere in the middle. The event-based architecture might
    be extremely helpful for some projects, and the fact that less is required in
    terms of using of LlamaIndex types provides greater flexibility for those not
    be fully using the framework across their application.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e4c647265b3453dd773d7ac32c1702b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by author
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, the core question may just come down to “are you already using LlamaIndex
    or LangChain to orchestrate your application?” LangGraph and Workflows are both
    so entwined with their respective underlying frameworks that the additional benefits
    of each agent-specific framework might not cause you to switch on merit alone.
  prefs: []
  type: TYPE_NORMAL
- en: The pure code approach will likely always be an attractive option. If you have
    the rigor to document and enforce any abstractions created, then ensuring nothing
    in an external framework slows you down is easy.
  prefs: []
  type: TYPE_NORMAL
- en: Key Questions To Help In Choosing An Agent Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course, “it depends” is never a satisfying answer. These three questions
    should help you decide which framework to use in your next agent project.
  prefs: []
  type: TYPE_NORMAL
- en: '***Are you already using LlamaIndex or LangChain for significant pieces of
    your project?***'
  prefs: []
  type: TYPE_NORMAL
- en: If yes, explore that option first.
  prefs: []
  type: TYPE_NORMAL
- en: '***Are you familiar with common agent structures, or do you want something
    telling you how you should structure your agent?***'
  prefs: []
  type: TYPE_NORMAL
- en: If you fall into the latter group, try Workflows. If you *really* fall into
    the latter group, try LangGraph.
  prefs: []
  type: TYPE_NORMAL
- en: '***Has your agent been built before?***'
  prefs: []
  type: TYPE_NORMAL
- en: One of the framework benefits is that there are many tutorials and examples
    built with each. There are far fewer examples of pure code agents to build from.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f8250fa7aea13c3785aeb32ecd006a74.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by author
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Picking an agent framework is just one choice among many that will impact outcomes
    in production for generative AI systems. As always, it pays to have robust guardrails
    and [LLM tracing](https://docs.arize.com/phoenix/tracing/llm-traces) in place
    — and to be agile as new agent frameworks, research, and models upend established
    techniques.
  prefs: []
  type: TYPE_NORMAL
