<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Building a Research Agent That Can Write to Google Docs (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Building a Research Agent That Can Write to Google Docs (Part 1)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-research-agent-that-can-write-to-google-docs-part-1-4b49ea05a292?source=collection_archive---------6-----------------------#2024-11-20">https://towardsdatascience.com/building-a-research-agent-that-can-write-to-google-docs-part-1-4b49ea05a292?source=collection_archive---------6-----------------------#2024-11-20</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="fr fs ft fu fv fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/467c2bf3a8c599809df9567803dcb8fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K3ft-8NkUixw6K7isGBWVw.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Dalle-3’s interpretation of “A quirky AI assistant hard at work checking documents”. Image generated by the author.</figcaption></figure><div/><div><h2 id="7989" class="pw-subtitle-paragraph hh gj gk bf b hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw cq dx">A tool that might help with your homework</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hx hy hz ia ib ab"><div><div class="ab ic"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@rmartinshort?source=post_page---byline--4b49ea05a292--------------------------------" rel="noopener follow"><div class="l id ie by if ig"><div class="l ed"><img alt="Robert Martin-Short" class="l ep by dd de cx" src="../Images/e3910071b72a914255b185b850579a5a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*-jfunT2ldyjlLaMX0t8PDA.jpeg"/><div class="ih by l dd de em n ii eo"/></div></div></a></div></div><div class="ij ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--4b49ea05a292--------------------------------" rel="noopener follow"><div class="l ik il by if im"><div class="l ed"><img alt="Towards Data Science" class="l ep by br in cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ih by l br in em n ii eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="io ab q"><div class="ab q ip"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b iq ir bk"><a class="af ag ah ai aj ak al am an ao ap aq ar is" data-testid="authorName" href="https://medium.com/@rmartinshort?source=post_page---byline--4b49ea05a292--------------------------------" rel="noopener follow">Robert Martin-Short</a></p></div></div></div><span class="it iu" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b iq ir dx"><button class="iv iw ah ai aj ak al am an ao ap aq ar ix iy iz" disabled="">Follow</button></p></div></div></span></div></div><div class="l ja"><span class="bf b bg z dx"><div class="ab cn jb jc jd"><div class="je jf ab"><div class="bf b bg z dx ab jg"><span class="jh l ja">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar is ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--4b49ea05a292--------------------------------" rel="noopener follow"><p class="bf b bg z ji jj jk jl jm jn jo jp bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="it iu" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">15 min read</span><div class="jq jr l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 20, 2024</span></div></span></div></span></div></div></div><div class="ab cp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="h k w ea eb q"><div class="kx l"><div class="ab q ky kz"><div class="pw-multi-vote-icon ed jh la lb lc"><div class=""><div class="ld le lf lg lh li lj am lk ll lm lc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ln lo lp lq lr ls lt"><p class="bf b dy z dx"><span class="le">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ld lu lv ab q ee lw lx" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="ly"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q ki kj kk kl km kn ko kp kq kr ks kt ku kv kw"><div class="lz k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al ma an ao ap ix mb mc md" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep me cn"><div class="l ae"><div class="ab cb"><div class="mf mg mh mi mj gb ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al ma an ao ap ix mk ml lx mm mn mo mp mq s mr ms mt mu mv mw mx u my mz na"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al ma an ao ap ix mk ml lx mm mn mo mp mq s mr ms mt mu mv mw mx u my mz na"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al ma an ao ap ix mk ml lx mm mn mo mp mq s mr ms mt mu mv mw mx u my mz na"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div></div><div class="ab cb nb nc nd ne" role="separator"><span class="nf by bm ng nh ni"/><span class="nf by bm ng nh ni"/><span class="nf by bm ng nh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="8f8c" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk"><strong class="nl gl"><em class="of">This article is the first of a two part series where we use LangGraph and Tavily to build a simple research agent, which writes and refines short articles. To keep track of the plans, articles and comments it generates we add the ability to programmatically create and edit Google Docs. In this article we focus on the agent, leaving the docs connection to the second article. You can find all the relevant code</em></strong><a class="af og" href="https://github.com/rmartinshort/research_assist" rel="noopener ugc nofollow" target="_blank"><strong class="nl gl"><em class="of"> here</em></strong></a><strong class="nl gl"><em class="of">.</em></strong></p></div></div></div><div class="ab cb nb nc nd ne" role="separator"><span class="nf by bm ng nh ni"/><span class="nf by bm ng nh ni"/><span class="nf by bm ng nh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="b909" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Large Language Models (LLMs) are quickly finding use in all sorts of applications relevant to analysts and researchers, especially when it comes to the extraction, organization and summarization of text information. The community — both commercial and open source — is also making it increasingly easy to build and scale so-called “agentic” applications, in which the LLM assumes the role of a (hopefully) skilled analyst and makes semi-autonomous decisions. In a chatbot application, for example, if the user asks a complex or multi-step query the LLM might need to design a plan of action, correctly query multiple external tools — perhaps calculators, web searchers, vector databases etc — assemble the results and generate an answer.</p><p id="09f3" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Systems like this are often said to use the <a class="af og" href="https://www.promptingguide.ai/techniques/react" rel="noopener ugc nofollow" target="_blank">ReAct framework</a> of prompt engineering, which stands for “Reasoning-Action”. Basically, the structure and sequence of prompts forces the LLM to answer the question in very methodical fashion, first by articulating a thought (typically a plan of attack), carrying out an action, then making an observation of the result. In agentic systems, this process can continue iteratively until the LLM decides that it’s come to an acceptable answer.</p><p id="1565" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In this series of articles, we’ll use the <a class="af og" href="https://www.langchain.com/langgraph" rel="noopener ugc nofollow" target="_blank">LangGraph</a> library and <a class="af og" href="https://tavily.com/" rel="noopener ugc nofollow" target="_blank">Tavily</a> search tool to build a simple research assistant that demonstrates some of these concepts and might even be useful for those of us looking to generate quick, well written reports about any subject. Our agent will be inspired by the plan -&gt; research -&gt; write -&gt; submit -&gt; review -&gt; revise cycle that happens in peer-reviewed research, and you can take a look at the prompts for these different sections <a class="af og" href="https://github.com/rmartinshort/research_assist/blob/main/research_assist/researcher/prompts.py" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="a227" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To make the system feel more complete, we’ll also add the ability to automatically add the material generated to a Google Doc, which is explored in <a class="af og" rel="noopener" target="_blank" href="/building-a-research-assistant-that-can-write-to-google-docs-part-2-ac9dcacff4ff">part 2</a>. This should be considered as more of an add-on than an integrated component of the agent, but it is interesting in its own right and so could also be read as a stand-alone article.</p><h1 id="5552" class="oh oi gk bf oj ok ol hk om on oo hn op oq or os ot ou ov ow ox oy oz pa pb pc bk">1. What should our research assistant do?</h1><p id="a9ba" class="pw-post-body-paragraph nj nk gk nl b hi pd nn no hl pe nq nr ns pf nu nv nw pg ny nz oa ph oc od oe fj bk">Before looking at how we can build this assistant and what it means for it to be “agentic”, we should think briefly about what we’d like it to do. The goal is to build a system that can plan and write short, informative articles about a given topic, then improve its own work through review and revision.</p><p id="5968" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Why? Mainly this is just an exploration of technology, but the use of LLMs as semi-autonomous researchers is an active field of investigation and is yielding interesting projects such as <a class="af og" href="https://github.com/assafelovic/gpt-researcher" rel="noopener ugc nofollow" target="_blank">GPT-researcher</a>. They have the potential to speed up the work of analysts, students, authors and researchers — though of course if the goal is human learning, there is no substitute for careful reading, note taking and discussion, which AI cannot replace.</p><p id="9d9c" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">LLMs like GPT4, Anthropic Claude Sonnet, Meta Llama 3, Google Gemini Pro etc. can already write great articles out of the box with just a single prompt. However, these LLMs have knowledge cutoffs and so need access to additional tools in order to fetch the latest information, such as news about current events. There are plenty of services — notably tools like Perplexity, ChatGPT (now accessible via chat.com) and Google’s AI overview that already have this ability, but they are geared more towards providing quick summaries than polished research reports.</p><p id="5eca" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Here, we’re making the assumption that multiple iterations of review and revision will improve the quality of an article generated by an LLM. This is certainly how it works in human writing. Our assistant will have the following components, each with its own instruction prompt</p><ul class=""><li id="bbfb" class="nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe pi pj pk bk"><strong class="nl gl">Planner.</strong> Turns a poorly defined task into a structured article plan</li><li id="720c" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Researcher.</strong> Takes the plan and searches the internet for relevant content.</li><li id="dd51" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Writer.</strong> Uses the plan, retrieved content and it own knowledge to write the report</li><li id="5afc" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Reviewer.</strong> Reads the report and offers constructive criticism</li><li id="ca95" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Editor.</strong> Reads the report and the reviewer’s criticism and decides if the report needs to be revised. If so, the report is sent back to the researcher and writer stages.</li></ul><p id="8449" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In our implementation each of these components will be calling the same LLM, namely GPT4o-mini, but in a real application they could just as easily use different, more specialized models.</p><p id="157a" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The output will be a well-written, informative report — preferably with references — that we can programmatically drop into a Google doc for safe keeping. It’s easy to modify the “personality” or our researcher by adapting the prompts. The editor is particularly important, because it’s the gatekeeper for the end of the process. If we make our editor very strict, the system might need to loop through many revisions to get accepted. To what extent will a stricter editor improve the quality of the result? That’s a very interesting question which, as they say, is beyond the scope of the current work!</p><h1 id="52ce" class="oh oi gk bf oj ok ol hk om on oo hn op oq or os ot ou ov ow ox oy oz pa pb pc bk">2. Structure of the agent</h1><p id="7690" class="pw-post-body-paragraph nj nk gk nl b hi pd nn no hl pe nq nr ns pf nu nv nw pg ny nz oa ph oc od oe fj bk">Our research assistant is based heavily on the example described in this <a class="af og" href="https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/" rel="noopener ugc nofollow" target="_blank">excellent short course about LangGraph</a>. LangGraph is an LLM orchestration library that attempts to make it easier for us to design and build reliable agents. For an in-depth comparison of LangGraph and LangChain, I recommend this excellent <a class="af og" rel="noopener" target="_blank" href="/ai-agent-workflows-a-complete-guide-on-whether-to-build-with-langgraph-or-langchain-117025509fa0">article</a>.</p><p id="f9f4" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">What exactly is an agent? It appears that the community has not yet settled on a definition, but at least broadly speaking we might say that an agent is a <a class="af og" href="https://blog.langchain.dev/what-is-an-agent/" rel="noopener ugc nofollow" target="_blank">multi-step system where an LLM is allowed to make meaningful decisions about the outcome</a>. This makes it more complex (and potentially more unpredictable) than a chain, which is just a predefined set of LLM calls one after the other.</p><p id="2907" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In an agent framework, the LLM has some autonomy over how to solve the problem it’s given, perhaps by choosing the appropriate tool to call or deciding when to stop refining a solution once it’s good enough. In that sense the LLM becomes more of the brain of the system, acting more like a human analyst than just an API call. One interesting challenge here is that while agents might be free to make decisions, they are usually embedded within or interact with traditional software systems that require structured inputs and outputs. It’s therefore very important to force the agent to return its answers in the way that these other systems understand, regardless of the decision it makes.</p><p id="f36b" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">For a more in-depth discussion of agents in the context of LangGraph, this <a class="af og" href="https://langchain-ai.github.io/langgraph/concepts/#graphs" rel="noopener ugc nofollow" target="_blank">documentation</a> is very helpful. Our research agent will be quite a simple one (partly because I am still learning this material too!) but hopefully could be a stepping stone towards something more sophisticated.</p><p id="13cd" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In LangGraph we define the logic of our system as a graph, which consists of nodes and edges. Nodes are where LLM calls are made, and edges pass information from one node to the next. Edges can be conditional, meaning that they can direct information to different nodes depending on what decision is made. Information is passed between nodes in a structured format defined by a state.</p><p id="93b2" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Our research assistant has a single stage called <code class="cx pq pr ps pt b">AgentState</code> and it looks like this</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="3ac8" class="qc oi gk pt b bg qd qe l qf qg">class AgentState(TypedDict):<br/>    """<br/>    A dictionary representing the state of the research agent.<br/><br/>    Attributes:<br/>        task (str): The description of the task to be performed.<br/>        plan (str): The research plan generated for the task.<br/>        draft (str): The current draft of the research report.<br/>        critique (str): The critique received for the draft.<br/>        content (List[str]): A list of content gathered during research.<br/>        revision_number (int): The current revision number of the draft.<br/>        max_revisions (int): The maximum number of revisions allowed.<br/>        finalized_state (bool): Indicates whether the report is finalized.<br/>    """<br/><br/>    task: str<br/>    plan: str<br/>    draft: str<br/>    critique: str<br/>    content: List[str]<br/>    editor_comment: str<br/>    revision_number: int<br/>    max_revisions: int<br/>    finalized_state: bool</span></pre><p id="a179" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This is where all the information relevant to our problem gets stored, and can be updated by LLM action inside a node of the graph.</p><p id="a166" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now we can define some nodes. In the code, all the nodes are kept within the <code class="cx pq pr ps pt b">AgentNodes</code> class, which is just a way I found helpful to group them. For example the planner node looks like this</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="315f" class="qc oi gk pt b bg qd qe l qf qg">    def plan_node(self, state: AgentState) -&gt; Dict[str, str]:<br/>        """<br/>        Generate a research plan based on the current state.<br/><br/>        Args:<br/>            state (AgentState): The current state of the research agent.<br/><br/>        Returns:<br/>            Dict[str, str]: A dictionary containing the generated research plan.<br/>        """<br/>        messages = [<br/>            SystemMessage(content=ResearchPlanPrompt.system_template),<br/>            HumanMessage(content=state["task"]),<br/>        ]<br/>        response = self.model.invoke(messages)<br/>        return {"plan": response.content}</span></pre><p id="237c" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Note how it takes in an <code class="cx pq pr ps pt b">AgentState</code> and returns a modification to one of its components, namely the text for the research plan. When this node is run, the plan is updated.</p><p id="d48d" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The code inside the node function uses standard LangChain syntax. <code class="cx pq pr ps pt b">self.model</code> is an instance of <code class="cx pq pr ps pt b">ChatOpenAI</code>, which looks like this</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="59ed" class="qc oi gk pt b bg qd qe l qf qg">model = ChatOpenAI(<br/>    model="gpt-4o-mini", temperature=0, api_key=secrets["OPENAI_API_KEY"]<br/>)</span></pre><p id="6d6b" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The prompt consists of a system message from the <code class="cx pq pr ps pt b">ResearchPlanPrompt</code> dataclass concatenated with the “task” element of the AgentState, which is the research topic provided by the user. The plan prompt looks like this.</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="5947" class="qc oi gk pt b bg qd qe l qf qg">@dataclass<br/>class ResearchPlanPrompt:<br/>    system_template: str = """<br/>    You are an expert writer tasked with creating a high-level outline for a research report.<br/>    Write such an outline for the user-provided topic. Include relevant notes or instructions for each section.<br/>    The style of the research report should be geared towards the educated public. It should be detailed enough to provide<br/>    a good level of understanding of the topic, but not unnecessarily dense. Think of it more like a whitepaper to be consumed <br/>    by a business leader rather than an academic journal article. <br/>    """</span></pre><p id="13a6" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Similar nodes need to be made for the following tasks</p><ul class=""><li id="86d6" class="nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe pi pj pk bk"><strong class="nl gl">Conduct research</strong>. This is where we use an LLM to convert the research task into a series of queries, then use the Tavily search tool to find their answers online and save this under “content” in the AgentStage. This process is discussed in more detail in section 2</li><li id="81bf" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Write the report</strong>. Here we make use of the task name, the research plan, the research content and any previous reviewer comments to actually write the research report. This gets saved under “draft” in the AgentState. Whenever this runs, the <code class="cx pq pr ps pt b">revision_number</code> indicator gets updated.</li><li id="5237" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Review the report.</strong> Call the LLM to critique the research report and save the review under “critique”</li><li id="16e8" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Conduct more research in response to the critique</strong>. This is going to take in the original draft and the review and generate some more queries for Tavily that should help the system address the reviewer comments. Once again, this information is saved under “content”</li><li id="9887" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Make a decision </strong>about whether or not the report satisfies the reviewer’s comments. This is done by the LLM with the guidance of the editor prompt, which instructs it to make a yes/no decision on the article and explain its reasoning.</li><li id="557d" class="nj nk gk nl b hi pl nn no hl pm nq nr ns pn nu nv nw po ny nz oa pp oc od oe pi pj pk bk"><strong class="nl gl">Dummy nodes</strong> for rejecting or accepting the research. Once we get to either of these, we can end the flow. The final research report can then be extracted from the AgentState</li></ul><p id="3660" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We need to make a conditional edge in the graph at the editor node: If the editor says yes, we go to the accepted node. If no, we go back to the review node.</p><p id="9749" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To define this logic, we need to make a function to run inside the conditional edge. I have chosen to put this in an AgentEdges class, but this is not a requirement.</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="ba6e" class="qc oi gk pt b bg qd qe l qf qg"> def should_continue(state: AgentState) -&gt; str:<br/>        """<br/>        Determine whether the research process should continue based on the current state.<br/><br/>        Args:<br/>            state (AgentState): The current state of the research agent.<br/><br/>        Returns:<br/>            str: The next state to transition to ("to_review", "accepted", or "rejected").<br/>        """<br/>        # always send to review if editor hasn't made comments yet<br/>        current_editor_comments = state.get("editor_comment", [])<br/>        if not current_editor_comments:<br/>            return "to_review"<br/><br/>        final_state = state.get("finalized_state", False)<br/>        if final_state:<br/>            return "accepted"<br/>        elif state["revision_number"] &gt; state["max_revisions"]:<br/>            logger.info("Revision number &gt; max allowed revisions")<br/>            return "rejected"<br/>        else:<br/>            return "to_review"</span></pre><p id="0421" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In code, the entire graph setup looks like this</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="1724" class="qc oi gk pt b bg qd qe l qf qg">from research_assist.researcher.AgentComponents import (<br/>    AgentNodes,<br/>    AgentState,<br/>    AgentEdges,<br/>)<br/># this is the predefined end node<br/>from langgraph.graph import END<br/><br/>agent = StateGraph(AgentState)<br/>nodes = AgentNodes(model, searcher)<br/>edges = AgentEdges()<br/><br/>## Nodes<br/>agent.add_node("initial_plan", nodes.plan_node)<br/>agent.add_node("write", nodes.generation_node)<br/>agent.add_node("review", nodes.review_node)<br/>agent.add_node("do_research", nodes.research_plan_node)<br/>agent.add_node("research_revise", nodes.research_critique_node)<br/>agent.add_node("reject", nodes.reject_node)<br/>agent.add_node("accept", nodes.accept_node)<br/>agent.add_node("editor", nodes.editor_node)<br/><br/>## Edges<br/>agent.set_entry_point("initial_plan")<br/>agent.add_edge("initial_plan", "do_research")<br/>agent.add_edge("do_research", "write")<br/>agent.add_edge("write", "editor")<br/><br/>## Conditional edges<br/>agent.add_conditional_edges(<br/>  "editor",<br/>  edges.should_continue,<br/>  {"accepted": "accept", "to_review": "review", "rejected": "reject"},<br/>)<br/>agent.add_edge("review", "research_revise")<br/>agent.add_edge("research_revise", "write")<br/>agent.add_edge("reject", END)<br/>agent.add_edge("accept", END)</span></pre><p id="479f" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Before data can flow through a graph, the graph must be compiled. My understanding from the docs is that just runs some simple checks on the structured of the graph and returns a <code class="cx pq pr ps pt b">CompiledGraph</code> object, which has methods like <code class="cx pq pr ps pt b">stream</code> and <code class="cx pq pr ps pt b">invoke.</code>These allow you to pass inputs to the start node, which is defined using <code class="cx pq pr ps pt b">set_entry_point</code> in the code above.</p><p id="da32" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">When building these graphs, it can be very helpful to visualize all the nodes and edges in a notebook. This can be done with the following command</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="0032" class="qc oi gk pt b bg qd qe l qf qg">from IPython.display import Image<br/><br/>Image(agent.compile().get_graph().draw_png())</span></pre><p id="4bf0" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk"><a class="af og" href="https://langchain-ai.github.io/langgraph/how-tos/visualization/" rel="noopener ugc nofollow" target="_blank">LangGraph offers a few different ways of drawing the graph</a>, depending on what visualization package you have installed. I’m using pygraphviz, which can be installed on an m-series mac using the following command</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="0244" class="qc oi gk pt b bg qd qe l qf qg">brew install graphviz<br/>pip install -U --no-cache-dir  \<br/>        --config-settings="--global-option=build_ext" \<br/>        --config-settings="--global-option=-I$(brew --prefix graphviz)/include/" \<br/>        --config-settings="--global-option=-L$(brew --prefix graphviz)/lib/" \<br/>        pygraphviz</span></pre><figure class="pu pv pw px py fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qh"><img src="../Images/234af656591507969c2639052529c85b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UbEWmRJZyL59E3sSiidqPg.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Visualization of the control flow for our agent. Nodes are where LLM calls occur, while edges indicate the flow of information. Image generated by the author.</figcaption></figure><p id="a903" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">How do we test our agent? The simplest way would just be to call invoke with initial values of some of the components of AgentState (i.e. task, max_revisions and revision number), which enter the graph at the entry point node.</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="4d43" class="qc oi gk pt b bg qd qe l qf qg">graph = agent.compile()<br/>res = graph.invoke(<br/>    {<br/>        "task": "What are the key trends in LLM research and application that you see in 2024",<br/>        "max_revisions": 1,<br/>        "revision_number": 0,<br/>    }<br/>)</span></pre><p id="9020" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">After some time (can be several minutes if the max_revisions is set to be large) this will return a dictionary of the agent state with all the components filled in. I’m using gpt4o-mini for this and the results are very impressive, although the extent to which adding the “review” and “editor” components really help to improve the quality of the article could be debated and we’ll return to that in section 3.</p><p id="812f" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">What if we want more insight into the inputs and outputs of the nodes at each stage of the graph? This is essential for debugging and explainable as the graph grows or if we’re hoping to deploy something like this in production. Thankfully LangGraph has some great tools here, which are covered under the <a class="af og" href="https://langchain-ai.github.io/langgraph/concepts/persistence/" rel="noopener ugc nofollow" target="_blank">persistence</a> and <a class="af og" href="https://langchain-ai.github.io/langgraph/concepts/streaming/" rel="noopener ugc nofollow" target="_blank">streaming</a> sections of its documentation. A minimal implementation looks something like this, where we are using an in memory store to keep track of the updates the come out of each stage of the graph.</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="388f" class="qc oi gk pt b bg qd qe l qf qg">from langgraph.store.memory import InMemoryStore<br/>from langgraph.checkpoint.memory import MemorySaver<br/>import uuid<br/><br/>checkpointer = MemorySaver()<br/>in_memory_store = InMemoryStore()<br/>graph = agent.compile(checkpointer=checkpointer, store=self.in_memory_store)<br/><br/># Invoke the graph<br/>user_id = "1"<br/>config = {"configurable": {"thread_id": "1", "user_id": user_id}}<br/>namespace = (user_id, "memories")<br/>        <br/>for i, update in enumerate(graph.stream(<br/>  {<br/>     "task": task_description,<br/>     "max_revisions": max_revisions,<br/>     "revision_number": 0,<br/>  }, config, stream_mode="updates"<br/>        )):<br/>   # print the data that just got generated <br/>   print(update)<br/>   memory_id = str(uuid.uuid4())<br/>   # store the data that just got generated in memory<br/>   self.in_memory_store.put(namespace, memory_id, {"memory": update})<br/>   results.append(update)</span></pre><p id="7c54" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">More sophisticated applications would access the store from inside the nodes themselves, allowing a chatbot to recall previous conversations with a given user for example. Here we’re just using the memory to save the outputs of each of the nodes, which can then be viewed for debugging purposes. We’ll explore that a bit more in the final section.</p><h1 id="fd2c" class="oh oi gk bf oj ok ol hk om on oo hn op oq or os ot ou ov ow ox oy oz pa pb pc bk"><strong class="al">3. What’s in the “<em class="qi">do_research</em>” node? The power of Tavily search</strong></h1><p id="9851" class="pw-post-body-paragraph nj nk gk nl b hi pd nn no hl pe nq nr ns pf nu nv nw pg ny nz oa ph oc od oe fj bk">Perhaps the most interesting parts of the control flow above are the <code class="cx pq pr ps pt b">do_research</code>and <code class="cx pq pr ps pt b">research_revise</code> nodes. Inside both of these nodes we are using an LLM to generate some web search queries relevant to the task, and then we’re using the <a class="af og" href="https://docs.tavily.com/docs/welcome" rel="noopener ugc nofollow" target="_blank">Tavily</a> API to actually conduct the search. Tavily is a relatively new service that offers a search engine optimized for AI agents. Practically what this means is that the service returns search results as chunks of relevant text from websites, rather than just a list of urls (which would need to be scraped and parsed) as in the case of typical search engine APIs.</p><p id="53f8" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Under the hood, Tavily is likely using web scrapers and LLMs to extract content relevant to the user’s search, but all of that is abstracted away. You can sign up <a class="af og" href="https://app.tavily.com/home" rel="noopener ugc nofollow" target="_blank">here</a> for Tavily’s free “Researcher” plan which gives 1000 free API calls. Unfortunately after that you’d need to pay a monthly fee to keep using it, which is likely only worth it for business use cases.</p><p id="d396" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Lets see an example using the code very similar to what’s going on inside <code class="cx pq pr ps pt b">AgentNodes.research_plan_node</code></p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="15bc" class="qc oi gk pt b bg qd qe l qf qg"><br/>from langchain_core.messages import (<br/>    SystemMessage,<br/>    HumanMessage,<br/>)<br/>from research_assist.researcher.prompts import (<br/>    ResearchPlanPrompt,<br/>)<br/>from langchain_openai import ChatOpenAI<br/>from tavily import TavilyClient<br/><br/>class Queries(BaseModel):<br/>    """<br/>    A model representing a list of search queries.<br/><br/>    Attributes:<br/>        queries (List[str]): A list of search queries to be executed.<br/>    """<br/><br/>    queries: List[str]<br/><br/># set up task<br/>task = """<br/>What are the key trends in LLM reseach and application that you see in 2024<br/>"""<br/><br/># set up LLM and Tavily<br/>model = ChatOpenAI(<br/>    model="gpt-4o-mini", temperature=0, api_key=secrets["OPENAI_API_KEY"]<br/>)<br/>tavily = TavilyClient(api_key=secrets["TAVILY_API_KEY"])<br/><br/># generate some queries relevant to the task<br/>queries = agent.nodes.model.with_structured_output(Queries).invoke(<br/>            [<br/>                SystemMessage(content=ResearchPlanPrompt.system_template),<br/>                HumanMessage(content=task),<br/>            ]<br/>)</span></pre><p id="dadb" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This generates 5 search queries relevant to the task we defined, which look like this</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="824b" class="qc oi gk pt b bg qd qe l qf qg">['key trends in LLM research 2024',<br/> 'LLM applications 2024',<br/> 'latest developments in LLM technology 2024',<br/> 'future of LLMs 2024',<br/> 'LLM research advancements 2024']</span></pre><p id="3ad0" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Next we can call Tavily search on each of these queries</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="6c8b" class="qc oi gk pt b bg qd qe l qf qg">response = tavily.search(query=queries[0], max_results=2)</span></pre><p id="d989" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This provides a nicely formatted result with url, title and text chunk.</p><figure class="pu pv pw px py fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qj"><img src="../Images/d53f7c7858080ce176276d07bcf8a46c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ggfmdmQTEpuZVIOL5bIq5A.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Example results from a Tavily search. Image generated by the author.</figcaption></figure><p id="3b91" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This is a very powerful and easy to use search tool that can give LLM applications access to the web without the need for extra work!</p><p id="de0e" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In our researcher agent, we’re currently only using the content field, which we extract and append to a list which is passed into the AgentState. That information then gets injected into the prompt thats used for the writer node, hence allowing the LLM to have access to it when generating the report.</p><p id="f5ec" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">There is a lot more you can do with Tavily search, but be aware that experimenting with it will quickly burn through your free API calls. In fact, for our report writing task there are many applications where Tavily calls probably aren’t necessary (i.e. the LLM already has sufficient knowledge to write the report), so I would recommend adding an additional conditional edge that allows the system to bypass the <code class="cx pq pr ps pt b">do_research</code> and <code class="cx pq pr ps pt b">research_revise</code> nodes if it determines that a web search is not needed. I will likely update the repo with this change soon.</p><h1 id="4486" class="oh oi gk bf oj ok ol hk om on oo hn op oq or os ot ou ov ow ox oy oz pa pb pc bk"><strong class="al">4. Walk through an example</strong></h1><p id="6d24" class="pw-post-body-paragraph nj nk gk nl b hi pd nn no hl pe nq nr ns pf nu nv nw pg ny nz oa ph oc od oe fj bk">To solidify everything we just learned, let’s walk through an example of the researcher in action, using the same task as above.</p><p id="7eba" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, we import the libraries and set up our LLM and searcher models</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="11d8" class="qc oi gk pt b bg qd qe l qf qg">from research_assist.researcher.Agent import ResearchAgent, load_secrets<br/>from langchain_openai import ChatOpenAI<br/>from tavily import TavilyClient<br/><br/>secrets = load_secrets()<br/>model = ChatOpenAI(<br/>    model="gpt-4o-mini", temperature=0, api_key=secrets["OPENAI_API_KEY"]<br/>)<br/>tavily = TavilyClient(api_key=secrets["TAVILY_API_KEY"])<br/><br/>agent = ResearchAgent(model, tavily)</span></pre><p id="0a6a" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now we can run the agent on a task and give it a maximum number of revisions.</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="3cd3" class="qc oi gk pt b bg qd qe l qf qg">task = """<br/>What are the key trends in LLM reseach and application that you see in 2024<br/>"""<br/>result = agent.run_task(task_description=task,max_revisions=3)</span></pre><p id="ed7f" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now the agent will run its task, which might take about a minute. Logging has been added to show what it’s doing and importantly, the results are being saved to the <code class="cx pq pr ps pt b">in_memory_store</code> , which we saw at the end of section 2.</p><p id="9c1e" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The final report is accessible in a few ways. Its stored in the result list and can be visualized in a notebook like this</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="53e7" class="qc oi gk pt b bg qd qe l qf qg">Markdown(result[-3]['write']['draft'])</span></pre><p id="252f" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Its also stored in the agent’s memory along with all the other outputs. We can access it as follows</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="7d91" class="qc oi gk pt b bg qd qe l qf qg">agent.in_memory_store.search(("1", "memories"))[-3].dict()</span></pre><p id="eb99" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The report itself is about 1300 words long — a bit too much to copy here — but I’ve pasted it into the repo <a class="af og" href="https://github.com/rmartinshort/research_assist/tree/main/research_assist/examples" rel="noopener ugc nofollow" target="_blank">here</a>. We can also take a look at what the editor thought of it after one round of revision</p><pre class="pu pv pw px py pz pt qa bp qb bb bk"><span id="3dea" class="qc oi gk pt b bg qd qe l qf qg">editor_comments = agent.in_memory_store.search(("1", "memories"))[-2].dict()</span></pre><pre class="qk pz pt qa bp qb bb bk"><span id="40a9" class="qc oi gk pt b bg qd qe l qf qg">{'value': {'memory': {'editor': {'editor_comment': <br/>'The report has addressed the critiques by enhancing depth in key sections, <br/>adding clarity, and improving structure with subheadings. <br/>It provides specific examples and discusses ethical considerations, <br/>making it a valuable resource. The revisions are sufficient for publication.',<br/>    'finalized_state': True}}},<br/> 'key': '9005ad06-c8eb-4c6f-bb94-e77f2bc867bc',<br/> 'namespace': ['1', 'memories'],<br/> 'created_at': '2024-11-11T06:09:46.170263+00:00',<br/> 'updated_at': '2024-11-11T06:09:46.170267+00:00'}</span></pre><p id="b99c" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It seems the editor was satisfied!</p><p id="a3f9" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">For debugging purposes, we probably need to read though all the other outputs though. This can be painful to do in a notebook so in the next article we’ll discuss how they can be programmatically dropped into Google Docs. Thanks for making it to the end and <a class="af og" rel="noopener" target="_blank" href="/building-a-research-assistant-that-can-write-to-google-docs-part-2-ac9dcacff4ff">we’ll pick up in part 2</a>!</p><p id="81a6" class="pw-post-body-paragraph nj nk gk nl b hi nm nn no hl np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The author is unaffiliated with any of the tools discussed in this article.</p></div></div></div></div>    
</body>
</html>