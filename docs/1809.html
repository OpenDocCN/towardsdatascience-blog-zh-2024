<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Build a Streaming Agent with Burr, FastAPI, and React</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Build a Streaming Agent with Burr, FastAPI, and React</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-streaming-agent-with-burr-fastapi-and-react-e2459ef527a8?source=collection_archive---------3-----------------------#2024-07-25">https://towardsdatascience.com/how-to-build-a-streaming-agent-with-burr-fastapi-and-react-e2459ef527a8?source=collection_archive---------3-----------------------#2024-07-25</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="bc8b" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">An overview of how to leverage streaming using open source tools applied to building a simple agentic chat bot</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@stefan.krawczyk?source=post_page---byline--e2459ef527a8--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Stefan Krawczyk" class="l ep by dd de cx" src="../Images/150405abaad9590e1dc2589168ed2fa3.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*WguG4w7ZZiDFLAxQQGNoww.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e2459ef527a8--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@stefan.krawczyk?source=post_page---byline--e2459ef527a8--------------------------------" rel="noopener follow">Stefan Krawczyk</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e2459ef527a8--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 25, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mi mj mk ml mm mn mo mp paragraph-image"><div class="ab cn cb mq"><img src="../Images/f76e421b3ba109b434f51c1d43eb0ba0.png" data-original-src="https://miro.medium.com/v2/format:webp/0*aJ_qv-FlFOJig5V4.png"/></div><figcaption class="ms mt mu mo mp mv mw bf b bg z dx">The model of our agentic application. We’ll show how you can build this with streaming so you can create a great user experience. Image by author.</figcaption></figure><p id="030d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In this post we will go over how to build an agentic chatbot that streams responses to the user, leveraging <a class="af nt" href="https://github.com/dagworks-inc/burr" rel="noopener ugc nofollow" target="_blank">Burr</a>’s (I’m an author) streaming capabilities, <a class="af nt" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank">FastAPI’s</a> <a class="af nt" href="https://fastapi.tiangolo.com/advanced/custom-response/?h=streamingresponse#using-streamingresponse-with-file-like-objects" rel="noopener ugc nofollow" target="_blank">StreamingResponse</a>, and server-sent-events (SSEs) queried by <a class="af nt" href="https://react.dev/" rel="noopener ugc nofollow" target="_blank">React</a>. All of these are open source tools. This is aimed at those who want to learn more about streaming in Python and how to add interactivity to their agent/application. While the tools we use will be fairly specific, the lessons should be applicable to a wide range of streaming response implementations.</p><p id="432b" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">First, we’ll talk about why streaming is important. Then we’ll go over the open-source tooling we use. We’ll walk through an example, and point you out to code that you can use to get started, then share more resources and alternate implementations.</p><p id="3192" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">You can follow along with the Burr + FastAPI code <a class="af nt" href="https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi" rel="noopener ugc nofollow" target="_blank">here</a> and the frontend code <a class="af nt" href="https://github.com/DAGWorks-Inc/burr/blob/main/telemetry/ui/src/examples/StreamingChatbot.tsx" rel="noopener ugc nofollow" target="_blank">here</a>. You can also run this example (you’ll need an OPENAI_API_KEY env variable) by running <code class="cx nu nv nw nx b">pip install “burr[start]” &amp;&amp; burr</code>, then navigating to localhost:7241/demos/streaming-chatbot; the browser will open automatically, just click demos/streaming-chatbot on the left. Note this example requires <code class="cx nu nv nw nx b">burr&gt;=0.23.0</code>.</p><h1 id="c92d" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Why Streaming?</h1><p id="8c58" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">While streaming media through the web is a technology from <a class="af nt" href="https://en.wikipedia.org/wiki/Streaming_media#:~:text=Online%20streaming%20was%20initially%20popularised,being%20offered%20since%20the%202010s." rel="noopener ugc nofollow" target="_blank">the 90s</a>, and is now ubiquitous (video games, streaming TV, music, etc…), the recent surge in generative AI applications has seen an interest in serving and rendering streaming text, word by word.</p><p id="8ee3" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">LLMs are a fun technology (perhaps even useful), but relatively slow to run, and users don’t like waiting. Luckily, it is possible to stream the results so that a user sees an LLM’s response as it is being generated. Furthermore, given the generally robotic and stuffy nature of LLMs, streaming can make them appear more interactive, almost as if they’re thinking.</p><p id="df76" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">A proper implementation will allow streaming communication across multiple service boundaries, enabling intermediate proxies to augment/store the streaming data as it is presented to the user.</p><figure class="mi mj mk ml mm mn mo mp paragraph-image"><div role="button" tabindex="0" class="pa pb ed pc bh pd"><div class="mo mp oz"><img src="../Images/9f99df7ca53e3a575dacdc8d977ef642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tT_dNtua0rsCKrLr.png"/></div></div><figcaption class="ms mt mu mo mp mv mw bf b bg z dx">A simple display of a chatbot architecture. Image by author.</figcaption></figure><p id="6c8a" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">While none of this is rocket science, the same tools that make web development easy and largely standardized (OpenAPI / FastAPI / React + friends, etc…) all have varying degrees of support, meaning that you often have multiple choices that are different than what you’re used to. Streaming is often an afterthought in framework design, leading to various limitations that you might not know until you’re halfway through building.</p><p id="873e" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Let’s go over some of the tools we’ll use to implement the stack above, then walk through an example.</p><h1 id="2642" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">The Open Source Tools</h1><p id="62da" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">The tools we’ll leverage to build this are nicely decoupled from each other — you can swap like with like if you want and still apply the same lessons/code.</p><h1 id="2b69" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Burr</h1><p id="47b8" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk"><a class="af nt" href="https://github.com/DAGWorks-Inc/burr/" rel="noopener ugc nofollow" target="_blank">Burr</a> is a lightweight Python library you use to build applications as state machines. You construct your application out of a series of actions (these can be either decorated functions or objects), which declare inputs from state, as well as inputs from the user. These specify custom logic (delegating to any framework), as well as instructions on how to update state. State is immutable, which allows you to inspect it at any given point. Burr handles orchestration, monitoring, persistence, etc…).</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="5903" class="ph nz fq nx b bg pi pj l pk pl">@action(reads=["count"], writes=["count"])<br/>def counter(state: State) -&gt; State:<br/>    return state.update(counter=state.get("count", 0) +1) </span></pre><p id="56e5" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">You run your Burr actions as part of an application — this allows you to string them together with a series of (optionally) conditional transitions from action to action.</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="9dfa" class="ph nz fq nx b bg pi pj l pk pl">from burr.core import ApplicationBuilder, default, expr<br/>app = (<br/>    ApplicationBuilder()<br/>    .with_actions(<br/>        count=count, <br/>        done=done # implementation left out above<br/>    ).with_transitions(<br/>        ("counter", "counter", expr("count &lt; 10")), # Keep counting if the counter is &lt; 10<br/>        ("counter", "done", default) # Otherwise, we're done<br/>    ).with_state(count=0)<br/>    .with_entrypoint("counter") # we have to start somewhere<br/>    .build()<br/>)</span></pre><p id="5bc2" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Burr comes with a user-interface that enables monitoring/telemetry, as well as hooks to persist state/execute arbitrary code during execution.</p><p id="1361" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">You can visualize this as a flow chart, i.e. graph / state machine:</p><figure class="mi mj mk ml mm mn mo mp paragraph-image"><div class="mo mp pm"><img src="../Images/f987bc5eedaa49d7f5a17e860b10a6e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/0*38RRC4qXdwVYpdV-.jpeg"/></div><figcaption class="ms mt mu mo mp mv mw bf b bg z dx">Burr gives you this image for free. Image by author.</figcaption></figure><p id="9090" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">And monitor it using the local telemetry debugger:</p><figure class="mi mj mk ml mm mn mo mp paragraph-image"><div role="button" tabindex="0" class="pa pb ed pc bh pd"><div class="mo mp oz"><img src="../Images/daf833de5eef0cfd6bd0b09cdb576096.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ibuehP2rYJCjCD11.png"/></div></div><figcaption class="ms mt mu mo mp mv mw bf b bg z dx">The OS telemetry UI tells you the state of your application at any given point in time. Image by author.</figcaption></figure><p id="077f" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">While the above example is a simple illustration, Burr is commonly used for Agents (like in this example), RAG applications, and human-in-the-loop AI interfaces. See the repository <a class="af nt" href="https://github.com/DAGWorks-Inc/burr/tree/main/examples" rel="noopener ugc nofollow" target="_blank">examples</a> for a (more exhaustive) set of use-cases. We’ll go over streaming and a few more powerful features a little later.</p><h1 id="0b81" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">FastAPI</h1><p id="bf2e" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk"><a class="af nt" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank">FastAPI</a> is a framework that lets you expose python functions in a REST API. It has a simple interface — you write your functions then decorate them, and run your script — turning it into a server with self-documenting endpoints through <a class="af nt" href="https://www.openapis.org/" rel="noopener ugc nofollow" target="_blank">OpenAPI</a>.</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="ca2e" class="ph nz fq nx b bg pi pj l pk pl">@app.get("/")<br/>def read_root():<br/>    return {"Hello": "World"}<br/><br/><br/>@app.get("/items/{item_id}")<br/>def read_item(item_id: int, q: Union[str, None] = None):<br/>    return {"item_id": item_id, "q": q}</span></pre><p id="a951" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">FastAPI provides a myriad of benefits. It is async native, supplies documentation through OpenAPI, and is easy to deploy on any cloud provider. It is infrastructure agnostic and can generally scale horizontally (so long as consideration into state management is done). See <a class="af nt" href="https://fastapi.tiangolo.com/deployment/cloud/?h=deploy" rel="noopener ugc nofollow" target="_blank">this page</a> for more information.</p><h1 id="3204" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">React</h1><p id="e75b" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">React needs no introduction — it is an extremely popular tool that powers much of the internet. Even recent popular tools (such as next.js/remix) build on top of it. For more reading, see <a class="af nt" href="http://react.dev/" rel="noopener ugc nofollow" target="_blank">react.dev</a>. We will be using React along with <a class="af nt" href="https://www.typescriptlang.org/" rel="noopener ugc nofollow" target="_blank">typescript</a> and <a class="af nt" href="https://tailwindcss.com/" rel="noopener ugc nofollow" target="_blank">tailwind</a>, but you can generally replace with your favorite frontend tools and be able to reuse much of this post.</p><h1 id="320b" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Building a simple Agentic chatbot</h1><p id="b85d" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">Let’s build a simple <em class="pn">agentic</em> chatbot — it will be <em class="pn">agentic</em> as it actually makes two LLM calls:</p><ol class=""><li id="a0b1" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns po pp pq bk">A call to determine the model to query. Our model will have a few “modes” — generate a poem, answer a question, etc…</li><li id="3371" class="mx my fq mz b go pr nb nc gr ps ne nf ng pt ni nj nk pu nm nn no pv nq nr ns po pp pq bk">A call to the actual model (in this case prompt + model combination)</li></ol><p id="1a7e" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">With the OpenAI API this is more of a toy example — their models are impressive jacks of all trades. That said, this pattern of tool delegation shows up in a wide variety of AI systems, and this example can be extrapolated cleanly.</p><h1 id="4a32" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Modeling the Agent in Burr</h1><h2 id="d099" class="pw nz fq bf oa px py pz od qa qb qc og ng qd qe qf nk qg qh qi no qj qk ql qm bk">Modeling as a State Machine</h2><p id="81f7" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">To leverage Burr, we model our agentic application as a state machine. The basic flow of logic looks like this:</p><figure class="mi mj mk ml mm mn mo mp paragraph-image"><div class="ab cn cb mq"><img src="../Images/f76e421b3ba109b434f51c1d43eb0ba0.png" data-original-src="https://miro.medium.com/v2/format:webp/0*aJ_qv-FlFOJig5V4.png"/></div><figcaption class="ms mt mu mo mp mv mw bf b bg z dx">We start at a user prompt input (top). Then we check for safety, and if it’s not safe, we go the specific response for “unsafe”. Otherwise we decide on the mode, and switch based on the value of the state field <em class="qn">mode</em>. Each of these returns a streaming response. Once they are done streaming, it circles back to prompt and waits for another user input… Image by author.</figcaption></figure><p id="e874" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">To model this with Burr, we will first create corresponding actions, using the <a class="af nt" href="https://burr.dagworks.io/concepts/streaming-actions/" rel="noopener ugc nofollow" target="_blank">streaming API</a>. Then we’ll tie them together as an <a class="af nt" href="https://burr.dagworks.io/concepts/state-machine/" rel="noopener ugc nofollow" target="_blank">application</a>.</p><h2 id="7933" class="pw nz fq bf oa px py pz od qa qb qc og ng qd qe qf nk qg qh qi no qj qk ql qm bk">Streaming Actions</h2><p id="7be0" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">In Burr, actions can leverage both a synchronous and asynchronous API. In this case we’ll be using <a class="af nt" href="https://docs.python.org/3/library/asyncio.html" rel="noopener ugc nofollow" target="_blank">async</a>. Streaming functions in Burr can also be mixed and match with non-streaming actions, but to simplify we will implement everything as streaming. So, whether it’s streaming from OpenAPI (which has its own <a class="af nt" href="https://www.asyncapi.com/tools/generator" rel="noopener ugc nofollow" target="_blank">async streaming interface</a>), or returning a fixed <em class="pn">Sorry I cannot answer this question</em> response, it will still be implemented as a generator.</p><p id="0c01" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For those who are unfamiliar, <a class="af nt" href="https://wiki.python.org/moin/Generators" rel="noopener ugc nofollow" target="_blank">generators</a> are a Python construct that enables efficient, lazy evaluation over a sequence of values. They are created by the <code class="cx nu nv nw nx b">yield </code>keyword, which cedes control from the function back to the caller, until the next item is needed. <a class="af nt" href="https://peps.python.org/pep-0525/" rel="noopener ugc nofollow" target="_blank">Async generators</a> function similarly, except they also cede control of the event loop on yield. Read more about <a class="af nt" href="https://wiki.python.org/moin/Generators" rel="noopener ugc nofollow" target="_blank">synchronous generators</a> and <a class="af nt" href="https://peps.python.org/pep-0525/" rel="noopener ugc nofollow" target="_blank">asynchronous generators</a>.</p><p id="4e7f" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Streaming actions in Burr are implemented as a generator that yields tuples, consisting of:</p><ol class=""><li id="4142" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns po pp pq bk">The intermediate result (in this case, delta token in the message)</li><li id="9a1f" class="mx my fq mz b go pr nb nc gr ps ne nf ng pt ni nj nk pu nm nn no pv nq nr ns po pp pq bk">The final state update, if it is complete, or None if it is still generating</li></ol><p id="a2fb" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Thus the final yield will indicate that the stream is complete, and output a final result for storage/debugging later. A basic response that proxies to OpenAI with some custom prompt manipulation looks like this:</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="0c4c" class="ph nz fq nx b bg pi pj l pk pl">@streaming_action(reads=["prompt", "chat_history", "mode"], writes=["response"])<br/>async def chat_response(<br/>    state: State, prepend_prompt: str, model: str = "gpt-3.5-turbo"<br/>) -&gt; AsyncGenerator[Tuple[dict, Optional[State]], None]:<br/>    """A simple proxy.<br/>    <br/>    This massages the chat history to pass the context to OpenAI, <br/>    streams the result back, and finally yields the completed result <br/>    with the state update.<br/>    """<br/>    client = _get_openai_client()<br/>    # code skipped that prepends a custom prompt and formats chat history<br/>    chat_history_for_openai = _format_chat_history(<br/>        state["chat_history"], <br/>        prepend_final_promprt=prepend_prompt)<br/>    result = await client.chat.completions.create(<br/>        model=model, messages=chat_history_api_format, stream=True<br/>    )<br/>    buffer = []<br/>    <br/>    async for chunk in result:<br/>        chunk_str = chunk.choices[0].delta.content<br/>        if chunk_str is None:<br/>            continue<br/>        buffer.append(chunk_str)<br/>        yield {"delta": chunk_str}, None<br/>        <br/>    result = {<br/>        "response": {"content": "".join(buffer), "type": "text", "role": "assistant"},<br/>    }<br/>    yield result, state.update(**result).append(chat_history=result["response"])</span></pre><p id="e045" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In the example, we also have a few other streaming actions — these will represent the “terminal” actions — actions that will trigger the workflow to pause when the state machine completes them.</p><h2 id="151b" class="pw nz fq bf oa px py pz od qa qb qc og ng qd qe qf nk qg qh qi no qj qk ql qm bk">Building an Application</h2><p id="02b7" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">To build the application, we’re first going to build a graph. We’ll be using the <a class="af nt" href="https://burr.dagworks.io/concepts/state-machine/#graph-api" rel="noopener ugc nofollow" target="_blank">Graph API</a> for Burr, allowing us to decouple the shape of the graph from other application concerns. In a web service the graph API is a very clean way to express state machine logic. You can build it once, globally, then reuse it per individual application instances. The graph builder looks like this — note it refers to the function <em class="pn">chat_response</em> from above:</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="1bda" class="ph nz fq nx b bg pi pj l pk pl"># Constructing a graph from actions (labeled by kwargs) and <br/># transitions (conditional or default).<br/>graph = (<br/>    GraphBuilder()<br/>    .with_actions(<br/>        prompt=process_prompt,<br/>        check_safety=check_safety,<br/>        decide_mode=choose_mode,<br/>        generate_code=chat_response.bind(<br/>            prepend_prompt="Please respond with *only* code and no other text" <br/>                "(at all) to the following",<br/>        ),<br/>        # more left out for brevity<br/>    )<br/>    .with_transitions(<br/>        ("prompt", "check_safety", default),<br/>        ("check_safety", "decide_mode", when(safe=True)),<br/>        ("check_safety", "unsafe_response", default),<br/>        ("decide_mode", "generate_code", when(mode="generate_code")),<br/>        # more left out for brevity<br/>    )<br/>    .build()<br/>)</span></pre><p id="81bc" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Finally, we can add this together in an Application — which exposes the right execution methods for the server to interact with:</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="8065" class="ph nz fq nx b bg pi pj l pk pl"># Here we couple more application concerns (telemetry, tracking, etc…).<br/>app = ApplicationBuilder()<br/>  .with_entrypoint("prompt")<br/>  .with_state(chat_history=[])<br/>  .with_graph(graph)<br/>  .with_tracker(project="demo_chatbot_streaming")<br/>  .with_identifiers(app_id=app_id)<br/>  .build()<br/>)</span></pre><p id="8883" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">When we want to run it, we can call out to <a class="af nt" href="https://burr.dagworks.io/concepts/streaming-actions/#usage" rel="noopener ugc nofollow" target="_blank">astream_results</a>. This takes in a set of <em class="pn">halting conditions</em>, and returns an <a class="af nt" href="https://burr.dagworks.io/reference/actions/#burr.core.action.AsyncStreamingResultContainer" rel="noopener ugc nofollow" target="_blank">AsyncStreamingResultContainer</a><code class="cx nu nv nw nx b"> </code>(a generator that caches the result and ensures Burr tracking is called), as well as the action that triggered the halt.</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="9688" class="ph nz fq nx b bg pi pj l pk pl"># Running the application as you would to test, <br/># (in a jupyter notebook, for instance).<br/>action, streaming_container = await app.astream_result(<br/>    halt_after=["generate_code", "unsafe_response", ...], # terminal actions<br/>    inputs={<br/>      "prompt": "Please generate a limerick about Alexander Hamilton and Aaron Burr"<br/>    }<br/>)<br/><br/>async for item in streaming_container:<br/>    print(item['delta'], end="")</span></pre><h1 id="6d25" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Exposing in a Web Server</h1><p id="e3bd" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">Now that we have the Burr application, we’ll want to integrate with FastAPI’s <a class="af nt" href="https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse" rel="noopener ugc nofollow" target="_blank">streaming response API</a> using server-sent-events (SSEs). While we won’t dig too much into SSEs, the TL;DR is that they function as a one way (server → client) version of web-sockets. You can read more in the links at the end.</p><p id="a6d8" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">To use these in FastAPI, we declare an endpoint as a function that returns a StreamingResponse — a class that wraps a generator. The standard is to provide streaming responses in a special shape, “data: &lt;contents&gt; \n\n”. Read more about why <a class="af nt" href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events" rel="noopener ugc nofollow" target="_blank">here</a>. While this is largely meant for the <a class="af nt" href="https://developer.mozilla.org/en-US/docs/Web/API/EventSource" rel="noopener ugc nofollow" target="_blank">EventSource</a> API (which we will be bypassing in favor of fetch and <a class="af nt" href="https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/getReader" rel="noopener ugc nofollow" target="_blank">getReader()</a>), we will keep this format for standards (and so that anyone using the EventSource API can reuse this code).</p><p id="d12a" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">We have separately implemented <code class="cx nu nv nw nx b">_get_application</code>, a utility function to get/load an application by ID.</p><p id="1e04" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The function will be a POST endpoint, as we are adding data to the server, although could easily be a PUT as well.</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="ada0" class="ph nz fq nx b bg pi pj l pk pl">@app.post("/response/{project_id}/{app_id}", response_class=StreamingResponse)<br/>async def chat_response(project_id: str, app_id: str, prompt: PromptInput) -&gt; StreamingResponse:<br/>    """A simple API that wraps our Burr application."""<br/>    burr_app = _get_application(project_id, app_id)<br/>    chat_history = burr_app.state.get("chat_history", [])<br/>    action, streaming_container = await burr_app.astream_result(<br/>        halt_after=chat_application.TERMINAL_ACTIONS, inputs=dict(prompt=prompt.prompt)<br/>    )<br/><br/>    async def sse_generator():<br/>        yield f"data: {json.dumps({'type': 'chat_history', 'value': chat_history})}\n\n"<br/><br/>        async for item in streaming_container:<br/>            yield f"data: {json.dumps({'type': 'delta', 'value': item['delta']})} \n\n"<br/><br/>    return StreamingResponse(sse_generator())</span></pre><p id="af99" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Note that we define a generator inside the function that wraps the Burr result and turns it into SSE-friendly outputs. This allows us to impose some structure on the result, which we will use on the frontend. Unfortunately, we will have to parse it on our own, as fastAPI does not enable strict typing of a StreamingResponse.</p><p id="e19a" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Furthermore, we actually yield the entire state at the beginning, prior to execution. While this is not strictly necessary (we can also have a separate API for chat history), it will make rendering easier.</p><p id="259d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">To test this you can use the requests library <a class="af nt" href="https://requests.readthedocs.io/en/latest/user/advanced/#body-content-workflow" rel="noopener ugc nofollow" target="_blank">Response.iter_lines</a> API.</p><h1 id="415c" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Building a UI</h1><p id="5886" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">Now that we have a server, our state machine, and our LLM lined up, let’s make it look nice! This is where it all ties together. While you can download and play with the entirety of the code in <a class="af nt" href="https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi" rel="noopener ugc nofollow" target="_blank">the example</a>, we will be focusing in on the function that queries the API when you click “send”.</p><figure class="mi mj mk ml mm mn mo mp paragraph-image"><div role="button" tabindex="0" class="pa pb ed pc bh pd"><div class="mo mp qo"><img src="../Images/a31aeb84cbc323ece54bc65f05a68bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dd_CuBfD5CNzNKtL0PuZSQ.png"/></div></div><figcaption class="ms mt mu mo mp mv mw bf b bg z dx">This is what the UI looks like. You can run this via the packaged Telemetry UI that Burr comes with. Image by author.</figcaption></figure><p id="cbec" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">First, let’s query our API using fetch (obviously adjust this to your endpoint, in this case we’re proxying all /api calls to another server…):</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="3d60" class="ph nz fq nx b bg pi pj l pk pl">// A simple fetch call with getReader()<br/>const response = await fetch(<br/>      `/api/v0/streaming_chatbot/response/${props.projectId}/${props.appId}`,<br/>      {<br/>        method: 'POST',<br/>        headers: { 'Content-Type': 'application/json' },<br/>        body: JSON.stringify({ prompt: currentPrompt })<br/>      }<br/>    );<br/>const reader = response.body?.getReader();</span></pre><p id="cd1f" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This looks like a plain old API call, leveraging the typescript <a class="af nt" href="https://blog.logrocket.com/async-await-typescript/" rel="noopener ugc nofollow" target="_blank">async API</a>. This extracts a <em class="pn">reader</em> object, which will help us stream results as they come in.</p><p id="f48b" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Let’s define some data types to leverage the structure we created above. In addition to the <code class="cx nu nv nw nx b">ChatItem</code> data types (which was generated using <a class="af nt" href="https://www.npmjs.com/package/openapi-typescript-codegen" rel="noopener ugc nofollow" target="_blank">openapi-typescript-codegen</a>), we’ll also define two classes, which correspond to the data types returned by the server.</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="a272" class="ph nz fq nx b bg pi pj l pk pl">// Datatypes on the frontend. <br/>// The contract is loose, as nothing in the framework encodes it<br/>type Event = {<br/>  type: 'delta' | 'chat_history';<br/>};<br/><br/>type ChatMessageEvent = Event &amp; {<br/>  value: string;<br/>};<br/><br/>type ChatHistoryEvent = Event &amp; {<br/>  value: ChatItem[];<br/>};</span></pre><p id="ed7b" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Next, we’ll iterate through the reader and parse. This assumes the following state variables in react:</p><ul class=""><li id="8796" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns qp pp pq bk"><code class="cx nu nv nw nx b">setCurrentResponse</code>/<code class="cx nu nv nw nx b">currentResponse</code></li><li id="01a1" class="mx my fq mz b go pr nb nc gr ps ne nf ng pt ni nj nk pu nm nn no pv nq nr ns qp pp pq bk"><code class="cx nu nv nw nx b">setDisplayedChatHistory</code></li></ul><p id="bdb6" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">We read through, splitting on “data:”, then looping through splits and parsing/reacting depending on the event type.</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="bcc2" class="ph nz fq nx b bg pi pj l pk pl">// Loop through, continually getting the stream. <br/>// For each item, parse it as our desired datatype and react appropriately.<br/>while (true) {<br/>    const result = await reader.read();<br/>    if (result.done) {<br/>      break;<br/>    }<br/>    const message = decoder.decode(result.value, { stream: true });<br/>    message<br/>      .split('data: ')<br/>      .slice(1)<br/>      .forEach((item) =&gt; {<br/>        const event: Event = JSON.parse(item);<br/>        if (event.type === 'chat_history') {<br/>          const chatMessageEvent = event as ChatHistoryEvent;<br/>          setDisplayedChatHistory(chatMessageEvent.value);<br/>        }<br/>        if (event.type === 'delta') {<br/>          const chatMessageEvent = event as ChatMessageEvent;<br/>          chatResponse += chatMessageEvent.value;<br/>          setCurrentResponse(chatResponse);<br/>        }<br/>      });<br/>}</span></pre><p id="0bcd" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">We’ve left out some cleanup/error handling code (to clear, initialize the state variables before/after requests, handle failure, etc…) — you can see more in the example.</p><p id="0f2d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Finally, we can render it (note this refers to additional state variables that are set/unset outside of the code above, as well as a ChatMessage react component that simply displays a chat message with the appropriate icon.</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="bba9" class="ph nz fq nx b bg pi pj l pk pl">&lt;!-- More to illustrates the example --&gt;<br/>&lt;div className="flex-1 overflow-y-auto p-4 hide-scrollbar" id={VIEW_END_ID}&gt;<br/>  {displayedChatHistory.map((message, i) =&gt; (<br/>    &lt;ChatMessage<br/>      message={message}<br/>      key={i}<br/>    /&gt;<br/>  ))}<br/>  {isChatWaiting &amp;&amp; (<br/>    &lt;ChatMessage<br/>      message={{<br/>        role: ChatItem.role.USER,<br/>        content: currentPrompt,<br/>        type: ChatItem.type.TEXT<br/>      }}<br/>    /&gt;<br/>  )}<br/>  {isChatWaiting &amp;&amp; (<br/>    &lt;ChatMessage<br/>      message={{<br/>        content: currentResponse,<br/>        type: ChatItem.type.TEXT,<br/>        role: ChatItem.role.ASSISTANT<br/>      }}<br/>    /&gt;<br/>  )}<br/>&lt;/div&gt;<br/>&lt;!-- Note: We've left out the isChatWaiting and currentPrompt state fields above, <br/> see StreamingChatbot.tsx for the full implementation. --&gt; </span></pre><p id="849d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">We finally have our whole app! For all the <a class="af nt" href="https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi" rel="noopener ugc nofollow" target="_blank">code click here</a>.</p><h1 id="cea7" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Alternate SSE Tooling</h1><p id="6b93" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">Note that what we presented above is just one approach to streaming with FastAPI/react/Burr. There are a host of other tools you can use, including:</p><ul class=""><li id="134c" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns qp pp pq bk">The <a class="af nt" href="https://developer.mozilla.org/en-US/docs/Web/API/EventSource" rel="noopener ugc nofollow" target="_blank">EventSource</a> API — standard but limited to get/ requests</li><li id="845b" class="mx my fq mz b go pr nb nc gr ps ne nf ng pt ni nj nk pu nm nn no pv nq nr ns qp pp pq bk">The <a class="af nt" href="https://github.com/Azure/fetch-event-source" rel="noopener ugc nofollow" target="_blank">FetchEventSource</a> API (appears unmaintained, but well built)</li></ul><p id="e2a2" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">As well as a host of other blog posts (that are awesome! I read these to get started). These will give you a better sense of architecture as well.</p><ul class=""><li id="459d" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns qp pp pq bk"><a class="af nt" href="https://medium.com/@hxu296/serving-openai-stream-with-fastapi-and-consuming-with-react-js-part-1-8d482eb89702" rel="noopener">Stream OpenAI with FastAPI and Consuming it with React.js</a></li><li id="3139" class="mx my fq mz b go pr nb nc gr ps ne nf ng pt ni nj nk pu nm nn no pv nq nr ns qp pp pq bk"><a class="af nt" href="https://www.vidavolta.io/streaming-with-fastapi/" rel="noopener ugc nofollow" target="_blank">Streaming with FastAPI</a></li></ul><h1 id="75e3" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Wrapping Up</h1><p id="5261" class="pw-post-body-paragraph mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns fj bk">In this post we covered a lot — we went over Burr, FastAPI, and React, talked about how to build a streaming <em class="pn">agentic </em>chatbot using the OpenAI API, built out the entire stack, and streamed data all the way through! While you may not use every one of the technologies, the individual pieces should be able to work on their own.</p><p id="0b0f" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">To download and play with this example, you can run:</p><pre class="mi mj mk ml mm pe nx pf bp pg bb bk"><span id="8743" class="ph nz fq nx b bg pi pj l pk pl">pip install "burr[start]"<br/>burr # will open up in a new window</span></pre><p id="b4bb" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Note you’ll need an <a class="af nt" href="http://platform.openai.com/" rel="noopener ugc nofollow" target="_blank">API key from OpenAI</a> for this specific demo. You will find the Burr + FastAPI code <a class="af nt" href="https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/streaming-fastapi" rel="noopener ugc nofollow" target="_blank">here</a> and the frontend code <a class="af nt" href="https://github.com/DAGWorks-Inc/hamilton/tree/main/telemetry/ui/src/examples/StreamingChatbot.tsx" rel="noopener ugc nofollow" target="_blank">here</a>.</p><h1 id="02bf" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Additional Resources</h1><ul class=""><li id="4b43" class="mx my fq mz b go ou nb nc gr ov ne nf ng ow ni nj nk ox nm nn no oy nq nr ns qp pp pq bk"><a class="af nt" href="http://github.com/dagworks-inc/burr" rel="noopener ugc nofollow" target="_blank">Github repository for Burr</a> (give us a star if you like what you see!)</li><li id="4a68" class="mx my fq mz b go pr nb nc gr ps ne nf ng pt ni nj nk pu nm nn no pv nq nr ns qp pp pq bk"><a class="af nt" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank">FastAPI guide</a></li><li id="e82c" class="mx my fq mz b go pr nb nc gr ps ne nf ng pt ni nj nk pu nm nn no pv nq nr ns qp pp pq bk"><a class="af nt" href="https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi" rel="noopener ugc nofollow" target="_blank">Example + README</a></li></ul></div></div></div></div>    
</body>
</html>