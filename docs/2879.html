<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Use Structured Generation for LLM-as-a-Judge Evaluations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Use Structured Generation for LLM-as-a-Judge Evaluations</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-structured-generation-for-llm-as-a-judge-evaluations-c6018cdab8be?source=collection_archive---------10-----------------------#2024-11-27">https://towardsdatascience.com/how-to-use-structured-generation-for-llm-as-a-judge-evaluations-c6018cdab8be?source=collection_archive---------10-----------------------#2024-11-27</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="f52a" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Structured generation is fundamental to building complex, multi-step reasoning agents in LLM evaluations — especially for open source models</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@calebkaiser?source=post_page---byline--c6018cdab8be--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Caleb Kaiser" class="l ep by dd de cx" src="../Images/c33ef43df24242501cb9e797e8d67a6c.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/2*skgRuq75u5nms8oFeU7s8w.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--c6018cdab8be--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@calebkaiser?source=post_page---byline--c6018cdab8be--------------------------------" rel="noopener follow">Caleb Kaiser</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--c6018cdab8be--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">20 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 27, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/f8849a88a2dfb9c66defaadbb3f70dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OVt7vjLxGE6GsMkPbFsFFA.jpeg"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Source: <a class="af nb" href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0" rel="noopener ugc nofollow" target="_blank">Generated with SDXL 1.0</a></figcaption></figure><p id="1bb5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">Disclosure: I am a maintainer of </em><a class="af nb" href="https://github.com/comet-ml/opik" rel="noopener ugc nofollow" target="_blank"><em class="ny">Opik</em></a><em class="ny">, one of the open source projects used later in this article.</em></p><p id="9c41" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For the past few months, I’ve been working on LLM-based evaluations (“LLM-as-a-Judge” metrics) for language models. The results have so far been extremely encouraging, particularly for evaluations like hallucination detection or content moderation, which are hard to quantify with heuristic methods.</p><p id="d5c6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Engineering LLM-based metrics, however, has been surprisingly challenging. Evaluations and unit tests, especially those with more complex logic, require you to know the structure of your data. And with LLMs and their probabilistic outputs, it’s difficult to reliably output specific formats and structures. Some hosted model providers now offer <code class="cx nz oa ob oc b">structured outputs</code> modes, but these still come with limitations, and if you're using open source or local models, those modes won't do you much good.</p><p id="ae90" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The solution to this problem is to use <strong class="ne fr">structured generation</strong>. Beyond its ability to make LLM-based evaluations more reliable, it also unlocks an entirely new category of complex, powerful multi-stage evaluations.</p><p id="58ba" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this piece, I want to introduce structured generation and some of the big ideas behind it, before diving into specific examples of hallucination detection with an LLM judge. All of the code samples below can be run from within this <a class="af nb" href="https://colab.research.google.com/drive/1-lQn0qvJMN1BBuDjRuCzySA7gLhpcdBo#scrollTo=8QOySg8J5AcT" rel="noopener ugc nofollow" target="_blank">Colab notebook</a>, so feel free to run the samples as you follow along.</p><h1 id="f2b8" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">A Brief Introduction to Structured Generation with Context-Free Grammars</h1><p id="b86a" class="pw-post-body-paragraph nc nd fq ne b go oz ng nh gr pa nj nk nl pb nn no np pc nr ns nt pd nv nw nx fj bk">Structured generation is a subfield of machine learning focused on guiding the outputs of generative models by constraining the outputs to fit some particular schema. As an example, instead of fine-tuning a model to output valid JSON, you might constrain a more generalized model’s output to only match valid JSON schemas.</p><p id="46b8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can constrain the outputs of a model through different strategies, but the most common is to interfere directly in the sampling phase, using some external schema to prevent “incorrect” tokens from being sampled.</p><p id="351a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">At this point, structured generation has become a fairly common feature in LLM servers. vLLM, NVIDIA NIM, llama.cpp, and Ollama all support it. If you’re not working with a model server, libraries like <a class="af nb" href="https://github.com/dottxt-ai/outlines" rel="noopener ugc nofollow" target="_blank">Outlines</a> make it trivial to implement for any model. OpenAI also provides a “Structured Output” mode, which similarly allows you to specify a response schema from their API.</p><p id="d715" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">But, I find it helps me develop my intuition for a concept to try a simple implementation from scratch, and so that’s what we’re going to do here.</p><p id="02ad" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There are two main components to structured generation:</p><ul class=""><li id="55f3" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pe pf pg bk">Defining a schema</li><li id="c557" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">Parsing the output</li></ul><p id="5c11" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For the schema, I’m going to use a context-free grammar (CFG). If you’re unfamiliar, a grammar is a schema for parsing a language. Loosely, it defines what is and isn’t considered “valid” in a language. If you’re in the mood for an <em class="ny">excellent</em> rabbit hole, context-free languages are a part of Chomsky’s hierarchy of languages. The amazing Kay Lack has <a class="af nb" href="https://www.youtube.com/watch?v=ENKT0Z3gldE" rel="noopener ugc nofollow" target="_blank">a fantastic introductory video to grammars and parsing here</a>, if you’re interested in learning more.</p><p id="adf1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The most popular library for parsing and constructing CFGs is Lark. In the below code, I’ve written out a simple JSON grammar using the library:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="323c" class="pp oe fq oc b bg pq pr l ps pt">from lark import Lark<br/><br/>grammar = r"""<br/>?start: value<br/><br/>?value: object<br/>       | array<br/>       | ESCAPED_STRING<br/>       | SIGNED_NUMBER      -&gt; number<br/>       | "true"             -&gt; true<br/>       | "false"            -&gt; false<br/>       | "null"             -&gt; null<br/><br/>array  : "[" [value ("," value)*] ["]"]<br/>object : "{" [pair ("," pair)*] ["}"]<br/>pair   : ESCAPED_STRING ":" value<br/><br/>%import common.ESCAPED_STRING<br/>%import common.SIGNED_NUMBER<br/>%import common.WS_INLINE<br/>%ignore WS_INLINE<br/>"""<br/><br/>parser = Lark(grammar, start="start", parser="lalr", debug=True)</span></pre><p id="e6ab" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If you’re not familiar with CFGs or Lark, the above might seem a little intimidating, but it’s actually pretty straightforward. The <code class="cx nz oa ob oc b">?start</code> line indicates that we begin with a <code class="cx nz oa ob oc b">value</code>. We then define a <code class="cx nz oa ob oc b">value</code> to be either an object, an array, an escaped string, a signed number, a boolean, or a null value. The <code class="cx nz oa ob oc b">-&gt;</code> symbols indicate that we map these string values to literal values. We then further specify what we mean by <code class="cx nz oa ob oc b">array</code> , <code class="cx nz oa ob oc b">object</code>, and <code class="cx nz oa ob oc b">pair</code>, before finally instructing our parser to ignore inline whitespace. Try to think of it as if we are constantly "expanding" each high level concept, like a <code class="cx nz oa ob oc b">start</code> or a <code class="cx nz oa ob oc b">value</code>, into composite parts, until we reach such a low level of abstraction that we can no longer expand. In the parlance of grammars, these "too low level to be expanded" symbols are called "terminals."</p><p id="b30e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">One immediate issue you’ll run into with this above code is that it only determines if a string is valid or invalid JSON. Since we’re using a language model and generating one token at a time, we’re going to have a lot of intermediary strings that are technically invalid. There are more elegant ways of handling this, but for the sake of speed, I’m just going to define a simple function to check if we’re in the middle of generating a string or not:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="8281" class="pp oe fq oc b bg pq pr l ps pt">def is_incomplete_string(input_string):<br/>    quote_count = input_string.count('"')<br/>    if quote_count % 2 != 0:<br/>        return True<br/>    return False</span></pre><p id="e7f9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">With all of this defined, let’s run a little test to see if our parser can accurately differentiate between valid, invalid, and incomplete JSON strings:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="f0b8" class="pp oe fq oc b bg pq pr l ps pt">from lark import UnexpectedCharacters, UnexpectedToken<br/><br/># We will use this method later in constraining our model output<br/>def try_and_recover(json_string):<br/>    try:<br/>        parser.parse(json_string)<br/>        return {"status": "valid", "message": "The JSON is valid."}<br/>    except UnexpectedToken as e:<br/>        return {"status": "incomplete", "message": f"Incomplete JSON. Error: {str(e)}"}<br/>    except UnexpectedCharacters as e:<br/>        if is_incomplete_string(json_string):<br/>            return {"status": "incomplete", "message": "Incomplete string detected."}<br/>        return {"status": "invalid", "message": f"Invalid JSON. Error: {str(e)}"}<br/>    except Exception as e:<br/>        return {"status": "invalid", "message": f"Unknown error. JSON is invalid. Error: {str(e)}"}<br/><br/># Test cases<br/>test_cases = [<br/>    '{"key": "value", "key2": ',  # Incomplete JSON<br/>    '[1, 2, 3',                   # Incomplete JSON<br/>    '{"key": "value"}',           # Complete JSON<br/>    'true',                       # Valid JSON<br/>    '{"key": true, "nested": {',  # Incomplete JSON<br/>    '{"answer": "Paris',          # Incomplete JSON<br/>    'invalid syntax'              # Invalid JSON<br/>]<br/><br/># Test and display results<br/>results = []<br/>for test in test_cases:<br/>    result = try_and_recover(test)<br/>    results.append({"input": test, "result": result})<br/><br/>for test in results:<br/>  print(test)</span></pre><pre class="pu pm oc pn bp po bb bk"><span id="1a0c" class="pp oe fq oc b bg pq pr l ps pt">{'input': '{"key": "value", "key2": ', 'result': {'status': 'incomplete', 'message': "..."}}<br/>{'input': '[1, 2, 3', 'result': {'status': 'valid', 'message': '...'}}<br/>{'input': '{"key": "value"}', 'result': {'status': 'valid', 'message': '...'}}<br/>{'input': 'true', 'result': {'status': 'valid', 'message': '...'}}<br/>{'input': '{"key": true, "nested": {', 'result': {'status': 'valid', 'message': '...'}}<br/>{'input': '{"answer": "Paris', 'result': {'status': 'incomplete', 'message': '...'}}<br/>{'input': 'invalid syntax', 'result': {'status': 'invalid', 'message': "..."}}</span></pre><p id="2036" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And it works!</p><p id="2f07" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As a final test, let’s use this <code class="cx nz oa ob oc b">try_and_recover()</code> function to guide our decoding process with a relatively smaller model. In the below code, we'll use an instruction-tuned Qwen 2.5 model with 3 billion parameters, and we'll ask it a simple question. First, let's initialize the model and tokenizer:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="0a98" class="pp oe fq oc b bg pq pr l ps pt">from transformers import AutoModelForCausalLM, AutoTokenizer<br/>model_name = "Qwen/Qwen2.5-3B-Instruct"<br/><br/>tokenizer = AutoTokenizer.from_pretrained(model_name)<br/>model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")</span></pre><p id="5b47" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, we want to define a function to recursively sample from the model, using our <code class="cx nz oa ob oc b">try_and_recover()</code> function to constrain the outputs. Below, I've defined the function, which works by recursively sampling the top 20 most likely next tokens, and selecting the first one which satisfies a valid or incomplete JSON string:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="92cc" class="pp oe fq oc b bg pq pr l ps pt">import torch<br/><br/>def sample_with_guidance(initial_text):<br/>    """<br/>    Generates a structured response from the model, guided by a validation function.<br/>    <br/>    Args:<br/>        initial_text (str): The initial input text to the model.<br/>    <br/>    Returns:<br/>        str: The structured response generated by the model.<br/>    """<br/>    response = ""  # Accumulate the response string here<br/>    next_token = None  # Placeholder for the next token<br/><br/>    while next_token != tokenizer.eos_token:  # Continue until the end-of-sequence token is generated<br/>        # Encode the current input (initial_text + response) for the model<br/>        input_ids = tokenizer.encode(initial_text + response, return_tensors="pt").to(device)<br/>        <br/>        with torch.no_grad():  # Disable gradients for inference<br/>            outputs = model(input_ids)<br/>            <br/>            # Get the top 20 most likely next tokens<br/>            top_tokens = torch.topk(outputs.logits[0, -1, :], 20, dim=-1).indices<br/>            candidate_tokens = tokenizer.batch_decode(top_tokens)<br/>        <br/>        for token in candidate_tokens:<br/>            # Check if the token is the end-of-sequence token<br/>            if token == tokenizer.eos_token:<br/>                # Validate the current response to decide if we should finish<br/>                validation_result = try_and_recover(response)<br/>                if validation_result['status'] == 'valid':  # Finish if the response is valid<br/>                    next_token = token<br/>                    break<br/>                else:<br/>                    continue  # Skip to the next token if invalid<br/>            <br/>            # Simulate appending the token to the response<br/>            extended_response = response + token<br/>            <br/>            # Validate the extended response<br/>            validation_result = try_and_recover(extended_response)<br/>            if validation_result['status'] in {'valid', 'incomplete'}:<br/>                # Update the response and set the token as the next token<br/>                response = extended_response<br/>                next_token = token<br/>                print(response)  # Just to see our intermediate outputs<br/>                break<br/><br/>    return response</span></pre><p id="1dc1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This isn’t the most performant or robust approach, but it works well enough for our purposes. If you want a better look at more optimal approaches, you can see how <a class="af nb" href="https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md" rel="noopener ugc nofollow" target="_blank">llama.cpp implements structured generation</a>, or how a library like <a class="af nb" href="https://github.com/dottxt-ai/outlines" rel="noopener ugc nofollow" target="_blank">Outlines handles things</a>.</p><p id="f12a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">With the following code, we can test the performance of this structured generation function:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="22bc" class="pp oe fq oc b bg pq pr l ps pt">import json<br/><br/>messages = [<br/>    {<br/>     "role": "user", <br/>     "content": "What is the capital of France? Please only answer using the following JSON schema: { \\"answer\\": str }."<br/>     }<br/>]<br/><br/># Format the text for our particular model<br/>input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)<br/><br/>output = sample_with_guidance(input_text)<br/><br/>print("Parsed JSON Object:")<br/>print(json.loads(output))</span></pre><pre class="pu pm oc pn bp po bb bk"><span id="00d9" class="pp oe fq oc b bg pq pr l ps pt">{<br/>{ "<br/>{ "answer<br/>{ "answer":<br/>{ "answer": "<br/>{ "answer": "Paris<br/>{ "answer": "Paris"<br/>{ "answer": "Paris" }<br/><br/>Parsed JSON Object:<br/>{ "answer": "Paris" }</span></pre><p id="b83e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This particular approach will obviously add some computational overhead to your code, but some of the more optimized implementations are actually capable of structuring the output of a model with minimal latency impact. Below is a side-by-side comparison of unstructured generation versus structured generation using llama.cpp’s grammar-structured generation feature:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pv"><img src="../Images/ef64ac9c814a3975332ad0bd4f4f6ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qQvlyiT4DPbbRrjA.gif"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Source: <a class="af nb" href="https://blog.dottxt.co/how-fast-cfg.html" rel="noopener ugc nofollow" target="_blank">How Fast Can Grammar-Structured Generation Be?</a></figcaption></figure><p id="6330" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This comparison was recorded by Brandon Willard from .txt (the company behind Outlines), as part of <a class="af nb" href="https://blog.dottxt.co/how-fast-cfg.html" rel="noopener ugc nofollow" target="_blank">his fantastic article on latency in structured generation</a>. I’d highly recommend giving it a read, if you’re interested in diving deeper into the field.</p><p id="3ead" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Alright, with that bit of introduction out of the way, let’s look at applying structured generation to an LLM-as-a-judge metric, like hallucination.</p><h1 id="871c" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">How to detect hallucinations with structured generation</h1><p id="c6c0" class="pw-post-body-paragraph nc nd fq ne b go oz ng nh gr pa nj nk nl pb nn no np pc nr ns nt pd nv nw nx fj bk">Hallucination detection is one of the “classic” applications of LLM-based evaluation. Traditional heuristic methods struggle with the subtlety of hallucination-in no small part due to the fact that there is no universally agreed upon definition of “hallucination.” For the purposes of this article, we’re going to use a definition from a <a class="af nb" href="https://arxiv.org/html/2403.16527v1" rel="noopener ugc nofollow" target="_blank">recent paper out of the University of Illinois Champagne-Urbana</a>, which I find to be descriptive and usable:</p><p id="6e43" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">A hallucination is a generated output from a model that conflicts with constraints or deviates from desired behavior in actual deployment, or is completely irrelevant to the task at hand, but could be deemed syntactically plausible under the circumstances.</em></p><p id="35fa" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In other words, a hallucination is an output that seems plausible. It is grammatically correct, it makes reference to its surrounding context, and it seems to fit the “flow” of the task. It also, however, contradicts some basic instruction of the task. This could mean drawing incorrect conclusions, citing nonexistent data, or completely ignoring the actual instructions of the task.</p><p id="426f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Obviously, encoding a discrete system of rules to parse outputs for something as ambiguous as hallucinations is a challenge. LLMs, however, are very well suited towards this kind of complex task.</p><p id="cfea" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Using an LLM to perform hallucination analysis isn’t too difficult to setup. All we need to do is prompt the model to analyze the output text for hallucinations. In <a class="af nb" href="https://github.com/comet-ml/opik" rel="noopener ugc nofollow" target="_blank">Opik’s built-in Hallucination() metric</a>, we use the following prompt:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="ce6a" class="pp oe fq oc b bg pq pr l ps pt">context_hallucination_template = """You are an expert judge tasked with evaluating the faithfulness of an AI-generated answer to the given context. Analyze the provided INPUT, CONTEXT, and OUTPUT to determine if the OUTPUT contains any hallucinations or unfaithful information.<br/><br/>Guidelines:<br/>1. The OUTPUT must not introduce new information beyond what's provided in the CONTEXT.<br/>2. The OUTPUT must not contradict any information given in the CONTEXT.<br/>2. The OUTPUT should not contradict well-established facts or general knowledge.<br/>3. Ignore the INPUT when evaluating faithfulness; it's provided for context only.<br/>4. Consider partial hallucinations where some information is correct but other parts are not.<br/>5. Pay close attention to the subject of statements. Ensure that attributes, actions, or dates are correctly associated with the right entities (e.g., a person vs. a TV show they star in).<br/>6. Be vigilant for subtle misattributions or conflations of information, even if the date or other details are correct.<br/>7. Check that the OUTPUT doesn't oversimplify or generalize information in a way that changes its meaning or accuracy.<br/><br/>Analyze the text thoroughly and assign a hallucination score between 0 and 1, where:<br/>- 0.0: The OUTPUT is entirely faithful to the CONTEXT<br/>- 1.0: The OUTPUT is entirely unfaithful to the CONTEXT<br/><br/>INPUT (for context only, not to be used for faithfulness evaluation):<br/>{input}<br/><br/>CONTEXT:<br/>{context}<br/><br/>OUTPUT:<br/>{output}<br/><br/>Provide your verdict in JSON format:<br/>{{<br/>    "score": &lt;your score between 0.0 and 1.0&gt;,<br/>    "reason": [<br/>        &lt;list your reasoning as bullet points&gt;<br/>    ]<br/>}}"""</span></pre><p id="d6a2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The difficult part, however, is performing this analysis programatically. In a real world setting, we’ll want to automatically parse the output of our model and collect the hallucination scores, either as part of our model evaluation or as part of our inference pipeline. Doing this will require us to write code that acts on the model outputs, and if the LLM responds with incorrectly formatted output, the evaluation will break.</p><p id="0d19" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This is a problem even for state of the art foundation models, but it is greatly exaggerated when working with smaller language models. Their outputs are probabilistic, and no matter how thorough you are in your prompt, there is no guarantee that they will always respond with the correct structure.</p><p id="7611" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">Unless</em>, of course, you use structured generation.</p><p id="d4b4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s run through a simple example using Outlines and Opik. First, we want to initialize our model using Outlines. In this example, we’ll be using the 0.5 billion parameter version of Qwen2.5. While this model is impressive for its size, and small enough for us to run quickly in a Colab notebook, you will likely want to use a larger model for more accurate results.</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="9496" class="pp oe fq oc b bg pq pr l ps pt">import outlines<br/><br/>model_kwargs = {<br/>    "device_map": "auto"<br/>}<br/><br/>model = outlines.models.transformers("Qwen/Qwen2.5-0.5B-Instruct", model_kwargs=model_kwargs)</span></pre><p id="43d6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">When your model finishes downloading, you can then create a <code class="cx nz oa ob oc b">generator</code>. In Outlines, a <code class="cx nz oa ob oc b">generator</code> is an inference pipeline that combines an output schema with a model. In the below code, we'll define a schema in Pydantic and initialize our generator:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="fa23" class="pp oe fq oc b bg pq pr l ps pt">import pydantic<br/>from typing import List<br/><br/>class HallucinationResponse(pydantic.BaseModel):<br/>    score: int<br/>    reason: List[str]<br/><br/>generator = outlines.generate.json(model, HallucinationResponse)</span></pre><p id="984a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, if we pass a string into the generator, it will output a properly formatted object.</p><p id="c6d0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, let’s setup our Hallucination metric in Opik. It’s pretty straightforward to create a metric using Opik’s baseMetric class:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="e376" class="pp oe fq oc b bg pq pr l ps pt">from typing import Optional, List, Any<br/>from opik.evaluation.metrics import base_metric<br/><br/>class HallucinationWithOutlines(base_metric.BaseMetric):<br/>    """<br/>    A metric that evaluates whether an LLM's output contains hallucinations based on given input and context.<br/>    """<br/><br/>    def __init__(<br/>        self,<br/>        name: str = "hallucination_metric",<br/>    ):<br/>        super().__init__(name=name)<br/><br/>    def score(<br/>        self,<br/>        input: str,<br/>        output: str,<br/>        context: Optional[List[str]] = None,<br/>        **ignored_kwargs: Any,<br/>    ) -&gt; HallucinationResponse:<br/>        """<br/>        Calculate the hallucination score for the given input, output, and optional context field.<br/><br/>        Args:<br/>            input: The original input/question.<br/>            output: The LLM's output to evaluate.<br/>            context: A list of context strings. If not provided, the presence of hallucinations will be evaluated based on the output only.<br/>            **ignored_kwargs: Additional keyword arguments that are ignored.<br/><br/>        Returns:<br/>            HallucinationResponse: A HallucinationResponse object with a score of 1.0 if hallucination<br/>                is detected, 0.0 otherwise, along with the reason for the verdict.<br/>        """<br/>        llm_query = context_hallucination_template.format(input=input, output=output, context=context)<br/>        <br/>        with torch.no_grad():<br/>            return generator(llm_query)</span></pre><p id="1f6c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">All we really do in the above is generate our prompt using the previously defined template string, and then pass it into our generator.</p><p id="78cb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, let’s try out our metric on an actual hallucination dataset, to get a sense of how it works. We’ll use a split from the HaluEval dataset, which is freely available via HuggingFace and permissively licensed, and we’ll upload it as an Opik Dataset for our experiments. We’ll use a little extra logic to make sure the dataset is balanced between hallucinated and non-hallucinated samples:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="1fc4" class="pp oe fq oc b bg pq pr l ps pt">import opik<br/>import pandas as pd<br/><br/>client = opik.Opik()<br/><br/># Create dataset<br/><br/>dataset = client.get_or_create_dataset(<br/>    name="HaluEval-qa-samples Balanced", <br/>    description="HaluEval-qa-samples dataset"<br/>)<br/><br/># Insert items into dataset<br/>df = pd.read_parquet(<br/>    "hf://datasets/pminervini/HaluEval/qa_samples/data-00000-of-00001.parquet"<br/>)<br/><br/>n_per_class = 100  # 100 each to get 200 total<br/>df_balanced = pd.concat([<br/>    df[df['hallucination'] == 'yes'].sample(n=n_per_class, random_state=42),<br/>    df[df['hallucination'] == 'no'].sample(n=n_per_class, random_state=42)<br/>])<br/>df = df_balanced<br/><br/>dataset_records = [<br/>    {<br/>        "input": x["question"],<br/>        "context": x['knowledge'],<br/>        "output": x["answer"],<br/>        "hallucination_label": x["hallucination"],<br/>    }<br/>    for x in df.to_dict(orient="records")<br/>]<br/><br/>dataset.insert(dataset_records)</span></pre><p id="a81a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And now, we simply define an evaluation task using our HallucinationWithOutlines() metric, and run it against our dataset:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="253d" class="pp oe fq oc b bg pq pr l ps pt">from opik.evaluation import evaluate<br/>from opik.evaluation.metrics import Equals<br/>from typing import Dict<br/><br/># Define the evaluation task<br/>def evaluation_task(x: Dict):<br/>    metric = HallucinationWithOutlines()<br/>    try:<br/>        metric_score = metric.score(<br/>            input=x["input"], context=x["context"], output=x["output"]<br/>        )<br/>        hallucination_score = metric_score.score<br/>        hallucination_reason = metric_score.reason<br/>    except Exception as e:<br/>        print(e)<br/>        hallucination_score = None<br/>        hallucination_reason = str(e)<br/><br/>    return {<br/>        "output": "yes" if hallucination_score == 1 else "no",<br/>        "hallucination_reason": hallucination_reason,<br/>        "reference": x["hallucination_label"],<br/>    }<br/><br/># Define the scoring metric<br/>check_hallucinated_metric = Equals(name="Correct hallucination score")<br/><br/>res = evaluate(<br/>    dataset=dataset,<br/>    task=evaluation_task,<br/>    scoring_metrics=[check_hallucinated_metric],<br/>)</span></pre><pre class="pu pm oc pn bp po bb bk"><span id="e04c" class="pp oe fq oc b bg pq pr l ps pt">Evaluation: 100%|██████████| 200/200 [09:34&lt;00:00,  2.87s/it]<br/>╭─   HaluEval-qa-samples Balanced (200 samples)  ─╮<br/>│                                                 │<br/>│ Total time:        00:09:35                     │<br/>│ Number of samples: 200                          │<br/>│                                                 │<br/>│ Correct hallucination score: 0.4600 (avg)       │<br/>│                                                 │<br/>╰─────────────────────────────────────────────────╯<br/>Uploading results to Opik ... <br/>View the results in your Opik dashboard.</span></pre><p id="30a4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And that’s all it takes! Notice that none of our samples failed because of improperly structured outputs. Let’s try running this same evaluation, but without structured generation. To achieve this, we can switch our generator type:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="1e2f" class="pp oe fq oc b bg pq pr l ps pt">generator = outlines.generate.text(model)</span></pre><p id="85d7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And modify our metric to parse JSON from the model output:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="c643" class="pp oe fq oc b bg pq pr l ps pt">from typing import Optional, List, Any<br/>from opik.evaluation.metrics import base_metric<br/>import json<br/><br/>class HallucinationUnstructured(base_metric.BaseMetric):<br/>    """<br/>    A metric that evaluates whether an LLM's output contains hallucinations based on given input and context.<br/>    """<br/><br/>    def __init__(<br/>        self,<br/>        name: str = "hallucination_metric",<br/>    ):<br/>        super().__init__(name=name)<br/><br/>    def score(<br/>        self,<br/>        input: str,<br/>        output: str,<br/>        context: Optional[List[str]] = None,<br/>        **ignored_kwargs: Any,<br/>    ) -&gt; HallucinationResponse:<br/>        """<br/>        Calculate the hallucination score for the given input, output, and optional context field.<br/><br/>        Args:<br/>            input: The original input/question.<br/>            output: The LLM's output to evaluate.<br/>            context: A list of context strings. If not provided, the presence of hallucinations will be evaluated based on the output only.<br/>            **ignored_kwargs: Additional keyword arguments that are ignored.<br/><br/>        Returns:<br/>            HallucinationResponse: A HallucinationResponse object with a score of 1.0 if hallucination<br/>                is detected, 0.0 otherwise, along with the reason for the verdict.<br/>        """<br/>        llm_query = context_hallucination_template.format(input=input, output=output, context=context)<br/>        <br/>        with torch.no_grad():<br/>            return json.loads(generator(llm_query)) # Parse JSON string from response</span></pre><p id="2287" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Keeping the rest of the code the same and running this now results in:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="f78a" class="pp oe fq oc b bg pq pr l ps pt">Evaluation:   0%|          | 0/200 [00:00&lt;?, ?it/s]Unterminated string starting at: line 5 column 9 (char 47)<br/>Evaluation:   2%|▏         | 1/200 [00:56&lt;46:15, 56.63s/it]Expecting value: line 1 column 2 (char 1)<br/>Expecting value: line 1 column 2 (char 1)<br/>Evaluation:   6%|▌         | 3/200 [00:57&lt;10:09, 12.96s/it]Unterminated string starting at: line 4 column 9 (char 45)<br/>Expecting value: line 1 column 2 (char 1)<br/>Evaluation:  12%|█▏        | 6/200 [00:57&lt;03:01,  4.12s/it]Unterminated string starting at: line 4 column 9 (char 45)</span></pre><p id="fd1d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Nearly every string fails to parse correctly. The inference time is also increased dramatically because of the variable length of responses, whereas the structured output helps keep the responses terse.</p><p id="1d7e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Without structured generation, it just isn’t feasible to run this kind of evaluation, especially with a model this small. As an experiment, try running this same code with a bigger model and see how the average accuracy score improves.</p><h1 id="a33e" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Can we build more complex LLM judges with structured generation?</h1><p id="8389" class="pw-post-body-paragraph nc nd fq ne b go oz ng nh gr pa nj nk nl pb nn no np pc nr ns nt pd nv nw nx fj bk">The above example of hallucination detection is pretty straightforward. The real value that structured generation brings to LLM judges, however, is that it enables us to build more complex, multi-turn evaluations.</p><p id="fd29" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To give an extreme example of what a multi-step evaluation might look like, one recent paper found success in LLM evals by constructing multiple “personas” for different LLM agents, and having the <a class="af nb" href="https://arxiv.org/html/2405.20267v4" rel="noopener ugc nofollow" target="_blank">agents debate in an actual courtroom structure</a>:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj pw"><img src="../Images/dde936a55ce3335b4578f945199af6f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*wb4LO_DhjxtByRuX.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><a class="af nb" href="https://arxiv.org/html/2405.20267v4" rel="noopener ugc nofollow" target="_blank">Source: Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions</a></figcaption></figure><p id="4dea" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Forcing different agents to advocate for different positions and examine each other’s arguments, all while having yet another agent act as a “judge” to emit a final decision, significantly increased the accuracy of evaluations.</p><p id="5e4f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In order for such a system to work, the handoffs between different agents must go smoothly. If an agent needs to pick between 5 possible actions, we need to be 100% sure that the model will only output one of those 5 valid actions. With structured generation, we can achieve that level of reliability.</p><p id="9de8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s try a worked example, extending our hallucination metric from earlier. We’ll try the following improvement:</p><ul class=""><li id="d01b" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pe pf pg bk">On first pass, the model will generate 3 candidate hallucinations, with reasoning for each.</li><li id="96c0" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">For each candidate, the model will evaluate them individually and assess if they are a hallucination, with expanded reasoning.</li><li id="e4ce" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">If the model finds any candidate to be a hallucination, it will return 1.0 for the entire sample.</li></ul><p id="a8b6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By giving the model the ability to generate longer chains of context, we give it space for more “intermediary computation,” and hopefully, a more accurate final output.</p><p id="b404" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First, let’s define a series of prompts for this task:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="957f" class="pp oe fq oc b bg pq pr l ps pt">generate_candidates_prompt = """<br/>You are an expert judge tasked with evaluating the faithfulness of an AI-generated answer to a given context. Your goal is to determine if the provided output contains any hallucinations or unfaithful information when compared to the given context.<br/><br/>Here are the key elements you'll be working with:<br/><br/>1. &lt;context&gt;{context}&lt;/context&gt;<br/>   This is the factual information against which you must evaluate the output. All judgments of faithfulness must be based solely on this context.<br/><br/>2. &lt;output&gt;{output}&lt;/output&gt;<br/>   This is the AI-generated answer that you need to evaluate for faithfulness.<br/><br/>3. &lt;input&gt;{input}&lt;/input&gt;<br/>   This is the original question or prompt. It's provided for context only and should not be used in your faithfulness evaluation.<br/><br/>Evaluation Process:<br/>1. Carefully read the CONTEXT and OUTPUT.<br/>2. Analyze the OUTPUT for any discrepancies or additions when compared to the CONTEXT.<br/>3. Consider the following aspects:<br/>   - Does the OUTPUT introduce any new information not present in the CONTEXT?<br/>   - Does the OUTPUT contradict any information given in the CONTEXT?<br/>   - Does the OUTPUT contradict well-established facts or general knowledge?<br/>   - Are there any partial hallucinations where some information is correct but other parts are not?<br/>   - Is the subject of statements correct? Ensure that attributes, actions, or dates are correctly associated with the right entities.<br/>   - Are there any subtle misattributions or conflations of information, even if dates or other details are correct?<br/>   - Does the OUTPUT oversimplify or generalize information in a way that changes its meaning or accuracy?<br/><br/>4. Based on your analysis, create a list of 3 statements in the OUTPUT which are potentially hallucinations or unfaithful. For each potentially hallucinated or unfaithful statement from the OUTPUT, explain why you think it violates any of the aspects from step 3.<br/><br/>5. Return your list of statements and associated reasons in the following structured format:<br/><br/>{{<br/>  "potential_hallucinations": [<br/>    {{<br/>      "output_statement": string,<br/>      "reasoning": string,<br/>    }},<br/>  ]<br/>}}<br/><br/>Here is an example output structure (do not use these specific values, this is just to illustrate the format):<br/><br/>{{<br/>  "potential_hallucinations": [<br/>    {{<br/>      "output_statement": "The company was founded in 1995",<br/>      "reasoning": "There is no mention of a founding date in the CONTEXT. The OUTPUT introduces new information not present in the CONTEXT.<br/>    }},<br/>    {{<br/>      "output_statement": "The product costs $49.99.",<br/>      "reasoning": "The CONTEXT lists the flagship product price at $39.99. The OUTPUT directly contradicts the price given in the CONTEXT."<br/>    }},<br/>    {{<br/>      "output_statement": "The flagship product was their most expensive item.",<br/>      "reasoning": "The CONTEXT lists mentions another product which is more expensive than the flagship product. The OUTPUT directly contradicts information given in the CONTEXT."<br/>    }}<br/>  ]<br/>}}<br/><br/>Now, please proceed with your analysis and evaluation of the provided INPUT, CONTEXT, and OUTPUT.<br/>"""<br/><br/>evaluate_candidate_prompt = """<br/>Please examine the following potential hallucination you detected in the OUTPUT:<br/><br/>{candidate}<br/><br/>You explained your reasons for flagging the statement like so:<br/><br/>{reason}<br/><br/>As a reminder, the CONTEXT you are evaluating the statement against is:<br/><br/>{context}<br/><br/>Based on the above, could you answer "yes" to any of the following questions?<br/>  - Does the OUTPUT introduce any new information not present in the CONTEXT?<br/>  - Does the OUTPUT contradict any information given in the CONTEXT?<br/>  - Does the OUTPUT contradict well-established facts or general knowledge?<br/>  - Are there any partial hallucinations where some information is correct but other parts are not?<br/>  - Is the subject of statements correct? Ensure that attributes, actions, or dates are correctly associated with the right entities.<br/>  - Are there any subtle misattributions or conflations of information, even if dates or other details are correct?<br/>  - Does the OUTPUT oversimplify or generalize information in a way that changes its meaning or accuracy?<br/><br/>Please score the potentially hallucinated statement using the following scale:<br/><br/>  - 1.0 if you answered "yes" to any of the previous questions, and you believe the statement is hallucinated or unfaithful to the CONTEXT.<br/>  - 0.0 if you answered "no" to all of the previous questions, and after further reflection, you believe the statement is not hallucinated or unfaithful to the CONTEXT.<br/><br/>Before responding, please structure your response with the following format<br/><br/>{{<br/>  "score": float,<br/>  "reason": string<br/><br/>}}<br/><br/>Here is an example output structure (do not use these specific values, this is just to illustrate the format):<br/><br/>{{<br/>  "score": 1.0,<br/>  "reason": "The CONTEXT and OUTPUT list different prices for the same product. This leads me to answer 'yes' to the question, 'Does the OUTPUT contradict any information given in the CONTEXT?'"<br/>}}<br/><br/>Now, please proceed with your analysis and evaluation.<br/><br/>"""<br/><br/></span></pre><p id="a5cb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And now, we can define some Pydantic models for our different model outputs:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="97f2" class="pp oe fq oc b bg pq pr l ps pt"># Generated by generate_candidates_prompt<br/>class PotentialHallucination(pydantic.BaseModel):<br/>    output_statement: str<br/>    reasoning: str<br/><br/>class HallucinationCandidates(pydantic.BaseModel):<br/>    potential_hallucinations: List[PotentialHallucination]<br/><br/># Generated by evaluate_candidate_prompt<br/>class HallucinationScore(pydantic.BaseModel):<br/>    score: float<br/>    reason: str</span></pre><p id="258e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">With all of this, we can put together two generators, one for generating candidate hallucinations, and one for scoring individual candidates:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="f012" class="pp oe fq oc b bg pq pr l ps pt">import outlines<br/><br/>model_kwargs = {<br/>    "device_map": "auto"<br/>}<br/><br/>model = outlines.models.transformers("Qwen/Qwen2.5-0.5B-Instruct", model_kwargs=model_kwargs)<br/><br/>candidate_generator = outlines.generate.json(model, HallucinationCandidates)<br/>generator = outlines.generate.json(model, HallucinationScore)</span></pre><p id="2a3a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Finally, we can construct an Opik metric. We’ll keep the code for this simple:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="6627" class="pp oe fq oc b bg pq pr l ps pt">class HallucinationMultistep(base_metric.BaseMetric):<br/>    """<br/>    A metric that evaluates whether an LLM's output contains hallucinations using a multi-step appraoch.<br/>    """<br/><br/>    def __init__(<br/>        self,<br/>        name: str = "hallucination_metric",<br/>    ):<br/>        super().__init__(name=name)<br/><br/>    def score(<br/>        self,<br/>        input: str,<br/>        output: str,<br/>        context: Optional[List[str]] = None,<br/>        **ignored_kwargs: Any,<br/>    ) -&gt; HallucinationScore:<br/>     # Generate candidates<br/>        candidates_query = generate_candidates_prompt.format(input=input, output=output, context=context)<br/>        output = candidate_generator(candidates_query)<br/>        <br/>        # Initialize to zero, in case the model simply finds no candidates for hallucination<br/>        score = HallucinationScore(score=0.0, reason="Found no candidates for hallucination")<br/><br/>        for candidate in output.potential_hallucinations:<br/>          followup_query = evaluate_candidate_prompt.format(candidate=candidate.output_statement, reason=candidate.reasoning, context=context)<br/>          new_score = generator(followup_query)<br/>          score = new_score<br/>          if new_score.score &gt; 0.0:<br/>           # Early return if we find a hallucination<br/>            return new_score<br/><br/>        return score</span></pre><p id="466c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">All we do here is generate the first prompt, which should produce several hallucination candidates when fed to the candidate generator. Then, we pass each candidate (formatted with the candidate evaluation prompt) into the candidate evaluation generator.</p><p id="b3ff" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If we run it using the same code as before, with slight modifications to use the new metric:</p><pre class="ml mm mn mo mp pm oc pn bp po bb bk"><span id="4802" class="pp oe fq oc b bg pq pr l ps pt"># Define the evaluation task<br/>def evaluation_task(x: Dict):<br/>  # Use new metric<br/>    metric = HallucinationMultistep()<br/>    try:<br/>        metric_score = metric.score(<br/>            input=x["input"], context=x["context"], output=x["output"]<br/>        )<br/>        hallucination_score = metric_score.score<br/>        hallucination_reason = metric_score.reason<br/>    except Exception as e:<br/>        print(e)<br/>        hallucination_score = None<br/>        hallucination_reason = str(e)<br/><br/>    return {<br/>        "output": "yes" if hallucination_score == 1 else "no",<br/>        "hallucination_reason": hallucination_reason,<br/>        "reference": x["hallucination_label"],<br/>    }<br/><br/># Define the scoring metric<br/>check_hallucinated_metric = Equals(name="Correct hallucination score")<br/><br/>res = evaluate(<br/>    dataset=dataset,<br/>    task=evaluation_task,<br/>    scoring_metrics=[check_hallucinated_metric],<br/>)<br/><br/></span></pre><pre class="pu pm oc pn bp po bb bk"><span id="22fb" class="pp oe fq oc b bg pq pr l ps pt">Evaluation: 100%|██████████| 200/200 [19:02&lt;00:00,  5.71s/it]<br/>╭─  HaluEval-qa-samples Balanced (200 samples)   ─╮<br/>│                                                 │<br/>│ Total time:        00:19:03                     │<br/>│ Number of samples: 200                          │<br/>│                                                 │<br/>│ Correct hallucination score: 0.5200 (avg)       │<br/>│                                                 │<br/>╰─────────────────────────────────────────────────╯<br/>Uploading results to Opik ... <br/>View the results in your Opik dashboard.</span></pre><p id="4ad7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We see a great improvement. Remember that running this same model, with a very similar initial prompt, on this same dataset, resulted in a score of 0.46. By simply adding this additional candidate evaluation step, we immediately increased the score to 0.52. For such a small model, this is great!</p><h1 id="b76b" class="od oe fq bf of og oh gq oi oj ok gt ol om on oo op oq or os ot ou ov ow ox oy bk">Structured generation’s role in the future of LLM evaluations</h1><p id="b346" class="pw-post-body-paragraph nc nd fq ne b go oz ng nh gr pa nj nk nl pb nn no np pc nr ns nt pd nv nw nx fj bk">Most foundation model providers, like OpenAI and Anthropic, offer some kind of <code class="cx nz oa ob oc b">structured output</code> mode which will respond to your queries with a predefined schema. However, the world of LLM evaluations extends well beyond the closed ecosystems of these providers' APIs.</p><p id="5ab8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For example:</p><ul class=""><li id="d1a1" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pe pf pg bk">So-called “white box” evaluations, which incorporate models’ internal states into the evaluation, are impossible with hosted models like GPT-4o.</li><li id="56cc" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">Fine-tuning a model for your specific evaluation use-case requires you to use open source models.</li><li id="2d83" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">If you need to run your evaluation pipeline locally, you obviously cannot use a hosted API.</li></ul><p id="2ebf" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And that’s without getting into comparisons of particular open source models against popular foundation models.</p><p id="019b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The future of LLM evaluations involves more complex evaluation suites, combining white box metrics, classic heuristic methods, and LLM judges into robust, multi-turn systems. Open source, or at the very least, locally-available LLMs are a major part of that future—and structured generation is a fundamental part of the infrastructure that is enabling that future.</p></div></div></div><div class="ab cb px py pz qa" role="separator"><span class="qb by bm qc qd qe"/><span class="qb by bm qc qd qe"/><span class="qb by bm qc qd"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="7b96" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">Originally published at </em><a class="af nb" href="https://www.comet.com/site/blog/structured-generation-llm-as-a-judge/" rel="noopener ugc nofollow" target="_blank"><em class="ny">https://www.comet.com</em></a><em class="ny"> on November 27, 2024.</em></p></div></div></div></div>    
</body>
</html>