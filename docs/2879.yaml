- en: How to Use Structured Generation for LLM-as-a-Judge Evaluations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-use-structured-generation-for-llm-as-a-judge-evaluations-c6018cdab8be?source=collection_archive---------10-----------------------#2024-11-27](https://towardsdatascience.com/how-to-use-structured-generation-for-llm-as-a-judge-evaluations-c6018cdab8be?source=collection_archive---------10-----------------------#2024-11-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Structured generation is fundamental to building complex, multi-step reasoning
    agents in LLM evaluations — especially for open source models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@calebkaiser?source=post_page---byline--c6018cdab8be--------------------------------)[![Caleb
    Kaiser](../Images/c33ef43df24242501cb9e797e8d67a6c.png)](https://medium.com/@calebkaiser?source=post_page---byline--c6018cdab8be--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c6018cdab8be--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c6018cdab8be--------------------------------)
    [Caleb Kaiser](https://medium.com/@calebkaiser?source=post_page---byline--c6018cdab8be--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c6018cdab8be--------------------------------)
    ·20 min read·Nov 27, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f8849a88a2dfb9c66defaadbb3f70dbb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Generated with SDXL 1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Disclosure: I am a maintainer of* [*Opik*](https://github.com/comet-ml/opik)*,
    one of the open source projects used later in this article.*'
  prefs: []
  type: TYPE_NORMAL
- en: For the past few months, I’ve been working on LLM-based evaluations (“LLM-as-a-Judge”
    metrics) for language models. The results have so far been extremely encouraging,
    particularly for evaluations like hallucination detection or content moderation,
    which are hard to quantify with heuristic methods.
  prefs: []
  type: TYPE_NORMAL
- en: Engineering LLM-based metrics, however, has been surprisingly challenging. Evaluations
    and unit tests, especially those with more complex logic, require you to know
    the structure of your data. And with LLMs and their probabilistic outputs, it’s
    difficult to reliably output specific formats and structures. Some hosted model
    providers now offer `structured outputs` modes, but these still come with limitations,
    and if you're using open source or local models, those modes won't do you much
    good.
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this problem is to use **structured generation**. Beyond its
    ability to make LLM-based evaluations more reliable, it also unlocks an entirely
    new category of complex, powerful multi-stage evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: In this piece, I want to introduce structured generation and some of the big
    ideas behind it, before diving into specific examples of hallucination detection
    with an LLM judge. All of the code samples below can be run from within this [Colab
    notebook](https://colab.research.google.com/drive/1-lQn0qvJMN1BBuDjRuCzySA7gLhpcdBo#scrollTo=8QOySg8J5AcT),
    so feel free to run the samples as you follow along.
  prefs: []
  type: TYPE_NORMAL
- en: A Brief Introduction to Structured Generation with Context-Free Grammars
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Structured generation is a subfield of machine learning focused on guiding the
    outputs of generative models by constraining the outputs to fit some particular
    schema. As an example, instead of fine-tuning a model to output valid JSON, you
    might constrain a more generalized model’s output to only match valid JSON schemas.
  prefs: []
  type: TYPE_NORMAL
- en: You can constrain the outputs of a model through different strategies, but the
    most common is to interfere directly in the sampling phase, using some external
    schema to prevent “incorrect” tokens from being sampled.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, structured generation has become a fairly common feature in LLM
    servers. vLLM, NVIDIA NIM, llama.cpp, and Ollama all support it. If you’re not
    working with a model server, libraries like [Outlines](https://github.com/dottxt-ai/outlines)
    make it trivial to implement for any model. OpenAI also provides a “Structured
    Output” mode, which similarly allows you to specify a response schema from their
    API.
  prefs: []
  type: TYPE_NORMAL
- en: But, I find it helps me develop my intuition for a concept to try a simple implementation
    from scratch, and so that’s what we’re going to do here.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main components to structured generation:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining a schema
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parsing the output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the schema, I’m going to use a context-free grammar (CFG). If you’re unfamiliar,
    a grammar is a schema for parsing a language. Loosely, it defines what is and
    isn’t considered “valid” in a language. If you’re in the mood for an *excellent*
    rabbit hole, context-free languages are a part of Chomsky’s hierarchy of languages.
    The amazing Kay Lack has [a fantastic introductory video to grammars and parsing
    here](https://www.youtube.com/watch?v=ENKT0Z3gldE), if you’re interested in learning
    more.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most popular library for parsing and constructing CFGs is Lark. In the
    below code, I’ve written out a simple JSON grammar using the library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If you’re not familiar with CFGs or Lark, the above might seem a little intimidating,
    but it’s actually pretty straightforward. The `?start` line indicates that we
    begin with a `value`. We then define a `value` to be either an object, an array,
    an escaped string, a signed number, a boolean, or a null value. The `->` symbols
    indicate that we map these string values to literal values. We then further specify
    what we mean by `array` , `object`, and `pair`, before finally instructing our
    parser to ignore inline whitespace. Try to think of it as if we are constantly
    "expanding" each high level concept, like a `start` or a `value`, into composite
    parts, until we reach such a low level of abstraction that we can no longer expand.
    In the parlance of grammars, these "too low level to be expanded" symbols are
    called "terminals."
  prefs: []
  type: TYPE_NORMAL
- en: 'One immediate issue you’ll run into with this above code is that it only determines
    if a string is valid or invalid JSON. Since we’re using a language model and generating
    one token at a time, we’re going to have a lot of intermediary strings that are
    technically invalid. There are more elegant ways of handling this, but for the
    sake of speed, I’m just going to define a simple function to check if we’re in
    the middle of generating a string or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With all of this defined, let’s run a little test to see if our parser can
    accurately differentiate between valid, invalid, and incomplete JSON strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: And it works!
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final test, let’s use this `try_and_recover()` function to guide our decoding
    process with a relatively smaller model. In the below code, we''ll use an instruction-tuned
    Qwen 2.5 model with 3 billion parameters, and we''ll ask it a simple question.
    First, let''s initialize the model and tokenizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we want to define a function to recursively sample from the model, using
    our `try_and_recover()` function to constrain the outputs. Below, I''ve defined
    the function, which works by recursively sampling the top 20 most likely next
    tokens, and selecting the first one which satisfies a valid or incomplete JSON
    string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This isn’t the most performant or robust approach, but it works well enough
    for our purposes. If you want a better look at more optimal approaches, you can
    see how [llama.cpp implements structured generation](https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md),
    or how a library like [Outlines handles things](https://github.com/dottxt-ai/outlines).
  prefs: []
  type: TYPE_NORMAL
- en: 'With the following code, we can test the performance of this structured generation
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This particular approach will obviously add some computational overhead to
    your code, but some of the more optimized implementations are actually capable
    of structuring the output of a model with minimal latency impact. Below is a side-by-side
    comparison of unstructured generation versus structured generation using llama.cpp’s
    grammar-structured generation feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef64ac9c814a3975332ad0bd4f4f6ac3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [How Fast Can Grammar-Structured Generation Be?](https://blog.dottxt.co/how-fast-cfg.html)'
  prefs: []
  type: TYPE_NORMAL
- en: This comparison was recorded by Brandon Willard from .txt (the company behind
    Outlines), as part of [his fantastic article on latency in structured generation](https://blog.dottxt.co/how-fast-cfg.html).
    I’d highly recommend giving it a read, if you’re interested in diving deeper into
    the field.
  prefs: []
  type: TYPE_NORMAL
- en: Alright, with that bit of introduction out of the way, let’s look at applying
    structured generation to an LLM-as-a-judge metric, like hallucination.
  prefs: []
  type: TYPE_NORMAL
- en: How to detect hallucinations with structured generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Hallucination detection is one of the “classic” applications of LLM-based evaluation.
    Traditional heuristic methods struggle with the subtlety of hallucination-in no
    small part due to the fact that there is no universally agreed upon definition
    of “hallucination.” For the purposes of this article, we’re going to use a definition
    from a [recent paper out of the University of Illinois Champagne-Urbana](https://arxiv.org/html/2403.16527v1),
    which I find to be descriptive and usable:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A hallucination is a generated output from a model that conflicts with constraints
    or deviates from desired behavior in actual deployment, or is completely irrelevant
    to the task at hand, but could be deemed syntactically plausible under the circumstances.*'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, a hallucination is an output that seems plausible. It is grammatically
    correct, it makes reference to its surrounding context, and it seems to fit the
    “flow” of the task. It also, however, contradicts some basic instruction of the
    task. This could mean drawing incorrect conclusions, citing nonexistent data,
    or completely ignoring the actual instructions of the task.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, encoding a discrete system of rules to parse outputs for something
    as ambiguous as hallucinations is a challenge. LLMs, however, are very well suited
    towards this kind of complex task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using an LLM to perform hallucination analysis isn’t too difficult to setup.
    All we need to do is prompt the model to analyze the output text for hallucinations.
    In [Opik’s built-in Hallucination() metric](https://github.com/comet-ml/opik),
    we use the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The difficult part, however, is performing this analysis programatically. In
    a real world setting, we’ll want to automatically parse the output of our model
    and collect the hallucination scores, either as part of our model evaluation or
    as part of our inference pipeline. Doing this will require us to write code that
    acts on the model outputs, and if the LLM responds with incorrectly formatted
    output, the evaluation will break.
  prefs: []
  type: TYPE_NORMAL
- en: This is a problem even for state of the art foundation models, but it is greatly
    exaggerated when working with smaller language models. Their outputs are probabilistic,
    and no matter how thorough you are in your prompt, there is no guarantee that
    they will always respond with the correct structure.
  prefs: []
  type: TYPE_NORMAL
- en: '*Unless*, of course, you use structured generation.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s run through a simple example using Outlines and Opik. First, we want to
    initialize our model using Outlines. In this example, we’ll be using the 0.5 billion
    parameter version of Qwen2.5\. While this model is impressive for its size, and
    small enough for us to run quickly in a Colab notebook, you will likely want to
    use a larger model for more accurate results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'When your model finishes downloading, you can then create a `generator`. In
    Outlines, a `generator` is an inference pipeline that combines an output schema
    with a model. In the below code, we''ll define a schema in Pydantic and initialize
    our generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now, if we pass a string into the generator, it will output a properly formatted
    object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s setup our Hallucination metric in Opik. It’s pretty straightforward
    to create a metric using Opik’s baseMetric class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: All we really do in the above is generate our prompt using the previously defined
    template string, and then pass it into our generator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s try out our metric on an actual hallucination dataset, to get a
    sense of how it works. We’ll use a split from the HaluEval dataset, which is freely
    available via HuggingFace and permissively licensed, and we’ll upload it as an
    Opik Dataset for our experiments. We’ll use a little extra logic to make sure
    the dataset is balanced between hallucinated and non-hallucinated samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'And now, we simply define an evaluation task using our HallucinationWithOutlines()
    metric, and run it against our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'And that’s all it takes! Notice that none of our samples failed because of
    improperly structured outputs. Let’s try running this same evaluation, but without
    structured generation. To achieve this, we can switch our generator type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'And modify our metric to parse JSON from the model output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Keeping the rest of the code the same and running this now results in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Nearly every string fails to parse correctly. The inference time is also increased
    dramatically because of the variable length of responses, whereas the structured
    output helps keep the responses terse.
  prefs: []
  type: TYPE_NORMAL
- en: Without structured generation, it just isn’t feasible to run this kind of evaluation,
    especially with a model this small. As an experiment, try running this same code
    with a bigger model and see how the average accuracy score improves.
  prefs: []
  type: TYPE_NORMAL
- en: Can we build more complex LLM judges with structured generation?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The above example of hallucination detection is pretty straightforward. The
    real value that structured generation brings to LLM judges, however, is that it
    enables us to build more complex, multi-turn evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To give an extreme example of what a multi-step evaluation might look like,
    one recent paper found success in LLM evals by constructing multiple “personas”
    for different LLM agents, and having the [agents debate in an actual courtroom
    structure](https://arxiv.org/html/2405.20267v4):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dde936a55ce3335b4578f945199af6f4.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Source: Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and
    Committee Discussions](https://arxiv.org/html/2405.20267v4)'
  prefs: []
  type: TYPE_NORMAL
- en: Forcing different agents to advocate for different positions and examine each
    other’s arguments, all while having yet another agent act as a “judge” to emit
    a final decision, significantly increased the accuracy of evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: In order for such a system to work, the handoffs between different agents must
    go smoothly. If an agent needs to pick between 5 possible actions, we need to
    be 100% sure that the model will only output one of those 5 valid actions. With
    structured generation, we can achieve that level of reliability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try a worked example, extending our hallucination metric from earlier.
    We’ll try the following improvement:'
  prefs: []
  type: TYPE_NORMAL
- en: On first pass, the model will generate 3 candidate hallucinations, with reasoning
    for each.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each candidate, the model will evaluate them individually and assess if
    they are a hallucination, with expanded reasoning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the model finds any candidate to be a hallucination, it will return 1.0 for
    the entire sample.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By giving the model the ability to generate longer chains of context, we give
    it space for more “intermediary computation,” and hopefully, a more accurate final
    output.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s define a series of prompts for this task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'And now, we can define some Pydantic models for our different model outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With all of this, we can put together two generators, one for generating candidate
    hallucinations, and one for scoring individual candidates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can construct an Opik metric. We’ll keep the code for this simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: All we do here is generate the first prompt, which should produce several hallucination
    candidates when fed to the candidate generator. Then, we pass each candidate (formatted
    with the candidate evaluation prompt) into the candidate evaluation generator.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run it using the same code as before, with slight modifications to use
    the new metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We see a great improvement. Remember that running this same model, with a very
    similar initial prompt, on this same dataset, resulted in a score of 0.46\. By
    simply adding this additional candidate evaluation step, we immediately increased
    the score to 0.52\. For such a small model, this is great!
  prefs: []
  type: TYPE_NORMAL
- en: Structured generation’s role in the future of LLM evaluations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most foundation model providers, like OpenAI and Anthropic, offer some kind
    of `structured output` mode which will respond to your queries with a predefined
    schema. However, the world of LLM evaluations extends well beyond the closed ecosystems
    of these providers' APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: So-called “white box” evaluations, which incorporate models’ internal states
    into the evaluation, are impossible with hosted models like GPT-4o.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning a model for your specific evaluation use-case requires you to use
    open source models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you need to run your evaluation pipeline locally, you obviously cannot use
    a hosted API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And that’s without getting into comparisons of particular open source models
    against popular foundation models.
  prefs: []
  type: TYPE_NORMAL
- en: The future of LLM evaluations involves more complex evaluation suites, combining
    white box metrics, classic heuristic methods, and LLM judges into robust, multi-turn
    systems. Open source, or at the very least, locally-available LLMs are a major
    part of that future—and structured generation is a fundamental part of the infrastructure
    that is enabling that future.
  prefs: []
  type: TYPE_NORMAL
- en: '*Originally published at* [*https://www.comet.com*](https://www.comet.com/site/blog/structured-generation-llm-as-a-judge/)
    *on November 27, 2024.*'
  prefs: []
  type: TYPE_NORMAL
