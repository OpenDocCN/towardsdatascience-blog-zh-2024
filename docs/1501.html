<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Multi AI Agent Systems 101</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Multi AI Agent Systems 101</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-ai-agent-systems-101-bac58e3bcc47?source=collection_archive---------0-----------------------#2024-06-16">https://towardsdatascience.com/multi-ai-agent-systems-101-bac58e3bcc47?source=collection_archive---------0-----------------------#2024-06-16</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="87df" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Automating Routine Tasks in Data Source Management with CrewAI</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://miptgirl.medium.com/?source=post_page---byline--bac58e3bcc47--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Mariya Mansurova" class="l ep by dd de cx" src="../Images/b1dd377b0a1887db900cc5108bca8ea8.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*7fFHr8XBAuR_SgJknIyODA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--bac58e3bcc47--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://miptgirl.medium.com/?source=post_page---byline--bac58e3bcc47--------------------------------" rel="noopener follow">Mariya Mansurova</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--bac58e3bcc47--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">26 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 16, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">13</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mj"><div class="ab cb"><div class="lm mk ln ml lo mm cf mn cg mo ci bh"><figure class="ms mt mu mv mw mj mx my paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq mr"><img src="../Images/a5a6e119bd80a1c3c4af2c7c64b02bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*uNj55dKXRioO_MnI1KIQSw.jpeg"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by DALL-E 3</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="d80f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Initially, when ChatGPT just appeared, we used simple prompts to get answers to our questions. Then, we encountered issues with hallucinations and began using RAG (Retrieval Augmented Generation) to provide more context to LLMs. After that, we started experimenting with AI agents, where LLMs act as a reasoning engine and can decide what to do next, which tools to use, and when to return the final answer.</p><p id="6716" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The next evolutionary step is to create teams of such agents that can collaborate with each other. This approach is logical as it mirrors human interactions. We work in teams where each member has a specific role:</p><ul class=""><li id="3b5e" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">The product manager proposes the next project to work on.</li><li id="d7a9" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">The designer creates its look and feel.</li><li id="5308" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">The software engineer develops the solution.</li><li id="6a0f" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">The analyst examines the data to ensure it performs as expected and identifies ways to improve the product for customers.</li></ul><p id="2e0b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Similarly, we can create a team of AI agents, each focusing on one domain. They can collaborate and reach a final conclusion together. Just as specialization enhances performance in real life, it could also benefit the performance of AI agents.</p><p id="b2a9" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Another advantage of this approach is increased flexibility. Each agent can operate with its own prompt, set of tools and even LLM. For instance, we can use different models for different parts of our system. You can use GPT-4 for the agent that needs more reasoning and GPT-3.5 for the one that does only simple extraction. We can even fine-tune the model for small specific tasks and use it in our crew of agents.</p><p id="7771" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The potential drawbacks of this approach are time and cost. Multiple interactions and knowledge sharing between agents require more calls to LLM and consume additional tokens. This could result in longer wait times and increased expenses.</p><p id="1ec5" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">There are several frameworks available for multi-agent systems today. <br/>Here are some of the most popular ones:</p><ul class=""><li id="7a25" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk"><a class="af on" href="https://github.com/microsoft/autogen?ref=blog.langchain.dev" rel="noopener ugc nofollow" target="_blank">AutoGen</a>: Developed by Microsoft, AutoGen uses a conversational approach and was one of the earliest frameworks for multi-agent systems,</li><li id="aafb" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk"><a class="af on" href="https://github.com/langchain-ai/langgraph" rel="noopener ugc nofollow" target="_blank">LangGraph</a>: While not strictly a multi-agent framework, LangGraph allows for defining complex interactions between actors using a graph structure. So, it can also be adapted to create multi-agent systems.</li><li id="34ff" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk"><a class="af on" href="https://github.com/joaomdmoura/crewAI?ref=blog.langchain.dev" rel="noopener ugc nofollow" target="_blank">CrewAI</a>: Positioned as a high-level framework, CrewAI facilitates the creation of “crews” consisting of role-playing agents capable of collaborating in various ways.</li></ul><p id="80c2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I’ve decided to start experimenting with multi-agent frameworks from CrewAI since it’s quite widely popular and user friendly. So, it looks like a good option to begin with.</p><p id="7c29" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In this article, I will walk you through how to use CrewAI. As analysts, we’re the domain experts responsible for documenting various data sources and addressing related questions. We’ll explore how to automate these tasks using multi-agent frameworks.</p><h1 id="f300" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Setting up the environment</h1><p id="3e0a" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Let’s start with setting up the environment. First, we need to install the CrewAI main package and an extension to work with tools.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="dd0c" class="pt op fq pq b bg pu pv l pw px">pip install crewai<br/>pip install 'crewai[tools]'</span></pre><p id="731b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">CrewAI was developed to work primarily with OpenAI API, but I would also like to try it with a local model. According to<a class="af on" href="https://chat.lmsys.org/?leaderboard=" rel="noopener ugc nofollow" target="_blank"> the ChatBot Arena Leaderboard</a>, the best model you can run on your laptop is Llama 3 (8b parameters). It will be the most feasible option for our use case.</p><p id="af4a" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can access Llama models using Ollama. Installation is pretty straightforward. You need to download Ollama from <a class="af on" href="https://ollama.com/download" rel="noopener ugc nofollow" target="_blank">the website</a> and then go through the installation process. That’s it.</p><p id="dda9" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, you can test the model in CLI by running the following command.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="6998" class="pt op fq pq b bg pu pv l pw px">ollama run llama3</span></pre><p id="b262" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">For example, you can ask something like this.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq py"><img src="../Images/b47f272e89a01f843e909b4d4e5cf665.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LKh7JSgBW_gtHM2YTFIBrw.png"/></div></div></figure><p id="f9e6" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s create a custom Ollama model to use later in CrewAI.</p><p id="0438" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We will start with a ModelFile (<a class="af on" href="https://github.com/ollama/ollama/blob/main/docs/modelfile.md" rel="noopener ugc nofollow" target="_blank">documentation</a>). I only specified the base model (<code class="cx pz qa qb pq b">llama3</code>), temperature and stop sequence. However, you might add more features. For example, you can determine the system message using <code class="cx pz qa qb pq b">SYSTEM</code> keyword.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="a15d" class="pt op fq pq b bg pu pv l pw px">FROM llama3<br/><br/># set parameters<br/>PARAMETER temperature 0.5<br/>PARAMETER stop Result</span></pre><p id="3efc" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I’ve saved it into a <code class="cx pz qa qb pq b">Llama3ModelFile</code> file.</p><p id="90f1" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s create a bash script to load the base model for Ollama and create the custom model we defined in ModelFile.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="941c" class="pt op fq pq b bg pu pv l pw px">#!/bin/zsh<br/><br/># define variables<br/>model_name="llama3"<br/>custom_model_name="crewai-llama3"<br/><br/># load the base model<br/>ollama pull $model_name<br/><br/># create the model file<br/>ollama create $custom_model_name -f ./Llama3ModelFile</span></pre><p id="70e0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s execute this file.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="7ef8" class="pt op fq pq b bg pu pv l pw px">chmod +x ./llama3_setup.sh<br/>./llama3_setup.sh</span></pre><blockquote class="qc qd qe"><p id="0d37" class="nj nk qf nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">You can find both files on GitHub: <a class="af on" href="https://github.com/miptgirl/miptgirl_medium/blob/main/crewai_answering_questions/Llama3ModelFile" rel="noopener ugc nofollow" target="_blank">Llama3ModelFile</a> and <a class="af on" href="https://github.com/miptgirl/miptgirl_medium/blob/main/crewai_answering_questions/llama3_setup.sh" rel="noopener ugc nofollow" target="_blank">llama3_setup.sh</a></p></blockquote><p id="d165" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We need to initialise the following environmental variables to use the local Llama model with CrewAI.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="31bb" class="pt op fq pq b bg pu pv l pw px">os.environ["OPENAI_API_BASE"]='http://localhost:11434/v1'<br/><br/>os.environ["OPENAI_MODEL_NAME"]='crewai-llama3' <br/># custom_model_name from the bash script<br/><br/>os.environ["OPENAI_API_KEY"] = "NA"</span></pre><p id="96be" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve finished the setup and are ready to continue our journey.</p><h1 id="3d59" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Use cases: working with documentation</h1><p id="6ace" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">As analysts, we often play the role of subject matter experts for data and some data-related tools. In my previous team, we used to have a channel with almost 1K participants, where we were answering lots of questions about our data and the ClickHouse database we used as storage. It took us quite a lot of time to manage this channel. It would be interesting to see whether such tasks can be automated with LLMs.</p><p id="e768" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">For this example, I will use the ClickHouse database. If you’re interested, You can learn more about ClickHouse and how to set it up locally in <a class="af on" href="https://clickhouse.com/" rel="noopener ugc nofollow" target="_blank">my previous article</a>. However, we won’t utilise any ClickHouse-specific features, so feel free to stick to the database you know.</p><p id="c9dc" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I’ve created a pretty simple data model to work with. There are just two tables in our DWH (Data Warehouse): <code class="cx pz qa qb pq b">ecommerce_db.users</code> and <code class="cx pz qa qb pq b">ecommerce_db.sessions</code>. As you might guess, the first table contains information about the users of our service.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qg"><img src="../Images/3de9376c5434676a728a3ee7f0d87037.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LukeFk5kSyBCOU4bV3yfzg.png"/></div></div></figure><p id="3d07" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The <code class="cx pz qa qb pq b">ecommerce_db.sessions</code> table stores information about user sessions.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qh"><img src="../Images/6ac727891735b98720fced70326530c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WqZwGilme-NwyQtRobomSw.png"/></div></div></figure><p id="97fa" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Regarding data source management, analysts typically handle tasks like writing and updating documentation and answering questions about this data. So, we will use LLM to write documentation for the table in the database and teach it to answer questions about data or ClickHouse.</p><p id="fe67" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">But before moving on to the implementation, let’s learn more about the CrewAI framework and its core concepts.</p><h1 id="3d42" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">CrewAI basic concepts</h1><p id="930f" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The cornerstone of a multi-agent framework is an <a class="af on" href="https://docs.crewai.com/core-concepts/Agents/" rel="noopener ugc nofollow" target="_blank"><strong class="nl fr">agent</strong></a> concept. In CrewAI, agents are powered by role-playing. Role-playing is a tactic when you ask an agent to adopt a persona and behave like a top-notch backend engineer or helpful customer support agent. So, when creating a CrewAI agent, you need to specify each agent's role, goal, and backstory so that LLM knows enough to play this role.</p><p id="3c6e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The agents’ capabilities are limited without <a class="af on" href="https://docs.crewai.com/core-concepts/Tools/" rel="noopener ugc nofollow" target="_blank"><strong class="nl fr">tools</strong></a> (functions that agents can execute and get results). With CrewAI, you can use one of the predefined tools (for example, to search the Internet, parse a website, or do RAG on a document), create a custom tool yourself or use LangChain tools. So, it’s pretty easy to create a powerful agent.</p><p id="a4eb" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s move on from agents to the work they are doing. Agents are working on <a class="af on" href="https://docs.crewai.com/core-concepts/Tasks/#task-attributes" rel="noopener ugc nofollow" target="_blank"><strong class="nl fr">tasks</strong></a> (specific assignments). For each task, we need to define a description, expected output (definition of done), set of available tools and assigned agent. I really like that these frameworks follow the managerial best practices like a clear definition of done for the tasks.</p><p id="cac2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The next question is how to define the execution order for tasks: which one to work on first, which ones can run in parallel, etc. CrewAI implemented <a class="af on" href="https://docs.crewai.com/core-concepts/Processes/" rel="noopener ugc nofollow" target="_blank"><strong class="nl fr">processes</strong></a> to orchestrate the tasks. It provides a couple of options:</p><ul class=""><li id="daf0" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk"><strong class="nl fr">Sequential</strong> —the most straightforward approach when tasks are called one after another.</li><li id="774b" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk"><strong class="nl fr">Hierarchical</strong> — when there’s a manager (specified as LLM model) that creates and delegates tasks to the agents.</li></ul><p id="fbce" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Also, CrewAI is working on a consensual process. In such a process, agents will be able to make decisions collaboratively with a democratic approach.</p><p id="4880" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">There are other levers you can use to tweak the process of tasks’ execution:</p><ul class=""><li id="fa42" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">You can mark tasks as “asynchronous”, then they will be executed in parallel, so you will be able to get an answer faster.</li><li id="b553" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">You can use the “human input” flag on a task, and then the agent will ask for human approval before finalising the output of this task. It can allow you to add an oversight to the process.</li></ul><p id="22b8" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve defined all the primary building blocks and can discuss the holly grail of CrewAI — <a class="af on" href="https://docs.crewai.com/core-concepts/Crews/#crew-attributes" rel="noopener ugc nofollow" target="_blank"><strong class="nl fr">crew</strong></a> concept. The crew represents the team of agents and the set of tasks they will be working on. The approach for collaboration (processes we discussed above) can also be defined at the crew level.</p><p id="bdea" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Also, we can set up the <a class="af on" href="https://docs.crewai.com/core-concepts/Memory/" rel="noopener ugc nofollow" target="_blank"><strong class="nl fr">memory</strong></a><strong class="nl fr"> </strong>for a crew. Memory is crucial for efficient collaboration between the agents. CrewAI supports three levels of memory:</p><ul class=""><li id="70ec" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">Short-term memory stores information related to the current execution. It helps agents to work together on the current task.</li><li id="4be9" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">Long-term memory is data about the previous executions stored in the local database. This type of memory allows agents to learn from earlier iterations and improve over time.</li><li id="be4f" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">Entity memory captures and structures information about entities (like personas, cities, etc.)</li></ul><p id="b183" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Right now, you can only switch on all types of memory for a crew without any further customisation. However, it doesn’t work with the Llama models.</p><p id="be04" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve learned enough about the CrewAI framework, so it’s time to start using this knowledge in practice.</p><h1 id="c65b" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Use case: writing documentation</h1><p id="e3be" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Let’s start with a simple task: putting together the documentation for our DWH. As we discussed before, there are two tables in our DWH, and I would like to create a detailed description for them using LLMs.</p><h2 id="ff92" class="qi op fq bf oq qj qk ql ot qm qn qo ow ns qp qq qr nw qs qt qu oa qv qw qx qy bk">First approach</h2><p id="36e9" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">In the beginning, we need to think about the team structure. Think of this as a typical managerial task. Who would you hire for such a job?</p><p id="242b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I would break this task into two parts: retrieving data from a database and writing documentation. So, we need a database specialist and a technical writer. The database specialist needs access to a database, while the writer won’t need any special tools.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qz"><img src="../Images/38ecf57b23d0f2c2cc2dd8f8031f6b1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0YLuYhwdFr0hKuS46qjEfA.png"/></div></div></figure><p id="63a4" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we have a high-level plan. Let’s create the agents.</p><p id="16e4" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">For each agent, I’ve specified the role, goal and backstory. I’ve tried my best to provide agents with all the needed context.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="7c5c" class="pt op fq pq b bg pu pv l pw px">database_specialist_agent = Agent(<br/>  role = "Database specialist",<br/>  goal = "Provide data to answer business questions using SQL",<br/>  backstory = '''You are an expert in SQL, so you can help the team <br/>  to gather needed data to power their decisions. <br/>  You are very accurate and take into account all the nuances in data.''',<br/>  allow_delegation = False,<br/>  verbose = True<br/>)<br/><br/>tech_writer_agent = Agent(<br/>  role = "Technical writer",<br/>  goal = '''Write engaging and factually accurate technical documentation <br/>    for data sources or tools''',<br/>  backstory = ''' <br/>  You are an expert in both technology and communications, so you can easily explain even sophisticated concepts.<br/>  You base your work on the factual information provided by your colleagues.<br/>  Your texts are concise and can be easily understood by a wide audience. <br/>  You use professional but rather an informal style in your communication.<br/>  ''',<br/>  allow_delegation = False,<br/>  verbose = True<br/>)</span></pre><p id="4d5d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We will use a simple sequential process, so there’s no need for agents to delegate tasks to each other. That’s why I specified <code class="cx pz qa qb pq b">allow_delegation = False</code>.</p><p id="3527" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The next step is setting the tasks for agents. But before moving to them, we need to create a custom tool to connect to the database.</p><p id="8f82" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, I put together a function to execute ClickHouse queries using HTTP API.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="fb33" class="pt op fq pq b bg pu pv l pw px">CH_HOST = 'http://localhost:8123' # default address <br/><br/>def get_clickhouse_data(query, host = CH_HOST, connection_timeout = 1500):<br/>  r = requests.post(host, params = {'query': query}, <br/>    timeout = connection_timeout)<br/>  if r.status_code == 200:<br/>      return r.text<br/>  else: <br/>      return 'Database returned the following error:\n' + r.text<br/></span></pre><p id="635f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">When working with LLM agents, it’s important to make tools fault-tolerant. For example, if the database returns an error (<code class="cx pz qa qb pq b">status_code != 200</code>), my code won’t throw an exception. Instead, it will return the error description to the LLM so it can attempt to resolve the issue.</p><p id="2021" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To create a CrewAI custom tool, we need to derive our class from <code class="cx pz qa qb pq b">crewai_tools.BaseTool</code>, implement the <code class="cx pz qa qb pq b">_run</code> method and then create an instance of this class.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="01f2" class="pt op fq pq b bg pu pv l pw px">from crewai_tools import BaseTool<br/><br/>class DatabaseQuery(BaseTool):<br/>  name: str = "Database Query"<br/>  description: str = "Returns the result of SQL query execution"<br/><br/>  def _run(self, sql_query: str) -&gt; str:<br/>      # Implementation goes here<br/>      return get_clickhouse_data(sql_query)<br/><br/>database_query_tool = DatabaseQuery()</span></pre><p id="3291" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we can set the tasks for the agents. Again, providing clear instructions and all the context to LLM is crucial.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="086b" class="pt op fq pq b bg pu pv l pw px">table_description_task = Task(<br/>  description = '''Provide the comprehensive overview for the data <br/>  in table {table}, so that it's easy to understand the structure <br/>  of the data. This task is crucial to put together the documentation <br/>  for our database''',<br/>  expected_output = '''The comprehensive overview of {table} in the md format. <br/>  Include 2 sections: columns (list of columns with their types) <br/>  and examples (the first 30 rows from table).''',<br/>  tools = [database_query_tool],<br/>  agent = database_specialist_agent<br/>)<br/><br/>table_documentation_task = Task(<br/>  description = '''Using provided information about the table, <br/>  put together the detailed documentation for this table so that <br/>  people can use it in practice''',<br/>  expected_output = '''Well-written detailed documentation describing <br/>  the data scheme for the table {table} in markdown format, <br/>  that gives the table overview in 1-2 sentences then then <br/>  describes each columm. Structure the columns description <br/>  as a markdown table with column name, type and description.''',<br/>  tools = [],<br/>  output_file="table_documentation.md",<br/>  agent = tech_writer_agent<br/>)</span></pre><p id="8a5a" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">You might have noticed that I’ve used <code class="cx pz qa qb pq b">{table}</code> placeholder in the tasks’ descriptions. We will use <code class="cx pz qa qb pq b">table</code> as an input variable when executing the crew, and this value will be inserted into all placeholders.</p><p id="3808" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Also, I’ve specified the output file for the table documentation task to save the final result locally.</p><p id="d5b0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We have all we need. Now, it’s time to create a crew and execute the process, specifying the table we are interested in. Let’s try it with the users table.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="ea17" class="pt op fq pq b bg pu pv l pw px">crew = Crew(<br/>  agents = [database_specialist_agent, tech_writer_agent],<br/>  tasks = [table_description_task,  table_documentation_task],<br/>  verbose = 2<br/>)<br/><br/>result = crew.kickoff({'table': 'ecommerce_db.users'})</span></pre><p id="b256" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It’s an exciting moment, and I’m really looking forward to seeing the result. Don’t worry if execution takes some time. Agents make multiple LLM calls, so it’s perfectly normal for it to take a few minutes. It took 2.5 minutes on my laptop.</p><p id="c2d0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We asked LLM to return the documentation in markdown format. We can use the following code to see the formatted result in Jupyter Notebook.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="dbb0" class="pt op fq pq b bg pu pv l pw px">from IPython.display import Markdown<br/>Markdown(result)</span></pre><p id="afab" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">At first glance, it looks great. We’ve got the valid markdown file describing the users' table.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq ra"><img src="../Images/e98ec48f91dc2754b39ac5b0c59424e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Ls4Gp_N_feYnJr4jO5k_g.png"/></div></div></figure><p id="65e5" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">But wait, it’s incorrect. Let’s see what data we have in our table.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qg"><img src="../Images/3de9376c5434676a728a3ee7f0d87037.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LukeFk5kSyBCOU4bV3yfzg.png"/></div></div></figure><p id="c2ec" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The columns listed in the documentation are completely different from what we have in the database. It’s a case of LLM hallucinations.</p><p id="3336" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve set <code class="cx pz qa qb pq b">verbose = 2</code> to get the detailed logs from CrewAI. Let’s read through the execution logs to identify the root cause of the problem.</p><p id="5e10" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, the database specialist couldn’t query the database due to complications with quotes.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rb"><img src="../Images/966fcf095524bc7809853c882d83ab57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8F9OpgR0LJA-mWw7ib_hrw.png"/></div></div></figure><p id="1b23" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The specialist didn’t manage to resolve this problem. Finally, this chain has been terminated by CrewAI with the following output: <code class="cx pz qa qb pq b">Agent stopped due to iteration limit or time limit</code>.</p><p id="6fa2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This means the technical writer didn’t receive any factual information about the data. However, the agent continued and produced completely fake results. That’s how we ended up with incorrect documentation.</p><h2 id="e85f" class="qi op fq bf oq qj qk ql ot qm qn qo ow ns qp qq qr nw qs qt qu oa qv qw qx qy bk">Fixing the issues</h2><p id="926b" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Even though our first iteration wasn’t successful, we’ve learned a lot. We have (at least) two areas for improvement:</p><ul class=""><li id="80ed" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">Our database tool is too difficult for the model, and the agent struggles to use it. We can make the tool more tolerant by removing quotes from the beginning and end of the queries. This solution is not ideal since valid SQL can end with a quote, but let’s try it.</li><li id="a521" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">Our technical writer isn’t basing its output on the input from the database specialist. We need to tweak the prompt to highlight the importance of providing only factual information.</li></ul><p id="a40d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, let’s try to fix these problems. First, we will fix the tool — we can leverage <code class="cx pz qa qb pq b">strip</code> to eliminate quotes.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="54d2" class="pt op fq pq b bg pu pv l pw px">CH_HOST = 'http://localhost:8123' # default address <br/><br/>def get_clickhouse_data(query, host = CH_HOST, connection_timeout = 1500):<br/>  r = requests.post(host, params = {'query': query.strip('"').strip("'")}, <br/>    timeout = connection_timeout)<br/>  if r.status_code == 200:<br/>    return r.text<br/>  else: <br/>    return 'Database returned the following error:\n' + r.text</span></pre><p id="1612" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Then, it’s time to update the prompt. I’ve included statements emphasizing the importance of sticking to the facts in both the agent and task definitions.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="2932" class="pt op fq pq b bg pu pv l pw px"><br/>tech_writer_agent = Agent(<br/>  role = "Technical writer",<br/>  goal = '''Write engaging and factually accurate technical documentation <br/>  for data sources or tools''',<br/>  backstory = ''' <br/>  You are an expert in both technology and communications, so you <br/>  can easily explain even sophisticated concepts.<br/>  Your texts are concise and can be easily understood by wide audience. <br/>  You use professional but rather informal style in your communication.<br/>  You base your work on the factual information provided by your colleagues. <br/>  You stick to the facts in the documentation and use ONLY <br/>  information provided by the colleagues not adding anything.''',<br/>  allow_delegation = False,<br/>  verbose = True<br/>)<br/><br/>table_documentation_task = Task(<br/>  description = '''Using provided information about the table, <br/>  put together the detailed documentation for this table so that <br/>  people can use it in practice''',<br/>  expected_output = '''Well-written detailed documentation describing <br/>  the data scheme for the table {table} in markdown format, <br/>  that gives the table overview in 1-2 sentences then then <br/>  describes each columm. Structure the columns description <br/>  as a markdown table with column name, type and description.<br/>  The documentation is based ONLY on the information provided <br/>  by the database specialist without any additions.''',<br/>  tools = [],<br/>  output_file = "table_documentation.md",<br/>  agent = tech_writer_agent<br/>)</span></pre><p id="4350" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s execute our crew once again and see the results.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rc"><img src="../Images/f79b2d4b9cfb0046ab1a6f48b6a4acb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fyVVxKGC3Dhr_4pqQwo1dg.png"/></div></div></figure><p id="aa98" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve achieved a bit better result. Our database specialist was able to execute queries and view the data, which is a significant win for us. Additionally, we can see all the relevant fields in the result table, though there are lots of other fields as well. So, it’s still not entirely correct.</p><p id="42f3" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I once again looked through the CrewAI execution log to figure out what went wrong. The issue lies in getting the list of columns. There’s no filter by database, so it returns some unrelated columns that appear in the result.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="475a" class="pt op fq pq b bg pu pv l pw px">SELECT column_name <br/>FROM information_schema.columns <br/>WHERE table_name = 'users'</span></pre><p id="287c" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Also, after looking at multiple attempts, I noticed that the database specialist, from time to time, executes <code class="cx pz qa qb pq b">select * from &lt;table&gt;</code> query. It might cause some issues in production as it might generate lots of data and send it to LLM.</p><h2 id="ac38" class="qi op fq bf oq qj qk ql ot qm qn qo ow ns qp qq qr nw qs qt qu oa qv qw qx qy bk">More specialised tools</h2><p id="4888" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">We can provide our agent with more specialised tools to improve our solution. Currently, the agent has a tool to execute any SQL query, which is flexible and powerful but prone to errors. We can create more focused tools, such as getting table structure and top-N rows from the table. Hopefully, it will reduce the number of mistakes.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="ac95" class="pt op fq pq b bg pu pv l pw px">class TableStructure(BaseTool):<br/>  name: str = "Table structure"<br/>  description: str = "Returns the list of columns and their types"<br/><br/>  def _run(self, table: str) -&gt; str:<br/>    table = table.strip('"').strip("'")<br/>    return get_clickhouse_data(<br/>      'describe {table} format TabSeparatedWithNames'\<br/>        .format(table = table)<br/>    )<br/><br/>class TableExamples(BaseTool):<br/>  name: str = "Table examples"<br/>  description: str = "Returns the first N rows from the table"<br/><br/>  def _run(self, table: str, n: int = 30) -&gt; str:<br/>    table = table.strip('"').strip("'")<br/>    return get_clickhouse_data(<br/>      'select * from {table} limit {n} format TabSeparatedWithNames'<br/>        \.format(table = table, n = n)<br/>    )<br/><br/>table_structure_tool = TableStructure()<br/>table_examples_tool = TableExamples()</span></pre><p id="f551" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we need to specify these tools in the task and re-run our script. After the first attempt, I got the following output from the Technical Writer.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="0c69" class="pt op fq pq b bg pu pv l pw px">Task output: This final answer provides a detailed and factual description <br/>of the ecommerce_db.users table structure, including column names, types, <br/>and descriptions. The documentation adheres to the provided information <br/>from the database specialist without any additions or modifications.</span></pre><p id="7e26" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">More focused tools helped the database specialist retrieve the correct table information. However, even though the writer had all the necessary information, we didn’t get the expected result.</p><p id="8fba" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">As we know, LLMs are probabilistic, so I gave it another try. And hooray, this time, the result was pretty good.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rd"><img src="../Images/536e784233791190a9045928c534d537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yWLsOgw-FPo4ys0XYfUQGQ.png"/></div></div></figure><p id="de78" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It’s not perfect since it still includes some irrelevant comments and lacks the overall description of the table. However, providing more specialised tools has definitely paid off. It also helped to prevent issues when the agent tried to load all the data from the table.</p><h2 id="c574" class="qi op fq bf oq qj qk ql ot qm qn qo ow ns qp qq qr nw qs qt qu oa qv qw qx qy bk">Quality assurance specialist</h2><p id="0c49" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">We’ve achieved pretty good results, but let’s see if we can improve them further. A common practice in multi-agent setups is quality assurance, which adds the final review stage before finalising the results.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq re"><img src="../Images/b452393cdc89394850940fa99040c1ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aYHqvVqM9DEsEMGmgT3UYw.png"/></div></div></figure><p id="a40e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s create a new agent — a Quality Assurance Specialist, who will be in charge of review.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="3448" class="pt op fq pq b bg pu pv l pw px">qa_specialist_agent = Agent(<br/>  role = "Quality Assurance specialist",<br/>  goal = """Ensure the highest quality of the documentation we provide <br/>  (that it's correct and easy to understand)""",<br/>  backstory = '''<br/>  You work as a Quality Assurance specialist, checking the work <br/>  from the technical writer and ensuring that it's inline <br/>  with our highest standards.<br/>  You need to check that the technical writer provides the full complete <br/>  answers and make no assumptions. <br/>  Also, you need to make sure that the documentation addresses <br/>  all the questions and is easy to understand.<br/>  ''',<br/>  allow_delegation = False,<br/>  verbose = True<br/>)</span></pre><p id="154f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, it’s time to describe the review task. I’ve used the <code class="cx pz qa qb pq b">context</code> parameter to specify that this task requires outputs from both <code class="cx pz qa qb pq b">table_description_task</code> and <code class="cx pz qa qb pq b">table_documentation_task</code>.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="57be" class="pt op fq pq b bg pu pv l pw px">qa_review_task = Task(<br/>  description = '''<br/>  Review the draft documentation provided by the technical writer.<br/>  Ensure that the documentation fully answers all the questions: <br/>  the purpose of the table and its structure in the form of table. <br/>  Make sure that the documentation is consistent with the information <br/>  provided by the database specialist. <br/>  Double check that there are no irrelevant comments in the final version <br/>  of documentation.<br/>  ''',<br/>  expected_output = '''<br/>  The final version of the documentation in markdown format <br/>  that can be published. <br/>  The documentation should fully address all the questions, be consistent <br/>  and follow our professional but informal tone of voice.<br/>  ''',<br/>  tools = [],<br/>  context = [table_description_task, table_documentation_task],<br/>  output_file="checked_table_documentation.md",<br/>  agent = qa_specialist_agent<br/>)</span></pre><p id="4d30" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s update our crew and run it.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="7166" class="pt op fq pq b bg pu pv l pw px">full_crew = Crew(<br/>  agents=[database_specialist_agent, tech_writer_agent, qa_specialist_agent],<br/>  tasks=[table_description_task,  table_documentation_task, qa_review_task],<br/>  verbose = 2,<br/>  memory = False # don't work with Llama<br/>)<br/><br/>full_result = full_crew.kickoff({'table': 'ecommerce_db.users'})</span></pre><p id="d040" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We now have more structured and detailed documentation thanks to the addition of the QA stage.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rf"><img src="../Images/207c43201fa01049208b438839e28ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U7Yt4hWfUD4y4BqKt_YhEA.png"/></div></div></figure><h2 id="4efa" class="qi op fq bf oq qj qk ql ot qm qn qo ow ns qp qq qr nw qs qt qu oa qv qw qx qy bk">Delegation</h2><p id="3ba7" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">With the addition of the QA specialist, it would be interesting to test the delegation mechanism. The QA specialist agent might have questions or requests that it could delegate to other agents.</p><p id="6c82" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I tried using the delegation with Llama 3, but it didn’t go well. Llama 3 struggled to call the co-worker tool correctly. It couldn’t specify the correct co-worker’s name.</p><p id="901f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We achieved pretty good results with a local model that can run on any laptop, but now it’s time to switch gears and use a way more powerful model — GPT-4o.</p><p id="2cbf" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To do it, we just need to update the following environment variables.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="ee44" class="pt op fq pq b bg pu pv l pw px">os.environ["OPENAI_MODEL_NAME"] = 'gpt-4o'  <br/>os.environ["OPENAI_API_KEY"] = config['OPENAI_API_KEY'] # your OpenAI key</span></pre><p id="4684" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To switch on the delegation, we should specify <code class="cx pz qa qb pq b">allow_delegation = True</code> for the QA specialist agent.</p><p id="cb7f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Also, we can use handy memory functionality for OpenAI models, as mentioned above. The memory will allow our agents to share their knowledge with each other during execution and leverage long-term memory to get information from previous executions.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="087f" class="pt op fq pq b bg pu pv l pw px">full_crew = Crew(<br/>  agents = [database_specialist_agent, tech_writer_agent, qa_specialist_agent],<br/>  tasks = [table_description_task,  table_documentation_task, qa_review_task],<br/>  verbose = 2,<br/>  memory = True <br/>)<br/><br/>full_result = full_crew.kickoff({'table': 'ecommerce_db.users'})</span></pre><p id="125d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s see the CrewAI execution logs to understand how delegation works. Here are all the logs for the QA specialist. We can see that it reached out to the database specialist to double-check the information.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="b5a7" class="pt op fq pq b bg pu pv l pw px">Thought: I need to review the provided draft documentation to ensure it <br/>fully answers all the questions and is complete, correct, and easy <br/>to understand. Specifically, I need to ensure that it explains the purpose <br/>of the table, its structure, and includes relevant examples without <br/>any irrelevant comments.<br/><br/>First, I will compare the two drafts to identify any discrepancies and <br/>missing information. Then, I will verify the accuracy and completeness of <br/>the information provided.<br/><br/>**Comparison:**<br/>1. **Introduction:**<br/>   - First draft: Includes an introduction and examples.<br/>   - Second draft: Adds a more detailed introduction about the purpose and importance of the table.<br/><br/>2. **Columns:**<br/>   - Both drafts have the same column structure and descriptions.<br/><br/>3. **Additional Information:**<br/>   - Both drafts include similar additional information, but the second draft is more concise.<br/><br/>4. **Examples:**<br/>   - The first draft includes examples, which are missing in the second draft.<br/><br/>5. **Final Checks:**<br/>   - Ensure there are no irrelevant comments.<br/>   - Verify consistency with information provided by the database specialist.<br/><br/>Action: Ask question to co-worker<br/>Action Input: {<br/>"question": "Can you confirm the accuracy of the provided column descriptions <br/>  and examples for the `ecommerce_db.users` table?", <br/>"context": "We are finalizing the documentation for the `ecommerce_db.users`<br/> table. The table includes columns `user_id`, `country`, `is_active`, and <br/>  `age`. Here are the examples provided:<br/><br/>  | user_id | country        | is_active | age |<br/>  |---------|----------------|-----------|-----|<br/>  | 1000001 | United Kingdom | 0         | 70  |<br/>  | 1000002 | France         | 1         | 87  |<br/>  | 1000003 | France         | 1         | 88  |<br/>  | 1000004 | Germany        | 1         | 25  |<br/>  | 1000005 | Germany        | 1         | 48  |<br/>  | 1000006 | France         | 1         | 78  |<br/>  | 1000007 | Netherlands    | 1         | 65  |<br/>  | 1000008 | Germany        | 1         | 31  |<br/>  | 1000009 | Germany        | 1         | 66  |<br/>  | 1000010 | Germany        | 1         | 73  |", <br/>"coworker": "database specialist"}<br/><br/>&lt;-- omitted logs from the database specialist --&gt;<br/><br/>Based on the provided context and examples for the `ecommerce_db.users` table, <br/>the column descriptions and examples appear accurate. Here are the details:<br/>- `user_id`: This column contains a unique identifier for each user. <br/>  The provided examples (e.g., 1000001, 1000002) align with this description <br/>  as they are unique numeric identifiers.<br/><br/>- `country`: This column specifies the country of the user. The provided <br/>  examples (e.g., United Kingdom, France, Germany, Netherlands) are <br/>  all valid country names.<br/><br/>- `is_active`: This column indicates whether the user is active (1) or not (0). The provided examples (e.g., 0, 1) correctly represent this binary status.<br/><br/>- `age`: This column shows the age of the user. The provided examples (e.g., 70, <br/>  87, 88, 25, 48, 78, 65, 31, 66, 73) are all valid ages.<br/><br/>Therefore, the column descriptions and examples provided for the <br/> `ecommerce_db.users` table are accurate and meet the expected criteria.<br/><br/>Thought: Based on the observation from the database specialist, <br/>the column descriptions and examples provided for the `ecommerce_db.users` <br/>table are accurate. Now, I will consolidate the best elements from both drafts,<br/> ensuring the documentation is complete, clear, and free of irrelevant comments.<br/><br/>Action: Finalize the documentation in markdown format, incorporating <br/>the detailed introduction, examples, and ensuring the tone is professional <br/>but informal.</span></pre><p id="c26b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">When I tried the delegation for the first time, I didn’t enable memory, which led to incorrect results. The data specialist and the technical writer initially returned the correct information. However, when the QA specialist returned with the follow-up questions, they started to hallucinate. So, it looks like delegation works better when memory is enabled.</p><p id="136e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Here’s the final output from GPT-4o. The result looks pretty nice now. We definitely can use LLMs to automate documentation.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rg"><img src="../Images/ccca4f521728af6e15a2d73bc450db2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-567hW4cSLS-Me6iKfRQWw.png"/></div></div></figure><p id="d630" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, the first task has been solved!</p><p id="19e4" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I used the same script to generate documentation for the <code class="cx pz qa qb pq b">ecommerce_db.sessions</code> table as well. It will be handy for our next task. So, let’s not waste any time and move on.</p><h1 id="a7dc" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Use case: answering questions</h1><p id="ea10" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Our next task is answering questions based on the documentation since it’s common for many data analysts (and other specialists).</p><p id="95c9" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We will start simple and will create just two agents:</p><ul class=""><li id="b372" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">The documentation support specialist will be answering questions based on the docs,</li><li id="9ed7" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">The support QA agent will review the answer before sharing it with the customer.</li></ul><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rh"><img src="../Images/211478ae8b1f633d5693c883fea42a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-KEcNJLuLb4N-5POD9Wz4Q.png"/></div></div></figure><p id="7e24" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We will need to empower the documentation specialist with a couple of tools that will allow them to see all the files stored in the directory and read the files. It’s pretty straightforward since CrewAI has implemented such tools.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="b9c1" class="pt op fq pq b bg pu pv l pw px">from crewai_tools import DirectoryReadTool, FileReadTool<br/><br/>documentation_directory_tool = DirectoryReadTool(<br/>    directory = '~/crewai_project/ecommerce_documentation')<br/><br/>base_file_read_tool = FileReadTool()</span></pre><p id="0097" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">However, since Llama 3 keeps struggling with quotes when calling tools, I had to create a custom tool on top of the <code class="cx pz qa qb pq b">FileReaderTool</code> to overcome this issue.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="c2ac" class="pt op fq pq b bg pu pv l pw px">from crewai_tools import BaseTool<br/><br/>class FileReadToolUPD(BaseTool):<br/>    name: str = "Read a file's content"<br/>    description: str = "A tool that can be used to read a file's content."<br/><br/>    def _run(self, file_path: str) -&gt; str:<br/>        # Implementation goes here<br/>        return base_file_read_tool._run(file_path = file_path.strip('"').strip("'"))<br/>        <br/>file_read_tool = FileReadToolUPD()</span></pre><p id="6436" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Next, as we did before, we need to create agents, tasks and crew.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="6a41" class="pt op fq pq b bg pu pv l pw px">data_support_agent = Agent(<br/>  role = "Senior Data Support Agent",<br/>  goal = "Be the most helpful support for you colleagues",<br/>  backstory = '''You work as a support for data-related questions <br/>  in the company. <br/>  Even though you're a big expert in our data warehouse, you double check <br/>  all the facts in documentation. <br/>  Our documentation is absolutely up-to-date, so you can fully rely on it <br/>  when answering questions (you don't need to check the actual data <br/>  in database).<br/>  Your work is very important for the team success. However, remember <br/>  that examples of table rows don't show all the possible values. <br/>  You need to ensure that you provide the best possible support: answering <br/>  all the questions, making no assumptions and sharing only the factual data.<br/>  Be creative try your best to solve the customer problem. <br/>  ''',<br/>  allow_delegation = False,<br/>  verbose = True<br/>)<br/><br/>qa_support_agent = Agent(<br/>  role = "Support Quality Assurance Agent",<br/>  goal = """Ensure the highest quality of the answers we provide <br/>  to the customers""",<br/>  backstory = '''You work as a Quality Assurance specialist, checking the work <br/>  from support agents and ensuring that it's inline with our highest standards.<br/>  You need to check that the agent provides the full complete answers <br/>  and make no assumptions. <br/>  Also, you need to make sure that the documentation addresses all <br/>  the questions and is easy to understand.<br/>  ''',<br/>  allow_delegation = False,<br/>  verbose = True<br/>)<br/><br/>draft_data_answer = Task(<br/>  description = '''Very important customer {customer} reached out to you <br/>  with the following question:<br/>  ```<br/>  {question}<br/>  ```<br/>  <br/>  Your task is to provide the best answer to all the points in the question <br/>  using all available information and not making any assumprions. <br/>  If you don't have enough information to answer the question, just say <br/>  that you don't know.''',<br/>  expected_output = '''The detailed informative answer to the customer's <br/>  question that addresses all the point mentioned. <br/>  Make sure that answer is complete and stict to facts <br/>  (without any additional information not based on the factual data)''',<br/>  tools = [documentation_directory_tool, file_read_tool], <br/>  agent = data_support_agent<br/>)<br/><br/>answer_review = Task(<br/>  description = '''<br/>  Review the draft answer provided by the support agent.<br/>  Ensure that the it fully answers all the questions mentioned <br/>  in the initial inquiry. <br/>  Make sure that the answer is consistent and doesn't include any assumptions.<br/>  ''',<br/>  expected_output = '''<br/>  The final version of the answer in markdown format that can be shared <br/>  with the customer. <br/>  The answer should fully address all the questions, be consistent <br/>  and follow our professional but informal tone of voice. <br/>  We are very chill and friendly company, so don't forget to include <br/>  all the polite phrases.<br/>  ''',<br/>  tools = [], <br/>  agent = qa_support_agent<br/>)<br/><br/>qna_crew = Crew(<br/>  agents = [data_support_agent, qa_support_agent],<br/>  tasks = [draft_data_answer,  answer_review],<br/>  verbose = 2,<br/>  memory = False # don't work with Llama<br/>)</span></pre><p id="1397" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s see how it works in practice.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="2259" class="pt op fq pq b bg pu pv l pw px">result = qna_crew.kickoff(<br/>  {'customer': "Max", <br/>   'question': """Hey team, I hope you're doing well. I need to find <br/>    the numbers before our CEO presentation tomorrow, so I will really <br/>    appreciate your help.<br/>    I need to calculate the number of sessions from our Windows users in 2023. I've tried to find the table with such data in our data warehouse, but wasn't able to. <br/>    Do you have any ideas whether we store the needed data somewhere, <br/>    so that I can query it? """<br/>  }<br/>)</span></pre><p id="755e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve got a polite, practical and helpful answer in return. That’s really great.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="d873" class="pt op fq pq b bg pu pv l pw px">**Hello Max,**<br/><br/>Thank you for reaching out with your question! I'm happy to help you <br/>find the number of sessions from Windows users in 2023. <br/>After reviewing our documentation, I found that we do store data <br/>related to sessions and users in our ecommerce database, specifically in <br/>the `ecommerce_db.sessions` table.<br/><br/>To answer your question, I can provide you with a step-by-step guide <br/>on how to query this table using SQL. First, you can use the `session_id` <br/>column along with the `os` column filtering for "Windows" and <br/>the `action_date` column filtering for dates in 2023. <br/>Then, you can group the results by `os` using the `GROUP BY` clause <br/>to count the number of sessions that meet these conditions.<br/><br/>Here's a sample SQL query that should give you the desired output:<br/><br/>```sql<br/>SELECT COUNT(*) <br/>FROM ecommerce_db.sessions <br/>WHERE os = 'Windows' <br/>AND action_date BETWEEN '2023-01-01' AND '2023-12-31'<br/>GROUP BY os;<br/>```<br/><br/>This query will return the total number of sessions from Windows <br/>users in 2023. I hope this helps! If you have any further questions or <br/>need more assistance, please don't hesitate to ask.</span></pre><p id="e1c8" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s complicate the task a bit. Suppose we can get not only questions about our data but also about our tool (ClickHouse). So, we will have another agent in the crew — ClickHouse Guru. To give our CH agent some knowledge, I will share a documentation website with it.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="237a" class="pt op fq pq b bg pu pv l pw px">from crewai_tools import ScrapeWebsiteTool, WebsiteSearchTool<br/>ch_documenation_tool = ScrapeWebsiteTool(<br/>  'https://clickhouse.com/docs/en/guides/creating-tables')</span></pre><p id="a433" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">If you need to work with a lengthy document, you might try using RAG (Retrieval Augmented generation) — <a class="af on" href="https://docs.crewai.com/tools/WebsiteSearchTool/" rel="noopener ugc nofollow" target="_blank">WebsiteSearchTool</a>. It will calculate embeddings and store them locally in ChromaDB. In our case, we will stick to a simple website scraper tool.</p><p id="f3e1" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now that we have two subject matter experts, we need to decide who will be working on the questions. So, it’s time to use a hierarchical process and add a manager to orchestrate all the tasks.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq ri"><img src="../Images/1e8a9048cb1cf80662b17df62655fd37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5O56Xqw-Cb87wZ_nKGg0iA.png"/></div></div></figure><p id="5c64" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">CrewAI provides the manager implementation, so we only need to specify the LLM model. I’ve picked the GPT-4o.</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="c565" class="pt op fq pq b bg pu pv l pw px">from langchain_openai import ChatOpenAI<br/>from crewai import Process<br/><br/>complext_qna_crew = Crew(<br/>  agents = [ch_support_agent, data_support_agent, qa_support_agent],<br/>  tasks = [draft_ch_answer, draft_data_answer, answer_review],<br/>  verbose = 2,<br/>  manager_llm = ChatOpenAI(model='gpt-4o', temperature=0),  <br/>  process = Process.hierarchical,  <br/>  memory = False <br/>)</span></pre><blockquote class="qc qd qe"><p id="512c" class="nj nk qf nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">At this point, I had to switch from Llama 3 to OpenAI models again to run a hierarchical process since it hasn’t worked for me with Llama (similar to <a class="af on" href="https://github.com/joaomdmoura/crewAI/issues/657" rel="noopener ugc nofollow" target="_blank">this issue</a>).</p></blockquote><p id="234d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we can try our new crew with different types of questions (either related to our data or ClickHouse database).</p><pre class="ms mt mu mv mw pp pq pr bp ps bb bk"><span id="7744" class="pt op fq pq b bg pu pv l pw px">ch_result = complext_qna_crew.kickoff(<br/>  {'customer': "Maria", <br/>   'question': """Good morning, team. I'm using ClickHouse to calculate <br/>   the number of customers. <br/>   Could you please remind whether there's an option to add totals <br/>   in ClickHouse?"""<br/>  }<br/>)<br/><br/>doc_result = complext_qna_crew.kickoff(<br/>  {'customer': "Max", <br/>   'question': """Hey team, I hope you're doing well. I need to find <br/>    the numbers before our CEO presentation tomorrow, so I will really <br/>    appreciate your help.<br/>    I need to calculate the number of sessions from our Windows users <br/>    in 2023. I've tried to find the table with such data <br/>    in our data warehouse, but wasn't able to. <br/>    Do you have any ideas whether we store the needed data somewhere, <br/>    so that I can query it. """<br/>  }<br/>)</span></pre><p id="2a9d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">If we look at the final answers and logs (<em class="qf">I’ve omitted them here since they are quite lengthy, bu</em>t <em class="qf">you can find them and full logs on </em><a class="af on" href="https://github.com/miptgirl/miptgirl_medium/blob/main/crewai_answering_questions/rag_documentation_poc_openai.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="qf">GitHub</em></a>), we will see that the manager was able to orchestrate correctly and delegate tasks to co-workers with relevant knowledge to address the customer's question. For the first (ClickHouse-related) question, we got a detailed answer with examples and possible implications of using <code class="cx pz qa qb pq b">WITH TOTALS</code> functionality. For the data-related question, models returned roughly the same information as we’ve seen above.</p><p id="bc96" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, we’ve built a crew that can answer various types of questions based on the documentation, whether from a local file or a website. I think it’s an excellent result.</p><blockquote class="qc qd qe"><p id="d43f" class="nj nk qf nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">You can find all the code on <a class="af on" href="https://github.com/miptgirl/miptgirl_medium/tree/main/crewai_answering_questions" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p></blockquote><h1 id="3696" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Summary</h1><p id="b3df" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">In this article, we’ve explored using the CrewAI multi-agent framework to create a solution for writing documentation based on tables and answering related questions.</p><p id="2fc0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Given the extensive functionality we’ve utilised, it’s time to summarise the strengths and weaknesses of this framework.</p><p id="7300" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Overall, I find <a class="af on" href="https://www.crewai.com/" rel="noopener ugc nofollow" target="_blank">CrewAI</a> to be an incredibly useful framework for multi-agent systems:</p><ul class=""><li id="0feb" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">It’s straightforward, and you can build your first prototype quickly.</li><li id="4550" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">Its flexibility allows to solve quite sophisticated business problems.</li><li id="5fb9" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">It encourages good practices like role-playing.</li><li id="db8b" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">It provides many handy tools out of the box, such as RAG and a website parser.</li><li id="ffb0" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">The support of different types of memory enhances the agents’ collaboration.</li><li id="b889" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">Built-in guardrails help prevent agents from getting stuck in repetitive loops.</li></ul><p id="608d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">However, there are areas that could be improved:</p><ul class=""><li id="bb92" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">While the framework is simple and easy to use, it’s not very customisable. For instance, you currently can’t create your own LLM manager to orchestrate the processes.</li><li id="db60" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">Sometimes, it’s quite challenging to get the full detailed information from the documentation. For example, it’s clear that CrewAI implemented some guardrails to prevent repetitive function calls, but the documentation doesn’t fully explain how it works.</li><li id="eaf5" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">Another improvement area is transparency. I like to understand how frameworks work under the hood. For example, in Langchain, you can use <code class="cx pz qa qb pq b">langchain.debug = True</code> to see all the LLM calls. However, I haven’t figured out how to get the same level of detail with CrewAI.</li><li id="8a95" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">The full support for the local models would be a great addition, as the current implementation either lacks some features or is difficult to get working properly.</li></ul><p id="f870" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The domain and tools for LLMs are evolving rapidly, so I’m hopeful that we’ll see a lot of progress in the near future.</p><blockquote class="qc qd qe"><p id="f2af" class="nj nk qf nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Thank you a lot for reading this article. I hope this article was insightful for you. If you have any follow-up questions or comments, please leave them in the comments section.</p></blockquote><h1 id="ca86" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Reference</h1><p id="d099" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">This article is inspired by the <a class="af on" href="https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/" rel="noopener ugc nofollow" target="_blank">“Multi AI Agent Systems with CrewAI”</a> short course from DeepLearning.AI.</p></div></div></div></div>    
</body>
</html>