- en: Mastering Marketing Mix Modelling In Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mastering-marketing-mix-modelling-in-python-7bbfe31360f9?source=collection_archive---------1-----------------------#2024-09-26](https://towardsdatascience.com/mastering-marketing-mix-modelling-in-python-7bbfe31360f9?source=collection_archive---------1-----------------------#2024-09-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Part 1 of a hands-on guide to help you master MMM in **pymc**
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@raz1470?source=post_page---byline--7bbfe31360f9--------------------------------)[![Ryan
    O''Sullivan](../Images/7cd161d38d67d2c0b7da2d8f3e7d33fe.png)](https://medium.com/@raz1470?source=post_page---byline--7bbfe31360f9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7bbfe31360f9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7bbfe31360f9--------------------------------)
    [Ryan O''Sullivan](https://medium.com/@raz1470?source=post_page---byline--7bbfe31360f9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7bbfe31360f9--------------------------------)
    ·21 min read·Sep 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/963728066476cce1befa283fb3499efc.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: What is this series about?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to part 1 of my series on marketing mix modeling (MMM), a hands-on guide
    to help you master MMM. Throughout this series, we’ll cover key topics such as
    model training, validation, calibration and budget optimisation, all using the
    powerful **pymc-marketing** python package. Whether you’re new to MMM or looking
    to sharpen your skills, this series will equip you with practical tools and insights
    to improve your marketing strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this article, we’ll start by providing some background on Bayesian MMM,
    including the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What open source packages can we use?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is Bayesian MMM?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are Bayesian priors?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are the default priors in **pymc-marketing** sensible?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will then move on to a walkthrough in Python using the **pymc-marketing**
    package, diving deep into the following areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Simulating data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validating the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameter recovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The full notebook can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/raz1470/pymc_marketing/blob/main/notebooks/1.%20training%20marketing%20mix%20models%20%28MMM%29%20in%20python.ipynb?source=post_page-----7bbfe31360f9--------------------------------)
    [## pymc_marketing/notebooks/1\. training marketing mix models (MMM) in python.ipynb
    at main ·…'
  prefs: []
  type: TYPE_NORMAL
- en: A demo of the MMM package pymc_marketing. Contribute to raz1470/pymc_marketing
    development by creating an account on…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/raz1470/pymc_marketing/blob/main/notebooks/1.%20training%20marketing%20mix%20models%20%28MMM%29%20in%20python.ipynb?source=post_page-----7bbfe31360f9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 1.0 MMM Background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s begin with a brief overview of Marketing Mix Modeling (MMM). We’ll explore
    various open-source packages available for implementation and delve into the principles
    of Bayesian MMM, including the concept of priors. Finally, we’ll evaluate the
    default priors used in **pymc-marketing** to gauge their suitability and effectiveness..
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 What open source packages can we use?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When it comes to MMM, there are several open-source packages we can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/52f6723ecd7065016292c73060be7eba.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several compelling reasons to focus on **pymc-marketing** in this
    series:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Python Compatibility**: Unlike Robyn, which is available only in R, pymc-marketing
    caters to a broader audience who prefer working in Python.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Current Availability**: Meridian has not yet been released (as of September
    23, 2024), making pymc-marketing a more accessible option right now.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Future Considerations**: LightweightMMM is set to be decommissioned once
    Meridian is launched, further solidifying the need for a reliable alternative.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Active Development**: pymc-marketing is continuously enhanced by its extensive
    community of contributors, ensuring it remains up-to-date with new features and
    improvements.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can check out the pymc-marketing package here, they offer some great notebook
    to illustrate some of the packages functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[## How-to - pymc-marketing 0.9.0 documentation'
  prefs: []
  type: TYPE_NORMAL
- en: Here you will find a collection of examples and how-to guides for using PyMC-Marketing
    MMM and CLV models.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.pymc-marketing.io](https://www.pymc-marketing.io/en/stable/notebooks/index.html?source=post_page-----7bbfe31360f9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 What is Bayesian MMM?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You’ll notice that 3 out of 4 of the packages highlighted above take a Bayesian
    approach. So let’s take a bit of time to understand what Bayesian MMM looks like!
    For beginners, Bayesian analysis is a bit of a rabbit hole but we can break it
    down into 5 key points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fe739acf49ab2eca4bf2ebf2e8a8805b.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: '**Bayes’ Theorem** — In Bayesian MMM, Bayes’ theorem is used to update our
    beliefs about how marketing channels impact sales as we gather new data. For example,
    if we have some initial belief about how much TV advertising affects sales, Bayes’
    theorem allows us to refine that belief after seeing actual data on sales and
    TV ad spend.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**P(θ)** — **Priors** represent our initial beliefs about the parameters in
    the model, such as the effect of TV spend on sales. For example, if we ran a geo-lift
    test which estimated that TV ads increase sales by 5%, we might set a prior based
    on that estimate.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**P(Data | θ)** — **The likelihood function,** which captures the probability
    of observing the sales data given specific levels of marketing inputs. For example,
    if you spent £100,000 on social media and saw a corresponding sales increase,
    the likelihood tells us how probable that sales jump is based on the assumed effect
    of social media.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**P(θ | Data)** — **The posterior** is what we ultimately care about in Bayesian
    MMM — it’s our updated belief about how different marketing channels impact sales
    after combining the data and our prior assumptions. For instance, after observing
    new sales data, our initial belief that TV ads drive a 5% increase in sales might
    be adjusted to a more refined estimate, like 4.7%.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Sampling** — Since Bayesian MMM involves complex models with multiple parameters
    (e.g. adstock, saturation, marketing channel effects, control effects etc.) computing
    the posterior directly can be difficult. MCMC (Markov Chain Monte Carlo) allows
    us to approximate the posterior by generating samples from the distribution of
    each parameter. This approach is particularly helpful when dealing with models
    that would be hard to solve analytically.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1.3 What are Bayesian priors?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Bayesian priors are supplied as probability distributions. Instead of assigning
    a fixed value to a parameter, we provide a range of potential values, along with
    the likelihood of each value being the true one. Common distributions used for
    priors include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Normal:** For parameters where we expect values to cluster around a mean.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Half-Normal**: For parameters where we want to enforce positivity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Beta**: For parameters which are constrained between 0 and 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gamma**: For parameters that are positive and skewed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may hear the term informative priors. Ideally, we supply these based on
    expert knowledge or randomized experiments. Informative priors reflect strong
    beliefs about the parameter values. However, when this is not feasible, we can
    use non-informative priors, which spread probability across a wide range of values.
    Non-informative priors allow the data to dominate the posterior, preventing prior
    assumptions from overly influencing the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: 1.4 Are the default priors in pymc-marketing sensible?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using the **pymc-marketing** package, the default priors are designed to
    be weakly informative, meaning they provide broad guidance without being overly
    specific. Instead of being overly specific, they guide the model without restricting
    it too much. This balance ensures the priors guide the model without overshadowing
    the data..
  prefs: []
  type: TYPE_NORMAL
- en: To build reliable models, it’s crucial to understand the default priors rather
    than use them blindly. In the following sections, we will examine the various
    priors used in **pymc-marketin**g and explain why the default choices are sensible
    for marketing mix models.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can start by using the code below to inspect the default priors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9400cb34fdda8bf521e61419a8d59c17.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'Above I have printed out a dictionary containing the 7 default priors — Let’s
    start by briefly understanding what each one is:'
  prefs: []
  type: TYPE_NORMAL
- en: '**intercept** — The baseline level of sales or target variable in the absence
    of any marketing spend or other variables. It sets the starting point for the
    model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**likelihood** — When you increase the focus on the likelihood, the model relies
    more heavily on the observed data and less on the priors. This means the model
    will be more data-driven, allowing the observed outcomes to have a stronger influence
    on the parameter estimates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gamma_control** — Control variables that account for external factors, such
    as macroeconomic conditions, holidays, or other non-marketing variables that might
    influence sales.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gamma_fourier** — Fourier terms used to model seasonality in the data, capturing
    recurring patterns or cycles in sales.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**adstock_alpha** — Controls the adstock effect, determining how much the impact
    of marketing spend decays over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**saturation_lamda** — Defines the steepness of the saturation curve, determining
    how quickly diminishing returns set in as marketing spend increases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**saturation_beta** — The marketing spend coefficient, which measures the direct
    effect of marketing spend on the target variable (e.g. sales).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next we are going to focus on gaining a more in depth understanding of parameters
    for marketing and control variables.
  prefs: []
  type: TYPE_NORMAL
- en: 1.4.1 Adstock alpha
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adstock reflects the idea that the influence of a marketing activity is delayed
    and builds up over time. Theadstock alpha (the decay rate)controls how quickly
    the effect diminishes over time, determining how long the impact of the marketing
    activity continues to influence sales.
  prefs: []
  type: TYPE_NORMAL
- en: 'A beta distribution is used as a prior for adstock alpha. Let’s first visualise
    the beta distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e3671fd16838d7163f2631f2d0ded101.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: We typically constrain adstock alpha values between 0 and 1, making the beta
    distribution a sensible choice. Specifically, using a beta(1, 3) prior for adstock
    alpha reflects the belief that, in most cases, the decay rate should be relatively
    high, meaning the effect of marketing activities wears off quickly.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build further intuition, we can visualise the effect of different adstock
    alpha values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/bdaf927c95b02e76d85e9809154dbf5c.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Low values of alpha have little impact and are suitable for channels which have
    a direct response e.g. paid social performance ads with a direct call to action
    aimed at prospects who have already visited your website.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Higher values of alpha have a stronger impact and are suitable for channels
    which have a longer term effect e.g. brand building videos with no direct call
    to action aimed at a broad range of prospects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1.4.2 Saturation lamda
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we increase marketing spend, it’s incremental impact of sales slowly starts
    to reduce — This is known as saturation. Saturation lamda controls the steepness
    of the saturation curve, determining how quickly diminishing returns set in.
  prefs: []
  type: TYPE_NORMAL
- en: 'A gamma distribution is used as a prior for saturation lambda. Let’s start
    by understanding what a gamma distribution looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/479cf4d94568e019efdd618fce3ed7df.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'At first glance it can be difficult to understand why the gamma distribution
    is a sensible choice of prior but plotting the impact of different lamda values
    helps clarify its appropriateness::'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5609476231ba26040181014d24f8e204.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: A lamda value of 1 keeps the relationship linear.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we increase lamda, the steepness of the saturation curve increases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From the chart we hopefully agree that it seems unlikely to have a saturation
    much steeper than what we see when the lamda value is 8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1.4.3 Saturation beta
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Saturation beta corresponds to the marketing channel coefficient, measuring
    the impact of marketing spend.
  prefs: []
  type: TYPE_NORMAL
- en: The half-normal prior is used as it enforces positivity which is a very reasonable
    assumption e.g. marketing shouldn’t have a negative effect. When sigma is set
    as 2, it tends towards low values. This helps regularize the coefficients, pulling
    them towards lower values unless there is strong evidence in the data that a particular
    channel has a significant impact.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/eccd7a85e2d0c231a137f92cad24fc2c.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Remember that both the marketing and target variables are scaled (ranging from
    0 to 1), so the beta prior must be in this scaled space.
  prefs: []
  type: TYPE_NORMAL
- en: 1.4.4 Gamma control
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The gamma control parameter is the coefficient for the control variables that
    account for external factors, such as macroeconomic conditions, holidays, or other
    non-marketing variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'A normal distribution is used which allows for both positive and negative effects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/707d7b29c3f5727586082ecd0a4dfb96.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Control variables are standardized, with values ranging from -1 to 1, so the
    gamma control prior must be in this scaled space.
  prefs: []
  type: TYPE_NORMAL
- en: 2.0 Python Walkthrough
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we have covered some of the theory, let’s but some of it into practice!
    In this walkthrough we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Simulating data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validating the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameter recovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The aim is to create some realistic training data where we set the parameters
    ourselves (adstock, saturation, beta etc.), train and validate a model utilising
    the pymc-marketing package, and then assess how well our model did at recovering
    the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to real world MMM data, you won’t know the parameters, but this
    exercise of parameter recovery is a great way to learn and get confident in MMM.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Simulating data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by simulating some data to train a model. The benefit of this approach
    is that we can set the parameters ourselves, which allows us to conduct a parameter
    recovery exercise to test how well our model performs!
  prefs: []
  type: TYPE_NORMAL
- en: 'The function below can be used to simulate some data with the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: A trend component with some growth.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A seasonal component with oscillation around 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The trend and seasonal component are used to create demand.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A proxy for demand is created which will be available for the model (demand
    will be an unobserved confounder).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Demand is a key driver of sales.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each marketing channel also contributes to sales, the marketing spend is correlated
    with demand and the appropriate transformation are applied (scaling, adstock,
    saturation).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now call the data generator function with some parameters which are
    realistic:'
  prefs: []
  type: TYPE_NORMAL
- en: 3 years of weekly data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3 channels from different parts of the marketing funnel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each channel has a different adstock, saturation and beta parameter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7ca303d078ee53b448bb1ee9b57a01a5.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Before we move onto training a model, let’s spend some time understanding the
    data we have generated.
  prefs: []
  type: TYPE_NORMAL
- en: The intuition behind how we have derived demand is that there has been an increasing
    trend for organic growth, with the addition of a high and low demand period each
    year.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/18d3746085c06c6c3d5c76a0b81d6cfc.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: We created a proxy for demand to be used as a control variable in the model.
    The idea here is that, in reality demand is an unobserved confounder, but we can
    sometimes find proxies for demand. One example of this is google search trends
    data for the product you are selling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/bb3c5867096a652e29c78489641372fc.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Spend follows the same trend for each marketing channel but the random noise
    we added should allow the model to unpick how each one is contributing to sales.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2d95c270ebfb611c102827cb886fa0c2.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: We applied two transformation to our marketing data, adstock and saturation.
    Below we can look at the effect of the different parameters we used for each channels
    saturation, with search having the steepest saturation and TV almost being linear.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f29c738a4a8ac910bf98e1128814e3d0.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Below we can see that our variables are highly correlated, something that is
    very common in MMM data due to marketing teams spending more in peak periods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/51b7a970f682018e63613dfd3777be03.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: And finally let’s take a look at sales — Remember our aim is to understand how
    marketing has contributed to sales.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5279c48b359969074e3dd862faba5bbf.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good understanding of the data generating process, let’s
    dive into training the model!
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Training the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It’s now time to move on to training the model. To begin with we need to prepare
    the training data by:'
  prefs: []
  type: TYPE_NORMAL
- en: Splitting data into features and target.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating indices for train and out-of-time slices — The out-of-time slice will
    help us validate our model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we initiate the MMM class. A major challenge in MMM is the fact that the
    ratio of parameters to training observations is high. One way we can mitigate
    this is by being pragmatic about the choice of transformations:'
  prefs: []
  type: TYPE_NORMAL
- en: We select geometric adstock which has 1 parameter (per channel) vs 2 compared
    to using weibull adstock.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We select logistic saturation which has 1 parameter (per channel) vs 2 compared
    to using hill saturation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use a proxy for demand and decide not to include a seasonal component or
    time varying trend which further reduces our parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We decide not to include time varying media parameters on the basis that, although
    it is true that performance varies over time, we ultimately want a response curve
    to help us optimise budgets and taking the average performance over the training
    dataset is a good way to do this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To summarise my view here, the more complexity we add to the model, the more
    we manipulate our marketing spend variables to fit the data which in turn gives
    us a “better model” (e.g. high R-squared and low mean squared error). But this
    is at the risk of moving away from the true data generating process which in-turn
    will give us biased causal effect estimates.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9400cb34fdda8bf521e61419a8d59c17.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s fit the model using the train indices. I’ve passed some optional
    key-word-arguments, let’s spend a bit of time understanding what they do:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tune** — This sets the number of tuning steps for the sampler. During tuning,
    the sampler adjusts its parameters to efficiently explore the posterior distribution.
    These initial 1,000 samples are discarded and not used for inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chains** — This specifies the number of independent Markov chains to run.
    Running multiple chains helps assess convergence and provides a more robust sampling
    of the posterior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Draws** — This sets the number of samples to draw from the posterior distribution
    per chain, after tuning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Target accept** — This is the target acceptance rate for the sampler. It
    helps balance exploration of the parameter space with efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: I’d advise sticking with the defaults here, and only changing them if you get
    some issues in the next steps in terms of divergences.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Validating the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After fitting the model, the first step is to check for divergences. Divergences
    indicate potential problems with either the model or the sampling process. Although
    delving deeply into divergences is beyond the scope of this article due to its
    complexity, it’s essential to note their importance in model validation.
  prefs: []
  type: TYPE_NORMAL
- en: Below, we check the number of divergences in our model. A result of 0 divergences
    indicates a good start.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/777b7fb5560a8528aeecf40c563bc8a9.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'Next we can get a comprehensive summary of the MCMC sampling results. Let’s
    focus on the key ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '**mean** — The average value of the parameter across all samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hdi_3% and hdi_97%** — The lower and upper bounds of the 94% Highest Density
    Interval (HDI). A 94% HDI means that there’s a 94% probability that the true value
    of the parameter lies within this interval, based on the observed data and prior
    information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rhat** — Gelman-Rubin statistic, measuring convergence across chains. Values
    close to 1 (typically < 1.05) indicate good convergence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our R-hats are all very close to 1, which is expected given the absence of divergences.
    We will revisit the mean parameter values in the next section when we conduct
    a parameter recovery exercise.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a240798d58cfb3beced35bc3f44392ea.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we generate diagnostic plots that are crucial for assessing the quality
    of our MCMC sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Posterior Distribution (left):** Displays the value of each parameter throughout
    the MCMC sampling. Ideally, these should be smooth and unimodal, with all chains
    showing similar distributions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trace Plots (right):** Illustrate the value of each parameter over the MCMC
    sampling process. Any trends or slow drifts may indicate poor mixing or non-convergence,
    while chains that don’t overlap could suggest they are stuck in different modes
    of the posterior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at our diagnostic plots there are no red flags.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/562fd3b92302d6301106a3300701dbd8.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: For each parameter we have a distribution of possible values which reflects
    the uncertainty in the parameter estimates. For the next set of diagnostics, we
    first need to sample from the posterior. This allows us to make predictions, which
    we will do for the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We can begin the posterior predictive checking diagnostics by visually assessing
    whether the observed data falls within the predicted ranges. It appears that our
    model has performed well.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/943e1bad64df9f23b6c48ad2687d8052.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Next we can calculate residuals between the posterior predictive mean and the
    actual data. We can plot these residuals over time to check for patterns or autocorrelation.
    It looks like the residuals oscillate around 0 as expected.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/69861606a8e25d688f660ac44ea6b4b6.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: We can also check whether the residuals are normally distributed around 0\.
    Again, we pass this diagnostic test.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/68f34d1d28ffb345180286225eee8eba.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Finally it is good practice to assess how good our model is at predicting outside
    of the training sample. First of all we need to sample from the posterior again
    but this time using the out-of-time data. We can then plot the observed sales
    against the predicted.
  prefs: []
  type: TYPE_NORMAL
- en: Below we can see that the observed sales generally lie within the intervals
    and the model seems to do a good job.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d38d396327df862fae164b3befa5a31a.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Based on our findings in this section, we believe we have a robust model. In
    the next section let’s carry out a parameter recovery exercise to see how close
    to the ground truth parameters we were.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Parameter recovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the last section, we validated the model as we would in a real-life scenario.
    In this section, we will conduct a parameter recovery exercise: remember, we are
    only able to do this because we simulated the data ourselves and stored the true
    parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.1 Parameter recovery — Adstock
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s begin by comparing the posterior distribution of the adstock parameters
    to the ground truth values that we previously stored in the adstock_alphas list.
    The model performed reasonably well, achieving the correct rank order, and the
    true values consistently lie within the posterior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/892a862a32784f26e6da5ec8f9b39a90.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.2 Parameter recovery — Saturation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we examine saturation, the model performs excellently in recovering lambda
    for TV, but it does not do as well in recovering the true values for social and
    search, although the results are not disastrous.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/418eee6dc457947cc8bcc7aae7732297.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.3 Parameter recovery — Channel betas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regarding the channel beta parameters, the model achieves the correct rank ordering,
    but it overestimates values for all channels. In the next section, we will quantify
    this in terms of contribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5e5d4ae64fa29861fd4c5733a829deaa.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.4 Parameter recovery — Channel contribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we calculate the ground truth contribution for each channel. We will
    also calculate the contribution of demand: remember we included a proxy for demand
    not demand itself.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/036cd2b56ddb8b1aa652170a03e81b41.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s plot the contributions from the model. The rank ordering for demand,
    TV, social, and search is correct. However, TV, social, and search are all overestimated.
    This appears to be driven by the demand proxy not contributing as much as true
    demand.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9222b02732fff116d22c5b9cb5e18b7d.png)'
  prefs: []
  type: TYPE_IMG
- en: User generated image
  prefs: []
  type: TYPE_NORMAL
- en: Closing thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In section 2.3, we validated the model and concluded that it was robust. However,
    the parameter recovery exercise demonstrated that our model considerably overestimates
    the effect of marketing. This overestimation is driven by the confounding factor
    of demand. In a real-life scenario, it is not possible to run a parameter recovery
    exercise. So, how would you identify that your model’s marketing contributions
    are biased? And once identified, how would you address this issue? This leads
    us to our next article on calibrating models!
  prefs: []
  type: TYPE_NORMAL
- en: I hope you enjoyed this first instalment! Follow me if you want to continue
    this path towards mastering MMM — In the next article we will shift our focus
    to calibrating our models using informative priors from experiments.
  prefs: []
  type: TYPE_NORMAL
