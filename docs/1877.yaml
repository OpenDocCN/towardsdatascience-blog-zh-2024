- en: 8 Practical Prompt Engineering Tips for Better LLM Apps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8ä¸ªå®ç”¨çš„æç¤ºå·¥ç¨‹æŠ€å·§ï¼Œå¸®åŠ©æå‡LLMåº”ç”¨
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/8-practical-prompt-engineering-tips-for-better-llm-apps-430eef9b0950?source=collection_archive---------4-----------------------#2024-08-01](https://towardsdatascience.com/8-practical-prompt-engineering-tips-for-better-llm-apps-430eef9b0950?source=collection_archive---------4-----------------------#2024-08-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/8-practical-prompt-engineering-tips-for-better-llm-apps-430eef9b0950?source=collection_archive---------4-----------------------#2024-08-01](https://towardsdatascience.com/8-practical-prompt-engineering-tips-for-better-llm-apps-430eef9b0950?source=collection_archive---------4-----------------------#2024-08-01)
- en: '[](https://medium.com/@almogbaku?source=post_page---byline--430eef9b0950--------------------------------)[![Almog
    Baku](../Images/3ac36986f6ca0ba56c8edced6ec7dd07.png)](https://medium.com/@almogbaku?source=post_page---byline--430eef9b0950--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--430eef9b0950--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--430eef9b0950--------------------------------)
    [Almog Baku](https://medium.com/@almogbaku?source=post_page---byline--430eef9b0950--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@almogbaku?source=post_page---byline--430eef9b0950--------------------------------)[![Almog
    Baku](../Images/3ac36986f6ca0ba56c8edced6ec7dd07.png)](https://medium.com/@almogbaku?source=post_page---byline--430eef9b0950--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--430eef9b0950--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--430eef9b0950--------------------------------)
    [Almog Baku](https://medium.com/@almogbaku?source=post_page---byline--430eef9b0950--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--430eef9b0950--------------------------------)
    Â·9 min readÂ·Aug 1, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--430eef9b0950--------------------------------)
    Â·9åˆ†é’Ÿé˜…è¯»Â·2024å¹´8æœˆ1æ—¥
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: â¤Prompt engineering is undoubtedly the most critical skill in developing an
    LLM-native application, as crafting the right prompts can significantly impact
    your applicationâ€™s performance and reliability.â¤
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºå·¥ç¨‹æ— ç–‘æ˜¯å¼€å‘LLMæœ¬åœ°åº”ç”¨ç¨‹åºä¸­æœ€å…³é”®çš„æŠ€èƒ½ï¼Œå› ä¸ºåˆ¶å®šæ­£ç¡®çš„æç¤ºå¯ä»¥æ˜¾è‘—å½±å“åº”ç”¨ç¨‹åºçš„æ€§èƒ½å’Œå¯é æ€§ã€‚
- en: Over the past two years, Iâ€™ve been helping organizations build and deploy dozens
    of LLM applications for real-world use cases. â¤â¤This experience gave me valuable
    insights into effective prompting techniques. â¤
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿‡å»çš„ä¸¤å¹´é‡Œï¼Œæˆ‘ä¸€ç›´åœ¨å¸®åŠ©ç»„ç»‡æ„å»ºå’Œéƒ¨ç½²æ•°åä¸ªç”¨äºå®é™…æ¡ˆä¾‹çš„LLMåº”ç”¨ç¨‹åºã€‚è¿™æ®µç»å†è®©æˆ‘å¯¹æœ‰æ•ˆçš„æç¤ºæŠ€å·§æœ‰äº†å®è´µçš„æ´å¯Ÿã€‚
- en: This article, informed by the [LLM Triangle Principles](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e),
    presents **eight practical tips** for prompt engineering to level up your LLM
    prompting game.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡åŸºäº[LLMä¸‰è§’åŸç†](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)ä»‹ç»äº†**å…«ä¸ªå®ç”¨çš„æç¤º**ï¼Œå¸®åŠ©æå‡ä½ çš„LLMæç¤ºå·¥ç¨‹æŠ€èƒ½ã€‚
- en: â€œLLM-Native apps are 10% sophisticated model, and 90% experimenting data-driven
    engineering work.â€
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œLLMæœ¬åœ°åº”ç”¨ç¨‹åºæ˜¯10%çš„å¤æ‚æ¨¡å‹å’Œ90%çš„å®éªŒæ€§æ•°æ®é©±åŠ¨å·¥ç¨‹å·¥ä½œã€‚â€
- en: '![](../Images/605d5e3a9c4a90b2659fc5bd57d9585e.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/605d5e3a9c4a90b2659fc5bd57d9585e.png)'
- en: (Generated with Midjourney)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆç”±Midjourneyç”Ÿæˆï¼‰
- en: Throughout this article, we'll use the â€œLanding Page Generatorâ€ example to demonstrate
    how each tip can be applied to enhance a real-world LLM application.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨â€œç™»å½•é¡µé¢ç”Ÿæˆå™¨â€ç¤ºä¾‹æ¥æ¼”ç¤ºå¦‚ä½•åº”ç”¨æ¯ä¸ªæŠ€å·§ï¼Œä»¥å¢å¼ºå®é™…çš„LLMåº”ç”¨ç¨‹åºã€‚
- en: You can also check out [the full script of Landing Page Generator example](https://gist.github.com/AlmogBaku/5de026a355f9ef8984fa6a5bebd8f51f),
    for a complete lookout.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥æŸ¥çœ‹[ç™»å½•é¡µé¢ç”Ÿæˆå™¨ç¤ºä¾‹çš„å®Œæ•´è„šæœ¬](https://gist.github.com/AlmogBaku/5de026a355f9ef8984fa6a5bebd8f51f)ï¼Œä»¥ä¾¿å…¨é¢äº†è§£ã€‚
- en: '**Note:** This is a simplified, non-production example created to illustrate
    these tips. The code and prompts are intentionally basic to highlight the concepts
    discussed.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š** è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„éç”Ÿäº§ç¤ºä¾‹ï¼Œæ—¨åœ¨è¯´æ˜è¿™äº›æŠ€å·§ã€‚ä»£ç å’Œæç¤ºæ•…æ„ç®€åŒ–ï¼Œä»¥çªå‡ºè®¨è®ºçš„æ¦‚å¿µã€‚'
- en: 1\. Define Clear Cognitive Process Boundaries
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. å®šä¹‰æ˜ç¡®çš„è®¤çŸ¥è¿‡ç¨‹è¾¹ç•Œ
- en: 'Start by defining the objective for each agent or prompt. Stick to **one cognitive
    process type per agent**, such as: conceptualizing a landing page, selecting components,
    or generating content for specific sections.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å®šä¹‰æ¯ä¸ªä»£ç†æˆ–æç¤ºçš„ç›®æ ‡å¼€å§‹ã€‚åšæŒ**æ¯ä¸ªä»£ç†ä¸€ä¸ªè®¤çŸ¥è¿‡ç¨‹ç±»å‹**ï¼Œä¾‹å¦‚ï¼šæ„æ€ä¸€ä¸ªç™»å½•é¡µé¢ã€é€‰æ‹©ç»„ä»¶æˆ–ä¸ºç‰¹å®šéƒ¨åˆ†ç”Ÿæˆå†…å®¹ã€‚
- en: Having clear boundaries maintains focus and clarity in your LLM interactions,
    aligning with the [*Engineering Techniques*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#3221)
    apex of the [LLM Triangle Principle](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#3221).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹¥æœ‰æ˜ç¡®çš„è¾¹ç•Œæœ‰åŠ©äºä¿æŒLLMäº¤äº’ä¸­çš„ä¸“æ³¨å’Œæ¸…æ™°ï¼Œè¿™ä¸[LLMä¸‰è§’åŸåˆ™](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#3221)çš„[*å·¥ç¨‹æŠ€æœ¯*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#3221)é¡¶ç«¯ä¿æŒä¸€è‡´ã€‚
- en: '*â€œ*Each step in our flow is a standalone process that must occur to achieve
    our task.*â€*'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*â€œ*æˆ‘ä»¬æµç¨‹ä¸­çš„æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„è¿‡ç¨‹ï¼Œå¿…é¡»å®Œæˆæ‰èƒ½å®ç°æˆ‘ä»¬çš„ä»»åŠ¡ã€‚â€* '
- en: 'For example, avoid combining different cognitive processes in the same prompt,
    which might yield suboptimal results. Instead, break these into separate, focused
    agents:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œé¿å…åœ¨åŒä¸€æç¤ºä¸­ç»„åˆä¸åŒçš„è®¤çŸ¥è¿‡ç¨‹ï¼Œè¿™å¯èƒ½ä¼šäº§ç”Ÿä¸ç†æƒ³çš„ç»“æœã€‚ç›¸åï¼Œå¯ä»¥å°†è¿™äº›è¿‡ç¨‹åˆ†è§£æˆç‹¬ç«‹çš„ã€ä¸“æ³¨çš„ä»£ç†ï¼š
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: By defining *clear boundaries* for each agent, we can ensure that each step
    in our workflow is tailored to a specific mental task. This will **improve the
    quality of outputs** and make it **easier to debug** and refine.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¸ºæ¯ä¸ªä»£ç†å®šä¹‰*æ˜ç¡®çš„è¾¹ç•Œ*ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿å·¥ä½œæµä¸­çš„æ¯ä¸ªæ­¥éª¤éƒ½ä¸“é—¨é’ˆå¯¹ç‰¹å®šçš„å¿ƒç†ä»»åŠ¡ã€‚è¿™å°†**æé«˜è¾“å‡ºçš„è´¨é‡**ï¼Œå¹¶ä½¿**è°ƒè¯•**å’Œç²¾ç‚¼å˜å¾—**æ›´å®¹æ˜“**ã€‚
- en: 2\. Specify Input/Output Clearly
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. æ˜ç¡®æŒ‡å®šè¾“å…¥/è¾“å‡º
- en: Define **clear input and output** structures to reflect the objectives and create
    explicit data models. This practice touches on the [LLM Triangle Principles](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)'
    [*Engineering Techniques*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#3221)
    and [*Contextual Data*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#7b49)
    apexes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰**æ˜ç¡®çš„è¾“å…¥å’Œè¾“å‡º**ç»“æ„ï¼Œä»¥åæ˜ ç›®æ ‡å¹¶åˆ›å»ºæ˜ç¡®çš„æ•°æ®æ¨¡å‹ã€‚è¿™ä¸ªå®è·µæ¶‰åŠåˆ°[LLMä¸‰è§’åŸåˆ™](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e)çš„[*å·¥ç¨‹æŠ€æœ¯*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#3221)å’Œ[*ä¸Šä¸‹æ–‡æ•°æ®*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#7b49)çš„é¡¶ç«¯ã€‚
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: These [Pydantic](https://pydantic.dev/) models define the structure of our **input
    and output data** and define clear boundaries and expectations for the agent.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›[Pydantic](https://pydantic.dev/)æ¨¡å‹å®šä¹‰äº†æˆ‘ä»¬**è¾“å…¥å’Œè¾“å‡ºæ•°æ®**çš„ç»“æ„ï¼Œå¹¶ä¸ºä»£ç†å®šä¹‰äº†æ˜ç¡®çš„è¾¹ç•Œå’ŒæœŸæœ›ã€‚
- en: 3\. Implement Guardrails
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. å®æ–½é˜²æŠ¤æªæ–½
- en: Place validations to ensure the quality and moderation of the LLM outputs. [Pydantic](https://pydantic.dev/)
    is excellent for implementing these guardrails, and we can utilize its native
    features for that.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¾ç½®éªŒè¯ä»¥ç¡®ä¿LLMè¾“å‡ºçš„è´¨é‡å’Œé€‚åº¦ã€‚[Pydantic](https://pydantic.dev/)éå¸¸é€‚åˆå®ç°è¿™äº›é˜²æŠ¤æªæ–½ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å…¶åŸç”ŸåŠŸèƒ½æ¥å®ç°ã€‚
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In this example, ensuring the quality of our application by defining two types
    of validators:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œé€šè¿‡å®šä¹‰ä¸¤ç§ç±»å‹çš„éªŒè¯å™¨æ¥ç¡®ä¿æˆ‘ä»¬åº”ç”¨ç¨‹åºçš„è´¨é‡ï¼š
- en: '**Using Pydanitcâ€™s** `**Field**` to define simple validations, such as a minimum
    of 2 tone/style attributes, or a minimum of 50 characters in the narrative'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨Pydanticçš„** `**Field**` æ¥å®šä¹‰ç®€å•çš„éªŒè¯ï¼Œä¾‹å¦‚è‡³å°‘åŒ…å«2ä¸ªè¯­è°ƒ/é£æ ¼å±æ€§ï¼Œæˆ–å™è¿°è‡³å°‘åŒ…å«50ä¸ªå­—ç¬¦'
- en: '**Using a custom** `**field_validator**`that ensures the generated narrative
    is complying with our content moderation policy (using AI)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨è‡ªå®šä¹‰çš„** `**field_validator**` æ¥ç¡®ä¿ç”Ÿæˆçš„å™è¿°ç¬¦åˆæˆ‘ä»¬çš„å†…å®¹å®¡æŸ¥æ”¿ç­–ï¼ˆä½¿ç”¨AIï¼‰ã€‚'
- en: 4\. Align with Human Cognitive Processes
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. ä¸äººç±»è®¤çŸ¥è¿‡ç¨‹å¯¹é½
- en: Structure your LLM workflow to mimic human cognitive processes by breaking down
    complex tasks into smaller steps that follow a logical sequence. To do that, follow
    the *SOP (Standard Operating Procedure)* guiding principle of the [LLM Triangle
    Principles](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#be9a).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°†å¤æ‚çš„ä»»åŠ¡åˆ†è§£ä¸ºéµå¾ªé€»è¾‘é¡ºåºçš„å°æ­¥éª¤ï¼Œæ¥æ„å»ºæ¨¡æ‹Ÿäººç±»è®¤çŸ¥è¿‡ç¨‹çš„LLMå·¥ä½œæµã€‚ä¸ºæ­¤ï¼Œéµå¾ª[LLMä¸‰è§’åŸåˆ™](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#be9a)ä¸­çš„*SOPï¼ˆæ ‡å‡†æ“ä½œç¨‹åºï¼‰*æŒ‡å¯¼åŸåˆ™ã€‚
- en: '*â€œWithout an SOP, even the most powerful LLM will fail to deliver consistently
    high-quality results.â€*'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*â€œæ²¡æœ‰æ ‡å‡†æ“ä½œç¨‹åºï¼ˆSOPï¼‰ï¼Œå³ä½¿æ˜¯æœ€å¼ºå¤§çš„LLMä¹Ÿæ— æ³• consistently äº¤ä»˜ä¸€è‡´çš„é«˜è´¨é‡ç»“æœã€‚â€*'
- en: 4.1 Capture hidden implicit cognition jumps
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 æ•æ‰éšè—çš„éšæ€§è®¤çŸ¥è·³è·ƒ
- en: In our example, we expect the model to return `LandingPageConcept` as a result.
    By asking the model to output certain fields, we guide the LLM similar to how
    a human marketer or designer might approach creating a landing page concept.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœŸæœ›æ¨¡å‹è¿”å›`LandingPageConcept`ä½œä¸ºç»“æœã€‚é€šè¿‡è¦æ±‚æ¨¡å‹è¾“å‡ºæŸäº›å­—æ®µï¼Œæˆ‘ä»¬æŒ‡å¯¼LLMï¼Œå°±åƒäººç±»å¸‚åœºè¥é”€äººå‘˜æˆ–è®¾è®¡å¸ˆåœ¨åˆ›å»ºç€é™†é¡µæ¦‚å¿µæ—¶å¯èƒ½é‡‡å–çš„æ–¹å¼ä¸€æ ·ã€‚
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `LandingPageConcept` structure encourages the LLM to follow a human-like
    reasoning process, mirroring the *subtle mental leaps* ([implicit cognition "jumps"](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#f8c9))
    that an expert would make instinctively, just as we modeled in our SOP.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`LandingPageConcept` ç»“æ„é¼“åŠ± LLM è·Ÿéšç±»ä¼¼äººç±»çš„æ¨ç†è¿‡ç¨‹ï¼Œæ¨¡ä»¿ä¸“å®¶åœ¨ç›´è§‰ä¸Šæ‰€åšçš„ *å¾®å¦™å¿ƒç†è·ƒè¿*ï¼ˆ[éšæ€§è®¤çŸ¥â€œè·³è·ƒâ€](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#f8c9)ï¼‰ï¼Œå°±åƒæˆ‘ä»¬åœ¨æ ‡å‡†æ“ä½œç¨‹åºï¼ˆSOPï¼‰ä¸­æ‰€å»ºæ¨¡çš„é‚£æ ·ã€‚'
- en: 4.2 Breaking complex processes into multiple steps/agents
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 å°†å¤æ‚çš„è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤/ä»£ç†
- en: 'For complex tasks, break the process down into various steps, each handled
    by a separate LLM call or *"agent"*:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œå°†è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤ç”±å•ç‹¬çš„ LLM è°ƒç”¨æˆ– *"ä»£ç†"* å¤„ç†ï¼š
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/7faf32bd345890ba949330bc1e8ad532.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7faf32bd345890ba949330bc1e8ad532.png)'
- en: Illustration of the multi-agent process code. (Image by author)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šä»£ç†è¿‡ç¨‹ä»£ç çš„ç¤ºæ„å›¾ã€‚ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰
- en: This multi-agent approach aligns with how humans tackle complex problems â€” by
    breaking them into smaller parts.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§å¤šä»£ç†æ–¹æ³•ä¸äººç±»è§£å†³å¤æ‚é—®é¢˜çš„æ–¹å¼ä¸€è‡´â€”â€”é€šè¿‡å°†é—®é¢˜åˆ†è§£æˆæ›´å°çš„éƒ¨åˆ†ã€‚
- en: 5\. Leverage Structured Data (YAML)
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. åˆ©ç”¨ç»“æ„åŒ–æ•°æ®ï¼ˆYAMLï¼‰
- en: '[YAML](https://en.wikipedia.org/wiki/YAML) is a *popular* human-friendly data
    serialization format. Itâ€™s designed to be easily readable by humans while still
    being easy for machines to parse â€” which makes it classic for LLM usage.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[YAML](https://en.wikipedia.org/wiki/YAML) æ˜¯ä¸€ç§ *æµè¡Œçš„* äººç±»å‹å¥½çš„æ•°æ®åºåˆ—åŒ–æ ¼å¼ã€‚å®ƒè®¾è®¡ä¸Šæ—¢ä¾¿äºäººç±»é˜…è¯»ï¼Œåˆæ˜“äºæœºå™¨è§£æâ€”â€”è¿™ä½¿å¾—å®ƒæˆä¸º
    LLM ä½¿ç”¨ä¸­çš„ç»å…¸é€‰æ‹©ã€‚'
- en: I found YAML is particularly effective for LLM interactions and yields much
    better results across different models. It focuses the token processing on valuable
    content rather than syntax.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å‘ç° YAML åœ¨ LLM äº¤äº’ä¸­ç‰¹åˆ«æœ‰æ•ˆï¼Œå¹¶ä¸”åœ¨ä¸åŒæ¨¡å‹ä¹‹é—´èƒ½äº§ç”Ÿæ›´å¥½çš„ç»“æœã€‚å®ƒå°†ä»¤ç‰Œå¤„ç†é›†ä¸­åœ¨æœ‰ä»·å€¼çš„å†…å®¹ä¸Šï¼Œè€Œéè¯­æ³•ã€‚
- en: YAML is also much more portable across different LLM providers and allows you
    to maintain a structured output format.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: YAML åœ¨ä¸åŒçš„ LLM æä¾›è€…ä¹‹é—´å…·æœ‰æ›´å¼ºçš„å¯ç§»æ¤æ€§ï¼Œå…è®¸ä½ ä¿æŒç»“æ„åŒ–çš„è¾“å‡ºæ ¼å¼ã€‚
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Notice how we're using few-shot examples to *"show, don't tell"* the expected
    YAML format. This approach is more effective than explicit instructions in prompt
    for the output structure.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨å°‘æ ·æœ¬ç¤ºä¾‹æ¥ *â€œé€šè¿‡å±•ç¤ºï¼Œè€Œä¸æ˜¯å‘Šè¯‰â€* é¢„æœŸçš„ YAML æ ¼å¼ã€‚ä¸æç¤ºä¸­æ˜ç¡®çš„è¾“å‡ºç»“æ„æŒ‡ä»¤ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•æ›´ä¸ºæœ‰æ•ˆã€‚
- en: 6\. Craft Your Contextual Data
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6. ç²¾å¿ƒè®¾è®¡ä½ çš„ä¸Šä¸‹æ–‡æ•°æ®
- en: Carefully consider how to model and present data to the LLM. This tip is central
    to the [*Contextual Data*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#7b49)
    apex of the [LLM Triangle Principles](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#7b49).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä»”ç»†è€ƒè™‘å¦‚ä½•å°†æ•°æ®å»ºæ¨¡å¹¶å‘ˆç°ç»™ LLMã€‚è¿™ä¸€æç¤ºå¯¹äº [*ä¸Šä¸‹æ–‡æ•°æ®*](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#7b49)
    æ˜¯ [LLM ä¸‰è§’åŸç†](/the-llm-triangle-principles-to-architect-reliable-ai-apps-d3753dd8542e#7b49)
    é¡¶ç«¯çš„å…³é”®ã€‚
- en: '*â€œEven the most powerful model requires relevant and well-structured contextual
    data to shine.â€*'
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*â€œå³ä½¿æ˜¯æœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œä¹Ÿéœ€è¦ç›¸å…³ä¸”ç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡æ•°æ®æ‰èƒ½å‘æŒ¥ä½œç”¨ã€‚â€*'
- en: Donâ€™t throw away all the data you have on the model. Instead, inform the model
    with the pieces of information that are relevant to the objective you defined.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦ä¸¢å¼ƒä½ æ‰€æœ‰å…³äºæ¨¡å‹çš„æ•°æ®ï¼Œè€Œæ˜¯å°†ä¸ä½ å®šä¹‰çš„ç›®æ ‡ç›¸å…³çš„ä¿¡æ¯æä¾›ç»™æ¨¡å‹ã€‚
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this example, we're using [Jinja](https://jinja.palletsprojects.com/en/3.1.x/)
    templates to dynamically compose our prompts. This creates focused and relevant
    contexts for each LLM interaction elegantly.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ [Jinja](https://jinja.palletsprojects.com/en/3.1.x/) æ¨¡æ¿åŠ¨æ€ç”Ÿæˆæç¤ºã€‚è¿™ä¸ºæ¯æ¬¡
    LLM äº¤äº’ä¼˜é›…åœ°åˆ›å»ºäº†èšç„¦ä¸”ç›¸å…³çš„ä¸Šä¸‹æ–‡ã€‚
- en: â€œData fuels the engine of LLM-native applications. A strategic design of contextual
    data unlocks their true potential.â€
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œæ•°æ®ä¸º LLM åŸç”Ÿåº”ç”¨æä¾›åŠ¨åŠ›ã€‚æˆ˜ç•¥æ€§åœ°è®¾è®¡ä¸Šä¸‹æ–‡æ•°æ®èƒ½é‡Šæ”¾å®ƒä»¬çš„çœŸæ­£æ½œåŠ›ã€‚â€
- en: 6.1 Harness the power of few-shot learning
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6.1 åˆ©ç”¨å°‘æ ·æœ¬å­¦ä¹ çš„åŠ›é‡
- en: Few-shot learning is a must-have technique in prompt engineering. Providing
    the LLM with relevant examples significantly improves its understanding of the
    task.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å°‘æ ·æœ¬å­¦ä¹ æ˜¯æç¤ºå·¥ç¨‹ä¸­å¿…ä¸å¯å°‘çš„æŠ€æœ¯ã€‚å‘ LLM æä¾›ç›¸å…³çš„ç¤ºä¾‹å¯ä»¥æ˜¾è‘—æé«˜å…¶å¯¹ä»»åŠ¡çš„ç†è§£ã€‚
- en: Notice that in both approaches we discuss below, we **reuse our Pydantic models
    for the few-shots** â€” this trick ensures consistency between the examples and
    our actual task! Unfortunately, I learned it the hard way.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œåœ¨æˆ‘ä»¬ä¸‹é¢è®¨è®ºçš„ä¸¤ç§æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬ **é‡ç”¨æˆ‘ä»¬çš„ Pydantic æ¨¡å‹è¿›è¡Œå°‘æ ·æœ¬å­¦ä¹ **â€”â€”è¿™ä¸€æŠ€å·§ç¡®ä¿äº†ç¤ºä¾‹å’Œå®é™…ä»»åŠ¡ä¹‹é—´çš„ä¸€è‡´æ€§ï¼ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘æ˜¯é€šè¿‡è‰°éš¾çš„æ–¹å¼å­¦åˆ°è¿™ä¸€ç‚¹çš„ã€‚
- en: 6.1.1 Examples Few-Shot Learning
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1.1 ç¤ºä¾‹ å°‘æ ·æœ¬å­¦ä¹ 
- en: 'Take a look at the `few_shots` dictionary in section 5\. In this approach:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹çœ‹ç¬¬ 5 èŠ‚ä¸­çš„ `few_shots` å­—å…¸ã€‚åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼š
- en: Examples are added to the `messages` list as separate user and assistant messages,
    followed by the actual user input.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ä½œä¸ºå•ç‹¬çš„ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°`æ¶ˆæ¯`åˆ—è¡¨ä¸­ï¼Œéšåæ˜¯å®é™…çš„ç”¨æˆ·è¾“å…¥ã€‚
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: By placing the examples as `messages`, we align with the training methodology
    of instruction models. It allows the model to see multiple â€œexample interactionsâ€
    before processing the user input â€” helping it understand the expected input-output
    pattern.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°†ç¤ºä¾‹ä½œä¸º`æ¶ˆæ¯`æ”¾ç½®ï¼Œæˆ‘ä»¬ä¸æŒ‡ä»¤æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•ä¿æŒä¸€è‡´ã€‚è¿™ä½¿å¾—æ¨¡å‹åœ¨å¤„ç†ç”¨æˆ·è¾“å…¥ä¹‹å‰ï¼Œèƒ½çœ‹åˆ°å¤šä¸ªâ€œç¤ºä¾‹äº¤äº’â€â€”â€”å¸®åŠ©å®ƒç†è§£é¢„æœŸçš„è¾“å…¥è¾“å‡ºæ¨¡å¼ã€‚
- en: As your application grows, you can add more few-shots to cover more use-cases.
    For even more advanced applications, consider implementing [dynamic few-shot](https://arxiv.org/abs/1804.09458)
    selection, where the most relevant examples are chosen based on the current input.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€åº”ç”¨ç¨‹åºçš„å¢é•¿ï¼Œä½ å¯ä»¥æ·»åŠ æ›´å¤šçš„å°‘é‡ç¤ºä¾‹ï¼ˆfew-shotsï¼‰æ¥æ¶µç›–æ›´å¤šçš„ä½¿ç”¨æ¡ˆä¾‹ã€‚å¯¹äºæ›´é«˜çº§çš„åº”ç”¨ï¼Œè€ƒè™‘å®ç°[åŠ¨æ€å°‘é‡ç¤ºä¾‹](https://arxiv.org/abs/1804.09458)é€‰æ‹©ï¼Œæ ¹æ®å½“å‰è¾“å…¥é€‰æ‹©æœ€ç›¸å…³çš„ç¤ºä¾‹ã€‚
- en: 6.1.2 Task-Specific Few-Shot Learning
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1.2 ä»»åŠ¡ç‰¹å®šçš„å°‘é‡ç¤ºä¾‹å­¦ä¹ 
- en: 'This method uses examples directly related to the current task *within the*
    ***prompt*** *itself.* For instance, this prompt template is used for generating
    additional unique selling points:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•ä½¿ç”¨ä¸å½“å‰ä»»åŠ¡ç›´æ¥ç›¸å…³çš„ç¤ºä¾‹*åœ¨* ***æç¤º*** *ä¸­*ã€‚ä¾‹å¦‚ï¼Œè¿™ä¸ªæç¤ºæ¨¡æ¿ç”¨äºç”Ÿæˆé¢å¤–çš„ç‹¬ç‰¹å–ç‚¹ï¼š
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This provides targeted guidance for specific content generation tasks by including
    the examples **directly in the prompt** rather than as separate messages.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é€šè¿‡ç›´æ¥å°†ç¤ºä¾‹åŒ…å«åœ¨æç¤ºä¸­ï¼Œè€Œä¸æ˜¯ä½œä¸ºå•ç‹¬çš„æ¶ˆæ¯ï¼Œæä¾›äº†é’ˆå¯¹ç‰¹å®šå†…å®¹ç”Ÿæˆä»»åŠ¡çš„æœ‰é’ˆå¯¹æ€§çš„æŒ‡å¯¼ã€‚
- en: 7\. KISS â€” Keep It Simple, Stupid
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. KISS â€” ä¿æŒç®€å•ï¼Œå‚»ç“œ
- en: While fancy prompt engineering techniques like â€œTree of Thoughtsâ€ or â€œGraph
    of Thoughtsâ€ are intriguing, especially for research, I found them quite impractical
    and often overkill for production. For real applications, focus on designing a
    proper LLM architecture(aka workflow engineering).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡åƒâ€œæ€ç»´æ ‘â€ï¼ˆTree of Thoughtsï¼‰æˆ–â€œæ€ç»´å›¾â€ï¼ˆGraph of Thoughtsï¼‰è¿™æ ·çš„ç²¾å¦™æç¤ºå·¥ç¨‹æŠ€æœ¯å¾ˆæœ‰è¶£ï¼Œç‰¹åˆ«æ˜¯åœ¨ç ”ç©¶ä¸­ï¼Œä½†æˆ‘å‘ç°å®ƒä»¬åœ¨å®é™…ç”Ÿäº§ä¸­ç›¸å½“ä¸åˆ‡å®é™…ï¼Œå¹¶ä¸”å¾€å¾€è¿‡äºå¤æ‚ã€‚å¯¹äºçœŸå®çš„åº”ç”¨ç¨‹åºï¼Œé‡ç‚¹åº”è¯¥æ”¾åœ¨è®¾è®¡åˆé€‚çš„LLMæ¶æ„ï¼ˆå³å·¥ä½œæµå·¥ç¨‹ï¼‰ä¸Šã€‚
- en: 'This extends to the use of agents in your LLM applications. It''s crucial to
    understand the distinction between standard agents and autonomous agents:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŒæ ·é€‚ç”¨äºåœ¨ä½ çš„LLMåº”ç”¨ä¸­ä½¿ç”¨ä»£ç†ã€‚ç†è§£æ ‡å‡†ä»£ç†ä¸è‡ªä¸»ä»£ç†ä¹‹é—´çš„åŒºåˆ«è‡³å…³é‡è¦ï¼š
- en: '**Agents:** â€œTake me from A â†’ B by doing XYZ.â€'
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ä»£ç†ï¼š** â€œé€šè¿‡åšXYZæŠŠæˆ‘ä»Aå¸¦åˆ°Bã€‚â€'
- en: ''
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Autonomous Agents:**â€œTake me from A â†’ B by doing something, I donâ€™t care
    how.â€'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**è‡ªä¸»ä»£ç†ï¼š** â€œé€šè¿‡åšæŸä»¶äº‹æŠŠæˆ‘ä»Aå¸¦åˆ°Bï¼Œæˆ‘ä¸åœ¨ä¹æ€ä¹ˆåšã€‚â€'
- en: While autonomous agents offer flexibility and quicker development, they can
    also introduce unpredictability and debugging challenges. Use autonomous agents
    carefully â€” only when the benefits *clearly outweigh* the potential loss of control
    and increased complexity.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è‡ªä¸»ä»£ç†æä¾›äº†çµæ´»æ€§å’Œæ›´å¿«çš„å¼€å‘é€Ÿåº¦ï¼Œä½†å®ƒä»¬ä¹Ÿå¯èƒ½å¸¦æ¥ä¸å¯é¢„æµ‹æ€§å’Œè°ƒè¯•æŒ‘æˆ˜ã€‚è°¨æ…ä½¿ç”¨è‡ªä¸»ä»£ç†â€”â€”åªæœ‰åœ¨å…¶ä¼˜ç‚¹*æ˜æ˜¾è¶…è¿‡*æ½œåœ¨çš„æ§åˆ¶æŸå¤±å’Œå¤æ‚æ€§å¢åŠ æ—¶æ‰ä½¿ç”¨ã€‚
- en: '![](../Images/cd8b67d63da85cbb333002cf95f30b70.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd8b67d63da85cbb333002cf95f30b70.png)'
- en: (Generated with Midjourney)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆç”±Midjourneyç”Ÿæˆï¼‰
- en: 8\. Iterate, Iterate, Iterate!
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8\. è¿­ä»£ï¼Œè¿­ä»£ï¼Œå†è¿­ä»£ï¼
- en: 'Continuous experimentation is vital to improving your LLM-native applications.
    Don''t be intimidated by the idea of experiments â€” they can be as small as tweaking
    a prompt. As outlined in ["Building LLM Apps: A Clear Step-by-Step Guide,"](/building-llm-apps-a-clear-step-by-step-guide-1fe1e6ef60fd)
    it''s crucial to *establish a baseline* andtrack improvements against it.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: æŒç»­çš„å®éªŒå¯¹äºæ”¹è¿›ä½ çš„LLMåŸç”Ÿåº”ç”¨è‡³å…³é‡è¦ã€‚ä¸è¦å¯¹å®éªŒçš„æƒ³æ³•æ„Ÿåˆ°å®³æ€•â€”â€”å®ƒä»¬å¯ä»¥åƒè°ƒæ•´ä¸€ä¸ªæç¤ºé‚£ä¹ˆå°ã€‚å¦‚åœ¨["æ„å»ºLLMåº”ç”¨ï¼šæ¸…æ™°çš„é€æ­¥æŒ‡å—"](/building-llm-apps-a-clear-step-by-step-guide-1fe1e6ef60fd)ä¸­æ‰€è¿°ï¼Œ*å»ºç«‹åŸºå‡†*å¹¶æ ¹æ®å®ƒè·Ÿè¸ªæ”¹è¿›æ˜¯è‡³å…³é‡è¦çš„ã€‚
- en: Like everything else in â€œAI,â€ LLM-native apps require a **research and experimentation
    *mindset*.**
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åƒå…¶ä»–æ‰€æœ‰â€œAIâ€é¢†åŸŸçš„æŠ€æœ¯ä¸€æ ·ï¼ŒLLMåŸç”Ÿåº”ç”¨éœ€è¦**ç ”ç©¶å’Œå®éªŒçš„*æ€ç»´æ–¹å¼*ã€‚**
- en: Another great trick is to try your prompts on a weaker model than the one you
    aim to use in production(such as open-source 8B models) â€” an â€œokayâ€ performing
    prompt on a smaller model will perform much better on a larger model.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªå¥½æŠ€å·§æ˜¯å°è¯•åœ¨æ¯”ä½ è®¡åˆ’åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨çš„æ¨¡å‹æ€§èƒ½æ›´å¼±çš„æ¨¡å‹ä¸Šæµ‹è¯•ä½ çš„æç¤ºï¼ˆä¾‹å¦‚ï¼Œå¼€æºçš„8Bæ¨¡å‹ï¼‰â€”â€”åœ¨è¾ƒå°æ¨¡å‹ä¸Šè¡¨ç°â€œè¿˜è¡Œâ€çš„æç¤ºåœ¨æ›´å¤§æ¨¡å‹ä¸Šä¼šè¡¨ç°å¾—æ›´å¥½ã€‚
- en: Conclusion
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: These eight tips provide a solid foundation for effective prompt engineering
    in LLM-native applications. By applying these tips in your prompts, you'll be
    able to create more reliable, efficient, and scalable LLM-native applications.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å…«ä¸ªæŠ€å·§ä¸ºæœ‰æ•ˆçš„æç¤ºå·¥ç¨‹æä¾›äº†åšå®çš„åŸºç¡€ï¼Œé€‚ç”¨äºLLMåŸç”Ÿåº”ç”¨ã€‚é€šè¿‡åœ¨æç¤ºä¸­åº”ç”¨è¿™äº›æŠ€å·§ï¼Œä½ å°†èƒ½å¤Ÿåˆ›å»ºæ›´å¯é ã€é«˜æ•ˆå’Œå¯æ‰©å±•çš„LLMåŸç”Ÿåº”ç”¨ã€‚
- en: Remember, the goal isn't to create the most complex system but to build something
    that works in the real world. Keep experimenting, learning, and building â€” the
    possibilities are endless.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œç›®æ ‡ä¸æ˜¯åˆ›å»ºæœ€å¤æ‚çš„ç³»ç»Ÿï¼Œè€Œæ˜¯æ„å»ºä¸€ä¸ªåœ¨ç°å®ä¸–ç•Œä¸­æœ‰æ•ˆçš„ç³»ç»Ÿã€‚ç»§ç»­å®éªŒã€å­¦ä¹ å’Œæ„å»ºâ€”â€”å¯èƒ½æ€§æ˜¯æ— é™çš„ã€‚
- en: If you find this article helpful, please give it a few **claps** ğŸ‘ on Medium
    and **share** it with your fellow AI enthusiasts. Your support means the world
    to me! ğŸŒ
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è§‰å¾—è¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·åœ¨Mediumä¸Šç»™å®ƒä¸€äº›**æŒå£°**ğŸ‘å¹¶**åˆ†äº«**ç»™ä½ èº«è¾¹çš„AIçˆ±å¥½è€…ã€‚ä½ çš„æ”¯æŒå¯¹æˆ‘æ„ä¹‰é‡å¤§ï¼ğŸŒ
- en: Let's keep the conversation going â€” feel free to reach out via [email](mailto:almog.baku@gmail.com)
    or [connect on LinkedIn](https://www.linkedin.com/in/almogbaku/) ğŸ¤
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»§ç»­ä¿æŒå¯¹è¯â€”â€”éšæ—¶é€šè¿‡[ç”µå­é‚®ä»¶](mailto:almog.baku@gmail.com)æˆ–[åœ¨LinkedInä¸Šè”ç³»](https://www.linkedin.com/in/almogbaku/)
    ğŸ¤
- en: Special thanks to [Liron Izhaki Allerhand](https://medium.com/u/251cd1007ce8?source=post_page---user_mention--430eef9b0950--------------------------------)
    and [Yam Peleg](https://medium.com/u/e0607cd7607d?source=post_page---user_mention--430eef9b0950--------------------------------);
    this article is based on insights from our conversations.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹åˆ«æ„Ÿè°¢[Liron Izhaki Allerhand](https://medium.com/u/251cd1007ce8?source=post_page---user_mention--430eef9b0950--------------------------------)å’Œ[Yam
    Peleg](https://medium.com/u/e0607cd7607d?source=post_page---user_mention--430eef9b0950--------------------------------)ï¼›è¿™ç¯‡æ–‡ç« åŸºäºæˆ‘ä»¬ä¹‹é—´çš„å¯¹è¯å’Œè§è§£ã€‚
