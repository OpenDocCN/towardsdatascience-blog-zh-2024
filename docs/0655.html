<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Revolutionize Web Browsing with AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Revolutionize Web Browsing with AI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/revolutionize-web-browsing-with-ai-5d5f6ce5f5df?source=collection_archive---------4-----------------------#2024-03-10">https://towardsdatascience.com/revolutionize-web-browsing-with-ai-5d5f6ce5f5df?source=collection_archive---------4-----------------------#2024-03-10</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="bba3" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Unlock Interactive Online Experiences Using GPT-4V and Puppeteer</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@bianbianzhu123?source=post_page---byline--5d5f6ce5f5df--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Tianyi Li" class="l ep by dd de cx" src="../Images/40fce472f42c650daa1433641bf732df.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*Maf5doyZMjEIBpI6"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--5d5f6ce5f5df--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@bianbianzhu123?source=post_page---byline--5d5f6ce5f5df--------------------------------" rel="noopener follow">Tianyi Li</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--5d5f6ce5f5df--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">23 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 10, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="b3ec" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Authors: <span class="ia"><span class="ia" aria-hidden="false"><a class="nf ib ng" href="https://medium.com/u/4092d7367010?source=post_page---user_mention--5d5f6ce5f5df--------------------------------" rel="noopener" target="_blank">Tianyi Li</a></span></span>, <span class="ia"><span class="ia" aria-hidden="false"><a class="nf ib ng" href="https://medium.com/u/7b9ea39b0d79?source=post_page---user_mention--5d5f6ce5f5df--------------------------------" rel="noopener" target="_blank">Selina Li</a></span></span></p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni nj"><img src="../Images/5534a8ac0a28ede1472534e7d922e9d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WfCc9A-4cjrxQRw0CN4SFg.jpeg"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Image generated by the author with DALL·E</figcaption></figure><p id="e34a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">· <a class="af oa" href="#ced3" rel="noopener ugc nofollow">Introduction</a><br/>· <a class="af oa" href="#b5c4" rel="noopener ugc nofollow">Potential Use Cases</a><br/>· <a class="af oa" href="#efe3" rel="noopener ugc nofollow">High-level Workflow</a><br/>· <a class="af oa" href="#2455" rel="noopener ugc nofollow">Architecture</a><br/> ∘ <a class="af oa" href="#1813" rel="noopener ugc nofollow">Starting Out</a><br/> ∘ <a class="af oa" href="#3fd7" rel="noopener ugc nofollow">Pick the Right Path</a><br/> ∘ <a class="af oa" href="#ce07" rel="noopener ugc nofollow">IT IS A LOOP!</a><br/> ∘ <a class="af oa" href="#30b8" rel="noopener ugc nofollow">Directory Structure</a><br/> ∘ <a class="af oa" href="#c456" rel="noopener ugc nofollow">Browser Controller Service</a><br/> ∘ <a class="af oa" href="#d19c" rel="noopener ugc nofollow">Element Annotation Service</a><br/>· <a class="af oa" href="#b379" rel="noopener ugc nofollow">Conclusion</a></p><h1 id="ced3" class="ob oc fq bf od oe of gq og oh oi gt oj ok ol om on oo op oq or os ot ou ov ow bk">Introduction</h1><p id="e543" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">Imagine you are keen on attending an AI event in your city this month, but you have specific criteria in mind, perhaps related to timing or the focus of the event. Normally, this would involve the following process:</p><ul class=""><li id="bb00" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pc pd pe bk">Launching a web search with terms like “AI events in [your city] this month.”</li><li id="bb3c" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Sifting through search results to find a link that seems promising.</li><li id="79c1" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Navigating the chosen website to determine its relevance, possibly needing to delve deeper through additional links.</li><li id="682f" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">After much back and forth, finally pinpointing the event that fits your criteria and noting its details for your calendar.</li></ul><p id="352d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If we break down the above process, it basically involves steps that can be categorized into the following:</p><ol class=""><li id="b6d1" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pk pd pe bk">Control the browser, such as go to a URL, click on a link, go back, etc.</li><li id="8d5c" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">Browse through the content of a page</li><li id="d680" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">Make decisions based on the content of that page, such as determining which link is relevant to your query.</li></ol><p id="b828" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">By utilizing the emerging Large Language Model (LLM) technology, now we are able to <strong class="ml fr">automate the whole process through a LLM powered AI Agent</strong>.</p><p id="e5a6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Enter the AI agent, it does exactly what you do as we described above.</p><ol class=""><li id="2535" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pk pd pe bk"><strong class="ml fr">Browser Control</strong>: the AI uses tools like <code class="cx pl pm pn po b">Puppeteer</code> to navigate the internet. Think of Puppeteer as the AI's hands, allowing it to open tabs, click on links, and navigate web pages with ease.</li><li id="0bba" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk"><strong class="ml fr">Content Browsing</strong>: Think of this as the AI’s eyes. <code class="cx pl pm pn po b">Puppeteer</code> can take screenshots of web pages, and feed them to the AI.</li><li id="0e81" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk"><strong class="ml fr">Decision-Making</strong>: This is where the AI’s brain, powered by Large Language Models (LLM), comes into play. It assesses the screenshot of each page, analyzing the image, determining relevance and deciding on the next steps, mimicking human judgment.</li></ol><figure class="nk nl nm nn no np"><div class="pp io l ed"><div class="pq pr l"/></div></figure><p id="e91b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this article, we will explore and build an AI agent that utilizes the power of the <code class="cx pl pm pn po b">gpt-4-vision-preview</code> model from OpenAI. The model can <strong class="ml fr">analyze images</strong> and provide textual responses.</p><p id="7ee7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This agent will be able to interact with the user, control a web browser, and process data. We’ll explore its structure and how it works.</p><p id="519b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This article is inspired by a youtube video <a class="af oa" href="https://www.youtube.com/watch?v=IXRkmqEYGZA&amp;t=184s" rel="noopener ugc nofollow" target="_blank">GPT4V + Puppeteer = AI agent browse web like human? 🤖</a> from <a class="af oa" href="https://www.youtube.com/@AIJasonZ" rel="noopener ugc nofollow" target="_blank">AI Jason</a>.</p><p id="b2e5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">All the code shown in this article can be found in this Github repo </strong><a class="af oa" href="https://github.com/bianbianzhu/ai-web-agent/tree/main/agent" rel="noopener ugc nofollow" target="_blank"><strong class="ml fr">AI Web Agent</strong></a><strong class="ml fr">.</strong></p><h1 id="b5c4" class="ob oc fq bf od oe of gq og oh oi gt oj ok ol om on oo op oq or os ot ou ov ow bk">Potential Use Cases</h1><ul class=""><li id="6ac9" class="mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne pc pd pe bk">Pairing with Text to speech, it can allow people with visual impairments to browse the web.</li><li id="5faa" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Quickly locate a product on an E-commerce website.</li><li id="b15d" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Auto-browse websites with dynamic loading contents (e.g. Real Estate listings)</li><li id="3d9b" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Auto-browse websites requiring personal logins (e.g. LinkedIn, Instagram, Facebook)</li><li id="642a" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Take online quiz and tests</li><li id="b98e" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Play web games</li><li id="c0b8" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Online seats / tickets grabbing</li><li id="5f51" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Automated application feature testing</li></ul><h1 id="efe3" class="ob oc fq bf od oe of gq og oh oi gt oj ok ol om on oo op oq or os ot ou ov ow bk">High-level Workflow</h1></div></div><div class="np"><div class="ab cb"><div class="lm ps ln pt lo pu cf pv cg pw ci bh"><figure class="nk nl nm nn no np py pz paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni px"><img src="../Images/586a1f94e2d077c069b61fadefe44de0.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*jU17DMatnEhbsnJ8W1zZJg.jpeg"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">The flowchart showing the high-level workflow of the agent.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="1bc7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">First user raises a question to the agent.</p><p id="deee" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Upon receiving the question, GPT-4V is going to return a URL as an entry point of the web searching. The URL can be specified by the user as part of the question; and if not specified, by default it will be a Google search on key words extracted by GPT from user’s question.</p><p id="b3f0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Upon receiving the URL, puppeteer will open the URL in webpage. It will highlight all interactive elements on the page such as links, clicks, buttons, and then take a screenshot of the page and return it.</p><p id="0ed0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Upon receiving the screenshot, GPT-4V will look into the page and process the highlighted information. As a brain, GPT will decide if it has already got a good answer to user’s questions.</p><p id="237f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If there is a good answer, GPT will provide the answer back to the user.</p><p id="bec8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">If not, GPT-4V will decide which URL or click to visit for the next step. Puppeteer will again opens the new URL, highlight the interactive elements and take a screenshot for further processing.</p><p id="94b4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This process will repeat until GPT decides it has got a good answer for the user.</p><h1 id="2455" class="ob oc fq bf od oe of gq og oh oi gt oj ok ol om on oo op oq or os ot ou ov ow bk">Architecture</h1><p id="f28c" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">As we are now clear on how the AI agent works, let’s take a look at the architecture of the agent. The agent is structured as follows:</p></div></div><div class="np"><div class="ab cb"><div class="lm ps ln pt lo pu cf pv cg pw ci bh"><figure class="nk nl nm nn no np py pz paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni qa"><img src="../Images/5a8375fa18a3f3434a9572dbdf104d0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*kBY7f00zTb8nOrhs8aXCsQ.gif"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Overview of the agent’s architecture</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="4664" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This architecture may look complex at first, but it’s actually quite simple once you understand the different components and how they work together. Let’s break it down.</p></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="1813" class="qj oc fq bf od qk ql qm og qn qo qp oj ms qq qr qs mw qt qu qv na qw qx qy qz bk">Starting Out</h2><p id="51a1" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">This is the starting point of the workflow. The user interacts with the agent by providing a prompt which clarifies the task (<code class="cx pl pm pn po b">user task prompt</code>). At the same time, the agent gets some default instructions (<code class="cx pl pm pn po b">system prompt</code>), about how it should do its job. These instructions tell the agent what its role is, how to format its answers, and other important info.</p><p id="0e10" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Here’s a simple view of the starting point:</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni ra"><img src="../Images/fffb4608e71295968f9cdae12e5bada0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-CyibAnEB3oyEy7EPY9fRw.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">The initial step</figcaption></figure><p id="7846" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The example of the <code class="cx pl pm pn po b">user task prompt</code> might be:</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="b6db" class="re oc fq po b bg rf rg l rh ri">I'm looking for AI events in Melbourne this month. Please prioritize events that are on weekends.</span></pre><p id="1b5d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">And here’s what the system prompt might look like:</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rj"><img src="../Images/dd728c47d52c1476b78ddd1a127ed3d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*14DfS20wjfcCvmpCrA-sbQ.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">A typical system prompt that provides context for the agent.</figcaption></figure><p id="52ff" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Credit: <a class="af oa" href="https://github.com/JayZeeDesign/Scrape-anything---Web-AI-agent" rel="noopener ugc nofollow" target="_blank">JayZeeDesign</a></p><p id="c22f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The system prompt is crucial because they help the agent decide how to act. The three main areas are highlighted in different colors:</p><ul class=""><li id="5de5" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pc pd pe bk">What is the role of the agent. (Aqua)</li><li id="a103" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">How the agent should present its answers. (Red)</li><li id="615f" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">Extra instructions to help the agent. (Yellow)</li></ul><p id="95d7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The prompts are then sent to the openai service, which is responsible for generating responses.</p><p id="a4b7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Based on these prompts, the agent’s response will be shaped into only 3 types:</p><ol class=""><li id="018d" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pk pd pe bk"><code class="cx pl pm pn po b">{ "url": "https://www.example.com" }</code> - The agent wants to navigate to a specific webpage.</li><li id="d070" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk"><code class="cx pl pm pn po b">{ "click": "text on a button" }</code> - The agent wants to click on a specific element on the page.</li><li id="8fc9" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk"><code class="cx pl pm pn po b">regular message</code> - The agent has finished the task and extracted the required information to the user.</li></ol><p id="215e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For the initial conversation, the response would normally be a Google search url, such as <code class="cx pl pm pn po b">https://www.google.com/search?q=AI+events+in+Melbourne+March</code>. This response would then trigger the browser-controller service to navigate to the URL.</p><p id="b894" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Code implementation of the starting point</strong></p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="c6ff" class="re oc fq po b bg rf rg l rh ri">const messages: ChatCompletionMessageParam[] = [];<br/><br/>// STEP 1: Welcome the user<br/>console.log(staticMessageMap.welcome);<br/>// STEP 2: provide the context of the conversation - system prompt<br/>messages.push(promptMap.context());<br/>// STEP 3: Ask and apply the user's query as a task - user task prompt<br/>const userPrompt = await userPromptInterfaceV2(staticMessageMap.you);<br/>messages.push(promptMap.task(userPrompt));</span></pre><p id="32cb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The following function creates the interface in the terminal for the user to input their query.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="175b" class="re oc fq po b bg rf rg l rh ri">/**<br/> * This service creates a user prompt interface and returns a promise that resolves to the user's input. Allow user to input in the `terminal`.<br/> * @param query - The message to hint the user on what to input<br/> * @returns A promise that resolves to the user's input<br/> */<br/>export const userPromptInterfaceV2 = async (query: string) =&gt; {<br/>  // Create an interface to read input from the user<br/>  const userInterface = readline.createInterface({<br/>    input: process.stdin,<br/>    output: process.stdout,<br/>  });<br/><br/>  // Return a promise that resolves to the user's input<br/>  // The userInterface.question method takes a query and a callback function<br/>  // The reason for using a promise is to make the user's input accessible outside of the callback function<br/>  return new Promise&lt;string&gt;((resolve) =&gt; {<br/>    userInterface.question(query, (input) =&gt; {<br/>      resolve(input);<br/>      userInterface.close(); // Close the user interface<br/>    });<br/>  });<br/>};</span></pre><p id="1ff8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">And you may notice the <code class="cx pl pm pn po b">promptMap</code> object in the code. It is a map of functions that returns all the prompts. Making it a function allows the prompts to be dynamic and change based on the context of the conversation. Here is an example:</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="e56e" class="re oc fq po b bg rf rg l rh ri">export const promptMap = {<br/>  context: (<br/>    role: "teacher" | "student" | "AI"<br/>  ): ChatCompletionMessageParam =&gt; ({<br/>    role: "system",<br/>    content: `You are a ${role}. You will be given instructions on what to do by browsing. You are connected to a web browser and you will be given the screenshot of the website you are on.`,<br/>  }),<br/>};</span></pre><p id="5634" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">An important note is that to allow the LLM to have the <code class="cx pl pm pn po b">memory</code> of the conversation, we need to always push the new prompts to the message array and send the whole array to the LLM. This could cause the explosion of the tokens. Use the <code class="cx pl pm pn po b">max_tokens</code> parameter to build the safe net.</p><p id="6372" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Below is how to use the openai service to generate the response.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="5d3f" class="re oc fq po b bg rf rg l rh ri">const taskFlow = async (): Promise&lt;void&gt; =&gt; {<br/>  console.log(`${staticMessageMap.agent}Let me think...`);<br/>  // Start the conversation with the LLM<br/>  const response = await openai.chat.completions.create({<br/>    model: "gpt-4-vision-preview",<br/>    max_tokens: 1024,<br/>    messages, // The messages array which contains the conversation history is sent to the LLM<br/>    temperature: 0,<br/>  });<br/><br/>// For the initial conversation, the agent will respond with the url (google search if not provided by the user)<br/>  const { message } = response.choices[0];<br/>  const { content: messageText } = message;<br/>  if (messageText === null) {<br/>    throw new Error("The response message text is null");<br/>  }<br/>  // Show the response in the terminal<br/>  console.log(`${staticMessageMap.agent}${messageText}`);<br/>  // Memorize the answer from agent<br/>  messages.push({<br/>    role: "assistant",<br/>    content: messageText,<br/>  });<br/>};<br/>await taskFlow();</span></pre><p id="e7f2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">And of course, to use <code class="cx pl pm pn po b">openai</code> service, you need to have the <code class="cx pl pm pn po b">openai</code> package installed and the API key. Here is a seperate file to handle the openai service.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="a1b9" class="re oc fq po b bg rf rg l rh ri">import dotenv from "dotenv";<br/>dotenv.config();<br/>import OpenAI from "openai";<br/><br/>/**<br/> * An instance of the OpenAI Class that can invoke the API methods<br/> * @example `openai.chat.completions.create`<br/> */<br/>export const openai = new OpenAI({<br/>  apiKey: process.env.OPENAI_API_KEY,<br/>});</span></pre></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="3fd7" class="qj oc fq bf od qk ql qm og qn qo qp oj ms qq qr qs mw qt qu qv na qw qx qy qz bk">Pick the Right Path</h2><p id="ecf9" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">As we mentioned earlier, the LLM response will be shaped into only 3 types. Each of these types will trigger a different browser-controller service to act accordingly.</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rk"><img src="../Images/6ca654ab4349b5e66c39e9985ead90bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GGZL1gwP16vPa6RA6R3r-Q.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Agent choosing the optimal path guided by LLM feedback.</figcaption></figure><p id="2be5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">URL Response Flow</strong></p><ul class=""><li id="824f" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pc pd pe bk"><strong class="ml fr">Response format { “url”: “</strong><a class="af oa" href="https://www.example.com" rel="noopener ugc nofollow" target="_blank"><strong class="ml fr">https://www.example.com</strong></a><strong class="ml fr">" }</strong></li><li id="e38c" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk"><strong class="ml fr">Indicate that the agent should navigate to a specific webpage.</strong></li><li id="dd38" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk"><strong class="ml fr">This response would trigger the following steps in the script:</strong></li></ul><ol class=""><li id="4052" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pk pd pe bk">Extract the URL from the response</li><li id="5857" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">Opens a browser using Puppeteer and navigates to the URL</li><li id="e5c0" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">The agent then takes a screenshot of the page and sends it with another special instruction prompt back to the LLM to analyze the content of the page and decide on the next steps.</li></ol><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rl"><img src="../Images/97229ad5607b2a6fcf9d24c47a1fe5a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BT4pGX-QYOh88rdc222oVg.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Processing flow for ‘url’ response messages.</figcaption></figure><p id="6f83" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Click Response Flow</strong></p><ul class=""><li id="f248" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pc pd pe bk"><strong class="ml fr">Response format { “click”: “text on a button” }</strong></li><li id="e740" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk"><strong class="ml fr">Indicate that the agent should click on a specific element on the page.</strong></li><li id="87a6" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk"><strong class="ml fr">The agent will undergo the following steps:</strong></li></ul><ol class=""><li id="cca4" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pk pd pe bk">Extract the link text from the response</li><li id="1988" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">The agent then uses Puppeteer to find the element with the matching text and clicks on it</li><li id="6653" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">The agent takes a screenshot of the page and sends it with another special instruction prompt back to the LLM to analyze the content of the page and decide on the next steps.</li></ol><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rm"><img src="../Images/a2d29ca66285afcabd6ea669bf885bc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtpDRERvrjNJb_o3HjcfxA.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Processing flow for ‘click’ response messages.</figcaption></figure><p id="b669" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let’s take a look at the <code class="cx pl pm pn po b">special instruction prompt</code> that the agent sends to the LLM after taking a screenshot of the page.</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rn"><img src="../Images/ff292db3f933db519ba4f04613fe2010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fvy5M04xDrWvwfuT_PlRkw.png"/></div></div></figure><p id="d64a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Credit: <a class="af oa" href="https://github.com/JayZeeDesign/Scrape-anything---Web-AI-agent" rel="noopener ugc nofollow" target="_blank">JayZeeDesign</a></p><p id="d9b1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This prompt basically tells the LLM to analyze the screenshot of the page and decide on the next steps. The response format should be exactly as we mentioned in the system prompt. With LLMs, it’s often necessary to reiterate rules or guidelines to ensure consistent performance.</p><p id="d8df" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Regular Message Flow — Regular message</strong></p><ul class=""><li id="ca83" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pc pd pe bk">Indicate that the agent has finished the task and extracted the required information to the user.</li><li id="a5fd" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">This is normally the end of the current task.</li><li id="2cf3" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">The agent will simply display the information to the user.</li></ul><p id="87d1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Code implementation of the path selection</strong></p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="5831" class="re oc fq po b bg rf rg l rh ri">// Use typescript to define the 3 types of response<br/>export type ResponseMessage =<br/>  | {<br/>      type: ResponseMessageCategory.URL;<br/>      url: string;<br/>    }<br/>  | {<br/>      type: ResponseMessageCategory.CLICK;<br/>      linkText: string;<br/>    }<br/>  // This initial type is simply a placeholder to indicate the start of the conversation in which the LLM has not yet provided a response (not relevant to the path selection logic)<br/>  | {<br/>      type: ResponseMessageCategory.INITIAL;<br/>      text: "initial";<br/>    }<br/>  | {<br/>      type: ResponseMessageCategory.REGULAR;<br/>      text: string;<br/>    };</span></pre><p id="bdba" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A function that converts the <strong class="ml fr">plain string response</strong> from the LLM to the defined type.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="7781" class="re oc fq po b bg rf rg l rh ri">export const convertTextToResponseMessage = (text: string): ResponseMessage =&gt; {<br/>  // The `extractActionFromString` function is a helper function that simply checks if a string contains a particular pattern, such as '{"url": "' or '{"click": "' which is directly related to the response format. See the repo for the full implementation.<br/>  if (extractActionFromString(text, ResponseMessageCategory.URL) !== null) {<br/>    return {<br/>      type: ResponseMessageCategory.URL,<br/>      // Extract the URL from the response and store it in the `url` property, so it can be accessed easily<br/>      url: extractActionFromString(text, ResponseMessageCategory.URL) as string,<br/>    };<br/>  }<br/><br/>  if (extractActionFromString(text, ResponseMessageCategory.CLICK) !== null) {<br/>    return {<br/>      type: ResponseMessageCategory.CLICK,<br/>      // Extract the link text from the response and store it in the `linkText` property, so it can be accessed easily<br/>      linkText: extractActionFromString(<br/>        text,<br/>        ResponseMessageCategory.CLICK<br/>      ) as string,<br/>    };<br/>  }<br/><br/>  if (text === ResponseMessageCategory.INITIAL) {<br/>    return {<br/>      type: ResponseMessageCategory.INITIAL,<br/>      text,<br/>    };<br/>  }<br/>  return {<br/>    type: ResponseMessageCategory.REGULAR,<br/>    text,<br/>  };<br/>};</span></pre><p id="0822" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To implement the <code class="cx pl pm pn po b">Path Selection</code>, the code should have the following backbone:</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="318e" class="re oc fq po b bg rf rg l rh ri">// messageText is the plain string response from the LLM (see above code)<br/>// It is then converted to the defined type using the `convertTextToResponseMessage` function<br/>responseMessage = convertTextToResponseMessage(messageText);<br/><br/>// if-else statement to determine the path based on the response type<br/>// URL Response Flow<br/>if (responseMessage.type === ResponseMessageCategory.URL) {<br/>  // 1. Extract the URL from the response<br/>  const { url } = responseMessage;<br/>  // 2. Opens a headless browser using Puppeteer and navigates to the URL and take a screenshot of the page<br/>  const imagePath = await screenshot(url, page);<br/>  if (imagePath === undefined) {<br/>    throw new Error("The screenshot path is undefined");<br/>  }<br/>  // converts the screenshot to a format that LLM accepts<br/>  const base64String = await imageToBase64String(imagePath);<br/>  // 3. Send the screenshot with the instruction prompt back to the LLM<br/>  messages.push(<br/>    promptMap.instruction({<br/>      url: base64String,<br/>      detail: "auto",<br/>    })<br/>  );<br/>  return; // end of this path<br/>}<br/>// Click Response Flow<br/>if (responseMessage.type === ResponseMessageCategory.CLICK) {<br/>  // 1. Extract the link text from the response<br/>  const { linkText } = responseMessage;<br/>  // 2. The agent then uses Puppeteer to find the element with the matching text and clicks on it<br/>  const imagePath = await clickNavigationAndScreenshot(linkText, page, browser);<br/>  if (imagePath === undefined) {<br/>    throw new Error("The screenshot path is undefined");<br/>  }<br/>  const base64String = await imageToBase64String(imagePath);<br/>  // 3. Send the screenshot with the instruction prompt back to the LLM<br/>  messages.push(<br/>    promptMap.instruction({<br/>      url: base64String,<br/>      detail: "auto",<br/>    })<br/>  );<br/>  return;<br/>}<br/>// Regular Message Flow - return message directly</span></pre></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="ce07" class="qj oc fq bf od qk ql qm og qn qo qp oj ms qq qr qs mw qt qu qv na qw qx qy qz bk">IT IS A LOOP!</h2><p id="2aa6" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">Now, we are clear on the different paths the agent can take. One thing to note is that the agent will keep looping through these steps until the task is completed and respond with a regular message.</p><p id="9aff" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">An example of the loop is like:</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni ro"><img src="../Images/cece81855a5ee85556bb1ccc9b2efffb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AtY3XM0ToIUlLAJp_wS73Q.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">The agent workflow is a loop!</figcaption></figure><p id="cf43" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The URL or Click Response Flow will be fired multiple times until the agent has found the answer.</p><p id="97f7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To implement the loop, the code should have the following structure:</p><p id="02c5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">first, a helper function to determine when to stop the loop.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="b6de" class="re oc fq po b bg rf rg l rh ri">export const shouldContinueLoop = (responseMessage: ResponseMessage) =&gt; {<br/><br/>// If the response is a regular message, the agent has finished the task and the loop should stop<br/>  if (responseMessage.type === ResponseMessageCategory.REGULAR) {<br/>    return false;<br/>  }<br/>  // Otherwise, the loop should continue<br/>  return true;<br/>};</span></pre><p id="71f0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Then, the main loop function.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="2c49" class="re oc fq po b bg rf rg l rh ri">// The initial response message before the loop starts. Basically, a placeholder.<br/>let responseMessage: ResponseMessage = {<br/>  type: ResponseMessageCategory.INITIAL,<br/>  text: "initial",<br/>};<br/>//==================================LOOP==================================<br/>// shouldContinueLoop determines when to stop the loop<br/>while (shouldContinueLoop(responseMessage)) {<br/><br/>  // +++++ openai service to generate the response +++++<br/>  console.log(`${staticMessageMap.agent}Let me think...`);<br/>  const response = await openai.chat.completions.create({<br/>    model: "gpt-4-vision-preview",<br/>    max_tokens: 1024,<br/>    messages,<br/>    temperature: 0,<br/>  });<br/><br/>  const { message } = response.choices[0];<br/>  const { content: messageText } = message;<br/>  if (messageText === null) {<br/>    throw new Error("The response message text is null");<br/>  }<br/>  console.log(`${staticMessageMap.agent}${messageText}`);<br/>  // +++++++++++++++++++++++++++++++++++++++++++++++++++<br/><br/>  // Memorize the answer from agent<br/>  messages.push({<br/>    role: "assistant",<br/>    content: messageText,<br/>  });<br/><br/>  // +++++ Path Selection +++++<br/>  responseMessage = convertTextToResponseMessage(messageText);<br/>  // URL Response Flow<br/>  if (responseMessage.type === ResponseMessageCategory.URL) {<br/>    const { url } = responseMessage;<br/>    const imagePath = await screenshot(url, page);<br/>    if (imagePath === undefined) {<br/>      throw new Error("The screenshot path is undefined");<br/>    }<br/>    const base64String = await imageToBase64String(imagePath);<br/>    messages.push(<br/>      promptMap.instruction({<br/>        url: base64String,<br/>        detail: "auto",<br/>      })<br/>    );<br/>    // Instead of stopping here, we need to continue the loop for the next step<br/>    continue;<br/>  }<br/>  // Click Response Flow<br/>  if (responseMessage.type === ResponseMessageCategory.CLICK) {<br/>    const { linkText } = responseMessage;<br/>    try {<br/>      const imagePath = await clickNavigationAndScreenshot(<br/>        linkText,<br/>        page,<br/>        browser<br/>      );<br/>      if (imagePath === undefined) {<br/>        throw new Error("The screenshot path is undefined");<br/>      }<br/>      const base64String = await imageToBase64String(imagePath);<br/>      messages.push(<br/>        promptMap.instruction({<br/>          url: base64String,<br/>          detail: "auto",<br/>        })<br/>      );<br/>      // continue the loop for the next step<br/>      continue;<br/>    } catch (err) {<br/>      // Handle the error and retry if the link is not found; sometimes the LLM just comes up with a link that doesn't exist or with a typo<br/>      if (<br/>        err instanceof Error &amp;&amp;<br/>        err.message.includes("Link with text not found")<br/>      ) {<br/>        console.log(`...Error clicking on link: ${err.message}`);<br/>        messages.push(promptMap.retryIfLinkNotFound(linkText));<br/>        continue;<br/>      } else {<br/>        console.log(`...Unexpected error: ${err}. Please try again.`);<br/>        break;<br/>      }<br/>    }<br/>  }<br/>  // ++++++++++++++++++++++++++++<br/>}</span></pre><p id="c266" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">As you may notice, we didn’t specify the regular message flow in the loop. This is because the regular message does not trigger any browser-controller service. It simply ends the loop and displays the message to the user, basically a <code class="cx pl pm pn po b">console.log</code> statement. Of course, you can add more logic to the regular message flow such as saving the message to a csv file, etc.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="f836" class="re oc fq po b bg rf rg l rh ri">console.log(`${staticMessageMap.agent}${messageText}`);</span></pre></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="30b8" class="qj oc fq bf od qk ql qm og qn qo qp oj ms qq qr qs mw qt qu qv na qw qx qy qz bk">Directory Structure</h2><p id="e44d" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">After understanding the main flow of the agent, let’s take a look at the directory structure of the agent.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="fe76" class="re oc fq po b bg rf rg l rh ri">agent.ts<br/>services/<br/>├── browser-controller.ts<br/>├── data-transformer.ts<br/>├── element-annotator.ts<br/>├── openai.ts<br/>├── prompt-map.ts<br/>└── user-prompt-interface.ts<br/>utils.ts</span></pre><p id="182a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><code class="cx pl pm pn po b">agent.ts</code>: This is the main script for our agent. It orchestrates the other services and is responsible for the main execution flow of the agent. It contains the starting point, the main loop, and the path selection logic.</p><p id="976b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><code class="cx pl pm pn po b">services/</code>: This directory contains various services used by the agent. Each service is responsible for a specific task.</p><ul class=""><li id="7dd3" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pc pd pe bk">browser-controller.ts: This service controls the browser using Puppeteer. It can navigate to pages, interact with elements, and take screenshots.</li><li id="2248" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">data-transformer.ts: This service transforms data for the agent. It can format data, clean it, and prepare it for further processing.</li><li id="270f" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">element-annotator.ts: This service annotates HTML elements for the agent. It can highlight elements, add unique identifiers to them, and more.</li><li id="7464" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">openai.ts: This service interfaces with the OpenAI API.</li><li id="009e" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">prompt-map.ts: This service maps user prompts to actions. It can determine what action the agent should take based on the user’s input.</li><li id="8750" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pc pd pe bk">user-prompt-interface.ts: This service interfaces with the user to get prompts. It can read user input and pass it to the agent.</li></ul><p id="9015" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><code class="cx pl pm pn po b">utils.ts</code>: This file contains utility functions used by the agent. These functions are used throughout the agent code to perform common tasks.</p><p id="86e1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For the full code implementation, please refer to the <a class="af oa" href="https://github.com/bianbianzhu/ai-web-agent" rel="noopener ugc nofollow" target="_blank">Ai Web Agent</a>.</p></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="c456" class="qj oc fq bf od qk ql qm og qn qo qp oj ms qq qr qs mw qt qu qv na qw qx qy qz bk">Browser Controller Service</h2><p id="dd5a" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">Now, let’s dive into how the agent controls the browser — how its hands work. A library called <code class="cx pl pm pn po b">Puppeteer</code> is used here. It provides a high-level API over the Chrome DevTools Protocol. See the <a class="af oa" href="https://pptr.dev/" rel="noopener ugc nofollow" target="_blank">Puppeteer documentation</a> for more details.</p><p id="1223" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Essentially, Puppeteer gets called after the agent receives a response from the LLM. Under different paths as we mentioned above, Puppeteer will execute different actions.</p><p id="abd9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Overall, the browser-controller service is responsible for the following:</p><ol class=""><li id="118c" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pk pd pe bk">Navigating to a URL</li><li id="3486" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">Clicking on a link</li><li id="e188" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">Taking a screenshot of the page</li></ol><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rp"><img src="../Images/3a30655d1ff49b52ff7e6a8eaa31cb5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Uh2YYjfttxSMksbXXBV-A.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">The tasks that Puppeteer would do in the workflow.</figcaption></figure><p id="1c51" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">There is, in fact, another step taken before the agent takes a screenshot of the page — <code class="cx pl pm pn po b">Highlighting interactive elements</code>. We have separated this service into a different file to make the code more modular and easier to maintain. It will be discussed in the next section.</p><p id="a32e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Code implementation of the browser-controller service</strong></p><p id="18f6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Step 1 — Initialize the browser and open a new tab</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="4095" class="re oc fq po b bg rf rg l rh ri">const browserWindowSize = { width: 900, height: 1600 };<br/><br/>/**<br/> * This service initializes a new browser session and a new page tab<br/> * @returns An object containing the browser and the page<br/> */<br/>export const initController = async () =&gt; {<br/>  const pup = puppeteer.default.use(StealthPlugin());<br/>  // launch the browser<br/>  const browser = await pup.launch({<br/>    // detailed configurations<br/>    headless: false, // Determines whether to run the browser in headless mode (without a GUI). boolean | "new" | undefined<br/>    executablePath: process.env.GOOGLE_CHROME_CANARY_PATH, // path to a browser executable to use instead of the bundled Chromium<br/>    userDataDir: process.env.GOOGLE_CHROME_CANARY_USER_DATA_DIR, // Path to a user data directory, i.e, the user profile<br/>    args: [<br/>      `--profile-directory=${process.env.PROFILE}`, // Select the expected profile<br/>      "--disable-setuid-sandbox",<br/>      "--no-sandbox",<br/>      "--no-zygote",<br/>      `--window-size=${browserWindowSize.width},${browserWindowSize.height}`,<br/>    ],<br/>  });<br/>  // open a new tab<br/>  const page = await browser.newPage();<br/>  // set the viewport<br/>  await page.setViewport({<br/>    width: browserWindowSize.width,<br/>    height: browserWindowSize.height,<br/>    deviceScaleFactor: 1,<br/>  });<br/>  // the initialized browser and page are returned<br/>  return { browser, page };<br/>};</span></pre><p id="0c97" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Based on different response flows, the agent would either navigate to a URL and take a screenshot, or click on a link which triggers a navigation and take a screenshot.</p><p id="6e35" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Step 2 — <code class="cx pl pm pn po b">URL Response Flow</code>: Navigate to a URL and take a screenshot</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="6e25" class="re oc fq po b bg rf rg l rh ri">export const navToUrlAndScreenshot = async (url: string, page: Page) =&gt; {<br/>  console.log(`...Opening ${url}`);<br/>  // validate the URL<br/>  if (!isValidURL(url)) {<br/>    throw new Error(`Invalid URL: ${url}`);<br/>  }<br/><br/>  // +++++ go to the URL +++++<br/>  await page.goto(url, {<br/>    // a simple logic to determine if the page is loaded: wait 500 ms after the number of active network requests are 2<br/>    waitUntil: "networkidle2",<br/>    timeout: TIMEOUT,<br/>  });<br/>  // +++++++++++++++++++++++++++<br/><br/>  // +++++ take a screenshot of the page +++++<br/>  // also include waiting for the page to load completely<br/>  const imagePath = await waitAndScreenshot(page);<br/>  // +++++++++++++++++++++++++++++++++++++++++<br/>  return imagePath;<br/>};</span></pre><p id="47fb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The <code class="cx pl pm pn po b">waitAndScreenshot</code> function</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="c724" class="re oc fq po b bg rf rg l rh ri">const waitAndScreenshot = async (page: Page) =&gt; {<br/>  // is the page still loading? `document.readyState` === 'loading' or there is a loading indicator on the page<br/>  const isLoading = await isPageExplicitlyLoading(page);<br/><br/>  // if the page is still loading, wait for the page to load completely<br/>  isLoading &amp;&amp; (await waitTillHTMLRendered(page));<br/><br/>  // apply Set-of-Mark Prompting<br/>  console.log(`...Highlight all interactive elements`);<br/>  await highlightInteractiveElements(page);<br/><br/>  // take a screenshot of the page<br/>  console.log(`...Taking screenshot`);<br/>  await page.screenshot({<br/>    //path: "/agent/web-agent-screenshot.jpg" is a wrong path<br/>    path: imagePath,<br/>    fullPage: true,<br/>  });<br/><br/>  return imagePath;<br/>};</span></pre><p id="e781" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The screenshot is simply taken by calling <code class="cx pl pm pn po b">page.screenshot()</code>. You may change the configuration to meet your needs.</p><p id="8c6c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The <code class="cx pl pm pn po b">waitTillHTMLRendered</code> function</p><p id="64a9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">As shown, the navigation to the URL is done via <code class="cx pl pm pn po b">page.goto()</code>. This method utilizes the <code class="cx pl pm pn po b">waitUntil</code> option for the page load. After the page is loaded, the agent takes a screenshot. It is very crucial to wait for all the visual content to be loaded before taking the screenshot to ensure the agent gets the full info of the page.</p><p id="1940" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Unfortunately, in many cases, the <code class="cx pl pm pn po b">waitUntil</code> in <code class="cx pl pm pn po b">GoToOptions</code> (page.goto()) is not enough to wait for the page to load completely (especially with dynamic loading content), so we need to use the custom function <code class="cx pl pm pn po b">waitTillHTMLRendered</code>.</p><p id="b54d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This function basically checks if the page is still loading via <code class="cx pl pm pn po b">document.readyState</code> or if there is a loading indicator on the page. If the page is still loading, the function will call <code class="cx pl pm pn po b">waitTillHTMLRendered</code> to undertake a comprehensive check:</p><ol class=""><li id="4143" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pk pd pe bk">It checks the HTML size every second.</li><li id="4893" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">If the HTML size remains the same for 3 consecutive seconds, it assumes the page has finished loading.</li><li id="5e61" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">Throw error if the page is still loading after 30 seconds (timeout).</li></ol><p id="9733" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The flowchart below shows the logic of the <code class="cx pl pm pn po b">waitTillHTMLRendered</code> function:</p></div></div><div class="np"><div class="ab cb"><div class="lm ps ln pt lo pu cf pv cg pw ci bh"><figure class="nk nl nm nn no np py pz paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rq"><img src="../Images/5620f6b1b199b44699cdf9b89410420e.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*0m-AIdYDBQwVNGFfSxR2EA.gif"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Flowchart of function <code class="cx pl pm pn po b">waitTillHTMLRendered.</code></figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="9d40" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To have a better understanding of the <code class="cx pl pm pn po b">waitAndScreenshot</code> function, let's take a look at the log of the function in action:</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rr"><img src="../Images/76781d17a83b9de376b0b37229a00f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CrG4DOjBZe0-M3VHykEnHA.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Logs capturing dynamic content rendering.</figcaption></figure><p id="a902" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">After the page is <strong class="ml fr">completely</strong> loaded, all interactive elements are highlighted and a screenshot is taken.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="6c38" class="re oc fq po b bg rf rg l rh ri">export const waitTillHTMLRendered = async (<br/>  page: Page,<br/>  timeout: number = 30000,<br/>  checkOnlyHTMLBody: boolean = false<br/>) =&gt; {<br/>  const waitTimeBetweenChecks: number = 1000;<br/>  const maximumChecks: number = timeout / waitTimeBetweenChecks; // assuming check itself does not take time<br/>  let lastHTMLSize = 0;<br/>  let stableSizeCount = 0;<br/>  const COUNT_THRESHOLD = 3;<br/><br/>  const isSizeStable = (currentSize: number, lastSize: number) =&gt; {<br/>    if (currentSize !== lastSize) {<br/>      return false; // still rendering<br/>    } else if (currentSize === lastSize &amp;&amp; lastSize === 0) {<br/>      return false; // page remains empty - failed to render<br/>    } else {<br/>      return true; // stable<br/>    }<br/>  };<br/><br/>  for (let i = 0; i &lt; maximumChecks; i++) {<br/>    const html = await page.content();<br/>    const currentHTMLSize = html.length;<br/>    const currentBodyHTMLSize = await page.evaluate(<br/>      () =&gt; document.body.innerHTML.length<br/>    );<br/><br/>    const currentSize = checkOnlyHTMLBody<br/>      ? currentBodyHTMLSize<br/>      : currentHTMLSize;<br/>    // logging<br/>    console.log(<br/>      "last: ",<br/>      lastHTMLSize,<br/>      " &lt;&gt; curr: ",<br/>      currentHTMLSize,<br/>      " body html size: ",<br/>      currentBodyHTMLSize<br/>    );<br/><br/>    stableSizeCount = isSizeStable(currentSize, lastHTMLSize)<br/>      ? stableSizeCount + 1<br/>      : 0;<br/>    console.log(`Stable size count: ${stableSizeCount}`);<br/>    <br/>    // if the HTML size remains the same for 3 consecutive seconds, it assumes the page has finished loading<br/>    if (stableSizeCount &gt;= COUNT_THRESHOLD) {<br/>      console.log("Page rendered fully..");<br/>      break;<br/>    }<br/><br/>    lastHTMLSize = currentSize;<br/>    await page.waitForTimeout(waitTimeBetweenChecks);<br/>  }<br/>};</span></pre><p id="35c2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Step 2 (cont.) — <code class="cx pl pm pn po b">Click Response Flow</code>: The <code class="cx pl pm pn po b">clickNavigationAndScreenshot</code> function</p><p id="4ded" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This function is used to click on a specific element on the page and wait for the page to load completely and then take a screenshot. For the <code class="cx pl pm pn po b">click</code> action, it utilizes another function called <code class="cx pl pm pn po b">clickOnLink</code>.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="ae4a" class="re oc fq po b bg rf rg l rh ri">export const clickNavigationAndScreenshot = async (<br/>  linkText: string,<br/>  page: Page,<br/>  browser: Browser<br/>) =&gt; {<br/>  let imagePath;<br/><br/>  try {<br/>    const navigationPromise = page.waitForNavigation();<br/>    // The Click action<br/>    const clickResponse = await clickOnLink(linkText, page);<br/><br/>    if (!clickResponse) {<br/>      // if the link triggers a navigation on the same page, wait for the page to load completely and then take a screenshot<br/>      await navigationPromise;<br/>      imagePath = await waitAndScreenshot(page);<br/>    } else {<br/>      // if the link opens in a new tab, ignore the navigationPromise as there won't be any navigation<br/>      navigationPromise.catch(() =&gt; undefined);<br/>      // switch to the new tab and take a screenshot<br/>      const newPage = await newTabNavigation(clickResponse, page, browser);<br/><br/>      if (newPage === undefined) {<br/>        throw new Error("The new page cannot be opened");<br/>      }<br/><br/>      imagePath = await waitAndScreenshot(newPage);<br/>    }<br/><br/>    return imagePath;<br/>  } catch (err) {<br/>    throw err;<br/>  }<br/>};</span></pre><p id="f401" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The <code class="cx pl pm pn po b">clickOnLink</code> function</p><p id="7327" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This function loops through all the elements with the <code class="cx pl pm pn po b">gpt-link-text</code> attribute (unique identifier received during element annotation) and clicks on the one that matches the link text provided by the LLM.</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="8c62" class="re oc fq po b bg rf rg l rh ri">const clickOnLink = async (linkText: string, page: Page) =&gt; {<br/>  try {<br/>    const clickResponse = await page.evaluate(async (linkText) =&gt; {<br/><br/>      const isHTMLElement = (element: Element): element is HTMLElement =&gt; {<br/>        return element instanceof HTMLElement;<br/>      };<br/><br/>      const elements = document.querySelectorAll("[gpt-link-text]");<br/><br/>      // loop through all elements with `gpt-link-text` attribute<br/>      for (const element of elements) {<br/><br/>        if (!isHTMLElement(element)) {<br/>          continue;<br/>        }<br/><br/>        // find the element that contains the targeted link text<br/>        if (<br/>          element<br/>            .getAttribute("gpt-link-text")<br/>            ?.includes(linkText.trim().toLowerCase())<br/>        ) {<br/>          // This if statement is to handle the case where the link opens in a new tab<br/>          if (element.getAttribute("target") === "_blank") {<br/>            return element.getAttribute("gpt-link-text");<br/>          }<br/><br/>          // highlight and perform the click action<br/>          element.style.backgroundColor = "rgba(255,255,0,0.25)";<br/>          element.click();<br/>          return;<br/>        }<br/><br/>      }<br/><br/>      // only if the loop ends without returning<br/>      throw new Error(`Link with text not found: "${linkText}"`);<br/>    }, linkText);<br/><br/>    return clickResponse;<br/>  } catch (err) {<br/>    if (err instanceof Error) {<br/>      throw err;<br/>    }<br/>  }<br/>};</span></pre><h2 id="d19c" class="qj oc fq bf od qk ql qm og qn qo qp oj ms qq qr qs mw qt qu qv na qw qx qy qz bk">Element Annotation Service</h2><p id="e53a" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">Let’s look deeper into the <code class="cx pl pm pn po b">highlightInteractiveElements</code> function that is called inside <code class="cx pl pm pn po b">waitAndScreenshot</code>.</p><p id="df15" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">It is a service that annotates the interactive HTML elements for the agent. It can highlight elements with a <code class="cx pl pm pn po b">red bounding box</code> and add unique identifiers to them.</p><p id="e11c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Imagine giving your AI agent a special pair of glasses that lets it see the interactive spots on a website — the buttons, links, and fields — like glowing treasures on a treasure map.</p><p id="4037" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">That’s essentially what the <code class="cx pl pm pn po b">highlightInteractiveElements</code> function does. It's like a highlighter for the digital world, sketching red boxes around clickable items and tagging them with digital nametags.</p><p id="93a8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">With the annotation, the accuracy of the agent’s interpretation of the image is largely improved</strong>. This concept is called <code class="cx pl pm pn po b">Set-of-Mark Prompting</code>.</p><p id="a7be" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Here is an example of the annotated screenshot:</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rs"><img src="../Images/b85a7f190d2179f011cdda31a784a805.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*41ZgBdcl0KiBnUzvJ4OwXQ.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">E-commerce site with interactive elements highlighted in red. Image from Officeworks website.</figcaption></figure><p id="b2c3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">There is a research paper discussing the importance of this topic in detail: <a class="af oa" href="https://arxiv.org/abs/2310.11441" rel="noopener ugc nofollow" target="_blank">Set-of-Mark Prompting</a>.</p><p id="47d2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Here’s how it performs:</p><ol class=""><li id="2890" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pk pd pe bk">It starts by removing any old digital nametags (html attribute <code class="cx pl pm pn po b">gpt-link-text</code>) that might confuse our AI.</li><li id="bccc" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">Then, it lights up every clickable thing it finds with a red outline to help the AI spot where to ‘click’.</li><li id="9f06" class="mj mk fq ml b go pf mn mo gr pg mq mr ms ph mu mv mw pi my mz na pj nc nd ne pk pd pe bk">Each interactive element gets a unique nametag. This tag/attribute will be used to identify the element that Puppeteer can later interact with.</li></ol><p id="eec4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">One key detail to remember is when dealing with puppeteer or any other testing framework that programmatically interacts with the web, the element with a link text may not be visible. Here is a simple example:</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="b6a0" class="re oc fq po b bg rf rg l rh ri">&lt;div style="display: none"&gt;<br/>  &lt;a href="https://www.example.com"&gt;<br/>    &lt;span&gt;Click me&lt;/span&gt;<br/>  &lt;/a&gt;<br/>&lt;/div&gt;</span></pre><p id="35f6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The parent div is hidden, so the link is not visible. This element should be excluded. Recursive checking the parent element is necessary to ensure the element is visible. See below graph for the logic:</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni rt"><img src="../Images/171f42e9c803a67604cb42a80db2a9c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I5K27AHE33-t4EeLH6_BQQ.gif"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Flowchart of function isElementVisible.</figcaption></figure><p id="e173" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Code implementation of the <code class="cx pl pm pn po b">highlightInteractiveElements</code> function</p><pre class="nk nl nm nn no rb po rc bp rd bb bk"><span id="62d2" class="re oc fq po b bg rf rg l rh ri">import { Page } from "puppeteer";<br/><br/>const INTERACTIVE_ELEMENTS = [<br/>  "a",<br/>  "button",<br/>  "input",<br/>  "textarea",<br/>  "[role=button]",<br/>  "[role=treeitem]",<br/>  '[onclick]:not([onclick=""])',<br/>];<br/>/**<br/> * Reset the unique identifier attribute and remove previously highlighted elements<br/> * @param page<br/> */<br/>const resetUniqueIdentifierAttribute = async (page: Page): Promise&lt;void&gt; =&gt; {<br/>  await page.evaluate(() =&gt; {<br/>    const UNIQUE_IDENTIFIER_ATTRIBUTE = "gpt-link-text";<br/>    const elements = document.querySelectorAll(<br/>      `[${UNIQUE_IDENTIFIER_ATTRIBUTE}]`<br/>    );<br/>    for (const element of elements) {<br/>      element.removeAttribute(UNIQUE_IDENTIFIER_ATTRIBUTE);<br/>    }<br/>  });<br/>};<br/>/**<br/> * This function annotates all the interactive elements on the page<br/> * @param page<br/> */<br/>const annotateAllInteractiveElements = async (page: Page) =&gt; {<br/>  // $$eval method runs Array.from(document.querySelectorAll(selector)) within the `page`and passes the result as the first argument to the pageFunction.<br/>  // If no elements match the selector, the first argument to the pageFunction is [].<br/>  await page.$$eval(<br/>    INTERACTIVE_ELEMENTS.join(", "), // the selector can be defined outside the browser context<br/>    // the argument `elements` can be an empty array if no elements match the selector<br/>    function (elements) {<br/>      // any console.log will not be visible in the node terminal<br/>      // instead, it will be visible in the browser console<br/>      // handle empty array<br/>      if (elements.length === 0) {<br/>        throw new Error("No elements found");<br/>      }<br/>      //======================================VALIDATE ELEMENT CAN INTERACT=================================================<br/>      // This run-time check must be defined inside the pageFunction as it is running in the browser context. If defined outside, it will throw an error: "ReferenceError: isHTMLElement is not defined"<br/>      const isHTMLElement = (element: Element): element is HTMLElement =&gt; {<br/>        // this assertion is to allow Element to be treated as HTMLElement and has `style` property<br/>        return element instanceof HTMLElement;<br/>      };<br/>      const isElementStyleVisible = (element: Element) =&gt; {<br/>        const style = window.getComputedStyle(element);<br/>        return (<br/>          style.display !== "none" &amp;&amp;<br/>          style.visibility !== "hidden" &amp;&amp;<br/>          style.opacity !== "0" &amp;&amp;<br/>          style.width !== "0px" &amp;&amp;<br/>          style.height !== "0px"<br/>        );<br/>      };<br/>      const isElementVisible = (element: Element | undefined | null) =&gt; {<br/>        if (element === null || element === undefined) {<br/>          throw new Error("isElementVisible: Element is null or undefined");<br/>        }<br/>        let currentElement: Element | null = element;<br/>        while (currentElement) {<br/>          if (!isElementStyleVisible(currentElement)) {<br/>            return false;<br/>          }<br/>          currentElement = currentElement.parentElement;<br/>        }<br/>        return true;<br/>      };<br/>      //========================================PREPARE UNIQUE IDENTIFIER================================================<br/>      const setUniqueIdentifierBasedOnTextContent = (element: Element) =&gt; {<br/>        const UNIQUE_IDENTIFIER_ATTRIBUTE = "gpt-link-text";<br/>        const { textContent, tagName } = element;<br/>        // if the node is a document or doctype, textContent will be null<br/>        if (textContent === null) {<br/>          return;<br/>        }<br/>        element.setAttribute(<br/>          UNIQUE_IDENTIFIER_ATTRIBUTE,<br/>          textContent.trim().toLowerCase()<br/>        );<br/>      };<br/>      //========================================HIGHLIGHT INTERACTIVE ELEMENTS================================================<br/>      for (const element of elements) {<br/>        if (isHTMLElement(element)) {<br/>          // highlight all the interactive elements with a red bonding box<br/>          element.style.outline = "2px solid red";<br/>        }<br/>        // assign a unique identifier to the element<br/>        if (isElementVisible(element)) {<br/>          // set a unique identifier attribute to the element<br/>          // this attribute will be used to identify the element that puppeteer should interact with<br/>          setUniqueIdentifierBasedOnTextContent(element);<br/>        }<br/>      }<br/>    }<br/>  );<br/>};<br/>/**<br/> * This function highlights all the interactive elements on the page<br/> * @param page<br/> */<br/>export const highlightInteractiveElements = async (page: Page) =&gt; {<br/>  await resetUniqueIdentifierAttribute(page);<br/>  await annotateAllInteractiveElements(page);<br/>};</span></pre><h1 id="b379" class="ob oc fq bf od oe of gq og oh oi gt oj ok ol om on oo op oq or os ot ou ov ow bk">Conclusion</h1><p id="38ae" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk">In this article, we have gone through the architecture of the AI agent, the code implementation of each step, and some concepts behind the design, such as Set-of-Mark Prompting. The agent is an elegant system that requires careful orchestration of different services to work effectively, and currently it has plenty of issues and limitations. If you have any questions or suggestions, please feel free to reach out to me. I would be happy to discuss this topic further.</p><h1 id="7efa" class="ob oc fq bf od oe of gq og oh oi gt oj ok ol om on oo op oq or os ot ou ov ow bk">Enjoyed This Story?</h1><p id="d0b9" class="pw-post-body-paragraph mj mk fq ml b go ox mn mo gr oy mq mr ms oz mu mv mw pa my mz na pb nc nd ne fj bk"><strong class="ml fr">Jason Li</strong> (<a class="af oa" href="https://medium.com/u/4092d7367010" rel="noopener">Tianyi Li</a>, <a class="af oa" href="https://www.linkedin.com/in/tianyi-li-jason/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>) is a Full-stack Developer working at <a class="af oa" href="https://www.mindsethealth.com/" rel="noopener ugc nofollow" target="_blank">Mindset Health</a> in Melbourne Australia. Jason is passionate about AI, front-end development and space related technologies.</p><p id="9fe4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Selina Li</strong> (<a class="af oa" href="https://medium.com/u/7b9ea39b0d79" rel="noopener">Selina Li</a>, <a class="af oa" href="https://www.linkedin.com/in/selina-zhuohang-li-3b7355120/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>) is a Principal Data Engineer working at <a class="af oa" href="https://www.officeworks.com.au/" rel="noopener ugc nofollow" target="_blank">Officeworks</a> in Melbourne Australia. Selina is passionate about AI/ML, data engineering and investment.</p><p id="39e1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Jason and Selina would love to explore technologies to help people achieve their goals.</p><p id="78cd" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><em class="ru">Unless otherwise noted, all images are by the authors.</em></p></div></div></div></div>    
</body>
</html>