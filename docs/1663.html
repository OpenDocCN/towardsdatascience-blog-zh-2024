<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>An Off-Beat Approach to Train-Test-Validation Split Your Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>An Off-Beat Approach to Train-Test-Validation Split Your Dataset</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-off-beat-approach-to-train-test-validation-split-your-dataset-esp-small-ones-650492b735fb?source=collection_archive---------2-----------------------#2024-07-07">https://towardsdatascience.com/an-off-beat-approach-to-train-test-validation-split-your-dataset-esp-small-ones-650492b735fb?source=collection_archive---------2-----------------------#2024-07-07</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="22c7" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Ensuring distributional integrity in splits of small datasets</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@soniamarpreet17?source=post_page---byline--650492b735fb--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Amarpreet Singh" class="l ep by dd de cx" src="../Images/eaa74303ea5583d1bfb44364883ef53f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/0*ymhf5ydTZnrs0pZ0."/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--650492b735fb--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@soniamarpreet17?source=post_page---byline--650492b735fb--------------------------------" rel="noopener follow">Amarpreet Singh</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--650492b735fb--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 7, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/fa894c871e506a99304ada5e4808197d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cF-MJtmL1hR7D_iNPkunbg.jpeg"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Generated with Microsoft Designer</figcaption></figure><p id="2b15" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We all require to sample our population to perform <strong class="nd fr">statistical analysis</strong> and gain insights. When we do so, the aim is to ensure that our sample’s distribution closely matches that of the population.</p><p id="c9fd" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For this, we have various methods: <strong class="nd fr">simple random sampling</strong> (where every member of the population has an equal chance of being selected), <strong class="nd fr">stratified sampling</strong> (which involves dividing the population into subgroups and sampling from each subgroup), <strong class="nd fr">cluster sampling</strong> (where the population is divided into clusters and entire clusters are randomly selected), <strong class="nd fr">systematic sampling</strong> (which involves selecting every nth member of the population), etc etc. Each method has its advantages and is chosen based on the specific needs and characteristics of the study.</p><p id="e029" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In this article, we won’t be focusing on sampling methods themselves per se, but rather on using these concepts to split the dataset used for machine learning approaches into <strong class="nd fr">Train-Test-Validation</strong> sets. These approaches work for all kinds of <strong class="nd fr">Tabular data</strong>. We will be working in Python here.</p><p id="74e4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Below are some approaches that you already might know:</p><h1 id="d749" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">1. Simple Train-Test-Val Split</h1><p id="48f3" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">This approach uses <strong class="nd fr">random-sampling</strong> method.<br/>Example code:</p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="40f5" class="pc ny fq oz b bg pd pe l pf pg">from sklearn.model_selection import train_test_split<br/># Assuming X is your feature set and y is your target variable<br/>X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)<br/>X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)</span></pre><h1 id="81ef" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">2. Stratified Train-Test-Val Split</h1><p id="8d15" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">This approach ensures that the splits maintain the <strong class="nd fr">same proportion of classes</strong> as the original dataset (with random sampling again of course), which is useful for imbalanced datasets. This approach will work when your target variable is <strong class="nd fr">not a continuous variable.</strong></p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="a0c0" class="pc ny fq oz b bg pd pe l pf pg">from sklearn.model_selection import train_test_split<br/><br/># Stratified split to maintain class distribution<br/>X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)<br/>X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)</span></pre><h1 id="f5cf" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">3. K-Fold Cross-Validation</h1><p id="65c7" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">In K-Fold cross-validation, the dataset is split into <code class="cx ph pi pj oz b">k</code> subsets (folds). The model is trained on <code class="cx ph pi pj oz b">k-1</code> folds and tested on the remaining fold. This process is repeated <code class="cx ph pi pj oz b">k</code> times.</p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="5f86" class="pc ny fq oz b bg pd pe l pf pg">from sklearn.model_selection import KFold, train_test_split<br/><br/>kf = KFold(n_splits=5, shuffle=True, random_state=42)<br/><br/>for train_index, test_index in kf.split(X):<br/>    X_train, X_test = X[train_index], X[test_index]<br/>    y_train, y_test = y[train_index], y[test_index]<br/>    <br/>    # Further split X_train and y_train into train and validation sets<br/>    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)<br/>    <br/>    # Now you have X_train, X_val, X_test, y_train, y_val, y_test for each fold<br/>    # You can now train and evaluate your model using these sets</span></pre><h1 id="b509" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">4. Stratified K-Fold Cross-Validation</h1><p id="c871" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">As the name suggests, this is a combination of Stratified sampling and K-fold cross-validation.</p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="5c8d" class="pc ny fq oz b bg pd pe l pf pg">from sklearn.model_selection import StratifiedKFold, train_test_split<br/><br/>skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)<br/><br/>for train_index, test_index in skf.split(X, y):<br/>    X_train, X_test = X[train_index], X[test_index]<br/>    y_train, y_test = y[train_index], y[test_index]<br/>    <br/>    # Further split X_train and y_train into train and validation sets<br/>    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)<br/>    <br/>    # Now you have X_train, X_val, X_test, y_train, y_val, y_test for each fold<br/>    # You can now train and evaluate your model using these sets</span></pre><p id="1151" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Full example usage:</p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="c68f" class="pc ny fq oz b bg pd pe l pf pg">from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score<br/><br/># Initialize lists to store the scores for each fold<br/>accuracy_scores = []<br/>precision_scores = []<br/>recall_scores = []<br/>f1_scores = []<br/><br/>skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)<br/><br/>for train_index, test_index in skf.split(X, y): #y is a categorical target variable<br/>    X_train, X_test = X[train_index], X[test_index]<br/>    y_train, y_test = y[train_index], y[test_index]<br/>    <br/>    # Further split X_train and y_train into train and validation sets<br/>    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)<br/>    <br/>    # Train the model<br/>    model = LogisticRegression(random_state=42)<br/>    model.fit(X_train, y_train)<br/>    <br/>    # Validate the model<br/>    y_val_pred = model.predict(X_val)<br/>    val_accuracy = accuracy_score(y_val, y_val_pred)<br/>    val_precision = precision_score(y_val, y_val_pred, average='weighted')<br/>    val_recall = recall_score(y_val, y_val_pred, average='weighted')<br/>    val_f1 = f1_score(y_val, y_val_pred, average='weighted')<br/>    <br/>    print(f"Validation Scores - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1 Score: {val_f1}")<br/>    <br/>    # Test the model<br/>    y_test_pred = model.predict(X_test)<br/>    test_accuracy = accuracy_score(y_test, y_test_pred)<br/>    test_precision = precision_score(y_test, y_test_pred, average='weighted')<br/>    test_recall = recall_score(y_test, y_test_pred, average='weighted')<br/>    test_f1 = f1_score(y_test, y_test_pred, average='weighted')<br/>    <br/>    # Store the scores<br/>    accuracy_scores.append(test_accuracy)<br/>    precision_scores.append(test_precision)<br/>    recall_scores.append(test_recall)<br/>    f1_scores.append(test_f1)<br/>    <br/>    print(f"Test Scores - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}")<br/><br/># Calculate and print the average scores across all folds<br/>print(f"\nAverage Test Scores across all folds - Accuracy: {sum(accuracy_scores) / len(accuracy_scores)}, Precision: {sum(precision_scores) / len(precision_scores)}, Recall: {sum(recall_scores) / len(recall_scores)}, F1 Score: {sum(f1_scores) / len(f1_scores)}")</span></pre><p id="9bb0" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Now, you can use these methods to split your dataset but they have the following <strong class="nd fr">limitations</strong>:</p><ul class=""><li id="2067" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw pk pl pm bk"><strong class="nd fr"><em class="pn">Random Train-Test-Val Split</em></strong><em class="pn">:</em> This method can’t guarantee <strong class="nd fr">similar</strong> <strong class="nd fr">distributions</strong> among the splits, especially if the dataset is not large enough or if there is an imbalance in the target variable.</li><li id="a616" class="nb nc fq nd b go po nf ng gr pp ni nj nk pq nm nn no pr nq nr ns ps nu nv nw pk pl pm bk"><strong class="nd fr"><em class="pn">Stratified Split</em></strong><em class="pn">:</em> This method is useful only when you have a <strong class="nd fr">non-continuous</strong> target variable (y). Although there are workarounds for continuous target variables (such as converting the continuous variable into categorical through some conditions, e.g., if y ≥ quartile1 → 1, else 0), these approaches may still not always ensure similar distributions among the splits.</li></ul><p id="affe" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Now, suppose you have a <strong class="nd fr">small</strong> total number of observations in your dataset and it’s difficult to ensure similar distributions amongst your splits. In that case, you can combine <strong class="nd fr">clustering</strong> and <strong class="nd fr">random sampling (or stratified sampling)</strong>.</p><p id="9ae8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Below is how I did it for <strong class="nd fr">my problem</strong> at hand:</p><h1 id="01dc" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">5. Clustering-based Train-Test-Validation split</h1><p id="692c" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">In this method, first, we cluster our dataset and then use sampling methods on each cluster to obtain our data splits.</p><p id="9717" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For example, using <strong class="nd fr"><em class="pn">HDBSCAN:</em></strong></p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="5bb2" class="pc ny fq oz b bg pd pe l pf pg">import hdbscan<br/>from sklearn.metrics import silhouette_score<br/>from sklearn.model_selection import ParameterGrid<br/>import random<br/>random.seed(48) #for regeneration of same results<br/><br/>def get_clusters(df):<br/>  to_drop =["cluster_", "ID"]<br/>  req_cols = sorted(set(df.columns) - set(to_drop))<br/>  X = df[req_cols] #keep only required columns in X<br/>  X_std = X.values #no need of scaling the training set for HDBSCAN<br/><br/>  # Define parameter grid for HDBSCAN, you can play with this grid accordingly<br/>  param_grid = {<br/>      'min_cluster_size': list(range(2,20))<br/>      #'min_samples': [1, 2, 3]<br/>  }<br/><br/>  best_score = -1<br/>  best_params = None<br/><br/>  # Iterate over parameter grid<br/>  for params in ParameterGrid(param_grid):<br/>    model = hdbscan.HDBSCAN(**params, gen_min_span_tree=True)<br/>    cluster_labels = model.fit_predict(X_std)<br/>    unique_labels = np.unique(cluster_labels)<br/>    if len(unique_labels) &gt; 1:  # Check if more than one cluster is formed<br/>      silhouette_avg = silhouette_score(X_std, cluster_labels) if len(unique_labels) &gt; 1 else -1<br/>      if silhouette_avg &gt; best_score:<br/>        best_score = silhouette_avg<br/>        best_params = params<br/><br/>  if best_params is not None:<br/>    print(best_params)<br/>    best_model = hdbscan.HDBSCAN(**best_params, gen_min_span_tree=True)<br/>    cluster_labels = best_model.fit_predict(X_std) #get cluster labels from best model<br/>    df["cluster_"] = [str(i) for i in cluster_labels]<br/>  else:<br/>    print("HDBSCAN produced only one cluster label. Unable to split the data.")<br/>    df["cluster_"] = "0" #when no clusters are found<br/><br/>  return df</span></pre><p id="4586" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">You can also use other clustering methods according to your problem for eg. <strong class="nd fr"><em class="pn">K-Means clustering</em></strong>:</p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="d60a" class="pc ny fq oz b bg pd pe l pf pg">import matplotlib.pyplot as plt<br/>from sklearn.cluster import KMeans<br/>from sklearn.metrics import silhouette_score<br/>from sklearn.preprocessing import StandardScaler<br/>from yellowbrick.cluster import KElbowVisualizer<br/><br/>def get_clusters(df):<br/><br/>  to_drop =["cluster_", "ID"]<br/>  req_cols = sorted(set(df.columns) - set(to_drop))<br/>  X = df[req_cols].values #keep only required columns in X<br/><br/>  scaler = StandardScaler()<br/>  X_std = scaler.fit_transform(X) #scaling is needed in case of K-Means<br/><br/>  model = KMeans()<br/>  visualizer = KElbowVisualizer(model, k=(2, 50)) #you can play with the range accordingly<br/>  visualizer.fit(X_std)<br/>  #visualizer.show()<br/><br/><br/>  optimal_n_clusters = visualizer.elbow_value_  #using elbow method to get optimal no. of clusters<br/>  kmeans = KMeans(n_clusters=optimal_n_clusters, random_state=42)<br/>  kmeans.fit(X_std)<br/><br/>  clust_labels = [str(i) for i in kmeans.labels_]<br/><br/>  # Evaluate the clustering using silhouette score<br/>  silhouette_avg = silhouette_score(X_std, clust_labels)<br/><br/>  df["cluster_"] = clust_labels<br/><br/>return df</span></pre><p id="b891" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Now you can also add <strong class="nd fr">levels of granularities</strong> (any categorical variable) to your dataset to get more refined clusters as follows:</p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="c218" class="pc ny fq oz b bg pd pe l pf pg">import matplotlib.pyplot as plt<br/>from sklearn.cluster import KMeans<br/>from sklearn.metrics import silhouette_score<br/>from sklearn.preprocessing import StandardScaler<br/>from yellowbrick.cluster import KElbowVisualizer<br/><br/>def get_clusters(df):<br/>  # taking animal categorical variable as a level of granularity to split on<br/>  grp1 = df.loc[(df['animal']=='cat')]<br/>  grp2 = df.loc[(df['animal']=='dog')]<br/><br/>  temps = []<br/>  for num, temp in enumerate([grp1, grp2]):<br/>    to_drop =["cluster_", "ID"]<br/>    final_cols = sorted(set(temp.columns) - set(to_drop))<br/>    X = temp[final_cols]<br/><br/>    X = X.values<br/>    scaler = StandardScaler()<br/>    X_std = scaler.fit_transform(X) #scaling of variables is needed for K-Means clustering<br/><br/>    model = KMeans()<br/>    visualizer = KElbowVisualizer(model, k=(2, 50))<br/>    visualizer.fit(X_std)<br/>    # visualizer.show()<br/>    <br/>    #get optimal no. of clusters, K using elbow method<br/>    optimal_n_clusters = visualizer.elbow_value_  <br/>    kmeans = KMeans(n_clusters=optimal_n_clusters, random_state=42) <br/>    kmeans.fit(X_std)<br/><br/>    clust_labels = [str(num) + "_" + str(i) for i in kmeans.labels_]<br/><br/>    # Evaluate the clustering using silhouette score<br/>    silhouette_avg = silhouette_score(X_std, clust_labels)<br/><br/>    temp["cluster_"] = clust_labels<br/>    temps.append(temp)<br/>  <br/>  df = pd.concat(temps, axis=0)<br/><br/>  return df</span></pre><p id="a5c9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Once you have obtained <strong class="nd fr">cluster labels</strong> from any clustering method, you can use <strong class="nd fr">random sampling or stratified sampling</strong> to select samples from each cluster.</p><p id="da7b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We will select indices randomly and then use these indices to select our train-test-val sets as follows:</p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="2d42" class="pc ny fq oz b bg pd pe l pf pg">import numpy as np<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/><br/># Assuming df is your DataFrame, "cluster_" is the column with cluster labels,<br/>unique_clusters = df["cluster_"].unique()<br/><br/>train_indices = []<br/>val_indices = []<br/>test_indices = []<br/><br/>for cluster in unique_clusters:<br/>    cluster_data = df[df["cluster_"] == cluster]<br/>    cluster_indices = cluster_data.index.values<br/>    cluster_y = cluster_data['y'].values<br/><br/>    if stratify_ == True: #if you have categorical target variable<br/>      train_idx, temp_idx, _, temp_y = train_test_split(cluster_indices, cluster_y, test_size=0.4, stratify=cluster_y, random_state=42)<br/>      val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=temp_y, random_state=42)<br/>    else:<br/>      # Split indices of the current cluster into train and temp (which will be further split into val and test)<br/>      train_idx, temp_idx = train_test_split(cluster_indices, test_size=0.4, random_state=42)<br/>      val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)<br/>    <br/>    <br/>    train_indices.extend(train_idx)<br/>    val_indices.extend(val_idx)<br/>    test_indices.extend(test_idx)<br/><br/># Convert the indices lists to numpy arrays<br/>train_indices = np.array(train_indices)<br/>val_indices = np.array(val_indices)<br/>test_indices = np.array(test_indices)<br/><br/># Assuming 'X' are the features and 'y' is the target column<br/>X = df.drop(columns=['y', 'cluster_']).values<br/>y = df['y'].values<br/><br/># Select the corresponding data for train, validation, and test sets<br/>X_train, y_train = X[train_indices], y[train_indices]<br/>X_val, y_val = X[val_indices], y[val_indices]<br/>X_test, y_test = X[test_indices], y[test_indices]</span></pre><p id="522a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As per <strong class="nd fr">my use-case</strong>, it was useful to sort my target variable y and then select every <strong class="nd fr">1st, 2nd, and 3rd</strong> indices for train, test, and validation set respectively (all mutually exclusive), a.k.a <strong class="nd fr">systematic random sampling </strong>as below:</p><pre class="ml mm mn mo mp oy oz pa bp pb bb bk"><span id="f129" class="pc ny fq oz b bg pd pe l pf pg">def get_indices(df):<br/>  np.random.seed(seed=48)<br/><br/>  total_length = len(df)<br/>  sample1_length = int(0.60 * total_length) #you can choose proportion accordingly<br/>  remaining_length = total_length - sample1_length<br/><br/>  sample2_length = int(remaining_length / 2)<br/>  sample3_length = total_length - (sample1_length + sample2_length)<br/>  <br/>  #create an array with range 0 - length of the df<br/>  all_indxs = np.array(range(total_length))<br/><br/>  # Create arrays of indices divisible by 2 and 3 exclusively<br/>  indices_divisible_by_2 = np.array(list(set(np.where(all_indxs % 2 == 0)[0]) - set(np.where(all_indxs % 6 == 0)[0])))<br/>  indices_divisible_by_3 = np.array(list(set(np.where(all_indxs % 3 == 0)[0]) - set([0])))<br/>  <br/>  #randomly choose indices divisibly by 2 with sample2_length<br/>  sample2_indices = sorted(indices_divisible_by_2[np.random.choice(len(indices_divisible_by_2), size=sample2_length, replace=False)])<br/>  try:<br/>    sample3_indices = sorted(indices_divisible_by_3[np.random.choice(len(indices_divisible_by_3), size=sample3_length, replace=False)])<br/>  except:<br/>    sample3_indices = []<br/>  <br/>  sample1_indices = sorted(set(all_indxs) - set(sample2_indices) - set(sample3_indices))<br/><br/>  return sample1_indices, sample2_indices, sample3_indices</span></pre><pre class="pt oy oz pa bp pb bb bk"><span id="058d" class="pc ny fq oz b bg pd pe l pf pg">indices_train = []<br/>indices_test = []<br/>indices_val = []<br/><br/>for num, cluster in enumerate(df['cluster_'].unique()):<br/>  temp_df = df[df['cluster_'] == cluster]<br/>  sample1_indices, sample2_indices, sample3_indices = get_indices(temp_df)<br/>  indices_train.append(list(temp_df.iloc[sample1_indices].index))<br/>  indices_test.append(list(temp_df.iloc[sample2_indices].index))<br/>  indices_val.append(list(temp_df.iloc[sample3_indices].index))<br/><br/># to flatten the list of lists containing indices for train,test,val set<br/>indices_train = [x for xs in indices_train for x in xs]<br/>indices_test = [x for xs in indices_test for x in xs]<br/>indices_val = [x for xs in indices_val for x in xs]</span></pre><pre class="pt oy oz pa bp pb bb bk"><span id="d6b8" class="pc ny fq oz b bg pd pe l pf pg">def traintestvalsplit(df, id_col, cols_to_drop, cont_var, train_indices, test_indices, val_indices):<br/><br/>  train, test, val = df.loc[train_indices], df.loc[test_indices], df.loc[val_indices]<br/><br/>  # Split the data into train, validation, and test sets based on indices<br/>  X_train = train.drop(cols_to_drop + [cont_var] ,axis=1) #add which columns to drop<br/>  X_test = test.drop(cols_to_drop + [cont_var] ,axis=1)<br/>  X_val = val.drop(cols_to_drop + [cont_var] ,axis=1)<br/><br/>  y_train = train[[cont_var]] #target variable<br/>  y_test = test[[cont_var]]<br/>  y_val = val[[cont_var]]<br/><br/>  train_ids = train[[id_col]] #to preserve the IDs<br/>  test_ids = test[[id_col]]<br/>  val_ids = val[[id_col]]<br/><br/>  print("Train set size:", X_train.shape, len(train_ids))<br/>  print("Test set size:", X_test.shape, len(test_ids))<br/>  print("Validation set size:", X_val.shape, len(val_ids))<br/><br/>  return X_train, X_val, X_test, y_train, y_val, y_test, train_ids, val_ids, test_ids<br/><br/>X_train, X_val, X_test, y_train, y_val, y_test, train_ids, val_ids, test_ids = traintestvalsplit(df, id_col, cols_to_drop, cont_var, train_indices, test_indices, val_indices)</span></pre><p id="cdcf" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The above-discussed approaches of combining clustering with different sampling methods are very useful when you have a small number of observations in your dataset as they ensure to maintain similar distributions amongst the Train, Test and Validation sets.</p><p id="d4d7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Thanks for reading, and I hope you find this article helpful!</p></div></div></div></div>    
</body>
</html>