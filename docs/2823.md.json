["```py\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import WeightedRandomSampler\nfrom torch.utils.data import random_split\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n```", "```py\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using {device} device\")\n\n# Specify hyperparameters\nminibatch_size = 10\nlearning_rate = 0.01\nepochs = 60\n```", "```py\n# Define loader function\ndef custom_loader(path):\n    with open(path, 'rb') as f:\n        img = Image.open(f)\n        img = img.crop((50, 60, 750, 460))  #Size: 700x400 px\n        img.load()\n        return img\n\n# Path of images (local to accelerate loading)\npath = \"data/Coil_Vision/01_train_val_test\"\n```", "```py\n# Transform function for loading\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5), (0.5))])\n\n# Create dataset out of folder structure\ndataset = datasets.ImageFolder(path, transform=transform, loader=custom_loader)\ntrain_set, val_set, test_set = random_split(dataset, [round(0.5*len(dataset)), \n                                                      round(0.3*len(dataset)), \n                                                      round(0.2*len(dataset))])\n```", "```py\n# Define a sampler to balance the classes\n# training dataset\nlbls = [dataset[idx][1] for idx in train_set.indices]\nbc = np.bincount(lbls)\np_nOK = bc.sum()/bc[0]\np_OK = bc.sum()/bc[1]\nlst_train = [p_nOK if lbl==0 else p_OK for lbl in lbls]\ntrain_sampler = WeightedRandomSampler(weights=lst_train, num_samples=len(lbls))\n```", "```py\n# Define loader with batchsize\ntrain_loader = DataLoader(dataset=train_set, batch_size=minibatch_size, sampler=train_sampler)\nval_loader = DataLoader(dataset=val_set, batch_size=minibatch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_set, shuffle=True)\n```", "```py\n# Figure and axes object\nfig, axs = plt.subplots(nrows=2, ncols=5, figsize=(20,7), sharey=True, sharex=True)\n\ncount_OK = 0\ncount_nOK = 0\n\n# Loop over loader batches\nfor (batch_data, batch_lbls) in train_loader:\n\n    # Loop over batch_lbls\n    for i, lbl in enumerate(batch_lbls):\n\n        # If label is 0 (nOK) plot image in row 1\n        if (lbl.item() == 0) and (count_nOK < 5):\n            axs[1, count_nOK].imshow(batch_data[i][0], cmap='gray')\n            axs[1, count_nOK].set_title(f\"nOK Part#: {str(count_nOK)}\", fontsize=14)\n            count_nOK += 1\n\n        # If label is 1 (OK) plot image in row 0\n        elif (lbl.item() == 1) and (count_OK < 5):\n            axs[0, count_OK].imshow(batch_data[i][0], cmap='gray')\n            axs[0, count_OK].set_title(f\"OK Part#: {str(count_OK)}\", fontsize=14)\n            count_OK += 1\n\n    # If both counters are >=5 stop looping\n    if (count_OK >=5) and (count_nOK >=5):\n        break\n\n# Config the plot canvas\nfig.suptitle(\"Sample plot of OK and nonOK Parts\", fontsize=24)\nplt.setp(axs, xticks=[], yticks=[]) \nplt.show()\n```", "```py\nclass CNN(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n\n        # Define model layers\n        self.model_layers = nn.Sequential(\n\n            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Flatten(),\n            nn.Linear(16*97*172, 120),\n            nn.ReLU(),\n            nn.Linear(120, 2)\n        )\n\n    def forward(self, x):\n        out = self.model_layers(x)\n        return out\n```", "```py\n# Define model on cpu or gpu\nmodel = CNN().to(device)\n\n# Loss and optimizer\nloss = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n```", "```py\n# Count number of parameters / thereof trainable\nnum_param = sum([p.numel() for p in model.parameters()])\nnum_param_trainable = sum([p.numel() for p in model.parameters() if p.requires_grad == True])\n\nprint(f\"Our model has {num_param:,} parameters. Thereof trainable are {num_param_trainable:,}!\")\n```", "```py\ndef val_test(dataloader, model):\n    # Get dataset size\n    dataset_size = len(dataloader.dataset)\n\n    # Turn off gradient calculation for validation\n    with torch.no_grad():\n        # Loop over dataset\n        correct = 0\n        wrong_preds = []\n        for (images, labels) in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            # Get raw values from model\n            output = model(images)\n\n            # Derive prediction\n            y_pred = output.argmax(1)\n\n            # Count correct classifications over all batches\n            correct += (y_pred == labels).type(torch.float32).sum().item()\n\n            # Save wrong predictions (image, pred_lbl, true_lbl)\n            for i, _ in enumerate(labels):\n                if y_pred[i] != labels[i]:\n                    wrong_preds.append((images[i], y_pred[i], labels[i]))\n\n        # Calculate accuracy\n        acc = correct / dataset_size\n\n    return acc, wrong_preds\n```", "```py\nacc_train = {}\nacc_val = {}\n# Iterate over epochs\nfor epoch in range(epochs):\n\n    n_correct=0; n_samples=0; n_true_OK=0\n    for idx, (images, labels) in enumerate(train_loader):\n        model.train()\n        # Push data to gpu if available\n        images, labels = images.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        l = loss(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        l.backward()\n        optimizer.step()\n\n        # Get prediced labels (.max returns (value,index))\n        _, y_pred = torch.max(outputs.data, 1)\n\n        # Count correct classifications\n        n_correct += (y_pred == labels).sum().item()\n        n_true_OK += (labels == 1).sum().item()\n        n_samples += labels.size(0)\n\n    # At end of epoch: Eval accuracy and print information\n    if (epoch+1) % 2 == 0:\n        model.eval()\n        # Calculate accuracy\n        acc_train[epoch+1] = n_correct / n_samples\n        true_OK = n_true_OK / n_samples\n        acc_val[epoch+1] = val_test(val_loader, model)[0]\n\n        # Print info\n        print (f\"Epoch [{epoch+1}/{epochs}], Loss: {l.item():.4f}\")\n        print(f\"      Training accuracy: {acc_train[epoch+1]*100:.2f}%\")\n        print(f\"      True OK: {true_OK*100:.3f}%\")\n        print(f\"      Validation accuracy: {acc_val[epoch+1]*100:.2f}%\")\n\n# Save model and state_dict\ntorch.save(model, \"model.pth\")\n```", "```py\n# Instantiate figure and axe object\nfig, ax = plt.subplots(figsize=(10,6))\nplt.plot(list(acc_train.keys()), list(acc_train.values()), label=\"training accuracy\")\nplt.plot(list(acc_val.keys()), list(acc_val.values()), label=\"validation accuracy\")\nplt.title(\"Accuracies\", fontsize=24)\nplt.ylabel(\"%\", fontsize=14)\nplt.xlabel(\"Epochs\", fontsize=14)\nplt.setp(ax.get_xticklabels(), fontsize=14)\nplt.legend(loc='best', fontsize=14)\nplt.show()\n```", "```py\n# Read model from file\nmodel = torch.load(\"model.pth\")\nmodel.eval()\n```", "```py\nprint(f\"test accuracy: {val_test(test_loader,model)[0]*100:0.1f}%\")\n```", "```py\n%matplotlib inline\n\n# Call test function\ntup = val_test(test_loader, model)\n\n# Check if wrong predictions occur\nif len(tup[1])>=1:\n\n    # Loop over wrongly predicted images\n    for i, t in enumerate(tup[1]):\n        plt.figure(figsize=(7,5))\n        img, y_pred, y_true = t\n        img = img.to(\"cpu\").reshape(400, 700)\n        plt.imshow(img, cmap=\"gray\")\n        plt.title(f\"Image {i+1} - Predicted: {y_pred}, True: {y_true}\", fontsize=24)\n        plt.axis(\"off\")\n        plt.show()\n        plt.close()\nelse:\n    print(\"No wrong predictions!\")\n```", "```py\n# Load the required libraries\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Define the CNN model exactly as in chapter 2.8\nclass CNN(nn.Module):\n\n    def __init__(self):\n        super(CNN, self).__init__()\n\n        # Define model layers\n        self.model_layers = nn.Sequential(\n\n            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Flatten(),\n            nn.Linear(16*97*172, 120),\n            nn.ReLU(),\n            nn.Linear(120, 2),\n            #nn.LogSoftmax(dim=1)\n        )\n\n    def forward(self, x):\n        out = self.model_layers(x)\n        return out\n\n# Load the model's parameters\nmodel = torch.load(\"model.pth\")\nmodel.eval()\n```", "```py\n# Define custom dataset\nclass Predict_Set(Dataset):\n    def __init__(self, img_folder, transform):\n        self.img_folder = img_folder\n        self.transform = transform\n        self.img_lst = os.listdir(self.img_folder)\n\n    def __len__(self):\n        return len(self.img_lst)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_folder, self.img_lst[idx])\n        img = Image.open(img_path)\n        img = img.crop((50, 60, 750, 460))  #Size: 700x400\n        img.load()\n        img_tensor = self.transform(img)\n        return img_tensor, self.img_lst[idx]\n```", "```py\n# Path to images (preferably local to accelerate loading)\npath = \"data/Coil_Vision/02_predict\"\n\n# Transform function for loading\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5), (0.5))])\n\n# Create dataset as instance of custom dataset\npredict_set = Predict_Set(path, transform=transform)\n\n# Define loader\npredict_loader = DataLoader(dataset=predict_set)\n```", "```py\ndef predict(dataloader, model):\n\n    # Turn off gradient calculation\n    with torch.no_grad():\n\n        img_lst = []; y_pred_lst = []; name_lst = []\n        # Loop over data loader\n        for image, name in dataloader:\n            img_lst.append(image)\n            image = image.to(device)\n\n            # Get raw values from model\n            output = model(image)\n\n            # Derive prediction\n            y_pred = output.argmax(1)\n            y_pred_lst.append(y_pred.item())\n            name_lst.append(name[0])\n\n    return img_lst, y_pred_lst, name_lst\n```", "```py\n# Predict labels for images\nimgs, lbls, names  = predict(predict_loader, model)\n\n# Iterate over classified images\nfor idx, image in enumerate(imgs):\n    plt.figure(figsize=(8,6))\n    plt.imshow(image.squeeze(), cmap=\"gray\")\n    plt.title(f\"\\nFile: {names[idx]}, Predicted label: {lbls[idx]}\", fontsize=18)\n    plt.axis(\"off\")\n    plt.show()\n    plt.close()\n```", "```py\n# Empty lists to store the layers and the weights\nall_layers = []; conv_weights = []\n\n# Iterate over the model's structure\n# (First level nn.Sequential)\nfor _, layer in enumerate(list(model.children())[0]):\n    if type(layer) == nn.Conv2d:\n        all_layers.append(layer)\n        conv_weights.append(layer.weight)\n    elif type(layer) in [nn.ReLU, nn.MaxPool2d]:\n        all_layers.append(layer)\n        conv_weights.append(\"*\")\n\n# Print layers and dimensions of weights\nfor idx, layer in enumerate(all_layers):\n    print(f\"{idx+1}. Layer: {layer}\")\n    if type(layer) == nn.Conv2d:\n        print(f\"          weights: {conv_weights[idx].shape}\")\n    else:\n        print(f\"          weights: {conv_weights[idx]}\")\n    print()\n```", "```py\nimport itertools\n\n# Iterate through all layers\nfor idx_out, layer in enumerate(all_layers):\n\n    # If layer is a convolutional filter\n    if type(layer) == nn.Conv2d:\n\n        # Print layer name\n        print(f\"\\n{idx_out+1}. Layer: {layer} \\n\")\n\n        # Prepare plot and weights\n        plt.figure(figsize=(25,6))\n        weights = conv_weights[idx_out][:,0,:,:] # only first input channel\n        weights = weights.detach().to('cpu')\n\n        # Enumerate over filter weights (only first input channel)\n        for idx_in, f in enumerate(weights):\n            plt.subplot(2,8, idx_in+1)\n            plt.imshow(f, cmap=\"gray\")\n            plt.title(f\"Filter {idx_in+1}\")\n\n            # Print texts\n            for i, j in itertools.product(range(f.shape[0]), range(f.shape[1])):\n                if f[i,j] > f.mean():\n                    color = 'black'\n                else:\n                    color = 'white'\n                plt.text(j, i, format(f[i, j], '.2f'), horizontalalignment='center', verticalalignment='center', color=color)\n\n            plt.axis(\"off\")\n        plt.show()\n        plt.close() \n```", "```py\n# Test loader has a batch size of 1\nimg = next(iter(test_loader))[0].to(device)\nprint(f\"\\nImage has shape: {img.shape}\\n\")\n\n# Plot image\nimg_copy = img.to('cpu')\nplt.imshow(img_copy.reshape(400,700), cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n```", "```py\n# Pass the image through the first layer\nresults = [all_layers[0](img)]\n\n# Pass the results of the previous layer to the next layer\nfor idx in range(1, len(all_layers)):  # Start at 1, first layer already passed!\n    results.append(all_layers[idx](results[-1]))  # Pass the last result to the layer\n```", "```py\ndef gradCAM(x):\n\n    # Run model and predict\n    logits = model(x)\n    pred = logits.max(-1)[-1] # Returns index of max value (0 or 1)\n\n    # Fetch activations at final conv layer\n    last_conv = model.model_layers[:5]\n    activations = last_conv(x)\n\n    # Compute gradients with respect to model's prediction\n    model.zero_grad()\n    logits[0,pred].backward(retain_graph=True)\n\n    # Compute average gradient per output channel of last conv layer\n    pooled_grads = model.model_layers[3].weight.grad.mean((1,2,3))\n\n    # Multiply each output channel with its corresponding average gradient\n    for i in range(activations.shape[1]):\n        activations[:,i,:,:] *= pooled_grads[i]\n\n    # Compute heatmap as average over all weighted output channels\n    heatmap = torch.mean(activations, dim=1)[0].cpu().detach()\n\n    return heatmap\n```", "```py\nimport cv2\n\ndef upsampleHeatmap(map, img):\n    m,M = map.min(), map.max()\n    i,I = img.min(), img.max()\n    map = 255 * ((map-m) / (M-m))\n    img = 255 * ((img-i) / (I-i))\n    map = np.uint8(map)\n    img = np.uint8(img)\n    map = cv2.resize(map, (700,400))\n    map = cv2.applyColorMap(255-map, cv2.COLORMAP_JET)\n    map = np.uint8(map)\n    img = cv2.applyColorMap(255-img, cv2.COLORMAP_JET)\n    img = np.uint8(img)\n    map = np.uint8(map*0.7 + img*0.3)\n    return map\n```", "```py\n# Iterate over dataloader\nfor idx, (image, name) in enumerate(predict_loader):\n\n    # Compute heatmap\n    image = image.to(device)\n    heatmap = gradCAM(image)\n    image = image.cpu().squeeze(0).permute(1,2,0)\n    heatmap = upsampleHeatmap(heatmap, image)\n\n    # Plot images and heatmaps\n    fig = plt.figure(figsize=(14,5))\n    fig.suptitle(f\"\\nFile: {names[idx]}, Predicted label: {lbls[idx]}\\n\", fontsize=24)\n    plt.subplot(1, 2, 1)\n    plt.imshow(image, cmap=\"gray\")\n    plt.title(f\"Image\", fontsize=14)\n    plt.axis(\"off\")\n    plt.subplot(1, 2, 2)\n    plt.imshow(heatmap)\n    plt.title(f\"Heatmap\", fontsize=14)\n    plt.tight_layout()\n    plt.axis(\"off\")\n    plt.show()\n    plt.close()\n```"]