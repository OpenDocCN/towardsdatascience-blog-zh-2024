- en: Training LLM, from Scratch, in Rust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/training-llm-from-scratch-in-rust-03381bbd7204?source=collection_archive---------2-----------------------#2024-12-26](https://towardsdatascience.com/training-llm-from-scratch-in-rust-03381bbd7204?source=collection_archive---------2-----------------------#2024-12-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this companion article, I’ll show my implementation for training from scratch
    a GPT-like model, in Rust. No GPUs, only CPUs, with a performance 30 times better
    than the native C code.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://stefanobosisio1.medium.com/?source=post_page---byline--03381bbd7204--------------------------------)[![Stefano
    Bosisio](../Images/450d904024a4cbf1adf8a625886d852e.png)](https://stefanobosisio1.medium.com/?source=post_page---byline--03381bbd7204--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--03381bbd7204--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--03381bbd7204--------------------------------)
    [Stefano Bosisio](https://stefanobosisio1.medium.com/?source=post_page---byline--03381bbd7204--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--03381bbd7204--------------------------------)
    ·14 min read·Dec 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2d10b30f55a0cd780f399191ce3b8e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [GoogleDeepMind](https://unsplash.com/@googledeepmind) on [Unsplash](https://unsplash.com/photos/a-close-up-of-a-metal-object-on-a-white-surface-yyl3iDuS3s8)
  prefs: []
  type: TYPE_NORMAL
- en: In my last [article](https://medium.com/towards-data-science/writing-llms-in-rust-looking-for-an-efficient-matrix-multiplication-e9539b0cb9d3),
    I introduced the problem of matrix multiplication, how the attention algorithm
    uses matrix multiplication to perform an averaging process, and how to efficiently
    implement — or at least, for me — a matrix multiplication function in Rust with
    [Blas](https://docs.rs/blas/latest/blas/).
  prefs: []
  type: TYPE_NORMAL
- en: In this new article, I want to show my first building block for implementing
    [llm.c](https://github.com/karpathy/llm.c) in Rust, namely, training a GPT-like
    model from scratch using Rust. This has been my way of learning more and more
    about the Rust ecosystem and understanding how comparable is with C. In particular,
    **I want my code to be able to train a GPT-like model, starting from GPT weights,
    using only CPUs**— so no GPUs or TPUs. My aim is to understand how much we can
    push these models on simple laptops, and how much the Rust ecosystem can be used
    for this. **Eventually, this code may also be useful to fine-tune GPT models with
    a given input corpus**.
  prefs: []
  type: TYPE_NORMAL
- en: All the relevant pieces of code can be found [here](https://github.com/Steboss/llm.rust).
  prefs: []
  type: TYPE_NORMAL
