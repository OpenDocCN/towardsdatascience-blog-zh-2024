# éšæœºæ£®æ—è§£æï¼šå¸¦æœ‰ä»£ç ç¤ºä¾‹çš„è§†è§‰æŒ‡å—

> åŸæ–‡ï¼š[https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07](https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07)

## é›†æˆå­¦ä¹ 

## ç”¨éšæœºæ ‘åšå‡ºæƒŠäººçš„é¢„æµ‹

[](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Samy Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------) [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------) Â·é˜…è¯»æ—¶é—´12åˆ†é’ŸÂ·2024å¹´11æœˆ7æ—¥

--

[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------) [## å†³ç­–æ ‘åˆ†ç±»å™¨è§£æï¼šå¸¦æœ‰ä»£ç ç¤ºä¾‹çš„åˆå­¦è€…è§†è§‰æŒ‡å—

### ä»å…¨æ–°çš„è§’åº¦çœ‹æˆ‘ä»¬æœ€å–œçˆ±çš„å€’ç«‹æ ‘

towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)

[å†³ç­–æ ‘](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹â€”â€”å®ƒä»¬ç›´è§‚ä¸”æ˜“äºç†è§£ã€‚ä½†æœ‰ä¸€ä¸ªé—®é¢˜ï¼šå®ƒä»¬åœ¨å¤„ç†æ–°æ•°æ®æ—¶å¾€å¾€æ•ˆæœä¸å¥½ã€‚é¢„æµ‹ç»“æœå¯èƒ½ä¸ç¨³å®šä¸”ä¸å¯é ï¼Œè¿™åœ¨ä½ è¯•å›¾æ„å»ºæœ‰ç”¨çš„ä¸œè¥¿æ—¶æ˜¯ä¸€ä¸ªçœŸæ­£çš„é—®é¢˜ã€‚

è¿™æ—¶ï¼Œéšæœºæ£®æ—å°±æ´¾ä¸Šç”¨åœºäº†ã€‚å®ƒç»“åˆäº†å†³ç­–æ ‘çš„ä¼˜ç‚¹ï¼Œå¹¶é€šè¿‡å°†å¤šæ£µæ ‘ç»“åˆåœ¨ä¸€èµ·ï¼Œä½¿å®ƒä»¬çš„æ•ˆæœæ›´å¥½ã€‚å®ƒå·²ç»æˆä¸ºè®¸å¤šæ•°æ®ç§‘å­¦å®¶æœ€å–œçˆ±çš„å·¥å…·ï¼Œå› ä¸ºå®ƒæ—¢æœ‰æ•ˆåˆå®ç”¨ã€‚

è®©æˆ‘ä»¬æ¥çœ‹çœ‹éšæœºæ£®æ—æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä»¥åŠå®ƒä¸ºä»€ä¹ˆå¯èƒ½æ­£æ˜¯ä½ ä¸‹ä¸€ä¸ªé¡¹ç›®æ‰€éœ€è¦çš„ã€‚æ˜¯æ—¶å€™ä¸å†è¿·å¤±åœ¨æ ‘æœ¨ä¸­ï¼ŒçœŸæ­£çœ‹åˆ°æ£®æ—çš„å…¨è²Œâ€”â€”ä½ ä¸‹ä¸€ä¸ªå¯é çš„æœºå™¨å­¦ä¹ å·¥å…·ã€‚

![](../Images/a46fad3053f42f475b5f070c27b60998.png)

æ‰€æœ‰å›¾åƒï¼šä½œè€…ä½¿ç”¨Canva Proåˆ›å»ºã€‚ä¼˜åŒ–äº†ç§»åŠ¨è®¾å¤‡æ˜¾ç¤ºï¼›åœ¨æ¡Œé¢è®¾å¤‡ä¸Šå¯èƒ½ä¼šæ˜¾å¾—è¿‡å¤§ã€‚

# å®šä¹‰

éšæœºæ£®æ—æ˜¯ä¸€ç§é›†æˆæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå®ƒç»“åˆäº†å¤šä¸ªå†³ç­–æ ‘ã€‚æ£®æ—ä¸­çš„æ¯ä¸€æ£µæ ‘éƒ½åœ¨æ•°æ®çš„éšæœºæ ·æœ¬ä¸Šè¿›è¡Œè®­ç»ƒï¼ˆè‡ªåŠ©é‡‡æ ·ï¼‰ï¼Œå¹¶ä¸”åœ¨åšå‡ºåˆ†è£‚æ—¶ä»…è€ƒè™‘ç‰¹å¾çš„éšæœºå­é›†ï¼ˆç‰¹å¾éšæœºåŒ–ï¼‰ã€‚

å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œæ£®æ—é€šè¿‡æ ‘ä¹‹é—´çš„å¤šæ•°æŠ•ç¥¨æ¥è¿›è¡Œé¢„æµ‹ï¼›è€Œå¯¹äºå›å½’ä»»åŠ¡ï¼Œå®ƒé€šè¿‡å¹³å‡å„æ£µæ ‘çš„é¢„æµ‹ç»“æœæ¥è¿›è¡Œé¢„æµ‹ã€‚è¯¥æ¨¡å‹çš„ä¼˜åŠ¿æ¥è‡ªäºå®ƒçš„â€œé›†ä½“æ™ºæ…§â€æ–¹æ³•â€”â€”è™½ç„¶å•æ£µæ ‘å¯èƒ½ä¼šçŠ¯é”™ï¼Œä½†é›†ä½“å†³ç­–è¿‡ç¨‹**å¾€å¾€èƒ½å°†è¿™äº›é”™è¯¯å¹³å‡åŒ–**ï¼Œä»è€Œå¾—å‡ºæ›´å¯é çš„é¢„æµ‹ç»“æœã€‚

![](../Images/a7c8ea0333ddfcdeb2779b785e896929.png)

éšæœºæ£®æ—æ˜¯è¢‹è£…ï¼ˆè‡ªåŠ©èšåˆï¼‰ç®—æ³•çš„ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºå®ƒä½¿ç”¨æ•°æ®çš„ä¸åŒéšæœºéƒ¨åˆ†æ¥æ„å»ºæ¯æ£µæ ‘ï¼Œå¹¶å°†å®ƒä»¬çš„ç»“æœç»“åˆèµ·æ¥ã€‚

# ä½¿ç”¨çš„æ•°æ®é›†

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä»¥ç»å…¸çš„é«˜å°”å¤«æ•°æ®é›†ä¸ºåˆ†ç±»ä»»åŠ¡çš„ä¾‹å­è¿›è¡Œè®²è§£ã€‚è™½ç„¶éšæœºæ£®æ—æ—¢å¯ä»¥å¤„ç†åˆ†ç±»ä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥å¤„ç†å›å½’ä»»åŠ¡ï¼Œä½†æˆ‘ä»¬å°†é›†ä¸­è®¨è®ºåˆ†ç±»éƒ¨åˆ†â€”â€”æ ¹æ®å¤©æ°”æ¡ä»¶é¢„æµ‹æŸäººæ˜¯å¦ä¼šæ‰“é«˜å°”å¤«ã€‚æˆ‘ä»¬æ¢è®¨çš„æ¦‚å¿µä¹Ÿå¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºå›å½’é—®é¢˜ï¼ˆä¾‹å¦‚é¢„æµ‹çƒå‘˜æ•°é‡ï¼‰ï¼Œä½¿ç”¨ç›¸åŒçš„åŸç†ã€‚

![](../Images/05586d1dcea17f8a18206b58019181ea.png)

åˆ—ï¼šâ€˜Overcastï¼ˆè¢«ä¸€çƒ­ç¼–ç æˆ3åˆ—ï¼‰â€™ï¼Œâ€™Temperatureï¼ˆåæ°æ¸©åº¦ï¼‰â€™ï¼Œâ€˜Humidityï¼ˆæ¹¿åº¦ï¼Œ%ï¼‰â€™ï¼Œâ€˜Windyï¼ˆæ˜¯å¦æœ‰é£ï¼ŒYes/Noï¼‰â€™å’Œâ€˜Playï¼ˆæ˜¯å¦æ‰“çƒï¼ŒYes/Noï¼Œç›®æ ‡ç‰¹å¾ï¼‰â€™

```py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# Create and prepare dataset
dataset_dict = {
    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 
                'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy',
                'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast',
                'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],
    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,
                   72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,
                   88.0, 77.0, 79.0, 80.0, 66.0, 84.0],
    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,
                 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,
                 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],
    'Wind': [False, True, False, False, False, True, True, False, False, False, True,
             True, False, True, True, False, False, True, False, True, True, False,
             True, False, False, True, False, False],
    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',
             'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',
             'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']
}

# Prepare data
df = pd.DataFrame(dataset_dict)
df = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)
df['Wind'] = df['Wind'].astype(int)
df['Play'] = (df['Play'] == 'Yes').astype(int)

# Rearrange columns
column_order = ['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind', 'Play']
df = df[column_order]

# Prepare features and target
X,y = df.drop('Play', axis=1), df['Play']
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)
```

# ä¸»è¦æœºåˆ¶

ä»¥ä¸‹æ˜¯éšæœºæ£®æ—çš„å·¥ä½œåŸç†ï¼š

1.  **è‡ªåŠ©é‡‡æ ·ï¼ˆBootstrap Samplingï¼‰ï¼š** æ¯æ£µæ ‘éƒ½æœ‰è‡ªå·±çš„ç‹¬ç‰¹è®­ç»ƒé›†ï¼Œè¿™äº›è®­ç»ƒé›†æ˜¯é€šè¿‡ä»åŸå§‹æ•°æ®ä¸­éšæœºæŠ½æ ·å¹¶å…è®¸é‡å¤æŠ½å–å¾—åˆ°çš„ã€‚è¿™æ„å‘³ç€ä¸€äº›æ•°æ®ç‚¹å¯èƒ½ä¼šå‡ºç°å¤šæ¬¡ï¼Œè€Œå…¶ä»–æ•°æ®ç‚¹åˆ™æœªè¢«ä½¿ç”¨ã€‚

1.  **éšæœºç‰¹å¾é€‰æ‹©ï¼š** åœ¨è¿›è¡Œåˆ†è£‚æ—¶ï¼Œæ¯æ£µæ ‘åªè€ƒè™‘ä¸€ä¸ªéšæœºçš„ç‰¹å¾å­é›†ï¼ˆé€šå¸¸æ˜¯æ€»ç‰¹å¾æ•°çš„å¹³æ–¹æ ¹ï¼‰ã€‚

1.  **ç”Ÿé•¿æ ‘æœ¨ï¼š** æ¯æ£µæ ‘ä»…ä½¿ç”¨å…¶è‡ªåŠ©æ ·æœ¬å’Œé€‰å®šçš„ç‰¹å¾è¿›è¡Œç”Ÿé•¿ï¼Œè¿›è¡Œåˆ†è£‚ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢ç‚¹ï¼ˆå¦‚çº¯å‡€ç»„æˆ–æœ€å°æ ·æœ¬é‡ï¼‰ã€‚

1.  **æœ€ç»ˆé¢„æµ‹ï¼š** æ‰€æœ‰æ ‘ä¸€èµ·æŠ•ç¥¨å†³å®šæœ€ç»ˆçš„é¢„æµ‹ç»“æœã€‚å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œé‡‡ç”¨ç±»åˆ«é¢„æµ‹çš„å¤šæ•°æŠ•ç¥¨ï¼›å¯¹äºå›å½’ä»»åŠ¡ï¼Œè®¡ç®—æ‰€æœ‰æ ‘çš„é¢„æµ‹å€¼çš„å¹³å‡å€¼ã€‚

![](../Images/3e815426c28ac98519c4884d12f43fac.png)

éšæœºæ£®æ—åˆ†ç±»å™¨é€šè¿‡ç»“åˆæ¥è‡ª100æ£µä¸åŒå†³ç­–æ ‘çš„ç»“æœæ¥è¿›è¡Œé¢„æµ‹ï¼Œæ¯æ£µæ ‘åˆ†æçš„ç‰¹å¾åŒ…æ‹¬æ¸©åº¦å’Œå¤©æ°”æ¡ä»¶ã€‚æœ€ç»ˆçš„é¢„æµ‹æ¥è‡ªæ‰€æœ‰æ ‘ä¸­æœ€å¸¸è§çš„ç­”æ¡ˆã€‚

# è®­ç»ƒæ­¥éª¤

éšæœºæ£®æ—ç®—æ³•æ„å»ºå¤šä¸ªå†³ç­–æ ‘å¹¶å°†å®ƒä»¬ç»“åˆèµ·æ¥ã€‚å…¶å·¥ä½œåŸç†å¦‚ä¸‹ï¼š

**æ­¥éª¤1ï¼šè‡ªåŠ©æ ·æœ¬åˆ›å»º**

1.0\. è®¾ç½®æ ‘çš„æ•°é‡ï¼ˆé»˜è®¤ = 100ï¼‰

1.1\. å¯¹äºæ£®æ—ä¸­çš„æ¯ä¸€æ£µæ ‘ï¼š

a. é€šè¿‡ä»åŸå§‹æ•°æ®ä¸­è¿›è¡ŒéšæœºæŠ½æ ·å¹¶å…è®¸é‡å¤æŠ½å–ï¼Œç›´åˆ°è¾¾åˆ°åŸå§‹æ•°æ®é›†çš„å¤§å°ã€‚è¿™è¢«ç§°ä¸º**è‡ªåŠ©é‡‡æ ·**ã€‚

b. æ ‡è®°å¹¶å°†æœªé€‰ä¸­çš„æ ·æœ¬ä½œä¸ºè¢‹å¤–ï¼ˆOOBï¼‰æ ·æœ¬ä¿ç•™ï¼Œä»¥ä¾¿åç»­è¿›è¡Œè¯¯å·®ä¼°ç®—

![](../Images/1671fe794bccb45ec5a642740a8d0d8f.png)

éšæœºæ£®æ—é€šè¿‡ä»åŸå§‹è®­ç»ƒé›†ä¸­éšæœºé€‰æ‹©æ•°æ®ç‚¹ä¸ºæ¯æ£µæ ‘åˆ›å»ºä¸åŒçš„è®­ç»ƒé›†ï¼ŒæŸäº›æ•°æ®ç‚¹å¯èƒ½ä¼šè¢«å¤šæ¬¡é€‰æ‹©ã€‚æœªä½¿ç”¨çš„æ•°æ®ç‚¹åˆ™æˆä¸ºæµ‹è¯•é›†ï¼Œç”¨äºæ£€æŸ¥æ¯æ£µæ ‘çš„æ€§èƒ½ã€‚

```py
# Generate 100 bootstrap samples
n_samples = len(X_train)
n_bootstraps = 100
all_bootstrap_indices = []
all_oob_indices = []

np.random.seed(42)  # For reproducibility
for i in range(n_bootstraps):
    # Generate bootstrap sample indices
    bootstrap_indices = np.random.choice(n_samples, size=n_samples, replace=True)

    # Find OOB indices
    oob_indices = list(set(range(n_samples)) - set(bootstrap_indices))

    all_bootstrap_indices.append(bootstrap_indices)
    all_oob_indices.append(oob_indices)

# Print details for samples 1, 2, and 100
samples_to_show = [0, 1, 99]

for i in samples_to_show:
    print(f"\nBootstrap Sample {i+1}:")
    print(f"Chosen indices: {sorted(all_bootstrap_indices[i])}")
    print(f"Number of unique chosen indices: {len(set(all_bootstrap_indices[i]))}")
    print(f"OOB indices: {sorted(all_oob_indices[i])}")
    print(f"Number of OOB samples: {len(all_oob_indices[i])}")
    print(f"Percentage of OOB: {len(all_oob_indices[i])/n_samples*100:.1f}%")
```

![](../Images/fd0d49cc5d9614e8b4d96dedd10a6ca2.png)

æ³¨æ„ï¼ŒOOBçš„ç™¾åˆ†æ¯”æ˜¯å¤šä¹ˆç›¸ä¼¼ï¼Ÿåœ¨è¿›è¡Œ*n*æ ·æœ¬çš„è‡ªåŠ©æ³•æŠ½æ ·æ—¶ï¼Œæ¯ä¸ªæ ·æœ¬å¤§çº¦æœ‰37%çš„æœºä¼šæ°¸è¿œä¸ä¼šè¢«é€‰æ‹©ã€‚è¿™æ¥è‡ªäºæ¦‚ç‡è®¡ç®—ï¼ˆ1â€“1/*n*)*â¿*ï¼Œéšç€*n*çš„å¢å¤§ï¼Œå®ƒæ¥è¿‘1/e â‰ˆ 0.368ã€‚å› æ­¤ï¼Œæ¯æ£µæ ‘æœ€ç»ˆä½¿ç”¨çº¦63%çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå…¶ä½™çš„37%æˆä¸ºOOBæ ·æœ¬ã€‚

**æ­¥éª¤2ï¼šæ ‘çš„æ„å»º**

2.1. ä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œä½¿ç”¨å®Œæ•´çš„è‡ªåŠ©æ³•æ ·æœ¬

![](../Images/58dd94d352eb90afbfe2312662b55270.png)

åœ¨æ„å»ºæ¯æ£µå†³ç­–æ ‘æ—¶ï¼Œéšæœºæ£®æ—ä¼šè€ƒè™‘æ•°æ®ç‚¹çš„å­é›†ï¼Œå¹¶åŸºäºè¿™äº›æ•°æ®ç‚¹çš„å€¼æå‡ºåˆ†å‰²é—®é¢˜â€”â€”å°†è¾ƒå°çš„å€¼åˆ†é…åˆ°å·¦ä¾§ï¼Œå°†è¾ƒå¤§çš„å€¼åˆ†é…åˆ°å³ä¾§è¿›è¡Œé¢„æµ‹ã€‚

a. ä½¿ç”¨èŠ‚ç‚¹ä¸­çš„æ‰€æœ‰æ ·æœ¬è®¡ç®—åˆå§‹èŠ‚ç‚¹æ‚è´¨

Â· åˆ†ç±»ï¼šåŸºå°¼æŒ‡æ•°æˆ–ç†µ

Â· å›å½’ï¼šå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰

![](../Images/49ffa6509e2a0b7efc710bf7c8891e58.png)

éšæœºæ£®æ—é¦–å…ˆè®¡ç®—æ•´ä¸ªæ•°æ®é›†çš„åŸºå°¼æ‚è´¨ï¼ˆåœ¨ä»»ä½•åˆ†å‰²ä¹‹å‰ï¼‰ï¼Œä½¿ç”¨YESå’ŒNOæ ‡ç­¾çš„æ¯”ä¾‹â€”â€”è¿™æ˜¯ä¸€ç§è¡¡é‡å½“å‰æ•°æ®ä¸­æ ‡ç­¾æ··åˆç¨‹åº¦çš„æŒ‡æ ‡ã€‚

b. ä»æ€»å¯ç”¨ç‰¹å¾ä¸­é€‰æ‹©éšæœºå­é›†ï¼š

Â· åˆ†ç±»ï¼šâˆšn_features

Â· å›å½’ï¼šn_features/3

![](../Images/71393bd15609a6d43354efe5d9f06ac3.png)

å¯¹äºæ ‘ä¸­çš„æ¯æ¬¡åˆ†å‰²ï¼Œéšæœºæ£®æ—ä¼šéšæœºé€‰æ‹©ä¸€ä¸ªå¤©æ°”ç‰¹å¾çš„å­é›†ï¼ˆè¿™é‡Œæ˜¯ä»6ä¸ªç‰¹å¾ä¸­é€‰æ‹©2ä¸ªï¼‰æ¥è¿›è¡Œè€ƒè™‘ï¼Œä»è€Œä½¿æ¯æ£µæ ‘å…³æ³¨æ•°æ®çš„ä¸åŒæ–¹é¢ã€‚

c. å¯¹æ¯ä¸ªé€‰å®šçš„ç‰¹å¾ï¼š

Â· æŒ‰ç‰¹å¾å€¼å¯¹æ•°æ®ç‚¹è¿›è¡Œæ’åº

Â· ç¡®å®šæ½œåœ¨çš„åˆ†å‰²ç‚¹ï¼ˆè¿ç»­å”¯ä¸€ç‰¹å¾å€¼ä¹‹é—´çš„ä¸­ç‚¹ï¼‰

![](../Images/31b2530c2f2eab495683e971a5cc88da.png)

å¯¹äºæ¯ä¸ªé€‰å®šçš„ç‰¹å¾ï¼Œéšæœºæ£®æ—ä¼šæŸ¥çœ‹æ’åºåçš„æ•°æ®ä¸­æ‰€æœ‰å¯èƒ½çš„åˆ†å‰²ç‚¹ï¼ˆå¦‚æ¸©åº¦å€¼66.0ã€69.0ã€71.0ç­‰ï¼‰ï¼Œä»¥æ‰¾å‡ºæœ€ä½³çš„æ–¹å¼å°†æ•°æ®åˆ†ä¸ºä¸¤ç»„ã€‚

d. å¯¹æ¯ä¸ªæ½œåœ¨çš„åˆ†å‰²ç‚¹ï¼š

Â· å°†æ ·æœ¬åˆ†ä¸ºå·¦å³ä¸¤ç»„

Â· ä½¿ç”¨å…¶æ ·æœ¬è®¡ç®—å·¦å­èŠ‚ç‚¹çš„æ‚è´¨

Â· ä½¿ç”¨å…¶æ ·æœ¬è®¡ç®—å³å­èŠ‚ç‚¹çš„æ‚è´¨

Â· è®¡ç®—æ‚è´¨å‡å°‘ï¼š

parent_impurity â€” (left_weight Ã— left_impurity + right_weight Ã— right_impurity)

![](../Images/3a76a1bc476cd60a143540debd4b04b3.png)

ä¸ºäº†æ‰¾åˆ°æœ€ä½³åˆ†å‰²ç‚¹ï¼Œéšæœºæ£®æ—ä¼šè®¡ç®—æ¯ä¸ªå¯èƒ½åˆ†å‰²ç‚¹çš„åŸºå°¼æ‚è´¨ï¼ŒåŸºäºç»„çš„å¤§å°è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œå¹¶é€‰æ‹©é‚£ä¸ªèƒ½æœ€å¤§ç¨‹åº¦å‡å°‘çˆ¶èŠ‚ç‚¹æ‚è´¨çš„åˆ†å‰²ç‚¹ã€‚

e. ä½¿ç”¨æä¾›æœ€å¤§çº¯åº¦å‡å°‘çš„ç‰¹å¾å’Œåˆ†å‰²ç‚¹æ¥åˆ†å‰²å½“å‰èŠ‚ç‚¹çš„æ•°æ®ã€‚ç„¶åå°†æ•°æ®ç‚¹ä¼ é€’ç»™å„è‡ªçš„å­èŠ‚ç‚¹ã€‚

![](../Images/e71e8da4672712136d3478ad9d1cd59b.png)

åœ¨æ¯”è¾ƒæ‰€æœ‰å¯èƒ½çš„åˆ†å‰²åï¼Œéšæœºæ£®æ—é€‰æ‹©73.5Â°Fçš„æ¸©åº¦é˜ˆå€¼ï¼Œå› ä¸ºå®ƒæä¾›äº†æœ€å¤§çš„çº¯åº¦å‡å°‘ï¼ˆ0.041ï¼‰ï¼Œå¹¶åˆ›å»ºäº†ä¸¤ä¸ªåˆ†ç»„ï¼šä¸€ä¸ªæ˜¯ä½äº73.5Â°Fçš„æ··åˆç»„ï¼Œå¦ä¸€ä¸ªæ˜¯çº¯å‡€ç»„ã€‚

f. å¯¹æ¯ä¸ªå­èŠ‚ç‚¹ï¼Œé‡å¤è¿‡ç¨‹ï¼ˆæ­¥éª¤b-eï¼‰ï¼Œç›´åˆ°ï¼š

- çº¯èŠ‚ç‚¹æˆ–æœ€å°ä¸çº¯åº¦å‡å°‘

- æœ€å°æ ·æœ¬æ•°é˜ˆå€¼

- æœ€å¤§æ·±åº¦

- æœ€å¤§å¶å­èŠ‚ç‚¹æ•°

![](../Images/8e9f1677218a52ede01934cdc731077e.png)

è¿™ä¸ªè¿‡ç¨‹å¯¹æ¯ä¸ªæ–°çš„åˆ†ç»„ï¼ˆèŠ‚ç‚¹ï¼‰ç»§ç»­è¿›è¡Œï¼šéšæœºé€‰æ‹©ç‰¹å¾ï¼Œæ‰¾åˆ°æœ€ä½³çš„åˆ†å‰²ç‚¹ï¼Œå¹¶è¿›ä¸€æ­¥åˆ’åˆ†æ•°æ®ï¼Œç›´åˆ°æ¯ä¸ªåˆ†ç»„æ˜¯çº¯å‡€çš„ï¼ˆå…¨éƒ¨ä¸ºYESæˆ–å…¨éƒ¨ä¸ºNOï¼‰æˆ–æ— æ³•å†åˆ†å‰²ã€‚

**æ­¥éª¤3ï¼šæ ‘æ„å»º** å¯¹å…¶ä»–è‡ªåŠ©æŠ½æ ·é‡å¤æ•´ä¸ªæ­¥éª¤2ã€‚

![](../Images/5a6197d5a37f101b794221d1c2c3383d.png)

éšæœºæ£®æ—ä¸­çš„æ¯æ£µå†³ç­–æ ‘é€šè¿‡ä½¿ç”¨ä¸åŒçš„ç‰¹å¾å’Œé˜ˆå€¼ä»¥ä¸åŒçš„æ–¹å¼åˆ†å‰²æ•°æ®ã€‚è¿™ç§å¤šæ ·æ€§å¸®åŠ©æ£®æ—åšå‡ºæ¯”å•æ£µæ ‘æ›´å¥½çš„é¢„æµ‹ã€‚

```py
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
from sklearn.ensemble import RandomForestClassifier

# Train Random Forest
np.random.seed(42)  # For reproducibility
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Create visualizations for trees 1, 2, and 100
trees_to_show = [0, 1, 99]  # Python uses 0-based indexing
feature_names = X_train.columns.tolist()
class_names = ['No', 'Yes']

# Set up the plot
fig, axes = plt.subplots(1, 3, figsize=(20, 6), dpi=300)  # Reduced height, increased DPI
fig.suptitle('Decision Trees from Random Forest', fontsize=16)

# Plot each tree
for idx, tree_idx in enumerate(trees_to_show):
    plot_tree(rf.estimators_[tree_idx], 
              feature_names=feature_names,
              class_names=class_names,
              filled=True,
              rounded=True,
              ax=axes[idx],
              fontsize=10)  # Increased font size
    axes[idx].set_title(f'Tree {tree_idx + 1}', fontsize=12)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
```

![](../Images/b46220bdf49910aa49e1d13e353fe1fc.png)

å½“å‰çš„scikit-learnå®ç°ä¸­æ— æ³•ç›´æ¥è®¿é—®å†…éƒ¨çš„è‡ªåŠ©æŠ½æ ·ç´¢å¼•ï¼Œå› æ­¤ç”Ÿæˆçš„æ ‘ä¸æˆ‘ä»¬ä¹‹å‰ç¤ºä¾‹ä¸­è®¡ç®—çš„æ ‘ä¸åŒã€‚

# æµ‹è¯•æ­¥éª¤

å¯¹äºé¢„æµ‹ï¼Œé€šè¿‡æ‰€æœ‰æ ‘è·¯ç”±æ–°æ ·æœ¬å¹¶è¿›è¡Œæ±‡æ€»ï¼š

- åˆ†ç±»ï¼šå¤šæ•°æŠ•ç¥¨

- å›å½’ï¼šå¹³å‡é¢„æµ‹

![](../Images/e8bd423acc3d8361e5ce82ec3fd542e4.png)

å½“æ–°æ•°æ®è¿›å…¥æ—¶ï¼Œéšæœºæ£®æ—ä¸­çš„æ¯æ£µæ ‘ä½¿ç”¨è‡ªå·±çš„å†³ç­–è·¯å¾„è¿›è¡Œé¢„æµ‹ã€‚æ£®æ—ç»“åˆæ‰€æœ‰è¿™äº›é¢„æµ‹ï¼ˆ74ä¸ªYESä¸26ä¸ªNOï¼‰ï¼Œå¹¶é€šè¿‡å¤šæ•°æŠ•ç¥¨å¾—åˆ°æœ€ç»ˆç­”æ¡ˆï¼ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­æ˜¯YESï¼‰ã€‚

## è¢‹å¤–ï¼ˆOOBï¼‰è¯„ä¼°

è®°ä½é‚£äº›æœªè¢«ç”¨äºè®­ç»ƒæ¯æ£µæ ‘çš„æ ·æœ¬â€”â€”é‚£å‰©ä¸‹çš„1/3ï¼Ÿå®ƒä»¬å°±æ˜¯ä½ çš„OOBæ ·æœ¬ã€‚éšæœºæ£®æ—ä¸ä»…ä»…æ˜¯å¿½ç•¥å®ƒä»¬ï¼Œè€Œæ˜¯å°†å®ƒä»¬ä½œä¸ºæ¯æ£µæ ‘çš„ä¾¿æ·éªŒè¯é›†ã€‚

![](../Images/afccd043882db9aba10d7e5fb93558e5.png)

æ¯æ£µæ ‘éƒ½ä¼šåœ¨å…¶è‡ªå·±çš„è¢‹å¤–æ ·æœ¬ä¸Šè¿›è¡Œæµ‹è¯•ï¼ˆå³æœªç”¨äºè®­ç»ƒçš„æ•°æ®ï¼‰ã€‚é€šè¿‡å¹³å‡è¿™äº›å•ä¸ªçš„OOBå‡†ç¡®ç‡å¾—åˆ†ï¼ˆ50%ã€66.6%ã€60%ï¼‰ï¼Œéšæœºæ£®æ—æä¾›äº†ä¸€ç§å†…å»ºçš„æ–¹å¼æ¥æµ‹é‡æ€§èƒ½ï¼Œæ— éœ€å•ç‹¬çš„æµ‹è¯•é›†ã€‚

# è¯„ä¼°æ­¥éª¤

æ„å»ºå®Œæ‰€æœ‰æ ‘åï¼Œæˆ‘ä»¬å¯ä»¥è¯„ä¼°æµ‹è¯•é›†ã€‚

![](../Images/55f4ae7dd4d6a6513400959cda5c3c12.png)

é€šè¿‡ç»“åˆå¤šä¸ªå¤šæ ·åŒ–çš„å†³ç­–æ ‘å¹¶ä½¿ç”¨å¤šæ•°æŠ•ç¥¨ï¼Œéšæœºæ£®æ—è¾¾åˆ°äº†85.7%çš„é«˜å‡†ç¡®ç‡â€”â€”é€šå¸¸æ¯”å•æ£µå†³ç­–æ ‘æˆ–æ›´ç®€å•çš„æ¨¡å‹è¡¨ç°æ›´å¥½ï¼

# å…³é”®å‚æ•°

éšæœºæ£®æ—çš„å…³é”®å‚æ•°ï¼ˆå°¤å…¶æ˜¯åœ¨`scikit-learn`ä¸­ï¼‰åŒ…æ‹¬æ‰€æœ‰å†³ç­–æ ‘å‚æ•°ï¼Œä»¥åŠä¸€äº›ç‹¬ç‰¹çš„å‚æ•°ã€‚

## éšæœºæ£®æ—ç‰¹å®šå‚æ•°

+   `oob_score` è¿™ä¸ªå‚æ•°ä½¿ç”¨å‰©ä½™çš„æ•°æ®ï¼ˆè¢‹å¤–æ ·æœ¬ï¼‰æ¥æ£€æŸ¥æ¨¡å‹çš„è¡¨ç°ã€‚è¿™ä¸ºä½ æä¾›äº†ä¸€ç§ä¸éœ€è¦å•ç‹¬è®¾ç½®æµ‹è¯•æ•°æ®æ¥æµ‹è¯•æ¨¡å‹çš„æ–¹æ³•ï¼Œå°¤å…¶é€‚ç”¨äºå°æ•°æ®é›†ã€‚

+   `n_estimators` è¿™ä¸ªå‚æ•°æ§åˆ¶è¦æ„å»ºå¤šå°‘æ£µæ ‘ï¼ˆé»˜è®¤å€¼æ˜¯100ï¼‰ã€‚ä¸ºäº†æ‰¾åˆ°æœ€ä½³çš„æ ‘æœ¨æ•°é‡ï¼Œ**åœ¨æ·»åŠ æ›´å¤šæ ‘æœ¨æ—¶è·Ÿè¸ªOOBè¯¯å·®ç‡**ã€‚è¯¯å·®é€šå¸¸ä¼šè¿…é€Ÿä¸‹é™ï¼Œç„¶åè¶‹äºå¹³ç¨³ã€‚**ç¨³å®šçš„ç‚¹å³æ˜¯æœ€ä½³æ ‘æœ¨æ•°é‡**â€”â€”åœ¨æ­¤ä¹‹åå¢åŠ æ›´å¤šæ ‘æœ¨åªä¼šå¸¦æ¥æœ€å°çš„æ”¹å–„ï¼ŒåŒæ—¶å¢åŠ è®¡ç®—æ—¶é—´ã€‚

```py
# Calculate OOB error for different numbers of trees
n_trees_range = range(10, 201)
oob_errors = [
    1 - RandomForestClassifier(n_estimators=n, oob_score=True, random_state=42).fit(X_train, y_train).oob_score_
    for n in n_trees_range
]

# Create a plot
plt.figure(figsize=(7, 5), dpi=300)
plt.plot(n_trees_range, oob_errors, 'b-', linewidth=2)
plt.xlabel('Number of Trees')
plt.ylabel('Out-of-Bag Error Rate')
plt.title('Random Forest OOB Error vs Number of Trees')
plt.grid(True, alpha=0.2)
plt.tight_layout()

# Print results at key intervals
print("OOB Error by Number of Trees:")
for i, error in enumerate(oob_errors, 1):
    if i % 10 == 0:
        print(f"Trees: {i:3d}, OOB Error: {error:.4f}")
```

![](../Images/97234d73657a128e85e5409216f55df5.png)![](../Images/3d6b30f69790966d7d1dc81b1bed0c83.png)

åœ¨æˆ‘ä»¬çš„ç»“æœä¸­ï¼Œå°½ç®¡å¤§çº¦27æ£µæ ‘æ˜¾ç¤ºå‡ºæœ€ä½³çš„å¾—åˆ†ï¼ˆ0.2857ï¼‰ï¼Œä½†è¿™ä¸ªæ—©æœŸè¡¨ç°å¯èƒ½ä¸å¤ªå¯é ã€‚åœ¨40åˆ°100æ£µæ ‘ä¹‹é—´ï¼Œè¯¯å·®ç‡å¤§çº¦ç¨³å®šåœ¨0.5000ï¼Œæ˜¾ç¤ºå‡ºæ›´ä¸€è‡´çš„ç»“æœã€‚è¶…è¿‡100æ£µæ ‘å¹¶æ²¡æœ‰å¸®åŠ©ï¼Œåè€Œæœ‰æ—¶ä¼šä½¿ç»“æœå˜å·®ã€‚è¿™è¡¨æ˜ï¼Œä½¿ç”¨å¤§çº¦50åˆ°60æ£µæ ‘æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©â€”â€”å®ƒæ—¢ç¨³å®šã€é«˜æ•ˆï¼Œåˆå¯é ã€‚

+   `bootstrap` è¿™ä¸ªå‚æ•°å†³å®šäº†æ¯æ£µæ ‘æ˜¯ä»æ•°æ®çš„éšæœºæ ·æœ¬ä¸­å­¦ä¹ ï¼ˆ`True`ï¼‰ï¼Œè¿˜æ˜¯ä½¿ç”¨æ‰€æœ‰æ•°æ®ï¼ˆ`False`ï¼‰ã€‚é»˜è®¤å€¼ï¼ˆ`True`ï¼‰æœ‰åŠ©äºåˆ›å»ºä¸åŒç±»å‹çš„æ ‘ï¼Œè¿™æ˜¯éšæœºæ£®æ—å·¥ä½œåŸç†çš„å…³é”®ã€‚**åªæœ‰åœ¨æ•°æ®éå¸¸å°‘ï¼Œæ— æ³•è·³è¿‡ä»»ä½•æ ·æœ¬æ—¶ï¼Œæ‰è€ƒè™‘å°†å…¶è®¾ç½®ä¸º**`**False**`ã€‚

+   `n_jobs` è¿™ä¸ªå‚æ•°æ§åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„å¤„ç†å™¨æ ¸å¿ƒæ•°ã€‚å°†å…¶è®¾ç½®ä¸º `-1` ä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æ ¸å¿ƒï¼ŒåŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œä½†ä¼šå ç”¨æ›´å¤šå†…å­˜ã€‚å¯¹äºå¤§æ•°æ®é›†ï¼Œä½ å¯èƒ½éœ€è¦ä½¿ç”¨æ›´å°‘çš„æ ¸å¿ƒï¼Œä»¥é¿å…å†…å­˜ä¸è¶³ã€‚

## ä¸å†³ç­–æ ‘å…±äº«çš„å‚æ•°

ä»¥ä¸‹å‚æ•°ä¸[å†³ç­–æ ‘ä¸­çš„å·¥ä½œæ–¹å¼ç›¸åŒ](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)ã€‚

+   `max_depth`: æœ€å¤§æ ‘æ·±åº¦

+   `min_samples_split`: åˆ‡åˆ†èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°

+   `min_samples_leaf`: å¶èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°

ä¸å†³ç­–æ ‘ç›¸æ¯”ï¼Œä»¥ä¸‹æ˜¯å‚æ•°é‡è¦æ€§çš„å…³é”®å·®å¼‚ï¼š

1.  `max_depth` åœ¨éšæœºæ£®æ—ä¸­ä¸å¤ªé‡è¦ï¼Œå› ä¸ºç»“åˆå¤šä¸ªæ ‘å¯ä»¥å¸®åŠ©é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå³ä½¿æ˜¯è¾ƒæ·±çš„æ ‘ä¹Ÿå¦‚æ­¤ã€‚é€šå¸¸ä½ å¯ä»¥è®©æ ‘é•¿å¾—æ›´æ·±ï¼Œä»¥æ•æ‰æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚

1.  `min_samples_split` å’Œ `min_samples_leaf` åœ¨éšæœºæ£®æ—ä¸­ä¸å¤ªé‡è¦ï¼Œå› ä¸ºä½¿ç”¨å¤šæ£µæ ‘å¤©ç„¶æœ‰åŠ©äºé¿å…è¿‡æ‹Ÿåˆã€‚é€šå¸¸å¯ä»¥å°†è¿™äº›å‚æ•°è®¾ç½®ä¸ºæ¯”å•æ£µå†³ç­–æ ‘æ›´å°çš„å€¼ã€‚

# ä¼˜ç‚¹ä¸ç¼ºç‚¹

## ä¼˜ç‚¹ï¼š

1.  **å¼ºå¤§ä¸”å¯é ï¼š** éšæœºæ£®æ—èƒ½æä¾›å‡†ç¡®çš„ç»“æœï¼Œå¹¶ä¸”æ¯”å•æ£µå†³ç­–æ ‘æ›´ä¸å®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆã€‚é€šè¿‡ä½¿ç”¨éšæœºé‡‡æ ·å¹¶åœ¨æ¯ä¸ªèŠ‚ç‚¹æ··åˆä¸åŒçš„ç‰¹å¾ï¼Œéšæœºæ£®æ—èƒ½åœ¨å¤šä¸ªé—®é¢˜ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä¸”æ— éœ€è¿‡å¤šè°ƒæ•´ã€‚

1.  **ç‰¹å¾é‡è¦æ€§ï¼š** é€šè¿‡è¡¡é‡æ¯ä¸ªç‰¹å¾åœ¨æ‰€æœ‰æ ‘ä¸­çš„è´¡çŒ®ï¼Œæ¨¡å‹å¯ä»¥å‘Šè¯‰ä½ å“ªäº›ç‰¹å¾å¯¹é¢„æµ‹æœ€ä¸ºé‡è¦ã€‚è¿™æœ‰åŠ©äºä½ ç†è§£é©±åŠ¨é¢„æµ‹çš„å› ç´ ã€‚

1.  **æœ€å°é¢„å¤„ç†ï¼š** éšæœºæ£®æ—èƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†æ•°å€¼å‹å’Œç±»åˆ«å‹å˜é‡ï¼Œå‡ ä¹ä¸éœ€è¦é¢å¤–çš„å‡†å¤‡å·¥ä½œã€‚å®ƒä»¬èƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼Œå¹¶ä¸”å¯ä»¥è‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„å¤æ‚å…³ç³»ã€‚

# ç¼ºç‚¹ï¼š

1.  **è®¡ç®—æˆæœ¬ï¼š** éšç€æ ‘çš„å¢åŠ æˆ–æ ‘çš„æ·±åº¦åŠ æ·±ï¼Œè®­ç»ƒå’Œä½¿ç”¨æ¨¡å‹æ‰€éœ€çš„æ—¶é—´ä¹Ÿä¼šå¢åŠ ã€‚å°½ç®¡å¯ä»¥é€šè¿‡ä½¿ç”¨å¤šä¸ªå¤„ç†å™¨æ¥åŠ é€Ÿè®­ç»ƒï¼Œä½†å¯¹äºå¤§æ•°æ®é›†æ¥è¯´ï¼Œä»ç„¶éœ€è¦å¤§é‡çš„è®¡ç®—èƒ½åŠ›ã€‚

1.  **æœ‰é™çš„å¯è§£é‡Šæ€§ï¼š** å°½ç®¡ä½ å¯ä»¥çœ‹åˆ°å“ªäº›ç‰¹å¾åœ¨æ•´ä½“ä¸Šæœ€é‡è¦ï¼Œä½†å¾ˆéš¾ç¡®åˆ‡ç†è§£æ¨¡å‹ä¸ºä½•åšå‡ºç‰¹å®šé¢„æµ‹ï¼Œè¿™ä¸å•æ£µå†³ç­–æ ‘ä¸åŒã€‚å½“ä½ éœ€è¦è§£é‡Šæ¯ä¸ªå†³ç­–æ—¶ï¼Œè¿™å¯èƒ½ä¼šæˆä¸ºä¸€ä¸ªé—®é¢˜ã€‚

1.  **é¢„æµ‹é€Ÿåº¦ï¼š** ä¸ºäº†åšå‡ºé¢„æµ‹ï¼Œæ•°æ®å¿…é¡»é€šè¿‡æ‰€æœ‰çš„æ ‘ï¼Œç„¶åå°†å®ƒä»¬çš„ç­”æ¡ˆç»“åˆèµ·æ¥ã€‚è¿™ä½¿å¾—éšæœºæ£®æ—æ¯”ç®€å•æ¨¡å‹æ›´æ…¢ï¼Œå¯èƒ½ä¼šæˆä¸ºå®æ—¶åº”ç”¨ä¸­çš„ä¸€ä¸ªé—®é¢˜ã€‚

# æœ€ç»ˆè¯„è®º

åœ¨çœ‹åˆ°éšæœºæ£®æ—åœ¨å®è·µä¸­çš„å‡ºè‰²è¡¨ç°åï¼Œæˆ‘å¼€å§‹çœŸæ­£å–œæ¬¢å®ƒä»¬ã€‚é€šè¿‡ç»“åˆå¤šæ£µæ ‘å¹¶è®©æ¯æ£µæ ‘ä»æ•°æ®çš„ä¸åŒéƒ¨åˆ†å­¦ä¹ ï¼Œå®ƒä»¬å§‹ç»ˆèƒ½åšå‡ºæ›´å¥½çš„é¢„æµ‹â€”â€”å½“ç„¶ï¼Œæ¯”ä»…ä½¿ç”¨å•æ£µæ ‘æ›´æœ‰æ•ˆã€‚

å°½ç®¡ä½ ç¡®å®éœ€è¦è°ƒæ•´ä¸€äº›è®¾ç½®ï¼Œæ¯”å¦‚æ ‘çš„æ•°é‡ï¼Œä½†é€šå¸¸å³ä½¿æ²¡æœ‰è¿‡å¤šçš„å¾®è°ƒï¼Œå®ƒä»¬ä¹Ÿèƒ½è¡¨ç°å¾—å¾ˆå¥½ã€‚å®ƒä»¬ç¡®å®éœ€è¦æ›´å¤šçš„è®¡ç®—èƒ½åŠ›ï¼ˆæœ‰æ—¶åœ¨å¤„ç†æ•°æ®ä¸­çš„ç¨€æœ‰æƒ…å†µæ—¶å¯èƒ½ä¼šé‡åˆ°å›°éš¾ï¼‰ï¼Œä½†å®ƒä»¬å¯é çš„æ€§èƒ½å’Œæ˜“ç”¨æ€§ä½¿å®ƒä»¬æˆä¸ºæˆ‘è®¸å¤šé¡¹ç›®ä¸­çš„é¦–é€‰ã€‚å¾ˆæ˜æ˜¾ï¼Œä¸ºä»€ä¹ˆè¿™ä¹ˆå¤šæ•°æ®ç§‘å­¦å®¶ä¹Ÿæœ‰åŒæ ·çš„çœ‹æ³•ï¼

# ğŸŒŸ éšæœºæ£®æ—åˆ†ç±»å™¨ä»£ç æ€»ç»“

```py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier

# Create dataset
dataset_dict = {
    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 
                'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy',
                'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast',
                'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],
    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,
                   72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,
                   88.0, 77.0, 79.0, 80.0, 66.0, 84.0],
    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,
                 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,
                 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],
    'Wind': [False, True, False, False, False, True, True, False, False, False, True,
             True, False, True, True, False, False, True, False, True, True, False,
             True, False, False, True, False, False],
    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',
             'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',
             'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']
}

# Prepare data
df = pd.DataFrame(dataset_dict)
df = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)
df['Wind'] = df['Wind'].astype(int)
df['Play'] = (df['Play'] == 'Yes').astype(int)

# Rearrange columns
column_order = ['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind', 'Play']
df = df[column_order]

# Split features and target
X, y = df.drop('Play', axis=1), df['Play']
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)

# Train Random Forest
rf = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)
rf.fit(X_train, y_train)

# Predict and evaluate
y_pred = rf.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
```

# ğŸŒŸ éšæœºæ£®æ—å›å½’å™¨ä»£ç æ€»ç»“

```py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import root_mean_squared_error
from sklearn.ensemble import RandomForestRegressor

# Create dataset
dataset_dict = {
    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 
                'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain',
                'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast',
                'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'],
    'Temp.': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,
              72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,
              88.0, 77.0, 79.0, 80.0, 66.0, 84.0],
    'Humid.': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,
               90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,
               65.0, 70.0, 60.0, 95.0, 70.0, 78.0],
    'Wind': [False, True, False, False, False, True, True, False, False, False, True,
             True, False, True, True, False, False, True, False, True, True, False,
             True, False, False, True, False, False],
    'Num_Players': [52, 39, 43, 37, 28, 19, 43, 47, 56, 33, 49, 23, 42, 13, 33, 29,
                    25, 51, 41, 14, 34, 29, 49, 36, 57, 21, 23, 41]
}

# Prepare data
df = pd.DataFrame(dataset_dict)
df = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='')
df['Wind'] = df['Wind'].astype(int)

# Split features and target
X, y = df.drop('Num_Players', axis=1), df['Num_Players']
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)

# Train Random Forest
rf = RandomForestRegressor(n_estimators=100, max_features='sqrt', random_state=42)
rf.fit(X_train, y_train)

# Predict and evaluate
y_pred = rf.predict(X_test)
rmse = root_mean_squared_error(y_test, y_pred)

print(f"Root Mean Squared Error: {rmse:.2f}") 
```

## è¿›ä¸€æ­¥é˜…è¯»

å¯¹äº[RandomForestClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html)å’Œ[RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)çš„è¯¦ç»†è§£é‡ŠåŠå…¶åœ¨scikit-learnä¸­çš„å®ç°ï¼Œè¯»è€…å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼Œå…¶ä¸­æä¾›äº†å…³äºä½¿ç”¨å’Œå‚æ•°çš„å…¨é¢ä¿¡æ¯ã€‚

## æŠ€æœ¯ç¯å¢ƒ

æœ¬æ–‡ä½¿ç”¨çš„æ˜¯Python 3.7å’Œscikit-learn 1.5ç‰ˆæœ¬ã€‚å°½ç®¡è®¨è®ºçš„æ¦‚å¿µé€šå¸¸æ˜¯é€‚ç”¨çš„ï¼Œä½†ä¸åŒç‰ˆæœ¬çš„ä»£ç å®ç°å¯èƒ½ä¼šç•¥æœ‰ä¸åŒã€‚

## å…³äºæ’å›¾

é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰æ’å›¾å‡ç”±ä½œè€…åˆ›ä½œï¼ŒåŒ…å«äº†æ¥è‡ªCanva Proçš„æˆæƒè®¾è®¡å…ƒç´ ã€‚

åœ¨è¿™é‡ŒæŸ¥çœ‹æ›´å¤šå…³äºé›†æˆå­¦ä¹ çš„ä¿¡æ¯ï¼š

![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)

[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)

## é›†æˆå­¦ä¹ 

[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----9f736a6e1b3c--------------------------------)4ä¸ªæ•…äº‹![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)

ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:

![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)

[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)

## åˆ†ç±»ç®—æ³•

[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----9f736a6e1b3c--------------------------------)8ä¸ªæ•…äº‹![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)
