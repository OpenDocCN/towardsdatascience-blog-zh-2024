- en: Vision Transformers, Contrastive Learning, Causal Inference, and Other Deep
    Dives You Shouldn’t Miss
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/vision-transformers-contrastive-learning-causal-inference-and-other-deep-dives-you-shouldnt-miss-3b869c77d724?source=collection_archive---------6-----------------------#2024-08-15](https://towardsdatascience.com/vision-transformers-contrastive-learning-causal-inference-and-other-deep-dives-you-shouldnt-miss-3b869c77d724?source=collection_archive---------6-----------------------#2024-08-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://towardsdatascience.medium.com/?source=post_page---byline--3b869c77d724--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page---byline--3b869c77d724--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3b869c77d724--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3b869c77d724--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page---byline--3b869c77d724--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3b869c77d724--------------------------------)
    ·Sent as a [Newsletter](/newsletter?source=post_page---byline--3b869c77d724--------------------------------)
    ·3 min read·Aug 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Feeling inspired to write your first TDS post? [We’re always open to contributions
    from new authors](http://bit.ly/write-for-tds).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As many of us are entering the final stretch of summer, why not take advantage
    of the calmer weeks before a typically hectic September kicks in and explore new
    topics in data science and machine learning?
  prefs: []
  type: TYPE_NORMAL
- en: To help all the learners and skill-growers among our readers, this week we’re
    presenting a special edition of The Variable, dedicated entirely to our best recent
    deep dives (and other articles that demand a bit more time and focus than usual).
    Their reading time might be longer, but they do a fantastic job covering their
    respective topics with nuance, care, and an eye towards practical applications.
    We hope you enjoy our selection.
  prefs: []
  type: TYPE_NORMAL
- en: '[**A Practical Guide to Contrastive Learning**](/a-practical-guide-to-contrastive-learning-26e912c0362f)Useful
    for learning underlying data representations without any explicit labels, contrastive
    learning comes with numerous real-world use cases; [Mengliu Zhao](https://medium.com/u/6db175d93233?source=post_page---user_mention--3b869c77d724--------------------------------)
    guides us through the process of building a SimSiam model using the example of
    the FashionMNIST dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Paper Walkthrough: Vision Transformer (ViT)**](/paper-walkthrough-vision-transformer-vit-c5dcf76f1a7a)We’re
    always in the mood for a solid, thorough paper analysis—and even more so when
    it covers a groundbreaking concept like vision transformers. If you’re new to
    this topic or would like to expand your existing knowledge of ViT, don’t miss
    [Muhammad Ardi](https://medium.com/u/9801a58700ac?source=post_page---user_mention--3b869c77d724--------------------------------)’s
    debut TDS article.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Speeding Up the Vision Transformer with BatchNorm**](/speeding-up-the-vision-transformer-with-batch-normalization-d37f13f20ae7)Let’s
    stay with the vision transformer for a bit longer: if you’re already familiar
    with it but could use some help making your workflows more efficient and streamlined,
    [Anindya Dey, PhD](https://medium.com/u/6527aecbd3c5?source=post_page---user_mention--3b869c77d724--------------------------------)
    provides a comprehensive guide to integrating batch normalization into an encoder-only
    transformer architecture, leading to reduced training and inference time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Enhancing E-Commerce with Generative AI — Part 1**](/enhancing-e-commerce-with-generative-ai-part-1-9e402fb30e7b)Some
    of the promised benefits of recently released AI tools remain to be seen. [Mina
    Ghashami](https://medium.com/u/c99ed9ed7b9a?source=post_page---user_mention--3b869c77d724--------------------------------)
    presents a new series that focuses on use cases where generative-AI applications
    are already poised to make a real impact, starting with one of the most common
    (and business-critical) tasks for e-commerce platforms: product recommendations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/3825c247c2abb7560bc8364e424aca21.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Nellie Adamyan](https://unsplash.com/@nellie_adamyan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[**Causal Inference with Python: A Guide to Propensity Score Matching**](/causal-inference-with-python-a-guide-to-propensity-score-matching-b3470080c84f)Bringing
    theory and practice together, [Lukasz Szubelak](https://medium.com/u/c1c5a4c55d65?source=post_page---user_mention--3b869c77d724--------------------------------)
    invites us to explore the ins and outs of causal inference in his patient deep
    dive, which focuses on propensity score matching as a powerful technique for estimating
    treatment effects in non-randomized settings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**ChatGPT vs. Claude vs. Gemini for Data Analysis (Part 1)**](/chatgpt-vs-claude-vs-gemini-for-data-analysis-part-1-821086810318)ML
    practitioners are facing an increasingly difficult choice when deciding which
    LLM-powered products to choose. [Yu Dong](https://medium.com/u/5462c48cfc57?source=post_page---user_mention--3b869c77d724--------------------------------)’s
    new series aims to bring clarity to an occasionally chaotic ecosystem by comparing
    the performance of three major offerings (ChatGPT, Claude, and Gemini) in essential
    data-analysis tasks—in this case, writing SQL queries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Omitted Variable Bias**](/omitted-variable-bias-7a23405b6c32)Reading [Sachin
    Date](https://medium.com/u/b75b5b1730f3?source=post_page---user_mention--3b869c77d724--------------------------------)’s
    math and statistics explainers is always a highlight for us—and his latest, on
    “one of the most frequently occurring, and easily missed, biases in regression
    studies” is no exception. We invite you to explore his deep dive on the omitted
    variable bias, which also outlines several approaches for analyzing and estimating
    its effects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thank you for supporting the work of our authors! We love publishing articles
    from new authors, so if you’ve recently written an interesting project walkthrough,
    tutorial, or theoretical reflection on any of our core topics, don’t hesitate
    to [share it with us](http://bit.ly/write-for-tds).
  prefs: []
  type: TYPE_NORMAL
- en: Until the next Variable,
  prefs: []
  type: TYPE_NORMAL
- en: TDS Team
  prefs: []
  type: TYPE_NORMAL
