- en: No Baseline? No Benchmarks? No Biggie! An Experimental Approach to Agile Chatbot
    Development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/lessons-from-agile-experimental-chatbot-development-73ea515ba762?source=collection_archive---------3-----------------------#2024-08-26](https://towardsdatascience.com/lessons-from-agile-experimental-chatbot-development-73ea515ba762?source=collection_archive---------3-----------------------#2024-08-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Lessons learned bringing LLM-based products to production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://katherineamunro.medium.com/?source=post_page---byline--73ea515ba762--------------------------------)[![Katherine
    Munro](../Images/8013140495c7b9bd25ef08d712f097bf.png)](https://katherineamunro.medium.com/?source=post_page---byline--73ea515ba762--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--73ea515ba762--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--73ea515ba762--------------------------------)
    [Katherine Munro](https://katherineamunro.medium.com/?source=post_page---byline--73ea515ba762--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--73ea515ba762--------------------------------)
    ·12 min read·Aug 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d299d52ea5c591442d1c95eb740087b.png)'
  prefs: []
  type: TYPE_IMG
- en: Today’s post recaps my recent talk on lessons learned trying to bring LLM-based
    products to production. You can check out the video [here](https://www.youtube.com/watch?v=kOpapPHt2JQ&t=221s).
  prefs: []
  type: TYPE_NORMAL
- en: What happens when you take a working chatbot that’s already serving thousands
    of customers a day in four different languages, and try to deliver an even better
    experience using Large Language Models? Good question.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s well known that evaluating and comparing LLMs is tricky. Benchmark datasets
    can be hard to come by, and metrics such as BLEU are imperfect. But those are
    largely academic concerns: How are industry data teams tackling these issues when
    incorporating LLMs into production projects?'
  prefs: []
  type: TYPE_NORMAL
- en: 'In my work as a Conversational AI Engineer, I’m doing exactly that. And that’s
    how I ended up centre-stage at a recent data science conference, giving the (optimistically
    titled) talk, “No baseline? No benchmarks? No biggie!” Today’s post is a recap
    of this, featuring:'
  prefs: []
  type: TYPE_NORMAL
- en: The challenges of evaluating an evolving, LLM-powered PoC against a working
    chatbot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How we’re using different types of testing at different stages of the PoC-to-production
    process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practical pros and cons of different test types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
