- en: How to Achieve Near Human-Level Performance in Chunking for RAGs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在RAGs中实现接近人类水平的分块效果
- en: 原文：[https://towardsdatascience.com/agentic-chunking-for-rags-091beccd94b1?source=collection_archive---------0-----------------------#2024-08-26](https://towardsdatascience.com/agentic-chunking-for-rags-091beccd94b1?source=collection_archive---------0-----------------------#2024-08-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/agentic-chunking-for-rags-091beccd94b1?source=collection_archive---------0-----------------------#2024-08-26](https://towardsdatascience.com/agentic-chunking-for-rags-091beccd94b1?source=collection_archive---------0-----------------------#2024-08-26)
- en: The costly yet powerful splitting technique for superior RAG retrieval
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本较高但强大的分块技术，有助于提升RAG的检索效果。
- en: '[](https://thuwarakesh.medium.com/?source=post_page---byline--091beccd94b1--------------------------------)[![Thuwarakesh
    Murallie](../Images/44f1a14a899426592bbd8c7f73ce169d.png)](https://thuwarakesh.medium.com/?source=post_page---byline--091beccd94b1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--091beccd94b1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--091beccd94b1--------------------------------)
    [Thuwarakesh Murallie](https://thuwarakesh.medium.com/?source=post_page---byline--091beccd94b1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://thuwarakesh.medium.com/?source=post_page---byline--091beccd94b1--------------------------------)[![Thuwarakesh
    Murallie](../Images/44f1a14a899426592bbd8c7f73ce169d.png)](https://thuwarakesh.medium.com/?source=post_page---byline--091beccd94b1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--091beccd94b1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--091beccd94b1--------------------------------)
    [Thuwarakesh Murallie](https://thuwarakesh.medium.com/?source=post_page---byline--091beccd94b1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--091beccd94b1--------------------------------)
    ·8 min read·Aug 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--091beccd94b1--------------------------------)
    ·8分钟阅读·2024年8月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/82aba3e7f7d96c5ab42e2324773c1286.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82aba3e7f7d96c5ab42e2324773c1286.png)'
- en: Photo by [Nataliya Vaitkevich](https://www.pexels.com/photo/a-person-cutting-melon-4772957/)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[娜塔莉娅·维特凯维奇](https://www.pexels.com/photo/a-person-cutting-melon-4772957/)提供。
- en: Good chunks make good RAGs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 好的分块能带来好的RAG。
- en: Chunking, embedding, and indexing are critical aspects of RAGs. A RAG app that
    uses the appropriate chunking technique performs well in terms of output quality
    and speed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 分块、嵌入和索引是RAGs（检索增强生成模型）的关键方面。使用合适的分块技术的RAG应用在输出质量和速度方面表现优异。
- en: When engineering an LLM pipeline, we use different strategies to split the text.
    Recursive character splitting is the most popular technique. It uses a sliding
    window approach with a fixed token length. However, this approach does not guarantee
    that it can sufficiently hold a theme within its window size. Also, there’s a
    risk that part of the context falls into different chunks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建LLM（大语言模型）管道时，我们使用不同的策略来拆分文本。递归字符拆分是最流行的技术。它采用滑动窗口方法，窗口长度固定。然而，这种方法不能保证足够地容纳一个主题在其窗口大小内。此外，还有可能部分上下文会被分配到不同的分块中。
- en: The other technique I love is semantic splitting. Semantic splitting breaks
    the text whenever there’s a significant change between two consecutive sentences.
    It has no length constraints. So, it can have many sentences or very few. But
    it’s more likely to capture the different themes more accurately.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢的另一种技术是语义分割。语义分割在两个连续句子之间有显著变化时进行拆分。它没有长度限制，因此可以有许多句子，也可以只有很少的句子。但它更有可能准确捕捉到不同的主题。
- en: Even the semantic splitting approach has a problem.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 即便是语义分割方法也存在问题。
- en: What if sentences far from each other are closer in their meaning?
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果彼此相距较远的句子在意义上更为接近，应该怎么处理呢？
