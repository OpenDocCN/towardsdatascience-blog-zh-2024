- en: 'Courage to Learn ML: Tackling Vanishing and Exploding Gradients (Part 2)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/courage-to-learn-ml-tackling-vanishing-and-exploding-gradients-part-2-d0b8aed1ce7a?source=collection_archive---------9-----------------------#2024-05-03](https://towardsdatascience.com/courage-to-learn-ml-tackling-vanishing-and-exploding-gradients-part-2-d0b8aed1ce7a?source=collection_archive---------9-----------------------#2024-05-03)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Comprehensive Survey on Activation Functions, Weights Initialization, Batch
    Normalization, and Their Applications in PyTorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://amyma101.medium.com/?source=post_page---byline--d0b8aed1ce7a--------------------------------)[![Amy
    Ma](../Images/2edf55456a1f92724535a1441fa2bef5.png)](https://amyma101.medium.com/?source=post_page---byline--d0b8aed1ce7a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d0b8aed1ce7a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d0b8aed1ce7a--------------------------------)
    [Amy Ma](https://amyma101.medium.com/?source=post_page---byline--d0b8aed1ce7a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d0b8aed1ce7a--------------------------------)
    ·37 min read·May 3, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Welcome back to a new chapter of “[Courage to Learn ML](https://towardsdatascience.com/tagged/courage-to-learn-ml).”
    For those new to this series, this series aims to make these complex topics accessible
    and engaging, much like a casual conversation between a mentor and a learner,
    inspired by the writing style of “[The Courage to Be Disliked](https://www.goodreads.com/book/show/43306206-the-courage-to-be-disliked),”
    with a specific focus on machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: This time we will continue our exploration into how to overcome the challenges
    of vanishing and exploding gradients. In our opening segment, we talked about
    why it’s critical to maintain stable gradients to ensure effective learning within
    our networks. We uncovered how unstable gradients can be barriers to deepening
    our networks, essentially putting a cap on the potential of deep “learning”. To
    bring these concepts to life, we use the an analogy of running a miniature ice
    cream factory named DNN (short for Delicious Nutritious Nibbles), and draw parallels
    to illuminate potent strategies for DNN training akin to orchestrating a seamless
    factory production line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, in this second installment, we’re diving deeper into each proposed solution,
    examining them with the same clarity and creativity that brought our ice cream
    factory to life. Here are the list of topics we’d cover in this part:'
  prefs: []
  type: TYPE_NORMAL
