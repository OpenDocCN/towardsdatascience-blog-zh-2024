# 未观察到的混杂因素的敏感性分析

> 原文：[https://towardsdatascience.com/sensitivity-analysis-for-unobserved-confounding-465970a969e0?source=collection_archive---------10-----------------------#2024-02-13](https://towardsdatascience.com/sensitivity-analysis-for-unobserved-confounding-465970a969e0?source=collection_archive---------10-----------------------#2024-02-13)

## 如何在观察性研究中了解那些无法知晓的事物

[](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)[![Ugur Yildirim](../Images/33db36531a170c9621504f466d61334b.png)](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------) [Ugur Yildirim](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------) ·阅读时间 10 分钟·2024年2月13日

--

# 大纲

1.  [引言](#48c3)

1.  [问题设置](#c5b8)

    2.1\. [因果图](#3d15)

    2.2\. [有无 *Z* 的模型](#b3b3)2.3\. [作为混杂因素的 *Z* 的强度](#4b5a)

1.  [敏感性分析](#e05a)

    3.1\. [目标](#3e88)

    3.2\. [稳健性值](#dd07)

1.  [PySensemakr](#5e81)

1.  [结论](#8395)

1.  [致谢](#d671)

1.  [参考文献](#b5bc)

# 1\. 引言

未观察到的混杂因素（即遗漏变量偏倚）是观察性研究中的一个著名问题。在大多数观察性研究中，除非我们能合理假设治疗分配在某些方面是随机的，如同自然实验一样，否则我们永远无法真正确定我们在模型中控制了所有可能的混杂因素。因此，如果我们未能控制住一个重要的混杂因素，我们的模型估计值可能会严重偏倚——而我们甚至不知道，因为未观察到的混杂因素，嗯，确实是未观察到的！

鉴于这个问题，评估我们的估计值对潜在未观察到的混杂因素的敏感性非常重要。换句话说，问问自己一个问题是有帮助的：如果未观察到的混杂因素足够大，我们的估计值会发生剧烈变化（例如，治疗效应不再具有统计显著性）吗？未观察到的混杂因素的敏感性分析是一个活跃的研究领域，解决这个问题有几种方法。在本文中，我将介绍一种基于部分 *R²* 概念的简单线性方法[[1]](https://academic.oup.com/jrsssb/article/82/1/39/7056023)，这种方法广泛适用于大多数情况。

# 2\. 问题设置

## 2.1\. 因果图

假设我们有四个变量：

+   *Y*: 结果

+   *D*: 治疗

+   *X*: 观察到的混杂因素

+   *Z*: 未观察到的混杂变量

这是许多观察性研究中的常见情境，研究人员希望在控制可能的治疗—结果混杂变量后，了解所关注的治疗是否对结果产生影响。

在我们的假设情境中，这些变量之间的关系是*X*和*Z*都影响*D*和*Y*，但*D*对*Y*没有影响。换句话说，我们描述的是一个真实治疗效应为零的情景。正如下一部分将明确指出的，敏感性分析的目的是能够推理出这个治疗效应，尽管我们通常无法访问*Z*，因为它是未观察到的。图1展示了我们的设定。

**图 1：问题设定**

![](../Images/bfd5d56edce6e7152043c61de6fe28f6.png)

## 2.2\. 带*Z*和不带*Z*的模型

为了展示未观察到的*Z*可能造成的问题，我根据上述问题设定模拟了一些数据。你可以参考[这个笔记本](https://github.com/uguryi/unobserved_confounding/blob/main/unobserved_confounding.ipynb)查看模拟的详细信息。

由于*Z*在现实生活中无法观察到，我们通常能拟合到数据的唯一模型是*Y~D+X*。让我们看看如果我们运行这个回归，结果会是什么。

根据这些结果，似乎*D*对*Y*的每单位变化有统计显著效应0.2686（*p*<0.001），但我们知道这不符合事实，因为我们生成数据的方式是没有*D*效应的。

现在，让我们看看当我们同时控制*Z*时，*D*估计值会发生什么变化。（在现实生活中，当然我们无法进行这个额外的回归，因为*Z*是未观察到的，但我们的模拟设置允许我们窥探真正的数据生成过程。）

正如预期的那样，控制*Z*后，*D*效应被正确移除，估计值收缩至零，并且我们得到的*p*值在𝛼=0.05的显著性水平下不再显著（*p*=0.059）。

## 2.3\. *Z*作为混杂变量的强度

到目前为止，我们已经确认*Z*足够强大，能够消除虚假的*D*效应，因为在我们控制*Z*之后，统计上显著的*D*效应消失了。我们尚未讨论的是*Z*作为混杂变量的具体强度。为此，我们将利用一个有用的统计学概念，叫做部分*R²*，它量化了一个给定的兴趣变量能够解释的变异量的比例，这些变异量是模型中现有变量无法解释的。换句话说，部分*R²*告诉我们该变量的*额外*解释力，超出了模型中已包含的其他变量。形式上，它可以定义如下：

![](../Images/841f01ffb074c5bbcd67165995585666.png)

其中，*RSS_reduced* 是不包含感兴趣变量的模型的残差平方和，而 *RSS_full* 是包含感兴趣变量的模型的残差平方和。

在我们的案例中，感兴趣的变量是 *Z*，我们想知道 *Z* 能解释 *Y* 和 *D* 中的变异性有多少是现有变量无法解释的。更准确地说，我们关注的是以下两个部分 *R²* 值：

![](../Images/ac6d3bca9e64679028bcb56422a4b6fc.png)

其中 (1) 量化了 *Y* 中无法通过 *D* 和 *X* 已经解释的部分，能够被 *Z* 解释的方差比例（因此，简化模型为 Y~D+X，完整模型为 Y~D+X+Z），(2) 量化了 *D* 中无法通过 *X* 已经解释的部分，能够被 *Z* 解释的方差比例（因此，简化模型为 D~X，完整模型为 D~X+Z）。

现在，让我们看看 *Z* 在我们的数据中与 *D* 和 *Y* 的关联程度，具体是通过部分 *R²* 来衡量。

结果表明，*Z* 解释了 *Y* 中 16% 的变异性，这是 *D* 和 *X* 无法解释的部分（这就是上面提到的部分 *R²* 方程 #1），并且解释了 *D* 中 20% 的变异性，这是 *X* 无法解释的部分（这就是上面提到的部分 *R²* 方程 #2）。

# 3\. 敏感性分析

## 3.1\. 目标

正如我们在前一节中讨论的，未观察到的混杂因素在真实研究环境中构成问题，正是因为，和我们的模拟设置不同，*Z* 无法被观察到。换句话说，我们只能使用模型 *Y~D+X*，而无法知道如果能运行模型 *Y~D+X+Z*，我们的结果会是什么样子。那么，我们能做什么呢？

直观地说，一个合理的敏感性分析方法应该能够告诉我们，如果数据中存在类似于 *Z* 的变量，它将使我们的结果失效。记住，*Z* 解释了 *Y* 中 16% 的变异性，以及 *D* 中 20% 的变异性，这些是现有变量无法解释的部分。因此，我们期望敏感性分析能够告诉我们，一个假设的、类似 *Z* 强度的混杂因素将足以消除统计上显著的 *D* 效应。

但是，如何计算未观察到的混杂因素的强度应该落在这个 16% 到 20% 范围内，*而且我们根本无法接触到它* 呢？这时就需要引入稳健性值。

## 3.2\. 稳健性值

稳健性值（RV）正式化了我们上面提到的概念，即确定一个假设的未观察到的混杂因素的必要强度，足以使我们的结果失效。稳健性值的实用性在于，我们只需要我们的可观察模型 *Y~D+X*，而不需要不可观察的模型 *Y~D+X+Z*，就能够计算出它。

正式地，我们可以将其写为如下形式，来量化需要多强的未观察到的混杂因素，才能改变我们观察到的处理效应的统计显著性（如果符号太复杂跟不上，可以记住这个关键点：RV是衡量混杂因素强度的度量，足以改变我们的结果）

![](../Images/a792c163556de1c4ad40364b6a2578b2.png)

图片由作者提供，方程式基于[[1]](https://academic.oup.com/jrsssb/article/82/1/39/7056023)，参见第49–52页

其中

+   𝛼是我们选择的显著性水平（通常设置为0.05或5%），

+   *q*决定了我们关心的显著性减少的百分比*q**100%（通常设置为1，因为我们通常关心能够将统计显著性减少1*100%=100%的混杂因素，从而使其不再具有统计显著性），

+   *t_betahat_treat*是我们从模型*Y~D+X*中观察到的* t*-值（在这种情况下为8.389，可以从上面的回归结果中看到），

+   *df*是我们的自由度（在这种情况下为1000–3=997，因为我们模拟了1000个样本，并且正在估计包括截距在内的3个参数），并且

+   *t*_alpha,df-1*是与给定𝛼和*df-1*（如果𝛼设置为0.05，则为1.96）相关的*t*-值临界值。

我们现在可以使用仅观察到的模型*Y~D+X*（*res_ydx*）在我们自己的数据中计算RV了。

我们的RV（18%）恰好落在我们为*Y~Z|D,X*（16%）和*D~Z|X*（20%）计算的部分*R²*值范围内，这并非偶然。这里RV告诉我们的是，*即使没有Z的明确知识*，我们仍然可以推理出，任何未观察到的混杂因素平均需要至少18%的强度，才能在部分*R²*尺度上对处理和结果都产生影响，从而使得我们原本显著的结果不再显著。

RV之所以不是16%或20%，而是落在中间（18%），是因为它被设计为一个单一的数字，*总结*了与结果和处理相关的混杂因素的必要强度，因此18%是合情合理的，考虑到我们对数据的了解。你可以这样理解：由于该方法在计算RV时没有实际访问16%和20%的数字，它尽力通过将18%分配给两个部分的*R²*值（*Y~Z|D,X* 和 *D~Z|X*），来量化混杂因素的强度，这一点与实际情况相差不大，实际上也很好地总结了混杂因素的强度。

当然，在现实生活中，我们不会有 *Z* 变量来再次检查我们的 RV 是否正确，但看到这两个结果的对齐至少可以让你对这个方法有一些信心。最后，一旦我们计算出 RV，我们应该考虑一个如此强度的未观察到的混杂因素是否合理。在我们的例子中，答案是“是的”，因为我们可以访问数据生成过程，但对于你的特定实际应用，假设存在如此强的混杂因素可能是不合理的。对你来说这是好消息，因为没有现实中未观察到的混杂因素可以极大地改变你的结果。

# 4\. PySensemakr

上述敏感性分析技术已经以 [PySensemakr](https://github.com/nlapier2/PySensemakr) 这个 Python 包的形式实现了，且具备了所有的功能（也有 R、Stata 和 Shiny App 版本）。例如，要获得与我们在前一部分手动计算的完全相同的结果，我们只需运行以下代码块。

请注意，“Robustness Value, q = 1 alpha = 0.05” 的值为 0.184，这正是我们之前计算的结果。除了用于统计显著性的 RV，软件包还提供了用于将系数估计值收缩至 0 所需的 RV。毫不奇怪，为了实现这一点，未观察到的混杂因素需要更大（0.233 与 0.184）。

该软件包还提供了两个部分 *R²* 值的轮廓图，这可以直观地显示治疗和结果可能的混杂程度对敏感性的影响（在这种情况下，看到满足红色虚线的 x/y 轴值对包括 0.18/0.18 和 0.20/0.16 是不足为奇的）。

你甚至可以将基准值添加到轮廓图中，作为混杂因素可能程度的代理。在我们的例子中，由于我们只有一个观察到的协变量 *X*，我们可以将基准值设置为与该观察到的协变量强度相当的 0.25x、0.5x 和 1x。由此得到的图表告诉我们，一个强度仅为 *X* 一半的混杂因素应该足以使我们统计显著的结果无效（因为“0.5x X”值恰好位于红色虚线处）。

最后，我想指出，尽管本示例中的模拟数据使用了一个连续的处理变量，但在实践中，该方法适用于任何类型的处理变量，包括二元处理。另一方面，结果变量在技术上需要是连续型的，因为我们处在 OLS 框架中。然而，即使结果是二元的，只要我们通过 OLS 建模（这称为 LPM [[2]](https://murraylax.org/rtutorials/linearprob.html)），该方法仍然可以使用。

# 5\. 结论

我们的效应估计可能由于未观察到的混杂因素而产生偏差，这是观察性研究中的常见风险。尽管存在这一潜在风险，观察性研究仍然是数据科学中一项至关重要的工具，因为在许多情况下，随机化实验是不可行的。因此，了解如何通过进行敏感性分析来解决未观察到的混杂因素问题，以查看我们的估计在潜在混杂因素下的鲁棒性，是非常重要的。

本文讨论的Cinelli和Hazlett提出的鲁棒值方法是一种简单直观的敏感性分析方法，基于熟悉的线性模型框架。如果你有兴趣深入了解该方法，我强烈推荐阅读原始论文以及[包文档](https://pysensemakr.readthedocs.io/en/latest/index.html)，在其中你可以了解该方法的许多有趣应用，如“极端情景”分析。

还有许多其他针对未观察到的混杂因素的敏感性分析方法，我在此简要提及其中一些，供有兴趣深入学习该主题的读者参考。一个多功能的技术是VanderWeele和Ding开发的E值，它将问题表述为风险比 [[3]](https://hrr.w.uib.no/files/2019/01/VanderWeeleDing_2017_e_-value.pdf)（在R中实现的版本 [这里](https://cran.r-project.org/web/packages/EValue/index.html)）。另一种技术是Veitch和Zaveri基于部分*R²*和倾向评分概念开发的Austen图 [[4]](https://proceedings.neurips.cc/paper_files/paper/2020/file/7d265aa7147bd3913fb84c7963a209d1-Paper.pdf)（在Python中实现的版本 [这里](https://github.com/anishazaveri/austen_plots)），还有一种最近的办法是Chernozhukov等人提出的 [[5]](https://www.nber.org/system/files/working_papers/w30302/w30302.pdf)（在Python中实现的版本 [这里](https://docs.doubleml.org/stable/examples/py_double_ml_sensitivity.html)）。

# 6\. 致谢

我想感谢Chad Hazlett解答我关于如何在二项结果中使用该方法的问题，并感谢Xinyi Zhang对本文提供了大量有价值的反馈。除非另有注明，文中的所有图片均由作者提供。

# 7\. 参考文献

[1] C. Cinelli 和 C. Hazlett， [理解敏感性：扩展遗漏变量偏差](https://academic.oup.com/jrsssb/article/82/1/39/7056023)（2019），《皇家统计学会学报》

[2] J. Murray，[线性概率模型](https://murraylax.org/rtutorials/linearprob.html)，Murray的个人网站

[3] T. VanderWeele 和 P. Ding，[观察性研究中的敏感性分析：引入E值](https://hrr.w.uib.no/files/2019/01/VanderWeeleDing_2017_e_-value.pdf)（2017），《内科学年鉴》

[4] V. Veitch 和 A. Zaveri， [敏感性与灵敏度分析：对未观察到的混杂因素引起的偏差的简单事后分析](https://proceedings.neurips.cc/paper_files/paper/2020/file/7d265aa7147bd3913fb84c7963a209d1-Paper.pdf) （2020），NeurIPS

[5] V. Chernozhukov, C. Cinelli, W. Newey, A. Sharma, 和 V. Syrgkanis， [简而言之：因果机器学习中的遗漏变量偏差](https://www.nber.org/system/files/working_papers/w30302/w30302.pdf) （2022），NBER
