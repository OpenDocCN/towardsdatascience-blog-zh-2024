["```py\ndef get_intrinsic_matrix(\n    f_x: float, f_y: float, c_x: float, c_y: float\n) -> torch.Tensor:\n    \"\"\"\n    Get the homogenous intrinsic matrix for the camera\n    \"\"\"\n    return torch.Tensor(\n        [\n            [f_x, 0, c_x, 0],\n            [0, f_y, c_y, 0],\n            [0, 0, 1, 0],\n        ]\n    )\n\ndef get_extrinsic_matrix(R: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Get the homogenous extrinsic matrix for the camera\n    \"\"\"\n    Rt = torch.zeros((4, 4))\n    Rt[:3, :3] = R\n    Rt[:3, 3] = t\n    Rt[3, 3] = 1.0\n    return Rt\n\ndef project_points(\n    points: torch.Tensor, intrinsic_matrix: torch.Tensor, extrinsic_matrix: torch.Tensor\n) -> torch.Tensor:\n    \"\"\"\n    Project the points to the image plane\n\n    Args:\n        points: Nx3 tensor\n        intrinsic_matrix: 3x4 tensor\n        extrinsic_matrix: 4x4 tensor\n    \"\"\"\n    homogeneous = torch.ones((4, points.shape[0]), device=points.device)\n    homogeneous[:3, :] = points.T\n    projected_to_camera_perspective = extrinsic_matrix @ homogeneous\n    projected_to_image_plane = (intrinsic_matrix @ projected_to_camera_perspective).T # Nx4\n\n    x = projected_to_image_plane[:, 0] / projected_to_image_plane[:, 2]\n    y = projected_to_image_plane[:, 1] / projected_to_image_plane[:, 2]\n    return x, y\n\ncolmap_path = \"treehill/sparse/0\"\nreconstruction = pycolmap.Reconstruction(colmap_path)\n\npoints3d = reconstruction.points3D\nimages = read_images_binary(f\"{colmap_path}/images.bin\")\ncameras = reconstruction.cameras\n\nall_points3d = []\nall_point_colors = []\n\nfor idx, point in enumerate(points3d.values()):\n    if point.track.length() >= 2:\n        all_points3d.append(point.xyz)\n        all_point_colors.append(point.color)\n\ngaussians = Gaussians(\n    torch.Tensor(all_points3d), \n    torch.Tensor(all_point_colors),\n    model_path=\"point_clouds\"\n)\n\n# we will examine the 100th image\nimage_num = 100    \nimage_dict = read_image_file(colmap_path)\ncamera_dict = read_camera_file(colmap_path)\n\n# convert quaternion to rotation matrix\nrotation_matrix = build_rotation(torch.Tensor(image_dict[image_num].qvec).unsqueeze(0))\ntranslation = torch.Tensor(image_dict[image_num].tvec).unsqueeze(0)\nextrinsic_matrix = get_extrinsic_matrix(\n    rotation_matrix, translation\n)\nfocal_x, focal_y = camera_dict[image_dict[image_num].camera_id].params[:2]\nc_x, c_y = camera_dict[image_dict[image_num].camera_id].params[2:4]\nintrinsic_matrix = get_intrinsic_matrix(focal_x, focal_y, c_x, c_y)\n\npoints = project_points(gaussians.points, intrinsic_matrix, extrinsic_matrix)\n```"]