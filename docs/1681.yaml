- en: The Ultimate Handbook for LLM Quantization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《大语言模型量化终极手册》
- en: 原文：[https://towardsdatascience.com/the-ultimate-handbook-for-llm-quantization-88bb7cb0d9d7?source=collection_archive---------1-----------------------#2024-07-10](https://towardsdatascience.com/the-ultimate-handbook-for-llm-quantization-88bb7cb0d9d7?source=collection_archive---------1-----------------------#2024-07-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-ultimate-handbook-for-llm-quantization-88bb7cb0d9d7?source=collection_archive---------1-----------------------#2024-07-10](https://towardsdatascience.com/the-ultimate-handbook-for-llm-quantization-88bb7cb0d9d7?source=collection_archive---------1-----------------------#2024-07-10)
- en: A deep dive into LLM quantization and techniques
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入探讨大语言模型的量化与技术
- en: '[](https://medium.com/@ashishabraham02?source=post_page---byline--88bb7cb0d9d7--------------------------------)[![Ashish
    Abraham](../Images/f49ce1b2f0f99889e40cdd3c24c5a4fc.png)](https://medium.com/@ashishabraham02?source=post_page---byline--88bb7cb0d9d7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--88bb7cb0d9d7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--88bb7cb0d9d7--------------------------------)
    [Ashish Abraham](https://medium.com/@ashishabraham02?source=post_page---byline--88bb7cb0d9d7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ashishabraham02?source=post_page---byline--88bb7cb0d9d7--------------------------------)[![Ashish
    Abraham](../Images/f49ce1b2f0f99889e40cdd3c24c5a4fc.png)](https://medium.com/@ashishabraham02?source=post_page---byline--88bb7cb0d9d7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--88bb7cb0d9d7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--88bb7cb0d9d7--------------------------------)
    [Ashish Abraham](https://medium.com/@ashishabraham02?source=post_page---byline--88bb7cb0d9d7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--88bb7cb0d9d7--------------------------------)
    ·15 min read·Jul 10, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--88bb7cb0d9d7--------------------------------)
    ·15分钟阅读·2024年7月10日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/af990aafb125e0549685a0b19b2ce0b9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af990aafb125e0549685a0b19b2ce0b9.png)'
- en: Photo by [Siednji Leon](https://unsplash.com/@siednji?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Siednji Leon](https://unsplash.com/@siednji?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: LLMs on CPU? Yes, you heard it right. From handling conversations to creating
    its own images, AI has come a long way since its beginnings. But it came with
    a bottleneck. As the models expanded, so did their computational demands. AI began
    to rely heavily on computational power. To meet these demands, we turned to GPUs,
    and the rest is history.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型在CPU上运行？没错，你没听错。从处理对话到生成自己的图像，人工智能自诞生以来已经走了很长一段路。但这也带来了瓶颈。随着模型的扩展，其计算需求也在增加。人工智能开始严重依赖计算能力。为了满足这些需求，我们转向了GPU，而其余的就是历史了。
- en: Many devices don’t possess powerful GPUs and so miss out on AI capabilities.
    It was necessary to scale down the size and power of these models to run an AI
    model on devices with limited computational power like a mobile phone or a computer
    with CPU only. Early efforts include techniques like pruning and distillation.
    However, these approaches were not viable when it came to LLMs, which typically
    have large-scale architectures.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 许多设备没有强大的GPU，因此无法体验人工智能的能力。为了能够在计算能力有限的设备（如手机或仅有CPU的电脑）上运行AI模型，必须缩小这些模型的规模和功耗。早期的尝试包括剪枝和蒸馏等技术。然而，这些方法在大语言模型面前并不适用，因为大语言模型通常具有大规模的架构。
- en: The recent AI revolution with LLMs was more or less based on cloud servers for
    training, deployment, and inference. However, major players are now extending
    LLM capabilities to edge devices. Microsoft’s copilot+PCs is a great example and
    something to wait for. As we move toward edge deployment, optimizing LLM size
    becomes crucial without compromising performance or quality. One effective method
    to achieve this optimization is through **quantization**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的人工智能革命，特别是大语言模型（LLMs）的发展，或多或少依赖于云服务器进行训练、部署和推理。然而，主要厂商现在正在将大语言模型的能力扩展到边缘设备。微软的copilot+PC就是一个很好的例子，值得期待。随着我们朝着边缘部署的方向前进，优化大语言模型的大小变得至关重要，同时又不影响性能或质量。实现这一优化的一个有效方法是通过**量化**技术。
