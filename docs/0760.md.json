["```py\nStudent#,Last Name,First Name,Favorite Color,Age\n1,Johnson,Mia,periwinkle,12\n2,Lopez,Liam,blue,green,13\n3,Lee,Isabella,,11\n4,Fisher,Mason,gray,-1\n5,Gupta,Olivia,9,102\n6,,Robinson,,Sophia,,blue,,12\n```", "```py\nAnalyse the table below and provide schema annotations based on Schema.org standards.\n\nStudent#,Last Name,First Name,Favorite Color,Age\n1,Johnson,Mia,periwinkle,12\n2,Lopez,Liam,blue,green,13\n3,Lee,Isabella,,11\n4,Fisher,Mason,gray,-1\n5,Gupta,Olivia,9,102\n6,,Robinson,,Sophia,,blue,,12\n\nFollow these steps:\n1\\. Identify the overall semantic type of the table.\n2\\. Provide a short description of each column.\n3\\. Annotate each column with its semantic type from Schema.org.\n4\\. Determine the most suitable data type for each column (after data cleaning).\n\nSummarise the table schema as follows:\n- Table Semantic Type: <type>\n- Column: <name>, Description: <description>, Semantic Type: <Schema.org type>, Pandas Type: <Pandas data type>\n```", "```py\nSummarise the table schema as follows:\n- Table Semantic Type: <type>\n- Column: <name>, Description: <description>, Semantic Type: <Schema.org type>, Pandas Type: <Pandas data type>\n```", "```py\n- Table Semantic Type: Person\n- Column: Student#, Description: Unique identifier for each student, Semantic Type: identifier, Pandas Type: int\n- Column: Last Name, Description: Family name of the student, Semantic Type: familyName, Pandas Type: string\n- Column: First Name, Description: Given name of the student, Semantic Type: givenName, Pandas Type: string\n- Column: Favorite Color, Description: Preferred color of the student, Semantic Type: color (custom), Pandas Type: string (or list if cleaned for multiple values)\n- Column: Age, Description: Age of the student, Semantic Type: age, Pandas Type: int (after cleaning invalid entries)\n```", "```py\nTask: Analyse the provided table to identify and document data quality issues.\n\nBelow are common data quality issues to guide your analysis. However, you may also identify other relevant issues:\n- Ingestion errors\n- Typecasting issues\n- Duplicates\n- Date parsing issues\n- Character encoding problems\n- Missing values\n- Typos/spelling mistakes\n- Anomalies/outliers\n- Conversion errors and inconsistent units\n- Privacy concerns (e.g., exposed PII)\n- Domain-specific errors (e.g., invalid formats for addresses, phone numbers, emails)\n\nInstructions:\n1\\. Examine silently the table and its metadata.\n2\\. Line by line, identify potential data quality issues without coding.\n3\\. Document each issue, including:\n   - Nature and description of the issue\n   - Expected correct state\n   - Violated constraint\n   - Confidence level in your assessment using ordinal categories: `low`, `medium`, `high` and `certain`.\n   - Specific location of the issue in the table (use 'None' for table-wide issues): Index and Column names.\n\nProvided Data:\n\nTable: \n,Student#,Last Name,First Name,Favorite Color,Age\n0,1,Johnson,Mia,periwinkle,12\n1,2,Lopez,Liam,blue,green,13\n2,3,Lee,Isabella,,11\n3,4,Fisher,Mason,gray,-1\n4,5,Gupta,Olivia,9,102\n5,6,,Robinson,,Sophia,,blue,,12\n\nMetadata:\n- Table Semantic Type: Person\n- Column: Student#, Description: Unique identifier for each student, Semantic Type: identifier, Pandas Type: int or string\n- Column: Last Name, Description: Family name of the student, Semantic Type: familyName, Pandas Type: string\n- Column: First Name, Description: Given name of the student, Semantic Type: givenName, Pandas Type: string\n- Column: Favorite Color, Description: Preferred color of the student, Semantic Type: color (custom), Pandas Type: string (or list if cleaned for multiple values)\n- Column: Age, Description: Age of the student, Semantic Type: age, Pandas Type: int (after cleaning invalid entries)\n\nDetected Data Issues:\n```", "```py\n1\\. Issue: Incorrect value format in \"Favorite Color\" column\n   - Nature and Description: The entry \"blue,green\" in the \"Favorite Color\" column for the second row appears to contain two colors instead of one, suggesting a possible ingestion or data entry error.\n   - Expected Correct State: Each cell under the \"Favorite Color\" column should contain only one color.\n   - Violated Constraint: Single value constraint.\n   - Confidence Level: High\n   - Specific Location: Index 1, Column \"Favorite Color\"\n\n2\\. Issue: Missing value in \"Favorite Color\" and \"Age\" columns\n   - Nature and Description: The third row has a missing value for \"Favorite Color\", and the sixth row has missing values for both \"Last Name\" and \"Favorite Color\".\n   - Expected Correct State: No missing values in any of the columns.\n   - Violated Constraint: Non-null constraint.\n   - Confidence Level: Certain\n   - Specific Location: Index 2, Column \"Favorite Color\"; Index 5, Columns \"Last Name\", \"Favorite Color\"\n\n3\\. Issue: Negative value in \"Age\" column\n   - Nature and Description: The fourth row has an age of \"-1\", which is not possible and indicates a data entry error.\n   - Expected Correct State: Age values should be positive integers.\n   - Violated Constraint: Age value range (greater than 0).\n   - Confidence Level: Certain\n   - Specific Location: Index 3, Column \"Age\"\n\n4\\. Issue: Misplaced values in \"Favorite Color\" and \"Age\" columns\n   - Nature and Description: In the fifth row, what appears to be an age (\"9\") is placed in the \"Favorite Color\" column, and an unlikely age (\"102\") is in the \"Age\" column, suggesting a possible shifting or misplacement of values.\n   - Expected Correct State: Age should be a reasonable positive integer, and favorite color should be a string denoting a color.\n   - Violated Constraint: Data type and value range constraint.\n   - Confidence Level: High\n   - Specific Location: Index 4, Columns \"Favorite Color\", \"Age\"\n\n5\\. Issue: Inconsistent formatting in row entries\n   - Nature and Description: The sixth row contains additional commas, which might indicate incorrect splitting or entry of the data, leading to misalignment of the values with their respective columns.\n   - Expected Correct State: Each row should consistently follow the format defined by the column headers without extra delimiters.\n   - Violated Constraint: Data format and consistency constraint.\n   - Confidence Level: High\n   - Specific Location: Index 5, Entire row\n```", "```py\n@dataclass\nclass DataIssue:\n    type_of_issue: str\n    expectation: str\n    constraint_violated: str\n    confidence_score: str # `low`, `medium`, `high` or `certain`\n    location: List[Tuple]  # Cell positions as (Index, Column). Use None for row/column-wide issues.\n```", "```py\nTask: Document data table issues using the provided `DataIssue` class.\n\nFor each identified issue and its description, document it using the provided `DataIssue` class structure. \n\n```", "```py\n\nThe goal is to generate Python code representing each data issue as a `DataIssue` object without redundant text. The identified issues are injected into the prompt using the placeholder `{issues_found}`.\n\nExample output:\n\n```", "```py\n\nThe final step involves converting the `location` attribute from lists of tuples to `numpy` arrays, which is detailed in the appendix.\n\nWith all elements in place, we can now calculate the *Data Dirtiness Score*.\n\n# Calculation of the Data Dirtiness Score and Comparison with Ground Truth\n\nLet’s revisit the function from the previous article, `compute_data_dirtiness_score`, which uses a list of `DataIssue` objects mentioned earlier.\n\n```", "```py\n\n> *Data Dirtiness Score: 28.33%*\n\nUsing the `GPT-4` model, we estimated the score to be around 28% for this sample. This is fairly close to the \"ground truth\" score of 31.87%.\n\nTo understand the discrepancy between these scores, let’s delve into more detailed metrics on data issue detection. In addition to the overall score, we have matrices of cell issue probabilities for both the ground truth and the model’s estimates.\n\nBelow is the ground truth matrix, with columns and indices added for clarity:\n\n```", "```py\n\nAnd here is the matrix of probabilities estimated by the model:\n\n```", "```py\n\nThough the matrices appear similar at first glance, we can apply threshold-based metrics such as `accuracy`, `recall`, `precision`, and `F1-score` to get a clearer picture. These metrics provide a straightforward evaluation of the model's performance by considering a cell problematic if the model's likelihood exceeds 0\\. Here are the metrics obtained:\n\n![](../Images/42ea3c3fee789daa72ba4af6d4548abe.png)\n\nThe model correctly identified 91% of problematic cells (`recall`), and all of its error predictions were accurate (`precision`).\n\nThe model missed one particular issue: “The `Favorite Color` and `First Name` fields might be swapped, considering `Olivia` can be both a name and a colour.\" This was deemed improbable with a `low` confidence score, suggesting `Olivia` is more likely the `First Name` rather than the `Favorite Color`. Consequently, even though this potential issue was overlooked, its minimal confidence score lessened its impact on the overall Data Dirtiness Score. This explains why the two scores are relatively close despite this omission.\n\nIn summary, this approach, based on large language models (LLMs), offers a method for detecting data quality issues in a data frame. While this method may not yet be fully automated and might need manual adjustments, it’s hoped that it will expedite the detection of data errors and the calculation of the *Data Dirtiness Score* for tabular data sets.\n\n# Next Steps and Challenges\n\nI use a two-step process to generate the issues as code. This is done because I have found this adds more stability over a one-in-all solution, i.e. scanning data set and metadatas and outputs data issues directly in right code format. This doesn’t imply it’s impossible, but I’ve chosen to divide this step into two phases to improve robustness for the time being.\n\nAn issue we face concerns managing large data sets, both in terms of the number of rows and columns. Despite recent advancements, LLMs still face limitations regarding the input context window and the length of generated content. These constraints limit the size of the table that can be serialised into the prompt for analysis and the length of the data issue report produced by the model. How to divide a data frame based on its size and the model’s capabilities is a question that arises.\n\nIn certain scenarios, the lack of general context can be problematic, such as when identifying duplicate rows in a database or detecting spelling errors without a broad understanding of the column values. For instance, in cases where duplicates are not straightforward, a common approach is **Entity Matching**. This technique is particularly useful in data cleaning processes and has seen advancements through the use of Large Language Models. Relevant research in this area includes studies like [Entity Matching using Large Language Models](https://www.semanticscholar.org/paper/Entity-Matching-using-Large-Language-Models-Peeters-Bizer/13c2ae7831c0f1579bc8c6f1a31c9aa8689e24a8) and [Can Foundation Models Wrangle Your Data?](https://arxiv.org/abs/2205.09911), along with [Large Language Models as Data Preprocessors](https://arxiv.org/abs/2308.16361) and [Jellyfish: A Large Language Model for Data Preprocessing](https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10).\n\nEnsemble methods in machine learning, which involve combining multiple models, can enhance performance and stability. This approach can be applied by running several LLMs simultaneously to identify issues in a data set. It’s beneficial to vary the prompts and settings for each LLM to ensure a diverse range of insights. Additionally, assigning specific error types, like spelling mistakes, to individual models can make the process more efficient. While this method can lead to more reliable results by dividing the task into smaller parts, it also increases both the cost and the complexity of the software. By gathering all the identified data issues, we can improve our chances of finding errors (increasing recall) but might also identify more false errors (decreasing precision). However, reviewing these identified errors is generally less time-consuming than finding them in the first place.\n\nThe ability of LLMs to interact directly with databases, similar to the code analysis capability in `ChatGPT-4`, opens up a wider range of possibilities for detecting data errors. A challenge here is automating this process, as the model may deviate from its intended path without sufficient guidance.\n\nDespite all the challenges, it is already quite promising what we can achieve with such as simple approach. With more work on engineering, I hope we can very soon provide a more robust solution to cover larger data sets and fully automate the detection process.\n\nThe next article will discuss automated data repair or, at the very least, suggest solutions for repair pending validation.\n\n# References\n\n*   [Data Dirtiness Score](https://medium.com/p/fe2ca5678d40)\n*   [Jellyfish: A Large Language Model for Data Preprocessing](https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10)\n*   [Can language models automate data wrangling?](http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf)\n*   [Large Language Models as Data Preprocessors](https://arxiv.org/abs/2308.16361)\n*   [Column Type Annotation using ChatGPT](https://arxiv.org/abs/2306.00745)\n*   [Annotating Columns with Pre-trained Language Models](https://paperswithcode.com/paper/annotating-columns-with-pre-trained-language)\n*   [SOTAB: The WDC Schema.org Table Annotation Benchmark](https://paperswithcode.com/paper/sotab-the-wdc-schema-org-table-annotation)\n*   [Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and Understanding — A Survey](https://arxiv.org/abs/2402.17944?utm_campaign=Data_Elixir&utm_source=Data_Elixir_475)\n*   [Entity Matching using Large Language Models](https://www.semanticscholar.org/paper/Entity-Matching-using-Large-Language-Models-Peeters-Bizer/13c2ae7831c0f1579bc8c6f1a31c9aa8689e24a8)\n\n# Appendix\n\nThe section explains how to transform the `location` attribute of a `DataIssue` object, which comes from a LLM, into a different format. This transformation changes a list of tuples, which represent cell positions, into a `numpy`array. This array acts as a mask for those cell positions.\nHere's a basic example using the `Students` data set:\n\n```", "```py\n\n```", "```py\n\nBelow are the function definitions:\n\n```"]