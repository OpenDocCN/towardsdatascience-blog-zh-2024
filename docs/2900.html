<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Making News Recommendations Explainable with Large Language Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Making News Recommendations Explainable with Large Language Models</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30">https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="2a54" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A prompt-based experiment to improve both accuracy and transparent reasoning in content personalization.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Alex Held" class="l ep by dd de cx" src="../Images/be76f042807c4816944531780d14a73d.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*EoRDqg2BxYlZp9PXgMnRwQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------" rel="noopener follow">Alex Held</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div><span data-testid="storyPublishDate">Nov 30, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/ff1026c0fe89bf7dceb16a6d47f1dc3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ASOYvGGW8pU5E5fVmFfKOw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Deliver relevant content to readers at the right time. Image by author.</figcaption></figure><p id="10aa" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">At <a class="af nx" href="https://www.spiegel.de/" rel="noopener ugc nofollow" target="_blank">DER SPIEGEL</a>, we are continually exploring ways to improve how we recommend news articles to our readers. In our latest (offline) experiment, we investigated whether <a class="af nx" href="https://vickiboykis.com/what_are_embeddings/" rel="noopener ugc nofollow" target="_blank">Large Language Models</a> (LLMs) could effectively predict which articles a reader would be interested in, based on their reading history.</p><p id="9c2e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Our Approach</strong></p><p id="ec3b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We conducted a study with readers who participated in a survey where they rated their interest in various news articles. This gave us a ground truth of reader preferences. For each participant, we had two key pieces of information: their actual reading history (which articles they had read before taking the survey) and their ratings of a set of new articles in the survey. Read more about this mixed-methods approach to offline evaluation of news recommender systems here:</p><div class="ny nz oa ob oc od"><a rel="noopener follow" target="_blank" href="/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------"><div class="oe ab ig"><div class="of ab co cb og oh"><h2 class="bf fr hw z io oi iq ir oj it iv fp bk">A Mixed-Methods Approach to Offline Evaluation of News Recommender Systems</h2><div class="ok l"><h3 class="bf b hw z io oi iq ir oj it iv dx">Combining reader feedback from surveys with behavioral click data to optimize content personalization.</h3></div><div class="ol l"><p class="bf b dy z io oi iq ir oj it iv dx">towardsdatascience.com</p></div></div><div class="om l"><div class="on l oo op oq om or lq od"/></div></div></a></div><p id="078b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We then used the <a class="af nx" href="https://github.com/anthropics/anthropic-sdk-python" rel="noopener ugc nofollow" target="_blank">Anthropic API</a> to access <a class="af nx" href="https://www.anthropic.com/news/claude-3-5-sonnet" rel="noopener ugc nofollow" target="_blank">Claude 3.5 Sonnet</a>, a state-of-the-art language model, as our recommendation engine. For each reader, we provided the model with their reading history (news title and article summary) and asked it to predict how interested they would be in the articles from the survey. Here is the prompt we used:</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="6e25" class="ow ox fq ot b bg oy oz l pa pb">You are a news recommendation system. Based on the user's reading history, <br/>predict how likely they are to read new articles. Score each article from 0 to 1000, <br/>where 1000 means highest likelihood to read.<br/><br/>Reading history (Previous articles read by the user):<br/>[List of previously read articles with titles and summaries]<br/><br/>Please rate the following articles (provide a score 0-1000 for each):<br/>[List of candidate articles to rate]<br/><br/>You must respond with a JSON object in this format:<br/>{<br/>    "recommendations": [<br/>        {<br/>            "article_id": "article-id-here",<br/>            "score": score<br/>        }<br/>    ]<br/>}</span></pre><p id="ca18" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">With this approach, we can now compare the actual ratings from the survey against the score predictions from the LLM. This comparison provides an ideal dataset for evaluating the language model‚Äôs ability to predict reader interests.</p><p id="786b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Results and Key Findings</strong></p><p id="c386" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The findings were impressively strong. To understand the performance, we can look at two key metrics. First, the <a class="af nx" href="https://www.evidentlyai.com/ranking-metrics/precision-recall-at-k" rel="noopener ugc nofollow" target="_blank">Precision@5</a>: the LLM achieved a score of 56%, which means that when the system recommended its top 5 articles for a user (out of 15), on average (almost) 3 out of these 5 articles were actually among the articles that user rated highest in our survey. Looking at the distribution of these predictions reveals even more impressive results: for 24% of users, the system correctly identified at least 4 or 5 of their top articles. For another 41% of users, it correctly identified 3 out of their top 5 articles.</p><p id="2606" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To put this in perspective, if we were to recommend articles randomly, we would only achieve 38.8% precision (see previous <a class="af nx" href="https://medium.com/towards-data-science/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501" rel="noopener">medium article</a> for details). Even recommendations based purely on article popularity (recommending what most people read) only reach 42.1%, and our previous approach using an embedding-based technique achieved 45.4%.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pc"><img src="../Images/73b93682f37bf1eb4cdc35c9c5a9c262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b8qclsNuoVPOfSPJnfjqcA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Graphic by author</figcaption></figure><p id="a330" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The graphic below shows the uplift: While having any kind of knowledge about the users is better than guessing (random model), the LLM-based approach shows the strongest performance. Even compared to our sophisticated embedding-based logic, the LLM achieves a significant uplift in prediction accuracy.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pc"><img src="../Images/944e6bf25ecad03090641f39d1448a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y67XTMPkDPDDBdSn0ouymQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Graphic by author</figcaption></figure><p id="5534" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As a second evaluation metric, we use <a class="af nx" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html" rel="noopener ugc nofollow" target="_blank">Spearman correlation</a>. At 0.41, it represents a substantial improvement over our embedding-based approach (0.17). This also shows that the LLM is not just better at finding relevant articles, but also at understanding how much a reader might prefer one article over another.</p><p id="937f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Beyond Performance: The Power of Explainability</strong></p><p id="ab7b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">What sets LLM-based recommendations apart is not just their performance but their ability to explain their decisions in natural language. Here is an example of how our system analyzes a user‚Äôs reading patterns and explains its recommendations (prompt not shown):</p><pre class="ml mm mn mo mp os ot ou bp ov bb bk"><span id="76a5" class="ow ox fq ot b bg oy oz l pa pb">User has 221 articles in reading history<br/><br/>Top 5 Comparison:<br/>--------------------------------------------------------------------------------<br/><br/>Top 5 Predicted by Claude:<br/>1. Wie ich mit 38 Jahren zum ersten Mal lernte, strukturiert zu arbeiten (Score: 850, Actual Value: 253.0)<br/>2. Warum wir den Umgang mit der Sonne neu lernen m√ºssen (Score: 800, Actual Value: 757.0)<br/>3. Lohnt sich ein Speicher f√ºr Solarstrom vom Balkon? (Score: 780, Actual Value: 586.0)<br/>4. ¬ªMan muss sich fragen, ob dieser spezielle deutsche Weg wirklich intelligent ist¬´ (Score: 750, Actual Value: 797.0)<br/>5. Wie Bayern versucht, sein Drogenproblem unsichtbar zu machen (Score: 720, Actual Value: 766.0)<br/><br/>Actual Top 5 from Survey:<br/>4. ¬ªMan muss sich fragen, ob dieser spezielle deutsche Weg wirklich intelligent ist¬´ (Value: 797.0, Predicted Score: 750)<br/>5. Wie Bayern versucht, sein Drogenproblem unsichtbar zu machen (Value: 766.0, Predicted Score: 720)<br/>2. Warum wir den Umgang mit der Sonne neu lernen m√ºssen (Value: 757.0, Predicted Score: 800)<br/>6. Abitur als Lotterie? (Value: 601.0, Predicted Score: 650)<br/>3. Lohnt sich ein Speicher f√ºr Solarstrom vom Balkon? (Value: 586.0, Predicted Score: 780)<br/><br/>Performance Metrics:<br/>--------------------------------------------------------------------------------<br/>Spearman Correlation: 0.673<br/>Precision@5: 0.800<br/><br/>Claude's Analysis:<br/>--------------------------------------------------------------------------------<br/>1. Key patterns in user's reading history:<br/>- Strong interest in social and political issues<br/>- Regular engagement with lifestyle and personal development content<br/>- Interest in health and wellness topics<br/>- Frequent reading of articles about economic and financial matters<br/>- Attraction to critical analysis and commentary pieces<br/>- Interest in food and cooking content<br/><br/>2. Scoring explanation:<br/><br/>Highest scored articles:<br/>- "Wie ich mit 38 Jahren zum ersten Mal lernte, strukturiert zu arbeiten" (850) - Aligns with the user's interest in personal development and lifestyle content<br/>- "Warum wir den Umgang mit der Sonne neu lernen m√ºssen" (800) - Matches interest in health and wellness topics<br/>- "Lohnt sich ein Speicher f√ºr Solarstrom vom Balkon?" (780) - Corresponds to interest in practical advice and economic considerations<br/><br/>Medium scored articles:<br/>- "Man muss sich fragen, ob dieser spezielle deutsche Weg wirklich intelligent ist" (750) - Fits pattern of interest in political commentary<br/>- "Wie Bayern versucht, sein Drogenproblem unsichtbar zu machen" (720) - Matches interest in social issues and critical reporting<br/>- "Abitur als Lotterie?" (650) - Aligns with interest in educational and social topics<br/><br/>Lower scored articles:<br/>- "Eine Brise Formel 1" (550) - Limited sports content in reading history<br/>- "Reizender Absatz" (450) - Less alignment with demonstrated interests<br/>- "Hier wird jetzt auf ganz, ganz hohem Niveau gemeckert" (400) - Style and topic less aligned with user preferences<br/><br/>The scoring prioritizes articles that match the user's demonstrated interests in social issues, practical advice, and critical analysis while giving lower scores to sports and lighter content that appears less frequently in their reading history.</span></pre><p id="0275" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Rather than operating as a black box, the system could articulate why it thinks a particular article might be interesting to a reader: <em class="pd">Because you frequently read articles about practical advice and economic matters, you might find this analysis about the cost-effectiveness of balcony solar storage particularly relevant.</em> This kind of transparent reasoning could make recommendations feel more personal and trustworthy.</p><p id="77d0" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Conclusion</strong></p><p id="33eb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">While our results are promising, several challenges need to be addressed. Due to long prompts (hundreds of article summaries per user), the most significant is cost. At about $0.21 per user for a single recommendation run, scaling this to full readerships would be irresponsibly expensive. Testing high-performing <a class="af nx" href="https://ai.meta.com/blog/meta-llama-3-1/" rel="noopener ugc nofollow" target="_blank">open-source models</a>, could potentially reduce these costs. Additionally, the current implementation is relatively slow, taking several seconds per user. For a news platform where content updates frequently and reader interests evolve sometimes even throughout a single day, we would need to run these recommendations multiple times daily to stay relevant.</p><p id="8196" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Furthermore, we used a single, straightforward prompt without any prompt engineering or optimization. There is likely (significant) room for improvement through systematic prompt refinement.[1] Additionally, our current implementation only uses article titles and summaries, without leveraging available metadata. We could potentially increase the performance by incorporating additional signals such as reading time per article (how long users spent reading each piece) or overall article popularity. Anyhow, due to high API costs, running iterative evaluation pipelines is currently not an option.</p><p id="7fee" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">All in all, the combination of strong predictive performance and natural language explanations suggests that LLMs will be a valuable tool in news recommendation systems. And beyond recommendations, they add a new way on how we analyze user journeys in digital news. Their ability to process and interpret reading histories alongside metadata opens up exciting possibilities: from understanding content journeys and topic progressions to creating personalized review summaries.</p></div></div></div><div class="ab cb pe pf pg ph" role="separator"><span class="pi by bm pj pk pl"/><span class="pi by bm pj pk pl"/><span class="pi by bm pj pk"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="1f82" class="pm ox fq bf pn po pp pq pr ps pt pu pv nk pw px py no pz qa qb ns qc qd qe qf bk"><strong class="al">Thanks for reading üôè</strong></h2><p id="ce8d" class="pw-post-body-paragraph nb nc fq nd b go qg nf ng gr qh ni nj nk qi nm nn no qj nq nr ns qk nu nv nw fj bk">I hope you liked it, if so, just make it clap. Please do not hesitate to <a class="af nx" href="https://www.linkedin.com/in/alex-held-1193b9234/" rel="noopener ugc nofollow" target="_blank">connect with me on LinkedIn</a> for further discussion or questions.</p><p id="970a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As a data scientist at <a class="af nx" href="https://www.spiegel.de/" rel="noopener ugc nofollow" target="_blank">DER SPIEGEL</a>, I have authorized access to proprietary user data and click histories, which form the basis of this study. This data is not publicly available. All presented results are aggregated and anonymized to protect user privacy while showcasing our methodological approach to news recommendation.</p><h2 id="d8e3" class="pm ox fq bf pn po pp pq pr ps pt pu pv nk pw px py no pz qa qb ns qc qd qe qf bk">References</h2><p id="b8cb" class="pw-post-body-paragraph nb nc fq nd b go qg nf ng gr qh ni nj nk qi nm nn no qj nq nr ns qk nu nv nw fj bk">[1] Dairui, Liu &amp; Yang, Boming &amp; Du, Honghui &amp; Greene, Derek &amp; Hurley, Neil &amp; Lawlor, Aonghus &amp; Dong, Ruihai &amp; Li, Irene. (2024). RecPrompt: A Self-tuning Prompting Framework for News Recommendation Using Large Language Models.</p></div></div></div></div>    
</body>
</html>