- en: Understanding Long RoPE in LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/understanding-long-rope-in-llms-29337dc7e4a9?source=collection_archive---------1-----------------------#2024-05-15](https://towardsdatascience.com/understanding-long-rope-in-llms-29337dc7e4a9?source=collection_archive---------1-----------------------#2024-05-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This blog post will go in detail about the Long RoPE Methodology used to expand
    the context lengths in LLMs without significant performance degradation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mgunton7?source=post_page---byline--29337dc7e4a9--------------------------------)[![Matthew
    Gunton](../Images/6f5a9530ad5252aa3f2fae87b3f272b1.png)](https://medium.com/@mgunton7?source=post_page---byline--29337dc7e4a9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--29337dc7e4a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--29337dc7e4a9--------------------------------)
    [Matthew Gunton](https://medium.com/@mgunton7?source=post_page---byline--29337dc7e4a9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--29337dc7e4a9--------------------------------)
    ·8 min read·May 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b0e0ea0d975d1c44708ca117d30e3066.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author — generated by Stable Diffusion 2.1
  prefs: []
  type: TYPE_NORMAL
- en: As the general public has begun using LLMs in their daily lives, one important
    problem arises when they have long-conversations. After a few dialogue turns,
    the LLM can appear to completely forget what was said before! Behind the scenes,
    each line of dialogue is fed into the LLM’s context, which you can think of as
    a giant input into the model. Once the conversation is too long for the context,
    you have to remove some of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Not only is this a bad customer experience, it also limits the amount of information
    that a LLM can reasonably process. Consequently, work has been ongoing to build
    LLMs with larger and larger contexts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Today’s paper, “LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens,”
    achieves just that.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/91cd200464c935f6ca2413deb5ae2d07.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1 from [the paper](https://arxiv.org/pdf/2402.13753)
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the above graph, we can see that the perplexity, a measurement of
    loss correlating to how well the LLM predicts the next token, stays low for LongRoPE,
    but spikes…
  prefs: []
  type: TYPE_NORMAL
