<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Counts Outlier Detector: Interpretable Outlier Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Counts Outlier Detector: Interpretable Outlier Detection</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/counts-outlier-detector-interpretable-outlier-detection-ead0d469557a?source=collection_archive---------2-----------------------#2024-06-19">https://towardsdatascience.com/counts-outlier-detector-interpretable-outlier-detection-ead0d469557a?source=collection_archive---------2-----------------------#2024-06-19</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="fa9d" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">An interpretable outlier detector based on multi-dimensional histograms.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@wkennedy934?source=post_page---byline--ead0d469557a--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="W Brett Kennedy" class="l ep by dd de cx" src="../Images/b3ce55ffd028167326c117d47c64c467.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*v8pf2r3SPMLuHoSmF4IwlA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--ead0d469557a--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@wkennedy934?source=post_page---byline--ead0d469557a--------------------------------" rel="noopener follow">W Brett Kennedy</a></p></div></div></div><div class="hz ia l"><div class="ab ib"><div class="ab"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewbox="0 0 16 16"><path fill="#437AFF" d="M15.163 8c0 .65-.459 1.144-.863 1.575-.232.244-.471.5-.563.719s-.086.543-.092.875c-.006.606-.018 1.3-.49 1.781-.47.481-1.15.494-1.744.5-.324.006-.655.013-.857.094s-.465.337-.704.575c-.422.412-.906.881-1.542.881-.637 0-1.12-.469-1.543-.881-.239-.238-.49-.482-.704-.575-.214-.094-.532-.088-.857-.094-.593-.006-1.273-.019-1.744-.5s-.484-1.175-.49-1.781c-.006-.332-.012-.669-.092-.875-.08-.207-.33-.475-.563-.719-.404-.431-.863-.925-.863-1.575s.46-1.144.863-1.575c.233-.244.472-.5.563-.719.092-.219.086-.544.092-.875.006-.606.019-1.3.49-1.781s1.15-.494 1.744-.5c.325-.006.655-.012.857-.094.202-.081.465-.337.704-.575C7.188 1.47 7.671 1 8.308 1s1.12.469 1.542.881c.239.238.49.481.704.575s.533.088.857.094c.594.006 1.273.019 1.745.5.47.481.483 1.175.49 1.781.005.331.011.669.091.875s.33.475.563.719c.404.431.863.925.863 1.575"/><path fill="#fff" d="M7.328 10.5c.195 0 .381.08.519.22.137.141.215.331.216.53 0 .066.026.13.072.177a.24.24 0 0 0 .346 0 .25.25 0 0 0 .071-.177c.001-.199.079-.389.216-.53a.73.73 0 0 1 .519-.22h1.959c.13 0 .254-.053.346-.146a.5.5 0 0 0 .143-.354V6a.5.5 0 0 0-.143-.354.49.49 0 0 0-.346-.146h-1.47c-.324 0-.635.132-.865.366-.23.235-.359.552-.359.884v2.5c0 .066-.025.13-.071.177a.24.24 0 0 1-.346 0 .25.25 0 0 1-.072-.177v-2.5c0-.332-.13-.65-.359-.884A1.21 1.21 0 0 0 6.84 5.5h-1.47a.49.49 0 0 0-.346.146A.5.5 0 0 0 4.88 6v4c0 .133.051.26.143.354a.49.49 0 0 0 .347.146z"/></svg></div></div></div><span class="ic id" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ie if ah ai aj ak al am an ao ap aq ar ig ih ii" disabled="">Follow</button></p></div></div></span></div></div><div class="l ij"><span class="bf b bg z dx"><div class="ab cn ik il im"><div class="in io ab"><div class="bf b bg z dx ab ip"><span class="iq l ij">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--ead0d469557a--------------------------------" rel="noopener follow"><p class="bf b bg z ir is it iu iv iw ix iy bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ic id" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">18 min read</span><div class="iz ja l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 19, 2024</span></div></span></div></span></div></div></div><div class="ab cp jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq"><div class="h k w ea eb q"><div class="kg l"><div class="ab q kh ki"><div class="pw-multi-vote-icon ed iq kj kk kl"><div class=""><div class="km kn ko kp kq kr ks am kt ku kv kl"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kw kx ky kz la lb lc"><p class="bf b dy z dx"><span class="kn">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao km lf lg ab q ee lh li" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count ld le">1</span></p></button></div></div></div><div class="ab q jr js jt ju jv jw jx jy jz ka kb kc kd ke kf"><div class="lj k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lk an ao ap ig ll lm ln" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lo cn"><div class="l ae"><div class="ab cb"><div class="lp lq lr ls lt lu ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="bd1f" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">This article continues a series on interpretable outlier detection. The previous article (<a class="af ni" href="https://medium.com/towards-data-science/interpretable-outlier-detection-frequent-patterns-outlier-factor-fpof-0d9cbf51b17a" rel="noopener">Interpretable Outlier Detection: Frequent Patterns Outlier Factor (FPOF)</a> ) covered the FPOF algorithm, as well as some of the basics of outlier detection and interpretability. This builds on that, and presents Counts Outlier Detector, another interpretable outlier detection method.</p><p id="76ce" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">As covered in the FPOF article, knowing <em class="nj">why </em>records are outliers can be as important as knowing which records are outliers. In fact, there can often be limited value in performing outlier detection where we cannot determine why the records flagged as outliers were flagged. For example, if an outlier detection system identifies what may be a security threat, to investigate this efficiently and effectively it’s necessary to know what is unusual: why this was identified as anomalous. Similarly where the outlier detection system identifies possible fraud, machine failures, scientific discoveries, unusually effective (or ineffective) business practices, or other outliers.</p><p id="498e" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Although the algorithms themselves employed by detectors are usually quite understandable, the individual predictions are generally not. For example, standard detectors such as Isolation Forest (IF), Local Outlier Factor (LOF), and kth Nearest Neighbors (kNN), have algorithms that are straightforward to understand, but produce scores that may be difficult to assess, particularly with high-dimensional data. It can be difficult to determine why records flagged as outliers are anomalous.</p><p id="6e0e" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">In principle, it’s quite manageable to explain outliers. With most outliers, there are only a small set of features that have anomalous values (very few outliers have anomalous values in every feature). Knowing which features are unusual, and how these features are unusual, is generally all that’s required to understand why outliers are outliers, but this is, unfortunately, usually unavailable.</p><p id="ccd6" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Only a small number of outlier detectors provide an explanation for the scores they produce. These include <a class="af ni" href="https://medium.com/towards-data-science/interpretable-outlier-detection-frequent-patterns-outlier-factor-fpof-0d9cbf51b17a" rel="noopener">FPOF </a>and a related outlier detection method based on Association Rules (both covered in <a class="af ni" href="https://www.manning.com/books/outlier-detection-in-python" rel="noopener ugc nofollow" target="_blank">Outlier Detection in Python</a>), to give two examples. But, there are far fewer interpretable models than would be wished. Motivated by this, I’ve developed two interpretable models, Counts Outlier Detector (COD), and Data Consistency Checker, which I’m still maintaining today.</p><p id="8541" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">They work quite a bit differently from each other but are both useful tools. The former is covered in this article; Data Consistency Checker will be covered in an upcoming article. As well, both are covered in <a class="af ni" href="https://www.manning.com/books/outlier-detection-in-python" rel="noopener ugc nofollow" target="_blank">Outlier Detection in Python</a>; the remainder of this article is taken from the section on Counts Outlier Detector.</p><h1 id="e908" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Counts Outlier Detector</h1><p id="e2ab" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">The main page for Counts Outlier Detector is <a class="af ni" href="https://github.com/Brett-Kennedy/CountsOutlierDetector" rel="noopener ugc nofollow" target="_blank">https://github.com/Brett-Kennedy/CountsOutlierDetector</a>.</p><p id="ed40" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Counts Outlier Detector (COD) is an outlier detector for tabular data, designed to provide clear explanations of the rows flagged as outliers and of their specific scores. More specifically, COD is a multivariate histogram-based model: it divides the data into sets of bins and identifies outliers as the records in bins with unusually low counts.</p><p id="405b" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">This is an effective, efficient, and interpretable technique for outlier detection. There are some very real limitations of multi-dimensional histograms, which we cover here, but, as we’ll also cover, these are quite addressable. Testing and evaluating the method has found it to be a strong detector, very often as useful as more standard tools, with the substantial benefit of being interpretable.</p><h1 id="cc7c" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Introduction to histogram-based outlier detection</h1><p id="ea97" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">Before explaining COD, I’ll explain another, simpler histogram-based algorithm for outlier detection that pre-dates COD, called HBOS (Histogram-Based Outlier Score). This is part of the popular <a class="af ni" href="https://github.com/yzhao062/pyod" rel="noopener ugc nofollow" target="_blank">PyOD </a>(Python Outlier Detection) library and is often an effective tool itself. Other histogram-based outlier detection algorithms exist as well, and work similarly.</p><p id="feb3" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">HBOS works based on a very straightforward idea: to determine how unusual a row in a table is, it simply assesses how unusual each individual value in the row is. To do this, the values are each compared to their columns. This is done by first creating a histogram to represent each feature (HBOS works strictly with numeric data) and comparing each value to the histogram.</p><p id="41a3" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">There are other means to determine how unusual a numeric value is relative to a table column (or other sequence of numeric values). Kernel density estimates, cumulative distributions, and other methods can also work well. But histograms are one straightforward and effective means. The other methods are covered in <a class="af ni" href="https://www.manning.com/books/outlier-detection-in-python" rel="noopener ugc nofollow" target="_blank">Outlier Detection in Python</a>, but for simplicity, and since this is what COD uses, we’ll look just at histograms in this article.</p><p id="aec1" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">HBOS divides each feature into a set of equal-width bins. Each feature may then be represented by a histogram such as:</p><figure class="oo op oq or os ot ol om paragraph-image"><div class="ol om on"><img src="../Images/9e5bb3a3f01dcfa7f35c3e335a839ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*qtDK6bJm9Pn9uPG_gNkZ8g.png"/></div></figure><p id="840e" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">In this case, the histogram uses 20 bins; with HBOS, we would normally use between about 5 and 50 bins per feature. If the table has, say, 30 features, there will be 30 histograms such as this.</p><p id="a3a9" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Any values that are in bins with a very low count would be considered unusual. In this histogram, a value around 6.0, for example, would be considered rare, as it’s bin has few examples from the training data; it would be given a relatively high outlier score. A value of 4.0, on the other hand, would be considered very normal, so given a low outlier score.</p><p id="0e85" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">So, to evaluate a row, HBOS determines how unusual each individual value in the row is (relative to the histogram for its feature), gives each value a score, and sums these scores together. In this way, the rows with the most rare values, and with the rarest rare values, will receive the highest overall outlier scores; a row may receive a high overall outlier score if it has a single value that’s extremely rare for its column, or if it has a number of values that are moderately rare for their columns.</p><p id="786c" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">This does mean that HBOS is only able to find one specific type of outlier: rows that contain one or more unusual single values; it cannot identify rows that contain unusual combinations of values. This is a very major limitation, but HBOS is able to work extremely fast, and the outliers it identifies tend to truly be strong outliers, even if it also misses many outliers.</p><p id="885c" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Still, it’s a major limitation that HBOS will miss unusual combinations of values. For example, in a table describing people, a record may have an age of 130, or a height of 7'2", and HBOS would detect these. But, a record may also have an age of 2 and a height of 5'10". The age and the height may both be common, but the combination not: it’s an example of a rare combination of two features.</p><p id="6fd5" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">It’s also possible to have rare combinations of three, four, or more features, and these may be as relevant as unusual single values.</p><h1 id="5050" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Overview of the Counts Outliers Detector</h1><p id="544f" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">COD extends the idea of histogram-based outlier detection and supports multi-dimensional histograms. This allows COD to identify outliers that are rare combinations of 2, 3, or more values, as well as the rare single values that can be detected by standard (1d) histogram-based methods such as HBOS. It can catch unusual single values such as heights of 7'2", and can also catch where a person has an age of 2 and a height of 5'10".</p><p id="8e6d" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">We look at 2d histograms first, but COD can support histograms up to 6 dimensions (we describe below why it does not go beyond this, and in fact, using only 2 or 3 or 4 dimensions will often work best).</p><p id="3b12" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">A 2d histogram can be viewed similarly as a heatmap. In the image below we see a histogram in 2d space where the data in each dimension is divided into 13 bins, creating 169 (13 x 13) bins in the 2d space. We can also see one point (circled) that is an outlier in the 2d space. This point is in a bin with very few items (in this case, only one item) and so can be identified as an outlier when examining this 2d space.</p><figure class="oo op oq or os ot ol om paragraph-image"><div class="ol om ov"><img src="../Images/d25505b68a750c02b179e4442c58354e.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*KJUu2-8KGSxeIsj63yUvMQ.png"/></div></figure><p id="92f4" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">This point is not an outlier in either 1d space; it is not unusual in the x dimension or the y dimension, so would be missed by HBOS and other tools that examine only single dimensions at a time.</p><p id="53d5" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">As with HBOS, COD creates a 1d histogram for each single feature. But then, COD also creates a 2d histogram like this for each pair of features, so is able to detect any unusual pairs of values. The same idea can then be applied to any number of dimensions. It is more difficult to draw, but COD creates 3d histograms for each triple of features (each bin is a cube), and so on. Again, it calculates the counts (using the training data) in each bin and is able to identify outliers: values (or combinations of values) that appear in bins with unusually low counts.</p><h1 id="60ba" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">The Curse of Dimensionality</h1><p id="d807" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">Although it’s effective to create histograms based on each set of 2, 3, and often more features, it is usually infeasible to create a histogram using all features, at least if there are more than about 6 or 7 features in the data. Due to what’s called <em class="nj">the curse of dimensionality</em>, we may have far more bins than data records.</p><p id="ae9b" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">For example, if there are 50 features, even using only 2 bins per feature, we would have 2 to the power of 50 bins in a 50d histogram, which is certainly many orders of magnitude greater than the number data records. Even with only 20 features (and using 2 bins per feature), we would have 2 to the power of 20, over one million, bins. Consequently, we can end up with most bins having no records, and those bins that do have any, containing only one or two items.</p><p id="f176" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Most data is relatively skewed and there are usually associations between the features, so the affect won’t be as strong as if the data were spread uniformly through the space, but there will still likely be far too many features to consider at once using a histogram-based method for outlier detection.</p><p id="e158" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Fortunately though, this is actually not a problem. It’s not necessary to create high-dimensional histograms; low-dimensional histograms are quite sufficient to detect the most relevant (and most interpretable) outliers. Examining each 1d, 2d and 3d space, for example, is sufficient to identify each unusual single value, pair of values, and triple of values. These are the most comprehensible outliers and, arguably, the most relevant (or at least typically among the most relevant). Where desired (and where there is sufficient data), examining 4d, 5d or 6d spaces is also possible with COD.</p><h1 id="6be6" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">The COD Algorithm</h1><p id="5867" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">The approach taken by COD is to first examine the 1d spaces, then the 2d spaces, then 3d, and so on, up to at most 6d. If a table has 50 features, this will examine (50 choose 1) 1d spaces (finding the unusual single values), then (50 choose 2) 2d spaces (finding the unusual pairs of values), then (50 choose 3) 3d spaces (finding the unusual triples of values), and so on. This covers a large number of spaces, but it means each record is inspected thoroughly and that anomalies (at least in lower dimensions) are not missed.</p><p id="921d" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Using histograms also allows for relatively fast calculations, so this is generally quite tractable. It can break down with very large numbers of features, but in this situation virtually all outlier detectors will eventually break down. Where a table has many features (for example, in the dozens or hundreds), it may be necessary to limit COD to 1d spaces, finding only unusual single values — which may be sufficient in any case for this situation. But for most tables, COD is able to examine even up to 4 or 5 or 6d spaces quite well.</p><p id="b788" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Using histograms also eliminates the distance metrics used by many outlier detector methods, including some of the most well-used. While very effective in lower dimensions methods, such as LOF, kNN, and several others use all features at once and can be highly susceptible to the curse of dimensionality in higher dimensions. For example, kNN identifies outliers as points that are relatively far from their k nearest neighbors. This is a sensible and generally affective approach, but with very high dimensionality, the distance calculations between points can become highly unreliable, making it impossible to identify outliers using kNN or similar algorithms.</p><p id="4839" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">By examining only small dimensionalities at a time, COD is able to handle far more features than many other outlier detection methods.</p><h1 id="77db" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Limiting evaluation to small dimensionalities</h1><p id="8d57" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">To see why it’s sufficient to examine only up to about 3 to 6 dimensions, we look at the example of 4d outliers. By <em class="nj">4d outliers</em>, I’m referring to outliers that are rare combinations of some four features, but are not rare combinations of any 1, 2, or 3 features. That is, each single feature, each pair of features, and each triple of features is fairly common, but the combination of all four features is rare.</p><p id="8232" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">This is possible, and does occur, but is actually fairly uncommon. For most records that have a rare combination of 4 features, at least some subset of two or three of those features will usually also be rare.</p><p id="aafe" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">One of the interesting things I discovered while working on this and other tools is that most outliers can be described based on a relatively small set of features. For example, consider a table (with four features) representing house prices, we may have features for: square feet, number of rooms, number of floors, and price. Any single unusual value would likely be interesting. Similarly for any pair of features (e.g. low square footage with a large number of floors; or low square feet with high price), and likely any triple of features. But there’s a limit to how unusual a combination of all four features can be without there being any unusual single value, unusual pair, or unusual triple of features.</p><p id="d91a" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">By checking only lower dimensions we cover most of the outliers. The more dimensions covered, the more outliers we find, but there are diminishing returns, both in the numbers of outliers, and in their relevance.</p><p id="0e0b" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Even where some legitimate outliers may exist that can only be described using, say, six or seven features, they are most likely difficult to interpret, and likely of lower importance than outliers that have a single rare value, or single pair, or triple of rare values. They also become difficult to quantify statistically, given the numbers of combinations of values can be extremely large when working with beyond a small number of features.</p><p id="1b74" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">By working with small numbers of features, COD provides a nice middle ground between detectors that consider each feature independently (such as HBOS, z-score, inter-quartile range, entropy-based tests and so on) and outlier detectors that consider all features at once (such as Local Outlier Factor and KNN).</p><h1 id="ee6f" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">How COD removes redundancy in explanations</h1><p id="c5cb" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">Counts Outlier Detector works by first examining each column individually and identifying all values that are unusual with respect to their columns (the <em class="nj">1d outliers)</em>.</p><p id="76b2" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">It then examines each pair of columns, identifying the rows with pairs of unusual values within each pair of columns (the <em class="nj">2d outliers)</em>. The detector then considers sets of 3 columns (identifying <em class="nj">3d outliers</em>), sets of 4 columns (identifying <em class="nj">4d outliers</em>), and so on.</p><p id="1223" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">At each stage, the algorithm looks for instances that are unusual, excluding values or combinations already flagged in lower-dimensional spaces. For example, in the table of people described above, a height of 7'2" would be rare. Given that, any combination of age and height (or height and anything else), where the height is 7'2", will be rare, simply because 7'2" is rare. As such, there is no need to identify, for example, a height of 7'2" and age of 25 as a rare combination; it is rare only because 7'2" is rare and reporting this as a 2d outlier would be redundant. Reporting it strictly as a 1d outlier (based only on the height) provides the clearest, simplest explanation for any rows containing this height.</p><p id="e5eb" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">So, once we identify 7'2" as a 1d outlier, we do not include this value in checks for 2d outliers, 3d outliers, and so on. The majority of values (the more typical heights relative to the current dataset) are, however, kept, which allows us to further examine the data and identify unusual combinations.</p><p id="81f3" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Similarly, any rare pairs of values in 2d spaces are excluded from consideration in 3d and higher-dimensional spaces; any rare triples of values in 3d space will be excluded from 4d and higher-dimensional spaces; and so on.</p><p id="ecfa" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">So, each anomaly is reported using as few features as possible, which keeps the explanations of each anomaly as simple as possible.</p><p id="2d0a" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Any row, though, may be flagged numerous times. For example, a row may have an unusual value in Column F; an unusual pair of values in columns A and E; another unusual pair of values in D and F; as well as an unusual triple of values in columns B, C, D. The row’s total outlier score would be the sum of the scores derived from these.</p><h1 id="88cb" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Interpretability</h1><p id="1c60" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">We can identify, for each outlier in the dataset, the specific set of features where it is anomalous. This, then, allows for quite clear explanations. And, given that a high fraction of outliers are outliers in 1d or 2d spaces, most explanations can be presented visually (examples are shown below).</p><h1 id="3917" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Scoring</h1><p id="d0df" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">Counts Outlier Detector takes its name from the fact it examines the exact count of each bin. In each space, the bins with unusually low counts (if any) are identified, and any records with values in these bins are identified as having an anomaly in this sense.</p><p id="41b8" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">The scoring system then used is quite simple, which further supports interpretability. Each rare value or combination is scored equivalently, regardless of the dimensionality or the counts within the bins. Each row is simply scored based on the number of anomalies found.</p><p id="a805" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">This can loose some fidelity (rare combinations are scored the same as very rare combinations), but allows for significantly faster execution times and more interpretable results. This also avoids any complication, and any arbitrariness, weighting outliers in different spaces. For example, it may not be clear how to compare outliers in a 4d space vs in a 2d space. COD eliminates this, treating each equally. So, this does trade-off some detail in the scores for interpretability, but the emphasis of the tool is interpretability, and the effect on accuracy is small (as well as being positive as often as negative — treating anomalies equivalently provides a regularizing effect).</p><p id="b522" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">By default, only values or combinations that are strongly anomalous will be flagged. This process can be tuned by setting a threshold parameter.</p><h1 id="1040" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Example</h1><p id="0985" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">Here, we provide a simple example using COD, working with the <a class="af ni" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris" rel="noopener ugc nofollow" target="_blank">iris </a>dataset, a toy dataset provided by scikit-learn. To execute this, the CountsOutlierDetector class must first be imported. Here, we then simply create an instance of CountsOutlierDetector and call fit_predict().</p><pre class="oo op oq or os ow ox oy bp oz bb bk"><span id="3375" class="pa nl fq ox b bg pb pc l pd pe">import pandas as pd<br/>from sklearn.datasets import load_iris<br/>from counts_outlier_detector import CountsOutlierDetector<br/><br/>iris = load_iris()<br/>X, y = iris.data, iris.target<br/>det = CountsOutlierDetector()<br/>results = det.fit_predict(X)</span></pre><p id="82e6" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">The results include a score for each row in the passed dataset, as well as information about why the rows where flagged, and summary statistics about the dataset’s outliers as a whole.</p><p id="8ffa" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">A number of sample notebooks are provided on the github page to help get you started, as well as help tuning the hyperparameters (as with almost all outlier detectors, the hyperparameters can affect what is flagged). But, generally using COD can be as simple as this example.</p><p id="8686" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">The notebooks provided on github also investigate its performance in more depth and cover some experiments to determine how many features typically need to be examined at once to find the relevant outliers in a dataset. As indicated, often limiting analysis to 2 or 3 dimensional histograms can be sufficient to identify the most relevant outliers in a dataset. Tests were performed using a large number of datasets from OpenML.</p><h1 id="a606" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Visual Explanations</h1><p id="7f82" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">COD provides a number of methods to help understand the outliers found. The first is the explain_row() API, where users can get a breakdown of the rational behind the score given for the specified row.</p><p id="eb54" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">As indicated, an outlier row many have any number of anomalies. For any one-dimension anomalies found, bar plots or histograms are presented putting the value in context of the other values in the column. For further context, other values flagged as anomalous are also shown.</p><p id="b868" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">The following image shows an outlier from the Examples_Counts_Outlier_Detector notebook on the github page (which used simple, synthetic data). This in an outlier in Row 1, having an unusual value in Column A. The left pane shows the distribution of Column A, with green vertical lines indicating the bin edges and the red vertical lines the flagged outliers. This example uses 7 bins (so divides numeric features into: ‘Very Low’, ‘Low’, ‘Med-Low’, ‘Med’, ‘Med-High’, ‘High’, ‘Very High').</p><p id="1a5f" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">The right pane shows the histogram. As 5 bins are empty (all values in this column are either ‘Very Low’ or ‘Very High’), only 2 bins are shown here. The plot indicates the rarity of ‘Very High’ values in this feature, which are substantially less common that ‘Very Low’ values and consequently considered outliers.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="pg ph ed pi bh pj"><div class="ol om pf"><img src="../Images/35727e511689d65786367ae3f815918c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e8mpLdSKDuNXf0OZGIXBWg.png"/></div></div></figure><p id="b22f" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">For any two-dimensional anomalies found, a scatter plot (in the case of two numeric columns), strip plot (in the case on one numeric and one categorical column), or heatmap (in the case of two categorical columns) will be presented. This shows clearly how the value compares to other values in the 2d space.</p><p id="54e9" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Shown here is an example (from the demo_OpenML notebook on the github site) with two numeric features. As well as the scatterplot (left pane), a heatmap (right pane) is shown to display the counts of each bin:</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="pg ph ed pi bh pj"><div class="ol om pk"><img src="../Images/22f7144345eae402c08113f33a1b5ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8JtVZ97DyLNkok0j.jpg"/></div></div></figure><p id="ba8a" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">This uses the abalone dataset from OpenML (<a class="af ni" href="https://www.openml.org/search?type=data&amp;sort=runs&amp;id=183&amp;status=active" rel="noopener ugc nofollow" target="_blank">https://www.openml.org/search?type=data&amp;sort=runs&amp;id=183&amp;status=active</a>, licenced under CC BY 4.0). The row being explained (Row 2407) is shown as a star in both plots. In this example, 3 bins per feature were used, so the 2d space has 9 bins. The row being explained is in a bin with only 36 records. The most populated bin, for comparison, has 2212.</p><p id="3154" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">In the scatterplot (the left pane), other records in this bin are shown in red. Records in other bins with unusually low counts are shown in yellow.</p><p id="2030" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Understanding 1d and 2d outliers is straightforward as the visualizations possible are quite comprehensible. Working with 3d and higher dimensions is conceptually similar, though it is more difficult to visualize. It is still quite manageable where the number of dimensions is reasonably low, but is not as straightforward as 1 or 2 dimensions.</p><p id="b028" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">For outliers beyond 2d, bar plots are presented, giving the counts of each combination of values within the current space (combination of features), giving the count for the flagged combination of values / bins in context.</p><p id="a9cc" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">The following is part of an explanation of an outlier row identified in the Abalone dataset, in this case containing a 3d outlier based on the Sex, Diameter, and Whole_weight features.</p><figure class="oo op oq or os ot ol om paragraph-image"><div class="ol om pl"><img src="../Images/05652be88ec21556f97b9eadb40ef997.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*PZE3Vdhhgm1KY7mWNfvtxQ.png"/></div></figure><p id="e58b" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">The explain_features() API may also be called to drill down further into any of these. In this case, it provides the counts of each combination and we can see the combination in the plot above (Sex=I, Diameter=Med; Whole_weight=Med) has a count of only 12:</p><figure class="oo op oq or os ot ol om paragraph-image"><div class="ol om pm"><img src="../Images/4101f4b8dac573245c2e0f597868ac1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*-WWqO_xiUr4FpPGPXDI-2A.png"/></div></figure><p id="5387" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">For the highest level of interpretability, I’d recommend limiting max_dimensions to 2, which will examine the dataset only for 1d and 2d outliers, presenting the results as one-dimensional bar plots or histograms, or two-dimensional plots, which allow the the most complete understanding of the space presented. However, using 3 or more dimensions (as with the plot for Sex, Diameter, and Whole_weight above) is still reasonably interpretable.</p><h1 id="99f7" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Accuracy Experiments</h1><p id="d141" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">Although the strength of COD is its interpretability, it’s still important that the algorithm identifies most meaningful outliers and does not erroneously flag more typical records.</p><p id="40ff" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Experiments (described on the github page) demonstrate that Counts Outlier Detector is competitive with Isolation Forest, at least as measured with respect to a form of testing called <em class="nj">doping</em>: where a small number of values within real datasets are modified (randomly, but so as to usually create anomalous records — records that do not have the normal associations between the features) and testing if outlier detectors are able to identify the modified rows.</p><p id="d9b5" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">There are other valid ways to evaluate outlier detectors, and even using the doping process, it can vary how the data is modified, how many records are doped, and so on. In these tests, COD slightly outperformed Isolation Forest, but in other tests Isolation Forest may do better than COD, and other detectors may as well. Nevertheless, this does demonstrate that COD performs well and is competitive, in terms of accuracy, with standard outlier detectors.</p><h1 id="5cc9" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Installation</h1><p id="dcc0" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">This tool uses a single class, CountsOutlierDetector, which needs to be included in any projects using this. This can be done simply by copying or downloading the single .py file that defines it, <a class="af ni" href="https://github.com/Brett-Kennedy/CountsOutlierDetector/blob/main/counts_outlier_detector.py" rel="noopener ugc nofollow" target="_blank">counts_outlier_detector.py</a> and importing the class.</p><h1 id="ce3d" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Conclusions</h1><p id="665c" class="pw-post-body-paragraph mm mn fq mo b go og mq mr gr oh mt mu mv oi mx my mz oj nb nc nd ok nf ng nh fj bk">This detector has the advantages of:</p><ol class=""><li id="bba1" class="mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh pn po pp bk">It is able to provide explanations of each outlier as clearly as possible. To explain why a row is scored as it is, an explanation is given using only as many features as necessary to explain its score.</li><li id="134d" class="mm mn fq mo b go pq mq mr gr pr mt mu mv ps mx my mz pt nb nc nd pu nf ng nh pn po pp bk">It is able to provide full statistics about each space, which allows it to provide full context of the outlierness of each row.</li></ol><p id="2c11" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">It’s generally agreed in outlier detection that each detector will identify certain types of outliers and that it’s usually beneficial to use multiple detectors to reliably catch most of the outliers in a dataset. COD may be useful simply for this purpose: it’s a straightforward, useful outlier detector that may detect outliers somewhat different from other detectors.</p><p id="6835" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">However, interpretability is often very important with outlier detection, and there are, unfortunately, few options available now for interpretable outlier detection. COD provides one of the few, and may be worth trying for this reason.</p><p id="60e9" class="pw-post-body-paragraph mm mn fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">All images are created by the author.</p></div></div></div></div>    
</body>
</html>