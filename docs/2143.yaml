- en: 5 Pillars for a Hyper-Optimized AI Workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/5-pillars-for-a-hyper-optimized-ai-workflow-21fcaefe48ca?source=collection_archive---------3-----------------------#2024-09-03](https://towardsdatascience.com/5-pillars-for-a-hyper-optimized-ai-workflow-21fcaefe48ca?source=collection_archive---------3-----------------------#2024-09-03)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An introduction to a methodology for creating production-ready, extensible &
    highly optimized AI workflows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@giladrubin?source=post_page---byline--21fcaefe48ca--------------------------------)[![Gilad
    Rubin](../Images/e98728582365c22c2803d5db0a0f3ca6.png)](https://medium.com/@giladrubin?source=post_page---byline--21fcaefe48ca--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--21fcaefe48ca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--21fcaefe48ca--------------------------------)
    [Gilad Rubin](https://medium.com/@giladrubin?source=post_page---byline--21fcaefe48ca--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--21fcaefe48ca--------------------------------)
    ·7 min read·Sep 3, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c2981f3bf6f6dd818737a86793759b75.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Credit: Google Gemini, prompt by the Author*'
  prefs: []
  type: TYPE_NORMAL
- en: Intro
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the last decade, I carried with me a deep question in the back of my mind
    in every project I’ve worked on:'
  prefs: []
  type: TYPE_NORMAL
- en: '**How** (the hell) **am I supposed to structure and develop my AI & ML projects?**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I wanted to know — is there an elegant way to build **production-ready** code
    in an iterative way? A codebase that is **extensible, optimized, maintainable
    & reproducible**?
  prefs: []
  type: TYPE_NORMAL
- en: And if so — where does this secret lie? Who owns the knowledge to this dark
    art?
  prefs: []
  type: TYPE_NORMAL
- en: I searched intensively for an answer over the course of many years — reading
    articles, watching tutorials and trying out different methodologies and frameworks.
    But I couldn’t find a satisfying answer. Every time I thought I was getting close
    to a solution, something was still missing.
  prefs: []
  type: TYPE_NORMAL
- en: After about 10 years of trial and error, with a focused effort in the last two
    years, I think I’ve finally found a satisfying answer to my long-standing quest.
    This post is the beginning of my journey of sharing what I’ve found.
  prefs: []
  type: TYPE_NORMAL
- en: My research has led me to identify **5 key pillars** that form the foundation
    of what I call a **hyper-optimized AI workflow**. In the post I will shortly introduce
    each of them — giving you an overview of what’s to come.
  prefs: []
  type: TYPE_NORMAL
- en: 'I want to emphasize that each of the pillars that I will present is grounded
    in practical methods and tools, which I’ll elaborate on in future posts. If you’re
    already curious to see them in action, feel free to check out this video from
    Hamilton’s meetup where I present them live:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Throughout this post and series, I’ll use the terms Artificial Intelligence
    (AI), Machine Learning (ML), and Data Science (DS) interchangeably. The concepts
    we’ll discuss apply equally to all these fields.*'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s explore each pillar.
  prefs: []
  type: TYPE_NORMAL
- en: 1 — Metric-Based Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In every AI project there is a certain goal we want to achieve, and ideally
    — a set of metrics we want to optimize.
  prefs: []
  type: TYPE_NORMAL
- en: 'These metrics can include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Predictive quality metrics**: Accuracy, F1-Score, Recall, Precision, etc…'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost metrics**: Actual $ amount, FLOPS, Size in MB, etc…'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance metrics**: Training speed, inference speed, etc…'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can choose one metric as our “north star” or create an aggregate metric.
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: 0.7 × F1-Score + 0.3 × (1 / Inference Time in ms)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0.6 × AUC-ROC + 0.2 × (1 / Training Time in hours) + 0.2 × (1 / Cloud Compute
    Cost in $)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*There’s a* [*wonderful short video*](https://www.youtube.com/watch?v=sofffBNhVSo)
    *by Andrew Ng. where here explains about the topic of a* ***Single Number Evaluation
    Metric****.*'
  prefs: []
  type: TYPE_NORMAL
- en: Once we have an agreed-upon metric to optimize and a set of constraints to meet,
    **our goal is to build a workflow that maximizes this metric while satisfying
    our constraints.**
  prefs: []
  type: TYPE_NORMAL
- en: 2 — Interactive Developer Experience
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the world of Data Science and AI development — interactivity is key.
  prefs: []
  type: TYPE_NORMAL
- en: As AI Engineers (or whatever title we Data Scientists go by these days), we
    need to build code that works bug-free across different scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike traditional software engineering, our role extends beyond writing code
    that “just” works. A significant aspect of our work involves examining the data
    and inspecting our models’ outputs and the results of various processing steps.
  prefs: []
  type: TYPE_NORMAL
- en: The most common environment for this kind of interactive exploration is Jupyter
    Notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: Working within a notebook allows us to **test different implementations, experiment
    with new APIs and inspect the intermediate results of our workflows and make decisions
    based on our observations.** This is the core of the second pillar.
  prefs: []
  type: TYPE_NORMAL
- en: However, As much as we enjoy these benefits in our day-to-day work, notebooks
    can sometimes contain notoriously bad code that can only be executed in a non-trivial
    order.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, some exploratory parts of the notebook might not be relevant for
    production settings, making it unclear how these can effectively be shipped to
    production.
  prefs: []
  type: TYPE_NORMAL
- en: 3 — Production-Ready Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “Production-Ready” can mean different things in different contexts. For one
    organization, it might mean serving results within a specified time frame. For
    another, it could refer to the service’s uptime (SLA). And yet for another, it
    might mean the code, model, or workflow has undergone sufficient testing to ensure
    reliability.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are all important aspects of shipping reliable products, and the specific
    requirements may vary from place to place. Since my exploration is focused on
    the “meta” aspect of building AI workflows, I want to discuss a common denominator
    across these definitions: **wrapping our workflow as a serviceable API and deploying
    it to an environment where it can be queried by external applications or users.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This means we need to have a way to abstract the complexity of our codebase
    into a clearly defined interface that can be used across various use-cases. Let’s
    consider an example:'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a complex RAG (Retrieval-Augmented Generation) system over PDF files
    that we’ve developed. It may contain 10 different parts, each consisting of hundreds
    of lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we can still wrap them into a simple API with just two main functions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'upload_document(file: PDF) -> document_id: str'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'query_document(document_id: str, query: str, output_format: str) -> response:
    str'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This abstraction allows users to:'
  prefs: []
  type: TYPE_NORMAL
- en: Upload a PDF document and receive a unique identifier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ask questions about the document using natural language.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specify the desired format for the response (e.g., markdown, JSON, Pandas Dataframe).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By providing this clean interface, we’ve effectively hidden the complexities
    and implementation details of our workflow.
  prefs: []
  type: TYPE_NORMAL
- en: '**Having a systematic way to convert arbitrarily complex workflows into deployable
    APIs is our third pillar.**'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we would ideally want to establish a methodology that ensures that
    our **iterative, daily work stays in sync with our production code**.
  prefs: []
  type: TYPE_NORMAL
- en: This means if we make a change to our workflow — fixing a bug, adding a new
    implementation, or even tweaking a configuration — we should be able to deploy
    these changes to our production environment with just a click of a button.
  prefs: []
  type: TYPE_NORMAL
- en: 4 — Modular & Extensible Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another crucial aspect of our methodology is maintaining a **Modular & Extensible**
    codebase.
  prefs: []
  type: TYPE_NORMAL
- en: This means that we can **add new implementations and test them against existing
    ones** that occupy the same logical step without modifying our existing code or
    overwriting other configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach aligns with the [**open-closed principle**](https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle),
    where our code is open for extension but closed for modification. It allows us
    to:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduce new implementations alongside existing ones
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Easily compare the performance of different approaches
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Maintain the integrity of our current working solutions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extend our workflow’s capabilities without risking the stability of the whole
    system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s look at a toy example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/76759faaabe47220288d951e11385ba8.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/56292fd73a23bbfc6d6dd636de73b554.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we can see a (pseudo) code that is modular and configurable.
    In this way, we can easily add new configurations and test their performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/04c39fc215cbe886f28c8bba50baf51e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: Once our code consists of multiple competing implementations & configurations,
    we enter a state that I like to call a **“superposition of workflows”**. In this
    state we can instantiate and execute a workflow using a specific set of configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 5 — Hierarchical & Visual Structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if we take modularity and extensibility a step further? What if we apply
    this approach to entire sections of our workflow?
  prefs: []
  type: TYPE_NORMAL
- en: So now, instead of configuring **this** LLM or **that** retriever, we can configure
    our whole preprocessing, training, or evaluation steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5425e8ced3cd5f570509c5f16dc98b29.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we see our entire ML workflow. Now, let’s add a new Data Prep implementation
    and zoom into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3fb1f2958404c2d54145cd6abd7dc377.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: When we work in this hierarchical and visual way, we can select a section of
    our workflow to improve and add a new implementation with the same input/output
    interface as the existing one.
  prefs: []
  type: TYPE_NORMAL
- en: We can then “zoom in” to that specific section, focusing solely on it without
    worrying about the rest of the project. Once we’re satisfied with our implementation
    — we can start testing it out alongside other various configurations in our workflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach unlocks several benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reduced mental overload**: Focus on one section at a time, providing clarity
    and reducing complexity in decision-making.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Easier collaboration**: A modular structure simplifies task delegation to
    teammates or AI assistants, with clear interfaces for each component.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reusability:** These encapsulated implementations can be utilized in different
    projects, potentially without modification to their source code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Self-documentation**: Visualizing entire workflows and their components makes
    it easier to understand the project’s structure and logic without diving into
    unnecessary details.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'These are the 5 pillars that I’ve found to hold the foundation to a **“hyper-optimized
    AI workflow”**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Metric-Based Optimization**: Define and optimize clear, project-specific
    metrics to guide decision-making and workflow improvements.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Interactive Developer Experience**: Utilize tools for iterative coding &
    data inspection like Jupyter Notebooks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Production-Ready Code**: Wrap complete workflows into deployable APIs and
    sync development and production code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Modular & Extensible Code**: Structure code to easily add, swap, and test
    different implementations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hierarchical & Visual Structures**: Organize projects into visual, hierarchical
    components that can be independently developed and easily understood at various
    levels of abstraction.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the upcoming blog posts, I’ll dive deeper into each of these pillars, providing
    more detailed insights, practical examples, and tools to help you implement these
    concepts in your own AI projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, I intend to introduce the methodology and tools I’ve built on
    top of [DAGWorks Inc](https://open.substack.com/users/141841981-dagworks-inc?utm_source=mentions)*
    Hamilton framework and my own packages: [Hypster](https://github.com/gilad-rubin/hypster)
    and [HyperNodes](https://github.com/gilad-rubin/hypernodes) (still in its early
    days).'
  prefs: []
  type: TYPE_NORMAL
- en: Stay tuned for more!
  prefs: []
  type: TYPE_NORMAL
- en: '*I am not affiliated with or employed by DAGWorks Inc.'
  prefs: []
  type: TYPE_NORMAL
