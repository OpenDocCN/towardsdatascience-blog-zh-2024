<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Duplicate Detection with GenAI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Duplicate Detection with GenAI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/duplicate-detection-with-genai-ba2b4f7845e7?source=collection_archive---------1-----------------------#2024-07-01">https://towardsdatascience.com/duplicate-detection-with-genai-ba2b4f7845e7?source=collection_archive---------1-----------------------#2024-07-01</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="cbbc" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How using LLMs and GenAI techniques can improve de-duplication</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@ianormy?source=post_page---byline--ba2b4f7845e7--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ian Ormesher" class="l ep by dd de cx" src="../Images/a5b25ae4b6242d91b9752bf9719bcb0a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/2*SR5X4bF4sxSh9EjoygqzMw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--ba2b4f7845e7--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@ianormy?source=post_page---byline--ba2b4f7845e7--------------------------------" rel="noopener follow">Ian Ormesher</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--ba2b4f7845e7--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">5 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 1, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/6d3ebdec98b1edebbfc275bcd00775e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kwJ4XkiU_feW5U50h6PS0g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">2D UMAP Musicbrainz 200K nearest neighbour plot</figcaption></figure><p id="9500" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Customer data is often stored as records in Customer Relations Management systems (CRMs). Data which is manually entered into such systems by one of more users over time leads to data replication, partial duplication or fuzzy duplication. This in turn means that there no longer a single source of truth for customers, contacts, accounts, etc. Downstream business processes become increasing complex and contrived without a unique mapping between a record in a CRM and the target customer. Current methods to detect and de-duplicate records use traditional Natural Language Processing techniques known as Entity Matching. But it is possible to use the latest advancements in Large Language Models and Generative AI to vastly improve the identification and repair of duplicated records. On common benchmark datasets I found an improvement in the accuracy of data de-duplication rates from 30 percent using NLP techniques to almost 60 percent using my proposed method.</p><p id="a4db" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">I want to explain the technique here in the hope that others will find it helpful and use it for their own de-duplication needs. It’s useful for other scenarios where you wish to identify duplicate records, not just for Customer data. I also wrote and published a research paper about this which you can view on Arxiv, if you want to know more in depth:</p><div class="ny nz oa ob oc od"><a href="https://arxiv.org/abs/2406.15483?source=post_page-----ba2b4f7845e7--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab ig"><div class="of ab co cb og oh"><h2 class="bf fr hw z io oi iq ir oj it iv fp bk">Duplicate Detection with GenAI</h2><div class="ok l"><h3 class="bf b hw z io oi iq ir oj it iv dx">Customer data is often stored as records in Customer Relations Management systems (CRMs). Data which is manually…</h3></div><div class="ol l"><p class="bf b dy z io oi iq ir oj it iv dx">arxiv.org</p></div></div><div class="om l"><div class="on l oo op oq om or lr od"/></div></div></a></div><h1 id="8778" class="os ot fq bf ou ov ow gq ox oy oz gt pa pb pc pd pe pf pg ph pi pj pk pl pm pn bk">Traditional Approach</h1><p id="8332" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">The task of identifying duplicate records is often done by pairwise record comparisons and is referred to as “Entity Matching” (EM). Typical steps of this process would be:</p><ul class=""><li id="f3f8" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">Data Preparation</li><li id="d288" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Candidate Generation</li><li id="caee" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Blocking</li><li id="2bcd" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Matching</li><li id="db77" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Clustering</li></ul><h2 id="d8c1" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Data Preparation</h2><p id="904b" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">Data preparation is the cleaning of the data and involves such things as removing non-ASCII characters, capitalisation and tokenising the text. This is an important and necessary step for the NLP matching algorithms later in the process which don’t work well with different cases or non-ASCII characters.</p><h2 id="eb8b" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Candidate Generation</h2><p id="69b4" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">In the usual EM method, we would produce candidate records by combining all the records in the table with themselves to produce a cartesian product. You would remove all combinations which are of a row with itself. For a lot of the NLP matching algorithms comparing row A with row B is equivalent to comparing row B with row A. For those cases you can get away with keeping just one of those pairs. But even after this, you’re still left with a lot of candidate records. In order to reduce this number a technique called “blocking” is often used.</p><h2 id="d556" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Blocking</h2><p id="7b49" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">The idea of blocking is to eliminate those records that we know could not be duplicates of each other because they have different values for the “blocked” column. As an example, If we were considering customer records, a potential column to block on could be something like “City”. This is because we know that even if all the other details of the record are similar enough, they cannot be the same customer if they’re located in different cities. Once we have generated our candidate records, we then use blocking to eliminate those records that have different values for the blocked column.</p><h2 id="4569" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Matching</h2><p id="9bfb" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">Following on from blocking we now examine all the candidate records and calculate traditional NLP similarity-based attribute value metrics with the fields from the two rows. Using these metrics, we can determine if we have a potential match or un-match.</p><h2 id="00da" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Clustering</h2><p id="e018" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">Now that we have a list of candidate records that match, we can then group them into clusters.</p><h1 id="db85" class="os ot fq bf ou ov ow gq ox oy oz gt pa pb pc pd pe pf pg ph pi pj pk pl pm pn bk">Proposed Method</h1><p id="5364" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">There are several steps to the proposed method, but the most important thing to note is that we no longer need to perform the “Data Preparation” or “Candidate Generation” step of the traditional methods. The new steps become:</p><ul class=""><li id="c800" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">Create Match Sentences</li><li id="9b6e" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Create Embedding Vectors of those Match Sentences</li><li id="75e5" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Clustering</li></ul><h2 id="dc70" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Create Match Sentences</h2><p id="1869" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">First a “Match Sentence” is created by concatenating the attributes we are interested in and separating them with spaces. As an example, let’s say we have a customer record which looks like this:</p><figure class="mm mn mo mp mq mr"><div class="qs io l ed"><div class="qt qu l"/></div></figure><p id="9687" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We would create a “Match Sentence” by concatenating with spaces the name1, name2, name3, address and city attributes which would give us the following:</p><blockquote class="qv qw qx"><p id="6534" class="nc nd qy ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">“John Hartley Smith 20 Main Street London”</p></blockquote><h2 id="df87" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Create Embedding Vectors</h2><p id="b5c2" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">Once our “Match Sentence” has been created it is then encoded into vector space using our chosen embedding model. This is achieved by using “<a class="af qz" href="https://huggingface.co/sentence-transformers/" rel="noopener ugc nofollow" target="_blank">Sentence Transformers</a>”. The output of this encoding will be a floating-point vector of pre-defined dimensions. These dimensions relate to the embedding model that is used. I used the <a class="af qz" href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2/" rel="noopener ugc nofollow" target="_blank">all-mpnet-base-v2 </a>embedding model which has a vector space of 768 dimensions. This embedding vector is then appended to the record. This is done for all the records.</p><h2 id="bb44" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Clustering</h2><p id="590a" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">Once embedding vectors have been calculated for all the records, the next step is to create clusters of similar records. To do this I use the DBSCAN technique. DBSCAN works by first selecting a random record and finding records that are close to it using a distance metric. There are 2 different kinds of distance metrics that I’ve found to work:</p><ul class=""><li id="ab36" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">L2 Norm distance</li><li id="4c38" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Cosine Similarity</li></ul><p id="5727" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For each of those metrics you choose an epsilon value as a threshold value. All records that are within the epsilon distance and have the same value for the “blocked” column are then added to this cluster. Once that cluster is complete another random record is selected from the unvisited records and a cluster then created around it. This then continues until all the records have been visited.</p><h1 id="91a9" class="os ot fq bf ou ov ow gq ox oy oz gt pa pb pc pd pe pf pg ph pi pj pk pl pm pn bk">Experiments and Results</h1><p id="479c" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">I used this approach to identify duplicate records with customer data in my work. It produced some very nice matches. In order to be more objective, I also ran some experiments using a benchmark dataset called “Musicbrainz 200K”. It produced some quantifiable results that were an improvement over standard NLP techniques.</p><h2 id="63c7" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Visualising Clustering</h2><p id="814c" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">I produced a nearest neighbour cluster map for the Musicbrainz 200K dataset which I then rendered in 2D using the UMAP reduction algorithm:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/6d3ebdec98b1edebbfc275bcd00775e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kwJ4XkiU_feW5U50h6PS0g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">2D UMAP Musicbrainz 200K nearest neighbour plot</figcaption></figure><h2 id="70b9" class="qb ot fq bf ou qc qd qe ox qf qg qh pa nl qi qj qk np ql qm qn nt qo qp qq qr bk">Resources</h2><p id="c043" class="pw-post-body-paragraph nc nd fq ne b go po ng nh gr pp nj nk nl pq nn no np pr nr ns nt ps nv nw nx fj bk">I have created various notebooks that will help with trying the method out for yourselves:</p><div class="ny nz oa ob oc od"><a href="https://github.com/ianormy/genai_duplicate_detection_paper?source=post_page-----ba2b4f7845e7--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab ig"><div class="of ab co cb og oh"><h2 class="bf fr hw z io oi iq ir oj it iv fp bk">GitHub - ianormy/genai_duplicate_detection_paper: Resources and notebooks to accompany the…</h2><div class="ok l"><h3 class="bf b hw z io oi iq ir oj it iv dx">Resources and notebooks to accompany the Duplicate Detection using GenAI paper …</h3></div><div class="ol l"><p class="bf b dy z io oi iq ir oj it iv dx">github.com</p></div></div><div class="om l"><div class="ra l oo op oq om or lr od"/></div></div></a></div></div></div></div><div class="ab cb rb rc rd re" role="separator"><span class="rf by bm rg rh ri"/><span class="rf by bm rg rh ri"/><span class="rf by bm rg rh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><ol class=""><li id="eb72" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx rj pu pv bk">Duplicate Detection with GenAI paper: <a class="af qz" href="https://arxiv.org/abs/2406.15483" rel="noopener ugc nofollow" target="_blank">[2406.15483] Duplicate Detection with GenAI</a></li><li id="b042" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx rj pu pv bk">GitHub resources: <a class="af qz" href="https://github.com/ianormy/genai_duplicate_detection_paper" rel="noopener ugc nofollow" target="_blank">https://github.com/ianormy/genai_duplicate_detection_paper</a></li><li id="c96a" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx rj pu pv bk">all-mpnet-base-v2 embedding model: <a class="af qz" href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2/" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/sentence-transformers/all-mpnet-base-v2/</a></li><li id="2239" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx rj pu pv bk">Sentence Transformers: <a class="af qz" href="https://huggingface.co/sentence-transformers/" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/sentence-transformers/</a></li><li id="22f4" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx rj pu pv bk">UMAP python package: <a class="af qz" href="https://pypi.org/project/umap-learn/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/umap-learn/</a></li><li id="a88a" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx rj pu pv bk">Benchmark datasets for entity resolution: <a class="af qz" href="https://dbs.uni-leipzig.de/research/projects/benchmark-datasets-for-entity-resolution/" rel="noopener ugc nofollow" target="_blank">https://dbs.uni-leipzig.de/research/projects/benchmark-datasets-for-entity-resolution/</a></li><li id="0629" class="nc nd fq ne b go pw ng nh gr px nj nk nl py nn no np pz nr ns nt qa nv nw nx rj pu pv bk">Musicbrainz 200K dataset: <a class="af qz" href="https://dbs.uni-leipzig.de/files/datasets/saeedi/musicbrainz-200-A01.csv.dapo" rel="noopener ugc nofollow" target="_blank">https://dbs.uni-leipzig.de/files/datasets/saeedi/musicbrainz-200-A01.csv.dapo</a></li></ol></div></div></div></div>    
</body>
</html>