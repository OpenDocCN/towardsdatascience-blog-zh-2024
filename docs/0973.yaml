- en: Advanced Retriever Techniques to Improve Your RAGs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升你的RAG的高级检索技术
- en: 原文：[https://towardsdatascience.com/advanced-retriever-techniques-to-improve-your-rags-1fac2b86dd61?source=collection_archive---------0-----------------------#2024-04-17](https://towardsdatascience.com/advanced-retriever-techniques-to-improve-your-rags-1fac2b86dd61?source=collection_archive---------0-----------------------#2024-04-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/advanced-retriever-techniques-to-improve-your-rags-1fac2b86dd61?source=collection_archive---------0-----------------------#2024-04-17](https://towardsdatascience.com/advanced-retriever-techniques-to-improve-your-rags-1fac2b86dd61?source=collection_archive---------0-----------------------#2024-04-17)
- en: 'Master Advanced Information Retrieval: Cutting-edge Techniques to Optimize
    the Selection of Relevant Documents with **Langchain** to Create Excellent RAGs'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精通高级信息检索：利用**Langchain**优化相关文档选择的前沿技术，打造卓越的RAG
- en: '[](https://medium.com/@damiangilgonzalez?source=post_page---byline--1fac2b86dd61--------------------------------)[![Damian
    Gil](../Images/8b378c321ee21b0bd40faa14db7e9487.png)](https://medium.com/@damiangilgonzalez?source=post_page---byline--1fac2b86dd61--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1fac2b86dd61--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1fac2b86dd61--------------------------------)
    [Damian Gil](https://medium.com/@damiangilgonzalez?source=post_page---byline--1fac2b86dd61--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@damiangilgonzalez?source=post_page---byline--1fac2b86dd61--------------------------------)[![Damian
    Gil](../Images/8b378c321ee21b0bd40faa14db7e9487.png)](https://medium.com/@damiangilgonzalez?source=post_page---byline--1fac2b86dd61--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1fac2b86dd61--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1fac2b86dd61--------------------------------)
    [Damian Gil](https://medium.com/@damiangilgonzalez?source=post_page---byline--1fac2b86dd61--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1fac2b86dd61--------------------------------)
    ·18 min read·Apr 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1fac2b86dd61--------------------------------)
    ·18分钟阅读·2024年4月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Content Table
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: '**·** [**Introduction**](#a896) **·** [**Vectore Store Creation**](#d7a4) **·**
    [**Method: Naive Retriever**](#10a9) **·** [**Method: Parent Document Retriever**](#1f6d)
    **·** [**Method: Self Query Retriever**](#b2c7)∘ [Query Constructor](#a483)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**引言**](#a896) **·** [**向量存储创建**](#d7a4) **·** [**方法：朴素检索器**](#10a9)
    **·** [**方法：父文档检索器**](#1f6d) **·** [**方法：自查询检索器**](#b2c7)∘ [查询构造器](#a483)'
- en: '∘ [Query Translater](#21ad) **·** [**Method: Contextual Compression Retriever
    (Reranking)**](#8232) **·** [**Conclusion**](#3c63)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [查询翻译器](#21ad) **·** [**方法：上下文压缩检索器（重排名）**](#8232) **·** [**结论**](#3c63)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: '***Let’s briefly remember what the 3 acronyms that make up the word RAG mean:***'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '***让我们简要回顾一下构成RAG这个词的三个缩写的含义：***'
- en: '**Retrieval**: The main objective of a RAG is to collect the most relevant
    documents/chunks regarding the query.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索**：RAG的主要目标是收集与查询相关的最相关文档/片段。'
- en: '**Augmented**: Create a well-structured prompt so that when the call is made
    to the LLM, it knows perfectly what its purpose is, what the context is and how
    it should respond.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强**：创建一个结构良好的提示，这样当调用LLM时，它能完全理解自己的目的、上下文以及应如何回应。'
- en: '**Generation**: This is where the LLM comes into play. When the model is given
    good context (provided by the “Retrieval” step) and has clear instructions (provided
    by the “Augmented” step), it will generate high-value responses for the user.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成**：这是大语言模型（LLM）发挥作用的地方。当模型提供了良好的上下文（由“检索”步骤提供）并且有清晰的指令（由“增强”步骤提供）时，它将为用户生成高价值的响应。'
- en: As we can see, the generation of the response to a user’s query (If we apply
    a RAG for the purpose of Q&A), depends directly on how well we have built the
    “*Augmented*” and especially the “*Retrieval*”.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，生成对用户查询的响应（如果我们应用RAG进行问答目的）直接依赖于我们如何构建“*增强*”部分，特别是“*检索*”部分。
- en: '**In this article we are going to focus exclusively on the “*Retrieval*” part**.
    In this important process of returning the most relevant documents, the concept
    of vector store appears.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**在本文中，我们将专注于“*检索*”部分**。在这一重要的返回最相关文档的过程中，向量存储的概念会出现。'
- en: '![](../Images/a581156c21a7c624ecde0048b05ffc5c.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a581156c21a7c624ecde0048b05ffc5c.png)'
- en: Overview of the techniques shown in this article (Image by Author).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本文展示的技术概述（图像来自作者）。
- en: To create these retrievals, we will use the Langchain library.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建这些检索，我们将使用Langchain库。
- en: '![](../Images/3182127071644529aa590a1862f565f2.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3182127071644529aa590a1862f565f2.png)'
- en: Overview of the technologies used in this article (Image by Author).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的技术概览（图片由作者提供）。
- en: The vectore store is nothing more than a vector database, which stores documents
    in vector format. This vector representation comes from the use of transformers.
    I’m not saying something you don’t know at the moment.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储就是一个向量数据库，用于存储以向量格式表示的文档。这种向量表示来自于transformers的使用。我并不是说一些你此刻不知道的事情。
- en: It is clear that the more robust and complete this vector store is, the better
    retriever we can run. We already know that the creation of this database is an
    art in itself. Depending on the size of the chunks or the embedding model we use,
    our RAG will be better or worse.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 很显然，这个向量存储越强大、越完整，我们能运行的检索器就越好。我们已经知道，创建这个数据库本身就是一门艺术。根据我们使用的块大小或嵌入模型，RAG的效果会有所不同。
- en: 'I make a clarification here:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在此我做出一个说明：
- en: In this post we are NOT going to discuss how to create this vector store.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们不会讨论如何创建这个向量存储。
- en: In this post we are going to discuss some of the techniques used to retrieve
    relevant documents.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将讨论一些用于检索相关文档的技术。
- en: 'Since a picture is worth a thousand words, I suggest you take a look at the
    following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 既然一图胜千言，我建议你查看以下内容：
- en: '![](../Images/7a733d4eae52fcc8376c3438a97622fc.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a733d4eae52fcc8376c3438a97622fc.png)'
- en: A RAG encompasses a series of well-defined steps. This post will only cover
    the retriever part (Image by Author).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个RAG包含一系列明确的步骤。本文只会介绍检索器部分（图片由作者提供）。
- en: Therefore, I reiterate that in this post we are going to deeply study one of
    the many important steps in creating a good RAG tool. The “*Retrieve*” step is
    key since it directly improves the context that the LLM has when generating a
    response.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我再次强调，在这篇文章中，我们将深入研究创建一个优秀RAG工具的众多重要步骤之一。 “*检索*”步骤至关重要，因为它直接影响LLM生成响应时的上下文。
- en: 'The methods we will study are:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究的方法是：
- en: '**Naive Retriever**'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朴素检索器**'
- en: '**Parent Document Retriever**'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**父文档检索器**'
- en: '**Self-Query Retriever**'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自查询检索器**'
- en: '**Contextual Compression Retriever (Reranking)**'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文压缩检索器（重新排序）**'
- en: 'You can find the project with the notebooks [**here**](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/tree/main)**.**
    And you can also take a look at my github:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[**这里**](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/tree/main)找到包含笔记本的项目**。**
    你也可以查看我的github：
- en: '[](https://github.com/damiangilgonzalez1995?source=post_page-----1fac2b86dd61--------------------------------)
    [## damiangilgonzalez1995 - Overview'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/damiangilgonzalez1995?source=post_page-----1fac2b86dd61--------------------------------)
    [## damiangilgonzalez1995 - 概览'
- en: Passionate about data, I transitioned from physics to data science. Worked at
    Telefonica, HP, and now CTO at…
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对数据充满热情，我从物理学转向了数据科学。曾在Telefonica、HP工作，现在是…
- en: github.com](https://github.com/damiangilgonzalez1995?source=post_page-----1fac2b86dd61--------------------------------)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/damiangilgonzalez1995?source=post_page-----1fac2b86dd61--------------------------------)
- en: Vectore Store Creation
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量存储创建
- en: To expose these methods, a practical use case will be carried out to improve
    the explanation. Therefore, we are going to create a RAG about reviews of the
    John Wick movies.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地阐释这些方法，将通过一个实际案例进行讲解。因此，我们将创建一个关于《约翰·威克》电影评论的RAG。
- en: So that the reader can follow each step of this post, they can access the repository
    that I have created. In it you will find the code for each of the methods, in
    addition to the documents used to create the vector store. The jupyter notebook
    in charge of this task can be found in the git repository, and is the file called
    “[0_***create_vectore_db.ipynb***](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/0_create_vectore_db.ipynb)”.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让读者能跟随本文的每一个步骤，他们可以访问我创建的仓库。在里面，你会找到每种方法的代码，以及用于创建向量存储的文档。负责此任务的jupyter notebook可以在git仓库中找到，文件名为“[0_***create_vectore_db.ipynb***](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/0_create_vectore_db.ipynb)”。
- en: 'In relation to the data source of our RAG, there are 4 csv’s each corresponding
    to the reviews obtained for each of the films in the John Wick saga. The files
    contain the following information:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们RAG的数据来源，有4个csv文件，每个文件对应约翰·威克系列电影的每部电影的评论。这些文件包含以下信息：
- en: '![](../Images/be5401cfc1f8f45719490ff05aa9528b.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be5401cfc1f8f45719490ff05aa9528b.png)'
- en: Dataset of the project (Image by Author).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 项目的数据集（图片由作者提供）。
- en: 'As you can see, the “**Review**” field will be the target of our retriever.
    The other fields being important to store as metadata:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，“**评论**”字段将是我们检索器的目标。其他字段作为元数据进行存储也很重要：
- en: '**Movie_Title**'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电影标题**'
- en: '**Review_Date**'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评论日期**'
- en: '**Review_Title**'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评论标题**'
- en: '**Review_Url**'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评论网址**'
- en: '**Author**'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**作者**'
- en: '**Rating**'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评分**'
- en: 'To read and convert each row of our files into the “*Document*” format, we
    execute the following code:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 要将我们文件的每一行读取并转换为“*文档*”格式，我们执行以下代码：
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We already have our documents in “*Document*” format:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了“*文档*”格式的文档：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We only have to create a vector database (**Vectore Store**) locally. For this,
    I have used **Chroma**. Also keep in mind that it is necessary to use an embedding
    model, which will transform our documents into vector format for storage. Everything
    mentioned can be seen in the following piece of code:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要在本地创建一个向量数据库（**向量存储**）。为此，我使用了**Chroma**。同时，记住需要使用一个嵌入模型，它将把我们的文档转换为向量格式进行存储。所有这些内容可以在以下代码片段中看到：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This will create a database on our premises called “***JonhWick_db***”. This
    will be the database that our RAG will use and from where our retriever will obtain
    the most relevant documents regarding the user’s queries.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在我们的服务器上创建一个名为“***JonhWick_db***”的数据库。这个数据库将被我们的RAG使用，检索器将从中获取与用户查询最相关的文档。
- en: Now is the time to present the different methods for creating a retriever.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候介绍创建检索器的不同方法了。
- en: '**Method: Naive Retriever**'
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**方法：朴素检索器**'
- en: Code in [1_naive_retriever.ipynb](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/1_naive_retriever.ipynb)
    file.
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 代码见[1_naive_retriever.ipynb](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/1_naive_retriever.ipynb)文件。
- en: This method is the simplest, in fact its name indicates it. We use this adjective
    to identify this method for the simple reason that when entering the query into
    our database, we hope (naively) that it will return the most relevant documents/chunks.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法是最简单的，实际上它的名字就说明了这一点。我们使用这个形容词来标识这种方法，原因很简单，当我们将查询输入到数据库时，我们（天真地）希望它返回最相关的文档/片段。
- en: Basically what happens is that we encode the user query with the same transformer
    with which we created the vector store. Once its vector representation is obtained,
    we calculate the similarity by calculating the cosine, the distance, etc.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上发生的情况是，我们使用与创建向量存储时相同的转换器对用户查询进行编码。一旦获得其向量表示后，我们通过计算余弦相似度、距离等来计算相似性。
- en: And we collect the top K documents closest/similar to the query.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们收集与查询最相似的前K个文档。
- en: 'The flow of this type of retriever can be seen in the following image:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的检索器流程可以在下图中看到：
- en: '![](../Images/fdf9e144f28b71307dd78345689f6d41.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdf9e144f28b71307dd78345689f6d41.png)'
- en: Simplified representation of a **Naive retriever** (Image by Author).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**朴素检索器**的简化表示（图像由作者提供）。'
- en: 'Keeping the scheme in mind, let’s see how all this looks in the code. We read
    the database:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这个方案，我们来看看所有这些在代码中的表现。我们读取数据库：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And we create our ***retriever***. We can configure the similarity calculation
    method, in addition to other parameters.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建我们的***检索器***。我们可以配置相似性计算方法以及其他参数。
- en: '**Retriever**'
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**检索器**'
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Actually, we have already created our “***Naive Retriever***”, but to see how
    it works, we will create the complete RAG that we remember is composed of the
    following components:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们已经创建了我们的“***朴素检索器***”，但为了看看它是如何工作的，我们将创建完整的RAG，回顾一下它由以下组件组成：
- en: '*R (Retrieval)*: **Done**'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*R（检索）*: **已完成**'
- en: '*A (Augmented)*: **Not yet**'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A（增强）*: **尚未完成**'
- en: '*G (Generation)*: **Not yet**'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*G（生成）*: **尚未完成**'
- en: '**Augmented & Generation**'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**增强与生成**'
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We already have the 3 components of our RAG. All that remains is to assemble
    them, and for this we will use the langchain chains to create a RAG.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经拥有了RAG的三个组件。剩下的就是将它们组装起来，为此我们将使用Langchain的链来创建RAG。
- en: 'I don’t know if you know the language created by langchain for creating chains
    in a more efficient way. This language is known as **LCEL (LangChain Expression
    Language).** If you are new to this way of creating chains in langchain, I leave
    you a very good tutorial here:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道你是否了解Langchain为更高效地创建链而设计的语言。这种语言被称为**LCEL（LangChain表达语言）**。如果你对这种创建Langchain链的方式不熟悉，我在这里为你提供一个非常好的教程：
- en: 'Finally, we create our RAG using Langchain’s own chain creation language (***LCEL***):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用Langchain自有的链创建语言（***LCEL***）来创建我们的RAG：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This is the simplest way to create a chain for a RAG. In the Jupyter notebook
    you can find the same chain but more robust. Since I don’t want us to get lost
    on this topic now, I have only shown the simplest form. Also so that we understand
    what is happening in the code above, I have created this very clarifying diagram:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为RAG创建链条的最简单方法。在Jupyter notebook中，你可以找到同样的链条，但更为强大。因为我不希望我们现在在这个话题上迷失，所以我只展示了最简单的形式。同时，为了让我们理解上面代码的内容，我创建了这个非常清晰的图示：
- en: '![](../Images/8c020ccc0b269e852d9b957ec4899227.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c020ccc0b269e852d9b957ec4899227.png)'
- en: Creation of a RAG with Langchain and its LCEL language (Image by Author).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Langchain创建RAG及其LCEL语言（图片来自作者）。
- en: Great, we’re done creating our ***Naive RAG***. Let’s move on to the next method.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，我们完成了创建我们的***简单RAG***。接下来让我们进入下一个方法。
- en: 'Method: Parent Document Retriever'
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法：父文档检索器
- en: Code in [2_parent_document_retriever.ipynb](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/2_parent_document_retriever.ipynb)
    file.
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在[2_parent_document_retriever.ipynb](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/2_parent_document_retriever.ipynb)文件中的代码。
- en: Imagine that we have created a RAG to recognize possible diseases by introducing
    some of their symptoms in the consultation. In the event that we have a Naive
    RAG, we may collect a series of possible diseases that only coincide in one or
    two symptoms, leaving our tool in a bit of a bad place.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们创建了一个RAG来通过输入一些症状来识别可能的疾病。如果我们使用的是一个简单的RAG，我们可能会收集到一系列只在一两个症状上相符的可能疾病，从而使我们的工具陷入困境。
- en: This is an ideal case to use Parent Doc Retriever. And the type of technique
    consists of cutting large chunks (parent chunk) into even smaller pieces (child
    chunk). By having small chunks, the information they contain is more concentrated
    and therefore, its informative value is not diluted between paragraphs of text.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用父文档检索器的理想案例。这种技术的类型包括将大块（父块）切分成更小的块（子块）。通过拥有小块，它们所包含的信息更加集中，因此，它的信息价值不会在文本段落之间被稀释。
- en: 'There is a small problem in all this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一切中有一个小问题：
- en: If we want to be precise in searching for the most relevant documents, we need
    to break our documents into ***small chunks***.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们希望在搜索最相关的文档时更加精确，我们需要将文档分割成***更小的块***。
- en: But it is also very important to provide good context to the LLM, which is achieved
    by providing ***larger chunks***.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但同样重要的是为LLM提供良好的上下文，这可以通过提供***更大的块***来实现。
- en: 'What has been said can be seen in the following image:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 之前所说的内容可以通过以下图片看到：
- en: '![](../Images/8413c96f449f1fa9ad87a95c0951e5bc.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8413c96f449f1fa9ad87a95c0951e5bc.png)'
- en: Representation of the balance between these two concepts/metrics (Image by Author).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种概念/度量之间平衡的表现（图片来自作者）。
- en: It seems that there is no way out of the problem, since when we increase the
    precision, the context is reduced, and vice versa. This is when this method appears
    that will solve our lives.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来似乎没有解决问题的方法，因为当我们提高精度时，上下文会减少，反之亦然。这时，这种方法出现了，它将解决我们的困境。
- en: The main idea is to further chop the large chunks (**Parent chunks/documents**)
    into smaller chunks (**Child Chunks/documents**). Once this is done, perform the
    search for the most relevant top K documents with the child chunks, and return
    the parents chunks to which the top K child document belongs.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思路是将大块（**父块/文档**）进一步切分成更小的块（**子块/文档**）。一旦完成这一点，就可以使用子块进行最相关的前K个文档的搜索，并返回属于这些前K个子文档的父块。
- en: 'We already have the main idea, now let’s get it down to earth. The best way
    to explain it is step by step:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了主要想法，现在让我们将其具体化。最好的解释方式是一步一步来：
- en: Obtain the documents and create the large chunks (**Parent chunks**)
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取文档并创建大块（**父块**）。
- en: Perform a split of each of the parent chunks for the growth of the **child chunks**.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对每个父块进行分割以生成**子块**。
- en: Save the child chunks (*Vector Representatio*n) in the **Vector Store**.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将子块（*向量表示*）保存在**向量存储**中。
- en: Save the ***parent chunks in memory*** (We do not need to create their vector
    representation).
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将***父块保存在内存中***（我们不需要创建它们的向量表示）。
- en: 'What has been said can be seen in the following image:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 之前所说的内容可以通过以下图片看到：
- en: '![](../Images/c6ef2ddb4cb287519a2c1535eb7c79c9.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6ef2ddb4cb287519a2c1535eb7c79c9.png)'
- en: Visual representation of how **child chunks** are created from **parent chunks**,
    and their storage. These are necessary steps to create a **parent document retriever**
    (Image by Author).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何从**父块**创建**子块**并进行存储的可视化表示。这些步骤是创建**父文档检索器**的必要步骤（图片来自作者）。
- en: This may seem very complex to create, since we have to create a new database
    with the small chunks, save the parent chunks in memory. Additionally, know which
    parent chunk each child chunk belongs to. Thank goodness **Langchain** exists
    and the way to build it is super simple.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来可能非常复杂，因为我们需要创建一个新的数据库，包含小块，且将父块保存在内存中。此外，还需要知道每个子块属于哪个父块。谢天谢地，**Langchain**的存在使得构建过程变得非常简单。
- en: Surely you have come to the conclusion that it is necessary to create a new
    vector store for this method. Furthermore, in the case of reviews of the John
    Wick movies, such as the data source with CSV files, it is not necessary to perform
    the first split (parent chunks). This is because we can consider each row of our
    csv files to be a chunk in itself.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你一定已经得出结论，创建这种方法需要一个新的向量存储。此外，在像约翰·威克电影评论这样的数据源（如CSV文件）中，不需要进行第一次切分（父块）。这是因为我们可以将每一行CSV文件看作是一个独立的块。
- en: 'Overall, let’s visualize the following image that reflects how this method
    works:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，让我们通过以下图像来可视化这一方法的工作原理：
- en: '![](../Images/96d669987379cb97201196e3a60d3d33.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96d669987379cb97201196e3a60d3d33.png)'
- en: Visual representation of how a **Parent Document Retriever** works (Image by
    Author).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**父文档检索器**的工作原理的可视化表示（图片来自作者）。'
- en: 'Going to code it is represented as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 编写代码的方式如下所示：
- en: '[PRE7]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Something intuitive about what happens here is that the **number of chunks
    in the vector store (number of child chunks) should be much higher than the number
    of documents stored in memory (parent chunks)**. With the following code we can
    check it:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这里直观的一个概念是，**向量存储中的块数（子块的数量）应该远远高于存储在内存中的文档数量（父块的数量）**。我们可以通过以下代码进行检查：
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Great, we would already have our **Parent Document Retriever**, we just need
    to create our RAG based on this retriever and that would be it. It would be done
    exactly the same as in the previous method. I attach the code for creating the
    chain in langchain. To see more details, take a look at the [jupyter notebook](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/2_parent_document_retriever.ipynb).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，我们已经有了我们的**父文档检索器**，接下来只需要基于这个检索器创建我们的RAG，完成方法与之前一样。我附上了在langchain中创建链条的代码。想查看更多细节，可以查看[jupyter
    notebook](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/2_parent_document_retriever.ipynb)。
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that it is exactly the same as in the previous case, only with the small
    difference that in the ***“setup_and_retrieval”*** variable, we configure that
    we want to use our ***“parent_document_retriever”***, instead of the ***“naive_retriever”***.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这与之前的情况完全相同，只是有一个小区别，即在***“setup_and_retrieval”***变量中，我们配置了使用我们的***“parent_document_retriever”***，而不是***“naive_retriever”***。
- en: 'Method: Self Query Retriever'
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法：自查询检索器
- en: Code in [3_self_query_retriever.ipynb](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/3_self_query_retriever.ipynb)
    file.
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[3_self_query_retriever.ipynb](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/3_self_query_retriever.ipynb)文件中的代码。'
- en: This is possibly one of the most optimal methods to improve the efficiency of
    our retriever.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是提高我们检索器效率的最优化方法之一。
- en: Its main feature is that it is capable of performing searches in the vector
    store, applying filters based on the metadata.
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 它的主要特点是能够在向量存储中执行搜索，并应用基于元数据的过滤器。
- en: We know that when we apply a “**Naive retrieval**”, we are calculating the similarity
    of all the chunks of the vector database with the query. The more chunks the vector
    store has, the more similarity calculations will have to be done. Now, imagine
    being able to do a prior **filter based on the metadata**, and after selecting
    the chunks that meet the conditions imposed in relation to the metadata, calculate
    similarities. **This can drastically reduce computational and time cost.**
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，当我们应用“**朴素检索**”时，我们在计算向量数据库中所有块与查询的相似度。向量存储的块越多，需要进行的相似度计算就越多。现在，试想一下如果能先基于**元数据进行过滤**，然后在选择出符合元数据条件的块之后，再进行相似度计算。**这可以极大地减少计算和时间成本。**
- en: Let’s look at a use case to fully understand when to apply this type of retreival.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个用例来全面理解何时应用这种类型的检索。
- en: 'Let’s imagine that we have stored in our vector database a large number of
    experiences and leisure offers (Ex: surf classes, zip line, gastronomic route,
    etc.). The description of the experience is what we have encoded, using our embedding
    model. Additionally, each offer has 3 key values or metadata: Date, price and
    place.'
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 假设我们在向量数据库中存储了大量的体验和休闲活动（例如：冲浪课程、滑索、 gastronomic 路线等）。这些体验的描述是我们通过嵌入模型编码的。此外，每个活动都有三个关键值或元数据：日期、价格和地点。
- en: ''
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let’s imagine that a user is looking for an experience of this style: An experience
    in nature, that is for the whole family and safe. Furthermore, the price must
    be less than $50 and the place is California.'
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 假设用户正在寻找一种这样的体验：一种适合全家人且安全的自然体验。此外，价格必须低于$50，地点在加利福尼亚。
- en: Something is clear here
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 有一点是明确的
- en: '**WE DO NOT WANT YOU TO RETURN US ACTIVITY/EXPERIENCES THAT DO NOT MEET THE
    PRICE OR PLACE THAT THE USER REQUESTS.**'
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**我们不希望你返回不符合用户请求的价格或地点的活动/体验。**'
- en: Therefore, it does not make sense to calculate similarities with chunks/experiences
    that do not comply with the metadata filter.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，计算与不符合元数据过滤器要求的片段/体验的相似度是没有意义的。
- en: This case is ideal for applying ***Self Query Retriever***. What this type of
    retriever allows us is to perform a first filter through the metadata, and then
    perform the similarity calculation between the chunks that meet the metadata requirements
    and the user input.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这个案例非常适合应用***自查询检索器（Self Query Retriever）***。这种类型的检索器允许我们首先通过元数据进行过滤，然后再在符合元数据要求的片段和用户输入之间进行相似度计算。
- en: 'This technique can be summarized in two very specific steps:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这个技术可以总结为两个非常具体的步骤：
- en: '**Query Constructor**'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询构造器**'
- en: '**Query Translater**'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询翻译器**'
- en: '**Query Constructor**'
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**查询构造器**'
- en: The objective of the step called “***Query Constructor***” is **to create the
    appropriate query and filters according to the user input.**
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: “***查询构造器***”步骤的目标是**根据用户输入创建适当的查询和过滤器。**
- en: Who is in charge of applying the corresponding filters and how do you know what
    they are?
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 谁负责应用相应的过滤器？你怎么知道它们是什么？
- en: 'For this we are going to use an LLM. This LLM will have to be able to decide
    which filters to apply and when. We will also have to explain beforehand what
    the metadata is and what each of them means. In short, the prompt must contain
    3 key points:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将使用一个LLM（大型语言模型）。这个LLM必须能够决定何时以及应用哪些过滤器。我们还需要事先解释元数据是什么以及它们的含义。简而言之，提示（prompt）必须包含三个关键点：
- en: '**Context**: Personality, how you should act, output format, etc.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**：个性，应该如何行动，输出格式等。'
- en: '**Metadata**: Information about available metadata.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据**：有关可用元数据的信息。'
- en: '**Query**: The user’s query/input/question.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询**：用户的查询/输入/问题。'
- en: The output generated by the LLM cannot be directly entered into the database.
    Therefore, the so-called “***Query Translater***” is needed.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: LLM生成的输出不能直接输入到数据库中。因此，需要所谓的“***查询翻译器***”。
- en: Query Translater
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询翻译器
- en: This is a module in charge of **translating the output of the LLM (Query Constructor)
    into the appropriate format to perform the query.** Depending on the vector database
    you use, you will have to use one or the other. In my case I used **Chroma db**,
    therefore, I need a translator focused on this database. Luckily, Langchain has
    specific database translators for almost all of them.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个负责**将LLM（查询构造器）的输出转换为适当格式以执行查询的模块**。根据你使用的向量数据库，你将需要使用不同的模块。以我为例，我使用的是**Chroma
    db**，因此，我需要一个针对这个数据库的翻译器。幸运的是，Langchain几乎为所有数据库提供了特定的数据库翻译器。
- en: 'As you may have already noticed, I am a big fan of diagrams. Let’s look at
    the following which provides quite a bit of clarity to the matter:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的，我是一个图表的忠实粉丝。让我们看看以下图示，它能为这个问题提供相当清晰的解释：
- en: '![](../Images/4f316e099990fd95c123b5e3de6d15ee.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f316e099990fd95c123b5e3de6d15ee.png)'
- en: Visual representation of how a **Self Query Retriever** works (Image by Author).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**自查询检索器**的工作原理的视觉表示（图片来自作者）。'
- en: 'Regarding the previous image, we see that everything begins with the user’s
    query. We create the prompt that contains the 3 key fields and is introduced to
    the LLM that generates a response with two key fields: “***Query***” and “***Filter***”.
    This is fed into the query translator which translates these two fields into the
    correct format needed by ***Chroma DB.*** Performs the query and returns the most
    relevant documents based on the user’s initial question.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 关于前面的图像，我们看到一切从用户的查询开始。我们创建一个包含 3 个关键字段的提示，并将其传递给 LLM，LLM 生成一个包含两个关键字段的响应：“***Query***”
    和 “***Filter***”。这个响应被传递到查询翻译器，查询翻译器将这两个字段转换为 ***Chroma DB*** 所需的正确格式。执行查询并根据用户最初的问题返回最相关的文档。
- en: Something to emphasize is that the query entered by the user does not have to
    be the same as the one entered into the database. In the diagram shown, it can
    be seen that the LLM, taking into account the **available metadata and the user’s
    question, detects that it can create a filter with the “Rating” metadata. It also
    creates a new query based on the user’s query.**
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 需要强调的是，用户输入的查询不必与输入数据库的查询相同。在图示中可以看到，LLM 根据**可用元数据和用户的提问**，发现可以使用“评级”元数据创建一个过滤器。它还根据用户的查询创建一个新的查询。
- en: 'Let’s look at all this in code. As I have explained, it is very important to
    provide the LLM with a detailed description of the metadata available in the vector
    store. This translates into the following piece of code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码中的实现。如我所解释的，提供一个详细描述向量库中可用元数据的信息对 LLM 来说非常重要。这可以通过以下代码段来实现：
- en: '[PRE10]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To define our retrieval we must define the following points:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要定义我们的检索方法，我们必须定义以下几个要点：
- en: The LLM to use
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要使用的 LLM
- en: The embedding model to be used
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要使用的嵌入模型
- en: The vector basis that is accessed
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问的向量库
- en: A description of what information can be found in the
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该文件的描述，说明可以找到哪些信息
- en: documents of this vector base.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该向量库中的文档。
- en: The metadata description
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据描述
- en: The Query translator you want to use
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您希望使用的查询翻译器
- en: 'Let’s see what it looks like in code:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码中的实现：
- en: '[PRE11]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let’s see with a very clear example how we have greatly improved our RAG by
    using this type of retriever. **First we use a naive retriever and then a self
    query retriever.**
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个非常清晰的例子来看看，如何通过使用这种类型的检索器大大改进我们的 RAG。**首先我们使用一个简单的检索器，然后使用自查询检索器。**
- en: '[PRE12]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As we can see, there is a notable improvement.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，效果显著提升。
- en: 'Method: Contextual Compression Retriever (Reranking)'
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法：上下文压缩检索器（重新排序）
- en: Code in [4_contextual_compression_retriever(reranking).ipynb](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/4_contextual_compression_retriever(reranking).ipynb)
    file.
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 代码见 [4_contextual_compression_retriever(reranking).ipynb](https://github.com/damiangilgonzalez1995/AdvancedRetrievalRags/blob/main/4_contextual_compression_retriever(reranking).ipynb)
    文件。
- en: '**Context Windows**: The more documents we obtain from the vectore store, **the
    more information the LLM** will have to give a good answer.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文窗口**：我们从向量库中获取的文档越多，**LLM 获得的信息就越多**，从而能够给出更好的答案。'
- en: '**Recall**: The more documents are retrieved from the vector store, the probability
    of obtaining **irrelevant chunks is greater and therefore, the recall increases**
    (Not a good thing).'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**：从向量库中检索的文档越多，获取到**不相关片段的概率越大，因此召回率会增加**（这不是一个好事）。'
- en: There seems to be no solution for this problem. When we achieve better performance
    in one of the metrics, the other seems destined to worsen. ***Are we sure about
    that?***
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎没有解决这个问题的方法。当我们在某个指标上提高性能时，另一个指标似乎注定要变差。***我们确定吗？***
- en: 'This is when this technique, compression retriever, is presented, focusing
    on the reranking technique. Let’s say that this technique consists of two very
    different steps:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是压缩检索器技术的应用，重点是重新排序技术。可以说，这项技术由两个截然不同的步骤组成：
- en: '**Step 1**: Get a good amount of relevant docs based on the input/question.
    Normally we set the most relevant K.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1**：根据输入/问题获取大量相关文档。通常我们会设置最相关的 K 个文档。'
- en: '**Step 2**: Recalculate which of these documents are really relevant. discarding
    the other documents that are not really useful (**Compression**).'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2**：重新计算这些文档中哪些是真正相关的，丢弃那些不太有用的文档（**压缩**）。'
- en: For the first step, what is known as **Bi-Encoder** is used, which is nothing
    more than what we usually use to make a basic RAG. Vectorize our documents. vectorize
    the query and calculate the similarity with any metric of our choice.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一步，使用的是所谓的**双编码器（Bi-Encoder）**，这实际上就是我们通常用来进行基本RAG的方式。将文档向量化，将查询向量化，并使用我们选择的任何度量计算相似度。
- en: The second step is something different from what we are used to seeing. This
    recalculation/reranking is executed by the **reranking model** or **cross-encoder.**
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步与我们通常看到的有所不同。这一重新计算/重新排序由**重新排序模型**或**跨编码器**执行。
- en: '**These models expect two documents/texts as input, returning a similarity
    score between the pair.**'
  id: totrans-175
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**这些模型期望接受两个文档/文本作为输入，并返回它们之间的相似度评分。**'
- en: If one of these two inputs is the **query** and the other is a **chunk**, we
    can calculate the similarity between the two.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这两种输入中的一个是**查询**，另一个是**文档块**，我们可以计算它们之间的相似度。
- en: 'These two methods can be displayed as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法可以如下展示：
- en: '![](../Images/733f0ca8db289656a32f5b509bea13e2.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/733f0ca8db289656a32f5b509bea13e2.png)'
- en: Visual representation of the two methods presented in the post to calculate
    the similarity between texts (Image by Author).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 计算文本之间相似度的两种方法的视觉表示（图像来源：作者）。
- en: 'You will have realized that the two methods in the end provide the same result,
    a metric that reflects the similarity between two texts. And this is totally true,
    but there is a key feature:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现这两种方法最终提供了相同的结果，即反映两个文本之间相似度的度量。这完全正确，但有一个关键特点：
- en: The result returned by the cross encoder is much more reliable than with the
    Bi-encoder
  id: totrans-181
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 跨编码器返回的结果比双编码器更加可靠。
- en: Okay, it works better, then, because we don’t use it directly with all chunks,
    instead of just the top K chunks. Because it would be ***terribly expensive in
    time and money/computation***. For this reason, we make a **first filter of the
    chunks closest in similarity to the query,** **reducing the use of the reranking
    model to only K times.**
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，它的效果更好，因为我们不会直接用所有文档块，而是只用前K个块。因为直接使用所有文档块将是***在时间和金钱/计算上的巨大开销***。因此，我们会**首先筛选出与查询最相似的文档块，**
    **将重新排序模型的使用限制在K次以内。**
- en: A good question would be where to find the Cross-Encoder models? We are lucky
    that there are open source models that we can find in [HuggingFace](https://huggingface.co/cross-encoder),
    but for the practical case of this post we are going to use the model made available
    by the company [Cohere](https://cohere.com).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的问题是：在哪里可以找到跨编码器（Cross-Encoder）模型？幸运的是，我们可以在[HuggingFace](https://huggingface.co/cross-encoder)找到开源模型，但在本文的实际案例中，我们将使用由公司[Cohere](https://cohere.com)提供的模型。
- en: '[](https://cohere.com/?source=post_page-----1fac2b86dd61--------------------------------)
    [## Cohere | The leading AI platform for enterprise'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://cohere.com/?source=post_page-----1fac2b86dd61--------------------------------)
    [## Cohere | 企业领先的人工智能平台'
- en: Cohere provides industry-leading large language models (LLMs) and RAG capabilities
    tailored to meet the needs of…
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Cohere提供行业领先的大型语言模型（LLMs）和RAG功能，专门为满足…
- en: cohere.com](https://cohere.com/?source=post_page-----1fac2b86dd61--------------------------------)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: cohere.com](https://cohere.com/?source=post_page-----1fac2b86dd61--------------------------------)
- en: To better understand the architecture of this method, let’s look at a visual
    example.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这种方法的架构，我们来看一个视觉示例。
- en: '![](../Images/f6e6821a5c1c17bfdc9eb5d3c0fadc87.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6e6821a5c1c17bfdc9eb5d3c0fadc87.png)'
- en: Visual representation of how a **Contextual Compression Retriever (Reranking)**
    works (Image by Author).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文压缩检索器（重新排序）**的视觉表示（图像来源：作者）。'
- en: 'The image shows the steps:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 该图像显示了步骤：
- en: '**1º)** We obtain the query, which we encode in its vector form with a transformer
    and we introduce it into the vector base.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1º)** 我们获取查询，将其用变换器编码为向量形式，并将其输入到向量数据库中。'
- en: '**2º)** Collect the documents **most similar to the query from our database**.
    We can use any retriever method.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2º)** 从我们的数据库中收集**与查询最相似的文档**。我们可以使用任何检索方法。'
- en: '**3º)** Next we use the Cohere cross-encoder model. In the example in the image,
    this model will be used a total of 4 times. Remember that the **input of this
    model will be the query and a document/chunk, to collect the similarity of these
    two texts.**'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**3º)** 接下来我们使用Cohere的跨编码器模型。在图中的示例中，这个模型将被使用4次。记住，**这个模型的输入将是查询和一个文档/文档块，用来计算这两篇文本的相似度。**'
- en: '**4º)** The 4 calls have been made to this model in the previous step and 4
    new values (between 0 and 1) of the similarity between the query and each of the
    documents have been obtained. As can be seen, the chunk number 1 obtained in the
    previous steps, after the reranking, is now in 4th place.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**4º)** 在之前的步骤中，已经对该模型进行了4次调用，并获得了查询与每个文档之间的相似度值（介于0到1之间）。如图所示，之前步骤中获得的第1块数据，在重排序后，现在排在第4位。'
- en: '**5º)** We add the first 3 chunks most relevant to the context.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**5º)** 我们添加了与上下文最相关的前三个块。'
- en: Returning again to the computational cost and time, if the cross-encoders were
    applied directly, think that with each **new query, the similarity of the query
    with each of the documents should be calculated**. Something that is not optimal
    at all.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 再次回到计算成本和时间，如果直接应用交叉编码器，考虑到每次**新查询时，都需要计算查询与每个文档的相似度**，这显然是非常低效的。
- en: On the other hand, using **Bi-Encoders, the vector representation of the documents
    is the same for each new query.**
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，使用**双编码器时，文档的向量表示对于每个新查询都是相同的。**
- en: We then have a much superior method that is expensive to execute, and on the
    other hand, another method that works well but does not have a large computational
    cost with each new query. All this ends with the conclusion of unifying these
    two methods for a better RAG. And this is known as the ***Contextual Compression
    with reranking method***.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们有了一个更为优越的方法，虽然执行起来很昂贵，但另一方面，另一个方法运行良好，并且每个新查询的计算成本不大。所有这些都得出了统一这两种方法以改进RAG的结论。这就是所谓的***带有重排序的上下文压缩方法***。
- en: 'Let’s move on to the code part. Let’s remember that this method uses a retreiver,
    which in our case will be a Naive Retriever:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续进行代码部分。让我们记住，这种方法使用了一个检索器，在我们的案例中将是一个简单检索器：
- en: '[PRE13]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Thanks to L**angchain** and its integration with **Cohere**, we only have to
    import the module that will execute the call to the Cohere cross-encoder model:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 由于**Langchain**和其与**Cohere**的集成，我们只需要导入一个模块，该模块将执行对Cohere交叉编码器模型的调用：
- en: '[PRE14]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, we create our **Contextual Compression Retriever with Langchain**:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建了我们的**带有Langchain的上下文压缩检索器**：
- en: '[PRE15]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As simple as that. Let’s see a comparison between a ***Naive Retriever and
    a Reranking Retriever***:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 就这么简单。让我们来比较一下***简单检索器和重排序检索器***：
- en: '![](../Images/70e6c3fa51c7f2afef9abf607072c3e8.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70e6c3fa51c7f2afef9abf607072c3e8.png)'
- en: Example of how the reranking method recalculates the similarity between the
    query and the chunks. This causes the most relevant documents returned by the
    first retriever (In our case, Naive retriever), to be completely reordered. The
    3 best are collected as shown (Image by Author).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这是重排序方法如何重新计算查询与块之间相似度的示例。这导致第一个检索器返回的最相关文档（在我们的案例中是简单检索器）被完全重新排序。前三个最相关的文档被收集，如所示（图片来自作者）。
- en: As we see, Naive returns us the top 10 chunks/documents. After performing the
    reranking and obtaining the 3 most relevant documents/chunks, there are noticeable
    changes. Notice how document **number 16**, which is in **third position** in
    relation to its relevance in the first retriever, **becomes first position** when
    performing the reranking.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，简单检索器返回了前10个块/文档。经过重排序并获取到最相关的3个文档/块后，发生了显著变化。注意，文档**编号16**，在第一次检索器中是**第三位**，在进行重排序后，**变成了第一位**。
- en: Conclusion
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We have seen that depending on the characteristics of the case where we want
    to apply a RAG, we will want to use one method or another. Furthermore, there
    may be the case in which one does not know which retriever method to use. For
    this, there are different libraries to evaluate your rags.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，根据我们想要应用RAG的案例的特点，我们可能会选择不同的方法。此外，也可能出现不知道使用哪种检索器方法的情况。为此，存在不同的库来评估你的RAG。
- en: There are several tools for this purpose. Some of those options that I personally
    recommend are the combination of [RAGAS](https://docs.ragas.io/en/stable/) and
    [LangSmith](https://www.langchain.com/langsmith).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为此目的有几种工具可供选择。我个人推荐的几个选项是[RAGAS](https://docs.ragas.io/en/stable/)和[LangSmith](https://www.langchain.com/langsmith)的组合。
- en: '[](https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/?source=post_page-----1fac2b86dd61--------------------------------)
    [## Evaluating RAG pipelines with Ragas + LangSmith'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/?source=post_page-----1fac2b86dd61--------------------------------)
    [## 使用Ragas + LangSmith评估RAG管道'
- en: 'Editor''s Note: This post was written in collaboration with the Ragas team.
    One of the things we think and talk about a…'
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编辑备注：本文由Ragas团队共同撰写。我们讨论和思考的一个问题是……
- en: blog.langchain.dev](https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/?source=post_page-----1fac2b86dd61--------------------------------)
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: blog.langchain.dev](https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/?source=post_page-----1fac2b86dd61--------------------------------)
- en: I highly recommend following, learning and watching the videos of these people
    who are really what inspired me to make this article.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈推荐关注、学习并观看这些人制作的视频，他们正是启发我写这篇文章的来源。
- en: '[## AI Makerspace'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[## AI 创客空间  '
- en: Learn how to build, ship, and share production Large Language Model applications
    with us!
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与我们一起学习如何构建、部署和分享生产级大语言模型应用！
- en: www.youtube.com](https://www.youtube.com/@AI-Makerspace?source=post_page-----1fac2b86dd61--------------------------------)
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: www.youtube.com](https://www.youtube.com/@AI-Makerspace?source=post_page-----1fac2b86dd61--------------------------------)
- en: '*Thank you for reading!*'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢阅读！*'
- en: '*If you find my work useful, you can subscribe to* [***get an email every time
    that I publish a new article***](https://medium.com/@damiangilgonzalez/subscribe)***.***'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你觉得我的工作有用，可以订阅* [***每次我发布新文章时都会收到邮件***](https://medium.com/@damiangilgonzalez/subscribe)***。***'
- en: '*If you’d like,* [***follow******me on Linkedin****!*](https://www.linkedin.com/in/damiangilgonzalez/)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你愿意，* [***在LinkedIn上关注我***](https://www.linkedin.com/in/damiangilgonzalez/)'
