- en: 'Chi-Squared Test: Revealing Hidden Patterns in Your Data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chi-squared-test-revealing-hidden-patterns-in-your-data-d939df2dda71?source=collection_archive---------7-----------------------#2024-06-25](https://towardsdatascience.com/chi-squared-test-revealing-hidden-patterns-in-your-data-d939df2dda71?source=collection_archive---------7-----------------------#2024-06-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Unlock hidden patterns in your data with the chi-squared test in Python.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://vitorihaldijiran.medium.com/?source=post_page---byline--d939df2dda71--------------------------------)[![Vito
    Rihaldijiran](../Images/bc704b6dbbe4c36c5d35d1b83810094f.png)](https://vitorihaldijiran.medium.com/?source=post_page---byline--d939df2dda71--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d939df2dda71--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d939df2dda71--------------------------------)
    [Vito Rihaldijiran](https://vitorihaldijiran.medium.com/?source=post_page---byline--d939df2dda71--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d939df2dda71--------------------------------)
    ·10 min read·Jun 25, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a3380b236178c0c749075f855497151.png)'
  prefs: []
  type: TYPE_IMG
- en: Cover Photo by [Sulthan Auliya](https://unsplash.com/@swafie) on [Unsplash](https://unsplash.com/photos/people-walking-on-brown-wooden-bridge-during-daytime-wTaJBslvJnE)
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 1: What is Chi-Squared Test?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When discussing hypothesis testing, there are many approaches we can take,
    depending on the particular cases. Common tests like the z-test and t-test are
    the go-to methods to test our hypotheses (null and alternative hypotheses). The
    metric we want to test differs depending on the problem. Usually, in generating
    hypotheses, we involve **population mean** or **population proportion** as the
    metric to state them. Let’s say we want to test whether the population proportion
    of the students who took the math test who got 75 is more than 80%. Let the null
    hypothesis be denoted by H0, and the alternative hypothesis be denoted by H1;
    we generate the hypotheses by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d0a645205f21f6f34c71e0eb5698339f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Example of generating hypotheses by Author'
  prefs: []
  type: TYPE_NORMAL
- en: After that, we should see our data, whether the population variance is known
    or unknown, to decide which test statistic formula we should use. In this case,
    we use z-statistic for proportion formula. To calculate the test statistics from
    our sample, first, we estimate the population proportion by dividing the total
    number of students who got 75 by the total number of students who participated
    in the test. After that, we plug in the estimated proportion to calculate the
    test statistic using the test statistic formula. Then, we determine from the test
    statistic result if it will reject or fail to reject the null hypothesis by comparing
    it with the rejection region or p-value.
  prefs: []
  type: TYPE_NORMAL
- en: But what if we want to test different cases? What if we make inferences about
    the proportion of the group of students (e.g., class A, B, C, etc.) variable in
    our dataset? What if we want to test if there is any association between groups
    of students and their preparation before the exam (are they doing extra courses
    outside school or not)? Is it independent or not? **What if we want to test categorical
    data and infer their population in our dataset?** To test that, we’ll be using
    **the chi-squared test.**
  prefs: []
  type: TYPE_NORMAL
- en: The chi-squared test is crafted to help us draw conclusions about categorical
    data that fall into different categories. It compares each category’s observed
    frequencies (counts) to the expected frequencies under the null hypothesis. Denoted
    as X², chi-squared has a distribution, namely **chi-squared distribution**, allowing
    us to determine the significance of the observed deviations from expected values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9cdc98f962c9990f5185ea61424821ce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Chi-Squared Distribution made in Matplotlib by Author'
  prefs: []
  type: TYPE_NORMAL
- en: The plot describes the continuous distribution of each degree of freedom in
    the chi-squared test. In the chi-squared test, to prove whether we will reject
    or fail to reject the null hypothesis, we don’t use the z or t table to decide,
    but we use **the chi-squared table**. **It lists probabilities of selected significance
    level and degree of freedom of chi-squared.** There are two types of chi-squared
    tests, **the chi-squared goodness-of-fit test and the chi-squared test of a contingency
    table.** Each of these types has a different purpose when tackling the hypothesis
    test. In parallel with the theoretical approach of each test, I’ll show you how
    to demonstrate those two tests in practical examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 2: **Chi-squared goodness-of-fit test**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is the first type of the chi-squared test. This test analyzes **a group
    of categorical data from a single categorical variable with k categories.** It
    is used to specifically explain the proportion of observations in each category
    within the population. For example, we surveyed 1000 students who got at least
    75 on their math test. We observed that from 5 groups of students (Class A to
    E), the distribution is like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ab3c9d31ce3c710e622f3f4abead1d6a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Dummy data generated randomly by Author'
  prefs: []
  type: TYPE_NORMAL
- en: We will do it in both manual and Python ways. Let’s start with the manual one.
  prefs: []
  type: TYPE_NORMAL
- en: Form Hypotheses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we know, we have already surveyed 1000 students. I want to test whether
    the population proportions in each class are equal. The hypotheses will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b1fa58b6bfca983a32904e8a42e5f14d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Hypotheses of Students who at least got 75 from 5 classes by Author'
  prefs: []
  type: TYPE_NORMAL
- en: Test Statistic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The test statistic formula for the chi-squared goodness-of-fit test is like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be69f1998740ae95c4796aeabfaffb09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The Chi-squared goodness-of-fit test by Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: 'k: number of categories'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'fi: observed counts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ei: expected counts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We already have the number of categories (5 from Class A to E) and the observed
    counts, but we don’t have the expected counts yet. To calculate that, we should
    reflect on our hypotheses. In this case, I assume that all class proportions are
    the same, which is 20%. We will make another column in the dataset named **Expected**.
    We calculate it by multiplying the total number of observations by the proportion
    we choose:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6d961b485520d45133d289f2cf3bb888.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Calculate expected Counts by Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we plug in the formula like this for each observed and expected value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9215305d09b7e7014bed3877f696c6f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Calculate Test Statistic of goodness-of-fit test by Author'
  prefs: []
  type: TYPE_NORMAL
- en: We already have the test statistic result. But how do we decide whether it will
    reject or fail to reject the null hypothesis?
  prefs: []
  type: TYPE_NORMAL
- en: Decision Rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned above, we’ll use **the chi-squared table** to compare the test
    statistic. Remember that a small test statistic supports the null hypothesis,
    whereas a significant test statistic supports the alternative hypothesis. So,
    we should reject the null hypothesis when the test statistic is substantial (meaning
    this is an upper-tailed test). Because we do this manually, we use the rejection
    region to decide whether it will reject or fail to reject the null hypothesis.
    The rejection region is defined as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bead4f25d65752d1aed05bc1f9466d58.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Rejection Region of goodness-of-fit test by Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: 'α: Significance Level'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'k: number of categories'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The rule of thumb is: **If our test statistic is more significant than the
    chi-squared table value we look up, we reject the null hypothesis.** We’ll use
    the significance level of 5% and look at the chi-squared table. The value of chi-squared
    with a 5% significance level and degrees of freedom of 4 (five categories minus
    1), we get 9.49\. Because our test statistic is way more significant than the
    chi-squared table value (**70.52 > 9.49**), **we reject the null hypothesis at
    a 5% significance level**. Now, you already know how to perform the chi-squared
    goodness-of-fit test!'
  prefs: []
  type: TYPE_NORMAL
- en: Python Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is the Python approach to the chi-squared goodness-of-fit test using SciPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Using the p-value, we also got the same result. **We reject the null hypothesis
    at a 5% significance level.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/548532944c62584afaa5160b7148dc6a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Result of goodness-of-fit test using Python by Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 3: **Chi-squared test of a contingency table**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We already know how to make inferences about the proportion of one categorical
    variable. But what if I want to test whether two categorical variables are independent?
  prefs: []
  type: TYPE_NORMAL
- en: To test that, we use the chi-squared test of the contingency table. We will
    utilize the contingency table to calculate the test statistic value. A contingency
    table is a cross-tabulation table that classifies counts summarizing the combined
    distribution of two categorical variables, each having a finite number of categories.
    From this table, you **can determine if the distribution of one categorical variable
    is consistent across all categories of the other categorical variable.**
  prefs: []
  type: TYPE_NORMAL
- en: 'I will explain how to do it manually and using Python. In this example, we
    sampled 1000 students who got at least 75 on their math test. I want to test whether
    the variable of a group of students and the variable of the students who have
    taken the supplementary course (Taken or Not) outside the school before the test
    is independent. The distribution is like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44abbca48de586e0ae86f479668fcde7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Dummy data of contingency table generated randomly by Author'
  prefs: []
  type: TYPE_NORMAL
- en: Form Hypotheses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To generate these hypotheses is very simple. We define the hypotheses as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c33a1416a69a0306775a2595754c026.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Generate hypotheses of contingency table test by Author'
  prefs: []
  type: TYPE_NORMAL
- en: Test Statistic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is the hardest part. In handling real data, I suggest you use Python or
    other statistical software directly because the calculation is too complicated
    if we do it manually. But because we want to know the approach from the formula,
    let’s do the manual calculation. The test statistic of this test is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/96b7f74d54a971e5946e5faeb0485f88.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: The Chi-squared contingency table formula by Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: r = number of rows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: c = number of columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'fij: the observed counts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: eij = (i th row total * j th row total)/sample size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recall Figure 9,** those values are just observed ones. Before we use the
    test statistic formula, we should calculate **the expected counts.** We do that
    by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/87179b6dad4b93d25c2bef66723f2b7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Expected Counts of the contingency table by Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we get the observed and expected counts. After that, we will calculate
    the test statistic by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/faca90513a4e55f9a574ec968eaf1e34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: Calculate Test Statistic of contingency table test by Author'
  prefs: []
  type: TYPE_NORMAL
- en: Decision Rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We already have the test statistic; now we compare it with the rejection region.
    The rejection region for the contingency table test is defined by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cf8f70795ac8d2430cce63bf3bbaa379.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: Rejection Region of contingency table test by Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: 'α: Significance Level'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: r = number of rows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: c = number of columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The rule of thumb is the same as the goodness-of-fit test: **If our test statistic
    is more significant than the chi-squared table value we look up, we reject the
    null hypothesis.** We will use the significance level of 5%. Because the total
    row is 5 and the total column is 2, we look up the value of chi-squared with a
    5% significance level and degrees of freedom of (5–1) * (2–1) = 4, and we get
    15.5\. Because the test statistic is lower than the chi-squared table value (**22.9758
    > 15.5**), **we reject the null hypothesis at a 5% significance level.**'
  prefs: []
  type: TYPE_NORMAL
- en: Python Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is the Python approach to the chi-squared contingency table test using
    SciPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Using the p-value, we also got the same result. **We reject the null hypothesis
    at a 5% significance level.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e48df9dbf370c9f5be67ae058b06a54b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Result of contingency table test using Python by Author'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you understand how to conduct hypothesis tests using the chi-square
    test method, it’s time to apply this knowledge to your own data. Happy experimenting!
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 4: Conclusion'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The chi-squared test is a powerful statistical method that helps us understand
    the relationships and distributions within categorical data. Forming the problem
    and proper hypotheses before jumping into the test itself is crucial. A large
    sample is also vital in conducting a chi-squared test; for instance, it works
    well for sizes down to 5,000 (Bergh, 2015), as small sample sizes can lead to
    inaccurate results. To interpret results correctly, choose the right significance
    level and compare the chi-square statistic to the critical value from the chi-square
    distribution table or the p-value.
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: G. Keller, [Statistics for Management and Economics](https://books.google.com.au/books/about/Statistics_for_Management_and_Economics.html?id=oM8tvgAACAAJ&redir_esc=y),
    11th ed., Chapter 15, Cengage Learning (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Daniel, Bergh. (2015). Chi-Squared Test of Fit and Sample Size-A Comparison
    between a Random Sample Approach and a Chi-Square Value Adjustment Method.. Journal
    of applied measurement, 16(2):204–217.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
