- en: Enhancing Interaction between Language Models and Graph Databases via a Semantic
    Layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/enhancing-interaction-between-language-models-and-graph-databases-via-a-semantic-layer-0a78ad3eba49?source=collection_archive---------0-----------------------#2024-01-18](https://towardsdatascience.com/enhancing-interaction-between-language-models-and-graph-databases-via-a-semantic-layer-0a78ad3eba49?source=collection_archive---------0-----------------------#2024-01-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Provide an LLM agent with a suite of robust tools it can use to interact with
    a graph database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://bratanic-tomaz.medium.com/?source=post_page---byline--0a78ad3eba49--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page---byline--0a78ad3eba49--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0a78ad3eba49--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0a78ad3eba49--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page---byline--0a78ad3eba49--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0a78ad3eba49--------------------------------)
    ·11 min read·Jan 18, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graphs provide a great representation of data with flexible data schema
    that can store [structured and unstructured information](https://medium.com/neo4j/using-a-knowledge-graph-to-implement-a-devops-rag-application-b6ba24831b16).
    You can use Cypher statements to retrieve information from a graph database like
    Neo4j. One option is to use LLMs to generate Cypher statements. While that option
    provides excellent flexibility, the truth is that base LLMs are still brittle
    at consistently generating precise Cypher statements. Therefore, we need to look
    for an alternative to guarantee consistency and robustness. What if, instead of
    developing Cypher statements, the LLM extracts parameters from user input and
    uses predefined functions or Cypher templates based on the user intent? In short,
    you could provide the LLM with a set of predefined tools and instructions on when
    and how to use them based on the user input, which is also known as the semantic
    layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aeeb64a2a96d1a41bf353ad6817a5d4e.png)'
  prefs: []
  type: TYPE_IMG
- en: Semantic layer is an intermediate step that provides additional accuracy and
    robust way of LLMs interacting with a Knowledge graph. Image by the author. Inspired
    by [this image](https://cube.dev/blog/semantic-layer-the-backbone-of-ai-powered-data-experiences).
  prefs: []
  type: TYPE_NORMAL
- en: A semantic layer consists of various tools exposed to an LLM that it can use
    to interact with a knowledge graph. They can be of various complexity. You can
    think of each tool in a semantic layer as a function. For example, take a look
    at the following function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The tools can have multiple input parameters, like in the above example, which
    allows you to implement complex tools. Additionally, the workflow can consist
    of more than a database query, allowing you to handle any edge cases or exceptions
    as you see fit. The advantage is that you turn prompt engineering problems, which
    might work most of the time, into code engineering problems, which work every
    time exactly as scripted.
  prefs: []
  type: TYPE_NORMAL
- en: Movie agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this blog post, we will demonstrate how to implement a semantic layer that
    allows an LLM agent to interact with a knowledge graph that contains information
    about actors, movies, and their ratings.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e04d930fdbbd3e70efc04a3060abfcff.png)'
  prefs: []
  type: TYPE_IMG
- en: Movie agent architecture. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Taken from the documentation (also written by me):'
  prefs: []
  type: TYPE_NORMAL
- en: The agent utilizes several tools to interact with the Neo4j graph database effectively.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*** Information tool**: Retrieves data about movies or individuals, ensuring
    the agent has access to the latest and most relevant information.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*** Recommendation Tool**: Provides movie recommendations based upon user preferences
    and input.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*** Memory Tool**: Stores information about user preferences in the knowledge
    graph, allowing for a personalized experience over multiple interactions.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An agent can use information or recommendation tools to retrieve information
    from the database or use the memory tool to store user preferences in the database.
  prefs: []
  type: TYPE_NORMAL
- en: Predefined functions and tools empower the agent to orchestrate intricate user
    experiences, guiding individuals towards specific goals or delivering tailored
    information that aligns with their current position within the user journey.
  prefs: []
  type: TYPE_NORMAL
- en: This predefined approach enhances the robustness of the system by reducing the
    artistic freedom of an LLM, ensuring that responses are more structured and aligned
    with predetermined user flows, thereby improving the overall user experience.
  prefs: []
  type: TYPE_NORMAL
- en: The semantic layer backend of a movie agent is implemented and available as
    a [LangChain template](https://github.com/langchain-ai/langchain/tree/master/templates/neo4j-semantic-layer).
    I have used this template to build a simple streamlit chat application.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e94a84617ebaa1796729ef1cae7a77d.png)'
  prefs: []
  type: TYPE_IMG
- en: Streamlit chat interface. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code is available on [GitHub](https://github.com/tomasonjo/llm-movieagent).
    You can start the project by defining environment variables and executing the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Graph model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The graph is based on the [MovieLens](https://grouplens.org/datasets/movielens/)
    dataset. It contains information about actors, movies, and 100k user ratings of
    movies.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1498878706b68d43ef3619c7bbbec6a1.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph schema. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The visualization depicts a knowledge graph of individuals who have either acted
    in or directed a movie, which is further categorized by genre. Each movie node
    holds information about its release date, title, and IMDb rating. The graph also
    contains user ratings, which we can use to provide recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: You can populate the graph by executing the `ingest.py` script, which is located
    in the root directory of the folder.
  prefs: []
  type: TYPE_NORMAL
- en: Defining tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we will define the tools an agent can use to interact with the knowledge
    graph. We will start with the **information tool**. Information tool is designed
    to fetch relevant information about actors, directors, and movies. The Python
    code looks the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The function starts by finding relevant people or movies mentioned using a full-text
    index. The [full-text index in Neo4j](https://neo4j.com/docs/cypher-manual/current/indexes-for-full-text-search/)
    uses Lucene under the hood. It enables a seamless implementation of text distance-based
    lookups, which allow the user to misspell some words and still get results. If
    no relevant entities are found, we can directly return a response. On the other
    hand, if multiple candidates are identified, we can guide the agent to ask the
    user a follow-up question and be more specific about the movie or person they
    are interested in. Imagine that a user asks, “Who is John?”.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the tool informs the agent that it needs additional information.
    With simple prompt engineering, we can steer the agent to ask the user a follow-up
    question. Suppose the user is specific enough, which allows the tool to identify
    a particular movie or a person. In that case, we use a parametrized Cypher statement
    to retrieve relevant information.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: With this information, the agent can answer most of the questions that concern
    Keanu Reeves.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s guide the agent on utilizing this tool effectively. Fortunately,
    with LangChain, the process is straightforward and efficient. First, we define
    the input parameters of the function using a Pydantic object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, we describe that both entity and entity_type parameters are strings. The
    entity parameter input is defined as the movie or a person mentioned in the question.
    On the other hand, with the entity_type, we also provide available options. When
    dealing with low cardinalities, meaning when there is a small number of distinct
    values, we can provide available options directly to an LLM so that it can use
    valid inputs. As we saw before, we use a full-text index to disambiguate movies
    or people as there are too many values to provide directly in the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s put it all together in a Information tool definition.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Accurate and concise tool definitions are an important part of a semantic layer,
    so that an agent can correctly pick relevant tools when needed.
  prefs: []
  type: TYPE_NORMAL
- en: The recommendation tool is slightly more complex.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The first thing to notice is that both input parameters are optional. Therefore,
    we need to introduce workflows that handle all the possible combinations of input
    parameters and the lack of them. To produce personalized recommendations, we first
    get a `user_id` , which is then passed into downstream Cypher recommendation statements.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly as before, we need to present the input of the function to the agent.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Since only 20 available genres exist, we provide their values as part of the
    prompt. For movie disambiguation, we again use a full-text index within the function.
    As before, we finish with the tool definition to inform the LLM when to use it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: So far, we have defined two tools to retrieve data from the database. However,
    the information flow doesn’t have to be one-way. For example, when a user informs
    the agent they have already watched a movie and maybe liked it, we can store that
    information in the database and use it in further recommendations. Here is where
    the memory tool comes in handy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The memory tool has two mandatory input parameters that define the movie and
    its rating. It’s a straightforward tool. One thing I should mention is that I
    noticed in my testing that it probably makes sense to provide examples of when
    to give a specific rating, as the LLM isn’t the best at it out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: Agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s put it now all together using [LangChain expression language](https://python.langchain.com/docs/expression_language/)
    (LCEL) to define an agent.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: LangChain expression language makes it very convenient to define an agent and
    expose all its functionalities. We won’t go into LCEL syntax as that is beyond
    the scope of this blog post.
  prefs: []
  type: TYPE_NORMAL
- en: The movie agent backend is exposed as an API endpoint using [LangServe](https://www.langchain.com/langserve).
  prefs: []
  type: TYPE_NORMAL
- en: Streamlit chat application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we just have to implement a streamlit application that connects to the LangServe
    API endpoint and we are good to go. We’ll just look at the async function that
    is used to retrieve an agent response.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The function `get_agent_response` is designed to interact with a movie-agent
    API. It sends a request with the user's input and chat history to the API and
    then processes the response asynchronously. The function handles different types
    of responses, updating the stream handler with new statuses and appending the
    generated text to the session state, which allows us to stream results to the
    user.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now test it out
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bce1fd1386d8ea222ccafa7738aa6b16.png)'
  prefs: []
  type: TYPE_IMG
- en: Movie agent in action. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting movie agent offers a surprisingly good and guided interaction
    with the user.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In conclusion, the integration of a semantic layer in language model interactions
    with graph databases, as exemplified by our Movie Agent, represents a significant
    leap forward in enhancing user experience and data interaction efficiency. By
    shifting the focus from generating arbitrary Cypher statements to utilizing a
    structured, predefined suite of tools and functions, the semantic layer brings
    a new level of precision and consistency to language model engagements. This approach
    not only streamlines the process of extracting relevant information from knowledge
    graphs but also ensures a more goal-oriented, user-centric experience.
  prefs: []
  type: TYPE_NORMAL
- en: The semantic layer acts as a bridge, translating user intent into specific,
    actionable queries that the language model can execute with accuracy and reliability.
    As a result, users benefit from a system that not only understands their queries
    more effectively but also guides them towards their desired outcomes with greater
    ease and less ambiguity. Furthermore, by constraining the language model’s responses
    within the parameters of these predefined tools, we mitigate the risks of incorrect
    or irrelevant outputs, thereby enhancing the trustworthiness and reliability of
    the system.
  prefs: []
  type: TYPE_NORMAL
- en: The code is available on [GitHub](https://github.com/tomasonjo/llm-movieagent).
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'F. Maxwell Harper and Joseph A. Konstan. 2015\. The MovieLens Datasets: History
    and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4:
    19:1–19:19\. [https://doi.org/10.1145/2827872](https://doi.org/10.1145/2827872)'
  prefs: []
  type: TYPE_NORMAL
