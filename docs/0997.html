<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Practical Computer Simulations for Product Analysts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Practical Computer Simulations for Product Analysts</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/practical-computer-simulations-for-product-analysts-90b5deb6a54e?source=collection_archive---------5-----------------------#2024-04-19">https://towardsdatascience.com/practical-computer-simulations-for-product-analysts-90b5deb6a54e?source=collection_archive---------5-----------------------#2024-04-19</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="a915" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Part 1: Task-specific approaches for scenario forecasting</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://miptgirl.medium.com/?source=post_page---byline--90b5deb6a54e--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Mariya Mansurova" class="l ep by dd de cx" src="../Images/b1dd377b0a1887db900cc5108bca8ea8.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*7fFHr8XBAuR_SgJknIyODA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--90b5deb6a54e--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://miptgirl.medium.com/?source=post_page---byline--90b5deb6a54e--------------------------------" rel="noopener follow">Mariya Mansurova</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--90b5deb6a54e--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">20 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 19, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mj"><div class="ab cb"><div class="lm mk ln ml lo mm cf mn cg mo ci bh"><figure class="ms mt mu mv mw mj mx my paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq mr"><img src="../Images/6987a0f2acb152826d29e342f49419d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*HlPTNgX9mx-xSPo780e_AA.jpeg"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by DALL-E</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="fab2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In product analytics, we quite often get "what-if" questions. Our teams are constantly inventing different ways to improve the product and want to understand how it can affect our KPI or other metrics.</p><p id="be64" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's look at some examples:</p><ul class=""><li id="8795" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">Imagine we're in the fintech industry and facing new regulations requiring us to check more documents from customers making the first donation or sending more than $100K to a particular country. We want to understand the effect of this change on our Ops demand and whether we need to hire more agents.</li><li id="cdd0" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">Let's switch to another industry. We might want to incentivise our taxi drivers to work late or take long-distance rides by introducing a new reward scheme. Before launching this change, it would be crucial for us to estimate the expected size of rewards and conduct a cost vs. benefit analysis.</li><li id="06e5" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">As the last example, let's look at the main Customer Support KPIs. Usually, companies track the average waiting time. There are many possible ways how to improve this metric. We can add night shifts, hire more agents or leverage LLMs to answer questions quickly. To prioritise these ideas, we will need to estimate their impact on our KPI.</li></ul><p id="ad7d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">When you see such questions for the first time, they look pretty intimidating.</p><p id="d56f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">If someone asks you to calculate monthly active users or 7-day retention, it's straightforward. You just need to go to your database, write SQL and use the data you have.</p><p id="ec56" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Things become way more challenging (and exciting) when you need to calculate something that doesn't exist. Computer simulations will usually be the best solution for such tasks. According to <a class="af on" href="https://en.wikipedia.org/wiki/Simulation" rel="noopener ugc nofollow" target="_blank">Wikipedia</a>, <strong class="nl fr">simulation</strong> is an imitative representation of a process or system that could exist in the real world. So, we will try to imitate different situations and use them in our decision-making.</p><p id="b845" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Simulation is a powerful tool that can help you in various situations. So, I would like to share with you the practical examples of computer simulations in the series of articles:</p><ul class=""><li id="95dd" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">In this article, we will discuss how to use simulations to estimate different scenarios. You will learn the basic idea of simulations and see how they can solve complex tasks.</li><li id="3c32" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">In the second part, we will diverge from scenario analysis and will focus on the classic of computer simulations — bootstrap. Bootstrap can help you get confidence intervals for your metrics and analyse A/B tests.</li><li id="9e43" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">I would like to devote the third part to <a class="af on" href="https://en.wikipedia.org/wiki/Agent-based_model" rel="noopener ugc nofollow" target="_blank">agent-based models</a>. We will model the CS agent behaviour to understand how our process changes can affect CS KPIs such as queue size or average waiting time.</li></ul><p id="dc96" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, it's time to start and discuss the task we will solve in this article.</p><h1 id="d9b3" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Our project: Launching tests for English courses</h1><p id="82ca" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Suppose we are working on an edtech product that helps people learn the English language. We've been working on a test that could assess the student's knowledge from different angles (reading, listening, writing and speaking). The test will give us and our students a clear understanding of their current level.</p><p id="6fca" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We agreed to launch it for all new students so that we can assess their initial level. Also, we will suggest existing students pass this test when they return to the service next time.</p><p id="77db" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Our goal is to build a forecast on the number of submitted tests over time. Since some parts of these tests (writing and speaking) will require manual review from our teachers, we would like to ensure that we will have enough capacity to check these tests on time.</p><p id="a114" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's try to structure our problem. We have two groups of students:</p><ul class=""><li id="6488" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">The first group is<strong class="nl fr"> existing students.</strong> It's a good practice to be precise in analytics, so we will define them as students who started using our service before this launch. We will need to check them once at their next transaction, so we will have a substantial spike while processing them all. Later, the demand from this segment will be negligible (only rare reactivations).</li><li id="10a2" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk"><strong class="nl fr">New students </strong>will hopefully continue joining our courses. So, we should expect consistent demand from this group.</li></ul><p id="b5f6" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, it's time to think about how we can estimate the demand for these two groups of customers.</p><p id="6a0d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The situation is pretty straightforward for <strong class="nl fr">new students</strong> — we need to predict the number of new customers weekly and use it to estimate demand. So, it's a classic task of time series forecasting.</p><p id="a49d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The task of predicting demand from <strong class="nl fr">existing customers</strong> might be more challenging. The direct approach would be to build a model to predict the week when students will return to the service next time and use it for estimations. It's a possible solution, but it sounds a bit overcomplicated to me.</p><p id="8ef4" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I would prefer the other approach. I would simulate the situation when we launched this test some time ago and use the previous data. In that case, we will have all the data after "this simulated launch" and will be able to calculate all the metrics. So, it's actually a basic idea of scenario simulations.</p><p id="7def" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Cool, we have a plan. Let's move on to execution.</p><h1 id="de5e" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Modelling demand from new customers</h1><p id="1efb" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Before jumping to analysis, let's examine the data we have. We keep a record of the lessons' completion events. We know each event's user identifier, date, module, and lesson number. We will use weekly data to avoid seasonality and capture meaningful trends.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq pp"><img src="../Images/43843a3d3569e67eaf6d34c85251d222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z8LT1eiz8OnQjNluS2bF3A.png"/></div></div></figure><p id="a722" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let me share some context about the educational process. Students primarily come to our service to learn English from scratch and pass six modules (from pre-A1 to C1). Each module consists of 100 lessons.</p><blockquote class="pq pr ps"><p id="5d8f" class="nj nk pt nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The data was generated explicitly for this use case, so we are working with a synthetic data set.</p></blockquote><p id="93fe" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, we need to calculate the metric we want to predict. We will offer students the opportunity to pass the initial evaluation test after completing the first demo lesson. So, we can easily calculate the number of customers who passed the first lesson or aggregate users by their first date.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="a948" class="py op fq pv b bg pz qa l qb qc">new_users_df = df.groupby('user_id', as_index = False).date.min()\<br/>  .rename(columns = {'date': 'cohort'})<br/><br/>new_users_stats_df = new_users_df.groupby('cohort')[['user_id']].count()\<br/>  .rename(columns = {'user_id': 'new_users'})</span></pre><p id="b9e3" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can look at the data and see an overall growing trend with some seasonal effects (i.e. fewer customers joining during the summer or Christmas time).</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qd"><img src="../Images/4f1587dc8cb87734b463b1df1d8ff7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EVPsk0i8kRQdB6uskWMYwA.png"/></div></div></figure><p id="151d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">For forecasting, we will use <a class="af on" href="https://facebook.github.io/prophet/" rel="noopener ugc nofollow" target="_blank">Prophet</a> — an open-source library from Meta. It works pretty well with business data since it can predict non-linear trends and automatically take into account seasonal effects. You can easily install it from PyPI.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="c1f0" class="py op fq pv b bg pz qa l qb qc">pip install prophet</span></pre><p id="e896" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Prophet library expects a data frame with two columns: <code class="cx qe qf qg pv b">ds</code> with timestamp and <code class="cx qe qf qg pv b">y</code> with a metric we want to predict. Also, <code class="cx qe qf qg pv b">ds</code> must be a datetime column. So, we need to transform our data to the expected format.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="e8cf" class="py op fq pv b bg pz qa l qb qc">pred_new_users_df = new_users_df.copy()<br/>pred_new_users_df = pred_new_users_df.rename(<br/>  columns = {'new_users': 'y', 'cohort': 'ds'})<br/>pred_new_users_df.ds = pd.to_datetime(pred_new_users_df.ds)</span></pre><p id="1c32" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we are ready to make predictions. As usual in ML, we need to initialise and fit a model.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="bf65" class="py op fq pv b bg pz qa l qb qc">from prophet import Prophet<br/><br/>m = Prophet()<br/>m.fit(pred_new_users_df)</span></pre><p id="702b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The next step is prediction. First, we need to create a future data frame specifying the number of periods and their frequency (in our case, weekly). Then, we need to call the <code class="cx qe qf qg pv b">predict</code> function.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="851e" class="py op fq pv b bg pz qa l qb qc">future = m.make_future_dataframe(periods= 52, freq = 'W')<br/>forecast_df = m.predict(future)<br/>forecast_df.tail()[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]</span></pre><p id="c3e3" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">As a result, we get the forecast (<code class="cx qe qf qg pv b">yhat</code>) and confidence interval (<code class="cx qe qf qg pv b">yhat_lower</code> and <code class="cx qe qf qg pv b">yhat_upper</code>).</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qh"><img src="../Images/038a1e1d4a20c36f00e76a9ffacecb3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d58w-ccfHGnqInSKHkl12w.png"/></div></div></figure><p id="6324" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It's difficult to understand the result without charts. Let's use Prophet functions to visualise the output better.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="079c" class="py op fq pv b bg pz qa l qb qc">m.plot(forecast_df) # forecast<br/>m.plot_components(forecast_df) # components</span></pre><p id="6c15" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The forecast chart shows you the forecast with a confidence interval.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qi"><img src="../Images/023fd7c58cfd4628e700d281faf1819d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zwAPW_8gXwlC-0UfbhU9nA.png"/></div></div></figure><p id="3c73" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The components view lets you understand the split between trend and seasonal effects. For example, the second chart displays a seasonal drop-off during summer and an increase at the beginning of September (when people might be more motivated to start learning something new).</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qj"><img src="../Images/c4c514ca943e9bf65483ddfa2e0f0fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hPZ7uXdpFosM2SvdiYZXAg.png"/></div></div></figure><p id="c8cf" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can put all this forecasting logic into one function. It will be helpful for us later.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="17f4" class="py op fq pv b bg pz qa l qb qc">import plotly.express as px<br/>import plotly.io as pio<br/>pio.templates.default = 'simple_white'<br/><br/>def make_prediction(tmp_df, param, param_name = '', periods = 52):<br/>    # pre-processing<br/>    df = tmp_df.copy()<br/>    date_param = df.index.name<br/>    df.index = pd.to_datetime(df.index)<br/>    <br/>    train_df = df.reset_index().rename(columns = {date_param: 'ds', param: 'y'})<br/>    <br/>    # model<br/>    m = Prophet()<br/>    m.fit(train_df)<br/><br/>    future = m.make_future_dataframe(periods=periods, freq = 'W')<br/>    forecast = m.predict(future)<br/>    forecast = forecast[['ds', 'yhat']].rename(columns = {'ds': date_param, 'yhat': param + '_model'})<br/>    <br/>    # join to actual data<br/>    forecast = forecast.set_index(date_param).join(df, how = 'outer')<br/>    <br/>    # visualisation<br/>    fig = px.line(forecast, <br/>        title = '&lt;b&gt;Forecast:&lt;/b&gt; ' + (param if param_name == '' else param_name),<br/>        labels = {'value': param if param_name == '' else param_name},<br/>        color_discrete_map = {param: 'navy', param + '_model': 'gray'}<br/>    )<br/>    fig.update_traces(mode='lines', line=dict(dash='dot'), <br/>        selector=dict(name=param + '_model'))<br/>    fig.update_layout(showlegend = False)<br/>    fig.show()<br/><br/>    return forecast<br/><br/>new_forecast_df = make_prediction(new_users_stats_df, <br/>  'new_users', 'new users', periods = 75)</span></pre><p id="8bd3" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I prefer to share with my stakeholders a more styled version of visualisation (especially for public presentations), so I've added it to the function as well.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qk"><img src="../Images/06eaa510b37b23b26f271744de6aaaf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*chbZwzTpYDQXpBz0BQN_8g.png"/></div></div></figure><p id="f10d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In this example, we've used the default Prophet model and got quite a plausible forecast. However, in some cases, you might want to tweak parameters, so I advise you to read <a class="af on" href="https://facebook.github.io/prophet/docs/quick_start.html#python-api" rel="noopener ugc nofollow" target="_blank">the Prophet docs</a> to learn more about the possible levers.</p><p id="00c2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">For example, in our case, we believe that our audience will continue growing at the same rate. However, this might not be the case, and you might expect it to have a cap of around 100 users. Let's update our prediction for saturating growth.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="ce8f" class="py op fq pv b bg pz qa l qb qc"># adding cap to the initial data<br/># it's not required to be constant<br/>pred_new_users_df['cap'] = 100<br/><br/>#specifying logistic growth<br/>m = Prophet(growth='logistic')<br/>m.fit(pred_new_users_df)<br/><br/># adding cap for the future<br/>future = m.make_future_dataframe(periods= 52, freq = 'W')<br/>future['cap'] = 100<br/>forecast_df = m.predict(future)</span></pre><p id="584f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can see that the forecast has changed significantly, and the growth stops at ~100 new clients per week.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq ql"><img src="../Images/c50618f0e4851c98c777991e5dad7c1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cqv5Ai6mCuhE3T1pPxE_lQ.png"/></div></div></figure><p id="0e26" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It's also interesting to look at the components' chart in this case. We can see that the seasonal effects stayed the same, while the trend has changed to logistic (as we specified).</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq pp"><img src="../Images/cd9448cab3099823c8aafa704be0f14f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OuNjAoIFQ-yRpPDU2gCQog.png"/></div></div></figure><p id="240b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We've learned a bit about the ability to tweak forecasts. However, for future calculations, we will use a basic model. Our business is still relatively small, and most likely, we haven’t reached saturation yet.</p><p id="d885" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We've got all the needed estimations for new customers and are ready to move on to the existing ones.</p><h1 id="3c1f" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Modelling demand from existing customers</h1><h2 id="fa48" class="qm op fq bf oq qn qo qp ot qq qr qs ow ns qt qu qv nw qw qx qy oa qz ra rb rc bk">The first version</h2><p id="cdb7" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The key point in our approach is to simulate the situation when we launched this test some time ago and calculate the demand using this data. Our solution is based on the idea that we can use the past data instead of predicting the future.</p><p id="6350" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Since there's significant yearly seasonality, I will use data for -1 year to take into account these effects automatically. We want to launch this project at the beginning of April. So, I will use past data from the week of 2nd April 2023.</p><p id="e2ef" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, we need to filter the data related to existing customers at the beginning of April 2023. We've already forecasted demand from new users, so we don't need to consider them in this estimation.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="8123" class="py op fq pv b bg pz qa l qb qc">model_existing_users = df[df.date &lt; '2023-04-02'].user_id.unique()<br/>raw_existing_df = df[df.user_id.isin(model_existing_users)]</span></pre><p id="0d73" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Then, we need to model the demand from these users. We will offer our existing students the chance to pass the test the next time they use our product. So, we need to define when each customer returned to our service after the launch and aggregate the number of customers by week. There's no rocket science at all.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="7c76" class="py op fq pv b bg pz qa l qb qc">existing_model_df = raw_existing_df[raw_existing_df.date &gt;= '2023-04-02']\<br/>  .groupby('user_id', as_index = False).date.min()\<br/>  .groupby('date', as_index = False).user_id.count()\<br/>  .rename(columns = {'user_id': 'existing_users'})</span></pre><p id="0980" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We got the first estimations. If we had launched this test in April 2023, we would have gotten around 1.3K tests in the first week, 0.3K for the second week, 80 cases in the third week, and even less afterwards.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rd"><img src="../Images/fbefdfd378810634f2b65d8598dd309d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dGm6JCaZseuCMpTAN1gmrQ.png"/></div></div></figure><p id="84ce" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We assumed that 100% of existing customers would finish the test, and we would need to check it. In real-life tasks, it's worth taking conversion into account and adjusting the numbers. Here, we will continue using 100% conversion for simplicity.</p><p id="e35e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, we've done our first modelling. It wasn't challenging at all. But is this estimation good enough?</p><h2 id="9ce8" class="qm op fq bf oq qn qo qp ot qq qr qs ow ns qt qu qv nw qw qx qy oa qz ra rb rc bk">Taking into account long-term trends</h2><p id="e3ff" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">We are using data from the previous year. However, everything changes. Let's look at the number of active customers over time.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="177c" class="py op fq pv b bg pz qa l qb qc">active_users_df = df.groupby('date')[['user_id']].nunique()\<br/>    .rename(columns = {'user_id': 'active_users'})</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq re"><img src="../Images/aa96d886a01bb6c2677baf121cc54707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ca4q6ZKKmLBs_HTZd6lmjA.png"/></div></div></figure><p id="a4b0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can see that it's growing steadily. I would expect it to continue growing. So, it's worth adjusting our forecast due to this YoY (<em class="pt">Year-over-Year</em>) growth. We can re-use our prediction function and calculate YoY using forecasted values to make it more accurate.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="7af2" class="py op fq pv b bg pz qa l qb qc"><br/>active_forecast_df = make_prediction(active_users_df, <br/>    'active_users', 'active users')</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rf"><img src="../Images/ee2f35233a05c10748da4fa37c376da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfo-U8JyM9XEHacyc_Qu3Q.png"/></div></div></figure><p id="f011" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's calculate YoY growth based on our forecast and adjust the model's predictions.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="232f" class="py op fq pv b bg pz qa l qb qc"># calculating YoYs<br/>active_forecast_df['active_user_prev_year'] = active_forecast_df.active_users.shift(52)<br/>active_forecast_df['yoy'] = active_forecast_df.active_users_model/\<br/>  active_forecast_df.active_user_prev_year<br/><br/>existing_model_df = existing_model_df.rename(<br/>  columns = {'date': 'model_date', 'existing_users': 'model_existing_users'})<br/><br/># adjusting dates from 2023 to 2024<br/>existing_model_df['date'] = existing_model_df.model_date.map(<br/>  lambda x: datetime.datetime.strptime(x, '%Y-%m-%d') + datetime.timedelta(364)<br/>)<br/><br/>existing_model_df = existing_model_df.set_index('date')\<br/>   .join(active_forecast_df[['yoy']])<br/><br/># updating estimations<br/>existing_model_df['existing_users'] = list(map(<br/>    lambda x, y: int(round(x*y)),<br/>    existing_model_df.model_existing_users,<br/>    existing_model_df.yoy<br/>))</span></pre><p id="ba6f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We've finished the estimations for the existing students as well. So, we are ready to merge both parts and get the result.</p><h1 id="6b1c" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Putting everything together</h1><h2 id="7773" class="qm op fq bf oq qn qo qp ot qq qr qs ow ns qt qu qv nw qw qx qy oa qz ra rb rc bk">First results</h2><p id="fc3a" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Now, we can combine all our previous estimations and see the final chart. For that, we need to convert data to the common format and add segments so that we can distinguish demand between new and existing students.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="41f5" class="py op fq pv b bg pz qa l qb qc"># existing segment<br/>existing_model_df = existing_model_df.reset_index()[['date', 'existing_users']]\<br/>  .rename(columns = {'existing_users': 'users'})<br/>existing_model_df['segment'] = 'existing'<br/><br/># new segment<br/>new_model_df = new_forecast_df.reset_index()[['cohort', 'new_users_model']]\<br/>  .rename(columns = {'cohort': 'date', 'new_users_model': 'users'})<br/>new_model_df = new_model_df[(new_model_df.date &gt;= '2024-03-31') <br/>  &amp; (new_model_df.date &lt; '2025-04-07')]<br/>new_model_df['users'] = new_model_df.users.map(lambda x: int(round(x)))<br/>new_model_df['segment'] = 'new'<br/><br/># combining everything<br/>demand_model_df = pd.concat([existing_model_df, new_model_df])<br/><br/># visualisation<br/>px.area(demand_model_df.pivot(index = 'date', <br/>          columns = 'segment', values = 'users').head(15)[['new', 'existing']], <br/>    title = '&lt;b&gt;Demand&lt;/b&gt;: modelling number of tests after launch',<br/>    labels = {'value': 'number of test'})</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rg"><img src="../Images/2ed261ca8aa5d7ae80ade41198fecebc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*936yFMSX5fwprJHOZraJpg.png"/></div></div></figure><p id="233b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We should expect around 2.5K tests for the first week after launch, mostly from existing customers. Then, within four weeks, we will review tests from existing users and will have only ~100–130 cases per week from new joiners.</p><p id="12b0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">That's wonderful. Now, we can share our estimations with colleagues so they can also plan their work.</p><h2 id="019e" class="qm op fq bf oq qn qo qp ot qq qr qs ow ns qt qu qv nw qw qx qy oa qz ra rb rc bk">What if we have demand constraints?</h2><p id="4169" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">In real life, you will often face the problem of capacity constraints when it's impossible to launch a new feature to 100% of customers. So, it’s time to learn how to deal with such situations.</p><p id="7307" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Suppose we've found out that our teachers can check only 1K tests each week. Then, we need to stagger our demand to avoid bad customer experience (when students need to wait for weeks to get their results).</p><p id="1a59" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Luckily, we can do it easily by rolling out tests to our existing customers in batches (or cohorts). We can switch the functionality on for all new joiners and X% of existing customers in the first week. Then, we can add another Y% of existing customers in the second week, etc. Eventually, we will evaluate all existing students and have ongoing demand only from new users.</p><p id="2e0e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's come up with a rollout plan without exceeding the 1K capacity threshold.</p><p id="4aeb" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Since we definitely want to launch it for all new students, let's start with them and add them to our plan. We will store all demand estimations by segments in the <code class="cx qe qf qg pv b">raw_demand_est_model_df</code> data frame and initialise them with our <code class="cx qe qf qg pv b">new_model_df</code> estimations that we got before.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="3a10" class="py op fq pv b bg pz qa l qb qc">raw_demand_est_model_df = new_model_df.copy()</span></pre><p id="fce7" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we can aggregate this data and calculate the remaining capacity.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="7b4b" class="py op fq pv b bg pz qa l qb qc">capacity = 1000<br/><br/>demand_est_model_df = raw_demand_est_model_df.pivot(index = 'date', <br/>    columns = 'segment', values = 'users')<br/><br/>demand_est_model_df['total_demand'] = demand_est_model_df.sum(axis = 1)<br/>demand_est_model_df['capacity'] = capacity<br/>demand_est_model_df['remaining_capacity'] = demand_est_model_df.capacity \<br/>    - demand_est_model_df.total_demand<br/><br/>demand_est_model_df.head()</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rh"><img src="../Images/259999a7d45437eadf0ac9b1dbabf9ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sZr0UtYGU-azhsDsjY3fTg.png"/></div></div></figure><p id="e476" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's put this logic into a separate function since we will need it to evaluate our estimations after each iteration.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="8c99" class="py op fq pv b bg pz qa l qb qc">import plotly.graph_objects as go<br/><br/>def get_total_demand_model(raw_demand_est_model_df, capacity = 1000):<br/>    demand_est_model_df = raw_demand_est_model_df.pivot(index = 'date', <br/>        columns = 'segment', values = 'users')<br/>    demand_est_model_df['total_demand'] = demand_est_model_df.sum(axis = 1)<br/>    demand_est_model_df['capacity'] = capacity<br/>    demand_est_model_df['remaining_capacity'] = demand_est_model_df.capacity \<br/>      - demand_est_model_df.total_demand<br/><br/>    tmp_df = demand_est_model_df.drop(['total_demand', 'capacity', <br/>        'remaining_capacity'], axis = 1)<br/>    fig = px.area(tmp_df,<br/>                 title = '&lt;b&gt;Demand vs Capacity&lt;/b&gt;',<br/>                  category_orders={'segment': ['new'] + list(sorted(filter(lambda x: x != 'new', tmp_df.columns)))},<br/>                 labels = {'value': 'tests'})<br/>    fig.add_trace(go.Scatter(<br/>        x=demand_est_model_df.index, y=demand_est_model_df.capacity, <br/>        name='capacity', line=dict(color='black', dash='dash'))<br/>    )<br/>    <br/>    fig.show()<br/>    return demand_est_model_df<br/><br/>demand_plan_df = get_total_demand_model(raw_demand_est_model_df)<br/>demand_plan_df.head()</span></pre><p id="2f71" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I've also added a chart to the output of this function that will help us to assess our results effortlessly.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq ri"><img src="../Images/67a0113dbc61d742f2dbf40c7e31ac44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W3ajKbh5TtERA3tSZFqh_g.png"/></div></div></figure><p id="9f9b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we can start planning the rollout for existing customers week by week.</p><p id="b10e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, let's transform our current demand model for existing students. I would like it to be indexed by the sequence number of weeks and show the 100% demand estimation. Then, I can smoothly get estimations for each batch by multiplying demand by weight and calculating the dates based on the launch date and week number.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="0a9a" class="py op fq pv b bg pz qa l qb qc">existing_model_df['num_week'] = list(range(existing_model_df.shape[0]))<br/>existing_model_df = existing_model_df.set_index('num_week')\<br/>    .drop(['date', 'segment'], axis = 1)<br/>existing_model_df.head()</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rj"><img src="../Images/736f165ce31047c1a725014b012a9c2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gvWuzN13Co87d3fe_TcMpQ.png"/></div></div></figure><p id="d677" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, for example, if we launch our evaluation test for 10% of random customers, then we expect to get 244 tests on the first week, 52 tests on the second week, 14 on the third, etc.</p><p id="33c0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I will be using the same estimations for all batches. I assume that all batches of the same size will produce the exact number of tests over the following weeks. So, I don't take into account any seasonal effects related to the launch date for each batch.</p><p id="3cd3" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This assumption simplifies your process quite a bit. And it's pretty reasonable in our case because we will do a rollout only within 4–5 weeks, and there are no significant seasonal effects during this period. However, if you want to be more accurate (or have considerable seasonality), you can build demand estimations for each batch by repeating our previous process.</p><p id="98b0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's start with the week of 31st March 2024. As we saw before, we have a spare capacity for 888 tests. If we launch our test to 100% of existing customers, we will get ~2.4K tests to check in the first week. So, we are ready to roll out only to a portion of all customers. Let's calculate it.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="cdc6" class="py op fq pv b bg pz qa l qb qc">cohort = '2024-03-31'<br/>demand_plan_df.loc[cohort].remaining_capacity/existing_model_df.iloc[0].users<br/># 0.3638</span></pre><p id="c0bc" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It's easier to operate with more round numbers, so let's round the number to a fraction of 5%. I've rounded the number down to have some buffer.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="cac2" class="py op fq pv b bg pz qa l qb qc">full_demand_1st_week = existing_model_df.iloc[0].users<br/>next_group_share = demand_plan_df.loc[cohort].remaining_capacity/full_demand_1st_week<br/>next_group_share = math.floor(20*next_group_share)/20<br/># 0.35</span></pre><p id="a68f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Since we will make several iterations, we need to track the percentage of existing customers for whom we’ve enabled the new feature. Also, it's worth checking whether we've already processed all the customers to avoid double-counting.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="8b74" class="py op fq pv b bg pz qa l qb qc">enabled_user_share = 0<br/><br/># if we can process more customers than are left, update the number<br/>if next_group_share &gt; 1 - enabled_user_share:<br/>    print('exceeded')<br/>    next_group_share = round(1 - enabled_user_share, 2)<br/><br/>enabled_user_share += next_group_share<br/># 0.35</span></pre><p id="102f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Also, saving our rollout plan in a separate variable will be helpful.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="e576" class="py op fq pv b bg pz qa l qb qc">rollout_plan = []<br/>rollout_plan.append(<br/>    {'launch_date': cohort, 'rollout_percent': next_group_share}<br/>)</span></pre><p id="68ab" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we need to estimate the expected demand from this batch. Launching tests for 35% of customers on 31st March will lead to some demand not only in the first week but also in the subsequent weeks. So, we need to calculate the total demand from this batch and add it to our plans.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="37f7" class="py op fq pv b bg pz qa l qb qc"># copy the model<br/>next_group_demand_df = existing_model_df.copy().reset_index()<br/><br/># calculate the dates from cohort + week number<br/>next_group_demand_df['date'] = next_group_demand_df.num_week.map(<br/>    lambda x: (datetime.datetime.strptime(cohort, '%Y-%m-%d') \<br/>        + datetime.timedelta(7*x))<br/>)<br/><br/># adjusting demand by weight<br/>next_group_demand_df['users'] = (next_group_demand_df.users * next_group_share).map(lambda x: int(round(x)))<br/><br/># labelling the segment<br/>next_group_demand_df['segment'] = 'existing, cohort = %s' % cohort<br/><br/># updating the plan<br/>raw_demand_est_model_df = pd.concat([raw_demand_est_model_df, <br/>    next_group_demand_df.drop('num_week', axis = 1)])</span></pre><p id="03e8" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we can re-use the function <code class="cx qe qf qg pv b">get_total_demand_mode</code>, which helps us analyse the current demand vs capacity balance.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="7132" class="py op fq pv b bg pz qa l qb qc">demand_plan_df = get_total_demand_model(raw_demand_est_model_df)<br/>demand_plan_df.head()</span></pre><p id="12a0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We are utilising most of our capacity for the first week. We still have some free resources, but it was our conscious decision to keep some buffer for sustainability. We can see that there’s almost no demand from this batch after 3 weeks.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rk"><img src="../Images/69099cf101463ab326d82459ced45d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N543anGQpfa2lcBzw__3Iw.png"/></div></div></figure><p id="0b6e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">With that, we've finished the first iteration and can move on to the following week — 4th April 2024. We can check an additional 706 cases during this week.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rl"><img src="../Images/3daf0fc5aa2f9e3b3152e00a51861ff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zWk3-xFlaoBHNiRT4onKbQ.png"/></div></div></figure><p id="4710" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can repeat the whole process for this week and move to the next one. We can iterate to the point when we launch our project to 100% of existing customers (<code class="cx qe qf qg pv b">enabled_user_share</code> equals to 1).</p><p id="aaa8" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can roll out our tests to all customers without breaching the 1K tests per week capacity constraint within just four weeks. In the end, we will have the following weekly forecast.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rm"><img src="../Images/ba0dd724bd732b52409020fe5c6e2b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9tC1Zuse_yNXIbhiJdfMOg.png"/></div></div></figure><p id="b4de" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can also look at the rollout plan we've logged throughout our simulations. So, we need to launch the test for randomly selected 35% of customers on the week of 31st March, then for the next 20% of customers next week, followed by 25% and 20% of existing users for the remaining two weeks. After that, we will roll out our project to all existing students.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="c6e7" class="py op fq pv b bg pz qa l qb qc">rollout_plan<br/># [{'launch_date': '2024-03-31', 'rollout_percent': 0.35},<br/># {'launch_date': '2024-04-07', 'rollout_percent': 0.2},<br/># {'launch_date': '2024-04-14', 'rollout_percent': 0.25},<br/># {'launch_date': '2024-04-21', 'rollout_percent': 0.2}]</span></pre><p id="61f1" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, congratulations. We now have a plan for how to roll out our feature sustainably.</p><h1 id="2c28" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Tracking students' performance over time</h1><p id="d03f" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">We've already done a lot to estimate demand. We've leveraged the idea of simulation by imitating the launch of our project a year ago, scaling it and assessing the consequences. So, it's definitely a simulation example.</p><p id="1e3b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">However, we mostly used the basic tools you use daily — some Pandas data wrangling and arithmetic operations. In the last part of the article, I would like to show you a bit more complex case where we will need to simulate the process for each customer independently.</p><p id="093c" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Product requirements often change over time, and it happened with our project. You, with a team, decided that it would be even better if you could allow your students to track progress over time (not only once at the very beginning). So, we would like to offer students to go through a performance test after each module (if more than one month has passed since the previous test) or if the student returned to the service after three months of absence.</p><p id="7257" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, the criteria for test assignments are pretty tricky. However, we can still use the same approach by looking at the data for the previous year. However, this time, we will need to look at each customer's behaviour and define at what point they would get a test.</p><p id="56a4" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We will take into account both new and existing customers since we want to estimate the effects of follow-up tests on all of them. We don't need any data before the launch because the first test will be assigned at the next active transaction, and all the history won't matter. So we can filter it out.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="f132" class="py op fq pv b bg pz qa l qb qc">sim_df = df[df.date &gt;= '2023-03-31']</span></pre><p id="91e8" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's also define a function that calculates the number of days between two date strings. It will be helpful for us in the implementation.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="2307" class="py op fq pv b bg pz qa l qb qc">def days_diff(date1, date2):<br/>    return (datetime.datetime.strptime(date2, '%Y-%m-%d')\<br/>        - datetime.datetime.strptime(date1, '%Y-%m-%d')).days</span></pre><p id="a45a" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's start with one user and discuss the logic with all the details. First, we will filter events related to this user and convert them into the list of dictionaries. It will be way easier for us to work with such data.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="b526" class="py op fq pv b bg pz qa l qb qc">user_id = 4861<br/>user_events = sim_df[sim_df.user_id == user_id]\<br/>    .sort_values('date')\<br/>    .to_dict('records')<br/><br/># [{'user_id': 4861, 'date': '2023-04-09', 'module': 'pre-A1', 'lesson_num': 8},<br/># {'user_id': 4861, 'date': '2023-04-16', 'module': 'pre-A1', 'lesson_num': 9},<br/># {'user_id': 4861, 'date': '2023-04-23', 'module': 'pre-A1', 'lesson_num': 10},<br/># {'user_id': 4861, 'date': '2023-04-23', 'module': 'pre-A1', 'lesson_num': 11},<br/># {'user_id': 4861, 'date': '2023-04-30', 'module': 'pre-A1', 'lesson_num': 12},<br/># {'user_id': 4861, 'date': '2023-05-07', 'module': 'pre-A1', 'lesson_num': 13}]</span></pre><p id="58d2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To simulate our product logic, we will be processing user events one by one and, at each point, checking whether the customer is eligible for the evaluation.</p><p id="0ca2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's discuss what variables we need to maintain to be able to tell whether the customer is eligible for the test or not. For that, let's recap all the possible cases when a customer might get a test:</p><ul class=""><li id="ac53" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">If there were no previous tests -&gt; we need to know whether they passed a test before.</li><li id="c1e1" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">If the customer finished the module and more than one month has passed since the previous test<strong class="nl fr"> -&gt;</strong> we need to know the last test date.</li><li id="8fd1" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">If the customer returns after three months <strong class="nl fr">-&gt;</strong> we need to store the date of the last lesson.</li></ul><p id="6b4d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To be able to check all these criteria, we can use only two variables: the last test date (<code class="cx qe qf qg pv b">None</code> if there was no test before) and the previous lesson date. Also, we will need to store all the generated tests to calculate them later. Let's initialise all the variables.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="e47d" class="py op fq pv b bg pz qa l qb qc">tmp_gen_tests = []<br/>last_test_date = None<br/>last_lesson_date = None</span></pre><p id="d6aa" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we need to iterate by event and check the criteria.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="8772" class="py op fq pv b bg pz qa l qb qc">for rec in user_events:<br/>  pass</span></pre><p id="0650" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let's go through all our criteria, starting from the initial test. In this case, <code class="cx qe qf qg pv b">last_test_date</code> will be equal to <code class="cx qe qf qg pv b">None</code>. It's important for us to update the <code class="cx qe qf qg pv b">last_test_date</code> variable after "assigning" the test.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="8699" class="py op fq pv b bg pz qa l qb qc">if last_test_date is None: # initial test<br/>    last_test_date = rec['date']<br/>    # TBD saving the test info</span></pre><p id="5705" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In the case of the finished module, we need to check that it's the last lesson in the module and that more than 30 days have passed.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="ab96" class="py op fq pv b bg pz qa l qb qc">if (rec['lesson_num'] == 100) and (days_diff(last_test_date, rec['date']) &gt;= 30): <br/>    last_test_date = rec['date']<br/>    # TBD saving the test info</span></pre><p id="ed30" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The last case is that the customer hasn't used our service for three months.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="0360" class="py op fq pv b bg pz qa l qb qc">if (days_diff(last_lesson_date, rec['date']) &gt;= 30): <br/>    last_test_date = rec['date']<br/>    # TBD saving the test info</span></pre><p id="8bbe" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Besides, we need to update the <code class="cx qe qf qg pv b">last_lesson_date</code> at each iteration to keep it accurate.</p><p id="d415" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We've discussed all the building blocks and are ready to combine them and do simulations for all our customers.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="8ce1" class="py op fq pv b bg pz qa l qb qc">import tqdm<br/>tmp_gen_tests = []<br/><br/>for user_id in tqdm.tqdm(sim_raw_df.user_id.unique()):<br/>    # initialising variables<br/>    last_test_date = None<br/>    last_lesson_date = None<br/><br/>    for rec in sim_raw_df[sim_raw_df.user_id == user_id].to_dict('records'):<br/>        # initial test<br/>        if last_test_date is None: <br/>            last_test_date = rec['date']<br/>            tmp_gen_tests.append(<br/>                {<br/>                    'user_id': rec['user_id'],<br/>                    'date': rec['date'],<br/>                    'trigger': 'initial test'<br/>                }<br/>            )<br/>        # finish module<br/>        elif (rec['lesson_num'] == 100) and (days_diff(last_test_date, rec['date']) &gt;= 30): <br/>            last_test_date = rec['date']<br/>            tmp_gen_tests.append(<br/>                {<br/>                    'user_id': rec['user_id'],<br/>                    'date': rec['date'],<br/>                    'trigger': 'finished module'<br/>                })<br/>        # reactivation<br/>        elif (days_diff(last_lesson_date, rec['date']) &gt;= 92):<br/>            last_test_date = rec['date']<br/>            tmp_gen_tests.append(<br/>                {<br/>                    'user_id': rec['user_id'],<br/>                    'date': rec['date'],<br/>                    'trigger': 'reactivation'<br/>                })<br/>        last_lesson_date = rec['date']</span></pre><p id="66b8" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we can aggregate this data. Since we are again using the previous year's data, I will adjust the number by ~80% YoY, as we've estimated before.</p><pre class="ms mt mu mv mw pu pv pw bp px bb bk"><span id="a7e1" class="py op fq pv b bg pz qa l qb qc">exist_model_upd_stats_df = exist_model_upd.pivot_table(<br/>    index = 'date', columns = 'trigger', values = 'user_id', <br/>    aggfunc = 'nunique'<br/>).fillna(0)<br/><br/>exist_model_upd_stats_df = exist_model_upd_stats_df\<br/>    .map(lambda x: int(round(x * 1.8)))</span></pre><p id="a953" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We got quite a similar estimation for the initial test. In this case, the "initial test" segment equals the sum of new and existing demand in our previous estimations.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rn"><img src="../Images/bc6a32d76bbf1b88a6a9de80fac98f1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*thtJagM8jub9VLsnB6TFHA.png"/></div></div></figure><p id="703d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, looking at other segments is way more interesting since they will be incremental to our previous calculations. We can see around 30–60 cases per week from customers who finished modules starting in May.</p><p id="e0b7" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">There will be almost no cases of reactivation. In our simulation, we got 4 cases per year in total.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq ri"><img src="../Images/9c2a0f348fed3e36d1efb42886f7b790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gpV1x8KPKaoT2yN3xlWlmw.png"/></div></div></figure><p id="a50b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Congratulations! Now the case is solved, and we’ve found a nice approach that allows us to make precise estimations without advanced math and with only simulation. You can use similar</p><blockquote class="pq pr ps"><p id="82ba" class="nj nk pt nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">You can find the full code for this example on <a class="af on" href="https://github.com/miptgirl/miptgirl_medium/blob/main/simulations/student_activities_model.ipynb" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p></blockquote><h1 id="394a" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Summary</h1><p id="e442" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Let me quickly recap what we've discussed today:</p><ul class=""><li id="d59a" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh bk">The main idea of computer simulation is imitation based on your data.</li><li id="1366" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">In many cases, you can reframe the problem from predicting the future to using the data you already have and simulating the process you're interested in. So, this approach is quite powerful.</li><li id="5768" class="nj nk fq nl b go oi nn no gr oj nq nr ns ok nu nv nw ol ny nz oa om oc od oe of og oh bk">In this article, we went through an end-to-end example of scenario estimations. We've seen how to structure complex problems and split them into a bunch of more defined ones. We've also learned to deal with constraints and plan a gradual rollout.</li></ul><blockquote class="pq pr ps"><p id="1b37" class="nj nk pt nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Thank you a lot for reading this article. If you have any follow-up questions or comments, please leave them in the comments section.</p></blockquote><h1 id="9c5d" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Reference</h1><p id="356a" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk"><em class="pt">All the images are produced by the author unless otherwise stated.</em></p></div></div></div></div>    
</body>
</html>