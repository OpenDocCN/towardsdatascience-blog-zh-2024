# å­¦ä¼šé—å¿˜ï¼šä¸ºä»€ä¹ˆæ•°æ®ç§‘å­¦å®¶å’Œ AI ä»ä¸šè€…åº”è¯¥ç†è§£æœºå™¨é—å¿˜

> åŸæ–‡ï¼š[`towardsdatascience.com/learning-to-unlearn-why-data-scientists-and-ai-practitioners-should-understand-machine-unlearning-866af9e5d712?source=collection_archive---------8-----------------------#2024-08-22`](https://towardsdatascience.com/learning-to-unlearn-why-data-scientists-and-ai-practitioners-should-understand-machine-unlearning-866af9e5d712?source=collection_archive---------8-----------------------#2024-08-22)

![](img/b325affbd7356ef4d8a853261870be17.png)

å›¾ç‰‡ç”± [Sue Winston](https://unsplash.com/@winniepix?utm_source=medium&utm_medium=referral) æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

## æ¢è®¨éšç§ä¸ AI çš„äº¤é›†ï¼Œå¹¶é€šè¿‡ä½¿ç”¨ SISA æŠ€æœ¯åº”ç”¨äºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰çš„ Python ç¤ºä¾‹ï¼ŒæŒ‡å¯¼å¦‚ä½•å»é™¤å•ä¸ªæ•°æ®ç‚¹å¯¹ AI è®­ç»ƒçš„å½±å“ã€‚

[](https://medium.com/@raul.vizcarrach?source=post_page---byline--866af9e5d712--------------------------------)![Raul Vizcarra Chirinos](https://medium.com/@raul.vizcarrach?source=post_page---byline--866af9e5d712--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--866af9e5d712--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--866af9e5d712--------------------------------) [Raul Vizcarra Chirinos](https://medium.com/@raul.vizcarrach?source=post_page---byline--866af9e5d712--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--866af9e5d712--------------------------------) Â·é˜…è¯»æ—¶é—´ï¼š20 åˆ†é’ŸÂ·2024 å¹´ 8 æœˆ 22 æ—¥

--

æˆªè‡³æœ¬æ–‡æ’°å†™ä¹‹æ—¶ï¼Œæ ¹æ®[ä¸–ç•Œé“¶è¡Œæ•°æ®](https://data.worldbank.org/country)ï¼Œå…¨çƒè¶…è¿‡ 32%çš„äººå£ï¼ˆå¤§çº¦ 80 äº¿äººï¼‰å¹´é¾„åœ¨äºŒåå²ä»¥ä¸‹ã€‚è¿™æ„å‘³ç€å¤§çº¦ 26 äº¿äººå‡ºç”Ÿåœ¨ç¤¾äº¤åª’ä½“æ—¶ä»£ï¼Œè€Œä¸”å‡ ä¹å¯ä»¥ç¡®å®šï¼Œä»–ä»¬å‡ ä¹æ‰€æœ‰çš„ç”Ÿæ´»éƒ½å·²ç»åœ¨çº¿è®°å½•ï¼Œç”±ä»–ä»¬çš„çˆ¶æ¯ã€äº²å¯†åœˆå­ï¼Œæœ€ç»ˆå¯èƒ½æ˜¯ä»–ä»¬è‡ªå·±*(å–å†³äºä»–ä»¬å¯¹ç¤¾äº¤åª’ä½“çš„ä¾èµ–ä»¥åŠä»–ä»¬çš„ç½‘ç»œ)*ã€‚å¦‚æœå†åŠ ä¸ŠäºŒååˆ°äº”åå²ä¹‹é—´çš„äººç¾¤ï¼Œæˆ‘ä»¬å°±æœ‰å¦å¤– 33 äº¿äººï¼Œåœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œä»–ä»¬çš„ç”Ÿæ´»çš„ä¸€éƒ¨åˆ†å·²ç»åœ¨çº¿è®°å½•ï¼Œæ¶µç›–ä¸åŒçš„æ¥æºå’Œæ ¼å¼*(å¦‚å›¾ç‰‡ã€è¯„è®ºã€è§†é¢‘ç­‰)*ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®è¶…è¿‡äº”åå²çš„äººç¾¤è¿›è¡Œè°ƒæ•´ï¼Œæˆ–è€…è€ƒè™‘åˆ°å¹¶éæ¯ä¸ªäººéƒ½æœ‰äº’è”ç½‘æ¥å…¥æˆ–ä½¿ç”¨äº’è”ç½‘*ï¼ˆ*[*æ ¹æ®ä¸–ç•Œé“¶è¡Œ 2021 å¹´ä¼°ç®—ï¼Œè‡³å°‘æœ‰ 35%çš„äººæ— æ³•æ¥å…¥æˆ–ä½¿ç”¨äº’è”ç½‘*](https://data.worldbank.org/indicator/IT.NET.USER.ZS?locations=ET%2F)*)*ï¼Œä½†æˆ‘ç›¸ä¿¡ä½ æ˜ç™½æˆ‘çš„æ„æ€ã€‚ä»Šå¤©çš„æ•°å­—ä¸–ç•Œä¸­ï¼Œç¡®å®æœ‰å¤§é‡çš„æˆ‘ä»¬ç”Ÿæ´»çš„è®°å½•ã€‚

å¦ä¸€ä¸ªé«˜æ¦‚ç‡æˆ–ä¹Ÿè®¸æ˜¯ç¡®å®šçš„*ï¼ˆ*[*æˆ‘ä»¬å¯ä»¥å†é—®ä¸€ä¸‹ OpenAI çš„ CTO*](https://youtu.be/mAUpxN-EIgU?feature=shared)*ğŸ™„)*æ˜¯ï¼Œè¿™äº›æ•°æ®ä¸­çš„å¤§éƒ¨åˆ†å·²ç»è¢«ç”¨æ¥è®­ç»ƒä»Šå¤©éƒ¨ç½²çš„æ‰€æœ‰â€œæœ€å…ˆè¿›â€æ¨¡å‹ï¼Œä»å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆ°å¯ä»¥å¤„ç†å›¾åƒã€è§†é¢‘æˆ–æ–‡æœ¬ç­‰ä¿¡æ¯çš„å¤šæ¨¡æ€ AI æ¨¡å‹ã€‚åœ¨è¿™ç§èƒŒæ™¯ä¸‹ï¼Œå½“è°ˆåˆ°æ•°æ®ã€æŠ€æœ¯å’Œéšç§æ—¶ï¼Œæˆ‘ä»¬å¸¸å¸¸çœ‹åˆ°ä¸¤æ–¹åœ¨å¯»æ‰¾ä¸­é—´ç«‹åœºçš„è¿‡ç¨‹ä¸­å±•å¼€æ–—äº‰ã€‚ä¸€æ–¹æ˜¯æ¯ä¸ªäººä¸æŠ€æœ¯ä¹‹é—´çš„ç¤¾ä¼šå¥‘çº¦ï¼Œæˆ‘ä»¬æ„¿æ„ä¸ºè·å¾—æŠ€æœ¯å¸¦æ¥çš„åˆ©ç›Šè€Œäº¤æ¢éƒ¨åˆ†æ•°æ®æƒåˆ©ã€‚å¦ä¸€æ–¹é¢ï¼Œæ˜¯å¿…é¡»åˆ’å®šç•Œé™çš„é—®é¢˜ï¼Œæ­£å¦‚è¿™ä¸€ç«‹åœºçš„æ”¯æŒè€…æ‰€è¯´ï¼Œ***â€œä»…ä»…å› ä¸ºæ•°æ®æ˜¯å¯è®¿é—®çš„ï¼Œå¹¶ä¸æ„å‘³ç€å®ƒå¯ä»¥è‡ªç”±æ”¶é›†å’Œä½¿ç”¨â€***ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨åœ¨è®¨è®º**äººå·¥æ™ºèƒ½ä¸­çš„éšç§**æ—¶å‡ºç°çš„ä¸€äº›æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¯¹**æœºå™¨é—å¿˜**å’Œ**SISA è®­ç»ƒæ–¹æ³•ï¼ˆåˆ†ç‰‡ã€éš”ç¦»ã€åˆ‡ç‰‡å’Œèšåˆè®­ç»ƒï¼‰**çš„ç®€è¦æ¦‚è¿°ï¼ŒSISA æ˜¯ä¸€ç§æœ€è¿‘å¼€å‘çš„æœºå™¨é—å¿˜æ¡†æ¶ï¼Œæ—¨åœ¨å¸®åŠ©ç®¡ç†æˆ–å‡å°‘ä¸ªä½“æ•°æ®ç‚¹åœ¨ AI è®­ç»ƒä¸­çš„å½±å“ï¼Œå¹¶è§£å†³ä¸â€œ**è¢«é—å¿˜æƒ**â€ç›¸å…³çš„åˆè§„æ€§æŒ‘æˆ˜ã€‚

![](img/87a2b54cfa5c87c3ce817b3778519984.png)

ç…§ç‰‡ç”±[Tingey Injury Law Firm](https://unsplash.com/@tingeyinjurylawfirm?utm_source=medium&utm_medium=referral)æä¾›ï¼Œæ¥æºäº[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

# å£ä¸­ä½è¯­çš„ï¼Œå°†åœ¨å±‹é¡¶ä¸Šå¤§å£°å®£å‘Šã€‚

å†å²ä¸Šæœ€æ—©å€¡å¯¼**éšç§æƒ**çš„å‡ºç‰ˆç‰©ä¹‹ä¸€æ˜¯ç”±ä¸¤ä½ç¾å›½å¾‹å¸ˆå¡ç¼ªå°”Â·DÂ·æ²ƒä¼¦å’Œè·¯æ˜“æ–¯Â·å¸ƒå…°ä»£æ–¯äº 1890 å¹´ä»£å‘è¡¨çš„ä¸€ç¯‡æ–‡ç« ã€‚è¯¥æ–‡ç« æ ‡é¢˜ä¸º[***éšç§æƒ***](https://www.cs.cornell.edu/~shmat/courses/cs5436/warren-brandeis.pdf)ï¼Œæ—¨åœ¨æé«˜äººä»¬å¯¹æœªç»æˆæƒçš„ç…§ç‰‡å’Œæ—©æœŸæŠ¥çº¸ä¼ä¸šå½±å“çš„è®¤è¯†ï¼Œä»–ä»¬è®¤ä¸ºè¿™äº›å½±å“å°†å…«å¦å˜æˆäº†ä¸€ç§å•†å“ï¼Œä¾µå®³äº†ä¸ªäººäº«å—ç”Ÿæ´»çš„æƒåˆ©ï¼Œå³**è¢«ç‹¬ç«‹å¯¹å¾…çš„æƒåˆ©**ã€‚

> ä¸ªäººåœ¨èº«ä½“å’Œè´¢äº§ä¸Šçš„å®Œå…¨ä¿æŠ¤æ˜¯ä¸æ™®é€šæ³•åŒæ ·å¤è€çš„åŸåˆ™ï¼›ä½†éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæœ‰æ—¶éœ€è¦é‡æ–°å®šä¹‰è¿™ç§ä¿æŠ¤çš„ç¡®åˆ‡æ€§è´¨å’ŒèŒƒå›´ã€‚â€¦.è¿‘æœŸçš„å‘æ˜å’Œå•†ä¸šæ–¹æ³•æé†’æˆ‘ä»¬ï¼Œå¿…é¡»é‡‡å–ä¸‹ä¸€æ­¥æªæ–½æ¥ä¿æŠ¤ä¸ªäººï¼Œå¹¶ä¿éšœä¸ªä½“çš„æƒåˆ©ï¼Œæ­£å¦‚åº“åˆ©æ³•å®˜æ‰€ç§°çš„â€œè¢«ç‹¬ç«‹å¯¹å¾…çš„æƒåˆ©â€ï¼ˆå¡ç¼ªå°”Â·DÂ·æ²ƒä¼¦ï¼Œè·¯æ˜“æ–¯Â·å¸ƒå…°ä»£æ–¯ï¼Œ1890 å¹´ï¼‰ã€‚

è‡ªã€Šéšç§æƒã€‹ä¸€ä¹¦å‘å¸ƒä»¥æ¥ï¼Œæ—¶ä»£å·²ç»å‘ç”Ÿäº†å˜åŒ–ï¼Œä½†æ²ƒä¼¦å’Œè·¯æ˜“æ–¯Â·å¸ƒå…°ä»£æ–¯åœ¨ä¸€ä»¶äº‹ä¸Šå¹¶æ²¡æœ‰é”™ï¼›**æŠ€æœ¯ã€æ”¿æ²»ã€ç¤¾ä¼šå’Œç»æµçš„å˜é©ä¸æ–­æŒ‘æˆ˜ç°æœ‰æˆ–æ–°å…´çš„æƒåˆ©**ã€‚å¯¹æ­¤ï¼Œæ™®é€šæ³•åº”å§‹ç»ˆä¿æŒå¼€æ”¾çš„æ€åº¦ï¼Œä»¥åº”å¯¹ç¤¾ä¼šçš„æ–°éœ€æ±‚ï¼Œè®¤è¯†åˆ°ç¤¾ä¼šçš„ä¿æŠ¤ä¸»è¦é€šè¿‡æ‰¿è®¤ä¸ªäººçš„æƒåˆ©æ¥å®ç°ã€‚

ä»é‚£æ—¶èµ·ï¼Œéšç§å¸¸å¸¸ä¸**ä¼ ç»Ÿçš„åšæ³•**ç›¸è”ç³»ï¼Œå³**ä¿æŠ¤æˆ‘ä»¬å…³å¿ƒå’Œæƒ³è¦éšè—çš„ä¸œè¥¿ï¼Œä¿æŒå…¶ä¸ä¸ºå…¬ä¼—æ‰€è§ï¼Œå¹¶æ§åˆ¶å…¶è®¿é—®å’Œä½¿ç”¨**ã€‚ä½†åŒæ ·çš„äº‹å®æ˜¯ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œéšç§çš„è¾¹ç•Œè¢«é¢ è¦†æ€§æŠ€æœ¯æ‰€æŒ‘æˆ˜ï¼›æ‘„å½±å’Œè§†é¢‘è®¾å®šäº†æ–°çš„è¾¹ç•Œï¼Œæœ€è¿‘åˆ™æ˜¯æ•°æ®çš„æŒ‡æ•°å¢é•¿ã€‚ç„¶è€Œï¼ŒåŸºäºæ•°æ®çš„æŠ€æœ¯ä¸ä»…å½±å“äº†æ•°æ®åˆè§„çš„æ ¼å±€ï¼›å®ƒä»¬è¿˜å¯¹æˆ‘ä»¬çš„ä¿¡ä»°å’Œä¹ æƒ¯äº§ç”Ÿäº†ä¸€äº›å½±å“ã€‚ç¤¾äº¤åª’ä½“å¹³å°æˆ–è¶…çº§åº”ç”¨å°±æ˜¯ä¸€ä¸ªä¾‹å­ï¼Œåœ¨è¿™äº›å¹³å°ä¸Šï¼Œæˆ‘ä»¬æ„¿æ„ä¸ºäº†æŠ€æœ¯å¸¦æ¥çš„å¥½å¤„è€Œäº¤æ¢éƒ¨åˆ†æ•°æ®éšç§ã€‚è¿™æ„å‘³ç€**è¯­å¢ƒå¾ˆé‡è¦**ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œåˆ†äº«æˆ‘ä»¬çš„æ•æ„Ÿä¿¡æ¯æ›´å¤šä¾èµ–äºåƒä¿¡ä»»è¿™æ ·çš„ä»·å€¼è§‚ï¼Œè€Œä¸ä¸€å®šæ˜¯è€ƒè™‘éšç§æ³„éœ²ã€‚

> *â€œæ•°æ®ä¸ä»…ä»…æ˜¯â€˜ç§å¯†â€™æˆ–â€˜éç§å¯†â€™ã€â€˜æ•æ„Ÿâ€™æˆ–â€˜éæ•æ„Ÿâ€™çš„ã€‚è¯­å¢ƒå¾ˆé‡è¦ï¼Œç¤¾ä¼šçš„è§„èŒƒæ€§ä»·å€¼è§‚ä¹Ÿæ˜¯...â€*ï¼ˆ[*ã€Šé«˜çº§ AI åŠ©æ‰‹çš„ä¼¦ç†ã€‹. Google DeepMind 2024*](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/ethics-of-advanced-ai-assistants/the-ethics-of-advanced-ai-assistants-2024-i.pdf)ï¼‰

**è¯­å¢ƒä¸éšç§ä¹‹é—´çš„å…³ç³»**æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æ€ç»´æ–¹å‘ï¼Œè¢«ç§°ä¸ºä¿¡æ¯éšç§æ¨¡å‹ã€‚

**â€œæƒ…å¢ƒå®Œæ•´æ€§â€ *(***[*Nissenbaum, 2004*](https://digitalcommons.law.uw.edu/cgi/viewcontent.cgi?article=4450&context=wlr)*)***.** å®ƒæŒ‡å‡ºï¼Œåœ¨å‘é€è€…å’Œæ¥æ”¶è€…ä¹‹é—´çš„æ¯ä¸€æ¬¡ä¿¡æ¯äº¤æ¢æˆ–æµåŠ¨ä¸­ï¼Œéƒ½æœ‰ç¤¾ä¼šè§„åˆ™æ¥è§„èŒƒå®ƒã€‚ç†è§£è¿™äº›è§„åˆ™å¯¹ç¡®ä¿ä¿¡æ¯äº¤æ¢å¾—åˆ°é€‚å½“ç›‘ç®¡è‡³å…³é‡è¦ã€‚

![](img/9aebf190562c633ed1345dca69ae20b6.png)

å›¾ 01 æ¥æºï¼šä½œè€…è‡ªåˆ›

ä¸€ä¸ªæ¸…æ™°çš„ä¾‹å­å¯èƒ½æ˜¯ï¼Œä¾‹å¦‚ï¼Œå…³äºæˆ‘å­©å­åœ¨å­¦æ ¡è¡¨ç°çš„ä¿¡æ¯ã€‚å¦‚æœä¸€ä½è€å¸ˆå°†æˆ‘å­©å­çš„æˆç»©è®°å½•ä¸å…¶ä»–å®¶é•¿æˆ–æ ¡å¤–é™Œç”Ÿäººå…±äº«ï¼Œæˆ‘å¯èƒ½ä¼šè®¤ä¸ºè¿™æ˜¯éšç§ä¾µçŠ¯ã€‚ç„¶è€Œï¼Œå¦‚æœåŒæ ·çš„è€å¸ˆå°†è¿™äº›ä¿¡æ¯ä¸å…¶ä»–æ•™æˆ‘å­©å­çš„è€å¸ˆå…±äº«ï¼Œä»¥ä¾¿äº¤æµç»éªŒå¹¶æ”¹å–„æˆ‘å­©å­çš„å­¦æ ¡è¡¨ç°ï¼Œæˆ‘å¯èƒ½å°±ä¸ä¼šé‚£ä¹ˆæ‹…å¿ƒï¼Œåè€Œä¼šä¾èµ–äºä¿¡ä»»ã€ä»·å€¼è§‚å’Œè€å¸ˆçš„è‰¯å¥½åˆ¤æ–­ã€‚å› æ­¤ï¼Œ**åœ¨æƒ…å¢ƒå®Œæ•´æ€§æ–¹æ³•ä¸‹**ï¼Œéšç§ä¸å†ä»…ä»…è¢«çœ‹ä½œæ˜¯â€œç‹¬ç«‹ç”Ÿæ´»çš„æƒåˆ©â€è¿™ä¸€åƒµåŒ–çš„çŠ¶æ€ã€‚ç›¸åï¼Œ**é‡è¦çš„æ˜¯ä¿¡æ¯æµåŠ¨åº”å½“å¾—åˆ°é€‚å½“çš„ç›‘ç®¡**ï¼Œè€ƒè™‘åˆ°å…¶ä¸­çš„èƒŒæ™¯å’Œæ²»ç†è§„èŒƒï¼Œä»¥ç•Œå®šå…¶è¾¹ç•Œã€‚éšç§ä½œä¸ºä¸€é¡¹åŸºæœ¬æƒåˆ©ä¸åº”æ”¹å˜ï¼Œä½†å¯ä»¥é‡æ–°æ€è€ƒã€‚

> **éšç§çš„å›ºæœ‰æ¦‚å¿µæ˜¯å¦åº”è¯¥ä¿æŒä¸å˜ï¼Ÿè¿˜æ˜¯æˆ‘ä»¬åº”è¯¥é¦–å…ˆç†è§£æ”¯é…ä¿¡æ¯æµåŠ¨çš„ç¤¾ä¼šè§„åˆ™ï¼Ÿ**

éšç€äººå·¥æ™ºèƒ½ç»§ç»­å¡‘é€ æœªæ¥ï¼Œè¿™ä¸€é‡æ–°æ€è€ƒæŒ‘æˆ˜ç€æˆ‘ä»¬è€ƒè™‘æ˜¯å¦éœ€è¦é€‚åº”ç°æœ‰çš„æƒåˆ©ï¼Œæˆ–å¯èƒ½å¼•å…¥æ–°çš„æ•°å­—æƒåˆ©ã€‚

# æœºå™¨â€œé—å¿˜â€

æ— è®ºä½ æ˜¯å°†éšç§è§†ä¸ºä¸€ä¸ªåƒµåŒ–çš„æ¦‚å¿µï¼Œè¿˜æ˜¯è€ƒè™‘æƒ…å¢ƒå®Œæ•´æ€§æ–¹æ³•ï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬å¤§å¤šæ•°äººéƒ½ä¼šåŒæ„ï¼Œæˆ‘ä»¬æ‰€æœ‰äººéƒ½åº”å½“äº«æœ‰å…¬å¹³å¤„ç†ä¸ªäººæ•°æ®çš„æƒåˆ©ï¼Œä¸”åœ¨éœ€è¦æ—¶èƒ½è·å¾—æˆ‘ä»¬çš„åŒæ„ï¼Œå¹¶æœ‰æƒçº æ­£æˆ–åˆ é™¤æ•°æ®ã€‚

å°½ç®¡ã€Šé€šç”¨æ•°æ®ä¿æŠ¤æ¡ä¾‹ã€‹ï¼ˆGDPRï¼‰ä¿ƒè¿›äº†æ•°æ®ä¸éšç§çš„å…±å­˜ï¼Œ**åœ¨ç›‘ç®¡æ¡†æ¶ä¸­å¹³è¡¡éšç§ä¸äººå·¥æ™ºèƒ½ä»ç„¶æ˜¯ä¸€ä¸ªä¸åŒçš„æŒ‘æˆ˜**ã€‚å°½ç®¡æˆ‘ä»¬å¯ä»¥ä»æ•°æ®é›†åˆ é™¤æˆ–ä¿®æ”¹æ•æ„Ÿæ•°æ®ï¼Œä½†åœ¨ AI æ¨¡å‹ä¸­è¿™æ ·åšè¦å¤æ‚å¾—å¤šã€‚AI æ¨¡å‹å¹¶éæ¯å¤©éƒ½é‡æ–°è®­ç»ƒï¼Œè€Œä¸”åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œéœ€è¦æ•°æœˆæ—¶é—´æ‰èƒ½ç¡®ä¿å…¶å¯é æ€§ã€‚ä¸ºäº†è§£å†³åœ¨ AI æ¨¡å‹ä¸­é€‰æ‹©æ€§åœ°åˆ é™¤ç‰¹å®šè®­ç»ƒæ•°æ®ç‚¹ï¼ˆ*åŠå…¶å½±å“*ï¼‰è€Œä¸æ˜¾è‘—ç‰ºç‰²æ¨¡å‹æ€§èƒ½çš„ä»»åŠ¡ï¼Œåƒ**æœºå™¨â€œé—å¿˜â€**è¿™æ ·çš„æŠ€æœ¯åº”è¿è€Œç”Ÿï¼Œå¹¶æ­£åœ¨è¿›è¡Œç ”ç©¶ï¼Œä»¥å¯»æ‰¾è§£å†³éšç§é—®é¢˜çš„æ–¹æ¡ˆï¼Œéµå®ˆå¯èƒ½å¼ºåˆ¶å®æ–½çš„æ³•è§„ï¼Œå¹¶ä¿æŠ¤ç”¨æˆ·åˆ é™¤æˆ–æ›´æ­£æ•°æ®çš„æ³•å®šæƒåˆ©ã€‚

ä¸å¯ä»¥è¿½æº¯åˆ°ä¸€ç™¾å¤šå¹´å‰çš„éšç§æ”¿ç­–ç ”ç©¶ç›¸æ¯”ï¼Œæœºå™¨â€œé—å¿˜â€æ˜¯ä¸€ä¸ªç›¸å¯¹è¾ƒæ–°çš„é¢†åŸŸï¼Œæœ€åˆçš„ç ”ç©¶å¤§çº¦å‡ºç°åœ¨ 10 å¹´å‰ï¼ˆ[Y. Cao å’Œ J. Yang, 2015](https://www.ieee-security.org/TC/SP2015/papers-archived/6949a463.pdf)ï¼‰ã€‚

***é‚£ä¹ˆæˆ‘ä»¬ä¸ºä»€ä¹ˆè¦å…³æ³¨æœºå™¨é—å¿˜å‘¢ï¼Ÿ*** æ— è®ºä½ æ˜¯æ¨åŠ¨äººå·¥æ™ºèƒ½è¾¹ç•Œçš„ AI ç ”ç©¶å‘˜ï¼Œè¿˜æ˜¯åœ¨ä¸ºç»ˆç«¯ç”¨æˆ·ä¼˜åŒ– AI è§£å†³æ–¹æ¡ˆçš„ä»ä¸šè€…ï¼Œä»¥ä¸‹æ˜¯å°†æœºå™¨é—å¿˜æŠ€æœ¯åº”ç”¨äºæœºå™¨å­¦ä¹ æµç¨‹çš„ä¸€äº›å¥½ç†ç”±ï¼š

Â· **è¢«é—å¿˜æƒï¼ˆRTBFï¼‰ï¼š** å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæœ€å…ˆè¿›çš„åŸºç¡€æ¨¡å‹ä»¥å¤æ‚ä¸”å¿«é€Ÿå‘å±•çš„æ–¹å¼å¤„ç†æ•°æ®ã€‚å¦‚åŒã€Šé€šç”¨æ•°æ®ä¿æŠ¤æ¡ä¾‹ã€‹ï¼ˆGDPRï¼‰æ‰€è§ï¼Œç”¨æˆ·è¯·æ±‚**åˆ é™¤æƒ**å¹¶å°†å…¶çº³å…¥ AI ç›¸å…³æ³•è§„çš„åˆ¶å®šï¼Œå·²åªæ˜¯æ—¶é—´é—®é¢˜ã€‚è¿™å°†è¦æ±‚ä»»ä½•ä½¿ç”¨ AI çš„å…¬å¸è°ƒæ•´æµç¨‹ä»¥ç¬¦åˆè¿™äº›è§„å®šï¼Œå¹¶å“åº”ç”¨æˆ·è¦æ±‚ï¼Œä»é¢„è®­ç»ƒæ¨¡å‹ä¸­ç§»é™¤ä¸ªäººæ•°æ®ã€‚

Â· **éé›¶å½±å“ï¼š** å¦‚ä»Šï¼Œ**å·®åˆ†éšç§**ç­‰æ¡†æ¶çš„å­˜åœ¨æ˜¯ä¸ºäº†é€šè¿‡å¼•å…¥å™ªéŸ³æ¥ç¡®ä¿å¯¹æ•æ„Ÿæ•°æ®é›†çš„ä¸€å®šéšç§ä¿æŠ¤ï¼Œä»è€Œéšè—å•ä¸ªæ•°æ®ç‚¹çš„è´¡çŒ®ã€‚ç„¶è€Œï¼Œè™½ç„¶å·®åˆ†éšç§æœ‰åŠ©äºå‡è½»å•ä¸ªæ•°æ®ç‚¹çš„å½±å“ï¼Œä½†è¿™ç§åŠªåŠ›ä»ç„¶æ˜¯â€œ**éé›¶çš„**â€ã€‚è¿™æ„å‘³ç€ï¼Œç›®æ ‡æ•°æ®ç‚¹ä»ç„¶æœ‰å¯èƒ½å¯¹æ¨¡å‹äº§ç”ŸæŸç§å½±å“ã€‚åœ¨éœ€è¦**å®Œå…¨åˆ é™¤**æ•°æ®ç‚¹çš„æƒ…å†µä¸‹ï¼Œå¯èƒ½éœ€è¦é‡‡å–ä¸åŒçš„å·®åˆ†éšç§æ–¹æ³•ã€‚

Â· **æ€§èƒ½ä¼˜åŒ–ï¼š** ä¼—æ‰€å‘¨çŸ¥ï¼ŒåŸºç¡€æ¨¡å‹éœ€è¦å¤§é‡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¿™éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚**ä»å¤´å¼€å§‹é‡æ–°è®­ç»ƒå®Œæ•´æ¨¡å‹ä»¥åˆ é™¤å•ä¸ªæ•°æ®ç‚¹å¯èƒ½æ˜¯æœ€æœ‰æ•ˆçš„æ–¹å¼**ï¼Œä»¥æ¶ˆé™¤è¯¥æ•°æ®ç‚¹åœ¨æ¨¡å‹ä¸­çš„ä»»ä½•å½±å“ï¼Œ**ä½†è¿™å¹¶ä¸æ˜¯æœ€é«˜æ•ˆçš„åšæ³•** *(æ¨¡å‹éœ€è¦é¢‘ç¹é‡æ–°è®­ç»ƒğŸ˜¨)*ã€‚æœºå™¨é—å¿˜é¢†åŸŸé€šè¿‡è€ƒè™‘æ—¶é—´å’Œè®¡ç®—èµ„æºä½œä¸ºåå‘å¤„ç†æˆ–æ¶ˆé™¤ç‰¹å®šæ•°æ®ç‚¹å¯¹æ¨¡å‹å‚æ•°å½±å“çš„çº¦æŸï¼Œæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

Â· **ç½‘ç»œå®‰å…¨ï¼š** æ¨¡å‹å¹¶ä¸å…å—å¯¹æ‰‹çš„æ”»å‡»ï¼Œè¿™äº›æ”»å‡»é€šè¿‡æ³¨å…¥æ•°æ®æ¥æ“æ§æ¨¡å‹è¡Œä¸ºï¼Œä»è€Œæ³„éœ²ç”¨æˆ·çš„æ•æ„Ÿä¿¡æ¯ã€‚æœºå™¨é—å¿˜å¯ä»¥å¸®åŠ©å»é™¤æœ‰å®³æ•°æ®ç‚¹ï¼Œä¿æŠ¤ç”¨äºè®­ç»ƒæ¨¡å‹çš„æ•æ„Ÿä¿¡æ¯ã€‚

åœ¨æœºå™¨é—å¿˜é¢†åŸŸï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°ä¸¤ç§æ€è·¯ï¼š**ç²¾ç¡®æœºå™¨é—å¿˜**å’Œ**è¿‘ä¼¼æœºå™¨é—å¿˜**ã€‚**ç²¾ç¡®æœºå™¨é—å¿˜**ä¾§é‡äºé€šè¿‡å®Œå…¨åˆ é™¤ç‰¹å®šæ•°æ®ç‚¹æ¥æ¶ˆé™¤å…¶å½±å“ *(å°±å¥½åƒè¿™äº›æ•°æ®ä»æœªè¢«å¼•å…¥æ¨¡å‹ä¸€æ ·)*ï¼Œè€Œ**è¿‘ä¼¼æœºå™¨é—å¿˜**æ—¨åœ¨é«˜æ•ˆåœ°å‡å°‘è®­ç»ƒæ¨¡å‹ä¸­æŸäº›æ•°æ®ç‚¹çš„å½±å“ *(ä½¿æ¨¡å‹çš„è¡Œä¸ºæ¥è¿‘äºå¦‚æœè¿™äº›æ•°æ®ç‚¹ä»æœªå¼•å…¥è¿‡æ¨¡å‹çš„çŠ¶æ€)*ã€‚è¿™ä¸¤ç§æ–¹æ³•éƒ½æä¾›äº†å¤šæ ·åŒ–çš„æŠ€æœ¯æ¥åº”å¯¹ç”¨æˆ·çš„åˆ é™¤æƒé—®é¢˜ï¼ŒåŒæ—¶è€ƒè™‘åˆ°æ¨¡å‹æ€§èƒ½ä¸‹é™ã€è®¡ç®—èµ„æºã€æ—¶é—´æ¶ˆè€—ã€å­˜å‚¨èµ„æºã€ç‰¹å®šå­¦ä¹ æ¨¡å‹æˆ–æ•°æ®ç»“æ„ç­‰é™åˆ¶ã€‚

ä¸ºäº†æ›´å¥½åœ°ç†è§£è¯¥é¢†åŸŸçš„æœ€æ–°ç ”ç©¶å·¥ä½œï¼Œæˆ‘æ¨èä¸¤ç¯‡æœ‰è¶£çš„é˜…è¯»ææ–™ï¼š[*æœºå™¨å»å­¦ä¹ ï¼šè§£å†³æ–¹æ¡ˆä¸æŒ‘æˆ˜ï¼ˆ2024ï¼‰*](https://arxiv.org/pdf/2308.07061) å’Œ [*å­¦ä¼šå»å­¦ä¹ ï¼šæœºå™¨å»å­¦ä¹ çš„è§è§£ï¼ˆ2023ï¼‰*](https://arxiv.org/pdf/2305.07512)ã€‚è¿™ä¸¤ç¯‡è®ºæ–‡å¾ˆå¥½åœ°å›é¡¾äº†è¿‘å¹´æ¥æœºå™¨å»å­¦ä¹ é¢†åŸŸç§‘å­¦å®¶å’Œç ”ç©¶äººå‘˜çš„éå‡¡å·¥ä½œã€‚

# SISA **ï¼ˆåˆ†ç‰‡ã€éš”ç¦»ã€åˆ‡ç‰‡å’Œèšåˆï¼‰**

**SISA æ¡†æ¶æ˜¯â€œç²¾ç¡®æœºå™¨å»å­¦ä¹ â€æ€æƒ³çš„ä¸€éƒ¨åˆ†**ï¼Œæ—¨åœ¨å»é™¤æ•°æ®è€Œæ— éœ€å¯¹æ¨¡å‹è¿›è¡Œå®Œå…¨é‡æ–°è®­ç»ƒã€‚è¯¥æ¡†æ¶ä»è¿™æ ·ä¸€ä¸ªå‰æå‡ºå‘ï¼šè™½ç„¶ä»å¤´å¼€å§‹é‡æ–°è®­ç»ƒï¼Œæ’é™¤éœ€è¦å»å­¦ä¹ çš„æ•°æ®ç‚¹ï¼Œæ˜¯ä¸â€œè¢«é—å¿˜æƒâ€åŸåˆ™å¯¹é½çš„æœ€ç›´æ¥æ–¹å¼ï¼ˆ*æä¾›è¯æ˜å¹¶ç¡®ä¿ä¸éœ€è¦çš„æ•°æ®å·²è¢«ç§»é™¤*ï¼‰ï¼Œä½†å®ƒä¹Ÿè®¤è¯†åˆ°ï¼Œå¯¹äºä½¿ç”¨å¤§é‡æ•°æ®é›†è®­ç»ƒçš„å¤æ‚åŸºç¡€æ¨¡å‹è€Œè¨€ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¼šè¢«è§†ä¸ºä¸€ç§å¤©çœŸçš„ç­–ç•¥ï¼Œå› ä¸ºè¿™ç±»æ¨¡å‹è®­ç»ƒéœ€è¦é«˜èµ„æºã€‚å› æ­¤ï¼Œä¸ºäº†åº”å¯¹å»å­¦ä¹ è¿‡ç¨‹çš„æŒ‘æˆ˜ï¼Œä»»ä½•æŠ€æœ¯éƒ½åº”è¯¥æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

1.  **æ˜“äºç†è§£ï¼ˆå¯ç†è§£æ€§ï¼‰ï¼š** è¯¥æŠ€æœ¯åº”æ˜“äºç†è§£å’Œå®ç°ã€‚

1.  **å‡†ç¡®æ€§ï¼š** è™½ç„¶æŸäº›å‡†ç¡®æ€§å¯èƒ½ä¼šä¸¢å¤±æ˜¯åˆç†çš„ï¼Œä½†è¿™ä¸€å·®è·åº”è¯¥å¾ˆå°ã€‚

1.  **æ—¶é—´/è®¡ç®—æ•ˆç‡ï¼š** å®ƒåº”æ¯”ä»å¤´æ’é™¤æ•°æ®ç‚¹æ‰€éœ€çš„æ—¶é—´æ›´å°‘ï¼Œå¹¶ä¸”æ‰€éœ€çš„è®¡ç®—èµ„æºåº”ç±»ä¼¼äºç°æœ‰è®­ç»ƒè¿‡ç¨‹æ‰€ç”¨çš„èµ„æºã€‚

1.  **æ˜“äºéªŒè¯ï¼ˆå¯è¯æ˜çš„ä¿è¯ï¼‰ï¼š** è¯¥æŠ€æœ¯åº”æ¸…æ¥šåœ°è¡¨æ˜æ‰€è¯·æ±‚çš„æ•°æ®ç‚¹å·²è¢«å»å­¦ä¹ ï¼Œè€Œä¸ä¼šå½±å“æ¨¡å‹å‚æ•°ï¼Œå¹¶ä¸”è¯æ˜å¯ä»¥è½»æ¾è§£é‡Šï¼ˆå³ä½¿æ˜¯éä¸“å®¶ä¹Ÿèƒ½ç†è§£ï¼‰ã€‚

1.  **ä¸æ¨¡å‹æ— å…³ï¼š** å®ƒåº”é€‚ç”¨äºå„ç§æ€§è´¨å’Œå¤æ‚åº¦çš„æ¨¡å‹ã€‚

> **æˆ‘ä»¬å¦‚ä½•ä¿è¯ç‰¹å®šè®­ç»ƒæ•°æ®ç‚¹çš„å®Œå…¨ç§»é™¤ï¼Ÿæˆ‘ä»¬å¦‚ä½•éªŒè¯å»å­¦ä¹ è¿‡ç¨‹çš„æˆåŠŸï¼Ÿ**

SISA æ¡†æ¶ï¼ˆåˆ†ç‰‡ã€éš”ç¦»ã€åˆ‡ç‰‡å’Œèšåˆï¼‰æœ€åˆåœ¨ 2019 å¹´ç”± Bourtoule ç­‰äººæå‡ºï¼Œå‘è¡¨äºè®ºæ–‡ *â€œ*[*æœºå™¨å»å­¦ä¹ *](https://arxiv.org/abs/1912.03817)*â€*ï¼Œæ—¨åœ¨æå‡ºä¸€ä¸ª**æ›¿ä»£è§£å†³æ–¹æ¡ˆï¼Œç”¨äºè§£å†³ä»æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­å»é™¤æ•°æ®çš„é—®é¢˜ï¼Œç¡®ä¿ç§»é™¤ä¿è¯æ˜“äºç†è§£**ã€‚è¯¥è®ºæ–‡åœ¨å¼•è¨€éƒ¨åˆ†æ˜“äºé˜…è¯»ï¼Œä½†å¦‚æœä½ ä¸ç†Ÿæ‚‰æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œå¯èƒ½ä¼šå˜å¾—å¤æ‚ã€‚å› æ­¤ï¼Œæˆ‘å°†å°è¯•æ€»ç»“ä¸€äº›æˆ‘è®¤ä¸ºæœ‰è¶£çš„æŠ€æœ¯ç‰¹å¾ï¼Œä½†å¦‚æœä½ æœ‰æ—¶é—´ï¼Œæˆ‘å¼ºçƒˆå»ºè®®é˜…è¯»è¿™ç¯‡è®ºæ–‡ï¼Œå®ƒå€¼å¾—ä¸€è¯»ï¼*(ä½ è¿˜å¯ä»¥è§‚çœ‹ä½œè€…åœ¨ IEEE å®‰å…¨ä¸éšç§ç ”è®¨ä¼šä¸Šè¿›è¡Œçš„* [*è¿™ç¯‡è§†é¢‘æ¼”ç¤º*](https://youtu.be/xUnMkCB0Gns?feature=shared) *ï¼Œå…¶ä¸­å¯¹è®ºæ–‡çš„å‘ç°è¿›è¡Œäº†æœ‰è¶£çš„å±•ç¤º)*

SISA è®­ç»ƒæ–¹æ³•**åŒ…æ‹¬å¤šæ¬¡å¤åˆ¶æ¨¡å‹**ï¼Œæ¯ä¸ªå‰¯æœ¬**åœ¨æ•°æ®é›†çš„ä¸åŒå­é›†ä¸Šè¿›è¡Œè®­ç»ƒ**ï¼ˆ*ç§°ä¸ºä¸€ä¸ªåˆ†ç‰‡*ï¼‰ã€‚**æ¯ä¸ªæ¨¡å‹è¢«ç§°ä¸ºâ€œæ„æˆæ¨¡å‹â€**ã€‚åœ¨æ¯ä¸ªåˆ†ç‰‡å†…ï¼Œ**æ•°æ®è¿›ä¸€æ­¥è¢«åˆ’åˆ†ä¸ºâ€œåˆ‡ç‰‡â€**ï¼Œå¹¶åº”ç”¨å¢é‡å­¦ä¹ ï¼Œç›¸åº”åœ°å½’æ¡£å‚æ•°ã€‚æ¯ä¸ªæ„æˆæ¨¡å‹åœ¨è®­ç»ƒé˜¶æ®µä¸»è¦ä¸å…¶åˆ†é…çš„åˆ†ç‰‡ä¸€èµ·å·¥ä½œï¼ŒåŒæ—¶åœ¨æ¯ä¸ªåˆ†ç‰‡å†…ä½¿ç”¨åˆ‡ç‰‡æ¥ç®¡ç†æ•°æ®å¹¶æ”¯æŒå¢é‡å­¦ä¹ ã€‚è®­ç»ƒåï¼Œæ¥è‡ªæ¯ä¸ªåˆ†ç‰‡çš„å­æ¨¡å‹ä¼šè¢«æ±‡æ€»ï¼Œå½¢æˆæœ€ç»ˆæ¨¡å‹ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œ**æ¥è‡ªä¸åŒæ„æˆæ¨¡å‹çš„é¢„æµ‹ç»“æœä¼šç»“åˆåœ¨ä¸€èµ·ï¼Œäº§ç”Ÿæ•´ä½“é¢„æµ‹ç»“æœ**ã€‚**å›¾ 02**è¯´æ˜äº† SISA è®­ç»ƒæ–¹æ³•çš„å·¥ä½œåŸç†ã€‚

![](img/8ff74577dc3e5573ec798beda7bfe2ba.png)

å›¾ 02 æ¥æºï¼šä½œè€…åŸºäº Bourtoule ç­‰äººè®ºæ–‡ï¼ˆ2019ï¼‰è‡ªè¡Œåˆ›ä½œ

**å½“éœ€è¦å»å­¦ä¹ æŸäº›æ•°æ®æ—¶**ï¼Œåªæœ‰åŒ…å«éœ€è¦å»å­¦ä¹ æ•°æ®ç‚¹çš„åˆ†ç‰‡ä¸­çš„æ„æˆæ¨¡å‹ä¼šè¢«é‡æ–°è®­ç»ƒï¼ˆ*æ•°æ®ç‚¹ä¼šä»ç‰¹å®šåˆ†ç‰‡ä¸­çš„æŸä¸ªåˆ‡ç‰‡ä¸­å»å­¦ä¹ *ï¼‰ã€‚

## åº”ç”¨ SISAï¼šé’ˆå¯¹å›¾åƒè¯†åˆ«çš„ CNN æ¨¡å‹å»å­¦ä¹ ä¸å†è®­ç»ƒ

ä¸ºäº†ç†è§£å¦‚ä½•åº”ç”¨ SISAï¼Œæˆ‘å°†ä½¿ç”¨ Python è¿›è¡Œä¸€ä¸ªæ¡ˆä¾‹ç¤ºä¾‹ã€‚æœ€è¿‘ï¼Œæˆ‘ä½¿ç”¨ PyTorchã€è®¡ç®—æœºè§†è§‰æŠ€æœ¯å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ„å»ºäº†ä¸€ä¸ªåŸºæœ¬çš„è®¾ç½®ï¼Œç”¨äºè¿½è¸ªå†°çƒçƒå‘˜å’Œçƒé˜Ÿï¼Œå¹¶æ”¶é›†ä¸€äº›åŸºæœ¬çš„è¡¨ç°ç»Ÿè®¡æ•°æ®*ï¼ˆ[*ä½ å¯ä»¥åœ¨è¿™é‡Œè®¿é—®å®Œæ•´çš„æ–‡ç« *](https://medium.com/towards-data-science/spicing-up-ice-hockey-with-ai-player-tracking-with-computer-vision-ce9ceec9122a)ï¼‰*ã€‚

![](img/7a960baa2383b62cff2c4cf942ad002a.png)

ä½¿ç”¨è®¡ç®—æœºè§†è§‰è¿›è¡Œçƒå‘˜è¿½è¸ª

å°½ç®¡ç§˜é²æ»‘æ—±å†°æ›²æ£çƒåä¼šï¼ˆAPHLï¼‰å·²åŒæ„å°† 40 ç§’çš„è§†é¢‘ç”¨äºè¯¥é¡¹ç›®ï¼Œä½†**æˆ‘ä»¬è®¾æƒ³ä¸€ä¸ª SISA åº”ç”¨æ¡ˆä¾‹çš„åœºæ™¯ï¼šæŸä¸ªçƒå‘˜æŠ±æ€¨è‡ªå·±çš„å›¾åƒè¢«ä½¿ç”¨ï¼Œå¹¶è¡Œä½¿åˆ é™¤æƒï¼Œè¦æ±‚ä»åˆ†ç±»æ¯ä¸ªçƒå‘˜æ‰€å±é˜Ÿä¼çš„ CNN é¢„è®­ç»ƒæ¨¡å‹ä¸­ç§»é™¤ä»–çš„å›¾åƒ**ã€‚è¿™å°†è¦æ±‚æˆ‘ä»¬ä»è®­ç»ƒæ•°æ®é›†ä¸­ç§»é™¤è¯¥å›¾åƒï¼Œå¹¶é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚ç„¶è€Œï¼Œé€šè¿‡åº”ç”¨ SISA æŠ€æœ¯ï¼Œæˆ‘ä»¬åªéœ€å¤„ç†åŒ…å«è¿™äº›å›¾åƒçš„åˆ†ç‰‡å’Œåˆ‡ç‰‡ï¼Œä»è€Œé¿å…äº†ä»å¤´å¼€å§‹é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼ŒèŠ‚çœäº†æ—¶é—´ã€‚

åŸå§‹ CNN æ¨¡å‹ç»“æ„å¦‚ä¸‹ï¼š

```py
# ************CONVOLUTIONAL NEURAL NETWORK-THREE CLASSES DETECTION**************************
# REFEREE
# WHITE TEAM (white_away)
# YELLOW TEAM (yellow_home)

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

#******************************Data transformation********************************************
# Training and Validation Datasets
data_dir = 'D:/PYTHON/teams_sample_dataset'

transform = transforms.Compose([
    transforms.Resize((150, 150)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Load datasets
train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)
val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

#********************************CNN Model Architecture**************************************
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(128 * 18 * 18, 512)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(512, 3)  #Three Classes

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(-1, 128 * 18 * 18)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)  
        return x

#********************************CNN TRAINING**********************************************

# Model-loss function-optimizer
model = CNNModel()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

#*********************************Training*************************************************
num_epochs = 10
train_losses, val_losses = [], []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        labels = labels.type(torch.LongTensor)  
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    train_losses.append(running_loss / len(train_loader))

    model.eval()
    val_loss = 0.0
    all_labels = []
    all_preds = []
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs)
            labels = labels.type(torch.LongTensor)  
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)  
            all_labels.extend(labels.tolist())
            all_preds.extend(preds.tolist())

#********************************METRICS & PERFORMANCE************************************

    val_losses.append(val_loss / len(val_loader))
    val_accuracy = accuracy_score(all_labels, all_preds)
    val_precision = precision_score(all_labels, all_preds, average='macro', zero_division=1)
    val_recall = recall_score(all_labels, all_preds, average='macro', zero_division=1)
    val_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=1)

    print(f"Epoch [{epoch + 1}/{num_epochs}], "
          f"Loss: {train_losses[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, "
          f"Val Acc: {val_accuracy:.2%}, "
          f"Val Precision: {val_precision:.4f}, "
          f"Val Recall: {val_recall:.4f}, "
          f"Val F1 Score: {val_f1:.4f}")

#*******************************SHOW METRICS & PERFORMANCE**********************************
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.legend()
plt.show()

# SAVE THE MODEL FOR THE GH_CV_track_teams CODE
torch.save(model.state_dict(), 'D:/PYTHON/hockey_team_classifier.pth')
```

å¦‚ä½ æ‰€è§ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸‰å±‚ï¼ˆconv1ï¼Œconv2ï¼Œconv3ï¼‰çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œä½¿ç”¨ ReLU ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œç»è¿‡å¤§çº¦ 90 å¼ åˆ†ç±»ä¸ºä¸‰ä¸ªç±»åˆ«çš„å›¾åƒè®­ç»ƒï¼šè£åˆ¤å‘˜ã€Team_Awayï¼ˆç™½è‰²çƒè¡£çš„çƒå‘˜ï¼‰å’Œ Team_Homeï¼ˆé»„è‰²çƒè¡£çš„çƒå‘˜ï¼‰ï¼Œå¹¶å®Œæˆäº† 10 è½®çš„å®Œæ•´å‘¨æœŸã€‚

è€ƒè™‘åˆ°è¿™ç§åˆæ­¥æ–¹æ³•ï¼Œåˆ é™¤å›¾åƒçš„è¯·æ±‚å°†æ¶‰åŠä»è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸­åˆ é™¤å›¾åƒï¼Œå¹¶é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚è™½ç„¶å¯¹äºåƒæˆ‘ä»¬è¿™æ ·çš„å°æ•°æ®é›†æ¥è¯´è¿™å¯èƒ½å¾ˆå®¹æ˜“ï¼Œä½†å¯¹äºæ›´å¤§çš„æ•°æ®é›†ï¼Œæ¯”å¦‚å½“å‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ‰€ä½¿ç”¨çš„æ•°æ®é›†ï¼Œè¿™å°†æ˜¯ä¸€æ¬¡èµ„æºçš„å·¨å¤§æ¶ˆè€—ã€‚æ­¤å¤–ï¼Œåå¤æ‰§è¡Œæ­¤è¿‡ç¨‹ä¹Ÿå¯èƒ½æˆä¸ºä¸€ä¸ªé™åˆ¶ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å‡è®¾åœ¨æ„å»ºæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬æ„è¯†åˆ°ç”¨æˆ·æœ‰åˆ é™¤æˆ–æ›´æ­£çš„æƒåˆ©ï¼Œå¹¶è€ƒè™‘åº”ç”¨ SISA æŠ€æœ¯ã€‚è¿™ç§æ–¹æ³•å°†ä¸ºæ¨¡å‹åšå¥½å‡†å¤‡ï¼Œä»¥åº”å¯¹æœªæ¥å¯èƒ½éœ€è¦å°†å›¾åƒä»è®­ç»ƒæ•°æ®é›†ä¸­æ°¸ä¹…åˆ é™¤çš„æƒ…å†µï¼Œä»¥åŠ CNN åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¯èƒ½æ•è·çš„ä»»ä½•ç‰¹å¾ã€‚ç¬¬ä¸€æ­¥æ˜¯å°†ä¸Šè¿°åˆå§‹æ¨¡å‹è°ƒæ•´ä¸ºåŒ…å« SISA æŠ€æœ¯çš„å››ä¸ªæ­¥éª¤ï¼šåˆ†ç‰‡ï¼ˆShardingï¼‰ã€éš”ç¦»ï¼ˆIsolatingï¼‰ã€åˆ‡ç‰‡ï¼ˆSlicingï¼‰å’Œèšåˆï¼ˆAggregationï¼‰ã€‚

**æ­¥éª¤ 01ï¼šåˆ†ç‰‡å’Œåˆ‡ç‰‡**

åœ¨å‰é¢ä»£ç ä¸­æŒ‡å®šçš„è½¬æ¢æ­¥éª¤ä¹‹åï¼Œæˆ‘ä»¬å°†é€šè¿‡å°†æ•°æ®é›†åˆ’åˆ†ä¸ºå¤šä¸ªåˆ†ç‰‡æ¥å¼€å§‹åº”ç”¨ SISAã€‚åœ¨ä»£ç ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°è¿™äº›åˆ†ç‰‡æ˜¯å¤šæ ·åŒ–çš„ï¼Œå¹¶ä¸”è¢«åˆ†å‰²æˆå¤§å°ç›¸ç­‰çš„éƒ¨åˆ†ï¼Œä»¥ç¡®ä¿æ¯ä¸ªåˆ†ç‰‡åŒ…å«å…·æœ‰ä»£è¡¨æ€§çš„æ ·æœ¬æ•°é‡ï¼Œå¹¶åœ¨æˆ‘ä»¬è¦é¢„æµ‹çš„ä¸åŒç±»åˆ«ä¹‹é—´ä¿æŒå¹³è¡¡*ï¼ˆåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬æ­£åœ¨é¢„æµ‹ä¸‰ç±»ï¼‰*ã€‚

```py
 #******************************Sharding the dataset**************************

def shard_dataset(dataset, num_shards):
    indices = list(range(len(dataset)))
    np.random.shuffle(indices)
    shards = []
    shard_size = len(dataset) // num_shards
    for i in range(num_shards):
        shard_indices = indices[i * shard_size : (i + 1) * shard_size]
        shards.append(Subset(dataset, shard_indices))
    return shards

#******************************Overlapping Slices***************************
def create_overlapping_slices(shard, slice_size, overlap):
    indices = list(shard.indices)
    slices = []
    step = slice_size - overlap
    for start in range(0, len(indices) - slice_size + 1, step):
        slice_indices = indices[start:start + slice_size]
        slices.append(Subset(shard.dataset, slice_indices))
    return slices
```

æ‚¨ä¼šæ³¨æ„åˆ°ï¼Œåœ¨åˆ‡ç‰‡è¿‡ç¨‹ä¸­ï¼Œæˆ‘æ²¡æœ‰åƒ SISA æŠ€æœ¯å»ºè®®çš„é‚£æ ·ä¸ºæ¯ä¸ªåˆ†ç‰‡åˆ†é…ç‹¬å çš„åˆ‡ç‰‡ã€‚ç›¸åï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é‡å çš„åˆ‡ç‰‡ã€‚è¿™æ„å‘³ç€æ¯ä¸ªåˆ‡ç‰‡ä¸ä»…ä»…ç”±æ¥è‡ªä¸€ä¸ªåˆ†ç‰‡çš„æ•°æ®ç‚¹ç»„æˆï¼›ä¸€äº›æ•°æ®ç‚¹ä¹Ÿä¼šå‡ºç°åœ¨ä¸‹ä¸€ä¸ªåˆ‡ç‰‡ä¸­ã€‚

***é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆæˆ‘è®©åˆ‡ç‰‡é‡å å‘¢ï¼Ÿ*** æ­£å¦‚ä½ å¯èƒ½å·²ç»çŒœåˆ°çš„é‚£æ ·ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†å¾ˆå°*ï¼ˆå¤§çº¦ 90 å¼ å›¾åƒï¼‰*ï¼Œå› æ­¤å¦‚æœæ¯ä¸ªåˆ†ç‰‡éƒ½ä½¿ç”¨ç‹¬å çš„åˆ‡ç‰‡ï¼Œå°†æ— æ³•ä¿è¯æ¯ä¸ªåˆ‡ç‰‡éƒ½æœ‰è¶³å¤Ÿå¹³è¡¡çš„æ•°æ®é›†æ¥ç»´æŒæ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ã€‚**é‡å åˆ‡ç‰‡** ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å¯ç”¨æ•°æ®å¹¶æé«˜æ³›åŒ–èƒ½åŠ›ã€‚å¯¹äºè¾ƒå¤§çš„æ•°æ®é›†ï¼Œéé‡å åˆ‡ç‰‡å¯èƒ½æ›´é«˜æ•ˆï¼Œå› ä¸ºå®ƒä»¬éœ€è¦çš„è®¡ç®—èµ„æºæ›´å°‘ã€‚**æœ€ç»ˆï¼Œåˆ›å»ºåˆ†ç‰‡å’Œåˆ‡ç‰‡éœ€è¦è€ƒè™‘æ•°æ®é›†çš„å¤§å°ã€è®¡ç®—èµ„æºä»¥åŠç»´æŒæ¨¡å‹é¢„æµ‹èƒ½åŠ›çš„éœ€æ±‚ã€‚**

æœ€åï¼Œåœ¨å®šä¹‰äº†å‡½æ•°ä¹‹åï¼Œæˆ‘ä»¬ç»§ç»­è®¾ç½®åˆ†ç‰‡å’Œåˆ‡ç‰‡è¿‡ç¨‹çš„è¶…å‚æ•°ï¼š

```py
 #**************************Applying Sharding and Slicing*******************

num_shards = 4  
slice_size = len(full_train_dataset) // num_shards // 2
overlap = slice_size // 2
shards = shard_dataset(full_train_dataset, num_shards)

#************************Overlapping slices for each shard*****************
all_slices = []
for shard in shards:
    slices = create_overlapping_slices(shard, slice_size, overlap)
    all_slices.extend(slices)
```

æ•°æ®é›†è¢«åˆ†ä¸º 4 ä¸ªç¢ç‰‡ï¼Œä½†æˆ‘åº”è¯¥æåˆ°ï¼Œæœ€åˆæˆ‘ä½¿ç”¨äº† 10 ä¸ªç¢ç‰‡ã€‚è¿™å¯¼è‡´æ¯ä¸ªç¢ç‰‡åªåŒ…å«å°‘é‡çš„æ ·æœ¬ï¼Œè¿™æ²¡æœ‰æ­£ç¡®ä»£è¡¨æ•´ä¸ªæ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€ç²¾ç¡®åº¦å’Œ F1 åˆ†æ•°ï¼‰æ˜¾è‘—ä¸‹é™ã€‚ç”±äºæˆ‘ä»¬å¤„ç†çš„æ˜¯ä¸€ä¸ªå°æ•°æ®é›†ï¼Œå‡å°‘ç¢ç‰‡æ•°é‡åˆ°å››ä¸ªæ˜¯ä¸€ä¸ªæ˜æ™ºçš„å†³å®šã€‚æœ€åï¼Œåˆ‡ç‰‡è¿‡ç¨‹å°†æ¯ä¸ªç¢ç‰‡åˆ’åˆ†ä¸ºä¸¤ä¸ªå…·æœ‰ 50% é‡å çš„åˆ‡ç‰‡ï¼Œæ„å‘³ç€æ¯ä¸ªåˆ‡ç‰‡ä¸­çš„ä¸€åŠå›¾åƒä¸ä¸‹ä¸€ä¸ªåˆ‡ç‰‡é‡å ã€‚

**æ­¥éª¤ 02ï¼šéš”ç¦»ç‰¹å®šæ•°æ®ç‚¹**

åœ¨è¿™ä¸€æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬ç»§ç»­éš”ç¦»æœ€ç»ˆç”¨æˆ·å¯èƒ½å¸Œæœ›ä¿®æ­£æˆ–ä»æ¨¡å‹å­¦ä¹ è¿‡ç¨‹ä¸­åˆ é™¤çš„ç‰¹å®šæ•°æ®ç‚¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå°†æŒ‡å®šçš„æ•°æ®ç‚¹ä»æ¯ä¸ªåˆ‡ç‰‡ä¸­ç§»é™¤ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ ¹æ®å›¾åƒçš„æ–‡ä»¶åæ¥ç¡®å®šå›¾åƒçš„ç´¢å¼•ã€‚ç„¶åï¼Œè¿™äº›ç´¢å¼•ç”¨æ¥æ›´æ–°æ¯ä¸ªåˆ‡ç‰‡ï¼Œç§»é™¤åŒ…å«è¿™äº›æ•°æ®ç‚¹çš„éƒ¨åˆ†ã€‚

```py
 #**************************+*Isolate datapoints******************************
def isolate_data_for_unlearning(slice, data_points_to_remove):
    new_indices = [i for i in slice.indices if i not in data_points_to_remove]
    return Subset(slice.dataset, new_indices)

#*****Identify the indices of the images we want to rectify/erasure**********
def get_indices_to_remove(dataset, image_names_to_remove):
    indices_to_remove = [] #list is empty
    image_to_index = {img_path: idx for idx, (img_path, _) in enumerate(dataset.imgs)}
    for image_name in image_names_to_remove:
        if image_name in image_to_index:
            indices_to_remove.append(image_to_index[image_name])
    return indices_to_remove

#*************************Specify and remove images***************************
images_to_remove = []
indices_to_remove = get_indices_to_remove(full_train_dataset, images_to_remove)
updated_slices = [isolate_data_for_unlearning(slice, indices_to_remove) for slice in all_slices]
```

**ç›®å‰ï¼Œåˆ—è¡¨ä¸ºç©ºï¼ˆimages_to_remove = []ï¼‰ï¼Œ**å› æ­¤æ­¤é˜¶æ®µæ²¡æœ‰åˆ é™¤ä»»ä½•å›¾åƒï¼Œä½†å½“è¯·æ±‚åˆ°è¾¾æ—¶ï¼Œè®¾ç½®å·²å‡†å¤‡å¥½ä½¿ç”¨ï¼ˆ*ç¨åæˆ‘ä»¬å°†åœ¨æœ¬æ–‡ä¸­çœ‹åˆ°ä¸€ä¸ªä¾‹å­*ï¼‰ã€‚

å®æ–½ SISA æŠ€æœ¯çš„å®Œæ•´æ¨¡å‹åº”è¯¥æ˜¯è¿™æ ·çš„ï¼š

```py
 import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader, Subset
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

#******************************Data transformation********************************************
# Training and Validation Datasets
data_dir = 'D:/PYTHON/teams_sample_dataset'

transform = transforms.Compose([
    transforms.Resize((150, 150)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Load data
full_train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)
val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)

#******************************Sharding the dataset**************************

def shard_dataset(dataset, num_shards):
    indices = list(range(len(dataset)))
    np.random.shuffle(indices)
    shards = []
    shard_size = len(dataset) // num_shards
    for i in range(num_shards):
        shard_indices = indices[i * shard_size : (i + 1) * shard_size]
        shards.append(Subset(dataset, shard_indices))
    return shards

#******************************Overlapping Slices***************************
def create_overlapping_slices(shard, slice_size, overlap):
    indices = list(shard.indices)
    slices = []
    step = slice_size - overlap
    for start in range(0, len(indices) - slice_size + 1, step):
        slice_indices = indices[start:start + slice_size]
        slices.append(Subset(shard.dataset, slice_indices))
    return slices

#**************************Applying Sharding and Slicing*******************

num_shards = 4  
slice_size = len(full_train_dataset) // num_shards // 2
overlap = slice_size // 2
shards = shard_dataset(full_train_dataset, num_shards)

#************************Overlapping slices for each shard*****************
all_slices = []
for shard in shards:
    slices = create_overlapping_slices(shard, slice_size, overlap)
    all_slices.extend(slices)

#**************************+*Isolate datapoints******************************
def isolate_data_for_unlearning(slice, data_points_to_remove):
    new_indices = [i for i in slice.indices if i not in data_points_to_remove]
    return Subset(slice.dataset, new_indices)

#*****Identify the indices of the images we want to rectify/erasure**********
def get_indices_to_remove(dataset, image_names_to_remove):
    indices_to_remove = []
    image_to_index = {img_path: idx for idx, (img_path, _) in enumerate(dataset.imgs)}
    for image_name in image_names_to_remove:
        if image_name in image_to_index:
            indices_to_remove.append(image_to_index[image_name])
    return indices_to_remove

#*************************Specify and remove images***************************
images_to_remove = []
indices_to_remove = get_indices_to_remove(full_train_dataset, images_to_remove)
updated_slices = [isolate_data_for_unlearning(slice, indices_to_remove) for slice in all_slices]

#********************************CNN Model Architecture**************************************

class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(128 * 18 * 18, 512)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(512, 3)  # Output three classes

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(-1, 128 * 18 * 18)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

#********************************CNN TRAINING**********************************************

# Model-loss function-optimizer
model = CNNModel()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

#*********************************Training*************************************************
num_epochs = 10
train_losses, val_losses = [], []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for slice in updated_slices:
        train_loader = DataLoader(slice, batch_size=32, shuffle=True)
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            labels = labels.type(torch.LongTensor)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

    train_losses.append(running_loss / (len(updated_slices)))

    model.eval()
    val_loss = 0.0
    all_labels = []
    all_preds = []
    with torch.no_grad():
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
        for inputs, labels in val_loader:
            outputs = model(inputs)
            labels = labels.type(torch.LongTensor)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            all_labels.extend(labels.tolist())
            all_preds.extend(preds.tolist())

#********************************METRICS & PERFORMANCE************************************

    val_losses.append(val_loss / len(val_loader))
    val_accuracy = accuracy_score(all_labels, all_preds)
    val_precision = precision_score(all_labels, all_preds, average='macro', zero_division=1)
    val_recall = recall_score(all_labels, all_preds, average='macro', zero_division=1)
    val_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=1)

    print(f"Epoch [{epoch + 1}/{num_epochs}], "
          f"Loss: {train_losses[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, "
          f"Val Acc: {val_accuracy:.2%}, "
          f"Val Precision: {val_precision:.4f}, "
          f"Val Recall: {val_recall:.4f}, "
          f"Val F1 Score: {val_f1:.4f}")

#*******************************SHOW METRICS & PERFORMANCE**********************************
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.legend()
plt.show()

# SAVE THE MODEL
torch.save(model.state_dict(), 'hockey_team_classifier_SISA.pth') 
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬è¿›å…¥æ“¦é™¤åœºæ™¯ã€‚å‡è®¾æ¨¡å‹å·²ç»éƒ¨ç½²äº†å‡ ä¸ªæœˆï¼Œä¸€åå†°çƒè¿åŠ¨å‘˜è¯·æ±‚ä» CNN æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­åˆ é™¤ä»–ä»¬çš„å›¾åƒã€‚å‡è®¾åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œè¯¥è¿åŠ¨å‘˜å‡ºç°åœ¨è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ä¸­ä¸‰å¼ å›¾åƒä¸­ï¼š**Away_image03.JPG, Away_image04.JPG å’Œ Away_image05.JPG**ã€‚ä¸ºäº†ä»è®­ç»ƒè¿‡ç¨‹ä¸­åˆ é™¤è¿™äº›å›¾åƒï¼Œåªéœ€åœ¨ä»£ç çš„ **â€œæŒ‡å®šå¹¶åˆ é™¤å›¾åƒâ€** éƒ¨åˆ†æŒ‡å®šè¿™äº›å›¾åƒï¼ˆå¦‚ä¸Šæ‰€ç¤ºï¼‰ã€‚åªæœ‰åŒ…å«è¿™äº›å›¾åƒçš„åˆ‡ç‰‡éœ€è¦é‡æ–°è®­ç»ƒã€‚

```py
#*************************Specify and remove images***************************
images_to_remove = ["Away_image03.JPG", "Away_image04.JPG", "Away_image05.JPG"]
indices_to_remove = get_indices_to_remove(full_train_dataset, images_to_remove)
updated_slices = [isolate_data_for_unlearning(slice, indices_to_remove) for slice in all_slices]
```

æœ€åï¼Œæˆ‘æƒ³åˆ†äº«ä¸€äº›å°† SISA æ¡†æ¶åº”ç”¨åˆ°æˆ‘çš„æ¨¡å‹ä¸­çš„å…³é”®ç»éªŒï¼š

+   **å¼±å­¦ä¹ è€…å’Œæ€§èƒ½æƒè¡¡ï¼š** ç”±äºæ¯ä¸ªæ„æˆæ¨¡å‹éƒ½åœ¨å°çš„å­é›†ï¼ˆ*ç¢ç‰‡å’Œåˆ‡ç‰‡*ï¼‰ä¸Šè¿›è¡Œè®­ç»ƒï¼Œäººä»¬å¯èƒ½ä¼šè®¤ä¸ºå®ƒä»¬çš„å‡†ç¡®åº¦ä¼šä½äºåœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒçš„å•ä¸€æ¨¡å‹ï¼Œä»è€Œé™ä½æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæ¨¡å‹çš„æ€§èƒ½æ˜¾è‘—æå‡ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºåœ¨å¤„ç†ä¸€ä¸ªå°çš„ã€é‡å çš„æ•°æ®é›†æ—¶ï¼Œå¯¼è‡´äº†æŸç§ç¨‹åº¦çš„è¿‡æ‹Ÿåˆã€‚åœ¨æ¶‰åŠå¤§æ•°æ®é›†çš„ä½¿ç”¨æ¡ˆä¾‹ä¸­ï¼Œ**éœ€è¦è€ƒè™‘æ½œåœ¨çš„æ€§èƒ½æƒè¡¡**ã€‚

+   **é€‚å½“çš„åˆ†ç‰‡ï¼š** æˆ‘æœ€åˆä½¿ç”¨äº†å¤§é‡çš„åˆ†ç‰‡ï¼Œå¯¼è‡´æ¯ä¸ªåˆ†ç‰‡åªæœ‰å¾ˆå°‘çš„æ ·æœ¬ï¼Œè¿™å¯¹æ¨¡å‹æ€§èƒ½äº§ç”Ÿäº†è´Ÿé¢å½±å“ã€‚**ä¸è¦ä½ä¼°åˆ†ç‰‡å’Œåˆ‡ç‰‡è¿‡ç¨‹çš„é‡è¦æ€§**ã€‚é€‚å½“çš„åˆ†ç‰‡æœ‰åŠ©äºæ¨¡å‹é¿å…è¿‡æ‹Ÿåˆï¼Œå¹¶åœ¨éªŒè¯é›†ä¸Šæ›´å¥½åœ°æ³›åŒ–ã€‚

æˆ‘å¸Œæœ›ä½ è§‰å¾—è¿™ä¸ªåº”ç”¨ SISA æŠ€æœ¯è¿›è¡Œæœºå™¨â€œå¿˜è®°â€çš„é¡¹ç›®æœ‰è¶£ã€‚ä½ å¯ä»¥åœ¨è¿™ä¸ª[GitHub ä»“åº“](https://github.com/rvizcarra15/MachineUnlearning_SISA_framework)è®¿é—®å®Œæ•´çš„ä»£ç ã€‚

# **æœ€åçš„æ€è€ƒ**

æˆ‘çš„å§å§å’Œæˆ‘æœ‰ä¸€ä¸ªå›ºå®šçš„ä¹ æƒ¯ï¼Œæˆ‘ä»¬ä¼šäº¤æ¢ç¤¾äº¤åª’ä½“å¹³å°æ¯å¤©æé†’æˆ‘ä»¬äº”å¹´ã€åå¹´æˆ–åäº”å¹´å‰å‘å¸ƒçš„å†…å®¹çš„å›¾ç‰‡ã€‚æˆ‘ä»¬ç»å¸¸ä¼šå¯¹å½“æ—¶åˆ†äº«çš„å†…å®¹æˆ–è¯„è®ºå¤§ç¬‘ï¼ˆ*æ˜¾ç„¶ï¼Œå› ä¸ºæˆ‘ä»¬å¤§å¤šæ•°äººåœ¨ç¤¾äº¤åª’ä½“åˆšå‡ºç°æ—¶å¹¶ä¸å®Œå…¨ç†è§£å®ƒ*ï¼‰ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæˆ‘å­¦ä¼šäº†æ›´æ˜æ™ºåœ°ä½¿ç”¨æˆ‘çš„ç¤¾äº¤åª’ä½“å­˜åœ¨ï¼Œæ¬£èµç¤¾äº¤åª’ä½“ç”Ÿæ€ç³»ç»Ÿä¹‹å¤–çš„å‘¨å›´ç¯å¢ƒï¼Œä»¥åŠæˆ‘ä»¬ç”Ÿæ´»ä¸­æŸäº›æ–¹é¢åº”å½“æ‹¥æœ‰çš„éšç§ã€‚ä½†äº‹å®æ˜¯ï¼Œæˆ‘å’Œæˆ‘çš„å§å§å·²ç»ä¸å†æ˜¯åæˆ–åäº”å¹´å‰çš„æˆ‘ä»¬ï¼Œå°½ç®¡è¿‡å»æ˜¯æˆ‘ä»¬ç°åœ¨èº«ä»½çš„é‡è¦éƒ¨åˆ†ï¼Œä½†å®ƒå¹¶ä¸å®šä¹‰æˆ‘ä»¬ï¼ˆ*åœ¨æ•°å­—ä¸–ç•Œä¸­ï¼Œå¹¶éæ‰€æœ‰äº‹æƒ…éƒ½å¿…é¡»â€œåˆ»åœ¨çŸ³æ¿ä¸Šâ€*ï¼‰ã€‚æˆ‘ä»¬æ¯ä¸ªäººéƒ½æœ‰æƒé€‰æ‹©æ˜¯å¦è®©è¿™äº›æ•°æ®åœç•™åœ¨æ•°å­—ä¸–ç•Œä¸­ï¼Œå¹¶å†³å®šæ˜¯å¦ç”¨äºå®šä¹‰æˆ‘ä»¬çš„é€‰æ‹©/åå¥½æˆ–ä»–äººçš„é€‰æ‹©ã€‚

çš„ç¡®ï¼ŒAI åœ¨ä½¿ç”¨ä¸å°†è¦ä½¿ç”¨å®ƒçš„ç”¨æˆ·ç›¸ä¼¼çš„æ•°æ®è¿›è¡Œè®­ç»ƒæ—¶è¡¨ç°æ›´å¥½ï¼ˆã€Šå…ˆè¿› AI åŠ©æ‰‹çš„ä¼¦ç†é—®é¢˜ã€‹ï¼Œè°·æ­Œ DeepMind 2024ï¼‰ã€‚ç„¶è€Œï¼Œ[***â€œéšç§è¦æ±‚é€æ˜â€***](https://s899a9742c3d83292.jimcontent.com/download/version/1648135848/module/8350351463/name/Rotenberg-GPA2021.pdf)ã€‚å› æ­¤ï¼Œä½¿ç”¨æœºå™¨å­¦ä¹ å¹¶ä¸”æ¶‰åŠé¢„è®­ç»ƒæ•æ„Ÿæ•°æ®çš„å…¬å¸ï¼Œå¦‚ä½•ä»¥åŠä½•æ—¶å®æ–½â€œè¢«é—å¿˜æƒâ€å¯¹äºæœç€æˆ‘ä»¬éƒ½å¸Œæœ›æ‹¥æœ‰çš„å¯ä¿¡ AI è¿ˆè¿›è‡³å…³é‡è¦ã€‚

*æ„Ÿè°¢æ‚¨çš„é˜…è¯»ï¼* ä¸€å¦‚æ—¢å¾€ï¼Œæ¬¢è¿æ‚¨çš„å»ºè®®ï¼Œå¹¶ä¿æŒå¯¹è¯çš„è¿›è¡Œã€‚
