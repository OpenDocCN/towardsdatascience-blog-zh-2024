- en: 'Why Deep Learning Models Run Faster on GPUs: A Brief Introduction to CUDA Programming'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么深度学习模型在 GPU 上运行更快：CUDA 编程简要介绍
- en: 原文：[https://towardsdatascience.com/why-deep-learning-models-run-faster-on-gpus-a-brief-introduction-to-cuda-programming-035272906d66?source=collection_archive---------1-----------------------#2024-04-17](https://towardsdatascience.com/why-deep-learning-models-run-faster-on-gpus-a-brief-introduction-to-cuda-programming-035272906d66?source=collection_archive---------1-----------------------#2024-04-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/why-deep-learning-models-run-faster-on-gpus-a-brief-introduction-to-cuda-programming-035272906d66?source=collection_archive---------1-----------------------#2024-04-17](https://towardsdatascience.com/why-deep-learning-models-run-faster-on-gpus-a-brief-introduction-to-cuda-programming-035272906d66?source=collection_archive---------1-----------------------#2024-04-17)
- en: For those who want to understand what .to(“cuda”) does
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对于那些想了解`.to("cuda")`的作用的人
- en: '[](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)[![Lucas
    de Lima Nogueira](../Images/76edd8ee4005d4c0b8bd476261eb06ae.png)](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------)
    [Lucas de Lima Nogueira](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)[![Lucas
    de Lima Nogueira](../Images/76edd8ee4005d4c0b8bd476261eb06ae.png)](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------)
    [Lucas de Lima Nogueira](https://medium.com/@lucasdelimanogueira?source=post_page---byline--035272906d66--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------)
    ·15 min read·Apr 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--035272906d66--------------------------------)
    ·15 分钟阅读 ·2024年4月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/38705e373a34d8ee180d497825e35868.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38705e373a34d8ee180d497825e35868.png)'
- en: Image by the author with the assistance of AI ([https://copilot.microsoft.com/images/create](https://copilot.microsoft.com/images/create))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者和 AI 协助制作 ([https://copilot.microsoft.com/images/create](https://copilot.microsoft.com/images/create))
- en: Nowadays, when we talk about deep learning, it is very common to associate its
    implementation with utilizing GPUs in order to improve performance.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，当我们谈论深度学习时，通常会将其实现与利用 GPU 以提高性能联系在一起。
- en: GPUs (Graphical Processing Units) were originally designed to accelerate rendering
    of images, 2D, and 3D graphics. However, due to their capability of performing
    many parallel operations, their utility extends beyond that to applications such
    as deep learning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: GPU（图形处理单元）最初是为了加速图像、2D 和 3D 图形的渲染而设计的。然而，由于其能够执行大量并行操作的能力，GPU 的应用范围超越了这一点，扩展到了深度学习等领域。
- en: The use of GPUs for deep learning models started around the mid to late 2000s
    and became very popular around 2012 with the emergence of AlexNet. AlexNet, a
    convolution neural network designed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey
    Hinton, won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in
    2012\. This victory marked a milestone as it demonstrated the effectiveness of
    deep neural networks for image classification and the use of GPUs for training
    large models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 在深度学习模型中的使用始于 2000 年代中后期，并在 2012 年随着 AlexNet 的出现变得非常流行。AlexNet 是由 Alex Krizhevsky、Ilya
    Sutskever 和 Geoffrey Hinton 设计的卷积神经网络，它在 2012 年赢得了 ImageNet 大规模视觉识别挑战赛（ILSVRC）。这一胜利标志着深度神经网络在图像分类中的有效性以及
    GPU 在训练大型模型中的重要作用。
- en: Following this breakthrough, the use of GPUs for deep learning models became
    increasingly popular, which contributed to the creation of frameworks like PyTorch
    and TensorFlow.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一突破之后，GPU 在深度学习模型中的使用变得越来越普及，这促进了像 PyTorch 和 TensorFlow 这样的框架的创建。
- en: Nowadays, we just write `.to("cuda")` in PyTorch to send data to GPU and expect
    the training to be accelerated. But how does deep learning algorithms take advantage
    of GPUs computation performance in practice? Let’s find out!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，我们只需在 PyTorch 中写 `.to("cuda")` 就能将数据发送到 GPU，并期望训练过程加速。但是，深度学习算法是如何在实际中利用
    GPU 的计算性能的呢？让我们一探究竟！
- en: Deep learning architectures like neural networks, CNNs, RNNs and transformers
    are basically constructed using mathematical operations such as matrix addition,
    matrix multiplication and applying a function a matrix. Thus, if we find a way
    to optimize these operations, we can improve the performance of the deep learning
    models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习架构，如神经网络、卷积神经网络（CNN）、递归神经网络（RNN）和变换器（transformers），基本上是通过数学运算构建的，比如矩阵加法、矩阵乘法以及将一个函数应用于矩阵。因此，如果我们找到优化这些运算的方法，就可以提高深度学习模型的性能。
- en: So, let’s start simple. Imagine you want to add two vectors *C = A + B*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们从简单的开始。假设你想要将两个向量相加 *C = A + B*。
- en: '![](../Images/2e831e31e1d8d8b0315146a0d898fab1.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e831e31e1d8d8b0315146a0d898fab1.png)'
- en: 'A simple implementation of this in C would be:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个用 C 实现的简单例子：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can notice, the computer must iterate over the vector, adding each pair
    of elements on each iteration sequentially. But these operations are independent
    of each other. The addition of the *ith* pair of elements does not rely on any
    other pair. So, what if we could execute these operations concurrently, adding
    all of the pairs of elements in parallel?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所注意到的，计算机必须遍历向量，在每次迭代中顺序地添加每一对元素。但这些操作是相互独立的。第 *i* 对元素的加法并不依赖于任何其他对。因此，如果我们能够并行执行这些操作，将所有元素对同时相加，会怎么样呢？
- en: A straightforward approach would be using CPU multithreading in order to run
    all of the computation in parallel. However, when it comes to deep learning models,
    we are dealing with massive vectors, with millions of elements. A common CPU can
    only handle around a dozen threads simultaneously. That’s when the GPUs come into
    action! Modern GPUs can run millions of threads simultaneously, enhancing performance
    of these mathematical operations on massive vectors.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一种直接的方法是使用 CPU 多线程来并行执行所有计算。然而，对于深度学习模型，我们处理的是大量的向量，包含数百万个元素。普通的 CPU 最多只能同时处理十几个线程。此时，GPU
    就派上用场了！现代的 GPU 可以同时运行数百万个线程，从而增强这些数学运算在大规模向量上的性能。
- en: GPU vs. CPU comparison
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU 与 CPU 的对比
- en: Although CPU computations can be faster than GPU for a single operation, the
    advantage of GPUs relies on its parallelization capabilities. The reason for this
    is that they are designed with different goals. While CPU is designed to execute
    a sequence of operations (thread) as fast as possible (and can only execute dozens
    of them simultaneously), the GPU is designed to execute millions of them in parallel
    (while sacrificing speed of individual threads).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管单次操作时 CPU 的计算可能比 GPU 更快，但 GPU 的优势在于它的并行化能力。其原因在于 CPU 和 GPU 的设计目标不同。CPU 设计的目的是尽可能快地执行一系列操作（线程），并且只能同时执行几十个线程，而
    GPU 的设计目标是并行执行成千上万的操作（尽管牺牲了每个线程的速度）。
- en: 'See the video below:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请看下面的视频：
- en: To illustrate, imagine that a CPU is like a Ferrari, and the GPU as a bus. If
    your task is to move one person, the Ferrari (CPU) is the better choice. However,
    if you are moving several people, even though the Ferrari (CPU) is faster per
    trip, the bus (GPU) can transport everyone in one go, transporting all people
    at once faster than the Ferrari traveling the route several times. So CPUs are
    better designed for handling sequential operations and GPUs for parallel operations.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，假设 CPU 就像一辆法拉利，而 GPU 就像一辆公交车。如果你的任务是搬运一个人，法拉利（CPU）显然是更好的选择。然而，如果你要搬运多人，尽管法拉利（CPU）每次的速度更快，但公交车（GPU）能够一次性将所有人都运送到目的地，比起法拉利多次往返，公交车能够更快地完成运输。所以，CPU
    更适合处理顺序操作，而 GPU 更适合处理并行操作。
- en: '![](../Images/a1a871c965e587ba2104a0c62b78a33c.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1a871c965e587ba2104a0c62b78a33c.png)'
- en: Image by the author with the assistance of AI ([https://copilot.microsoft.com/images/create](https://copilot.microsoft.com/images/create))
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 作者借助 AI 提供的图像（[https://copilot.microsoft.com/images/create](https://copilot.microsoft.com/images/create)）
- en: In order to provide higher parallel capabilities, GPU designs allocate more
    transistors for data processing than to data caching and flow control, unlike
    CPUs which allocate a significant portion of transistors for that purpose, in
    order to optimize single-threaded performance and complex instruction execution.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供更高的并行能力，GPU 的设计将更多的晶体管分配给数据处理，而非数据缓存和流控制，这与 CPU 的设计不同，CPU 通常将大量晶体管分配给这些目的，以优化单线程性能和复杂指令执行。
- en: The figure below illustrates the distribution of chip resources for CPU vs GPU.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 CPU 与 GPU 的芯片资源分配情况。
- en: '![](../Images/b2bc61a6cffc46a6ab7e554fa5f3daf3.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2bc61a6cffc46a6ab7e554fa5f3daf3.png)'
- en: Image by the author with inspiration from [CUDA C++ Programming Guide](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作者所用图像灵感来源于[CUDA C++ 编程指南](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf)
- en: CPUs have powerful cores and a more complex cache memory architecture (allocating
    a significant amount of transistors for that). This design enables faster handling
    of sequential operations. On the other hand, GPUs prioritize having a large number
    of cores to achieve a higher level of parallelism.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: CPU拥有强大的核心和更复杂的缓存内存架构（为此分配了大量晶体管）。这种设计使得顺序操作处理更快。另一方面，GPU优先考虑拥有大量核心，以实现更高程度的并行性。
- en: Now that we understood these basic concepts, how can we take advantage of this
    parallel computation capabilities in practice?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理解了这些基本概念，如何在实践中利用这些并行计算能力呢？
- en: Introduction to CUDA
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA简介
- en: When you are running some deep learning model, probably your choice is to use
    some popular Python library such as PyTorch or TensorFlow. However, it is well-known
    that the core of these libraries run C/C++ code underneath. Also, as we mentioned
    before, you might use GPUs to speed up processing. That’s where CUDA comes in!
    CUDA stands for *Compute Unified Architecture* and it is a platform developed
    by NVIDIA for general-purpose processing on their GPUs. Thus, while DirectX is
    used by game engines to handle graphical computation, CUDA enables developers
    to integrate NVIDIA’s GPU computational power into their general-purpose software
    applications, extending beyond just graphics rendering.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行一些深度学习模型时，你可能会选择使用一些流行的Python库，如PyTorch或TensorFlow。然而，众所周知，这些库的核心在底层运行的是C/C++代码。另外，正如我们之前提到的，你可能会使用GPU来加速处理。这时，CUDA就派上用场了！CUDA代表*计算统一架构*，它是NVIDIA为其GPU上的通用处理开发的平台。因此，尽管DirectX被游戏引擎用来处理图形计算，CUDA使开发人员能够将NVIDIA的GPU计算能力集成到他们的通用软件应用中，超越了仅仅是图形渲染的应用。
- en: In order to implement that, CUDA provides a simple C/C++ based interface (CUDA
    C/C++) that grants access to the GPU’s virtual intruction set and specific operations
    (such as moving data between CPU and GPU).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，CUDA提供了一个简单的基于C/C++的接口（CUDA C/C++），使得可以访问GPU的虚拟指令集和特定操作（如在CPU和GPU之间移动数据）。
- en: 'Before we go further, let’s understand some basic CUDA Programming concepts
    and terminology:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步探讨之前，让我们先理解一些基本的CUDA编程概念和术语：
- en: '*host*: refers to the CPU and its memory;'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*host*：指的是CPU及其内存；'
- en: '*device*: refers to the GPU and its memory;'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*device*：指的是GPU及其内存；'
- en: '*kernel*: refers to a function that is executed on the device (GPU);'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kernel*：指的是在设备（GPU）上执行的函数；'
- en: So, in a basic code written using CUDA, the program runs on the *host* (CPU)*,*
    sends data to the *device* (GPU) and launches *kernels* (functions) to be executed
    on the *device* (GPU)*.* These kernels are executed by several threads in parallel.
    After the execution, the results are transfered back from the *device* (*GP*U)
    to the *host* (CPU).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在使用CUDA编写的基本代码中，程序在*host*（CPU）上运行，发送数据到*device*（GPU），并启动在*device*（GPU）上执行的*kernels*（函数）。这些内核由多个线程并行执行。执行后，结果从*device*（GPU）传回*host*（CPU）。
- en: 'So let’s go back to our problem of adding two vectors:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到添加两个向量的问题：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In CUDA C/C++, the programmers can define C/C++ functions, called *kernels*,
    that when called, are executed N times in parallel by N different CUDA threads.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在CUDA C/C++中，程序员可以定义C/C++函数，称为*kernels*，当调用时，这些内核会被N个不同的CUDA线程并行执行N次。
- en: 'To define a kernel, you can use a `__global__` declaration specifier, and the
    number of CUDA threads that execute this kernel can be specified using `<<<...>>>`
    notation:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要定义一个内核，你可以使用`__global__`声明符，并且执行此内核的CUDA线程数可以通过`<<<...>>>`符号来指定：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Each thread executes the kernel and is given a unique thread ID `threadIdx`
    accessible within the kernel through built-in variables. The code above adds two
    vectors A and B, of size N and stores the result into vector C. As you can notice,
    instead of a loop to execute each pair-wise addition sequentially, CUDA allows
    us to perform all of these operations simultaneously, using N threads in parallel.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 每个线程执行内核，并被赋予一个唯一的线程ID `threadIdx`，可以通过内置变量在内核中访问。上面的代码将两个大小为N的向量A和B相加，并将结果存储到向量C中。正如你所注意到的，与其使用循环顺序执行每对加法操作，CUDA允许我们同时执行所有这些操作，使用N个线程并行处理。
- en: 'But before we can run this code, we need to do another modification. It is
    important to remember that the *kernel* function runs within the device (GPU).
    So all of its data needs to be stored in the device memory. You can do this by
    using the following CUDA built-in functions:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们能够运行此代码之前，还需要进行另一个修改。重要的是要记住，*内核*函数是在设备（GPU）内运行的。因此，所有数据都需要存储在设备内存中。您可以通过以下CUDA内置函数来实现：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Instead of directly passing variables A, B and C to the *kernel*, we need to
    use pointers. In CUDA programming, you can’t directly use *host* arrays (like
    `A`, `B`, and `C` in the example) within kernel launches (`<<<...>>>`). CUDA kernels
    operate on device memory, so you need to pass device pointers (`d_A`, `d_B`, and
    `d_C`) to the kernel for it to operate on.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用指针，而不是直接将变量A、B和C传递给*内核*。在CUDA编程中，不能直接在内核启动（`<<<...>>>`）中使用*主机*数组（如示例中的`A`、`B`和`C`）。CUDA内核在设备内存上操作，因此需要将设备指针（`d_A`、`d_B`和`d_C`）传递给内核，以便它能够在设备上执行操作。
- en: Beyond that, we need to allocate memory on the *device* by using `cudaMalloc`,
    and copy data between *host* and *device* using `cudaMemcpy.`
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们需要使用`cudaMalloc`在*设备*上分配内存，并使用`cudaMemcpy`在*主机*和*设备*之间复制数据。
- en: Now we can add the initialization of vectors A and B, and refresh cuda memory
    at the end of the code.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以添加向量A和B的初始化，并在代码末尾刷新cuda内存。
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Also, we need to add `cudaDeviceSynchronize();` after we call the kernel. This
    is a function used to synchronize the host thread with the device. When this function
    is called, the host thread will wait until all previously issued CUDA commands
    on the device are completed before continuing execution.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们在调用内核之后需要添加`cudaDeviceSynchronize();`。这是一个用于同步主机线程和设备的函数。调用此函数时，主机线程将等待，直到设备上所有先前发出的CUDA命令完成，才会继续执行。
- en: Beyond that, it is important to add some CUDA error checking so we can identify
    bugs on GPU. If we do not add this checking, the code will continues execution
    of the *host* thread (CPU) and it will be difficult to identify CUDA related errors.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，添加一些CUDA错误检查非常重要，这样我们才能在GPU上识别出错误。如果不添加此检查，代码将继续执行*主机*线程（CPU），并且很难识别与CUDA相关的错误。
- en: 'The implementation of both techniques below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是这两种技术的实现：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To compile and run the CUDA code, you’ll need to ensure that the CUDA toolkit
    is installed on your system. Then, you can compile the code using `nvcc`, the
    NVIDIA CUDA Compiler. If you don’t have a GPU on your machine, you can use Google
    Colab. You just need to select a GPU on Runtime → Notebook settings, then save
    the code on a `example.cu` file and run:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行CUDA代码，您需要确保CUDA工具包已安装在您的系统上。然后，您可以使用`nvcc`，NVIDIA CUDA编译器，来编译代码。如果您的计算机上没有GPU，可以使用Google
    Colab。只需要在运行时→笔记本设置中选择一个GPU，然后将代码保存到`example.cu`文件中并运行：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'However, our code still is not fully optimized. The example above uses a vector
    of size N = 1000\. But, this is a small number that will not fully demonstrate
    the GPU’s parallelization capability. Also, when dealing with deep learning problem,
    we often handle massive vectors with millions of parameters. However, if we try
    settings, for example, N = 500000 and run the kernel with `<<<1, 500000>>>` using
    the example above, it will throw an error. Thus, to improve the code and perform
    such operation, we first need to understand an important concept of CUDA programming:
    Thread hierarchy.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的代码仍然没有完全优化。上面的示例使用了一个大小为N = 1000的向量。但这是一个小数字，无法充分展示GPU的并行化能力。此外，在处理深度学习问题时，我们通常会处理具有数百万个参数的大规模向量。然而，如果我们尝试设置，例如，N
    = 500000并使用`<<<1, 500000>>>`运行上面的内核，它将抛出一个错误。因此，为了改进代码并执行此类操作，我们首先需要了解CUDA编程中的一个重要概念：线程层次结构。
- en: Thread hierarchy
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程层次结构
- en: The calling of kernel functions is done using the notation `<<<number_of_blocks,
    threads_per_block>>>`. So, in our example above, we run 1 block with N CUDA threads.
    However, each block has a limit on the number of threads it can support. This
    occurs because every thread within a block is required to be located on the same
    streaming multiprocessor core and must share the memory resources of that core.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 内核函数的调用使用`<<<number_of_blocks, threads_per_block>>>`表示法进行。因此，在我们上面的示例中，我们运行1个块，包含N个CUDA线程。然而，每个块对其支持的线程数量有限制。这是因为每个块中的线程都需要位于同一个流式多处理器核心，并且必须共享该核心的内存资源。
- en: 'You can get this limit using the following snippet of code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码片段获取此限制：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'On current Colab GPUs, a thread block may contain up to 1024 threads. Thus,
    we need more blocks to execute much more threads in order to process a massive
    vector in the example. Also, blocks are organized into grids, as illustrated below:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的Colab GPU上，一个线程块最多可以包含1024个线程。因此，我们需要更多的块来执行更多的线程，以处理示例中的大向量。此外，块被组织成网格，如下所示：
- en: '![](../Images/748e7f97d26b7d7fa6f8f8ed799b0c0a.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/748e7f97d26b7d7fa6f8f8ed799b0c0a.png)'
- en: '[https://handwiki.org/wiki/index.php?curid=1157670](https://handwiki.org/wiki/index.php?curid=1157670)
    ([CC BY-SA 3.0)](https://creativecommons.org/licenses/by-sa/3.0/%7C)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://handwiki.org/wiki/index.php?curid=1157670](https://handwiki.org/wiki/index.php?curid=1157670)
    ([CC BY-SA 3.0)](https://creativecommons.org/licenses/by-sa/3.0/%7C)'
- en: 'Now, the thread ID can be accessed using:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可以使用以下方式访问线程ID：
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'So, our script becomes:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们的脚本变成了：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Performance comparison
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能比较
- en: Below a comparison of CPU and GPU computation of this adding two vector operation
    for different vector sizes.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是不同向量大小下CPU和GPU进行这两个向量加法操作的比较。
- en: '![](../Images/b8e80e991576bd43865f4bd9783f4b52.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8e80e991576bd43865f4bd9783f4b52.png)'
- en: Image by the author
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: As one can see, the advantage of GPU processing only becomes apparent with a
    large vector size N. Also, remember that this time comparison is only considering
    the execution of the kernel/function. It is not taking into account the time to
    copy data between *host* and *device*, which although may not be significant on
    most cases, it is relatively considerable in our case as we are performing only
    a simple addition operation. Therefore, it is important to remember that GPU computation
    only demonstrates its advantage when dealing with highly compute-intensive computations
    that are also highly parallelized.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，GPU处理的优势只有在向量大小N非常大的情况下才会显现出来。此外，请记住，这个时间比较仅仅考虑了内核/函数的执行时间，并没有考虑在*主机*和*设备*之间复制数据的时间，尽管在大多数情况下这个时间可能不显著，但在我们这个简单的加法操作中，它相对来说是比较可观的。因此，重要的是要记住，GPU计算只有在处理高度计算密集且高度并行的计算时才展示其优势。
- en: Multidimensional threads
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多维线程
- en: Okay, now we know how to increase performance of a simple array operation. But
    when dealing with deep learning models, we need to handle matrix and tensor operations.
    In our previous example, we only used one-dimensional blocks with N threads. However,
    it is also possible to execute multidimensional thread blocks (up to 3 dimensions).
    So, for convenience you can run a thread block of NxM threads if you need to run
    matrix operations. In this case, you could obtain the matrix rows columns indices
    as `row = threadIdx.x, col = threadIdx.y`. Also, for convenience, you can use
    `dim3` variable type to define the `number_of_blocks` and `threads_per_block.`
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，现在我们知道如何提高一个简单数组操作的性能。但在处理深度学习模型时，我们需要处理矩阵和张量操作。在我们之前的示例中，我们只使用了一维块和N个线程。然而，也可以执行多维线程块（最多支持3个维度）。因此，为了方便起见，如果你需要执行矩阵操作，你可以运行一个NxM线程的线程块。在这种情况下，你可以获取矩阵的行列索引，方法是`row
    = threadIdx.x, col = threadIdx.y`。同样，为了方便，你可以使用`dim3`变量类型来定义`number_of_blocks`和`threads_per_block`。
- en: The example below illustrates how to add two matrices.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的示例演示了如何加法两个矩阵。
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can also extend this example to handle multiple blocks:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以扩展这个示例来处理多个块：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can also extend this example to process 3-dimensional operations using the
    same idea.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用相同的思路扩展这个示例来处理三维操作。
- en: 'Now that you know how to operate multidimensional data, there is another important
    and simple concept to learn: how to call functions within a kernel. Basically
    this is simply done by using a `__device__` declaration specifier. This defines
    functions that can be called by the *device* (GPU) directly. Thus, they can only
    be called from `__global__` or another `__device__` function. The example below
    apply a sigmoid operation to a vector (very common operation on deep learning
    models).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道如何操作多维数据了，还有一个重要且简单的概念需要学习：如何在内核中调用函数。基本上，这是通过使用`__device__`声明修饰符来完成的。这定义了可以由*设备*（GPU）直接调用的函数。因此，它们只能从`__global__`或另一个`__device__`函数中调用。下面的示例对向量应用了sigmoid操作（这是深度学习模型中非常常见的操作）。
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'So, now that you know the basic important concepts of CUDA programming, you
    can start creating CUDA kernels. In the case of deep learning models, they are
    basically a bunch of matrix and tensor operations such as sum, multiplication,
    convolution, normalization and others. For instance, a naive matrix multiplication
    algorithm can be parallelized as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在你已经了解了CUDA编程的一些基本重要概念，你可以开始创建CUDA内核。在深度学习模型的情况下，它们基本上是一些矩阵和张量操作，如加法、乘法、卷积、归一化等。例如，一个简单的矩阵乘法算法可以像下面这样进行并行化：
- en: '![](../Images/eea3441283b27a0b357d8f148ba9f6e5.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eea3441283b27a0b357d8f148ba9f6e5.png)'
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now compare this with a normal CPU implementation of two matrices multiplication
    below:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将这个与下面的普通CPU实现的两个矩阵乘法进行对比：
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can notice that on the GPU version we have less loops, resulting in a faster
    processing of the operation. Below is a comparison of performance between CPU
    and GPU of NxN matrix multiplications:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以注意到，在GPU版本中，我们的循环次数更少，从而使得操作的处理速度更快。下面是CPU和GPU在NxN矩阵乘法性能对比：
- en: '![](../Images/fa9aef35ede725268ad91f948b4e9ca6.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa9aef35ede725268ad91f948b4e9ca6.png)'
- en: Image by the author
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: As you may observe, the performance improvement of GPU processing is even higher
    for matrix multiplication operations as the matrix size increases.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所观察到的，随着矩阵大小的增加，GPU处理的性能提升在矩阵乘法操作中表现得更加明显。
- en: 'Now, consider a basic neural network, which mostly involves **y** = σ(W**x**
    + **b**) operations, as shown below:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑一个基本的神经网络，它主要涉及**y** = σ(W**x** + **b**)的操作，如下所示：
- en: '![](../Images/568620fec12aad34ce87ccd1c37caaca.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/568620fec12aad34ce87ccd1c37caaca.png)'
- en: Image by the author
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: These operations primarily comprise matrix multiplication, matrix addition,
    and applying a function to an array, all of which you’re already familiar with
    the parallelization techniques. Thus, you are now capable of implementing your
    own neural network that runs on GPUs from scratch!
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作主要包括矩阵乘法、矩阵加法和对数组应用函数，所有这些你已经熟悉并行化技术。因此，现在你已经能够从零开始实现一个运行在GPU上的神经网络！
- en: Conclusion
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this post we covered introductory concepts regarding GPU processing to enhance
    deep learning models performance. However, it is also important to mention that
    the concepts you have seen are only the basics and there is a lot more to be learned.
    Libraries like PyTorch and Tensorflow implement optimization techniques that involves
    other more complex concepts such as optimized memory access, batched operations
    and others (they harness libraries built on top of CUDA, such as cuBLAS and cuDNN).
    However, I hope this post helps clear up what goes on behind the scenes when you
    write `.to("cuda")` and execute deep learning models on GPUs.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了关于GPU处理的基础概念，以提高深度学习模型的性能。然而，也需要提到的是，你所看到的这些概念仅仅是基础，还有很多东西需要学习。像PyTorch和TensorFlow这样的库实现了优化技术，涉及其他更复杂的概念，如优化内存访问、批处理操作等（它们利用了基于CUDA的库，如cuBLAS和cuDNN）。但我希望这篇文章能帮助你理清当你编写`.to("cuda")`并在GPU上执行深度学习模型时，背后发生了什么。
- en: In future posts, I will try to bring more complex concepts regarding CUDA Programming.
    Please let me know what you think or what you would like me to write about next
    in the comments! Thanks so much for reading! 😊
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来的文章中，我将尝试带来更多关于CUDA编程的复杂概念。请在评论中告诉我你对这篇文章的看法，或者你希望我接下来写些什么！非常感谢你的阅读！😊
- en: Further reading
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[CUDA Programming Guide](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf)
    — NVIDIA CUDA Programming documentation.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[CUDA编程指南](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf) —
    NVIDIA CUDA编程文档。'
- en: '[CUDA Documentation](https://docs.nvidia.com/cuda/) — NVIDIA complete CUDA
    documentation.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[CUDA文档](https://docs.nvidia.com/cuda/) — NVIDIA完整的CUDA文档。'
- en: '[CUDA Neural Network training implementation](https://luniak.io/cuda-neural-network-implementation-part-1/)
    — Pure CUDA C++ implementation of a neural network training.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[CUDA神经网络训练实现](https://luniak.io/cuda-neural-network-implementation-part-1/)
    — 用纯CUDA C++实现的神经网络训练。'
- en: '[CUDA LLM training implementation](https://github.com/karpathy/llm.c) — Training
    implementation of LLM with pure CUDA C.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[CUDA LLM训练实现](https://github.com/karpathy/llm.c) — 用纯CUDA C实现的LLM训练。'
