<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>De-biasing Treatment Effects with Double Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>De-biasing Treatment Effects with Double Machine Learning</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/de-biasing-treatment-effects-with-double-machine-learning-63b16fcb3e97?source=collection_archive---------2-----------------------#2024-04-05">https://towardsdatascience.com/de-biasing-treatment-effects-with-double-machine-learning-63b16fcb3e97?source=collection_archive---------2-----------------------#2024-04-05</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="a79c" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Causal AI, exploring the integration of causal reasoning into machine learning</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@raz1470?source=post_page---byline--63b16fcb3e97--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ryan O'Sullivan" class="l ep by dd de cx" src="../Images/7cd161d38d67d2c0b7da2d8f3e7d33fe.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*tAw1S072P0f0sUswKPN6VQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--63b16fcb3e97--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@raz1470?source=post_page---byline--63b16fcb3e97--------------------------------" rel="noopener follow">Ryan O'Sullivan</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--63b16fcb3e97--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 5, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/ab5fa72d3cb69f3db74f7b4b8b53bf4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kJZ-OljykNeCuVmu"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@alesnesetril?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ales Nesetril</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="fdb9" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk"><strong class="al">What is this series of articles about?</strong></h1><p id="352f" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Welcome to my series on Causal AI, where we will explore the integration of causal reasoning into machine learning models. Expect to explore a number of practical applications across different business contexts.</p><p id="9187" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In the last article we explored <em class="pa">making Causal Discovery work in real-world business settings</em>. This time we will cover <em class="pa">de-biasing treatment effects with Double Machine Learning</em>.</p><p id="b62d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">If you missed the last article on Causal Discovery, check it out here:</p><div class="pb pc pd pe pf pg"><a rel="noopener follow" target="_blank" href="/making-causal-discovery-work-in-real-world-business-settings-80e80c5f66b8?source=post_page-----63b16fcb3e97--------------------------------"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">Making Causal Discovery work in real-world business settings</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">Causal AI, exploring the integration of causal reasoning into machine learning</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">towardsdatascience.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu lr pg"/></div></div></a></div><h1 id="125c" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Introduction</h1><p id="befc" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">This article will demonstrate why Double Machine Learning is an essential part of the Causal AI toolbox:</p><p id="08a4" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><strong class="ob fr">Expect to gain a deep understanding of:</strong></p><ul class=""><li id="03ea" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">Average treatment effects (ATE)</li><li id="11d1" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">The challenges of using Linear Regression to estimate ATE</li><li id="88c5" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Double Machine Learning and how it overcomes the challenges Linear Regression faces</li><li id="2b50" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">A worked case study in Python illustrating how to apply Double Machine Learning.</li></ul><p id="b8cf" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The full notebook can be found here:</p><div class="pb pc pd pe pf pg"><a href="https://github.com/raz1470/causal_ai/blob/main/notebooks/estimating%20average%20treatment%20effects%20with%20double%20machine%20learning.ipynb?source=post_page-----63b16fcb3e97--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">causal_ai/notebooks/estimating average treatment effects with double machine learning.ipynb at main…</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">This project introduces Causal AI and how it can drive business value. - causal_ai/notebooks/estimating average…</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">github.com</p></div></div><div class="pp l"><div class="qd l pr ps pt pp pu lr pg"/></div></div></a></div><h1 id="87bb" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Average Treatment Effects (ATE)</h1><h2 id="4cd4" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">ATE</h2><p id="e28d" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">ATE is the average impact of a treatment or intervention on a population. We can calculate it by comparing the average change in a chosen metric between a treatment and control group.</p><p id="e786" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">For example, consider a marketing team is running a promotion. The treatment group consists of customers who receive an offer, while the control group consists of customers who didn’t. We can calculate ATE comparing the average number of orders in the treatment and control group.</p><h2 id="02be" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Potential outcomes framework</h2><p id="9cb3" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">The potential outcomes framework was developed by Donald Rubin and has become a foundational concept in causal inference. Lets try and understand it using the example above from the marketing team.</p><ol class=""><li id="4fdb" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qv pw px bk"><strong class="ob fr"><em class="pa">Treatment assignment:</em></strong> Each customer has two potential outcomes, the outcome of being in the treatment group (sent offer) and the outcome of being in the control group (not sent offer). However, only one potential outcome is observed for each customer.</li><li id="3757" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou qv pw px bk"><strong class="ob fr"><em class="pa">Counterfactuals:</em></strong> The potential outcome which is not observed is a counterfactual e.g. what would have happened if this customer was in the control group (not sent offer).</li><li id="45d8" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou qv pw px bk"><strong class="ob fr"><em class="pa">Causal effect: </em></strong>The causal effect of a treatment is the difference between the potential outcomes under different treatment conditions (sent off vs not sent offer).</li><li id="1f02" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou qv pw px bk"><strong class="ob fr"><em class="pa">Estimation:</em></strong> Causal effects can be estimated using experimental or observational data using a range of causal techniques.</li></ol><p id="fa49" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Several assumptions are made to help ensure the estimated effects are valid:</p><ul class=""><li id="3c6e" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr"><em class="pa">Stable Unit Treatment Value Assumption (SUTVA):</em></strong> The potential outcome for any customer is unaffected by the treatment assignment of other customers.</li><li id="8ff7" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr"><em class="pa">Positivity: </em></strong>For any combination of features, there must be some probability that a customer could receive either treatment or control</li><li id="954a" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr"><em class="pa">Ignorability:</em></strong> All confounders which effects both treatment and outcome are observed.</li></ul><h2 id="13b6" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Experimental data</h2><p id="336e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Estimating ATE with experimental data is relatively straightforward.</p><p id="1b34" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Randomised Controlled Trials (RCTs) or AB tests are designed to randomly assign participants to treatment and control groups. This ensures that any differences in outcomes can be attributed to the treatment effect rather than pre-existing characteristics of the participants.</p><p id="66c7" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Back to the example from the marketing team. If they randomly split customers between the treatment and control group, the average difference in orders is the causal effect of the offer sent.</p><h2 id="a8d1" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Observational data</h2><p id="323f" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Estimating ATE using observational data is more challenging.</p><p id="6071" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The most common challenge is confounding variables which effect both the treatment and outcome. Failure to control for confounders will lead to biased estimates of the treatment effect. We will come back to this later in the article in the worked case study.</p><p id="2b2e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Other challenges include:</p><ul class=""><li id="8284" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">Selection bias — The treatment assignment is influenced by factors related to the outcome.</li><li id="9b16" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Heterogenous treatment effects — The treatment effect varies across different subgroups of the population.</li></ul><h1 id="0cc5" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Estimating ATE using Linear Regression</h1><h2 id="e1d2" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Overview</h2><p id="bb3c" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Linear regression can be used to estimate ATE using observational data. The treatment (T) and control features (X) are included as variables in the model.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qw"><img src="../Images/7376810d24b3d2809491a9d3a5ef646c.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*26cQWQdjIOGl0jELgZj3wg.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Use generated image</figcaption></figure><p id="c0ca" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The coefficient of the treatment variable is the ATE — the average change in the outcome variable associated with a unit change in the treatment variable, while keeping control features constant.</p><h2 id="c95f" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Data-generating process</h2><p id="d03e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">We can use a simple data-generating process with one outcome, treatment and confounder to illustrate how we can use linear regression to estimate ATE.</p><p id="d7b6" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">First of all we can visualise the causal graph:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="8403" class="rb ne fq qy b bg rc rd l re rf"># Create node lookup variables<br/>node_lookup = {0: 'Confounder',<br/>               1: 'Treatment',<br/>               2: 'Outcome'                                                                                       <br/> }<br/><br/>total_nodes = len(node_lookup)<br/><br/># Create adjacency matrix - this is the base for our graph<br/>graph_actual = np.zeros((total_nodes, total_nodes))<br/><br/># Create graph using expert domain knowledge<br/>graph_actual[0, 1] = 1.0 # Confounder -&gt; Treatment<br/>graph_actual[0, 2] = 1.0 # Confounder -&gt; Outcome<br/>graph_actual[1, 2] = 1.0 # Treatment -&gt; Outcome<br/>     <br/>plot_graph(input_graph=graph_actual, node_lookup=node_lookup)</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rg"><img src="../Images/47433c1ed4b55f5eea942decc7e270bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*1IqytdkG4LzsfikZhetnRg.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="7171" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">And then we can create samples using the simple data-generating process. Pay close attention to the coefficient of the treatment variable (0.75) — this is our ground truth ATE.</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="06fe" class="rb ne fq qy b bg rc rd l re rf">np.random.seed(123)<br/><br/># Create dataframe with a confounder, treatment and outcome<br/>df = pd.DataFrame(columns=['Confounder', 'Treatment', 'Outcome'])<br/>df['Confounder'] = np.random.normal(loc=100, scale=25, size=1000)<br/>df['Treatment'] = np.random.normal(loc=50, scale=10, size=1000) + 0.50 * df['Confounder']<br/>df['Outcome'] = 0.25 * df['Confounder'] + 0.75 * df['Treatment'] + np.random.normal(loc=0, scale=5, size=1000)<br/><br/>sns.pairplot(df, corner=True)</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rh"><img src="../Images/685d36d4f99ac2ed2f3144007ec5c5cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Ra13dGfxBc9_EMpGVBD_A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><h2 id="5973" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Linear regression</h2><p id="601f" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">We can then train a linear regression model and extract the coefficient of the treatment variable — We can see that it correctly estimates the ATE (0.75).</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="805e" class="rb ne fq qy b bg rc rd l re rf"># Set target and features<br/>y = df['Outcome']<br/>X = df[['Confounder', 'Treatment']]<br/><br/># Train model <br/>model = RidgeCV()<br/>model = model.fit(X, y)<br/><br/># Extract the treatment coefficient<br/>ate_lr = round(model.coef_[1], 2)<br/><br/>print(f'The average treatment effect using Linear Regression is: {ate_lr}')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ri"><img src="../Images/40ba21494af79a37542ae973b900291c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*WT_FW4e57p4vbgXbJQPdyQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><h2 id="3d9b" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Challenges</h2><p id="755e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Linear regression can be a very effective method for estimating ATE. However, there are some challenges to be aware of:</p><ul class=""><li id="01ba" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">It struggles when we have high-dimensional data.</li><li id="f488" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">The “nuisance parameters” (the control features which are a “nuisance” to estimate) may be too complex for linear regression to estimate.</li><li id="b110" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">It assumes the treatment effect is constant across different subgroups of the population (e.g. no heterogeneity).</li><li id="33c6" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Assumes no unobserved confounders.</li><li id="430f" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Assumes that the treatment effect is linear.</li></ul><h1 id="6107" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Double Machine Learning (DML)</h1><h2 id="f833" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Overview</h2><p id="fd21" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Double Machine Learning is a causal method first introduced in 2017 in the paper “Double/Debiased Machine Learning for Treatment and Structural Parameters”:</p><div class="pb pc pd pe pf pg"><a href="https://arxiv.org/abs/1608.00060?source=post_page-----63b16fcb3e97--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">Double/Debiased Machine Learning for Treatment and Causal Parameters</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">Most modern supervised statistical/machine learning (ML) methods are explicitly designed to solve prediction problems…</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">arxiv.org</p></div></div><div class="pp l"><div class="rj l pr ps pt pp pu lr pg"/></div></div></a></div><p id="e498" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">It aims to reduce bias and improve the estimation of causal effects in situations where we have high-dimensional data and/or complex nuisance parameters.</p><p id="9fd8" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">It is inspired by the Frisch-Waugh-Lovell theorem, so let’s start by understanding this.</p><h2 id="62f2" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Frisch-Waugh-Lovell theorem</h2><p id="d062" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">The FWL theorem is used to decompose the effects of multiple regressors on an outcome variable, allowing us to isolate effects of interest.</p><p id="e565" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Imagine you had two sets of features, X1 and X2. You could estimate the model parameters using linear regression like we did before. However, you can also get the same parameter for X1 by following these steps:</p><ol class=""><li id="44f2" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qv pw px bk">Use X2 only to predict the outcome</li><li id="d13f" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou qv pw px bk">Use X2 only to predict X1</li><li id="23fc" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou qv pw px bk">Calculate the residuals from the outcome model (step 1) and feature model (step 2)</li><li id="1b09" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou qv pw px bk">Regress the residuals of the outcome model on the residuals of the feature model to estimate the parameter for X1</li></ol><p id="cf1f" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">At first glance this can be quite hard to follow, so let’s try it out in Python to illustrate. We use the same data as before, but take the treatment column as X1 and the confounder column as X2:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="7cda" class="rb ne fq qy b bg rc rd l re rf"># Set treatment, outcome and confounder samples<br/>treatment = df['Treatment'].to_numpy().reshape(-1,1)<br/>outcome = df['Outcome'].to_numpy().reshape(-1,1)<br/>confounder = df['Confounder'].to_numpy().reshape(-1,1)<br/><br/># Train treatment model and calculate residuals<br/>treatment_model = RidgeCV()<br/>treatment_model = treatment_model.fit(confounder, treatment)<br/>treatment_pred = treatment_model.predict(confounder)<br/>treatment_residuals = treatment - treatment_pred<br/><br/># Train outcome model and calculate residuals<br/>outcome_model = RidgeCV()<br/>outcome_model = outcome_model.fit(confounder, outcome)<br/>outcome_pred = outcome_model.predict(confounder)<br/>outcome_residuals = outcome - outcome_pred<br/><br/># Train residual model and calculate average treatment effect<br/>final_model = RidgeCV()<br/>final_model = final_model.fit(treatment_residuals, outcome_residuals)<br/>ate_dml = round(final_model.coef_[0][0], 2)<br/><br/>print(f'The average treatment effect is: {ate_fwl}')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rk"><img src="../Images/65373cb179311c38f15b7dee86f3957a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*8gJhivrl27xsUrvtK8C_bA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="ae23" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We can see that it correctly estimates the coefficient of the treatment variable (0.75).</p><h2 id="f092" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Double Machine Learning</h2><p id="76f5" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Double Machine Learning builds upon FWL by isolating the effects of treatment and control features and by using flexible machine learning models.</p><p id="5971" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The first stage is often referred to as orthogonalization as the nuisance parameters are estimated independently of the treatment effect estimation.</p><p id="a360" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">First stage:</p><ul class=""><li id="7edf" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr"><em class="pa">Treatment model (de-biasing):</em></strong> Machine learning model used to estimate the probability of treatment assignment (often referred to as propensity score). The treatment model residuals are then calculated.</li><li id="f07c" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr"><em class="pa">Outcome model (de-noising):</em></strong> Machine learning model used to estimate the outcome using just the control features. The outcome model residuals are then calculated.</li></ul><p id="795f" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Second stage:</p><ul class=""><li id="5baf" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">The treatment model residuals are used to predict the outcome model residuals.</li></ul><p id="c688" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The coefficient of the second stage model is the ATE. It is worth noting that the second stage model is a linear model, meaning we are assuming our treatment effect is linear (this is why we call DML a partially linear model).</p><p id="6671" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Rather than code it up ourselves we can use the Microsoft package EconML. EconML has a wide range of Causal ML techniques implemented including a number of implementations of DML:</p><div class="pb pc pd pe pf pg"><a href="https://econml.azurewebsites.net/?source=post_page-----63b16fcb3e97--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">Welcome to econml's documentation! - econml 0.15.0 documentation</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">Estimation Methods for Dynamic Treatment Regimes</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">econml.azurewebsites.net</p></div></div><div class="pp l"><div class="rl l pr ps pt pp pu lr pg"/></div></div></a></div><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="248d" class="rb ne fq qy b bg rc rd l re rf"># Train DML model<br/>dml = LinearDML(discrete_treatment=False)<br/>dml.fit(df['Outcome'].to_numpy().reshape(-1,1), T=df['Treatment'].to_numpy().reshape(-1,1), X=None, W=df['Confounder'].to_numpy().reshape(-1,1))<br/><br/># Calculate average treatment effect<br/>ate_dml = round(dml.ate()[0], 2)<br/><br/>print(f'The average treatment effect using the DML is: {ate_dml}')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rm"><img src="../Images/114df1a5af40ff552d6988100f981da2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*2HvZVt9_z6X9qQ55c5mwAA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="eec9" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We again can see that it correctly estimates the coefficient of the treatment variable (0.75).</p><h1 id="b276" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Marketing Case Study</h1><h2 id="8e9a" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Background</h2><p id="c26e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">The Marketing team send attractive offers to selected customers. They don’t currently hold out a randomly selected sample of customers to measure the impact of the offers.</p><p id="bf76" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The Data Science team is asked to estimate how the offers affect customer orders.</p><h2 id="3cb1" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Confounding bias</h2><p id="0123" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Naively comparing customers who were and weren’t sent offers is biased. This is driven by confounding factors:</p><ul class=""><li id="9178" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">Customers who opt-out of email can’t receive an offer - this population is less engaged and less likely to order.</li><li id="0d30" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">The CRM team target customers based on their order history — order history effects how likely you are to order again.</li></ul><h2 id="92d3" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Data generating process</h2><p id="131c" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">We set up a data generating process with the following characteristics:</p><ul class=""><li id="0755" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">Difficult nuisance parameters</li><li id="bf08" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Simple treatment effect (no heterogeneity)</li></ul><p id="7cbb" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The X features are customer characteristics taken before the treatment:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rn"><img src="../Images/8afb0c2d4588af0545c01cc9248d533d.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*x77ovi9hSa2IjJpoqQexbA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="9547" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">T is a binary flag indicating whether the customer received the offer.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ro"><img src="../Images/0c53dd6127d10b58a8b3d16279cac3b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aaQEc_52in_8gmJ6tiV12g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="ee19" class="rb ne fq qy b bg rc rd l re rf">np.random.seed(123)<br/><br/># Set number of observations<br/>n=100000<br/><br/># Set number of features<br/>p=10<br/><br/># Create features<br/>X = np.random.uniform(size=n * p).reshape((n, -1))<br/><br/># Nuisance parameters<br/>b = (<br/>    np.sin(np.pi * X[:, 0] * X[:, 1])<br/>    + 2 * (X[:, 2] - 0.5) ** 2<br/>    + X[:, 3]<br/>    + 0.5 * X[:, 4]<br/>    + X[:, 5] * X[:, 6]<br/>    + X[:, 7] ** 3<br/>    + np.sin(np.pi * X[:, 8] * X[:, 9])<br/>)<br/><br/># Create binary treatment<br/>T = np.random.binomial(1, expit(b))<br/><br/># Set treatment effect<br/>tau = 0.75<br/><br/># Calculate outcome<br/>y = b + T * tau + np.random.normal(size=n)</span></pre><p id="5a0e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The data generating process python code is based on the synthetic data creator from Ubers Causal ML package. Being able to create realistic synthetic data is crucial when it comes to assessing causal inference methods so I highly recommend you check it out:</p><div class="pb pc pd pe pf pg"><a href="https://github.com/uber/causalml/blob/master/causalml/dataset/regression.py?source=post_page-----63b16fcb3e97--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">causalml/causalml/dataset/regression.py at master · uber/causalml</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">Uplift modeling and causal inference with machine learning algorithms - causalml/causalml/dataset/regression.py at…</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">github.com</p></div></div><div class="pp l"><div class="rp l pr ps pt pp pu lr pg"/></div></div></a></div><h2 id="3cf7" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Linear Regression</h2><p id="7c5e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">We start by using linear regression to estimate the ATE. Our expectation is that it will struggle to capture the nuisance parameters and then potentially mis-specify the treatment effect.</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="1f14" class="rb ne fq qy b bg rc rd l re rf"># Append features and treatment<br/>X_T = np.append(X, T.reshape(-1, 1), axis=1)<br/><br/># Train linear regression model <br/>model = RidgeCV()<br/>model = model.fit(X_T, y)<br/>y_pred = model.predict(X_T)<br/><br/># Extract the treatment coefficient<br/>ate_lr = round(model.coef_[-1], 2)<br/><br/>print(f'The average treatment effect using Linear Regression is: {ate_lr}')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rm"><img src="../Images/cfb31a3c1ca5076492b4b662a5aec340.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*JUnjnRop8pJHFLqwS4UL9w.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><h2 id="106a" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Double Machine Learning</h2><p id="d5da" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">We then train a DML model using LightGBM as flexible first stage models. This should allow us to capture the difficult nuisance parameters whilst correctly calculating the treatment effect.</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="e5d7" class="rb ne fq qy b bg rc rd l re rf">np.random.seed(123)<br/><br/># Train DML model using flexible stage 1 models<br/>dml = LinearDML(model_y=LGBMRegressor(), model_t=LGBMClassifier(), discrete_treatment=True)<br/>dml.fit(y, T=T, X=None, W=X)<br/><br/># Calculate average treatment effect<br/>ate_dml = round(dml.ate(), 2)<br/><br/>print(f'The average treatment effect using the DML is: {ate_dml}')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rq"><img src="../Images/846376efd6ddfe95c40381066958beb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*f9H1xaeiHjnW_o5Vq8JNXA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><h2 id="76a7" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Comparison</h2><p id="556a" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">When we compare the results, we observe that linear regression gives us a biased estimate whilst DML is very close to the ground truth. This really shows the power of DML!</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="02e4" class="rb ne fq qy b bg rc rd l re rf"># Plot comparison of results<br/>categories = ['Ground truth', 'DML', 'Linear Regression']<br/>sns.barplot(x=categories, y=[tau, ate_dml, ate_lr])<br/>plt.ylabel('ATE')<br/>plt.title('Average Treatment Effect comparison')<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rr"><img src="../Images/80196d33787aebf96e40acac24077d4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*l4Evld7kWKGvkB96jiOJ2A.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><h1 id="9102" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Other methods</h1><p id="90c5" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">There a several other causal methods which we can use to estimate ATE (a lot of which are implemented in both EconML and CausalML packages):</p><ul class=""><li id="41d2" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">Propensity score matching (PSM)</li><li id="6ebd" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Inverse-propensity score matching (IPSM)</li><li id="391f" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">S-Learner</li><li id="975e" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">T-Learner</li><li id="488b" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Doubly-Robust Learner (DR)</li><li id="7b6a" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Instrument variable learner (IV)</li></ul><p id="9b90" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">If you want to delve into these methods further, I would recommend starting with the S-Learner and T-Learner (often referred to as meta-learners). A couple of key learnings to help you start to work out when and where you could apply them:</p><ul class=""><li id="d8f9" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">When your treatment is binary, and your treatment and control size is equally balanced, the T-Learner is often a simpler alternative to DML.</li><li id="fe29" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">When your treatment is continuous, and you suspect the treatment effect may be non-linear, the S-Learner may be more appropriate than DML.</li><li id="5a4b" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Meta-learners can struggle with regularization bias (particularly the S-learner) — When we do see DML outperform meta-learners, this is usually the reason.</li></ul></div></div></div><div class="ab cb rs rt ru rv" role="separator"><span class="rw by bm rx ry rz"/><span class="rw by bm rx ry rz"/><span class="rw by bm rx ry"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="8270" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Follow me if you want to continue this journey into Causal AI — In the next article we will explore how we can estimate Conditional Average Treatment Effects (CATE) with Double Machine Learning to help us personalise treatments at a customer level.</p></div></div></div></div>    
</body>
</html>