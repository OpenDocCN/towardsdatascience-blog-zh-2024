<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Dummy Classifier, Explained: A Visual Guide with Code Examples for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Dummy Classifier, Explained: A Visual Guide with Code Examples for Beginners</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e?source=collection_archive---------3-----------------------#2024-08-14">https://towardsdatascience.com/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e?source=collection_archive---------3-----------------------#2024-08-14</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="9c21" class="fo fp fq bf b dy fr fs ft fu fv fw dx fx" aria-label="kicker paragraph">CLASSIFICATION ALGORITHM</h2><div/><div><h2 id="7433" class="pw-subtitle-paragraph gs fz fq bf b gt gu gv gw gx gy gz ha hb hc hd he hf hg hh cq dx">Setting the bar in machine learning with simple baseline models</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hi hj hk hl hm ab"><div><div class="ab hn"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@samybaladram?source=post_page---byline--009ff95fc86e--------------------------------" rel="noopener follow"><div class="l ho hp by hq hr"><div class="l ed"><img alt="Samy Baladram" class="l ep by dd de cx" src="../Images/715cb7af97c57601966c5d2f9edd0066.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="hs by l dd de em n ht eo"/></div></div></a></div></div><div class="hu ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--009ff95fc86e--------------------------------" rel="noopener follow"><div class="l hv hw by hq hx"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hy cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hs by l br hy em n ht eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hz ab q"><div class="ab q ia"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ib ic bk"><a class="af ag ah ai aj ak al am an ao ap aq ar id" data-testid="authorName" href="https://medium.com/@samybaladram?source=post_page---byline--009ff95fc86e--------------------------------" rel="noopener follow">Samy Baladram</a></p></div></div></div><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span><p class="bf b ib ic dx"><button class="ig ih ah ai aj ak al am an ao ap aq ar ii ij ik" disabled="">Follow</button></p></div></div></span></div></div><div class="l il"><span class="bf b bg z dx"><div class="ab cn im in io"><div class="ip iq ab"><div class="bf b bg z dx ab ir"><span class="is l il">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar id ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--009ff95fc86e--------------------------------" rel="noopener follow"><p class="bf b bg z it iu iv iw ix iy iz ja bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="jb jc l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span></div><span data-testid="storyPublishDate">Aug 14, 2024</span></div></span></div></span></div></div></div><div class="ab cp jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js"><div class="h k w ea eb q"><div class="ki l"><div class="ab q kj kk"><div class="pw-multi-vote-icon ed is kl km kn"><div class=""><div class="ko kp kq kr ks kt ku am kv kw kx kn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ky kz la lb lc ld le"><p class="bf b dy z dx"><span class="kp">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ko lh li ab q ee lj lk" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lg"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lf lg">3</span></p></button></div></div></div><div class="ab q jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="ll k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lm an ao ap ii ln lo lp" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lq cn"><div class="l ae"><div class="ab cb"><div class="lr ls lt lu lv lw ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/7d5f5043f52cd1660f09ce3ca7c6cdca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CXGTLNFmP20MOIGgWo9RrQ.png"/></div></div></figure><p id="6357" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><code class="cx ny nz oa ob b">â›³ï¸ More CLASSIFICATION ALGORITHM, explained:<br/> â–¶ <a class="af oc" rel="noopener" target="_blank" href="/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e">Dummy Classifier</a><br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1">K Nearest Neighbor Classifier</a><br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6">Bernoulli Naive Bayes</a><br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c">Gaussian Naive Bayes</a><br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e">Decision Tree Classifier</a><br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505">Logistic Regression</a><br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9">Support Vector Classifier</a><br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c">Multilayer Perceptron</a></code></p><p id="52e3" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Have you ever wondered how data scientists measure the performance of their machine learning models? Enter the dummy classifier â€” a simple yet powerful tool in the world of data science. Think of it as the baseline player in a game, setting the minimum standard that other, more sophisticated models need to beat.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/0a0897b06ce54ce8e54d961956cd7d50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eVxxKT4DKvRVuAHBGknJ7w.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">All visuals: Author-created using Canva Pro. Optimized for mobile; may appear oversized on desktop.</figcaption></figure><h1 id="ba4f" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Definition</h1><p id="3f7e" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">A dummy classifier is a simple machine learning model that makes predictions using basic rules, without actually learning from the input data. It serves as a baseline for comparing the performance of more complex models. The dummy classifier helps us understand if our sophisticated models are actually learning useful patterns or just guessing.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp pj"><img src="../Images/834c5b63a06e05517583e5ef01f746fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g25KZSSB_CqyebMcsSu6mg.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">Dummy Classifier is one of the basic key algorithms in machine learning.</figcaption></figure><h1 id="d1e6" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">ğŸ“Š Dataset &amp; Libraries</h1><p id="3a3f" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Throughout this article, weâ€™ll use this simple artificial golf dataset (inspired by [1]) as an example. This dataset predicts whether a person will play golf based on weather conditions. It includes features like outlook, temperature, humidity, and wind, with the target variable being whether to play golf or not.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp pk"><img src="../Images/e66ab987f34572e8d046e05b218444ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vqKw7VKWblzcHmNxFCoRsg.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">Columns: â€˜Outlookâ€™, â€˜Temperatureâ€™, â€˜Humidityâ€™, â€˜Windâ€™ and â€˜Playâ€™ (target feature)</figcaption></figure><pre class="mr ms mt mu mv pl ob pm bp pn bb bk"><span id="095a" class="po oj fq ob b bg pp pq l pr ps"># Import libraries<br/>from sklearn.model_selection import train_test_split<br/>import pandas as pd<br/><br/># Make a dataset<br/>dataset_dict = {<br/>    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain', 'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast', 'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'],<br/>    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],<br/>    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],<br/>    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],<br/>    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']<br/>}<br/>df = pd.DataFrame(dataset_dict)<br/><br/># One-hot Encode 'Outlook' Column<br/>df = pd.get_dummies(df, columns=['Outlook'],  prefix='', prefix_sep='', dtype=int)<br/><br/># Convert 'Windy' (bool) and 'Play' (binary) Columns to 0 and 1<br/>df['Wind'] = df['Wind'].astype(int)<br/>df['Play'] = (df['Play'] == 'Yes').astype(int)<br/><br/># Set feature matrix X and target vector y<br/>X, y = df.drop(columns='Play'), df['Play']<br/><br/># Split the data into training and testing sets<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)</span></pre><h1 id="50f1" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Main Mechanism</h1><p id="fc10" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">The dummy classifier operates on simple strategies to make predictions. These strategies donâ€™t involve any actual learning from the data. Instead, they use basic rules like:</p><ol class=""><li id="3b74" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk">Always predicting the most frequent class</li><li id="1145" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Randomly predicting a class based on the training setâ€™s class distribution</li><li id="33cb" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk">Always predicting a specific class</li></ol><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp qb"><img src="../Images/e1b4e2a1f75224a4bcd2ba1463a3f662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5BzpebX7_wftYhutnRURKw.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">For our golf dataset, a dummy classifier might always predict â€œYesâ€ for playing golf if thatâ€™s the most common outcome in the training data.</figcaption></figure><h1 id="575b" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Training Steps</h1><p id="3bf8" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">The â€œtrainingâ€ process for a dummy classifier is quite simple and doesnâ€™t involve the usual learning algorithms. Hereâ€™s a general outline:</p><h2 id="0717" class="qc oj fq bf ok qd qe qf on qg qh qi oq nl qj qk ql np qm qn qo nt qp qq qr fw bk">1. Select Strategy</h2><p id="bd94" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Choose one of the following strategies:</p><ul class=""><li id="07f1" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx qs pu pv bk"><strong class="ne ga">Stratified</strong>: Makes random guesses based on the original class distribution.</li><li id="aaa9" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx qs pu pv bk"><strong class="ne ga">Most Frequent</strong>: Always picks the most common class.</li><li id="18ae" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx qs pu pv bk"><strong class="ne ga">Uniform</strong>: Randomly picks any class.</li></ul><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp qt"><img src="../Images/193f2e00ddd807b5bfa47b80495d4bf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6TTQBO6lGVqlGiVvcsmpiQ.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">Depends on the strategy, Dummy Classifier makes different prediction.</figcaption></figure><pre class="mr ms mt mu mv pl ob pm bp pn bb bk"><span id="3042" class="po oj fq ob b bg pp pq l pr ps">from sklearn.dummy import DummyClassifier<br/><br/># Choose a strategy for your DummyClassifier (e.g., 'most_frequent', 'stratified', etc.)<br/>strategy = 'most_frequent'</span></pre><h2 id="494e" class="qc oj fq bf ok qd qe qf on qg qh qi oq nl qj qk ql np qm qn qo nt qp qq qr fw bk">2. Collect Training Labels</h2><p id="ec31" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Collect the class labels from the training dataset to determine the strategy parameters.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp qu"><img src="../Images/958c4951d13c4f031f4c031406d4d28d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B0N5vC9-0IJSQWuDkPoaPA.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">The algorithm is simply getting information of the â€œMost Frequentâ€ class in the training dataset â€” in this case â€œYesâ€.</figcaption></figure><pre class="mr ms mt mu mv pl ob pm bp pn bb bk"><span id="f20f" class="po oj fq ob b bg pp pq l pr ps"># Initialize the DummyClassifier<br/>dummy_clf = DummyClassifier(strategy=strategy)<br/><br/># "Train" the DummyClassifier (although no real training happens)<br/>dummy_clf.fit(X_train, y_train)</span></pre><h2 id="8a8a" class="qc oj fq bf ok qd qe qf on qg qh qi oq nl qj qk ql np qm qn qo nt qp qq qr fw bk">3. Apply Strategy to Test Data</h2><p id="a1c3" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Use the chosen strategy to <strong class="ne ga">generate a list of predicted labels</strong> for your test data.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp qv"><img src="../Images/7fef1b9ca434ce80d241417b6b352ff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5TQZNP-Rt5JrnigCMR-Wtw.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">If we choose the â€œmost frequentâ€ strategy and find that â€œYesâ€ (play golf) appears more often in our training data, the dummy classifier will simply remember to always predict â€œYesâ€.</figcaption></figure><pre class="mr ms mt mu mv pl ob pm bp pn bb bk"><span id="529d" class="po oj fq ob b bg pp pq l pr ps"># Use the DummyClassifier to make predictions<br/>y_pred = dummy_clf.predict(X_test)<br/>print("Label     :",list(y_test))<br/>print("Prediction:",list(y_pred))</span></pre><h2 id="54d1" class="qc oj fq bf ok qd qe qf on qg qh qi oq nl qj qk ql np qm qn qo nt qp qq qr fw bk">Evaluate the Model</h2><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp qu"><img src="../Images/1215f23c0f13b608c805f8ade38364ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rl2Sialw_td3sLbLus2Agw.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">Dummy classifier gives 64% accuracy as the baseline for future models.</figcaption></figure><pre class="mr ms mt mu mv pl ob pm bp pn bb bk"><span id="42f1" class="po oj fq ob b bg pp pq l pr ps"># Evaluate the DummyClassifier's accuracy<br/>from sklearn.metrics import accuracy_score<br/><br/>accuracy = accuracy_score(y_test, y_pred)<br/>print(f"Dummy Classifier Accuracy: {round(accuracy,4)*100}%")</span></pre><h1 id="51da" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Key Parameters</h1><p id="9cf4" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">While dummy classifiers are simple, they do have a few important parameters:</p><ol class=""><li id="1e9a" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk"><strong class="ne ga">Strategy</strong>: This determines how the classifier makes predictions. Common options include:<br/>- â€˜most_frequentâ€™: Always predicts the most common class in the training set.<br/>- â€˜stratifiedâ€™: Generates predictions based on the training setâ€™s class distribution.<br/>- â€˜uniformâ€™: Generates predictions uniformly at random.<br/>- â€˜constantâ€™: Always predicts a specified class.</li><li id="142b" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne ga">Random State</strong>: If using a strategy that involves randomness (like â€˜stratifiedâ€™ or â€˜uniformâ€™), this parameter ensures reproducibility of results.</li><li id="2002" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne ga">Constant</strong>: When using the â€˜constantâ€™ strategy, this parameter specifies which class to always predict.</li></ol><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp qu"><img src="../Images/da1d5ccd4035c1ab005bddf2f648b443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aSAWtlEZeERdpsiOddnpsQ.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">For our golf dataset, we might choose the â€˜most_frequentâ€™ strategy, which doesnâ€™t require additional parameters.</figcaption></figure><h1 id="7472" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Pros and Cons</h1><p id="a28f" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Like any tool in machine learning, dummy classifiers have their strengths and limitations.</p><p id="bcea" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Pros:</strong></p><ol class=""><li id="4294" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk"><strong class="ne ga">Simplicity</strong>: Easy to understand and implement.</li><li id="5318" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne ga">Baseline Performance</strong>: Provides a minimum performance benchmark for other models.</li><li id="bb7c" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne ga">Overfitting Check</strong>: Helps identify when complex models are overfitting by comparing their performance to the dummy classifier.</li><li id="ff56" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne ga">Quick to Train and Predict</strong>: Requires minimal computational resources.</li></ol><p id="cc1f" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Cons:</strong></p><ol class=""><li id="c6ce" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pt pu pv bk"><strong class="ne ga">Limited Predictive Power</strong>: By design, it doesnâ€™t learn from the data, so its predictions are often inaccurate.</li><li id="34bb" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne ga">No Feature Importance</strong>: It doesnâ€™t provide insights into which features are most important for predictions.</li><li id="68f3" class="nc nd fq ne b gt pw ng nh gw px nj nk nl py nn no np pz nr ns nt qa nv nw nx pt pu pv bk"><strong class="ne ga">Not Suitable for Complex Problems</strong>: In real-world scenarios with intricate patterns, dummy classifiers are too simplistic to be useful on their own.</li></ol><h1 id="5c41" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Final Remarks</h1><p id="a02b" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Understanding dummy classifiers is crucial for any data scientist or machine learning enthusiast. They serve as a reality check, helping us ensure that our more complex models are actually learning useful patterns from the data. As you continue your journey in machine learning, always remember to compare your models against these simple baselines â€” you might be surprised by what you learn!</p><h1 id="dfcf" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">ğŸŒŸ Dummy Classifier Code Summarized</h1><pre class="mr ms mt mu mv pl ob pm bp pn bb bk"><span id="2053" class="po oj fq ob b bg pp pq l pr ps"># Import necessary libraries<br/>import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.dummy import DummyClassifier<br/><br/># Make dataset<br/>dataset_dict = {<br/>    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain', 'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast', 'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'],<br/>    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],<br/>    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],<br/>    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],<br/>    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']<br/>}<br/>df = pd.DataFrame(dataset_dict)<br/><br/># Perform one-hot encoding on 'Outlook' column<br/>df = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)<br/><br/># Convert 'Wind' and 'Play' columns to binary indicators<br/>df['Wind'] = df['Wind'].astype(int)<br/>df['Play'] = (df['Play'] == 'Yes').astype(int)<br/><br/># Split data into features (X) and target (y), then into training and test sets<br/>X, y = df.drop(columns='Play'), df['Play']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)<br/><br/># Initialize and train the dummy classifier model<br/>dummy_clf = DummyClassifier(strategy='most_frequent')<br/>dummy_clf.fit(X_train, y_train)<br/><br/># Make predictions on the test data<br/>y_pred = dummy_clf.predict(X_test)<br/><br/># Calculate and print the model's accuracy on the test data<br/>print(f"Accuracy: {accuracy_score(y_test, y_pred)*100:.4f}%")</span></pre></div></div></div><div class="ab cb qw qx qy qz" role="separator"><span class="ra by bm rb rc rd"/><span class="ra by bm rb rc rd"/><span class="ra by bm rb rc"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="7b43" class="qc oj fq bf ok qd qe qf on qg qh qi oq nl qj qk ql np qm qn qo nt qp qq qr fw bk">Further Reading</h2><p id="8bba" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">For a detailed explanation of the <a class="af oc" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html" rel="noopener ugc nofollow" target="_blank">DummyClassifier</a> and its implementation in scikit-learn, readers can refer to the official documentation [2], which provides comprehensive information on its usage and parameters.</p><h2 id="8778" class="qc oj fq bf ok qd qe qf on qg qh qi oq nl qj qk ql np qm qn qo nt qp qq qr fw bk">Technical Environment</h2><p id="c795" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">This article uses Python 3.7 and scikit-learn 1.5. While the concepts discussed are generally applicable, specific code implementations may vary slightly with different versions.</p><h2 id="fcaa" class="qc oj fq bf ok qd qe qf on qg qh qi oq nl qj qk ql np qm qn qo nt qp qq qr fw bk">About the Illustrations</h2><p id="511e" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Unless otherwise noted, all images are created by the author, incorporating licensed design elements from Canva Pro.</p></div></div><div class="mw"><div class="ab cb"><div class="lr re ls rf lt rg cf rh cg ri ci bh"><figure class="mr ms mt mu mv mw rk rl paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp rj"><img src="../Images/408bdcc3b6471d42cad83e91e574d97e.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*2wT1C7jZxmNpGsgEwvveHQ.jpeg"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">For a concise visual summary of Dummy Classifier, check out <a class="af oc" href="https://www.instagram.com/p/C-ssgsAyFSI/" rel="noopener ugc nofollow" target="_blank">the companion Instagram pos</a>t.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="2857" class="qc oj fq bf ok qd qe qf on qg qh qi oq nl qj qk ql np qm qn qo nt qp qq qr fw bk">Reference</h2><p id="9cc0" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">[1] T. M. Mitchell, <a class="af oc" href="https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html" rel="noopener ugc nofollow" target="_blank">Machine Learning</a> (1997), McGraw-Hill Science/Engineering/Math, pp. 59</p><p id="2f36" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ˜¾ğ™¡ğ™–ğ™¨ğ™¨ğ™ğ™›ğ™ğ™˜ğ™–ğ™©ğ™ğ™¤ğ™£ ğ˜¼ğ™¡ğ™œğ™¤ğ™§ğ™ğ™©ğ™ğ™¢ğ™¨ ğ™ğ™šğ™§ğ™š:</p><div class="rm rn ro rp rq"><div role="button" tabindex="0" class="ab bx cp kj it rr rs bp rt lw ao"><div class="ru l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rv rw cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rv rw em n ay uh"/></div><div class="rx l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----009ff95fc86e--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq sa hp l"><h2 class="bf ga xd ic it xe iv iw xf iy ja fz bk">Classification Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk xg wf wg wh wi lj wj wk us ii wl wm wn uw ux uy ep bm uz oe" href="https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----009ff95fc86e--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xh l il"><span class="bf b dy z dx">8 stories</span></div></div></div><div class="sj dz sk it ab sl il ed"><div class="ed sd bx se sf"><div class="dz l"><img alt="" class="dz" src="../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*eVxxKT4DKvRVuAHBGknJ7w.png"/></div></div><div class="ed sd bx kk sg sh"><div class="dz l"><img alt="" class="dz" src="../Images/6ea70d9d2d9456e0c221388dbb253be8.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uFvDKl3iA2_G961vw5QFpg.png"/></div></div><div class="ed bx hx si sh"><div class="dz l"><img alt="" class="dz" src="../Images/7221f0777228e7bcf08c1adb44a8eb76.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*1TbEIdTs_Z8V_TPD9MXxJw.png"/></div></div></div></div></div><p id="595f" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:</p><div class="rm rn ro rp rq"><div role="button" tabindex="0" class="ab bx cp kj it rr rs bp rt lw ao"><div class="ru l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rv rw cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rv rw em n ay uh"/></div><div class="rx l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----009ff95fc86e--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq sa hp l"><h2 class="bf ga xd ic it xe iv iw xf iy ja fz bk">Regression Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk xg wf wg wh wi lj wj wk us ii wl wm wn uw ux uy ep bm uz oe" href="https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----009ff95fc86e--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xh l il"><span class="bf b dy z dx">5 stories</span></div></div></div><div class="sj dz sk it ab sl il ed"><div class="ed sd bx se sf"><div class="dz l"><img alt="A cartoon doll with pigtails and a pink hat. This â€œdummyâ€ doll, with its basic design and heart-adorned shirt, visually represents the concept of a dummy regressor in machine. Just as this toy-like figure is a simplified, static representation of a person, a dummy regressor is a basic models serve as baselines for more sophisticated analyses." class="dz" src="../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qMSGk19S51CXGl3DiAGuKw.png"/></div></div><div class="ed sd bx kk sg sh"><div class="dz l"><img alt="" class="dz" src="../Images/44e6d84e61c895757ff31e27943ee597.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*nMaPpVdNqCci31YmjfCMRQ.png"/></div></div><div class="ed bx hx si sh"><div class="dz l"><img alt="" class="dz" src="../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qTpdMoaZClu-KDV3nrZDMQ.png"/></div></div></div></div></div><div class="rm rn ro rp rq"><div role="button" tabindex="0" class="ab bx cp kj it rr rs bp rt lw ao"><div class="ru l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rv rw cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rv rw em n ay uh"/></div><div class="rx l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----009ff95fc86e--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq sa hp l"><h2 class="bf ga xd ic it xe iv iw xf iy ja fz bk">Ensemble Learning</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk xg wf wg wh wi lj wj wk us ii wl wm wn uw ux uy ep bm uz oe" href="https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----009ff95fc86e--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xh l il"><span class="bf b dy z dx">4 stories</span></div></div></div><div class="sj dz sk it ab sl il ed"><div class="ed sd bx se sf"><div class="dz l"><img alt="" class="dz" src="../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:388:388/1*FBhxEgEzbfYWiSK0LYOv6g.gif"/></div></div><div class="ed sd bx kk sg sh"><div class="dz l"><img alt="" class="dz" src="../Images/22a5d43568e70222eb89fd36789a9333.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:388:388/1*-qqvZRF8gPn2fP8N-kS3nA.gif"/></div></div><div class="ed bx hx si sh"><div class="dz l"><img alt="" class="dz" src="../Images/8ea1a2f29053080a5feffc709f5b8669.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:388:388/1*FBDim33AJDmZUEDHk2z-tA.gif"/></div></div></div></div></div></div></div></div></div>    
</body>
</html>