- en: Create an AI-Driven Movie Quiz with Gemini LLM, Python, FastAPI, Pydantic, RAG
    and more
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/create-an-ai-driven-movie-quiz-with-gemini-llm-python-fastapi-pydantic-rag-and-more-e15322be4f66?source=collection_archive---------0-----------------------#2024-04-18](https://towardsdatascience.com/create-an-ai-driven-movie-quiz-with-gemini-llm-python-fastapi-pydantic-rag-and-more-e15322be4f66?source=collection_archive---------0-----------------------#2024-04-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Discover the basics of using Gemini with Python via VertexAI, creating APIs
    with FastAPI, data validation with Pydantic and the fundamentals of Retrieval-Augmented
    Generation (RAG)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://vojay.medium.com/?source=post_page---byline--e15322be4f66--------------------------------)[![Volker
    Janz](../Images/0825160d6d521f4152948f0187cf354b.png)](https://vojay.medium.com/?source=post_page---byline--e15322be4f66--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e15322be4f66--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e15322be4f66--------------------------------)
    [Volker Janz](https://vojay.medium.com/?source=post_page---byline--e15322be4f66--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e15322be4f66--------------------------------)
    ¬∑21 min read¬∑Apr 18, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/50e962ece900e09fb6fcb997adafede4.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kenny Eliason](https://unsplash.com/@neonbrand?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Within this article, I share some of the basics to create a LLM-driven web-application,
    using various technologies, such as: Python, [FastAPI](https://fastapi.tiangolo.com/),
    [Pydantic](https://docs.pydantic.dev/latest/), [VertexAI](https://cloud.google.com/vertex-ai)
    and more.'
  prefs: []
  type: TYPE_NORMAL
- en: You will learn how to create such a project from the very beginning and get
    an overview of the underlying concepts, including **Retrieval-Augmented Generation**
    (RAG).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Disclaimer: I am using data from The Movie Database within this project. The
    API is free to use for non-commercial purposes and complies with the Digital Millennium
    Copyright Act (DMCA). For further information about TMDB data usage, please* [*read
    the official FAQ*](https://developer.themoviedb.org/docs/faq)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Table of contents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ‚Äì [Inspiration](#bf8e)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [System Architecture](#a588)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [Understanding Retrieval-Augmented Generation (RAG)](#d0b3)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [Python projects with Poetry](#4cfd)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [Create the API with FastAPI](#ca13)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [Data validation and quality with Pydantic](#103f)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [TMDB client with httpx](#fe62)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [Gemini LLM client with VertexAI](#040c)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [Modular prompt generator with Jinja](#2bf6)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [Frontend](#f4be)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [API examples](#809a)
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì [Conclusion](#165c)
  prefs: []
  type: TYPE_NORMAL
- en: The best way to share this knowledge is through a practical example. Hence,
    I‚Äôll use my project **Gemini Movie Detectives** to cover the various aspects.
    The project was created as part of the [Google AI Hackathon 2024](https://googleai.devpost.com/),
    which is still running while I am writing this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3d44844866ab4bb81b2e6b5acaf52bf1.png)'
  prefs: []
  type: TYPE_IMG
- en: Gemini Movie Detectives (by author)
  prefs: []
  type: TYPE_NORMAL
- en: Gemini Movie Detectives is a project aimed at leveraging the power of the Gemini
    Pro model via VertexAI to create an engaging quiz game using the latest movie
    data from [The Movie Database (TMDB)](https://www.themoviedb.org/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Part of the project was also to make it deployable with Docker and to create
    a live version. Try it yourself: [movie-detectives.com](https://movie-detectives.com/).
    Keep in mind that this is a simple prototype, so there might be unexpected issues.
    Also, I had to add some limitations in order to control costs that might be generated
    by using GCP and VertexAI.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f949342e71bc028936d5836525e42f0d.png)'
  prefs: []
  type: TYPE_IMG
- en: Gemini Movie Detectives (by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'The project is **fully open-source** and is split into two separate repositories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**üöÄ Github repository for backend**: [https://github.com/vojay-dev/gemini-movie-detectives-api](https://github.com/vojay-dev/gemini-movie-detectives-api)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**üñ•Ô∏è Github repository for frontend**: [https://github.com/vojay-dev/gemini-movie-detectives-ui](https://github.com/vojay-dev/gemini-movie-detectives-ui)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The focus of the article is the backend project and underlying concepts. It
    will therefore only briefly explain the frontend and its components.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following video, I also give an overview over the project and its components:'
  prefs: []
  type: TYPE_NORMAL
- en: Inspiration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Growing up as a passionate gamer and now working as a Data Engineer, I‚Äôve always
    been drawn to the intersection of gaming and data. With this project, I combined
    two of my greatest passions: gaming and data. Back in the 90‚Äô I always enjoyed
    the video game series You Don‚Äôt Know Jack, a delightful blend of trivia and comedy
    that not only entertained but also taught me a thing or two. Generally, the usage
    of games for educational purposes is another concept that fascinates me.'
  prefs: []
  type: TYPE_NORMAL
- en: In 2023, I organized a workshop to teach kids and young adults game development.
    They learned about mathematical concepts behind collision detection, yet they
    had fun as everything was framed in the context of gaming. It was eye-opening
    that gaming is not only a huge market but also holds a great potential for knowledge
    sharing.
  prefs: []
  type: TYPE_NORMAL
- en: With this project, called Movie Detectives, I aim to showcase the magic of Gemini,
    and AI in general, in crafting engaging trivia and educational games, but also
    how game design can profit from these technologies in general.
  prefs: []
  type: TYPE_NORMAL
- en: By feeding the Gemini LLM with accurate and up-to-date movie metadata, I could
    ensure the accuracy of the questions from Gemini. An important aspect, because
    without this Retrieval-Augmented Generation (RAG) methodology to enrich queries
    with real-time metadata, there‚Äôs a risk of propagating misinformation ‚Äî a typical
    pitfall when using AI for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Another game-changer lies in the modular prompt generation framework I‚Äôve crafted
    using Jinja templates. It‚Äôs like having a Swiss Army knife for game design ‚Äî effortlessly
    swapping show master personalities to tailor the game experience. And with the
    language module, translating the quiz into multiple languages is a breeze, eliminating
    the need for costly translation processes.
  prefs: []
  type: TYPE_NORMAL
- en: Taking that on a business perspective, it can be used to reach a much broader
    audience of customers, without the need of expensive translation processes.
  prefs: []
  type: TYPE_NORMAL
- en: From a business standpoint, this modularization opens doors to a wider customer
    base, transcending language barriers without breaking a sweat. And personally,
    I‚Äôve experienced firsthand the transformative power of these modules. Switching
    from the default quiz master to the dad-joke-quiz-master was a riot ‚Äî a nostalgic
    nod to the heyday of You Don‚Äôt Know Jack, and a testament to the versatility of
    this project.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44ed0a40a77f059c48e616639864e51e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Movie Detectives ‚Äî Example: Santa Claus personality (by author)'
  prefs: []
  type: TYPE_NORMAL
- en: System Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we jump into details, let‚Äôs get an overview of how the application was
    built.
  prefs: []
  type: TYPE_NORMAL
- en: '**Tech Stack: üöÄ Backend**'
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.12 + [FastAPI](https://fastapi.tiangolo.com/) API development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[httpx](https://www.python-httpx.org/) for TMDB integration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Jinja](https://jinja.palletsprojects.com/) templating for modular prompt generation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pydantic](https://docs.pydantic.dev/latest/) for data modeling and validation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Poetry](https://python-poetry.org/) for dependency management'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Docker](https://www.docker.com/) for deployment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TMDB API](https://www.themoviedb.org/) for movie data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VertexAI](https://cloud.google.com/vertex-ai) and [Gemini](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini)
    for generating quiz questions and evaluating answers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Ruff](https://docs.astral.sh/ruff/) as linter and code formatter together
    with [pre-commit](https://pre-commit.com/) hooks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Github Actions to automatically run tests and linter on every push
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tech Stack: üñ•Ô∏è Frontend**'
  prefs: []
  type: TYPE_NORMAL
- en: '[VueJS](https://vuejs.org/) 3.4 as the frontend framework'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Vite](https://vitejs.dev/) for frontend tooling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Essentially, the application fetches up-to-date movie metadata from an external
    API (TMDB), constructs a prompt based on different modules (personality, language,
    ‚Ä¶), enriches this prompt with the metadata and that way, uses Gemini to initiate
    a movie quiz in which the user has to guess the correct title.
  prefs: []
  type: TYPE_NORMAL
- en: The backend infrastructure is built with FastAPI and Python, employing the Retrieval-Augmented
    Generation (RAG) methodology to enrich queries with real-time metadata. Utilizing
    Jinja templating, the backend modularizes prompt generation into base, personality,
    and data enhancement templates, enabling the generation of accurate and engaging
    quiz questions.
  prefs: []
  type: TYPE_NORMAL
- en: The frontend is powered by Vue 3 and Vite, supported by daisyUI and Tailwind
    CSS for efficient frontend development. Together, these tools provide users with
    a sleek and modern interface for seamless interaction with the backend.
  prefs: []
  type: TYPE_NORMAL
- en: In Movie Detectives, quiz answers are interpreted by the Language Model (LLM)
    once again, allowing for dynamic scoring and personalized responses. This showcases
    the potential of integrating LLM with RAG in game design and development, paving
    the way for truly individualized gaming experiences. Furthermore, it demonstrates
    the potential for creating engaging quiz trivia or educational games by involving
    LLM. Adding and changing personalities or languages is as easy as adding more
    Jinja template modules. With very little effort, this can change the full game
    experience, reducing the effort for developers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b33ff35fa8348020b98001d766fc0b0f.png)'
  prefs: []
  type: TYPE_IMG
- en: System Overview (by author)
  prefs: []
  type: TYPE_NORMAL
- en: As can be seen in the overview, Retrieval-Augmented Generation (RAG) is one
    of the essential ideas of the backend. Let‚Äôs have a closer look at this particular
    paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Retrieval-Augmented Generation (RAG)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the realm of Large Language Models (LLM) and AI, one paradigm becoming more
    and more popular is Retrieval-Augmented Generation (RAG). But what does RAG entail,
    and how does it influence the landscape of AI development?
  prefs: []
  type: TYPE_NORMAL
- en: At its essence, RAG enhances LLM systems by incorporating external data to enrich
    their predictions. Which means, you pass relevant context to the LLM as an additional
    part of the prompt, but how do you find relevant context? Usually, this data can
    be automatically retrieved from a database with vector search or dedicated vector
    databases. Vector databases are especially useful, since they store data in a
    way, so that it can be queried for similar data quickly. The LLM then generates
    the output based on both, the query and the retrieved documents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Picture this: you have an LLM capable of generating text based on a given prompt.
    RAG takes this a step further by infusing additional context from external sources,
    like up-to-date movie data, to enhance the relevance and accuracy of the generated
    text.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs break down the key components of RAG:'
  prefs: []
  type: TYPE_NORMAL
- en: '**LLMs**: LLMs serve as the backbone of RAG workflows. These models, trained
    on vast amounts of text data, possess the ability to understand and generate human-like
    text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Vector Indexes for contextual enrichment**: A crucial aspect of RAG is the
    use of vector indexes, which store embeddings of text data in a format understandable
    by LLMs. These indexes allow for efficient retrieval of relevant information during
    the generation process. In the context of the project this could be a database
    of movie metadata.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retrieval process**: RAG involves retrieving pertinent documents or information
    based on the given context or prompt. This retrieved data acts as the additional
    input for the LLM, supplementing its understanding and enhancing the quality of
    generated responses. This could be getting all relevant information known and
    connected to a specific movie.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generative Output**: With the combined knowledge from both the LLM and the
    retrieved context, the system generates text that is not only coherent but also
    contextually relevant, thanks to the augmented data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/256066ba8bd31d76d97009fb106ed7d4.png)'
  prefs: []
  type: TYPE_IMG
- en: RAG architecture (by author)
  prefs: []
  type: TYPE_NORMAL
- en: While in the Gemini Movie Detectives project, the prompt is enhanced with external
    API data from The Movie Database, RAG typically involves the use of vector indexes
    to streamline this process. It is using much more complex documents as well as
    a much higher amount of data for enhancement. Thus, these indexes act like signposts,
    guiding the system to relevant external sources quickly.
  prefs: []
  type: TYPE_NORMAL
- en: In this project, it is therefore a mini version of RAG but showing the basic
    idea at least, demonstrating the power of external data to augment LLM capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: In more general terms, RAG is a very important concept, especially when crafting
    trivia quizzes or educational games using LLMs like Gemini. This concept can avoid
    the risk of false positives, asking wrong questions, or misinterpreting answers
    from the users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some open-source projects that might be helpful when approaching RAG
    in one of your projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**txtai**](https://github.com/neuml/txtai): All-in-one open-source embeddings
    database for semantic search, LLM orchestration and language model workflows.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**LangChain**](https://python.langchain.com/): LangChain is a framework for
    developing applications powered by large language models (LLMs).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Qdrant**](https://github.com/qdrant/qdrant): Vector Search Engine for the
    next generation of AI applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Weaviate**](https://github.com/weaviate/weaviate): Weaviate is a cloud-native,
    open source vector database that is robust, fast, and scalable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, with the potential value of this approach for LLM-based applications,
    there are many more open- and close-source alternatives, but with these, you should
    be able to get your research on the topic started.
  prefs: []
  type: TYPE_NORMAL
- en: Python projects with Poetry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that the main concepts are clear, let‚Äôs have a closer look how the project
    was created and how dependencies are managed in general.
  prefs: []
  type: TYPE_NORMAL
- en: 'The three main tasks Poetry can help you with are: Build, Publish and Track.
    The idea is to have a deterministic way to manage dependencies, to share your
    project and to track dependency states.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/989ff4a10f32ee19b1a7a4fcd1be4171.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kat von Wood](https://unsplash.com/@kat_von_wood?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Poetry also handles the creation of virtual environments for you. Per default,
    those are in a centralized folder within your system. However, if you prefer to
    have the virtual environment of project in the project folder, like I do, it is
    a simple config change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'With `poetry new` you can then create a new Python project. It will create
    a virtual environment linking you systems default Python. If you combine this
    with [pyenv](https://github.com/pyenv/pyenv), you get a flexible way to create
    projects using specific versions. Alternatively, you can also tell Poetry directly
    which Python version to use: `poetry env use /full/path/to/python`.'
  prefs: []
  type: TYPE_NORMAL
- en: Once you have a new project, you can use `poetry add` to add dependencies to
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this, I created the project for Gemini Movie Detectives:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The metadata about your projects, including the dependencies with the respective
    versions, are stored in the `poetry.toml` and `poetry.lock` files. I added more
    dependencies later, which resulted in the following `poetry.toml` for the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Create the API with FastAPI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FastAPI is a Python framework that allows for rapid API development. Built on
    open standards, it offers a seamless experience without new syntax to learn. With
    automatic documentation generation, robust validation, and integrated security,
    FastAPI streamlines development while ensuring great performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/65d620d2f1c52e0d1241ecb8e0fbd0b8.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Florian Steciuk](https://unsplash.com/@flo_stk?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Implementing the API for the Gemini Movie Detectives projects, I simply started
    from a Hello World application and extended it from there. Here is how to get
    started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Assuming you also keep the virtual environment within the project folder as
    `.venv/` and use uvicorn, this is how to start the API with the reload feature
    enabled, in order to test code changes without the need of a restart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have not yet installed [jq](https://jqlang.github.io/jq/), I highly
    recommend doing it now. I might cover this wonderful JSON Swiss Army knife in
    a future article. This is how the response looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/154da389d897c5178844dd5d3a349398.png)'
  prefs: []
  type: TYPE_IMG
- en: Hello FastAPI (by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'From here, you can develop your API endpoints as needed. This is how the API
    endpoint implementation to start a movie quiz in Gemini Movie Detectives looks
    like for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Within this code, you can see already three of the main components of the backend:'
  prefs: []
  type: TYPE_NORMAL
- en: '`tmdb_client`: A client I implemented using `httpx` to fetch data from The
    Movie Database (TMDB).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_generator`: A class that helps to generate modular prompts based on
    Jinja templates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gemini_client`: A client to interact with the Gemini LLM via VertexAI in Google
    Cloud.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will look at these components in detail later, but first some more helpful
    insights regarding the usage of FastAPI.
  prefs: []
  type: TYPE_NORMAL
- en: 'FastAPI makes it really easy to define the HTTP method and data to be transferred
    to the backend. For this particular function, I expect a `POST` request as this
    creates a new quiz. This can be done with the `post` decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, I am expecting some data within the request sent as JSON in the body.
    In this case, I am expecting an instance of `QuizConfig` as JSON. I simply defined
    `QuizConfig` as a subclass of `BaseModel` from Pydantic (*will be covered later*)
    and with that, I can pass it in the API function and FastAPI will do the rest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Furthermore, you might notice two custom decorators:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: These I implemented to reduce duplicate code. They wrap the API function to
    retry the function in case of errors and to introduce a global rate limit of how
    many movie quizzes can be started per day.
  prefs: []
  type: TYPE_NORMAL
- en: 'What I also liked personally is the error handling with FastAPI. You can simply
    raise a `HTTPException`, give it the desired status code and the user will then
    receive a proper response, for example, if no movie could be found with a given
    configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'With this, you should have an overview of creating an API like the one for
    Gemini Movie Detectives with FastAPI. Keep in mind: all code is open-source, so
    feel free to have a look at the [API repository on Github](https://github.com/vojay-dev/gemini-movie-detectives-api).'
  prefs: []
  type: TYPE_NORMAL
- en: Data validation and quality with Pydantic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main challenges with todays AI/ML projects is data quality. But that
    does not only apply to ETL/ELT pipelines, which prepare datasets to be used in
    model training or prediction, but also to the AI/ML application itself. Using
    Python for example usually enables Data Engineers and Scientist to get a reasonable
    result with little code but being (mostly) dynamically typed, Python lacks of
    data validation when used in a naive way.
  prefs: []
  type: TYPE_NORMAL
- en: 'That is why in this project, I combined FastAPI with Pydantic, a powerful data
    validation library for Python. The goal was to make the API lightweight but strict
    and strong, when it comes to data quality and validation. Instead of plain dictionaries
    for example, the Movie Detectives API strictly uses custom classes inherited from
    the `BaseModel` provided by Pydantic. This is the configuration for a quiz for
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This example illustrates, how not only correct type is ensured, but also further
    validation is applied to the actual values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, up-to-date Python features, like `StrEnum` are used to distinguish
    certain types, like personalities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, duplicate code is avoided by defining custom decorators. For example,
    the following decorator limits the number of quiz sessions today, to have control
    over GCP costs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'It is then simply applied to the related API function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The combination of up-to-date Python features and libraries, such as FastAPI,
    Pydantic or Ruff makes the backend less verbose but still very stable and ensures
    a certain data quality, to ensure the LLM output has the expected quality.
  prefs: []
  type: TYPE_NORMAL
- en: TMDB client with httpx
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The TMDB Client class is using [httpx](https://www.python-httpx.org/) to perform
    requests against the TMDB API.
  prefs: []
  type: TYPE_NORMAL
- en: '`httpx` is a rising star in the world of Python libraries. While `requests`
    has long been the go-to choice for making HTTP requests, `httpx` offers a valid
    alternative. One of its key strengths is asynchronous functionality. `httpx` allows
    you to write code that can handle multiple requests concurrently, potentially
    leading to significant performance improvements in applications that deal with
    a high volume of HTTP interactions. Additionally, `httpx` aims for broad compatibility
    with `requests`, making it easier for developers to pick it up.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In case of Gemini Movie Detectives, there are two main requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '`get_movies`: Get a list of random movies based on specific settings, like
    average number of votes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`get_movie_details`: Get details for a specific movie to be used in a quiz'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In order to reduce the amount of external requests, the latter one uses the
    `lru_cache` decorator, which stands for ‚ÄúLeast Recently Used cache‚Äù. It‚Äôs used
    to cache the results of function calls so that if the same inputs occur again,
    the function doesn‚Äôt have to recompute the result. Instead, it returns the cached
    result, which can significantly improve the performance of the program, especially
    for functions with expensive computations. In our case, we cache the details for
    1024 movies, so if 2 players get the same movie, we do not need to make a request
    again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Accessing data from The Movie Database (TMDB) is for free for non-commercial
    usage, you can simply [generate an API key](https://developer.themoviedb.org/docs/getting-started)
    and start making requests.
  prefs: []
  type: TYPE_NORMAL
- en: Gemini LLM client with VertexAI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before Gemini via VertexAI can be used, you need a Google Cloud project with
    VertexAI enabled and a Service Account with sufficient access together with its
    JSON key file.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/45142cdb2203e3f44a702c25a5395b06.png)'
  prefs: []
  type: TYPE_IMG
- en: Create GCP project (by author)
  prefs: []
  type: TYPE_NORMAL
- en: After creating a new project, navigate to *APIs & Services* ‚Äì> *Enable APIs
    and service* ‚Äì> search for *VertexAI API* ‚Äì> *Enable*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/67fec39048c6afd73eb41b485431904b.png)'
  prefs: []
  type: TYPE_IMG
- en: Enable VertexAI (by author)
  prefs: []
  type: TYPE_NORMAL
- en: To create a Service Account, navigate to *IAM & Admin* ‚Äì> *Service Accounts*
    ‚Äì> *Create service account*. Choose a proper name and go to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fc8a142ea8bcd0bd9da74ed24cd518e6.png)'
  prefs: []
  type: TYPE_IMG
- en: Create Service Account (by author)
  prefs: []
  type: TYPE_NORMAL
- en: Now ensure to assign the account the pre-defined role *Vertex AI User*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3cfa198c9646a12a29bac51e718d2dba.png)'
  prefs: []
  type: TYPE_IMG
- en: Assign correct role (by author)
  prefs: []
  type: TYPE_NORMAL
- en: Finally you can generate and download the JSON key file by clicking on the new
    user ‚Äì> *Keys* ‚Äì> *Add Key* ‚Äì> *Create new key* ‚Äì> *JSON*. With this file, you
    are good to go.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e3e4f8e583b623603de57bb4a372e75.png)'
  prefs: []
  type: TYPE_IMG
- en: Create JSON key file (by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Gemini from Google with Python via VertexAI starts by adding the necessary
    dependency to the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'With that, you can import and initialize `vertexai` with your JSON key file.
    Also you can load a model, like the newly released Gemini 1.5 Pro model, and start
    a chat session like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now use `chat.send_message()` to send a prompt to the model. However,
    since you get the response in chunks of data, I recommend using a little helper
    function, so that you simply get the full response as one String:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'A full example can then look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this, Gemini gave me the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cda38295b73a2e42d444a20a344055f2.png)'
  prefs: []
  type: TYPE_IMG
- en: You are awesome (by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'I agree with Gemini:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Eres incre√≠ble***'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Another hint when using this: you can also configure the model generation by
    passing a configuration to the `generation_config` parameter as part of the `send_message`
    function. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'I am using this in Gemini Movie Detectives to set the `temperature` to 0.5,
    which gave me best results. In this context `temperature` means: how creative
    are the generated responses by Gemini. The value must be between 0.0 and 1.0,
    whereas closer to 1.0 means more creativity.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the main challenges apart from sending a prompt and receive the reply
    from Gemini is to parse the reply in order to extract the relevant information.
  prefs: []
  type: TYPE_NORMAL
- en: 'One learning from the project is:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Specify a format for Gemini, which does not rely on exact words but uses
    key symbols to separate information elements***'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'For example, the question prompt for Gemini contains this instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The naive approach would be, to parse the answer by looking for a line that
    starts with `Question:`. However, if we use another language, like German, the
    reply would look like: `Antwort:`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, focus on the structure and key symbols. Read the reply like this:'
  prefs: []
  type: TYPE_NORMAL
- en: It has 3 lines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first line is the question
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second line the first hint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third line the second hint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key and value are separated by `:`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With this approach, the reply can be parsed language agnostic, and this is
    my implementation in the actual client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the future, the parsing of responses will become even easier. During the
    Google Cloud Next ‚Äô24 conference, Google announced that Gemini 1.5 Pro is now
    publicly available and with that, they also announced some features including
    a JSON mode to have responses in JSON format. Checkout [this article](https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from that, I wrapped the Gemini client into a configurable class. You
    can find the [full implementation open-source on Github](https://github.com/vojay-dev/gemini-movie-detectives-api/blob/main/gemini_movie_detectives_api/gemini.py).
  prefs: []
  type: TYPE_NORMAL
- en: Modular prompt generator with Jinja
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Prompt Generator is a class wich combines and renders Jinja2 template files
    to create a modular prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two base templates: one for generating the question and one for evaluating
    the answer. Apart from that, there is a metadata template to enrich the prompt
    with up-to-date movie data. Furthermore, there are language and personality templates,
    organized in separate folders with a template file for each option.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1ca5d024d4a77205380c152045e2a02e.png)'
  prefs: []
  type: TYPE_IMG
- en: Prompt Generator (by author)
  prefs: []
  type: TYPE_NORMAL
- en: Using Jinja2 allows to have advanced features like template inheritance, which
    is used for the metadata.
  prefs: []
  type: TYPE_NORMAL
- en: This makes it easy to extend this component, not only with more options for
    personalities and languages, but also to extract it into its own open-source project
    to make it available for other Gemini projects.
  prefs: []
  type: TYPE_NORMAL
- en: Frontend
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Gemini Movie Detectives frontend is split into four main components and
    uses `vue-router` to navigate between them.
  prefs: []
  type: TYPE_NORMAL
- en: The Home component simply displays the welcome message.
  prefs: []
  type: TYPE_NORMAL
- en: The Quiz component displays the quiz itself and talks to the API via `fetch`.
    To create a quiz, it sends a POST request to `api/quiz` with the desired settings.
    The backend is then selecting a random movie based on the user settings, creates
    the prompt with the modular prompt generator, uses Gemini to generate the question
    and hints and finally returns everything back to the component so that the quiz
    can be rendered.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, each quiz gets a session ID assigned in the backend and is stored
    in a limited LRU cache.
  prefs: []
  type: TYPE_NORMAL
- en: For debugging purposes, this component fetches data from the `api/sessions`
    endpoint. This returns all **active** sessions from the cache.
  prefs: []
  type: TYPE_NORMAL
- en: This component displays statistics about the service. However, so far there
    is only one category of data displayed, which is the quiz limit. To limit the
    costs for VertexAI and GCP usage in general, there is a daily limit of quiz sessions,
    which will reset with the first quiz of the next day. Data is retrieved form the
    `api/limit` endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/260549abb360ab6e866e64b9ae1cd851.png)'
  prefs: []
  type: TYPE_IMG
- en: Vue components (by author)
  prefs: []
  type: TYPE_NORMAL
- en: API examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course using the frontend is a nice way to interact with the application,
    but it is also possible to just use the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how to start a quiz via the API using the Santa
    Claus / Christmas personality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/44ed0a40a77f059c48e616639864e51e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Movie Detectives ‚Äî Example: Santa Claus personality (by author)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This example shows how to change the language for a quiz:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'And this is how to answer to a quiz via an API call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After I finished the basic project, adding more personalities and languages
    was so easy with the modular prompt approach, that I was impressed by the possibilities
    this opens up for game design and development. I could change this game from a
    pure educational game about movies, into a comedy trivia ‚ÄúYou Don‚Äôt Know Jack‚Äù-like
    game within a minute by adding another personality.
  prefs: []
  type: TYPE_NORMAL
- en: Also, combining up-to-date Python functionality with validation libraries like
    Pydantic is very powerful and can be used to ensure good data quality for LLM
    input.
  prefs: []
  type: TYPE_NORMAL
- en: And there you have it, folks! You‚Äôre now equipped to craft your own LLM-powered
    web application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feeling inspired but need a starting point? Check out the open-source code
    for the Gemini Movie Detectives project:'
  prefs: []
  type: TYPE_NORMAL
- en: '**üöÄ Github repository for backend**: [https://github.com/vojay-dev/gemini-movie-detectives-api](https://github.com/vojay-dev/gemini-movie-detectives-api)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**üñ•Ô∏è Github repository for frontend**: [https://github.com/vojay-dev/gemini-movie-detectives-ui](https://github.com/vojay-dev/gemini-movie-detectives-ui)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The future of AI-powered applications is bright, and you‚Äôre holding the paintbrush!
    Let‚Äôs go make something remarkable. And if you need a break, feel free to try
    [https://movie-detectives.com/](https://movie-detectives.com/).
  prefs: []
  type: TYPE_NORMAL
