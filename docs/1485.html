<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Take a Look Under the Hood</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Take a Look Under the Hood</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/take-a-look-under-the-hood-24e40281c900?source=collection_archive---------7-----------------------#2024-06-13">https://towardsdatascience.com/take-a-look-under-the-hood-24e40281c900?source=collection_archive---------7-----------------------#2024-06-13</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="ca15" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Using Monosemanticity to understand the concepts a Large Language Model learned</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@doriandrost?source=post_page---byline--24e40281c900--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Dorian Drost" class="l ep by dd de cx" src="../Images/1795395ad0586eafd83d3e2f7b975ca8.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*5v2p4tW_yrIG7b5PxYyFvA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--24e40281c900--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@doriandrost?source=post_page---byline--24e40281c900--------------------------------" rel="noopener follow">Dorian Drost</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--24e40281c900--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 13, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/2276f286b884bf6fec521e0d14acb17f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9n5f76SCQJmi4yMc"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Just like with the brain, it is quite hard to understand, what is really happening inside an LLM. Photo by <a class="af nb" href="https://unsplash.com/@averey?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Robina Weermeijer</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="e9e3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">With the increasing use of Large Language Models (LLMs), the need for understanding their reasoning and behavior increases as well. In this article, I want to present to you an approach that sheds some light on the concepts an LLM represents internally. In this approach, a representation is extracted that allows one to understand a model's activation in terms of discrete concepts being used for a given input. This is called <a class="af nb" href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html" rel="noopener ugc nofollow" target="_blank">Monosemanticity</a>, indicating that these concepts have just a single (mono) meaning (semantic).</p><p id="d27a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In this article, I will first describe the main idea behind Monosemanticity. For that, I will explain sparse autoencoders, which are a core mechanism within the approach, and show how they are used to structure an LLM’s activation in an interpretable way. Then I will retrace some demonstrations the authors of the Monosemanticity approach proposed to explain the insights of their approach, which closely follows <a class="af nb" href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html" rel="noopener ugc nofollow" target="_blank">their original publication</a>.</p><h1 id="53d3" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Sparse autoencoders</h1><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ou"><img src="../Images/57186dd272b00fbd5f6be5bcb887a1ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S7NzOdUsjwNXcjyr"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Just like an hourglass, an autoencoder has a bottleneck the data must pass through. Photo by <a class="af nb" href="https://unsplash.com/@alexandar_todov?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alexandar Todov</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9c3d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We have to start by taking a look at sparse autoencoders. First of all, an autoencoder is a neural net that is trained to reproduce a given input, i.e. it is supposed to produce exactly the vector it was given. Now you wonder, what’s the point? The important detail is, that the autoencoder has intermediate layers that are smaller than the input and output. Passing information through these layers necessarily leads to a loss of information and hence the model is not able to just learn the element by heart and reproduce it fully. It has to pass the information through a bottleneck and hence needs to come up with a dense representation of the input that still allows it to reproduce it as well as possible. The first half of the model we call the <em class="ov">encoder</em> (from input to bottleneck) and the second half we call the <em class="ov">decoder</em> (from bottleneck to output). After having trained the model, you may throw away the decoder. The encoder now transforms a given input into a representation that keeps important information but has a different structure than the input and potentially removes unneeded parts of the data.</p><p id="a2ac" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To make an autoencoder <em class="ov">sparse</em>, its objective is extended. Besides reconstructing the input as well as possible, the model is also encouraged to activate as few neurons as possible. Instead of using all the neurons a little, it should focus on using just a few of them but with a high activation. This also allows to have more neurons in total, making the bottleneck disappear in the model’s architecture. However, the fact that activating too many neurons is punished still keeps the idea of compressing the data as much as possible. The neurons that are activated are then expected to represent important concepts that describe the data in a meaningful way. We call them <em class="ov">features</em> from now on.</p><p id="58dc" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In the original Monosemanticity publication, such a sparse autoencoder is trained on an intermediate layer in the middle of the <a class="af nb" href="https://www.anthropic.com/news/claude-3-family" rel="noopener ugc nofollow" target="_blank">Claude 3 Sonnet</a> model (an LLM published by <a class="af nb" href="https://www.anthropic.com/" rel="noopener ugc nofollow" target="_blank">Anthropic</a> that can be said to play in the same league as the GPT models from OpenAI). That is, you can take some tokens (i.e. text snippets), forward them to the first half of the Claude 3 Sonnett model, and forward that activation to the sparse autoencoder. You will then get an activation of the features that represent the input. However, we don’t really know what these features mean so far. To find out, let’s imagine we feed the following texts to the model:</p><ul class=""><li id="c5a5" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ow ox oy bk">The cat is chasing the dog.</li><li id="cefe" class="nc nd fq ne b go oz ng nh gr pa nj nk nl pb nn no np pc nr ns nt pd nv nw nx ow ox oy bk">My cat is lying on the couch all day long.</li><li id="b9fe" class="nc nd fq ne b go oz ng nh gr pa nj nk nl pb nn no np pc nr ns nt pd nv nw nx ow ox oy bk">I don’t have a cat.</li></ul><p id="0118" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If there is one feature that activates for all three of the sentences, you may guess that this feature represents the idea of a <em class="ov">cat</em>. There may be other features though, that just activate for single sentences but not for the others. For sentence one, you would expect the feature for <em class="ov">dog</em> to be activated, and to represent the meaning of sentence three, you would expect a feature that represents some form of <em class="ov">negation</em> or “<em class="ov">not having something</em>”.</p><h2 id="6484" class="pe nz fq bf oa pf pg ph od pi pj pk og nl pl pm pn np po pp pq nt pr ps pt pu bk">Different features</h2><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pv"><img src="../Images/89d3a1d1783a558a8342f1cd531ecf61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rHX6iu7pwGPfAUkt"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Features can describe quite different things, from apples and bananas to the notion of being edible and tasting sweet. Photo by <a class="af nb" href="https://unsplash.com/@jkakaroto?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jonas Kakaroto</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ba3b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">From the aforementioned example, we saw that features can describe quite different things. There may be features that represent concrete objects or entities (such as <em class="ov">cats</em>, the <em class="ov">Eiffel Tower,</em> or <em class="ov">Benedict Cumberbatch</em>), but there may also be features dedicated to more abstract concepts like <em class="ov">sadness</em>, <em class="ov">gender</em>, <em class="ov">revolution</em>, <em class="ov">lying</em>, <em class="ov">things that can melt</em> or the <em class="ov">german letter ß </em>(yes, we indeed have an additional letter just for ourselves). As the model also saw programming code during its training, it also includes many features that are related to programming languages, representing contexts such as <em class="ov">code errors </em>or <em class="ov">computational functions</em>. You can explore the features of the Claude 3 model <a class="af nb" href="https://transformer-circuits.pub/2024/scaling-monosemanticity/features/index.html?featureId=1M_781220" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="1ad9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If the model is capable of speaking multiple languages, the features are found to be multilingual. That means, a feature that corresponds to, say, the concept of <em class="ov">sorrow</em>, would be activated in relevant sentences in each language. In a likewise fashion, the features are also multimodal, if the model is able to work with different input modalities. The Benedict Cumberbatch feature would then activate for the name, but also for pictures or verbal mentions of Benedict Cumberbatch.</p><h2 id="cfbc" class="pe nz fq bf oa pf pg ph od pi pj pk og nl pl pm pn np po pp pq nt pr ps pt pu bk">Influence on behavior</h2><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/7959beedc7cfd09f544567d96dcd39c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Oxx1Fv6hUHpePB0b"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Features can influence behavior, just like a steering wheel influences the way you take. Photo by <a class="af nb" href="https://unsplash.com/@niklasgarnholz?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Niklas Garnholz</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2985" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">So far we have seen that certain features are activated when the model produces a certain output. From a model’s perspective, the direction of causality is the other way round though. If the feature for the <em class="ov">Golden Gate Bridge</em> is activated, this causes the model to produce an answer that is related to this feature’s concept. In the following, this is demonstrated by artificially increasing the activation of a feature within the model’s inference.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pw"><img src="../Images/9ad46a1d3f77a8cb239afab01a76049b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3o4e2oOMl0hmdMZ0QlK1Xw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Answers of the model being influenced by a high activation of a certain feature. Image taken from the <a class="af nb" href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html" rel="noopener ugc nofollow" target="_blank">original publication</a>.</figcaption></figure><p id="f373" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">On the left, we see the answers to two questions in the normal setup, and on the right we see, how these answers change if the activation of the features <em class="ov">Golden Gate Bridge</em> (first row) and <em class="ov">brain sciences</em> (second row) are increased. It is quite intuitive, that activating these features makes the model produce texts that include the concepts of the <em class="ov">Golden Gate Bridge</em> and <em class="ov">brain sciences</em>. In the usual case, the features are activated from the model’s input and its prompt, but with the approach we saw here, one can also activate some features in a more deliberate and explicit way. You could think of always activating the <em class="ov">politeness</em> feature to steer the model’s answers in the desired way. Without the notion of features, you would do that by adding instructions to the prompt such as “<em class="ov">always be polite in your answers”, </em>but with the feature concept, this could be done more explicitly. On the other hand, you can also think of deactivating features explicitly to avoid the model telling you how to build an atomic bomb or conduct tax fraud.</p><h1 id="250a" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Taking a deeper look: Specificity, Sensitivity and Completeness</h1><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj px"><img src="../Images/4b6d406b56f3b48205cf43932f5ff416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mHaH7IbXgIqrxUuP"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Let’s observe the features in more detail. Photo by <a class="af nb" href="https://unsplash.com/@_k8_?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">K8</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f870" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now that we have understood how the features are extracted, we can follow some of the author’s experiments that show us which features and concepts the model actually learned.</p><p id="2bb9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First, we want to know how <em class="ov">specific</em> the features are, i.e. how well they stick to their exact concept. We may ask, does the feature that represents Benedict Cumberbatch indeed activate <strong class="ne fr">only</strong> for Benedict Cumberbatch and not for other actors? To shed some light on this question, the authors used an LLM to rate texts regarding their relevance to a given concept. In the following example, it was assessed how much a text relates to the concept of brain science on a scale from 0 (completely irrelevant) to 3 (very relevant). In the next figure, we see these ratings as the colors (blue for 0, red for 3) and we see the activation level on the x-axis. The more we go to the right, the more the feature is activated.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj py"><img src="../Images/d38cb47ea6b34fb67388e5597e1985fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n35OiU1aBYP4tsHaOVsBzw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">The activation of the feature for brain science together with relevance scores of the inputs. Image taken from the <a class="af nb" href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html" rel="noopener ugc nofollow" target="_blank">original publication</a>.</figcaption></figure><p id="378c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We see a clear correlation between the activation (x-axis) and the relevance (color). The higher the activation, the more often the text is considered highly relevant to the topic of brain sciences. The other way round, for texts that are of little or no relevance to the topic of brain sciences, the feature only activates marginally (if at all). That means, that the feature is quite specific for the topic of brain science and does not activate that much for related topics such as psychology or medicine.</p><h2 id="a772" class="pe nz fq bf oa pf pg ph od pi pj pk og nl pl pm pn np po pp pq nt pr ps pt pu bk">Sensitivity</h2><p id="48a7" class="pw-post-body-paragraph nc nd fq ne b go pz ng nh gr qa nj nk nl qb nn no np qc nr ns nt qd nv nw nx fj bk">The other side of the coin to <em class="ov">specificity</em> is <em class="ov">sensitivity</em>. We just saw an example, of how a feature activates only for its topic and not for related topics (at least not so much), which is the specificity. Sensitivity now asks the question “but does it activate for <strong class="ne fr">every</strong> mention of the topic?” In general, you can easily have the one without the other. A feature may only activate for the topic of brain science (high specificity), but it may miss the topic in many sentences (low sensitivity).</p><p id="63c5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The authors spend less effort on the investigation of sensitivity. However, there is a demonstration that is quite easy to understand: The feature for the <em class="ov">Golden Gate Bridge</em> activates for sentences on that topic in many different languages, even without the explicit mention of the English term “Golden Gate Bridge”. More fine-grained analyses are quite difficult here because it is not always clear what a feature is supposed to represent in detail. Say you have a feature that you think represents <em class="ov">Benedict Cumberbatch</em>. Now you find out, that it is very specific (reacting to Benedict Cumberbatch only), but only reacts to some — not all — pictures. How can you know, if the feature is just insensitive, or if it is rather a feature for a more fine-grained subconcept such as <em class="ov">Sherlock from the BBC series</em> (played by Benedict Cumberbatch)?</p><h2 id="3cac" class="pe nz fq bf oa pf pg ph od pi pj pk og nl pl pm pn np po pp pq nt pr ps pt pu bk">Completeness</h2><p id="86a7" class="pw-post-body-paragraph nc nd fq ne b go pz ng nh gr qa nj nk nl qb nn no np qc nr ns nt qd nv nw nx fj bk">In addition to the features’ activation for their concepts (specificity and sensitivity), you may wonder if the model has features for all important concepts. It is quite difficult to decide which concepts it should have though. Do you really <em class="ov">need</em> a feature for Benedict Cumberbatch? Are “<em class="ov">sadness</em>” and “<em class="ov">feeling sad</em>” two different features? Is “<em class="ov">misbehaving</em>” a feature on its own, or can it be represented by the combination of the features for “<em class="ov">behaving</em>” and “<em class="ov">negation</em>”?</p><p id="9b63" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To catch a glance at the feature completeness, the authors selected some categories of concepts that have a limited number such as the elements in the periodic table. In the following figure, we see all the elements on the x-axis and we see whether a corresponding feature has been found for three different sizes of the autoencoder model (from 1 million to 34 million parameters).</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qe"><img src="../Images/3be6b6670fd4b10c506861c402e8e777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qhXK-CWNa7mfT4TOpmRM5g.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Elements of the periodic table having a feature in the autoencoders of different sizes. Image taken from <a class="af nb" href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html" rel="noopener ugc nofollow" target="_blank">original publication</a>.</figcaption></figure><p id="0feb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It is not surprising, that the biggest autoencoder has features for more different elements of the periodic table than the smaller ones. However, it also doesn’t catch all of them. We don’t know though, if this really means, that the model does not have a clear concept of, say, Bohrium, or if it just did not survive within the autoencoder.</p><h2 id="a8d9" class="pe nz fq bf oa pf pg ph od pi pj pk og nl pl pm pn np po pp pq nt pr ps pt pu bk">Limitations</h2><p id="0dd6" class="pw-post-body-paragraph nc nd fq ne b go pz ng nh gr qa nj nk nl qb nn no np qc nr ns nt qd nv nw nx fj bk">While we saw some demonstrations of the features representing the concepts the model learned, we have to emphasize that these were in fact qualitative demonstrations and not quantitative evaluations. All the examples were great to get an idea of what the model actually learned and to demonstrate the usefulness of the Monosemanticity approach. However, a formal evaluation that assesses all the features in a systematic way is needed, to really backen the insights gained from such investigations. That is easy to say and hard to conduct, as it is not clear, how such an evaluation could look like. Future research is needed to find ways to underpin such demonstrations with quantitative and systematic data.</p><h1 id="343d" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Summary</h1><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qf"><img src="../Images/0bdd7ec1db2de88e15c8aa73416d04f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4YdWF6YFQAiKERWt"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Monosemanticity is an interesting path, but we don’t yet know where it will lead us. Photo by <a class="af nb" href="https://unsplash.com/@kseny?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ksenia Kudelkina</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="69b9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We just saw an approach that allows to gain some insights into the concepts a Large Language Model may leverage to arrive at its answers. A number of demonstrations showed how the features extracted with a sparse autoencoder can be interpreted in a quite intuitive way. This promises a new way to understand Large Language Models. If you know that the model has a feature for the concept of <em class="ov">lying</em>, you could expect it do to so, and having a concept of <em class="ov">politeness</em> (vs. not having it) can influence its answers quite a lot. For a given input, the features can also be used to understand the model’s thought traces. When asking a model to tell a story, the activation of the feature <em class="ov">happy end</em> may explain how it comes to a certain ending, and when the model does your tax declaration, you may want to know if the concept of <em class="ov">fraud</em> is activated or not.</p><p id="8ec2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As we see, there is quite some potential to understand LLMs in more detail. A more formal and systematical evaluation of the features is needed though, to back the promises this format of analysis introduces.</p></div></div></div><div class="ab cb qg qh qi qj" role="separator"><span class="qk by bm ql qm qn"/><span class="qk by bm ql qm qn"/><span class="qk by bm ql qm"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="11ee" class="ny nz fq bf oa ob qo gq od oe qp gt og oh qq oj ok ol qr on oo op qs or os ot bk">Sources</h1><p id="e60e" class="pw-post-body-paragraph nc nd fq ne b go pz ng nh gr qa nj nk nl qb nn no np qc nr ns nt qd nv nw nx fj bk">This article is based on this publication, where the Monosemanticity approach is applied to an LLM:</p><ul class=""><li id="2460" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ow ox oy bk"><a class="af nb" href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html" rel="noopener ugc nofollow" target="_blank">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</a></li></ul><p id="32a5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There is also a previous work that introduces the core ideas in a more basic model:</p><ul class=""><li id="b32e" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ow ox oy bk"><a class="af nb" href="https://transformer-circuits.pub/2023/monosemantic-features/index.html" rel="noopener ugc nofollow" target="_blank">Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</a></li></ul><p id="69e6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For the Claude 3 model that has been analyzed, see here:</p><ul class=""><li id="4d70" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ow ox oy bk"><a class="af nb" href="https://www.anthropic.com/news/claude-3-family" rel="noopener ugc nofollow" target="_blank">https://www.anthropic.com/news/claude-3-family</a></li></ul><p id="2aa2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The features can be explored here:</p><ul class=""><li id="323a" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ow ox oy bk"><a class="af nb" href="https://transformer-circuits.pub/2024/scaling-monosemanticity/features/index.html?featureId=1M_354889" rel="noopener ugc nofollow" target="_blank">https://transformer-circuits.pub/2024/scaling-monosemanticity/features/index.html?featureId=1M_354889</a></li></ul><p id="95de" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ov">Like this article? </em><a class="af nb" href="/@doriandrost" rel="noopener ugc nofollow" target="_blank"><em class="ov">Follow me</em></a><em class="ov"> to be notified of my future posts.</em></p></div></div></div></div>    
</body>
</html>