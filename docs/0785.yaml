- en: A Practitioners Guide to Retrieval Augmented Generation (RAG)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-practitioners-guide-to-retrieval-augmented-generation-rag-36fd38786a84?source=collection_archive---------2-----------------------#2024-03-26](https://towardsdatascience.com/a-practitioners-guide-to-retrieval-augmented-generation-rag-36fd38786a84?source=collection_archive---------2-----------------------#2024-03-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How basic techniques can be used to build powerful applications with LLMs…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page---byline--36fd38786a84--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page---byline--36fd38786a84--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--36fd38786a84--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--36fd38786a84--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page---byline--36fd38786a84--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--36fd38786a84--------------------------------)
    ·27 min read·Mar 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e09707c11f8f2b650d60672bcd689228.png)'
  prefs: []
  type: TYPE_IMG
- en: (Photo by [Matthew Dockery](https://unsplash.com/@matt_dockery?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/closeup-photo-of-person-wiping-white-racing-card-s99-JP8P3Hg?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash))
  prefs: []
  type: TYPE_NORMAL
- en: The recent surge of interest in generative AI has led to a proliferation of
    AI assistants that can be used to solve a variety of tasks, including anything
    from [shopping for products](https://www.aboutamazon.com/news/retail/amazon-rufus)
    to [searching for relevant information](https://www.perplexity.ai/). All of these
    interesting applications are powered by modern advancements in large language
    models (LLMs), which are trained over vast amounts of textual information to amass
    a sizable knowledge base. However, LLMs have a notoriously poor ability to retrieve
    and manipulate the knowledge that they possess, which leads to issues like hallucination
    (i.e., generating incorrect information), knowledge cutoffs, and poor understanding
    of specialized domains. *Is there a way that we can improve an LLM’s ability to
    access and utilize high-quality information?*
  prefs: []
  type: TYPE_NORMAL
- en: “If AI assistants are to play a more useful role in everyday life, they need
    to be able not just to access vast quantities of information but, more importantly,
    to access the correct information.” *—* *source*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The answer to the above question is a definitive “yes”. In this overview, we
    will explore one of the most popular techniques for injecting knowledge into an
    LLM — *retrieval augmented generation (RAG)*…
  prefs: []
  type: TYPE_NORMAL
