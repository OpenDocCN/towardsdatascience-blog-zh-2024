- en: I Fine-Tuned the Tiny Llama 3.2 1B to Replace GPT-4o
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/i-fine-tuned-the-tiny-llama-3-2-1b-to-replace-gpt-4o-7ce1e5619f3d?source=collection_archive---------0-----------------------#2024-10-15](https://towardsdatascience.com/i-fine-tuned-the-tiny-llama-3-2-1b-to-replace-gpt-4o-7ce1e5619f3d?source=collection_archive---------0-----------------------#2024-10-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is the fine-tuning effort worth more than few-shot prompting?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://thuwarakesh.medium.com/?source=post_page---byline--7ce1e5619f3d--------------------------------)[![Thuwarakesh
    Murallie](../Images/44f1a14a899426592bbd8c7f73ce169d.png)](https://thuwarakesh.medium.com/?source=post_page---byline--7ce1e5619f3d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7ce1e5619f3d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7ce1e5619f3d--------------------------------)
    [Thuwarakesh Murallie](https://thuwarakesh.medium.com/?source=post_page---byline--7ce1e5619f3d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7ce1e5619f3d--------------------------------)
    ·8 min read·Oct 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aebbd921b0305baa1fc782b987d9532a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by the author using Flux.1.1-pro
  prefs: []
  type: TYPE_NORMAL
- en: A young pediatrician and a renowned physician, who would treat a baby’s cough
    better?
  prefs: []
  type: TYPE_NORMAL
- en: Although both are doctors and can treat a child’s cough, a pediatrician is a
    specialist who can better diagnose a baby, isn’t it?
  prefs: []
  type: TYPE_NORMAL
- en: This is what fine-tuning does to smaller models. They make the tiny, weaker
    models solve specific problems better than the giants, which claim to do everything
    under the sun.
  prefs: []
  type: TYPE_NORMAL
- en: I was recently in a situation where I had to pick one over the other.
  prefs: []
  type: TYPE_NORMAL
- en: I was building a query-routing bot. It routes the user query to the correct
    department, where a human agent would continue the conversation. Under the hood,
    it’s a simple text classification task.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4o (and the mini one) does it incredibly well, but it’s rigid and expensive.
    It’s a closed model, so you can’t fine-tune it on your infrastructure. OpenAI
    offers fine-tuning on its platform itself, but that’s too costly for me.
  prefs: []
  type: TYPE_NORMAL
- en: Training GPT-4o costs $25/1M token. My training data was quickly a few million
    tokens. Plus, **serving the fine-tuned models costs about 50% more** than the
    regular ones.
  prefs: []
  type: TYPE_NORMAL
