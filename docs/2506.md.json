["```py\n#Load model:\nmodel_id = ‘microsoft/Florence-2-large’\nmodel = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, torch_dtype='auto').eval().cuda()\nprocessor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n\n#Load image:\nimage = Image.open(img_path)\n```", "```py\ndef run_example(image, task_prompt, text_input=''):\n\n    prompt = task_prompt + text_input\n\n    inputs = processor(text=prompt, images=image, return_tensors=”pt”).to(‘cuda’, torch.float16)\n\n    generated_ids = model.generate(\n        input_ids=inputs[“input_ids”].cuda(),\n        pixel_values=inputs[“pixel_values”].cuda(),\n        max_new_tokens=1024,\n        do_sample=False,\n        num_beams=3,\n        early_stopping=False,\n    )\n\n    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n    parsed_answer = processor.post_process_generation(\n        generated_text,\n        task=task_prompt,\n        image_size=(image.width, image.height)\n    )\n\n    return parsed_answer\n```", "```py\nprint (run_example(image, task_prompt='<CAPTION>'))\n# Output: 'A black camera sitting on top of a wooden table.'\n\nprint (run_example(image, task_prompt='<DETAILED_CAPTION>'))\n# Output: 'The image shows a black Kodak V35 35mm film camera sitting on top of a wooden table with a blurred background.'\n\nprint (run_example(image, task_prompt='<MORE_DETAILED_CAPTION>'))\n# Output: 'The image is a close-up of a Kodak VR35 digital camera. The camera is black in color and has the Kodak logo on the top left corner. The body of the camera is made of wood and has a textured grip for easy handling. The lens is in the center of the body and is surrounded by a gold-colored ring. On the top right corner, there is a small LCD screen and a flash. The background is blurred, but it appears to be a wooded area with trees and greenery.'\n```", "```py\ntask_prompt = '<REGION_TO_CATEGORY>'\nbox_str = '<loc_335><loc_412><loc_653><loc_832>'\nresults = run_example(image, task_prompt, text_input=box_str)\n# Output: 'camera lens'\n```", "```py\ntask_prompt = '<REGION_TO_DESCRIPTION>'\nbox_str = '<loc_335><loc_412><loc_653><loc_832>'\nresults = run_example(image, task_prompt, text_input=box_str)\n# Output: 'camera'\n```", "```py\nresults = run_example(image, task_prompt='<OD>')\ndraw_bbox(image, results['<OD>'])\n```", "```py\ntask_prompt results = run_example(image, task_prompt= '<DENSE_REGION_CAPTION>')\ndraw_bbox(image, results['<DENSE_REGION_CAPTION>'])\n```", "```py\ntask_prompt = '<CAPTION_TO_PHRASE_GROUNDING>'\nresults = run_example(image,task_prompt, text_input=”lens. camera. table. logo. flash.”)\ndraw_bbox(image, results['<CAPTION_TO_PHRASE_GROUNDING>'])\n```", "```py\nresults = run_example(image, task_prompt='<REFERRING_EXPRESSION_SEGMENTATION>', text_input=”camera”)\ndraw_polygons(image, results[task_prompt])\n```", "```py\nresults = run_example(image, task_prompt='<REGION_TO_SEGMENTATION>', text_input=\"<loc_345><loc_417><loc_648><loc_845>\")\ndraw_polygons(output_image, results['<REGION_TO_SEGMENTATION>'])\n```", "```py\nresults = run_example(image,task_prompt)\ndraw_ocr_bboxes(image, results['<OCR_WITH_REGION>'])\n```"]