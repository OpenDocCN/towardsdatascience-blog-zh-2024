- en: Human and Artificial General Intelligence Arises from Next Token Prediction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人类与人工通用智能源于下一个词的预测
- en: 原文：[https://towardsdatascience.com/human-and-artificial-general-intelligence-arises-from-next-token-prediction-712500310a93?source=collection_archive---------1-----------------------#2024-04-28](https://towardsdatascience.com/human-and-artificial-general-intelligence-arises-from-next-token-prediction-712500310a93?source=collection_archive---------1-----------------------#2024-04-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/human-and-artificial-general-intelligence-arises-from-next-token-prediction-712500310a93?source=collection_archive---------1-----------------------#2024-04-28](https://towardsdatascience.com/human-and-artificial-general-intelligence-arises-from-next-token-prediction-712500310a93?source=collection_archive---------1-----------------------#2024-04-28)
- en: '[](https://rachel-draelos.medium.com/?source=post_page---byline--712500310a93--------------------------------)[![Rachel
    Draelos, MD, PhD](../Images/edc30d41f9fea7e57dcf0c44caf68165.png)](https://rachel-draelos.medium.com/?source=post_page---byline--712500310a93--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--712500310a93--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--712500310a93--------------------------------)
    [Rachel Draelos, MD, PhD](https://rachel-draelos.medium.com/?source=post_page---byline--712500310a93--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rachel-draelos.medium.com/?source=post_page---byline--712500310a93--------------------------------)[![Rachel
    Draelos, MD, PhD](../Images/edc30d41f9fea7e57dcf0c44caf68165.png)](https://rachel-draelos.medium.com/?source=post_page---byline--712500310a93--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--712500310a93--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--712500310a93--------------------------------)
    [Rachel Draelos, MD, PhD](https://rachel-draelos.medium.com/?source=post_page---byline--712500310a93--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--712500310a93--------------------------------)
    ·16 min read·Apr 28, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--712500310a93--------------------------------)
    ·16分钟阅读·2024年4月28日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/85569874c8d96b9d8ec78e431992c703.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85569874c8d96b9d8ec78e431992c703.png)'
- en: Featured image generated by the author using DALLE2
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 封面图由作者使用DALLE2生成
- en: What if human intelligence derives from successful next token prediction, and
    what if next token prediction is a sufficient objective function for emergence
    of artificial general intelligence?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果人类的智能来自于成功的下一个词预测，那如果下一个词预测是人工通用智能涌现的足够目标函数，会怎样？
- en: This post frames and explores the hypothesis that general intelligence arises
    when a learning system becomes very good at next token prediction. This hypothesis
    is often implied, hidden, or dancing at the margins of industrial and academic
    AI research — but so far, I don’t think it’s received as much open discussion
    as I think it merits. Here I explore the idea from different angles, including
    via discussions of existing LLM pretraining objectives, humans as prediction machines,
    beneficial properties of next token prediction, and missing pieces. My motivation
    in writing this post is to spark deeper interest in the relationship between next
    token prediction and the development of intelligent thought.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章提出并探讨了这样一个假设：当一个学习系统非常擅长下一个词的预测时，通用智能就会出现。这个假设在工业和学术界的AI研究中往往是隐含的，模糊的，或者在边缘游走——但到目前为止，我认为它没有得到足够的公开讨论。这里我从不同的角度探讨这一观点，包括通过讨论现有的LLM预训练目标、人类作为预测机器、下一个词预测的有益特性以及缺失的部分。写这篇文章的动机是激发对下一个词预测与智能思维发展之间关系的更深层次兴趣。
- en: '**Backstory**'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**背景**'
- en: I was driving to the park last week and suddenly felt that it would be so depressing
    if the language center in my brain is merely a next word predictor. Large language
    models acquire [incredible emergent abilities](https://glassboxmedicine.com/2023/11/26/sparks-of-artificial-general-intelligence-highlights-from-95-pages/)
    from predicting the next word, so could my own linguistic intelligence also come
    from something as simplistic as predicting the next word?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 上周我开车去公园，突然觉得，如果大脑中的语言中心仅仅是一个下一个词的预测器，那将是多么令人沮丧。大型语言模型通过预测下一个词获得了[令人难以置信的涌现能力](https://glassboxmedicine.com/2023/11/26/sparks-of-artificial-general-intelligence-highlights-from-95-pages/)，那么我的语言智能是否也可能来源于像预测下一个词这样简单的机制？
