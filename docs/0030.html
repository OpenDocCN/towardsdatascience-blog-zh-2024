<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>On the Statistical Analysis of Rounded or Binned Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>On the Statistical Analysis of Rounded or Binned Data</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/on-the-statistical-analysis-of-rounded-or-binned-data-e24147a12fa0?source=collection_archive---------17-----------------------#2024-01-04">https://towardsdatascience.com/on-the-statistical-analysis-of-rounded-or-binned-data-e24147a12fa0?source=collection_archive---------17-----------------------#2024-01-04</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="fb3c" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Sheppard’s corrections offer approximations, but errors persist. Analytical bounds provide insight into the magnitude of these errors</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@mplaue?source=post_page---byline--e24147a12fa0--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Matthias Plaue" class="l ep by dd de cx" src="../Images/3663c89478e6acf276002dad0a5d1ea4.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*7JgrKpd8Vi_MCZ45M-pHkg.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--e24147a12fa0--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@mplaue?source=post_page---byline--e24147a12fa0--------------------------------" rel="noopener follow">Matthias Plaue</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--e24147a12fa0--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 4, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/c093b820f3535d3863bac1d63c20a74d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZOTieyZC_Qzl8APE"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Photo by <a class="af nb" href="https://unsplash.com/@charlesdeluvio?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">charlesdeluvio</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="41af" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Imagine having a list of length measurements in inches, precise to the inch. This list might represent, for instance, the heights of individuals participating in a medical study, forming a sample from a cohort of interest. Our goal is to estimate the average height within this cohort.</p><p id="fa49" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Consider an arithmetic mean of 70.08 inches. The crucial question is: How accurate is this figure? Despite a large sample size, the reality is that each individual measurement is only precise up to the inch. Thus, even with abundant data, we might cautiously assume that the true average height falls within the range of 69.5 inches to 70.5 inches, and round the value to 70 inches.</p><p id="ac24" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This isn’t merely a theoretical concern easily dismissed. Take, for instance, determining the average height in metric units. One inch equals exactly 2.54 centimeters, so we can easily convert the measurements from inches to the finer centimeter scale, and compute the mean. Yet, considering the inch-level accuracy, we can only confidently assert that the average height lies somewhere between 177 cm and 179 cm. The question arises: Can we confidently conclude that the average height is <em class="ny">precisely</em> 178 cm?</p><p id="9e6b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Rounding errors or <a class="af nb" href="https://en.wikipedia.org/wiki/Quantization_(signal_processing)" rel="noopener ugc nofollow" target="_blank">quantization errors</a> can have <a class="af nb" href="https://slate.com/technology/2019/10/round-floor-software-errors-stock-market-battlefield.html" rel="noopener ugc nofollow" target="_blank">enormous consequences</a>— such as changing the <a class="af nb" href="https://catless.ncl.ac.uk/Risks/13/37#subj4" rel="noopener ugc nofollow" target="_blank">outcome of elections</a>, or changing the course of a ballistic missile, leading to <a class="af nb" href="https://www-users.cse.umn.edu/~arnold/disasters/patriot.html" rel="noopener ugc nofollow" target="_blank">accidental death and injury</a>. How rounding errors affect statistical analyses is a non-trivial inquiry that we aim to elucidate in this article.</p><h1 id="f2d1" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Sheppard’s corrections</h1><p id="5d91" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Suppose that we observe values produced by a continuous random variable <strong class="ne fr"><em class="ny">X </em></strong>that have been rounded, or binned<em class="ny">. </em>These observations follow the distribution of a discrete random variable <strong class="ne fr"><em class="ny">Y</em></strong> defined by:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pa"><img src="../Images/cf954df685039f9c1e28372b1c1e02d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uuZyvZFFKTyHTnGfpXCuwQ.png"/></div></div></figure><p id="bd7c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">where <strong class="ne fr"><em class="ny">h</em></strong> is the bin width and ⌊ ⋅ ⌋ denotes the floor function. For example, <strong class="ne fr"><em class="ny">X</em></strong> could generate length measurements. Since rounding is not an invertible operation, reconstructing the original data from the rounded values alone is impossible.</p><p id="661e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The following approximations relate the mean and the variance of these distributions, known as <a class="af nb" href="https://en.wikipedia.org/wiki/Sheppard%27s_correction" rel="noopener ugc nofollow" target="_blank">Sheppard’s corrections</a> [<a class="af nb" href="https://doi.org/10.1112/plms/s1-29.1.353" rel="noopener ugc nofollow" target="_blank">Sheppard 1897</a>]:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pb"><img src="../Images/0339fa02c499f3eaf4c6c2cefca7ecda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YwoTL1nZddMEMuB1RGCTTA.png"/></div></div></figure><p id="b562" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For example, if we are given measurements rounded to the inch, <strong class="ne fr"><em class="ny">h </em></strong>= 2.54 cm, and observe a standard deviation of 10.0 cm, Sheppard’s second moment correction asks us to assume that the original data have in fact a smaller standard deviation of <strong class="ne fr">σ </strong>= 9.97 cm. For many practical purposes, the correction is very small. Even if the standard deviation is of similar magnitude as the bin width, the correction only amounts to 5% of the original value.</p><p id="1f23" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Sheppard’s corrections can be applied if the following conditions hold [<a class="af nb" href="https://doi.org/10.2307/2980630" rel="noopener ugc nofollow" target="_blank">Kendall 1938</a>, <a class="af nb" href="https://doi.org/10.1214/ss/1177012601" rel="noopener ugc nofollow" target="_blank">Heitjan 1989</a>]:</p><ul class=""><li id="2177" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pc pd pe bk">the probability density function of <strong class="ne fr"><em class="ny">X</em></strong> is sufficiently smooth and its derivatives tend to zero at its tails,</li><li id="611d" class="nc nd fq ne b go pf ng nh gr pg nj nk nl ph nn no np pi nr ns nt pj nv nw nx pc pd pe bk">the bin width <strong class="ne fr"><em class="ny">h</em></strong> is not too large (<strong class="ne fr"><em class="ny">h</em></strong> &lt; 1.6 <strong class="ne fr">σ</strong>),</li><li id="4e0b" class="nc nd fq ne b go pf ng nh gr pg nj nk nl ph nn no np pi nr ns nt pj nv nw nx pc pd pe bk">the sample size <strong class="ne fr"><em class="ny">N </em></strong>is not too small and not too large (5 &lt; <strong class="ne fr"><em class="ny">N </em></strong>&lt; 100).</li></ul><p id="cc68" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The first two requirements present as the typical “no free lunch” situation in statistical inference: in order to check whether these conditions hold, we would have to know the true distribution in the first place. The first of these conditions, in particular, is a local condition in the sense that it involves derivatives of the density which we cannot robustly estimate given only the rounded or binned data.</p><p id="dd27" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The requirement on the sample size not being too <em class="ny">large </em>does not mean that the propagation of rounding errors becomes less controllable (in absolute value) with large sample size. Instead, it addresses the situation where Sheppard’s corrections may cease to be adequate when attempting to compare the bias introduced by rounding/binning with the diminishing standard error in larger samples.</p><h1 id="537b" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Total variation bounds on the rounding error in estimating the mean</h1><p id="92e7" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Sheppard’s corrections are only approximations. For example, in general, the bias in estimating the mean, <em class="ny">E</em>[<strong class="ne fr"><em class="ny">Y</em></strong>] - <em class="ny">E</em>[<strong class="ne fr"><em class="ny">X</em></strong>], is in fact non-zero. We want to compute some upper bounds on the absolute value of this bias. The simplest bound is a result of the monotonicity of the expected value, and the fact that rounding/binning can change the values by at most <strong class="ne fr"><em class="ny">h</em></strong> / 2:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pk"><img src="../Images/472e10acdf4f0952be7b6326b878a685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WQFDsrr10IRtA-T8ZowTng.png"/></div></div></figure><p id="57c0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">With no additional information on the distribution of <strong class="ne fr"><em class="ny">X </em></strong>available, we are not able to improve on this bound: imagine that the probability mass of <strong class="ne fr"><em class="ny">X</em></strong> is highly concentrated just above the midpoint of a bin, then all values produced by <strong class="ne fr"><em class="ny">X</em></strong> will be shifted by + <strong class="ne fr"><em class="ny">h</em></strong> / 2 to result in a value for <strong class="ne fr"><em class="ny">Y</em></strong>, realizing the upper bound.</p><p id="8e29" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">However, the following exact formula can be given, based on [Theorem 2.3 (i), <a class="af nb" href="https://doi.org/10.1214/009117906000000232" rel="noopener ugc nofollow" target="_blank">Janson 2006</a>]:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pl"><img src="../Images/8a5b0cb730e73434979d75921a06756e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqUFQF3CuNZKW5Ane46LGg.png"/></div></div></figure><p id="a7e2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here, <strong class="ne fr">φ</strong>( ⋅ ) denotes the <a class="af nb" href="https://en.wikipedia.org/wiki/Characteristic_function_(probability_theory)" rel="noopener ugc nofollow" target="_blank">characteristic function</a> of <strong class="ne fr"><em class="ny">X</em></strong>, i.e., the Fourier transform of the unknown probability density function <strong class="ne fr"><em class="ny">p</em></strong>( ⋅ ). This formula implies the following bound:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pm"><img src="../Images/b0c88040213dfa77deba3ff43c0d53ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IF7w_r_hvjl85mgY3mIccA.png"/></div></div></figure><p id="4156" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can calculate this bound for some of our favorite distributions, for example the uniform distribution with support on the interval [<strong class="ne fr"><em class="ny">a</em></strong>, <strong class="ne fr"><em class="ny">b</em></strong>]:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pn"><img src="../Images/f6025a73590856608aa5928213da31e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EqkyxsKvq6BWnp76bvuSyQ.png"/></div></div></figure><p id="39b1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here, we have used the well-known value of the <a class="af nb" href="https://en.wikipedia.org/wiki/Basel_problem" rel="noopener ugc nofollow" target="_blank">sum of reciprocals of squares</a>. For example, if we sample from a uniform distribution with range <strong class="ne fr"><em class="ny">b</em></strong> - <strong class="ne fr"><em class="ny">a</em></strong> = 10 cm, and compute the mean from data that has been rounded to a precision of <strong class="ne fr"><em class="ny">h</em></strong> = 2.54 cm, the bias in estimating the mean is at most 1.1 millimeters.</p><p id="dfa2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By a calculation very similar to one performed in [<a class="af nb" href="https://doi.org/10.1002/sta4.478" rel="noopener ugc nofollow" target="_blank">Ushakov &amp; Ushakov 2022</a>], we may also bound the rounding error when sampling from a normal distribution with variance <strong class="ne fr">σ</strong>²:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj po"><img src="../Images/629ccb8e220047f7cf0d3d26edf5ae5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9e4fCmXOWYpZFIxL44BZXA.png"/></div></div></figure><p id="3af0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The exponential term decays very fast with smaller values of the bin width. For example, given a standard deviation of <strong class="ne fr">σ </strong>= 10 cm and a bin width of <strong class="ne fr"><em class="ny">h</em></strong> = 2.54 cm the rounding error in estimating the mean is of the order 10^(-133), i.e., it is negligible for any practical purpose.</p><p id="3d4f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Applying Theorem 2.5.3 of [<a class="af nb" href="https://doi.org/10.1515/9783110935981" rel="noopener ugc nofollow" target="_blank">Ushakov 1999</a>], we can give a more general bound in terms of the total variation <em class="ny">V</em>(<strong class="ne fr"><em class="ny">p</em></strong>) of the probability density function <strong class="ne fr"><em class="ny">p</em></strong>( ⋅ ) instead of its characteristic function:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pp"><img src="../Images/bb3a67fc6fc58c870833e86996d4a91d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HRuv4IpFFPvUwnVTGUzuag.png"/></div></div></figure><p id="7018" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">where</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pq"><img src="../Images/1277b6984d3c1a63794cbb0b3f3ffb6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YQizNjJ7X3ZsjjsxnwwxUg.png"/></div></div></figure><p id="fae7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The calculation is similar to one provided in [<a class="af nb" href="https://doi.org/10.1007/s10958-018-4042-3" rel="noopener ugc nofollow" target="_blank">Ushakov &amp; Ushakov 2018</a>]. For example, the total variation of the uniform distribution with support on the interval [<strong class="ne fr"><em class="ny">a</em></strong>, <strong class="ne fr"><em class="ny">b</em></strong>] is given by 2 / (<strong class="ne fr"><em class="ny">b</em></strong> - <strong class="ne fr"><em class="ny">a</em></strong>), so the above formula provides the same bound as the previous calculation, via the modulus of the characteristic function.</p><p id="3279" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The total variation bound allows us to provide a formula for practical use that estimates an upper bound for the rounding error, based on the histogram with bin width <strong class="ne fr"><em class="ny">h</em></strong>:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pr"><img src="../Images/5351f9c3dc5370234c8410973cade24d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_IPF4E4Ua-YMChK8RHqC5A.png"/></div></div></figure><p id="2ea8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here, <strong class="ne fr"><em class="ny">n_k</em></strong> is the number of observations that fall into the <strong class="ne fr"><em class="ny">k</em></strong>-th bin.</p><p id="9559" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As a numerical example, we analyze <strong class="ne fr"><em class="ny">N</em></strong> = 412,659 of person’s height values surveyed by the U.S. Centers for Disease Control and Prevention [<a class="af nb" href="https://www.cdc.gov/brfss/annual_data/annual_2022.html" rel="noopener ugc nofollow" target="_blank">CDC 2022</a>], given in inches. The mean height in metric units is given by 170.33 cm. Because of the large sample size, the standard error <strong class="ne fr"><em class="ny">σ</em></strong> / √<strong class="ne fr"><em class="ny">N</em></strong> is very small, 0.02 cm. However, the error due to rounding may be larger, as the total variation bound can be estimated to be 0.05 cm. In this case, the statistical errors are negligible since differences in body height well below a centimeter are rarely of practical relevance. For other cases that require highly accurate estimates of the average value of measurements, however, it may not be sufficient to just compute the standard error when the data is subject to quantization.</p><h1 id="0671" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Bounds based on Fisher information</h1><p id="5e84" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">If the probability density function <strong class="ne fr"><em class="ny">p</em></strong>( ⋅ ) is continuously differentiable, we can express its total variation <em class="ny">V</em>(<strong class="ne fr"><em class="ny">p</em></strong>) as an integral over the derivatives’ modulus. Applying <a class="af nb" href="https://en.wikipedia.org/wiki/H%C3%B6lder%27s_inequality" rel="noopener ugc nofollow" target="_blank">Hölder’s inequality</a>, we can bound the total variation by (the square root of) the Fisher information <em class="ny">I</em>(<strong class="ne fr"><em class="ny">p</em></strong>):</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ps"><img src="../Images/472aef89126a01db1259cef07338b5ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zal4hl8QxJq7eNLhBiWltw.png"/></div></div></figure><p id="acc5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Consequently, we can write down an additional upper bound to the bias when computing the mean of rounded or binned data:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pt"><img src="../Images/bb2941122b5815dda1a1ff21ec21fdcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hslK_NH2pQ_0oPIxoxPmRA.png"/></div></div></figure><p id="1f91" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This new bound is of (theoretical) interest since Fisher information is a characteristic of the density function that is more commonly used than its total variation.</p><p id="ea08" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">More bounds can be found via known upper bounds for the Fisher information, many of which can be found in [<a class="af nb" href="https://doi.org/10.1214/22-ejp834" rel="noopener ugc nofollow" target="_blank">Bobkov 2022</a>], including the following involving the third derivative of the probability density function:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pu"><img src="../Images/15554aa27d3b01809408b5cf12b1f6e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UGsLKKAwsglyrOaxOTV6ig.png"/></div></div></figure><p id="cabf" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Curiously, Fisher information also holds significance in certain formulations of quantum mechanics, wherein it serves as the component of the Hamiltonian responsible for inducing quantum effects [<a class="af nb" href="https://doi.org/10.1016/j.physa.2019.121570" rel="noopener ugc nofollow" target="_blank">Curcuraci &amp; Ramezani 2019</a>]. One might ponder the existence of a concrete and meaningful link between quantized physical matter and classical measurements subjected to “ordinary” quantization. However, it is important to note that such speculation is likely rooted in mathematical pareidolia.</p><h1 id="3851" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Conclusion</h1><p id="bd71" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Sheppard’s corrections are approximations that can be used to account for errors in computing the mean, variance, and other (central) moments of a distribution based on rounded or binned data.</p><p id="721d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Although Sheppard’s correction for the mean is zero, the actual error may be comparable to, or even exceed, the standard error, especially for larger samples. We can constrain the error in computing the mean based on rounded or binned data by considering the total variation of the probability density function, a quantity estimable from the binned data.</p><p id="c88f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Additional bounds on the rounding error when estimating the mean can be expressed in terms of the Fisher information and higher derivatives of the probability density function of the unknown distribution.</p><h1 id="9984" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">References</h1><p id="64f3" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.1112/plms/s1-29.1.353" rel="noopener ugc nofollow" target="_blank">Sheppard 1897</a>] Sheppard, W.F. (1897). “On the Calculation of the most Probable Values of Frequency-Constants, for Data arranged according to Equidistant Division of a Scale.” Proceedings of the London Mathematical Society s1–29: 353–380.</p><p id="6344" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.2307/2980630" rel="noopener ugc nofollow" target="_blank">Kendall 1938</a>] Kendall, M. G. (1938). “The Conditions under which Sheppard’s Corrections are Valid.” Journal of the Royal Statistical Society 101(3): 592–605.</p><p id="a161" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.1214/ss/1177012601" rel="noopener ugc nofollow" target="_blank">Heitjan 1989</a>] Daniel F. Heitjan (1989). “Inference from Grouped Continuous Data: A Review.” Statist. Sci. 4 (2): 164–179.</p><p id="c081" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.1214/009117906000000232" rel="noopener ugc nofollow" target="_blank">Janson 2006</a>] Janson, Svante (2005). “Rounding of continuous random variables and oscillatory asymptotics.” <em class="ny">Annals of Probability</em> 34 (5): 1807–1826.</p><p id="fb4c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.1002/sta4.478" rel="noopener ugc nofollow" target="_blank">Ushakov &amp; Ushakov 2022</a>] Ushakov, N. G., &amp; Ushakov, V. G. (2022). “On the effect of rounding on hypothesis testing when sample size is large.” Stat 11(1): e478.</p><p id="8b79" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.1515/9783110935981" rel="noopener ugc nofollow" target="_blank">Ushakov 1999</a>] Ushakov, N. G. (1999). “Selected Topics in Characteristic Functions.” De Gruyter.</p><p id="d1a9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.1007/s10958-018-4042-3" rel="noopener ugc nofollow" target="_blank">Ushakov &amp; Ushakov 2018</a>] Ushakov, N. G., Ushakov, V. G. Statistical Analysis of Rounded Data: Measurement Errors vs Rounding Errors. J Math Sci 234 (2018): 770–773.</p><p id="d70f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://www.cdc.gov/brfss/annual_data/annual_2022.html" rel="noopener ugc nofollow" target="_blank">CDC 2022</a>] Centers for Disease Control and Prevention (CDC). Behavioral Risk Factor Surveillance System Survey Data 2022. Atlanta, Georgia: U.S. Department of Health and Human Services, Centers for Disease Control and Prevention.</p><p id="1318" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.1214/22-ejp834" rel="noopener ugc nofollow" target="_blank">Bobkov 2022</a>] Bobkov, Sergey G. (2022). “Upper Bounds for Fisher information.” Electron. J. Probab. 27: 1–44.</p><p id="fc8e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">[<a class="af nb" href="https://doi.org/10.1016/j.physa.2019.121570" rel="noopener ugc nofollow" target="_blank">Curcuraci &amp; Ramezani 2019</a>] L. Curcuraci, M. Ramezani (2019). “A thermodynamical derivation of the quantum potential and the temperature of the wave function.” Physica A: Statistical Mechanics and its Applications 530: 121570.</p></div></div></div></div>    
</body>
</html>