<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Data Dirtiness Score</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Data Dirtiness Score</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-dirtiness-score-fe2ca5678d40?source=collection_archive---------1-----------------------#2024-03-02">https://towardsdatascience.com/data-dirtiness-score-fe2ca5678d40?source=collection_archive---------1-----------------------#2024-03-02</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="ceb8" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">New method to measure tabular dataset quality</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@simon.grah?source=post_page---byline--fe2ca5678d40--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Simon Grah" class="l ep by dd de cx" src="../Images/f8fd00600db79bc910ff51e9f64503d0.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*CDlge1Xe4sSvIgAbC-1Ttg.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--fe2ca5678d40--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@simon.grah?source=post_page---byline--fe2ca5678d40--------------------------------" rel="noopener follow">Simon Grah</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--fe2ca5678d40--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 2, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><blockquote class="mj mk ml"><p id="72bf" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">This article, the first in a series on data cleaning practices involving Large Language Models (LLMs), focuses on quantifying the cleanliness or dirtiness of a dataset</p></blockquote></div></div></div><div class="ab cb nj nk nl nm" role="separator"><span class="nn by bm no np nq"/><span class="nn by bm no np nq"/><span class="nn by bm no np"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="nu nv nw nx ny nz nr ns paragraph-image"><div role="button" tabindex="0" class="oa ob ed oc bh od"><div class="nr ns nt"><img src="../Images/4c8f68fd06ac2bc78782f13b1a251904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZFnZ9LRaegEp1iMu"/></div></div><figcaption class="of og oh nr ns oi oj bf b bg z dx">Photo by <a class="af ok" href="https://unsplash.com/@conti_photos?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Fabrizio Conti</a> on <a class="af ok" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="9f89" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Starting with the Why</h1><p id="4971" class="pw-post-body-paragraph mm mn fq mp b go ph mr ms gr pi mu mv mw pj my mz na pk nc nd ne pl ng nh ni fj bk">This article introduces a concept for evaluating the dirtiness of a dataset, a topic that presents challenges due to the lack of a tangible score or loss function related to data cleaning. The primary objective here is to establish a metric that can effectively measure the cleanliness level of a dataset, translating this concept into a concrete optimisation problem.</p><p id="05a8" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Data cleaning is defined as a two-phase process:</p><ol class=""><li id="8181" class="mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni pm pn po bk">First, <strong class="mp fr">detecting data errors</strong> such as formatting issues, duplicate records, and outliers;</li><li id="d3e4" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni pm pn po bk">Second, <strong class="mp fr">fixing</strong> these <strong class="mp fr">errors</strong>.</li></ol><p id="7587" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">The evaluation of each phase typically relies on comparing a dirty dataset against a clean (ground truth) version, using classification metrics like recall, precision, and F1-score for error detection (see for example <a class="af ok" href="https://arxiv.org/abs/2205.09911" rel="noopener ugc nofollow" target="_blank">Can Foundation Models Wrangle Your Data?</a>, <a class="af ok" href="https://cs.uwaterloo.ca/~ilyas/papers/AbedjanVLDB2016.pdf" rel="noopener ugc nofollow" target="_blank">Detecting Data Errors: Where are we and what needs to be done?</a>) and accuracy or overlap-based metrics for data repair tasks (see <a class="af ok" href="https://www.semanticscholar.org/reader/5191f08424a3ec0cdaf2b3285860216caca57463" rel="noopener ugc nofollow" target="_blank">Automatic Data Repair: Are We Ready to Deploy?</a> or <a class="af ok" href="https://arxiv.org/abs/1702.00820" rel="noopener ugc nofollow" target="_blank">HoloClean: Holistic Data Repairs with Probabilistic Inference</a>).<br/>However, these metrics are task-specific and do not offer a unified measure for the overall cleanliness of a dataset that includes various types of errors.</p><p id="c04c" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">This discussion is focused on <strong class="mp fr">structured and tidy tabular datasets</strong> (see <a class="af ok" href="https://www.jstatsoft.org/article/view/v059i10" rel="noopener ugc nofollow" target="_blank">Tidy Data | Journal of Statistical Software</a>), <strong class="mp fr">distinguishing data cleaning from broader data quality concerns</strong> that include data governance, lineage, cataloguing, drift, and more.</p><h1 id="4e5e" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">The score blueprint</h1><p id="1024" class="pw-post-body-paragraph mm mn fq mp b go ph mr ms gr pi mu mv mw pj my mz na pk nc nd ne pl ng nh ni fj bk">All the assumptions hereafter are the foundations the <em class="mo">Data Dirtiness Score</em> relies on. There are largely inspired by the article <a class="af ok" rel="noopener" target="_blank" href="/how-to-quantify-data-quality-743721bdba03">How to quantify Data Quality?</a>. Of course, all of them could be debated and criticised but it is crucial to clearly state them to enhance discussions.</p><p id="f6a3" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Data errors are tied to violated constraints</strong>, which arise from <strong class="mp fr">expectations</strong> about the data. For example, if the expectation is that the ID column should have no missing values, the presence of missing IDs would constitute a constraint violation.</p><p id="cd66" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">No Expectation No Cry. <strong class="mp fr">The absence of expectations means no impact on the score</strong>. In other words, no data issues can be identified without predefined expectations, and thus, can’t violate constraints that don’t exist.</p><p id="c825" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Data issues should be locateable to specific cells</strong>. The score relies on the ability to pinpoint errors to particular cells in the dataset.</p><p id="6959" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Confidence scores for data errors</strong>. Not all data errors can be identified with the same level of certainty. Each detected issue should be tagged with a confidence level, indicating how likely it is that the identified issue is indeed an error. This approach acknowledges that some errors might be open to interpretation. Instead of using a continuous scale from 0 to 1, which might be too detailed, we suggest categorising this confidence level into four ordinal categories: <code class="cx pu pv pw px b">low</code>, <code class="cx pu pv pw px b">medium</code>, <code class="cx pu pv pw px b">high</code>, and <code class="cx pu pv pw px b">certain</code>. These categories correspond to probability values of 0.25, 0.5, 0.75, and 1, respectively.</p><p id="18be" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><strong class="mp fr">Uniform impact of cells on the overall score</strong>. Each cell in a dataset has an equal potential impact on the dirtiness score. Addressing an issue related to a given cell may resolve issues in others, suggesting a uniform distribution of cell weights in the score calculation.</p><h1 id="a90f" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">A toy example for illustration</h1><p id="67fc" class="pw-post-body-paragraph mm mn fq mp b go ph mr ms gr pi mu mv mw pj my mz na pk nc nd ne pl ng nh ni fj bk">When examining a dataset, it’s not uncommon to spot potential data quality issues at a glance. Consider the following simple dataset for analysis:</p><pre class="nu nv nw nx ny py px pz bp qa bb bk"><span id="ad51" class="qb om fq px b bg qc qd l qe qf">Student#,Last Name,First Name,Favorite Color,Age<br/>1,Johnson,Mia,periwinkle,12<br/>2,Lopez,Liam,blue,green,13<br/>3,Lee,Isabella,,11<br/>4,Fisher,Mason,gray,-1<br/>5,Gupta,Olivia,9,102<br/>6,,Robinson,,Sophia,,blue,,12</span></pre><p id="5ebd" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">This example from the book <a class="af ok" href="https://github.com/PacktPublishing/Cleaning-Data-for-Effective-Data-Science" rel="noopener ugc nofollow" target="_blank">Cleaning Data for Effective Data Science</a> illustrates data quality issues within a dataset representing a 6th-grade class. This dataset includes multiple variables for each student, organised such that there are 6 students and 5 variables per student.</p><p id="1e64" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Upon inspection, certain entries might raise concerns due to apparent inconsistencies or errors:</p><ul class=""><li id="08da" class="mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni qg pn po bk">The entry for the student with <code class="cx pu pv pw px b">Student#</code> 2 (Lopez, Liam) appears to have an extra value in the <code class="cx pu pv pw px b">Favorite Color</code> column, which looks like two values ('blue,green') have been merged. Typically, this column should only contain a single value. Given the uncertainty, this issue is flagged with a <code class="cx pu pv pw px b">high</code>confidence level for further inspection.</li><li id="8f2b" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk">The next student, Isabella Lee, lacks a <code class="cx pu pv pw px b">Favorite Color</code> value. Given that this column should not have any missing entries, this issue is identified with <code class="cx pu pv pw px b">certain</code>confidence for correction.</li><li id="b2f5" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk">The record for student number 4, Mason Fisher, lists an age of <code class="cx pu pv pw px b">-1</code>, an implausible value. This might represent a sentinel value indicating missing data, as it is common practice to use such placeholders. However, ages should be positive integers, necessitating a review of this entry.</li><li id="81d3" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk">The row for student number 5, Olivia Gupta, while free from structural errors, presents an unusual case as several explanations are plausible. The <code class="cx pu pv pw px b">Favorite Color</code> and <code class="cx pu pv pw px b">First Name</code> fields might be swapped, considering <code class="cx pu pv pw px b">Olivia</code> can be both a name and a colour. Alternatively, the number <code class="cx pu pv pw px b">9</code> could represent a colour code, but this hypothesis lacks corroborating evidence. Moreover, an age of <code class="cx pu pv pw px b">102</code> for a 6th-grade student is highly improbable, suggesting potential typographical errors (e.g. <code class="cx pu pv pw px b">102</code> instead of <code class="cx pu pv pw px b">12</code>).</li><li id="dfb2" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk">The last row contains superfluous commas, indicating a possible data ingestion issue. However, aside from this formatting concern, the entry itself seems valid, leading to a <code class="cx pu pv pw px b">high</code>confidence level in identifying the nature of this error.</li></ul><p id="5507" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Following our guidelines to compute the dirtiness score, we can adopt a methodical approach by introducing a <code class="cx pu pv pw px b">DataIssue</code> class in Python, designed to encapsulate various aspects of a data issue:</p><pre class="nu nv nw nx ny py px pz bp qa bb bk"><span id="0529" class="qb om fq px b bg qc qd l qe qf">@dataclass<br/>class DataIssue:<br/>    type_of_issue: str<br/>    expectation: str<br/>    constraint_violated: str<br/>    confidence_score: float<br/>    location: np.ndarray</span></pre><p id="7456" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">To locate specific errors, a <code class="cx pu pv pw px b">numpy</code> array of size <code class="cx pu pv pw px b">(6, 5)</code> is utilised, where each element corresponds to a cell in the dataset. This array consists of 0s and 1s, with 1 indicating a potential issue in the corresponding cell of the dataset.<br/>All the identified data issues are instantiated hereafter:</p><pre class="nu nv nw nx ny py px pz bp qa bb bk"><span id="15ae" class="qb om fq px b bg qc qd l qe qf"># Issue with Student# 2 - Extra value in 'Favorite Color'<br/>issue_1 = DataIssue(<br/>    type_of_issue="Extra Value",<br/>    expectation="Single value in 'Favorite Color'",<br/>    constraint_violated="It looks like two values ('blue,green') have been merged",<br/>    confidence_score=0.75, # `high`<br/>    location=np.array([<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 1, 0],<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0]<br/>		], <br/>	)<br/>)<br/><br/># Issue with Student# 3 - Missing 'Favorite Color'<br/>issue_2 = DataIssue(<br/>    type_of_issue="Missing Value",<br/>    expectation="No missing values in 'Favorite Color'",<br/>    constraint_violated="Non-null constraint",<br/>    confidence_score=1.0, # `certain`<br/>    location=np.array([<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 1, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0]<br/>		], <br/>	)<br/>)<br/><br/># Issue with Student# 4 - Implausible Age<br/>issue_3 = DataIssue(<br/>    type_of_issue="Implausible Value",<br/>    expectation="Positive integer for 'Age'",<br/>    constraint_violated="Positive integer constraint",<br/>    confidence_score=1.0, # `certain`<br/>    location=np.array([<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 1], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0]<br/>		], <br/>	)<br/>)<br/><br/># Issues with Student# 5 - Multiple potential issues<br/>issue_4 = DataIssue(<br/>    type_of_issue="Structural/Typographical Error",<br/>    expectation="Consistent and plausible data entries",<br/>    constraint_violated="The `Favorite Color` and `First Name` fields might be swapped, considering `Olivia` can be both a name and a colour",<br/>    confidence_score=0.25, # `low`<br/>    location=np.array([<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 1, 1, 0], <br/>		[0, 0, 0, 0, 0]<br/>		], <br/>	)<br/>)<br/><br/>issue_5 = DataIssue(<br/>    type_of_issue="Typecasting error",<br/>    expectation="`Favorite Color` must only contain values from known color strings",<br/>    constraint_violated="`9` is not a valid colour name",<br/>    confidence_score=0.75, # `high`<br/>    location=np.array([<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 1, 0], <br/>		[0, 0, 0, 0, 0]<br/>		],<br/>	)<br/>)<br/><br/>issue_6 = DataIssue(<br/>    type_of_issue="Anomaly",<br/>    expectation="Realistic age values for 6th-grade students",<br/>    constraint_violated="An age of `102` is highly improbable",<br/>    confidence_score=0.75, # `high`<br/>    location=np.array([<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 1], <br/>		[0, 0, 0, 0, 0]<br/>		], <br/>	)<br/>)<br/><br/># Issue with last row - Superfluous commas<br/>issue_7 = DataIssue(<br/>    type_of_issue="Formatting Error",<br/>    expectation="Correct delimiter usage",<br/>    constraint_violated="Duplicate commas as separators",<br/>    confidence_score=1.0, # `certain`<br/>    location=np.array([<br/>		[0, 0, 0, 0, 0],<br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[0, 0, 0, 0, 0], <br/>		[1, 1, 1, 1, 1]<br/>		], <br/>	)<br/>)</span></pre><p id="935b" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">The categorisation of multiple data errors into specific <code class="cx pu pv pw px b">DataIssue</code> instances can be somewhat subjective, similar to the nuances involved in bug reporting in software development. The fields—<code class="cx pu pv pw px b">type_of_issue</code>, <code class="cx pu pv pw px b">expectation</code>, and <code class="cx pu pv pw px b">constraint_violated</code>—serve to elucidate the nature of the error, facilitating understanding during investigations or reviews.<br/>For computing the dirtiness score, the critical elements are the locations of the errors and the associated confidence scores. In this example, the confidence scores are estimated based on the perceived certainty of an error's presence.</p><blockquote class="mj mk ml"><p id="8572" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><em class="fq">Repeated issues pointing to the same cells significantly increase the likelihood of a problem being present there.</em></p></blockquote><p id="f9ac" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Now that we have all the information we need, let’s see how to calculate the dirtiness score for this small data set.</p><h1 id="2ec2" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Calculation of the Data Dirtiness Score</h1><blockquote class="mj mk ml"><p id="746c" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><em class="fq">The </em>Data Dirtiness Score<em class="fq"> represents the </em><strong class="mp fr"><em class="fq">expected fraction of cells</em></strong><em class="fq"> in a dataset </em><strong class="mp fr"><em class="fq">that contain errors</em></strong><em class="fq">.</em></p></blockquote><p id="a2b3" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">The theory and calculation for this score are elaborated in the <code class="cx pu pv pw px b">Score Theory</code> section of the appendix.</p><p id="23a2" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">By using confidence scores for various issues as estimates for the independent probability of an error in each cell, we can apply fundamental probability principles to calculate the likelihood of an issue per cell, and consequently, the <em class="mo">Data Dirtiness Score</em>.</p><p id="3200" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Below is a Python function to calculate this metric based on a list of identified data issues:</p><pre class="nu nv nw nx ny py px pz bp qa bb bk"><span id="fd74" class="qb om fq px b bg qc qd l qe qf">def compute_data_dirtiness_score(data_issues: List[DataIssue]) -&gt; float:<br/>    """<br/>    Computes the Data Dirtiness Score based on a list of data issues.<br/>    Each issue's impact on data quality is represented by a confidence score <br/>    and its location within the dataset.<br/>    The function aggregates these impacts to estimate the overall 'dirtiness' <br/>    of the dataset, with higher scores indicating lower quality.<br/><br/>    Parameters:<br/>        data_issues: A list of DataIssue instances, <br/>        each detailing a specific data quality issue.<br/><br/>    Returns:<br/>        The overall Data Dirtiness Score for the dataset, as a float.<br/>    """<br/>    <br/>    # Stack the probability arrays of a cell being error-free per issue<br/>    stacked_error_free_probs = np.stack(<br/>        [(1 - issue.confidence_score*issue.location) for issue in data_issues],<br/>        axis=-1,<br/>    )<br/><br/>    # Calculate the combined matrix probabilities of an issue for each cell<br/>    probs_issue = 1 - np.prod(stacked_error_free_probs, axis=-1)<br/><br/>    # Find the average probability across all cells to get the dirtiness score<br/>    data_dirtiness_score = np.mean(probs_issue)<br/>    <br/>    return data_dirtiness_score</span></pre><p id="41b5" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Let’s compute the score for the data set presented earlier:</p><pre class="nu nv nw nx ny py px pz bp qa bb bk"><span id="2498" class="qb om fq px b bg qc qd l qe qf">compute_data_dirtiness_score(data_issues)</span></pre><blockquote class="mj mk ml"><p id="bd76" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><em class="fq">Data Dirtiness Score: 31.87%</em></p></blockquote><p id="1483" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">To improve (reduce) this score, a natural step is to tackle the simplest errors, such as correcting duplicate commas used as separators in the last row.<br/>Here is the new version of the dataset:</p><pre class="nu nv nw nx ny py px pz bp qa bb bk"><span id="bef5" class="qb om fq px b bg qc qd l qe qf">Student#,Last Name,First Name,Favorite Color,Age<br/>1,Johnson,Mia,periwinkle,12<br/>2,Lopez,Liam,blue,green,13<br/>3,Lee,Isabella,,11<br/>4,Fisher,Mason,gray,-1<br/>5,Gupta,Olivia,9,102<br/>6,Robinson,Sophia,blue,12</span></pre><p id="4a27" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Let’s recompute the score once again to see the improvement.</p><pre class="nu nv nw nx ny py px pz bp qa bb bk"><span id="57f5" class="qb om fq px b bg qc qd l qe qf">compute_data_dirtiness_score(data_issues)</span></pre><blockquote class="mj mk ml"><p id="07c8" class="mm mn mo mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk"><em class="fq">Data Dirtiness Score: 15.21%</em></p></blockquote><p id="4e45" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Reevaluating the score post-correction reveals a significant improvement, halving the score due to the nature of the error affecting an entire row in a relatively small dataset.</p><p id="11b6" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">In conclusion, this measure provides a quantitative means of monitoring and improving the cleanliness of our dataset by correcting iteratively identified data errors.</p><h1 id="f030" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Next Steps and Challenges</h1><p id="4357" class="pw-post-body-paragraph mm mn fq mp b go ph mr ms gr pi mu mv mw pj my mz na pk nc nd ne pl ng nh ni fj bk">Creating expectations or constraints for data can be challenging and costly due to the need for human labelling and domain knowledge. A solution is to automate the generation of constraints and data error detection, allowing humans to later review and adjust these automated constraints by either removing issues or modifying confidence scores. For that purpose, LLMs are really good candidates (cf. <a class="af ok" href="https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10" rel="noopener ugc nofollow" target="_blank">Jellyfish: A Large Language Model for Data Preprocessing</a>, <a class="af ok" href="http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf" rel="noopener ugc nofollow" target="_blank">Can language models automate data wrangling?</a> or <a class="af ok" href="https://arxiv.org/abs/2308.16361" rel="noopener ugc nofollow" target="_blank">Large Language Models as Data Preprocessors</a>).</p><p id="a42c" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">The likelihood of certain constraints and violations isn’t always crystal-clear, which necessitates a confidence score to account for this uncertainty. Even experts might not always agree on specific data issues, so when automation is involved in detecting these issues, having an estimated likelihood becomes particularly useful.</p><p id="08f1" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">What about absent expectations or missed data errors? The effectiveness of error detection directly influences the cleanliness score and can lead to an overly optimistic value. However, there’s a counterargument to consider: errors that are more difficult to detect, and thus more concealed, might not be as critical in their impact on data usability or downstream applications. This suggests that such errors should be assigned a lower confidence score when identified as issues, reflecting their reduced significance. While this approach may not be without its flaws, it serves to limit the influence of these overlooked errors on the overall dirtiness score by weighting their importance accordingly.</p><p id="4688" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Another aspect to consider is the dynamic nature of the score. Addressing one issue could potentially affect other issues, raising questions about how to update the score efficiently without much hassle.</p><p id="0f32" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">There’s also the question of whether to include indexes and column names as part of the dataset cells when calculating the cleanliness score, as their accuracy can also affect the data cleaning process (see for example <a class="af ok" href="https://arxiv.org/abs/2306.00745" rel="noopener ugc nofollow" target="_blank">Column Type Annotation using ChatGPT</a>).</p><p id="01ce" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Future articles in this series will explore various related topics, including a taxonomy of data errors, leveraging LLMs for automated issue detection, and strategies for data correction and repair. Stay tuned then!</p><p id="bf46" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">-&gt; Link to the 2nd article: <a class="af ok" rel="noopener" target="_blank" href="/automated-detection-of-data-quality-issues-54a3cb283a91">Data Quality Error Detection powered by LLMs</a>.</p></div></div></div><div class="ab cb nj nk nl nm" role="separator"><span class="nn by bm no np nq"/><span class="nn by bm no np nq"/><span class="nn by bm no np"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="1222" class="ol om fq bf on oo qh gq oq or qi gt ot ou qj ow ox oy qk pa pb pc ql pe pf pg bk">References</h1><ul class=""><li id="4d46" class="mm mn fq mp b go ph mr ms gr pi mu mv mw pj my mz na pk nc nd ne pl ng nh ni qg pn po bk"><a class="af ok" href="https://arxiv.org/abs/2205.09911" rel="noopener ugc nofollow" target="_blank">Can Foundation Models Wrangle Your Data?</a></li><li id="27aa" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="https://cs.uwaterloo.ca/~ilyas/papers/AbedjanVLDB2016.pdf" rel="noopener ugc nofollow" target="_blank">Detecting Data Errors: Where are we and what needs to be done?</a></li><li id="35de" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="https://www.semanticscholar.org/reader/5191f08424a3ec0cdaf2b3285860216caca57463" rel="noopener ugc nofollow" target="_blank">Automatic Data Repair: Are We Ready to Deploy?</a></li><li id="dd75" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="https://arxiv.org/abs/1702.00820" rel="noopener ugc nofollow" target="_blank">HoloClean: Holistic Data Repairs with Probabilistic Inference</a></li><li id="5a37" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="https://www.jstatsoft.org/article/view/v059i10" rel="noopener ugc nofollow" target="_blank">Tidy Data | Journal of Statistical Software</a></li><li id="615d" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" rel="noopener" target="_blank" href="/how-to-quantify-data-quality-743721bdba03">How to quantify Data Quality?</a></li><li id="d0bb" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="https://github.com/PacktPublishing/Cleaning-Data-for-Effective-Data-Science" rel="noopener ugc nofollow" target="_blank">Cleaning Data for Effective Data Science</a></li><li id="1c7a" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10" rel="noopener ugc nofollow" target="_blank">Jellyfish: A Large Language Model for Data Preprocessing</a></li><li id="9a97" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf" rel="noopener ugc nofollow" target="_blank">Can language models automate data wrangling?</a></li><li id="1dc8" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="https://arxiv.org/abs/2308.16361" rel="noopener ugc nofollow" target="_blank">Large Language Models as Data Preprocessors</a></li><li id="eb8a" class="mm mn fq mp b go pp mr ms gr pq mu mv mw pr my mz na ps nc nd ne pt ng nh ni qg pn po bk"><a class="af ok" href="https://arxiv.org/abs/2306.00745" rel="noopener ugc nofollow" target="_blank">Column Type Annotation using ChatGPT</a></li></ul><h1 id="f263" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Score theory</h1><p id="583e" class="pw-post-body-paragraph mm mn fq mp b go ph mr ms gr pi mu mv mw pj my mz na pk nc nd ne pl ng nh ni fj bk">Let’s dive into the concept of calculating the <em class="mo">Data Dirtiness Score</em> for a dataset, denoted as 𝒟. This dataset comprises I rows, representing individuals, and J columns, representing different variables.</p><p id="745b" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">We introduce a matrix X, which is of the same dimensions as 𝒟, with I rows and J columns:</p><figure class="nu nv nw nx ny nz nr ns paragraph-image"><div class="nr ns qm"><img src="../Images/9e7f620081e61c7931d40d94f0cbba78.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*aCf5L9PRq-OfAfM9-brTtw.png"/></div></figure><p id="91ce" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">In this matrix, each element X_{ij} follows a Bernoulli distribution with parameter π_{ij}. The value of X_{ij} is set to 0 if the cell (i, j) in dataset 𝒟 is free from data issues, and 1 if there is an issue, with the probability 𝔼[X_{ij}] = π_{ij} indicating the likelihood of an issue being present.</p><p id="db76" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">Next, we define a random variable Y that represents the proportion of cells in 𝒟 that are problematic. The formula for Y is given by:</p><figure class="nu nv nw nx ny nz nr ns paragraph-image"><div class="nr ns qn"><img src="../Images/5b81b04e0127fadd5e595f155ada72ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*1heJi8_8Y6N6toEs7QQlcA.png"/></div></figure><p id="10e2" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">The <em class="mo">Data Dirtiness Score</em> is then the expected value of Y:</p><figure class="nu nv nw nx ny nz nr ns paragraph-image"><div role="button" tabindex="0" class="oa ob ed oc bh od"><div class="nr ns qo"><img src="../Images/9751e5fc469f30e2848fb5cde58471e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c4QV7gl4Tch1LsN9LXRiMw.png"/></div></div></figure><p id="9c4f" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">To connect this back to our earlier discussion, the link between the confidence scores for each cell’s data error and the probabilities π_{ij} is captured by the following relationship:</p><figure class="nu nv nw nx ny nz nr ns paragraph-image"><div class="nr ns qp"><img src="../Images/6dd87d19370c09f8103e0cae7236a483.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*zL-zr7mbMpQyB0iu7OdwnA.png"/></div></figure><p id="fe12" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">This means that the probability of a cell being error-free is calculated as the product of the complements of the confidence scores for potential errors in that cell.</p><p id="b3c5" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">If all confidence scores are set to 1, indicating absolute certainty of errors, the dirtiness score simplifies to the proportion of cells with errors in the dataset.<br/>Calculating the dirtiness score or the cleanliness score for a dataset essentially yields the same insight, just from different perspectives. The formula for the <em class="mo">Data Cleanliness Score</em> is simply one minus the <em class="mo">Data Dirtiness Score</em>:</p><figure class="nu nv nw nx ny nz nr ns paragraph-image"><div class="nr ns qq"><img src="../Images/b96f59c6e83b5836924288130a2d89f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*gMuoPedK22WOkCe3e3WuKw.png"/></div></figure><p id="9f3f" class="pw-post-body-paragraph mm mn fq mp b go mq mr ms gr mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni fj bk">In this way, a dataset with no errors at all would have a cleanliness score of 100% and a dirtiness score of 0%.</p><h1 id="8d14" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Changes</h1><p id="7d51" class="pw-post-body-paragraph mm mn fq mp b go ph mr ms gr pi mu mv mw pj my mz na pk nc nd ne pl ng nh ni fj bk">EDIT-2024–03–21: Convert confidence values to ordinal categories: <code class="cx pu pv pw px b">low</code>, <code class="cx pu pv pw px b">medium</code>, <code class="cx pu pv pw px b">high</code>, and <code class="cx pu pv pw px b">certain</code>. These represent probabilities of 0.25, 0.5, 0.75, and 1, respectively.</p></div></div></div></div>    
</body>
</html>