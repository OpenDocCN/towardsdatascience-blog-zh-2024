# å¾®è°ƒ Llama 3 ä¸ ORPO

> åŸæ–‡ï¼š[https://towardsdatascience.com/fine-tune-llama-3-with-orpo-56cfab2f9ada?source=collection_archive---------3-----------------------#2024-04-19](https://towardsdatascience.com/fine-tune-llama-3-with-orpo-56cfab2f9ada?source=collection_archive---------3-----------------------#2024-04-19)

## *ä¸€ç§æ›´ä¾¿å®œã€æ›´å¿«é€Ÿçš„ç»Ÿä¸€å¾®è°ƒæŠ€æœ¯*

[](https://medium.com/@mlabonne?source=post_page---byline--56cfab2f9ada--------------------------------)[![Maxime Labonne](../Images/a7efdd305e3cc77d5509bbb1076d57d8.png)](https://medium.com/@mlabonne?source=post_page---byline--56cfab2f9ada--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--56cfab2f9ada--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--56cfab2f9ada--------------------------------) [Maxime Labonne](https://medium.com/@mlabonne?source=post_page---byline--56cfab2f9ada--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--56cfab2f9ada--------------------------------) Â·é˜…è¯»æ—¶é•¿ 8 åˆ†é’Ÿ Â·2024å¹´4æœˆ19æ—¥

--

![](../Images/0024fbce8d1d7e5a96348655f9f40d35.png)

å›¾ç‰‡ç”± DALL-E 3 ç”Ÿæˆï¼Œç”±ä½œè€…æä¾›

ORPO æ˜¯ä¸€ç§**æ–°å…´çš„ä»¤äººå…´å¥‹çš„å¾®è°ƒæŠ€æœ¯**ï¼Œå®ƒå°†ä¼ ç»Ÿçš„ç›‘ç£å¾®è°ƒå’Œåå¥½å¯¹é½é˜¶æ®µåˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€è¿‡ç¨‹ã€‚è¿™å‡å°‘äº†è®­ç»ƒæ‰€éœ€çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚æ­¤å¤–ï¼Œå®è¯ç»“æœè¡¨æ˜ï¼ŒORPO åœ¨å¤šç§æ¨¡å‹è§„æ¨¡å’ŒåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å…¶ä»–å¯¹é½æ–¹æ³•ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ ORPO å’Œ TRL åº“å¾®è°ƒæ–°çš„ Llama 3 8B æ¨¡å‹ã€‚ä»£ç å¯ä»¥åœ¨ [Google Colab](https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi?usp=sharing) å’Œ GitHub ä¸Šçš„ [LLM è¯¾ç¨‹](https://github.com/mlabonne/llm-course) ä¸­æ‰¾åˆ°ã€‚

# âš–ï¸ ORPO

æŒ‡ä»¤å¾®è°ƒå’Œåå¥½å¯¹é½æ˜¯å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€‚åº”ç‰¹å®šä»»åŠ¡çš„å…³é”®æŠ€æœ¯ã€‚ä¼ ç»Ÿä¸Šï¼Œè¿™æ¶‰åŠåˆ°ä¸€ä¸ªå¤šé˜¶æ®µçš„è¿‡ç¨‹ï¼š1/ **ç›‘ç£å¾®è°ƒ**ï¼ˆSFTï¼‰ï¼Œä»¥ä½¿æ¨¡å‹é€‚åº”ç›®æ ‡é¢†åŸŸï¼Œç„¶åæ˜¯ 2/ **åå¥½å¯¹é½æ–¹æ³•**ï¼Œå¦‚äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æˆ–ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ï¼Œä»¥æé«˜ç”Ÿæˆé¦–é€‰å“åº”è€Œéè¢«æ‹’ç»å“åº”çš„æ¦‚ç‡ã€‚

![](../Images/29cac2fc31790a8a74230a95bd7e7b4b.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

ç„¶è€Œï¼Œç ”ç©¶äººå‘˜å‘ç°è¿™ç§æ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚è™½ç„¶ SFT å¯ä»¥æœ‰æ•ˆåœ°å°†æ¨¡å‹é€‚åº”æ‰€éœ€é¢†åŸŸï¼Œä½†å®ƒæ— æ„ä¸­**å¢åŠ äº†ç”Ÿæˆä¸è‰¯ç­”æ¡ˆçš„æ¦‚ç‡**ï¼Œè€Œè¿™äº›ç­”æ¡ˆä¸é¦–é€‰ç­”æ¡ˆä¸€èµ·å‡ºç°ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåå¥½å¯¹é½é˜¶æ®µæ˜¯å¿…è¦çš„ï¼Œå®ƒèƒ½æ‹‰å¤§é¦–é€‰è¾“å‡ºå’Œè¢«æ‹’ç»è¾“å‡ºä¹‹é—´çš„æ¦‚ç‡å·®è·ã€‚

![](../Images/d27c0588ee55984b02754a279bb715f4.png)

æ³¨æ„ï¼Œç»è¿‡ç›‘ç£å¾®è°ƒåï¼Œè¢«æ‹’ç»çš„å“åº”æ¦‚ç‡æ˜¯å¦‚ä½•å¢åŠ çš„ï¼ˆå›¾ç‰‡æ¥è‡ªORPOè®ºæ–‡ï¼‰ã€‚

ç”±[Hong and Lee (2024)](https://arxiv.org/abs/2403.07691)æå‡ºï¼ŒORPOé€šè¿‡å°†æŒ‡ä»¤å¾®è°ƒå’Œåå¥½å¯¹é½ç»“åˆåˆ°ä¸€ä¸ªå•ä¸€çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæä¾›äº†ä¸€ä¸ªä¼˜é›…çš„è§£å†³æ–¹æ¡ˆã€‚ORPOä¿®æ”¹äº†æ ‡å‡†çš„è¯­è¨€å»ºæ¨¡ç›®æ ‡ï¼Œå°†è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ä¸èµ”ç‡æ¯”ï¼ˆORï¼‰é¡¹ç»“åˆèµ·æ¥ã€‚è¿™ä¸ªORæŸå¤±åœ¨æƒ©ç½šè¢«æ‹’ç»çš„å“åº”æ—¶ç›¸å¯¹è¾ƒå¼±ï¼Œè€Œåœ¨å¥–åŠ±åå¥½çš„å“åº”æ—¶åˆ™è¾ƒå¼ºï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤ŸåŒæ—¶å­¦ä¹ ç›®æ ‡ä»»åŠ¡å¹¶ä¸äººç±»åå¥½å¯¹é½ã€‚

![](../Images/246e9df3fef5d97400c82a00263c7f5d.png)

ORPOå·²ç»åœ¨ä¸»è¦çš„å¾®è°ƒåº“ä¸­å®ç°ï¼Œä¾‹å¦‚[TRL](https://github.com/huggingface/trl)ã€[Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)å’Œ[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)ã€‚åœ¨ä¸‹ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä¸TRLä¸€èµ·ä½¿ç”¨ã€‚

# ğŸ’» ä½¿ç”¨ORPOå¾®è°ƒLlama 3

[Llama 3](https://github.com/meta-llama/llama3/tree/main)æ˜¯Metaå¼€å‘çš„æœ€æ–°LLMç³»åˆ—ã€‚è¿™äº›æ¨¡å‹åœ¨ä¸€ä¸ªåºå¤§çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå…±**15ä¸‡äº¿ä¸ªæ ‡è®°**ï¼ˆç›¸æ¯”ä¹‹ä¸‹ï¼ŒLlama 2ä¸º2ä¸‡äº¿æ ‡è®°ï¼‰ã€‚å·²ç»å‘å¸ƒäº†ä¸¤ç§æ¨¡å‹å¤§å°ï¼šä¸€ä¸ª70äº¿å‚æ•°æ¨¡å‹å’Œä¸€ä¸ªè¾ƒå°çš„80äº¿å‚æ•°æ¨¡å‹ã€‚70Bæ¨¡å‹å·²ç»å±•ç¤ºäº†å‡ºè‰²çš„æ€§èƒ½ï¼Œåœ¨MMLUåŸºå‡†æµ‹è¯•ä¸­å¾—åˆ†ä¸º82ï¼Œåœ¨HumanEvalåŸºå‡†æµ‹è¯•ä¸­å¾—åˆ†ä¸º81.7ã€‚

Llama 3æ¨¡å‹è¿˜å°†ä¸Šä¸‹æ–‡é•¿åº¦å¢åŠ åˆ°8,192ä¸ªæ ‡è®°ï¼ˆLlama 2ä¸º4,096ä¸ªæ ‡è®°ï¼‰ï¼Œå¹¶å¯èƒ½é€šè¿‡RoPEæ‰©å±•åˆ°32kã€‚æ­¤å¤–ï¼Œæ¨¡å‹ä½¿ç”¨äº†ä¸€ä¸ªæ–°çš„åˆ†è¯å™¨ï¼Œå…·æœ‰128Kæ ‡è®°çš„è¯æ±‡è¡¨ï¼Œå°†ç¼–ç æ–‡æœ¬æ‰€éœ€çš„æ ‡è®°æ•°å‡å°‘äº†15%ã€‚è¿™ä¸ªè¯æ±‡è¡¨ä¹Ÿè§£é‡Šäº†ä»7Båˆ°8Bå‚æ•°çš„æå‡ã€‚

![](../Images/1fb24c5aea241733ae340216214e0bb8.png)

*æ¥è‡ªORPO-DPO-mix-40kçš„æ ·æœ¬ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰ã€‚*

ORPOéœ€è¦ä¸€ä¸ªåå¥½æ•°æ®é›†ï¼ŒåŒ…æ‹¬ä¸€ä¸ªæç¤ºè¯­ã€ä¸€ä¸ªé€‰æ‹©çš„ç­”æ¡ˆå’Œä¸€ä¸ªè¢«æ‹’ç»çš„ç­”æ¡ˆã€‚åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`[mlabonne/orpo-dpo-mix-40k](https://huggingface.co/datasets/mlabonne/orpo-dpo-mix-40k)`ï¼Œå®ƒæ˜¯ä»¥ä¸‹é«˜è´¨é‡DPOæ•°æ®é›†çš„ç»„åˆï¼š

+   `[argilla/distilabel-capybara-dpo-7k-binarized](https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized)`ï¼šå¾—åˆ†è¾ƒé«˜çš„é€‰æ‹©ç­”æ¡ˆ>=5ï¼ˆ2,882ä¸ªæ ·æœ¬ï¼‰

+   `[argilla/distilabel-intel-orca-dpo-pairs](https://huggingface.co/datasets/argilla/distilabel-intel-orca-dpo-pairs)`ï¼šå¾—åˆ†è¾ƒé«˜çš„é€‰æ‹©ç­”æ¡ˆ>=9ï¼Œä½†ä¸åœ¨GSM8Kä¸­ï¼ˆ2,299ä¸ªæ ·æœ¬ï¼‰

+   `[argilla/ultrafeedback-binarized-preferences-cleaned](https://huggingface.co/datasets/argilla/ultrafeedback-binarized-preferences-cleaned)`ï¼šå¾—åˆ†è¾ƒé«˜çš„é€‰æ‹©ç­”æ¡ˆ>=5ï¼ˆ22,799ä¸ªæ ·æœ¬ï¼‰

+   `[argilla/distilabel-math-preference-dpo](https://huggingface.co/datasets/argilla/distilabel-math-preference-dpo)`ï¼šå¾—åˆ†è¾ƒé«˜çš„é€‰æ‹©ç­”æ¡ˆ>=9ï¼ˆ2,181ä¸ªæ ·æœ¬ï¼‰

+   `[unalignment/toxic-dpo-v0.2](https://huggingface.co/datasets/unalignment/toxic-dpo-v0.2)`ï¼ˆ541ä¸ªæ ·æœ¬ï¼‰

+   `[M4-ai/prm_dpo_pairs_cleaned](https://huggingface.co/datasets/M4-ai/prm_dpo_pairs_cleaned)`ï¼ˆ7,958ä¸ªæ ·æœ¬ï¼‰

+   `[jondurbin/truthy-dpo-v0.1](https://huggingface.co/datasets/jondurbin/truthy-dpo-v0.1)`ï¼ˆ1,016ä¸ªæ ·æœ¬ï¼‰

æ„Ÿè°¢[argilla](https://huggingface.co/argilla)ã€[unalignment](https://huggingface.co/unalignment)ã€[M4-ai](https://huggingface.co/M4-ai)å’Œ[jondurbin](https://huggingface.co/jondurbin)æä¾›æºæ•°æ®é›†ã€‚

å¦‚å¸¸ï¼Œæˆ‘ä»¬ä»å®‰è£…æ‰€éœ€çš„åº“å¼€å§‹ï¼š

```py
pip install -U transformers datasets accelerate peft trl bitsandbytes wandb
```

ä¸€æ—¦å®‰è£…å®Œæˆï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯¼å…¥å¿…è¦çš„åº“å¹¶ç™»å½•W&Bï¼ˆå¯é€‰ï¼‰ï¼š

```py
import gc
import os

import torch
import wandb
from datasets import load_dataset
from google.colab import userdata
from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    TrainingArguments,
    pipeline,
)
from trl import ORPOConfig, ORPOTrainer, setup_chat_format
wb_token = userdata.get('wandb')
wandb.login(key=wb_token)
```

å¦‚æœä½ æœ‰ä¸€å—è¾ƒæ–°çš„GPUï¼Œä½ åº”è¯¥ä¹Ÿèƒ½å¤Ÿä½¿ç”¨[Flash Attentionåº“](https://github.com/Dao-AILab/flash-attention)ï¼Œå°†é»˜è®¤çš„æ€¥åˆ‡æ³¨æ„åŠ›å®ç°æ›¿æ¢ä¸ºæ›´é«˜æ•ˆçš„å®ç°ã€‚

```py
if torch.cuda.get_device_capability()[0] >= 8:
    !pip install -qqq flash-attn
    attn_implementation = "flash_attention_2"
    torch_dtype = torch.bfloat16
else:
    attn_implementation = "eager"
    torch_dtype = torch.float16
```

åœ¨æ¥ä¸‹æ¥çš„æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡[bitsandbytes](https://github.com/TimDettmers/bitsandbytes)ä»¥4ä½ç²¾åº¦åŠ è½½Llama 3 8Bæ¨¡å‹ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨[PEFT](https://github.com/huggingface/peft)ä¸ºQLoRAè®¾ç½®LoRAé…ç½®ã€‚æˆ‘è¿˜ä½¿ç”¨äº†æ–¹ä¾¿çš„`setup_chat_format()`å‡½æ•°ï¼Œæ¥ä¿®æ”¹æ¨¡å‹å’Œåˆ†è¯å™¨ä»¥æ”¯æŒ[ChatML](https://huggingface.co/docs/transformers/en/chat_templating#what-template-should-i-use)ã€‚å®ƒä¼šè‡ªåŠ¨åº”ç”¨è¿™ä¸ªèŠå¤©æ¨¡æ¿ï¼Œæ·»åŠ ç‰¹æ®Šæ ‡è®°ï¼Œå¹¶è°ƒæ•´æ¨¡å‹çš„åµŒå…¥å±‚å¤§å°ä»¥åŒ¹é…æ–°çš„è¯æ±‡è¡¨å¤§å°ã€‚

è¯·æ³¨æ„ï¼Œä½ éœ€è¦æäº¤è¯·æ±‚ä»¥è®¿é—®[meta-llama/Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)ï¼Œå¹¶ä¸”ç™»å½•ä½ çš„Hugging Faceè´¦æˆ·ã€‚æˆ–è€…ï¼Œä½ å¯ä»¥åŠ è½½æ²¡æœ‰æƒé™é™åˆ¶çš„æ¨¡å‹å‰¯æœ¬ï¼Œå¦‚[NousResearch/Meta-Llama-3-8B](https://huggingface.co/NousResearch/Meta-Llama-3-8B)ã€‚

```py
# Model
base_model = "meta-llama/Meta-Llama-3-8B"
new_model = "OrpoLlama-3-8B"

# QLoRA config
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch_dtype,
    bnb_4bit_use_double_quant=True,
)

# LoRA config
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']
)

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(base_model)

# Load model
model = AutoModelForCausalLM.from_pretrained(
    base_model,
    quantization_config=bnb_config,
    device_map="auto",
    attn_implementation=attn_implementation
)
model, tokenizer = setup_chat_format(model, tokenizer)
model = prepare_model_for_kbit_training(model)
```

ç°åœ¨æ¨¡å‹å·²ç»å‡†å¤‡å¥½è¿›è¡Œè®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å¤„ç†æ•°æ®é›†ã€‚æˆ‘ä»¬åŠ è½½`[mlabonne/orpo-dpo-mix-40k](https://huggingface.co/datasets/mlabonne/orpo-dpo-mix-40k)`ï¼Œå¹¶ä½¿ç”¨`apply_chat_template()`å‡½æ•°å°†â€œé€‰æ‹©çš„â€å’Œâ€œæ‹’ç»çš„â€åˆ—è½¬æ¢ä¸ºChatMLæ ¼å¼ã€‚è¯·æ³¨æ„ï¼Œæˆ‘åªä½¿ç”¨äº†1,000ä¸ªæ ·æœ¬ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ•°æ®é›†ï¼Œå› ä¸ºè¿è¡Œæ•´ä¸ªæ•°æ®é›†éœ€è¦çš„æ—¶é—´å¤ªé•¿ã€‚

```py
dataset_name = "mlabonne/orpo-dpo-mix-40k"
dataset = load_dataset(dataset_name, split="all")
dataset = dataset.shuffle(seed=42).select(range(1000))

def format_chat_template(row):
    row["chosen"] = tokenizer.apply_chat_template(row["chosen"], tokenize=False)
    row["rejected"] = tokenizer.apply_chat_template(row["rejected"], tokenize=False)
    return row

dataset = dataset.map(
    format_chat_template,
    num_proc= os.cpu_count(),
)
dataset = dataset.train_test_split(test_size=0.01)
```

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®ä¸€äº›è¶…å‚æ•°ï¼š

+   `learning_rate`ï¼šORPOä½¿ç”¨çš„å­¦ä¹ ç‡æ¯”ä¼ ç»Ÿçš„SFTæˆ–DPOè¦ä½å¾—å¤šã€‚è¿™ä¸ª8e-6çš„å€¼æ¥è‡ªåŸè®ºæ–‡ï¼Œç²—ç•¥å¯¹åº”SFTå­¦ä¹ ç‡çš„1e-5å’ŒDPOå­¦ä¹ ç‡çš„5e-6ã€‚æˆ‘å»ºè®®å°†å…¶å¢åŠ åˆ°1e-6å·¦å³ï¼Œä»¥è¿›è¡ŒçœŸæ­£çš„å¾®è°ƒã€‚

+   `beta`ï¼šå®ƒæ˜¯è®ºæ–‡ä¸­çš„$\lambda$å‚æ•°ï¼Œé»˜è®¤å€¼ä¸º0.1ã€‚åŸè®ºæ–‡çš„é™„å½•å±•ç¤ºäº†å¦‚ä½•é€šè¿‡æ¶ˆèå®éªŒæ¥é€‰æ‹©è¿™ä¸ªå€¼ã€‚

+   å…¶ä»–å‚æ•°ï¼Œå¦‚`max_length`å’Œæ‰¹å¤„ç†å¤§å°ï¼Œè®¾ç½®ä¸ºå°½å¯èƒ½ä½¿ç”¨æ‰€æœ‰çš„VRAMï¼ˆåœ¨æ­¤é…ç½®ä¸‹çº¦ä¸º20GBï¼‰ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šå°†æ¨¡å‹è®­ç»ƒ3-5ä¸ªå‘¨æœŸï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬å°†åªè®­ç»ƒ1ä¸ªå‘¨æœŸã€‚

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ORPOTrainerè¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå®ƒå……å½“äº†ä¸€ä¸ªå°è£…å™¨ã€‚

```py
orpo_args = ORPOConfig(
    learning_rate=8e-6,
    beta=0.1,
    lr_scheduler_type="linear",
    max_length=1024,
    max_prompt_length=512,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    gradient_accumulation_steps=4,
    optim="paged_adamw_8bit",
    num_train_epochs=1,
    evaluation_strategy="steps",
    eval_steps=0.2,
    logging_steps=1,
    warmup_steps=10,
    report_to="wandb",
    output_dir="./results/",
)

trainer = ORPOTrainer(
    model=model,
    args=orpo_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    peft_config=peft_config,
    tokenizer=tokenizer,
)

trainer.train()
trainer.save_model(new_model)
```

åœ¨è¿™äº›1,000ä¸ªæ ·æœ¬ä¸Šè®­ç»ƒæ¨¡å‹èŠ±è´¹äº†å¤§çº¦2å°æ—¶ï¼Œä½¿ç”¨çš„æ˜¯L4 GPUã€‚è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹W&Bçš„å›¾è¡¨ï¼š

![](../Images/4ea31a21aa2d957cab4982835b4be4e9.png)

è™½ç„¶æŸå¤±ä¸‹é™ï¼Œä½†é€‰æ‹©ç­”æ¡ˆå’Œæ‹’ç»ç­”æ¡ˆä¹‹é—´çš„å·®å¼‚å¹¶ä¸æ˜æ˜¾ï¼šå¹³å‡è¾¹é™…å’Œå‡†ç¡®ç‡åˆ†åˆ«ä»…ç•¥é«˜äºé›¶å’Œ0.5ã€‚

åœ¨åŸå§‹è®ºæ–‡ä¸­ï¼Œä½œè€…åœ¨`[Anthropic/hh-rlhf](https://huggingface.co/datasets/Anthropic/hh-rlhf)`æ•°æ®é›†ï¼ˆ161kæ ·æœ¬ï¼‰ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œå¹¶è¿›è¡Œäº†10ä¸ªepochsçš„è®­ç»ƒï¼Œè®­ç»ƒæ—¶é—´è¿œé•¿äºæˆ‘ä»¬çš„å¿«é€Ÿè¿è¡Œã€‚ä»–ä»¬è¿˜å¯¹Llama 3è¿›è¡Œäº†å®éªŒï¼Œå¹¶å‹å¥½åœ°[åˆ†äº«äº†ä»–ä»¬çš„æ—¥å¿—](https://huggingface.co/orpo-explorers/hf-llama3-8b-orpo-v0.0/tensorboard)ç»™æˆ‘ï¼ˆæ„Ÿè°¢[Jiwoo Hong](https://twitter.com/jiwoohong98)ï¼‰ã€‚

åœ¨æœ¬æ•™ç¨‹çš„ç»“å°¾ï¼Œè®©æˆ‘ä»¬å°†QLoRAé€‚é…å™¨ä¸åŸºç¡€æ¨¡å‹åˆå¹¶ï¼Œå¹¶å°†å…¶æ¨é€åˆ°Hugging Face Hubã€‚

```py
# Flush memory
del trainer, model
gc.collect()
torch.cuda.empty_cache()

# Reload tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(base_model)
model = AutoModelForCausalLM.from_pretrained(
    base_model,
    low_cpu_mem_usage=True,
    return_dict=True,
    torch_dtype=torch.float16,
    device_map="auto",
)
model, tokenizer = setup_chat_format(model, tokenizer)

# Merge adapter with base model
model = PeftModel.from_pretrained(model, new_model)
model = model.merge_and_unload()
model.push_to_hub(new_model, use_temp_dir=False)
tokenizer.push_to_hub(new_model, use_temp_dir=False)
```

æ­å–œï¼Œæˆ‘ä»¬å®Œæˆäº†Llama 3çš„å¿«é€Ÿå¾®è°ƒï¼š[mlabonne/OrpoLlama-3â€“8B](https://huggingface.co/mlabonne/OrpoLlama-3-8B)ã€‚ä½ å¯ä»¥é€šè¿‡è¿™ä¸ª[Hugging Face Space](https://huggingface.co/spaces/mlabonne/OrpoLlama-3-8B)æ¥ç©è¿™ä¸ªæ¨¡å‹ï¼ˆè¿™é‡Œæœ‰ä¸€ä¸ª[notebook](https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC?usp=sharing)æ¥åˆ›å»ºä½ è‡ªå·±çš„æ¨¡å‹ï¼‰ã€‚å°½ç®¡å¦‚W&Bæ›²çº¿æ‰€ç¤ºï¼Œæ¨¡å‹è¿˜æœªç»è¿‡å……åˆ†è®­ç»ƒï¼Œæˆ‘åœ¨Nousçš„åŸºå‡†å¥—ä»¶ä¸Šä½¿ç”¨[LLM AutoEval](https://github.com/mlabonne/llm-autoeval)è¿›è¡Œäº†ä¸€äº›è¯„ä¼°ã€‚

![](../Images/127c1583eb4512d807a080e6d4bc4223.png)

æˆ‘ä»¬çš„ORPOå¾®è°ƒå®é™…ä¸Šç›¸å½“ä¸é”™ï¼Œä¸”åœ¨æ¯ä¸ªåŸºå‡†æµ‹è¯•ä¸­éƒ½æå‡äº†åŸºç¡€æ¨¡å‹çš„è¡¨ç°ã€‚è¿™æ˜¯ä»¤äººé¼“èˆçš„ï¼Œä¸”å¾ˆå¯èƒ½æ„å‘³ç€å¯¹æ•´ä¸ª40kæ ·æœ¬è¿›è¡Œå¾®è°ƒå°†å–å¾—å¾ˆå¥½çš„ç»“æœã€‚

è¿™æ˜¯å¼€æºç¤¾åŒºçš„æ¿€åŠ¨äººå¿ƒæ—¶åˆ»ï¼Œè¶Šæ¥è¶Šå¤šé«˜è´¨é‡çš„å¼€æºæƒé‡æ¨¡å‹è¢«å‘å¸ƒã€‚é—­æºæ¨¡å‹å’Œå¼€æºæƒé‡æ¨¡å‹ä¹‹é—´çš„å·®è·æ­£åœ¨æ…¢æ…¢ç¼©å°ï¼Œå¾®è°ƒæ˜¯è·å–æœ€ä½³æ€§èƒ½çš„å¿…å¤‡å·¥å…·ã€‚

![](../Images/885096bd13d294fa53f7589664afdd0b.png)

å›¾ç‰‡æ¥æºï¼šä½œè€…

# ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ORPOç®—æ³•ï¼Œå¹¶è§£é‡Šäº†å®ƒå¦‚ä½•å°†SFTå’Œåå¥½å¯¹é½é˜¶æ®µç»Ÿä¸€ä¸ºä¸€ä¸ªè¿‡ç¨‹ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨TRLå¯¹Llama 3 8Bæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼ŒåŸºäºè‡ªå®šä¹‰çš„åå¥½æ•°æ®é›†ã€‚æœ€ç»ˆçš„æ¨¡å‹æ˜¾ç¤ºå‡ºä»¤äººé¼“èˆçš„ç»“æœï¼Œçªå‡ºäº†ORPOä½œä¸ºä¸€ç§æ–°çš„å¾®è°ƒèŒƒå¼çš„æ½œåŠ›ã€‚

å¸Œæœ›è¿™å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæˆ‘å»ºè®®ä½ è¿è¡Œ[Colab notebook](https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi?usp=sharing)æ¥å¾®è°ƒä½ è‡ªå·±çš„Llama 3æ¨¡å‹ã€‚åœ¨æœªæ¥çš„æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•åˆ›å»ºé«˜è´¨é‡çš„æ•°æ®é›†â€”â€”è¿™æ˜¯ä¸€ä¸ªç»å¸¸è¢«å¿½è§†çš„é‡ç‚¹ã€‚å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·åœ¨[Hugging Face](https://huggingface.co/mlabonne/)å’ŒTwitterä¸Šå…³æ³¨æˆ‘[@maximelabonne](https://twitter.com/maximelabonne)ã€‚

# å‚è€ƒæ–‡çŒ®

+   J. Hong, N. Lee å’Œ J. Thorneï¼Œ[ORPO: æ— éœ€å‚è€ƒæ¨¡å‹çš„å•ä½“åå¥½ä¼˜åŒ–](https://arxiv.org/abs/2403.07691)ã€‚2024å¹´ã€‚

+   L. von Werra ç­‰äºº, TRL: Transformer å¼ºåŒ–å­¦ä¹ . GitHub, 2020\. [åœ¨çº¿]. å¯ç”¨é“¾æ¥: [https://github.com/huggingface/trl](https://github.com/huggingface/trl)

+   Bartolome, A., Martin, G., & Vila, D. (2023). Notus. åœ¨ GitHub ä»“åº“ä¸­ã€‚GitHub. [https://github.com/argilla-io/notus](https://github.com/argilla-io/notus)

+   Meta çš„äººå·¥æ™ºèƒ½ï¼Œ[ä»‹ç» Meta Llama 3](https://ai.meta.com/blog/meta-llama-3/)ï¼Œ2024å¹´ã€‚
