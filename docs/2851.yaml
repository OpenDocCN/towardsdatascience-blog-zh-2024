- en: Building a Knowledge Graph From Scratch Using LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-a-knowledge-graph-from-scratch-using-llms-f6f677a17f07?source=collection_archive---------0-----------------------#2024-11-25](https://towardsdatascience.com/building-a-knowledge-graph-from-scratch-using-llms-f6f677a17f07?source=collection_archive---------0-----------------------#2024-11-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Turn your Pandas data frame into a knowledge graph using LLMs. Build your own
    LLM graph-builder from scratch, implement LLMGraphTransformer by LangChain, and
    QA your KG.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@cristianleo120?source=post_page---byline--f6f677a17f07--------------------------------)[![Cristian
    Leo](../Images/99074292e7dfda50cf50a790b8deda79.png)](https://medium.com/@cristianleo120?source=post_page---byline--f6f677a17f07--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f6f677a17f07--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f6f677a17f07--------------------------------)
    [Cristian Leo](https://medium.com/@cristianleo120?source=post_page---byline--f6f677a17f07--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f6f677a17f07--------------------------------)
    ·36 min read·Nov 25, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5b9cb939817996b93d12ee568410a678.png)'
  prefs: []
  type: TYPE_IMG
- en: Knowledge Graph about 1000 Movies from Wikipedia — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: In today’s AI world, knowledge graphs are becoming increasingly important, as
    they enable many of the knowledge retrieval systems behind LLMs. Many data science
    teams across companies are investing heavily in retrieval augmented generation
    (RAG), as it’s an efficient way to improve the output accuracy of LLMs and prevent
    hallucinations.
  prefs: []
  type: TYPE_NORMAL
- en: 'But there is more to it; on a personal note, graph-RAG is democratizing the
    AI space. This is because before if we wanted to customize a model to a use-case
    — either for fun or business — we would have three options: pre-training the model
    providing a bigger exposure to a dataset within the industry of your use-case,
    fine-tuning the model on a specific dataset, and context prompting.'
  prefs: []
  type: TYPE_NORMAL
- en: As for pre-training, this option is incredibly expensive and technical, and
    it’s not an option for most developers.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning is easier than pre-training, and although the cost of fine-tuning
    depends on the model and the training corpus, it’s generally a more affordable
    option. This one was…
  prefs: []
  type: TYPE_NORMAL
