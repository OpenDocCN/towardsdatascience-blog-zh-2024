- en: Do not over-think about ‘outliers’, use a student-t distribution instead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/do-not-over-think-about-outliers-use-a-student-t-distribution-instead-b6c584b91d5c?source=collection_archive---------0-----------------------#2024-03-30](https://towardsdatascience.com/do-not-over-think-about-outliers-use-a-student-t-distribution-instead-b6c584b91d5c?source=collection_archive---------0-----------------------#2024-03-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Bayesian approach using R and Brms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@damanrique?source=post_page---byline--b6c584b91d5c--------------------------------)[![Daniel
    Manrique-Castano](../Images/06f857ae6e82688113f1089c7f03be88.png)](https://medium.com/@damanrique?source=post_page---byline--b6c584b91d5c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b6c584b91d5c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b6c584b91d5c--------------------------------)
    [Daniel Manrique-Castano](https://medium.com/@damanrique?source=post_page---byline--b6c584b91d5c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b6c584b91d5c--------------------------------)
    ·15 min read·Mar 30, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: For many researchers, outliers are rogue waves that can dramatically alter the
    course of the analysis or “confound” some expected effects. I prefer to use the
    term “extreme observations” and leave the term outlier for observations that are
    not truly part of the population being studied. For example, in my field (brain
    ischemia research), an outlier is an animal that does not have ischemia (when
    it should have), while extreme observations are animals with small or large ischemias
    that are very different from the others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional (frequentist) statistical models are built on the strong foundation
    of Gaussian distributions. This has a significant limitation: an inherent assumption
    that all data points will cluster around a central mean in a predictable pattern
    (based on the central limit theorem). This may be true in Plato’s world of ideas,
    but we, scientists in the biomedical field, are aware it''s challenging to rely
    on this assumption given the limited sampling (number of animals) we have available
    to make observations.'
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian distributions are very sensitive to extreme observations, and their
    use leads scientists to believe that eliminating extreme observations is the best
    way to get “clearer” or “cleaner” results (whatever that means). As I once commented
    in an article as reviewer 2, “The problem is not the extreme observations that
    may “hide” your effects, but the fact that you are using a statistical model that
    (I believe) is inappropriate for your purposes”.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that no statistical model is the “right” or “appropriate”
    one, but we can estimate that, given the data, there are certain statistical models
    that are more likely to generate the observed data (generative models) than others.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fortunately, nothing forces us to be bound by the assumptions of the Gaussian
    models, right? We have other options, such as the **Student’s t-distribution**
    ([*1*](#ref-ahsanullah2014)). I see it as a more adaptable vessel to navigate
    the turbulent seas of real-world biomedical data. The Student’s t-distribution
    provides a robust alternative to acknowledge that our data may be populated by
    extreme observations that are normal biological responses that we can expect in
    any context. There may be patients or animals that don’t respond or overreact
    to treatment, and it is valuable that our modeling approach recognizes these responses
    as part of the spectrum. Therefore, this tutorial explores the modeling strategies
    using Student’s t-distributions through the lens of the `**brms**` package for
    R ([*2*](#ref-brms))—a powerful ally for Bayesian modeling
  prefs: []
  type: TYPE_NORMAL
- en: What’s behind a student’s t-distribution?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A [Student’s t-distribution](https://mathworld.wolfram.com/Studentst-Distribution.html)
    is nothing more than a Gaussian distribution with heavier tails. In other words,
    we can say that the Gaussian distribution is a special case of the Student’s t-distribution.
    The Gaussian distribution is defined by the mean (μ) and the standard deviation
    (σ). The Student t distribution, on the other hand, adds an additional parameter,
    the degrees of freedom (df), which controls the “thickness” of the distribution.
    This parameter assigns greater probability to events further from the mean. This
    feature is particularly useful for small sample sizes, such as in biomedicine,
    where the assumption of normality is questionable. Note that as the degrees of
    freedom increase, the Student t-distribution approaches the Gaussian distribution.
    We can visualize this using density plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b033f2cc8f3e1543b3b8427615f45731.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Comparison of Gaussian and Student t-Distributions with different
    degrees of freedom.'
  prefs: []
  type: TYPE_NORMAL
- en: Note in [Figure 1](#fig-Fig1) that the hill around the mean gets smaller as
    the degrees of freedom decrease as a result of the probability mass going to the
    tails, which are thicker. This property is what gives the Student’s t-distribution
    a reduced sensitivity to outliers. For more details on this matter, you can check
    [this](https://online.stat.psu.edu/stat414/lesson/26/26.4) blog.
  prefs: []
  type: TYPE_NORMAL
- en: Load the required packages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We load the required libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Exploratory data visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, let’s skip data simulations and get serious. We’ll work with real data I
    have acquired from mice performing the rotarod test.
  prefs: []
  type: TYPE_NORMAL
- en: First, we load the dataset into our environment and set the corresponding factor
    levels. The dataset contains IDs for the animals, a groping variable (Genotype),
    an indicator for two different days on which the test was performed (day), and
    different trials for the same day. For this article, we model only one of the
    trials (Trial3). We will save the other trials for a future article on modeling
    variation.
  prefs: []
  type: TYPE_NORMAL
- en: As the data handling implies, our modeling strategy will be based on Genotype
    and Day as categorical predictors of the distribution of `Trial3`.
  prefs: []
  type: TYPE_NORMAL
- en: In biomedical science, categorical predictors, or grouping factors, are more
    common than continuous predictors. Scientists in this field like to divide their
    samples into groups or conditions and apply different treatments.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/33dfae9980cce2de5d4a4692da86d549.png)'
  prefs: []
  type: TYPE_IMG
- en: Data frame
  prefs: []
  type: TYPE_NORMAL
- en: Let’s have an initial view of the data using **Raincloud plots** as shown by
    [Guilherme A. Franchi, PhD](https://medium.com/u/3cca5ff4ed5d?source=post_page---user_mention--b6c584b91d5c--------------------------------)
    in [this](https://medium.com/@amorimfranchi/raincloud-plots-for-clear-precise-and-efficient-data-communication-4c71d0a37c23#:~:text=Raincloud%20plots%20for%20clear%2C%20precise%20and%20efficient%20data%20communication,-Guilherme%20A.&text=Raw%20data%20visualization%20involves%20presenting,quality%20assessment%20of%20your%20data.)
    great blog post.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/de2b062a13472328ee63bc1febd3e0b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Exploratory data visualization.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2](#fig-Fig2) looks different from the original by [Guilherme A. Franchi,
    PhD](https://medium.com/u/3cca5ff4ed5d?source=post_page---user_mention--b6c584b91d5c--------------------------------)
    because we are plotting two factors instead of one. However, the nature of the
    plot is the same. Pay attention to the red dots, these are the ones that can be
    considered extreme observations that tilt the measures of central tendency (especially
    the mean) toward one direction. We also observe that the variances are different,
    so modeling also sigma can give better estimates. Our task now is to model the
    output using the `brms` package.'
  prefs: []
  type: TYPE_NORMAL
- en: Fitting statistical models with brms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here we fit our model with `Day` and `Genotype` as interacting categorical predictors
    for the distribution of `Trial 3`. Let’s first fit a typical Gaussian model, which
    is analogous to an ordinary least squares (OLS) model from the frequentist framework,
    since we are using the default flat `brms` [priors](https://paul-buerkner.github.io/brms/reference/set_prior.html).
    Priors are beyond the scope of this article, but I promise we’ll cover them in
    a future blog.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have results from the Gaussian model, we can compare them to the large
    results from the Student’s t model. We then add`sigma` to the equation to account
    for the difference in the variance of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting a “typical” (frequentists) model in Gaussian land
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our Gaussian model is built under the typical (and often incorrect) assumption
    of homoscedasticity ([*3*](#ref-yang2019)). In other words, we assume that all
    groups have the same (or very similar) variance. I do not recall seeing this as
    a researcher.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Model diagnostics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before proceeding, it’s a good idea to do some simple model diagnostics to compare
    the actual observations with the predictions made by our model. We can do this
    in several ways, but the most common is to plot full densities. We can achieve
    this using the `pp_check` function from `brms`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/10b7786f4b7b43cd0f9e8f5563282a5f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Diagnostics for the Gaussian model'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3](#fig-GaussianDiag1) suggests that our observations (dark blue) are
    not meaningfully different from the model predictions. Below, I leave you with
    additional code to check other `pp_check` alternatives with their respective graphs.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Checking the results for the Gaussian distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we use the `describe_posterior` function from the `bayestestR` package
    ([*4*](#ref-bayestestR)) to see the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/375718185cf407d1addd0197e82d3368.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s focus here on the ‘intercept’, which is the value for WT at 1 DPI, and
    ‘GenotypeKO’, the estimated difference for KO animals at the same time point.
    We see that WT animals spend about 37 seconds in the rotarod, while their KO counterparts
    spend less than a second (0.54) more. As a researcher in this field, I can say
    that this difference is meaningless and that genotype has no effect on rotarod
    performance. Even the effect of day, which is 2.9, seems meaningless to me under
    this model. We can easily visualize these estimates using the wonderful `conditional_effects`
    function from brms.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e0f0c649cc2a815a598a96279b882d49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Conditional effects for the Gaussian model'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 8](#fig-GaussianEff) we can see the estimates and uncertainty for
    the interaction terms. I have customized the plot with a number of ggplot elements,
    which you can check in the original [Quarto Notebook](https://github.com/daniel-manrique/MediumBlog/blob/main/20240222_OutliersStudent-t.qmd).
    Note the similar uncertainty for both time points, even though the dispersion
    is larger on day 1 than on day 2\. We will address this point in a small snippet
    at the end of this article.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s see how much our understanding changes when we model the same data
    using a student-t distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fitting our guest: a model with a student-t distribution'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s time to use the student-t distribution in our `brms` model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Model diagnostics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We plot the model diagnostics as done before:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3dcaf9d4af3919790fa3ee9d281e48b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Model diagnostics for student-t distribution'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9](#fig-StudentDiag1) shows that the mean shape and the peak of the
    observations and the predictions match. It’s important to note that our model
    seems to predict values below 0\. This is an important research issue that we
    will skip for now. However, it does imply the use of informative priors or distribution
    families that set a lower bound at 0, such as the `log_normal'',`hurdle_lognormal’,
    or `zero_inflated_poisson’, depending on the case. Andrew Heiss ([*5*](#ref-heiss2021))
    offers a [great example](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/)
    in this regard.'
  prefs: []
  type: TYPE_NORMAL
- en: Checking the results for the student-t distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s take a look at the posterior distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/8ab1ec417192b14fbabdeae270a75572.png)'
  prefs: []
  type: TYPE_IMG
- en: Under this model, we can see that our estimates have changed moderately, I would
    say. Our estimate for the intercept (WT at 1 day) is reduced by 7 seconds. And
    why is that? Because the extreme values we discovered at the beginning have less
    influence on the measures of central tendency of the data. Thus, this is a more
    accurate measure of the “typical” WT animal on day 1\. We also observe a substantial
    increase in the effect of day, with almost 10 seconds more than our initial Gaussian
    estimates. Importantly, the effect of our KO genotype appears to be more notorious,
    increasing about 10 times from 0.52 in our Gaussian model to 5.5 in our student-t
    model. From my perspective, given the context of these data, the contrasts between
    the two models are notorious.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see it in graphical terms using `conditional_effects`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ad19138d3dffa2365ad138d3641aed65.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Conditional effects for the Student-t model'
  prefs: []
  type: TYPE_NORMAL
- en: Can we get better estimates? For this particular example, I think we can. From
    the start, it was easy to notice the difference in the variance of the data, especially
    when we compare the first and second-day visuals. We improved our estimates using
    the student-t distribution, and we can improve them further by developing a model
    for heteroscedasticity that predicts sigma (the residual variance).
  prefs: []
  type: TYPE_NORMAL
- en: In this way, the model does not assume that your residual variance is equal
    across your grouping variables, but it becomes a response that can be modeled
    by predictors.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is the little point we left for the end.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting sigma using a student-t distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We include sigma as a response variable using the`bf` function from `brms`.
    In this case, we are going to model this parameter using the same predictors `Day`
    and `Genotype`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Model diagnostics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/51c1140d256a0e6f98db9202a94037f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Model diagnostics for student-t distribution with sigma'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 11](#fig-StudentDiag2) looks good, except for the uncomfortable predictions
    below 0\. For this case, I judge that this does not strongly bias the estimates
    and their uncertainty. However, this is an aspect I will take into account when
    doing actual research.'
  prefs: []
  type: TYPE_NORMAL
- en: Checking the results for the student-t distribution with predicted sigma
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let’s take a look at the posterior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d6d22fa261f290155a4af992fc14c76.png)'
  prefs: []
  type: TYPE_IMG
- en: We see more parameters compared to the other two fitted models because the response
    for sigma is now included as a main effect in the model. Under this scheme, we
    see that the intercepts are closer to those of the Gaussian model and the effect
    of genotype (`GenotypeKO`) is reduced by half.
  prefs: []
  type: TYPE_NORMAL
- en: There is one aspect to note, however. In our first Student-t model, the uncertainty
    for the intercept was 24.1–37.4\. On the other hand, in the last model, the uncertainty
    increases to 24.3–46.1\. This means that when we consider the different variances,
    we are less certain of this (and other) parameters. The same is true for day,
    for example, which changes from 1.2–18.9 to -5.6–18.1\. In this case, we are now
    less certain that the second day is associated with an increase in time spent
    on the rotarod.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, the purpose of statistical modeling is to provide the best possible
    quantification of the uncertainty in a measurement, and that’s what we’re doing
    right now. Of course, our uncertainty increases when we have extreme values that
    are part of our sample and therefore part of our population.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this example, we see that accounting for the different variances in our data
    gives us a very different idea of our results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can see that sigma, plotted on the log scale, varies meaningfully
    with day and genotype:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1941426e2013a1539ee1a8da88ac2c56.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Conditional effects for the Student-t model with sigma'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f77b06a4fa8a838c0f16030ac55f20ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Conditional effects for sigma'
  prefs: []
  type: TYPE_NORMAL
- en: What we see in the second graph is sigma, which effectively accounts for the
    variance in this parameter between days and genotypes. We see a much higher uncertainty
    at day 1, especially for WT mice, while the parameter is analogous at day 2.
  prefs: []
  type: TYPE_NORMAL
- en: We can conclude this article by comparing the three models for out-of-sample
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Model comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We perform model comparisons using the WAIC criteria ([*6*](#ref-gelman2013))for
    estimating the out-of-sample prediction error. By considering both the log-likelihood
    of the observed data and the effective number of parameters, it provides a balance
    between model fit and complexity. Unlike some other criteria, WAIC inherently
    accounts for the posterior distribution of the parameters rather than relying
    on point estimates, making it particularly suited to Bayesian analyses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a data set and a Bayesian model, the WAIC is calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: WAIC=−2×(LLPD−*p*WAIC​)
  prefs: []
  type: TYPE_NORMAL
- en: 'Where: LLPD is the log pointwise predictive density, calculated as the average
    log-likelihood for each observed data point across the posterior samples. WAIC
    is the effective number of parameters, computed as the difference between the
    average of the log-likelihoods and the log-likelihood of the averages across posterior
    samples.'
  prefs: []
  type: TYPE_NORMAL
- en: We use the `compare_performance` function from the `performance` package, part
    of the `easystats` environment ([*4*](#ref-bayestestR), [*7*](#ref-performance),
    [*8*](#ref-makowski2019)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows that our Student-t model predicting sigma is the least penalized
    (WAIC = 497) for out-of-sample prediction. Note that there is no estimate for
    sigma in this model because it was included as a response variable. This table
    also shows that the student-t model has less residual variance (sigma) than the
    Gaussian model, which means that the variance is better explained by the predictors.
    We can visualize the same results as a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/71b63f75bbbc0c81ad01b17c21412573.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: Model comparison by WAIC'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 14](#fig-Models_Graph) shows that our last model is less penalized
    for out-of-sample prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: You can find an updated version of this post on my [GitHub site](https://github.com/daniel-manrique/MediumBlog/blob/main/20240222_OutliersStudent-t.qmd).
    Let me know if this journey was useful to you, and if you have any constructive
    comments to add to this exercise.
  prefs: []
  type: TYPE_NORMAL
- en: '*Unless otherwise noted, all images are generated by the author using R code.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1.M. Ahsanullah, B. M. G. Kibria, M. Shakil, *Normal and student´s t distributions
    and their applications* (Atlantis Press, 2014; [http://dx.doi.org/10.2991/978-94-6239-061-4](http://dx.doi.org/10.2991/978-94-6239-061-4)).
  prefs: []
  type: TYPE_NORMAL
- en: '2\. P.-C. Bürkner, Brms: An r package for bayesian multilevel models using
    stan. **80** (2017), doi:[10.18637/jss.v080.i01](https://doi.org/10.18637/jss.v080.i01).'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. K. Yang, J. Tu, T. Chen, [Homoscedasticity: an overlooked critical assumption
    for linear regression](https://doi.org/10.1136/gpsych-2019-100148). *General Psychiatry*.
    **32**, e100148 (2019).'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. D. Makowski, M. S. Ben-Shachar, D. Lüdecke, [bayestestR: Describing effects
    and their uncertainty, existence and significance within the bayesian framework.](https://doi.org/10.21105/joss.01541)
    **4**, 1541 (2019).'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. A. Heiss, A guide to modeling proportions with bayesian beta and zero-inflated
    beta regression models (2021), (available at [http://dx.doi.org/10.59350/7p1a4-0tw75](http://dx.doi.org/10.59350/7p1a4-0tw75)).
  prefs: []
  type: TYPE_NORMAL
- en: 6\. A. Gelman, J. Hwang, A. Vehtari, [Understanding predictive information criteria
    for Bayesian models](https://doi.org/10.1007/s11222-013-9416-2). *Statistics and
    Computing*. **24**, 997–1016 (2013).
  prefs: []
  type: TYPE_NORMAL
- en: '7\. D. Lüdecke, M. S. Ben-Shachar, I. Patil, P. Waggoner, D. Makowski, [Performance:
    An r package for assessment, comparison and testing of statistical models](https://doi.org/10.21105/joss.03139).
    **6**, 3139 (2021).'
  prefs: []
  type: TYPE_NORMAL
- en: '8\. D. Makowski, M. Ben-Shachar, D. Lüdecke, [bayestestR: Describing effects
    and their uncertainty, existence and significance within the bayesian framework](https://doi.org/10.21105/joss.01541).
    *Journal of Open Source Software*. **4**, 1541 (2019).'
  prefs: []
  type: TYPE_NORMAL
