["```py\nnp.random.seed(123)\n\nn = 10000 # Set number of observations\np = 4 # Set number of pre-experiment covariates\n\n# Create pre-experiment covariates\nX = np.random.uniform(size=n * p).reshape((n, -1))\n\n# Nuisance parameters\nb = (\n    1.5 * X[:, 0] +\n    2.5 * X[:, 1] +\n    X[:, 2] ** 3 +     \n    X[:, 3] ** 2 +\n    X[:, 1] * X[:, 2]  \n)\n\n# Create some noise\nnoise = np.random.normal(size=n)\n\n# Calculate outcome\ny = np.maximum(b + noise, 0)\n\n# Scale variables for interpretation\ndf_pre = pd.DataFrame({\"noise\": noise * 1000,\n                   \"u_income\": X[:, 0] * 1000,                   \n                   \"x_recency\": X[:, 1] * 1000,\n                   \"x_frequency\": X[:, 2] * 1000,\n                   \"x_value\": X[:, 3] * 1000,\n                   \"y_value\": y * 1000     \n})\n\n# Visualise target metric\nsns.histplot(df_pre['y_value'], bins=30, kde=False)\nplt.xlabel('Sales Value')\nplt.ylabel('Frequency')\nplt.title('Sales Value')\nplt.show()\n```", "```py\nfrom typing import Union\nimport pandas as pd\nimport numpy as np\nimport statsmodels.stats.power as smp\n\ndef power_analysis(metric: Union[np.ndarray, pd.Series], exp_perc_change: float, alpha: float = 0.05, power: float = 0.80) -> int:\n    '''\n    Perform a power analysis to determine the minimum sample size required for a given metric.\n\n    Args:\n        metric (np.ndarray or pd.Series): Array or Series containing the metric values for the control group.\n        exp_perc_change (float): The expected percentage change in the metric for the test group.\n        alpha (float, optional): The significance level for the test. Defaults to 0.05.\n        power (float, optional): The desired power of the test. Defaults to 0.80.\n\n    Returns:\n        int: The minimum sample size required for each group to detect the expected percentage change with the specified power and significance level.\n\n    Raises:\n        ValueError: If `metric` is not a NumPy array or pandas Series.\n    '''\n\n    # Validate input types\n    if not isinstance(metric, (np.ndarray, pd.Series)):\n        raise ValueError(\"metric should be a NumPy array or pandas Series.\")\n\n    # Calculate statistics\n    control_mean = metric.mean()\n    control_std = np.std(metric, ddof=1) # Use ddof=1 for sample standard deviation\n    test_mean = control_mean * (1 + exp_perc_change)\n    test_std = control_std # Assume the test group has the same standard deviation as the control group\n\n    # Calculate (Cohen's D) effect size\n    mean_diff = control_mean - test_mean\n    pooled_std = np.sqrt((control_std**2 + test_std**2) / 2)\n    effect_size = abs(mean_diff / pooled_std)  # Cohen's d should be positive\n\n    # Run power analysis\n    power_analysis = smp.TTestIndPower()\n    sample_size = round(power_analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power))\n\n    print(f\"Control mean: {round(control_mean, 3)}\")\n    print(f\"Control std: {round(control_std, 3)}\")\n    print(f\"Min sample size: {sample_size}\")\n\n    return sample_size\n```", "```py\nexp_perc_change = 0.05 # Set the expected percentage change in the chosen metric caused by the treatment\n\nmin_sample_size = power_analysis(df_pre[\"y_value\"], exp_perc_change\n```", "```py\ndef exp_data_generator(t_perc_change, t_samples):\n\n    # Create copy of pre-experiment data ready to manipulate into experiment data\n    df_exp = df_pre.reset_index(drop=True)\n\n    # Calculate the initial treatment effect\n    treatment_effect = round((df_exp[\"y_value\"] * (t_perc_change)).mean(), 2)\n\n    # Create treatment column\n    treated_indices = np.random.choice(df_exp.index, size=t_samples, replace=False)\n    df_exp[\"treatment\"] = 0\n    df_exp.loc[treated_indices, \"treatment\"] = 1\n\n    # treatment effect\n    df_exp[\"treatment_effect\"] = 0\n    df_exp.loc[df_exp[\"treatment\"] == 1, \"treatment_effect\"] = treatment_effect\n\n    # Apply treatment effect\n    df_exp[\"y_value_exp\"] = df_exp[\"y_value\"] \n    df_exp.loc[df_exp[\"treatment\"] == 1, \"y_value_exp\"] = df_exp[\"y_value\"] + df_exp[\"treatment_effect\"]\n\n    # Calculate mean diff before treatment\n    mean_t0_pre = df_exp[df_exp[\"treatment\"] == 0][\"y_value\"].mean()\n    mean_t1_pre = df_exp[df_exp[\"treatment\"] == 1][\"y_value\"].mean()\n    mean_diff_pre  = round(mean_t1_pre  - mean_t0_pre)\n\n    # Calculate mean diff after treatment\n    mean_t0_post = df_exp[df_exp[\"treatment\"] == 0][\"y_value_exp\"].mean()\n    mean_t1_post = df_exp[df_exp[\"treatment\"] == 1][\"y_value_exp\"].mean()\n    mean_diff_post  = round(mean_t1_post  - mean_t0_post)\n\n    # Calculate ate\n    treatment_effect = round(df_exp[df_exp[\"treatment\"]==1][\"treatment_effect\"].mean())\n\n    print(f\"Diff-in-means before treatment: {mean_diff_pre}\")\n    print(f\"Diff-in-means after treatment: {mean_diff_post}\")\n    print(f\"ATE: {treatment_effect}\")\n\n    return df_exp\n```", "```py\nnp.random.seed(123)\ndf_exp_1 = exp_data_generator(exp_perc_change, min_sample_size)\n```", "```py\nfrom typing import Union\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\ndef mean_diff(group_a: Union[np.ndarray, pd.Series], group_b: Union[np.ndarray, pd.Series]) -> float:\n    '''\n    Calculate the difference in means between two groups.\n\n    Args:\n        group_a (Union[np.ndarray, pd.Series]): The first group of data points.\n        group_b (Union[np.ndarray, pd.Series]): The second group of data points.\n\n    Returns:\n        float: The difference between the mean of group_a and the mean of group_b.\n    '''\n    return np.mean(group_a) - np.mean(group_b)\n\ndef bootstrapping(df: pd.DataFrame, adjusted_metric: str, n_resamples: int = 10000) -> np.ndarray:\n    '''\n    Perform bootstrap resampling on the adjusted metric of two groups in the dataframe to estimate the mean difference and confidence intervals.\n\n    Args:\n        df (pd.DataFrame): The dataframe containing the data. Must include a 'treatment' column indicating group membership.\n        adjusted_metric (str): The name of the column in the dataframe representing the metric to be resampled.\n        n_resamples (int, optional): The number of bootstrap resamples to perform. Defaults to 1000.\n\n    Returns:\n        np.ndarray: The array of bootstrap resampled mean differences.\n    '''\n\n    # Separate the data into two groups based on the 'treatment' column\n    group_a = df[df[\"treatment\"] == 1][adjusted_metric]\n    group_b = df[df[\"treatment\"] == 0][adjusted_metric]\n\n    # Perform bootstrap resampling\n    res = stats.bootstrap((group_a, group_b), statistic=mean_diff, n_resamples=n_resamples, method='percentile')\n    ci = res.confidence_interval\n\n    # Extract the bootstrap distribution and confidence intervals\n    bootstrap_means = res.bootstrap_distribution\n    bootstrap_ci_lb = round(ci.low,)\n    bootstrap_ci_ub = round(ci.high)    \n    bootstrap_mean = round(np.mean(bootstrap_means))\n\n    print(f\"Bootstrap confidence interval lower bound: {bootstrap_ci_lb}\")\n    print(f\"Bootstrap confidence interval upper bound: {bootstrap_ci_ub}\")    \n    print(f\"Bootstrap mean diff: {bootstrap_mean}\")\n\n    return bootstrap_means\n```", "```py\nbootstrap_og_1 = bootstrapping(df_exp_1, \"y_value_exp\")\n```", "```py\nfrom typing import Union\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndef cuped(df: pd.DataFrame, pre_covariates: Union[str, list], target_metric: str) -> pd.Series:\n    '''\n    Implements the CUPED (Controlled Experiments Using Pre-Experiment Data) technique to adjust the target metric \n    by removing predictable variation using pre-experiment covariates. This reduces the variance of the metric and \n    increases the statistical power of the experiment.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame containing both the pre-experiment covariates and the target metric. \n        pre_covariates (Union[str, list]): The column name(s) in the DataFrame corresponding to the pre-experiment covariates used for the adjustment. \n        target_metric (str): The column name in the DataFrame representing the metric to be adjusted.\n\n    Returns:\n        pd.Series: A pandas Series containing the CUPED-adjusted target metric.\n    '''\n\n    # Fit control model using pre-experiment covariates\n    control_group = df[df['treatment'] == 0]\n    X_control = control_group[pre_covariates]\n    X_control = sm.add_constant(X_control)\n    y_control = control_group[target_metric]\n    model_control = sm.OLS(y_control, X_control).fit()\n\n    # Compute residuals and adjust target metric\n    X_all = df[pre_covariates]\n    X_all = sm.add_constant(X_all)\n    residuals = df[target_metric].to_numpy().flatten() - model_control.predict(X_all)\n    adjustment_term = model_control.params['const'] + sum(model_control.params[covariate] * df[pre_covariates].mean()[covariate] for covariate in pre_covariates)\n    adjusted_target = residuals + adjustment_term\n\n    return adjusted_target\n```", "```py\n# Apply CUPED\npre_covariates = [\"x_recency\", \"x_frequency\", \"x_value\"]\ntarget_metric = [\"y_value_exp\"]\ndf_exp_1[\"adjusted_target\"] = cuped(df_exp_1, pre_covariates, target_metric)\n\n# Plot results\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df_exp_1[df_exp_1['treatment'] == 0], x=\"adjusted_target\", hue=\"treatment\", fill=True, palette=\"Set1\", label=\"Adjusted Value\")\nsns.kdeplot(data=df_exp_1[df_exp_1['treatment'] == 0], x=\"y_value_exp\", hue=\"treatment\", fill=True, palette=\"Set2\", label=\"Original Value\")\nplt.title(f\"Distribution of Value by Original vs CUPED\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Density\")\nplt.legend(title=\"Distribution\")\n```", "```py\nbootstrap_cuped_1 = bootstrapping(df_exp_1, \"adjusted_target\")\n```", "```py\nbootstrap_1 = pd.DataFrame({\n    'original': bootstrap_og_1,\n    'cuped': bootstrap_cuped_1\n})\n\n# Plot the KDE plots\nplt.figure(figsize=(10, 6))\nsns.kdeplot(bootstrap_1['original'], fill=True, label='Original', color='blue')\nsns.kdeplot(bootstrap_1['cuped'], fill=True, label='CUPED', color='orange')\n\n# Add mean lines\nplt.axvline(bootstrap_1['original'].mean(), color='blue', linestyle='--', linewidth=1)\nplt.axvline(bootstrap_1['cuped'].mean(), color='orange', linestyle='--', linewidth=1)\nplt.axvline(round(df_exp_1[df_exp_1[\"treatment\"]==1][\"treatment_effect\"].mean(), 3), color='green', linestyle='--', linewidth=1, label='Treatment effect')\n\n# Customize the plot\nplt.title('Distribution of Value by Original vs CUPED')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.legend()\n\n# Show the plot\nplt.show()\n```", "```py\ntreatment_effect_1 = round(df_exp_1[df_exp_1[\"treatment\"]==1][\"treatment_effect\"].mean(), 2)\ncuped_sample_size = power_analysis(df_exp_1[df_exp_1['treatment'] == 0]['adjusted_target'], treatment_effect_1 / df_exp_1[df_exp_1['treatment'] == 0]['adjusted_target'].mean())\n```", "```py\n# Train DML model\ndml = LinearDML(discrete_treatment=False)\ndml.fit(df_exp_1[target_metric].to_numpy().ravel(), T=df_exp_1['treatment'].to_numpy().ravel(), X=df_exp_1[pre_covariates], W=None)\nate_dml = round(dml.ate(df_exp_1[pre_covariates]))\nate_dml_lb = round(dml.ate_interval(df_exp_1[pre_covariates])[0])\nate_dml_ub = round(dml.ate_interval(df_exp_1[pre_covariates])[1])\n\nprint(f'DML confidence interval lower bound: {ate_dml_lb}')\nprint(f'DML confidence interval upper bound: {ate_dml_ub}')\nprint(f'DML ate: {ate_dml}')\n```", "```py\n# Fit model outcome model using pre-experiment covariates\nX_all = df_exp_1[pre_covariates]\nX_all = sm.add_constant(X)\ny_all = df_exp_1[target_metric]\noutcome_model = sm.OLS(y_all, X_all).fit()\n\n# Compute residuals and adjust target metric\ndf_exp_1['outcome_residuals'] = df_exp_1[target_metric].to_numpy().flatten() - outcome_model.predict(X_all)\n\n# Plot results\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df_exp_1[df_exp_1['treatment'] == 0], x=\"outcome_residuals\", hue=\"treatment\", fill=True, palette=\"Set1\", label=\"Adjusted Target\")\nsns.kdeplot(data=df_exp_1[df_exp_1['treatment'] == 0], x=\"y_value_exp\", hue=\"treatment\", fill=True, palette=\"Set2\", label=\"Original  Value\")\nplt.title(f\"Distribution of Value by Original vs DML\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Density\")\nplt.legend(title=\"Distribution\")\n\nplt.show()\n```"]