["```py\nCH_HOST = 'http://localhost:8123' # default address \nimport requests\n\ndef get_clickhouse_data(query, host = CH_HOST, connection_timeout = 1500):\n  r = requests.post(host, params = {'query': query}, \n    timeout = connection_timeout)\n  if r.status_code == 200:\n      return r.text\n  else: \n      return 'Database returned the following error:\\n' + r.text\n```", "```py\nfrom langchain_core.tools import tool\nfrom pydantic.v1 import BaseModel, Field\nfrom typing import Optional\n\nclass SQLQuery(BaseModel):\n  query: str = Field(description=\"SQL query to execute\")\n\n@tool(args_schema = SQLQuery)\ndef execute_sql(query: str) -> str:\n  \"\"\"Returns the result of SQL query execution\"\"\"\n  return get_clickhouse_data(query)\n```", "```py\nprint(f'''\nname: {execute_sql.name}\ndescription: {execute_sql.description}\narguments: {execute_sql.args}\n''')\n\n# name: execute_sql\n# description: Returns the result of SQL query execution\n# arguments: {'query': {'title': 'Query', 'description': \n#   'SQL query to execute', 'type': 'string'}}\n```", "```py\n# useful imports\nfrom langgraph.graph import StateGraph, END\nfrom typing import TypedDict, Annotated\nimport operator\nfrom langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n\n# defining agent state\nclass AgentState(TypedDict):\n   messages: Annotated[list[AnyMessage], operator.add]\n```", "```py\nclass SQLAgent:\n  # initialising the object\n  def __init__(self, model, tools, system_prompt = \"\"):\n    self.system_prompt = system_prompt\n\n    # initialising graph with a state \n    graph = StateGraph(AgentState)\n\n    # adding nodes \n    graph.add_node(\"llm\", self.call_llm)\n    graph.add_node(\"function\", self.execute_function)\n    graph.add_conditional_edges(\n        \"llm\",\n        self.exists_function_calling,\n        {True: \"function\", False: END}\n    )\n    graph.add_edge(\"function\", \"llm\")\n\n    # setting starting point\n    graph.set_entry_point(\"llm\")\n\n    self.graph = graph.compile()\n    self.tools = {t.name: t for t in tools}\n    self.model = model.bind_tools(tools)\n```", "```py\nclass SQLAgent:\n  <...>\n\n  def call_llm(self, state: AgentState):\n    messages = state['messages']\n    # adding system prompt if it's defined\n    if self.system_prompt:\n        messages = [SystemMessage(content=self.system_prompt)] + messages\n\n    # calling LLM\n    message = self.model.invoke(messages)\n\n    return {'messages': [message]}\n```", "```py\nclass SQLAgent:\n  <...>  \n\n  def execute_function(self, state: AgentState):\n    tool_calls = state['messages'][-1].tool_calls\n\n    results = []\n    for tool in tool_calls:\n      # checking whether tool name is correct\n      if not t['name'] in self.tools:\n      # returning error to the agent \n      result = \"Error: There's no such tool, please, try again\" \n      else:\n      # getting result from the tool\n      result = self.tools[t['name']].invoke(t['args'])\n\n      results.append(\n        ToolMessage(\n          tool_call_id=t['id'], \n          name=t['name'], \n          content=str(result)\n        )\n    )\n    return {'messages': results}\n```", "```py\nclass SQLAgent:\n  <...>  \n\n  def exists_function_calling(self, state: AgentState):\n    result = state['messages'][-1]\n    return len(result.tool_calls) > 0\n```", "```py\nimport os\n\n# setting up credentioals\nos.environ[\"OPENAI_MODEL_NAME\"]='gpt-4o-mini'  \nos.environ[\"OPENAI_API_KEY\"] = '<your_api_key>'\n\n# system prompt\nprompt = '''You are a senior expert in SQL and data analysis. \nSo, you can help the team to gather needed data to power their decisions. \nYou are very accurate and take into account all the nuances in data.\nYour goal is to provide the detailed documentation for the table in database \nthat will help users.'''\n\nmodel = ChatOpenAI(model=\"gpt-4o-mini\")\ndoc_agent = SQLAgent(model, [execute_sql], system=prompt)\n```", "```py\n! brew install graphviz\n! python3 -m pip install -U --no-cache-dir  \\\n    --config-settings=\"--global-option=build_ext\" \\\n    --config-settings=\"--global-option=-I$(brew --prefix graphviz)/include/\" \\\n    --config-settings=\"--global-option=-L$(brew --prefix graphviz)/lib/\" \\\n    pygraphviz\n```", "```py\nfrom IPython.display import Image\nImage(doc_agent.graph.get_graph().draw_png())\n```", "```py\nmessages = [HumanMessage(content=\"What info do we have in ecommerce_db.users table?\")]\nresult = doc_agent.graph.invoke({\"messages\": messages})\n```", "```py\nresult['messages']\n\n# [\n#   HumanMessage(content='What info do we have in ecommerce_db.users table?'), \n#   AIMessage(content='', tool_calls=[{'name': 'execute_sql', 'args': {'query': 'DESCRIBE ecommerce_db.users;'}, 'id': 'call_qZbDU9Coa2tMjUARcX36h0ax', 'type': 'tool_call'}]), \n#   ToolMessage(content='user_id\\tUInt64\\t\\t\\t\\t\\t\\ncountry\\tString\\t\\t\\t\\t\\t\\nis_active\\tUInt8\\t\\t\\t\\t\\t\\nage\\tUInt64\\t\\t\\t\\t\\t\\n', name='execute_sql', tool_call_id='call_qZbDU9Coa2tMjUARcX36h0ax'), \n#   AIMessage(content='The `ecommerce_db.users` table contains the following columns: <...>')\n# ]\n```", "```py\nprint(result['messages'][-1].content)\n\n# The `ecommerce_db.users` table contains the following columns:\n# 1\\. **user_id**: `UInt64` - A unique identifier for each user.\n# 2\\. **country**: `String` - The country where the user is located.\n# 3\\. **is_active**: `UInt8` - Indicates whether the user is active (1) or inactive (0).\n# 4\\. **age**: `UInt64` - The age of the user.\n```", "```py\nfrom langgraph.prebuilt import create_react_agent\nprebuilt_doc_agent = create_react_agent(model, [execute_sql],\n  state_modifier = system_prompt)\n```", "```py\nfrom langgraph.checkpoint.sqlite import SqliteSaver\nmemory = SqliteSaver.from_conn_string(\":memory:\")\n```", "```py\nprebuilt_doc_agent = create_react_agent(model, [execute_sql], \n  checkpointer=memory)\n```", "```py\nclass SQLAgent:\n  def __init__(self, model, tools, system_prompt = \"\"):\n    <...>\n    self.graph = graph.compile(checkpointer=memory)\n    <...>\n```", "```py\n # defining thread\nthread = {\"configurable\": {\"thread_id\": \"1\"}}\nmessages = [HumanMessage(content=\"What info do we have in ecommerce_db.users table?\")]\n\nfor event in prebuilt_doc_agent.stream({\"messages\": messages}, thread):\n    for v in event.values():\n        v['messages'][-1].pretty_print()\n\n# ================================== Ai Message ==================================\n# Tool Calls:\n#  execute_sql (call_YieWiChbFuOlxBg8G1jDJitR)\n#  Call ID: call_YieWiChbFuOlxBg8G1jDJitR\n#   Args:\n#     query: SELECT * FROM ecommerce_db.users LIMIT 1;\n# ================================= Tool Message =================================\n# Name: execute_sql\n# 1000001 United Kingdom 0 70\n# \n# ================================== Ai Message ==================================\n# \n# The `ecommerce_db.users` table contains at least the following information for users:\n# \n# - **User ID** (e.g., `1000001`)\n# - **Country** (e.g., `United Kingdom`)\n# - **Some numerical value** (e.g., `0`)\n# - **Another numerical value** (e.g., `70`)\n# \n# The specific meaning of the numerical values and additional columns \n# is not clear from the single row retrieved. Would you like more details \n# or a broader query?\n```", "```py\n followup_messages = [HumanMessage(content=\"I would like to know the column names and types. Maybe you could look it up in database using describe.\")]\n\nfor event in prebuilt_doc_agent.stream({\"messages\": followup_messages}, thread):\n    for v in event.values():\n        v['messages'][-1].pretty_print()\n\n# ================================== Ai Message ==================================\n# Tool Calls:\n#   execute_sql (call_sQKRWtG6aEB38rtOpZszxTVs)\n#  Call ID: call_sQKRWtG6aEB38rtOpZszxTVs\n#   Args:\n#     query: DESCRIBE ecommerce_db.users;\n# ================================= Tool Message =================================\n# Name: execute_sql\n# \n# user_id UInt64     \n# country String     \n# is_active UInt8     \n# age UInt64     \n# \n# ================================== Ai Message ==================================\n# \n# The `ecommerce_db.users` table has the following columns along with their data types:\n# \n# | Column Name | Data Type |\n# |-------------|-----------|\n# | user_id     | UInt64    |\n# | country     | String    |\n# | is_active   | UInt8     |\n# | age         | UInt64    |\n# \n# If you need further information or assistance, feel free to ask!\n```", "```py\nnew_thread = {\"configurable\": {\"thread_id\": \"42\"}}\nfollowup_messages = [HumanMessage(content=\"I would like to know the column names and types. Maybe you could look it up in database using describe.\")]\n\nfor event in prebuilt_doc_agent.stream({\"messages\": followup_messages}, new_thread):\n    for v in event.values():\n        v['messages'][-1].pretty_print()\n\n# ================================== Ai Message ==================================\n# Tool Calls:\n#   execute_sql (call_LrmsOGzzusaLEZLP9hGTBGgo)\n#  Call ID: call_LrmsOGzzusaLEZLP9hGTBGgo\n#   Args:\n#     query: DESCRIBE your_table_name;\n# ================================= Tool Message =================================\n# Name: execute_sql\n# \n# Database returned the following error:\n# Code: 60\\. DB::Exception: Table default.your_table_name does not exist. (UNKNOWN_TABLE) (version 23.12.1.414 (official build))\n# \n# ================================== Ai Message ==================================\n# \n# It seems that the table `your_table_name` does not exist in the database. \n# Could you please provide the actual name of the table you want to describe?\n```", "```py\nclass MultiAgentState(TypedDict):\n    question: str\n    question_type: str\n    answer: str\n    feedback: str\n```", "```py\nquestion_category_prompt = '''You are a senior specialist of analytical support. Your task is to classify the incoming questions. \nDepending on your answer, question will be routed to the right team, so your task is crucial for our team. \nThere are 3 possible question types: \n- DATABASE - questions related to our database (tables or fields)\n- LANGCHAIN- questions related to LangGraph or LangChain libraries\n- GENERAL - general questions\nReturn in the output only one word (DATABASE, LANGCHAIN or  GENERAL).\n'''\n\ndef router_node(state: MultiAgentState):\n  messages = [\n    SystemMessage(content=question_category_prompt), \n    HumanMessage(content=state['question'])\n  ]\n  model = ChatOpenAI(model=\"gpt-4o-mini\")\n  response = model.invoke(messages)\n  return {\"question_type\": response.content}\n```", "```py\nmemory = SqliteSaver.from_conn_string(\":memory:\")\n\nbuilder = StateGraph(MultiAgentState)\nbuilder.add_node(\"router\", router_node)\n\nbuilder.set_entry_point(\"router\")\nbuilder.add_edge('router', END)\n\ngraph = builder.compile(checkpointer=memory)\n```", "```py\nthread = {\"configurable\": {\"thread_id\": \"1\"}}\nfor s in graph.stream({\n    'question': \"Does LangChain support Ollama?\",\n}, thread):\n    print(s)\n\n# {'router': {'question_type': 'LANGCHAIN'}}\n\nthread = {\"configurable\": {\"thread_id\": \"2\"}}\nfor s in graph.stream({\n    'question': \"What info do we have in ecommerce_db.users table?\",\n}, thread):\n    print(s)\n# {'router': {'question_type': 'DATABASE'}}\n\nthread = {\"configurable\": {\"thread_id\": \"3\"}}\nfor s in graph.stream({\n    'question': \"How are you?\",\n}, thread):\n    print(s)\n\n# {'router': {'question_type': 'GENERAL'}}\n```", "```py\n# database expert\nsql_expert_system_prompt = '''\nYou are an expert in SQL, so you can help the team \nto gather needed data to power their decisions. \nYou are very accurate and take into account all the nuances in data. \nYou use SQL to get the data before answering the question.\n'''\n\ndef sql_expert_node(state: MultiAgentState):\n    model = ChatOpenAI(model=\"gpt-4o-mini\")\n    sql_agent = create_react_agent(model, [execute_sql],\n        state_modifier = sql_expert_system_prompt)\n    messages = [HumanMessage(content=state['question'])]\n    result = sql_agent.invoke({\"messages\": messages})\n    return {'answer': result['messages'][-1].content} \n```", "```py\n# search expert \nfrom langchain_community.tools.tavily_search import TavilySearchResults\nos.environ[\"TAVILY_API_KEY\"] = 'tvly-...'\ntavily_tool = TavilySearchResults(max_results=5)\n\nsearch_expert_system_prompt = '''\nYou are an expert in LangChain and other technologies. \nYour goal is to answer questions based on results provided by search.\nYou don't add anything yourself and provide only information baked by other sources. \n'''\n\ndef search_expert_node(state: MultiAgentState):\n    model = ChatOpenAI(model=\"gpt-4o-mini\")\n    sql_agent = create_react_agent(model, [tavily_tool],\n        state_modifier = search_expert_system_prompt)\n    messages = [HumanMessage(content=state['question'])]\n    result = sql_agent.invoke({\"messages\": messages})\n    return {'answer': result['messages'][-1].content}\n```", "```py\n# general model\ngeneral_prompt = '''You're a friendly assistant and your goal is to answer general questions.\nPlease, don't provide any unchecked information and just tell that you don't know if you don't have enough info.\n'''\n\ndef general_assistant_node(state: MultiAgentState):\n    messages = [\n        SystemMessage(content=general_prompt), \n        HumanMessage(content=state['question'])\n    ]\n    model = ChatOpenAI(model=\"gpt-4o-mini\")\n    response = model.invoke(messages)\n    return {\"answer\": response.content}\n```", "```py\ndef route_question(state: MultiAgentState):\n    return state['question_type']\n```", "```py\nbuilder = StateGraph(MultiAgentState)\nbuilder.add_node(\"router\", router_node)\nbuilder.add_node('database_expert', sql_expert_node)\nbuilder.add_node('langchain_expert', search_expert_node)\nbuilder.add_node('general_assistant', general_assistant_node)\nbuilder.add_conditional_edges(\n    \"router\", \n    route_question,\n    {'DATABASE': 'database_expert', \n     'LANGCHAIN': 'langchain_expert', \n     'GENERAL': 'general_assistant'}\n)\n\nbuilder.set_entry_point(\"router\")\nbuilder.add_edge('database_expert', END)\nbuilder.add_edge('langchain_expert', END)\nbuilder.add_edge('general_assistant', END)\ngraph = builder.compile(checkpointer=memory)\n```", "```py\nthread = {\"configurable\": {\"thread_id\": \"2\"}}\nresults = []\nfor s in graph.stream({\n  'question': \"What info do we have in ecommerce_db.users table?\",\n}, thread):\n  print(s)\n  results.append(s)\nprint(results[-1]['database_expert']['answer'])\n\n# The `ecommerce_db.users` table contains the following columns:\n# 1\\. **User ID**: A unique identifier for each user.\n# 2\\. **Country**: The country where the user is located.\n# 3\\. **Is Active**: A flag indicating whether the user is active (1 for active, 0 for inactive).\n# 4\\. **Age**: The age of the user.\n# Here are some sample entries from the table:\n# \n# | User ID | Country        | Is Active | Age |\n# |---------|----------------|-----------|-----|\n# | 1000001 | United Kingdom  | 0         | 70  |\n# | 1000002 | France         | 1         | 87  |\n# | 1000003 | France         | 1         | 88  |\n# | 1000004 | Germany        | 1         | 25  |\n# | 1000005 | Germany        | 1         | 48  |\n# \n# This gives an overview of the user data available in the table.\n```", "```py\n thread = {\"configurable\": {\"thread_id\": \"42\"}}\nresults = []\nfor s in graph.stream({\n    'question': \"Does LangChain support Ollama?\",\n}, thread):\n    print(s)\n    results.append(s)\n\nprint(results[-1]['langchain_expert']['answer'])\n\n# Yes, LangChain supports Ollama. Ollama allows you to run open-source \n# large language models, such as Llama 2, locally, and LangChain provides \n# a flexible framework for integrating these models into applications. \n# You can interact with models run by Ollama using LangChain, and there are \n# specific wrappers and tools available for this integration.\n# \n# For more detailed information, you can visit the following resources:\n# - [LangChain and Ollama Integration](https://js.langchain.com/v0.1/docs/integrations/llms/ollama/)\n# - [ChatOllama Documentation](https://js.langchain.com/v0.2/docs/integrations/chat/ollama/)\n# - [Medium Article on Ollama and LangChain](https://medium.com/@abonia/ollama-and-langchain-run-llms-locally-900931914a46)\n```", "```py\ndef human_feedback_node(state: MultiAgentState):\n    pass\n\neditor_prompt = '''You're an editor and your goal is to provide the final answer to the customer, taking into account the feedback. \nYou don't add any information on your own. You use friendly and professional tone.\nIn the output please provide the final answer to the customer without additional comments.\nHere's all the information you need.\n\nQuestion from customer: \n----\n{question}\n----\nDraft answer:\n----\n{answer}\n----\nFeedback: \n----\n{feedback}\n----\n'''\n\ndef editor_node(state: MultiAgentState):\n  messages = [\n    SystemMessage(content=editor_prompt.format(question = state['question'], answer = state['answer'], feedback = state['feedback']))\n  ]\n  model = ChatOpenAI(model=\"gpt-4o-mini\")\n  response = model.invoke(messages)\n  return {\"answer\": response.content} \n```", "```py\nbuilder = StateGraph(MultiAgentState)\nbuilder.add_node(\"router\", router_node)\nbuilder.add_node('database_expert', sql_expert_node)\nbuilder.add_node('langchain_expert', search_expert_node)\nbuilder.add_node('general_assistant', general_assistant_node)\nbuilder.add_node('human', human_feedback_node)\nbuilder.add_node('editor', editor_node)\n\nbuilder.add_conditional_edges(\n  \"router\", \n  route_question,\n  {'DATABASE': 'database_expert', \n  'LANGCHAIN': 'langchain_expert', \n  'GENERAL': 'general_assistant'}\n)\n\nbuilder.set_entry_point(\"router\")\n\nbuilder.add_edge('database_expert', 'human')\nbuilder.add_edge('langchain_expert', 'human')\nbuilder.add_edge('general_assistant', 'human')\nbuilder.add_edge('human', 'editor')\nbuilder.add_edge('editor', END)\ngraph = builder.compile(checkpointer=memory, interrupt_before = ['human'])\n```", "```py\nthread = {\"configurable\": {\"thread_id\": \"2\"}}\n\nfor event in graph.stream({\n    'question': \"What are the types of fields in ecommerce_db.users table?\",\n}, thread):\n    print(event)\n\n# {'question_type': 'DATABASE', 'question': 'What are the types of fields in ecommerce_db.users table?'}\n# {'router': {'question_type': 'DATABASE'}}\n# {'database_expert': {'answer': 'The `ecommerce_db.users` table has the following fields:\\n\\n1\\. **user_id**: UInt64\\n2\\. **country**: String\\n3\\. **is_active**: UInt8\\n4\\. **age**: UInt64'}}\n```", "```py\nuser_input = input(\"Do I need to change anything in the answer?\")\n# Do I need to change anything in the answer? \n# It looks wonderful. Could you only make it a bit friendlier please?\n\ngraph.update_state(thread, {\"feedback\": user_input}, as_node=\"human\")\n```", "```py\nprint(graph.get_state(thread).values['feedback'])\n# It looks wonderful. Could you only make it a bit friendlier please?\n\nprint(graph.get_state(thread).next)\n# ('editor',)\n```", "```py\nfor event in graph.stream(None, thread, stream_mode=\"values\"):\n  print(event)\n\nprint(event['answer'])\n\n# Hello! The `ecommerce_db.users` table has the following fields:\n# 1\\. **user_id**: UInt64\n# 2\\. **country**: String\n# 3\\. **is_active**: UInt8\n# 4\\. **age**: UInt64\n# Have a nice day!\n```", "```py\nfrom langchain_community.tools import HumanInputRun\nhuman_tool = HumanInputRun()\n\neditor_agent_prompt = '''You're an editor and your goal is to provide the final answer to the customer, taking into the initial question.\nIf you need any clarifications or need feedback, please, use human. Always reach out to human to get the feedback before final answer.\nYou don't add any information on your own. You use friendly and professional tone. \nIn the output please provide the final answer to the customer without additional comments.\nHere's all the information you need.\n\nQuestion from customer: \n----\n{question}\n----\nDraft answer:\n----\n{answer}\n----\n'''\n\nmodel = ChatOpenAI(model=\"gpt-4o-mini\")\neditor_agent = create_react_agent(model, [human_tool])\nmessages = [SystemMessage(content=editor_agent_prompt.format(question = state['question'], answer = state['answer']))]\neditor_result = editor_agent.invoke({\"messages\": messages})\n\n# Is the draft answer complete and accurate for the customer's question about the types of fields in the ecommerce_db.users table?\n# Yes, but could you please make it friendlier.\n\nprint(editor_result['messages'][-1].content)\n# The `ecommerce_db.users` table has the following fields:\n# 1\\. **user_id**: UInt64\n# 2\\. **country**: String\n# 3\\. **is_active**: UInt8\n# 4\\. **age**: UInt64\n# \n# If you have any more questions, feel free to ask!\n```", "```py\ndef editor_agent_node(state: MultiAgentState):\n  model = ChatOpenAI(model=\"gpt-4o-mini\")\n  editor_agent = create_react_agent(model, [human_tool])\n  messages = [SystemMessage(content=editor_agent_prompt.format(question = state['question'], answer = state['answer']))]\n  result = editor_agent.invoke({\"messages\": messages})\n  return {'answer': result['messages'][-1].content}\n\nbuilder = StateGraph(MultiAgentState)\nbuilder.add_node(\"router\", router_node)\nbuilder.add_node('database_expert', sql_expert_node)\nbuilder.add_node('langchain_expert', search_expert_node)\nbuilder.add_node('general_assistant', general_assistant_node)\nbuilder.add_node('editor', editor_agent_node)\n\nbuilder.add_conditional_edges(\n  \"router\", \n  route_question,\n  {'DATABASE': 'database_expert', \n   'LANGCHAIN': 'langchain_expert', \n    'GENERAL': 'general_assistant'}\n)\n\nbuilder.set_entry_point(\"router\")\n\nbuilder.add_edge('database_expert', 'editor')\nbuilder.add_edge('langchain_expert', 'editor')\nbuilder.add_edge('general_assistant', 'editor')\nbuilder.add_edge('editor', END)\n\ngraph = builder.compile(checkpointer=memory)\n\nthread = {\"configurable\": {\"thread_id\": \"42\"}}\nresults = []\n\nfor event in graph.stream({\n  'question': \"What are the types of fields in ecommerce_db.users table?\",\n}, thread):\n  print(event)\n  results.append(event)\n```"]