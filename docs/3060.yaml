- en: 'Advanced Prompt Engineering: Chain of Thought (CoT)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/advanced-prompt-engineering-chain-of-thought-cot-8d8b090bf699?source=collection_archive---------0-----------------------#2024-12-23](https://towardsdatascience.com/advanced-prompt-engineering-chain-of-thought-cot-8d8b090bf699?source=collection_archive---------0-----------------------#2024-12-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Working with Large Language Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Comparing different techniques for reasoning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@ilsilfverskiold?source=post_page---byline--8d8b090bf699--------------------------------)[![Ida
    Silfverskiöld](../Images/a2c0850bc0198688f70a5eca858cf8b5.png)](https://medium.com/@ilsilfverskiold?source=post_page---byline--8d8b090bf699--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8d8b090bf699--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8d8b090bf699--------------------------------)
    [Ida Silfverskiöld](https://medium.com/@ilsilfverskiold?source=post_page---byline--8d8b090bf699--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8d8b090bf699--------------------------------)
    ·20 min read·Dec 23, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ac39b3dac5c2c00c2dd3b8e1b3216a4.png)'
  prefs: []
  type: TYPE_IMG
- en: Reasoning techniques in some of its forms | Image by author
  prefs: []
  type: TYPE_NORMAL
- en: '*If you’re not a member but want to read this article, see this friend link*
    [*here.*](https://medium.com/@ilsilfverskiold/8d8b090bf699?sk=f6afe11542fb309fe1260863e63d4a26)'
  prefs: []
  type: TYPE_NORMAL
- en: Chain of Thought (CoT) has been around for quite some time and is technically
    a type of advanced prompt engineering, but it remains relevant even now, a few
    years after it was first introduced. CoT, in its various forms, is typically an
    effort to force large language models to reason.
  prefs: []
  type: TYPE_NORMAL
- en: After OpenAI’s preview of their model o1 was released this September, we saw
    the hype around CoT increase.
  prefs: []
  type: TYPE_NORMAL
- en: No one completely knows how o1 works (except for OpenAI, that is), whether it’s
    a combination system, what kind of data it has been fine-tuned with, if they are
    using reinforcement learning, or if there are several models working together.
  prefs: []
  type: TYPE_NORMAL
- en: '*Maybe one model does the planning, another the thinking, and a third rates.
    But we do know they are employing some type of step-by-step reasoning.*'
  prefs: []
  type: TYPE_NORMAL
- en: There has been quite a lot of open research around this that you might want
    to dig into. So for this piece, I will go through what’s out there so you know
    what you can use. Naturally I will test the different techniques to see how…
  prefs: []
  type: TYPE_NORMAL
