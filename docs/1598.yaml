- en: Data Engineering, Redefined
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/data-engineering-redefined-643249cbbadd?source=collection_archive---------1-----------------------#2024-06-28](https://towardsdatascience.com/data-engineering-redefined-643249cbbadd?source=collection_archive---------1-----------------------#2024-06-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How data engineering is practiced today and why we should redefine it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@bernd.wessely?source=post_page---byline--643249cbbadd--------------------------------)[![Bernd
    Wessely](../Images/e60e01c19412d8af8f8bddf78e561275.png)](https://medium.com/@bernd.wessely?source=post_page---byline--643249cbbadd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--643249cbbadd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--643249cbbadd--------------------------------)
    [Bernd Wessely](https://medium.com/@bernd.wessely?source=post_page---byline--643249cbbadd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--643249cbbadd--------------------------------)
    ·7 min read·Jun 28, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: What is the Problem with Data Engineering Today?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you search for a clear definition of what data engineering actually is, you’ll
    get so many different proposals that it leaves you with more questions than answers.
  prefs: []
  type: TYPE_NORMAL
- en: 'But as I want to explain what needs to be redefined, I’ll better use one of
    the more popular definitions that clearly represents the current state and mess
    we all face:'
  prefs: []
  type: TYPE_NORMAL
- en: Data engineering is the development, implementation, and maintenance of systems
    and processes that take in raw data and produce high-quality, consistent information
    that supports downstream use cases, such as analysis and machine learning. Data
    engineering is the intersection of security, data management, DataOps, data architecture,
    orchestration, and software engineering. A data engineer manages the data engineering
    lifecycle, beginning with getting data from source systems and ending with serving
    data for use cases, such as analysis or machine learning.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — Joe Reis and Matt Housley in “Fundamentals of Data Engineering”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: That is a fine definition and now, what is the mess?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the first sentence, where I highlight the important part that
    we should delve into:'
  prefs: []
  type: TYPE_NORMAL
- en: '***…take in raw data and produce high-quality, consistent information that
    supports downstream use cases…***'
  prefs: []
  type: TYPE_NORMAL
- en: Accordingly, data engineering takes raw data and ***transforms*** it to (produces)
    information that supports use cases. Only two examples are given, like analysis
    or machine learning, but I would assume that this includes all other potential
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: The ***data transformation*** is what drives me and all my fellow data engineers
    crazy. Data transformation is the monumental task of *applying the right logic*
    to raw data to transform it into information that enables all kinds of intelligent
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: To apply the right logic is actually the main task of *applications*. Applications
    are the systems that implement the logic that drives the business (use cases)
    — I continue to refer to it as an application and implicitly also mean services
    that are small enough to fit into the microservices architecture. The applications
    are usually built by application developers (software engineers if you like).
    But to meet our current definition of data engineering, the data engineers must
    now implement business logic. The whole mess starts with this wrong approach.
  prefs: []
  type: TYPE_NORMAL
- en: I have written an article about that topic, where I stress that [“Data Engineering
    **is** Software Engineering…”](https://medium.com/@bernd.wessely/data-engineering-is-software-engineering-a4c5df052492).
    Unfortunately, we already have millions of brittle data pipelines that have been
    implemented by data engineers. These pipelines sometimes — or regrettably, even
    oftentimes — do not have the same software quality that you would expect from
    an application. But the bigger problem is the fact that these pipelines often
    contain uncoordinated and therefore incorrect and sometimes even hidden business
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: However, the solution is not that all data engineers should now be turned into
    application developers. Data engineers still need to be qualified software engineers,
    but they should by no means turn into application developers. Instead, I advocate
    a redefinition of data engineering as “*all about the movement, manipulation,
    and management of data”*. This definition comes from the book “*What Is Data Engineering?
    by* Lewis Gavin *(O’Reilly, 2019)”.* However, and this is a clear difference to
    current practices, we should **limit manipulation to purely technical ones**.
  prefs: []
  type: TYPE_NORMAL
- en: We should no longer allow the development and use of business logic outside
    of applications.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To be very clear, data engineering should **not** implement business logic.
    The trend in modern application development is actually to keep stateless application
    logic separate from state management. We do not put application logic in the database
    and we do not put persistent state (or data) in the application. In the functional
    programming community they joke “We believe in the separation of church and state”.
    If you now think, “Where is the joke?”, then [this might help](https://en.wikipedia.org/wiki/Functional_programming).
    But now without any jokes: “We should believe in the separation of business logic
    and business data”. Accordingly, I believe we should explicitly leave data concerns
    to the data engineer and logic concerns to the application developer.'
  prefs: []
  type: TYPE_NORMAL
- en: What are “technical manipulations” that still are allowed for the data engineer,
    you might ask. I would define this as *any manipulation to data that does not
    change or add new business information*. We can still partition, bucket, reformat,
    normalize, index, technically aggregate, etc., but as soon as real business logic
    is necessary, we should address it to the application developers in the business
    domain responsible for the respective data set.
  prefs: []
  type: TYPE_NORMAL
- en: Why Data Engineering Got Sidetracked
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/5627991f57e82f1bd2fc7e6ee5bd1a17.png)'
  prefs: []
  type: TYPE_IMG
- en: The simple and obvious principle of separation of concerns – Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Why have we moved away from this simple and obvious principle?
  prefs: []
  type: TYPE_NORMAL
- en: I think this shift can be attributed to the rapid evolution of databases into
    multifunctional systems. Initially, databases served as simple, durable storage
    solutions for business data. They provided very helpful abstractions to offload
    functionality to persist data from the real business logic in the applications.
    However, vendors quickly enhanced these systems by embedding software development
    functionality in their database products to attract application developers. This
    integration transformed databases from mere data repositories into comprehensive
    platforms, incorporating sophisticated programming languages and tools for full-fledged
    software development. Consequently, databases evolved into powerful transformation
    engines, enabling data specialists to implement business logic outside traditional
    applications. The demand for this shift was further amplified by the advent of
    large-scale data warehouses, designed to consolidate scattered data storage —
    a problem that became more pronounced with the rise of microservices architecture.
    This technological progression made it practical and efficient to combine business
    logic with business data within the database.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, not all software engineers succumbed to the temptation of bundling
    their application logic within the database, preserving hope for a cleaner separation.
    As data continued to grow in volume and complexity, big data tools like Hadoop
    and its successors emerged, even replacing traditional databases in some areas.
    This shift presented an opportunity to move business logic out of the database
    and back to application developers. However, the notion that data engineering
    encompasses more than just data movement and management had already taken root.
    We had developed numerous tools to support business intelligence, advanced analytics,
    and complex transformation pipelines, allowing the implementation of sophisticated
    business logic.
  prefs: []
  type: TYPE_NORMAL
- en: These tools have become integral components of the modern data stack (MDS),
    establishing data engineering as its own discipline. The MDS comprises a comprehensive
    suit of tools for data mangling and transformation, but these tools remain largely
    unfamiliar to the typical application developer or software engineer. Despite
    the potential to [“turn the database inside out”](https://martin.kleppmann.com/2015/03/04/turning-the-database-inside-out.html)
    and relocate business logic back to the application layer, we failed to fully
    embrace this opportunity. The unfortunate practice of implementing business logic
    remains with data engineers to this day.
  prefs: []
  type: TYPE_NORMAL
- en: How Data Engineering Can be Redefined
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s more precisely define what “*all about the movement, manipulation, and
    management of data”* involves*.*
  prefs: []
  type: TYPE_NORMAL
- en: Data engineers can and should provide the most mature tools and platforms to
    be used by application developers to handle data. This is also the main idea with
    the [“self-serving data platform”](https://martinfowler.com/articles/data-monolith-to-mesh.html#DataAndSelf-servePlatformDesignConvergence)
    in the data mesh. However, the responsibility of defining and maintaining the
    business logic remains within the business domains. These people far better know
    the business and what business transformation logic should be applied to data.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, so what about these nice ideas like data warehouse systems and more general
    the overall [“data engineering lifecycle”](https://medium.com/towards-data-engineering/data-engineering-lifecycle-d1e7ee81632e)
    as defined by Joe Reis and Matt Housley?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2a71e249539fff492919a8553f05cf45.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Engineering Lifecycle cmpleted — Image by author based on Joe Reis’ and
    Matt Housley’s view
  prefs: []
  type: TYPE_NORMAL
- en: “Data pipelines” are really just agents between applications, but if business
    logic is to be implemented in the pipelines, these systems should be considered
    their own applications in the enterprise. Applications that should be maintained
    by application developers in the business domains and not by data engineers.
  prefs: []
  type: TYPE_NORMAL
- en: The nice and clear flow of data from source (“Generation” as they named it in
    their reference) to serving for consumers is actually idealistically reduced.
    The output from “Reverse ETL” is data that again serves as input for downstream
    applications. And not only “Reverse ETL” but also “Analytics” and “Machine Learning”
    create output to be consumed by analytical and operational downstream applications.
    The journey of data through the organization does not end with the training or
    application of an ML model or the creation of a business analysis. The results
    of these applications need to be further processed within the company and therefore
    be integrated into the overall business process flow (indicated by the blue boxes
    and arrows). This view blurs the rigid distinction still practiced between the
    operational and analytical planes, [the elimination of which I have described
    as a core target of data mesh](https://medium.com/towards-data-science/challenges-and-solutions-in-data-mesh-part-1-24cd45290805).
  prefs: []
  type: TYPE_NORMAL
- en: So what is the real task of the data engineer? We should evolve the enterprise
    architecture to enable application developers to take back the business logic
    into their applications, while allowing seamless exchange and sharing of data
    between these applications. Data engineers effectively build the “Data Infrastructure”
    and all the tooling that integrate business logic through a data mesh of interconnected
    business applications. This is by far more complicated than just providing a collection
    of different database types, a data warehouse or a data lake, whether on-premises
    or in the cloud. It comprises the implementation of tools and infrastructure,
    the definition and application of governance and data sharing principles (including
    modeling) that ultimately enables the **universal data supply** in the enterprise.
    However, the implementation of business logic should definitely be outside the
    scope of data engineering.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e12f43b1f42bcec87e2db35da6ef4776.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Infrastructure as the data engineers’ services to be used by all application
    developers — Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'This redefined data engineering practice is in line with the adapted data mesh
    approach that I proposed in this three-part series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/challenges-and-solutions-in-data-mesh-part-1-24cd45290805?source=post_page-----643249cbbadd--------------------------------)
    [## Challenges and Solutions in Data Mesh – Part 1'
  prefs: []
  type: TYPE_NORMAL
- en: Why the Data Mesh as defined by Zhamak Dehghani has its challenges and how these
    can be addressed.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/challenges-and-solutions-in-data-mesh-part-1-24cd45290805?source=post_page-----643249cbbadd--------------------------------)
    [](/challenges-and-solutions-in-data-mesh-part-2-7dfe97aa461a?source=post_page-----643249cbbadd--------------------------------)
    [## Challenges and Solutions in Data Mesh — Part 2
  prefs: []
  type: TYPE_NORMAL
- en: “Data as a Product” is a core principle in Data Mesh. Why the current definition
    needs adaptation to fully enable the…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/challenges-and-solutions-in-data-mesh-part-2-7dfe97aa461a?source=post_page-----643249cbbadd--------------------------------)
    [](/challenges-and-solutions-in-data-mesh-part-3-dacb917f3c91?source=post_page-----643249cbbadd--------------------------------)
    [## Challenges and Solutions in Data Mesh — Part 3
  prefs: []
  type: TYPE_NORMAL
- en: A practical approach to achieving interoperability in the data mesh through
    federated enterprise data modeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/challenges-and-solutions-in-data-mesh-part-3-dacb917f3c91?source=post_page-----643249cbbadd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
