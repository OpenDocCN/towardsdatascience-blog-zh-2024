- en: 'Scaling Monosemanticity: Anthropic’s One Step Towards Interpretable & Manipulable
    LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/scaling-monosemanticity-anthropics-one-step-towards-interpretable-manipulable-llms-4b9403c4341e?source=collection_archive---------7-----------------------#2024-05-28](https://towardsdatascience.com/scaling-monosemanticity-anthropics-one-step-towards-interpretable-manipulable-llms-4b9403c4341e?source=collection_archive---------7-----------------------#2024-05-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'GenAI Byte: A Byte a Day Keeps Imposter Syndrome Away'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From prompt engineering to activation engineering for more controllable and
    safer LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)[![Jack
    Chih-Hsu Lin](../Images/044c46619ba339417278ec485677c945.png)](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)
    [Jack Chih-Hsu Lin](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)
    ·11 min read·May 28, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Background/Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monosemanticity vs Polysemanticity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In neural networks (the algorithm type of LLMs inspired by human brains), the
    neurons are usually *polysemantic*, which means their activations respond to multiple
    meanings and concepts. On the other hand, if each neuron represents only one meaning/concept,
    they are *monosemantic.* For example, both phrases “I feel blue” and “I’m heavy-hearted”
    as the LLMs inputs only activate the same set of neurons that represent sadness
    or negative emotion. The sadness neurons are also not activated by other concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Feature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In machine learning, “features” refer to the measurable/observable properties
    used as inputs in the machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: To be noted, however, in this work “features*”* mean something different. “Features”
    refer to the high-dimensional layer outputs of the encoding layer in the sparse
    autoencoder trained to predict the LLM intermediate activations. (Check the Approaches/Methods
    section below to understand the details). At a high level, I interpret “features”
    as the…
  prefs: []
  type: TYPE_NORMAL
