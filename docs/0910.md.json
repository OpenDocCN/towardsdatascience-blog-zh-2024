["```py\n# defining samples\ncontrol_values = df[df.treatment == 0].time_spent_mins.values\nexp_values = df[df.treatment == 1].time_spent_mins.values\n\n# calculating p-values\nfrom scipy.stats import ttest_ind\n\nttest_ind(exp_values, control_values)\n# Output: TtestResult(statistic=-70.2769283935386, pvalue=0.0, df=89742.0)\n```", "```py\nfrom scipy import stats\nimport numpy as np\n\n# Calculate sample statistics\nmean1, mean2 = np.mean(exp_values), np.mean(control_values)\nstd1, std2 = np.std(exp_values, ddof=1), np.std(control_values, ddof=1)\nn1, n2 = len(exp_values), len(control_values)\npooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\ndegrees_of_freedom = n1 + n2 - 2\nconfidence_level = 0.95\n\n# Calculate margin of error\nmargin_of_error = stats.t.ppf((1 + confidence_level) / 2, degrees_of_freedom) * pooled_std * np.sqrt(1 / n1 + 1 / n2)\n\n# Calculate confidence interval\nmean_difference = mean1 - mean2\nconf_interval = (mean_difference - margin_of_error, \n    mean_difference + margin_of_error)\n\nprint(\"Confidence Interval:\", list(map(lambda x: round(x, 3), conf_interval)))\n# Output: Confidence Interval: [-1.918, -1.814]\n```", "```py\nimport statsmodels.formula.api as smf\nmodel = smf.ols('time_spent_mins ~ treatment', data=df).fit()\nmodel.summary().tables[1]\n```", "```py\nimport statsmodels.formula.api as smf\nmodel = smf.ols('time_spent_mins ~ treatment + complexity', data=df).fit()\nmodel.summary().tables[1]\n```", "```py\ntime_model = smf.ols('time_spent_mins ~ complexity', data=df).fit()\n\nprint('Initial variance: %.2f' % (df.time_spent_mins.var()))\nprint('Residual variance after accounting for complexity: %.2f' \\\n  % (time_model.resid.var()))\n\n# Output: \n# Initial variance: 16.63\n# Residual variance after accounting for complexity: 5.94\n```", "```py\nmodel = smf.ols('time_spent_mins ~ treatment * passed_training + complexity', \n    data=df).fit()\nmodel.summary().tables[1]\n```", "```py\nmodel = smf.ols('time_spent_mins ~ treatment * passed_training + complexity + tenure', data=df).fit()\nmodel.summary().tables[1]\n```", "```py\nmodel = smf.ols('time_spent_mins ~ treatment + complexity + tenure + cs_center', \n    data=df[df.treatment == df.passed_training]).fit()\nmodel.summary().tables[1]\n```", "```py\nmodel = smf.ols('time_spent_mins ~ treatment + complexity + tenure + within_sla', \n    data=df[df.treatment == df.passed_training]).fit()\nmodel.summary().tables[1]\n```", "```py\nagents_df = df.groupby(['agent_id', 'treatment', 'complexity', 'tenure', \n  'passed_training'], as_index = False).aggregate(\n    {'case_id': 'nunique', 'time_spent_mins': 'mean'}\n)\n```", "```py\n model = smf.ols('time_spent_mins ~ treatment + complexity + tenure', \n    data = agents_df[agents_df.treatment == agents_df.passed_training],\n    weights = agents_df[agents_df.treatment == agents_df.passed_training]['case_id'])\\\n    .fit()\nmodel.summary().tables[1]\n```", "```py\ndf = pd.read_csv('student-mat.csv', sep = ';')\nmodel = smf.ols('G3 ~ higher', data=df).fit()\nmodel.summary().tables[1]\n```", "```py\nmodel = smf.ols('G3 ~ higher + Medu + Fedu', data=df).fit()\nmodel.summary().tables[1]\n```"]