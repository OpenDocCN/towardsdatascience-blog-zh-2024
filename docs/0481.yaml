- en: End-to-End Machine Learning in Azure
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Azure 中的端到端机器学习
- en: 原文：[https://towardsdatascience.com/end-to-end-machine-learning-in-azure-1429528ecbe5?source=collection_archive---------3-----------------------#2024-02-20](https://towardsdatascience.com/end-to-end-machine-learning-in-azure-1429528ecbe5?source=collection_archive---------3-----------------------#2024-02-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/end-to-end-machine-learning-in-azure-1429528ecbe5?source=collection_archive---------3-----------------------#2024-02-20](https://towardsdatascience.com/end-to-end-machine-learning-in-azure-1429528ecbe5?source=collection_archive---------3-----------------------#2024-02-20)
- en: How to train and deploy a machine learning model in Azure
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何在 Azure 中训练和部署机器学习模型
- en: '[](https://medium.com/@jonathanbogerd?source=post_page---byline--1429528ecbe5--------------------------------)[![Jonathan
    Bogerd](../Images/e844961c6ea9766476d3d520dd993ae2.png)](https://medium.com/@jonathanbogerd?source=post_page---byline--1429528ecbe5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1429528ecbe5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1429528ecbe5--------------------------------)
    [Jonathan Bogerd](https://medium.com/@jonathanbogerd?source=post_page---byline--1429528ecbe5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jonathanbogerd?source=post_page---byline--1429528ecbe5--------------------------------)[![Jonathan
    Bogerd](../Images/e844961c6ea9766476d3d520dd993ae2.png)](https://medium.com/@jonathanbogerd?source=post_page---byline--1429528ecbe5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1429528ecbe5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1429528ecbe5--------------------------------)
    [Jonathan Bogerd](https://medium.com/@jonathanbogerd?source=post_page---byline--1429528ecbe5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1429528ecbe5--------------------------------)
    ·10 min read·Feb 20, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1429528ecbe5--------------------------------)
    ·10 分钟阅读·2024年2月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '**Introduction**'
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**介绍**'
- en: In this article, we will go through an end-to-end example of a machine learning
    use case in Azure. We will discuss how to transform the data such that we can
    use it to train a model using Azure Synapse Analytics. Then we will train a model
    in Azure Machine Learning and score some test data with it. The purpose of this
    article is to give you an overview of what techniques and tools you need in Azure
    to do this and to show exactly how you do this. In researching this article, I
    found many conflicting code snippets of which most are outdated and contain bugs.
    Therefore, I hope this article gives you a good overview of techniques and tooling
    and a set of code snippets that help you to quickly start your machine learning
    journey in Azure.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将通过一个端到端的示例来讲解如何在 Azure 中使用机器学习。我们将讨论如何转换数据，以便可以利用 Azure Synapse Analytics
    来训练模型。接着，我们将在 Azure Machine Learning 中训练一个模型，并用它对一些测试数据进行评分。本文的目的是给你一个关于在 Azure
    中实现这一过程所需的技术和工具的概览，并详细展示如何操作。在研究这篇文章时，我发现了许多冲突的代码片段，其中大多数是过时的并且包含错误。因此，我希望本文能为你提供一个良好的技术和工具概览，并附上一些帮助你快速开始
    Azure 机器学习之旅的代码片段。
- en: '![](../Images/6e71e88a1216c4c2de900afb5686dd31.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e71e88a1216c4c2de900afb5686dd31.png)'
- en: Photo by [Igor Omilaev](https://unsplash.com/@omilaev?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Igor Omilaev](https://unsplash.com/@omilaev?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '**Data and Objective**'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**数据和目标**'
- en: To build a Machine Learning example for this article, we need data. We will
    use a dataset I created on ice cream sales for every state in the US from 2017
    to 2022\. This dataset can be found [here](https://github.com/jonathanbogerd/icecreamdata).
    You are free to use it for your own machine learning test projects. The objective
    is to train a model to forecast the number of ice creams sold on a given day in
    a state. To achieve this goal, we will combine this dataset with population data
    from each state, sourced from [USAFacts](https://usafacts.org/data/topics/people-society/population-and-demographics/population-data/population/).
    It is shared under a Creative Commons license, which can be found [here](https://usafacts.org/faq/).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在本文中构建一个机器学习示例，我们需要数据。我们将使用我创建的一个关于2017年至2022年间美国各州冰淇淋销售的数据集。该数据集可以在[此处](https://github.com/jonathanbogerd/icecreamdata)找到。你可以自由地使用它进行自己的机器学习测试项目。我们的目标是训练一个模型，预测某一天某个州的冰淇淋销量。为了实现这一目标，我们将把这个数据集与每个州的人口数据结合起来，后者来自[USAFacts](https://usafacts.org/data/topics/people-society/population-and-demographics/population-data/population/)。它是以
    Creative Commons 许可证共享的，详细信息可以在[此处](https://usafacts.org/faq/)找到。
- en: To build a machine learning model, several data transformation steps are required.
    First, data formats need to be aligned and both data sets have to be combined.
    We will perform these steps in Azure Synapse Analytics in the next section. Then
    we will split the data into train and test data to train and evaluate the machine
    learning model.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个机器学习模型需要几个数据转换步骤。首先，数据格式需要对齐，且两个数据集必须合并。我们将在下一节中使用 Azure Synapse Analytics
    执行这些步骤。然后，我们将数据拆分为训练数据和测试数据，以训练和评估机器学习模型。
- en: '**Azure**'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Azure**'
- en: Microsoft Azure is a suite of cloud computing services offered by Microsoft
    to build and manage applications in the cloud. It includes many different services,
    including storage, computing, and analytics services. Specifically for machine
    learning, Azure provides a Machine Learning Service which we will use in this
    article. Next to that, Azure also contains Azure Synapse Analytics, a tool for
    data orchestration, storage, and transformation. Therefore, a typical machine
    learning workflow in Azure uses Synapse to retrieve, store, and transform data
    and to call the model for inference and uses Azure Machine Learning to train,
    save, and deploy machine learning models. This workflow will be demonstrated in
    this article.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 微软 Azure 是微软提供的一套云计算服务，用于构建和管理云中的应用程序。它包括许多不同的服务，包括存储、计算和分析服务。专门针对机器学习，Azure
    提供了一个机器学习服务，我们将在本文中使用它。此外，Azure 还包含 Azure Synapse Analytics，这是一个用于数据编排、存储和转换的工具。因此，Azure
    中典型的机器学习工作流使用 Synapse 来检索、存储和转换数据，并调用模型进行推理，同时使用 Azure 机器学习来训练、保存和部署机器学习模型。本文将演示这一工作流。
- en: '**Synapse**'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Synapse**'
- en: As already mentioned, Azure Synapse Analytics is a tool for data pipelines and
    storage. I assume you have already created a Synapse workspace and a Spark cluster.
    Details on how to do this can be found [here](https://learn.microsoft.com/en-us/azure/synapse-analytics/get-started-create-workspace).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Azure Synapse Analytics 是用于数据管道和存储的工具。我假设你已经创建了一个 Synapse 工作区和一个 Spark
    集群。有关如何操作的详细信息，请参考[此处](https://learn.microsoft.com/en-us/azure/synapse-analytics/get-started-create-workspace)。
- en: Before making any transformation on the data, we first have to upload it to
    the storage account of Azure Synapse. Then, we create integration datasets for
    both source datasets. Integration datasets are references to your dataset and
    can be used in other activities. Let’s also create two integration datasets for
    the data when the transformations are done, such that we can use them as storage
    locations after transforming the data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在对数据进行任何转换之前，我们首先必须将数据上传到 Azure Synapse 的存储账户中。然后，我们为两个源数据集创建集成数据集。集成数据集是对你的数据集的引用，可以在其他活动中使用。我们还将为数据转换完成后创建两个集成数据集，以便在转换数据后将其用作存储位置。
- en: 'Now we can start transforming the data. We will use two steps for this: The
    first step is to clean both datasets and save the cleaned versions, and the second
    step is to combine both datasets into one. This setup follows the standard bronze,
    silver, and gold procedure.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始转换数据了。我们将使用两个步骤：第一步是清理两个数据集并保存清理后的版本，第二步是将两个数据集合并成一个。这一过程遵循标准的青铜、白银和黄金流程。
- en: '**Data Flow**'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**数据流**'
- en: For the first step, we will use Azure Data Flow. Data Flow is a no-code option
    for data transformations in Synapse. You can find it under the Develop tab. There,
    create a data flow Icecream with the source integration dataset of the ice cream
    data as a source and the sink integration data set as a sink. The only transformation
    we will do here is to create the date column with the standard toDate function.
    This casts the date to the correct format. In the sink data set, you can also
    rename columns under the mapping tab.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，我们将使用 Azure Data Flow。Data Flow 是 Synapse 中用于数据转换的无代码选项。你可以在“开发”标签下找到它。在这里，创建一个名为
    Icecream 的数据流，使用冰淇淋数据作为源集成数据集，使用汇总集成数据集作为汇集。我们在这里做的唯一转换是使用标准的 toDate 函数创建日期列。这样会将日期转换为正确的格式。在汇总数据集中，你还可以在映射标签下重命名列。
- en: For the population data set, we will rename some columns and unpivot the columns.
    Note that you can do all this without writing code, making it an easy solution
    for quick data transformation and cleaning.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于人口数据集，我们将重命名一些列并进行列的反透视操作。请注意，你可以在不编写代码的情况下完成所有这些操作，从而使其成为快速数据转换和清洗的简单解决方案。
- en: '**Spark**'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Spark**'
- en: 'Now, we will use a Spark notebook to join the two datasets and save the result
    to be used by Azure Machine Learning. Notebooks can be used in several programming
    languages, all use the Spark API. In this example, we will use PySpark, the Python
    API for Spark as it is complete. After reading the file, we join the population
    data per year on the ice creamdata, split it into a train and test data set, and
    write the result to our storage account. The details can be found in the script
    below:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用 Spark Notebook 来联接这两个数据集，并将结果保存供 Azure 机器学习使用。Notebook 可以使用多种编程语言，所有语言都使用
    Spark API。在本示例中，我们将使用 PySpark，这是 Spark 的 Python API，因为它功能完整。读取文件后，我们将按年份将人口数据与冰淇淋数据合并，拆分为训练集和测试集，并将结果写入我们的存储帐户。详细信息可以在以下脚本中找到：
- en: Note that for using AutoML in Machine Learning, it is required to save the data
    sets as mltable format instead of parquet files. To do this, you can convert the
    parquets using the provided code snippet. You might need to authenticate with
    your Microsoft account in order to run this.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用 AutoML 进行机器学习时，数据集需要保存为 mltable 格式，而不是 parquet 文件。为此，你可以使用提供的代码片段将 parquet
    文件转换为 mltable 格式。你可能需要使用你的 Microsoft 帐户进行身份验证，以便运行此操作。
- en: '**Pipelines**'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**管道**'
- en: 'Now that we have created all activities, we have to create a pipeline to run
    these activities. Pipelines in Synapse are used to execute activities in a specified
    order and trigger. This makes it possible to retrieve data for instance daily
    or to retrain your model automatically every month. Let’s create a pipeline with
    three activities, two dataflow activities, and a Notebook activity. The result
    should be something similar to this:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了所有活动，我们需要创建一个管道来运行这些活动。Synapse 中的管道用于按指定顺序和触发器执行活动。这样，你可以例如每天定时获取数据，或每月自动重新训练模型。让我们创建一个包含三项活动的管道，其中有两项数据流活动和一项
    Notebook 活动。结果应该类似于下面所示：
- en: '![](../Images/ae8f1e10c440d137b9315c94526ed5e3.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ae8f1e10c440d137b9315c94526ed5e3.png)'
- en: Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '**Machine Learning**'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**机器学习**'
- en: Azure Machine Learning (AML) is a tool that enables the training, testing, and
    deploying of machine learning models. The tool has a UI in which you can run machine
    learning workloads without programming. However, it is often more convenient to
    build and train models using the Python SDK (v2). It allows for more control and
    allows you to work in your favorite programming environment. So, let’s first install
    all packages required to do this. You can simply pip install this requirements.txt
    file to follow along with this example. Note that we will use lightgbm to create
    a model. You do not need this package if you are going to use a different model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习（AML）是一个工具，能够进行机器学习模型的训练、测试和部署。该工具提供了一个界面，你可以在其中运行机器学习任务，而无需编程。然而，通常使用
    Python SDK（v2）来构建和训练模型更为方便。它提供了更多控制，并允许你在喜欢的编程环境中工作。因此，我们首先需要安装所有必需的包。你可以简单地通过
    pip 安装这个 requirements.txt 文件，以便跟随本示例进行操作。请注意，我们将使用 lightgbm 创建一个模型。如果你打算使用不同的模型，则不需要这个包。
- en: Now let’s start using the Python SDK to train a model. First, we have to authenticate
    to Azure Machine Learning using either the default or interactive credential class
    to get an MLClient. This will lazily authenticate to AML, whenever you need access
    to it.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始使用 Python SDK 来训练模型。首先，我们需要通过默认或交互式凭证类进行身份验证，以获取 MLClient。每当你需要访问时，它会延迟进行
    AML 身份验证。
- en: '**Compute**'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**计算**'
- en: 'The next step is to create a compute, something to run the actual workload.
    AML has several types of compute you can use. Compute instances are well suited
    as a development environment or for training runs. Compute clusters are for larger
    training runs or inference. We will create both a compute instance and a compute
    cluster in this article: the first for training, and the second for inferencing.
    The code to create a compute instance can be found below, the compute cluster
    will be created when we deploy a model to an endpoint.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个计算资源，用于实际运行工作负载。AML 提供了几种类型的计算资源可以使用。计算实例非常适合作为开发环境或用于训练任务。计算集群则适用于更大的训练任务或推理任务。在本文中，我们将创建一个计算实例和一个计算集群：第一个用于训练，第二个用于推理。创建计算实例的代码可以在下面找到，计算集群将在我们将模型部署到端点时创建。
- en: It is also possible to use external clusters from for instance Databricks or
    Synapse. However, currently, Spark clusters from Synapse do not run a supported
    version for Azure Machine Learning. More information on clusters can be found
    [here](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target?view=azureml-api-2).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用外部集群，例如 Databricks 或 Synapse。但是，目前来自 Synapse 的 Spark 集群不支持运行适用于 Azure 机器学习的版本。有关集群的更多信息，请访问[这里](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target?view=azureml-api-2)。
- en: '**Environment**'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**环境**'
- en: Training Machine Learning models on different machines can be challenging if
    you do not have a proper environment setup to run them. It is easy to miss a few
    dependencies or have slightly different versions. To solve this, AML uses the
    concept of a Environment, a Docker-backed Python environment to run your workloads.
    You can use existing Environments or create your own by selecting a Docker base
    image (or creating one yourself) and adding a conda.yaml file with all dependencies.
    For this article, we will create our environment from a Microsoft base image.
    The conda.yaml file and code to create an environment are provided.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同机器上训练机器学习模型可能会很具挑战性，特别是当您没有正确的环境设置来运行它们时。很容易漏掉一些依赖项或使用略有不同的版本。为了解决这个问题，AML
    使用了环境的概念，即一个基于 Docker 的 Python 环境来运行您的工作负载。您可以使用现有的环境，或通过选择一个 Docker 基础镜像（或者自己创建一个）并添加一个包含所有依赖项的
    `conda.yaml` 文件来创建自己的环境。对于本文，我们将从微软基础镜像创建环境。`conda.yaml` 文件和创建环境的代码已经提供。
- en: Do not forget to include the azureml-inference-server-http package. You do not
    need it to train a model, however it is required for inferencing. If you forget
    it now, you will get errors during scoring and you have to start from here again.
    In the AML UI, you can inspect the progress and the underlying Docker image. Environments
    are also versioned, such that you can always revert to the previous version if
    required.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记包含 `azureml-inference-server-http` 包。虽然在训练模型时不需要它，但进行推理时是必需的。如果现在忘记它，您将在评分时遇到错误，必须从这里重新开始。在
    AML 用户界面中，您可以检查进度和底层的 Docker 镜像。环境也有版本控制，因此如果需要，您始终可以恢复到之前的版本。
- en: '**Data**'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**数据**'
- en: 'Now that we have an environment to run our machine learning workload, we need
    access to our dataset. In AML there are several ways to add data to the training
    run. We will use the option to register our training dataset before using it to
    train a model. In this way, we again have versioning of our data. Doing this is
    quite straightforward by using the following script:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个可以运行机器学习工作负载的环境，接下来我们需要访问我们的数据集。在 AML 中，有多种方法可以将数据添加到训练任务中。我们将使用在训练模型之前注册训练数据集的方法。通过这种方式，我们的数据也可以进行版本控制。使用以下脚本可以非常简单地实现这一点：
- en: '**Training**'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**训练**'
- en: 'Finally, we can start building the training script for our lightgbm model.
    In AML, this training script runs in a command with all the required parameters.
    So, let’s set up the structure of this training script first. We will use MLFlow
    for logging, saving and packaging of the model. The main advantage of using MLFlow,
    is that all dependencies will be packaged in the model file. Therefore, when deploying,
    we do not need to specify any dependencies as they are part of the model. Following
    an example script for an MLFlow model provided by Microsoft, this is the basic
    structure of a training script:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以开始构建我们 lightgbm 模型的训练脚本。在 AML 中，训练脚本在命令中运行，包含所有必需的参数。因此，让我们首先设置这个训练脚本的结构。我们将使用
    MLFlow 来记录、保存和打包模型。使用 MLFlow 的主要优点是，所有的依赖项都会打包在模型文件中。因此，在部署时，我们不需要指定任何依赖项，因为它们已经是模型的一部分。以下是根据微软提供的
    MLFlow 模型示例脚本，训练脚本的基本结构：
- en: 'Filling in this template, we start with adding the parameters of the lightgbm
    model. This includes the number of leaves and the number of iterations and we
    parse them in the parse_args method. Then we will read the provided parquet file
    in the data set that we registered above. For this example, we will drop the date
    and state columns, although you can use them to improve your model. Then we will
    create and train the model using a part of the data as our validation set. In
    the end, we save the model such that we can use it later to deploy it in AML.
    The full script can be found below:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 填写这个模板时，我们首先添加 lightgbm 模型的参数。这包括叶子数和迭代次数，我们在 `parse_args` 方法中解析这些参数。然后，我们会读取之前注册的数据集中的提供的
    parquet 文件。在这个示例中，我们会去掉日期和状态列，尽管你可以利用这些列来改进模型。接着，我们将使用部分数据作为验证集来创建并训练模型。最后，我们保存模型，以便后续在
    AML 中进行部署。完整的脚本如下：
- en: Now we have to upload this script to AML together with the dataset reference,
    environment, and the compute to use. In AML, this is done by creating a command
    with all these components and sending it to AML.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须将这个脚本与数据集引用、环境以及计算资源一起上传到 AML。在 AML 中，这是通过创建一个包含所有这些组件的命令并将其发送到 AML 来完成的。
- en: This will yield a URL to the training job. You can follow the status of training
    and the logging in the AML UI. Note that the cluster will not always start on
    its own. This at least happened to me sometimes. In that case, you can just manually
    start the compute instance via the UI. Training this model will take roughly a
    minute.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个指向训练作业的 URL。你可以在 AML 用户界面中跟踪训练状态和日志。请注意，集群并不会总是自动启动。至少有时我遇到过这种情况。在这种情况下，你可以通过用户界面手动启动计算实例。训练这个模型大约需要一分钟。
- en: '**Endpoints**'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**端点**'
- en: 'To use the model, we first need to create an endpoint for it. AML has two different
    types of endpoints. One, called an online endpoint is used for real-time inferencing.
    The other type is a batch endpoint, used for scoring batches of data. In this
    article, we will deploy the same model both to an online and a batch endpoint.
    To do this, we first need to create the endpoints. The code for creating an online
    endpoint is quite simple. This yields the following code for creating the endpoint:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用模型，我们首先需要为它创建一个端点。AML 有两种不同类型的端点。一种是在线端点，用于实时推理。另一种是批处理端点，用于批量评分数据。在本文中，我们将同一个模型部署到在线端点和批处理端点。为此，我们首先需要创建端点。创建在线端点的代码非常简单。它会生成以下用于创建端点的代码：
- en: 'We only need a small change to create the batch endpoint:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要做一个小的改动，就可以创建批处理端点：
- en: '**Deployment**'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**部署**'
- en: 'Now that we have an endpoint, we need to deploy the model to this endpoint.
    Because we created an MLFlow model, the deployment is easier, because all requirements
    are packaged inside the model. The model needs to run on a compute cluster, we
    can create one while deploying the model to the endpoint. Deploying the model
    to the online endpoint will take roughly ten minutes. After the deployment, all
    traffic needs to be pointed to this deployment. This is done in the last lines
    of this code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了端点，需要将模型部署到这个端点。因为我们创建了一个 MLFlow 模型，所以部署比较简单，因为所有的要求都已经打包在模型内部。模型需要在计算集群上运行，我们可以在将模型部署到端点时创建一个。将模型部署到在线端点大约需要十分钟。部署完成后，所有的流量需要指向这个部署。这可以通过代码中的最后几行来完成：
- en: To deploy the same model to the batch endpoint, we first need to create a compute
    target. This target is then used to run the model on. Next, we create a deployment
    with deployment settings. In these settings, you can specify the batch size, concurrency
    settings, and the location for the output. After you have specified this, the
    steps are similar to deployment to an online endpoint.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将相同的模型部署到批处理端点，我们首先需要创建一个计算目标。这个目标将用于运行模型。接下来，我们创建一个包含部署设置的部署。在这些设置中，你可以指定批处理大小、并发设置以及输出的存储位置。指定好这些后，步骤与部署到在线端点类似。
- en: '**Scoring with the Online Endpoint**'
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**使用在线端点进行评分**'
- en: Everything is now ready to use our model via the endpoints. Let’s first consume
    the model from the online endpoint. AML provides a sample scoring script that
    you can find in the endpoint section. However, creating the right format for the
    sample data can be slightly frustrating. The data needs to be sent in a nested
    JSON with the column indices, the indices of the sample, and the actual data.
    You can find a quick and dirty approach to do this in the example below. After
    you encode the data, you have to send it to the URL of the endpoint with the API
    key. You can find both in the endpoint menu. Note that you should **never** save
    the API key of your endpoint in your code. Azure provides a Key vault to save
    secrets. You can then reference the secret in your code to avoid saving it there
    directly. For more information see this link to the [Microsoft documentation](https://learn.microsoft.com/en-us/azure/key-vault/general/overview).
    The result variable will contain the predictions of your model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一切都准备好通过端点使用我们的模型了。首先，让我们通过在线端点调用模型。AML 提供了一个示例评分脚本，你可以在端点部分找到它。然而，为示例数据创建正确的格式可能会有些让人沮丧。数据需要以嵌套
    JSON 的形式发送，其中包括列索引、样本索引和实际数据。你可以在下面的示例中找到一种快速但粗略的方法。在编码数据之后，你需要将其发送到端点的 URL，并附上
    API 密钥。你可以在端点菜单中找到这两个信息。请注意，**绝不要**将你的端点 API 密钥保存在代码中。Azure 提供了一个密钥保管库来保存机密信息。你可以在代码中引用该密钥，而不是直接保存它。欲了解更多信息，请参阅
    [Microsoft 文档](https://learn.microsoft.com/en-us/azure/key-vault/general/overview)。结果变量将包含模型的预测结果。
- en: '**Scoring with the Batch Endpoint**'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**通过批量端点评分**'
- en: Scoring data via the batch endpoint works a bit differently. Typically, it involves
    more data, therefore it can be useful to register a dataset for this in AML. We
    have done this before in this article for the training data. We will then create
    a scoring job with all the information and send this to our endpoint. During scoring,
    we can review the progress of the job and poll for instance its status. After
    the job is completed, we can download the results from the output location that
    we specified when creating the batch endpoint. In this case, we saved the results
    in a CSV file.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过批量端点进行评分的方式稍有不同。通常，这涉及到更多数据，因此在 AML 中注册一个数据集可能会很有用。我们之前在本文中做过一次，针对训练数据。接下来，我们将创建一个评分任务，包含所有信息，并将其发送到我们的端点。在评分过程中，我们可以查看任务的进度，并轮询例如其状态。任务完成后，我们可以从创建批量端点时指定的输出位置下载结果。在此案例中，我们将结果保存在
    CSV 文件中。
- en: Although we scored the data and received the output locally, we can run the
    same code in Azure Synapse Analytics to score the data from there. However, in
    most cases, I find it easier to first test everything locally before running it
    in Synapse.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经在本地对数据进行了评分并得到了输出，但我们也可以在 Azure Synapse Analytics 中运行相同的代码，直接从那里进行评分。然而，在大多数情况下，我发现先在本地测试一切再在
    Synapse 中运行会更容易。
- en: '**Conclusion**'
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论**'
- en: We have reached the end of this article. To summarize, we imported data in Azure
    using Azure Synapse Analytics, transformed it using Synapse, and trained and deployed
    a machine learning model with this data in Azure Machine Learning. Last, we scored
    a dataset with both endpoints. I hope this article helped create an understanding
    of how to use Machine Learning in Azure. If you followed along, do not forget
    to delete endpoints, container registries and other resources you have created
    to avoid incurring costs for them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 本文已接近尾声。总结一下，我们在 Azure 中使用 Azure Synapse Analytics 导入数据，利用 Synapse 对其进行转换，然后在
    Azure Machine Learning 中使用这些数据训练并部署机器学习模型。最后，我们用两个端点对数据集进行了评分。希望本文有助于你理解如何在 Azure
    中使用机器学习。如果你跟着本文操作，请不要忘记删除你创建的端点、容器注册表和其他资源，以避免产生额外费用。
- en: '**Sources**'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**来源**'
- en: '[](https://usafacts.org/data/topics/people-society/population-and-demographics/population-data/population/?source=post_page-----1429528ecbe5--------------------------------)
    [## US population over time'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://usafacts.org/data/topics/people-society/population-and-demographics/population-data/population/?source=post_page-----1429528ecbe5--------------------------------)
    [## 美国人口变化'
- en: Explore government data on the demographics of the US population year over year.
    Download the data or use our…
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索美国人口的政府数据，了解其年度变化。下载数据或使用我们的…
- en: usafacts.org](https://usafacts.org/data/topics/people-society/population-and-demographics/population-data/population/?source=post_page-----1429528ecbe5--------------------------------)
    [](https://github.com/Azure/azureml-examples/blob/main/sdk/python/endpoints/batch/deploy-models/heart-classifier-mlflow/mlflow-for-batch-tabular.ipynb?source=post_page-----1429528ecbe5--------------------------------)
    [## azureml-examples/sdk/python/endpoints/batch/deploy-models/heart-classifier-mlflow/mlflow-for-batch-t…
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[usafacts.org](https://usafacts.org/data/topics/people-society/population-and-demographics/population-data/population/?source=post_page-----1429528ecbe5--------------------------------)
    [](https://github.com/Azure/azureml-examples/blob/main/sdk/python/endpoints/batch/deploy-models/heart-classifier-mlflow/mlflow-for-batch-tabular.ipynb?source=post_page-----1429528ecbe5--------------------------------)
    [## azureml-examples/sdk/python/endpoints/batch/deploy-models/heart-classifier-mlflow/mlflow-for-batch-t…'
- en: Official community-driven Azure Machine Learning examples, tested with GitHub
    Actions. …
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 官方社区驱动的 Azure 机器学习示例，已通过 GitHub Actions 测试。
- en: github.com](https://github.com/Azure/azureml-examples/blob/main/sdk/python/endpoints/batch/deploy-models/heart-classifier-mlflow/mlflow-for-batch-tabular.ipynb?source=post_page-----1429528ecbe5--------------------------------)
    [](https://github.com/Azure/azureml-examples/blob/main/tutorials/get-started-notebooks/quickstart.ipynb?source=post_page-----1429528ecbe5--------------------------------)
    [## azureml-examples/tutorials/get-started-notebooks/quickstart.ipynb at main
    · Azure/azureml-examples
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/Azure/azureml-examples/blob/main/sdk/python/endpoints/batch/deploy-models/heart-classifier-mlflow/mlflow-for-batch-tabular.ipynb?source=post_page-----1429528ecbe5--------------------------------)
    [](https://github.com/Azure/azureml-examples/blob/main/tutorials/get-started-notebooks/quickstart.ipynb?source=post_page-----1429528ecbe5--------------------------------)
    [## azureml-examples/tutorials/get-started-notebooks/quickstart.ipynb at main
    · Azure/azureml-examples'
- en: Official community-driven Azure Machine Learning examples, tested with GitHub
    Actions. …
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 官方社区驱动的 Azure 机器学习示例，已通过 GitHub Actions 测试。
- en: github.com](https://github.com/Azure/azureml-examples/blob/main/tutorials/get-started-notebooks/quickstart.ipynb?source=post_page-----1429528ecbe5--------------------------------)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/Azure/azureml-examples/blob/main/tutorials/get-started-notebooks/quickstart.ipynb?source=post_page-----1429528ecbe5--------------------------------)'
- en: '[https://learn.microsoft.com/en-us/azure/machine-learning](https://learn.microsoft.com/en-us/azure/machine-learning)/'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://learn.microsoft.com/zh-cn/azure/machine-learning](https://learn.microsoft.com/en-us/azure/machine-learning)/'
