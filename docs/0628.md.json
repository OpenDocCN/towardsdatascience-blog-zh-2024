["```py\n# First block: Conv => ReLU => MaxPool\nself.conv1 = Conv2d(in_channels=channels, out_channels=20, kernel_size=(5, 5), padding=2)\nself.relu1 = ReLU()\nself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n\n# Second block: Conv => ReLU => MaxPool\nself.conv2 = Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5), padding=2)\nself.relu2 = ReLU()\nself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n\n# Third block: Conv => ReLU => MaxPool layers\nself.conv3 = Conv2d(in_channels=50, out_channels=final_out_channels, kernel_size=(5, 5), padding=2)\nself.relu3 = ReLU()\nself.maxpool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n\n# Fourth block: Linear => Dropout => ReLU layers\nself.linear1 = Linear(in_features=fully_connected_input_size, out_features=fully_connected_input_size // 2)\nself.dropout1 = Dropout(p=0.3)\nself.relu3 = ReLU()\n\n# Fifth block: Linear => Dropout layers\nself.linear2 = Linear(in_features=fully_connected_input_size // 2, out_features=fully_connected_input_size // 4)\nself.dropout2 = Dropout(p=0.3)\n\n# Sixth block: Linear => Dropout layers\nself.linear3 = Linear(in_features=fully_connected_input_size // 4, out_features=classes)\nself.dropout3 = Dropout(p=0.3)\n\nself.logSoftmax = LogSoftmax(dim=1)\n```", "```py\ndef classify(X, y):\n  model = MyModel()                   # Not yet initialized\n  p = model(X)                        # Not yet computed\n  loss = mlx.nn.losses.nll_loss(p, y) # Not yet computed\n\n  print(f\"loss value: {loss}\") # Inits `model`, computes `loss` _and_ `p`\n  mlx.eval(p)                  # No-op\n\n  # Without the print() above, would return `p` and lazy `loss`\n  return p, loss \n```", "```py\ntest_start = time.perf_counter_ns() # Start time block\naccuracy, _ = eval(test_data_loader, model, n)\nmx.eval(accuracy) # Force calculation within measurement block\ntest_end = time.perf_counter_ns() # End time block\n```", "```py\nfor X, y in dataloader:\n  p = model(X)\n  loss = loss_fn(p, y)\n  optimizer.zero_grad()\n  loss.backward()\n  optimizer.step()\n```", "```py\ndef loss_fn(model, X, y):\n  return nn.losses.cross_entropy(model(X), y, reduction=\"mean\")\n\nloss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n\n@partial(mx.compile, inputs=model.state, outputs=model.state)\ndef step(X, y):\n  loss, grads = loss_and_grad_fn(model, X, y)\n  optimizer.update(model, grads)\n  return loss\n\n# batch_iterate is a custom generator function\nfor X, y in batch_iterate(batch_size, train_images, train_labels):\n  loss = step(X, y)\n```", "```py\n ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n      426   86.564    0.203   86.564    0.203 {built-in method mlx.core.eval}\n        1    2.732    2.732   86.271   86.271 /Users/mike/code/cnn/src/python/mlx/cnn.py:48(train)\n    10051    0.085    0.000    0.625    0.000 /Users/mike/code/cnn/src/python/mlx/model.py:80(__call__)\n    30153    0.079    0.000    0.126    0.000 /Users/mike/Library/Python/3.9/lib/python/site-packages/mlx/nn/layers/pooling.py:23(_sliding_windows)\n    30153    0.072    0.000    0.110    0.000 /Users/mike/Library/Python/3.9/lib/python/site-packages/mlx/nn/layers/convolution.py:122(__call__)\n        1    0.062    0.062    0.062    0.062 {built-in method _posixsubprocess.fork_exec}\n    40204    0.055    0.000    0.055    0.000 {built-in method relu}\n    10051    0.054    0.000    0.054    0.000 {built-in method mlx.core.mean}\n      424    0.050    0.000    0.054    0.000 {built-in method step}\n```", "```py\n ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n    15585   41.385    0.003   41.385    0.003 {method 'item' of 'torch._C.TensorBase' objects}\n    20944    6.473    0.000    6.473    0.000 {built-in method torch.stack}\n    31416    1.865    0.000    1.865    0.000 {built-in method torch.conv2d}\n    41888    1.559    0.000    1.559    0.000 {built-in method torch.relu}\n    31416    1.528    0.000    1.528    0.000 {built-in method torch._C._nn.linear}\n    31416    1.322    0.000    1.322    0.000 {built-in method torch.max_pool2d}\n    10472    1.064    0.000    1.064    0.000 {built-in method torch._C._nn.nll_loss_nd}\n    31416    0.952    0.000    7.537    0.001 /Users/mike/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:88(collate)\n      424    0.855    0.002    0.855    0.002 {method 'run_backward' of 'torch._C._EngineBase' objects}\n        5    0.804    0.161   19.916    3.983 /Users/mike/code/cnn/src/python/pytorch/cnn.py:176(eval)\n```"]