- en: Fine-tune Google Gemma with Unsloth and Distilled DPO on Your Computer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/fine-tune-google-gemma-with-unsloth-and-distilled-dpo-on-your-computer-ca1ce8828122?source=collection_archive---------5-----------------------#2024-03-18](https://towardsdatascience.com/fine-tune-google-gemma-with-unsloth-and-distilled-dpo-on-your-computer-ca1ce8828122?source=collection_archive---------5-----------------------#2024-03-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Following Hugging Face’s Zephyr recipe
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@bnjmn_marie?source=post_page---byline--ca1ce8828122--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page---byline--ca1ce8828122--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ca1ce8828122--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ca1ce8828122--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page---byline--ca1ce8828122--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ca1ce8828122--------------------------------)
    ·8 min read·Mar 18, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b55099aa531dd1323734916dffb4496b.png)'
  prefs: []
  type: TYPE_IMG
- en: Generated with DALL-E
  prefs: []
  type: TYPE_NORMAL
- en: Finding good training hyperparameters for new LLMs is always difficult and time-consuming.
    With [Zephyr Gemma 7B](https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-v0.1),
    Hugging Face seems to have found a good recipe for fine-tuning Gemma. They used
    a combination of distilled supervised fine-tuning and DPO similar to what they
    did for their [original Zephyr based on Mistral 7B](https://medium.com/towards-data-science/zephyr-7b-beta-a-good-teacher-is-all-you-need-c931fcd0bfe7).
    However, training Gemma with DPO on consumer hardware is challenging due to its
    memory consumption.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I first review the recipe used by Hugging Face to train Zephyr
    Gemma 7B. Then, I show how to use this recipe with Unsloth, a framework implementing
    various optimizations for fast and memory-efficient training. The method presented
    in this article has a peak memory consumption of 19 GB of VRAM and a total training
    time of only 8 hours. In other words, DPO training for Gemma is possible on consumer
    hardware.
  prefs: []
  type: TYPE_NORMAL
- en: A Closer Look at Zephyr Gemma
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supervised Fine-tuning (SFT)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'DPO must use for reference a model trained with supervised fine-tuning (SFT)
    on an instruction dataset. Hugging Face also released this SFT model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[HuggingFaceH4/zephyr-7b-gemma-sft-v0.1](https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-sft-v0.1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
