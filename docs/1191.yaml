- en: 'CodeLlama vs. CodeGemma: Using Open Models for AI Coding Assistance'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/codellama-vs-codegemma-using-open-models-for-ai-coding-assistance-da446c9157b8?source=collection_archive---------6-----------------------#2024-05-11](https://towardsdatascience.com/codellama-vs-codegemma-using-open-models-for-ai-coding-assistance-da446c9157b8?source=collection_archive---------6-----------------------#2024-05-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Integrating 7B and 13B Models with an IDE and Terminal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://dmitryelj.medium.com/?source=post_page---byline--da446c9157b8--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--da446c9157b8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--da446c9157b8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--da446c9157b8--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--da446c9157b8--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--da446c9157b8--------------------------------)
    ·13 min read·May 11, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5c7f1ce4b25814e6af62deff202137b1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by AltumCode, [Unsplash](https://unsplash.com/@altumcode)
  prefs: []
  type: TYPE_NORMAL
- en: The AI coding-tools market is a billion-dollar industry. It is expected to reach
    $17.2 billion by 2030, and even today, AI plugins for VS Code or JetBrains IDE
    have millions of downloads. But can we run a local model as a free coding assistant,
    and how well will it perform? In this article, I will test two open models, Code
    Gemma and Code Llama. I will install them on my PC, and we will see how they work.
  prefs: []
  type: TYPE_NORMAL
- en: Without further ado, let’s get into it!
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the time of writing this article, two major open models are available for
    free download and could be used for coding purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[CodeLlama](https://ai.meta.com/blog/code-llama-large-language-model-coding/).
    The model was released in 2023 by Meta; it is available in 7B, 13B, 34B, and 70B
    sizes. “Base,” “Instruct,” and “Python” models are available. Despite four sizes,
    only the 7B and 13B models can realistically be used locally; others are just
    too “heavy.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CodeGemma](https://ai.google.dev/gemma/docs/codegemma). The model was released
    in 2024 by Google and is available in 2B and 7B sizes. A 2B model was trained
    only for code completion, and a 7B model was trained for code infilling and natural
    language prompts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
