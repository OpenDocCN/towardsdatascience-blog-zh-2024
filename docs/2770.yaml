- en: 'Writing LLMs in Rust: Looking for an Efficient Matrix Multiplication'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/writing-llms-in-rust-looking-for-an-efficient-matrix-multiplication-e9539b0cb9d3?source=collection_archive---------4-----------------------#2024-11-14](https://towardsdatascience.com/writing-llms-in-rust-looking-for-an-efficient-matrix-multiplication-e9539b0cb9d3?source=collection_archive---------4-----------------------#2024-11-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Starting from Karpathy `llm.c,` I wonder myself “Could I write this in Rust?”
    Here are the lessons I learned and how I am writing `llm.rust.` In this first
    article, let’s tackle the matrix multiplication problem.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://stefanobosisio1.medium.com/?source=post_page---byline--e9539b0cb9d3--------------------------------)[![Stefano
    Bosisio](../Images/450d904024a4cbf1adf8a625886d852e.png)](https://stefanobosisio1.medium.com/?source=post_page---byline--e9539b0cb9d3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e9539b0cb9d3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e9539b0cb9d3--------------------------------)
    [Stefano Bosisio](https://stefanobosisio1.medium.com/?source=post_page---byline--e9539b0cb9d3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e9539b0cb9d3--------------------------------)
    ·14 min read·Nov 14, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1769e0bfb8a5da7e50ac3f79dba6ce6c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [GoogleDeepMind](https://unsplash.com/@googledeepmind) on [Unsplash](https://unsplash.com/photos/a-bonsai-tree-growing-out-of-a-concrete-block-K2V_fqM2RY8)
  prefs: []
  type: TYPE_NORMAL
- en: Matrix multiplication may be the most important operation in Machine Learning.
    I still remember when I was an engineering student, and in one of the first linear
    algebra lessons, the teacher started to explain matrices, eigenvectors, and basis
    and orthonormal basis. I was very confused, my head took a little while to start
    understanding why we were bothering so much about matrices and basis sets, and
    what a good basis implies for our world. From there, I always found linear algebra
    so fascinating, and, from a pure computer science point of view, how amazing all
    those algorithms that try to be more and more efficient in handling matrices.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, we know that the matrix-vector product is pretty simple, but
    things are getting more and more complicated when we have matrices-matrices or
    tensors-tensors products. From here, many methodologies have been implemented
    to optimize the matrix multiplication. For example, a long time ago I posted about
    [DeepMind](https://medium.com/towards-data-science/understanding-deepmind-matrix-multiplication-c8dc49687ce7)…
  prefs: []
  type: TYPE_NORMAL
