- en: Explaining Complex Models to Business Stakeholders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/explaining-complex-models-to-business-stakeholders-5af0691bacd4?source=collection_archive---------11-----------------------#2024-04-30](https://towardsdatascience.com/explaining-complex-models-to-business-stakeholders-5af0691bacd4?source=collection_archive---------11-----------------------#2024-04-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/10b1475735b39b40c9cbea27c8cbf262.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [niko photos](https://unsplash.com/@niko_photos?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/green-leaf-tree-under-blue-sky-tGTVxeOr_Rs?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: Explaining a LightGBM model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@fkarvoun?source=post_page---byline--5af0691bacd4--------------------------------)[![Frida
    Karvouni](../Images/49aad19f6bdd7ffdc68c212722079c6f.png)](https://medium.com/@fkarvoun?source=post_page---byline--5af0691bacd4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5af0691bacd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5af0691bacd4--------------------------------)
    [Frida Karvouni](https://medium.com/@fkarvoun?source=post_page---byline--5af0691bacd4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5af0691bacd4--------------------------------)
    ·5 min read·Apr 30, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Business stakeholders are starting to recognise the value machine learning models
    bring to their operations, gaining a deeper understanding of their benefits and
    drawbacks. Simultaneously, there’s a rising demand for more accurate and swifter
    machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 'A challenge emerges as these models advance rapidly, attaining greater accuracy
    but becoming more complex and less explainable (referred to as “black-box” models).
    Consequently, it becomes increasingly difficult for data scientists to:'
  prefs: []
  type: TYPE_NORMAL
- en: explain the methodologies and outcomes to stakeholders, thereby hindering model
    adoption rates,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: evaluate how alterations in features impact model performance,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: gain insights into how adjustments in model hyper-parameters influence its structure,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ensure model fairness, particularly in compliance with regulations like GDPR
    (which prohibits the use of personal data in ways that may harm or mislead customers),
    **[1]**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: identify vulnerabilities within the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Global and local explainability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LightGBM, a tree-based boosting model, delivers precise outcomes but poses challenges
    in comprehension due to its inherent complexity.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll construct a LightGBM model and delve into its internal mechanisms. Initially,
    we’ll preprocess the diabetes dataset sourced from scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The dataset has already been scaled, and in this scenario, the target variable
    will represent the progression of diabetes as a regression value. The features
    encompass various patient characteristics along with blood level measurements.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f256e220a4513ffeec1a8dd1edc4fe49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The diabetes dataset used was provided by scikit-learn Data: [3]'
  prefs: []
  type: TYPE_NORMAL
- en: 'The assumption is that higher blood pressure would contribute to higher progression
    of diabetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/987f228828f8260c999cb4d87f046b2b.png)'
  prefs: []
  type: TYPE_IMG
- en: Relationship between blood sugar and diabetes progression
  prefs: []
  type: TYPE_NORMAL
- en: The same assumption exists for a higher BMI index.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2d0b0e963b4041976cd774aadd958c36.png)'
  prefs: []
  type: TYPE_IMG
- en: Relationship between BMI and diabetes progression
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, the scaled features are already challenging to interpret and
    explain to stakeholders. A LightGBM model is fit as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: At a high level, a data scientist must grasp the model’s inner workings, ascertain
    if it captures the most pertinent features aligned with business insights, and
    identify any crucial features omitted from the model. At this point, it is challenging
    to explain the fitted model.
  prefs: []
  type: TYPE_NORMAL
- en: Global explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assessing the global explainability of a LightGBM model entails calculating
    the feature importance or the mean of the Shapley values.
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The feature importance of the model is calculated as such:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/800e0761a663a8a8db8f37b332aff06a.png)'
  prefs: []
  type: TYPE_IMG
- en: Feature importance of the LightGBM model
  prefs: []
  type: TYPE_NORMAL
- en: The BMI index is the feature that improves the model’s predictions by significantly
    creating better splits in the model. The level of triglycerides, blood sugar,
    and blood pressure are also crucial features of the model. These findings are
    all reasonable, as the BMI index of a person, as well as the levels of blood sugar
    and triglycerides are highly likely contributors to diabetes.
  prefs: []
  type: TYPE_NORMAL
- en: Shapley values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The mean of the Shapley values should give a very similar picture as above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/cbf7ccee357d6a385f53b1888582d83e.png)'
  prefs: []
  type: TYPE_IMG
- en: Mean values of marginal contribution of each feature to the LightGBM model
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, the results are very similar when using either of these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Local explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These tools are invaluable for assessing the overall performance of a model.
    With Shapley values, it’s also feasible to conduct an in-depth analysis of the
    marginal contribution of each feature to the prediction at the level of a data
    point.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6cce9dfb1a834c513c76d8b459dd060.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Marginal contribution within a non-linear model. Source: [2]'
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, we can analyse the impact of each feature on the progression
    of diabetes for a particular patient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/89b363a7abfaef3a25e56651630401a2.png)'
  prefs: []
  type: TYPE_IMG
- en: The marginal contribution of each feature to the prediction of the LightGBM
    model for one patient
  prefs: []
  type: TYPE_NORMAL
- en: This perspective would empower us to offer tailored advice to that patient,
    suggesting a focus on optimising their BMI index.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In summary, while machine learning models offer significant advantages, their
    increasing complexity poses challenges regarding explainability, interpretability,
    and compliance, impacting their adoption and effectiveness. Techniques, such as
    SHAP and feature importance empower data scientists to understand their models
    better, therefore accommodating the process of explaining the predictions to the
    business.
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Unless otherwise noted, all images have been generated by the author'
  prefs: []
  type: TYPE_NORMAL
- en: '**[1]**[https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/principles/lawfulness-fairness-and-transparency/#:~:text=In%20general%2C%20fairness%20means%20that,also%20about%20whether%20you%20should](https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/principles/lawfulness-fairness-and-transparency/#:~:text=In%20general%2C%20fairness%20means%20that,also%20about%20whether%20you%20should).'
  prefs: []
  type: TYPE_NORMAL
- en: '**[2]**[https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html)
    © Copyright 2018, Scott Lundberg. Revision dffc346f'
  prefs: []
  type: TYPE_NORMAL
- en: '**[3]**[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html)
    © 2007–2024, scikit-learn developers (BSD License)'
  prefs: []
  type: TYPE_NORMAL
- en: 'LightGBM documentation: [https://lightgbm.readthedocs.io/en/stable/](https://lightgbm.readthedocs.io/en/stable/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'SHAP documentation: [https://shap.readthedocs.io/en/latest/index.html](https://shap.readthedocs.io/en/latest/index.html)'
  prefs: []
  type: TYPE_NORMAL
