- en: 'The Story of RLHF: Origins, Motivations, Techniques, and Modern Applications'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-story-of-rlhf-origins-motivations-techniques-and-modern-applications-16dfac9e4a45?source=collection_archive---------7-----------------------#2024-02-29](https://towardsdatascience.com/the-story-of-rlhf-origins-motivations-techniques-and-modern-applications-16dfac9e4a45?source=collection_archive---------7-----------------------#2024-02-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How learning from human feedback revolutionized generative language models…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page---byline--16dfac9e4a45--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page---byline--16dfac9e4a45--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--16dfac9e4a45--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--16dfac9e4a45--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page---byline--16dfac9e4a45--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16dfac9e4a45--------------------------------)
    ·31 min read·Feb 29, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aa2218c0fe05bde5d2b1dd7cd6368f4f.png)'
  prefs: []
  type: TYPE_IMG
- en: (Photo by [Towfiqu barbhuiya](https://unsplash.com/@towfiqu999999?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/a-row-of-yellow-stars-sitting-on-top-of-a-blue-and-pink-surface-0ZUoBtLw3y4?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash))
  prefs: []
  type: TYPE_NORMAL
- en: For a long time, the AI community has leveraged different styles of language
    models (e.g., [n-gram models](https://en.wikipedia.org/wiki/Word_n-gram_language_model),
    [RNNs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/), [transformers](https://cameronrwolfe.substack.com/i/108182616/different-transformer-architectures),
    etc.) to automate generative and discriminative natural language tasks. This area
    of research experienced a surge of interest in 2018 with the proposal of BERT
    [10], which demonstrated that the transformer architecture, self-supervised pretraining,
    and supervised transfer learning form a powerful combination. In fact, BERT set
    new state-of-the-art performance on every benchmark on which it was applied at
    the time. Although BERT could not be used for generative tasks, we saw with the
    proposal of [T5](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part)
    [11] that supervised transfer learning was effective in this domain as well. Despite
    these accomplishments, however, such models pale in comparison to the generative
    capabilities of LLMs like GPT-4 that we have today. To create a model like this,
    we need training techniques that go far beyond supervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: “Our goal is to advance digital intelligence in the way that is most likely
    to benefit humanity as a whole.” *— OpenAI* [*Founding Statement*](https://openai.com/blog/introducing-openai)
    *(Dec. 2015)*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
