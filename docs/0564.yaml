- en: 'The Story of RLHF: Origins, Motivations, Techniques, and Modern Applications'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-story-of-rlhf-origins-motivations-techniques-and-modern-applications-16dfac9e4a45?source=collection_archive---------7-----------------------#2024-02-29](https://towardsdatascience.com/the-story-of-rlhf-origins-motivations-techniques-and-modern-applications-16dfac9e4a45?source=collection_archive---------7-----------------------#2024-02-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How learning from human feedback revolutionized generative language models…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page---byline--16dfac9e4a45--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page---byline--16dfac9e4a45--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--16dfac9e4a45--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--16dfac9e4a45--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page---byline--16dfac9e4a45--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16dfac9e4a45--------------------------------)
    ·31 min read·Feb 29, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aa2218c0fe05bde5d2b1dd7cd6368f4f.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: (Photo by [Towfiqu barbhuiya](https://unsplash.com/@towfiqu999999?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/a-row-of-yellow-stars-sitting-on-top-of-a-blue-and-pink-surface-0ZUoBtLw3y4?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: For a long time, the AI community has leveraged different styles of language
    models (e.g., [n-gram models](https://en.wikipedia.org/wiki/Word_n-gram_language_model),
    [RNNs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/), [transformers](https://cameronrwolfe.substack.com/i/108182616/different-transformer-architectures),
    etc.) to automate generative and discriminative natural language tasks. This area
    of research experienced a surge of interest in 2018 with the proposal of BERT
    [10], which demonstrated that the transformer architecture, self-supervised pretraining,
    and supervised transfer learning form a powerful combination. In fact, BERT set
    new state-of-the-art performance on every benchmark on which it was applied at
    the time. Although BERT could not be used for generative tasks, we saw with the
    proposal of [T5](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part)
    [11] that supervised transfer learning was effective in this domain as well. Despite
    these accomplishments, however, such models pale in comparison to the generative
    capabilities of LLMs like GPT-4 that we have today. To create a model like this,
    we need training techniques that go far beyond supervised learning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 长期以来，人工智能领域一直利用不同风格的语言模型（例如，[n-gram模型](https://en.wikipedia.org/wiki/Word_n-gram_language_model)，[RNNs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)，[transformers](https://cameronrwolfe.substack.com/i/108182616/different-transformer-architectures)等）来自动化生成性和判别性自然语言任务。2018年，随着BERT
    [10]的提出，这一研究领域迎来了前所未有的关注，BERT展示了transformer架构、自监督预训练和监督迁移学习的强大结合。事实上，BERT在当时应用的每个基准测试中都创下了新的最先进性能。尽管BERT不能用于生成任务，但我们通过[T5](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part)
    [11]的提出看到了监督迁移学习在这一领域的有效性。然而，尽管取得了这些成就，这些模型与如今如GPT-4等LLM的生成能力相比仍显得微不足道。要创建这样的模型，我们需要远远超越监督学习的训练技术。
- en: “Our goal is to advance digital intelligence in the way that is most likely
    to benefit humanity as a whole.” *— OpenAI* [*Founding Statement*](https://openai.com/blog/introducing-openai)
    *(Dec. 2015)*
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们的目标是以最有可能造福全人类的方式推进数字智能。” *— OpenAI* [*创始声明*](https://openai.com/blog/introducing-openai)
    *(2015年12月)*
