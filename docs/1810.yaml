- en: Multimodal RAG — Intuitively and Exhaustively Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/multimodal-rag-intuitively-and-exhaustively-explained-5713d8069eb0?source=collection_archive---------4-----------------------#2024-07-25](https://towardsdatascience.com/multimodal-rag-intuitively-and-exhaustively-explained-5713d8069eb0?source=collection_archive---------4-----------------------#2024-07-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Artificial Intelligence | Retrieval Augmented Generation | Multimodality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Modern RAG for modern models.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)
    ·10 min read·Jul 25, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/439b5f04f55575e85c358964da8b2e91.png)'
  prefs: []
  type: TYPE_IMG
- en: “Multicolored Team” by Daniel Warfield using Midjourney. All images by the author
    unless otherwise specified. Article originally made available on [Intuitively
    and Exhaustively Explained](https://iaee.substack.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal Retrieval Augmented Generation is an emerging design paradigm that
    allows AI models to interface with stores of text, images, video, and more.
  prefs: []
  type: TYPE_NORMAL
- en: In exploring this topic we’ll first cover what retrieval augmented generation
    (RAG) is, the idea of multimodality, and how the two are being combined to make
    modern multimodal RAG systems. Once we understand the fundamental concepts of
    multimodal RAG, we’ll build a multimodal RAG system ourselves using Google Gemini
    and a CLIP style model for encoding.
  prefs: []
  type: TYPE_NORMAL
- en: '**Who is this useful for?** Anyone interested in modern AI.'
  prefs: []
  type: TYPE_NORMAL
- en: '**How advanced is this post?** Even though multimodal RAG is at the forefront
    of AI, it’s intuitively simple and accessible. This article should be interesting
    to senior AI researchers, while simple enough for a beginner.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-requisites:** None'
  prefs: []
  type: TYPE_NORMAL
- en: A Brief Introduction to Retrieval Augmented Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we get into Multimodal RAG, let’s briefly go over traditional Retrieval
    Augmented Generation (RAG). Basically, the idea…
  prefs: []
  type: TYPE_NORMAL
