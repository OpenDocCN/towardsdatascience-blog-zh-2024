<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Building a Data Science Platform with Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Building a Data Science Platform with Kubernetes</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-data-science-tool-stack-with-kubernetes-00c74b491b9d?source=collection_archive---------7-----------------------#2024-07-11">https://towardsdatascience.com/building-a-data-science-tool-stack-with-kubernetes-00c74b491b9d?source=collection_archive---------7-----------------------#2024-07-11</a></blockquote><div><div class="em ff fg fh fi fj"/><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><div/><div><h2 id="e4e1" class="pw-subtitle-paragraph go fq fr bf b gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd cq dx">How Kubernetes — the back-end tool — powers the data science team with end-to-end ML life-cycle from model development to deployment</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://avinashknmr.medium.com/?source=post_page---byline--00c74b491b9d--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Avinash Kanumuru" class="l ep by dd de cx" src="../Images/7d9f0547542650178297ed04365fb7da.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*mMIza-xXGdX13-qVs3MFBA.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--00c74b491b9d--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://avinashknmr.medium.com/?source=post_page---byline--00c74b491b9d--------------------------------" rel="noopener follow">Avinash Kanumuru</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--00c74b491b9d--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 11, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk lb lc ab q ee ld le" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lf"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap ie li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/6e99dc373ba82e9468ce30f2575fb1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S9ZpyKlWf6mcpWfE"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@growtika?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Growtika</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="da7f" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">When I started in my new role as Manager of Data Science, little did I know about setting up a data science platform for the team. In all my previous roles, I had worked on building models and to some extent deploying models (or at least supporting the team that was deploying models), but I never needed to set up something from scratch (infra, I mean). The data science team did not exist then.</p><p id="30b4" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">So first of my objective was to set up a platform, not just for the data science team in a silo, but that can be integrated with data engineering and software teams. This is when I was introduced to Kubernetes (k8s) directly. I had heard of it earlier but hadn’t worked beyond creating docker images and someone else would deploy in some infra.</p><p id="d762" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Now, why is Kubernetes required for the data science team? What are some of the challenges faced by data science teams?</p><ul class=""><li id="a3f3" class="nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob bk">A scalable computer based on requirement — as a data scientist we work on different problems every day and each has different resource requirements. There isn’t a one-size-fits-all computer. Even if it exists, it can’t be given to everyone on the data science team</li><li id="2c6c" class="nd ne fr nf b gp oc nh ni gs od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Version issues — Python and package version issues when working in a team or when we deploy to production</li><li id="2a95" class="nd ne fr nf b gp oc nh ni gs od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Different technologies and platforms — some pre-processing and model building require spark, and some can be done in pandas. So again, there isn’t a one-size-fits-all in local computer</li><li id="f816" class="nd ne fr nf b gp oc nh ni gs od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Sharing work within the team — Sharing and tracking of model results done in an Excel spreadsheet and circulated after each iteration</li><li id="686a" class="nd ne fr nf b gp oc nh ni gs od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">And most importantly, Production deployment — how do I get the finished model to production? Models don’t get to production for real-time use cases, as we as data scientists are not aware of building API/system around a model. Eventually, we end up running the model score in batch</li></ul><p id="81b9" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">I’ve explored solutions, including Cloud Platform solutions (AWS SageMaker, GCP AI Platform, Azure Machine Learning), but our main factor is cost and next is cloud-agnostic. If cost is not a factor, then one can use the above-mentioned cloud platform services.</p><p id="dff5" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">We identified that Kubernetes is an ideal platform that satisfies most of these requirements — to scale and serve containerized images. Also this way, we are cloud-agnostic. If we have to move to a different vendor, we just lift and shift everything with minimal changes.</p><p id="eef9" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Many tools provide complete/similar solutions like KubeFlow, Weights &amp; Biases, Kedro, …, but I ended up deploying the below 3 services as the first version of the data science platform. Though these don’t provide the complete MLOps framework, this gets us started to build the data science platform and team.</p><ol class=""><li id="dade" class="nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oh oa ob bk"><strong class="nf fs">JupyterHub</strong> — Containerized user environments for developing models in interactive Jupyter Notebooks</li><li id="d237" class="nd ne fr nf b gp oc nh ni gs od nk nl nm oe no np nq of ns nt nu og nw nx ny oh oa ob bk"><strong class="nf fs">MLflow</strong> — Experiment tracking and storing model artifacts</li><li id="a62b" class="nd ne fr nf b gp oc nh ni gs od nk nl nm oe no np nq of ns nt nu og nw nx ny oh oa ob bk"><strong class="nf fs">Seldon Core</strong> — Simplified way to deploy models in Kubernetes</li></ol><p id="d38a" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">With these 3 services, I get my team to build models including big data processing in JupyterHub, track different fine-tuned parameters, and metrics, and store artifacts using MLflow and serve the model for production using Seldon-Core.</p><h2 id="a0d3" class="oi oj fr bf ok ol om on oo op oq or os nm ot ou ov nq ow ox oy nu oz pa pb pc bk">JupyterHub</h2><p id="e0dd" class="pw-post-body-paragraph nd ne fr nf b gp pd nh ni gs pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fk bk">Deploying this was the trickiest of all. JupyterHub in a standalone setup is easy compared to Kubernetes installation. But most of the required configuration was available here —</p><div class="pi pj pk pl pm pn"><a href="https://z2jh.jupyter.org/?source=post_page-----00c74b491b9d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="po ab ih"><div class="pp ab co cb pq pr"><h2 class="bf fs hx z ip ps ir is pt iu iw fq bk">Zero to JupyterHub with Kubernetes</h2><div class="pu l"><h3 class="bf b hx z ip ps ir is pt iu iw dx">JupyterHub allows users to interact with a computing environment through a webpage. As most devices have access to a…</h3></div><div class="pv l"><p class="bf b dy z ip ps ir is pt iu iw dx">z2jh.jupyter.org</p></div></div><div class="pw l"><div class="px l py pz qa pw qb lr pn"/></div></div></a></div><p id="5077" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Since we want to use Spark for some of our data processing, we created 2 docker images —</p><ol class=""><li id="69d2" class="nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oh oa ob bk">Basic Notebook — extended from <code class="cx qc qd qe qf b">jupyter/minimal-notebook:python-3.9</code></li><li id="e4ec" class="nd ne fr nf b gp oc nh ni gs od nk nl nm oe no np nq of ns nt nu og nw nx ny oh oa ob bk">Spark Notebook — extended from above with additional spark setup.</li></ol><p id="9f5f" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Code for these notebook docker images and helm values for installing JupyterHub using these docker images are available <a class="af nc" href="https://github.com/avinashknmr/data-science-tools" rel="noopener ugc nofollow" target="_blank">here</a>.</p><div class="pi pj pk pl pm pn"><a href="https://github.com/avinashknmr/data-science-tools?source=post_page-----00c74b491b9d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="po ab ih"><div class="pp ab co cb pq pr"><h2 class="bf fs hx z ip ps ir is pt iu iw fq bk">GitHub - avinashknmr/data-science-tools</h2><div class="pu l"><h3 class="bf b hx z ip ps ir is pt iu iw dx">Contribute to avinashknmr/data-science-tools development by creating an account on GitHub.</h3></div><div class="pv l"><p class="bf b dy z ip ps ir is pt iu iw dx">github.com</p></div></div><div class="pw l"><div class="qg l py pz qa pw qb lr pn"/></div></div></a></div><p id="7e6b" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">There are a lot of tweaks done to enable Google Oauth, starting Notebook as a root user, but running them as an individual user, retrieving the username, user-level permissions, persistent volume claims, and service accounts, … which took me days to get it working, especially with the Auth. But this code in the repo, can give you a skeleton to get started.</p><h2 id="b9ac" class="oi oj fr bf ok ol om on oo op oq or os nm ot ou ov nq ow ox oy nu oz pa pb pc bk">MLflow</h2><p id="2ed1" class="pw-post-body-paragraph nd ne fr nf b gp pd nh ni gs pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fk bk">Setting up MLFlow was easy.</p><div class="pi pj pk pl pm pn"><a href="https://mlflow.org/docs/latest/introduction/index.html?source=post_page-----00c74b491b9d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="po ab ih"><div class="pp ab co cb pq pr"><h2 class="bf fs hx z ip ps ir is pt iu iw fq bk">What is MLflow?</h2><div class="pu l"><h3 class="bf b hx z ip ps ir is pt iu iw dx">Stepping into the world of Machine Learning (ML) is an exciting journey, but it often comes with complexities that can…</h3></div><div class="pv l"><p class="bf b dy z ip ps ir is pt iu iw dx">mlflow.org</p></div></div><div class="pw l"><div class="qh l py pz qa pw qb lr pn"/></div></div></a></div><p id="fb28" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">MLflow offers model tracking, model registry, and model serving capabilities. But for model serving, we use the next tool (Seldon-Core).</p><p id="7f52" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Build a Docker image with the required Python packages.</p><pre class="mm mn mo mp mq qi qf qj bp qk bb bk"><span id="6e46" class="ql oj fr qf b bg qm qn l qo qp">FROM python:3.11-slim<br/><br/>RUN pip install mlflow==2.0.1 boto3==1.26.12 awscli==1.27.22 psycopg2-binary==2.9.5<br/><br/>EXPOSE 5000</span></pre><p id="147e" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Once the docker image is created and pushed to the container registry of your choice, we create a deployment and service file for Kubernetes (similar to any other docker image deployment). A snippet of the deployment yaml is given below.</p><pre class="mm mn mo mp mq qi qf qj bp qk bb bk"><span id="f988" class="ql oj fr qf b bg qm qn l qo qp">containers:<br/>- image: avinashknmr/mlflow:2.0.1<br/>  imagePullPolicy: IfNotPresent<br/>  name: mlflow-server<br/>  command: ["mlflow", "server"]<br/>  args:<br/>  - --host=0.0.0.0<br/>  - --port=5000<br/>  - --artifacts-destination=$(MLFLOW_ARTIFACTS_LOCATION)<br/>  - --backend-store-uri=postgresql+psycopg2://$(MLFLOW_DB_USER):$(MLFLOW_DB_PWD)@$(MLFLOW_DB_HOST):$(MLFLOW_DB_PORT)/$(MLFLOW_DB_NAME)<br/>  - --workers=2</span></pre><p id="c5e9" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">There are 2 main configurations here that took time for me to understand and configure —</p><ol class=""><li id="3a09" class="nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oh oa ob bk">artifact’s location</li><li id="c003" class="nd ne fr nf b gp oc nh ni gs od nk nl nm oe no np nq of ns nt nu og nw nx ny oh oa ob bk">backend store</li></ol><p id="90f0" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">The artifact location will be a blob storage where your model file will be stored and can be used for model-serving purposes. But in our case, this is AWS S3 where all models are stored, and is a model registry for us. There are a couple of other options to store the model locally in the server, but whenever the pod restarts the data is done, and PersistentVolume is accessible only via the server. By using Cloud Storage, we can integrate with other services — for example, Seldon-Core can pick from this location to serve the model. The backend store stores all metadata required to run the application including model tracking — parameters and metrics of each experiment/run.</p><h2 id="bb11" class="oi oj fr bf ok ol om on oo op oq or os nm ot ou ov nq ow ox oy nu oz pa pb pc bk">Seldon-Core</h2><p id="6943" class="pw-post-body-paragraph nd ne fr nf b gp pd nh ni gs pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fk bk">The second most trickiest of the three is Seldon-Core.</p><p id="0f29" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Seldon-Core is like a wrapper to your model that can package, deploy, and monitor ML models. This removes the dependency on ML engineers to make the deployment pipelines.</p><div class="pi pj pk pl pm pn"><a href="https://github.com/SeldonIO/seldon-core?source=post_page-----00c74b491b9d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="po ab ih"><div class="pp ab co cb pq pr"><h2 class="bf fs hx z ip ps ir is pt iu iw fq bk">GitHub - SeldonIO/seldon-core: An MLOps framework to package, deploy, monitor and manage thousands…</h2><div class="pu l"><h3 class="bf b hx z ip ps ir is pt iu iw dx">An MLOps framework to package, deploy, monitor and manage thousands of production machine learning models …</h3></div><div class="pv l"><p class="bf b dy z ip ps ir is pt iu iw dx">github.com</p></div></div><div class="pw l"><div class="qq l py pz qa pw qb lr pn"/></div></div></a></div><p id="7d5d" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">We did the installation using a Helm chart and Istio for ingress. There are 2 options for ingress — Istio &amp; Ambassador. I’m not getting into setting up Istio, as the DevOps team did this setup. Seldon is installed with the below Helm and Kubectl commands.</p><pre class="mm mn mo mp mq qi qf qj bp qk bb bk"><span id="f5d3" class="ql oj fr qf b bg qm qn l qo qp">kubectl create namespace seldon-system<br/>kubectl label namespace seldon-system istio-injection=enabled<br/><br/>helm repo add seldonio https://storage.googleapis.com/seldon-charts<br/>helm repo update<br/><br/>helm install seldon-core seldon-core-operator \<br/>    --repo https://storage.googleapis.com/seldon-charts \<br/>    --set usageMetrics.enabled=true \<br/>    --set istio.enabled=true \<br/>    --set istio.gateway=seldon-system/seldon-gateway \<br/>    --namespace seldon-system</span></pre><p id="d950" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">But assuming you have Istio set, below is the Yaml to set up Gateway and VirtualService for our Seldon.</p><pre class="mm mn mo mp mq qi qf qj bp qk bb bk"><span id="9823" class="ql oj fr qf b bg qm qn l qo qp">apiVersion: networking.istio.io/v1alpha3<br/>kind: Gateway<br/>metadata:<br/>  name: seldon-gateway<br/>  namespace: seldon-system<br/>spec:<br/>  selector:<br/>    istio: ingressgateway<br/>  servers:<br/>  - port:<br/>      number: 80<br/>      name: http<br/>      protocol: HTTP<br/>    hosts:<br/>    - "*"<br/>---<br/>apiVersion: networking.istio.io/v1alpha3<br/>kind: VirtualService<br/>metadata:<br/>  name: seldon-vs<br/>  namespace: seldon-system<br/>spec:<br/>  hosts:<br/>  - "*"<br/>  gateways:<br/>  - seldon-gateway<br/>  http:<br/>  - match:<br/>    - uri:<br/>        prefix: /seldon<br/>    route:<br/>    - destination:<br/>        host: seldon-webhook-service.seldon-system.svc.cluster.local<br/>        port:<br/>          number: 8000</span></pre><p id="da37" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Below is a sample k8s deployment file to serve the iris model from GCS. If using <code class="cx qc qd qe qf b">scikit-learn</code> package for model development, the model should be exported using <code class="cx qc qd qe qf b">joblib</code> and named as <code class="cx qc qd qe qf b">model.joblib</code> .</p><pre class="mm mn mo mp mq qi qf qj bp qk bb bk"><span id="afc1" class="ql oj fr qf b bg qm qn l qo qp">apiVersion: machinelearning.seldon.io/v1<br/>kind: SeldonDeployment<br/>metadata:<br/>  name: iris-model<br/>  namespace: prod-data-science<br/>spec:<br/>  name: iris<br/>  predictors:<br/>  - graph:<br/>      implementation: SKLEARN_SERVER<br/>      modelUri: gs://seldon-models/v1.16.0-dev/sklearn/iris<br/>      name: classifier<br/>    name: default<br/>    replicas: 1</span></pre><p id="0b56" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">In this example, we use SKLEARN_SERVER, but it has integrations for MLFLOW_SERVER, and TF_SERVER for MLflow and TensorFlow respectively.</p><p id="0d22" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">Seldon-Core not only supports REST API but also gRPC for seamless server-server calls.</p><h2 id="b7c5" class="oi oj fr bf ok ol om on oo op oq or os nm ot ou ov nq ow ox oy nu oz pa pb pc bk">Conclusion</h2><p id="04a0" class="pw-post-body-paragraph nd ne fr nf b gp pd nh ni gs pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny fk bk">These tools are open source and deployable in Kubernetes, so they are cost-effective for small teams and also cloud-agnostic. They cover most challenges of a data science team like a centralized Jupyter Notebook for collaboration without version issues and serving models without dedicated ML engineers.</p><p id="f57c" class="pw-post-body-paragraph nd ne fr nf b gp ng nh ni gs nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fk bk">JupyterHub and Seldon-Core leverage the Kubernetes capabilities. JupyterHub spins up a pod for users when they log in and kills it when idle. Seldon-Core wraps the model and serves it as an API in a few minutes. MLflow is the only standalone installation that connects model development and model deployment. MLflow acts as a model registry to track models and store artifacts for later use.</p></div></div></div></div>    
</body>
</html>