<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Memory in AI: Key Benefits and Investment Considerations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Memory in AI: Key Benefits and Investment Considerations</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-important-role-of-memory-in-agentic-ai-896b22542b3e?source=collection_archive---------15-----------------------#2024-06-18">https://towardsdatascience.com/the-important-role-of-memory-in-agentic-ai-896b22542b3e?source=collection_archive---------15-----------------------#2024-06-18</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="7892" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Memory will be a critical component that dramatically improves the performance of AI systems — both in accuracy and efficiency</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@sandibesen?source=post_page---byline--896b22542b3e--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Sandi Besen" class="l ep by dd de cx" src="../Images/97361d97f50269f70b6621da2256bc29.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*gHEvwZHf-nDi0QXwnsUeFg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--896b22542b3e--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@sandibesen?source=post_page---byline--896b22542b3e--------------------------------" rel="noopener follow">Sandi Besen</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--896b22542b3e--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">5 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 18, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="96a7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Just as humans depend on memory to make informed decisions and draw logical conclusions, AI relies on its ability to retrieve relevant information, understand contexts, and learn from past experiences. This article delves into why memory is pivotal for AI, exploring its role in recall, reasoning, and continuous learning.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nh"><img src="../Images/0300026eea8f0efe2791300fde5612c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KpXquoWPw-gpAhLL-R-l3w.jpeg"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">colorful brain with microchip representing memory source: DALLE3</figcaption></figure><h1 id="eb30" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Memory’s Role in Recall</h1><p id="9493" class="pw-post-body-paragraph mj mk fq ml b go ou mn mo gr ov mq mr ms ow mu mv mw ox my mz na oy nc nd ne fj bk">Some believe that enlarging the context window will enhance model performance, as it allows the model to ingest more information. While this is true to an extent, our current understanding of how language models prioritize context is still developing. In fact, studies have shown that “model performance is highest when when relevant information occurs at the beginning or end of its input context.”<a class="af oz" href="https://arxiv.org/pdf/2307.03172" rel="noopener ugc nofollow" target="_blank">[1]</a> The larger a context window, the more likely we are to encounter the infamous “lost in the middle” problem, where specific facts or text are not recalled by the model due to important information being buried in the middle [<a class="af oz" href="https://dev.to/llmware/why-long-context-windows-for-llms-can-be-deceptive-lost-in-the-middle-problem-oj2" rel="noopener ugc nofollow" target="_blank">2]</a>.</p><p id="012a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To understand how memory impacts recall, consider how humans process information. When we travel, we passively listen to many announcements including airline advertisements, credit card offers, safety briefings, luggage collection details, etc. We may not realize how much information we absorb until it is time for us to recall relevant pieces. For instance, if a language model that is relying on retrieving relevant information to answer a question, rather than its inherent knowledge, is asked “What should I do in case of an emergency landing?” it might not be able to recall the pertinent details needed to answer this important question because too much information is retrieved. However, with a long-term memory, the model can store and recall the most critical information, enabling more effective reasoning with the proper context.</p><h1 id="4c1f" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Memory’s Role in Reasoning and Continuous Learning</h1><p id="e588" class="pw-post-body-paragraph mj mk fq ml b go ou mn mo gr ov mq mr ms ow mu mv mw ox my mz na oy nc nd ne fj bk">Memory provides essential context and allows models to understand past problem-solving approaches, identifying what worked and what needs improvement. It doesn’t just offer important context; it also equips models with the ability to recall the methods previously used to solve problems, recognize successful strategies, and pinpoint areas needing improvement. This improvement can in turn aid the model’s ability to effectively reason about complex multi-step tasks. Without adequate reasoning, language models struggle to understand tasks, think logically about objectives, solve multistep problems, or utilize appropriate tools. You can read more about the importance of reasoning and advanced reasoning techniques in my previous article <a class="af oz" href="https://medium.com/ai-mind-labs/advanced-language-model-reasoning-pre-training-fine-tuning-and-inference-time-techniques-f5c87ad080f5" rel="noopener">here</a>.</p><p id="e1cb" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Consider the example of manually finding relevant data in a company’s data warehouse. There are thousands of tables, but because you possess an understanding of what data is needed it allows you to focus on a subset. After hours of searching, relevant data is found across five different tables. Three months later, when the data needs updating, the search process must be repeated but you can’t remember the 5 source tables you used to create this new report. The manual search process repeats again. Without long term memory, a language model might approach the problem the same way — with brute force — until it finds the relevant data to complete the task. However a language model equipped with long term memory could store its initial search plan, a description of each table, and a revised plan based on its search findings from each table. When the data needs refreshing, it can start from a previously successful approach, improving efficiency and performance.</p><p id="dbb3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This method allows systems to learn over time, continually revising the best approach to tasks and accumulating knowledge to produce more efficient, higher-performing autonomous systems.</p><h1 id="067b" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Evaluating the Investment to Include Long-Term Memory in Your AI Solutions</h1><p id="15f6" class="pw-post-body-paragraph mj mk fq ml b go ou mn mo gr ov mq mr ms ow mu mv mw ox my mz na oy nc nd ne fj bk">Incorporating long-term memory into AI systems can significantly enhance their capabilities, but determining whether this capability is worthy of the necessary development investment involves consideration.</p><p id="9560" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">1. Understand the Nature of the Tasks</strong></p><ul class=""><li id="9fce" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pa pb pc bk"><strong class="ml fr">Complexity and Duration</strong>: If your tasks involves complex, multi-step processes or requires information retention over long periods, long-term memory can improve efficiency and accuracy. For example, project management applications, where tasks span over months can benefit from AI’s ability to remember and adapt from previous context and iterations.</li><li id="2ca3" class="mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne pa pb pc bk"><strong class="ml fr">Context Sensitivity</strong>: Tasks that heavily depend on contextual understanding, such as customer service interactions, personalization in marketing, or medical diagnostics, can leverage long-term memory to provide more personalized responses. For instance, an IT help desk assistant would benefit from remembering if a customer has already encountered this problem and how it was trouble shooted during previous interactions.</li></ul><p id="58c3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">2. Assess the Volume and Variability of Data</strong></p><ul class=""><li id="6672" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pa pb pc bk"><strong class="ml fr">High Data Volume</strong>: If your application deals with large amounts of data that need to be referenced regularly, long-term memory can prevent the need for repeatedly processing the same information — saving time and computational resources.</li><li id="c269" class="mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne pa pb pc bk"><strong class="ml fr">Data Variability</strong>: In environments where the data changes frequently, long-term memory helps in keeping the AI updated with the latest information, ensuring more accurate outputs without having to re-train.</li></ul><p id="e6dc" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">3. Evaluate the Cost-Benefit Ratio</strong></p><ul class=""><li id="6af1" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pa pb pc bk"><strong class="ml fr">Balance Cost with Performance Benefit</strong>: Implementing long-term memory can be resource-intensive and will continue to scale over time as more memories accumulate. It is important to weigh the financial investment of data storage against potential performance improvements. For small businesses or applications with limited resources, the efficiency of Small Language Models (SLMs) with long-term memory might offer a more balanced solution​​​​.</li><li id="80d5" class="mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne pa pb pc bk"><strong class="ml fr">Competitive Advantage</strong>: By improving the efficiency and effectiveness of AI applications, long-term memory can provide a significant competitive edge, enabling businesses to offer superior services compared to those using traditional models without memory capabilities.</li></ul><p id="03d4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">4. Address Security and Compliance Concerns</strong></p><ul class=""><li id="ca70" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pa pb pc bk"><strong class="ml fr">Data Privacy</strong>: Long-term memory involves storing more data, which can raise privacy concerns. Ensure that your system complies with data protection regulations and that sensitive information follows best security practice.</li></ul><h2 id="671e" class="pi nz fq bf oa pj pk pl od pm pn po og ms pp pq pr mw ps pt pu na pv pw px py bk">In Essence…</h2><p id="922f" class="pw-post-body-paragraph mj mk fq ml b go ou mn mo gr ov mq mr ms ow mu mv mw ox my mz na oy nc nd ne fj bk">Incorporating long-term memory into AI systems presents a significant opportunity to enhance their capabilities by providing improvements in accuracy, efficiency, and contextual understanding. However, deciding whether to invest in this capability requires consideration and cost to benefit analysis. If implemented strategically, the inclusion of long term memory can delivery tangible benefits to your AI solutions.</p></div></div></div><div class="ab cb pz qa qb qc" role="separator"><span class="qd by bm qe qf qg"/><span class="qd by bm qe qf qg"/><span class="qd by bm qe qf"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="47dd" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Have questions or think that something needs to be further clarified? Drop me a DM on <a class="af oz" href="https://www.linkedin.com/in/sandibesen/" rel="noopener ugc nofollow" target="_blank">Linkedin</a>! I‘m always eager to engage in food for thought and iterate on my work. My work does not represent the opinion of my employer.</p></div></div></div></div>    
</body>
</html>