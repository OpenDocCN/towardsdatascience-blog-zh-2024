- en: Gender Bias in AI (International Women’s Day Edition)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/gender-bias-in-ai-international-womens-day-edition-45fa4fa72b75?source=collection_archive---------8-----------------------#2024-03-08](https://towardsdatascience.com/gender-bias-in-ai-international-womens-day-edition-45fa4fa72b75?source=collection_archive---------8-----------------------#2024-03-08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A brief overview and discussion on gender bias in AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@artfish?source=post_page---byline--45fa4fa72b75--------------------------------)[![Yennie
    Jun](../Images/b635e965f21c3d55833269e12e861322.png)](https://medium.com/@artfish?source=post_page---byline--45fa4fa72b75--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--45fa4fa72b75--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--45fa4fa72b75--------------------------------)
    [Yennie Jun](https://medium.com/@artfish?source=post_page---byline--45fa4fa72b75--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--45fa4fa72b75--------------------------------)
    ·13 min read·Mar 8, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4be5c2e1ab6b7d6b3ef431b480c37d45.png)'
  prefs: []
  type: TYPE_IMG
- en: Created using Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: '*This article was originally published on* [*art fish intelligence*](https://www.artfish.ai/p/gender-bias-in-ai-international-womens)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For International Women’s Day, I wanted to write a short article about gender
    bias in AI.
  prefs: []
  type: TYPE_NORMAL
- en: AI models reflect, and often exaggerate, existing gender biases from the real
    world. It is important to quantify such biases present in models in order to properly
    address and mitigate them.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I showcase a small selection of important work done (and currently
    being done) to uncover, evaluate, and measure different aspects of gender bias
    in AI models. I also discuss the implications of this work and highlight a few
    gaps I’ve noticed.
  prefs: []
  type: TYPE_NORMAL
- en: But what even is bias?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All of these terms (”gender”, “bias”, and “AI”) can be somewhat overused and
    ambiguous.
  prefs: []
  type: TYPE_NORMAL
- en: “Gender”, within the context of AI research, typically encompasses binary man/woman
    (because it is easier for computer scientists to measure) with the occasional
    “neutral” category. “AI” refers to machine learning systems trained on human-created
    data and encompasses both statistical models like word embeddings and modern Transformer-based
    models like…
  prefs: []
  type: TYPE_NORMAL
