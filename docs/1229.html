<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A Whimsical Journey Through Wait Times</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>A Whimsical Journey Through Wait Times</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-whimsical-journey-through-wait-times-b02a41d337fc?source=collection_archive---------9-----------------------#2024-05-15">https://towardsdatascience.com/a-whimsical-journey-through-wait-times-b02a41d337fc?source=collection_archive---------9-----------------------#2024-05-15</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="7108" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">From Microwave Countdowns to Never-Ending Call Holds, with Python</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@carlmkadie?source=post_page---byline--b02a41d337fc--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Carl M. Kadie" class="l ep by dd de cx" src="../Images/9dbe27c76e9567136e5a7dc587f1fb15.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*RGViuuvF-_GQ-LXuVDQN7w.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--b02a41d337fc--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@carlmkadie?source=post_page---byline--b02a41d337fc--------------------------------" rel="noopener follow">Carl M. Kadie</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--b02a41d337fc--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">16 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/f115c1bd71d609d4441bd795efbdcef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QfMUB-T1cV5lCcle2ybc0A.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Waiting “on hold”, for popcorn, and for a lottery win — Source: <a class="af nc" href="https://openai.com/dall-e-2/" rel="noopener ugc nofollow" target="_blank">https://openai.com/dall-e-2/</a>. All other figures from the author.</figcaption></figure><p id="4e88" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Ever notice how microwave oven minutes march steadily toward zero, yet phone hold minutes stretch into eternity?</p><p id="91ff" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Consider this: barely a minute into microwaving your popcorn, you’re gathering bowls to be ready to serve. But a minute into a call hold? You’re wondering if you’ll ever speak to a human again. Fast forward 10 minutes, and you are enjoying your popcorn. But on the phone? The hold music has become the soundtrack for an endless purgatory.</p><p id="7401" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And lurking in a twilight zone between waiting for popcorn and waiting on hold … your weekly lottery ticket. You wait for a win. Each week’s new ticket holds a fresh promise, a promise untouched by previous weekly disappointments.</p><p id="eac3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To summarize, there appears to be three disparate types of waiting:</p><ul class=""><li id="3390" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob bk">“On Hold”-Type — The longer you’ve waited, the longer you expect to wait.</li><li id="d8bd" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">“Popcorn”-Type — The longer you’ve waited, the less you expect to wait.</li><li id="adec" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">“Lottery Win”-Type — Regardless of your wait so far, your expected wait remains the same.</li></ul><p id="62ee" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Are these disparities in wait-times genuine, or a trick of the mind? We’ll answer this question in two parts.</p><ul class=""><li id="f575" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Part 1 — Analyzing Data</li><li id="6c79" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Part 2 — Modeling Data</li></ul><p id="1d48" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For each part, we’ll look at each type of waiting, alternating between detailed Python code and a discussion. If you are interested in Python, read the code sections. If you are only interested in learning about wait times, you may skip over the code.</p></div></div></div><div class="ab cb oh oi oj ok" role="separator"><span class="ol by bm om on oo"/><span class="ol by bm om on oo"/><span class="ol by bm om on"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><blockquote class="op"><p id="4ec0" class="oq or fq bf os ot ou ov ow ox oy ny dx">Part 1: Analyzing Data</p></blockquote><h1 id="d2d8" class="oz pa fq bf pb pc pd gq pe pf pg gt ph pi pj pk pl pm pn po pp pq pr ps pt pu bk">“On Hold”-Type Waits — The longer you’ve waited, the longer you expect to wait.</h1><p id="1966" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">We’d like to start with data, but I don’t have data for “on hold” times. So, instead, how about the time between edits of a computer file? One place that I see such edit times is on Wikipedia.</p><p id="74dc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Suppose I place you on a Wikipedia page. Can you look at just the time since the last edit and predict how long until the next edit?</p><blockquote class="qa qb qc"><p id="ddf9" class="nd ne qd nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Aside 1: No fair editing the page yourself.<br/>Aside 2: Analogously, if I somehow place you “on hold” for some number of minutes (so far), can you predict how much longer until the call is re-connected?</p></blockquote><p id="3459" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For Wikipedia page edits, how might you express your prediction of the time until the next edit? You could try to predict the <strong class="nf fr">exact </strong>moment of the next edit, for example: “I predict this page will next be edited in exactly 5 days, 3 hours, 20 minutes” That, however, seems too specific, and you’d nearly always be wrong.</p><p id="6112" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">You could predict a range of times: “I predict this page will be next edited sometime between now and 100 years from now”. That would nearly always be right but is vague and uninteresting.</p><p id="ee24" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A more practical prediction takes the form of the “median next-edit time”. You might say: “I predict a 50% chance that this page will be edited within the next 5 days, 3 hours, 20 minutes.” I, your adversary, would then pick “before” or “after”. Suppose I think the real median next-edit time is 3 days. I would then pick “before”. We then wait up to 5 days, 3 hours, 20 minutes. If anyone (again, other than us) edits the page in that time, I get a point; otherwise, you get a point. With this scoring system, if you’re a better predictor than I, you should earn more points.</p><p id="fdd9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s next dive into Python and see how we might make such predictions:</p><h2 id="447f" class="qe pa fq bf pb qf qg qh pe qi qj qk ph nm ql qm qn nq qo qp qq nu qr qs qt qu bk">“On Hold”-Type Waits — Python</h2><p id="b8c2" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">Consider the Wikipedia article about the artist Marie Cochran. We can look at the article’s <a class="af nc" href="https://en.wikipedia.org/w/index.php?title=Marie_Cochran&amp;action=history" rel="noopener ugc nofollow" target="_blank">revision history</a>:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qv"><img src="../Images/73cb643a251b40fd0dfd20c22cdb0e8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HI87lbwIeyibu9XnlP1ZSQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Screen capture from Wikipedia. Subsequent figures from author.</figcaption></figure><p id="a458" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To gather such data from various Wikipedia articles, I wrote a little Python script that:</p><ul class=""><li id="749d" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Picks a random English-language Wikipedia page via <code class="cx qw qx qy qz b"><a class="af nc" href="https://en.wikipedia.org/wiki/Special:Random" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Special:Random</a></code>.</li><li id="1919" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Goes to that page’s revision history, for example, <code class="cx qw qx qy qz b"><a class="af nc" href="https://en.wikipedia.org/w/index.php?title=Marie_Cochran&amp;action=history" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/w/index.php?title=Marie_Cochran&amp;action=history</a></code>.</li><li id="e980" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Pulls out the date and times of (up to the) last 50 edits. Times are to the resolution of a minute.</li><li id="3acd" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Creates lines made up of the article title, an edit time, and the time of the script’s run. All times use the UTC time zone. Tabs separate columns.</li><li id="dbd8" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Appends the lines to a file.</li></ul><blockquote class="qa qb qc"><p id="cdfe" class="nd ne qd nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Aside: This approach brings up several issues. First, in what sense <code class="cx qw qx qy qz b">Special:Random</code> random? I don’t know. For the purpose of this demonstration, it seems random enough. Why up-to-the-last 50 edits? Why not all the edits? Why not just the most recent edit? I don’t have a good reason beyond “up-to-the-last 50” is the default and works well enough for this article. Finally, why script against the regular Wikipedia server when we could instead retrieve the <strong class="nf fr">full</strong> edit history for <strong class="nf fr">all</strong> articles from <code class="cx qw qx qy qz b"><a class="af nc" href="https://dumps.wikimedia.org/" rel="noopener ugc nofollow" target="_blank">https://dumps.wikimedia.org</a></code>? Because we only need a sample. Also, writing this script was easy, but writing a program to process the full data would be hard. Sadly, I will not share the easy script because I don’t want to enable uncontrolled bots hitting the Wikipedia site. Happily, I am sharing on <a class="af nc" href="https://raw.githubusercontent.com/CarlKCarlK/wait-times/main/edit_history.txt" rel="noopener ugc nofollow" target="_blank">GitHub</a> all the data I collected. You may use it as you wish.</p></blockquote><p id="c874" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here is a fragment of the edit time data:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="b13f" class="rd pa fq qz b bg re rf l rg rh">Marie_Cochran 01:20, 8 January 2024 01:16, 08 February 2024<br/>Marie_Cochran 01:10, 27 September 2023 01:16, 08 February 2024<br/>Marie_Cochran 00:59, 12 September 2023 01:16, 08 February 2024<br/>Marie_Cochran 11:43, 2 November 2022 01:16, 08 February 2024<br/>...<br/>Marie_Cochran 19:20, 10 March 2018 01:16, 08 February 2024<br/>Peter_Tennant 15:03, 29 July 2023 01:16, 08 February 2024<br/>Peter_Tennant 21:39, 15 April 2022 01:16, 08 February 2024<br/>...</span></pre><p id="ecaa" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s read this into a Pandas dataframe and compute <code class="cx qw qx qy qz b">Time Delta</code>, the wait times between edits:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="bceb" class="rd pa fq qz b bg re rf l rg rh">import pandas as pd<br/><br/># Read the data<br/>wiki_df = pd.read_csv("edit_history.txt", sep='\t', header=None, names=["Title", "Edit DateTime", "Probe DateTime"], usecols=["Title", "Edit DateTime"])<br/>wiki_df['Edit DateTime'] = pd.to_datetime(wiki_df['Edit DateTime']) # text to datetime<br/><br/># Sort the DataFrame by 'Title' and 'Edit DateTime' to ensure the deltas are calculated correctly<br/>wiki_df.sort_values(by=['Title', 'Edit DateTime'], inplace=True)<br/><br/># Calculate the time deltas for consecutive edits within the same title<br/>wiki_df['Time Delta'] = wiki_df.groupby('Title')['Edit DateTime'].diff()<br/>wiki_df.head()</span></pre><p id="47e8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The resulting Pandas dataframe starts with the alphabetically-first article (among those sampled). That article tells readers about <a class="af nc" href="https://en.wikipedia.org/wiki/%C3%96nd%C3%B6r_Gongor" rel="noopener ugc nofollow" target="_blank">Öndör Gongor</a>, a very tall person from Mongolia:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ri"><img src="../Images/f684364a802b3584aa6e528df26fefb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*UdUYMOvo6_D726fOaGsapA.png"/></div></figure><p id="d429" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Within that article’s last 50 edits, we first see an edit on January 27th, 2008, at 3:13 PM (UTC). We next see an edit 16 minutes later. The edit after that occurs within a minute (the limit of the data’s resolution) and so shows <code class="cx qw qx qy qz b">0 days 00:00:00</code>.</p><p id="7ee1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Continuing our processing, let’s drop the <code class="cx qw qx qy qz b">NaT</code> (not-a-time) rows that appear at the start of each article. We’ll also sort by the wait times and reset Panda’s index:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="0c18" class="rd pa fq qz b bg re rf l rg rh"># Remove rows with not-a-time (NaT) values in the 'Time Delta' column<br/>wiki_df.dropna(subset=['Time Delta'], inplace=True)<br/># Sort by time delta and reset the index<br/>wiki_df.sort_values(by='Time Delta', inplace=True)<br/>wiki_df.reset_index(drop=True, inplace=True)<br/>display(wiki_df)<br/>wiki_df['Time Delta'].describe()</span></pre><p id="421d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This produces a dataframe that start and ends like this:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rj"><img src="../Images/4a429039bac77612e79f5cd06d2c6745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*1U03rTBAuwoGE7JlhAYmwg.png"/></div></figure><p id="a9dd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">with this statistical summary:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="cee0" class="rd pa fq qz b bg re rf l rg rh">count                          36320<br/>mean      92 days 13:46:11.116189427<br/>std      195 days 11:36:52.016155110<br/>min                  0 days 00:00:00<br/>25%                  0 days 00:27:00<br/>50%                 15 days 05:41:00<br/>75%                100 days 21:45:45<br/>max               4810 days 17:39:00<br/></span></pre><p id="8a10" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We see that the sampled wait times vary from <code class="cx qw qx qy qz b">0 days 00:00:00</code> (so, less than a minute) to over 13 years. (The 13 year edit wait was for an article about <a class="af nc" href="https://en.wikipedia.org/wiki/The_Rotunda_(Longwood_University)" rel="noopener ugc nofollow" target="_blank">a building at a Virginia university</a>.) One quarter of the edits happen within 27 minutes of a previous edit. The median time between edits is just over 15 days.</p><p id="e82c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Before we go farther, I want to improve the display of wait times with a little function:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="f176" class="rd pa fq qz b bg re rf l rg rh">def seconds_to_text(seconds):<br/>    seconds = round(seconds)<br/>    result = []<br/>    for unit_name, unit_seconds in [('y', 86400 * 365.25),('d', 86400),('h', 3600),('m', 60),('s', 1)]:<br/>        if seconds &gt;= unit_seconds:<br/>            unit_value, seconds = divmod(seconds, unit_seconds)<br/>            result.append(f"{int(unit_value)}{unit_name}")<br/>    return ' '.join(result) if result else "&lt;1s"<br/><br/>seconds_to_text(100)</span></pre><p id="6863" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The <code class="cx qw qx qy qz b">seconds_to_text</code> function displays 100 seconds as <code class="cx qw qx qy qz b">'1m 40s'</code>.</p><p id="8e72" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">With this we can construct a “wait wait” table for the Wikipedia data. Given the wait so far for the next edit on an article, the table tells our median additional wait. (Recall that “median” means that half the time, we expect to wait less than this time for an edit. The other half of the time, we expect to wait more than this time.)</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="d603" class="rd pa fq qz b bg re rf l rg rh">import numpy as np<br/><br/>def wait_wait_table(df, wait_ticks):<br/>    sorted_time_deltas_seconds = df['Time Delta'].dt.total_seconds()<br/>    results = []<br/>    for wait_tick in wait_ticks:<br/>        greater_or_equal_values = sorted_time_deltas_seconds[sorted_time_deltas_seconds &gt;= wait_tick]<br/>        median_wait = np.median(greater_or_equal_values)<br/>        additional_wait = median_wait - wait_tick<br/>        results.append({"Wait So Far": seconds_to_text(wait_tick), "Median Additional Wait": seconds_to_text(additional_wait)})<br/>    return pd.DataFrame(results)<br/><br/>wiki_wait_ticks = [0, 60, 60*5, 60*15, 3600, 3600*4, 86400, 86400 * 7,86400 * 30, 86400 * 100, 86400 * 365.25, 86400 * 365.25 * 5, 86400 * 365.25 * 10]<br/>wiki_wait_tick_labels = [seconds_to_text(wait_tick) for wait_tick in wiki_wait_ticks]<br/>wait_wait_table(wiki_df, wiki_wait_ticks).style.hide(axis="index")</span></pre><p id="cca6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We’ll discuss the output of this table next.</p><h2 id="c6f6" class="qe pa fq bf pb qf qg qh pe qi qj qk ph nm ql qm qn nq qo qp qq nu qr qs qt qu bk">“On Hold”-Type Waits — Discussion</h2><p id="ce46" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">The preceding Python code produces this table. Call it a “wait-wait” table.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rk"><img src="../Images/7a64fcdaa5c9e78090147ec0fe2295f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*gARQIdw-2hnuD7Nbf34P8g.png"/></div></figure><p id="a598" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The table says that if we haven’t waited at all (in other words, someone just edited the page), we can anticipate the next edit in just over 15 days. However, if after a minute, no one has edited the article again, we can anticipate a wait of 19 days. Thus, waiting one minute leads to almost 4 days more of additional expected waiting. If, after one hour, no one has edited the article, our anticipated additional wait more-than-doubles to 47 days.</p><blockquote class="qa qb qc"><p id="7253" class="nd ne qd nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Aside: When I use the term ‘anticipate’ in this context, I’m referring to the median waiting time derived from our historical data. In other words, based on past trends, we bet that half of the very next edits will occur sooner than this time frame, and half will occur later.</p></blockquote><p id="c8dc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">One way to think about this phenomenon: When we start our wait for the next edit, we don’t know what kind of page we are on. Is this an article about a hot pop-culture topic such as <code class="cx qw qx qy qz b"><a class="af nc" href="https://en.wikipedia.org/w/index.php?title=Taylor_Swift&amp;action=history" rel="noopener ugc nofollow" target="_blank">Taylor Swift</a></code>? Or is this an article about a niche, slow-moving topic such as <a class="af nc" href="https://en.wikipedia.org/w/index.php?title=The_Rotunda_%28Longwood_University%29&amp;action=history" rel="noopener ugc nofollow" target="_blank">The Rotunda, a building at a 5000-student university</a>. With every minute that passes without an edit, the probabilities shift from this being a Taylor-Swift-like article and toward a The-Rotunda-like article.</p><p id="b7c4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Likewise, when we call customer service and are put on hold — at the start we don’t know what kind of customer service we are waiting on. With every passing minute, however, we learn that we are likely waiting for poor, slow customer service. Our anticipated additional wait, thus, grows.</p><p id="1b6f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Up to this point, we have used the data directly. We can also try to model the data with a probability distribution. Before we move to modeling, however, let’s look at our other two examples: microwaving popcorn and waiting for a lotto win.</p><h1 id="a7bf" class="oz pa fq bf pb pc pd gq pe pf pg gt ph pi rl pk pl pm rm po pp pq rn ps pt pu bk">“Popcorn”-type Waits — The longer you’ve waited, the less you expect to wait.</h1><p id="f7af" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">Let’s apply the techniques from waiting for Wikipedia edits to waiting for microwave popcorn. Rather than collecting real data (as delicious as that might be), I’m content to simulate data. We’ll use a random number generator. We assume that the time to cook, perhaps based on a sensor, is 5 minutes plus or minus 15 seconds.</p><h2 id="9311" class="qe pa fq bf pb qf qg qh pe qi qj qk ph nm ql qm qn nq qo qp qq nu qr qs qt qu bk">“Popcorn”-type Waits — Python</h2><p id="ea2c" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">Specifically in Python:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="a38c" class="rd pa fq qz b bg re rf l rg rh">seed = 0<br/>rng = np.random.default_rng(seed)<br/>sorted_popcorn_time_deltas = np.sort(rng.normal(5*60, 15, 30_000))<br/>popcorn_df = pd.DataFrame(pd.to_timedelta(sorted_popcorn_time_deltas,unit="s"), columns=["Time Delta"])<br/>print(popcorn_df.describe())</span></pre><p id="526b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Which produces a Panda dataframe with this statistical summary:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="d6e9" class="rd pa fq qz b bg re rf l rg rh">                      Time Delta<br/>count                      30000<br/>mean   0 days 00:05:00.060355606<br/>std    0 days 00:00:14.956424467<br/>min    0 days 00:03:52.588244397<br/>25%    0 days 00:04:50.011437922<br/>50%    0 days 00:04:59.971380399<br/>75%    0 days 00:05:10.239357827<br/>max    0 days 00:05:59.183245298</span></pre><p id="74f2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As expected, when generating data from this normal distribution, the mean is 5 minutes, and the standard deviation is about 15 seconds. Our simulated waits range from 3 minutes 52 seconds to 6 minutes.</p><p id="fc96" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We can now generate a “wait-wait” table:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="e902" class="rd pa fq qz b bg re rf l rg rh">wait_wait_table(popcorn_df, [0, 10, 30, 60, 2*60, 3*60, 4*60, 5*60]).style.hide(axis="index")</span></pre><h2 id="3ecf" class="qe pa fq bf pb qf qg qh pe qi qj qk ph nm ql qm qn nq qo qp qq nu qr qs qt qu bk">“Popcorn”-type Waits — Discussion</h2><p id="e661" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">Our “wait-wait” table for popcorn looks like this:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ro"><img src="../Images/04468d41f7961a6b20b39e48fa20a444.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*94ie2ENEedhzZKY4uYLZRA.png"/></div></figure><p id="de5b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Our table says that at the beginning, we expect a 5-minute wait. After we wait for 10 seconds, our additional expected wait falls exactly 10 seconds (to 4 minutes 50 seconds). After we wait one minute, our additional wait falls to 4 minutes and so on. At 5 minutes, the anticipated additional wait continues to go down (but not to zero).</p><p id="a0c3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In a later section, we’ll see how to model this data. For now, let’s look next at waiting for a lottery win.</p><h1 id="9ff6" class="oz pa fq bf pb pc pd gq pe pf pg gt ph pi rl pk pl pm rm po pp pq rn ps pt pu bk">“Lottery Win”-Style Waits — Regardless of your wait so far, your expected wait remains the same.</h1><p id="45bd" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">For lottery data, I’m again comfortable creating simulated data. The Washington State Lotto offers odds of 1 to 27.1 for a win. (The most common win, pays $3 for a $1 bet.) Let’s play the lotto for 1 million weeks (about 19,000 years) and collect data on our waits between wins.</p><h2 id="e0df" class="qe pa fq bf pb qf qg qh pe qi qj qk ph nm ql qm qn nq qo qp qq nu qr qs qt qu bk">“Lottery Win”-Style Waits — Python</h2><p id="a3aa" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">We simulate 1 million weeks of lotto play:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="ba23" class="rd pa fq qz b bg re rf l rg rh">seed = 0<br/>rng = np.random.default_rng(seed)<br/>last_week_won = None<br/>lotto_waits = []<br/>for week in range(1_000_000):<br/>    if rng.uniform(high=27.1) &lt; 1.0:<br/>        if last_week_won is not None:<br/>            lotto_waits.append(week - last_week_won)<br/>        last_week_won = week<br/>sorted_lotto_time_deltas = np.sort(np.array(lotto_waits) * 7 * 24 * 60 * 60)<br/>lotto_df = pd.DataFrame(pd.to_timedelta(sorted_lotto_time_deltas,unit="s"), columns=["Time Delta"])<br/>print(lotto_df.describe())</span></pre><pre class="rp ra qz rb bp rc bb bk"><span id="e19c" class="rd pa fq qz b bg re rf l rg rh">                        Time Delta<br/>count                        36773<br/>mean   190 days 08:21:00.141951976<br/>std    185 days 22:42:41.462765808<br/>min                7 days 00:00:00<br/>25%               56 days 00:00:00<br/>50%              133 days 00:00:00<br/>75%              259 days 00:00:00<br/>max             2429 days 00:00:00</span></pre><p id="3fe4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Our shortest possible interval between wins is 7 days. Our longest simulated dry spell is over 6 years. Our median wait is 133 days.</p><p id="095e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We generate the “wait-wait” table with:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="2ff5" class="rd pa fq qz b bg re rf l rg rh">lotto_days = [0, 7, 7.00001,  2*7, 4*7, 183, 365.25, 2*365.25, 5*365.25]<br/>lotto_waits = [day * 24 * 60 * 60 for day in lotto_days]<br/>wait_wait_table(lotto_df, lotto_waits).style.hide(axis="index")</span></pre><h2 id="494c" class="qe pa fq bf pb qf qg qh pe qi qj qk ph nm ql qm qn nq qo qp qq nu qr qs qt qu bk">“Lottery Win”-Style Waits — Discussion</h2><p id="d57b" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">Here is the “wait-wait” table:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rq"><img src="../Images/091b3e4d2b53a58d7f313e50ed5b2d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*bvmfNpAf4o1GiXgNFHoTqA.png"/></div></figure><p id="0411" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The table shows that the lotto doesn’t care how long we’ve waited for a win. Whether we just won (<code class="cx qw qx qy qz b">Wait So Far &lt; 1s</code>) or haven’t won for a year, our anticipated additional wait until our next win is almost always between 126 days and 133 days.</p><p id="2ee8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Three entries on the table might seem strange. What do you think is going on at <code class="cx qw qx qy qz b">7d</code> and <code class="cx qw qx qy qz b">7d 1s</code>? Why does the additional wait jump, almost instantly from 126 days to about 133 days? The answer is at the moment of the weekly drawing, the minimum wait for a win shifts from 0 days to 7 days. And what about <code class="cx qw qx qy qz b">5y</code>? Is this showing that if we wait 5 years, we can anticipate a win in just 50 days, much less than the usual 133 days? Sadly, no. Rather it shows the limitation of our data. In the data, we only see 5-year waits three times:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="244e" class="rd pa fq qz b bg re rf l rg rh">lotto_df[lotto_df["Time Delta"] &gt; pd.to_timedelta(24*60*60 * 365.25 * 5, unit="s")]</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rr"><img src="../Images/5d73f7a2e2968fecd5ad995b1a9d3498.png" data-original-src="https://miro.medium.com/v2/resize:fit:338/format:webp/1*HMybit9YQZ9cfwKkHIrGgw.png"/></div></figure><p id="8082" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Three values lead to a noisy estimate of the median.</p></div></div></div><div class="ab cb oh oi oj ok" role="separator"><span class="ol by bm om on oo"/><span class="ol by bm om on oo"/><span class="ol by bm om on"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="a3e4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To summarize what we’ve seen so far in real and simulated data:</p><ul class=""><li id="5b9b" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Wikipedia Edits —The longer you’ve waited, the longer you expect to wait</li><li id="6704" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Popcorn — The longer you’ve waited, the less you expect to wait</li><li id="5657" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Lottery Wins— Regardless of your wait so far, your expected wait remains the same</li></ul><p id="4077" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In the next section, we’ll look at the hows and (importantly) the whys of modeling. We’ll start with our lotto data.</p></div></div></div><div class="ab cb oh oi oj ok" role="separator"><span class="ol by bm om on oo"/><span class="ol by bm om on oo"/><span class="ol by bm om on"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><blockquote class="op"><p id="86de" class="oq or fq bf os ot ou ov ow ox oy ny dx">Part 2: Modeling Data</p></blockquote><p id="9814" class="pw-post-body-paragraph nd ne fq nf b go rs nh ni gr rt nk nl nm ru no np nq rv ns nt nu rw nw nx ny fj bk">In this part, we’ll try to find simple expressions for wait-time predictions. Such simplicity is not needed for predictions. What we’ve created so far, called an <em class="qd">empirical distribution</em>, works fine. A simpler expression can, however, be more convenient. Also, it may make comparisons between different types of waits easier to understand.</p><p id="f88f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We will proceed by looking at our three examples starting with the simplest (Lottery Wins) to the most complex (Wikipedia Edits). As before, I’ll alternate between Python code (that you can skip over) and discussion.</p><p id="0715" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We’ll start by adding a cumulative distribution column to our three wait-time dataframes. Recall that we previously sorted the dataframes by <code class="cx qw qx qy qz b">Time Delta</code>.</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="ac20" class="rd pa fq qz b bg re rf l rg rh">wiki_df['CDF'] = wiki_df['Time Delta'].rank(pct=True)<br/>popcorn_df['CDF'] = popcorn_df['Time Delta'].rank(pct=True)<br/>lotto_df['CDF'] = lotto_df['Time Delta'].rank(pct=True)<br/>wiki_df</span></pre><p id="6f0e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The column labeled <code class="cx qw qx qy qz b">CDF</code>, for cumulative distribution function, contains values near 0.0 for the shortest wait times and a value of 1.0 for the longest wait time. In other words, it is the rank of each row expressed as a fraction. The Wikipedia dataframe now looks like:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rx"><img src="../Images/f87f0a93e618e63753f80656682b2bfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*kuTOVEWhRtPEge2_PFyalw.png"/></div></figure><p id="ab77" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We can now plot <code class="cx qw qx qy qz b">CDF</code> (y-axis) vs. the wait time <code class="cx qw qx qy qz b">Time Delta</code> (x-axis). Here is some plotting code in Python:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="6e5a" class="rd pa fq qz b bg re rf l rg rh">import matplotlib.pyplot as plt<br/><br/>def wait_cdf(title, sorted_df, wait_ticks, dist=None, dist_label=None, left=None, right=None, xscale='linear'):<br/>    wait_seconds = sorted_df['Time Delta'].dt.total_seconds() # x values<br/>    cdf = sorted_df['CDF'] # y values<br/><br/>    left = left or wait_seconds.min()<br/>    right = right or wait_seconds.max()<br/><br/>    plt.figure(figsize=(10, 6))<br/>    plt.title(title + ' Cumulative Distribution Function (CDF)')<br/>    plt.plot(wait_seconds, cdf, marker='.', linestyle=" ", label='Empirical CDF')<br/><br/>    if dist is not None:<br/>        dist_x = np.logspace(np.log10(left), np.log10(right), 100) if xscale == 'log' else np.linspace(left, right, 100)<br/>        dist_y = dist.cdf(dist_x)<br/>        plt.plot(dist_x, dist_y, label = dist_label)<br/><br/>    plt.xlabel('Wait')<br/>    plt.ylabel('CDF')<br/>    plt.xscale(xscale)<br/>    plt.xticks(wait_ticks, [seconds_to_text(wait_tick) for wait_tick in wait_ticks], rotation=45)<br/>    plt.xlim(left=left, right=right)<br/>    plt.grid(True, which="both", ls="--")<br/>    plt.legend(loc='upper left')<br/>    plt.show()<br/><br/>wait_cdf("Lottery Wins", lotto_df, wiki_wait_ticks, xscale='log')</span></pre><p id="c6b3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here is the CDF plot of Lottery Wins with wait time on a log scale:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ry"><img src="../Images/eba178ed8ad2f3e946719a620171f932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VmfJdR4cptgBhs4zRf4zdw.png"/></div></div></figure><p id="1b38" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The curve looks simple so let’s try to fit a simple curve to it. The obvious candidate curve is the exponential distribution. It’s the simplest common function related to wait times.</p><p id="1c2a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Python’s <code class="cx qw qx qy qz b">scipy.stats</code> package makes it easy to fit an exponential curve to our data and to represent the resulting curve as a Python object, here named <code class="cx qw qx qy qz b">lotto_expon_dist</code>.</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="c9b8" class="rd pa fq qz b bg re rf l rg rh">from scipy.stats import expon<br/><br/>_, lotto_e_scale = expon.fit(lotto_df['Time Delta'].dt.total_seconds(), floc=0)<br/>lotto_expon_dist = expon(scale=lotto_e_scale)<br/>print(f"Lottery wins exponential median is {seconds_to_text(lotto_expon_dist.median())}. The scale parameter is {seconds_to_text(lotto_e_scale)}.")</span></pre><p id="4276" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This code prints:</p><p id="ceb8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><code class="cx qw qx qy qz b">Lottery wins exponential median is 131d 22h 32m 20s. The scale parameter is 190d 8h 21m.</code></p><p id="ba55" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The median of the fitted curve, about 132 days, is close to the empirical median of 133 days. By convention, we parameterize an exponential curve with a single number, here called <code class="cx qw qx qy qz b">scale</code>. It corresponds to the mean of the distribution, but we can easily determine median from mean and vice versa.</p><p id="f557" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here is a plot of the empirical CDF and fitted CDF for Lottery Wins:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="8a74" class="rd pa fq qz b bg re rf l rg rh">lotto_expon_label = f'ExponentialDistribution(scale={seconds_to_text(lotto_e_scale)})'<br/>wait_cdf("Lottery Wins", lotto_df, wiki_wait_ticks, dist=lotto_expon_dist, dist_label=lotto_expon_label, xscale='log')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ry"><img src="../Images/b6e0a0cf0a28750d18f06ed80a26079d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8EjB5xnHLGaoQcTpZi4PuA.png"/></div></div></figure><p id="b372" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">They match closely. The slight mismatch on the left is caused by the instant 7-day jump at the moment of the lottery drawing. We’ll ignore this tiny mismatch in this article.</p><p id="11b7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Exponential works well on our (simulated) lottery win data. Let’s see how it works on our Popcorn and Wikipedia data. Here is the code to fit an exponential distribution to these dataframes.</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="6b58" class="rd pa fq qz b bg re rf l rg rh">_, popcorn_e_scale = expon.fit(popcorn_df['Time Delta'].dt.total_seconds(), floc=0)<br/>popcorn_expon_dist = expon(scale=popcorn_e_scale)<br/>print(f"Popcorn exponential median is {seconds_to_text(popcorn_expon_dist.median())}")<br/>popcorn_expon_label = f'ExponentialDistribution(scale={seconds_to_text(popcorn_e_scale)})'<br/>wait_cdf("Popcorn", popcorn_df, popcorn_ticks, dist=popcorn_expon_dist, dist_label=popcorn_expon_label, left=10, right=6*60, xscale='linear' )<br/><br/>_, wiki_e_scale = expon.fit(wiki_df['Time Delta'].dt.total_seconds(), floc=0)<br/>wiki_expon_dist = expon(scale=wiki_e_scale)<br/>print(f"Wiki exponential median is {seconds_to_text(wiki_expon_dist.median())}")<br/>wiki_expon_label = f'ExponentialDistribution(scale={seconds_to_text(wiki_e_scale)})'<br/>wait_cdf("Wiki Edits", wiki_df, wiki_wait_ticks, dist=wiki_expon_dist, dist_label=wiki_expon_label, xscale='log', left=60)</span></pre><p id="0c78" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And here are the plots:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rz"><img src="../Images/83422f297200848b69f412cce3ecb918.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S5q_itBeQugmOPqHn4xBxg.png"/></div></div></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ry"><img src="../Images/c9442dbe769a11121b8f180276b80f6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xr2Hb9BsxHX_xch42aH4Og.png"/></div></div></figure><p id="0248" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Yikes, these curve fits are terrible! The problem is that exponential distributions <em class="qd">only</em> model “Lottery-Win”-like data. Specifically, waits in which regardless of your wait so far, your expected wait remains the same. Because the exponential distribution fits waits that ignore your wait so far, it is called <em class="qd">memoryless</em>. Moreover, among continuous distributions, the exponential distribution is the <em class="qd">only</em> memoryless distribution.</p><p id="c3fc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">But what if we need our distribution to have memory? The next simplest distribution to try is the Weibull distribution.</p><p id="9220" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Two parameters, <code class="cx qw qx qy qz b">shape</code> and <code class="cx qw qx qy qz b">scale</code> parameterize a Weibull. Let’s give it a try starting with the lottery data:</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="385a" class="rd pa fq qz b bg re rf l rg rh">from scipy.stats import weibull_min<br/><br/>lotto_shape, _, lotto_w_scale = weibull_min.fit(lotto_df['Time Delta'].dt.total_seconds(), floc=0)<br/>lotto_weibull_dist = weibull_min(c=lotto_shape,scale=lotto_w_scale)<br/><br/>print(f"Lottery Wins Weibull median is {seconds_to_text(lotto_weibull_dist.median())}")<br/>lotto_weibull_label = f'WeibullDistribution(shape={lotto_shape:.3},scale={seconds_to_text(lotto_w_scale)})'<br/>wait_cdf("Lottery Wins", lotto_df, wiki_wait_ticks, dist=lotto_weibull_dist, dist_label=lotto_weibull_label, xscale='log')</span></pre><p id="b594" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This produces a fitted curve that looks like the exponential. Indeed, when <code class="cx qw qx qy qz b">shape</code> is 1, a Weibull distribution <strong class="nf fr">is</strong> an exponential distribution. Here shape is 1.06.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ry"><img src="../Images/de58306913bf8afdcc66e9fc78bd423f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pam5J-PRS78PDTfVVoUibA.png"/></div></div></figure><p id="3666" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">What happens when we try to fit a Weibull to our Popcorn data?</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="6f4c" class="rd pa fq qz b bg re rf l rg rh">popcorn_shape, _, popcorn_w_scale = weibull_min.fit(popcorn_df['Time Delta'].dt.total_seconds(), floc=0)<br/>popcorn_weibull_dist = weibull_min(c=popcorn_shape, scale=popcorn_w_scale)<br/>print(f"Popcorn Weibull median is {seconds_to_text(popcorn_weibull_dist.median())}")<br/>popcorn_df_weibull_label = f'Weibull(shape={popcorn_shape:.3}, scale={seconds_to_text(popcorn_w_scale)})'<br/>wait_cdf("Popcorn", popcorn_df, popcorn_ticks, dist=popcorn_weibull_dist, dist_label=popcorn_df_weibull_label, left=3*60, right=7*60, xscale='linear')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rz"><img src="../Images/fcfbcaf877b73111e0f8e805369e1232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TiRCOYa28Rvf44wlK9jq6A.png"/></div></div></figure><p id="a766" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">While not perfect, this fit is much better than the exponential’s fit. Notice the shape parameter’s value of 20. When a Weibull’s shape parameter is greater than 1, it indicates: “the longer you’ve waited, the less you expect to wait”.</p><p id="db8f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Finally, let’s try the Weibull on the Wikipedia data.</p><pre class="mm mn mo mp mq ra qz rb bp rc bb bk"><span id="aa8f" class="rd pa fq qz b bg re rf l rg rh">wiki_shape, _, wiki_w_scale = weibull_min.fit(wiki_df['Time Delta'].dt.total_seconds(), floc=0)<br/>wiki_weibull_dist = weibull_min(c=wiki_shape, scale=wiki_w_scale)<br/>print(f"Wiki Weibull median is {seconds_to_text(wiki_weibull_dist.median())}")<br/>wiki_df_weibull_label = f'Weibull(shape={wiki_shape:.3},scale={seconds_to_text(wiki_w_scale)})'<br/>wait_cdf("Wiki Edits", wiki_df, wiki_wait_ticks, dist=wiki_weibull_dist, dist_label=wiki_df_weibull_label, xscale='log', left=60)</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ry"><img src="../Images/507d924fff7d2bc30c6aeca9d9d54958.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ks5agqOpCdbQXU-uGY4ZaA.png"/></div></div></figure><p id="f3b7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This curve fit is less than perfect, but still much better than the exponential’s fit. Notice the shape parameter value of 0.292. When a Weibull’s shape parameter is less than 1 that indicates that “the longer you’ve waited, the longer you expect to wait”. However, the Weibull is not unique in this. An infinite number of distributions also have this property. Indeed, the empirical Wikipedia distribution has this property but is not a Weibull.</p><blockquote class="qa qb qc"><p id="96ab" class="nd ne qd nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Aside: I don’t know of a better simple model for the Wikipedia data. The empirical curve looks only a little more complicated than the Weibull. Perhaps we just need to identify (or invent) a slightly more general distribution with one or two additional parameters.</p></blockquote></div></div></div><div class="ab cb oh oi oj ok" role="separator"><span class="ol by bm om on oo"/><span class="ol by bm om on oo"/><span class="ol by bm om on"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="2acf" class="oz pa fq bf pb pc sa gq pe pf sb gt ph pi sc pk pl pm sd po pp pq se ps pt pu bk">Conclusion</h1><p id="c6d1" class="pw-post-body-paragraph nd ne fq nf b go pv nh ni gr pw nk nl nm px no np nq py ns nt nu pz nw nx ny fj bk">In conclusion, you and I are not (necessarily) crazy.</p><p id="58c2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We have seen that there really are situations for which the longer you have waited, the longer you should expect to wait. We see it empirically in the times between Wikipedia edits. We also see it in the Weibull distribution when the shape parameter is less than 1.</p><p id="d1f5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Likewise, for some other waits, “The longer you’ve waited, the less you expect to wait”. We see that for popcorn. We also see it in the Weibull distribution when the shape parameter is greater than 1.</p><p id="2e56" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Finally, there exists a third class of waits: memoryless. For these, regardless of your wait so far, your expected wait remains the same. We saw this with the time between lottery wins. It also corresponds to a Weibull distribution with a shape parameter of 1 (which is the same as an exponential distribution).</p><p id="83d1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When you have wait data to analyze, I recommend trying a Weibull distribution. Python makes fitting such a curve easy. However, if your data doesn’t fit the Weibull well, don’t use the Weibull. Instead, let your data speak for itself by using your empirical distribution directly.</p><p id="41d4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Thank you for joining me on this journey into wait times. I hope you now better understand wait times and their analysis.</p><p id="cece" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="qd">Please </em><a class="af nc" href="https://medium.com/@carlmkadie" rel="noopener"><em class="qd">follow Carl on Medium</em></a><em class="qd">. I write on scientific programming in Rust and Python, machine learning, and statistics. I tend to write about one article per month.</em></p></div></div></div></div>    
</body>
</html>