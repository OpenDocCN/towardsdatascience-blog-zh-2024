- en: Leveraging Large Language Models for Business Efficiency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用大语言模型提升商业效率
- en: 原文：[https://towardsdatascience.com/leveraging-large-language-models-for-business-efficiency-b06cb943a286?source=collection_archive---------2-----------------------#2024-03-01](https://towardsdatascience.com/leveraging-large-language-models-for-business-efficiency-b06cb943a286?source=collection_archive---------2-----------------------#2024-03-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/leveraging-large-language-models-for-business-efficiency-b06cb943a286?source=collection_archive---------2-----------------------#2024-03-01](https://towardsdatascience.com/leveraging-large-language-models-for-business-efficiency-b06cb943a286?source=collection_archive---------2-----------------------#2024-03-01)
- en: 'Implementing Large Language Models for Business Improvement: A Step-by-Step
    Guide'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施大语言模型提升商业改善：逐步指南
- en: '[](https://medium.com/@benoit_courty?source=post_page---byline--b06cb943a286--------------------------------)[![Benoît
    Courty](../Images/3c68e22acdb98c15c7fdd5a33be6d260.png)](https://medium.com/@benoit_courty?source=post_page---byline--b06cb943a286--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b06cb943a286--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b06cb943a286--------------------------------)
    [Benoît Courty](https://medium.com/@benoit_courty?source=post_page---byline--b06cb943a286--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@benoit_courty?source=post_page---byline--b06cb943a286--------------------------------)[![Benoît
    Courty](../Images/3c68e22acdb98c15c7fdd5a33be6d260.png)](https://medium.com/@benoit_courty?source=post_page---byline--b06cb943a286--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b06cb943a286--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b06cb943a286--------------------------------)
    [Benoît Courty](https://medium.com/@benoit_courty?source=post_page---byline--b06cb943a286--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b06cb943a286--------------------------------)
    ·15 min read·Mar 1, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b06cb943a286--------------------------------)
    ·15分钟阅读·2024年3月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '**TL;DR:** This article talks about how Large Language Models can improve your
    company process. Its target audience is people with technical backgrounds like
    software architects or CTO. The article shows the options to use LLM efficiently,
    you will learn how to use modern techniques like Retrieval Augmented Generation
    (RAG), function calling and fine-tuning with examples on a use case.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**TL;DR:** 本文讨论了大语言模型如何提升公司流程。目标读者是具有技术背景的人，如软件架构师或首席技术官（CTO）。文章展示了如何高效使用大语言模型（LLM），你将学习如何利用现代技术，如检索增强生成（RAG）、函数调用和微调，并通过案例学习应用。'
- en: Table of content
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 目录
- en: · [Identifying a Business Need](#46f5)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: · [识别商业需求](#46f5)
- en: · [Explore an idea by yourself](#e419)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: · [自己探索一个想法](#e419)
- en: · [Creating an Evaluation Dataset](#4336)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: · [创建评估数据集](#4336)
- en: · [Considering Internal Industrialization](#2e17)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: · [考虑内部工业化](#2e17)
- en: · [Customizing Responses with Company Data](#5f9c)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: · [通过公司数据定制响应](#5f9c)
- en: · [Function Calling to use APIs](#ef52)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: · [通过函数调用使用API](#ef52)
- en: · [Breaking Down Tasks into Multiple Prompts](#4391)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: · [将任务分解为多个提示](#4391)
- en: · [Fine-tuning to improve performance](#a809)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: · [通过微调提高性能](#a809)
- en: · [Combining Model](#0397)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: · [组合模型](#0397)
- en: · [Conclusion](#5549)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: · [结论](#5549)
- en: '![](../Images/2ff7d5145d86e9094d2342638cf3ce6d.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ff7d5145d86e9094d2342638cf3ce6d.png)'
- en: Photo by [Andrea De Santis](https://unsplash.com/@santesson89?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Andrea De Santis](https://unsplash.com/@santesson89?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In the rapidly evolving landscape of technology, Artificial Intelligence (AI)
    and Machine Learning (ML) have emerged as pivotal forces driving innovation, efficiency,
    and competitive advantage across industries. For Chief Technology Officers, IT
    Directors, Tech Project Managers, and Tech Product Managers, understanding and
    integrating these technologies into business strategies is no longer optional;
    it’s imperative.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速发展的技术环境中，人工智能（AI）和机器学习（ML）已成为推动创新、提高效率和竞争优势的关键力量，遍布各行各业。对于首席技术官（CTO）、IT总监、技术项目经理和技术产品经理来说，理解并将这些技术融入商业战略已不再是可选项，而是必须。
- en: It’s not a surprise, Large language Models (LLMs) like ChatGPT could do more
    than chat.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLM），如ChatGPT，能够做的不仅仅是聊天，这一点并不令人惊讶。
- en: We will explore step by step strategies to prevent data distortion, enhance
    operational efficiency, and better use your company’s resources.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将一步步探讨防止数据失真、提升操作效率并更好地利用贵公司资源的策略。
- en: Identifying a Business Need
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定业务需求
- en: You already know that Large Language Models (LLMs) such as ChatGPT, Gemini,
    Mistral, etc… have emerged as powerful tools that can automate tasks and enhance
    customer service. As a business decision-maker, understanding the capabilities
    and limitations of LLMs can help you make informed decisions about their implementation.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经知道，像ChatGPT、Gemini、Mistral等大型语言模型（LLMs）已成为强大的工具，可以自动化任务并提升客户服务。作为一名商业决策者，了解LLMs的能力与局限性将帮助您做出有关其实施的明智决策。
- en: The first step in leveraging LLMs is to identify a task that can be automated
    to improve customer service or relieve employees of repetitive tasks. For instance,
    LLMs can be used to automate information retrieval in documents, write reports,
    or process customer requests.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 利用大语言模型（LLMs）的第一步是识别一个可以自动化的任务，以改善客户服务或解放员工免于重复性任务。例如，LLMs可以用于自动化文档中的信息检索、撰写报告或处理客户请求。
- en: Explore an idea by yourself
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自己探索一个想法
- en: Once you have identified a business case, the next step is to manually evaluate
    this with ChatGPT (or Gemini) to estimate if the current reasoning capabilities
    of generative AI are sufficient to meet the need.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了业务需求，下一步是与ChatGPT（或Gemini）一起手动评估，估算当前生成性AI的推理能力是否足够满足需求。
- en: You can create a list of sample inputs and evaluate the accuracy of the responses
    generated by ChatGPT.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以创建一组示例输入，并评估ChatGPT生成的响应的准确性。
- en: Let’s say you want to automate the dispatching of emails your company receives.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您想要自动化公司收到的邮件分发。
- en: You have to get some emails and test if an online LLM is able to sort them and
    prepare an answer.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要获取一些邮件并测试在线LLM是否能够整理它们并准备回应。
- en: '![](../Images/532ebdc0bb344935bdbd2ff2c95786c5.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/532ebdc0bb344935bdbd2ff2c95786c5.png)'
- en: Photo by [Serhat Beyazkaya](https://unsplash.com/@serhatbeyazkaya?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Serhat Beyazkaya](https://unsplash.com/@serhatbeyazkaya?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Here is a sample prompt:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例提示：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Hi,
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你好，
- en: 'I hope this email finds you well. I am writing to request time off from work
    for the upcoming holiday season. Specifically, I would like to take the following
    days off:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这封邮件能找到您一切安好。我写信是为了申请在即将到来的假期期间休假。具体来说，我希望请以下几天假：
- en: Monday, December 20th
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 12月20日，星期一
- en: Tuesday, December 21st
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 12月21日，星期二
- en: Wednesday, December 22nd
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 12月22日，星期三
- en: Thursday, December 23rd
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 12月23日，星期四
- en: Friday, December 24th
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 12月24日，星期五
- en: I understand that this is a busy time of year for the company, and I apologize
    for any inconvenience my absence may cause. However, I have accrued enough vacation
    time to cover these days, and I believe that taking this time off will allow me
    to come back refreshed and ready to tackle the new year.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我理解这是公司一年中最忙碌的时段，对我的缺席可能会带来的不便表示歉意。然而，我已经积累了足够的假期时间来覆盖这些天，我相信请假将使我得以休息，并以充沛的精力迎接新的一年。
- en: Please let me know if there are any issues with my request, or if you need any
    additional information from me. Thank you for your time and consideration.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我的请求有任何问题，或者您需要我提供其他信息，请告知。感谢您的时间和考虑。
- en: Best regards, [Employee Name]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此致，敬礼，[员工姓名]
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The model answer:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 模型答案：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ⚠️ Don’t hesitate to iterate with your prompting until you get the intended
    form of response you want to reproduce. This could take some time to get used
    to it. Don’t stop at first failure, nor first success. Don’t hesitate to restart
    from scratch. You could even challenge the model to write a prompt for you.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 不要犹豫继续调整提示，直到得到您希望复现的响应形式。这可能需要一些时间去适应。不要因为第一次失败或第一次成功就停下脚步。不要犹豫从头再来，甚至可以挑战模型为您编写一个提示。
- en: ⚠️ Don’t forget to test edge cases, be sure to evaluate at least for 80% of
    your use case.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 不要忘记测试边缘情况，确保至少评估80%的使用案例。
- en: Creating an Evaluation Dataset
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建评估数据集
- en: It’s time to expand your test. Previously you proved that it worked with few
    examples, now try again with more data to measure the accuracy.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候扩大您的测试了。之前您已经证明它在少量示例下有效，现在请使用更多数据重新测试，以衡量准确度。
- en: Creating a dataset is essential to evaluate a process. You can use this dataset
    to test the model, ensuring that it meets your business needs. The dataset should
    be representative of the real-world scenarios that your business will encounter.
    Ideally, one should use code to create a reproducible evaluation chain. For example,
    by calling OpenAI’s API from a list of questions and automatically comparing expected
    answers.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 创建数据集对于评估一个过程至关重要。你可以使用这个数据集来测试模型，确保它满足你的业务需求。数据集应该代表你的业务可能遇到的真实世界场景。理想情况下，应该使用代码创建一个可重复的评估链。例如，通过从问题列表调用
    OpenAI 的 API，并自动比较预期的答案。
- en: With a ChatGPT subscription if you look at Explore GPTs you can also try Data
    Analyst to upload an Excel file and interact with the AI on it.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 ChatGPT 订阅，查看 Explore GPTs，你还可以尝试 Data Analyst 上传 Excel 文件并与 AI 进行交互。
- en: '**Compile an Email Dataset**: Start by assembling an Excel file containing
    100 sample emails that your company might receive.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编制电子邮件数据集**：首先组建一个包含 100 封样本电子邮件的 Excel 文件，这些是你的公司可能会接收到的邮件。'
- en: '**Draft a Detailed Prompt**'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**草拟详细提示**'
- en: 'In this case you can structure your prompt in three segments:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你可以将提示结构化为三个部分：
- en: '**Part 1**: Detail the various departments within your company, outlining their
    specific functions and areas of responsibility.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第 1 部分**：详细描述你公司内的各个部门，概述其具体职能和责任领域。'
- en: '**Part 2**: Introduce the dataset to the model, instructing it to analyze the
    content of each email to determine the most suitable department.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第 2 部分**：将数据集引入模型，指示其分析每封电子邮件的内容，以确定最合适的部门。'
- en: '**Part 3**: Direct the model to append its recommendations in a new column
    within your Excel file, effectively categorizing each email.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第 3 部分**：指示模型将其建议添加到 Excel 文件中的新列中，有效地对每封电子邮件进行分类。'
- en: '**Execute and Evaluate**: Utilize the prompt to task the model with identifying
    the correct recipient department for each email. Following the model’s processing,
    review its suggestions to assess accuracy and relevance.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行与评估**：利用提示让模型为每封电子邮件确定正确的接收部门。在模型处理后，审查其建议，以评估准确性和相关性。'
- en: '![](../Images/f617610727359982d5d6ecf15c73d01d.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f617610727359982d5d6ecf15c73d01d.png)'
- en: Screenshot of a sample dataset (AI generated by the autor with Mistral-medium)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 示例数据集截图（由作者使用 Mistral-medium AI 生成）
- en: 'Before considering going further you can manually rate each answer and compute
    the average to evaluate if the result is good enough for this use case. In our
    example, remember that the use case is a <human>(email) to <machine> (routing
    & proposed answer) to <human> (department) workflow, so an error can be tolerated
    : the human could modify the answer, or a department can reroute an email to another…
    If it happens on ten emails in a hundred it can be good enough.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑进一步操作之前，你可以手动对每个答案进行评分，并计算平均值，以评估结果是否足够好。以我们的例子为例，记住这个用例是一个 <human>（电子邮件）到
    <machine>（路由与建议回答）再到 <human>（部门）的工作流，所以可以容忍一定的错误：人类可以修改答案，或者部门可以将电子邮件重新路由到另一个……如果在
    100 封邮件中发生 10 次这样的情况，可能就足够了。
- en: Considering Internal Industrialization
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑内部工业化
- en: You can fastrack a production ready solution by using an API provided by an
    external provider.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用外部提供商提供的 API，加快生产就绪解决方案的速度。
- en: 'You can use OpenAI API or others for your MVP, but there are several factors
    that you should consider, including:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 OpenAI API 或其他 API 来构建你的 MVP，但你需要考虑多个因素，包括：
- en: '**All the Data you provide to an external API or chat is recorded somewhere**'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**你提供给外部 API 或聊天的所有数据都会在某个地方被记录**'
- en: You should anonymize your data even if the service provider claims that it is
    not using your data…
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使服务提供商声称不使用你的数据，你仍然应该对数据进行匿名化处理……
- en: 'Risk of industrial **secret leakage**: If you are outside of the US, be aware
    that OpenAI is subject to the [Cloud Act](https://en.wikipedia.org/wiki/CLOUD_Act).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工业**机密泄露**风险：如果你在美国以外地区，请注意 OpenAI 受到 [Cloud Act](https://en.wikipedia.org/wiki/CLOUD_Act)
    的约束。
- en: '**Speed limitations**: It often takes several seconds to obtain a complete
    response from OpenAI, which may not be fast enough for certain use cases.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度限制**：从 OpenAI 获取完整回复通常需要几秒钟，对于某些用例来说，这可能不够快。'
- en: '**Call limitations**: The number of calls per second [are limited](https://platform.openai.com/docs/guides/rate-limits?context=tier-five),
    as well as maximum monthly expenses'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调用限制**：每秒的调用次数 [是有限制的](https://platform.openai.com/docs/guides/rate-limits?context=tier-five)，每月的最大费用也有限制。'
- en: '**Environmental impact**: Large generalist models have a [significant environmental
    impact](/chatgpts-energy-use-per-query-9383b8654487), and this should be taken
    into account when considering their use.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境影响**：大型通用模型对环境有[显著影响](/chatgpts-energy-use-per-query-9383b8654487)，在考虑使用这些模型时应将其纳入考量。'
- en: '**Cost variation**: ie OpenAI APIs are subject to cost variation, which can
    impact your budget.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本波动**：例如，OpenAI API的费用可能会波动，这会影响您的预算。'
- en: 'Difficulty in asserting a **competitive advantage**: It can be challenging
    to assert a competitive advantage when using OpenAI APIs, as they are available
    to all businesses.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以确立**竞争优势**：使用OpenAI API时，确立竞争优势可能很具挑战性，因为这些API对所有企业开放。
- en: '**Stability**: LLM private models like Gemini, Mistral, Claude2, GPT4 … are
    not always stable and you should consider monitoring the quality and stability
    of the answers provided. You also have to add rail guards to protect your service
    quality and you & your customers from hazardous behaviors coming from in and out.
    Problems can occur from the input or the output.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稳定性**：像Gemini、Mistral、Claude2、GPT4等LLM私人模型并不总是稳定，您应当考虑监控回答的质量和稳定性。您还需要增加安全措施，以保护您的服务质量，并避免来自内外部的危险行为。问题可能出现在输入或输出环节。'
- en: 'To avoid some of these pitfalls, you can turn to open-source models such as
    LLAMA or Mistral. These open-source alternatives offer several advantages:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为避免这些陷阱，您可以选择使用像LLAMA或Mistral这样的开源模型。这些开源替代方案提供了多个优势：
- en: '**Privacy and Security**: Self hosted models, reduce the risk of industrial
    secret leakage.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**隐私与安全**：自托管模型降低了工业机密泄漏的风险。'
- en: '**Customization**: You can fine-tune open-source models to better suit your
    specific business needs.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定制化**：您可以微调开源模型，使其更好地适应您的特定业务需求。'
- en: '**Lower Costs**: Open-source models are often less expensive than proprietary
    solutions, especially when considering the limitations on the number of calls
    and monthly expenses.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更低的成本**：开源模型通常比专有解决方案便宜，尤其是在考虑调用次数和月度支出的限制时。'
- en: '**Environmental Impact**: Open-source models are smaller and can be optimized
    for specific use cases, potentially reducing their environmental footprint. You
    could measure it with [CodeCarbon](https://codecarbon.io/).'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**环境影响**：开源模型通常较小，可以针对特定的应用场景进行优化，可能会减少它们的环境足迹。你可以使用[CodeCarbon](https://codecarbon.io/)来衡量这一点。'
- en: '**Competitive Advantage**: By customizing an open-source model, you can create
    a unique solution that sets your business apart from competitors.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**竞争优势**：通过定制开源模型，您可以创建一个独特的解决方案，使您的业务在竞争中脱颖而出。'
- en: Now you have automated the routing of the email, let’s improve the quality of
    the answer. A way to do it is to add company documents to the capability of the
    model. This will allow the model to find answers in your document instead of his
    “memory”.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经自动化了电子邮件的路由，让我们来提高答案的质量。一种方法是将公司文档添加到模型的能力中，这样模型就能从您的文档中找到答案，而不是依赖其“记忆”。
- en: Customizing Responses with Company Data
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用公司数据定制回答
- en: Customizing responses from a LLM with company data will create a more accurate
    and tailored experience for users.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用公司数据定制LLM的回答将为用户创造一个更准确、更量身定制的体验。
- en: '![](../Images/3443cc7f2e6867538d16ab5847fde206.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3443cc7f2e6867538d16ab5847fde206.png)'
- en: Photo by [Yasamine June](https://unsplash.com/@yasamine?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Yasamine June](https://unsplash.com/@yasamine?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: You can’t send all company data within the prompt. That’s why [**Retrieval Augmented
    Generation**](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html)(RAG)
    is useful, it’s a technique that combines information retrieval from a database
    and generation capabilities of a LLM. By using RAG, you can improve the accuracy
    of responses. And you could tell to the user which documents have been used for
    the answer.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你不能将所有公司数据都放入提示中。这就是为什么[**检索增强生成**](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html)(RAG)很有用，它是一种将数据库的信息检索与大型语言模型的生成能力结合起来的技术。通过使用RAG，你可以提高回答的准确性。你还可以告诉用户哪些文档被用于生成回答。
- en: 'RAG technique can be simply presented by this formula:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 技术可以通过以下公式简洁地表达：
- en: <LLM trained with billion of data> + <**Your prompt**> + <**Your company dataset**>
    = **Responses aligned with your context**
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: <使用数十亿数据训练的LLM> + <**您的提示**> + <**您的公司数据集**> = **与您的业务背景对齐的回答**
- en: 'RAG is often done with a vector database as it works in most cases, here is
    how to create the database:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: RAG通常使用向量数据库，因为它在大多数情况下都有效，以下是如何创建该数据库：
- en: Split your documents by shorts chapters
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的文档按短章节进行拆分
- en: Convert chapters to vectors using an [embedding model](/neural-network-embeddings-explained-4d028e6f0526).
    The vector on the same subjects will be near in the n-dimensional spaces. Typical
    vector is an array of 1,024 floats values. Think of it like if each value represents
    a characteristic, like color, size, gender… It’s not hard coded, the model finds
    the value by himself in training.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[嵌入模型](/neural-network-embeddings-explained-4d028e6f0526)将章节转换为向量。相同主题的向量将在n维空间中接近。典型的向量是一个包含1,024个浮动值的数组。可以把它想象成每个值代表一个特征，比如颜色、大小、性别……它不是硬编码的，模型在训练时会自行找到这些值。
- en: Store them in a vector database
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将它们存储在向量数据库中
- en: '![](../Images/9e9f8462bd722e026c4a767adfe505b2.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e9f8462bd722e026c4a767adfe505b2.png)'
- en: Image by the author
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'When you receive an email, you will use RAG like this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当您收到电子邮件时，您将像这样使用RAG：
- en: Convert the email of your customer to a vector
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您客户的电子邮件转换为向量
- en: Query the database with this vector to retrieve the 10 nearest vectors of paragraphs
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个向量查询数据库，检索与段落最接近的10个向量
- en: Take the text of these paragraphs and add them to the prompt
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些段落的文本添加到提示中
- en: Ask the LLM for an answer
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向LLM询问答案
- en: The answer will be based on the data provided in the prompt
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案将基于提示中提供的数据
- en: '![](../Images/25cdc87b81e0f1bef58cf2c207b834a4.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/25cdc87b81e0f1bef58cf2c207b834a4.png)'
- en: Image by the author
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: If you want to learn more, read [**Retrieval Augmented Generation**](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)(RAG)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多，请阅读[**检索增强生成**](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)(RAG)
- en: Now your answer will be using your data, so it helps prevent what is called
    *hallucination*.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的答案将使用您的数据，因此有助于防止所谓的*幻觉*。
- en: ℹ️ Model Hallucination is not an easy problem to manage. Because the “memory”
    of a LLM is more like a human memory (compressed representation of the world)
    than a computer’s exact memory. And models are trained to help you so they will
    try to, even when they don’t know the answer, misleading information will be presented
    as fact. RAG helps cope with this problem by providing relevant data to the model.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ℹ️ 模型幻觉（Hallucination）并不是一个容易处理的问题。因为LLM的“记忆”更像是人类的记忆（对世界的压缩表示），而不像计算机的精确内存。而且模型是经过训练来帮助您的，即使它们不知道答案，它们也会尽量提供帮助，错误信息可能会被呈现为事实。RAG通过为模型提供相关数据来帮助应对这个问题。
- en: RAG is really good for unstructured data, but sometimes you have a better way
    to answer the question like tabular data with pricing for each product, or you
    may even want to compute taxes, or looking for a slot in an agenda to arrange
    a meeting. Let’s see how to do that with *function calling*.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: RAG对于非结构化数据非常有效，但有时您可能有更好的方式来回答问题，比如包含每个产品定价的表格数据，或者您甚至可能需要计算税款，或者寻找一个日程中的空位安排会议。让我们看看如何通过*函数调用*来实现。
- en: Function Calling to use APIs
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用API的函数调用
- en: 'Function calling is a way to allow interaction between a LLM and your enterprise
    API, like:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用是一种允许LLM与您的企业API进行交互的方式，例如：
- en: Salesforce, SAP for your ERP
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salesforce，SAP作为您的ERP系统
- en: Service Now or other ticketing services
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Service Now或其他票务服务
- en: Agendas
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日程
- en: Invoice, pricing
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发票，定价
- en: Custom API to do anything in your company
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义API来执行贵公司中的任何操作
- en: Third party API
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三方API
- en: '[Function calling](https://platform.openai.com/docs/guides/function-calling)
    is an essential feature that allows you to use APIs without exposing them to the
    outside world. This feature opens up many possibilities beyond simple chat applications.
    For instance, you can integrate specialized internal services or tools into the
    LLM, making it more versatile and valuable for your business. You can take a mail
    from a customer requesting a price, send it to the LLM to turn it into a parameter
    to call your pricing API, then use the API answer to ask the LLM back to write
    the answer to the customer.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[函数调用](https://platform.openai.com/docs/guides/function-calling)是一个至关重要的功能，它允许您在不将API暴露给外界的情况下使用API。这个功能为超越简单聊天应用程序的多种可能性打开了大门。例如，您可以将专门的内部服务或工具集成到LLM中，使其对您的业务更加多功能和有价值。您可以从客户处获取请求价格的邮件，将其发送给LLM，将其转化为一个参数以调用定价API，然后使用API的答案请LLM返回给客户写出回答。'
- en: 'Given the request:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 给定请求：
- en: “
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “
- en: '*Hello,'
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*你好，'
- en: I really like your company. I would like to order you a solar panel mounting
    rail, what would be the price ?
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我真的很喜欢贵公司。我想为您订购一个太阳能面板安装轨道，请问价格是多少？
- en: Best regards* “
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最佳问候*
- en: 'You send the request to the LLM, with the definitions of the API that exist
    in your company:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 您将请求发送给LLM，并提供您公司中存在的API定义：
- en: '[PRE3]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'So the LLM extract the product name from the mail and give you the JSON to
    make the API call:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所以LLM从邮件中提取产品名称，并给出JSON以进行API调用：
- en: '[PRE4]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'It’s up to you to call the API, so it is totally secured : the LLM never knows
    where your API is, just what it can do.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 由你来调用API，因此它是完全安全的：LLM永远不知道你的API在哪里，只知道它能做什么。
- en: The answer of the API could be sent back to the LLM to build a natural language
    answer.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: API的回答可以返回给LLM，以构建自然语言答案。
- en: '*Can you answer this email given that the price for a “solar panel mounting
    rail” is $10 without a VAT of 5% ? “Hello, I really like your company. I would
    like to order you a solar panel mounting rail, what would be the price ? Best
    regards Your customer “*'
  id: totrans-128
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*您能否根据以下条件回复此邮件：“太阳能面板安装轨道”的价格是10美元，未含5%的增值税？“你好，我非常喜欢你们公司。我想订购一个太阳能面板安装轨道，价格是多少？此致敬礼，您的客户”*'
- en: 'The answer will be:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 答复将是：
- en: '*Hello,*'
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*你好，*'
- en: ''
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Thank you for your interest in our company and for considering our solar panel
    mounting rail. The price for the mounting rail is 10 before taxes, with a VAT
    of 5%, so $10.50 taxes included.*'
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*感谢您对我们公司的关注，并考虑我们的太阳能面板安装轨道。该安装轨道的价格为税前10美元，加上5%的增值税，所以含税价为$10.50。*'
- en: ''
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Please let me know if you have any other questions or if you would like to
    proceed with the order.*'
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*如果你有任何其他问题或想继续进行订单，请告诉我。*'
- en: ''
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Best regards,*'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*此致敬礼，*'
- en: So you now have a system that can use your internal services to better prepare
    answers for your customers. That’s a game changer if you have already [invested
    in APIs](https://blog.dreamfactory.com/api-first-the-advantages-of-an-api-first-approach-to-app-development/).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你现在有了一个可以利用内部服务更好地准备客户答复的系统。如果你已经[投资于API](https://blog.dreamfactory.com/api-first-the-advantages-of-an-api-first-approach-to-app-development/)，这将是一个游戏规则的改变者。
- en: We just saw that we may call a LLM more than once for a single task, let see
    that in more detail.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到，我们可以对一个任务多次调用LLM，让我们更详细地看看这个过程。
- en: Breaking Down Tasks into Multiple Prompts
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将任务分解为多个提示
- en: It’s important to note that a single prompt is often not enough for complex
    tasks. Your project will likely require breaking down the task into multiple prompts
    that will chain together and combine several techniques.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，单一提示通常不足以完成复杂任务。你的项目很可能需要将任务分解为多个提示，这些提示将串联起来并结合多种技术。
- en: For exemple [https://360learning.com/](https://360learning.com/) build a platform
    to help building online courses with AI from a single text document as input.
    Their pipelines make use of 9 prompts, used for 30 OpenAI calls, and RAG to achieve
    their goal. A first prompt asks for a resume of the document, a second asks for
    a plan for an online course from the resume, then RAG is used to retrieve each
    part of the document from the title, and so on.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[https://360learning.com/](https://360learning.com/)构建了一个平台，帮助基于单一文本文件输入使用AI创建在线课程。他们的流程使用了9个提示，进行了30次OpenAI调用，并结合RAG来实现目标。第一个提示要求对文档进行总结，第二个提示要求根据总结制定在线课程计划，然后使用RAG从标题开始逐步提取文档的各个部分，依此类推。
- en: 'Here is some slides of their presentation:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是他们演示的一些幻灯片：
- en: '![](../Images/fd6966165afb053a352611e5d59bade0.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd6966165afb053a352611e5d59bade0.png)'
- en: Caption from [360learning](https://360learning.com/)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[360learning](https://360learning.com/)的标题
- en: '![](../Images/2afd654348d284f9094fc757ec7440ce.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2afd654348d284f9094fc757ec7440ce.png)'
- en: Caption from [360learning](https://360learning.com/)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[360learning](https://360learning.com/)的标题
- en: 'Video source : [https://www.youtube.com/watch?v=1Eyc2GypnF4](https://www.youtube.com/watch?v=1Eyc2GypnF4)
    (in French)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 视频来源：[https://www.youtube.com/watch?v=1Eyc2GypnF4](https://www.youtube.com/watch?v=1Eyc2GypnF4)（法语）
- en: They are using LangChain, a framework that helps to create these types of LLM
    pipelines.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 他们使用LangChain，一个帮助创建这些类型LLM管道的框架。
- en: 'ℹ️ You probably heard of “AI Agents”: they are *just* a way to combine prompts,
    but without writing them in advance. An agent is a call to a LLM to get a list
    of tasks. Then, make a call to LLM for each task, and so on. It works best with
    giving the ability to the LLM to call external tools like browsing the web using
    functions like we saw before.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ℹ️ 你可能听说过“AI代理”：它们*只是*一种结合提示的方式，但无需事先编写提示。代理是对LLM的调用，用以获取任务列表。然后，为每个任务再进行一次LLM调用，依此类推。它在赋予LLM调用外部工具的能力时效果最佳，例如像我们之前看到的那样通过浏览网页的功能。
- en: Now you have a powerful pipeline, but how to improve the model itself to have
    faster and better answers ? You can fine tune a model.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你拥有了一个强大的管道，但如何改进模型本身以获得更快和更好的回答呢？你可以对模型进行微调。
- en: Fine-tuning to improve performance
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调以提高性能
- en: Fine-tuning can often improve the model’s performance and reduce its size while
    maintaining equal performance, because you could use smaller models, like [Mistral-7B](https://mistral.ai/news/announcing-mistral-7b/),
    or even [Phi-2](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 微调通常可以提高模型的性能，并在保持相同性能的同时减少其体积，因为你可以使用更小的模型，如[Mistral-7B](https://mistral.ai/news/announcing-mistral-7b/)，甚至是[Phi-2](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)。
- en: Very few companies could afford to train a LLM from scratch because it requires
    a huge dataset and hundreds of GPUs, almost 2 millions GPU hours for Llama2–70B
    for example. But you can take an already pre-trained model and fine-tune it, only
    an afternoon of fine-tuning is needed in most cases.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有公司能够负担得起从头训练一个LLM，因为这需要一个庞大的数据集和数百个GPU，比如Llama2-70B大约需要200万GPU小时。但你可以选择一个已经预训练的模型并进行微调，在大多数情况下，只需要一个下午的微调时间。
- en: The drawback is that you have to build a training dataset with hundreds of questions
    and answers.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点是你需要构建一个包含数百个问题和答案的训练数据集。
- en: Combining Model
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型结合
- en: It’s a new technique to combine multiple models in one. The result is a big
    model, called [Mixture of Experts](https://medium.aiplanet.com/create-your-own-mixture-of-experts-model-with-mergekit-and-runpod-8b3e91fb027a)
    (MoE), with better capabilities than a single of the same size. The easiest way
    to do that is with [MergeKit](https://medium.com/towards-data-science/merge-large-language-models-with-mergekit-2118fb392b54).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种将多个模型结合成一个模型的新技术。结果是一个大型模型，称为[专家混合模型](https://medium.aiplanet.com/create-your-own-mixture-of-experts-model-with-mergekit-and-runpod-8b3e91fb027a)（MoE），其能力超过同等大小的单一模型。实现这一点最简单的方法是使用[MergeKit](https://medium.com/towards-data-science/merge-large-language-models-with-mergekit-2118fb392b54)。
- en: '![](../Images/29ea2b44bbdd41147283fb765f16bdd0.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29ea2b44bbdd41147283fb765f16bdd0.png)'
- en: '**Generated with AI** — Bing Copilot — “An image of a mathematician, a physicist
    and a mechanical engineer working on the same problem around a desk featuring
    a dismantled uav”'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**由AI生成** — Bing Copilot — “一幅数学家、物理学家和机械工程师围坐在桌子旁，共同解决同一个问题，桌上摆放着一架拆解的无人机”'
- en: 'This could help you if it’s difficult to decide which model to use : with MoE,
    it’s the model who decides which one to use.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你很难决定使用哪个模型，这可能对你有帮助：在MoE中，由模型决定使用哪个。
- en: Conclusion
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Customizing responses from LLMs with company data and API create a more accurate
    and tailored experience for users. Fine-tuning can improve the performance, and
    breaking down tasks into multiple prompts can help tackle complex tasks.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用公司数据和API定制LLM的响应可以为用户创造更准确、更个性化的体验。微调能够提高性能，并且将任务分解为多个提示可以帮助处理复杂的任务。
- en: While all of this may seem complex and reserved for specialists, abundant documentation
    and numerous libraries are available to facilitate implementation. Popular libraries
    include [HuggingFace](https://github.com/huggingface/transformers), [Langchain](https://python.langchain.com/docs/get_started/introduction),
    [HayStack](https://haystack.deepset.ai/), [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
    and so on…
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这一切看起来可能复杂且专门针对专家，但丰富的文档和众多库可以帮助简化实现。流行的库包括[HuggingFace](https://github.com/huggingface/transformers)、[Langchain](https://python.langchain.com/docs/get_started/introduction)、[HayStack](https://haystack.deepset.ai/)、[Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)等…
- en: However, don’t forget the cost of integration. As with any project, there is
    a significant cost associated with moving from a functional prototype to a fully
    industrialized solution within an existing IT system. You will often discover
    that the process of your company is more complex than expected. Or that the data
    needs a bit of cleaning to be processed.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，不要忘记集成的成本。与任何项目一样，从一个功能原型过渡到在现有IT系统中完全工业化的解决方案，涉及的成本是相当可观的。你常常会发现，你公司的流程比预期的更复杂，或者数据需要进行一定的清理才能处理。
- en: While large language models offer many advantages, don’t neglect the benefits
    of “older” machine learning techniques like [random forest](https://www.ibm.com/topics/random-forest)
    or [DistiliBert](https://huggingface.co/docs/transformers/model_doc/distilbert).
    These techniques can still provide values, including faster processing, easier
    integration into existing tools, no need for GPUs, better explainability, and
    lower costs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大型语言模型提供了许多优势，但不要忽视“老牌”机器学习技术的优势，比如[随机森林](https://www.ibm.com/topics/random-forest)或[DistiliBert](https://huggingface.co/docs/transformers/model_doc/distilbert)。这些技术仍然具有价值，包括更快的处理速度、更易于集成到现有工具中、无需GPU、较好的可解释性以及较低的成本。
- en: We hope that this article provides a view on how to include LLM in your software
    architecture.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望这篇文章能为您如何将大型语言模型（LLM）纳入您的软件架构提供一些见解。
- en: Article written in february 2024 by Benoît Courty, data scientist, with the
    help of Stéphane Van-Bosterhaudt, CEO of [UpScale](https://upscaleparis.ai/).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章由数据科学家Benoît Courty于2024年2月撰写，并在[UpScale](https://upscaleparis.ai/)的首席执行官Stéphane
    Van-Bosterhaudt的帮助下完成。
- en: 'More readings on the subject:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 更多相关阅读：
- en: 'Cloud Act: [https://en.wikipedia.org/wiki/CLOUD_Act](https://en.wikipedia.org/wiki/CLOUD_Act)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '云法案: [https://en.wikipedia.org/wiki/CLOUD_Act](https://en.wikipedia.org/wiki/CLOUD_Act)'
- en: 'RAG: [https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'RAG: [https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)'
- en: 'Embeddings: [https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526](/neural-network-embeddings-explained-4d028e6f0526)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '嵌入式表示: [https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526](/neural-network-embeddings-explained-4d028e6f0526)'
- en: 'Function calling: [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '函数调用: [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)'
- en: 'Fine-tuning: [https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '微调: [https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html)'
- en: 'Mixture of Experts: [https://medium.aiplanet.com/create-your-own-mixture-of-experts-model-with-mergekit-and-runpod-8b3e91fb027a](https://medium.aiplanet.com/create-your-own-mixture-of-experts-model-with-mergekit-and-runpod-8b3e91fb027a)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '专家混合模型: [https://medium.aiplanet.com/create-your-own-mixture-of-experts-model-with-mergekit-and-runpod-8b3e91fb027a](https://medium.aiplanet.com/create-your-own-mixture-of-experts-model-with-mergekit-and-runpod-8b3e91fb027a)'
