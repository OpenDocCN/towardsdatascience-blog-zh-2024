["```py\nimport cv2\nimport os\n\nimage_dir = '../data/raw/'\nimg = cv2.imread(image_dir + 'IMG_6828.png')\n\nplt.imshow(img)\nplt.show()\n```", "```py\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nplt.imshow(gray, cmap='gray')\nplt.show()\n```", "```py\nimport easyocr\n\nreader = easyocr.Reader(['en'])\nresult = reader.readtext(gray[1850:2100, 200:580])\nfor bbox, text, prob in result:\n    print(f\"Detected text: {text} with confidence {prob}\")\n```", "```py\n>> Detected text: 340 with confidence 0.999995182215476\n```", "```py\nfrom pingouin import circ_mean\n\narithmetic_mean = data['radians'].mean()\ncircular_mean = circ_mean(data['radians'])\n\nprint(f\"Arithmetic mean: {arithmetic_mean:.3f}; Circular mean: {circular_mean:.3f}\")\n```", "```py\n>> Arithmetic mean: 0.082; Circular mean: 2.989\n```", "```py\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy.stats import vonmises\nfrom pingouin import convert_angles\nfrom typing import Tuple, List\n\ndef vonmises_kde(series: np.ndarray, kappa: float, n_bins: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Estimate a von Mises kernel density estimate (KDE) over circular data using scipy.\n\n    Parameters:\n    series: np.ndarray \n        The input data in radians, expected to be a 1D array.\n    kappa: float\n        The concentration parameter for the von Mises distribution.\n    n_bins: int\n        The number of bins for the KDE estimate (default is 100).\n\n    Returns:\n    bins: np.ndarray\n        The bin edges (x-values) used for the KDE.\n    kde: np.ndarray\n        The estimated density values (y-values) for each bin.\n    \"\"\"\n    bins = np.linspace(-np.pi, np.pi, n_bins)\n    kde = np.zeros(n_bins)\n\n    for angle in series:\n        kde += vonmises.pdf(bins, kappa, loc=angle)\n\n    kde = kde / len(series)\n    return bins, kde\n\ndef plot_circular_distribution(\n    data: pd.DataFrame,\n    plot_type: str = 'kde',\n    bins: int = 30,\n    figsize: tuple = (4, 4),\n    **kwargs\n) -> None:\n    \"\"\"\n    Plot a compass rose with either KDE or histogram for circular data.\n\n    Parameters:\n    -----------\n    data: pd.DataFrame\n        DataFrame containing 'degrees'and 'radians' columns with circular data\n    plot_type: str\n        Type of plot to create: 'kde' or 'histogram'\n    bins: int\n        Number of bins for histogram or smoothing parameter for KDE\n    figsize: tuple\n        Figure size as (width, height)\n    **kwargs: dict\n        Additional styling arguments for histogram (color, edgecolor, etc.)\n    \"\"\"\n    plt.figure(figsize=figsize)\n    ax = plt.subplot(111, projection='polar')\n\n    ax.set_theta_zero_location('N')\n    ax.set_theta_direction(-1)\n\n    # add cardinal directions\n    directions = ['N', 'E', 'S', 'W']\n    angles = [0, np.pi / 2, np.pi, 3 * np.pi / 2]\n    for direction, angle in zip(directions, angles):\n        ax.text(\n            angle, 0.45, direction,\n            horizontalalignment='center',\n            verticalalignment='center',\n            fontsize=12,\n            weight='bold'\n        )\n\n    if plot_type.lower() == 'kde':\n        x, kde = vonmises_kde(data['radians'].values, bins)\n        ax.plot(x, kde, color=kwargs.get('color', 'red'), lw=2)\n\n    elif plot_type.lower() == 'histogram':\n        hist_kwargs = {\n            'color': 'teal',\n            'edgecolor': 'black',\n            'alpha': 0.7\n        }\n        hist_kwargs.update(kwargs) \n\n        angles_rad = np.deg2rad(data['degrees'].values)\n        counts, bin_edges = np.histogram(\n            angles_rad, \n            bins=bins, \n            range=(0, 2*np.pi), \n            density=True\n        )\n        widths = np.diff(bin_edges)\n        ax.bar(\n            bin_edges[:-1],\n            counts,\n            width=widths,\n            align='edge',\n            **hist_kwargs\n        )\n\n    else:\n        raise ValueError(\"plot_type must be either 'kde' or 'histogram'\")\n\n    ax.xaxis.grid(True, linestyle='--', alpha=0.5)\n    ax.yaxis.grid(True, linestyle='--', alpha=0.5)\n    ax.set_yticklabels([]) \n    plt.show()\n```", "```py\ndata = pd.read_csv('../data/processed/compass_degrees.csv', index_col=0)\ndata['radians'] = convert_angles(data['degrees'], low=0, high=360)\n\nplot_circular_distribution(data, plot_type='histogram', figsize=(6, 6))\nplot_circular_distribution(data, plot_type='kde', figsize=(5, 5))\n```", "```py\nfrom pingouin import circ_rayleigh\n\nz, pval = circ_rayleigh(data['radians'])\nprint(f\"Z-statistics: {z:.3f}; p-value: {pval:.6f}\")\n```", "```py\n>> Z-statistics: 3.893; p-value: 0.020128\n```", "```py\nfrom pingouin import circ_vtest\n\nv, pval = circ_vtest(data['radians'], dir=np.pi)\nprint(f\"V-statistics: {v:.3f}; p-value: {pval:.6f}\")\n```", "```py\n>> V-statistics: 24.127; p-value: 0.002904\n```", "```py\nimport imageio\nfrom io import BytesIO\n\ndef get_posterior_distribution_image_array(\n    mu_grid: np.ndarray, \n    posterior_pdf: np.ndarray, \n    current_samples: List[float], \n    idx: int, \n    fig_size: Tuple[int, int], \n    dpi: int, \n    r_max_posterior: float\n) -> np.ndarray:\n    \"\"\"\n    Creates the posterior distribution and observed samples histogram on a polar plot, \n    converts it to an image array, and returns it for GIF processing.\n\n    Parameters:\n    -----------\n\n    mu_grid (np.ndarray): \n        Grid of mean direction values for plotting the posterior PDF.\n    posterior_pdf (np.ndarray): \n        Posterior probability density function values for the given `mu_grid`.\n    current_samples (List[float]): \n        List of observed angle samples in radians.\n    idx (int): \n        The current step index, used for labeling the plot.\n    fig_size (Tuple[int, int]): \n        Size of the plot figure (width, height).\n    dpi (int): \n        Dots per inch (resolution) for the plot.\n    r_max_posterior (float): \n        Maximum radius for the posterior PDF plot, used to set plot limits.\n\n    Returns:\n        np.ndarray: Image array of the plot in RGB format, suitable for GIF processing.\n    \"\"\"\n    fig = plt.figure(figsize=fig_size, dpi=dpi)\n    ax = plt.subplot(1, 1, 1, projection='polar')\n    ax.set_theta_zero_location('N')  \n    ax.set_theta_direction(-1)  \n    ax.plot(mu_grid, posterior_pdf, color='red', linewidth=2, label='Posterior PDF')\n\n    # observed samples histogram\n    n_bins = 48\n    hist_bins = np.linspace(-np.pi, np.pi, n_bins + 1)\n    hist_counts, _ = np.histogram(current_samples, bins=hist_bins)\n\n    # normalize the histogram counts\n    if np.max(hist_counts) > 0:\n        hist_counts_normalized = hist_counts / np.max(hist_counts)\n    else:\n        hist_counts_normalized = hist_counts\n\n    bin_centers = (hist_bins[:-1] + hist_bins[1:]) / 2\n    bin_width = hist_bins[1] - hist_bins[0]\n\n    # set the maximum radius to accommodate both the posterior pdf and histogram bars\n    r_histogram_height = r_max_posterior * 0.9 \n    r_max = r_max_posterior + r_histogram_height\n    ax.set_ylim(0, r_max)\n\n    # plot the histogram bars outside the circle\n    for i in range(len(hist_counts_normalized)):\n        theta = bin_centers[i]\n        width = bin_width\n        hist_height = hist_counts_normalized[i] * r_histogram_height\n        if hist_counts_normalized[i] > 0:\n            ax.bar(\n                theta, hist_height, width=width, bottom=r_max_posterior, \n                color='teal', edgecolor='black', alpha=0.5\n            )\n\n    ax.text(\n        0.5, 1.1, f'Posterior Distribution (Step {idx + 1})', \n        transform=ax.transAxes, ha='center', va='bottom', fontsize=18\n    )\n    ax.set_yticklabels([])\n    ax.grid(linestyle='--')\n    ax.yaxis.set_visible(False)\n    ax.spines['polar'].set_visible(False)\n    plt.subplots_adjust(top=0.85, bottom=0.05, left=0.05, right=0.95)\n\n    # saving to buffer for gif processing\n    buf = BytesIO()\n    plt.savefig(buf, format='png', bbox_inches=None, pad_inches=0)\n    buf.seek(0)\n    img_array = plt.imread(buf)\n    img_array = (img_array * 255).astype(np.uint8)\n    plt.close(fig)\n    return img_array\n```", "```py\n# initial prior parameters\nmu_prior = 0.0  # initial mean direction (any value, since kappa_prior = 0)\nkappa_prior = 0.0  # uniform prior over the circle\n\n# fixed concentration parameter for the likelihood\nkappa_likelihood = 2.0\n\nposterior_mus = []\nposterior_kappas = []\n\nmu_grid = np.linspace(-np.pi, np.pi, 200)\n\n# vizualisation parameters\nfig_size = (10, 10)\ndpi = 100\n\ncurrent_samples = []\nframes = []\n\nfor idx, theta_n in enumerate(data['radians']):\n\n    # compute posterior parameters\n    C = kappa_prior * np.cos(mu_prior) + kappa_likelihood * np.cos(theta_n)\n    S = kappa_prior * np.sin(mu_prior) + kappa_likelihood * np.sin(theta_n)\n    kappa_post = np.sqrt(C**2 + S**2)\n    mu_post = np.arctan2(S, C)\n\n    # posterior distribution\n    posterior_pdf = np.exp(kappa_post * np.cos(mu_grid - mu_post)) / (2 * np.pi * i0(kappa_post))\n\n    # store posterior parameters and observed samples\n    posterior_mus.append(mu_post)\n    posterior_kappas.append(kappa_post)\n    current_samples.append(theta_n)\n\n    # plot posterior distribution\n    r_max_posterior = max(posterior_pdf) * 1.1\n    img_array = get_posterior_distribution_image_array(\n        mu_grid, \n        posterior_pdf, \n        current_samples, \n        idx, \n        fig_size, \n        dpi, \n        r_max_posterior\n        )\n    frames.append(img_array)\n\n    # updating priors for next iteration\n    mu_prior = mu_post\n    kappa_prior = kappa_post\n\n# Create GIF\nfps = 10\nframes.extend([img_array]*fps*3) # repeat last frame a few times to make a \"pause\" at the end of the GIF\nimageio.mimsave('../images/posterior_updates.gif', frames, fps=fps)\n```", "```py\n# Convert posterior_mus to degrees\nposterior_mus_deg = np.rad2deg(posterior_mus) % 360\nn_samples = data.shape[0]\ntrue_mu = data['degrees'].mean()\n# Plot evolution of posterior mean direction\nfig, ax1 = plt.subplots(figsize=(12, 6))\n\ncolor = 'tab:blue'\nax1.set_xlabel('Number of Observations')\nax1.set_ylabel('Posterior Mean Direction (Degrees)', color=color)\nax1.plot(range(1, n_samples + 1), posterior_mus_deg, marker='o', color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.axhline(true_mu, color='red', linestyle='--', label='Sample Distribution Mean Direction')\nax1.legend(loc='upper left')\nax1.grid(True)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:orange'\nax2.set_ylabel('Posterior Concentration Parameter (kappa)', color=color)  # we already handled the x-label with ax1\nax2.plot(range(1, n_samples + 1), posterior_kappas, marker='o', color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nsns.despine()\nplt.title('Evolution of Posterior Mean Direction and Concentration Over Time')\nplt.show()\n```", "```py\n# Calculate log likelihood for H0\nlog_likelihood_h0 = vonmises.logpdf(data['radians'], kappa=0, loc=0).sum()\n```", "```py\nimport pymc as pm\nimport arviz as az\nimport arviz.data.inference_data as InferenceData\nfrom scipy.stats import halfnorm, gaussian_kde\n\nwith pm.Model() as model_uni:\n    # Prior for kappa \n    kappa = pm.HalfNormal('kappa', sigma=10)\n    # Likelihood\n    likelihood_h1 = pm.VonMises('angles', mu=np.pi, kappa=kappa, observed=data['radians'])\n    # Sample from posterior \n    trace_uni = pm.sample(\n        10000, tune=3000, chains=4, \n        return_inferencedata=True, \n        idata_kwargs={'log_likelihood': True})\n```", "```py\n# Model graph\npm.model_to_graphviz(model_uni)\n```", "```py\naz.plot_posterior(trace_uni, var_names=['kappa'])\nplt.show()\n```", "```py\n# Posterior samples for kappa\nkappa_samples = trace_uni.posterior.kappa.values.flatten()\n# Log likelihood for each sample\nlog_likes = []\nfor k in kappa_samples:\n    # Von Mises log likelihood\n    log_like = vonmises.logpdf(data['radians'], k, loc=np.pi).sum()\n    log_likes.append(log_like)\n# Log-mean-exp trick for numerical stability\nlog_likelihood_h1 = np.max(log_likes) +\\\n       np.log(np.mean(np.exp(log_likes - np.max(log_likes))))\nBF = np.exp(log_likelihood_h1 - log_likelihood_h0)\nprint(f\"Bayes Factor: {BF:.4f}\")\nprint(f\"Probability kappa > 0.5: {np.mean(kappa_samples > 0.5):.4f}\")\n```", "```py\n>> Bayes Factor: 32.4645\n>> Probability kappa > 0.5: 0.0649\n```", "```py\n# Type aliases\nArrayLike = Union[np.ndarray, pd.Series]\nResultDict = Dict[str, Union[float, InferenceData.InferenceData]]\n\ndef compute_mixture_vonmises_logpdf(\n    series: ArrayLike,\n    kappa: float,\n    weights: npt.NDArray[np.float64],\n    mus: List[float]\n) -> float:\n    \"\"\"\n    Compute log PDF for a mixture of von Mises distributions\n\n    Parameters:\n    -----------\n    series: ArrayLike \n        Array of observed angles in radians\n    kappa: float\n        Concentration parameter\n    weights: npt.NDArray[np.float64],\n        Array of mixture weights\n    mus: List[float] \n        Array of means for each component\n\n    Returns:\n    --------\n    float: Sum of log probabilities for all data points\n    \"\"\"\n    mixture_pdf = np.zeros_like(series)\n\n    for w, mu in zip(weights, mus):\n        mixture_pdf += w * vonmises.pdf(series, kappa, loc=mu)\n\n    return np.log(np.maximum(mixture_pdf, 1e-300)).sum()\n\ndef compute_log_likelihoods(\n    trace: az.InferenceData, \n    series: ArrayLike,\n    mus: List[float]\n    ) -> np.ndarray:\n    \"\"\"\n    Compute log likelihoods for each sample in the trace\n\n    Parameters:\n    -----------\n    trace: az.InferenceData\n        The trace from the PyMC3 model sampling.\n\n    series: ArrayLike\n        Array of observed angles in radians\n\n    \"\"\"\n\n    kappa_samples = trace.posterior.kappa.values.flatten()\n    weights_samples = trace.posterior.weights.values.reshape(-1, 2)\n    # Calculate log likelihood for each posterior sample\n    log_likes = []\n    for k, w in zip(kappa_samples, weights_samples):\n        log_like = compute_mixture_vonmises_logpdf(\n            series, \n            kappa=k, \n            weights=w, \n            mus=mus\n        )\n        log_likes.append(log_like)\n\n    # Calculate marginal likelihood using log-sum-exp trick\n    log_likelihood_h1 = np.max(log_likes) + np.log(np.mean(np.exp(log_likes - np.max(log_likes))))\n    return log_likelihood_h1\n\ndef posterior_report(\n    log_likelihood_h0: float, \n    log_likelihood_h1: float, \n    kappa_samples: ArrayLike,\n    kappa_threshold: float = 0.5\n    ) -> str:\n\n    \"\"\"\n    Generate a report with Bayes Factor and probability kappa > threshold\n\n    Parameters:\n    -----------\n    log_likelihood_h0: float\n        Log likelihood for the null hypothesis\n    log_likelihood_h1: float\n        Log likelihood for the alternative hypothesis\n    kappa_samples: ArrayLike\n        Flattened posterior samples of the concentration parameter\n    kappa_threshold: float\n        Threshold for computing the probability that kappa > threshold\n\n    Returns:\n    --------\n    summary: str\n        A formatted string containing the summary statistics.\n    \"\"\"\n    BF = np.exp(log_likelihood_h1 - log_likelihood_h0)\n\n    summary = (\n        f\"Bayes Factor: {BF:.4f}\\n\"\n        f\"Probability kappa > {kappa_threshold}: {np.mean(kappa_samples > kappa_threshold):.4f}\"\n    )\n\n    return summary\n```", "```py\nmu1 = 0            # 0 degrees\nmu2 = np.pi        # 180 degrees\n\nwith pm.Model() as model_mixture_bimodal_NS:\n    # Priors for concentration parameters\n    kappa = pm.HalfNormal('kappa', sigma=10) \n    # Priors for component weights\n    weights = pm.Dirichlet('weights', a=np.ones(2))\n\n    # Define the von Mises components\n    vm1 = pm.VonMises.dist(mu=mu1, kappa=kappa)\n    vm2 = pm.VonMises.dist(mu=mu2, kappa=kappa)\n\n    # Mixture distribution\n    likelihood = pm.Mixture(\n        'angles',\n        w=weights,\n        comp_dists=[vm1, vm2],\n        observed=data['radians']\n    )\n\n    # Sample from the posterior\n    trace_mixture_bimodal_NS = pm.sample(\n        10000, tune=3000, chains=4, return_inferencedata=True, idata_kwargs={'log_likelihood': True})\n\n    # Get kappa samples\n    kappa_samples = trace_mixture_bimodal_NS.posterior.kappa.values.flatten()\n```", "```py\n# Model graph\npm.model_to_graphviz(model_mixture_bimodal_NS)\n```", "```py\n# Posterior Analysis\naz.plot_posterior(trace_mixture_bimodal_NS, var_names=['kappa'])\nplt.show()\n```", "```py\nlog_likelihood_h1 = compute_log_likelihoods(trace_mixture_bimodal_NS, data['radians'], [mu1, mu2])\nprint(posterior_report(log_likelihood_h0, log_likelihood_h1, kappa_samples))\n```", "```py\n>> Bayes Factor: 214.2333\n>> Probability kappa > 0.5: 0.9110\n```", "```py\nmu1 = np.pi          # 180 degrees\nmu2 = 3 * np.pi / 2  # 270 degrees\n\nwith pm.Model() as model_mixture_bimodal_WS:\n    # Priors for concentration parameters\n    kappa = pm.HalfNormal('kappa', sigma=10)\n\n    # Priors for component weights\n    weights = pm.Dirichlet('weights', a=np.ones(2))\n\n    # Define the four von Mises components\n    vm1 = pm.VonMises.dist(mu=mu1, kappa=kappa)\n    vm2 = pm.VonMises.dist(mu=mu2, kappa=kappa)\n\n    # Mixture distribution\n    likelihood = pm.Mixture(\n        'angles',\n        w=weights,\n        comp_dists=[vm1, vm2],\n        observed=data['radians']\n    )\n\n    # Sample from the posterior\n    trace_mixture_bimodal_WS = pm.sample(\n        10000, tune=3000, chains=4, return_inferencedata=True, idata_kwargs={'log_likelihood': True})\n\n    # Get kappa samples\n    kappa_samples = trace_mixture_bimodal_WS.posterior.kappa.values.flatten()\n\n# Posterior Analysis\naz.plot_posterior(trace_mixture_bimodal_WS, var_names=['kappa'])\nplt.show()\n\nlog_likelihood_h1 = compute_log_likelihoods(trace_mixture_bimodal_WS, data['radians'], [mu1, mu2])\nprint(posterior_report(log_likelihood_h0, log_likelihood_h1, kappa_samples))\n```", "```py\n>> Bayes Factor: 20.2361\n>> Probability kappa > 0.5: 0.1329\n```", "```py\nmu1 = 0            # 0 degrees\nmu2 = np.pi / 2    # 90 degrees\nmu3 = np.pi        # 180 degrees\nmu4 = 3 * np.pi / 2  # 270 degrees\n\nwith pm.Model() as model_mixture_quad:\n    # Priors for concentration parameters\n    kappa = pm.HalfNormal('kappa', sigma=10)\n\n    # Priors for component weights\n    weights = pm.Dirichlet('weights', a=np.ones(4))\n\n    # Define the four von Mises components\n    vm1 = pm.VonMises.dist(mu=mu1, kappa=kappa)\n    vm2 = pm.VonMises.dist(mu=mu2, kappa=kappa)\n    vm3 = pm.VonMises.dist(mu=mu3, kappa=kappa)\n    vm4 = pm.VonMises.dist(mu=mu4, kappa=kappa)\n\n    # Mixture distribution\n    likelihood = pm.Mixture(\n        'angles',\n        w=weights,\n        comp_dists=[vm1, vm2, vm3, vm4],\n        observed=data['radians']\n    )\n\n    # Sample from the posterior\n    trace_mixture_quad = pm.sample(\n        10000, tune=3000, chains=4, return_inferencedata=True, idata_kwargs={'log_likelihood': True}\n    )\n    # Get kappa samples\n    kappa_samples = trace_mixture_quad.posterior.kappa.values.flatten()\n# Posterior Analysis\naz.plot_posterior(trace_mixture_quad, var_names=['kappa'])\nplt.show()\nlog_likelihood_h1 = compute_log_likelihoods(trace_mixture_quad, data['radians'], [mu1, mu2, mu3, mu4])\nprint(posterior_report(log_likelihood_h0, log_likelihood_h1, kappa_samples))\n```", "```py\n>> Bayes Factor: 0.0000\n>> Probability kappa > 0.5: 0.9644\n```", "```py\n# Compute WAIC for each model\nwail_uni = az.waic(trace_uni)\nwaic_quad = az.waic(trace_mixture_quad)\nwaic_bimodal_NS = az.waic(trace_mixture_bimodal_NS)\nwaic_bimodal_WS = az.waic(trace_mixture_bimodal_WS)\n\nmodel_dict = {\n    'Quadrimodal Model': trace_mixture_quad,\n    'Bimodal Model (NS)': trace_mixture_bimodal_NS,\n    'Bimodal Model (WS)': trace_mixture_bimodal_WS,\n    'Unimodal Model': trace_uni \n}\n# Compare models using WAIC\nwaic_comparison = az.compare(model_dict, ic='waic')\nwaic_comparison\n```", "```py\n# Compare models using LOO\nloo_comparison = az.compare(model_dict, ic='loo')\nloo_comparison\n```", "```py\n# Visualize the comparison\naz.plot_compare(waic_comparison)\nplt.show()\n```"]