- en: Building, Evaluating and Tracking a Local Advanced RAG System | Mistral 7b +
    LlamaIndex + W&B
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/building-evaluating-and-tracking-a-local-advanced-rag-system-mistral-7b-llamaindex-w-b-5c9c69059f92?source=collection_archive---------1-----------------------#2024-01-19](https://towardsdatascience.com/building-evaluating-and-tracking-a-local-advanced-rag-system-mistral-7b-llamaindex-w-b-5c9c69059f92?source=collection_archive---------1-----------------------#2024-01-19)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Explore building an advanced RAG system on your computer. Full-cycle step-by-step
    guide with code.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@nikita_kiselov?source=post_page---byline--5c9c69059f92--------------------------------)[![Nikita
    Kiselov](../Images/7a9cca0418a58e35e1024d59a8c634bf.png)](https://medium.com/@nikita_kiselov?source=post_page---byline--5c9c69059f92--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5c9c69059f92--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5c9c69059f92--------------------------------)
    [Nikita Kiselov](https://medium.com/@nikita_kiselov?source=post_page---byline--5c9c69059f92--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5c9c69059f92--------------------------------)
    ¬∑9 min read¬∑Jan 19, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f0ee5a6bf5549decf39b4807fe19ac8f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author | Mistral + LlamaIndex + W&B
  prefs: []
  type: TYPE_NORMAL
- en: '**Retrieval Augmented Generation (RAG)** is a powerful NLP technique that combines
    large language models with selective access to knowledge. It allows us to reduce
    LLM hallucinations by providing the relevant pieces of the context from our documents.
    The idea of this article is to show how you can build your RAG system using locally
    running LLM, which techniques can be used to improve it, and finally ‚Äî how to
    track the experiments and compare results in W&B.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will cover the following key aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Building** a baseline local RAG system using Mistral-7b and LlamaIndex.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Evaluating** its performance in terms of *faithfulness* and *relevancy*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tracking** experiments end-to-end using Weights & Biases (W&B).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implementing **advanced RAG** techniques, such as hierarchical nodes and re-ranking.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The complete notebook, including detailed comments and the full code, is [available
    on GitHub](https://github.com/kinivi/AlchemyLab/blob/main/Advanced_RAG/Encahnced.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: '**üè† Making Local RAG system**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
