- en: Semantic Segmentation of Remote Sensing Imagery using k-Means
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/semantic-segmentation-of-remote-sensing-imagery-using-k-means-e4c165d9218e?source=collection_archive---------2-----------------------#2024-03-14](https://towardsdatascience.com/semantic-segmentation-of-remote-sensing-imagery-using-k-means-e4c165d9218e?source=collection_archive---------2-----------------------#2024-03-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: From scratch in pythonüêç
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alexroz?source=post_page---byline--e4c165d9218e--------------------------------)[![Aleksei
    Rozanov](../Images/748b69bfaccf39c9aa568a9e6f41eec3.png)](https://medium.com/@alexroz?source=post_page---byline--e4c165d9218e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e4c165d9218e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e4c165d9218e--------------------------------)
    [Aleksei Rozanov](https://medium.com/@alexroz?source=post_page---byline--e4c165d9218e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e4c165d9218e--------------------------------)
    ¬∑9 min read¬∑Mar 14, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/904dc8dee478d11729c5abcd698f3412.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: One of the most simple and genius ML models, in my opinion, is k-Means clustering.
    It relates to the group of unsupervised learning algorithms and is capable of
    finding patterns inside an unlabeled dataset. The most pleasant feature is that
    it lacks complicated math, and basically any high school student can successfully
    implement and use this method. So in this article I want to share how you can
    build k-Means algorithm from scratch in python using only *numpy* and *pandas*
    libraries and apply it to a real world problem ‚Äî semantic segmentation of satellite
    imagery.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, let‚Äôs talk about the data we have.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In one of my previous articles, I talked about the problem of the Aral Sea shrinkage.
    As a result, we managed to get remote sensing imagery from MODIS using Google
    Earth Engine, which strongly indicates that the sea is drying. So I wondered,
    how can we estimate the change of the water surface between 2000 and 2023 using
    ML semantic segmentation? The answer is k-Means!
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alexroz/how-can-a-sea-disappear-case-study-of-the-aral-sea-using-python-and-modis-data-c59429cb73dd?source=post_page-----e4c165d9218e--------------------------------)
    [## How can a sea disappear? Case study of the Aral Sea using Python and MODIS
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs create a timelapse and check if it‚Äôs true!
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@alexroz/how-can-a-sea-disappear-case-study-of-the-aral-sea-using-python-and-modis-data-c59429cb73dd?source=post_page-----e4c165d9218e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into coding, let‚Äôs have a look at the data we are going to use
    in this tutorial. These are two RGB images of the same area with an interval of
    23 years, however it‚Äôs clear that the land surface properties and atmospheric
    conditions (clouds, aerosols etc.) are different. That‚Äôs why I decided to train
    two separate k-Means models, one for each image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cfcc0332a5f81c03112fc9ecc408c78.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: To follow up the tutorial, you can download and run the notebook [**here**](https://github.com/alexxxroz/Medium/blob/main/Medium_k_Means.ipynb).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'First of all, let‚Äôs import the necessary libraries and upload the data to the
    notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that the area covered by the images is quite large, so I suggest
    to zoom in a little:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/03b13a7e33bfb6dd16192ee0c087b008.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: And the last step before the ML phase, let‚Äôs convert our images to *pandas*
    dataframes (one column for each image channel). I do that for the sake of visibility
    of my explanations. If you want to get it optimized, it‚Äôs better to use *numpy*
    arrays instead.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: k-Means
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So what is the idea behind the algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine that you judge about the taste of food using two criteria: sweetness
    and price. Keeping this in mind, I‚Äôll give you a set of possible options to eat:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3bd99b33a1a63713051e4885099ad0dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: 'I bet your brain has already split the options into three clusters: fruits,
    drinks and bakery. Basically, you unconsciously clustered the 2-dimensional data,
    which are defined by a pair of values ‚Äî (sweetness; price).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1003f1dda8b9e40cced2c3a901d42e22.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: In the case of **k-Means**, the goal of the algorithm is quite similar ‚Äî to
    find a *pre-set* number of cluster, **k**, in n-dimensional space (e.g. besides
    sweetness and price you want to account for nutrition, health, presence of the
    food in your fridge, and in this case, n = 5).
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithms includes the following stages:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I. Define the number of clusters.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As I mentioned beforehand, **k** in k-Means is the number of clusters you want
    to get in the end, and you‚Äôre supposed to set this value **before** training the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: II. Randomly initialize centroids.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Centroid is an integral part of k-Means. Basically, centroid is a circle with
    a center, which is defined a set of coordinates, and each centroid represents
    a cluster. For instance, in our previous example there are 3 centroids.
  prefs: []
  type: TYPE_NORMAL
- en: III. Calculate distances and assign clusters.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we need to find how far each point is from each centroid. Based on this
    calculations, we assign each point to the least distant centroid (cluster).
  prefs: []
  type: TYPE_NORMAL
- en: IV. Calculate new centroids.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now each of our clusters contains at least one points, so it‚Äôs time to re-calculate
    the centroids simply by taking mean coordinates across all cluster points.
  prefs: []
  type: TYPE_NORMAL
- en: And that‚Äôs it! We repeat steps 2‚Äì4 until centroids are not changing.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e7c1dcf0ff1310e65cf999afb3f7c39c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: Time To Code.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let‚Äôs wrap this really simple idea behind k-Means into python code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reminder: in this task we have **3D** problem, i.e. our **X**, **Y** and **Z**
    are **Red**, **Green** and **Blue** image channels!'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: On the first stage we create a list **L** to collect all the distances between
    clusters to visualize them afterwards and randomly sample K points from the dataset
    to make them our centroids (or alternatively, you can assign random values to
    the centroids).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now we need to calculate the distances between centroids and data points. There
    are lots of different distance metrics in Data Science, but let‚Äôs focus on the
    following ones ‚Äî Euclidean, Manhattan, Chebyshev.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Euclidean distance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b94c0589edc3248b5a6e9327a831cce.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: 'For Manhattan:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ab3ef1f64e041902d895fe4f4217963f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: 'For Chebyshev:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fcffdf977d6d12766b4d9f542421497f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: 'To use this formulas, let‚Äôs write a versatile function for **any** number of
    dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: So now we can simply calculate distances and assign a cluster to each data point.
    Thus, our new centroids became old, so we store them in another variable and recalculate
    the new ones. To do that we iterate over each cluster and take a mean across all
    the coordinates (in our case, across RGB channels). Therefore, the variable new_centroids
    has a shape of **(k,3)**.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we repeat all these steps until centroids‚Äô coordinates don‚Äôt change
    anymore. I expressed this condition as this: the difference between average cluster
    coordinates should be less than 0.001\. But you can play around with other numbers
    here.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: And that‚Äôs it. The algorithm is ready to be trained! So let‚Äôs set k = 3 and
    store the results into dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: I decided to compare all the distance metrics for this particular task as you
    can see, and it‚Äôs evident that here Manhattan distance was the fastest.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3bec8b58dce86ff8c83f8b20c27e9bd6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: 'Before visualizing the clusters, let‚Äôs convert the clusters names into int
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Time make the final plots!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b00aff5116c9cbab942e585d4252f441.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/492f7beda408d7069bb741e67a3163b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dfe919b855acb1e371c3bbe9e8bb4ee5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: It‚Äôs not hard to see that Euclidean and Manhattan distance turned out be the
    most suitable for this particular task. But to make sure that it‚Äôs true, let‚Äôs
    evaluate the k-Means clustering results using the Silhouette Coefficient. This
    metric is perfect for training results assessment when there are no labeled true
    values for the clustered points.
  prefs: []
  type: TYPE_NORMAL
- en: To calculate it we will use *sklearn* function [[1]](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac04245c27d5fd1d3c6482d2a748d9a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score).
  prefs: []
  type: TYPE_NORMAL
- en: '**a ‚Äî** the mean distance between a sample and all other points in the same
    class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**b ‚Äî** the mean distance between a sample and all other points in the *next
    nearest cluster*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The range of values of the Silhouette Coefficient is [-1,1]. And yep, it‚Äôs computationally
    expensive, as you need to calculate distances between thousands of point several
    times, so be ready to wait.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/11dad952095ba1c10b5e3f8be1e2cc4c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can see that we proved it: Euclidean and Manhattan distances have similarly
    good performance, so let‚Äôs estimate the water surface area loss, using both of
    them.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3eb0a222f2765449872f20b68e294596.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äî ‚Äî ‚Äî ‚Äî
  prefs: []
  type: TYPE_NORMAL
- en: 'Distance: euclidean'
  prefs: []
  type: TYPE_NORMAL
- en: 'Water Area Before: 17125 km¬≤'
  prefs: []
  type: TYPE_NORMAL
- en: 'Water Area After: 1960 km¬≤'
  prefs: []
  type: TYPE_NORMAL
- en: 'Change: -89%'
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî
  prefs: []
  type: TYPE_NORMAL
- en: 'Distance: manhattan'
  prefs: []
  type: TYPE_NORMAL
- en: 'Water Area Before: 16244 km¬≤'
  prefs: []
  type: TYPE_NORMAL
- en: 'Water Area After: 2003 km¬≤'
  prefs: []
  type: TYPE_NORMAL
- en: 'Change: -88%'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, according to our clustering results, the change in water surface
    area is almost **90% (!!!) water loss** over last 23 years, which is real proof
    of the fact that the Aral Sea shrinkage is a planetary tragedy‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: ===========================================
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[1] [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score)'
  prefs: []
  type: TYPE_NORMAL
- en: ===========================================
  prefs: []
  type: TYPE_NORMAL
- en: '***All my publications on Medium are free and open-access, that‚Äôs why I‚Äôd really
    appreciate if you followed me here!***'
  prefs: []
  type: TYPE_NORMAL
- en: P.s. I‚Äôm extremely passionate about (Geo)Data Science, ML/AI and Climate Change.
    So if you want to work together on some project pls contact me in [LinkedIn](https://www.linkedin.com/in/alexxxroz/).
  prefs: []
  type: TYPE_NORMAL
- en: üõ∞Ô∏èFollow for moreüõ∞Ô∏è
  prefs: []
  type: TYPE_NORMAL
