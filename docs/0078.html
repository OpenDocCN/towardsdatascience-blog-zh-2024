<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Probabilistic Data Structures Decoded: Enhancing Performance in Modern Computing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Probabilistic Data Structures Decoded: Enhancing Performance in Modern Computing</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/probabilistic-data-structures-decoded-enhancing-performance-in-modern-computing-17f700e6ea47?source=collection_archive---------5-----------------------#2024-01-09">https://towardsdatascience.com/probabilistic-data-structures-decoded-enhancing-performance-in-modern-computing-17f700e6ea47?source=collection_archive---------5-----------------------#2024-01-09</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="4c4c" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">The Ultimate Guide to Understanding and Implementing Bloom Filters and Count Min Sketch in Python</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://namanagr03.medium.com/?source=post_page---byline--17f700e6ea47--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Naman Agrawal" class="l ep by dd de cx" src="../Images/6bb885397aec17f5029cfac7f01edad9.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*bK6r-T7HXs0aByFOGPsiOw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--17f700e6ea47--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://namanagr03.medium.com/?source=post_page---byline--17f700e6ea47--------------------------------" rel="noopener follow">Naman Agrawal</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--17f700e6ea47--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">26 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 9, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mj bh"><figure class="mk ml mm mn mo mj bh paragraph-image"><img src="../Images/4192b4e13217e5e16700e6354b81f9c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:4800/format:webp/1*8_x9LohHkshWkOfLbDU4NQ.jpeg"/><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Photo by Google DeepMind: <a class="af mx" href="https://www.pexels.com/photo/an-artist-s-illustration-of-artificial-intelligence-ai-this-image-visualises-the-input-and-output-of-neural-networks-and-how-ai-systems-perceive-data-it-was-created-by-rose-pilkington-17485706/" rel="noopener ugc nofollow" target="_blank">https://www.pexels.com/photo/an-artist-s-illustration-of-artificial-intelligence-ai-this-image-visualises-the-input-and-output-of-neural-networks-and-how-ai-systems-perceive-data-it-was-created-by-rose-pilkington-17485706/</a></figcaption></figure></div><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="a10d" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Contents</h1><ol class=""><li id="e394" class="nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk">Introduction</li><li id="cacf" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">What is a Probabilistic Data Structure?</li><li id="bcd1" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">Bloom Filters<br/>3.1 How Do They Work <br/>3.2 Implementing Bloom Filters in Python <br/>3.3 Bloom Filters: Time &amp; Space Complexity Analysis <br/>3.4 Bloom Filters: The Math</li><li id="700b" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">Count Min Sketch<br/>3.1 How Do They Work <br/>3.2 Implementing Count Min Sketch in Python <br/>3.3 Count Min Sketch: Time &amp; Space Complexity Analysis <br/>3.4 Count Min Sketch: The Math</li><li id="9d6f" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">The Bottom Line</li><li id="e8d0" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">References</li></ol><blockquote class="oy oz pa"><p id="9027" class="nu nv pb nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk"><strong class="nw fr">Note:</strong> The entire code file used in this article is available at the following repository: <a class="af mx" href="https://github.com/namanlab/Probabilistic_Data_Structures" rel="noopener ugc nofollow" target="_blank">https://github.com/namanlab/Probabilistic_Data_Structures</a></p></blockquote><h1 id="7c02" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Introduction</h1><p id="ea43" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Computer science enthusiasts often find themselves enamored by the subtle charm of algorithms — the silent workhorses that streamline our digital interactions. At its core, programming is all about getting tasks done through the use of efficient algorithms synchronized with optimal data structures. That’s why there’s a whole field in Computer Science dedicated to the design and analysis of algorithms given their role as the architects of the digital age, quietly shaping our technological experiences with a blend of logic and precision.</p><p id="7f6a" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">A traditional curriculum in data structures and algorithms often exposes students to some of the fundamental data structures (deterministic) such as Arrays, Linked Lists, Stacks and Queues, Binary Search Trees, AVL trees, Heaps, Hash Maps, and of course Graphs. Indeed, the study of such data structures and the associated algorithms constitutes the foundation for the development of much more sophisticated programs aimed at solving a variety of tasks. In this article, I will introduce probabilistic data structures such as Bloom Filters and Count-Min Sketch, some of the lesser-known data structures. While some introductory courses do talk about a few of these briefly, they constitute a subset of those data structures that are often neglected, yet come out as important ideas in various academic discussions. In this article, we will describe what probabilistic data structures are, their significance, examples, and their implementation, as well as go through some of the math required to better gauge their performance. Let’s begin!</p><h1 id="26eb" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">What is a Probabilistic Data Structure?</h1><p id="2a26" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Probabilistic data structures are clever tools in computer science that provide fast and memory-efficient approximations of certain operations. Unlike deterministic data structures, which always give precise and accurate results, probabilistic ones sacrifice a bit of accuracy for added efficiency. In simple terms, these structures use randomness to quickly estimate answers to questions without storing all the exact details; somewhat like smart shortcuts, making educated guesses rather than doing the full work.</p><p id="c3ce" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Take the example of a bloom filter, a probabilistic data structure quite similar to HashSet. It helps you check whether an element is likely in a set or definitely not. It might say ”possibly in the set” or ”definitely not in the set,” but it won’t guarantee ”definitely in the set.” This uncertainty allows it to be fast and save a lot more memory than a traditional hash set.</p><p id="e872" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Deterministic data structures such as linked lists and AVL trees that we commonly encounter, on the other hand, give you 100% sure answers. For example, if you ask whether an element is in a hash set, it’ll say ”yes” or ”no” without any doubt. However, this certainty often comes at the cost of using more memory or taking longer to process.</p><p id="5843" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">The over-arching idea is that probabilistic data structures trade a bit of accuracy for speed and efficiency, making them handy in situations where you can tolerate a small chance of error. They’re like quick and savvy assistants that provide close-to-perfect answers without doing all the heavy lifting. Imagine you have a huge collection of data and want to perform operations like searching, inserting, or checking membership. Deterministic structures guarantee correctness but may become sluggish when dealing with massive datasets. Probabilistic structures, by embracing a bit of uncertainty, provide a way to handle these tasks swiftly and with reduced memory requirements. For the rest of this article, we will explore some of the commonly used probabilistic data structures: Bloom Filters and Count-Min Sketch. Let’s start with Bloom Filters!</p><h1 id="6ba0" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Bloom Filters</h1><p id="1daa" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Bloom filters are designed for quick and memory-efficient membership tests i.e., they help answer the question: ”Is this element a member of a set?” They are particularly handy in scenarios where speed and resource conservation are critical, such as database lookups, network routers, and caching systems.</p><h2 id="1447" class="ph mz fq bf na pi pj pk nd pl pm pn ng od po pp pq oh pr ps pt ol pu pv pw px bk">How Do They Work?</h2><p id="2f17" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">A bloom filter is implemented as an m-sized bit array, which is just an array of size m that is filled with either 0 or 1. An empty bloom filter is initially filled with all 0s. Whenever an element is added, a set of hash functions maps the element to a set of indices. A hash function is a function that transforms input data of any size into a small integer (called a hash code or hash value) that can be used as the index.</p><p id="1ab2" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Recall, how a traditional hash set works. A traditional hash set applies just one hash function on the input data (the element to be added to the set) and produces a hash code corresponding to the index to which the element is added to the table. While this approach provides a simple and fast way to organize and retrieve data (usually in constant, O(1) time), it comes with inherent memory inefficiencies, primarily related to collisions and fixed-size tables.</p><p id="c376" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">The use of a single hash function can lead to collisions, where different elements produce the same hash code and attempt to occupy the same index in the hash table. This affects the efficiency of the hash set, as it necessitates additional mechanisms to handle and resolve such conflicts. Moreover, the fixed size of the hash table leads to inefficiencies in adapting to varying workloads. As the number of elements increases or decreases, the load factor (the ratio of elements to the table size) may become unfavorable. This can lead to increased collisions and degradation of performance. To counter this, hash sets often need to be resized, a process that involves creating a new, larger table and rehashing all existing elements. This operation, while necessary, introduces additional computational overhead and memory requirements.</p><p id="8683" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">A bloom filter on the other hand doesn’t need such a large table, it can do the job with a smaller m-sized array and through the use of multiple hash functions (say, k different hash functions) instead of just a single one. The filter works by applying all the k hash functions on the input data and marking all the k output indices as 1 in the original array. Here’s an example to show how it works.</p><p id="7f4c" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Suppose, we have an m = 5-bit sized array initially filled with 0s and k = 2 hash functions. Usually, the hash functions we use must satisfy two key properties: i) they should be fast to compute, and ii) the output should be more or less uniformly distributed to minimize the risk of false positives (don’t worry, details will be discussed later). Next, we add the elements 64 and 78 to the array.</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu py"><img src="../Images/bcefca769e3234baab4a582897714f1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tvscw5Qb-zgzC723-s-xuQ.jpeg"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Bloom Filter Example [Image by Author]</figcaption></figure><p id="8c9a" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">The above diagram illustrates the process of adding the entries to the array. Once the entries have been added, we can do the membership test. Suppose, we test for the membership of element 36. If h1 and h2 produce index 0 and 3, we can easily see that index 0 has not been occupied yet. This means, that for certain the element is not present in the set. However, we may get the index 2 instead of 3, which is already marked as occupied. This may lead us to the wrong conclusion that 36 is present in the set, even though this was never the case. This is a situation of false positives, that is why we say that a bloom filter can only guarantee when an element is not present. If the element is said to be present, there is still the possibility that it might not be, although the probability of such a case can be made quite small by adjusting the values of m and k.</p><p id="bb8d" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">If you’re still not clear, it may help to imagine a bloom filter as a compact checklist with empty boxes. This checklist represents a set that is initially empty. When you add an element to the set, the bloom filter fills in certain boxes based on the element’s characteristics: each element is hashed multiple times using different hash functions which determine which boxes to mark in the checklist. Multiple hash functions ensure that different parts of the checklist are affected, making it more resilient to false positives. When you want to check if an element is in the set, you hash it using the same functions that marked the boxes during insertion. If all the corresponding boxes are marked, the bloom filter suggests that the element might be in the set. However, false positives can occur — the filter might claim an element is in the set when it’s not. False negatives, on the other hand, never happen. If the boxes aren’t marked, the element is definitely not in the set.</p><p id="cde0" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">As you can see, bloom filters offer speed and efficiency at the expense of some trade-offs. They can produce false positives, but never false negatives. They are fantastic for scenarios where saving memory and quickly filtering out non-members is crucial, but may not be ideal for applications where absolute certainty is required. Now, let’s try to implement them in Python!</p><h2 id="2fe8" class="ph mz fq bf na pi pj pk nd pl pm pn ng od po pp pq oh pr ps pt ol pu pv pw px bk">Implementing Bloom Filters in Python</h2><p id="924f" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Following is the Python implementation of a Bloom Filter.</p><pre class="mk ml mm mn mo qd qe qf bp qg bb bk"><span id="83b0" class="qh mz fq qe b bg qi qj l qk ql">import hashlib<br/>from bitarray import bitarray<br/><br/>class BloomFilter:<br/>    def __init__(self, size, hash_functions):<br/>        """<br/>        Initialize the Bloom Filter with a given size and number of hash functions.<br/><br/>        :param size: Size of the Bloom Filter (number of bits in the bit array).<br/>        :param hash_functions: Number of hash functions to use.<br/>        """<br/>        self.size = size<br/>        self.bit_array = bitarray(size)<br/>        self.bit_array.setall(0)<br/>        self.hash_functions = hash_functions<br/><br/>    def add(self, item):<br/>        """<br/>        Add an element to the Bloom Filter.<br/><br/>        :param item: The item to be added to the Bloom Filter.<br/>        """<br/>        for i in range(self.hash_functions):<br/>            # Calculate the index using the hash function and update the corresponding bit to 1.<br/>            index = self._hash_function(item, i) % self.size<br/>            self.bit_array[index] = 1<br/><br/>    def contains(self, item):<br/>        """<br/>        Check if an element is likely to be in the Bloom Filter.<br/><br/>        :param item: The item to check for presence in the Bloom Filter.<br/><br/>        :return: True if the element is likely present, False otherwise.<br/>        """<br/>        for i in range(self.hash_functions):<br/>            # Calculate the index using the hash function.<br/>            index = self._hash_function(item, i) % self.size<br/>            # If any corresponding bit is 0, the item is definitely not in the set.<br/>            if not self.bit_array[index]:<br/>                return False<br/>        # If all corresponding bits are 1, the item is likely in the set.<br/>        return True<br/><br/>    def _hash_function(self, item, index):<br/>        """<br/>        To compute the hash function for a given item and index.<br/><br/>        :param item: The item to be hashed.<br/>        :param index: The index used to vary the input to the hash function.<br/><br/>        :return: An integer value obtained by hashing the concatenated string of item and index.<br/>        """<br/>        hash_object = hashlib.sha256()<br/>        hash_object.update((str(item) + str(index)).encode('utf-8'))<br/>        return int.from_bytes(hash_object.digest(), byteorder='big')<br/><br/># Example usage:<br/>size = 10  # Size of the Bloom Filter<br/>hash_functions = 3  # Number of hash functions<br/><br/>bloom_filter = BloomFilter(size, hash_functions)<br/><br/># Add elements to the Bloom Filter<br/>bloom_filter.add("apple")<br/>bloom_filter.add("banana")<br/>bloom_filter.add("orange")<br/><br/># Check if elements are present in the Bloom Filter<br/>print(bloom_filter.contains("apple"))    # True<br/>print(bloom_filter.contains("grape"))    # False (not added)</span></pre><p id="e1d3" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">In the above code, we’ve used the bitarray library for a more memory-efficient representation of the filter. You can install it using: <em class="pb">pip3 install bitarray</em> command.</p><p id="a215" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">The BloomFilter class is initialized with a specified size (representing the number of bits in the internal bit array) and the number of hash functions to use. The class has methods to add elements to the filter (add) and check for their probable presence (contains). The hash function method is a private function generating hash values based on the SHA-256 algorithm (it’s a good choice since it is known to produce uniformly distributed outputs).</p><h2 id="5d1d" class="ph mz fq bf na pi pj pk nd pl pm pn ng od po pp pq oh pr ps pt ol pu pv pw px bk">Bloom Filters: Time &amp; Space Complexity Analysis</h2><p id="01be" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Let’s also do a quick time and space analysis of bloom filters. In terms of time complexity, both adding elements (add operation) and checking for their probable presence (contains operation) are constant time operations — O(k), where k is the number of hash functions. This is because the filter involves multiple hash functions, each contributing a constant time to the overall process (assuming that hash functions can be evaluated in constant time).</p><p id="6b62" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">In terms of space complexity, Bloom Filters are memory-efficient since they use a fixed-size bit array. The space required is proportional to the size of the array and the number of hash functions employed. The space complexity is O(m), where m is the size of the bit array. The space efficiency is especially advantageous when dealing with large datasets, as the filter can represent a set of elements using significantly less memory compared to other data structures.</p><h2 id="c8e6" class="ph mz fq bf na pi pj pk nd pl pm pn ng od po pp pq oh pr ps pt ol pu pv pw px bk">Bloom Filters: The Math</h2><p id="252a" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Finally, when it comes to probabilistic data structures, it becomes quintessential to at least propose a bound on the error they can make since they aren’t perfect, unlike their deterministic counterparts. Here, we will go through some math to quantify the probability of making a false positive error and use that to derive meaningful insights.</p><p id="0302" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">First, suppose we have an m-sized bit array along with k hash functions. Furthermore, we assume that our hash functions work uniformly, i.e., for any given input they are equally likely to select any of the m lots in the array. Then, the probability of a particular index i being selected is:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qm"><img src="../Images/e80200507ce7dad84a05d8863c43a2f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q3KhTGFHCGXYNxbTA8DbNg.png"/></div></div></figure><p id="baeb" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Consequently, the probability that the ith index of the bit array is not selected is:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qn"><img src="../Images/e8ed8d08a2fc10072ddbf1a69f602c6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0cTDzbIWhU6kx_yLPYKwYQ.png"/></div></div></figure><p id="fa51" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Now, we bring in the k hash functions. We assume that each of them works independently and produces an output. Further, suppose n elements have been already inserted into the array. This means, that the hash functions were used independently for a total of nk times. The probability that the ith index is still empty is therefore:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qo"><img src="../Images/33e2cfe401208c6572672d72e75267c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fFpdUTQNCO9_B7UNQI4K5w.png"/></div></div></figure><p id="e56c" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Thus, the probability that the ith index is occupied is now:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qp"><img src="../Images/7e9c2161cbccc6035cd98e945f5346e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v8GD5cA-aA9owpN56jMnvQ.png"/></div></div></figure><p id="b299" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">When does a false positive occur? When the index returned by all the elements is 1 even though the element is not present in the set. This happens when the indices produced by all the k hash functions turn out to be occupied. Again, by the independence of the hash function assumption, this amounts to the following probability:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qq"><img src="../Images/89250e768d46d0986904e7c3603fd322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-AnlhCMxXB7hOyGk645iIA.png"/></div></div></figure><p id="b113" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">For sufficiently large values of m, we can approximate the above probability into a much simpler expression:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qr"><img src="../Images/6c5c50cc8ccef57b8a0c48625db778fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QippPQ252DcXFxWt61DEdA.png"/></div></div></figure><p id="93f1" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Can we use this to find the optimal value of k that minimizes ε? Sure, it’s just a simple calculus exercise. We simply take the derivative of the above function with respect to k and set it to 0. But, before that, we can simplify the function a bit by taking logarithms on both sides,</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qs"><img src="../Images/1ce2d350910f32f4293ac3c38f071448.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f1x9DGcuoFl_IXtN6xwzdg.png"/></div></div></figure><p id="0f25" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">This gives us the value of k that minimizes the false positive rate. To ensure that this is really the minimum of the error function, we would ideally want to calculate the second derivative of f(k) and verify our calculation. For the sake of simplicity, we’ve omitted the proof here, but it should be straightforward to show using simple calculus. Next, using the optimal value of k, we can find the minimum value of the error function:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qt"><img src="../Images/652c08b0ad3c78c713fc89639bdc0a7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q3UaNtYzmd5IisPlezzYQg.png"/></div></div></figure><p id="dc49" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Using the above expression, we can also solve for the optimal value of m:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qu"><img src="../Images/18611cdcf57b590e8ccf447ee95def6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-fx8Y23dmTE8hSNyy4nfNA.png"/></div></div></figure><p id="6bc7" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Okay, that’s a lot of math. Let’s try to understand what and why we’ve done. First, we just used some simple probabilistic expressions to find the probability that the slot at the ith index remains empty after n elements have been inserted using k hash functions. Using this, we obtained the probability of false positive error as a function of n, k, and m. Then, we minimized the function with respect to k. Using this optimal value of k, we found the minimum value of the error function. Solving this for m allows us to determine the minimum size of the bit array such that we can tolerate a given value of error.</p><p id="1156" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Let’s take an example to better gauge these results. Suppose we want to implement a bloom filter and need to find the right values of m and k. We expect about 200,000 elements to be inserted i.e., n = 200000, and the max false positive error we can tolerate is about 1% i.e., ε ̄ = 0.01 Then, the optimal values of m and k can be found as follows:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qv"><img src="../Images/452b4f6caf8198282ecbb033bb760d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wDWtKDGFtPC-eCCPozUAJg.png"/></div></div></figure><p id="bc8b" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Using these calculations, we can optimize our original bloom filter implementation:</p><pre class="mk ml mm mn mo qd qe qf bp qg bb bk"><span id="95a2" class="qh mz fq qe b bg qi qj l qk ql">import math<br/>import hashlib<br/>from bitarray import bitarray<br/><br/>class OptimizedBloomFilter:<br/>    def __init__(self, n=10000, p=0.05):<br/>        """<br/>        Initialize the Optimized Bloom Filter with dynamically calculated parameters.<br/><br/>        :param n: Expected number of elements to be added.<br/>        :param p: Acceptable false positive rate.<br/>        """<br/>        self.n = n<br/>        self.p = p<br/>        self.m, self.k = self._calculate_parameters(n, p)<br/><br/>        self.bit_array = bitarray(self.m)<br/>        self.bit_array.setall(0)<br/><br/>    def add(self, item):<br/>        """<br/>        Add an element to the Optimized Bloom Filter.<br/><br/>        :param item: The item to be added to the Bloom Filter.<br/>        """<br/>        for i in range(self.k):<br/>            index = self._hash_function(item, i) % self.m<br/>            self.bit_array[index] = 1<br/><br/>    def contains(self, item):<br/>        """<br/>        Check if an element is likely to be in the Optimized Bloom Filter.<br/><br/>        :param item: The item to check for presence in the Bloom Filter.<br/><br/>        :return: True if the element is likely present, False otherwise.<br/>        """<br/>        for i in range(self.k):<br/>            index = self._hash_function(item, i) % self.m<br/>            if not self.bit_array[index]:<br/>                return False<br/>        return True<br/><br/>    def _calculate_parameters(self, n, p):<br/>        """<br/>        To calculate the optimal parameters m and k based on n and p.<br/><br/>        :param n: Expected number of elements.<br/>        :param p: Acceptable false positive rate.<br/><br/>        :return: Tuple (m, k) representing the optimal parameters.<br/>        """<br/>        m = - (n * math.log(p)) / (math.log(2) ** 2)<br/>        k = (m / n) * math.log(2)<br/>        return round(m), round(k)<br/><br/>    def _hash_function(self, item, index):<br/>        """<br/>        To compute the hash function for a given item and index.<br/><br/>        :param item: The item to be hashed.<br/>        :param index: The index used to vary the input to the hash function.<br/><br/>        :return: An integer value obtained by hashing the concatenated string of item and index.<br/>        """<br/>        hash_object = hashlib.sha256()<br/>        hash_object.update((str(item) + str(index)).encode('utf-8'))<br/>        return int.from_bytes(hash_object.digest(), byteorder='big')<br/><br/># Example usage:<br/>expected_elements = 2000000<br/>false_positive_rate = 0.01<br/><br/>optimized_bloom_filter = OptimizedBloomFilter(expected_elements, false_positive_rate)<br/><br/># Add elements to the Optimized Bloom Filter<br/>optimized_bloom_filter.add("apple")<br/>optimized_bloom_filter.add("banana")<br/>optimized_bloom_filter.add("orange")<br/><br/># Check if elements are present in the Optimized Bloom Filter<br/>print(optimized_bloom_filter.contains("apple"))    # True<br/>print(optimized_bloom_filter.contains("grape"))    # False (not added)</span></pre><p id="b6bb" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">In this implementation, the OptimizedBloomFilter class dynamically calculates the optimal values for m and k based on the provided expected number of elements (n) and acceptable false positive rate (p). The calculate parameters method handles this calculation. The rest of the implementation remains similar to the previous version, with the optimized parameters improving space efficiency and minimizing the probability of false positives.</p><p id="7879" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">This concludes our discussion on bloom filters. Hope you enjoyed reading so far! In the next section, we will discuss another important probabilistic data structure: Count Min Sketch.</p><h1 id="9c8c" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">Count Min Sketch</h1><p id="1f3b" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">In this section, we will discuss another interesting probabilistic data structure: Count Min Sketch. Count Min Sketch is somewhat like an extension of Bloom Filters. Just as the probabilistic counterpart of a hash set is a bloom filter, the counterpart of a multi-set is a count min sketch.</p><p id="5620" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">A multi-set is essentially a set that also keeps count of the frequency or number of occurrences of an element in the input data stream. For instance, if input data is [2, 3, 3, 4, 1, 1, 0, 1, 0], a set would simply be the collection of unique elements i.e., {0, 1, 2, 3, 4}. But, a multi-set would also record the frequency, { 0: 2, 1: 3, 2: 1, 3: 3, 4: 1 }, which can be queried as per requirement. A traditional hash table uses the same data structure as a hash set but also records the frequency count of each element. While it is extremely efficient and can be queried in O(1), there may be a large memory cost to store all the elements as well as additional overhead to handle collisions.</p><p id="42de" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Just as before, count min sketch can be much more efficient than the deterministic hash table by significantly reducing the memory requirements and removing the unnecessary computational cost in handling collisions. But, it must pay the price of accuracy, which fortunately can be accounted for by adjusting for the values of m and k as before. Let us take a closer look at how count min sketch works.</p><h2 id="87a3" class="ph mz fq bf na pi pj pk nd pl pm pn ng od po pp pq oh pr ps pt ol pu pv pw px bk">How Do They Work?</h2><p id="9fbf" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">The core idea behind Count Min Sketch involves using multiple hash functions to map input elements to an array of counters. The array is organized as a two-dimensional matrix, consisting of m columns and k rows with each row corresponding to the hash functions and the columns representing the counters. When an element is encountered in the data stream, it is hashed using each of the hash functions, and the corresponding counters in the matrix are incremented. Due to the nature of hash functions, collisions are inevitable. However, the use of multiple hash functions and a two-dimensional matrix allows Count Min Sketch to distribute the collisions across different counters. This distribution helps in reducing the impact of collisions on the accuracy of the counts.</p><p id="918a" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Suppose, we have an m = 5 (number of columns) and k = 2 (number of rows) hash functions. This means, we only need an array of size m×k = 5×2. Initially, the array is filled with all 0s. Next, we add the elements 2, 3, 2, 2, and 1 to the set. The process is similar to that of a bloom filter. We apply the k hash filters on the input data (the element to be added) and get k indices. Let ji be the output of the ith hash function. Then, we increment the jith index of the ith row by 1. The following figure illustrates how it’s done:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qw"><img src="../Images/e2f74d630ade158add500c26316a616f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kR8PZ-PsVpUK3_iAhNhNCQ.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Count Min Sketch Example [Image by Author]</figcaption></figure><p id="7b3f" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">To estimate the frequency of an element, one looks up the counters corresponding to its hashed values and selects the minimum count among them. This minimum count provides an approximation of the true frequency. By repeating this process for multiple elements and taking the minimum counts, one can obtain approximate frequency estimates for various items in the data stream. For instance, if we query for the frequency of 2 in the set, we look at the minimum of 3 and 4 which is 3, and this is indeed the frequency of 2 in the input stream. Similarly, the frequency of 1 is the minimum of 1 and 4, which is 1, again the correct output. It is important to note that count min sketch only provides a maximum bound on the frequency of an element. This bound is derived from the way the algorithm distributes counts across different counters. It may be possible that the indices corresponding to the output of all the k hash functions on the input data might be incremented, not because of the addition of that element per se, but all the other elements in that set. An example is shown below, when we add 4 to the set as well.</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qx"><img src="../Images/de2dd71a25353c509686e5b9429e3913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gig22bsklg7DBTd1fVZFaw.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Count Min Sketch Example (False Positive) [Image by Author]</figcaption></figure><p id="4e04" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Now if we try to query the frequency for 4, we look at the minimum of 4 and 2, which is 2, higher than the actual frequency of 1. This is because the indices corresponding to the output of the hash functions were already filled with those from the other elements due to collisions. The output isn’t perfect, but it is still an upper bound on the actual frequency.</p><p id="3ba2" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">As before, the parameters ’m’ and ’k’ in the Count Min Sketch matrix play a crucial role in balancing memory usage and accuracy. The number of rows ’m’ determines the number of hash functions employed, while the number of columns ’k’ dictates the size of each row and, consequently, the amount of memory used. Adjusting these parameters allows users to control the trade-off between space efficiency and estimation accuracy based on the specific requirements of their application.</p><h2 id="a392" class="ph mz fq bf na pi pj pk nd pl pm pn ng od po pp pq oh pr ps pt ol pu pv pw px bk">Implementing Count Min Sketch in Python</h2><p id="e947" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Following is the Python implementation of a Count Min Sketch.</p><pre class="mk ml mm mn mo qd qe qf bp qg bb bk"><span id="7a19" class="qh mz fq qe b bg qi qj l qk ql">import hashlib<br/><br/>class CountMinSketch:<br/>    def __init__(self, m, k):<br/>        """<br/>        Initialize the Count-Min Sketch with specified width and depth.<br/><br/>        :param width: Number of counters in each hash function's array.<br/>        :param depth: Number of hash functions.<br/>        """<br/>        self.width = m<br/>        self.depth = k<br/>        self.counters = [[0] * m for _ in range(k)]<br/><br/>    def update(self, item, count=1):<br/>        """<br/>        Update the Count-Min Sketch with the occurrence of an item.<br/><br/>        :param item: The item to be counted.<br/>        :param count: The count or frequency of the item (default is 1).<br/>        """<br/>        for i in range(self.depth):<br/>            index = self._hash_function(item, i) % self.width<br/>            self.counters[i][index] += count<br/><br/>    def estimate(self, item):<br/>        """<br/>        Estimate the count or frequency of an item in the Count-Min Sketch.<br/><br/>        :param item: The item to estimate the count for.<br/><br/>        :return: The estimated count of the item.<br/>        """<br/>        min_count = float('inf')<br/>        for i in range(self.depth):<br/>            index = self._hash_function(item, i) % self.width<br/>            min_count = min(min_count, self.counters[i][index])<br/>        return min_count<br/><br/>    def _hash_function(self, item, index):<br/>        """<br/>        To compute the hash function for a given item and index.<br/><br/>        :param item: The item to be hashed.<br/>        :param index: The index used to vary the input to the hash function.<br/><br/>        :return: An integer value obtained by hashing the concatenated string of item and index.<br/>        """<br/>        hash_object = hashlib.sha256()<br/>        hash_object.update((str(item) + str(index)).encode('utf-8'))<br/>        return int.from_bytes(hash_object.digest(), byteorder='big')<br/><br/># Example usage:<br/>m = 100<br/>k = 5<br/><br/>count_min_sketch = CountMinSketch(m, k)<br/><br/># Update the sketch with occurrences of items<br/>count_min_sketch.update("apple", 3)<br/>count_min_sketch.update("banana", 5)<br/>count_min_sketch.update("orange", 2)<br/><br/># Estimate counts for items<br/>print(count_min_sketch.estimate("apple"))    # Estimated count for "apple"<br/>print(count_min_sketch.estimate("grape"))    # Estimated count for "grape" (not updated)</span></pre><p id="ba6a" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">In the above code, the CountMinSketch class is initialized with specified m and k parameters, representing the number of counters in each hash function’s array and the number of hash functions, respectively. The sketch is updated with occurrences of items, and estimates of item counts can be obtained. The hash function method is responsible for generating hash values, and the example usage section demonstrates how to use the Count-Min Sketch to estimate counts for specific items in a streaming fashion. As in the case of bloom filters, the SHA-256 algorithm is used for hashing since it is known to produce uniformly distributed outputs.</p><h2 id="3599" class="ph mz fq bf na pi pj pk nd pl pm pn ng od po pp pq oh pr ps pt ol pu pv pw px bk">Count Min Sketch: Time &amp; Space Complexity Analysis</h2><p id="a113" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Let’s also do a quick time and space analysis of the count min sketch. In terms of time complexity, both the addition of elements (incrementing counters) and the estimation of their frequencies in Count Min Sketch are constant time operations: O(k). The constant factor is influenced by the number of hash functions (’k’) and the size of the matrix (’m’). However, assuming that hash functions can be evaluated in constant time, the overall complexity remains constant. The operations involve multiple hash functions, each contributing a constant time to the overall process.</p><p id="bc7e" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Regarding space complexity, Count Min Sketch is memory-efficient due to its use of a compact matrix structure. The space required is proportional to the product of the number of rows (’m’) and the number of counters per row (’k’). Thus, the space complexity is expressed as O(m * k). We have the flexibility to adjust the values of ’m’ and ’k’ to strike a balance between space efficiency and estimation accuracy. Smaller values result in reduced memory usage but may lead to more estimation errors, while larger values improve accuracy at the expense of increased memory requirements. This tunability makes Count Min Sketch a versatile solution for scenarios where memory constraints are critical, and approximate frequency counts are acceptable.</p><h2 id="74cb" class="ph mz fq bf na pi pj pk nd pl pm pn ng od po pp pq oh pr ps pt ol pu pv pw px bk">Count Min Sketch: The Math</h2><p id="1035" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">As before, using our knowledge of probability theory, we can optimize the count min sketch i.e., find the values of m and k that minimize the possibility of an error. First, let us formalize the notations. Let hat-fₓ denote the frequency estimate for the element x and fₓ denote the actual frequency of that element. Based on our earlier discussion, we must have:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qy"><img src="../Images/930919c0257cbf1e2b2f1b63d93ff125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rdzjTcyyDa6cS2ESEEBkzw.png"/></div></div></figure><p id="3d23" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">i.e., we are always sure that our estimate is at least the actual frequency count. But is this enough? A stupid algorithm that always outputs a very large number can also achieve this. What makes the count min sketch so special is that we can upper bound not only the actual frequency fₓ but also the deviation of the estimated frequency hat-fₓ from the actual frequency (probabilistic-ally of course). Using an optimal value of m and k, we can guarantee the following:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qz"><img src="../Images/137f0ee281a9576a8c9fb6a9d348f661.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SG_TSSuvcw7YbLTjQ_hTZg.png"/></div></div></figure><p id="9b34" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">i.e., the probability that the estimated frequency exceeds the actual frequency by a value of more than or equal to εn (n is the size of the input stream) is at least (1 − δ), where ε and δ can be made as small as required. The values of m and k that satisfy this are as follows:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu ra"><img src="../Images/cd4813fc28efb1f0a71352535e2f74cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1z-PAeHjqj7TgGO43l6vFA.png"/></div></div></figure><p id="21fb" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">As we can see, the number of columns (m) controls for the max value of deviation (hat-fₓ −fₓ ), while the number of rows/hash functions (k) controls for the probabilistic guarantee, 1 − δ. The proof of this is quite convoluted and requires some intermediate knowledge of probability theory like random variables and Markov inequality. I will be going through this proof in detail in the following paragraphs. If you’re curious and have the necessary prerequisites, you may continue reading.</p><p id="94f5" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">So, let’s begin with the proof. First, we define certain quantities: Let αᵢ, ₕᵢ₍ₓ₎ denote the value in the ith row and hᵢ(x) the column of the count min sketch array. This is simply the frequency estimate of x as per the ith row/ith hash function used. This means that the estimated frequency is simply the minimum of this value for all rows:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rb"><img src="../Images/816700ab8f3054b96763e00135ada35f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v6yefY3cBlq5wmSl8se0WA.png"/></div></div></figure><p id="7847" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">We now define the random variable Zᵢ (called over-count) as follows:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rc"><img src="../Images/cfda04f9b26574ad76ebbc97c8d645e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PtW2n8upqk3-ixzZerwtVg.png"/></div></div></figure><p id="48cc" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Next, we define an indicator random variable Xᵢ,ᵧ to check if a collision has occurred in the ith row with some other element y ≠ x. Formally,</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rd"><img src="../Images/4dae31722d2ff1cdf4c9f193755fe928.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W9Qf_XMEAY5XUjFlHi-F9g.png"/></div></div></figure><p id="51ec" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Now, let’s think of the relationship between Zᵢ and Xᵢ,ᵧ Recall that Zᵢ is the over-count i.e., the value by which αᵢ, ₕᵢ₍ₓ₎ exceeds the actual frequency fₓ. When does this happen? This happens when there are collisions with elements y ≠ x. This allows us to define the following relation:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu re"><img src="../Images/4a7c559b4e11d039caec84d056d2d5b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fmVxAKoZ3WW8vE9peZ8hrQ.png"/></div></div></figure><p id="077f" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Note that we’ve weighted the sum with the actual frequency estimates of y since the elements may occur multiple times, each time causing the overcount to increase. The next step involves finding the expected value of Zᵢ or the over-count using properties of expectation:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rf"><img src="../Images/61c49c4da41ce40dc16335d536be62d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Y8Iy9bGvv4iPh8iHTuqtw.png"/></div></div></figure><p id="b3a9" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">where n denotes the expected length of the input stream, which is more than or equal to the sum of the frequencies of all the other elements. Finally, we use Markov’s inequality to find the probability that Zᵢ exceeds its expectation multiplied by a constant:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rg"><img src="../Images/3d80bdbe1caa09ee8ccd0a529425515a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ccS3GTzx4YrYrHQJQzduCA.png"/></div></div></figure><p id="0ccc" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">The above is just the direct use of Markov’s inequality. We may now use the fact that E [Zᵢ] ≤ n/m to get:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rh"><img src="../Images/44fa4d57df89fc32e9bffee19a71aa86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B5EcVi7qoMoia_8Vqmsl8g.png"/></div></div></figure><p id="117d" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Recall the expression we want to prove. All we want on the right-hand side of the inequality in the probability term is εn. Currently, we have an/m. Taking a = mε will allow us to get this term. Therefore,</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu ri"><img src="../Images/3aa530c03256b0ee476535a955e98415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JRAknBxslhSPYve2ktlEnA.png"/></div></div></figure><p id="0516" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Now we substitute in m = e/ε to get:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rj"><img src="../Images/070aab6abb8b36d25b182ad432ef9cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mhu2mxIqG43gY9olMx2AQA.png"/></div></div></figure><p id="810a" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">The above must be true for all Zᵢ from i = 1 to i = k. Thus, we can write:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rk"><img src="../Images/bdc29310badf3cceb511d254432eba55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7KaEH-JI8evhJwx79IXHHg.png"/></div></div></figure><p id="f225" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Since the above expression holds for all i, it must also hold for the minimum:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rl"><img src="../Images/878f45a3df2d2327e196d2935615c338.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2KMR47LI37rwa_fOuyflEg.png"/></div></div></figure><p id="e467" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Finally, we take the complement of the above probability and substitute for the value of k:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu rm"><img src="../Images/8038942a83fefb97db26aaada0973176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q2U4qB6Pbscz0jf2-eEarQ.png"/></div></div></figure><p id="1b33" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">This completes the proof. From this, we can conclude that to achieve a max deviation of εn with a probabilistic guarantee of 1 − δ, we need the following:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="pz qa ed qb bh qc"><div class="mt mu qm"><img src="../Images/576644e30b9173c9941a9d03ea1af174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m29SkwloIfwRL7shBCjUFw.png"/></div></div></figure><p id="afaa" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Using these calculations, we can optimize our original count min sketch implementation:</p><pre class="mk ml mm mn mo qd qe qf bp qg bb bk"><span id="092d" class="qh mz fq qe b bg qi qj l qk ql">import hashlib<br/>import math<br/><br/>class OptimizedCountMinSketch:<br/>    def __init__(self, epsilon, delta):<br/>        """<br/>        Initialize the Count-Min Sketch with specified width and depth.<br/><br/>        :param epsilon: Quantifies the max deviation from true count (epsilon * n)<br/>        :param delta: To compute the probabilistic guarantee<br/>        """<br/>        self.epsilon = epsilon<br/>        self.delta = delta<br/>        self.width, self.depth = self._calculate_parameters(epsilon, delta)<br/>        self.counters = [[0] * self.width for _ in range(self.depth)]<br/><br/>    def update(self, item, count=1):<br/>        """<br/>        Update the Count-Min Sketch with the occurrence of an item.<br/><br/>        :param item: The item to be counted.<br/>        :param count: The count or frequency of the item (default is 1).<br/>        """<br/>        for i in range(self.depth):<br/>            index = self._hash_function(item, i) % self.width<br/>            self.counters[i][index] += count<br/><br/>    def estimate(self, item):<br/>        """<br/>        Estimate the count or frequency of an item in the Count-Min Sketch.<br/><br/>        :param item: The item to estimate the count for.<br/><br/>        :return: The estimated count of the item.<br/>        """<br/>        min_count = float('inf')<br/>        for i in range(self.depth):<br/>            index = self._hash_function(item, i) % self.width<br/>            min_count = min(min_count, self.counters[i][index])<br/>        return min_count<br/><br/>    def _calculate_parameters(self, epsilon, delta):<br/>        """<br/>        To calculate the optimal parameters m and k based on s and e.<br/><br/>        :param epsilon: Quantifies the max deviation from true count (epsilon * n)<br/>        :param delta: To compute the probabilistic guarantee<br/><br/>        :return: Tuple (m, k) representing the optimal parameters.<br/>        """<br/>        m = math.ceil(math.e/epsilon)<br/>        k = math.ceil(math.log(1/delta))<br/>        return m, k<br/><br/>    def _hash_function(self, item, index):<br/>        """<br/>        To compute the hash function for a given item and index.<br/><br/>        :param item: The item to be hashed.<br/>        :param index: The index used to vary the input to the hash function.<br/><br/>        :return: An integer value obtained by hashing the concatenated string of item and index.<br/>        """<br/>        hash_object = hashlib.sha256()<br/>        hash_object.update((str(item) + str(index)).encode('utf-8'))<br/>        return int.from_bytes(hash_object.digest(), byteorder='big')<br/><br/># Example usage:<br/>eps = 0.01<br/>delta = 0.05<br/><br/>optimized_count_min_sketch = OptimizedCountMinSketch(eps, delta)<br/><br/># Update the sketch with occurrences of items<br/>optimized_count_min_sketch.update("apple", 3)<br/>optimized_count_min_sketch.update("banana", 5)<br/>optimized_count_min_sketch.update("orange", 2)<br/><br/># Estimate counts for items<br/>print(count_min_sketch.estimate("apple"))    # Estimated count for "apple"<br/>print(count_min_sketch.estimate("grape"))    # Estimated count for "grape" (not updated)</span></pre><p id="d1cd" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">In this implementation, the OptimizedCountMinSketch class dynamically calculates the optimal values for m and k based on the provided max deviation tolerance (epsilon) and probabilistic requirement (delta). The calculate parameters method handles this calculation. The rest of the implementation remains similar to the previous version, with the optimized parameters achieving the required guarantee.</p><p id="21db" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">This concludes our discussion on Count Min Sketch.</p><h1 id="0d74" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">The Bottom Line</h1><p id="d19b" class="pw-post-body-paragraph nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op fj bk">Donald Knuth, the father of the analysis of algorithms had said,</p><blockquote class="rn"><p id="fd09" class="ro rp fq bf rq rr rs rt ru rv rw op dx">“An algorithm must be seen to be believed”.</p></blockquote><p id="d02b" class="pw-post-body-paragraph nu nv fq nw b go rx ny nz gr ry ob oc od rz of og oh sa oj ok ol sb on oo op fj bk">Indeed, the ability to appreciate an algorithm comes, not only from using it, but understanding how it works and why it works. In this article, I’ve tried to describe the inner workings of two important probabilistic data structures and their algorithms. We talked about their performance relative to their deterministic counterparts, and implementation, as well as used some math to quantify their error bound. Although quite important in literature, these data structures merely constitute the surface of an ocean of other probabilistic data structures such as skip lists, hyper log-log, treap, quotient filter, min hash, etc. Many of these are very interesting and have a lot of potential applications in the field of computer science. I hope to go through some of these in further detail in my subsequent articles.</p><p id="4c4a" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">Hope you enjoyed reading this article! In case you have any doubts or suggestions, do reply in the comment box. Please feel free to contact me via <a class="af mx" href="mailto:naman.agr03@gmail.com" rel="noopener ugc nofollow" target="_blank">mail</a>.</p><p id="0c11" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk">If you liked my article and want to read more of them, please follow me.</p><p id="5f40" class="pw-post-body-paragraph nu nv fq nw b go pc ny nz gr pd ob oc od pe of og oh pf oj ok ol pg on oo op fj bk"><strong class="nw fr">Note:</strong> All images (except for the cover image) have been made by the author.</p><h1 id="4af5" class="my mz fq bf na nb nc gq nd ne nf gt ng nh ni nj nk nl nm nn no np nq nr ns nt bk">References</h1><ol class=""><li id="6054" class="nu nv fq nw b go nx ny nz gr oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk">Bloom filter — Wikipedia — en.wikipedia.org. <a class="af mx" href="https://en.wikipedia.org/wiki/Bloom_filter." rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Bloom_filter.</a> [Accessed 07–01- 2024].</li><li id="7e3c" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">Bloom Filters — Introduction and Implementation — GeeksforGeeks — geeksforgeeks.org. <a class="af mx" href="https://www." rel="noopener ugc nofollow" target="_blank">https://www.</a> geeksforgeeks.org/bloom-filters-introduction-and-python-implementation/. [Accessed 07–01–2024].</li><li id="55a4" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">Count-Min Sketch Data Structure with Implementation — GeeksforGeeks — geeksforgeeks.org. <a class="af mx" href="https://www." rel="noopener ugc nofollow" target="_blank">https://www.</a> geeksforgeeks.org/count-min-sketch-in-java-with-examples/. [Accessed 07–01–2024].</li><li id="8cbe" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">Counting Bloom Filters — Introduction and Implementation — GeeksforGeeks — geeksforgeeks.org. <a class="af mx" href="https://www." rel="noopener ugc nofollow" target="_blank">https://www.</a> geeksforgeeks.org/counting-bloom-filters-introduction-and-implementation/. [Accessed 07–01–2024].</li><li id="1c58" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">Count–min sketch — Wikipedia — en.wikipedia.org. <a class="af mx" href="https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch." rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch.</a> [Accessed 07–01–2024].</li><li id="ec78" class="nu nv fq nw b go ot ny nz gr ou ob oc od ov of og oh ow oj ok ol ox on oo op oq or os bk">Humberto Villalta. Bloom Filter Mathematical Proof — humberto521336. <a class="af mx" href="https://medium.com/@humberto521336/" rel="noopener">https://medium.com/@humberto521336/</a> bloom-filters-mathematical-proof-8aa2e5d7b06b. [Accessed 07–01–2024].</li></ol></div></div></div></div>    
</body>
</html>