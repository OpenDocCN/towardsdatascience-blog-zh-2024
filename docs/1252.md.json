["```py\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n\nmessages = [\n        {\n            \"role\": \"user\",\n            \"content\": \"some questions.\",\n        },\n]\n\nencodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\nmodel_inputs = encodeds.to(\"cuda\")\n```", "```py\nimport torch\n\nwith torch.no_grad():\n    return model(model_inputs).logits\n```", "```py\nimport torch\nwith torch.no_grad():\n    return model(model_inputs).logits[:, -1, :]\n```", "```py\nimport torch\ndef compute_cosine_similarity(vec1, vec2):\n    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n    return cos(vec1, vec2)\n```", "```py\nimport torch\nfrom termcolor import colored\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.1\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n\ndef generate_last_token_embeddings(question):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": question,\n        },\n    ]\n    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n    model_inputs = encodeds.to(\"cuda\")\n    with torch.no_grad():\n        return model(model_inputs).logits[:, -1, :]\n\ndef get_similarities(questions, answers):\n    for question in questions:\n        for answer in answers:\n            q_embedding, a_embedding = (\n                generate_last_token_embeddings(question),\n                generate_last_token_embeddings(answer),\n            )\n            similarity = compute_cosine_similarity(q_embedding, a_embedding)\n            print(colored(f\"question: {question} and ans: {answer}\", \"green\"))\n            print(colored(f\"result: {similarity}\", \"blue\"))\n\nquestions = [\"Where is the headquarter of OpenAI?\", \"What is GPU?\"]\nanswers = [\n    \"OpenAI is based at San Francisco.\",\n    \"A graphics processing unit (GPU) is an electronic circuit that can perform mathematical calculations quickly\",\n]\nget_similarities(questions, answers)\n```", "```py\ntokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-mistral-7b-instruct\")\nmodel = AutoModelForCausalLM.from_pretrained(\n  \"intfloat/e5-mistral-7b-instruct\"\n)\n```"]