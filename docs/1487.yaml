- en: Understanding Buffer of Thoughts (BoT) — Reasoning with Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解思维缓冲区（BoT）——与大型语言模型推理
- en: 原文：[https://towardsdatascience.com/understanding-buffer-of-thoughts-bot-reasoning-with-large-language-models-391919d2f76f?source=collection_archive---------1-----------------------#2024-06-14](https://towardsdatascience.com/understanding-buffer-of-thoughts-bot-reasoning-with-large-language-models-391919d2f76f?source=collection_archive---------1-----------------------#2024-06-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/understanding-buffer-of-thoughts-bot-reasoning-with-large-language-models-391919d2f76f?source=collection_archive---------1-----------------------#2024-06-14](https://towardsdatascience.com/understanding-buffer-of-thoughts-bot-reasoning-with-large-language-models-391919d2f76f?source=collection_archive---------1-----------------------#2024-06-14)
- en: A new prompting tool for complex reasoning, compared with Chain of thought (CoT)
    and Tree of Thought (ToT)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种用于复杂推理的新提示工具，与思维链（CoT）和思维树（ToT）进行比较
- en: '[](https://medium.com/@itshesamsheikh?source=post_page---byline--391919d2f76f--------------------------------)[![Hesam
    Sheikh](../Images/b8d5f4f285eef77634e4c1d4321580ed.png)](https://medium.com/@itshesamsheikh?source=post_page---byline--391919d2f76f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--391919d2f76f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--391919d2f76f--------------------------------)
    [Hesam Sheikh](https://medium.com/@itshesamsheikh?source=post_page---byline--391919d2f76f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@itshesamsheikh?source=post_page---byline--391919d2f76f--------------------------------)[![Hesam
    Sheikh](../Images/b8d5f4f285eef77634e4c1d4321580ed.png)](https://medium.com/@itshesamsheikh?source=post_page---byline--391919d2f76f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--391919d2f76f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--391919d2f76f--------------------------------)
    [Hesam Sheikh](https://medium.com/@itshesamsheikh?source=post_page---byline--391919d2f76f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--391919d2f76f--------------------------------)
    ·10 min read·Jun 14, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--391919d2f76f--------------------------------)
    ·阅读时间：10分钟·2024年6月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: If you’re not a member, [**read for free!**](https://hesamsheikh.substack.com/)
    **✨**
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你不是会员，[**免费阅读！**](https://hesamsheikh.substack.com/) **✨**
- en: '![](../Images/1dd8cf331a7b47649dd087344982ff56.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1dd8cf331a7b47649dd087344982ff56.png)'
- en: Photo by [Etienne Girardet](https://unsplash.com/@etiennegirardet?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Etienne Girardet](https://unsplash.com/@etiennegirardet?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Squeezing proficiency in complex reasoning tasks and avoiding hallucinations
    remains a major research topic in Large Language Models (LLMs). Despite the effort,
    LLMs need help with generalized reasoning capabilities. Traditional methods such
    as **Chain-of-Thought (CoT)** or **Tree-of-Thought (ToT)** often require multiple
    assumptions or numerous back-and-forth prompting which means intensive computation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 提升在复杂推理任务中的能力并避免幻觉依然是大型语言模型（LLMs）中的一个主要研究课题。尽管进行了大量努力，LLMs 仍然在广泛推理能力上需要帮助。传统方法，如**思维链（CoT）**或**思维树（ToT）**，通常需要多个假设或大量的反复提示，这意味着需要强大的计算资源。
- en: '![](../Images/acb9be520c3976344727f77d1cbdfb81.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/acb9be520c3976344727f77d1cbdfb81.png)'
- en: 'Buffer of Thoughts (BoT) vs other prompting methods. (source: [Paper](https://arxiv.org/abs/2406.04271))'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 思维缓冲区（BoT）与其他提示方法的比较。（来源：[论文](https://arxiv.org/abs/2406.04271)）
- en: 'The new proposed method in the paper, [**Buffer of Thoughts: Thought-Augmented
    Reasoning with Large Language Models**](https://arxiv.org/abs/2406.04271) **[1]**,
    combats these limitations with a dynamic, adaptive repository of high-level thought
    templatescalled **meta-buffer.** In BoT, once the user presents a new problem,
    it is first simplified and analyzed to extract key elements, which then guide
    the retrieval of a relevant thought template from a dynamic dataset. This allows
    adaptive and efficient problem-solving through modified and complex reasoning
    patterns. According to the original paper, this is so effective that *“****Llama3–8B+BoT***
    *has the potential to surpass* ***Llama3–70B model.”***'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中提出的新的方法，[**思维缓冲区：基于大语言模型的思维增强推理**](https://arxiv.org/abs/2406.04271) **[1]**，通过一个动态、自适应的高层次思维模板库——**元缓冲区（meta-buffer）**，来应对这些局限。在BoT中，一旦用户提出一个新问题，首先对问题进行简化和分析，以提取关键信息，然后从动态数据集中检索与之相关的思维模板。这使得通过修改和复杂的推理模式实现自适应和高效的问题解决。根据原始论文，效果如此显著，*“****Llama3–8B+BoT***
    *有潜力超越* ***Llama3–70B模型。”***
- en: '**BoT** achieves efficient reasoning across problems that are similar to its
    templates as it:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**BoT**通过以下方式，在与其模板相似的问题中实现高效推理：'
- en: (1) leverages previous solutions on new challenges,
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1) 在新挑战中借用以前的解决方案，
- en: (2) boosts efficiency by eliminating the need for multiple query iterations
    (as we see in Graph-of-Thoughts (GoT) or ToT), and
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (2) 提高效率，避免多次查询迭代（正如我们在思维图（Graph-of-Thoughts, GoT）或思维链（ToT）中所看到的），并
- en: (3) dynamically updates its template repository to ensure it evolves as it encounters
    new tasks.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (3) 动态更新其模板库，以确保在遇到新任务时能够不断发展。
- en: In this article, we will first go through the general outline of how BoT works,
    understand the function of each key part, and test the procedure with an example.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将首先了解BoT如何工作的一般概述，理解每个关键部分的功能，并通过一个示例测试该过程。
- en: How does BoT work?
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BoT是如何工作的？
- en: The general thought-augmented reasoning process (as shown in the figure below)
    starts with **Problem Distillation**, which analyzes and condenses the incoming
    task into essential elements and constraints and then creates a simplified problem
    statement.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一般的思维增强推理过程（如下图所示）从**问题提炼**开始，分析并浓缩传入的任务，提取出关键元素和约束条件，进而创建简化的问题陈述。
- en: This distilled information is then used to query the **Meta-Buffer**, a dynamic
    repository that contains high-level thought templates. From the thought templates,
    one that is most similar to the distilled problem is retrieved. Then, during the
    **Instantiation Process**, it is instantiated with specific requirements and information
    about the distilled problem.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些提炼的信息随后被用来查询**元缓冲区（Meta-Buffer）**，这是一个包含高层次思维模板的动态库。从思维模板中，检索出与提炼问题最相似的模板。接下来，在**实例化过程（Instantiation
    Process）**中，它会根据提炼问题的具体要求和信息进行实例化。
- en: Throughout this process, the **Buffer Manager** actively keeps an eye on the
    **Meta-Buffer.** Once it detects a new insight not included in the meta-buffer,
    **Buffer Manager** updates it to ensure a continual evolution of the thought template
    repository.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，**缓冲区管理器（Buffer Manager）**会主动监控**元缓冲区（Meta-Buffer）**。一旦检测到元缓冲区中未包含的新见解，**缓冲区管理器（Buffer
    Manager）**会更新元缓冲区，确保思维模板库的持续进化。
- en: '![](../Images/32292bd0be51f32c6798de545021c314.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32292bd0be51f32c6798de545021c314.png)'
- en: 'The BoT process. (source: [Paper](http://Paper))'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: BoT过程。（来源：[论文](http://Paper)）
- en: 'Let’s go through each of these key parts to gain a more detailed look:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一了解这些关键部分，深入探讨每一部分的细节：
- en: Problem Distiller
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题提炼器
- en: Problem Distiller can be thought of as a **preprocess** on the input tasks in
    order to…
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 问题提炼器可以看作是对输入任务的**预处理**，目的是……
- en: (1) extract essential information of the problem, and
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1) 提取问题的关键信息，并
- en: (2) simplify complex tasks for a better search and retrieval of thought templates.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (2) 简化复杂任务，以便更好地搜索和检索思维模板。
- en: 'Problem Distiller takes the burden off of LLM to identify and extract vital
    information and constraints of the problem. This is done by a meta prompt ϕ:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 问题提炼器（Problem Distiller）通过元提示ϕ减轻了大语言模型（LLM）识别和提取问题的关键信息与约束的负担：
- en: '![](../Images/944bc53eb01b77fdf82f8608b1a19b46.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/944bc53eb01b77fdf82f8608b1a19b46.png)'
- en: '(source: [Paper](http://Paper))'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: （来源：[论文](http://Paper)）
- en: 'The prompt used by the authors to distill key information about a task is as
    follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作者用于提炼任务关键信息的提示如下：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Meta-Buffer
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元缓冲区（Meta-Buffer）
- en: The meta-buffer is a central database that stores high-level thought templates.
    These templates are high-level abstractions representing various problem-solving
    processes. The idea is that LLM can leverage past problems and insights to solve
    current challenges. The best part is that the Meta-Buffer dynamically updates
    to ensure new unseen problems are also included. The Meta-Buffer doesn’t enforce
    thought templates to follow a specific instruction.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 元缓冲区是一个中央数据库，存储着高级的思维模板。这些模板是表示各种问题解决过程的高级抽象。其理念是LLM可以利用过去的问题和见解来解决当前的挑战。最棒的是，元缓冲区会动态更新，以确保新的未见过的问题也能被包括在内。元缓冲区不会强制思维模板遵循特定的指令。
- en: '**Template Retrieval**: Once a task is distilled, BoT would go through the
    thought templates and grab the one most similar to the task. This is done by calculating
    the embedding similarity between the task and the thought templates.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**模板检索**：一旦任务被提炼，BoT会遍历思维模板并抓取与任务最相似的一个。通过计算任务与思维模板之间的嵌入相似度来完成此操作。'
- en: '![](../Images/3877ad60c789b210ee2cd5f42b642b33.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3877ad60c789b210ee2cd5f42b642b33.png)'
- en: 'The retriever would calculate the similarity between the embedding of the input
    task f(xd), and the embedding of templates f(DTi ). (source: [Paper](https://arxiv.org/abs/2406.04271))'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 检索器会计算输入任务f(xd)的嵌入与模板f(DTi)的嵌入之间的相似度。（来源：[论文](https://arxiv.org/abs/2406.04271)）
- en: 'the retriever would calculate the similarity between the embedding of the input
    task **f(xd)**, and the embedding of templates **f(D*Ti* ).** This is only done
    if the similarity is above a certain threshold δ (0.5–0.7). If none of the thought
    templates have a similarity score with the task above the δ threshold, then the
    **xd** is identified as a new task. Depending on if the task is new or not, one
    of the two paths would be taken:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 检索器会计算输入任务**f(xd)**的嵌入与模板**f(D*Ti*)**的嵌入之间的相似度。仅在相似度超过某个阈值δ（0.5–0.7）时才会进行此操作。如果没有思维模板与任务的相似度超过δ阈值，则**xd**会被识别为新任务。根据任务是否是新任务，将选择以下两条路径之一：
- en: If the task is similar to one of the thought templates, the template would be
    instantiated with the distilled information using an instantiation prompt (which
    you can check in the paper). This instantiation process can be denoted as
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果任务与某个思维模板相似，则会使用实例化提示（可以在论文中查看）用提炼过的信息实例化该模板。这个实例化过程可以表示为
- en: '![](../Images/872661a6c9986487d31d5d362f937a78.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/872661a6c9986487d31d5d362f937a78.png)'
- en: 'Instantiated Reasoning. (source: [Paper](https://arxiv.org/abs/2406.04271))'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化推理。（来源：[论文](https://arxiv.org/abs/2406.04271)）
- en: If the task is new, a general thought template that is designed to address a
    broad set of problems is used. As the task is processed, the **Buffer Manager**
    observes and learns and potentially creates a new, more specific thought template
    and pushes it to the meta-buffer.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果任务是新的，则使用一个旨在解决广泛问题的通用思维模板。随着任务的处理，**缓冲区管理器**会观察并学习，并可能创建一个新的、更具体的思维模板并将其推送到元缓冲区。
- en: Buffer Manager
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓冲区管理器
- en: The Buffer Manager serves as a crucial player in maintaining and enhancing the
    meta-buffer. Based on the new insights and outcomes from the tasks that are solved,
    it updates the thought templates. Also, whenever a new or drastically different
    problem is solved, the buffer manager assesses whether or not to create a new
    thought template. This is to ensure thought templates remain to the point and
    are not redundant.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲区管理器在维护和增强元缓冲区中发挥着至关重要的作用。根据从解决任务中获得的新见解和结果，它更新思维模板。同时，每当解决一个新的或截然不同的问题时，缓冲区管理器会评估是否创建一个新的思维模板。这是为了确保思维模板始终紧扣主题，不冗余。
- en: '![](../Images/64359637991b99ea155bceb95391d9d6.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64359637991b99ea155bceb95391d9d6.png)'
- en: 'checking whether or not a newly generated template is similar to the existing
    ones. (source: Paper)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 检查新生成的模板是否与现有模板相似。（来源：论文）
- en: By employing the above formulation, the Buffer Manager checks whether or not
    the meta-buffer already has the necessary knowledge to tackle a problem.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过采用上述公式，缓冲区管理器检查元缓冲区是否已经拥有解决问题所需的知识。
- en: BoT vs. Single-Query vs. Multi-Query
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BoT vs. 单查询 vs. 多查询
- en: How does the BoT stand out compared to previous methods? The authors of the
    paper evaluate various methods on different datasets of various tasks, such as
    Data Understanding, Python Programming Puzzles, Multilingual Grade School Math(MGSM),
    etc. The results show a surprising advantage of **BoT** in almost all the tasks.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: BoT 相较于之前的方法有什么突出之处？论文的作者在多个数据集和不同任务上评估了各种方法，如数据理解、Python 编程难题、语言学年级数学（MGSM）等。结果显示，**BoT**
    在几乎所有任务中都表现出意想不到的优势。
- en: '![](../Images/498b49fc3dd24dbe76978a7fb2099b3f.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/498b49fc3dd24dbe76978a7fb2099b3f.png)'
- en: 'BoT vs previous methods. The best results (marked in blue) are all achieved
    by BoT. (source: [Paper](https://arxiv.org/abs/2406.04271))'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: BoT 与之前的方法比较。最佳结果（标记为蓝色）全部由 BoT 实现。（来源：[Paper](https://arxiv.org/abs/2406.04271)）
- en: One of the key advantages of BoT is its efficiency — requiring **only 12%**
    of the computational cost on average when compared to multi-query prompting methods.
    This high computational cost and latency of multi-query methods such as ToT often
    renders them impractical in real-world use cases.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: BoT 的关键优势之一是其效率——与多查询提示方法相比，平均仅需 **12%** 的计算成本。这种多查询方法（如 ToT）通常因其高计算成本和延迟，在实际应用中变得不切实际。
- en: BoT+Llama3–8B has the potential to surpass single Llama3–70B model
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: BoT+Llama3–8B 有潜力超越单一的 Llama3–70B 模型
- en: '![](../Images/d343e715b3bfa85f8ddd6a75569f32f8.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d343e715b3bfa85f8ddd6a75569f32f8.png)'
- en: 'comparing the effect of BoT on Llama3–8B and 70B. Annotated. (source: [Paper](https://arxiv.org/abs/2406.04271))'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 比较 BoT 在 Llama3–8B 和 70B 上的效果。已标注。（来源：[Paper](https://arxiv.org/abs/2406.04271)）
- en: Buffer of Thoughts in Practice
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践中的 Buffer of Thoughts
- en: 'The demo code for Buffer of Thoughts is published on [GitHub](https://github.com/YangLing0818/buffer-of-thought-llm)
    [2]. To test out the functionality in practice, I will use this method on a custom
    task: Word Reordering. In this task, the LLM must take a scrambled sentence, such
    as *“Sam name is my”*, and return a permutation of these words that is semantically
    meaningful, which in this example would be *“my name is Sam”,* (this is not a
    benchmark with baseline performance). Some examples of the scrambled sentences
    and the correct ones are as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Buffer of Thoughts 的演示代码已发布在 [GitHub](https://github.com/YangLing0818/buffer-of-thought-llm)
    [2] 上。为了在实践中测试其功能，我将在一个自定义任务中使用该方法：词语重排。在这个任务中，LLM 必须接受一个乱序的句子，例如 *“Sam name is
    my”*，并返回一个语义上有意义的单词排列，在这个例子中是 *“my name is Sam”*，（这不是一个基准测试，且没有基准性能）。以下是一些乱序句子及其正确版本的示例：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'I will also use the following user prompt to explain the task:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我还将使用以下用户提示来解释任务：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Provided this task, the BoT framework first distills my task and extracts the
    goal, the restriction, and how I would like my output along with other key information.
    The full procedure of BoT in detail, is the following terminal output:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 提供这个任务时，BoT 框架首先提炼我的任务并提取目标、限制条件以及我希望的输出方式，和其他关键信息。BoT 的完整流程如下终端输出：
- en: '[PRE3]python'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE3]python'
- en: 'def ReorderWords(input_sentence):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 'def ReorderWords(input_sentence):'
- en: Remove the start and end tags, and split the sentence into words
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除开始和结束标签，并将句子拆分成单词
- en: words = input_sentence.replace("<start>", "").replace("<end>", "").strip().split()
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: words = input_sentence.replace("<start>", "").replace("<end>", "").strip().split()
- en: Tentative reordering to form a meaningful sentence
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初步重排以形成有意义的句子
- en: Based on the context provided in the task, the following reordering seems logical
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 根据任务中提供的上下文，以下重排看起来是合乎逻辑的
- en: reordered_words = ["the", "melting", "in", "solid", "metals", "is", "achieved",
    "by", "mixing", "gold", "leaf", "and", "desired", "other", "color", "gold"]
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: reordered_words = ["the", "melting", "in", "solid", "metals", "is", "achieved",
    "by", "mixing", "gold", "leaf", "and", "desired", "other", "color", "gold"]
- en: Join the words into a single sentence and add start and end tags
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将单词合并成一个句子，并添加开始和结束标签
- en: reordered_sentence = "<start> " + " ".join(reordered_words) + " <end>"
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: reordered_sentence = "<start> " + " ".join(reordered_words) + " <end>"
- en: return reordered_sentence
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return reordered_sentence
- en: Input sentence provided in the task
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务中提供的输入句子
- en: input_sentence = "<start> the melting in solid to gold leaf metals is achieve
    made by desired gold and mixing color other <end>"
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: input_sentence = "<start> the melting in solid to gold leaf metals is achieve
    made by desired gold and mixing color other <end>"
- en: print(ReorderWords(input_sentence))
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: print(ReorderWords(input_sentence))
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Some of the examples of the reordered sentences using BoT:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 BoT 重排的句子的一些示例：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note, that the BoT repository I used is a demo code and lacks some of the features
    mentioned in the original paper, such as a general thought template, the dynamic
    updating of the Meta-Buffer, or finding the closest template embedding to the
    user task. These are important aspects of the framework and without them, we cannot
    conclude the performance of Buffer of Thoughts in practice.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我使用的BoT仓库是一个演示代码，缺少原论文中提到的一些功能，比如通用思维模板、Meta-Buffer的动态更新，或者找到与用户任务最接近的模板嵌入。这些是框架的重要方面，没有它们，我们无法得出思想缓冲区在实际应用中的表现。
- en: Final Words
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的话
- en: In conclusion, BoT shows promising results in both accuracy and efficiency in
    various domains and tasks. It’s an interesting approach to breaking down a reasoning
    problem into its fundamental restrictions and key information and building on
    top of previous solutions and templates to better formulate the task for an LLM
    to understand.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，BoT在各个领域和任务中表现出色，既准确又高效。这是一种有趣的方法，通过将推理问题分解为基本限制和关键信息，并在之前的解决方案和模板基础上构建，以更好地构造任务，使LLM能够理解。
- en: By addressing some of the limitations in other prompting techniques, Buffer
    of Thoughts allows LLM to have more complex thinking patterns, potentially making
    smaller lightweight models perform at the level of larger ones.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解决其他提示技术的一些局限性，思想缓冲区使LLM能够具备更复杂的思维模式，可能使较小的轻量级模型达到更大模型的性能水平。
- en: Allowing small LLMs to achieve results close to large LLMs is a key topic addressed
    in many of the current research papers. The goal is to employ various prompting
    and fine-tuning techniques to extract accurate AI outputs with low computation
    and cost.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 允许小型LLM实现接近大型LLM的结果是当前许多研究论文中讨论的一个关键主题。目标是采用各种提示和微调技术，以低计算量和成本提取准确的AI输出。
- en: Buffer of Thoughts is a novel and promising prompting framework that leverages
    a domain of techniques to guide LLM step by step, in a reasoning process. A complete
    practical implementation of the Buffer of Thoughts technique is yet to come, but
    in the meanwhile, test out the provided benchmarks in the demo GitHub repository
    [2].
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 思想缓冲区是一个新颖且有前景的提示框架，利用一系列技术引导LLM逐步进行推理过程。思想缓冲区技术的完整实践实现尚未到来，但在此期间，可以在提供的演示GitHub仓库[2]中测试基准。
- en: 'If you have made it this far, consider this for a **further read**:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经读到这里，考虑继续**阅读更多**：
- en: '[](/platonic-representation-hypothesis-c812813d7248?source=post_page-----391919d2f76f--------------------------------)
    [## Platonic Representation: Are AI Deep Network Models Converging?'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/platonic-representation-hypothesis-c812813d7248?source=post_page-----391919d2f76f--------------------------------)
    [## 柏拉图式表征：人工智能深度网络模型是否趋同？'
- en: Are Artificial Intelligence models evolving towards a unified representation
    of reality? The Platonic Representation…
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能模型是否正在朝着现实的统一表征发展？柏拉图式表征……
- en: towardsdatascience.com](/platonic-representation-hypothesis-c812813d7248?source=post_page-----391919d2f76f--------------------------------)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/platonic-representation-hypothesis-c812813d7248?source=post_page-----391919d2f76f--------------------------------)
- en: '**🌟 Join +1000 people learning about** Python, ML / MLOps / AI, Data Science,
    and LLM. [**follow me**](https://medium.com/@itshesamsheikh/subscribe)and check
    out my [**X/Twitter**](https://twitter.com/itsHesamSheikh), where I keep you updated
    Daily**.**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**🌟 加入+1000人一起学习** Python、机器学习 / MLOps / 人工智能、数据科学和LLM。 [**关注我**](https://medium.com/@itshesamsheikh/subscribe)并查看我的[**X/Twitter**](https://twitter.com/itsHesamSheikh)，我每天为你更新**。**'
- en: Thanks for reading,
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读，
- en: — Hesam
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: — Hesam
- en: '[1] Yang, L., Yu, Z., Zhang, T., Cao, S., Xu, M., Zhang, W., Gonzalez, J. E.,
    & Cui, B. (2024). Buffer of Thoughts: Thought-Augmented Reasoning with Large Language
    Models. *arXiv*. Retrieved from [https://arxiv.org/abs/2406.04271](https://arxiv.org/abs/2406.04271)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 杨凌、余泽、张涛、曹胜、许梦、张伟、戈恩萨雷斯、崔博（2024）。《思想缓冲区：通过大型语言模型增强的思维推理》。*arXiv*。取自[https://arxiv.org/abs/2406.04271](https://arxiv.org/abs/2406.04271)'
- en: '[2] buffer-of-thought-llm, [https://github.com/YangLing0818/buffer-of-thought-llm](https://github.com/YangLing0818/buffer-of-thought-llm)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] buffer-of-thought-llm, [https://github.com/YangLing0818/buffer-of-thought-llm](https://github.com/YangLing0818/buffer-of-thought-llm)'
