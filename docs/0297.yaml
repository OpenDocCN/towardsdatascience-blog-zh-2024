- en: Basics of Reinforcement Learning for LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/basics-of-reinforcement-learning-for-llms-d74c5178cd2d?source=collection_archive---------5-----------------------#2024-01-31](https://towardsdatascience.com/basics-of-reinforcement-learning-for-llms-d74c5178cd2d?source=collection_archive---------5-----------------------#2024-01-31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Understanding the problem formulation and basic algorithms for RL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page---byline--d74c5178cd2d--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page---byline--d74c5178cd2d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d74c5178cd2d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d74c5178cd2d--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page---byline--d74c5178cd2d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d74c5178cd2d--------------------------------)
    ·18 min read·Jan 31, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3e89f8565100e5322bcdaf6af0d84e22.png)'
  prefs: []
  type: TYPE_IMG
- en: (Photo by [Ricardo Gomez Angel](https://unsplash.com/@rgaleriacom?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/grayscale-photo-of-metal-mesh-screen-z6CcN8rlftY?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash))
  prefs: []
  type: TYPE_NORMAL
- en: Recent AI research has revealed that reinforcement learning — *more specifically,*
    [*reinforcement learning from human feedback (RLHF)*](https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives)
    — is a key component of training a state-of-the-art large language model (LLM).
    Despite this fact, most open-source research on language models heavily emphasizes
    supervised learning strategies, such as supervised fine-tuning (SFT). This lack
    of emphasis upon reinforcement learning can be attributed to several factors,
    including the necessity to curate human preference data or the amount of data
    needed to perform high-quality RLHF. However, one undeniable factor that likely
    underlies skepticism towards reinforcement learning is the simple fact that it
    is not as commonly-used compared to supervised learning. As a result, AI practitioners
    (including myself!) avoid reinforcement learning due to a simple lack of understanding
    — *we tend to stick with using the approaches that we know best*.
  prefs: []
  type: TYPE_NORMAL
- en: “Many among us expressed a preference for supervised annotation, attracted by
    its denser signal… However, reinforcement learning proved highly effective, particularly
    given its cost and time effectiveness.” *— from [8]*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**This series.** In the next few overviews, we will aim to eliminate this problem
    by building…'
  prefs: []
  type: TYPE_NORMAL
