["```py\ngit clone https://github.com/KasperGroesLudvigsen/local_llm.git \n```", "```py\nMODEL_ID = \"mistralai/Mistral-7B-v0.1\"\n```", "```py\npython quantize.py\n```", "```py\nFROM ./mistral7b/quantized.gguf\n\nPARAMETER num_ctx 8000\n\nTEMPLATE \"\"\"<|im_start|>system {{ .System }}<|im_end|><|im_start|>user {{ .Prompt }}<|im_end|><|im_start|>assistant<|im_end|>\"\"\"\n\nPARAMETER stop <|im_end|>\nPARAMETER stop <|im_start|>user\nPARAMETER stop <|end|>\n```", "```py\nollama create choose-a-model-name -f <location of the file e.g. ./Modelfile>'\n```", "```py\nollama serve\n```", "```py\ngit clone https://github.com/ivanfioravanti/chatbot-ollama.git\nnpm ci\n```", "```py\ndocker build -t chatbot-ollama .\n\ndocker run -p 3000:3000 chatbot-ollama\n```"]