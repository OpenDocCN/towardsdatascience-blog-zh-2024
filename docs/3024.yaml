- en: '2024 in Review: What I Got Right, Where I Was Wrong, and Bolder Predictions
    for 2025'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/2024-in-review-what-i-got-right-where-i-was-wrong-and-bolder-predictions-for-2025-4092c2d726cd?source=collection_archive---------7-----------------------#2024-12-17](https://towardsdatascience.com/2024-in-review-what-i-got-right-where-i-was-wrong-and-bolder-predictions-for-2025-4092c2d726cd?source=collection_archive---------7-----------------------#2024-12-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What I got right (and wrong) about trends in 2024 and daring to make bolder
    predictions for the year ahead
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)
    ·8 min read·Dec 17, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7b891fef4d659f8e35239ca469597357.png)'
  prefs: []
  type: TYPE_IMG
- en: AI Buzzword and Trend Bingo (Image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: In 2023, building AI-powered applications felt full of promise, but the challenges
    were already starting to show. By 2024, we began experimenting with techniques
    to tackle the hard realities of making them work in production.
  prefs: []
  type: TYPE_NORMAL
- en: 'Last year, I [reviewed the biggest trends in AI in 2023 and made predictions
    for 2024](/2023-in-review-recapping-the-post-chatgpt-era-and-what-to-expect-for-2024-bb4357a4e827?sk=0a494f87bd0b0344594fa1e6694773a6).
    This year, instead of a timeline, I want to focus on key themes: What trends emerged?
    Where did I get it wrong? And what can we expect for 2025?'
  prefs: []
  type: TYPE_NORMAL
- en: 2024 in Review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If I have to summarize the AI space in 2024, it would be the “Captain, it’s
    Wednesday” meme. The amount of major releases this year was overwhelming. I don’t
    blame anyone in this space who’s feeling exhausted towards the end of this year.
    It’s been a crazy ride, and it's been hard to keep up. Let’s review key themes
    in the AI space and see if I correctly predicted them last year.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by looking at some generative AI solutions that made it to production.
    There aren’t many. As a [survey by A16Z](https://a16z.com/generative-ai-enterprise-2024/)
    revealed in 2024, companies are still hesitant to deploy generative AI in customer-facing
    applications. Instead, they feel more confident using it for internal tasks, like
    document search or chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: So, why aren’t there that many customer-facing generative AI applications in
    the wild? Probably because we are still figuring out how to evaluate them properly.
    This was one of my predictions for 2024.
  prefs: []
  type: TYPE_NORMAL
- en: Much of the research involved using another LLM to evaluate the output of an
    LLM ([LLM-as-a-judge](https://arxiv.org/abs/2411.15594)). While the approach may
    be clever, it’s also imperfect due to added cost, introduction of bias, and unreliability.
  prefs: []
  type: TYPE_NORMAL
- en: Looking back, I anticipated we would see this issue solved this year. However,
    looking at the landscape today, despite being a major topic of discussion, we
    still haven’t found a reliable way to evaluate generative AI solutions effectively.
    Although I think LLM-as-a-judge is the only way we’re able to evaluate generative
    AI solutions at scale, this shows how early we are in this field.
  prefs: []
  type: TYPE_NORMAL
- en: Multimodality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although this one might have been obvious to many of you, I didn’t have this
    on my radar for 2024\. With the releases of [GPT4](https://openai.com/index/gpt-4-research/),
    [Llama 3.2](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/),
    and [ColPali](https://arxiv.org/abs/2407.01449), multimodal foundation models
    were a big trend in 2024\. While we, developers, were busy figuring out how to
    make LLMs work in our existing pipelines, researchers were already one step ahead.
    They were already building foundation models that could handle more than one modality.
  prefs: []
  type: TYPE_NORMAL
- en: “There is ***absolutely no way in hell*** we will ever reach human-level AI
    without getting machines to learn from high-bandwidth sensory inputs, such as
    vision.” — [Yann LeCun](https://www.linkedin.com/posts/yann-lecun_parm-prmshra-on-x-activity-7172266619103080448-iqvP/?utm_source=share&utm_medium=member_desktop)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Take PDF parsing as an example of multimodal models’ usefulness beyond text-to-image
    tasks. [ColPali](https://arxiv.org/abs/2407.01449)’s researchers avoided the difficult
    steps of OCR and layout extraction by using visual language models (VLMs). Systems
    like ColPali and [ColQwen2](https://huggingface.co/vidore/colqwen2-v0.1) process
    PDFs as images, extracting information directly without pre-processing or chunking.
    This is a reminder that simpler solutions often come from changing how you frame
    the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal models are a bigger shift than they might seem. Document search across
    PDFs is just the beginning. Multimodality in foundation models will unlock entirely
    new possibilities for applications across industries. With more modalities, AI
    is no longer just about language — it’s about understanding the world.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning open-weight models and quantization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Open-weight models are closing the performance gap to closed models. Fine-tuning
    them gives you a performance boost while still being lightweight. Quantization
    makes these models smaller and more efficient (see also [Green AI](https://medium.com/towards-data-science/towards-green-ai-how-to-make-deep-learning-models-more-efficient-in-production-3b1e7430a14))
    to run anywhere, even on small devices. Quantization pairs well with fine-tuning,
    especially since fine-tuning language models is inherently challenging (see [QLoRA](https://arxiv.org/abs/2305.14314)).
  prefs: []
  type: TYPE_NORMAL
- en: Together, these trends make it clear that the future isn’t just bigger models
    — it’s smarter ones.
  prefs: []
  type: TYPE_NORMAL
- en: Great visual summary by [Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page---user_mention--4092c2d726cd--------------------------------).
    Also, check out his blog if you are interested in fine-tuning LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: I don’t think I explicitly mentioned this one and only [wrote a small piece
    on this in the second quarter of 2024](https://medium.com/towards-data-science/shifting-tides-the-competitive-edge-of-open-source-llms-over-closed-source-llms-aee76018b5c7).
    So, I will not give myself a point here.
  prefs: []
  type: TYPE_NORMAL
- en: AI agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This year, AI agents and agentic workflows gained much attention, as Andrew
    Ng predicted at the beginning of the year. We saw [Langchain](https://www.langchain.com/langgraph)
    and [LlamaIndex](https://docs.llamaindex.ai/en/stable/use_cases/agents/) move
    into incorporating agents, [CrewAI](https://www.crewai.com/) gained a lot of momentum,
    and OpenAI came out with [Swarm](https://github.com/openai/swarm). This is another
    topic I hadn’t seen coming since I didn’t look into it.
  prefs: []
  type: TYPE_NORMAL
- en: “I think AI agentic workflows will drive massive AI progress this year — perhaps
    even more than the next generation of foundation models.” — [Andrew Ng](https://x.com/AndrewYNg/status/1770897666702233815?lang=en)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/02dce8059388e447c1d4872fbfcd443b.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Screenshot from Google Trends for the term “AI agents” in 2024.](https://trends.google.com/trends/explore?date=2024-01-01+2024-12-16&q=AI+agents&hl=en-US)'
  prefs: []
  type: TYPE_NORMAL
- en: Despite the massive interest in AI agents, they can be controversial. First,
    there is still no clear definition of “AI agent” and its capabilities. Are AI
    agents just LLMs with access to tools, or do they have other specific capabilities?
    Second, they come with added latency and cost. I have read many comments saying
    that agent systems aren’t suitable for production systems due to this.
  prefs: []
  type: TYPE_NORMAL
- en: But I think we have already been seeing some agentic pipelines in production
    with lightweight workflows, such as routing user queries to specific function
    calls. I think we will continue to see agents in 2025\. Hopefully, we will get
    a clearer definition and picture.
  prefs: []
  type: TYPE_NORMAL
- en: RAG isn’t de*d and retrieval goes mainstream
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Retrieval-Augmented Generation (RAG)](https://medium.com/@iamleonie/building-retrieval-augmented-generation-systems-be587f42aedb)
    gained significant attention in 2023 and remained a key topic in 2024, with many
    new variants emerging. However, it remains a topic of debate. Some argue it’s
    becoming obsolete with long-context models, while others question whether it’s
    even a new idea. While I think the criticism of the terminology is justified,
    I think the concept is here to stay (for a little while at least).'
  prefs: []
  type: TYPE_NORMAL
- en: All the different RAG variants
  prefs: []
  type: TYPE_NORMAL
- en: Every time a new long context model is released, some people predict it will
    be the end of RAG pipelines. I don’t think that’s going to happen. This whole
    discussion should be a blog post of its own, so I’m not going into depth here
    and saving the discussion for another one. Let me just say that I don’t think
    it’s one or the other. They are complements. Instead, we will probably be using
    long context models together with RAG pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Also, having a database in applications is not a new concept. The term ‘RAG,’
    which refers to retrieving information from a knowledge source to enhance an LLM’s
    output, has faced criticism. Some argue it’s merely a rebranding of techniques
    long used in other fields, such as software engineering. While I think we will
    probably part from the term in the long run, the technique is here to stay.
  prefs: []
  type: TYPE_NORMAL
- en: Despite predictions of RAG’s demise, retrieval remains a cornerstone of AI pipelines.
    While I may be biased by my work in retrieval, it felt like this topic became
    more mainstream in AI this year. It started with many discussions around keyword
    search (BM25) as a baseline for RAG pipelines. It then evolved into a larger discussion
    around dense retrieval models, such as [ColBERT](https://arxiv.org/abs/2004.12832)
    or ColPali.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graphs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I completely missed this topic because I’m not too familiar with it. Knowledge
    graphs in RAG systems (e.g., Graph RAG) were another big topic. Since all I can
    say about knowledge graphs at this moment is that they seem to be a powerful external
    knowledge source, I will keep this section short.
  prefs: []
  type: TYPE_NORMAL
- en: The key topics of 2024 suggest that we are now realizing the limitations of
    building applications with foundation models. The hype around ChatGPT may have
    settled, but the drive to integrate foundation models into applications is still
    very much alive. It’s just way more difficult than we had anticipated.
  prefs: []
  type: TYPE_NORMAL
- en: “ The race to make AI more efficient and more useful, before investors lose
    their enthusiasm, is on.” — [The Economist](https://www.economist.com/the-world-ahead/2024/11/18/will-the-bubble-burst-for-ai-in-2025-or-will-it-start-to-deliver)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 2024 taught us that scaling foundation models isn’t enough. We need better evaluation,
    smarter retrieval, and more efficient workflows to make AI useful. The limitations
    we ran into this year aren’t signs of stagnation — they’re clues about what we
    need to fix next in 2025.
  prefs: []
  type: TYPE_NORMAL
- en: My 2025 Predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OK, now, for the interesting part, what are my 2025 predictions? This year,
    I want to make some bolder predictions for the next year to make it a little more
    fun:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Video will be an important modality:** After text-only LLMs evolved into
    multimodal foundation models (mostly text and images), it’s only natural that
    video will be the next modality. I can imagine seeing more video-capable foundation
    models follow in [Sora](https://openai.com/sora/)’s footsteps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**From one-shot to agentic to human-in-the-loop:** I imagine we will start
    incorporating humans into AI-powered systems. While we started with one-shot systems,
    we are not at the stage of having AI agents coordinate different tasks to improve
    results. But AI agents won’t replace humans. They’ll empower them. Systems that
    incorporate human feedback will deliver better outcomes across industries. In
    the long-term, I imagine that we will have to have systems that wait for human
    feedback before taking action on the next task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fusion of AI and crypto:** Admittedly, I don’t know much about the entire
    crypto scene, but I saw [this Tweet by Brian Armstrong about how AI agents should
    be equipped with crypto wallets](https://x.com/brian_armstrong/status/1824547713012080806).
    Also, concepts like [DePin (Decentralized Physical Infrastructure)](https://tokenomicsexplained.com/depin/)
    could be interesting to explore for model training and inference. While this sounds
    like buzzword bingo, I’m curious to see if early experiments will show if this
    is hype or reality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Latency and cost per token will drop:** Currently, one big issue for AI agents
    is added latency and cost. However, with Moore’s law and research for making AI
    models more efficient, like quantization and efficient training techniques (not
    only for cost reasons but also for environmental reasons), I can imagine both
    the latency and cost per token going down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I am curious to hear your predictions for the AI space in 2025!**'
  prefs: []
  type: TYPE_NORMAL
- en: 'PS: Funnily, I was researching recipes for Christmas cookies with ChatGPT a
    few days ago instead of using Google, which I was wondering about two years ago
    when ChatGPT was released.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/geekculture/will-we-be-using-chatgpt-instead-of-google-to-get-a-christmas-cookie-recipe-next-year-45360d4a1178?source=post_page-----4092c2d726cd--------------------------------)
    [## Will We Be Using ChatGPT Instead of Google To Get a Christmas Cookie Recipe
    Next Year?'
  prefs: []
  type: TYPE_NORMAL
- en: Will ChatGPT replace search engines? A walkthrough with the use case of looking
    up a sugar cookie recipe
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/geekculture/will-we-be-using-chatgpt-instead-of-google-to-get-a-christmas-cookie-recipe-next-year-45360d4a1178?source=post_page-----4092c2d726cd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Enjoyed This Story?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Subscribe for free*](https://medium.com/subscribe/@iamleonie) *to get notified
    when I publish a new story.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----4092c2d726cd--------------------------------)
    [## Get an email whenever Leonie Monigatti publishes.'
  prefs: []
  type: TYPE_NORMAL
- en: Get an email whenever Leonie Monigatti publishes. By signing up, you will create
    a Medium account if you don’t already…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----4092c2d726cd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/804250ab/),[*Twitter*](https://twitter.com/helloiamleonie)*,
    and* [*Kaggle*](https://www.kaggle.com/iamleonie)*!*'
  prefs: []
  type: TYPE_NORMAL
