["```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        conv_layers = []\n        for i in range(4):\n            conv_layers.append(nn.Conv2d(4 ** i, 4 ** (i + 1), 3,\n                                         padding='same'))\n            conv_layers.append(nn.MaxPool2d(2, 2))\n            conv_layers.append(nn.ReLU())\n        self.conv_layers = nn.Sequential(*conv_layers)\n\n        self.lin1 = nn.Linear(256 * 256, 256 * 64)\n        self.lin2 = nn.Linear(256 * 64, 256 * 4)\n\n    def forward(self, x):\n        x = self.conv_layers(x.float())\n        x = self.lin2(F.relu(self.lin1(x.view((-1, 256 * 256)))))\n        return x.view((-1, 256, 4))\n\ndef generalized_box_iou(boxes1, boxes2):\n    # loosly based on torchvision generalized_box_iou_loss code\n    epsilon = 1e-5\n\n    area1 = (boxes1[..., 2]-boxes1[..., 0])*(boxes1[..., 3]-boxes1[..., 1])\n    area2 = (boxes2[..., 2]-boxes2[..., 0])*(boxes2[..., 3]-boxes2[..., 1])\n\n    lt = torch.max(boxes1[..., :2], boxes2[..., :2])\n    rb = torch.min(boxes1[..., 2:], boxes2[..., 2:])\n\n    wh = (rb - lt).clamp(min=0)\n    inter = wh[..., 0] * wh[..., 1]\n\n    union = area1 + area2 - inter\n    iou = inter / union.clamp(epsilon)\n\n    lti = torch.min(boxes1[..., :2], boxes2[..., :2])\n    rbi = torch.max(boxes1[..., 2:], boxes2[..., 2:])\n\n    whi = (rbi - lti).clamp(min=0)\n    areai = (whi[..., 0] * whi[..., 1]).clamp(epsilon)\n\n    return iou - (areai - union) / areai\n\ndef loss_fn(pred, targets_list):\n    batch_size = len(targets_list)\n    total_boxes = 0\n    loss_sum = 0.\n    for i in range(batch_size):\n        targets = targets_list[i]\n        num_targets = targets.shape[0]\n        if num_targets > 0:\n            sample_preds = pred[i, :num_targets]\n            total_boxes += num_targets\n            loss_sum += generalized_box_iou(sample_preds, targets).sum()\n    return loss_sum / max(total_boxes, 1)\n```", "```py\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\n\n# A dataset with random images and gt boxes\nclass FakeDataset(Dataset):\n    def __init__(self):\n        super().__init__()\n        self.size = 256\n        self.img_size = [256, 256]\n\n    def __len__(self):\n        return 1000000\n\n    def __getitem__(self, index):\n        rand_image = torch.randint(low=0, high=256, \n                                   size=[1]+self.img_size,\n                                   dtype=torch.uint8)\n\n        # set the distribution over the number of boxes to reflect the fact\n        # that the vast majority of images have fewer than 10 faces\n        n_boxes = np.clip(np.floor(np.abs(np.random.normal(0, 3)))\n                                      .astype(np.int32), 0, 255)\n\n        box_sizes = torch.randint(low=1, high=self.size, size=(n_boxes,2))\n        top_left = torch.randint(low=0, high=self.size-1, size=(n_boxes, 2))\n        bottom_right = torch.clamp(top_left + box_sizes, 0, self.size -1)\n        rand_boxes = torch.concat((top_left,bottom_right), dim = 1)\n        return rand_image, rand_boxes.to(torch.uint8)\n\ndef collate_fn(batch):\n    images = torch.stack([b[0] for b in batch],dim=0)\n    boxes = [b[1] for b in batch]\n    return images, boxes\n\ntrain_loader = DataLoader(\n    dataset = FakeDataset(),\n    batch_size=1024,\n    pin_memory=True,\n    num_workers=16,\n    collate_fn=collate_fn\n)\n```", "```py\ndef data_to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return type(data)(\n            data_to_device(val, device) for val in data\n        )\n    elif isinstance(data, torch.Tensor):\n        return data.to(device=device, non_blocking=True)\n```", "```py\ndevice = torch.device(\"cuda:0\")\nmodel = torch.compile(Net()).to(device).train()\n\n# forward portion of training loop wrapped with profiler object\nwith torch.profiler.profile(\n   schedule=torch.profiler.schedule(wait=5, warmup=5, active=10, repeat=1),\n   on_trace_ready=torch.profiler.tensorboard_trace_handler('/tmp/perf/'),\n   profile_memory=True\n) as prof:\n    for step, data in enumerate(train_loader):\n\n        with torch.profiler.record_function('copy data'):\n            images, boxes = data_to_device(data, device)\n            torch.cuda.synchronize(device)\n\n        with torch.profiler.record_function('forward'):\n            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n                outputs = model(images)\n            torch.cuda.synchronize(device)\n\n        with torch.profiler.record_function('calc loss'):\n            loss = loss_fn(outputs, boxes)\n            torch.cuda.synchronize(device)\n        prof.step()\n        if step > 30:\n            break\n\n    # filter and print profiler results\n    event_list = prof.key_averages()\n    for i in range(len(event_list) - 1, -1, -1):\n        if event_list[i].key not in ['forward', 'calc loss', 'copy data']:\n            del event_list[i]\n    print(event_list.table())\n```", "```py\n-------------  ------------  ------------\n         Name     CPU total  CPU time avg\n-------------  ------------  ------------\n    copy data     288.164ms      28.816ms\n      forward        1.192s     119.221ms\n    calc loss        9.381s     938.067ms\n-------------  ------------  ------------\nSelf CPU time total: 4.018s\nSelf CUDA time total: 10.107s\n```", "```py\ndef loss_with_concat(pred, targets_list):\n    bs = len(targets_list)\n    all_targets = torch.concat(targets_list, dim = 0)\n    num_boxes = [targets_list[i].shape[0] for i in range(bs)]\n    all_preds = torch.concat([pred[i,: num_boxes[i]] for i in range(bs)],\n                              dim=0)\n    total_boxes = sum(num_boxes)\n    loss_sum = generalized_box_iou(all_targets, all_preds).sum()\n    return loss_sum/max(total_boxes, 1)\n```", "```py\n-------------  ------------  ------------\n         Name     CPU total  CPU time avg\n-------------  ------------  ------------\n    copy data     522.326ms      52.233ms\n      forward        1.187s     118.715ms\n    calc loss     254.047ms      25.405ms\n-------------  ------------  ------------\nSelf CPU time total: 396.674ms\nSelf CUDA time total: 1.871s\n```", "```py\ndef collate_with_padding(batch):\n    images = torch.stack([b[0] for b in batch],dim=0)\n    padded_boxes = []\n    for b in batch:\n        p = torch.nn.functional.pad(\n                       b[1], (0, 0, 0, 256 - b[1].shape[0]), value = 0)\n        padded_boxes.append(p)\n    boxes = torch.stack(padded_boxes,dim=0)\n    return images, boxes\n```", "```py\ndef loss_with_padding(pred, targets):\n    mask = (targets[...,3] > 0).to(pred.dtype)\n    total_boxes = mask.sum()\n    loss = generalized_box_iou(targets, pred)\n    masked_loss = loss*mask\n    loss_sum = masked_loss.sum()\n    return loss_sum/torch.clamp(total_boxes, 1)\n```", "```py\n-------------  ------------  ------------\n         Name     CPU total  CPU time avg\n-------------  ------------  ------------\n    copy data      57.125ms       5.713ms\n      forward        1.315s     131.503ms\n    calc loss      18.438ms       1.844ms\n-------------  ------------  ------------\nSelf CPU time total: 11.723ms\nSelf CUDA time total: 1.378s\n```", "```py\n#include <torch/extension.h>\n\n#include <cuda.h>\n#include <cuda_runtime.h>\n\nnamespace extension_cpp {\n\n__global__ void giou_kernel(const float* boxes1,\n                            const float* boxes2, \n                            float* giou, \n                            bool* mask) {\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  bool valid = boxes2[4*idx+3] != 0;\n  mask[idx] = valid;\n\n  const float epsilon = 1e-5;\n\n  const float* box1 = &boxes1[idx * 4];\n  const float* box2 = &boxes2[idx * 4];\n\n  // Compute area of each box\n  float area1 = (box1[2] - box1[0]) * (box1[3] - box1[1]);\n  float area2 = (box2[2] - box2[0]) * (box2[3] - box2[1]);\n\n  // Compute the intersection\n  float left = max(box1[0], box2[0]);\n  float top = max(box1[1], box2[1]);\n  float right = min(box1[2], box2[2]);\n  float bottom = min(box1[3], box2[3]);\n\n  float inter_w = max(right - left, 0);\n  float inter_h = max(bottom - top, 0);\n  float inter_area = inter_w * inter_h;\n\n  // Compute the union area\n  float union_area = area1 + area2 - inter_area;\n\n  // IoU\n  float iou_val = inter_area / max(union_area, epsilon);\n\n  // Compute the smallest enclosing box\n  float enclose_left = min(box1[0], box2[0]);\n  float enclose_top = min(box1[1], box2[1]);\n  float enclose_right = max(box1[2], box2[2]);\n  float enclose_bottom = max(box1[3], box2[3]);\n\n  float enclose_w = max(enclose_right - enclose_left, 0);\n  float enclose_h = max(enclose_bottom - enclose_top, 0);\n  float enclose_area = enclose_w * enclose_h;\n\n  float result = iou_val - (enclose_area-union_area)/max(enclose_area, epsilon);\n  // Generalized IoU\n  giou[idx] = result * valid;\n}\n\nat::Tensor giou_loss_cuda(const at::Tensor& a, const at::Tensor& b) {\n  TORCH_CHECK(a.sizes() == b.sizes());\n  TORCH_CHECK(a.dtype() == at::kFloat);\n  TORCH_CHECK(b.dtype() == at::kFloat);\n  TORCH_INTERNAL_ASSERT(a.device().type() == at::DeviceType::CUDA);\n  TORCH_INTERNAL_ASSERT(b.device().type() == at::DeviceType::CUDA);\n  int bs = a.sizes()[0];\n  at::Tensor a_contig = a.contiguous();\n  at::Tensor b_contig = b.contiguous();\n  at::Tensor giou = torch::empty({a_contig.sizes()[0], a_contig.sizes()[1]},\n                                  a_contig.options());\n  at::Tensor mask = torch::empty({a_contig.sizes()[0], a_contig.sizes()[1]},\n                                  a_contig.options().dtype(at::kBool));\n  const float* a_ptr = a_contig.data_ptr<float>();\n  const float* b_ptr = b_contig.data_ptr<float>();\n  float* giou_ptr = giou.data_ptr<float>();\n  bool* mask_ptr = mask.data_ptr<bool>();\n\n  // Launch the kernel\n  // The number of blocks is set according to the batch size.\n  // Each block has 256 threads corresponding to the number of boxes per sample\n  giou_kernel<<<bs, 256>>>(a_ptr, b_ptr, giou_ptr, mask_ptr);\n\n  at::Tensor total_boxes = torch::clamp(mask.sum(), 1);\n  torch::Tensor loss_sum = giou.sum();\n  return loss_sum/total_boxes;\n}\n\n// Registers CUDA implementations for giou_loss\nTORCH_LIBRARY_IMPL(extension_cpp, CUDA, m) {\n  m.impl(\"giou_loss\", &giou_loss_cuda);\n}\n\n}\n```", "```py\n// Add the C++ definition\nm.def(“giou_loss(Tensor a, Tensor b) -> Tensor”);\n```", "```py\n# define the Python operator\ndef giou_loss(a: Tensor, b: Tensor) -> Tensor:\n    return torch.ops.extension_cpp.giou_loss.default(a, b)\n```", "```py\ndef loss_with_kernel(pred, targets):\n    pred = pred.to(torch.float32)\n    targets = targets.to(torch.float32)\n    import extension_cpp\n    return extension_cpp.ops.giou_loss(pred, targets)\n```", "```py\n-------------  ------------  ------------\n         Name     CPU total  CPU time avg   \n-------------  ------------  ------------\n    copy data      56.901ms       5.690ms    \n      forward        1.327s     132.704ms      \n    calc loss       6.287ms     628.743us     \n-------------  ------------  ------------\nSelf CPU time total: 6.907ms\nSelf CUDA time total: 1.380s\n```", "```py\n__global__ void giou_kernel(const float* boxes1,\n                            const float* boxes2,\n                            float* giou,\n                            bool* mask) {\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  bool valid = boxes2[4*idx+3] != 0;\n  mask[idx] = valid;\n  if (valid)\n  {\n    const float* box1 = &boxes1[idx * 4];\n    const float* box2 = &boxes2[idx * 4];\n    giou[idx] = compute_giou(box1, box2);\n  }\n  else\n  {\n    giou[idx] = 0;\n  }\n}\n```", "```py\n-------------  ------------  ------------\n         Name     CPU total  CPU time avg\n-------------  ------------  ------------\n    copy data      57.008ms       5.701ms\n      forward        1.318s     131.850ms\n    calc loss       6.234ms     623.426us\n-------------  ------------  ------------\nSelf CPU time total: 7.139ms\nSelf CUDA time total: 1.371s\n```"]