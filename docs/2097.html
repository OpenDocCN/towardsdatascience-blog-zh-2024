<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Machine Learning Operations (MLOps) For Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Machine Learning Operations (MLOps) For Beginners</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-operations-mlops-for-beginners-a5686bfe02b2?source=collection_archive---------0-----------------------#2024-08-29">https://towardsdatascience.com/machine-learning-operations-mlops-for-beginners-a5686bfe02b2?source=collection_archive---------0-----------------------#2024-08-29</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="83e0" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">End-to-end Project Implementation</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@prasadmahamulkar?source=post_page---byline--a5686bfe02b2--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Prasad Mahamulkar" class="l ep by dd de cx" src="../Images/ed895003bf372f0c109f70e08458dad8.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*obR5npkiregF8GrZ1SYF1w.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--a5686bfe02b2--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@prasadmahamulkar?source=post_page---byline--a5686bfe02b2--------------------------------" rel="noopener follow">Prasad Mahamulkar</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--a5686bfe02b2--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">19 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 29, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">31</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/4e4347f61e9dc1b6ed4aaddf273822a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ub_u88a4MB5Uj-9Eb60VNA.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by the author</figcaption></figure><p id="87ad" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Developing, deploying, and maintaining machine learning models in production can be challenging and complex. This is where Machine Learning Operations (MLOps) comes into play. MLOps is a set of practices that automate and simplify machine learning (ML) workflows and deployments. In this article, I will be sharing some basic MLOps practices and tools through an end-to-end project implementation that will help you manage machine learning projects more efficiently, from development to production.</p><p id="2b12" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After reading this article, you will know:</p><ul class=""><li id="832f" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk">How to use <strong class="ne fr">DVC</strong> for data versioning.</li><li id="6f0d" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">How to track logs, artifacts, and register model versions using <strong class="ne fr">MLflow.</strong></li><li id="e0c4" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">How to deploy a model using <strong class="ne fr">FastAPI</strong>, <strong class="ne fr">Docker</strong>, and <strong class="ne fr">AWS ECS</strong>.</li><li id="9d33" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">How to monitor a model in production using <strong class="ne fr">Evidently AI</strong>.</li></ul><p id="1a36" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">All the code used in this article is available on <a class="af og" href="https://github.com/prsdm/mlops-project" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p><blockquote class="oh oi oj"><p id="f825" class="nc nd ok ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Please note that GIF examples might not load completely in the Medium app but should work fine in a browser.</p></blockquote><p id="884b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Before we start, let’s first quickly understand what is MLOps.</p><h1 id="c3bb" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">What is MLOps?</h1><p id="93c3" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">MLOps is a set of techniques and practices designed to simplify and automate the lifecycle of machine learning (ML) systems. MLOps aims to improve the efficiency and reliability of deploying ML models into production by providing clear guidelines and responsibilities for professionals and researchers. It bridges the gap between ML development and production, ensuring that machine learning models can be efficiently developed, deployed, managed, and maintained in real-world environments. This approach helps reduce system design errors, enabling more robust and accurate predictions in real-world settings.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pm"><img src="../Images/433e86c6688830bd32fc52cd42c760bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M2Cmy6S6P4ozs9Wylz1eFg.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created by the author</figcaption></figure><p id="f371" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Why do we need MLOps?</strong></p><p id="b51d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Typically, any machine learning project starts with defining the business problem. Once the problem is defined, data extraction, data preparation, feature engineering, and model training steps are implemented to develop the model. After the model is developed, it is usually stored somewhere so that the engineering and operations teams can deploy it for production use.</p><p id="37c0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">What is wrong with this approach?</strong></p><p id="f759" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It creates a gap between the development and deployment phases, leading to inefficiencies and potential errors. Without collaboration between data scientists and engineers, models may not be optimized for production, which can result in issues such as performance degradation, lack of scalability, and maintenance difficulties.</p><p id="461a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">MLOps solves these problems by creating a unified workflow that integrates development and operations. It ensures that models are reliable, scalable, and easier to maintain. This approach reduces the risk of errors, accelerates deployment, and keeps models effective and up-to-date through continuous monitoring.</p><p id="b67c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now that we have a basic understanding of MLOps, let’s move on to the implementation part.</p><h1 id="e9e2" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Project Setup</h1><p id="5ff5" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">Machine learning project requires a standard project structure to ensure it can be easily maintained and modified. A good project structure allows team members to collaborate easily and effectively.</p><p id="51ed" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For this project, we will use a very basic structure that will help us manage the entire lifecycle of a machine learning project, including data ingestion, preprocessing, model training, evaluation, deployment, and monitoring.</p><p id="76c3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To begin, clone the mlops-project repository from <a class="af og" href="https://github.com/prsdm/mlops-project" rel="noopener ugc nofollow" target="_blank">GitHub</a> and follow along.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="24d6" class="pr om fq po b bg ps pt l pu pv">#clone repository from github<br/>git clone https://github.com/prsdm/mlops-project.git</span></pre><p id="370a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After cloning the repository the project structure will look something like this:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="21d8" class="pr om fq po b bg ps pt l pu pv">.<br/>├── .github                         # DVC metadata and configuration<br/>│   └── workflows                   # GitHub Actions workflows for CI/CD<br/>│       └── docs.yml                <br/>├── data                            # Directory for storing data files<br/>│   ├── train.csv                   <br/>│   └── test.csv                                  <br/>├── docs                            # Project documentation.<br/>│   └── index.md                    <br/>├── models                          # Store trained models <br/>├── mlruns                          # Directory for MLflow run logs and artifacts<br/>├── steps                           # Source code for data processing and model training<br/>│   ├── __init__.py                <br/>│   ├── ingest.py                   <br/>│   ├── clean.py                    <br/>│   ├── train.py                    <br/>│   └── predict.py                  <br/>├── tests                           # Directory to store tests<br/>│   ├── __init__.py                 <br/>│   ├── test_ingest.py              <br/>│   └── test_clean.py              <br/>├── .gitignore                      # To ignore files that can't commit to Git<br/>├── app.py                          # FastAPI app file<br/>├── config.yml                      # Configuration file<br/>├── data.dvc                        # For tracking data files and their versions<br/>├── dataset.py                      # Script to download or generate data<br/>├── dockerfile                      # Dockerfile for containerizing FastAPI<br/>├── LICENSE                         # License for project<br/>├── main.py                         # To automate model training<br/>├── Makefile                        # To store useful commands to make train or make test <br/>├── mkdocs.yml                      # Configuration file for MkDocs<br/>├── README.md                       # Project description<br/>├── requirements.txt                # Requirements file for reproducing the environment.<br/>├── samples.json                    # Sample data for testing<br/><br/>'''Extra files for monitoring'''<br/>├── data                           <br/>│   └──production.csv               # data for Monitoring<br/>├── monitor.ipynb                   # Model Monitoring notebook <br/>├── test_data.html                  # monitoring results for test data  <br/>└── production_data.html            # monitoring results for production data</span></pre><p id="a2e8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here is a breakdown of the structure:</p><ul class=""><li id="1c0b" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><strong class="ne fr">data</strong>: Stores data files used for model training and evaluation.</li><li id="8b65" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">docs</strong>: Contains project documentation.</li><li id="a58f" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">models</strong>: Stores trained machine learning models.</li><li id="114d" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">mlruns</strong>: Contains logs and artifacts generated by MLflow.</li><li id="805a" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">steps</strong>: Includes source code for data ingestion, cleaning, and model training.</li><li id="4b08" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">tests</strong>: Includes unit tests to verify the functionality of the code.</li><li id="a3ae" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">app.py</strong>: Contains the FastAPI application code for deploying the model.</li><li id="fc6b" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">config.yml</strong>: Configuration file for storing project parameters and paths.</li><li id="93fe" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">data.dvc</strong>: Tracks data files and their versions using DVC.</li><li id="acda" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">dataset.py</strong>: Script for downloading or generating data.</li><li id="2787" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">dockerfile</strong>: Used to build a Docker image for containerizing the FastAPI application.</li><li id="8516" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">main.py</strong>: Automates the model training process.</li><li id="815c" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">Makefile</strong>: Contains commands for automating tasks such as training or testing.</li><li id="6b4a" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">mkdocs.yml</strong>: Configuration file for MkDocs, used to generate project documentation.</li><li id="ed6c" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">requirements.txt</strong>: Contains all the required packages for the project.</li><li id="fd28" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">samples.json</strong>: Contains sample data for testing purposes.</li><li id="3897" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">monitor.ipynb</strong>: Jupyter notebook for monitoring model performance.</li><li id="449b" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">production_data.html</strong> and <strong class="ne fr">test_data.html</strong>: Stores monitoring results for test and production data.</li></ul><p id="a245" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This project structure is designed to organize the entire machine learning project, from development to monitoring.</p><p id="627f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, let's create a virtual environment and activate it using the following commands:</p><p id="ec6d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">For bash:</strong></p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="75e6" class="pr om fq po b bg ps pt l pu pv">#create venv<br/>python3 -m venv venv</span></pre><pre class="pw pn po pp bp pq bb bk"><span id="569f" class="pr om fq po b bg ps pt l pu pv">#activate<br/>source venv/bin/activate</span></pre><p id="14ab" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">For cmd:</strong></p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="9bba" class="pr om fq po b bg ps pt l pu pv">#create venv<br/>python -m venv venv</span></pre><pre class="pw pn po pp bp pq bb bk"><span id="0745" class="pr om fq po b bg ps pt l pu pv">#activate<br/>.\venv\Scripts\activate</span></pre><p id="4e5e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, install all required packages using the <code class="cx px py pz po b">requirements.txt</code> file.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="0a7f" class="pr om fq po b bg ps pt l pu pv">#install all the dependancies<br/>pip install -r requirements.txt</span></pre><h2 id="af24" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/488421180facfca41024fb0e159dc7fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jaW0AXduRLnnJk1wPyAOSg.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of project setup</figcaption></figure><p id="4083" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">With the environment set up and dependencies installed, we can now move on to the model training part.</p><h1 id="a633" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Model Training</h1><p id="1ff8" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">In model training, the first step is to get data from the source, which could be either local storage or remote storage. To do this, run the <code class="cx px py pz po b">dataset.py</code> file.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="fd3f" class="pr om fq po b bg ps pt l pu pv">#to get data from source<br/>python3 dataset.py</span></pre><p id="f6ea" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This script retrieves the data from its source, splits it into training and testing datasets, and then stores them in the <code class="cx px py pz po b">data/</code> directory.</p><h2 id="10da" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/8efa34dfc2f40d4e48f1356718dbffe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NR2vAo0zjmDboAlH7KBdLw.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of data extraction</figcaption></figure><p id="7183" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Once the data is stored in the data directory, the next steps include cleaning, processing, and model training. The <code class="cx px py pz po b">steps/</code> folder contains modules for each of these stages.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="aa22" class="pr om fq po b bg ps pt l pu pv">#model training part from project structure<br/><br/>├── steps/                     <br/>│   ├── ingest.py              <br/>│   ├── clean.py <br/>│   ├── train.py            <br/>│   └── predict.py<br/>├── main.py                    <br/>├── models/model.pkl</span></pre><p id="1835" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let's take a look at what each file does:</p><ul class=""><li id="bb93" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><code class="cx px py pz po b">ingestion.py</code> handles the initial data ingestion, ensuring that data is correctly loaded and available for the next stages.</li><li id="340c" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><code class="cx px py pz po b">clean.py</code> focuses on data cleaning tasks, such as handling missing values, removing duplicates, and making other data quality improvements.</li><li id="6d8c" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><code class="cx px py pz po b">train.py</code> responsible for training the model on the cleaned data and saving the model as <code class="cx px py pz po b">model.pkl</code> in the <code class="cx px py pz po b">models/</code> directory.</li><li id="e689" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><code class="cx px py pz po b">predict.py</code>is used to evaluate model performance on test data using the trained model.</li></ul><blockquote class="oh oi oj"><p id="e8fb" class="nc nd ok ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Note:</strong> These files can be changed or removed depending on project requirements.</p></blockquote><p id="67d0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To run all these steps in sequence, execute the <code class="cx px py pz po b">main.py</code> file:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="a360" class="pr om fq po b bg ps pt l pu pv">#to train the model<br/>python3 main.py</span></pre><p id="e0d7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here’s how the <code class="cx px py pz po b">main.py</code> file looks in this project:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="cadd" class="pr om fq po b bg ps pt l pu pv">import logging<br/>from steps.ingest import Ingestion<br/>from steps.clean import Cleaner<br/>from steps.train import Trainer<br/>from steps.predict import Predictor<br/><br/># Set up logging<br/>logging.basicConfig(level=logging.INFO,format='%(asctime)s:%(levelname)s:%(message)s')<br/><br/>def main():<br/>    # Load data<br/>    ingestion = Ingestion()<br/>    train, test = ingestion.load_data()<br/>    logging.info("Data ingestion completed successfully")<br/><br/>    # Clean data<br/>    cleaner = Cleaner()<br/>    train_data = cleaner.clean_data(train)<br/>    test_data = cleaner.clean_data(test)<br/>    logging.info("Data cleaning completed successfully")<br/><br/>    # Prepare and train model<br/>    trainer = Trainer()<br/>    X_train, y_train = trainer.feature_target_separator(train_data)<br/>    trainer.train_model(X_train, y_train)<br/>    trainer.save_model()<br/>    logging.info("Model training completed successfully")<br/><br/>    # Evaluate model<br/>    predictor = Predictor()<br/>    X_test, y_test = predictor.feature_target_separator(test_data)<br/>    accuracy, class_report, roc_auc_score = predictor.evaluate_model(X_test, y_test)<br/>    logging.info("Model evaluation completed successfully")<br/>    <br/>    # Print evaluation results<br/>    print("\n============= Model Evaluation Results ==============")<br/>    print(f"Model: {trainer.model_name}")<br/>    print(f"Accuracy Score: {accuracy:.4f}, ROC AUC Score: {roc_auc_score:.4f}")<br/>    print(f"\n{class_report}")<br/>    print("=====================================================\n")<br/><br/>if __name__ == "__main__":<br/>    main()</span></pre><h2 id="69bf" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk"><strong class="al">Example:</strong></h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/6c5658496e301f579e1ff3d2b6d49497.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5W2tefWJouuSGv9l6ccsVw.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of model training</figcaption></figure><p id="0e9b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, let’s see how we can improve this project using tools like DVC and MLflow.</p><h1 id="bc79" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Data Version Control (DVC)</h1><p id="c871" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">Let’s start with Data Version Control (DVC), a free, open-source tool designed to manage large datasets, automate ML pipelines, and handle experiments. It helps data science and machine learning teams manage their data more effectively, ensure reproducibility, and improve collaboration.</p><p id="8d93" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Why use DVC over GitHub?</strong></p><p id="3664" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Git is excellent for versioning source code and text files, but it has limitations when dealing with large binary files such as datasets. Git does not provide meaningful comparisons between versions of binary files; it only stores new versions without showing detailed differences, making it challenging to track changes over time. Additionally, storing large datasets or sensitive data in GitHub is not ideal, as it can lead to bloated repositories and potential security risks.</p><p id="83f6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">DVC addresses these issues by managing large files through metadata and external storage (such as S3, Google Cloud Storage, or Azure Blob Storage) while maintaining detailed tracking of data changes and version history. DVC uses human-readable metafiles to define data versions and integrates with Git or any source control management (SCM) tool to version and share the entire project, including data assets. Additionally, it provides secure collaboration by controlling access to project components and sharing them with designated teams and individuals.</p><p id="8368" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To get started with DVC, first install it (if it’s not already installed):</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="327c" class="pr om fq po b bg ps pt l pu pv">#install DVC via pip<br/>pip install dvc</span></pre><p id="02bc" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then, initialize DVC:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="f707" class="pr om fq po b bg ps pt l pu pv">#initialize a DVC<br/>dvc init</span></pre><p id="8f09" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This sets up the necessary DVC configuration files.</p><p id="2751" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, add data files to DVC:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="48a9" class="pr om fq po b bg ps pt l pu pv">#add data<br/>dvc add data</span></pre><p id="5ff1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This tracks the data files with DVC, storing the actual data in external storage.</p><p id="0413" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Configure remote storage:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="7223" class="pr om fq po b bg ps pt l pu pv">#add remote storage configuration<br/>dvc remote add -d &lt;remote_name&gt; &lt;remote_storage_path&gt;</span></pre><p id="fbbb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Replace <code class="cx px py pz po b">&lt;remote_name&gt;</code> with a name for remote storage and <code class="cx px py pz po b">&lt;remote_storage_path&gt;</code> with the path to the remote storage (e.g., s3://mybucket/mydata).</p><p id="0bfe" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Push data to remote storage:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="72da" class="pr om fq po b bg ps pt l pu pv">#commit the DVC configuration changes to Git<br/>git commit .dvc/config -m 'config dvc store'</span></pre><pre class="pw pn po pp bp pq bb bk"><span id="83d9" class="pr om fq po b bg ps pt l pu pv">#upload data to the configured remote storage<br/>dvc push</span></pre><p id="7e7d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This uploads data to the configured remote storage.</p><p id="5d22" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Push all committed changes to git:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="980a" class="pr om fq po b bg ps pt l pu pv">#push all committed changes to the Git repository<br/>git push origin main</span></pre><h2 id="a17b" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/621cfc48be2931844cdb2bfd443bf86f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gsCd9xtN2XDmQgiH8VS6sg.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of DVC push</figcaption></figure><p id="85ca" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To pull the latest data version from remote storage to the local directory, use the following command:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="e16c" class="pr om fq po b bg ps pt l pu pv">#pull the latest version of the data<br/>dvc pull</span></pre><h2 id="1d20" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/486c09f9c048043971f6ceccee56fd54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IYtCCqeTFGm1JThRKgqwEg.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of DVC pull</figcaption></figure><p id="7ff1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By integrating DVC, we can manage large datasets efficiently while keeping the Git repository focused on source code.</p><blockquote class="oh oi oj"><p id="41ff" class="nc nd ok ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Note: </strong>We can use DVC to version models just like data files.</p></blockquote><h1 id="2aea" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">MLflow</h1><p id="1266" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">After versioning data with DVC, it’s crucial to maintain a clear record of model training, version changes, and parameter configurations, even if we are not actively experimenting with multiple models.</p><p id="25e4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Without systematic tracking, several issues can arise:</p><ol class=""><li id="b478" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx qs nz oa bk"><strong class="ne fr">Loss of Version Details</strong>: Without keeping track of which parameters and code changes were used for each model version, it becomes hard to reproduce or build on past work. This can slow down the progress and cause repeated mistakes.</li><li id="2dcc" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx qs nz oa bk"><strong class="ne fr">Difficulty in Version Comparison</strong>: Consistently recording how well each model performs helps compare different versions. Without this, it is tough to see if a model is improving or not.</li><li id="b8f6" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx qs nz oa bk"><strong class="ne fr">Collaboration Challenges</strong>: In a team, not having a clear way to manage model versions can lead to confusion and accidental overwrites of each other’s work, complicating the collaborative process.</li></ol><p id="efc8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This is where MLflow comes in. MLflow is not just for experimenting; it also plays a critical role in tracking the lifecycle of ML models. It logs metrics, artifacts, and parameters, ensuring that every version change is documented and easily retrievable. With MLflow, we can monitor each run, and compare different versions. So that the most effective model is always identifiable and ready for deployment.</p><p id="f757" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To integrate MLflow, first install MLflow (if it’s not already installed):</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="3bbe" class="pr om fq po b bg ps pt l pu pv">#install mlfow<br/>pip install mlflow</span></pre><p id="a95b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then update the <code class="cx px py pz po b">main.py</code> file to include logging of parameters, metrics, and models. The code will look something like this:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="8226" class="pr om fq po b bg ps pt l pu pv">import logging<br/>import yaml<br/>import mlflow<br/>import mlflow.sklearn<br/>from steps.ingest import Ingestion<br/>from steps.clean import Cleaner<br/>from steps.train import Trainer<br/>from steps.predict import Predictor<br/>from sklearn.metrics import classification_report<br/><br/># Set up logging<br/>logging.basicConfig(level=logging.INFO,format='%(asctime)s:%(levelname)s:%(message)s')<br/><br/>def main():<br/><br/>    with open('config.yml', 'r') as file:<br/>        config = yaml.safe_load(file)<br/><br/>    mlflow.set_experiment("Model Training Experiment")<br/>    <br/>    with mlflow.start_run() as run:<br/>        # Load data<br/>        ingestion = Ingestion()<br/>        train, test = ingestion.load_data()<br/>        logging.info("Data ingestion completed successfully")<br/><br/>        # Clean data<br/>        cleaner = Cleaner()<br/>        train_data = cleaner.clean_data(train)<br/>        test_data = cleaner.clean_data(test)<br/>        logging.info("Data cleaning completed successfully")<br/><br/>        # Prepare and train model<br/>        trainer = Trainer()<br/>        X_train, y_train = trainer.feature_target_separator(train_data)<br/>        trainer.train_model(X_train, y_train)<br/>        trainer.save_model()<br/>        logging.info("Model training completed successfully")<br/>        <br/>        # Evaluate model<br/>        predictor = Predictor()<br/>        X_test, y_test = predictor.feature_target_separator(test_data)<br/>        accuracy, class_report, roc_auc_score = predictor.evaluate_model(X_test, y_test)<br/>        report = classification_report(y_test, trainer.pipeline.predict(X_test), output_dict=True)<br/>        logging.info("Model evaluation completed successfully")<br/>        <br/>        # Tags <br/>        mlflow.set_tag('Model developer', 'prsdm')<br/>        mlflow.set_tag('preprocessing', 'OneHotEncoder, Standard Scaler, and MinMax Scaler')<br/>        <br/>        # Log metrics<br/>        model_params = config['model']['params']<br/>        mlflow.log_params(model_params)<br/>        mlflow.log_metric("accuracy", accuracy)<br/>        mlflow.log_metric("roc", roc_auc_score)<br/>        mlflow.log_metric('precision', report['weighted avg']['precision'])<br/>        mlflow.log_metric('recall', report['weighted avg']['recall'])<br/>        mlflow.sklearn.log_model(trainer.pipeline, "model")<br/>                <br/>        # Register the model<br/>        model_name = "insurance_model" <br/>        model_uri = f"runs:/{run.info.run_id}/model"<br/>        mlflow.register_model(model_uri, model_name)<br/><br/>        logging.info("MLflow tracking completed successfully")<br/><br/>        # Print evaluation results<br/>        print("\n============= Model Evaluation Results ==============")<br/>        print(f"Model: {trainer.model_name}")<br/>        print(f"Accuracy Score: {accuracy:.4f}, ROC AUC Score: {roc_auc_score:.4f}")<br/>        print(f"\n{class_report}")<br/>        print("=====================================================\n")<br/>        <br/>if __name__ == "__main__":<br/>    main()</span></pre><p id="8f8e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, run the <code class="cx px py pz po b">main.py</code> script and view experiment details using the following command:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="2b42" class="pr om fq po b bg ps pt l pu pv">#to launch MLflow UI<br/>mlflow ui</span></pre><p id="470c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Open the provided URL <code class="cx px py pz po b">http://127.0.0.1:5000</code> in a browser to explore and compare logged parameters, metrics, and models.</p><h2 id="583d" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/2b0c5e829afeb61208545943899ba635.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jaTGjhFn3MJWdu471an6uw.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of MLflow tracking</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/76fa71c6428e417e297efad96fbdc37b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pK9uVPfoFNBR2DU2Kh-_-g.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of MLflow model comparison</figcaption></figure><p id="0676" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By using MLflow, we can easily track model versions and manage changes, ensuring reproducibility and the ability to select the most effective model for deployment.</p><p id="2fa1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Before we move to the deployment part, let’s take a look at the <code class="cx px py pz po b">Makefile</code> and <code class="cx px py pz po b">config.yml</code> files that are present in the project. These files help simplify the workflow and ensure consistency in the project setup and configuration.</p><h1 id="7550" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Makefile</h1><p id="4eda" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">Using <code class="cx px py pz po b">make</code> file can be very helpful for managing Python projects. Many Data Scientists and ML Engineers don’t realize this but <code class="cx px py pz po b">make</code>can automate routine tasks such as setting up the environment, installing dependencies, model training, running tests, and cleaning up files, which saves time and reduces mistakes. <code class="cx px py pz po b">make</code> file is commonly used in software development because it helps manage long and complex commands that are difficult to remember.</p><p id="0feb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The <code class="cx px py pz po b">make</code> file in this project looks something like this:</p><p id="bc6a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">bash:</strong></p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="7f99" class="pr om fq po b bg ps pt l pu pv">python = venv/bin/python<br/>pip = venv/bin/pip<br/><br/>setup:<br/> python3 -m venv venv<br/> $(python) -m pip install --upgrade pip<br/> $(pip) install -r requirements.txt<br/><br/>run:<br/> $(python) main.py<br/><br/>mlflow:<br/> venv/bin/mlflow ui<br/><br/>test:<br/> $(python) -m pytest<br/>  <br/>clean:<br/> rm -rf steps/__pycache__<br/> rm -rf __pycache__<br/> rm -rf .pytest_cache<br/> rm -rf tests/__pycache__<br/><br/>remove:<br/> rm -rf venv</span></pre><p id="1dfc" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For Windows (<strong class="ne fr">cmd</strong>), the file needs to be modified a little bit.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="a2e7" class="pr om fq po b bg ps pt l pu pv">python = venv/Scripts/python<br/>pip = venv/Scripts/pip<br/><br/>setup:<br/> python -m venv venv<br/> $(python) -m pip install --upgrade pip<br/> $(pip) install -r requirements.txt<br/><br/>run:<br/> $(python) main.py<br/><br/>mlflow:<br/> venv/Scripts/mlflow ui<br/><br/>test:<br/> $(python) -m pytest<br/>  <br/>clean:<br/> @if exist steps\__pycache__ (rmdir /s /q steps\__pycache__)<br/> @if exist __pycache__ (rmdir /s /q __pycache__)<br/> @if exist .pytest_cache (rmdir /s /q .pytest_cache)<br/> @if exist tests\__pycache__ (rmdir /s /q tests\__pycache__)<br/><br/>remove:<br/> @if exist venv (rmdir /s /q venv)</span></pre><p id="6e38" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here’s a breakdown of each part:</p><ul class=""><li id="67b9" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><strong class="ne fr">make setup</strong>: Creates a virtual environment (<code class="cx px py pz po b">venv</code>), upgrades <code class="cx px py pz po b">pip</code>, and installs the required packages from <code class="cx px py pz po b">requirements.txt</code>. This ensures that all dependencies are consistently installed across different environments.</li><li id="8e0d" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">make run</strong>: Executes the <code class="cx px py pz po b">main.py</code> using the Python interpreter from the virtual environment.</li><li id="a530" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">make mlflow</strong>: Starts the <code class="cx px py pz po b">mlflow ui</code> for tracking experiments and model metrics.</li><li id="1f50" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">make test</strong>: This command runs all test cases defined in the project using <code class="cx px py pz po b">pytest</code>.</li><li id="a96c" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">make clean</strong>: Removes cache files such as <code class="cx px py pz po b">__pycache__</code>, <code class="cx px py pz po b">.pytest_cache</code>, and other temporary files to keep the directory clean.</li><li id="2d95" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">make remove</strong>: Removes the virtual environment (<code class="cx px py pz po b">venv</code>) completely from the project.</li></ul><p id="8c53" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Sample commands to run make file:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="7d6b" class="pr om fq po b bg ps pt l pu pv"># For example, to set up the environment<br/>make setup<br/><br/># OR To run the main script<br/>make run<br/><br/># OR To run the tests<br/>make test<br/><br/># so on...</span></pre><h2 id="d770" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/41fc482a0cc487231ca3bf1574c4647b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ju2QsZvFTKXZTQ0fRcunjQ.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of Make Commands</figcaption></figure><p id="7b33" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By using the <code class="cx px py pz po b">make</code> file, we can automate and streamline various tasks, ensuring consistency and reducing manual errors across different environments.</p><h1 id="a17c" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Config.yml</h1><p id="0f78" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">YAML files are a great way to store and manage configuration settings for Machine Learning models. They help manage data/model paths, model parameters, and other configurations, making it easier to experiment with different configurations and maintain code reusability.</p><p id="5879" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The <code class="cx px py pz po b">Config.yml</code> file looks like this:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="0908" class="pr om fq po b bg ps pt l pu pv">data: <br/>  train_path: data/train.csv<br/>  test_path: data/test.csv<br/><br/>train:<br/>  test_size: 0.2<br/>  random_state: 42<br/>  shuffle: true<br/><br/>model:<br/>  name: DecisionTreeClassifier<br/>  params:<br/>    criterion: entropy<br/>    max_depth: null<br/>  store_path: models/<br/><br/>  # name: GradientBoostingClassifier<br/>  # params:<br/>  #   max_depth: null<br/>  #   n_estimators: 10<br/>  # store_path: models/<br/><br/>  # name: RandomForestClassifier<br/>  # params:<br/>  #   n_estimators: 50<br/>  #   max_depth: 10<br/>  #   random_state: 42<br/>  # store_path: models/</span></pre><p id="9a94" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here's what each part does:</p><ul class=""><li id="5522" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><strong class="ne fr">data</strong>: Specifies the paths to the training, test, and production (latest) datasets. This ensures that the data locations are managed in one place and can be easily updated.</li><li id="d0af" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">train</strong>: Contains parameters for splitting the data into training and test sets, such as <code class="cx px py pz po b">test_size</code>, <code class="cx px py pz po b">random_state</code>, and whether to <code class="cx px py pz po b">shuffle</code> the data. These settings help maintain consistent data splitting and reproducibility.</li><li id="b1b2" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">model</strong>: Defines the model name, its parameters, and the location for storing the trained model. This configuration enables easy switching between different models, offering flexibility in model selection.</li></ul><p id="fb09" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Using the <code class="cx px py pz po b">config.yml</code> file simplifies the management of model parameters and paths. It allows for easy experimentation with different configurations and models, improves reproducibility by keeping parameter settings consistent, and helps maintain cleaner code by separating configuration from code logic.</p><h2 id="2f39" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><p id="9fbd" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">In the following example model is changed to<strong class="ne fr"> ‘</strong>GradientBoostingClassifier’ based on the configuration specified in the <code class="cx px py pz po b">config.yml</code> file.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/ece4352cdd5170ffa837850b64d05f68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OOkkhjSOwoGBDOfeUS0edg.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of config.yml file</figcaption></figure><p id="6e99" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, let’s move on to the deployment part, where we will use FastAPI, Docker and AWS ECS. This setup will help us create a scalable and easily manageable application for serving machine learning model.</p><h1 id="f6c8" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">FastAPI</h1><p id="fe4b" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">FastAPI is a modern framework for building APIs with Python. It is efficient for serving machine learning models due to its speed and simplicity.</p><p id="9218" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First, install FastAPI and Uvicorn (if it’s not already installed):</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="6d4c" class="pr om fq po b bg ps pt l pu pv">#install fastapi and uvicorn<br/>pip install fastapi uvicorn</span></pre><p id="74ea" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Define the FastAPI application and endpoints for serving the model in the <code class="cx px py pz po b">app.py</code>file.</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="7b9b" class="pr om fq po b bg ps pt l pu pv">from fastapi import FastAPI<br/>from pydantic import BaseModel<br/>import pandas as pd<br/>import joblib<br/><br/>app = FastAPI()<br/><br/>class InputData(BaseModel):<br/>    Gender: str<br/>    Age: int<br/>    HasDrivingLicense: int<br/>    RegionID: float<br/>    Switch: int<br/>    PastAccident: str<br/>    AnnualPremium: float<br/><br/>model = joblib.load('models/model.pkl')<br/><br/>@app.get("/")<br/>async def read_root():<br/>    return {"health_check": "OK", "model_version": 1}<br/><br/>@app.post("/predict")<br/>async def predict(input_data: InputData):<br/>    <br/>        df = pd.DataFrame([input_data.model_dump().values()], <br/>                          columns=input_data.model_dump().keys())<br/>        pred = model.predict(df)<br/>        return {"predicted_class": int(pred[0])}</span></pre><p id="d939" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then, test the FastAPI server locally at <code class="cx px py pz po b"><a class="af og" href="http://127.0.0.1:8000/docs." rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:8000/docs</a></code>using the following command:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="62c9" class="pr om fq po b bg ps pt l pu pv">#run the FastAPI app<br/>uvicorn app:app --reload</span></pre><h2 id="7e75" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/ff6022408bfec3ee5ca68f5b95dbdc63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TesjobVr4hS4Gp1-JRfUKQ.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of FastAPI</figcaption></figure><p id="a692" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s now containerize this API using Docker.</p><h1 id="e189" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Docker</h1><p id="1092" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">Docker is an open-source platform that simplifies the deployment of software applications by packaging them into containers. These containers act as lightweight, portable units that include everything needed to run the application across different environments.</p><p id="4558" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Why Use Containers?</strong></p><p id="d9a0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Containers offer a streamlined way to isolate and deploy applications, ensuring they run consistently across various environments, whether on a developer’s laptop or the cloud. This isolation enhances portability and resource efficiency, making docker an essential tool for modern software development.</p><p id="654d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To install Docker, follow the instructions on the Docker <a class="af og" href="https://docs.docker.com/engine/install/" rel="noopener ugc nofollow" target="_blank">website</a>.</p><p id="d942" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, create a <code class="cx px py pz po b">Dockerfile</code> in the project directory to build the Docker image:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="591f" class="pr om fq po b bg ps pt l pu pv">#official Python 3.10 image<br/>FROM python:3.10<br/><br/>#set the working directory <br/>WORKDIR /app<br/><br/>#add app.py and models directory<br/>COPY app.py .<br/>COPY models/ ./models/<br/><br/># add requirements file<br/>COPY requirements.txt .<br/><br/># install python libraries<br/>RUN pip install --no-cache-dir -r requirements.txt<br/><br/># specify default commands<br/>CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "80"]</span></pre><p id="3226" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, build a Docker image using the following command:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="f4ee" class="pr om fq po b bg ps pt l pu pv"># To build docker image<br/>docker build -t &lt;image_name&gt; &lt;path_to_dockerfile&gt;</span></pre><h2 id="113d" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/6a4b94e713432e4dd043e616c9252956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-akol2hTBZQUQok7oo1cKA.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of docker build</figcaption></figure><p id="55ea" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Finally, run the Docker container to test the API at <code class="cx px py pz po b"><a class="af og" href="http://localhost:8000/predict" rel="noopener ugc nofollow" target="_blank">http://localhost:80/predict</a></code>:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="b81e" class="pr om fq po b bg ps pt l pu pv"># To run docker container<br/>docker run -d -p 80:80 &lt;image_name&gt;</span></pre><h2 id="c852" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/987e60966002426488027646f2a2da9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_XGLjLtWGxGlPPJRGTgLnA.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of docker run</figcaption></figure><p id="6659" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To stop a running Docker container, find the container ID or name of the running container using the following command:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="3b39" class="pr om fq po b bg ps pt l pu pv"># To show running containers<br/>docker ps</span></pre><p id="c88f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Once the container ID or name is identified, it can be stopped using the following command:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="0fe1" class="pr om fq po b bg ps pt l pu pv"># To stop the container<br/>docker stop &lt;container_id_or_name&gt;</span></pre><h2 id="a568" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/17f265eb272f9f80a8365c4045e2be0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cAdsa-5DtJ5v8SSyCy9RyQ.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of stopping running container</figcaption></figure><p id="4b5f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, to push the Docker image to Docker Hub, follow these steps:</p><p id="5815" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">List all Docker images on the system along with their tags and find the correct image to be pushed:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="4763" class="pr om fq po b bg ps pt l pu pv"># List images by name and tag.<br/>docker image ls</span></pre><p id="94ef" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Tag the image with the desired repository and name:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="a15d" class="pr om fq po b bg ps pt l pu pv"># Tag the image<br/>docker tag &lt;image_name&gt; &lt;dockerhub_username&gt;/&lt;docker-repo-name&gt;</span></pre><p id="b1eb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Upload the tagged image to Docker Hub using the following command:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="2c7c" class="pr om fq po b bg ps pt l pu pv"># Push the Docker image <br/>docker push &lt;dockerhub_username&gt;/&lt;docker-repo-name&gt;:latest</span></pre><p id="7e63" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This command will upload the image to the specified repository on <a class="af og" href="https://hub.docker.com/r/prsdm17/ml-fastapi" rel="noopener ugc nofollow" target="_blank">Docker Hub</a>.</p><h2 id="663f" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/6cbeca077321b30125b63f03cf8c8cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rFVwUJhnUDNzd6GhNy7MPw.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of Docker Push Commands</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qt"><img src="../Images/cd391dafbbf7faacc837a7544a304b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GwWQTdLohr6r2DkrxL4fiA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of Docker Hub Repository</figcaption></figure><p id="b76b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now that we have pushed the Docker image to <a class="af og" href="https://hub.docker.com/r/prsdm17/ml-fastapi" rel="noopener ugc nofollow" target="_blank">Docker Hub</a>, we can move on to deploy it on AWS Elastic Container Service (ECS).</p><h1 id="0df0" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">AWS ECS</h1><p id="f0aa" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">AWS ECS is a fully managed container orchestration service that allows running and scaling Docker containers on AWS easily. It supports both EC2 and Fargate launch types. Here is a step-by-step guide:</p><p id="53ed" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">First, create an ECS Cluster:</strong></p><ul class=""><li id="9b1d" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><strong class="ne fr">Step 1: </strong>Log in to the <a class="af og" href="https://aws.amazon.com/console/" rel="noopener ugc nofollow" target="_blank">AWS</a> account then go to the ECS service and create a new ECS cluster by selecting “Create Cluster.”</li><li id="5f82" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">Step 2:</strong> Give a name to the cluster, select AWS Fargate (serverless), and click on “Create.” (This will take a few minutes.)</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/73c0a880af4734335fbe9f7195681157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0QRdjQYQh224NsdzSA6jSg.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of AWS Cluster</figcaption></figure><p id="8559" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Then, define a Task Definition:</strong></p><ul class=""><li id="4651" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><strong class="ne fr">Step 1:</strong> In the ECS console, go to “Task Definitions” and create a new task definition.</li><li id="b5d7" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">Step 2:</strong> Give the task a name and configure settings such as memory and CPU requirements.</li><li id="73d9" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">Step 3:</strong> Docker image URL from Docker Hub in the container definitions and keep the container port mappings default. Click on “Create.”</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/19ce792b71f55a9c6a2631e354032621.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F3gW4s-4iau7guds2xwkKQ.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of Task Definition</figcaption></figure><p id="21c0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">After that, add a Security Group:</strong></p><ul class=""><li id="c24e" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><strong class="ne fr">Step 1:</strong> Go to EC2, then in Networks and Security, select Security Groups and click on “Create Security Group.” Give it a name and description.</li><li id="8a97" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">Step 2:</strong> In Inbound Rules, select the type HTTP and source Anywhere-IPv4 first, then do the same for Anywhere-IPv6. Click “Create Security Group.”</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/c84e4e7149e7fe304b8dc251c35ec1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IYSpaCKKs2Pzd88aMAsG_w.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of AWS security Group</figcaption></figure><p id="256e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Then, create a Service:</strong></p><ul class=""><li id="4c69" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk"><strong class="ne fr">Step 1:</strong> Go to the ECS cluster that was created and add a new service.</li><li id="e1d7" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">Step 2:</strong> Select the ‘launch type’ compute options and ‘Fargate’ launch type. Then select the task definition that was created and give the service name in the deployment configuration.</li><li id="014f" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk"><strong class="ne fr">Step 3:</strong> Finally, select the security group created earlier under Networking and click “Create.” (This will take 5–8 minutes to create the service.)</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/a98607ff0fc23752d7c68c3b904ba920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IMlio45hl07uJ51Hhss7wg.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of services</figcaption></figure><p id="1ed8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">And Finally, Access the Running Service:</strong></p><p id="ad0f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Once the service is deployed, go to the ECS cluster’s “Services” tab. Find service, go to the “Tasks” tab, and select a running task. Open the public IP address of the task to access the FastAPI application. It will look something like this:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qu"><img src="../Images/2e699102eb90f96d1c722da9f5ba8dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W_Uzaj5gIYJI6db9rp-vTA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of Public IP</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qt"><img src="../Images/c29015d8e8feecab646eeb5264dd2d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*adFBAcl9CCPmR1sD5dLlpg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of deployed service</figcaption></figure><p id="bf62" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By following these steps, we can deploy the FastAPI application in a Docker container to AWS ECS. This enables a scalable and manageable environment for serving machine learning model.</p><blockquote class="oh oi oj"><p id="f6b2" class="nc nd ok ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Note:</strong> We can also add Elastic Load Balancing (ELB) if needed.</p></blockquote><p id="79bc" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After successfully deploying the model, the next step is to continuously monitor the model in production to ensure it performs well on production data. Model monitoring involves evaluating various factors such as server metrics (e.g., CPU usage, memory consumption, latency), data quality, data drift, target drift, concept drift, performance metrics, etc.</p><p id="c36e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To keep it beginner-friendly, we are going to focus on a few methods such as data drift, target drift, and data quality using Evidently AI.</p><h1 id="c065" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Evidently AI</h1><p id="c7a0" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">Evidently AI is a good tool for monitoring model performance, detecting data drift, and data quality over time. It helps ensure that the model remains accurate and reliable as new data comes in. Evidently AI provides detailed insights into how model performance evolves and identifies any significant shifts in the data distribution, which is crucial for maintaining model accuracy in production environments.</p><p id="918a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To install Evidently AI use the following command:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="5a25" class="pr om fq po b bg ps pt l pu pv">#to install<br/>pip install evidently<br/><br/>#or<br/>pip install evidently @ git+https://github.com/evidentlyai/evidently.git</span></pre><p id="1c0e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Next, run <code class="cx px py pz po b">monitor.ipynb</code> file to detect data quality, data drifts, and target drifts. The file looks something like this:</p><pre class="mm mn mo mp mq pn po pp bp pq bb bk"><span id="71db" class="pr om fq po b bg ps pt l pu pv"># If this .py file doesn't work, then use a notebook to run it.<br/>import joblib<br/>import pandas as pd<br/>from steps.clean import Cleaner<br/>from evidently.report import Report<br/>from evidently.metric_preset import DataDriftPreset, DataQualityPreset, TargetDriftPreset<br/>from evidently import ColumnMapping<br/>import warnings<br/>warnings.filterwarnings("ignore")<br/><br/><br/># # import mlflow model version 1<br/># import mlflow<br/># logged_model = 'runs:/47b6b506fd2849429ee13576aef4a852/model'<br/># model = mlflow.pyfunc.load_model(logged_model)<br/><br/># # OR import from models/<br/>model = joblib.load('models/model.pkl')<br/><br/><br/># Loading data<br/>reference = pd.read_csv("data/train.csv")<br/>current = pd.read_csv("data/test.csv")<br/>production = pd.read_csv("data/production.csv")<br/><br/><br/># Clean data<br/>cleaner = Cleaner()<br/>reference = cleaner.clean_data(reference)<br/>reference['prediction'] = model.predict(reference.iloc[:, :-1])<br/><br/>current = cleaner.clean_data(current)<br/>current['prediction'] = model.predict(current.iloc[:, :-1])<br/><br/>production = cleaner.clean_data(production)<br/>production['prediction'] = model.predict(production.iloc[:, :-1])<br/><br/><br/># Apply column mapping<br/>target = 'Result'<br/>prediction = 'prediction'<br/>numerical_features = ['Age', 'AnnualPremium', 'HasDrivingLicense', 'RegionID', 'Switch']<br/>categorical_features = ['Gender','PastAccident']<br/>column_mapping = ColumnMapping()<br/><br/>column_mapping.target = target<br/>column_mapping.prediction = prediction<br/>column_mapping.numerical_features = numerical_features<br/>column_mapping.categorical_features = categorical_features<br/><br/><br/><br/># Data drift detaction part<br/>data_drift_report = Report(metrics=[<br/>    DataDriftPreset(),<br/>    DataQualityPreset(),<br/>    TargetDriftPreset()<br/>])<br/>data_drift_report.run(reference_data=reference, current_data=current, column_mapping=column_mapping)<br/>data_drift_report<br/># data_drift_report.json()<br/>data_drift_report.save_html("test_drift.html")</span></pre><h2 id="89ae" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example of Test data:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/909559efedea6b04a1634846dc5d2385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ByS7RpsyanvIucYUGpcxQ.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of Test data quality and drift detect</figcaption></figure><h2 id="8c64" class="qa om fq bf on qb qc qd oq qe qf qg ot nl qh qi qj np qk ql qm nt qn qo qp qq bk">Example of Production data:</h2><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/1f9483ebcf1b453e4e82edb3bd5c0699.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bMmDme-vkym6PeUyAXTukA.gif"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of Production data quality and drift detect</figcaption></figure><p id="4dfb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Run the monitoring script regularly on incoming data to generate reports on data drift and model performance. These reports can help us identify when retraining is needed and ensure that our model remains accurate and reliable over time.</p><p id="399e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">With this step, we have successfully completed the MLOps project implementation.</p><h1 id="79fb" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Summary</h1><p id="5b44" class="pw-post-body-paragraph nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx fj bk">In this article, we covered basic MLOps practices and tools through a hands-on project. We versioned data with DVC, tracked and registered models using MLflow, and deployed a model with FastAPI, Docker, and AWS ECR. We also set up model monitoring (data quality, data drift, and target drift) with Evidently AI. These steps provide a solid foundation for managing machine learning projects using MLOps tools and practices, from development to production. As you gain experience with these tools and techniques, you can explore more advanced automation and orchestration methods to enhance your MLOps workflows.</p><h1 id="8695" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Reference</h1><ol class=""><li id="ac9b" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx qs nz oa bk">Machine Learning Operations (MLOps): Overview, Definition, and Architecture. (<a class="af og" href="https://arxiv.org/pdf/2205.02302" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2205.02302</a>)</li><li id="39d5" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx qs nz oa bk">Data Version Control (DVC): <a class="af og" href="https://dvc.org/doc" rel="noopener ugc nofollow" target="_blank">https://dvc.org/doc</a></li><li id="4fa0" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx qs nz oa bk">MLflow: <a class="af og" href="https://mlflow.org/docs/latest/index.html" rel="noopener ugc nofollow" target="_blank">https://mlflow.org/docs/latest/index.html</a></li><li id="12f4" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx qs nz oa bk">FastAPI: <a class="af og" href="https://fastapi.tiangolo.com/tutorial/" rel="noopener ugc nofollow" target="_blank">https://fastapi.tiangolo.com/tutorial/</a></li><li id="a3b4" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx qs nz oa bk">Docker: <a class="af og" href="https://docs.docker.com/" rel="noopener ugc nofollow" target="_blank">https://docs.docker.com/</a></li><li id="bc32" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx qs nz oa bk">Evidently AI: <a class="af og" href="https://docs.evidentlyai.com/tutorials-and-examples/examples" rel="noopener ugc nofollow" target="_blank">https://docs.evidentlyai.com/tutorials-and-examples/examples</a></li></ol></div></div></div><div class="ab cb qv qw qx qy" role="separator"><span class="qz by bm ra rb rc"/><span class="qz by bm ra rb rc"/><span class="qz by bm ra rb"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="1a03" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Subscribe for free to get notified when I publish a new article.</p><div class="rd re rf rg rh ri"><a href="https://medium.com/@prasadmahamulkar/subscribe?source=post_page-----a5686bfe02b2--------------------------------" rel="noopener follow" target="_blank"><div class="rj ab ig"><div class="rk ab co cb rl rm"><h2 class="bf fr hw z io rn iq ir ro it iv fp bk">Get an email whenever Prasad Mahamulkar publishes</h2><div class="rp l"><h3 class="bf b hw z io rn iq ir ro it iv dx">Get an email whenever Prasad Mahamulkar publishes Learn about data science, machine learning, and more. By signing up…</h3></div><div class="rq l"><p class="bf b dy z io rn iq ir ro it iv dx">medium.com</p></div></div><div class="rr l"><div class="rs l rt ru rv rr rw lr ri"/></div></div></a></div><p id="6924" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can also find me on <a class="af og" href="https://www.linkedin.com/in/prasad-mahamulkar/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> and <a class="af og" href="https://x.com/prsdm_" rel="noopener ugc nofollow" target="_blank">Twitter</a>!</p></div></div></div></div>    
</body>
</html>