- en: Discover What Every Neuron in the Llama Model Does
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‘ç°Llamaæ¨¡å‹ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ä½œç”¨
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/-0927524e4807?source=collection_archive---------6-----------------------#2024-10-25](https://towardsdatascience.com/-0927524e4807?source=collection_archive---------6-----------------------#2024-10-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/-0927524e4807?source=collection_archive---------6-----------------------#2024-10-25](https://towardsdatascience.com/-0927524e4807?source=collection_archive---------6-----------------------#2024-10-25)
- en: Transluceâ€™s new tool is changing the game for AI transparency â€” a test case
    and some food for thought
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Transluceçš„æ–°å·¥å…·æ­£åœ¨æ”¹å˜AIé€æ˜åº¦çš„æ¸¸æˆè§„åˆ™â€”â€”ä¸€ä¸ªæµ‹è¯•æ¡ˆä¾‹å’Œä¸€äº›æ€è€ƒææ–™
- en: '[](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)[![Ben
    Hagag](../Images/a06fa102dfbe84afc6da846c622265a3.png)](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------)
    [Ben Hagag](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)[![Ben
    Hagag](../Images/a06fa102dfbe84afc6da846c622265a3.png)](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------)
    [Ben Hagag](https://medium.com/@benhagag10?source=post_page---byline--0927524e4807--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------)
    Â·7 min readÂ·Oct 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0927524e4807--------------------------------)
    Â·7åˆ†é’Ÿé˜…è¯»Â·2024å¹´10æœˆ25æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a37c05472f6079eaec9558314ca0054d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a37c05472f6079eaec9558314ca0054d.png)'
- en: Image by the author â€” caught in the act of playing with the new tool!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›â€”â€”æ‹ä¸‹äº†ä½¿ç”¨æ–°å·¥å…·çš„ç¬é—´ï¼
- en: '[Transluce](https://transluce.org/), a new non-profit research lab with an
    inspiring mission, has just released (23.10.24) a fascinating tool that provides
    insights into neuron behavior in LLMs. Or in their own words:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Transluce](https://transluce.org/)ï¼Œä¸€ä¸ªå…·æœ‰å¯å‘æ€§ä½¿å‘½çš„éè¥åˆ©ç ”ç©¶å®éªŒå®¤ï¼Œåˆšåˆšå‘å¸ƒäº†ä¸€ä¸ªå¼•äººå…¥èƒœçš„å·¥å…·ï¼Œæä¾›äº†LLMä¸­ç¥ç»å…ƒè¡Œä¸ºçš„æ´å¯Ÿã€‚æˆ–è€…ç”¨ä»–ä»¬è‡ªå·±çš„è¯æ¥è¯´ï¼š'
- en: When an AI system behaves unexpectedly, weâ€™d like to understand the â€œthought
    processâ€ that explains why the behavior occurred. This lets us predict and fix
    problems with AI models , surface hidden knowledge, and uncover learned biases
    and spurious correlations.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å½“AIç³»ç»Ÿçš„è¡Œä¸ºå‡ºä¹æ„æ–™æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›äº†è§£â€œæ€è€ƒè¿‡ç¨‹â€ï¼Œä»¥è§£é‡Šä¸ºä½•ä¼šå‘ç”Ÿè¿™ç§è¡Œä¸ºã€‚è¿™è®©æˆ‘ä»¬èƒ½å¤Ÿé¢„æµ‹å¹¶ä¿®å¤AIæ¨¡å‹ä¸­çš„é—®é¢˜ï¼Œæ­ç¤ºéšè—çš„çŸ¥è¯†ï¼Œæ­éœ²å­¦åˆ°çš„åè§å’Œè™šå‡çš„å…³è”ã€‚
- en: To fulfill their mission, they have launched an observability interface where
    you can input your own prompts, receive responses, and see which neurons are activated.
    You can then explore the activated neurons and their attribution to the modelâ€™s
    output, all enabled by their novel approach to automatically producing high-quality
    descriptions of neurons inside language models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°ä»–ä»¬çš„ä½¿å‘½ï¼Œä»–ä»¬æ¨å‡ºäº†ä¸€ä¸ªå¯è§‚å¯Ÿæ€§ç•Œé¢ï¼Œä½ å¯ä»¥åœ¨å…¶ä¸­è¾“å…¥è‡ªå·±çš„æç¤ºè¯­ï¼Œè·å–å›åº”ï¼Œå¹¶æŸ¥çœ‹å“ªäº›ç¥ç»å…ƒè¢«æ¿€æ´»ã€‚ä½ å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢è¿™äº›æ¿€æ´»çš„ç¥ç»å…ƒåŠå…¶å¯¹æ¨¡å‹è¾“å‡ºçš„å½’å› ï¼Œæ‰€æœ‰è¿™äº›éƒ½å¾—ç›Šäºä»–ä»¬é€šè¿‡åˆ›æ–°æ–¹æ³•è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„ç¥ç»å…ƒæè¿°ã€‚
- en: If you want to test the tool, go [here](https://monitor.transluce.org/dashboard/chat).
    They also offer some helpful tutorials. In this article, I will try to provide
    another use case and share my own experience.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³æµ‹è¯•è¿™ä¸ªå·¥å…·ï¼Œå¯ä»¥[ç‚¹å‡»è¿™é‡Œ](https://monitor.transluce.org/dashboard/chat)ã€‚ä»–ä»¬è¿˜æä¾›äº†ä¸€äº›æœ‰ç”¨çš„æ•™ç¨‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†å°è¯•æä¾›å¦ä¸€ä¸ªç”¨ä¾‹ï¼Œå¹¶åˆ†äº«æˆ‘è‡ªå·±çš„ç»éªŒã€‚
- en: 'There are probably many things to know (depending on your background), but
    Iâ€™ll focus on two key features: Activation and Attribution.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½éœ€è¦äº†è§£å¾ˆå¤šå†…å®¹ï¼ˆå…·ä½“å–å†³äºä½ çš„èƒŒæ™¯ï¼‰ï¼Œä½†æˆ‘å°†é‡ç‚¹ä»‹ç»ä¸¤ä¸ªå…³é”®ç‰¹æ€§ï¼šæ¿€æ´»å€¼å’Œå½’å› ã€‚
- en: '**Activation** measures the (normalized) activation value of the neuron. Llama
    uses gated MLPs, meaning that activations can be either positive or negative.
    We normalize by the value of the 10â€“5 quantile of the neuron across a large dataset
    of examples.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**æ¿€æ´»å€¼**è¡¡é‡çš„æ˜¯ç¥ç»å…ƒçš„ï¼ˆå½’ä¸€åŒ–ï¼‰æ¿€æ´»å€¼ã€‚Llamaä½¿ç”¨é—¨æ§MLPï¼Œè¿™æ„å‘³ç€æ¿€æ´»å€¼å¯ä»¥æ˜¯æ­£æ•°ä¹Ÿå¯ä»¥æ˜¯è´Ÿæ•°ã€‚æˆ‘ä»¬é€šè¿‡ç¥ç»å…ƒåœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„10â€“5åˆ†ä½æ•°å€¼è¿›è¡Œå½’ä¸€åŒ–ã€‚'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***Attribution*** *measures how much the neuron affects the modelâ€™s output.
    Attribution must be conditioned on a specific output token, and is equal to the
    gradient of that output tokenâ€™s probability with respect to the neuronâ€™s activation,
    times the activation value of the neuron. Attribution values are not normalized,
    and are reported as absolute values.*'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***å½’å› *** *è¡¡é‡ç¥ç»å…ƒå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ç¨‹åº¦ã€‚å½’å› å¿…é¡»åŸºäºç‰¹å®šçš„è¾“å‡ºæ ‡è®°ï¼Œå¹¶ç­‰äºè¯¥è¾“å‡ºæ ‡è®°æ¦‚ç‡ç›¸å¯¹äºç¥ç»å…ƒæ¿€æ´»çš„æ¢¯åº¦ï¼Œä¹˜ä»¥ç¥ç»å…ƒçš„æ¿€æ´»å€¼ã€‚å½’å› å€¼æ²¡æœ‰æ ‡å‡†åŒ–ï¼Œä»¥ç»å¯¹å€¼çš„å½¢å¼æŠ¥å‘Šã€‚*'
- en: Using these two features you can explore the modelâ€™s behavior, the neurons behavior
    and even notice for patterns (or as they call it â€œclustersâ€) of neuronsâ€™ behavior
    phenomena.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ©ç”¨è¿™ä¸¤ä¸ªç‰¹å¾ï¼Œä½ å¯ä»¥æ¢ç´¢æ¨¡å‹çš„è¡Œä¸ºã€ç¥ç»å…ƒçš„è¡Œä¸ºï¼Œç”šè‡³æ³¨æ„åˆ°ç¥ç»å…ƒè¡Œä¸ºç°è±¡çš„æ¨¡å¼ï¼ˆæˆ–è€…ä»–ä»¬ç§°ä¹‹ä¸ºâ€œèšç±»â€ï¼‰ã€‚
- en: If the model output isnâ€™t what you expect, or if the model gets it wrong, the
    tool allows you to steer neurons and â€˜fixâ€™ the issue by either strengthening or
    suppressing concept-related neurons (There are great work on how to steer based
    on concepts â€” one of them is [this](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d066d21c619d0a78c5b557fa3291a8f4-Abstract-Conference.html)
    great work).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ¨¡å‹è¾“å‡ºä¸æ˜¯ä½ æœŸæœ›çš„ï¼Œæˆ–è€…æ¨¡å‹å¾—å‡ºäº†é”™è¯¯çš„ç»“æœï¼Œè¯¥å·¥å…·å…è®¸ä½ é€šè¿‡åŠ å¼ºæˆ–æŠ‘åˆ¶ä¸æ¦‚å¿µç›¸å…³çš„ç¥ç»å…ƒæ¥å¼•å¯¼å¹¶â€œä¿®å¤â€é—®é¢˜ï¼ˆæœ‰è®¸å¤šå‡ºè‰²çš„å·¥ä½œè®²è§£å¦‚ä½•æ ¹æ®æ¦‚å¿µè¿›è¡Œå¼•å¯¼
    â€”â€” å…¶ä¸­ä¹‹ä¸€æ˜¯[è¿™ç¯‡](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d066d21c619d0a78c5b557fa3291a8f4-Abstract-Conference.html)å‡ºè‰²çš„å·¥ä½œï¼‰ã€‚
- en: So, curious enough, I tested this with my own prompt.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œå‡ºäºå¥½å¥‡ï¼Œæˆ‘ç”¨æˆ‘è‡ªå·±çš„æç¤ºè¿›è¡Œäº†æµ‹è¯•ã€‚
- en: I took a simple logic question that most models today fail to solve.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘é€‰æ‹©äº†ä¸€ä¸ªå¤§å¤šæ•°ä»Šå¤©çš„æ¨¡å‹æ— æ³•è§£å†³çš„ç®€å•é€»è¾‘é—®é¢˜ã€‚
- en: 'Q: â€œğ—”ğ—¹ğ—¶ğ—°ğ—² ğ—µğ—®ğ˜€ ğŸ° ğ—¯ğ—¿ğ—¼ğ˜ğ—µğ—²ğ—¿ğ˜€ ğ—®ğ—»ğ—± ğŸ® ğ˜€ğ—¶ğ˜€ğ˜ğ—²ğ—¿ğ˜€. ğ—›ğ—¼ğ˜„ ğ—ºğ—®ğ—»ğ˜† ğ˜€ğ—¶ğ˜€ğ˜ğ—²ğ—¿ğ˜€ ğ—±ğ—¼ğ—²ğ˜€ ğ—”ğ—¹ğ—¶ğ—°ğ—²â€™ğ˜€ ğ—¯ğ—¿ğ—¼ğ˜ğ—µğ—²ğ—¿
    ğ—µğ—®ğ˜ƒğ—²?â€'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šâ€œğ—”ğ—¹ğ—¶ğ—°ğ—² æœ‰ 4 ä¸ªå…„å¼Ÿå’Œ 2 ä¸ªå§å¦¹ã€‚çˆ±ä¸½ä¸çš„å…„å¼Ÿæœ‰å¤šå°‘ä¸ªå§å¦¹ï¼Ÿâ€
- en: '![](../Images/6c41be48fd76516494d0442bce1e91b0.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c41be48fd76516494d0442bce1e91b0.png)'
- en: Homepage. Image via [monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»é¡µã€‚å›¾ç‰‡æ¥è‡ª[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
- en: '**And voilaâ€¦.**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç§ï¼ŒæˆåŠŸäº†â€¦â€¦**'
- en: '![](../Images/0d39acc9f66ced5a61b6a8b549963162.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d39acc9f66ced5a61b6a8b549963162.png)'
- en: Llama gets it wrong. Image via [monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Llama åšé”™äº†ã€‚å›¾ç‰‡æ¥è‡ª[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
- en: '**Or not.**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**æˆ–è€…æ²¡æœ‰ã€‚**'
- en: On the left side, you can see the prompt and the output. On the right side,
    you can see the neurons that â€œfireâ€ the most and observe the main clusters these
    neurons group into.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å·¦ä¾§ï¼Œä½ å¯ä»¥çœ‹åˆ°æç¤ºå’Œè¾“å‡ºã€‚åœ¨å³ä¾§ï¼Œä½ å¯ä»¥çœ‹åˆ°â€œæ¿€æ´»â€æœ€å¤šçš„ç¥ç»å…ƒï¼Œå¹¶è§‚å¯Ÿè¿™äº›ç¥ç»å…ƒèšé›†çš„ä¸»è¦ç°‡ã€‚
- en: If you hover over the tokens on the left, you can see the top probabilities.
    If you click on one of the tokens, you can find out which neurons contributed
    to predicting that token.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å°†é¼ æ ‡æ‚¬åœåœ¨å·¦ä¾§çš„æ ‡è®°ä¸Šï¼Œä½ å¯ä»¥çœ‹åˆ°æœ€é«˜çš„æ¦‚ç‡ã€‚å¦‚æœä½ ç‚¹å‡»å…¶ä¸­ä¸€ä¸ªæ ‡è®°ï¼Œä½ å¯ä»¥æ‰¾åˆ°å“ªäº›ç¥ç»å…ƒå‚ä¸äº†é¢„æµ‹è¯¥æ ‡è®°ã€‚
- en: '![](../Images/1d67a52b25dad4a1afc90411715c2468.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d67a52b25dad4a1afc90411715c2468.png)'
- en: Hover over â€œin.â€ We can see tokens with the top probabilities. Image via [monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å°†é¼ æ ‡æ‚¬åœåœ¨â€œinâ€ä¸Šã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æœ€é«˜æ¦‚ç‡çš„æ ‡è®°ã€‚å›¾ç‰‡æ¥è‡ª[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
- en: '**As you can see, both the logic and the answer are wrong.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œé€»è¾‘å’Œç­”æ¡ˆéƒ½æ˜¯é”™è¯¯çš„ã€‚**'
- en: â€œSince Alice has 4 brothers, we need to find out how many sisters they have
    in commonâ€ >>> Ugh! You already know that.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: â€œå› ä¸ºçˆ±ä¸½ä¸æœ‰ 4 ä¸ªå…„å¼Ÿï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰¾å‡ºä»–ä»¬å…±æœ‰å¤šå°‘ä¸ªå§å¦¹â€ >>> å“å‘€ï¼ä½ å·²ç»çŸ¥é“ç­”æ¡ˆäº†ã€‚
- en: And of course, if Alice has two sisters (which is given in the input), **it
    doesnâ€™t mean Aliceâ€™s brother has 2 sisters :(**
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œå¦‚æœçˆ±ä¸½ä¸æœ‰ä¸¤ä¸ªå§å¦¹ï¼ˆè¿™æ˜¯è¾“å…¥ä¸­ç»™å®šçš„ï¼‰ï¼Œ**è¿™å¹¶ä¸æ„å‘³ç€çˆ±ä¸½ä¸çš„å…„å¼Ÿæœ‰ 2 ä¸ªå§å¦¹ :(**
- en: So, letâ€™s try to fix this. After examining the neurons, I noticed that the â€œdiversityâ€
    concept was overly active (perhaps it was confused about Aliceâ€™s identity?). So,
    I tried steering these neurons.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬è¯•ç€ä¿®å¤è¿™ä¸ªé—®é¢˜ã€‚åœ¨æ£€æŸ¥ç¥ç»å…ƒä¹‹åï¼Œæˆ‘æ³¨æ„åˆ°â€œå¤šæ ·æ€§â€æ¦‚å¿µè¿‡äºæ´»è·ƒï¼ˆä¹Ÿè®¸å®ƒå¯¹çˆ±ä¸½ä¸çš„èº«ä»½æ„Ÿåˆ°å›°æƒ‘ï¼Ÿï¼‰ã€‚å› æ­¤ï¼Œæˆ‘å°è¯•è°ƒæ•´è¿™äº›ç¥ç»å…ƒã€‚
- en: '![](../Images/b7a1954b87ef3876f4e203a9c5965741.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7a1954b87ef3876f4e203a9c5965741.png)'
- en: Steering window. Image via [monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å¼•å¯¼çª—å£ã€‚å›¾ç‰‡æ¥è‡ª[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
- en: 'I suppressed the neurons related to this concept and tried again:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æŠ‘åˆ¶äº†ä¸æ­¤æ¦‚å¿µç›¸å…³çš„ç¥ç»å…ƒï¼Œå¹¶é‡æ–°å°è¯•ï¼š
- en: '![](../Images/28c482a5f7e57c723dc472f51b631904.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28c482a5f7e57c723dc472f51b631904.png)'
- en: Adjusted model after steering. Image via [monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒæ•´åçš„æ¨¡å‹åœ¨å¼•å¯¼åã€‚å›¾ç‰‡æ¥è‡ª[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
- en: As you can see, it still output wrong answer. But if you look closely at the
    output, the logic has changed and its seems quite better â€” it catches that we
    need to â€œshiftâ€ to â€œone of her brothers perspectiveâ€. And also, it understood
    that Alice is a sister (Finally!).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼Œå®ƒä»ç„¶è¾“å‡ºäº†é”™è¯¯çš„ç­”æ¡ˆã€‚ä½†å¦‚æœä»”ç»†è§‚å¯Ÿè¾“å‡ºï¼Œé€»è¾‘å·²ç»æœ‰æ‰€å˜åŒ–ï¼Œçœ‹èµ·æ¥å¥½å¤šäº†â€”â€”å®ƒæ•æ‰åˆ°æˆ‘ä»¬éœ€è¦â€œè½¬å˜â€åˆ°â€œå…¶ä¸­ä¸€ä¸ªå…„å¼Ÿçš„è§†è§’â€ã€‚è€Œä¸”ï¼Œå®ƒä¹Ÿç†è§£äº†çˆ±ä¸½ä¸æ˜¯ä¸€ä¸ªå§å¦¹ï¼ˆç»ˆäºï¼ï¼‰ã€‚
- en: The final answer is though still incorrect.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆç­”æ¡ˆä»ç„¶ä¸æ­£ç¡®ã€‚
- en: I decided to strengthen the â€œgender rolesâ€ concept, thinking it would help the
    model better understand the roles of the brother and sister in this question,
    while maintaining its understanding of Aliceâ€™s relationship to her siblings.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å†³å®šåŠ å¼ºâ€œæ€§åˆ«è§’è‰²â€è¿™ä¸€æ¦‚å¿µï¼Œè®¤ä¸ºè¿™æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°ç†è§£é—®é¢˜ä¸­å…„å¦¹çš„è§’è‰²ï¼ŒåŒæ—¶ä¿æŒå®ƒå¯¹çˆ±ä¸½ä¸ä¸å¥¹å…„å¦¹å…³ç³»çš„ç†è§£ã€‚
- en: '![](../Images/a3da0f27dc4528db009dc4e99ebd31c3.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a3da0f27dc4528db009dc4e99ebd31c3.png)'
- en: Another adjustment. Image via [monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªè°ƒæ•´ã€‚å›¾ç‰‡æ¥è‡ª[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
- en: Ok, the answer was still incorrect, but it seemed that the reasoning thought
    process improved slightly. The model stated that â€œAliceâ€™s 2 sisters are being
    referred to.â€ The first half of the sentence indicated some understanding (Yes,
    this is also in the input. And no, Iâ€™m not arguing that the model or any model
    can truly understand â€” but thatâ€™s a discussion for another time) that Alice has
    two sisters. It also still recognized that Alice is a sister herself (â€œâ€¦the brother
    has 2 sisters â€” Alice and one other sisterâ€¦â€). But still, the answer was wrong.
    So closeâ€¦
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œç­”æ¡ˆä»ç„¶ä¸æ­£ç¡®ï¼Œä½†ä¼¼ä¹æ¨ç†è¿‡ç¨‹ç•¥æœ‰æ”¹å–„ã€‚æ¨¡å‹è¡¨ç¤ºâ€œæåˆ°çš„æ˜¯çˆ±ä¸½ä¸çš„ä¸¤ä¸ªå§å¦¹â€ã€‚å¥å­çš„å‰åŠéƒ¨åˆ†è¡¨ç°å‡ºä¸€å®šçš„ç†è§£ï¼ˆæ˜¯çš„ï¼Œè¿™éƒ¨åˆ†ä¹Ÿåœ¨è¾“å…¥ä¸­ã€‚å¹¶ä¸”ä¸ï¼Œæˆ‘å¹¶ä¸æ˜¯åœ¨äº‰è®ºæ¨¡å‹æˆ–ä»»ä½•æ¨¡å‹èƒ½å¦çœŸæ­£ç†è§£â€”â€”è¿™æ˜¯å¦ä¸€ä¸ªè®¨è®ºçš„è¯é¢˜ï¼‰ï¼Œå³çˆ±ä¸½ä¸æœ‰ä¸¤ä¸ªå§å¦¹ã€‚å®ƒä¹Ÿä¾ç„¶è®¤çŸ¥åˆ°çˆ±ä¸½ä¸è‡ªå·±æ˜¯ä¸€ä¸ªå§å¦¹ï¼ˆâ€œâ€¦è¿™ä¸ªå…„å¼Ÿæœ‰2ä¸ªå§å¦¹â€”â€”çˆ±ä¸½ä¸å’Œå¦ä¸€ä¸ªå§å¦¹â€¦â€ï¼‰ã€‚ä½†ç­”æ¡ˆè¿˜æ˜¯é”™çš„ã€‚çœŸæ˜¯å·®ä¸€ç‚¹â€¦â€¦
- en: Now that weâ€™re close, I noticed an unrelated concept (â€œchemical compounds and
    reactionsâ€) influencing the "2" token (highlighted in orange on the left side).
    Iâ€™m not sure why this concept had high influence, but I decided it was irrelevant
    to the question and suppressed it.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æ¥è¿‘æ­£ç¡®ç­”æ¡ˆäº†ï¼Œæˆ‘æ³¨æ„åˆ°ä¸€ä¸ªæ— å…³çš„æ¦‚å¿µï¼ˆâ€œåŒ–å­¦åŒ–åˆç‰©ä¸ååº”â€ï¼‰å½±å“äº†â€œ2â€è¿™ä¸ªç¬¦å·ï¼ˆå·¦ä¾§ä»¥æ©™è‰²é«˜äº®æ˜¾ç¤ºï¼‰ã€‚æˆ‘ä¸ç¡®å®šä¸ºä»€ä¹ˆè¿™ä¸ªæ¦‚å¿µä¼šæœ‰è¿™ä¹ˆå¤§çš„å½±å“ï¼Œä½†æˆ‘å†³å®šå®ƒä¸é—®é¢˜æ— å…³ï¼Œäºæ˜¯å°†å…¶æŠ‘åˆ¶äº†ã€‚
- en: The result?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœå¦‚ä½•ï¼Ÿ
- en: '![](../Images/10e6ad6d150d44a9cd1c9cb98925e0d2.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10e6ad6d150d44a9cd1c9cb98925e0d2.png)'
- en: Final result. Image via [monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆç»“æœã€‚å›¾ç‰‡æ¥è‡ª[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
- en: Success!! (ish)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æˆåŠŸäº†ï¼ï¼ï¼ˆå·®ä¸å¤šï¼‰
- en: As you can see above, it finally got the answer right.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸Šæ‰€ç¤ºï¼Œå®ƒç»ˆäºå¾—åˆ°äº†æ­£ç¡®çš„ç­”æ¡ˆã€‚
- en: Butâ€¦how was the reasoning?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯â€¦â€¦æ¨ç†è¿‡ç¨‹å¦‚ä½•å‘¢ï¼Ÿ
- en: wellâ€¦
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯â€¦â€¦
- en: '![](../Images/f30bd90c65a2c7d35c8e06db1026ad6f.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f30bd90c65a2c7d35c8e06db1026ad6f.png)'
- en: Final output. Image via [monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆè¾“å‡ºã€‚å›¾ç‰‡æ¥è‡ª[monitor.transluce.org](https://monitor.transluce.org/dashboard/chat)
- en: It followed a strange logical process with some role-playing confusion, but
    it still ended up with the correct answer (if you can explain it, please share).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè·Ÿéšäº†ä¸€ç§å¥‡æ€ªçš„é€»è¾‘è¿‡ç¨‹ï¼Œå¸¦æœ‰ä¸€äº›è§’è‰²æ‰®æ¼”ä¸Šçš„æ··ä¹±ï¼Œä½†æœ€ç»ˆè¿˜æ˜¯å¾—å‡ºäº†æ­£ç¡®çš„ç­”æ¡ˆï¼ˆå¦‚æœä½ èƒ½è§£é‡Šè¿™ä¸ªè¿‡ç¨‹ï¼Œè¯·åˆ†äº«ï¼‰ã€‚
- en: So, after some trial and error, I got there â€” almost. After adjusting the neurons
    related to gender and chemical compounds, the model produced the correct answer,
    but the reasoning wasnâ€™t quite there. Iâ€™m not sure, maybe with more tweaks and
    adjustments (and maybe better choices of concepts and neurons), I would get both
    the right answer and the correct logic. I challenge you to try.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œåœ¨ä¸€äº›è¯•é”™åï¼Œæˆ‘å‡ ä¹æˆåŠŸäº†ã€‚åœ¨è°ƒæ•´äº†ä¸æ€§åˆ«å’ŒåŒ–å­¦åŒ–åˆç‰©ç›¸å…³çš„ç¥ç»å…ƒåï¼Œæ¨¡å‹ç»™å‡ºäº†æ­£ç¡®ç­”æ¡ˆï¼Œä½†æ¨ç†è¿‡ç¨‹è¿˜ä¸å¤Ÿå®Œå–„ã€‚æˆ‘ä¸ç¡®å®šï¼Œä¹Ÿè®¸é€šè¿‡æ›´å¤šçš„å¾®è°ƒå’Œè°ƒæ•´ï¼ˆæˆ–è®¸æ›´å¥½çš„æ¦‚å¿µå’Œç¥ç»å…ƒé€‰æ‹©ï¼‰ï¼Œæˆ‘èƒ½å¤ŸåŒæ—¶å¾—åˆ°æ­£ç¡®çš„ç­”æ¡ˆå’Œæ­£ç¡®çš„é€»è¾‘ã€‚æˆ‘æŒ‘æˆ˜ä½ è¯•è¯•çœ‹ã€‚
- en: This is still experimental and I didnâ€™t use any systematic approach, but to
    be honest, Iâ€™m impressed and think itâ€™s incredibly promising. Why? Because the
    ability to observe and get descriptions of every neuron, understand (even partially)
    their influence, and steer behavior (without retraining or prompting) in real
    time is impressive â€” and yes, also a bit addictive, so be careful!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä»ç„¶æ˜¯å®éªŒæ€§çš„ï¼Œæˆ‘æ²¡æœ‰ä½¿ç”¨ä»»ä½•ç³»ç»ŸåŒ–çš„æ–¹æ³•ï¼Œä½†è¯´å®è¯ï¼Œæˆ‘å¾ˆå—éœ‡æ’¼ï¼Œè®¤ä¸ºè¿™éå¸¸æœ‰å‰æ™¯ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºèƒ½å¤Ÿè§‚å¯Ÿå¹¶è·å–æ¯ä¸ªç¥ç»å…ƒçš„æè¿°ï¼Œç†è§£ï¼ˆå³ä½¿æ˜¯éƒ¨åˆ†ç†è§£ï¼‰å®ƒä»¬çš„å½±å“ï¼Œå¹¶å®æ—¶åœ°å¼•å¯¼è¡Œä¸ºï¼ˆæ— éœ€é‡æ–°è®­ç»ƒæˆ–æç¤ºï¼‰çœŸæ˜¯ä»¤äººå°è±¡æ·±åˆ»â€”â€”æ˜¯çš„ï¼Œä¹Ÿæœ‰ç‚¹ä¸Šç˜¾ï¼Œæ‰€ä»¥è¦å°å¿ƒï¼
- en: 'Another thought I have: if the descriptions are accurate (reflecting actual
    behavior), and if we can experiment with different setups manually, why not try
    building a model based on neuron activations and attribution values? Transluce
    team, if you''re reading thisâ€¦what do you think?'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæƒ³æ³•æ˜¯ï¼šå¦‚æœè¿™äº›æè¿°æ˜¯å‡†ç¡®çš„ï¼ˆåæ˜ äº†å®é™…è¡Œä¸ºï¼‰ï¼Œè€Œä¸”å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿæ‰‹åŠ¨å°è¯•ä¸åŒçš„è®¾ç½®ï¼Œä¸ºä»€ä¹ˆä¸å°è¯•åŸºäºç¥ç»å…ƒæ¿€æ´»å’Œå½’å› å€¼æ„å»ºä¸€ä¸ªæ¨¡å‹å‘¢ï¼ŸTransluceå›¢é˜Ÿï¼Œå¦‚æœä½ ä»¬åœ¨çœ‹è¿™æ¡ä¿¡æ¯â€¦â€¦ä½ ä»¬æ€ä¹ˆçœ‹ï¼Ÿ
- en: All in all, great job. I highly recommend diving deeper into this. The ease
    of use and the ability to observe neuron behavior is compelling, and I believe
    weâ€™ll see more tools embracing these techniques to help us better understand our
    models.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»çš„æ¥è¯´ï¼Œåšå¾—å¾ˆå¥½ã€‚æˆ‘å¼ºçƒˆå»ºè®®æ·±å…¥ç ”ç©¶ä¸€ä¸‹ã€‚å®ƒçš„æ˜“ç”¨æ€§å’Œè§‚å¯Ÿç¥ç»å…ƒè¡Œä¸ºçš„èƒ½åŠ›éå¸¸æœ‰å¸å¼•åŠ›ï¼Œæˆ‘ç›¸ä¿¡æˆ‘ä»¬ä¼šçœ‹åˆ°æ›´å¤šçš„å·¥å…·é‡‡ç”¨è¿™äº›æŠ€æœ¯æ¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£æˆ‘ä»¬çš„æ¨¡å‹ã€‚
- en: Iâ€™m now going to test this on some of our most challenging legal reasoning use
    cases â€” to see how it captures more complex logical structures.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç°åœ¨æ‰“ç®—åœ¨ä¸€äº›æœ€å…·æŒ‘æˆ˜æ€§çš„æ³•å¾‹æ¨ç†ç”¨ä¾‹ä¸­æµ‹è¯•è¿™ä¸ªâ€”â€”çœ‹çœ‹å®ƒå¦‚ä½•æ•æ‰æ›´å¤æ‚çš„é€»è¾‘ç»“æ„ã€‚
- en: What does this mean for AI? Weâ€™ll have to wait and seeâ€¦ but just like GPT was
    embraced so quickly and naturally, I think this release opens a new chapter in
    LLM interpretability. More importantly, it moves us closer to building tools that
    are better aligned and more responsible.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¹äººå·¥æ™ºèƒ½æ„å‘³ç€ä»€ä¹ˆï¼Ÿæˆ‘ä»¬å¾—æ‹­ç›®ä»¥å¾…â€¦â€¦ä½†å°±åƒGPTå¦‚æ­¤è¿…é€Ÿè‡ªç„¶åœ°è¢«æ¥å—ä¸€æ ·ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªç‰ˆæœ¬çš„å‘å¸ƒä¸ºå¤§è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæ€§å¼€è¾Ÿäº†æ–°ç¯‡ç« ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå®ƒå°†æˆ‘ä»¬å¸¦å¾—æ›´è¿‘ï¼Œæœç€æ„å»ºæ›´åŠ å¯¹é½å’Œè´Ÿè´£ä»»çš„å·¥å…·è¿ˆè¿›ã€‚
- en: Now that their work is open source, itâ€™s up to the community to challenge it,
    improve it, or build on it.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶ä»–ä»¬çš„å·¥ä½œæ˜¯å¼€æºçš„ï¼Œé‚£ä¹ˆå°±ç”±ç¤¾åŒºæ¥æŒ‘æˆ˜å®ƒã€æ”¹è¿›å®ƒæˆ–åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ„å»ºã€‚
- en: So, give it a try.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œè¯•è¯•çœ‹å§ã€‚
- en: In the meantime, what do you think?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ­¤åŒæ—¶ï¼Œä½ æ€ä¹ˆçœ‹ï¼Ÿ
- en: '**Some limitations (very briefly):**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¸€äº›é™åˆ¶ï¼ˆç®€è¦è¯´æ˜ï¼‰ï¼š**'
- en: The tool was just released yesterday, and I havenâ€™t had the chance to fully
    review the entire documentation.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥å·¥å…·å°±åœ¨æ˜¨å¤©å‘å¸ƒï¼Œæˆ‘è¿˜æ²¡æœ‰å®Œå…¨æœ‰æœºä¼šå®¡é˜…æ•´ä¸ªæ–‡æ¡£ã€‚
- en: I tried simple questions successfully, but when I asked similar questions with
    different attributes, the logic still failed. Generalization is key here â€” trying
    to â€œcaptureâ€ some generalization within the observability tool would take it to
    the next level.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘æˆåŠŸåœ°å°è¯•äº†ç®€å•çš„é—®é¢˜ï¼Œä½†å½“æˆ‘æå‡ºå¸¦æœ‰ä¸åŒå±æ€§çš„ç±»ä¼¼é—®é¢˜æ—¶ï¼Œé€»è¾‘ä»ç„¶å¤±è´¥ã€‚å½’çº³èƒ½åŠ›æ˜¯è¿™é‡Œçš„å…³é”®â€”â€”å°è¯•åœ¨å¯è§‚å¯Ÿæ€§å·¥å…·ä¸­â€œæ•æ‰â€æŸäº›å½’çº³æ€§ï¼Œå°†ä½¿å…¶è¾¾åˆ°æ–°çš„é«˜åº¦ã€‚
- en: Itâ€™s not always reproducible, even with low or zero temperature settings.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å³ä½¿åœ¨ä½æ¸©æˆ–é›¶æ¸©è®¾ç½®ä¸‹ï¼Œä¹Ÿå¹¶éæ€»æ˜¯å¯ä»¥é‡ç°ã€‚
- en: There is no single path to both a correct answer and logical reasoning.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ²¡æœ‰å•ä¸€çš„è·¯å¾„å¯ä»¥åŒæ—¶è·å¾—æ­£ç¡®ç­”æ¡ˆå’Œé€»è¾‘æ¨ç†ã€‚
- en: It involves quite a bit of trial and error. After a few iterations, I got a
    â€œfeelâ€ for it, but it felt similar to the early days of using GPT â€” exciting when
    it worked, but often leaving you wondering, â€œWhat really happened here?â€ So thereâ€™s
    still work to be done.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ¶‰åŠåˆ°ç›¸å½“å¤šçš„åå¤è¯•éªŒã€‚åœ¨å‡ æ¬¡è¿­ä»£åï¼Œæˆ‘å¼€å§‹â€œæ„Ÿè§‰åˆ°â€å®ƒçš„è¿ä½œï¼Œä½†è¿™å’Œåˆšå¼€å§‹ä½¿ç”¨GPTæ—¶å¾ˆåƒâ€”â€”å½“å®ƒæœ‰æ•ˆæ—¶ä»¤äººå…´å¥‹ï¼Œä½†å¸¸å¸¸è®©ä½ é™·å…¥å›°æƒ‘ï¼Œâ€œè¿™é‡Œåˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿâ€å› æ­¤ï¼Œä»ç„¶éœ€è¦è¿›ä¸€æ­¥çš„å·¥ä½œã€‚
