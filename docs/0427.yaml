- en: Using LangChain ReAct Agents for Answering Multi-hop Questions in RAG Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e?source=collection_archive---------0-----------------------#2024-02-15](https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e?source=collection_archive---------0-----------------------#2024-02-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '#LLM FOR BEGINNERS'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Useful when answering complex queries on internal documents in a step-by-step
    manner with ReAct and Open AI Tools agents.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)[![Dr.
    Varshita Sher](../Images/a3f2e9bf1dc1d8cbe018e54f9341f608.png)](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)
    [Dr. Varshita Sher](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)
    ·43 min read·Feb 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f9c86e008b8faef32897c564b10f8949.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image generated by Author (prompt engineering credits: Fabian Nitka)'
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The basic RAG chatbots I have built in the past using standard LangChain components
    such as vectorstore, retrievers, etc have worked out well for me. Depending on
    the internal dataset I feed in, they are capable of handling humble questions
    such as “What is the parental leave policy in India” (source dataset: HR policy
    documents), “What are the main concerns regarding the flavor of our product” (source
    dataset: social media/Tweets), “What are the themes in Monet paintings” (source
    dataset: Art Journals), etc. More recently, the complexity of queries being fed
    to it has increased, for instance, “Has there been an increase in the concerns
    regarding flavor in the past 1 month”. Unless there is a specific section in the
    internal documents that specifically talks about the comparison, it is highly
    unlikely the chatbot would display the correct answer. The reason is — the correct
    answer requires the following steps to be planned/executed systematically:'
  prefs: []
  type: TYPE_NORMAL
- en: 'STEP 1: calculate the *start* date and *end* date based on “past 1 month” and
    today’s date'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'STEP 2: fetch the queries mentioning flavor issues for the *start* date'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'STEP 3: count the queries from Step 2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'STEP 4: fetch the queries mentioning flavor issues for the *end* date'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'STEP 5: count the queries from Step 4'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'STEP 6: calculate the percentage increase/decrease using counts from Step 3
    and Step 5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luckily for us, LLMs are very good at such *planning*! And Langchain agents
    are the ones orchestrating this planning for us.
  prefs: []
  type: TYPE_NORMAL
- en: The core idea of agents is to use a language model to choose a sequence of actions
    to take. In agents, a language model is used as a reasoning engine to determine
    which actions to take and in which order. [[Source](https://python.langchain.com/docs/modules/agents)]
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/991e5a86b326cc3876bedba860b192a4.png)'
  prefs: []
  type: TYPE_IMG
- en: Agent answering a multi-hop question in a step-by-step manner. (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Agents typically require a set of tools to be specified at the time of their
    instantiation. For instance, to solve the aforementioned multi-hop question, we
    should define four tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Tool_Date`: A Python function that takes as input a relative time frame (such
    as the *past 6 months*) and calculates the start date by subtracting the time
    frame from today’s date (for Step#1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tool_Search`: A search engine that can take as input a search term and return
    the list of relevant documents (for Step#2 and Step#4)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tool_Length`: A Python function that takes as input a list and returns the
    length of that list (for Step#3 and Step#5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tool_PercCalculator`: A Python function that takes as input two numbers and
    returns the percent change calculation (for Step#6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally speaking — be mindful of the choice of tools you provide an agent,
    as these are the *only* tools that the agent will use to answer each of the intermediate
    steps. If it finds a relevant tool — great, it will use it to get the answer.
    If it doesn’t, it will usually iterate a few times (i.e. trying one of the other
    available tools or its own logical reasoning) and finally return a sub-optimal
    answer.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin by jumping straight into code, if you’d like to follow along, here’s
    the [GitHub repo](https://github.com/V-Sher/LangChain_ReAct_Demo).
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While I was tempted to use the ever-popular `[state_of_the_union.txt](https://github.com/hwchase17/chat-your-data/blob/master/state_of_the_union.txt)`
    for this demo, I couldn’t come up with complex questions to ask that document.
    Hence, I have created a dummy HR document (using ChatGPT) for a fictitious company
    called GlobalCorp. You can view `globalcorp_hr_policy.txt` [here](https://github.com/V-Sher/LangChain_ReAct_Demo/blob/main/data/globalcorp_hr_policy.txt).
    The main highlights of the file include (a) country-specific annual budgets (b)
    in different currencies and (c) country-specific leave policies.
  prefs: []
  type: TYPE_NORMAL
- en: LLM and Embedding models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be using Azure Open AI models (`gpt3.5 turbo` , `gpt-4-turbo` and `ada-embeddings`)
    for this tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Disclaimer — I will be using the terms “RAG tool”, “Q&A system”, and “QnA
    tool” interchangeably. For this tutorial, all refer to a tool that is capable
    of looking up a bunch of documents to answer a specific user query but does* ***not***
    *have any conversational memory i.e. you won’t be able to ask follow-up questions
    in a chat-like manner. However, that can be easily implemented in LangChain and
    will likely be covered in some future article. The focus here is just to get the
    multi-hop questions working.*'
  prefs: []
  type: TYPE_NORMAL
- en: RAG-based QnA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s go ahead and build a standard Q&A system using this data.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using `TextLoader` for loading the dummy HR document.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`Chroma` as the vectorstore (for storing the document embeddings),'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`LocalFileStore` as the docstore (for storing the parent documents),'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: PDR (`parentdocumentretriever`) as the `retriever` (for retrieving relevant
    data from the index).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: With all the setup done, we are ready to add our document to the retriever using
    `add_documents()` command. Additionally, I also recommend persisting the vectorstore
    using `.persist()` command (i.e. storing the contents of the vectorstore to your
    disk so you don’t have to recompute the embeddings again once you terminate your
    current session)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Once you run these commands, you should see two folders — `local_docstore` and
    `local_vectorstore` — created in your working session. Feel free to check the
    contents for each.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9eff59ac6709193585ebaefdf989691e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Quick sanity check to see if the `retriever` is set correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we’ll build the `RetrievalQA` chain to do question-answering using
    all the aforementioned components.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Asking standard questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Having manually reviewed the policy document, it is safe to say the answers
    make sense.
  prefs: []
  type: TYPE_NORMAL
- en: Asking complex/multi-hop questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Mathematically speaking, the response is not 100% correct. Even though the logic
    it used is correct (i.e. converting the amount from ¥ to $ ), the exchange rate
    used is out of date.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try helping it by providing the exchange rate information (1 USD = 147.72
    JPY) as part of the query itself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Interestingly enough, LLM was able to use the exchange rate as part of the calculations
    and the answer it gave (i.e. $338,164.25) was very close to the actual answer
    (i.e. 338,478.20). Having said that, there’s still room for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try another question, this time a comparison question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Again, the response is not correct since it didn’t do the currency conversion
    before comparing the budgets with other countries like the US, Germany, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '*Observation*: All the aforementioned questions could be reliably answered
    if instead of jumping on a final answer, we had a systematic way of planning the
    intermediate steps. To do so, let’s introduce `agents`.'
  prefs: []
  type: TYPE_NORMAL
- en: ReAct Agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this tutorial, we will be using LangChain’s implementation of the ReAct (Reason
    + Act) agent, first introduced in [this](https://arxiv.org/abs/2210.03629) paper.
    The key takeaway from the paper is that if we prompt the LLM to generate both
    reasoning traces and task-specific actions in a step-by-step manner, its performance
    on the task improves. In other words, we are explicitly asking it to have multiple
    thought-action-observation steps to solve a task instance instead of coming to
    the final answer in one single jump (which ultimately leads to reduced hallucination).
  prefs: []
  type: TYPE_NORMAL
- en: Apart from ReAct, LangChain supports other agents such as `Open AI tools`, `XML`,
    `StructuredChat`, `Self Ask with Search`, etc that I strongly encourage you to
    read about [here](https://python.langchain.com/docs/modules/agents/agent_types/).
    One key thing to note here is that ReAct agents can only support tools that can
    take only 1 input parameter (for instance, from the tools described above, it
    can support `Tool_Length`, `Tool_Date`, and `Tool_Search` ). If you want to use
    tools that take more than 1 input (for instance `Tool_PercCalculator`), you will
    be better off using `Open AI Tools` agent or `Open AI Functions` agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: “OpenAI termed the capability to invoke a single function as `functions`,
    and the capability to invoke one or more functions as `tools`. As per the official
    website, `functions` are now considered a legacy option that is deprecated in
    favor of `tools`. So if you’re creating agents using OpenAI models, you should
    be using this `OpenAI Tools` agent rather than the `OpenAI functions` agent.”
    [[Source](https://python.langchain.com/docs/modules/agents/agent_types/openai_tools)]'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Defining the tools for the agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As I mentioned above, we first need to define the tools that this agent will
    have access to. For starters, we will only define one tool: `tool_search`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`tool_search`: Given a search query, we need a tool that will return the relevant
    chunks of the HR document. But wait, isn’t that what our PDR retriever does anyway?
    In fact, we can easily convert our retriever into a tool using the `create_retriever_tool()`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'A couple of pointers:'
  prefs: []
  type: TYPE_NORMAL
- en: The `name`and`description` of the tool will be passed in the API call to the
    LLM, so make sure it is as unambiguous as possible for the agent to understand.
    In our case, we have clearly defined that this tool returns excerpts (i.e. chunks)
    from the HR policy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Under the hood, this tool uses the `get_relevant_documents()` function of the
    `retriever`. You can check it using `.func`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: You can even check the schema of this tool using `.schema()`. It is useful for
    verifying the `required` parameters necessary for calling the tool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '*Pro-tip: You can use* `*tool.invoke({"inp_param_name": inp_param_value})*`
    *to quickly test if a custom tool has been set up properly. For example:* `*tool_search.invoke({“query”:
    “enter query here”})*`'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let’s set up the ReAct agent using a prompt that emphasizes multiple
    thought-action-observation steps. Luckily for us, this is already available on
    the LangChain hub (you can also override this by defining your own). The prompt
    template requires three input_variables i.e. `tools`, `input` and `agent_scratchpad`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '*Note 1: While this prompt works fine 8 out of 10 times, I highly recommend
    modifying it to suit your use case — especially if the agent is getting confused
    about the sequence of actions or thoughts. For instance, in one of the projects
    where the questions were comparison-based (such as ‘Compare the increase in sales
    between China and the US in the last 1 year’), this is how I updated the react
    prompt (and introduced a new input variable* `*{today_date}*`*:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '*Note 2: Doing the above (i.e. a more detailed/lengthy prompt) can exponentially
    increase the token count for your use case. My recommendation is to switch to
    the chaining of LLMs* ***if*** *(and this is a big if) you know beforehand the
    order in which the action/thoughts need to be executed. For example: if you know
    that the only type of questions your system needs to answer is comparison questions
    like the one I mentioned above, it makes more sense to create a sequential chain
    of calls to the LLM where output from one is fed as input to the other. I have
    touched upon the technical implementation of this in LangChain in my previous*
    [*article*](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a ReAct agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We also need to instantiate `AgentExecutor` that will execute the logical steps
    that `react_agent` will generate.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Testing the ReAct agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, it is time to test it on the same sample queries as before.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: While I was tempted to cherry-pick examples for this article, it is
    important to show that these agents can be unreliable at times and a lot of testing
    needs to be done to establish their capabilities and limitations.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'A few points for consideration:'
  prefs: []
  type: TYPE_NORMAL
- en: Notice the `Action Input` (i.e. “highest country budget”) for the first `Action`
    . This is the search query that will be passed to the `get_relevant_function()`
    of the PDR `retriever` (rather than the actual input query i.e. `Which country
    has the highest budget?`). That means, if there was a section in the underlying
    documents that talked about the highest country budget we would have been sorted!
    Sadly, that’s not the case here.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Observation` (i.e. the results from running the `action` i.e. tool with
    the `action inputs`) is printed right after `Action Input`. In our case, it is
    the retrieved document (`[Document(page_content=’**Grievance and Disciplinary
    Procedures:**\nOur grievance and disciplinary procedures are …`) and it contains
    the information necessary for answering the query. Even so, the final response
    is still incorrect. [P.S. Based on my testing, this happens mostly with gpt3.5.]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (To make it work with gpt-3.5) I tried updating the search query to `"Which
    of the two countries has the highest budget — Japan or Unites States?"` , hoping
    the agent would pick up on the country names and make 2 consecutive calls to the
    retriever to fetch the relevant info. Unfortunately, the final answer was the
    same as above.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, after slight rewording, we have a query that works (with gpt3.5).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Main takeaway: (1) Even for similar-looking prompts, the responses can vary
    drastically. (2) GPT4 is better suited than GPT3.5 for implementing ReAct agents.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '*P.S. I was not too pleased with the unnecessary Action-Action Input loops
    even though the relevant answer was revealed in the first iteration itself. Again,
    something I am currently debugging.*'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the implementation of the agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*LangChain library can be a bit daunting at first and if you would like to
    debug how things are working under the hood w.r.t. react agents, here are some
    useful* [*breakpoints to set in your debugger*](/how-to-make-most-of-your-python-debugger-in-vscode-9e05dfce533f)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'I. [setup of the ReAct agent](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L113-L120):
    here you will find the 4 main steps (chained together through the `|` symbol)
    that the agent will take at each iteration. (*I have also included snippets to
    show you inputs/outputs for each of the four steps in isolation).'
  prefs: []
  type: TYPE_NORMAL
- en: P.S. If it is your first time seeing this pipe symbol* `*|*` *in LangChain,
    I recommend going through* [*this*](https://python.langchain.com/docs/expression_language/why)
    *and* [*this*](https://python.langchain.com/docs/expression_language/cookbook/prompt_llm_parser)
    *first. In simple terms, the* `*|*`*takes passes the output from the first step
    and passes it as input to the next step in the chain.*
  prefs: []
  type: TYPE_NORMAL
- en: '(a) `Runnable.assign()`: updates `agent_scratchpad` with observations i.e.
    all prior thought-action-observations and creates a dictionary that can be passed
    as input to the next step i.e. `PromptTemplate`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While I have used dummy data in the snippet below, a typical `agent_scratchpad`
    would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '`` `I need to check if there is any information in the HR policy regarding
    budget allocation for different countries.\nAction: search_hr_policy\nAction Input:
    “budget allocation for different countries”\nObservation: [Document(page_content=\’**Griev....]metadata={\’source\’:
    \’../data/globalcorp_hr_policy.txt\’})]\nThought: ``'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '(b) `PromptTemplate`: frames the final react prompt for the LLM call based
    on the updated `agent_scratchpad` and creates a `StringPromptValue`'
  prefs: []
  type: TYPE_NORMAL
- en: '(Note: As per the react prompt template, we also need another `input_variables`
    called `tools` which is already appended using `prompt.partial` [here](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L99-L102)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '(c ) `AzureChatOpenAI`: passes the prompt to the `llm` for the generation step
    and fetches the response i.e. `AIMessage`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: (d) `ReActSingleInputOutputParser():` parses the output (i.e. `AIMessage`) returned
    by the `llm`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'II. [agent at work](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/core/langchain_core/runnables/base.py#L2052):
    this is where you can see the `for` loop for iterating over all four aforementioned
    steps. Feel free to set watch variables and investigate the intermediate results.
    After going through all four steps, the final response is either of type `AgentAction`
    (whether to call another tool) or `AgentFinish`(finish the loop). Here is a quick
    snapshot of my debugger at all the four steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cd862def19b093e5e6607441b5d56fc8.png)![](../Images/8c10cfe73dfc902dfb6fa60b3d1193dd.png)![](../Images/c6cb10ba661cd55ac44667c2f07c2671.png)![](../Images/d37a025c163ed34d555c12d8bd184cfa.png)'
  prefs: []
  type: TYPE_IMG
- en: Intermediate output from the agent
  prefs: []
  type: TYPE_NORMAL
- en: 'III. D[eep dive into the](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)
    `[parse()](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)`
    [of](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)
    `[ReactSingleInputOutputParser](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)`:
    if you want to know how it’s decided whether `AIMessage` should result in `AgentAction`
    or `AgentFinish`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'IV. [custom tool being used](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1204):
    this is where you can see your custom tool being used by the agent (if `AgentAction`
    was returned).'
  prefs: []
  type: TYPE_NORMAL
- en: V. the `[while](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1390)`
    [loop](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1390)
    that keeps the agent looping (unless `AgentFinish` is encountered or a time-out
    occurs) after [updating the intermediate steps](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1403)
    with the observations from the previous iteration.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Intermediate steps are a collection of observations and observations
    will often be the output of the tool. So in the case of the retriever tool, it
    will be a list of Documents, in the case of currency conversion, it will be a
    number, and so on.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa837b6676eef62a6ea1a41349a85fd7.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of intermediate steps
  prefs: []
  type: TYPE_NORMAL
- en: 'Final thoughts: If the questions anticipated for a QnA system are fundamentally
    basic, meaning they can be adequately handled by a standard retrieval-based QA
    mechanism without the need for multi-hop reasoning, it’s best to steer clear of
    agents. This is especially true if the only tool required is a ‘retriever-turned-tool’.
    Introducing agents in such scenarios can needlessly complicate matters. Moreover,
    if you are using a retriever as a tool, the input to its `get_relevant_function()`
    gets modified by the agent (as you noticed above) as it sees fit and you no longer
    have control over it. This may be an issue in some cases (although an easy fix
    for that is to update the description of the tool to `tool_search.description
    = “Searches and returns excerpts from the HR policy. Input should be a fully formed
    question”`)'
  prefs: []
  type: TYPE_NORMAL
- en: The true potential of agents is unlocked when we give it complex questions and
    more tools to work with as we will see next.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing more tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s introduce another tool : `currency_conversion` and run the same query
    as above.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some helper functions this tool needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s re-run the earlier query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: You may be wondering what’s the big deal about this answer. Even without this
    tool, the previous answer we received was correct. However, what’s noteworthy
    here is its capability to perform currency conversions to USD before arriving
    at the ultimate conclusion that the budgets are indeed different. This helps build
    trust in the responses. Without this tool, I am willing to bet that if the HR
    policy stated the budget for Japan and the US as ¥741 million and $5 million,
    respectively, the LLM would respond that they have different budgets even though
    after conversion (as per today’s rate) they should be same.
  prefs: []
  type: TYPE_NORMAL
- en: 'A couple of observations:'
  prefs: []
  type: TYPE_NORMAL
- en: Given that the tools and their description get appended to the prompt, the model
    knows it has access to these tools if needed. I believe it helps them utilize
    as many of these tools as they deem necessary during answering a query. Hence,
    the decision to use the currency conversion tool in the second action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s update the query to get the actual difference in figures.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The LLM has done a great job at handling the subtraction (although I remain
    cautious about relying on LLMs for any type of calculations.). If we want to make
    it even more robust, we can add another tool, say `calculator_subtract` for calculating
    the difference between two numbers. As I mentioned before, ReAct agents cannot
    handle multi-input tools, and doing so would raise an error. This is where Open
    AI Tools agents come in picture.
  prefs: []
  type: TYPE_NORMAL
- en: Open AI Tools Agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s create a new tool — `perc_diff()`that takes two numbers as inputs and
    calculates the difference in percentage between these two numbers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '*Note: Another way to initialize the same tool (giving more control over the
    setup)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Finally, with all the pieces in place, let’s use `create_openai_tools_agent`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '*Note: Upon running this line of code, you may notice errors like* [*this*](https://github.com/Azure/azure-sdk-for-java/issues/38115)
    *i.e.*`*Unrecognized request argument supplied: tools*`*. It means that under
    the hood when the API call is made to the* `*llm*`*, it does not recognize the*
    `*tools*` *parameter. Given that only the newer version of the APIs recognize
    this parameter, it must mean you are using an older version of the model. You
    can fix this by:*'
  prefs: []
  type: TYPE_NORMAL
- en: '*if you are using Azure Open AI services — deploy one of the newer models (see
    image below) and update the* `*deployment_name*` *in your codebase i.e.* `*llm=AzureChatOpenAI(deployment_name=...,
    )*`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9a2a77e4aabc5f6ca5230d171c3c0344.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Available models on Azure Open AI*'
  prefs: []
  type: TYPE_NORMAL
- en: '*if you are using Open AI’s API directly — check that the model is a newer
    one from* [*this*](https://platform.openai.com/docs/models/gpt-3-5-turbo) *list.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*To test this fixed the issue, here’s a comparison before and after the version
    update (complete code snippet can be found* [*here*](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Exploring%20ChatGPT%20Function%20Calling.ipynb)*):*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having taken a deep dive into the inner workings of the ReAct agent, I hope
    you feel more confident implementing it for your projects. This article just scratched
    the surface, there is so much more to cover. For instance, how to add memory to
    these QnA systems so you can use them in a chat-like manner.
  prefs: []
  type: TYPE_NORMAL
- en: As always if there’s an easier way to do/explain some of the things mentioned
    in this article, do let me know. In general, refrain from unsolicited destructive/trash/hostile
    comments!
  prefs: []
  type: TYPE_NORMAL
- en: Until next time ✨
  prefs: []
  type: TYPE_NORMAL
- en: '[](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=post_page-----893208c1847e--------------------------------)
    [## A Gentle Intro to Chaining LLMs, Agents, and utils via LangChain'
  prefs: []
  type: TYPE_NORMAL
- en: Understand the basics of agents, tools, and prompts and some learnings along
    the way
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=post_page-----893208c1847e--------------------------------)
    [](https://medium.com/illumination/3-apps-to-make-you-the-smartest-person-in-the-room-1cc2d927971d?source=post_page-----893208c1847e--------------------------------)
    [## 3 Apps to Make You the Smartest Person in the Room
  prefs: []
  type: TYPE_NORMAL
- en: With minimum daily time commitments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/illumination/3-apps-to-make-you-the-smartest-person-in-the-room-1cc2d927971d?source=post_page-----893208c1847e--------------------------------)
    [](/is-googles-notebooklm-going-to-disrupt-the-podcasting-industry-ea8e1ec7f431?source=post_page-----893208c1847e--------------------------------)
    [## Is Google’s NotebookLM Going to Disrupt the Podcasting Industry?
  prefs: []
  type: TYPE_NORMAL
- en: Especially if all it takes is 1 click to turn any content into podcast
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/is-googles-notebooklm-going-to-disrupt-the-podcasting-industry-ea8e1ec7f431?source=post_page-----893208c1847e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
