- en: Using LangChain ReAct Agents for Answering Multi-hop Questions in RAG Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LangChain ReAct代理回答RAG系统中的多跳问题
- en: 原文：[https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e?source=collection_archive---------0-----------------------#2024-02-15](https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e?source=collection_archive---------0-----------------------#2024-02-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e?source=collection_archive---------0-----------------------#2024-02-15](https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e?source=collection_archive---------0-----------------------#2024-02-15)
- en: '#LLM FOR BEGINNERS'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '#LLM 初学者指南'
- en: Useful when answering complex queries on internal documents in a step-by-step
    manner with ReAct and Open AI Tools agents.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在使用ReAct和Open AI Tools代理逐步回答复杂查询时非常有用，特别是在处理内部文档时。
- en: '[](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)[![Dr.
    Varshita Sher](../Images/a3f2e9bf1dc1d8cbe018e54f9341f608.png)](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)
    [Dr. Varshita Sher](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)[![Dr.
    Varshita Sher](../Images/a3f2e9bf1dc1d8cbe018e54f9341f608.png)](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)
    [Dr. Varshita Sher](https://varshitasher.medium.com/?source=post_page---byline--893208c1847e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)
    ·43 min read·Feb 15, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--893208c1847e--------------------------------)
    ·阅读时长43分钟·2024年2月15日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f9c86e008b8faef32897c564b10f8949.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9c86e008b8faef32897c564b10f8949.png)'
- en: 'Image generated by Author (prompt engineering credits: Fabian Nitka)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者生成（提示工程学贡献：Fabian Nitka）
- en: Motivation
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机
- en: 'The basic RAG chatbots I have built in the past using standard LangChain components
    such as vectorstore, retrievers, etc have worked out well for me. Depending on
    the internal dataset I feed in, they are capable of handling humble questions
    such as “What is the parental leave policy in India” (source dataset: HR policy
    documents), “What are the main concerns regarding the flavor of our product” (source
    dataset: social media/Tweets), “What are the themes in Monet paintings” (source
    dataset: Art Journals), etc. More recently, the complexity of queries being fed
    to it has increased, for instance, “Has there been an increase in the concerns
    regarding flavor in the past 1 month”. Unless there is a specific section in the
    internal documents that specifically talks about the comparison, it is highly
    unlikely the chatbot would display the correct answer. The reason is — the correct
    answer requires the following steps to be planned/executed systematically:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我过去使用标准的LangChain组件（如vectorstore、retrievers等）构建的基本RAG聊天机器人效果很好。根据我提供的内部数据集，它们能够处理一些简单的问题，比如“印度的产假政策是什么”（源数据集：HR政策文档）、“我们产品的口味主要有哪些问题”（源数据集：社交媒体/Twitter）、“莫奈画作中的主题是什么”（源数据集：艺术期刊）等。最近，输入的查询复杂度增加了，例如，“过去1个月内，关于口味的关注是否有所增加”。除非内部文档中有专门讨论比较的部分，否则聊天机器人很难给出正确答案。原因是——正确的答案需要以下步骤被有序地规划和执行：
- en: 'STEP 1: calculate the *start* date and *end* date based on “past 1 month” and
    today’s date'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一步：根据“过去1个月”和今天的日期计算*开始*日期和*结束*日期
- en: 'STEP 2: fetch the queries mentioning flavor issues for the *start* date'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二步：获取提到口味问题的*开始*日期的查询
- en: 'STEP 3: count the queries from Step 2'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三步：计数第二步中的查询
- en: 'STEP 4: fetch the queries mentioning flavor issues for the *end* date'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四步：获取提到口味问题的*结束*日期的查询
- en: 'STEP 5: count the queries from Step 4'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第五步：计数第四步中的查询
- en: 'STEP 6: calculate the percentage increase/decrease using counts from Step 3
    and Step 5.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第六步：使用第三步和第五步中的计数计算百分比的增减。
- en: Luckily for us, LLMs are very good at such *planning*! And Langchain agents
    are the ones orchestrating this planning for us.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，大型语言模型在这种*规划*方面非常擅长！而 Langchain 代理则是为我们协调这些规划的工具。
- en: The core idea of agents is to use a language model to choose a sequence of actions
    to take. In agents, a language model is used as a reasoning engine to determine
    which actions to take and in which order. [[Source](https://python.langchain.com/docs/modules/agents)]
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 代理的核心思想是使用语言模型选择一系列要执行的操作。在代理中，语言模型作为推理引擎，决定采取哪些行动以及以什么顺序执行。[[来源](https://python.langchain.com/docs/modules/agents)]
- en: '![](../Images/991e5a86b326cc3876bedba860b192a4.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/991e5a86b326cc3876bedba860b192a4.png)'
- en: Agent answering a multi-hop question in a step-by-step manner. (Image by Author)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 代理以逐步方式回答多跳问题。（图像由作者提供）
- en: 'Agents typically require a set of tools to be specified at the time of their
    instantiation. For instance, to solve the aforementioned multi-hop question, we
    should define four tools:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 代理通常需要在实例化时指定一组工具。例如，要解决上述的多跳问题，我们应该定义四个工具：
- en: '`Tool_Date`: A Python function that takes as input a relative time frame (such
    as the *past 6 months*) and calculates the start date by subtracting the time
    frame from today’s date (for Step#1)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Tool_Date`：一个 Python 函数，输入一个相对时间框架（如*过去 6 个月*），并通过从今天的日期中减去该时间框架来计算开始日期（用于步骤#1）'
- en: '`Tool_Search`: A search engine that can take as input a search term and return
    the list of relevant documents (for Step#2 and Step#4)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Tool_Search`：一个搜索引擎，输入搜索词并返回相关文档列表（用于步骤#2 和步骤#4）'
- en: '`Tool_Length`: A Python function that takes as input a list and returns the
    length of that list (for Step#3 and Step#5)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Tool_Length`：一个 Python 函数，输入一个列表并返回该列表的长度（用于步骤#3 和步骤#5）'
- en: '`Tool_PercCalculator`: A Python function that takes as input two numbers and
    returns the percent change calculation (for Step#6)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Tool_PercCalculator`：一个 Python 函数，输入两个数字并返回百分比变化计算结果（用于步骤#6）'
- en: Generally speaking — be mindful of the choice of tools you provide an agent,
    as these are the *only* tools that the agent will use to answer each of the intermediate
    steps. If it finds a relevant tool — great, it will use it to get the answer.
    If it doesn’t, it will usually iterate a few times (i.e. trying one of the other
    available tools or its own logical reasoning) and finally return a sub-optimal
    answer.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说——请注意你为代理提供的工具选择，因为这些是代理在回答每一个中间步骤时会使用的*唯一*工具。如果它找到相关工具——太好了，它将使用该工具来获得答案。如果没有，它通常会迭代几次（即尝试使用其他可用工具或其自身的逻辑推理），最终返回一个次优的答案。
- en: Let’s begin by jumping straight into code, if you’d like to follow along, here’s
    the [GitHub repo](https://github.com/V-Sher/LangChain_ReAct_Demo).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接进入代码，如果你想跟着一起操作，以下是 [GitHub 仓库](https://github.com/V-Sher/LangChain_ReAct_Demo)。
- en: Dataset
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: While I was tempted to use the ever-popular `[state_of_the_union.txt](https://github.com/hwchase17/chat-your-data/blob/master/state_of_the_union.txt)`
    for this demo, I couldn’t come up with complex questions to ask that document.
    Hence, I have created a dummy HR document (using ChatGPT) for a fictitious company
    called GlobalCorp. You can view `globalcorp_hr_policy.txt` [here](https://github.com/V-Sher/LangChain_ReAct_Demo/blob/main/data/globalcorp_hr_policy.txt).
    The main highlights of the file include (a) country-specific annual budgets (b)
    in different currencies and (c) country-specific leave policies.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我很想使用那个非常流行的 `[state_of_the_union.txt](https://github.com/hwchase17/chat-your-data/blob/master/state_of_the_union.txt)`
    来做这个演示，但我没能想出可以对该文档提问的复杂问题。因此，我创建了一个虚构公司 GlobalCorp 的虚拟 HR 文档（使用 ChatGPT）。你可以在
    [这里](https://github.com/V-Sher/LangChain_ReAct_Demo/blob/main/data/globalcorp_hr_policy.txt)
    查看 `globalcorp_hr_policy.txt` 文件。该文件的主要亮点包括：（a）国家特定的年度预算（b）不同货币的预算，以及（c）国家特定的假期政策。
- en: LLM and Embedding models
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 和嵌入模型
- en: We will be using Azure Open AI models (`gpt3.5 turbo` , `gpt-4-turbo` and `ada-embeddings`)
    for this tutorial.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本教程中使用 Azure Open AI 模型（`gpt3.5 turbo`、`gpt-4-turbo` 和 `ada-embeddings`）。
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Disclaimer — I will be using the terms “RAG tool”, “Q&A system”, and “QnA
    tool” interchangeably. For this tutorial, all refer to a tool that is capable
    of looking up a bunch of documents to answer a specific user query but does* ***not***
    *have any conversational memory i.e. you won’t be able to ask follow-up questions
    in a chat-like manner. However, that can be easily implemented in LangChain and
    will likely be covered in some future article. The focus here is just to get the
    multi-hop questions working.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明 — 我将交替使用“RAG工具”、“Q&A系统”和“QnA工具”这几个术语。在本教程中，它们都指的是一个能够查找一堆文档以回答特定用户查询的工具，但它*
    ***没有*** *任何对话记忆，即你不能以类似聊天的方式提问后续问题。不过，这可以在LangChain中轻松实现，可能会在未来的某篇文章中讨论。这里的重点仅仅是让多跳问题能够正常工作。*'
- en: RAG-based QnA
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于RAG的QnA
- en: Let’s go ahead and build a standard Q&A system using this data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用这些数据构建一个标准的问答系统。
- en: We will be using `TextLoader` for loading the dummy HR document.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`TextLoader`加载虚拟HR文档。
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`Chroma` as the vectorstore (for storing the document embeddings),'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`Chroma`作为向量存储（用于存储文档嵌入），'
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`LocalFileStore` as the docstore (for storing the parent documents),'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`LocalFileStore`作为文档存储（用于存储父文档），'
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: PDR (`parentdocumentretriever`) as the `retriever` (for retrieving relevant
    data from the index).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: PDR（`parentdocumentretriever`）作为`retriever`（用于从索引中检索相关数据）。
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: With all the setup done, we are ready to add our document to the retriever using
    `add_documents()` command. Additionally, I also recommend persisting the vectorstore
    using `.persist()` command (i.e. storing the contents of the vectorstore to your
    disk so you don’t have to recompute the embeddings again once you terminate your
    current session)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有设置后，我们准备使用`add_documents()`命令将文档添加到检索器中。此外，我还建议使用`.persist()`命令持久化向量存储（即将向量存储的内容保存到磁盘，这样你在终止当前会话后就不必重新计算嵌入了）。
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once you run these commands, you should see two folders — `local_docstore` and
    `local_vectorstore` — created in your working session. Feel free to check the
    contents for each.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行这些命令，你应该会看到在工作会话中创建了两个文件夹 — `local_docstore`和`local_vectorstore`。可以随意检查每个文件夹的内容。
- en: '![](../Images/9eff59ac6709193585ebaefdf989691e.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9eff59ac6709193585ebaefdf989691e.png)'
- en: 'Quick sanity check to see if the `retriever` is set correctly:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 快速检查`retriever`是否设置正确：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Finally, we’ll build the `RetrievalQA` chain to do question-answering using
    all the aforementioned components.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将构建`RetrievalQA`链，通过之前提到的所有组件进行问答。
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Asking standard questions
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提问标准问题
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Having manually reviewed the policy document, it is safe to say the answers
    make sense.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动审核过政策文档后，可以放心地说，答案是有意义的。
- en: Asking complex/multi-hop questions
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提问复杂/多跳问题
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Mathematically speaking, the response is not 100% correct. Even though the logic
    it used is correct (i.e. converting the amount from ¥ to $ ), the exchange rate
    used is out of date.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，响应并不是100%正确。虽然它使用的逻辑是正确的（即将金额从¥转换为$），但所使用的汇率已过时。
- en: Let’s try helping it by providing the exchange rate information (1 USD = 147.72
    JPY) as part of the query itself.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试通过在查询中提供汇率信息（1美元 = 147.72日元）来帮助它。
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Interestingly enough, LLM was able to use the exchange rate as part of the calculations
    and the answer it gave (i.e. $338,164.25) was very close to the actual answer
    (i.e. 338,478.20). Having said that, there’s still room for improvement.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，LLM能够将汇率作为计算的一部分，并且它给出的答案（即$338,164.25）非常接近实际答案（即338,478.20）。不过，还是有改进的空间。
- en: 'Let’s try another question, this time a comparison question:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试另一个问题，这次是一个比较问题：
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Again, the response is not correct since it didn’t do the currency conversion
    before comparing the budgets with other countries like the US, Germany, etc.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在与其他国家（如美国、德国等）比较预算时没有进行货币兑换，因此该响应不正确。
- en: '*Observation*: All the aforementioned questions could be reliably answered
    if instead of jumping on a final answer, we had a systematic way of planning the
    intermediate steps. To do so, let’s introduce `agents`.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*观察*：如果我们有一种系统化的方式来规划中间步骤，而不是直接跳到最终答案，那么上述所有问题都可以可靠地回答。为此，让我们引入`agents`。'
- en: ReAct Agent
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReAct Agent
- en: In this tutorial, we will be using LangChain’s implementation of the ReAct (Reason
    + Act) agent, first introduced in [this](https://arxiv.org/abs/2210.03629) paper.
    The key takeaway from the paper is that if we prompt the LLM to generate both
    reasoning traces and task-specific actions in a step-by-step manner, its performance
    on the task improves. In other words, we are explicitly asking it to have multiple
    thought-action-observation steps to solve a task instance instead of coming to
    the final answer in one single jump (which ultimately leads to reduced hallucination).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用 LangChain 实现的 ReAct（Reason + Act）代理，最早在[这篇](https://arxiv.org/abs/2210.03629)论文中介绍。论文的关键要点是，如果我们提示
    LLM 按步骤生成推理过程和任务特定的行动，其在任务上的表现会有所提升。换句话说，我们明确要求它进行多个思考-行动-观察步骤来解决任务实例，而不是一步到位地得出最终答案（这最终会减少幻觉的发生）。
- en: Apart from ReAct, LangChain supports other agents such as `Open AI tools`, `XML`,
    `StructuredChat`, `Self Ask with Search`, etc that I strongly encourage you to
    read about [here](https://python.langchain.com/docs/modules/agents/agent_types/).
    One key thing to note here is that ReAct agents can only support tools that can
    take only 1 input parameter (for instance, from the tools described above, it
    can support `Tool_Length`, `Tool_Date`, and `Tool_Search` ). If you want to use
    tools that take more than 1 input (for instance `Tool_PercCalculator`), you will
    be better off using `Open AI Tools` agent or `Open AI Functions` agent.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 ReAct，LangChain 还支持其他代理，例如`Open AI tools`、`XML`、`StructuredChat`、`Self Ask
    with Search`等，我强烈建议你阅读[这里](https://python.langchain.com/docs/modules/agents/agent_types/)的相关内容。这里需要注意的一点是，ReAct
    代理只能支持那些只接受一个输入参数的工具（例如，在上述描述的工具中，它可以支持`Tool_Length`、`Tool_Date`和`Tool_Search`）。如果你想使用需要多个输入的工具（例如`Tool_PercCalculator`），你最好使用`Open
    AI Tools`代理或`Open AI Functions`代理。
- en: 'Note: “OpenAI termed the capability to invoke a single function as `functions`,
    and the capability to invoke one or more functions as `tools`. As per the official
    website, `functions` are now considered a legacy option that is deprecated in
    favor of `tools`. So if you’re creating agents using OpenAI models, you should
    be using this `OpenAI Tools` agent rather than the `OpenAI functions` agent.”
    [[Source](https://python.langchain.com/docs/modules/agents/agent_types/openai_tools)]'
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：“OpenAI 将调用单一功能的能力称为`functions`，而调用一个或多个功能的能力称为`tools`。根据官网信息，`functions`现在被视为一个遗留选项，已被`tools`取代。因此，如果你在使用
    OpenAI 模型创建代理，应该使用这个`OpenAI Tools`代理，而不是`OpenAI functions`代理。”[[来源](https://python.langchain.com/docs/modules/agents/agent_types/openai_tools)]
- en: Defining the tools for the agent
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为代理定义工具
- en: 'As I mentioned above, we first need to define the tools that this agent will
    have access to. For starters, we will only define one tool: `tool_search`.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，我们首先需要定义这个代理将访问的工具。首先，我们只定义一个工具：`tool_search`。
- en: '`tool_search`: Given a search query, we need a tool that will return the relevant
    chunks of the HR document. But wait, isn’t that what our PDR retriever does anyway?
    In fact, we can easily convert our retriever into a tool using the `create_retriever_tool()`.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`tool_search`：给定一个搜索查询，我们需要一个工具来返回相关的 HR 文档片段。但是等等，这不正是我们 PDR 检索器所做的吗？事实上，我们可以使用`create_retriever_tool()`轻松地将我们的检索器转换成一个工具。'
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'A couple of pointers:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一些提示：
- en: The `name`and`description` of the tool will be passed in the API call to the
    LLM, so make sure it is as unambiguous as possible for the agent to understand.
    In our case, we have clearly defined that this tool returns excerpts (i.e. chunks)
    from the HR policy.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该工具的`name`和`description`将在 API 调用中传递给 LLM，因此请确保它尽可能清晰，以便代理能够理解。在我们的例子中，我们已明确指定该工具返回
    HR 政策中的摘录（即片段）。
- en: 'Under the hood, this tool uses the `get_relevant_documents()` function of the
    `retriever`. You can check it using `.func`:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在底层，这个工具使用了`retriever`的`get_relevant_documents()`函数。你可以通过`.func`来检查它：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You can even check the schema of this tool using `.schema()`. It is useful for
    verifying the `required` parameters necessary for calling the tool.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你甚至可以通过`.schema()`来检查这个工具的架构。它有助于验证调用该工具所需的`required`参数。
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Pro-tip: You can use* `*tool.invoke({"inp_param_name": inp_param_value})*`
    *to quickly test if a custom tool has been set up properly. For example:* `*tool_search.invoke({“query”:
    “enter query here”})*`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*专业提示：你可以使用*`*tool.invoke({"inp_param_name": inp_param_value})*`*快速测试自定义工具是否已正确设置。例如：*`*tool_search.invoke({“query”:
    “在这里输入查询”})*`'
- en: Finally, let’s set up the ReAct agent using a prompt that emphasizes multiple
    thought-action-observation steps. Luckily for us, this is already available on
    the LangChain hub (you can also override this by defining your own). The prompt
    template requires three input_variables i.e. `tools`, `input` and `agent_scratchpad`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们使用一个强调多步骤思考-行动-观察的提示来设置 ReAct 代理。幸运的是，这个提示已经在 LangChain hub 上提供（你也可以通过定义自己的提示来覆盖它）。该提示模板需要三个输入变量，即
    `tools`、`input` 和 `agent_scratchpad`。
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*Note 1: While this prompt works fine 8 out of 10 times, I highly recommend
    modifying it to suit your use case — especially if the agent is getting confused
    about the sequence of actions or thoughts. For instance, in one of the projects
    where the questions were comparison-based (such as ‘Compare the increase in sales
    between China and the US in the last 1 year’), this is how I updated the react
    prompt (and introduced a new input variable* `*{today_date}*`*:*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意 1：虽然这个提示在 10 次中有 8 次可以正常工作，但我强烈建议根据你的使用场景进行修改——特别是当代理在执行思考或行动的顺序时感到困惑时。例如，在一个以比较为基础的问题的项目中（如“比较过去一年中国和美国的销售增长”），这是我更新
    react 提示的方式（并引入了一个新的输入变量 `*{today_date}*`）：*'
- en: '[PRE18]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '*Note 2: Doing the above (i.e. a more detailed/lengthy prompt) can exponentially
    increase the token count for your use case. My recommendation is to switch to
    the chaining of LLMs* ***if*** *(and this is a big if) you know beforehand the
    order in which the action/thoughts need to be executed. For example: if you know
    that the only type of questions your system needs to answer is comparison questions
    like the one I mentioned above, it makes more sense to create a sequential chain
    of calls to the LLM where output from one is fed as input to the other. I have
    touched upon the technical implementation of this in LangChain in my previous*
    [*article*](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81)*.*'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意 2：进行上述操作（即更详细/更长的提示）可能会指数级增加你的用例的 token 数量。我的建议是，如果你提前知道行动/思考的执行顺序，那么切换到
    LLM 的链式调用会更有效* ***如果*** *(且这是一个很大的前提条件)*。例如：如果你知道你的系统需要回答的唯一类型问题是像我上面提到的比较问题，那么创建一个
    LLM 的顺序链条（一个输出作为另一个输入）会更有意义。我在之前的* [*文章*](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81)*
    中讲解了如何在 LangChain 中实现这一技术。*'
- en: Creating a ReAct agent
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 ReAct 代理
- en: '[PRE19]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We also need to instantiate `AgentExecutor` that will execute the logical steps
    that `react_agent` will generate.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要实例化 `AgentExecutor`，它将执行 `react_agent` 生成的逻辑步骤。
- en: '[PRE20]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Testing the ReAct agent
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试 ReAct 代理
- en: Finally, it is time to test it on the same sample queries as before.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，是时候在与之前相同的示例查询上进行测试了。
- en: '*Note: While I was tempted to cherry-pick examples for this article, it is
    important to show that these agents can be unreliable at times and a lot of testing
    needs to be done to establish their capabilities and limitations.*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：虽然我很想为这篇文章挑选一些例子，但展示这些代理有时不可靠是很重要的，很多测试需要进行以确认它们的能力和局限性。*'
- en: '[PRE21]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'A few points for consideration:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑的几点：
- en: Notice the `Action Input` (i.e. “highest country budget”) for the first `Action`
    . This is the search query that will be passed to the `get_relevant_function()`
    of the PDR `retriever` (rather than the actual input query i.e. `Which country
    has the highest budget?`). That means, if there was a section in the underlying
    documents that talked about the highest country budget we would have been sorted!
    Sadly, that’s not the case here.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意第一个 `Action` 的 `Action Input`（即“最高国家预算”）。这是将传递给 PDR `retriever` 的 `get_relevant_function()`
    的搜索查询（而不是实际的输入查询，即“哪个国家的预算最高？”）。这意味着，如果底层文档中有讨论最高国家预算的部分，我们就可以顺利找到答案！可惜，情况并非如此。
- en: The `Observation` (i.e. the results from running the `action` i.e. tool with
    the `action inputs`) is printed right after `Action Input`. In our case, it is
    the retrieved document (`[Document(page_content=’**Grievance and Disciplinary
    Procedures:**\nOur grievance and disciplinary procedures are …`) and it contains
    the information necessary for answering the query. Even so, the final response
    is still incorrect. [P.S. Based on my testing, this happens mostly with gpt3.5.]
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Observation`（即运行 `action`（工具与 `action inputs`）后的结果）会在 `Action Input` 后立即打印。在我们的例子中，它是检索到的文档（`[Document(page_content=’**申诉和纪律程序：**\n我们的申诉和纪律程序是...）`），并包含回答查询所需的信息。尽管如此，最终的回答仍然不正确。[P.S.
    根据我的测试，这种情况主要出现在 gpt3.5 中。]'
- en: (To make it work with gpt-3.5) I tried updating the search query to `"Which
    of the two countries has the highest budget — Japan or Unites States?"` , hoping
    the agent would pick up on the country names and make 2 consecutive calls to the
    retriever to fetch the relevant info. Unfortunately, the final answer was the
    same as above.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (为了使其与gpt-3.5兼容) 我尝试将搜索查询更新为`"Which of the two countries has the highest budget
    — Japan or Unites States?"`，希望代理能够识别国家名称，并连续进行两次检索调用以获取相关信息。不幸的是，最终的答案与之前相同。
- en: Finally, after slight rewording, we have a query that works (with gpt3.5).
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终，经过轻微的措辞调整，我们有了一个有效的查询（与gpt3.5兼容）。
- en: 'Main takeaway: (1) Even for similar-looking prompts, the responses can vary
    drastically. (2) GPT4 is better suited than GPT3.5 for implementing ReAct agents.'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 主要要点：(1) 即使是看起来相似的提示，响应也可能有很大差异。(2) GPT4比GPT3.5更适合实现ReAct代理。
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*P.S. I was not too pleased with the unnecessary Action-Action Input loops
    even though the relevant answer was revealed in the first iteration itself. Again,
    something I am currently debugging.*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*P.S. 尽管在第一次迭代中就揭示了相关答案，但我对不必要的行动-行动输入循环并不满意。这是我当前正在调试的部分。*'
- en: Understanding the implementation of the agent
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解代理的实现
- en: '*LangChain library can be a bit daunting at first and if you would like to
    debug how things are working under the hood w.r.t. react agents, here are some
    useful* [*breakpoints to set in your debugger*](/how-to-make-most-of-your-python-debugger-in-vscode-9e05dfce533f)*.*'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*LangChain库刚开始可能有点令人生畏，如果你想调试与react代理相关的底层工作原理，这里有一些有用的* [*调试器中的断点设置*](/how-to-make-most-of-your-python-debugger-in-vscode-9e05dfce533f)*。*'
- en: 'I. [setup of the ReAct agent](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L113-L120):
    here you will find the 4 main steps (chained together through the `|` symbol)
    that the agent will take at each iteration. (*I have also included snippets to
    show you inputs/outputs for each of the four steps in isolation).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: I. [ReAct代理的设置](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L113-L120)：在这里你将看到代理在每次迭代时所采取的四个主要步骤（通过`|`符号连接）。(*我还包含了片段，展示了每个步骤的输入/输出。)
- en: P.S. If it is your first time seeing this pipe symbol* `*|*` *in LangChain,
    I recommend going through* [*this*](https://python.langchain.com/docs/expression_language/why)
    *and* [*this*](https://python.langchain.com/docs/expression_language/cookbook/prompt_llm_parser)
    *first. In simple terms, the* `*|*`*takes passes the output from the first step
    and passes it as input to the next step in the chain.*
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: P.S. 如果你是第一次看到这个管道符号* `*|*` *在LangChain中，我建议先阅读* [*这个*](https://python.langchain.com/docs/expression_language/why)
    *和* [*这个*](https://python.langchain.com/docs/expression_language/cookbook/prompt_llm_parser)
    *。简单来说，`*|*`*符号将第一个步骤的输出作为输入传递给链中的下一步。*
- en: '(a) `Runnable.assign()`: updates `agent_scratchpad` with observations i.e.
    all prior thought-action-observations and creates a dictionary that can be passed
    as input to the next step i.e. `PromptTemplate`.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: (a) `Runnable.assign()`：使用观察结果更新`agent_scratchpad`，即所有先前的思考-行动-观察，并创建一个字典，可以将其作为输入传递给下一步，即`PromptTemplate`。
- en: 'While I have used dummy data in the snippet below, a typical `agent_scratchpad`
    would look like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我在下面的片段中使用了虚拟数据，但典型的`agent_scratchpad`应该如下所示：
- en: '`` `I need to check if there is any information in the HR policy regarding
    budget allocation for different countries.\nAction: search_hr_policy\nAction Input:
    “budget allocation for different countries”\nObservation: [Document(page_content=\’**Griev....]metadata={\’source\’:
    \’../data/globalcorp_hr_policy.txt\’})]\nThought: ``'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`` `I need to check if there is any information in the HR policy regarding
    budget allocation for different countries.\nAction: search_hr_policy\nAction Input:
    “budget allocation for different countries”\nObservation: [Document(page_content=\’**Griev....]metadata={\’source\’:
    \’../data/globalcorp_hr_policy.txt\’})]\nThought: ``'
- en: '[PRE23]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '(b) `PromptTemplate`: frames the final react prompt for the LLM call based
    on the updated `agent_scratchpad` and creates a `StringPromptValue`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: (b) `PromptTemplate`：基于更新后的`agent_scratchpad`框架最终的react提示，以便调用LLM，并创建一个`StringPromptValue`。
- en: '(Note: As per the react prompt template, we also need another `input_variables`
    called `tools` which is already appended using `prompt.partial` [here](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L99-L102)).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: (注意：根据react提示模板，我们还需要另一个名为`tools`的`input_variables`，它已经通过`prompt.partial`在[这里](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L99-L102)附加了。)
- en: '[PRE24]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '(c ) `AzureChatOpenAI`: passes the prompt to the `llm` for the generation step
    and fetches the response i.e. `AIMessage`'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: (c) `AzureChatOpenAI`：将提示传递给`llm`进行生成步骤并获取响应，即`AIMessage`。
- en: '[PRE25]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: (d) `ReActSingleInputOutputParser():` parses the output (i.e. `AIMessage`) returned
    by the `llm`.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: (d) `ReActSingleInputOutputParser():` 解析`llm`返回的输出（即`AIMessage`）。
- en: '[PRE26]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'II. [agent at work](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/core/langchain_core/runnables/base.py#L2052):
    this is where you can see the `for` loop for iterating over all four aforementioned
    steps. Feel free to set watch variables and investigate the intermediate results.
    After going through all four steps, the final response is either of type `AgentAction`
    (whether to call another tool) or `AgentFinish`(finish the loop). Here is a quick
    snapshot of my debugger at all the four steps:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: II. [工作中的代理](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/core/langchain_core/runnables/base.py#L2052)：这里可以看到用于遍历之前四个步骤的`for`循环。可以自由设置观察变量并检查中间结果。在完成所有四个步骤后，最终的响应类型要么是`AgentAction`（是否调用另一个工具），要么是`AgentFinish`（结束循环）。下面是我在四个步骤中的调试器快照：
- en: '![](../Images/cd862def19b093e5e6607441b5d56fc8.png)![](../Images/8c10cfe73dfc902dfb6fa60b3d1193dd.png)![](../Images/c6cb10ba661cd55ac44667c2f07c2671.png)![](../Images/d37a025c163ed34d555c12d8bd184cfa.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd862def19b093e5e6607441b5d56fc8.png)![](../Images/8c10cfe73dfc902dfb6fa60b3d1193dd.png)![](../Images/c6cb10ba661cd55ac44667c2f07c2671.png)![](../Images/d37a025c163ed34d555c12d8bd184cfa.png)'
- en: Intermediate output from the agent
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的中间输出
- en: 'III. D[eep dive into the](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)
    `[parse()](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)`
    [of](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)
    `[ReactSingleInputOutputParser](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)`:
    if you want to know how it’s decided whether `AIMessage` should result in `AgentAction`
    or `AgentFinish`.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: III. 深入探讨[parse()](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)
    [函数](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)
    [的实现](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L51)：如果你想了解如何决定`AIMessage`应该导致`AgentAction`还是`AgentFinish`。
- en: 'IV. [custom tool being used](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1204):
    this is where you can see your custom tool being used by the agent (if `AgentAction`
    was returned).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: IV. [使用自定义工具](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1204)：这里可以看到代理使用自定义工具的过程（如果返回了`AgentAction`）。
- en: V. the `[while](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1390)`
    [loop](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1390)
    that keeps the agent looping (unless `AgentFinish` is encountered or a time-out
    occurs) after [updating the intermediate steps](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1403)
    with the observations from the previous iteration.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: V. `[while](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1390)`
    [循环](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1390)，它使代理持续循环（除非遇到`AgentFinish`或发生超时）并在每次迭代后[更新中间步骤](https://github.com/langchain-ai/langchain/blob/ac970c9497e2aca1f6396c3f6954b4f6cd0ac879/libs/langchain/langchain/agents/agent.py#L1403)。
- en: '*Note: Intermediate steps are a collection of observations and observations
    will often be the output of the tool. So in the case of the retriever tool, it
    will be a list of Documents, in the case of currency conversion, it will be a
    number, and so on.*'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：中间步骤是观测结果的集合，而这些观测通常是工具的输出。所以在检索工具的情况下，它将是文档的列表，在货币转换的情况下，它将是一个数字，等等。*'
- en: '![](../Images/fa837b6676eef62a6ea1a41349a85fd7.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa837b6676eef62a6ea1a41349a85fd7.png)'
- en: Example of intermediate steps
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 中间步骤示例
- en: 'Final thoughts: If the questions anticipated for a QnA system are fundamentally
    basic, meaning they can be adequately handled by a standard retrieval-based QA
    mechanism without the need for multi-hop reasoning, it’s best to steer clear of
    agents. This is especially true if the only tool required is a ‘retriever-turned-tool’.
    Introducing agents in such scenarios can needlessly complicate matters. Moreover,
    if you are using a retriever as a tool, the input to its `get_relevant_function()`
    gets modified by the agent (as you noticed above) as it sees fit and you no longer
    have control over it. This may be an issue in some cases (although an easy fix
    for that is to update the description of the tool to `tool_search.description
    = “Searches and returns excerpts from the HR policy. Input should be a fully formed
    question”`)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的思考：如果预期的问答系统问题本质上是基本的，意味着它们可以通过标准的基于检索的问答机制来充分处理，而不需要多跳推理，那么最好避免使用代理。特别是当唯一需要的工具是一个“检索器变成的工具”时，在这种情况下引入代理会无谓地增加复杂性。此外，如果你使用检索器作为工具，它的`get_relevant_function()`的输入会被代理修改（正如你上面看到的），它会按需修改，你将不再控制它。这在某些情况下可能是个问题（尽管解决这个问题的简单方法是更新工具的描述，例如`tool_search.description
    = “搜索并返回人力资源政策中的摘录。输入应是一个完整的问题”`）。
- en: The true potential of agents is unlocked when we give it complex questions and
    more tools to work with as we will see next.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们向代理提供复杂的问题和更多的工具时，代理的真正潜力才会被释放，正如我们接下来将看到的那样。
- en: Introducing more tools
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入更多工具
- en: 'Let’s introduce another tool : `currency_conversion` and run the same query
    as above.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们引入另一个工具：`currency_conversion`，并运行与上面相同的查询。
- en: '[PRE27]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here are some helper functions this tool needs:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该工具需要的一些辅助函数：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let’s re-run the earlier query:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新运行之前的查询：
- en: '[PRE29]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: You may be wondering what’s the big deal about this answer. Even without this
    tool, the previous answer we received was correct. However, what’s noteworthy
    here is its capability to perform currency conversions to USD before arriving
    at the ultimate conclusion that the budgets are indeed different. This helps build
    trust in the responses. Without this tool, I am willing to bet that if the HR
    policy stated the budget for Japan and the US as ¥741 million and $5 million,
    respectively, the LLM would respond that they have different budgets even though
    after conversion (as per today’s rate) they should be same.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，这个答案有什么大不了的。即使没有这个工具，我们之前得到的答案也是正确的。然而，值得注意的是，它能够在得出预算确实不同的最终结论之前，先将货币转换为美元。这有助于建立对回答的信任。如果没有这个工具，我敢打赌，如果人力资源政策上显示日本和美国的预算分别为7.41亿日元和500万美元，LLM会回应说它们的预算不同，尽管按今天的汇率转换后，应该是相同的。
- en: 'A couple of observations:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一些观察：
- en: Given that the tools and their description get appended to the prompt, the model
    knows it has access to these tools if needed. I believe it helps them utilize
    as many of these tools as they deem necessary during answering a query. Hence,
    the decision to use the currency conversion tool in the second action.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于工具及其描述会附加到提示中，模型会知道如果需要，可以使用这些工具。我认为这有助于它们在回答问题时，尽可能多地利用这些工具。因此，决定在第二个动作中使用货币转换工具。
- en: Let’s update the query to get the actual difference in figures.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更新查询，获得实际的数字差异。
- en: '[PRE30]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The LLM has done a great job at handling the subtraction (although I remain
    cautious about relying on LLMs for any type of calculations.). If we want to make
    it even more robust, we can add another tool, say `calculator_subtract` for calculating
    the difference between two numbers. As I mentioned before, ReAct agents cannot
    handle multi-input tools, and doing so would raise an error. This is where Open
    AI Tools agents come in picture.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在处理减法时做得很好（尽管我仍然谨慎依赖LLM进行任何类型的计算）。如果我们想让它更加健壮，我们可以添加另一个工具，比如`calculator_subtract`来计算两个数字之间的差异。如我之前提到的，ReAct代理无法处理多输入工具，做这件事会引发错误。这就是Open
    AI工具代理的用武之地。
- en: Open AI Tools Agent
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Open AI 工具代理
- en: Let’s create a new tool — `perc_diff()`that takes two numbers as inputs and
    calculates the difference in percentage between these two numbers.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个新工具——`perc_diff()`，它接受两个数字作为输入，并计算这两个数字之间的百分比差异。
- en: '[PRE31]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '*Note: Another way to initialize the same tool (giving more control over the
    setup)*'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：初始化相同工具的另一种方式（提供更多的控制权来进行设置）*'
- en: '[PRE32]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Finally, with all the pieces in place, let’s use `create_openai_tools_agent`
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，所有部分就绪，让我们使用`create_openai_tools_agent`
- en: '[PRE33]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '*Note: Upon running this line of code, you may notice errors like* [*this*](https://github.com/Azure/azure-sdk-for-java/issues/38115)
    *i.e.*`*Unrecognized request argument supplied: tools*`*. It means that under
    the hood when the API call is made to the* `*llm*`*, it does not recognize the*
    `*tools*` *parameter. Given that only the newer version of the APIs recognize
    this parameter, it must mean you are using an older version of the model. You
    can fix this by:*'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：运行这行代码时，您可能会遇到类似* [*这个*](https://github.com/Azure/azure-sdk-for-java/issues/38115)
    *的错误，即*`*Unrecognized request argument supplied: tools*`*。这意味着在API调用到* `*llm*`*时，系统无法识别*
    `*tools*` *参数。鉴于只有新版API能识别该参数，这就意味着您正在使用旧版模型。您可以通过以下方式修复这个问题：*'
- en: '*if you are using Azure Open AI services — deploy one of the newer models (see
    image below) and update the* `*deployment_name*` *in your codebase i.e.* `*llm=AzureChatOpenAI(deployment_name=...,
    )*`'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如果你使用的是Azure Open AI服务 — 请部署新版模型（见下图），并在你的代码库中更新* `*deployment_name*` *，即*
    `*llm=AzureChatOpenAI(deployment_name=..., )*`'
- en: '![](../Images/9a2a77e4aabc5f6ca5230d171c3c0344.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a2a77e4aabc5f6ca5230d171c3c0344.png)'
- en: '*Available models on Azure Open AI*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*Azure Open AI上的可用模型*'
- en: '*if you are using Open AI’s API directly — check that the model is a newer
    one from* [*this*](https://platform.openai.com/docs/models/gpt-3-5-turbo) *list.*'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如果你直接使用Open AI的API — 请检查模型是否为* [*这个*](https://platform.openai.com/docs/models/gpt-3-5-turbo)
    *列表中的新版。*'
- en: '*To test this fixed the issue, here’s a comparison before and after the version
    update (complete code snippet can be found* [*here*](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Exploring%20ChatGPT%20Function%20Calling.ipynb)*):*'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '*为了测试这个是否解决了问题，这里有一个版本更新前后的比较（完整代码片段可以在* [*这里*](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Exploring%20ChatGPT%20Function%20Calling.ipynb)*找到）：*'
- en: '[PRE34]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Conclusion
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Having taken a deep dive into the inner workings of the ReAct agent, I hope
    you feel more confident implementing it for your projects. This article just scratched
    the surface, there is so much more to cover. For instance, how to add memory to
    these QnA systems so you can use them in a chat-like manner.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究ReAct代理的内部工作原理后，我希望你在实施此代理到你的项目时能更加自信。本文只是略有涉及，实际上还有很多内容需要探讨。例如，如何为这些问答系统添加记忆，以便你可以以聊天的方式使用它们。
- en: As always if there’s an easier way to do/explain some of the things mentioned
    in this article, do let me know. In general, refrain from unsolicited destructive/trash/hostile
    comments!
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，如果有更简单的方式来做/解释本文中提到的一些内容，请告知我。一般来说，避免发表未经请求的破坏性/无意义/敌意评论！
- en: Until next time ✨
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 下次再见 ✨
- en: '[](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=post_page-----893208c1847e--------------------------------)
    [## A Gentle Intro to Chaining LLMs, Agents, and utils via LangChain'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=post_page-----893208c1847e--------------------------------)
    [## 通过LangChain轻松了解LLM、代理和工具的串联'
- en: Understand the basics of agents, tools, and prompts and some learnings along
    the way
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解代理、工具和提示的基本概念，以及在此过程中获得的一些学习经验
- en: towardsdatascience.com](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=post_page-----893208c1847e--------------------------------)
    [](https://medium.com/illumination/3-apps-to-make-you-the-smartest-person-in-the-room-1cc2d927971d?source=post_page-----893208c1847e--------------------------------)
    [## 3 Apps to Make You the Smartest Person in the Room
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=post_page-----893208c1847e--------------------------------)
    [](https://medium.com/illumination/3-apps-to-make-you-the-smartest-person-in-the-room-1cc2d927971d?source=post_page-----893208c1847e--------------------------------)
    [## 让你成为房间里最聪明的人的3个应用'
- en: With minimum daily time commitments
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最少的每日时间投入
- en: medium.com](https://medium.com/illumination/3-apps-to-make-you-the-smartest-person-in-the-room-1cc2d927971d?source=post_page-----893208c1847e--------------------------------)
    [](/is-googles-notebooklm-going-to-disrupt-the-podcasting-industry-ea8e1ec7f431?source=post_page-----893208c1847e--------------------------------)
    [## Is Google’s NotebookLM Going to Disrupt the Podcasting Industry?
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/illumination/3-apps-to-make-you-the-smartest-person-in-the-room-1cc2d927971d?source=post_page-----893208c1847e--------------------------------)
    [](/is-googles-notebooklm-going-to-disrupt-the-podcasting-industry-ea8e1ec7f431?source=post_page-----893208c1847e--------------------------------)
    [## 谷歌的NotebookLM会颠覆播客行业吗？'
- en: Especially if all it takes is 1 click to turn any content into podcast
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尤其是如果只需要点击1次就能将任何内容转成播客
- en: towardsdatascience.com](/is-googles-notebooklm-going-to-disrupt-the-podcasting-industry-ea8e1ec7f431?source=post_page-----893208c1847e--------------------------------)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/is-googles-notebooklm-going-to-disrupt-the-podcasting-industry-ea8e1ec7f431?source=post_page-----893208c1847e--------------------------------)'
