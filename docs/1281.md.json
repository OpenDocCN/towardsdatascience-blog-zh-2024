["```py\nlibrary(GeoLift)\n\ndata(GeoLift_PreTest)\n```", "```py\n> head(GeoLift_PreTest)\n  location    Y       date\n1 new york 3300 2021-01-01\n2 new york 3202 2021-01-02\n3 new york 4138 2021-01-03\n4 new york 3716 2021-01-04\n5 new york 3270 2021-01-05\n6 new york 3260 2021-01-06\n```", "```py\nGeoTestData_PreTest <- GeoDataRead(data = GeoLift_PreTest,\n                                   date_id = \"date\",\n                                   location_id = \"location\",\n                                   Y_id = \"Y\",\n                                   X = c(), #empty list as we have no covariates\n                                   format = \"yyyy-mm-dd\",\n                                   summary = TRUE)\n\n##################################\n#####       Summary       #####\n##################################\n* Raw Number of Locations: 40\n* Time Periods: 90\n* Final Number of Locations (Complete): 40\n```", "```py\nweights <- GetWeights(Y_id = \"Y\",\n                          location_id = \"location\",\n                          time_id = \"time\",\n                          data = GeoTestData_PreTest,\n                          locations = c(\"austin\"),\n                          pretreatment_end_time = 90,\n                          fixed_effects = TRUE)\n```", "```py\nexclude_markets <- c(\"honolulu\",\"washington\")\nGeoTestData_PreTest_Excl <- subset(GeoTestData_PreTest, !location %in% exclude_markets)\n```", "```py\n> head(dplyr::arrange(weights, desc(weight)))\n     location     weight\n1  cincinnati 0.35232541\n2     detroit 0.27955009\n3    honolulu 0.12960818\n4 minneapolis 0.10951033\n5    portland 0.06265098\n6 san antonio 0.01844960\n```", "```py\nwrite.csv(weights, \"/Users/mandyliu/Documents/R/geolift_weights.csv\", row.names=FALSE)\nwrite.csv(GeoLift_PreTest, \"/Users/mandyliu/Documents/R/market_data.csv\", row.names=FALSE)\n```", "```py\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta, date\n```", "```py\ndf_weights = pd.read_csv('/Users/mandyliu/Documents/R/geolift_weights.csv')  \ndf_markets = pd.read_csv('/Users/mandyliu/Documents/R/market_data.csv')\n```", "```py\n# convert to pandas datetime\ndf_markets['date']=pd.to_datetime(df_markets['date'],format = '%Y-%m-%d')\n\n# combine control markets with weights\ndf_markets_weights = df_markets.merge(df_weights, on='location')\ndf_markets_weights['weighted_Y'] = df_markets_weights['Y'] * df_markets_weights['weight']\n\n# sum weighted_Y by date to create a single synthetic control city\ndf_syn_control = df_markets_weights.groupby('date').sum('weighted_Y')\\\n.reset_index()[['date','weighted_Y']].rename(columns = {'weighted_Y':'Y'})\ndf_syn_control['location'] = 'syn_control'\n\n# append Austin data to syn control\ndf_markets_austin = df_markets[df_markets['location']=='austin'].reset_index(drop = True)\ndf_syn_control_austin = pd.concat([df_markets_austin,df_syn_control],ignore_index = True)\n```", "```py\nsns.lineplot(data=df_syn_control_austin, x=\"date\", y=\"Y\",hue = 'location',palette=['purple', 'pink'])\nplt.xticks(rotation=45)\n```", "```py\ndf_corr = df_syn_control[['date','Y']].merge(df_markets_austin[['date','Y']],on = 'date')\ndf_corr['Y_x'].corr(df_corr['Y_y'])\n```", "```py\n# create multiplier\naustin_Y = df_markets_austin.loc[df_markets_austin['date']==df_markets_austin['date'].max(),'Y'].iloc[0]\nsyn_control_Y = df_syn_control.loc[df_syn_control['date']==df_syn_control['date'].max(),'Y'].iloc[0]\n\nM = austin_Y/syn_control_Y\n```", "```py\n# create a list of dates\ndate_list = []\nstart_date = df_markets_austin['date'].max()\n\nk = 15\nfor day in range(1,k):\n    date = start_date + timedelta(days=day)\n    date_list.append(date)\n\n# create fake austin data post-launch\ndata_austin_new = {\n    \"date\":date_list, \n    \"Y\":   df_markets_austin.tail(14)['Y'].values*1.2, #assuming a 20% lift\n    \"location\":  ['austin'] * 14\n}\ndf_austin_new = pd.DataFrame(data_austin_new)\ndf_markets_austin_test = pd.concat([df_markets_austin,df_austin_new])\n\n# create fake synthetic control data post-launch\ndata_syn_control_new = {\n    \"date\":date_list, \n    \"Y\":   df_syn_control.tail(14)['Y'].values, \n    \"location\":  ['syn_control'] * 14\n}\ndf_syn_control_new = pd.DataFrame(data_syn_control_new)\ndf_syn_control_test = pd.concat([df_syn_control,df_syn_control_new])\n\n#adjust synthetic control with multiplier M\ndf_syn_control_adj = df_syn_control_test.copy()\ndf_syn_control_adj['Y'] = df_syn_control_adj['Y']*M\n\n# combine austin and adjusted control data\ndf_syn_control_austin_adj = pd.concat([df_markets_austin_test,df_syn_control_adj]\\\n                                      ,ignore_index = True)\n```", "```py\nax = sns.lineplot(data=df_syn_control_austin_adj, x=\"date\", y=\"Y\",hue = 'location',palette=['purple', 'pink'])\nax.axvline(x = date(2021,3,31),c='b', linestyle = \"dashed\")\nplt.xticks(rotation=45)\n```"]