- en: 'How to Get JSON Output from LLMs: A Practical Guide'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-get-json-output-from-llms-a-practical-guide-838234ba3bab?source=collection_archive---------1-----------------------#2024-08-16](https://towardsdatascience.com/how-to-get-json-output-from-llms-a-practical-guide-838234ba3bab?source=collection_archive---------1-----------------------#2024-08-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tutorial on enforcing JSON output with Llama.cpp or the Gemini’s API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--838234ba3bab--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--838234ba3bab--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--838234ba3bab--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--838234ba3bab--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--838234ba3bab--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--838234ba3bab--------------------------------)
    ·6 min read·Aug 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4f4a4ebe1e72bb0b28eee0286a787add.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Etienne Girardet](https://unsplash.com/@etiennegirardet?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) are great at generating text, but getting structured
    output like JSON usually requires clever prompting and hoping the LLM understands.
    Thankfully, **JSON mode** is becoming more common in LLM frameworks and services.
    This lets you define the exact output schema you want.
  prefs: []
  type: TYPE_NORMAL
- en: This post gets into constrained generation using JSON mode. We’ll use a complex,
    nested and realistic JSON schema example to guide LLM frameworks/APIs like Llama.cpp
    or Gemini API to generate structured data, specifically tourist location information.
    This builds on a previous post about constrained generation using **Guidance**,
    but focuses on the more widely adopted JSON mode.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/save-time-and-effort-when-building-llm-apps-using-guided-generation-05f7237a3512?source=post_page-----838234ba3bab--------------------------------)
    [## Save Time and Effort When Building LLM Apps Using Guided Generation'
  prefs: []
  type: TYPE_NORMAL
- en: Make LLM outputs conform to your expectation using Guidance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/save-time-and-effort-when-building-llm-apps-using-guided-generation-05f7237a3512?source=post_page-----838234ba3bab--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: While more limited than **Guidance**, JSON mode’s broader support makes it more
    accessible, especially with cloud-based LLM providers.
  prefs: []
  type: TYPE_NORMAL
- en: During a personal project, I discovered that while JSON mode was straightforward
    with Llama.cpp, getting it to…
  prefs: []
  type: TYPE_NORMAL
