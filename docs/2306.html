<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Your Documents Are Trying to Tell You What’s Relevant: Better RAG Using Links</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Your Documents Are Trying to Tell You What’s Relevant: Better RAG Using Links</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/your-documents-are-trying-to-tell-you-whats-relevant-better-rag-using-links-386b7433d0f2?source=collection_archive---------3-----------------------#2024-09-21">https://towardsdatascience.com/your-documents-are-trying-to-tell-you-whats-relevant-better-rag-using-links-386b7433d0f2?source=collection_archive---------3-----------------------#2024-09-21</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="184b" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Document datasets already have structure. Take advantage of it.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@briangodsey?source=post_page---byline--386b7433d0f2--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Brian Godsey" class="l ep by dd de cx" src="../Images/1a657e68741618b79bf470f34f9f3b26.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*JKqfHf0hYYkJJWWBkS3r7A.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--386b7433d0f2--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@briangodsey?source=post_page---byline--386b7433d0f2--------------------------------" rel="noopener follow">Brian Godsey</a></p></div></div></div><div class="hz ia l"><div class="ab ib"><div class="ab"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewbox="0 0 16 16"><path fill="#437AFF" d="M15.163 8c0 .65-.459 1.144-.863 1.575-.232.244-.471.5-.563.719s-.086.543-.092.875c-.006.606-.018 1.3-.49 1.781-.47.481-1.15.494-1.744.5-.324.006-.655.013-.857.094s-.465.337-.704.575c-.422.412-.906.881-1.542.881-.637 0-1.12-.469-1.543-.881-.239-.238-.49-.482-.704-.575-.214-.094-.532-.088-.857-.094-.593-.006-1.273-.019-1.744-.5s-.484-1.175-.49-1.781c-.006-.332-.012-.669-.092-.875-.08-.207-.33-.475-.563-.719-.404-.431-.863-.925-.863-1.575s.46-1.144.863-1.575c.233-.244.472-.5.563-.719.092-.219.086-.544.092-.875.006-.606.019-1.3.49-1.781s1.15-.494 1.744-.5c.325-.006.655-.012.857-.094.202-.081.465-.337.704-.575C7.188 1.47 7.671 1 8.308 1s1.12.469 1.542.881c.239.238.49.481.704.575s.533.088.857.094c.594.006 1.273.019 1.745.5.47.481.483 1.175.49 1.781.005.331.011.669.091.875s.33.475.563.719c.404.431.863.925.863 1.575"/><path fill="#fff" d="M7.328 10.5c.195 0 .381.08.519.22.137.141.215.331.216.53 0 .066.026.13.072.177a.24.24 0 0 0 .346 0 .25.25 0 0 0 .071-.177c.001-.199.079-.389.216-.53a.73.73 0 0 1 .519-.22h1.959c.13 0 .254-.053.346-.146a.5.5 0 0 0 .143-.354V6a.5.5 0 0 0-.143-.354.49.49 0 0 0-.346-.146h-1.47c-.324 0-.635.132-.865.366-.23.235-.359.552-.359.884v2.5c0 .066-.025.13-.071.177a.24.24 0 0 1-.346 0 .25.25 0 0 1-.072-.177v-2.5c0-.332-.13-.65-.359-.884A1.21 1.21 0 0 0 6.84 5.5h-1.47a.49.49 0 0 0-.346.146A.5.5 0 0 0 4.88 6v4c0 .133.051.26.143.354a.49.49 0 0 0 .347.146z"/></svg></div></div></div><span class="ic id" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ie if ah ai aj ak al am an ao ap aq ar ig ih ii" disabled="">Follow</button></p></div></div></span></div></div><div class="l ij"><span class="bf b bg z dx"><div class="ab cn ik il im"><div class="in io ab"><div class="bf b bg z dx ab ip"><span class="iq l ij">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--386b7433d0f2--------------------------------" rel="noopener follow"><p class="bf b bg z ir is it iu iv iw ix iy bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ic id" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">13 min read</span><div class="iz ja l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 21, 2024</span></div></span></div></span></div></div></div><div class="ab cp jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq"><div class="h k w ea eb q"><div class="kg l"><div class="ab q kh ki"><div class="pw-multi-vote-icon ed iq kj kk kl"><div class=""><div class="km kn ko kp kq kr ks am kt ku kv kl"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kw kx ky kz la lb lc"><p class="bf b dy z dx"><span class="kn">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao km lf lg ab q ee lh li" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count ld le">1</span></p></button></div></div></div><div class="ab q jr js jt ju jv jw jx jy jz ka kb kc kd ke kf"><div class="lj k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lk an ao ap ig ll lm ln" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lo cn"><div class="l ae"><div class="ab cb"><div class="lp lq lr ls lt lu ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mp mq mr ms mt mu mm mn paragraph-image"><div role="button" tabindex="0" class="mv mw ed mx bh my"><div class="mm mn mo"><img src="../Images/bb16a49705e46a551ca67dcf91e7de42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QZJs1zfDciWD8RmC"/></div></div><figcaption class="na nb nc mm mn nd ne bf b bg z dx">Photo by <a class="af nf" href="https://unsplash.com/@jayneharr33?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jayne Harris</a> on <a class="af nf" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2130" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">There are layered challenges in building retrieval-augmented generation (RAG) applications. Document retrieval, a huge part of the RAG workflow, is itself a complex set of steps that can be approached in different ways depending on the use case.</p><p id="76ad" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">It is difficult for RAG systems to find the best set of documents relevant to a nuanced input prompt, especially when relying entirely on vector search to find the best candidates. Yet often our documents themselves are telling us where we should look for more information on a given topic — via citations, cross-references, footnotes, hyperlinks, etc. In this article, we’ll show how a new data model — linked documents — unlocks performance improvements by enabling us to parse and preserve these direct references to other texts, making them available for simultaneous retrieval — regardless of whether they were overlooked by vector search.</p><h1 id="6c00" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">AI captures complexity, but not structure</h1><p id="985e" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">When answering complex or nuanced questions requiring supporting details from disparate documents, RAG systems often struggle to locate all of the relevant documents needed for a well-informed and complete response. Yet we keep relying almost exclusively on text embeddings and vector similarity to locate and retrieve relevant documents.</p><p id="06eb" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">One often-understated fact: there is a lot of document information lost during the process of parsing, chunking, and embedding text. Document structure — including section hierarchy, headings, footnotes, cross-references, citations, and hyperlinks — are almost entirely lost in a typical text-to-vector workflow, unless we take specific action to preserve them. When the structure and metadata are telling us what other documents are directly related to what we are reading, why shouldn’t we preserve this information?</p><p id="5d78" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">In particular, links and references are ignored in a typical chunking and embedding process, which means they can’t be used by the AI to help answer queries. But, links and references are valuable pieces of information that often point to more useful documents and text — why wouldn’t we want to check those target documents at query time, in case they’re useful?</p><p id="347d" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Parsing and following links and references programmatically is not difficult, and in this article we present a simple yet powerful implementation designed for RAG systems. We show how to use <strong class="ni fr">document linking</strong> to preserve known connections between document chunks, connections which typical vector embedding and retrieval might fail to make.</p><h1 id="85b1" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Document connections get lost in vector space</h1><p id="a44b" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">Documents in a vector store are essentially pieces of knowledge embedded into a high-dimensional vector space. These vectors are essentially the internal “language” of LLMs — given an LLM and all of its internal parameter values, including previous context and state, a vector is the starting point from which a model generates text. So, all of the vectors in a vector store are embedded documents that an LLM might use to generate a response, and, similarly, we embed prompts into vectors that we then use to search for nearest neighbors in semantic vector space. These nearest neighbors correspond to documents that are likely to contain information that can address the prompt.</p><p id="6ad7" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">In a vector store, the closeness of vectors indicates document similarity in a semantic sense, but where there is no real concept of connectedness beyond similarity. However, documents that are close to each other (and typically retrieved together) can be viewed as a type of connection between those pieces of knowledge, forming an implicit knowledge graph where each chunk of text is connected to its nearest neighbors. A graph built in this sense would not be static or rigid like most knowledge graphs; it would change as new documents are added or search parameters adjusted. So it is not a perfect comparison, but this implicit graph can be helpful as a conceptual framework that is useful for thinking about how document retrieval works within RAG systems.</p><p id="8c34" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">In terms of real-world knowledge — in contrast to vector representations — semantic similarity is just one of many ways that pieces of text may be related. Even before computers and digital representations of data, we’ve been connecting knowledge for centuries: glossaries, indexes, catalogs, tables-of-contents, dictionaries, and cross-references are all ways to connect pieces of knowledge with each other. Implementing these in software is quite simple, but they typically haven’t been included in vector stores, RAG systems, and other gen AI applications. Our documents are telling us what other knowledge is important and relevant; we just need to give our knowledge stores the capability to understand and follow the connections.</p><h1 id="af1e" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Connect knowledge with document linking</h1><p id="50a3" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">We’ve developed document linking for cases in which our documents are telling us what other knowledge is relevant, but our vector store isn’t capturing that and the document retrieval process is falling short. Document linking is a straightforward yet potent method for representing directed connections between documents. It encapsulates all the traditional ways we navigate and discover knowledge, whether through a table of contents, glossary, keyword — and of course the easiest for a programmatic parser to follow: hyperlinks. This concept of linking documents allows for relationships that can be asymmetric or tagged with qualitative metadata for filtering or other purposes. Links are not only easy to conceptualize and work with but also scale efficiently to large, dynamic datasets, supporting robust and efficient retrieval.</p><h1 id="4e08" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">The data model for links</h1><p id="49a4" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">As a data type, document links are quite simple. Link information is stored alongside document vectors as metadata. That means that retrieving a given document automatically retrieves information about the links that lead from and to the given document. Outbound links point to more information that’s likely to be useful in the context of the document, inbound links show which other documents may be supported by the given document, and bi-directional (or undirected) links can represent other types of connections. Links can also be tagged with further metadata that provides qualitative information that can be used for link or document filtering, ranking, and graph traversal algorithms.</p><p id="176a" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">As described in <a class="af nf" href="https://thenewstack.io/scaling-knowledge-graphs-by-eliminating-edges/" rel="noopener ugc nofollow" target="_blank">more detail in the article “Scaling Knowledge Graphs by Eliminating Edges,”</a> rather than storing every link individually, as in typical graph database implementations, our efficient and scalable implementation uses link types and link groups as intermediate data types that greatly reduce storage and compute needs during graph traversal. This implementation has a big advantage when, for example, two groups of documents are closely related.</p><p id="e673" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Let’s say that we have a group of documents on the topic of the City of Seattle (call it Group A) and we have another group of documents that mention Seattle (Group B). We would like to make sure that documents mentioning Seattle can find all of the documents about the City of Seattle, and so we would like to link them. We could create a link from all of the documents in Group B to all of the documents in Group A, but unless the two groups are small, this is a lot of edges! The way we handle this is to create one link type object representing the keyword “Seattle” (<code class="cx pd pe pf pg b">kw:seattle</code>), and then creating directed links from the documents in Group B to this <code class="cx pd pe pf pg b">kw:seattle</code> object as well as links from the <code class="cx pd pe pf pg b">kw:seattle </code>object to the documents in Group A. This results in far fewer links to store with each document — there is only one link each — and no information is lost.</p><h1 id="9c3e" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Using document links during retrieval</h1><p id="0241" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">The main goal of the retrieval process in RAG systems is to find a set of documents that is sufficient to answer a given query. Standard vector search and retrieval finds documents that are most “relevant” to the query in a semantic sense, but might miss some supporting documents if their overall content doesn’t closely match the content of the query.</p><p id="ac99" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">For example, let’s say we have a large document set that includes the documents related to Seattle as described above. We have the following prompt about the Space Needle, a prominent landmark in Seattle:</p><blockquote class="ph pi pj"><p id="8799" class="ng nh pk ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><strong class="ni fr"><em class="fq">“What is close to the Space Needle?”</em></strong></p></blockquote><p id="b5d1" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">A vector search starting with this prompt would retrieve documents mentioning the Space Needle directly, because that is the most prominent feature of the prompt text from a semantic content perspective. Documents mentioning the Space Needle are likely to mention its location in Seattle as well. Without using any document linking, a RAG system would have to try to answer the prompt using mainly documents mentioning the Space Needle, without any guarantee that other helpful documents that don’t mention the Space Needle directly would also be retrieved and used.</p><p id="d47d" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Below, we construct a practical example (with code!) based on this Space Needle dataset and query. Keep reading to understand how a RAG system might miss helpful documents when links are not used, and then “find” helpful documents again by simply following link information contained within the original documents themselves.</p><h1 id="e543" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Document links in action</h1><p id="e2d6" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">In order to illustrate how document linking works, and how it can make connections between documents and knowledge that might be missed otherwise, let’s look at a simple example.</p><p id="779b" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">We’ll start with two related documents containing some text from Wikipedia pages: one document from the page for the <a class="af nf" href="https://en.wikipedia.org/wiki/Space_Needle" rel="noopener ugc nofollow" target="_blank">Space Needle</a>, and one for the neighborhood where the Space Needle is located, <a class="af nf" href="https://en.wikipedia.org/wiki/Lower_Queen_Anne,_Seattle" rel="noopener ugc nofollow" target="_blank">Lower Queen Anne</a>. The Space Needle document has an HTML link to the Lower Queen Anne document, but not the other way around. The document on the Space needle begins as follows:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="226f" class="po od fq pg b bg pp pq l pr ps">'url': 'https://en.wikipedia.org/wiki/Space_Needle'<br/><br/>The Space Needle is an observation tower in Seattle, Washington, <br/>United States. Considered to be an icon of the city, it has been <br/>designated a Seattle landmark. Located in the Lower Queen Anne <br/>neighborhood, it was built in the Seattle Center for the 1962 <br/>World's Fair, which drew over 2.3 million visitors...</span></pre><p id="4764" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">In addition to these two documents derived from real, informative sources, we have also added four very short, uninformative documents — two that mention the Space Needle and two that don’t. These documents (and their fake URLs) are designed to be irrelevant or uninformative documents, such as social media posts that are merely commenting on the Space Needle and Seattle, such as:</p><blockquote class="ph pi pj"><p id="19b2" class="ng nh pk ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">“The Space Needle is TALL.”</p></blockquote><p id="4f20" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">and</p><blockquote class="ph pi pj"><p id="69b6" class="ng nh pk ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">“Queen Anne was a person.”</p></blockquote><p id="75dd" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">The full document set is included in <a class="af nf" href="https://drive.google.com/file/d/1Fhf92TXCCtj7IUf8Vg4xLxhExN1zcliW/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">the Colab notebook</a>. They are HTML documents that we then process using <a class="af nf" href="https://beautiful-soup-4.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">BeautifulSoup4</a> as well as the <code class="cx pd pe pf pg b"><a class="af nf" href="https://python.langchain.com/v0.2/api_reference/community/graph_vectorstores/langchain_community.graph_vectorstores.extractors.html_link_extractor.HtmlLinkExtractor.html" rel="noopener ugc nofollow" target="_blank">HtmlLinkExtractor</a></code><a class="af nf" href="https://python.langchain.com/v0.2/api_reference/community/graph_vectorstores/langchain_community.graph_vectorstores.extractors.html_link_extractor.HtmlLinkExtractor.html" rel="noopener ugc nofollow" target="_blank"> from LangChain</a>, adding those links back to the <code class="cx pd pe pf pg b">Document</code> objects with the <code class="cx pd pe pf pg b">add_links</code> function specifically so we can make use of them in the<code class="cx pd pe pf pg b">GraphVectorStore</code> , a relatively new addition to <a class="af nf" href="https://api.python.langchain.com/en/latest/community_api_reference.html#module-langchain_community.graph_vectorstores" rel="noopener ugc nofollow" target="_blank">the LangChain codebase</a>, <a class="af nf" href="https://www.datastax.com/blog/now-in-langchain-graph-vector-store-add-structured-data-to-rag-apps" rel="noopener ugc nofollow" target="_blank">contributed by my colleagues at DataStax</a>. All of this is open-source.</p><p id="6737" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Each document is processed as follows:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="ea1c" class="po od fq pg b bg pp pq l pr ps">from langchain_core.documents import Document<br/>from langchain_core.graph_vectorstores.links import add_links<br/>from langchain_community.graph_vectorstores.extractors.html_link_extractor import HtmlInput, HtmlLinkExtractor<br/><br/>soup_doc = BeautifulSoup(html_doc, 'html.parser')<br/>doc = Document(<br/>        page_content=soup_doc.get_text(),<br/>        metadata={"source": url}<br/>    )<br/>doc.metadata['content_id'] = url  # the ID for Links to point to this document<br/>html_link_extractor = HtmlLinkExtractor()add_links(doc, html_link_extractor.extract_one(HtmlInput(soup_doc, url)))</span></pre><p id="0805" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><a class="af nf" href="https://cassio.org/" rel="noopener ugc nofollow" target="_blank">Using `cassio`</a>, we initialize the <code class="cx pd pe pf pg b">GraphVectorStore</code> as below:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="93e7" class="po od fq pg b bg pp pq l pr ps">from langchain_openai import OpenAIEmbeddings<br/>from langchain_community.graph_vectorstores.cassandra import CassandraGraphVectorStore<br/><br/># Create a GraphVectorStore, combining Vector nodes and Graph edges.<br/>EMBEDDING = 'text-embedding-3-small'<br/>gvstore = CassandraGraphVectorStore(OpenAIEmbeddings(model=EMBEDDING))<br/><br/></span></pre><p id="9f5f" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">We set up the LLM and other helpers for the RAG chain in the standard way — <a class="af nf" href="https://drive.google.com/file/d/1Fhf92TXCCtj7IUf8Vg4xLxhExN1zcliW/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">see the notebook for details</a>. Note that, while almost everything used here is open-source, in the notebook we are using two SaaS products, OpenAI and DataStax’s <em class="pk">Astra</em> — LLM and vector data store, respectively — both of which have free usage tiers. See <a class="af nf" href="https://python.langchain.com/docs/integrations/text_embedding/" rel="noopener ugc nofollow" target="_blank">the LangChain documentation</a> for alternatives.</p><h1 id="4f3c" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Running RAG With default settings</h1><p id="5874" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">We can run the RAG system end-to-end using a graph retriever with <code class="cx pd pe pf pg b">depth=0</code>— which means no graph traversal at all — and other default parameters as below:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="b569" class="po od fq pg b bg pp pq l pr ps">retriever = gvstore.as_retriever(<br/>    search_kwargs={<br/>        "depth": 0,  # depth of graph traversal; 0 is no traversal at all<br/>    }<br/>)</span></pre><p id="8ef2" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">This gives an output such as:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="e0b0" class="po od fq pg b bg pp pq l pr ps">Question:<br/> What is close to the Space Needle? <br/><br/>Retrieved documents:<br/>['https://TheSpaceNeedleisGreat',<br/> 'https://TheSpaceNeedleisTALL',<br/> 'https://en.wikipedia.org/wiki/Space_Needle',<br/> 'https://SeattleIsOutWest',<br/> 'https://en.wikipedia.org/wiki/Lower_Queen_Anne,_Seattle',<br/> 'https://QueenAnneWasAPerson']<br/><br/>LLM response:<br/>('The Space Needle is close to several locations in the Lower Queen Anne '<br/> 'neighborhood, including Climate Pledge Arena, the Exhibition Hall, McCaw '<br/> 'Hall, Cornish Playhouse, Bagley Wright Theater, the studios for KEXP radio, '<br/> 'SIFF Cinema Uptown, and On the Boards.')</span></pre><p id="972b" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Of course in realistic scenarios, a RAG system would not retrieve the full document set, as we are doing here.</p><h1 id="e97e" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">A more realistic scenario: We can’t retrieve all documents</h1><p id="1bc9" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">Retrieving all documents for each query is impractical or even impossible in some cases. It also defeats the purpose of using vector search in the first place. For all realistic scenarios, only a small fraction of documents can be retrieved for each query, which is why it is so important to get the most relevant and helpful documents near the top of the list.</p><p id="51d7" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">To make things a little more realistic for our example with our tiny dataset, let’s change the settings of the retriever so that <code class="cx pd pe pf pg b">k=3</code>, meaning that a maximum of three documents are returned by each vector search. This means that three of the six total documents — the least similar or relevant according to vector similarity — will be left out of the returned document set. We can change the settings of the retriever like this:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="d54a" class="po od fq pg b bg pp pq l pr ps">retriever = gvstore.as_retriever(<br/>    search_kwargs={<br/>        "depth": 0,  # depth of graph traversal; 0 is no traversal at all<br/>        "k": 3       # number of docs returned by initial vector search---not including graph Links<br/>    }<br/>)</span></pre><p id="9bc7" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Querying the system with these settings gives the output:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="8ae1" class="po od fq pg b bg pp pq l pr ps">Question:<br/> What is close to the Space Needle? <br/><br/>Retrieved documents:<br/>['https://TheSpaceNeedleisGreat',<br/> 'https://TheSpaceNeedleisTALL',<br/> 'https://en.wikipedia.org/wiki/Space_Needle']<br/><br/>LLM response:<br/>('The context does not provide specific information about what is close to the '<br/> 'Space Needle. It only mentions that it is located in the Lower Queen Anne '<br/> 'neighborhood and built for the Seattle Center for the 1962 World's Fair.')</span></pre><p id="d5c9" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">We can see that this final response is much less informative than the previous one, now that we have access to only half of the document set, instead of having all six documents available for response generation.</p><p id="1fbd" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">There are some important points to note here.</p><ol class=""><li id="5f99" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob pt pu pv bk">One document that was left out was the document on <em class="pk">Lower Queen Anne</em>, which is the only document that describes some significant places in the neighborhood where the Space Needle is located.</li><li id="4824" class="ng nh fq ni b go pw nk nl gr px nn no np py nr ns nt pz nv nw nx qa nz oa ob pt pu pv bk">The <em class="pk">Lower Queen Anne</em> document does not specifically mention the Space Needle, whereas three other documents do. So it makes sense that the initial query “What is close to the Space Needle?” returns those three.</li><li id="0c03" class="ng nh fq ni b go pw nk nl gr px nn no np py nr ns nt pz nv nw nx qa nz oa ob pt pu pv bk">The main document about the Space Needle has an HTML link directly to <em class="pk">Lower Queen Anne</em>, and any curious human would probably click on that link to learn about the area.</li><li id="66b1" class="ng nh fq ni b go pw nk nl gr px nn no np py nr ns nt pz nv nw nx qa nz oa ob pt pu pv bk">Without any sense of linking or graph traversal, this RAG system retrieves the most semantically similar documents — including two uninformative ones — and misses the one article that has the most information for answering the query.</li></ol><p id="480e" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Now, let’s look at how document linking affects results.</p><h1 id="b0bf" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Following links finds the missing information</h1><p id="687f" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">A simple change to our retriever setup — setting <code class="cx pd pe pf pg b">depth=1</code> — enables the retriever to follow any document links from the documents that are initially retrieved by vector search. (For reference, note that setting <code class="cx pd pe pf pg b">depth=2</code> would not only follow links in the initial document set, but would also follow the next set of links in the resulting document set — but we won’t go that far yet.)</p><p id="f661" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">We change the retriever <code class="cx pd pe pf pg b">depth</code> parameter like this:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="479e" class="po od fq pg b bg pp pq l pr ps">retriever = gvstore.as_retriever(<br/>    search_kwargs={<br/>        "depth": 1,  # depth of graph traversal; 0 is no traversal at all<br/>        "k": 3       # number of docs returned by initial vector search---not including graph Links<br/>    }<br/>)</span></pre><p id="9fe8" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">which gives the following output:</p><pre class="mp mq mr ms mt pl pg pm bp pn bb bk"><span id="243b" class="po od fq pg b bg pp pq l pr ps">Question:<br/> What is close to the Space Needle? <br/><br/>Retrieved documents:<br/>['https://TheSpaceNeedleisGreat',<br/> 'https://TheSpaceNeedleisTALL',<br/> 'https://en.wikipedia.org/wiki/Space_Needle',<br/> 'https://en.wikipedia.org/wiki/Lower_Queen_Anne,_Seattle']<br/><br/>LLM response:<br/>('The Space Needle is located in the Lower Queen Anne neighborhood, which '<br/> 'includes Climate Pledge Arena, Exhibition Hall, McCaw Hall, Cornish '<br/> 'Playhouse, Bagley Wright Theater, the studios for KEXP radio, a three-screen '<br/> 'movie theater (SIFF Cinema Uptown), and On the Boards, a center for '<br/> 'avant-garde theater and music.')</span></pre><p id="8388" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">We can see that the first <code class="cx pd pe pf pg b">k</code> documents retrieved by vector search are the same three as before, but setting <code class="cx pd pe pf pg b">depth=1</code> instructed the system to follow links from those three documents and include those linked documents as well. So, the direct link from the <em class="pk">Space Needle</em> document to <em class="pk">Lower Queen Anne</em> included that document as well, giving the LLM access to the neighborhood information that it needed to answer the query properly.</p><h1 id="2981" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Document linking can improve RAG apps</h1><p id="642a" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">This hybrid approach of vector and graph retrieval can significantly enhance the context relevance and diversity of results in RAG applications. It can lead to fewer hallucinations and higher-quality outcomes by ensuring that the system retrieves the most contextually appropriate and diverse content.</p><p id="2b70" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Beyond improving the quality of responses of RAG systems, document linking has some advantages for implementation in a production system. Some beneficial properties of include:</p><ol class=""><li id="6ee6" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob pt pu pv bk"><strong class="ni fr">Lossless</strong> — The original content remains intact within the nodes, ensuring that no information is discarded during the graph creation process. This preserves the integrity of the data, reducing the need for frequent re-indexing as needs evolve and leveraging the LLM’s strength in extracting answers from contextual clues.</li><li id="487e" class="ng nh fq ni b go pw nk nl gr px nn no np py nr ns nt pz nv nw nx qa nz oa ob pt pu pv bk"><strong class="ni fr">Hands-off </strong>— This method does not require expert intervention to refine knowledge extraction. Instead, adding some edge extraction capabilities based on keywords, hyperlinks, or other document properties to the existing vector-search pipeline allows for the automatic addition of links.</li><li id="2184" class="ng nh fq ni b go pw nk nl gr px nn no np py nr ns nt pz nv nw nx qa nz oa ob pt pu pv bk"><strong class="ni fr">Scalable</strong> — The graph creation process involves straightforward operations on the content without necessitating the use of an LLM to generate the knowledge graph.</li></ol><p id="e171" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Performance benchmarks and a more detailed analysis of scaling document linking is included in the <a class="af nf" href="https://thenewstack.io/scaling-knowledge-graphs-by-eliminating-edges/" rel="noopener ugc nofollow" target="_blank">article mentioned earlier</a>.</p><p id="a624" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">As always, there are some limitations. If your document set truly doesn’t have links or other structure, the strategies presented here won’t accomplish much. Also, while building and traversing graph connections can be powerful, it also adds complexity to the retrieval process that might be challenging to debug and optimize — primarily if traversing the graph to depths of 2 or greater.</p><p id="420e" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Overall, incorporating document linking into RAG systems combines the strengths of traditional, deterministic software methodologies, graph algorithms, and modern AI techniques. By explicitly defining links between documents, we enhance the AI’s ability to navigate knowledge as a human researcher might, improving not only retrieval accuracy but also the contextual depth of responses. This approach creates more robust, capable systems that align with the complex ways humans seek and use knowledge.</p><h1 id="79c9" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Getting started with document linking</h1><p id="ca38" class="pw-post-body-paragraph ng nh fq ni b go oy nk nl gr oz nn no np pa nr ns nt pb nv nw nx pc nz oa ob fj bk">Complete code from this article can be found in <a class="af nf" href="https://drive.google.com/file/d/1Fhf92TXCCtj7IUf8Vg4xLxhExN1zcliW/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">this Colab notebook</a>. And, check out <a class="af nf" href="https://www.datastax.com/blog/now-in-langchain-graph-vector-store-add-structured-data-to-rag-apps?utm_medium=byline&amp;utm_source=tds&amp;utm_campaign=graph&amp;utm_content=doc-linking" rel="noopener ugc nofollow" target="_blank">this introductory blog post</a> by my colleague at DataStax, or see <a class="af nf" href="https://api.python.langchain.com/en/latest/community_api_reference.html#module-langchain_community.graph_vectorstores" rel="noopener ugc nofollow" target="_blank">the documentation for </a><code class="cx pd pe pf pg b"><a class="af nf" href="https://api.python.langchain.com/en/latest/community_api_reference.html#module-langchain_community.graph_vectorstores" rel="noopener ugc nofollow" target="_blank">G</a>raphVectorStore</code> in LangChain for detailed API information and how to use document linking to enhance your RAG applications and push the boundaries of what your knowledge systems can achieve.</p></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="e5ef" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><em class="pk">by Brian Godsey, Ph.D. (</em><a class="af nf" href="https://bit.ly/4enqFRa" rel="noopener ugc nofollow" target="_blank"><em class="pk">LinkedIn</em></a><em class="pk">)— mathematician, data scientist and engineer // works on AI products at </em><a class="af nf" href="https://www.datastax.com/" rel="noopener ugc nofollow" target="_blank"><em class="pk">DataStax</em></a><em class="pk"> // Wrote the book </em><a class="af nf" href="https://manning.com/books/think-like-a-data-scientist?a_aid=thinklikeadatascientist&amp;a_bid=eb49dc22" rel="noopener ugc nofollow" target="_blank"><em class="pk">Think Like a Data Scientist</em></a></p></div></div></div></div>    
</body>
</html>