- en: 'Reinforcement Learning, Part 8: Feature State Construction'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习，第8部分：特征状态构建
- en: 原文：[https://towardsdatascience.com/reinforcement-learning-part-8-feature-state-construction-62e7d2fc5152?source=collection_archive---------4-----------------------#2024-09-21](https://towardsdatascience.com/reinforcement-learning-part-8-feature-state-construction-62e7d2fc5152?source=collection_archive---------4-----------------------#2024-09-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/reinforcement-learning-part-8-feature-state-construction-62e7d2fc5152?source=collection_archive---------4-----------------------#2024-09-21](https://towardsdatascience.com/reinforcement-learning-part-8-feature-state-construction-62e7d2fc5152?source=collection_archive---------4-----------------------#2024-09-21)
- en: Enhancing linear methods by smartly incorporating state features into the learning
    objective
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过智能地将状态特征融入学习目标来增强线性方法
- en: '[](https://medium.com/@slavahead?source=post_page---byline--62e7d2fc5152--------------------------------)[![Vyacheslav
    Efimov](../Images/441e600862b2b93564c6cd81abb0092d.png)](https://medium.com/@slavahead?source=post_page---byline--62e7d2fc5152--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--62e7d2fc5152--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--62e7d2fc5152--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page---byline--62e7d2fc5152--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead?source=post_page---byline--62e7d2fc5152--------------------------------)[![Vyacheslav
    Efimov](../Images/441e600862b2b93564c6cd81abb0092d.png)](https://medium.com/@slavahead?source=post_page---byline--62e7d2fc5152--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--62e7d2fc5152--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--62e7d2fc5152--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page---byline--62e7d2fc5152--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--62e7d2fc5152--------------------------------)
    ·13 min read·Sep 21, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--62e7d2fc5152--------------------------------)
    ·阅读时间13分钟·2024年9月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/91aea78300be2957b1059721e4a216d5.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91aea78300be2957b1059721e4a216d5.png)'
- en: R**einforcement learning** is a domain in machine learning that introduces the
    concept of an agent learning optimal strategies in complex environments. The agent
    learns from its actions, which result in rewards, based on the environment’s state.
    Reinforcement learning is a challenging topic and differs significantly from other
    areas of machine learning.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习（**Reinforcement learning**）是机器学习的一个领域，引入了智能体在复杂环境中学习最优策略的概念。智能体通过其行动来学习，根据环境的状态产生奖励。强化学习是一个具有挑战性的话题，与机器学习的其他领域有显著不同。
- en: What is remarkable about reinforcement learning is that the same algorithms
    can be used to enable the agent adapt to completely different, unknown, and complex
    conditions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的一个显著特点是，相同的算法可以用于使智能体适应完全不同、未知且复杂的环境条件。
- en: About this article
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于本文
- en: In [part 7](https://medium.com/towards-data-science/reinforcement-learning-part-7-introduction-to-value-function-approximation-2e22495f7008),
    we introduced **value-function approximation** algorithms which scale standard
    tabular methods. Apart from that, we particularly focused on a very important
    case when the approximated value function is **linear**. As we found out, the
    linearity provides guaranteed convergence either to the ***global optimum*** or
    to the ***TD fixed point*** (in ***semi-gradient*** methods).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第7部分](https://medium.com/towards-data-science/reinforcement-learning-part-7-introduction-to-value-function-approximation-2e22495f7008)
    中，我们介绍了**价值函数近似**算法，这些算法扩展了标准的表格方法。除此之外，我们特别关注了一个非常重要的情况，即当近似的价值函数是**线性**时。正如我们所发现的，线性化提供了保证的收敛性，能够收敛到***全局最优解***或***TD固定点***（在***半梯度***方法中）。
- en: The problem is that sometimes we might want to use a more complex approximation
    value function, rather than just a simple scalar product, without leaving the
    linear optimization space. The…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，有时我们可能希望使用更复杂的近似价值函数，而不仅仅是一个简单的标量积，同时又不脱离线性优化空间。
