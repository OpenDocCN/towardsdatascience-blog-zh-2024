- en: Of LLMs, Gradients, and Quantum Mechanics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于LLM、梯度和量子力学
- en: 原文：[https://towardsdatascience.com/of-llms-gradients-and-quantum-mechanics-bdcaaf940fbb?source=collection_archive---------6-----------------------#2024-11-12](https://towardsdatascience.com/of-llms-gradients-and-quantum-mechanics-bdcaaf940fbb?source=collection_archive---------6-----------------------#2024-11-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/of-llms-gradients-and-quantum-mechanics-bdcaaf940fbb?source=collection_archive---------6-----------------------#2024-11-12](https://towardsdatascience.com/of-llms-gradients-and-quantum-mechanics-bdcaaf940fbb?source=collection_archive---------6-----------------------#2024-11-12)
- en: Can Quantum Computing help improving our ability to train Large Neural Networks
    encoding language models (LLMs)?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量子计算是否能帮助我们提高训练大型神经网络语言模型（LLM）的能力？
- en: '[](https://riccardo-disipio.medium.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)[![Riccardo
    Di Sipio](../Images/07d5e8829a0bba4f32a91e261378d969.png)](https://riccardo-disipio.medium.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)
    [Riccardo Di Sipio](https://riccardo-disipio.medium.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://riccardo-disipio.medium.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)[![Riccardo
    Di Sipio](../Images/07d5e8829a0bba4f32a91e261378d969.png)](https://riccardo-disipio.medium.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)
    [Riccardo Di Sipio](https://riccardo-disipio.medium.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)
    ·13 min read·Nov 12, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bdcaaf940fbb--------------------------------)
    ·13分钟阅读·2024年11月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c29f7df67db71e4b0399ae2ff25a9683.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c29f7df67db71e4b0399ae2ff25a9683.png)'
- en: Photo by Alessio Soggetti (@asoggetti) from Unsplash.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Alessio Soggetti (@asoggetti) 来自 Unsplash.com
- en: What is “training”?
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是“训练”？
- en: 'In the lingo of Artificial Intelligence (AI) studies, “training” means optimizing
    a statistical *model*, often implemented as a [neural network](https://en.wikipedia.org/wiki/Neural_network_(machine_learning)),
    to make predictions based on some input data and a measure of how good these predictions
    are (“cost” or “loss” function). There are three [main paradigms](https://www.geeksforgeeks.org/supervised-unsupervised-learning/)
    in which such procedure can happen: *supervised*, *unsupervised* (often [autoregressive](https://aws.amazon.com/what-is/autoregressive-models/)),
    and *reinforcement* learning. In **supervised** learning, each data point is labelled
    so the model predictions can be directly compared to the true values (*e.g.* this
    is the image of a cat or a dog). In **unsupervised** training, there are no explicit
    labels, but the comparison is carried out with features extracted from the data
    itself (*e.g.* predicting the next word in a sentence). Finally, **reinforcement**
    learning is based on optimizing the long-term returns of a sequence of decisions
    (predictions) based on the interaction between the statistical model and the environment
    (should the car slow down or speed up at a yellow traffic light?).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能（AI）研究的术语中，“训练”是指优化一个统计*模型*，通常表现为一个[神经网络](https://en.wikipedia.org/wiki/Neural_network_(machine_learning))，使其能够根据输入数据和这些预测的好坏（“成本”或“损失”函数）来做出预测。这样的过程可以通过三种[主要范式](https://www.geeksforgeeks.org/supervised-unsupervised-learning/)来进行：*监督学习*、*无监督学习*（通常是[自回归](https://aws.amazon.com/what-is/autoregressive-models/)的），以及*强化学习*。在**监督学习**中，每个数据点都有标签，因此可以将模型的预测结果与真实值进行直接比较（*例如*：这是猫还是狗的图像）。在**无监督学习**中，没有明确的标签，但通过从数据本身提取的特征进行比较（*例如*：预测句子中的下一个单词）。最后，**强化学习**是基于通过统计模型与环境的互动来优化一系列决策（预测）的长期回报（例如：在黄色交通灯前，汽车应该减速还是加速？）。
- en: In all these cases, the optimization of the **parameters of the model** is a
    lengthy process which requires a…
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些情况下，**模型参数的优化**是一个漫长的过程，需要…
