["```py\ndef construct_translation_prompt(medical_note):\n    \"\"\"\n    Construct a prompt template for translating spanish medical notes to english.\n\n    Args:\n        medical_note (str): The medical case note.\n\n    Returns:\n        str: A structured template ready to be used as input for a language model.\n    \"\"\"    \n    translation_prompt = \"\"\"You are an expert Spanish-to-English translator. You are provided with a clinical note written in Spanish.\nYou must translate the note into English. You must ensure that you properly translate the medical and technical terms from Spanish to English without any mistakes.\nSpanish Medical Note:\n{medical_note}\"\"\"\n\n    return translation_prompt.format(medical_note = medical_note)\n```", "```py\ndef get_icd_codes(medical_note, model_name=\"gpt-3.5-turbo-0613\", temperature=0.0):\n    \"\"\"\n    Identifies relevant ICD-10 codes for a given medical note by querying a language model.\n\n    This function implements the tree-search algorithm for ICD coding described in https://openreview.net/forum?id=mqnR8rGWkn.\n\n    Args:\n        medical_note (str): The medical note for which ICD-10 codes are to be identified.\n        model_name (str): The identifier for the language model used in the API (default is 'gpt-3.5-turbo-0613').\n\n    Returns:\n        list of str: A list of confirmed ICD-10 codes that are relevant to the medical note.\n    \"\"\"\n    assigned_codes = []\n    candidate_codes = [x.name for x in CHAPTER_LIST]\n    parent_codes = []\n    prompt_count = 0\n\n    while prompt_count < 50:\n        code_descriptions = {}\n        for x in candidate_codes:\n            description, code = get_name_and_description(x, model_name)\n            code_descriptions[description] = code\n\n        prompt = build_zero_shot_prompt(medical_note, list(code_descriptions.keys()), model_name=model_name)\n        lm_response = get_response(prompt, model_name, temperature=temperature, max_tokens=500)\n        predicted_codes = parse_outputs(lm_response, code_descriptions, model_name=model_name)\n\n        for code in predicted_codes:\n            if cm.is_leaf(code[\"code\"]):\n                assigned_codes.append(code[\"code\"])\n            else:\n                parent_codes.append(code)\n\n        if len(parent_codes) > 0:\n            parent_code = parent_codes.pop(0)\n            candidate_codes = cm.get_children(parent_code[\"code\"])\n        else:\n            break\n\n        prompt_count += 1\n\n    return assigned_codes\n```", "```py\nimport simple_icd_10_cm as cm\n\ndef get_name_and_description(code, model_name):\n    \"\"\"\n    Retrieve the name and description of an ICD-10 code.\n\n    Args:\n        code (str): The ICD-10 code.\n\n    Returns:\n        tuple: A tuple containing the formatted description and the name of the code.\n    \"\"\"\n    full_data = cm.get_full_data(code).split(\"\\n\")\n    return format_code_descriptions(full_data[3], model_name), full_data[1]\n```", "```py\nprompt_template_dict = {\"gpt-3.5-turbo-0613\" : \"\"\"[Case note]:\n{note}\n[Example]:\n<example prompt>\nGastro-esophageal reflux disease\nEnteropotosis\n\n<response>\nGastro-esophageal reflux disease: Yes, Patient was prescribed omeprazole.\nEnteropotosis: No.\n\n[Task]:\nConsider each of the following ICD-10 code descriptions and evaluate if there are any related mentions in the case note.\nFollow the format in the example precisely.\n\n{code_descriptions}\"\"\",\n\n\"meta-llama/Llama-2-70b-chat-hf\": \"\"\"[Case note]:\n{note}\n\n[Example]:\n<code descriptions>\n* Gastro-esophageal reflux disease\n* Enteroptosis\n* Acute Nasopharyngitis [Common Cold]\n</code descriptions>\n\n<response>\n* Gastro-esophageal reflux disease: Yes, Patient was prescribed omeprazole.\n* Enteroptosis: No.\n* Acute Nasopharyngitis [Common Cold]: No.\n</response>\n\n[Task]:\nFollow the format in the example response exactly, including the entire description before your (Yes|No) judgement, followed by a newline. \nConsider each of the following ICD-10 code descriptions and evaluate if there are any related mentions in the Case note.\n\n{code_descriptions}\"\"\"\n}\n```", "```py\ndef construct_prompt_template(case_note, code_descriptions, model_name):\n    \"\"\"\n    Construct a prompt template for evaluating ICD-10 code descriptions against a given case note.\n\n    Args:\n        case_note (str): The medical case note.\n        code_descriptions (str): The ICD-10 code descriptions formatted as a single string.\n\n    Returns:\n        str: A structured template ready to be used as input for a language model.\n    \"\"\"\n    template = prompt_template_dict[model_name]\n\n    return template.format(note=case_note, code_descriptions=code_descriptions)\n\ndef build_zero_shot_prompt(input_note, descriptions, model_name, system_prompt=\"\"):\n    \"\"\"\n    Build a zero-shot classification prompt with system and user roles for a language model.\n\n    Args:\n        input_note (str): The input note or query.\n        descriptions (list of str): List of ICD-10 code descriptions.\n        system_prompt (str): Optional initial system prompt or instruction.\n\n    Returns:\n        list of dict: A structured list of dictionaries defining the role and content of each message.\n    \"\"\"\n    if model_name == \"meta-llama/Llama-2-70b-chat-hf\":\n        code_descriptions = \"\\n\".join([\"* \" + x for x in descriptions])\n    else:\n        code_descriptions = \"\\n\".join(descriptions)\n\n    input_prompt = construct_prompt_template(input_note, code_descriptions, model_name)\n    return [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": input_prompt}]\n```", "```py\ndef get_response(messages, model_name, temperature=0.0, max_tokens=500):\n    \"\"\"\n    Obtain responses from a specified model via the chat-completions API.\n\n    Args:\n        messages (list of dict): List of messages structured for API input.\n        model_name (str): Identifier for the model to query.\n        temperature (float): Controls randomness of response, where 0 is deterministic.\n        max_tokens (int): Limit on the number of tokens in the response.\n\n    Returns:\n        str: The content of the response message from the model.\n    \"\"\"\n    response = client.chat.completions.create(\n        model=model_name,\n        messages=messages,\n        temperature=temperature,\n        max_tokens=max_tokens\n    )\n    return response.choices[0].message.content\n```", "```py\ndef remove_noisy_prefix(text):\n    # Removing numbers or letters followed by a dot and optional space at the beginning of the string\n    cleaned_text = text.replace(\"* \", \"\").strip()\n    cleaned_text = re.sub(r\"^\\s*\\w+\\.\\s*\", \"\", cleaned_text)\n    return cleaned_text.strip()\n\ndef parse_outputs(output, code_description_map, model_name):\n    \"\"\"\n    Parse model outputs to confirm ICD-10 codes based on a given description map.\n\n    Args:\n        output (str): The model output containing confirmations.\n        code_description_map (dict): Mapping of descriptions to ICD-10 codes.\n\n    Returns:\n        list of dict: A list of confirmed codes and their descriptions.\n    \"\"\"\n    confirmed_codes = []\n    split_outputs = [x for x in output.split(\"\\n\") if x]\n    for item in split_outputs:\n        try:                \n            code_description, confirmation = item.split(\":\", 1)\n            if model_name == \"meta-llama/Llama-2-70b-chat-hf\":\n                code_description = remove_noisy_prefix(code_description)\n\n            if confirmation.lower().strip().startswith(\"yes\"):\n                try:\n                    code = code_description_map[code_description]\n                    confirmed_codes.append({\"code\": code, \"description\": code_description})\n                except Exception as e:\n                    print(str(e) + \" Here\")\n                    continue\n        except:\n            continue\n    return confirmed_codes\n```", "```py\nwhile prompt_count < 50:\n    code_descriptions = {}\n    for x in candidate_codes:\n        description, code = get_name_and_description(x, model_name)\n        code_descriptions[description] = code\n\n    prompt = build_zero_shot_prompt(medical_note, list(code_descriptions.keys()), model_name=model_name)\n    lm_response = get_response(prompt, model_name, temperature=temperature, max_tokens=500)\n    predicted_codes = parse_outputs(lm_response, code_descriptions, model_name=model_name)\n\n    for code in predicted_codes:\n        if cm.is_leaf(code[\"code\"]):\n            assigned_codes.append(code[\"code\"])\n        else:\n            parent_codes.append(code)\n\n    if len(parent_codes) > 0:\n        parent_code = parent_codes.pop(0)\n        candidate_codes = cm.get_children(parent_code[\"code\"])\n    else:\n        break\n\n    prompt_count += 1\n```"]