<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Understanding Ghost Attention in LLaMa 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Understanding Ghost Attention in LLaMa 2</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-ghost-attention-in-llama-2-dba624901586?source=collection_archive---------7-----------------------#2024-01-23">https://towardsdatascience.com/understanding-ghost-attention-in-llama-2-dba624901586?source=collection_archive---------7-----------------------#2024-01-23</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="15d5" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">This blog post explains the Ghost Attention method of fine-tuning introduced in the LLaMa 2 paper.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@mgunton7?source=post_page---byline--dba624901586--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Matthew Gunton" class="l ep by dd de cx" src="../Images/6f5a9530ad5252aa3f2fae87b3f272b1.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*F8sHS2ai6w95qbGIZ9qM_g.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--dba624901586--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@mgunton7?source=post_page---byline--dba624901586--------------------------------" rel="noopener follow">Matthew Gunton</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--dba624901586--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 23, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/92079d14f31ee22d6208bf88a6085700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ROxCQoc9arEMggrm9wMzEw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">DALL-E generated image of a ghost llama</figcaption></figure><h1 id="eec6" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">The Problem</h1><p id="9e6f" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Often times, we want the LLM to be given an instruction once and then follow it until told otherwise. Nevertheless, as the below example shows LLMs can quickly forget instructions after a few turns of dialogue.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ot"><img src="../Images/c6567cf2486a8f3ad6430d77dd67300b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CJM7rkObs_zBJFB1mjlg-w.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Figure 9 from <a class="af ou" href="https://arxiv.org/pdf/2307.09288.pdf" rel="noopener ugc nofollow" target="_blank">the LLaMa 2 paper</a> illustrating how instructions can be ignored after a few turns of dialogue</figcaption></figure><p id="73bb" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">One way to get the model to pay attention consistently is appending the instruction to each user message. While this will work, it comes at the cost of more tokens put into the context, thus limiting how many turns of dialogue your LLM can have. How do we get around this? By fine tuning! Ghost Attention is meant to let the LLM follow instructions for more turns of dialogue.</p><h1 id="64bf" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Methodology Summary</h1><p id="bf7d" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Let’s start by imagining our dialogues as a data array. We have a user message, followed by an assistant message, and the two go back and forth. When the last item in our array is a user message, then we would expect the LLM to generate a message as the assistant.</p><p id="c28d" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">Importantly, we make sure the instruction does not appear in any of the user messages except the first, as in the real world this is likely the only time a user would organically introduce instructions.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pa"><img src="../Images/a3b52797085918892ba91dd8e5f6d763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LA3fz3_Qo9QzZZBUSYb7w.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the Author: The data array showing alternating user and assistant messages</figcaption></figure><p id="1600" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">Also in our setup is a Reinforcement Learning Human Feedback (RLHF) model that we can sample from and know what a good response to the prompt would look like.</p><p id="b6e5" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">With our sample and dialogue, we perform rejection sampling — asking the LLM to generate an arbitrary number of different responses and then scoring them with the RLHF model. We save the response that ranks the highest and use all of these highest quality responses to fine tune the model.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pb"><img src="../Images/a9043cfe3b7e5fe6290874cb1d6f6723.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v8urro0Q7MHw4tI-tWtnXw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the Author: A diagram showing how we create the fine-tuning data that will enable our model to focus on the instruction for multiple turns of dialogue</figcaption></figure><p id="00b0" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">When we fine-tune with our dialogue and best sample, we set the loss to zero for all tokens generated in previous dialogue turns. As far as I can tell, this was done as the researchers noted this improved performance.</p><p id="bd41" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">It is worth calling out that while Ghost Attention will interact with the self-attention mechanism used for Transformer models, Ghost Attention is not itself a replacement for self-attention, rather a way to give the self-attention mechanism better data so it will remember instructions given early on over longer contexts.</p><h1 id="3b34" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Generating Instructions</h1><p id="1bcc" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">The LLaMa 2 paper highlights three specific types of instructions that they tested this with: (1) acting as a public figure, (2) speaking in a certain language, and (3) enjoying specific hobbies. As the set of possible public figures and hobbies is large, they wanted to avoid the LLM being given a hobby or person that wasn’t present in the training data. To solve this, they asked the LLM to generate the list of hobbies and public figures that it would then be instructed to act like; hopefully, if it generated the subject, it was more likely to know things about it and thus less likely to hallucinate. To further improve the data, they would make the instruction as concise as possible. It is not discussed if there are any limits to the types of instructions that could be given, so presumably it is up to us to test what types of instructions work best on models fine-tuned via ghost attention.</p><h1 id="44e4" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Results</h1><p id="e735" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">So what are the effects of this new method on the LLM?</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pc"><img src="../Images/880996860c94ab89e19cb9e590717415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iUyBpEK1ksF7AJFHhewygA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><a class="af ou" href="https://arxiv.org/pdf/2307.09288.pdf" rel="noopener ugc nofollow" target="_blank">Figure 28 from the LLaMa 2 paper</a> showing the results of Ghost Attention on new instructions</figcaption></figure><p id="6f0d" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">In the paper, they attach the above image showing how the model reacts to instructions not found in its fine-tuning data set. On the left, they test the instruction of “always answer with Haiku”, and on the right they test the instruction of suggest architecture-related activities when possible. While the haiku answers seem to miss some syllables as it progresses, there is no doubt it is trying to maintain the general format in each response. The architecture one is especially interesting to me, as you can see the model appropriately does not bring this up in the first message when it is not relevant but does bring it up later.</p><p id="6b90" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">Try this for yourself on lmsys.org’s llama-2 interface. You can see that while it is not as perfect as the screen captures in the paper, it still is far better than the LLaMa 1 versions</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pd"><img src="../Images/56397c860ace11b97085e57e4c320492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hTF9g6uGQ0aFpQZCZlxs3Q.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: a screen capture of llama-2–70b-chat model on chat.lmsys.org following the “respond in emojis” instruction</figcaption></figure><p id="29f1" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">Importantly, we also see that this methodology has an impact on the attention of the model. Below is a heat map graph of the attention given to each token by the model. The left and bottom side of the graph show tokens that are being put into the model. We do not see the top right side of the graph because it is generating the rest, and so the tokens that would appear beyond the current token are not available to the model. As we generate more of the text, we can see that more tokens become available. Heat maps show higher values with darker colors, so the darker the color is here, the more attention being paid to those tokens. We can see that the ‘Act as Oscar Wilde’ tokens get progressively darker as we generate more tokens, suggesting they get paid more and more attention.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pe"><img src="../Images/06756787026f40bb4afdb6b2d321f0a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yF1QKpXbuYBJvyxSA5UnEA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><a class="af ou" href="https://arxiv.org/pdf/2307.09288.pdf" rel="noopener ugc nofollow" target="_blank">Figure 10 from the LLaMa2 Paper</a> showing a heat map of attention before and after Ghost Attention was applied</figcaption></figure><p id="c6bb" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">The paper tells us that after more than 20 turns, the context is often filled, causing issues with the attention. Interestingly, the graph they provide in the appendix also shows that as they kept fine-tuning the model the score assigned to it by the RLHF model kept going down. It would be interesting to see if this is because the instructions were getting longer, due to their complexity for each subsequent batch, or if this was somehow related to a limitation of the data they were using to train the model. If the second, then it’s possible that with more training data you could go through even more batches before seeing the score decrease. Either way, there may be diminishing returns to fine-tuning via Ghost Attention.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pf"><img src="../Images/70291ed31a98a5d7b502fdd9ddd24b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*05LhcX2Ceg_fHNkZsN1biA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><a class="af ou" href="https://arxiv.org/pdf/2307.09288.pdf" rel="noopener ugc nofollow" target="_blank">Figure 26 from the LLaMa 2 paper</a> showing how the reward model scored prompt samples after each batch</figcaption></figure></div></div></div><div class="ab cb pg ph pi pj" role="separator"><span class="pk by bm pl pm pn"/><span class="pk by bm pl pm pn"/><span class="pk by bm pl pm"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="8b55" class="nb nc fq bf nd ne po gq ng nh pp gt nj nk pq nm nn no pr nq nr ns ps nu nv nw bk">Closing Thoughts</h1><p id="313e" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">In closing, the LLaMa2 paper introduced many interesting training techniques for LLMs. As the field has had ground-breaking research published seemingly every day, there are some interesting questions that arise when we look back at this critical paper and Ghost Attention in particular.</p><p id="f61a" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">As Ghost Attention is one way to fine-tune a model using the Proximal Policy Optimization (PPO) technique, one critical question is how this method fares when we use Direct Preference Optimization(DPO). DPO does not require a separate RLHF model to be trained and then sampled from to generate good fine-tuning data, so the loss set in Ghost Attention may simply become unnecessary, potentially greatly improving the results from the technique.</p><p id="1e26" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">As LLMs are used for more consumer applications, the need to keep the LLM focused on instructions will only increase. Ghost Attention shows great promise for training an LLM to maintain its focus through multiple turns of dialogue. Time will tell just how far into a conversation the LLM can maintain its attention on the instruction.</p><p id="ee4e" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">Thanks for reading!</p><p id="064d" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">[1] H. Touvron, et al., <a class="af ou" href="https://arxiv.org/abs/2307.09288" rel="noopener ugc nofollow" target="_blank">Llama 2: Open Foundation and Fine-Tuned Chat Models (2023)</a>, arXiv</p><p id="45ac" class="pw-post-body-paragraph nx ny fq nz b go ov ob oc gr ow oe of og ox oi oj ok oy om on oo oz oq or os fj bk">[2] R. Rafailov, et al., <a class="af ou" href="https://arxiv.org/abs/2305.18290" rel="noopener ugc nofollow" target="_blank">Direct Preference Optimization: Your Language Model is Secretly a Reward Model (2023)</a>, arXiv</p></div></div></div></div>    
</body>
</html>