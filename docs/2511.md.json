["```py\npip install sdv\n```", "```py\nfrom sklearn.datasets import load_iris\nfrom sdv.single_table import GaussianCopulaSynthesizer\nfrom sdv.metadata.metadata import Metadata\n\ndata = load_iris(return_X_y=False, as_frame=True)\nreal_data = data[\"data\"]\n\n# metadata of the `iris` dataset\nmetadata = Metadata().load_from_dict({\n    \"tables\": {\n        \"iris\": {\n            \"columns\": {\n                \"sepal length (cm)\": {\n                    \"sdtype\": \"numerical\",\n                    \"computer_representation\": \"Float\"\n                },\n                \"sepal width (cm)\": {\n                    \"sdtype\": \"numerical\",\n                    \"computer_representation\": \"Float\"\n                },\n                \"petal length (cm)\": {\n                    \"sdtype\": \"numerical\",\n                    \"computer_representation\": \"Float\"\n                },\n                \"petal width (cm)\": {\n                    \"sdtype\": \"numerical\",\n                    \"computer_representation\": \"Float\"\n                }\n            },\n            \"primary_key\": None\n        }\n    },\n    \"relationships\": [],\n    \"METADATA_SPEC_VERSION\": \"V1\"\n})\n\n# train the synthesizer\nsynthesizer = GaussianCopulaSynthesizer(metadata)\nsynthesizer.fit(data=real_data)\n# generate samples - in this case, \n# synthetic_data has the same shape as real_data\nsynthetic_data = synthesizer.sample(num_rows=150)\n```", "```py\nimport pandas as pd \nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef classification_evaluation(\n  real_data: pd.DataFrame, \n  synthetic_data: pd.DataFrame\n) -> float:\n\n    X = pd.concat((real_data, synthetic_data))\n    y = np.concatenate(\n        (\n            np.zeros(real_data.shape[0]),\n            np.ones(synthetic_data.shape[0])\n        )\n    )\n\n    Xtrain, Xtest, ytrain, ytest = train_test_split(\n        X,\n        y,\n        test_size=0.2,\n        stratify=y\n    )\n\n    clf = RandomForestClassifier()\n    clf.fit(Xtrain, ytrain)\n    score = accuracy_score(clf.predict(Xtest), ytest)\n\n    return score\n\nclassification_evaluation(real_data, synthetic_data)\n>>> 0.9\n```", "```py\nimport pandas as pd\nfrom scipy.stats import ks_2samp\n\ndef univariate_distributions_tests(\n  real_data: pd.DataFrame, \n  synthetic_data: pd.DataFrame\n) -> None:\n    for col in real_data.columns:\n        if real_data[col].dtype.kind in \"biufc\": \n            stat, p_value = ks_2samp(real_data[col], synthetic_data[col])\n            print(f\"Column: {col}\")\n            print(f\"P-value: {p_value:.4f}\")\n            print(\"Significantly different\" if p_value < 0.05 else \"Not significantly different\")\n            print(\"---\")\n```", "```py\nunivariate_distributions_tests(real_data, synthetic_data)\n\n>>> Column: sepal length (cm)\nP-value: 0.9511\nNot significantly different\n---\nColumn: sepal width (cm)\nP-value: 0.0000\nSignificantly different\n---\nColumn: petal length (cm)\nP-value: 0.0000\nSignificantly different\n---\nColumn: petal width (cm)\nP-value: 0.1804\nNot significantly different\n---\n```", "```py\npip install umap-learn\n```", "```py\nimport pandas as pd\nimport seaborn as sns\nimport umap\nimport matplotlib.pyplot as plt\n\ndef plot(\n  real_data: pd.DataFrame, \n  synthetic_data: pd.DataFrame, \n  kind: str = \"pairplot\"\n):\n\n    assert kind in [\"umap\", \"pairplot\"]\n    real_data[\"label\"] = \"real\"\n    synthetic_data[\"label\"] = \"synthetic\"\n    X = pd.concat((real_data, synthetic_data))\n\n    if kind == \"pairplot\":\n        sns.pairplot(X, hue=\"label\")\n\n    elif kind == \"umap\": \n        reducer = umap.UMAP()\n        embedding = reducer.fit_transform(X.drop(\"label\", axis=1))\n        plt.scatter(\n            embedding[:, 0],\n            embedding[:, 1],\n            c=[sns.color_palette()[x] for x in X[\"label\"].map({\"real\":0, \"synthetic\":1})],\n            s=30,\n            edgecolors=\"white\"\n        )\n        plt.gca().set_aspect('equal', 'datalim')\n        sns.despine(top=True, right=True, left=False, bottom=False)\n```", "```py\nplot(real_data, synthetic_data, kind=\"pairplot\")\n```", "```py\nplot(real_data, synthetic_data, kind=\"umap\")\n```", "```py\nimport pandas as pd \nfrom typing import Tuple\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef tstr(\n  real_data: pd.DataFrame, \n  synthetic_data: pd.DataFrame, \n  target: str = None\n) -> Tuple[float]:\n\n    # if no target is specified, use the last column of the dataset\n    if target is None: \n        target = real_data.columns[-1]\n\n    X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n        real_data.drop(target, axis=1), \n        real_data[target],\n        test_size=0.2\n    )\n\n    X_synthetic, y_synthetic = synthetic_data.drop(target, axis=1), synthetic_data[target]\n    # create regressors (could have been classifiers)\n    reg_real = RandomForestRegressor()\n    reg_synthetic = RandomForestRegressor()\n    # train the models\n    reg_real.fit(X_real_train, y_real_train)\n    reg_synthetic.fit(X_synthetic, y_synthetic)\n    # evaluate \n    trtr_score = reg_real.score(X_real_test, y_real_test)\n    tstr_score = reg_synthetic.score(X_real_test, y_real_test)\n\n    return trtr_score, tstr_score\n```", "```py\ntstr(real_data, synthetic_data)\n>>> (0.918261846477529, 0.5644428690930647)\n```"]