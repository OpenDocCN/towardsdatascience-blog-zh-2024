<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Implementing “Modular RAG” with Haystack and Hypster</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Implementing “Modular RAG” with Haystack and Hypster</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-modular-rag-with-haystack-and-hypster-d2f0ecc88b8f?source=collection_archive---------3-----------------------#2024-10-18">https://towardsdatascience.com/implementing-modular-rag-with-haystack-and-hypster-d2f0ecc88b8f?source=collection_archive---------3-----------------------#2024-10-18</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="abe6" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Transforming RAG systems into LEGO-like reconfigurable frameworks</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@giladrubin?source=post_page---byline--d2f0ecc88b8f--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Gilad Rubin" class="l ep by dd de cx" src="../Images/e98728582365c22c2803d5db0a0f3ca6.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*2eQSgutUIAdpKBsPCsFAfw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d2f0ecc88b8f--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@giladrubin?source=post_page---byline--d2f0ecc88b8f--------------------------------" rel="noopener follow">Gilad Rubin</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d2f0ecc88b8f--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 18, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/665f1ebb6e484102c452f4295f32035a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vy_nGYth-rPVRBWwogf8sA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image Generated using <a class="af nc" href="https://www.midjourney.com/" rel="noopener ugc nofollow" target="_blank">Midjourney AI</a>, Prompted by the author</figcaption></figure><h1 id="2876" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Intro</h1><p id="34b5" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Keeping up with the latest in AI can be a challenge, especially when it comes to an increasingly evolving field like Retrieval Augmented Generation (RAG). With so many different solutions and implementations, one can easily feel lost.</p><p id="3579" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I struggled with this myself for a long time, trying to wrap my head around every new article or “trick” to make RAG systems better in one way or another. Every new paper, tutorial or blogpost felt like something completely new and it became increasingly difficult to keep up with all the acronyms for all the newest fancy methods - HyDE, RAPTOR, CRAG, FLARE — they started to sound like Pokémon character names to me.</p><p id="45e0" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Then I came across this paper by Gao et al. (2024) “<a class="af nc" href="https://arxiv.org/abs/2407.21059" rel="noopener ugc nofollow" target="_blank"><strong class="ob fr">Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks”</strong></a><strong class="ob fr">.</strong></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pa"><img src="../Images/c9f2768a8d8fb903c8fa98e34bd40d0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w1TvQzAylcTQFPib9jrh-A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">The main figure from the paper that shows the components from which the authors construct RAG solutions. Source: <a class="af nc" href="https://arxiv.org/abs/2407.21059" rel="noopener ugc nofollow" target="_blank">Modular RAG</a></figcaption></figure><h1 id="4ea2" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Modular RAG</h1><p id="fb24" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">This paper provides a structured approach for breaking down RAG systems into a unified framework that can encompass diverse solutions and approaches. They proposed six main components:</p><ul class=""><li id="ed15" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pb pc pd bk"><strong class="ob fr">Indexing:</strong> Organize your data for efficient search.</li><li id="6163" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk"><strong class="ob fr">Pre-Retrieval:</strong> Process the user’s query before searching.</li><li id="e5b4" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk"><strong class="ob fr">Retrieval:</strong> Find the most relevant information.</li><li id="ffcb" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk"><strong class="ob fr">Post-Retrieval:</strong> Refine the retrieved information.</li><li id="3580" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk"><strong class="ob fr">Generation:</strong> Use an LLM to generate a response.</li><li id="1e05" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk"><strong class="ob fr">Orchestration:</strong> Control the overall flow of the system.</li></ul><p id="e7a5" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The key insight from this paper is that a wide range of existing RAG solutions can be described using these components in a LEGO-like manner. This modularity provides a framework for understanding, designing, and navigating the process of building a RAG system with greater flexibility and clarity.</p><p id="5807" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In the paper, the authors showcase how this is possible by taking examples of existing RAG solutions and expressing them using the same building blocks. For example:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pj"><img src="../Images/d41279dd94909e693a0427b0faab823b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MUMgGco5vXqxugTPar3_1w.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><strong class="bf nf">Adaptive RAG flow</strong> - where the “judge” decides whether or not to use retrieval. Source: <a class="af nc" href="https://arxiv.org/abs/2407.21059" rel="noopener ugc nofollow" target="_blank">Modular RAG</a></figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pk"><img src="../Images/818a2c6d61007b364397301bf777d21f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zEU89QcphytbdPMIB7vbYw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><strong class="bf nf">FLARE - F</strong>orward-<strong class="bf nf">L</strong>ooking <strong class="bf nf">A</strong>ctive <strong class="bf nf">RE</strong>trieval where each sentence can trigger a retrieval step. Source: <a class="af nc" href="https://arxiv.org/abs/2407.21059" rel="noopener ugc nofollow" target="_blank">Modular RAG</a></figcaption></figure><p id="a492" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I highly recommend reading this paper and the set of blog-posts by the author of the paper, Yunfan Gao: Modular RAG and RAG Flow: <a class="af nc" href="https://medium.com/@yufan1602/modular-rag-and-rag-flow-part-%E2%85%B0-e69b32dc13a3" rel="noopener">Part I</a>, <a class="af nc" href="https://medium.com/@yufan1602/modular-rag-and-rag-flow-part-ii-77b62bf8a5d3" rel="noopener">Part II</a>.</p><p id="73b0" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Personally, this framework helped me understand how different RAG approaches relate to each other, and now I can easily make sense of new papers and implementations.</p><h1 id="c5d0" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Implementing Modular RAG</h1><p id="93b3" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">So, how can we actually implement this “Modular RAG” framework?</p><p id="bc6e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Since it’s more of a meta-framework — what does that mean in practical terms? Does it mean that we need to implement <em class="pl">all</em> the possible combinations of components? Or do we just build the individual components and let developers figure out how to put them together?</p><p id="ad3d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I believe that in most real-life situations — it’s not necessary to try to cover <em class="pl">every</em> possible RAG configuration, but to narrow down the space of relevant configurations based on the requirements and constraints of each project.</p><p id="6ab6" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In this tutorial, I’ll show you a concrete example of how to build a configurable system using a small set of options. Hopefully, this will give you the right perspective and tools to create your own version of a Modular RAG that contains the set of relevant configurations for your specific use-case.</p><p id="abd4" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Let’s go on to explore the two main tools we’ll be using:</p><h1 id="ef75" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Haystack — The Main Components Library</h1><p id="1f58" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk"><code class="cx pm pn po pp b">haystack</code> is an open-source framework for building production-ready LLM applications, retrieval-augmented generative pipelines and state-of-the-art search systems that work intelligently over large document collections.</p><div class="pq pr ps pt pu pv"><a href="https://haystack.deepset.ai/?source=post_page-----d2f0ecc88b8f--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pw ab ig"><div class="px ab co cb py pz"><h2 class="bf fr hw z io qa iq ir qb it iv fp bk">Haystack | Haystack</h2><div class="qc l"><h3 class="bf b hw z io qa iq ir qb it iv dx">Haystack, the composable open-source AI framework</h3></div><div class="qd l"><p class="bf b dy z io qa iq ir qb it iv dx">haystack.deepset.ai</p></div></div><div class="qe l"><div class="qf l qg qh qi qe qj lr pv"/></div></div></a></div><p id="73a1" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><strong class="ob fr">Pros:</strong></p><ul class=""><li id="6da8" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pb pc pd bk">Great component design</li><li id="7feb" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk">The pipeline is very flexible and allows for dynamic configurations</li><li id="7e0b" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk">Extremely (!) well documented</li><li id="ff31" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk">The framework includes many existing implementations and integrations with Generative AI providers.</li></ul><p id="7f99" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><strong class="ob fr">Cons:</strong></p><ul class=""><li id="f145" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pb pc pd bk">The pipeline interface can be a bit verbose</li><li id="e54f" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk">Using components outside of a pipeline is not very ergonomic.</li></ul><p id="84df" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I’ve played around with a few different Generative AI frameworks, and Haystack was by far the easiest for me to understand, use and customize.</p><h1 id="471f" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Hypster — Managing Configuration Spaces</h1><p id="be5d" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk"><code class="cx pm pn po pp b"><strong class="ob fr">hypster</strong></code> is a lightweight pythonic configuration system for AI &amp; Machine Learning projects. It offers minimal, intuitive pythonic syntax, supporting hierarchical and swappable configurations.</p><div class="pq pr ps pt pu pv"><a href="https://medium.com/@giladrubin/introducing-hypster-a-pythonic-framework-for-managing-configurations-to-build-highly-optimized-ai-5ee004dbd6a5?source=post_page-----d2f0ecc88b8f--------------------------------" rel="noopener follow" target="_blank"><div class="pw ab ig"><div class="px ab co cb py pz"><h2 class="bf fr hw z io qa iq ir qb it iv fp bk">Introducing HyPSTER: A Pythonic Framework for Managing Configurations to Build Highly Optimized AI…</h2><div class="qc l"><h3 class="bf b hw z io qa iq ir qb it iv dx">Image by the Author</h3></div><div class="qd l"><p class="bf b dy z io qa iq ir qb it iv dx">medium.com</p></div></div><div class="qe l"><div class="qk l qg qh qi qe qj lr pv"/></div></div></a></div><p id="848e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Hypster is a new open-source project that I’ve developed to enable a new kind of programming paradigm for AI &amp; ML workflows — one that moves beyond single solutions towards a “superposition of workflows” or a “hyper-workflow.”</p><p id="fb57" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Hypster allows you to define a range of possible configurations and easily switch between them for experimentation and optimization. This makes it simple to add and customize your own configuration spaces, instantiate them with different settings, and ultimately select the optimal configuration for your production environment.</p><p id="ecd4" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><strong class="ob fr">Note:</strong> Hypster is currently under active development. It is not yet recommended for production environments.</p><h1 id="ad18" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Codebase</h1><p id="2944" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk"><strong class="ob fr">This is an advanced tutorial.</strong> It assumes you’re already familiar with the main components of RAG.</p><p id="4320" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I’ll break down the main parts of the codebase and provide my insights as we go.</p><p id="e68d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The full and updated code is in the following repository. Don’t forget to add your ⭐️</p><div class="pq pr ps pt pu pv"><a href="https://github.com/gilad-rubin/modular-rag?source=post_page-----d2f0ecc88b8f--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pw ab ig"><div class="px ab co cb py pz"><h2 class="bf fr hw z io qa iq ir qb it iv fp bk">GitHub - gilad-rubin/modular-rag</h2><div class="qc l"><h3 class="bf b hw z io qa iq ir qb it iv dx">Contribute to gilad-rubin/modular-rag development by creating an account on GitHub.</h3></div><div class="qd l"><p class="bf b dy z io qa iq ir qb it iv dx">github.com</p></div></div><div class="qe l"><div class="ql l qg qh qi qe qj lr pv"/></div></div></a></div><h1 id="2075" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">LLM</h1><p id="7681" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s start with our LLM configuration-space definition:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="f20c" class="qp ne fq pp b bg qq qr l qs qt">from hypster import config, HP</span></pre><pre class="qu qm pp qn bp qo bb bk"><span id="9080" class="qp ne fq pp b bg qq qr l qs qt">@config<br/>def llm_config(hp: HP):<br/>  anthropic_models = {"haiku": "claude-3-haiku-20240307", <br/>                      "sonnet": "claude-3-5-sonnet-20240620"}<br/>  openai_models = {"gpt-4o-mini": "gpt-4o-mini", <br/>                   "gpt-4o": "gpt-4o", <br/>                   "gpt-4o-latest": "gpt-4o-2024-08-06"}<br/>  <br/>  model_options = {**anthropic_models, **openai_models}<br/>  model = hp.select(model_options, default="gpt-4o-mini")<br/>  temperature = hp.number(0.0)<br/>  <br/>  if model in openai_models.values():<br/>    from haystack.components.generators import OpenAIGenerator<br/>    <br/>    llm = OpenAIGenerator(model=model, <br/>                          generation_kwargs={"temperature": temperature})<br/>  else: #anthropic<br/>    from haystack_integrations.components.generators.anthropic import AnthropicGenerator<br/>    <br/>    llm = AnthropicGenerator(model=model, <br/>                             generation_kwargs={"temperature": temperature})</span></pre><p id="f9bd" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">This code snippet demonstrates a basic example of Hypster and Haystack. Using the <code class="cx pm pn po pp b">@config</code> decorator, we define a function called <code class="cx pm pn po pp b">llm_config</code> that encapsulates the configuration space for our LLM. This space includes options for selecting different LLM providers (Anthropic or OpenAI) and their corresponding models, as well as a parameter for controlling the temperature.</p><p id="329f" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Within the <code class="cx pm pn po pp b">llm_config</code> function, we use conditional logic to instantiate the appropriate Haystack component based on the selected model. This allows us to seamlessly switch between different LLMs using a selection without modifying the structure of our code.</p><p id="e89d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">For example, to create an Anthropic generator with the “haiku” model and a temperature of 0.5, we can instantiate the configuration as follows:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="f3eb" class="qp ne fq pp b bg qq qr l qs qt">result = llm_config(final_vars=["llm"], <br/>                    values={"model" : "haiku", "temperature" : 0.5})</span></pre><h1 id="cac1" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Indexing pipeline</h1><p id="e6ba" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s move on to create our indexing pipeline, where we’ll define how to process our input files. In our case — PDF files.</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="a185" class="qp ne fq pp b bg qq qr l qs qt">@config<br/>def indexing_config(hp: HP):<br/>    from haystack import Pipeline<br/>    from haystack.components.converters import PyPDFToDocument<br/>    pipeline = Pipeline()<br/>    pipeline.add_component("loader", PyPDFToDocument())</span></pre><p id="e6d3" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Next, we’ll add an optional functionality — enriching the document with an LLM summary based on the first 1000 characters of the document.</p><p id="fbdc" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">This is a nice trick where we use the first <code class="cx pm pn po pp b">n</code> characters of a document and then, upon splitting the document into chunks, each chunk "inherits" this enriched information for its embeddings and response generation.</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="ce62" class="qp ne fq pp b bg qq qr l qs qt">  enrich_doc_w_llm = hp.select([True, False], default=True)<br/>  if enrich_doc_w_llm:<br/>    from textwrap import dedent<br/>    from haystack.components.builders import PromptBuilder<br/>    from src.haystack_utils import AddLLMMetadata<br/>    <br/>    template = dedent("""<br/>        Summarize the document's main topic in one sentence (15 words max). <br/>        Then list 3-5 keywords or acronyms that best \<br/>        represent its content for search purposes.<br/>        Context:<br/>        {{ documents[0].content[:1000] }}<br/>        <br/>        ============================<br/>        <br/>        Output format:<br/>        Summary:<br/>        Keywords:<br/>    """)<br/>    <br/>    llm = hp.nest("configs/llm.py")<br/>    pipeline.add_component("prompt_builder", PromptBuilder(template=template))<br/>    pipeline.add_component("llm", llm["llm"])<br/>    pipeline.add_component("document_enricher", AddLLMMetadata())<br/>    <br/>    pipeline.connect("loader", "prompt_builder")<br/>    pipeline.connect("prompt_builder", "llm")<br/>    pipeline.connect("llm", "document_enricher")<br/>    pipeline.connect("loader", "document_enricher")<br/>    splitter_source = "document_enricher"<br/>  else:<br/>    splitter_source = "loader"<br/>  <br/>  split_by = hp.select(["sentence", "word", "passage", "page"], <br/>                       default="sentence")<br/>  splitter = DocumentSplitter(split_by=split_by, <br/>                              split_length=hp.int(10), <br/>                              split_overlap=hp.int(2))<br/>  pipeline.add_component("splitter", splitter)<br/>  pipeline.connect(splitter_source, "splitter")</span></pre><p id="b51d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Here we can see Haystack’s pipeline in action. If the user selects <code class="cx pm pn po pp b">enrich_doc_w_llm==True</code> we go on to add components and connections that enable this enrichment. In our case: PromptBuilder → LLM → AddLLMMetadata.</p><p id="2310" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">As you can see — it’s very flexible and we can construct it on-the-fly using conditional logic. This is extremely powerful.</p><p id="43a1" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Now we can instantiate the configuration object in a couple of ways. For example:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="20d4" class="qp ne fq pp b bg qq qr l qs qt">results = indexing_config(values={"enrich_doc_w_llm": False, <br/>                                  "split_by" : "page", <br/>                                  "split_length" : 1})</span></pre><p id="98ce" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Here we get a simple pipeline with a loader and a splitter, with the selected splitter configurations</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qv"><img src="../Images/fd78f82144e6a23775f181cf847f5c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0RyrVme3h6e5WDwzDXKQ5Q.png"/></div></div></figure><p id="67d2" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Otherwise, we can select to enrich the document with an LLM summary:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="74d0" class="qp ne fq pp b bg qq qr l qs qt">results = indexing_config(values={"enrich_doc_w_llm": True})</span></pre><p id="4894" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Notice that Hypster takes on default values that are defined in each parameter, so there’s no need to specify all the parameter selections every time. Here’s an illustration of the resulting pipeline:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/424c4b7586fb3b12cf3330291cca6f42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*agJkWCuvDos1oH9myverQw.png"/></div></div></figure><p id="875b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Notice how we casually inserted the <code class="cx pm pn po pp b">llm_config</code> inside our indexing pipeline using <code class="cx pm pn po pp b">hp.nest(“configs/llm_config.py")</code>. This nesting ability lets us create nested configurations in a hierarchical way. We can define parameters values within the nested <code class="cx pm pn po pp b">llm_config</code> using dot notation. For example:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="6e7f" class="qp ne fq pp b bg qq qr l qs qt">results = indexing_config(values={"llm.model" : "gpt-4o-latest"})</span></pre><p id="0efb" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">This will result in instantiating an indexing pipeline with the LLM enrichment task using the OpenAI <code class="cx pm pn po pp b">gpt-4o-2024–08</code> model.</p></div></div></div><div class="ab cb qx qy qz ra" role="separator"><span class="rb by bm rc rd re"/><span class="rb by bm rc rd re"/><span class="rb by bm rc rd"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="5ac3" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">So far, we’ve built a compact configuration space for many potential indexing pipelines.</p><p id="91a7" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">For the sake of brevity, I will skip over the embedding configuration, where I incorporated <code class="cx pm pn po pp b">fastembed</code> and <code class="cx pm pn po pp b">jina</code> embeddings. If you're curious, please check out the <a class="af nc" href="https://github.com/gilad-rubin/modular-rag" rel="noopener ugc nofollow" target="_blank">full implementation</a>.</p><p id="e119" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Let’s move on to the retrieval pipeline.</p><h1 id="fff6" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Retrieval</h1><p id="0f74" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Haystack comes with an in-memory document store for fast experimentation. It includes an embedding retriever and a BM25 retriever. In this section — we’ll build a configuration space that enables using either a BM25, an embedding retriever or both.</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="80d3" class="qp ne fq pp b bg qq qr l qs qt">@config<br/>def in_memory_retrieval(hp: HP):<br/>  from haystack import Pipeline<br/>  from haystack.document_stores.in_memory import InMemoryDocumentStore<br/>  from src.haystack_utils import PassThroughDocuments, PassThroughText<br/><br/>  pipeline = Pipeline()<br/>  # utility components for the first and last parts of the pipline  <br/>  pipeline.add_component("query", PassThroughText())<br/>  pipeline.add_component("retrieved_documents", PassThroughDocuments())<br/>  <br/>  retrieval_types = hp.multi_select(["bm25", "embeddings"], <br/>                                    default=["bm25", "embeddings"])<br/>  if len(retrieval_types) == 0:<br/>      raise ValueError("At least one retrieval type must be selected.")<br/>  <br/>  document_store = InMemoryDocumentStore()<br/>  <br/>  if "embedding" in retrieval_types:<br/>    from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever<br/>    embedding_similarity_function = hp.select(["cosine", "dot_product"], default="cosine")<br/>    document_store.embedding_similarity_function = embedding_similarity_function<br/>    pipeline.add_component("embedding_retriever", InMemoryEmbeddingRetriever(document_store=document_store))<br/><br/>  if "bm25" in retrieval_types:<br/>    from haystack.components.retrievers.in_memory import InMemoryBM25Retriever<br/>    bm25_algorithm = hp.select(["BM25Okapi", "BM25L", "BM25Plus"], default="BM25L")<br/>    document_store.bm25_algorithm = bm25_algorithm<br/>    pipeline.add_component("bm25_retriever", InMemoryBM25Retriever(document_store=document_store))<br/>    pipeline.connect("query", "bm25_retriever")<br/><br/>  if len(retrieval_types) == 2:  # both bm25 and embeddings<br/>    from haystack.components.joiners.document_joiner import DocumentJoiner<br/><br/>    bm25_weight = hp.number(0.5)<br/>    join_mode = hp.select(["distribution_based_rank_fusion", <br/>                          "concatenate", "merge", <br/>                          "reciprocal_rank_fusion"],<br/>                          default="distribution_based_rank_fusion")<br/>    joiner = DocumentJoiner(join_mode=join_mode, top_k=hp.int(10),<br/>                            weights=[bm25_weight, 1-bm25_weight])<br/><br/>    pipeline.add_component("document_joiner", joiner)<br/>    pipeline.connect("bm25_retriever", "document_joiner")<br/>    pipeline.connect("embedding_retriever", "document_joiner")<br/>    pipeline.connect("document_joiner", "retrieved_documents")<br/>  elif "embeddings" in retrieval_types: #only embeddings retriever<br/>    pipeline.connect("embedding_retriever", "retrieved_documents")<br/>  else:  # only bm25<br/>    pipeline.connect("bm25_retriever", "retrieved_documents")</span></pre><p id="da49" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Here, we’re using a couple of “tricks” to make it work. First of all, we use <code class="cx pm pn po pp b">hp.multi_select</code> which allows us to select multiple options from the options. Second, we add “helper” components from the start and end of the pipeline (PassThroughText, PassThroughDocuments) to make sure that any selection will start with <code class="cx pm pn po pp b">query</code>and end with <code class="cx pm pn po pp b">retrieved_documents</code> and the rest is relatively straightforward.</p><p id="6c87" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">A couple of example instantiations would be:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="8120" class="qp ne fq pp b bg qq qr l qs qt">in_memory_retrieval(values={"retrieval_types": ["bm25"], <br/>                                "bm25_algorithm": "BM25Okapi"})</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rf"><img src="../Images/b0c0e300e43b6f5eb2180093b5aec6f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iPVAJeEEVot-EWQ0abBgdQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by the author</figcaption></figure><p id="c47d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">And:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="8bec" class="qp ne fq pp b bg qq qr l qs qt">in_memory_retrieval(values={"join_mode": "reciprocal_rank_fusion"})</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rg"><img src="../Images/7a2b2312dbc0d40475e14fe896db9c3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qhXNPsOYwSrQqMsEthsr3Q.png"/></div></div></figure></div></div></div><div class="ab cb qx qy qz ra" role="separator"><span class="rb by bm rc rd re"/><span class="rb by bm rc rd re"/><span class="rb by bm rc rd"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="8d61" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In the full implementation, I’ve added a Qdrant vector store, an optional reranking step, and a final generation pipeline. These are all meant as examples to show the possibilities of adding and customizing the different components in these pipelines and you can find them as well in the full repository.</p><p id="cbdf" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Eventually, we have the main config that binds all of these settings together:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="0d8e" class="qp ne fq pp b bg qq qr l qs qt">@config<br/>def rag_config(hp: HP):<br/>  indexing = hp.nest("configs/indexing.py")<br/>  indexing_pipeline = indexing["pipeline"]<br/>  <br/>  embedder_type = hp.select(["fastembed", "jina"], default="fastembed")<br/>  match embedder_type:<br/>    case "fastembed":<br/>      embedder = hp.nest("configs/fast_embed.py")<br/>    case "jina":<br/>      embedder = hp.nest("configs/jina_embed.py")<br/>  <br/>  indexing_pipeline.add_component("doc_embedder", embedder["doc_embedder"])<br/>  document_store_type = hp.select(["in_memory", "qdrant"], <br/>                                  default="in_memory")<br/>  match document_store_type:<br/>    case "in_memory":<br/>      retrieval = hp.nest("configs/in_memory_retrieval.py")<br/>    case "qdrant":<br/>      retrieval = hp.nest("configs/qdrant_retrieval.py", <br/>                  values={"embedding_dim": embedder["embedding_dim"]})<br/>  <br/>  from haystack.components.writers import DocumentWriter<br/>  from haystack.document_stores.types import DuplicatePolicy<br/>  <br/>  document_writer = DocumentWriter(retrieval["document_store"], <br/>                                   policy=DuplicatePolicy.OVERWRITE)<br/>  indexing_pipeline.add_component("document_writer", document_writer)<br/>  indexing_pipeline.connect("splitter", "doc_embedder")<br/>  indexing_pipeline.connect("doc_embedder", "document_writer")<br/>  <br/>  # Retrieval + Generation Pipeline<br/>  pipeline = retrieval["pipeline"]<br/>  pipeline.add_component("text_embedder", embedder["text_embedder"])<br/>  pipeline.connect("query", "text_embedder")<br/>  pipeline.connect("text_embedder", "embedding_retriever.query_embedding")<br/>  <br/>  from src.haystack_utils import PassThroughDocuments<br/>  pipeline.add_component("docs_for_generation", PassThroughDocuments())<br/>  <br/>  use_reranker = hp.select([True, False], default=True)<br/>  if use_reranker:<br/>      reranker = hp.nest("configs/reranker.py")<br/>      pipeline.add_component("reranker", reranker["reranker"])<br/>      pipeline.connect("retrieved_documents", "reranker")<br/>      pipeline.connect("reranker", "docs_for_generation")<br/>      pipeline.connect("query", "reranker")<br/>  else:<br/>      pipeline.connect("retrieved_documents", "docs_for_generation")<br/>  <br/>  response = hp.nest("configs/response.py")<br/>  from haystack.components.builders import PromptBuilder<br/>  pipeline.add_component("prompt_builder", PromptBuilder(template=response["template"]))<br/>  pipeline.add_component("llm", response["llm"])<br/>  pipeline.connect("prompt_builder", "llm")<br/>  pipeline.connect("query.text", "prompt_builder.query")<br/>  pipeline.connect("docs_for_generation", "prompt_builder")</span></pre><p id="4a49" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">from here we can define pretty much anything we want inside any of the sub-components. For example:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="24ed" class="qp ne fq pp b bg qq qr l qs qt">results = rag_config(values={"indexing.enrich_doc_w_llm": True,<br/>                             "indexing.llm.model": "gpt-4o-mini",<br/>                             "document_store": "qdrant",<br/>                             "embedder_type": "fastembed",<br/>                             "reranker.model": "tiny-bert-v2",<br/>                             "response.llm.model": "sonnet",<br/>                             "indexing.splitter.split_length": 6,<br/>                             "reranker.top_k": 3})</span></pre><p id="28d8" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">And we’ve instantiated a concrete set of working pipelines:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rh"><img src="../Images/e6833095970f9a1928cfc184f1db1d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gt4RnGki5x2iqvtrtOqw0A.png"/></div></div></figure><p id="88d9" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We can now execute them sequentially:</p><pre class="mm mn mo mp mq qm pp qn bp qo bb bk"><span id="2e37" class="qp ne fq pp b bg qq qr l qs qt">indexing_pipeline = results["indexing_pipeline"]<br/>indexing_pipeline.warm_up()<br/><br/>file_paths = ["data/raw/modular_rag.pdf", "data/raw/enhancing_rag.pdf"]<br/>for file_path in file_paths:  # this can be parallelized<br/>    indexing_pipeline.run({"loader": {"sources": [file_path]}})<br/><br/>query = "What are the 6 main modules of the modular RAG framework?"<br/><br/>pipeline = results["pipeline"]<br/>pipeline.warm_up()<br/>response = pipeline.run({"query": {"text": query}})<br/><br/>print("Response: ", response["llm"]["replies"][0])</span></pre><pre class="qu qm pp qn bp qo bb bk"><span id="dc7c" class="qp ne fq pp b bg qq qr l qs qt">Response: The six main modules of the modular RAG framework are <br/>Indexing, Pre-retrieval, Retrieval, Post-retrieval, Generation, <br/>and Orchestration.<br/><br/>Supporting quote from Document 1: "Based on the current stage of RAG <br/>development, we have established six main modules: Indexing, <br/>Pre-retrieval, Retrieval, Post-retrieval, Generation, and Orchestration."</span></pre><p id="e81a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Great Response! 👏</p><h1 id="e796" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Summary</h1><p id="e4c6" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">For some of you, this might be a lot to take in at once. You might be new to Haystack, and this is probably your first encounter with Hypster. That’s perfectly understandable!</p><p id="e833" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The code is complex, but I believe that this comes from the inherent complexity of building a modular system like this. In addition, defining the exact routings of a workflow is a visual task and it’s sometimes harder to read via text.</p><p id="6d44" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">That being said, this is the first time I’ve seen a fully configurable, modular RAG system. It’s exciting for me, and I hope for you as well!</p><p id="5832" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I believe this represents a fundamentally different approach to AI/ML projects. Instead of building a codebase for a single solution, we’re building a codebase that accommodates multiple potential workflows — a “superposition of workflows” or a “hyper-workflow.”</p><p id="aba5" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Once you get into this kind of programming — you immediately unlock incredible benefits:</p><ol class=""><li id="ca5e" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou ri pc pd bk"><strong class="ob fr">Hyperparameter Optimization</strong> is easily available (more on that in future posts)</li><li id="161a" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou ri pc pd bk"><strong class="ob fr">Utilizing different configurations for diverse scenarios</strong>. For example, queries of type X can use a RAG system with a high weight assigned to the BM25 retriever and queries of type Y focus mainly on dense embedding techniques.</li><li id="92d5" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou ri pc pd bk"><strong class="ob fr">Agentic Tool Use - </strong>It’s relatively straightforward to wrap this as a tool that can be instantiated and used in different scenarios, which means that… Yes! We can turn this into<strong class="ob fr"> </strong>a tool that an AI Agent uses. Think of the possibilities there.</li><li id="51b0" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou ri pc pd bk"><strong class="ob fr">A/B testing in Production - </strong>we can deploy this RAG hyperspace to production and perform A/B testing just by specifying configurations for each individual API request.</li></ol><h1 id="dcab" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk"><strong class="al">Outro</strong></h1><p id="add8" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">So, how was it for you?</p><p id="6b6b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Making this knowledge accessible is important to me, so your inputs are valuable. If you have any questions or comments on this implementation or the overall approach, please feel free to add your comments to this article.</p><p id="38f9" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I also offer consultation and freelance services to companies looking for a structured, common-sense approach to solving business problems using state-of-the-art Generative AI and Machine Learning tools.</p><p id="c25b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Feel free to contact me via <a class="af nc" href="mailto:me@giladrubin.com" rel="noopener ugc nofollow" target="_blank"><strong class="ob fr">E-Mail</strong></a>, <a class="af nc" href="https://www.linkedin.com/in/gilad-rubin-2b72b3218/" rel="noopener ugc nofollow" target="_blank"><strong class="ob fr">LinkedIn</strong></a> or my <a class="af nc" href="http://www.giladrubin.com" rel="noopener ugc nofollow" target="_blank"><strong class="ob fr">Website</strong></a><strong class="ob fr"> 🌟</strong></p><h1 id="8088" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Resources</h1><ul class=""><li id="8ef9" class="nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou pb pc pd bk">Gao, Y., Xiong, Y., Wang, M., &amp; Wang, H. (2024). <a class="af nc" href="https://arxiv.org/abs/2407.21059" rel="noopener ugc nofollow" target="_blank">Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks</a>. arXiv preprint arXiv:2407.21059.</li></ul><h1 id="4887" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk"><strong class="al">Further Reading</strong></h1><ul class=""><li id="14dd" class="nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou pb pc pd bk"><strong class="ob fr">Haystack’s </strong><a class="af nc" href="https://docs.haystack.deepset.ai/docs/intro" rel="noopener ugc nofollow" target="_blank">Documentation</a> | <a class="af nc" href="https://www.deeplearning.ai/short-courses/building-ai-applications-with-haystack/" rel="noopener ugc nofollow" target="_blank">DeepLearning.ai Course</a> | <a class="af nc" href="https://github.com/deepset-ai/haystack" rel="noopener ugc nofollow" target="_blank">Github Repo</a></li><li id="399f" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk"><strong class="ob fr">Hypster’s </strong><a class="af nc" href="https://medium.com/@giladrubin/introducing-hypster-a-pythonic-framework-for-managing-configurations-to-build-highly-optimized-ai-5ee004dbd6a5" rel="noopener">Introduction</a> | <a class="af nc" href="https://gilad-rubin.gitbook.io/hypster" rel="noopener ugc nofollow" target="_blank">Documentation</a> | <a class="af nc" href="https://github.com/gilad-rubin/hypster" rel="noopener ugc nofollow" target="_blank">Github Repo</a></li><li id="54f3" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk"><strong class="ob fr">Modular-RAG </strong><a class="af nc" href="https://github.com/gilad-rubin/modular-rag" rel="noopener ugc nofollow" target="_blank">Github Repo</a></li></ul><h1 id="e536" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Notes</h1><ul class=""><li id="5a36" class="nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou pb pc pd bk">All images without a caption were created by the author</li><li id="113b" class="nz oa fq ob b go pe od oe gr pf og oh oi pg ok ol om ph oo op oq pi os ot ou pb pc pd bk">I’m not affiliated with Deepset/Haystack in any way.</li></ul></div></div></div></div>    
</body>
</html>