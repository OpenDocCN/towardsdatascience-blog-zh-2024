<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Synthetic Data in Practice: A Shopify Case Study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Synthetic Data in Practice: A Shopify Case Study</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/synthetic-data-in-practice-a-shopify-case-study-79b0af024880?source=collection_archive---------6-----------------------#2024-12-10">https://towardsdatascience.com/synthetic-data-in-practice-a-shopify-case-study-79b0af024880?source=collection_archive---------6-----------------------#2024-12-10</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="9fed" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Testing new Snowflake functionality with a 30k records dataset</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@piotr.gruszecki_22364?source=post_page---byline--79b0af024880--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Piotr Gruszecki" class="l ep by dd de cx" src="../Images/0d8b89957a88b258e87887cf7e1de093.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*Z6VMDOS8w5LdqFpJ3xW3Wg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--79b0af024880--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@piotr.gruszecki_22364?source=post_page---byline--79b0af024880--------------------------------" rel="noopener follow">Piotr Gruszecki</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--79b0af024880--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">13 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 10, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/86f740f9908c2f0378251c2b79b24a67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ReC2-bh_PXCLA463IFvTrw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image created with DALL·E, based on author’s prompt</figcaption></figure><p id="2f47" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Working with data, I keep running into the same problem more and more often. On one hand, we have growing requirements for data privacy and confidentiality; on the other — the need to make quick, data-driven decisions. Add to this the modern business reality: freelancers, consultants, short-term projects.</p><p id="41ba" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As a decision maker, I face a dilemma: I need analysis right now, the internal team is overloaded, and I can’t just hand over confidential data to every external analyst.</p><p id="d8de" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And this is where synthetic data comes in.</p><p id="9245" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">But wait — I don’t want to write another theoretical article about what synthetic data is. There are enough of those online already. Instead, I’ll show you a specific comparison: 30 thousand real Shopify transactions versus their synthetic counterpart.</p><p id="8ddc" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">What exactly did I check?</p><ul class=""><li id="c209" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk">How faithfully does synthetic data reflect real trends?</li><li id="d220" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Where are the biggest discrepancies?</li><li id="29ed" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">When can we trust synthetic data, and when should we be cautious?</li></ul><p id="20bb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This won’t be another “how to generate synthetic data” guide (though I’ll show the code too). I’m focusing on what really matters — whether this data is actually useful and what its limitations are.</p><p id="4fa7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">I’m a practitioner — less theory, more specifics. Let’s begin.</p><h1 id="4e3b" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Data Overview</h1><p id="f975" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">When testing synthetic data, you need a solid reference point. In our case, we’re working with real transaction data from a growing e-commerce business:</p><ul class=""><li id="fe1c" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk">30,000 transactions spanning 6 years</li><li id="8f7c" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Clear growth trend year over year</li><li id="615a" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Mix of high and low-volume sales months</li><li id="630d" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Diverse geographical spread, with one dominant market</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/31ef72599e5edf82fdb5519351e97c5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X8ox81HH7nauOwVruUermw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">All charts created by author, using his own R code</figcaption></figure><p id="8f59" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For practical testing, I focused on transaction-level data such as order values, dates, and basic geographic information. Most assessments require only essential business information, without personal or product specifics.</p><p id="644d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The procedure was simple: export raw Shopify data, analyze it to maintain only the most important information, produce synthetic data in Snowflake, then compare the two datasets side by side. One can think of it as generating a “digital twin” of your business data, with comparable trends but entirely anonymized.</p><p id="bc1e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pi">[Technical note: If you’re interested in the detailed data preparation process, including R code and Snowflake setup, check the appendix at the end of this article.]</em></p><h1 id="6633" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Monthly Revenue Analysis</h1><p id="ce6f" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">The first test for any synthetic dataset is how well it captures core business metrics. Let’s start with monthly revenue — arguably the most important metric for any business (for sure in top 3).</p><p id="7eaf" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Looking at the raw trends (Figure 1), both datasets follow a similar pattern: steady growth over the years with seasonal fluctuations. The synthetic data captures the general trend well, including the business’s growth trajectory. However, when we dig deeper into the differences, some interesting patterns emerge.</p><p id="3475" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To quantify these differences, I calculated a monthly delta:</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="1577" class="pn oh fq pk b bg po pp l pq pr">Δ % = (Synthetic - Shopify) / Shopify</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/b90f2b2c5623a7444841831b96c2d95f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y6SQOkplSmuKufgBZQ0Qaw.png"/></div></div></figure><p id="82c9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We see from the plot, that monthly revenue delta varies — sometimes original is bigger, and sometimes synthetic. But the bars seem to be symmetrical and also the differences are getting smaller with time. I added number of records (transactions) per month, maybe it has some impact? Let’s dig a bit deeper.</p><p id="a221" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The deltas are indeed quite well balanced, and if we look at the cumulative revenue lines, they are very well aligned, without large variations. I am skipping this chart.</p><h1 id="5efb" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Sample Size Impact</h1><p id="0a88" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">The deltas are getting smaller, and we intuitively feel it is because of larger number of records. Let us check it — next plot shows absolute values of revenue deltas as a function of records per month. While the number of records does grow with time, the X axis is not exactly time — it’s the records.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/cfe8da970d0b893877a5aa979e66f96a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZmLmfIHF9a4P7cHzP8M1Vw.png"/></div></div></figure><p id="bebf" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The deltas (absolute values) do decrease, as the number of records per month is higher — as we expected. But there is one more thing, quite intriguing, and not that obvious, at least at first glance. Above around 500 records per month, the deltas do not fall further, they stay at (in average) more or less same level.</p><p id="4023" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">While this specific number is derived from our dataset and might vary for different business types or data structures, the pattern itself is important: there exists a threshold where synthetic data stability improves significantly. Below this threshold, we see high variance; above it, the differences stabilize but don’t disappear entirely — synthetic data maintains some variation by design, which actually helps with privacy protection.</p><p id="c9a3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There is a noise, which makes monthly values randomized, also with larger samples. All, while preserves consistency on higher aggregates (yearly, or cumulative). And while reproducing overall trend very well.</p><p id="e276" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It would be quite interesting to see similar chart for other metrics and datasets.</p><p id="d004" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We already know revenue delta depends on number of records, but is it just that more records in a given month, the higher the revenue of synthetic data? Let us find out …</p><p id="4648" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">So we want to check how revenue delta depends on number of records delta. And we mean by delta Synthetic-Shopify, whether it is monthly revenue or monthly number of records.</p><p id="b102" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The chart below shows exactly this relationship. There is some (light) correlation - if number of records per month differ substantially between Synthetic and Shopify, or vice-versa (high delta values), the revenue delta follows. But it is far from simple linear relationship - there is extra noise there as well.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/765bdbe50a11b668f852fffec32616f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uowxnpem0fi8ARwt1cAC0A.png"/></div></div></figure><h1 id="b1fc" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Dimensional Analysis</h1><p id="0e20" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">When generating synthetic data, we often need to preserve not just overall metrics, but also their distribution across different dimensions like geography. I kept country and state columns in our test dataset to see how synthetic data handles dimensional analysis.</p><p id="1e88" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The results reveal two important aspects:</p><ol class=""><li id="ebc9" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ps nz oa bk">The reliability of synthetic data strongly depends on the sample size within each dimension</li><li id="abb0" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ps nz oa bk">Dependencies between dimensions are not preserved</li></ol><p id="1aa8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Looking at revenue by country:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pt"><img src="../Images/3ae2bbb8dc5959e1b5593f23ea6ee3d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eM6A4uibaVRhPz2c1Rf08g.png"/></div></div></figure><p id="7c11" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For the dominant market with thousands of transactions, the synthetic data provides a reliable representation — revenue totals are comparable between real and synthetic datasets. However, for countries with fewer transactions, the differences become significant.</p><p id="69f0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A critical observation about dimensional relationships: in the original dataset, state information appears only for US transactions, with empty values for other countries. However, in the synthetic data, this relationship is lost — we see randomly generated values in both country and state columns, including states assigned to other countries, not US. This highlights an important limitation: synthetic data generation does not maintain logical relationships between dimensions.</p><p id="2720" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There is, however, a practical way to overcome this country-state dependency issue. Before generating synthetic data, we could preprocess our input by concatenating country and state into a single dimension (e.g., ‘US-California’, ‘US-New York’, while keeping just ‘Germany’ or ‘France’ for non-US transactions). This simple preprocessing step would preserve the business logic of states being US-specific and prevent the generation of invalid country-state combinations in the synthetic data.</p><p id="4f65" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This has important practical implications:</p><ul class=""><li id="eaeb" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk">Synthetic data works well for high-volume segments</li><li id="4cb4" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Be cautious when analyzing smaller segments</li><li id="18f1" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Always check sample sizes before drawing conclusions</li><li id="93d9" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Be aware that logical relationships between dimensions may be lost, consider pre-aggregation of some columns</li><li id="14d8" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Consider additional data validation if dimensional integrity is crucial</li></ul><h1 id="aa47" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Transaction value distribution</h1><p id="e9ac" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">One of the most interesting findings in this analysis comes from examining transaction value distributions. Looking at these distributions year by year reveals both the strengths and limitations of synthetic data.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pt"><img src="../Images/81ea005b766e189066459f614c5fe583.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bcqaaWBf3uZMtRUo38mzxA.png"/></div></div></figure><p id="ccbf" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The original Shopify data shows what you’d typically expect in e-commerce: highly asymmetric distribution with a long tail towards higher values, and distinct peaks corresponding to popular single-product transactions, showing clear bestseller patterns.</p><p id="193f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The synthetic data tells an interesting story: it maintains very well the overall shape of the distribution, but the distinct peaks from bestseller products are smoothed out. The distribution becomes more “theoretical”, losing some real-world specifics.</p><p id="f96f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This smoothing effect isn’t necessarily a bad thing. In fact, it might be preferable in some cases:</p><ul class=""><li id="6fae" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk">For general business modeling and forecasting</li><li id="3d65" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">When you want to avoid overfitting to specific product patterns</li><li id="40a0" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">If you’re looking for underlying trends rather than specific product effects</li></ul><p id="8f64" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">However, if you’re specifically interested in bestseller analysis or single-product transaction patterns, you’ll need to factor in this limitation of synthetic data.</p><p id="d867" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Knowing, the goal is product analysis, we’d prepare original dataset differently.</p><p id="0ac7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To quantify how well the synthetic data matches the real distribution, we’ll look at statistical validation in the next section.</p><h1 id="30a4" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Statistical Validation (K-S Test)</h1><p id="0221" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Let’s validate our observations with the Kolmogorov-Smirnov test — a standard statistical method for comparing two distributions.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/f4eb956f09eb0fd83d377d84b726b859.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KX0VJkKY-l0-iK-nNER5NQ.png"/></div></div></figure><p id="46ec" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The findings are positive, but what do these figures mean in practice? The Kolmogorov-Smirnov test compares two distributions and returns two essential metrics: D = 0.012201 (smaller is better, with 0 indicating identical distributions), and p-value = 0.0283 (below the normal 0.05 level, indicating statistically significant differences).</p><p id="1119" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">While the p-value indicates some variations between distributions, the very low D statistic (nearly to 0) verifies the plot’s findings: a near-perfect match in the middle, with just slight differences at the extremities. The synthetic data captures crucial patterns while keeping enough variance to ensure anonymity, making it suitable for commercial analytics.</p><p id="9bf9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In practical terms, this means:</p><ul class=""><li id="4d48" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk">The synthetic data provides an excellent match in the most important mid-range of transaction values</li><li id="8706" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">The match is particularly strong where we have the most data points</li><li id="64f0" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Differences appear mainly in edge cases, which is expected and even desirable from a privacy perspective</li><li id="6e67" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">The statistical validation confirms our visual observations from the distribution plots</li></ul><p id="86e4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This kind of statistical validation is crucial before deciding to use synthetic data for any specific analysis. In our case, the results suggest that the synthetic dataset is reliable for most business analytics purposes, especially when focusing on typical transaction patterns rather than extreme values.</p><h1 id="a0ca" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Conclusions</h1><p id="5b14" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Let’s summarize our journey from real Shopify transactions to their synthetic counterpart.</p><p id="7477" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Overall business trends and patterns are maintained, including transactions value distributions. Spikes are ironed out, resulting in more theoretical distributions, while maintaining key characteristics.</p><p id="9f94" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Sample size matters, by design. Going too granular we will get noise, preserving confidentiality (in addition to removing all PII of course).</p><p id="20c9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Dependencies between columns are not preserved (country-state), but there is an easy walk around, so I think it is not a real issue.</p><p id="2a34" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It is important to understand how the generated dataset will be used — what kind of analysis we expect, so that we can take it into account while reshaping the original dataset.</p><p id="0f52" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The synthetic dataset will work perfectly for applications testing, but we should manually check edge cases, as these might be missed during generation.</p><p id="cb17" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In our Shopify case, the synthetic data proved reliable enough for most business analytics scenarios, especially when working with larger samples and focusing on general patterns rather than specific product-level analysis.</p><h1 id="6e65" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Future Work</h1><p id="ad2a" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">This analysis focused on transactions, as one of key metrics and an easy case to start with.</p><p id="4d40" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can proceed with products analysis and also explore multi-table scenarios.</p><p id="fd93" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It is also worth to develop internal guidelines how to use synthetic data, including check and limitations.</p><h1 id="1b9c" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Appendix: Data Preparation and Methodology</h1><p id="e37b" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">You can scroll through this section, as it is quite technical on how to prepare data.</p><h2 id="62c6" class="pu oh fq bf oi pv pw px ol py pz qa oo nl qb qc qd np qe qf qg nt qh qi qj qk bk">Raw Data Export</h2><p id="8f2f" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Instead of relying on pre-aggregated Shopify reports, I went straight for the raw transaction data. At Alta Media, this is our standard approach — we prefer working with raw data to maintain full control over the analysis process.</p><p id="f552" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The export process from Shopify is straightforward but not immediate:</p><ul class=""><li id="70df" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk">Request raw transaction data export from the admin panel</li><li id="015a" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Wait for email with download links</li><li id="1591" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Download multiple ZIP files containing CSV data</li></ul><h2 id="22db" class="pu oh fq bf oi pv pw px ol py pz qa oo nl qb qc qd np qe qf qg nt qh qi qj qk bk">Data Reshaping</h2><p id="526b" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">I used R for exploratory data analysis, processing, and visualization. The code snippets are in R, copied from my working scripts, but of course one can use other languages to achieve the same final data frame.</p><p id="be04" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The initial dataset had dozens of columns, so the first step was to select only the relevant ones for our synthetic data experiment.</p><p id="cf71" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="pi">Code formatting is adjusted, so that we don’t have horizontal scroll.</em></p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="e94e" class="pn oh fq pk b bg po pp l pq pr">#-- 0. libs<br/>pacman::p_load(data.table, stringr, digest)<br/><br/>#-- 1.1 load data; the csv files are what we get as a <br/># full export from Shopify<br/>xs1_dt &lt;- fread(file = "shopify_raw/orders_export_1.csv")<br/>xs2_dt &lt;- fread(file = "shopify_raw/orders_export_2.csv")<br/>xs3_dt &lt;- fread(file = "shopify_raw/orders_export_3.csv")<br/><br/>#-- 1.2 check all columns, limit them to essential (for this analysis) <br/># and bind into one data.table<br/>xs1_dt |&gt; colnames()<br/># there are 79 columns in full export, so we select a subset, <br/># relevant for this analysis<br/>sel_cols &lt;- c(<br/>"Name", "Email", "Paid at", "Fulfillment Status", "Accepts Marketing", <br/>"Currency", "Subtotal", <br/>"Lineitem quantity", "Lineitem name", "Lineitem price", "Lineitem sku", <br/>"Discount Amount", "Billing Province", "Billing Country")</span></pre><p id="a4fb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We need one data frame, so we need to combine three files. Since we use data.table package, the syntax is very simple. And we pipe combined dataset to trim columns, keeping only selected ones.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="766c" class="pn oh fq pk b bg po pp l pq pr">xs_dt &lt;- data.table::rbindlist(<br/>  l = list(xs1_dt, xs2_dt, xs3_dt), <br/>  use.names = T, fill = T, idcol = T) %&gt;% .[, ..sel_cols]</span></pre><p id="bc14" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s also change column names to single string, replacing spaces with underscore “_” — we don’t need to deal with extra quotations in SQL.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="41b7" class="pn oh fq pk b bg po pp l pq pr">#-- 2. data prep<br/>#-- 2.1 replace spaces in column names, for easier handling<br/>sel_cols_new &lt;- sel_cols |&gt; <br/>  stringr::str_replace(pattern = " ", replacement = "_")<br/><br/>setnames(xs_dt, old = sel_cols, new = sel_cols_new)</span></pre><p id="091a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">I also change transaction id from character “#1234”, to numeric “1234”. I create a new column, so we can easily compare if transformation went as expected.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="27be" class="pn oh fq pk b bg po pp l pq pr">xs_dt[, `:=` (Transaction_id = stringr::str_remove(Name, pattern = "#") |&gt; <br/>              as.integer())]</span></pre><p id="a8e3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Of course you can also overwrite.</p><h2 id="dde8" class="pu oh fq bf oi pv pw px ol py pz qa oo nl qb qc qd np qe qf qg nt qh qi qj qk bk">Extra experimentation</h2><p id="fe53" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Since this was an experiment with Snowflake’s synthetic data generation, I made some additional preparations. The Shopify export contains actual customer emails, which would be masked in Snowflake while generating synthetic data, but I hashed them anyway.</p><p id="2c8e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">So I hashed these emails using MD5 and created an additional column with numerical hashes. This was purely experimental — I wanted to see how Snowflake handles different types of unique identifiers.</p><p id="3783" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">By default, Snowflake masks text-based unique identifiers as it considers them personally identifiable information. For a real application, we’d want to remove any data that could potentially identify customers.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="17a5" class="pn oh fq pk b bg po pp l pq pr">new_cols &lt;- c("Email_hash", "e_number")<br/>xs_dt[, (new_cols) := .(digest::digest(Email, algo = "md5"),<br/>                        digest::digest2int(Email, seed = 0L)), .I]</span></pre><p id="f9b0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">I was also curious how logical column will be handled, so I changed type of a binary column, which has “yes/no” values.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="addb" class="pn oh fq pk b bg po pp l pq pr">#-- 2.3 change Accepts_Marketing to logical column<br/>xs_dt[, `:=` (Accepts_Marketing_lgcl = fcase(<br/>    Accepts_Marketing == "yes", TRUE, <br/>    Accepts_Marketing == "no", FALSE, <br/>    default = NA))]</span></pre><h2 id="2a32" class="pu oh fq bf oi pv pw px ol py pz qa oo nl qb qc qd np qe qf qg nt qh qi qj qk bk">Filter transactions</h2><p id="9ddb" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">The dataset contains records per each item, while for this particular analysis we need only transactions.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="3408" class="pn oh fq pk b bg po pp l pq pr">xs_dt[Transaction_id == 31023, .SD, .SDcols = c(<br/>  "Transaction_id", "Paid_at", "Currency", "Subtotal", "Discount_Amount", <br/>  "Lineitem_quantity", "Lineitem_price", "Billing_Country")]</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ql"><img src="../Images/505e4fd5854a0a53d702c5419b4b126a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KnC2MAtaPPjofu_t8uqaGA.png"/></div></div></figure><p id="36cb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Final subset of columns and filtering records with total amount paid.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="2b67" class="pn oh fq pk b bg po pp l pq pr">trans_sel_cols &lt;- c(<br/>  "Transaction_id", "Email_hash", "e_number", "Paid_at", "Subtotal", <br/>  "Currency", "Billing_Province", "Billing_Country",<br/>  "Fulfillment_Status", "Accepts_Marketing_lgcl")<br/>xst_dt &lt;- xs_dt[!is.na(Paid_at), ..trans_sel_cols]</span></pre><h2 id="d539" class="pu oh fq bf oi pv pw px ol py pz qa oo nl qb qc qd np qe qf qg nt qh qi qj qk bk">Export dataset</h2><p id="10b0" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Once we have a dataset, we nee to export it as a csv file. I export full dataset, and I also produce a 5% sample, which I use for initial test run in Snowflake.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="af0a" class="pn oh fq pk b bg po pp l pq pr">#-- full dataset<br/>xst_dt |&gt; fwrite(file = "data/transactions_a.csv")<br/>#-- a 5% sample<br/>xst_5pct_dt &lt;- xst_dt[sample(.N, .N * .05)]<br/>xst_5pct_dt |&gt; fwrite(file = "data/transactions_a_5pct.csv")</span></pre><p id="80b8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And also saving in Rds format, so I don’t need to repeat all the preparatory steps (which are scripted, so they are executed in seconds anyway).</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="c726" class="pn oh fq pk b bg po pp l pq pr">#-- 3.3 save Rds file<br/>list(xs_dt = xs_dt, xst_dt = xst_dt, xst_5pct_dt = xst_5pct_dt) |&gt; <br/>  saveRDS(file = "data/xs_lst.Rds")</span></pre><h1 id="4590" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Appendix: Data generation in Snowflake</h1><p id="bc77" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Once we have our dataset, prepared according to our needs, generation of it’s synthetic “sibling” is straightforward. One needs to upload the data, run generation, and export results. For details follow Snowflake guidelines. Anyway, I will add here short summary, for complteness of this article.</p><p id="5304" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">First, we need to make some preparations — role, database and warehouse.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="8b43" class="pn oh fq pk b bg po pp l pq pr">USE ROLE ACCOUNTADMIN;<br/>CREATE OR REPLACE ROLE data_engineer;<br/>CREATE OR REPLACE DATABASE syndata_db;<br/>CREATE OR REPLACE WAREHOUSE syndata_wh WITH<br/>  WAREHOUSE_SIZE = 'MEDIUM'<br/>  WAREHOUSE_TYPE = 'SNOWPARK-OPTIMIZED';<br/><br/>GRANT OWNERSHIP ON DATABASE syndata_db TO ROLE data_engineer;<br/>GRANT USAGE ON WAREHOUSE syndata_wh TO ROLE data_engineer;<br/>GRANT ROLE data_engineer TO USER "PIOTR";<br/>USE ROLE data_engineer;</span></pre><p id="ac78" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Create schema and stage, if not defined yet.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="b6ea" class="pn oh fq pk b bg po pp l pq pr">CREATE SCHEMA syndata_db.experimental;<br/><br/>CREATE STAGE syn_upload <br/> DIRECTORY = ( ENABLE = true ) <br/> COMMENT = 'import files';</span></pre><p id="30e9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Upload csv files(s) to stage, and then import them to table(s).</p><p id="69b5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Then, run generation of synthetic data. I like having a small “pilot”, somethiong like 5% records to make initial check if it goes through. It is a time saver (and costs too), in case of more complicated cases, where we might need some SQL adjustment. In this case it is rather pro-forma.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="f915" class="pn oh fq pk b bg po pp l pq pr">-- generate synthetic<br/>-- small file, 5% records<br/>call snowflake.data_privacy.generate_synthetic_data({<br/>    'datasets':[<br/>    {<br/>        'input_table':  'syndata_db.experimental.transactions_a_5pct',<br/>        'output_table': 'syndata_db.experimental.transactions_a_5pct_synth'    <br/>    }<br/>    ],<br/>    'replace_output_tables':TRUE<br/>});</span></pre><p id="a661" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It is good to inspect what we have as a result — checking tables directly in Snowflake.</p><p id="707d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And then run a full dataset.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="32dc" class="pn oh fq pk b bg po pp l pq pr">-- large file, all records<br/>call snowflake.data_privacy.generate_synthetic_data({<br/>    'datasets':[<br/>    {<br/>        'input_table':  'syndata_db.experimental.transactions_a',<br/>        'output_table': 'syndata_db.experimental.transactions_a_synth'    <br/>    }<br/>    ],<br/>    'replace_output_tables':TRUE<br/>});</span></pre><p id="1b12" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The execution time is non-linear, for the full dataset it is way, way faster than what data volume would suggest.</p><p id="514d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now we export files.</p><p id="ef88" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Some preparations:</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="c828" class="pn oh fq pk b bg po pp l pq pr">-- export files to unload stage<br/>CREATE STAGE syn_unload <br/> DIRECTORY = ( ENABLE = true ) <br/> COMMENT = 'export files';<br/><br/>CREATE OR REPLACE FILE FORMAT my_csv_unload_format<br/>  TYPE = 'CSV'<br/>  FIELD_DELIMITER = ','<br/>  FIELD_OPTIONALLY_ENCLOSED_BY = '"';</span></pre><p id="3772" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And export (small and full dataset):</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="d63a" class="pn oh fq pk b bg po pp l pq pr">COPY INTO @syn_unload/transactions_a_5pct_synth <br/>FROM syndata_db.experimental.transactions_a_5pct_synth<br/>FILE_FORMAT = my_csv_unload_format<br/>HEADER = TRUE;<br/><br/>COPY INTO @syn_unload/transactions_a_synth <br/>FROM syndata_db.experimental.transactions_a_synth<br/>FILE_FORMAT = my_csv_unload_format<br/>HEADER = TRUE;</span></pre><p id="25fd" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">So now we have both original Shopify dataset and Synthetic. Time to analyze, compare, and make some plots.</p><h1 id="ec4b" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Appendix: Data comparison &amp; charting</h1><p id="2d57" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">For this analysis, I used R for both data processing and visualization. The choice of tools, however, is secondary — the key is having a systematic approach to data preparation and validation. Whether you use R, Python, or other tools, the important steps remain the same:</p><ul class=""><li id="7e2b" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa bk">Clean and standardize the input data</li><li id="1abf" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Validate the transformations</li><li id="9c0e" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Create reproducible analysis</li><li id="6908" class="nc nd fq ne b go ob ng nh gr oc nj nk nl od nn no np oe nr ns nt of nv nw nx ny nz oa bk">Document key decisions</li></ul><p id="4801" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The detailed code and visualization techniques could indeed be a topic for another article.</p><p id="93de" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If you’re interested in specific aspects of the implementation, feel free to reach out.</p></div></div></div></div>    
</body>
</html>