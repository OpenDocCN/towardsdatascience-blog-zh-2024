<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Dummy Regressor, Explained: A Visual Guide with Code Examples for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Dummy Regressor, Explained: A Visual Guide with Code Examples for Beginners</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629?source=collection_archive---------11-----------------------#2024-09-26">https://towardsdatascience.com/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629?source=collection_archive---------11-----------------------#2024-09-26</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="3657" class="fo fp fq bf b dy fr fs ft fu fv fw dx fx" aria-label="kicker paragraph">REGRESSION ALGORITHM</h2><div/><div><h2 id="8519" class="pw-subtitle-paragraph gs fz fq bf b gt gu gv gw gx gy gz ha hb hc hd he hf hg hh cq dx">Naively choosing the best number for all of your prediction</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hi hj hk hl hm ab"><div><div class="ab hn"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@samybaladram?source=post_page---byline--4007c3d16629--------------------------------" rel="noopener follow"><div class="l ho hp by hq hr"><div class="l ed"><img alt="Samy Baladram" class="l ep by dd de cx" src="../Images/715cb7af97c57601966c5d2f9edd0066.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="hs by l dd de em n ht eo"/></div></div></a></div></div><div class="hu ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--4007c3d16629--------------------------------" rel="noopener follow"><div class="l hv hw by hq hx"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hy cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hs by l br hy em n ht eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hz ab q"><div class="ab q ia"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ib ic bk"><a class="af ag ah ai aj ak al am an ao ap aq ar id" data-testid="authorName" href="https://medium.com/@samybaladram?source=post_page---byline--4007c3d16629--------------------------------" rel="noopener follow">Samy Baladram</a></p></div></div></div><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span><p class="bf b ib ic dx"><button class="ig ih ah ai aj ak al am an ao ap aq ar ii ij ik" disabled="">Follow</button></p></div></div></span></div></div><div class="l il"><span class="bf b bg z dx"><div class="ab cn im in io"><div class="ip iq ab"><div class="bf b bg z dx ab ir"><span class="is l il">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar id ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--4007c3d16629--------------------------------" rel="noopener follow"><p class="bf b bg z it iu iv iw ix iy iz ja bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="jb jc l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span></div><span data-testid="storyPublishDate">Sep 26, 2024</span></div></span></div></span></div></div></div><div class="ab cp jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js"><div class="h k w ea eb q"><div class="ki l"><div class="ab q kj kk"><div class="pw-multi-vote-icon ed is kl km kn"><div class=""><div class="ko kp kq kr ks kt ku am kv kw kx kn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ky kz la lb lc ld le"><p class="bf b dy z dx"><span class="kp">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ko lh li ab q ee lj lk" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lg"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lf lg">3</span></p></button></div></div></div><div class="ab q jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="ll k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lm an ao ap ii ln lo lp" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lq cn"><div class="l ae"><div class="ab cb"><div class="lr ls lt lu lv lw ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="9d23" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">There are a lot of times when my students come to me saying that they want to try the most sophisticated model out there for their machine learning tasks, and sometimes, I jokingly said, â€œHave you tried the <em class="nk">best ever model</em> first?â€ Especially in regression case (where we donâ€™t have that â€œ100% accuracyâ€ goal), some machine learning models seemingly get a good low error score but when you compare it with the dummy model, itâ€™s actuallyâ€¦ not that great.</p><p id="6c77" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">So, hereâ€™s dummy regressor. <a class="af nl" rel="noopener" target="_blank" href="/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e">Just like in classifier</a>, the regression task also has its baseline model â€” the first model you have to try to get the rough idea of how much better your machine learning could be.</p><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn no"><img src="../Images/a26c1218b6656b6c7a27afad643df65f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qMSGk19S51CXGl3DiAGuKw.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">All visuals: Author-created using Canva Pro. Optimized for mobile; may appear oversized on desktop.</figcaption></figure><h1 id="f637" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">Definition</h1><p id="ddb8" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">A dummy regressor is a simple machine learning model that predicts numerical values using basic rules, without actually learning from the input data. Like <a class="af nl" rel="noopener" target="_blank" href="/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e">its classification counterpart</a>, it serves as a baseline for comparing the performance of more complex regression models. The dummy regressor helps us understand if our models are actually learning useful patterns or just making naive predictions.</p><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn pg"><img src="../Images/fb0de27cedea46784a68d59a04efe209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZnkV9WcpJWX1_Mmp2TdVRg.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">Dummy Regressor is the simplest machine learning model imaginable.</figcaption></figure><h1 id="bda5" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">ğŸ“Š Dataset &amp; Libraries</h1><p id="3a3f" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Throughout this article, weâ€™ll use this simple artificial golf dataset as an example. This dataset predicts the number of golfers visiting our golf course. It includes features like outlook, temperature, humidity, and wind, with the target variable being the number of golfers.</p><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn ph"><img src="../Images/6b391a1419ca551296c6405cfc93b4c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ys-vh5B4keHaSNURMdsrog.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">Columns: â€˜Outlookâ€™, â€˜Temperatureâ€™ (in Fahrenheit), â€˜Humidityâ€™ (in %), â€˜Windâ€™ (Yes/No) and â€˜Number of Playersâ€™ (numerical, target feature)</figcaption></figure><pre class="np nq nr ns nt pi pj pk bp pl bb bk"><span id="6272" class="pm og fq pj b bg pn po l pp pq"># Import libraries<br/>import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/><br/># Create dataset<br/>dataset_dict = {<br/>    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain', 'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast', 'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'],<br/>    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],<br/>    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],<br/>    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],<br/>    'Num_Players': [52,39,43,37,28,19,43,47,56,33,49,23,42,13,33,29,25,51,41,14,34,29,49,36,57,21,23,41]<br/>}<br/>df = pd.DataFrame(dataset_dict)<br/><br/># One-hot encode 'Outlook' column<br/>df = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)<br/><br/># Convert 'Wind' column to binary<br/>df['Wind'] = df['Wind'].astype(int)<br/><br/># Split data into features and target, then into training and test sets<br/>X, y = df.drop(columns='Num_Players'), df['Num_Players']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)</span></pre><h1 id="e754" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">Evaluating Regression Result</h1><p id="5b56" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Before getting into the dummy regressor itself, letâ€™s recap the method to evaluate the regression result. While in classification case, it is very intuitive to check the accuracy of the model (just check the ratio of the matching values), in regression, it is a bit different.</p><p id="c658" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">RMSE (root mean squared error) is like a <strong class="mq ga">score for regression models</strong>. It tells us how far off our predictions are from the actual values. Just as we want high accuracy in classification to get more right answers, <strong class="mq ga">we want a low RMSE </strong>in regression to be closer to the true values.</p><p id="45d6" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">People like using RMSE because <strong class="mq ga">its value is in the same type</strong> as what weâ€™re trying to guess.</p><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn no"><img src="../Images/89a57cc0f48f0bd3d7d523be535fc9bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iGBDvSDILany_zGgY67HHg.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">Having RMSE = 3 can be interpreted that the actual value is within Â±3 range from the prediction.</figcaption></figure><pre class="np nq nr ns nt pi pj pk bp pl bb bk"><span id="8cd5" class="pm og fq pj b bg pn po l pp pq">from sklearn.metrics import mean_squared_error<br/><br/>y_true = np.array([10, 15, 20, 15, 10]) # True labels<br/>y_pred = np.array([15, 11, 18, 14, 10]) # Predicted values<br/><br/># Calculate RMSE using scikit-learn<br/>rmse = mean_squared_error(y_true, y_pred, squared=False)<br/><br/>print(f"RMSE = {rmse:.2f}")</span></pre><p id="2a06" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">With that in mind, letâ€™s get into the algorithm.</p><h1 id="3c82" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">Main Mechanism</h1><p id="fe6e" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Dummy Regressor makes predictions based on simple rules, such as always returning the <strong class="mq ga">mean or median</strong> of the target values in the training data.</p><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn pr"><img src="../Images/39b0253d963d586062170f055900981d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I69nsjA9Iw0iBsfcWh5nZg.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">For our golf dataset, a dummy regressor might always predict â€œ40.5â€ for number of players as that is the median of the training label.</figcaption></figure><h1 id="f66d" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">Training Steps</h1><p id="3bf8" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Itâ€™s a bit of a lie saying that thereâ€™s any training process in dummy regressor but anyway, hereâ€™s a general outline:</p><h2 id="0717" class="ps og fq bf oh pt pu pv ok pw px py on mx pz qa qb nb qc qd qe nf qf qg qh fw bk">1. Select Strategy</h2><p id="bd94" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Choose one of the following strategies:</p><ul class=""><li id="07f1" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qi qj qk bk"><strong class="mq ga">Mean</strong>: Always predicts the mean of the training target values.</li><li id="af3c" class="mo mp fq mq b gt ql ms mt gw qm mv mw mx qn mz na nb qo nd ne nf qp nh ni nj qi qj qk bk"><strong class="mq ga">Median</strong>: Always predicts the median of the training target values.</li><li id="18ae" class="mo mp fq mq b gt ql ms mt gw qm mv mw mx qn mz na nb qo nd ne nf qp nh ni nj qi qj qk bk"><strong class="mq ga">Constant</strong>: Always predicts a constant value provided by the user.</li></ul><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn qq"><img src="../Images/672b8a6fa897d96a46e726c4019d4983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dhj2SjIO9iW2Z2E4MO5JbQ.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">Depends on the strategy, Dummy Regressor makes different numerical prediction.</figcaption></figure><pre class="np nq nr ns nt pi pj pk bp pl bb bk"><span id="56d3" class="pm og fq pj b bg pn po l pp pq">from sklearn.dummy import DummyRegressor<br/><br/># Choose a strategy for your DummyRegressor ('mean', 'median', 'constant')<br/>strategy = 'median'</span></pre><h2 id="44c9" class="ps og fq bf oh pt pu pv ok pw px py on mx pz qa qb nb qc qd qe nf qf qg qh fw bk">2. Calculate the Metric</h2><p id="ec31" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Calculate either mean or median, depending on your strategy.</p><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn qr"><img src="../Images/b7175d6ed9dd85ce474d5ced46169f34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pxhGIDCyIS8d1FY1UUQlkQ.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">The algorithm is simply calculating the median of the training dataâ€” in this case we get 40.5.</figcaption></figure><pre class="np nq nr ns nt pi pj pk bp pl bb bk"><span id="375d" class="pm og fq pj b bg pn po l pp pq"># Initialize the DummyRegressor<br/>dummy_reg = DummyRegressor(strategy=strategy)<br/><br/># "Train" the DummyRegressor (although no real training happens)<br/>dummy_reg.fit(X_train, y_train)</span></pre><h2 id="942f" class="ps og fq bf oh pt pu pv ok pw px py on mx pz qa qb nb qc qd qe nf qf qg qh fw bk">3. Apply Strategy to Test Data</h2><p id="a1c3" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Use the chosen strategy to <strong class="mq ga">generate a list of predicted numerical labels</strong> for your test data.</p><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn no"><img src="../Images/a76c34d4df043dad4fa5b8979674f65a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cEj8ap8F9DpGxwTMCVbSXA.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">If we choose the â€œmedianâ€ strategy, the calculated median (40.5) will simply be the prediction for everything.</figcaption></figure><pre class="np nq nr ns nt pi pj pk bp pl bb bk"><span id="fdc7" class="pm og fq pj b bg pn po l pp pq"># Use the DummyRegressor to make predictions<br/>y_pred = dummy_reg.predict(X_test)<br/>print("Label     :",list(y_test))<br/>print("Prediction:",list(y_pred))</span></pre><h2 id="36a6" class="ps og fq bf oh pt pu pv ok pw px py on mx pz qa qb nb qc qd qe nf qf qg qh fw bk">Evaluate the Model</h2><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn no"><img src="../Images/33152fd5f7de890cce4d0e70511619fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jlHVKIn7h74KuaPeQnkgMg.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">Dummy regressor with this strategy gives error value of 13.28 as the baseline for future models.</figcaption></figure><pre class="np nq nr ns nt pi pj pk bp pl bb bk"><span id="c909" class="pm og fq pj b bg pn po l pp pq"># Evaluate the Dummy Regressor's error<br/>from sklearn.metrics import mean_squared_error<br/><br/>rmse = mean_squared_error(y_test, y_pred, squared=False)<br/>print(f"Dummy Regression Error: {rmse.round(2)}")</span></pre><h1 id="1cd9" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">Key Parameters</h1><p id="9cf4" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Thereâ€™s only one main key parameter in dummy regressor, which is:</p><ol class=""><li id="1e9a" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qs qj qk bk"><strong class="mq ga">Strategy</strong>: This determines how the regressor makes predictions. Common options include:<br/>- <strong class="mq ga">mean</strong>: Provides an average baseline, commonly used for general scenarios.<br/>- <strong class="mq ga">median</strong>: More robust against outliers, good for skewed target distributions.<br/>- <strong class="mq ga">constant</strong>: Useful when domain knowledge suggests a specific constant prediction.</li><li id="2002" class="mo mp fq mq b gt ql ms mt gw qm mv mw mx qn mz na nb qo nd ne nf qp nh ni nj qs qj qk bk"><strong class="mq ga">Constant</strong>: When using the â€˜constantâ€™ strategy, this parameter specifies which class to always predict.</li></ol><figure class="np nq nr ns nt nu nm nn paragraph-image"><div role="button" tabindex="0" class="nv nw ed nx bh ny"><div class="nm nn qt"><img src="../Images/5c33e7107ab363c5c632e09294b96ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Piz9fNDP-wxPlZRlRUoReQ.png"/></div></div><figcaption class="oa ob oc nm nn od oe bf b bg z dx">Regardless of the strategy used, the result are all equally bad but for sure our next regression model should have RMSE value lower than 12.</figcaption></figure><h1 id="4689" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">Pros and Cons</h1><p id="a28f" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">As a lazy predictor, dummy regressor for sure have their strengths and limitations.</p><p id="bcea" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk"><strong class="mq ga">Pros:</strong></p><ol class=""><li id="4294" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qs qj qk bk"><strong class="mq ga">Easy Benchmark</strong>: Quickly shows the minimum performance other models should beat.</li><li id="5318" class="mo mp fq mq b gt ql ms mt gw qm mv mw mx qn mz na nb qo nd ne nf qp nh ni nj qs qj qk bk"><strong class="mq ga">Fast</strong>: Takes no time to set up and run.</li></ol><p id="cc1f" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk"><strong class="mq ga">Cons:</strong></p><ol class=""><li id="c6ce" class="mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj qs qj qk bk"><strong class="mq ga">Doesnâ€™t Learn</strong>: Just uses simple rules, so itâ€™s often outperformed by real models.</li><li id="34bb" class="mo mp fq mq b gt ql ms mt gw qm mv mw mx qn mz na nb qo nd ne nf qp nh ni nj qs qj qk bk"><strong class="mq ga">Ignores Features</strong>: Doesnâ€™t consider any input data when making predictions.</li></ol><h1 id="5c41" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">Final Remarks</h1><p id="a02b" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Using dummy regressor should be the first step whenever we have a regression task. They provide a standard base line, so that we are sure that a more complex model actually gives better result rather than random prediction. As you learn more advanced technique, never forget to compare your models against these simple baselines â€” these naive prediction might be what you first need!</p><h1 id="f2c3" class="of og fq bf oh oi oj gv ok ol om gy on oo op oq or os ot ou ov ow ox oy oz pa bk">ğŸŒŸ Dummy Regressor Code Summarized</h1><pre class="np nq nr ns nt pi pj pk bp pl bb bk"><span id="2283" class="pm og fq pj b bg pn po l pp pq"># Import libraries<br/>import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import mean_squared_error<br/>from sklearn.dummy import DummyRegressor<br/><br/># Create dataset<br/>dataset_dict = {<br/>    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain', 'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast', 'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'],<br/>    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],<br/>    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],<br/>    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],<br/>    'Num_Players': [52,39,43,37,28,19,43,47,56,33,49,23,42,13,33,29,25,51,41,14,34,29,49,36,57,21,23,41]<br/>}<br/>df = pd.DataFrame(dataset_dict)<br/><br/># One-hot encode 'Outlook' column<br/>df = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)<br/><br/># Convert 'Wind' column to binary<br/>df['Wind'] = df['Wind'].astype(int)<br/><br/># Split data into features and target, then into training and test sets<br/>X, y = df.drop(columns='Num_Players'), df['Num_Players']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)<br/><br/># Initialize and train the model<br/>dummy_reg = DummyRegressor(strategy='median')<br/>dummy_reg.fit(X_train, y_train)<br/><br/># Make predictions<br/>y_pred = dummy_reg.predict(X_test)<br/><br/># Calculate and print RMSE<br/>print(f"RMSE: {mean_squared_error(y_test, y_pred, squared=False)}")</span></pre></div></div></div><div class="ab cb qu qv qw qx" role="separator"><span class="qy by bm qz ra rb"/><span class="qy by bm qz ra rb"/><span class="qy by bm qz ra"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="1e26" class="ps og fq bf oh pt pu pv ok pw px py on mx pz qa qb nb qc qd qe nf qf qg qh fw bk">Further Reading</h2><p id="8bba" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">For a detailed explanation of the<a class="af nl" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html" rel="noopener ugc nofollow" target="_blank"> DummyRegressor </a>and its implementation in scikit-learn, readers can refer to the official documentation, which provides comprehensive information on its usage and parameters.</p><h2 id="8778" class="ps og fq bf oh pt pu pv ok pw px py on mx pz qa qb nb qc qd qe nf qf qg qh fw bk">Technical Environment</h2><p id="c795" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">This article uses Python 3.7 and scikit-learn 1.5. While the concepts discussed are generally applicable, specific code implementations may vary slightly with different versions.</p><h2 id="fcaa" class="ps og fq bf oh pt pu pv ok pw px py on mx pz qa qb nb qc qd qe nf qf qg qh fw bk">About the Illustrations</h2><p id="511e" class="pw-post-body-paragraph mo mp fq mq b gt pb ms mt gw pc mv mw mx pd mz na nb pe nd ne nf pf nh ni nj fj bk">Unless otherwise noted, all images are created by the author, incorporating licensed design elements from Canva Pro.</p><p id="1288" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ™ğ™šğ™œğ™§ğ™šğ™¨ğ™¨ğ™ğ™¤ğ™£ ğ˜¼ğ™¡ğ™œğ™¤ğ™§ğ™ğ™©ğ™ğ™¢ğ™¨ ğ™ğ™šğ™§ğ™š:</p><div class="rc rd re rf rg"><div role="button" tabindex="0" class="ab bx cp kj it rh ri bp rj lw ao"><div class="rk l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rl rm cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rl rm em n ay tx"/></div><div class="rn l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----4007c3d16629--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq rq hp l"><h2 class="bf ga wv ic it ww iv iw wx iy ja fz bk">Regression Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk wy vx vy vz wa lj wb wc ui ii wd we wf um un uo ep bm up ob" href="https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----4007c3d16629--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wz l il"><span class="bf b dy z dx">5 stories</span></div></div></div><div class="rz dz sa it ab sb il ed"><div class="ed rt bx ru rv"><div class="dz l"><img alt="A cartoon doll with pigtails and a pink hat. This â€œdummyâ€ doll, with its basic design and heart-adorned shirt, visually represents the concept of a dummy regressor in machine. Just as this toy-like figure is a simplified, static representation of a person, a dummy regressor is a basic models serve as baselines for more sophisticated analyses." class="dz" src="../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qMSGk19S51CXGl3DiAGuKw.png"/></div></div><div class="ed rt bx kk rw rx"><div class="dz l"><img alt="" class="dz" src="../Images/44e6d84e61c895757ff31e27943ee597.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*nMaPpVdNqCci31YmjfCMRQ.png"/></div></div><div class="ed bx hx ry rx"><div class="dz l"><img alt="" class="dz" src="../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qTpdMoaZClu-KDV3nrZDMQ.png"/></div></div></div></div></div><p id="ae35" class="pw-post-body-paragraph mo mp fq mq b gt mr ms mt gw mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj fj bk">ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:</p><div class="rc rd re rf rg"><div role="button" tabindex="0" class="ab bx cp kj it rh ri bp rj lw ao"><div class="rk l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rl rm cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rl rm em n ay tx"/></div><div class="rn l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----4007c3d16629--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq rq hp l"><h2 class="bf ga wv ic it ww iv iw wx iy ja fz bk">Classification Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk wy vx vy vz wa lj wb wc ui ii wd we wf um un uo ep bm up ob" href="https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----4007c3d16629--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wz l il"><span class="bf b dy z dx">8 stories</span></div></div></div><div class="rz dz sa it ab sb il ed"><div class="ed rt bx ru rv"><div class="dz l"><img alt="" class="dz" src="../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*eVxxKT4DKvRVuAHBGknJ7w.png"/></div></div><div class="ed rt bx kk rw rx"><div class="dz l"><img alt="" class="dz" src="../Images/6ea70d9d2d9456e0c221388dbb253be8.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uFvDKl3iA2_G961vw5QFpg.png"/></div></div><div class="ed bx hx ry rx"><div class="dz l"><img alt="" class="dz" src="../Images/7221f0777228e7bcf08c1adb44a8eb76.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*1TbEIdTs_Z8V_TPD9MXxJw.png"/></div></div></div></div></div></div></div></div></div>    
</body>
</html>