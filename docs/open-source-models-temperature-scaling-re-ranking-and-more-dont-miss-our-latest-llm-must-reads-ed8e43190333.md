# 开源模型、温度缩放、重排序等：不要错过我们近期的 LLM 必读文章

> 原文：[https://towardsdatascience.com/open-source-models-temperature-scaling-re-ranking-and-more-dont-miss-our-latest-llm-must-reads-ed8e43190333?source=collection_archive---------7-----------------------#2024-05-16](https://towardsdatascience.com/open-source-models-temperature-scaling-re-ranking-and-more-dont-miss-our-latest-llm-must-reads-ed8e43190333?source=collection_archive---------7-----------------------#2024-05-16)

[](https://towardsdatascience.medium.com/?source=post_page---byline--ed8e43190333--------------------------------)[![TDS 编辑部](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page---byline--ed8e43190333--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ed8e43190333--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ed8e43190333--------------------------------) [TDS 编辑部](https://towardsdatascience.medium.com/?source=post_page---byline--ed8e43190333--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ed8e43190333--------------------------------) ·作为 [新闻简报](/newsletter?source=post_page---byline--ed8e43190333--------------------------------) 发送 ·阅读时间 3 分钟 ·2024年5月16日

--

> 想要写下你的第一篇 TDS 文章吗？[我们始终欢迎新作者的贡献](http://bit.ly/write-for-tds)。

新的 LLM（大语言模型）几乎每天都在不断涌现，而它们带来的工具和工作流程则以更快的速度繁荣发展。我们认为现在是时候回顾一下近期关于这一不断变化领域的讨论了，而我们也想不到比精选过去几周内一些最强文章的方式更好的方式来做到这一点。

我们整理的这些文章既涉及高层次的议题，也探讨了细致的问题，因此无论你是对 AI 伦理、开源技术的演变，还是创新的 RAG 方法感兴趣，我们确信你会在这里找到能够激发你兴趣的内容。让我们深入探讨。

+   [**变化的潮流：开源 LLM 相较于封闭源 LLM 的竞争优势**](/shifting-tides-the-competitive-edge-of-open-source-llms-over-closed-source-llms-aee76018b5c7)最初的生成式 AI 工具由像 OpenAI 发布的专有模型引领。 [Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page---user_mention--ed8e43190333--------------------------------) 的新文章聚焦于一个新兴趋势：小型开源基础模型的崛起及其日益主导地位，这些模型因数据安全、可定制性和成本等因素而受到关注。

+   [**聊天机器人道德问题？**](/chatbot-morality-47953ad4838c) 我们知道，当被要求提供事实信息时，LLM可能会产生幻觉；那么，当用户开始向它们询问以伦理为重点的建议时会发生什么呢？[Eyal Aharoni](https://medium.com/u/6aade1545942?source=post_page---user_mention--ed8e43190333--------------------------------)和[Eddy Nahmias](https://medium.com/u/61c68598fdb1?source=post_page---user_mention--ed8e43190333--------------------------------)展示了他们在这一棘手问题上的最新研究，并探讨了聊天机器人“能够在特定、受控情况下模仿或合成人的道德话语”这一现象所固有的危险。

+   [**LLM的推荐是否可以被操控以提升产品的可见性？**](/can-recommendations-from-llms-be-manipulated-to-enhance-a-products-visibility-64c64fa9cd24) 电子商务是一个已经容易受到操控和可疑商业行为影响的领域。正如[Parul Pandey](https://medium.com/u/7053de462a28?source=post_page---user_mention--ed8e43190333--------------------------------)在她对一篇近期论文的分析中所展示的那样，LLM凭借其快速、大规模生成文本和其他媒体的能力，已经准备好利用这个生态系统中的各种漏洞和盲点。

![](../Images/803e85cf617a782d805b767ff22b30c3.png)

图片由[Thomas Kelley](https://unsplash.com/@thkelley?utm_source=medium&utm_medium=referral)提供，来源：[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

+   [**LLM中的温度缩放与束搜索文本生成，面向机器学习相关领域**](/temperature-scaling-and-beam-search-text-generation-in-llms-for-the-ml-adjacent-21212cc5dddb) 在一篇内容详尽、举例丰富的指南中，[Mike Cvet](https://medium.com/u/bc23035f3073?source=post_page---user_mention--ed8e43190333--------------------------------)深入解析了在生成式AI工作流中“温度”这一概念：它是一个修改模型输出序列可预测性的参数，掌握其细微差别有助于从业者更有效地使用AI工具。

+   [**如何通过重新排序改进LLM RAG检索**](/how-to-use-re-ranking-for-better-llm-rag-retrieval-243f89414266) 在检索增强生成（RAG）初步兴奋过后，许多从业者很快意识到，RAG系统通常可以从更先进的精炼方法中受益。[Dr. Leon Eversberg](https://medium.com/u/a67b10ad1762?source=post_page---user_mention--ed8e43190333--------------------------------)的最新教程带我们了解了一种工作流，它利用两步检索（使用开源的双编码器和交叉编码器）以获得更好的结果。

正如他们一贯所做的那样，我们的作者们在近期几周涉及了许多其他话题，创作了一些高质量的文章；以下是一个代表性样本：

+   在她精彩的客户生命周期价值系列文章的完结篇中，[Katherine Munro](https://medium.com/u/b84716d39740?source=post_page---user_mention--ed8e43190333--------------------------------)提供了[可用预测方法的详细概述](/from-probabilistic-to-predictive-methods-for-mastering-customer-lifetime-value-72f090ebcde2)，以及市场营销人员和数据科学家可以从每种方法中期待的结果。

+   每一篇[Sachin Date](https://medium.com/u/b75b5b1730f3?source=post_page---user_mention--ed8e43190333--------------------------------)的深度剖析都值得庆祝，而最新的这篇也不例外：它是[对统计收敛的细致探索](/statistical-convergence-and-its-consequences-1134a0b4d936)，通过一个19世纪船难的故事讲述。

+   在她最新的初学者友好指南中，[Srijanie Dey博士](https://medium.com/u/d60d06fe8655?source=post_page---user_mention--ed8e43190333--------------------------------)转向了Llama 3，并[深入剖析了其变换器架构的细微差别](/deep-dive-into-llama-3-by-hand-️-6c6b23dc92b2)。

+   [Murto Hilali](https://medium.com/u/5e4440e19f87?source=post_page---user_mention--ed8e43190333--------------------------------)在分子生物学、计算生物学和人工智能的交叉领域写作，展示了他是如何[构建一个多分类器模型来预测突变对蛋白质相互作用的影响](/protein-interactions-alphafold-04eeb8f56d79)的。

+   如果你正在考虑从物理学（及相关领域）转向数据科学的[职业转型](/how-to-transition-from-physics-to-data-science-a-comprehensive-guide-ff1951090f65)，不要错过[Sara Nóbrega](https://medium.com/u/7606b796c9df?source=post_page---user_mention--ed8e43190333--------------------------------)的实用指南，基于她个人的历程和一路上积累的经验。

+   对于任何刚刚踏入深度学习领域的人，[Shreya Rao](https://medium.com/u/99b63de2f2c3?source=post_page---user_mention--ed8e43190333--------------------------------)带着她的新作回来了，这是一本面向初学者的、[巧妙插图的卷积神经网络入门书](/deep-learning-illustrated-part-3-convolutional-neural-networks-96b900b0b9e0)。

+   揭示Kolmogorov-Arnold网络（KANs）的论文才刚刚两周，但已经在该领域掀起了巨大波澜。[Theo Wolf](https://medium.com/u/ea2521d61d62?source=post_page---user_mention--ed8e43190333--------------------------------)的首篇TDS文章[帮助我们理解KANs是如何工作的](/kolmogorov-arnold-networks-the-latest-advance-in-neural-networks-simply-explained-f083cf994a85)，以及它为何如此引起关注。

感谢你支持我们作者的工作！我们非常喜欢发布新作者的文章，因此，如果你最近写了一个有趣的项目演示、教程，或对我们核心主题的理论反思，别犹豫，[与我们分享](http://bit.ly/write-for-tds)。

直到下一个变量，

TDS团队
