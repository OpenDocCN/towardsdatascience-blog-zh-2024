- en: 'AI Agents: The Intersection of Tool Calling and Reasoning in Generative AI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ai-agents-the-intersection-of-tool-calling-and-reasoning-in-generative-ai-ff268eece443?source=collection_archive---------2-----------------------#2024-10-05](https://towardsdatascience.com/ai-agents-the-intersection-of-tool-calling-and-reasoning-in-generative-ai-ff268eece443?source=collection_archive---------2-----------------------#2024-10-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Unpacking problem solving and tool-driven decision making in AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tula.masterman?source=post_page---byline--ff268eece443--------------------------------)[![Tula
    Masterman](../Images/c36b3740befd5dfdb8719dc6596f1a99.png)](https://medium.com/@tula.masterman?source=post_page---byline--ff268eece443--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ff268eece443--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ff268eece443--------------------------------)
    [Tula Masterman](https://medium.com/@tula.masterman?source=post_page---byline--ff268eece443--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ff268eece443--------------------------------)
    ·11 min read·Oct 5, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3279c4d07b6b2c6d9e752246854f9da1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author and GPT-4o depicting an AI agent at the intersection of reasoning
    and tool calling
  prefs: []
  type: TYPE_NORMAL
- en: 'Introduction: The Rise of Agentic AI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today, new libraries and low-code platforms are making it easier than ever to
    build AI agents, also referred to as digital workers. Tool calling is one of the
    primary abilities driving the “agentic” nature of Generative AI models by extending
    their ability beyond conversational tasks. By executing tools (functions), agents
    can take action on your behalf and solve complex, multi-step problems that require
    robust decision making and interacting with a variety of external data sources.
  prefs: []
  type: TYPE_NORMAL
- en: This article focuses on how reasoning is expressed through tool calling, explores
    some of the challenges of tool use, covers common ways to evaluate tool-calling
    ability, and provides examples of how different models and agents interact with
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: Expressions of Reasoning to Solve Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the core of successful agents lie two key expressions of reasoning: **reasoning
    through evaluation and planning** and **reasoning through tool use**.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reasoning through evaluation and planning** relates to an agent’s ability
    to effectively breakdown a problem by iteratively planning, assessing progress,
    and adjusting its approach until the task is completed. Techniques like [Chain-of-Thought](https://arxiv.org/abs/2201.11903)
    (CoT), [ReAct](https://arxiv.org/abs/2210.03629), and [Prompt Decomposition](https://arxiv.org/abs/2210.02406)
    are all patterns designed to improve the model’s ability to reason strategically
    by breaking down tasks to solve them correctly. This type of reasoning is more
    macro-level, ensuring the task is completed correctly by working iteratively and
    taking into account the results from each stage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reasoning through tool use** relates to the agents ability to effectively
    interact with it’s environment, deciding which tools to call and how to structure
    each call. These tools enable the agent to retrieve data, execute code, call APIs,
    and more. The strength of this type of reasoning lies in the proper execution
    of tool calls rather than reflecting on the results from the call.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While both expressions of reasoning are important, they don’t always need to
    be combined to create powerful solutions. For example, **OpenAI’s new** **o1 model
    excels at reasoning through evaluation and planning** because it was trained to
    reason using chain of thought. This has significantly improved its ability to
    think through and solve complex challenges as reflected on a variety of benchmarks.
    For example, the o1 model has been shown to **surpass human PhD-level accuracy
    on the GPQA benchmark** covering physics, biology, and chemistry, and scored in
    the **86th-93rd percentile on Codeforces** contests. While o1’s reasoning ability
    could be used to generate text-based responses that suggest tools based on their
    descriptions, it currently lacks explicit tool calling abilities (at least for
    now!).
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, **many models are fine-tuned specifically for reasoning through
    tool use** enabling them to generate function calls and interact with APIs very
    effectively. These models are focused on calling the right tool in the right format
    at the right time, but are typically not designed to evaluate their own results
    as thoroughly as o1 might. The [**Berkeley Function Calling Leaderboard**](https://gorilla.cs.berkeley.edu/leaderboard.html)
    **(BFCL) is a great resource for comparing how different models perform on function
    calling tasks**. It also provides an **evaluation suite to compare your own fine-tuned
    model** on various challenging tool calling tasks. In fact, the [latest dataset,
    BFCL v3](https://huggingface.co/datasets/gorilla-llm/Berkeley-Function-Calling-Leaderboard),
    was just released and now includes [multi-step, multi-turn function calling](https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html),
    further raising the bar for tool based reasoning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Both types of reasoning are powerful independently, and when combined, they
    have the potential to create agents that can effectively breakdown complicated
    tasks and autonomously interact with their environment. For more examples of AI
    agent architectures for reasoning, planning, and tool calling [check out my team’s
    survey paper on ArXiv](https://arxiv.org/abs/2404.11584).
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenges with Tool-Calling: Navigating Complex Agent Behaviors'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building robust and reliable agents requires overcoming many different challenges.
    When solving complex problems, an agent often needs to balance multiple tasks
    at once including planning, interacting with the right tools at the right time,
    formatting tool calls properly, remembering outputs from previous steps, avoiding
    repetitive loops, and adhering to guidance to protect the system from jailbreaks/prompt
    injections/etc.
  prefs: []
  type: TYPE_NORMAL
- en: '**Too many demands can easily overwhelm a single agent, leading to a growing
    trend where what may appear to an end user as one agent, is behind the scenes
    a collection of many agents and prompts working together to divide and conquer
    completing the task**. This division allows tasks to be broken down and handled
    in parallel by different models and agents tailored to solve that particular piece
    of the puzzle.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s here that models with excellent tool calling capabilities come into play.
    While tool-calling is a powerful way to enable productive agents, it comes with
    its own set of challenges. Agents need to understand the available tools, select
    the right one from a set of potentially similar options, format the inputs accurately,
    call tools in the right order, and potentially integrate feedback or instructions
    from other agents or humans. Many models are fine-tuned specifically for tool
    calling, allowing them to specialize in selecting functions at the right time
    with high accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '**Some of the key considerations when fine-tuning a model for tool calling
    include:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Proper Tool Selection**: The model needs to understand the relationship between
    available tools, make nested calls when applicable, and select the right tool
    in the presence of other similar tools.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Handling Structural Challenges**: Although most models use JSON format for
    tool calling, other formats like YAML or XML can also be used. Consider whether
    the model needs to generalize across formats or if it should only use one. Regardless
    of the format, the model needs to include the appropriate parameters for each
    tool call, potentially using results from a previous call in subsequent ones.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Ensuring Dataset Diversity and Robust Evaluations**: The dataset used should
    be diverse and cover the complexity of multi-step, multi-turn function calling.
    Proper evaluations should be performed to prevent overfitting and avoid benchmark
    contamination.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Common Benchmarks to Evaluate Tool-Calling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the growing importance of tool use in language models, many datasets have
    emerged to help evaluate and improve model tool-calling capabilities. Two of the
    most popular benchmarks today are the Berkeley Function Calling Leaderboard and
    Nexus Function Calling Benchmark, both of which [Meta used to evaluate the performance
    of their Llama 3.1 model series](https://arxiv.org/pdf/2407.21783). A recent paper,
    [ToolACE](https://arxiv.org/abs/2409.00920), demonstrates how agents can be used
    to create a diverse dataset for fine-tuning and evaluating model tool use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s explore each of these benchmarks in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Berkeley Function Calling Leaderboard (**[**BFCL**](https://gorilla.cs.berkeley.edu/leaderboard.html)**):**
    BFCL contains 2,000 question-function-answer pairs across multiple programming
    languages. Today there are 3 versions of the BFCL dataset each with enhancements
    to better reflect real-world scenarios. For example, [BFCL-V2](https://gorilla.cs.berkeley.edu/blogs/12_bfcl_v2_live.html),
    released August 19th, 2024 includes user contributed samples designed to address
    evaluation challenges related to dataset contamination. [BFCL-V3](https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html)
    released September 19th, 2024 adds multi-turn, multi-step tool calling to the
    benchmark. This is critical for agentic applications where a model needs to make
    multiple tool calls over time to successfully complete a task. Instructions for
    e[valuating models on BFCL can be found on GitHub](https://github.com/ShishirPatil/gorilla),
    with the [latest dataset available on HuggingFace](https://huggingface.co/datasets/gorilla-llm/Berkeley-Function-Calling-Leaderboard),
    and the [current leaderboard accessible here](https://gorilla.cs.berkeley.edu/leaderboard.html).
    The Berkeley team has also released various versions of their Gorilla Open-Functions
    model fine-tuned specifically for function-calling tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nexus Function Calling Benchmark:** This benchmark evaluates models on zero-shot
    function calling and API usage across nine different tasks classified into three
    major categories for single, parallel, and nested tool calls. Nexusflow released
    NexusRaven-V2, a model designed for function-calling. The [Nexus benchmark is
    available on GitHub](https://github.com/nexusflowai/NexusRaven-V2/tree/master#benchmarks)
    and the corresponding [leaderboard is on HuggingFace](https://huggingface.co/spaces/Nexusflow/Nexus_Function_Calling_Leaderboard).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ToolACE:** The [ToolACE paper](https://arxiv.org/pdf/2409.00920) demonstrates
    a creative approach to overcoming challenges related to collecting real-world
    data for function-calling. The research team created an agentic pipeline to generate
    a synthetic dataset for tool calling consisting of over 26,000 different APIs.
    The dataset includes examples of single, parallel, and nested tool calls, as well
    as non-tool based interactions, and supports both single and multi-turn dialogs.
    The team released a fine-tuned version of Llama-3.1–8B-Instruct, [ToolACE-8B](https://huggingface.co/Team-ACE/ToolACE-8B),
    designed to handle these complex tool-calling related tasks. A [subset of the
    ToolACE dataset is available on HuggingFace](https://huggingface.co/datasets/Team-ACE/ToolACE).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these benchmarks facilitates our ability to evaluate model reasoning
    expressed through tool calling. These benchmarks and fine-tuned models reflect
    a growing trend towards developing more specialized models for specific tasks
    and increasing LLM capabilities by extending their ability to interact with the
    real-world.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of Tool-Calling in Action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you’re interested in exploring tool-calling in action, here are some examples
    to get you started organized by ease of use, ranging from simple built-in tools
    to using fine-tuned models, and agents with tool-calling abilities.
  prefs: []
  type: TYPE_NORMAL
- en: '**Level 1 — ChatGPT**: The best place to start and see tool-calling live without
    needing to define any tools yourself, is through ChatGPT. Here you can use GPT-4o
    through the chat interface to call and execute tools for web-browsing. For example,
    when asked “what’s the latest AI news this week?” ChatGPT-4o will conduct a web
    search and return a response based on the information it finds. *Remember the
    new o1 model does not have tool-calling abilities yet and cannot search the web.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d4e671c962183b932578d58a05a894c1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author 9/30/24
  prefs: []
  type: TYPE_NORMAL
- en: While this built-in web-searching feature is convenient, most use cases will
    require defining custom tools that can integrate directly into your own model
    workflows and applications. This brings us to the next level of complexity.
  prefs: []
  type: TYPE_NORMAL
- en: '**Level 2 — Using a Model with Tool Calling Abilities and Defining Custom Tools**:'
  prefs: []
  type: TYPE_NORMAL
- en: This level involves using a model with tool-calling abilities to get a sense
    of how effectively the model selects and uses it’s tools. It’s important to note
    that **when a model is trained for tool-calling, it only generates the text or
    code for the tool call, it does not actually execute the code itself. Something
    external to the model needs to invoke the tool, and it’s at this point — where
    we’re combining generation with execution — that we transition from language model
    capabilities to agentic systems.**
  prefs: []
  type: TYPE_NORMAL
- en: To get a sense for how models express tool calls we can turn towards the Databricks
    Playground. For example, we can select the model Llama 3.1 405B and give it access
    to the sample tools get_distance_between_locations and get_current_weather. When
    prompted with the user message “I am going on a trip from LA to New York how far
    are these two cities? And what’s the weather like in New York? I want to be prepared
    for when I get there” the model decides which tools to call and what parameters
    to pass so it can effectively reply to the user.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ccc6160bc9393164ecb15310a765b94b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author 10/2/2024 depicting using the Databricks Playground for sample
    tool calling
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the model suggests two tool calls. Since the model cannot execute
    the tools, the user needs to fill in a sample result to simulate the tool output
    (e.g., “2500” for the distance and “68” for the weather). The model then uses
    these simulated outputs to reply to the user.
  prefs: []
  type: TYPE_NORMAL
- en: This approach to using the Databricks Playground allows you to observe how the
    model uses custom defined tools and is a great way to test your function definitions
    before implementing them in your tool-calling enabled applications or agents.
  prefs: []
  type: TYPE_NORMAL
- en: Outside of the Databricks Playground, we can observe and evaluate how effectively
    different models available on platforms like HuggingFace use tools through code
    directly. For example, we can load different models like Llama 3.2–3B-Instruct,
    ToolACE-8B, NexusRaven-V2–13B, and more from HuggingFace, give them the same system
    prompt, tools, and user message then observe and compare the tool calls each model
    returns. This is a great way to understand how well different models reason about
    using custom-defined tools and can help you determine which tool-calling models
    are best suited for your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example demonstrating a tool call generated by Llama-3.2–3B-Instruct
    based on the following tool definitions and user message, the same steps could
    be followed for other models to compare generated tool calls.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c611f529dd5a8b70118f307696a7b85b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author sample output demonstrating generated tool call from Llama 3.2–3B-Instruct
  prefs: []
  type: TYPE_NORMAL
- en: From here we can move to Level 3 where we’re defining Agents that execute the
    tool-calls generated by the language model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Level 3 Agents (invoking/executing LLM tool-calls)**: Agents often express
    reasoning both through planning and execution as well as tool calling making them
    an increasingly important aspect of AI based applications. Using libraries like
    LangGraph, AutoGen, Semantic Kernel, or LlamaIndex, you can quickly create an
    agent using models like GPT-4o or Llama 3.1–405B which support both conversations
    with the user and tool execution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out these guides for some exciting examples of agents in action:'
  prefs: []
  type: TYPE_NORMAL
- en: 'LangGraph: [Local RAG Agent with Llama 3](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag_local/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AutoGen: [Solve Tasks Requiring Web Info](https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Semantic Kernel: [Getting Started with Agents in Semantic Kernel](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/GettingStartedWithAgents/README.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LlamaIndex: [Agent Usage Pattern Documentation](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/usage_pattern/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conclusion:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The future of agentic systems will be driven by models with strong reasoning
    abilities enabling them to effectively interact with their environment. As the
    field evolves, I expect we will continue to see a proliferation of smaller, specialized
    models focused on specific tasks like tool-calling and planning.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to consider the current limitations of model sizes when building
    agents. For example, according to the [Llama 3.1 model card](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1),
    the Llama 3.1–8B model is not reliable for tasks that involve both maintaining
    a conversation and calling tools. Instead, larger models with 70B+ parameters
    should be used for these types of tasks. This alongside other emerging research
    for fine-tuning small language models suggests that smaller models may serve best
    as specialized tool-callers while larger models may be better for more advanced
    reasoning. By combining these abilities, we can build increasingly effective agents
    that provide a seamless user experience and allow people to leverage these reasoning
    abilities in both professional and personal endeavors.
  prefs: []
  type: TYPE_NORMAL
- en: '*Interested in discussing further or collaborating? Reach out on* [*LinkedIn*](https://www.linkedin.com/in/tula-masterman/)*!*'
  prefs: []
  type: TYPE_NORMAL
