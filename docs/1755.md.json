["```py\ndef compute_gaussian_weight(\n   pixel_coord: torch.Tensor,  # (1, 2) tensor\n   point_mean: torch.Tensor,\n   inverse_covariance: torch.Tensor,\n) -> torch.Tensor:\n\n   difference = point_mean - pixel_coord\n   power = -0.5 * difference @ inverse_covariance @ difference.T\n   return torch.exp(power).item()\n```", "```py\ndef render_pixel(\n       self,\n       pixel_coords: torch.Tensor,\n       points_in_tile_mean: torch.Tensor,\n       colors: torch.Tensor,\n       opacities: torch.Tensor,\n       inverse_covariance: torch.Tensor,\n       min_weight: float = 0.000001,\n   ) -> torch.Tensor:\n       total_weight = torch.ones(1).to(points_in_tile_mean.device)\n       pixel_color = torch.zeros((1, 1, 3)).to(points_in_tile_mean.device)\n       for point_idx in range(points_in_tile_mean.shape[0]):\n           point = points_in_tile_mean[point_idx, :].view(1, 2)\n           weight = compute_gaussian_weight(\n               pixel_coord=pixel_coords,\n               point_mean=point,\n               inverse_covariance=inverse_covariance[point_idx],\n           )\n           alpha = weight * torch.sigmoid(opacities[point_idx])\n           test_weight = total_weight * (1 - alpha)\n           if test_weight < min_weight:\n               return pixel_color\n           pixel_color += total_weight * alpha * colors[point_idx]\n           total_weight = test_weight\n       # in case we never reach saturation\n       return pixel_color\n```", "```py\n def render_tile(\n     self,\n     x_min: int,\n     y_min: int,\n     points_in_tile_mean: torch.Tensor,\n     colors: torch.Tensor,\n     opacities: torch.Tensor,\n     inverse_covariance: torch.Tensor,\n     tile_size: int = 16,\n ) -> torch.Tensor:\n     \"\"\"Points in tile should be arranged in order of depth\"\"\"\n\n     tile = torch.zeros((tile_size, tile_size, 3))\n\n     # iterate by tiles for more efficient processing\n     for pixel_x in range(x_min, x_min + tile_size):\n         for pixel_y in range(y_min, y_min + tile_size):\n             tile[pixel_x % tile_size, pixel_y % tile_size] = self.render_pixel(\n                 pixel_coords=torch.Tensor([pixel_x, pixel_y])\n                 .view(1, 2)\n                 .to(points_in_tile_mean.device),\n                 points_in_tile_mean=points_in_tile_mean,\n                 colors=colors,\n                 opacities=opacities,\n                 inverse_covariance=inverse_covariance,\n             )\n     return tile\n```", "```py\ndef render_image(self, image_idx: int, tile_size: int = 16) -> torch.Tensor:\n    \"\"\"For each tile have to check if the point is in the tile\"\"\"\n    preprocessed_scene = self.preprocess(image_idx)\n    height = self.images[image_idx].height\n    width = self.images[image_idx].width\n\n    image = torch.zeros((width, height, 3))\n\n    for x_min in tqdm(range(0, width, tile_size)):\n        x_in_tile = (x_min >= preprocessed_scene.min_x) & (\n            x_min + tile_size <= preprocessed_scene.max_x\n        )\n        if x_in_tile.sum() == 0:\n            continue\n        for y_min in range(0, height, tile_size):\n            y_in_tile = (y_min >= preprocessed_scene.min_y) & (\n                y_min + tile_size <= preprocessed_scene.max_y\n            )\n            points_in_tile = x_in_tile & y_in_tile\n            if points_in_tile.sum() == 0:\n                continue\n            points_in_tile_mean = preprocessed_scene.points[points_in_tile]\n            colors_in_tile = preprocessed_scene.colors[points_in_tile]\n            opacities_in_tile = preprocessed_scene.sigmoid_opacity[points_in_tile]\n            inverse_covariance_in_tile = preprocessed_scene.inverse_covariance_2d[\n                points_in_tile\n            ]\n            image[x_min : x_min + tile_size, y_min : y_min + tile_size] = (\n                self.render_tile(\n                    x_min=x_min,\n                    y_min=y_min,\n                    points_in_tile_mean=points_in_tile_mean,\n                    colors=colors_in_tile,\n                    opacities=opacities_in_tile,\n                    inverse_covariance=inverse_covariance_in_tile,\n                    tile_size=tile_size,\n                )\n            )\n    return image\n```", "```py\ndef load_cuda(cuda_src, cpp_src, funcs, opt=True, verbose=False):\n    return load_inline(\n        name=\"inline_ext\",\n        cpp_sources=[cpp_src],\n        cuda_sources=[cuda_src],\n        functions=funcs,\n        extra_cuda_cflags=[\"-O1\"] if opt else [],\n        verbose=verbose,\n    )\n\nclass GaussianScene(nn.Module):\n\n    # OTHER CODE NOT SHOWN    \n\n    def compile_cuda_ext(\n        self,\n    ) -> torch.jit.ScriptModule:\n\n        cpp_src = \"\"\"\n        torch::Tensor render_image(\n            int image_height,\n            int image_width,\n            int tile_size,\n            torch::Tensor point_means,\n            torch::Tensor point_colors,\n            torch::Tensor inverse_covariance_2d,\n            torch::Tensor min_x,\n            torch::Tensor max_x,\n            torch::Tensor min_y,\n            torch::Tensor max_y,\n            torch::Tensor opacity);\n        \"\"\"\n\n        cuda_src = Path(\"splat/c/render.cu\").read_text()\n\n        return load_cuda(cuda_src, cpp_src, [\"render_image\"], opt=True, verbose=True)\n\n    def render_image_cuda(self, image_idx: int, tile_size: int = 16) -> torch.Tensor:\n        preprocessed_scene = self.preprocess(image_idx)\n        height = self.images[image_idx].height\n        width = self.images[image_idx].width\n        ext = self.compile_cuda_ext()\n\n        now = time.time()\n        image = ext.render_image(\n            height,\n            width,\n            tile_size,\n            preprocessed_scene.points.contiguous(),\n            preprocessed_scene.colors.contiguous(),\n            preprocessed_scene.inverse_covariance_2d.contiguous(),\n            preprocessed_scene.min_x.contiguous(),\n            preprocessed_scene.max_x.contiguous(),\n            preprocessed_scene.min_y.contiguous(),\n            preprocessed_scene.max_y.contiguous(),\n            preprocessed_scene.sigmoid_opacity.contiguous(),\n        )\n        torch.cuda.synchronize()\n        print(\"Operation took seconds: \", time.time() - now)\n        return image\n```", "```py\n#include <cstdio>\n#include <cmath> // Include this header for expf function\n#include <torch/extension.h>\n\n__device__ float compute_pixel_strength(\n    int pixel_x,\n    int pixel_y,\n    int point_x,\n    int point_y,\n    float inverse_covariance_a,\n    float inverse_covariance_b,\n    float inverse_covariance_c)\n{\n    // Compute the distance between the pixel and the point\n    float dx = pixel_x - point_x;\n    float dy = pixel_y - point_y;\n    float power = dx * inverse_covariance_a * dx + 2 * dx * dy * inverse_covariance_b + dy * dy * inverse_covariance_c;\n    return expf(-0.5f * power);\n}\n\n__global__ void render_tile(\n    int image_height,\n    int image_width,\n    int tile_size,\n    int num_points,\n    float *point_means,\n    float *point_colors,\n    float *image,\n    float *inverse_covariance_2d,\n    float *min_x,\n    float *max_x,\n    float *min_y,\n    float *max_y,\n    float *opacity)\n{\n    // Calculate the pixel's position in the image\n    int pixel_x = blockIdx.x * tile_size + threadIdx.x;\n    int pixel_y = blockIdx.y * tile_size + threadIdx.y;\n\n    // Ensure the pixel is within the image bounds\n    if (pixel_x >= image_width || pixel_y >= image_height)\n    {\n        return;\n    }\n\n    float total_weight = 1.0f;\n    float3 color = {0.0f, 0.0f, 0.0f};\n\n    for (int i = 0; i < num_points; i++)\n    {\n        float point_x = point_means[i * 2];\n        float point_y = point_means[i * 2 + 1];\n\n        // checks to make sure we are within the bounding box\n        bool x_check = pixel_x >= min_x[i] && pixel_x <= max_x[i];\n        bool y_check = pixel_y >= min_y[i] && pixel_y <= max_y[i];\n        if (!x_check || !y_check)\n        {\n            continue;\n        }\n        float strength = compute_pixel_strength(\n            pixel_x,\n            pixel_y,\n            point_x,\n            point_y,\n            inverse_covariance_2d[i * 4],\n            inverse_covariance_2d[i * 4 + 1],\n            inverse_covariance_2d[i * 4 + 3]);\n\n        float initial_alpha = opacity[i] * strength;\n        float alpha = min(.99f, initial_alpha);\n        float test_weight = total_weight * (1 - alpha);\n        if (test_weight < 0.001f)\n        {\n            break;\n        }\n        color.x += total_weight * alpha * point_colors[i * 3];\n        color.y += total_weight * alpha * point_colors[i * 3 + 1];\n        color.z += total_weight * alpha * point_colors[i * 3 + 2];\n        total_weight = test_weight;\n    }\n\n    image[(pixel_y * image_width + pixel_x) * 3] = color.x;\n    image[(pixel_y * image_width + pixel_x) * 3 + 1] = color.y;\n    image[(pixel_y * image_width + pixel_x) * 3 + 2] = color.z;\n\n}\n\ntorch::Tensor render_image(\n    int image_height,\n    int image_width,\n    int tile_size,\n    torch::Tensor point_means,\n    torch::Tensor point_colors,\n    torch::Tensor inverse_covariance_2d,\n    torch::Tensor min_x,\n    torch::Tensor max_x,\n    torch::Tensor min_y,\n    torch::Tensor max_y,\n    torch::Tensor opacity)\n{\n    // Ensure the input tensors are on the same device\n    torch::TensorArg point_means_t{point_means, \"point_means\", 1},\n        point_colors_t{point_colors, \"point_colors\", 2},\n        inverse_covariance_2d_t{inverse_covariance_2d, \"inverse_covariance_2d\", 3},\n        min_x_t{min_x, \"min_x\", 4},\n        max_x_t{max_x, \"max_x\", 5},\n        min_y_t{min_y, \"min_y\", 6},\n        max_y_t{max_y, \"max_y\", 7},\n        opacity_t{opacity, \"opacity\", 8};\n    torch::checkAllSameGPU(\"render_image\", {point_means_t, point_colors_t, inverse_covariance_2d_t, min_x_t, max_x_t, min_y_t, max_y_t, opacity_t});\n\n    // Create an output tensor for the image\n    torch::Tensor image = torch::zeros({image_height, image_width, 3}, point_means.options());\n\n    // Calculate the number of tiles in the image\n    int num_tiles_x = (image_width + tile_size - 1) / tile_size;\n    int num_tiles_y = (image_height + tile_size - 1) / tile_size;\n\n    // Launch a CUDA kernel to render the image\n    dim3 block(tile_size, tile_size);\n    dim3 grid(num_tiles_x, num_tiles_y);\n    render_tile<<<grid, block>>>(\n        image_height,\n        image_width,\n        tile_size,\n        point_means.size(0),\n        point_means.data_ptr<float>(),\n        point_colors.data_ptr<float>(),\n        image.data_ptr<float>(),\n        inverse_covariance_2d.data_ptr<float>(),\n        min_x.data_ptr<float>(),\n        max_x.data_ptr<float>(),\n        min_y.data_ptr<float>(),\n        max_y.data_ptr<float>(),\n        opacity.data_ptr<float>());\n\n    return image;\n}\n```"]