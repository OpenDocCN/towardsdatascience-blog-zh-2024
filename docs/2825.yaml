- en: How to Easily Deploy a Local Generative Search Engine Using VerifAI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何轻松部署本地生成式搜索引擎使用VerifAI
- en: 原文：[https://towardsdatascience.com/how-to-easily-deploy-a-local-generative-search-engine-using-verifai-cdf9dedf53c0?source=collection_archive---------4-----------------------#2024-11-21](https://towardsdatascience.com/how-to-easily-deploy-a-local-generative-search-engine-using-verifai-cdf9dedf53c0?source=collection_archive---------4-----------------------#2024-11-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-easily-deploy-a-local-generative-search-engine-using-verifai-cdf9dedf53c0?source=collection_archive---------4-----------------------#2024-11-21](https://towardsdatascience.com/how-to-easily-deploy-a-local-generative-search-engine-using-verifai-cdf9dedf53c0?source=collection_archive---------4-----------------------#2024-11-21)
- en: An open-source initiative to help you deploy generative search based on your
    local files and self-hosted (Mistral, Llama 3.x) or commercial LLM models (GPT4,
    GPT4o, etc.)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个开源倡议，帮助你基于本地文件和自托管（Mistral, Llama 3.x）或商业LLM模型（GPT4, GPT4o等）部署生成式搜索。
- en: '[](https://datawarrior.medium.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)[![Nikola
    Milosevic (Data Warrior)](../Images/ebea6501c00030561a59a4a12ab7a79a.png)](https://datawarrior.medium.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)
    [Nikola Milosevic (Data Warrior)](https://datawarrior.medium.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://datawarrior.medium.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)[![Nikola
    Milosevic (Data Warrior)](../Images/ebea6501c00030561a59a4a12ab7a79a.png)](https://datawarrior.medium.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)
    [Nikola Milosevic (Data Warrior)](https://datawarrior.medium.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)
    ·8 min read·Nov 21, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--cdf9dedf53c0--------------------------------)
    ·8分钟阅读·2024年11月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'I have previously written about [building your own simple generative search](/how-to-build-a-generative-search-engine-for-your-local-files-using-llama-3-399551786965),
    as well as on the [VerifAI project](/verifai-project-open-source-biomedical-question-answering-with-verified-answers-5417cd9003e0)
    on Towards Data Science. However, there has been a major update worth revisiting.
    Initially, VerifAI was developed as a biomedical generative search with referenced
    and AI-verified answers. This version is still available, and we now call it **VerifAI
    BioMed**. It can be accessed here: [https://app.verifai-project.com/](https://app.verifai-project.com/).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前曾写过关于[构建自己的简单生成式搜索引擎](/how-to-build-a-generative-search-engine-for-your-local-files-using-llama-3-399551786965)的文章，也写过关于[VerifAI项目](/verifai-project-open-source-biomedical-question-answering-with-verified-answers-5417cd9003e0)的文章，发布在《Towards
    Data Science》网站上。然而，这次有一个重大更新值得重新关注。最初，VerifAI被开发为一个生物医学生成式搜索引擎，提供参考资料和AI验证的答案。这个版本仍然可以使用，我们现在称之为**VerifAI
    BioMed**。可以在这里访问：[https://app.verifai-project.com/](https://app.verifai-project.com/)。
- en: '**The major update, however, is that you can now index your local files and
    turn them into your own generative search engine** (or productivity engine, as
    some refer to these systems based on GenAI). It can serve also as an enterprise
    or organizational generative search. We call this version **VerifAI Core**, as
    it serves as the foundation for the other version. In this article, we will explore
    how you can in a few simple steps, deploy it and start using it. Given that it
    has been written in Python, it can be run on any kind of operating system.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**然而，主要的更新是，你现在可以索引本地文件，并将它们转化为你自己的生成式搜索引擎**（或者称之为生产力引擎，正如一些人称基于GenAI的这些系统）。它也可以作为企业或组织的生成式搜索引擎。我们称这个版本为**VerifAI
    Core**，因为它作为其他版本的基础。在本文中，我们将探讨如何通过几个简单的步骤来部署它并开始使用。鉴于它是用Python编写的，所以可以在任何操作系统上运行。'
- en: Architecture
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构
- en: 'The best way to describe a generative search engine is by breaking it down
    into three parts (or components, in our case):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 描述生成式搜索引擎的最佳方式是将其分解为三个部分（或组件，在我们的案例中）：
- en: Indexing
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引
- en: Retrieval-Augmented Generation (RAG) Method
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）方法
- en: VerifAI contains an additional component, which is a verification engine, on
    top of the usual generative search capabilities
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VerifAI 包含一个附加组件，即一个验证引擎，位于常规生成式搜索功能之上。
- en: Indexing in VerifAI can be done by pointing its indexer script to a local folder
    containing files such as PDF, MS Word, PowerPoint, Text, or Markdown (.md). The
    script reads and indexes these files. Indexing is performed in dual mode, utilizing
    both lexical and semantic indexing.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在 VerifAI 中进行索引可以通过将其索引脚本指向包含 PDF、MS Word、PowerPoint、Text 或 Markdown (.md) 文件的本地文件夹来完成。该脚本读取并索引这些文件。索引是以双重模式执行的，同时利用词汇和语义索引。
- en: For lexical indexing, VerifAI uses **OpenSearch**. For semantic indexing, it
    vectorizes chunks of the documents using an embedding model specified in the configuration
    file (models from **Hugging Face** are supported) and then stores these vectors
    in **Qdrant**. A visual representation of this process is shown in the diagram
    below.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于词汇索引，VerifAI 使用**OpenSearch**。对于语义索引，它使用在配置文件中指定的嵌入模型对文档块进行向量化（支持来自**Hugging
    Face**的模型），然后将这些向量存储在**Qdrant**中。这个过程的视觉表示如下图所示。
- en: '![](../Images/5d23755d1cc6f35287d4b9a18ce08121.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d23755d1cc6f35287d4b9a18ce08121.png)'
- en: Architecture of indexing (diagram by author)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 索引架构（图由作者提供）
- en: When it comes to answering questions using VerifAI, the method is somewhat complex.
    User questions, written in natural language, undergo preprocessing (e.g., stopwords
    are excluded) and are then transformed into queries.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 VerifAI 来回答问题时，方法有些复杂。用户问题以自然语言编写，经过预处理（例如，排除停用词），然后转化为查询。
- en: For **OpenSearch**, only lexical processing is performed (e.g., excluding stopwords),
    and the most relevant documents are retrieved. For **Qdrant**, the query is transformed
    into embeddings using the same model that was used to embed document chunks when
    they were stored in Qdrant. These embeddings are then used to query Qdrant, retrieving
    the most similar documents based on **dot product similarity**. The dot product
    is employed because it accounts for both the angle and magnitude of the vectors.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**OpenSearch**，只执行词汇处理（例如，排除停用词），并检索最相关的文档。对于**Qdrant**，查询会使用与存储在Qdrant中的文档块相同的模型进行嵌入。这些嵌入随后用于查询Qdrant，基于**点积相似度**检索最相似的文档。使用点积是因为它考虑了向量的角度和大小。
- en: Finally, the results from the two engines must be merged. This is done by normalizing
    the retrieval scores from each engine to values between 0 and 1 (achieved by dividing
    each score by the highest score from its respective engine). Scores corresponding
    to the same document are then added together and sorted by their combined score
    in descending order.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，必须将两个引擎的结果合并。这是通过将每个引擎的检索得分标准化到0和1之间来完成的（通过将每个得分除以其各自引擎中的最高得分）。然后，将对应于同一文档的得分相加，并按合并后的得分降序排序。
- en: Using the retrieved documents, a prompt is built. The prompt contains instructions,
    the top documents, and the user’s question. This prompt is then passed to the
    large language model of choice (which can be specified in the configuration file,
    or, if no model is set, defaults to our locally deployed fine-tuned version of
    Mistral). Finally, a verification model is applied to ensure there are no hallucinations,
    and the answer is presented to the user through the GUI. The schematic of this
    process is shown in the image below.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用检索到的文档，构建一个提示。该提示包含指令、最相关的文档和用户的问题。然后，将该提示传递给选择的大型语言模型（可以在配置文件中指定，如果未设置模型，则默认为我们本地部署并微调的
    Mistral 版本）。最后，应用验证模型以确保没有幻觉，答案通过GUI呈现给用户。该过程的示意图如下图所示。
- en: '![](../Images/2be84f495093fd14b2f9ef63f0548f71.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2be84f495093fd14b2f9ef63f0548f71.png)'
- en: 'Architecture of retrieval, generation, and verification (image by author).
    The model is based on the combination of the following papers: [https://arxiv.org/pdf/2407.11485](https://arxiv.org/pdf/2407.11485),
    [https://aclanthology.org/2024.bionlp-1.44/](https://aclanthology.org/2024.bionlp-1.44/)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 检索、生成和验证架构（图由作者提供）。该模型基于以下论文的结合：[https://arxiv.org/pdf/2407.11485](https://arxiv.org/pdf/2407.11485)，[https://aclanthology.org/2024.bionlp-1.44/](https://aclanthology.org/2024.bionlp-1.44/)
- en: Installing the necessary libraries
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装必要的库
- en: To install VerifAI Generative Search, you can start by cloning the latest codebase
    from GitHub or using one of the available releases.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 VerifAI 生成式搜索，可以先从 GitHub 克隆最新的代码库或使用可用的版本之一。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: When installing VerifAI Search, it is recommended to start by creating a clean
    Python environment. I have tested it with Python 3.6, but it should work with
    most Python 3 versions. However, Python 3.10+ may encounter compatibility issues
    with certain dependencies.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 VerifAI Search 时，建议首先创建一个干净的 Python 环境。我已经在 Python 3.6 上进行了测试，但它应该适用于大多数
    Python 3 版本。然而，Python 3.10 及以上版本可能会与某些依赖项存在兼容性问题。
- en: 'To create a Python environment, you can use the `venv` library as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个 Python 环境，可以使用 `venv` 库，如下所示：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After activating the environment, you can install the required libraries. The
    requirements file is located in the`verifAI/backend`directory**.** You can run
    the following command to install all the dependencies:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 激活环境后，你可以安装所需的库。需求文件位于`verifAI/backend`目录中**。**你可以运行以下命令来安装所有依赖项：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Configuring system
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置系统
- en: The next step is configuring VerifAI and its interactions with other tools.
    This can be done either by setting environment variables directly or by using
    an environment file (the preferred option).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是配置 VerifAI 及其与其他工具的交互。可以通过直接设置环境变量或使用环境文件（首选选项）来完成。
- en: 'An example of an environment file for VerifAI is provided in the `backend`
    folder as `.env.local.example`. You can rename this file to `.env`, and the VerifAI
    backend will automatically read it. The file structure is as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `backend` 文件夹中提供了一个 VerifAI 环境文件的示例，文件名为 `.env.local.example`。你可以将此文件重命名为
    `.env`，VerifAI 后端将自动读取该文件。文件结构如下：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Some of the variables are quite straightforward. The first Secret key and Algorithm
    are used for communication between the frontend and the backend.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一些变量相当直观。第一个密钥和算法用于前端与后端之间的通信。
- en: Then there are variables configuring access to the **PostgreSQL** database.
    It needs the database name (**DBNAME**), username, password, and host address
    where the database is located. In our case, it is on localhost, on the docker
    image.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是配置访问**PostgreSQL**数据库的变量。需要提供数据库名称（**DBNAME**）、用户名、密码以及数据库所在的主机地址。在我们的例子中，它位于
    localhost 上，是在 Docker 镜像中。
- en: The next section is the configuration of **OpenSearch** access. There is IP
    (localhost in our case again), username, password, port number (default port is
    9200), and variable defining whether to use SSL.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分是配置**OpenSearch**访问。包括 IP 地址（在我们的例子中仍是 localhost）、用户名、密码、端口号（默认端口为 9200），以及定义是否使用
    SSL 的变量。
- en: A similar configuration section has **Qdrant**, just for Qdrant, we use an API
    key, which has to be here defined.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一个类似的配置部分是**Qdrant**，对于 Qdrant，我们使用一个 API 密钥，必须在此处定义。
- en: The next section defined the generative model. VerifAI uses the OpenAI python
    library, which became the industry standard, and allows it to use both **OpenAI
    API, Azure API**, **and user deployments via vLLM, OLlama, or** [**Nvidia NIMs**](https://developer.nvidia.com/nim)**.**
    The user needs to define the path to the interface, API key, and model deployment
    name that will be used. We are soon adding support where users can modify or change
    the prompt that is used for generation. In case no path to an interface is provided
    and no key, the model will download the Mistral 7B model, with the QLoRA adapter
    that we have fine-tuned, and deploy it locally. However, in case you do not have
    enough GPU RAM, or RAM in general, this may fail, or work terribly slowly.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分定义了生成模型。VerifAI 使用了 OpenAI Python 库，这已成为行业标准，并允许它同时使用**OpenAI API、Azure
    API**、**以及通过 vLLM、OLlama 或** [**Nvidia NIMs**](https://developer.nvidia.com/nim)**。**
    用户需要定义接口路径、API 密钥以及将要使用的模型部署名称。我们即将增加支持，允许用户修改或更改用于生成的提示。如果没有提供接口路径和密钥，模型将下载我们已经微调的
    Mistral 7B 模型，并部署到本地。但是，如果你的 GPU 内存不足，或者内存总量不足，这可能会失败，或者运行非常缓慢。
- en: You can set also **MAX_CONTEXT_LENGTH**, in this case it is set to 128,000 tokens,
    as that is context size of GPT4o. The context length variable is used to build
    context. Generally, it is built by putting in instruction about answering question
    factually, with references, and then providing retrieved relevant documents and
    question. However, documents can be large, and exceed context length. If this
    happens, the documents are splitted in chunks and top n chunks that fit into the
    context size will be used to context.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以设置**MAX_CONTEXT_LENGTH**，在这种情况下它设置为 128,000 个 token，因为这是 GPT4o 的上下文大小。上下文长度变量用于构建上下文。通常，它通过输入有关回答问题的指令（要事实性回答，并提供参考资料），然后提供检索到的相关文档和问题来构建上下文。然而，文档可能很大，超过上下文长度。如果发生这种情况，文档将被分割成多个部分，并选择最适合上下文大小的前
    n 个部分。
- en: The next part contains the HuggingFace name of the model that is used for embeddings
    of documents in Qdrant. Finally, there are names of indexes both in OpenSearch
    (**INDEX_NAME_LEXICAL**) and Qdrant (**INDEX_NAME_SEMANTIC**).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分包含用于在 Qdrant 中嵌入文档的模型的 HuggingFace 名称。最后，还列出了在 OpenSearch (**INDEX_NAME_LEXICAL**)
    和 Qdrant (**INDEX_NAME_SEMANTIC**) 中的索引名称。
- en: As we previously said, VerifAI has a component that verifies whether the generated
    claim is based on the provided and referenced document. However, this can be turned
    on or off, as for some use-cases this functionality is not needed. One can turn
    this off by setting **USE_VERIFICATION** to False.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所说，VerifAI 有一个组件，用于验证生成的声明是否基于提供的和引用的文档。然而，这个功能可以开启或关闭，因为对于某些用例，可能不需要此功能。可以通过将
    **USE_VERIFICATION** 设置为 False 来关闭此功能。
- en: Installing datastores
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装数据存储
- en: The final step of the installation is to run the `install_datastores.py` file.
    Before running this file, you need to install Docker and ensure that the Docker
    daemon is running. As this file reads configuration for setting up the user names,
    passwords, or API keys for the tools it is installing, it is necessary to first
    make a configuration file. This is explained in the next section.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 安装的最后一步是运行 `install_datastores.py` 文件。在运行此文件之前，您需要安装 Docker 并确保 Docker 守护进程正在运行。由于该文件读取用于设置用户名称、密码或
    API 密钥的配置，因此需要首先创建配置文件。下一节会对此进行说明。
- en: This script sets up the necessary components, including OpenSearch, Qdrant,
    and PostgreSQL, and creates a database in PostgreSQL.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本设置了必要的组件，包括 OpenSearch、Qdrant 和 PostgreSQL，并在 PostgreSQL 中创建了数据库。
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note that this script installs Qdrant and OpenSearch without SSL certificates,
    and the following instructions assume SSL is not required. If you need SSL for
    a production environment, you will need to configure it manually.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此脚本在没有 SSL 证书的情况下安装 Qdrant 和 OpenSearch，以下说明假设不需要 SSL。如果生产环境中需要 SSL，您需要手动配置它。
- en: Also, note that we are talking about local installation on docker here. If you
    already have Qdrant and OpenSearch deployed, you can simply update the configuration
    file to point to those instances.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请注意，我们在此讨论的是在 Docker 上的本地安装。如果您已经部署了 Qdrant 和 OpenSearch，只需更新配置文件，指向这些实例即可。
- en: Indexing files
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 索引文件
- en: 'This configuration is used by both the indexing method and the backend service.
    Therefore, it must be completed before indexing. Once the configuration is set
    up, you can run the indexing process by pointing **index_files.py** to the folder
    containing the files to be indexed:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置由索引方法和后台服务共同使用。因此，必须在索引之前完成该配置。配置完成后，可以通过将 **index_files.py** 指向包含要索引文件的文件夹来运行索引过程：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We have included a folder called **test_data** in the repository, which contains
    several test files (primarily my papers and other past writings). You can replace
    these files with your own and run the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在仓库中包含了一个名为 **test_data** 的文件夹，其中包含几个测试文件（主要是我的论文和其他过去的写作）。您可以用自己的文件替换这些文件，并运行以下命令：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This would run indexing over all files in that folder and its subfolders. Once
    finished, one can run VerifAI services for backend and frontend.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这将对该文件夹及其子文件夹中的所有文件进行索引。完成后，可以运行 VerifAI 服务，供后台和前端使用。
- en: Running the generative search
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行生成性搜索
- en: 'The backend of VerifAI can be run simply by running:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 只需运行以下命令，即可启动 VerifAI 后台：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This will start the FastAPI service that would act as a backend, and pass requests
    to OpenSearch, and Qdrant to retrieve relevant files for given queries and to
    the deployment of LLM for generating answers, as well as utilize the local model
    for claim verification.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动 FastAPI 服务，作为后台服务，传递请求给 OpenSearch 和 Qdrant，以检索给定查询的相关文件，并部署 LLM 生成答案，同时利用本地模型进行声明验证。
- en: 'Frontend is a folder called client-gui/verifai-ui and is written in React.js,
    and therefore would need a local installation of Node.js, and npm. Then you can
    simply install dependencies by running npm install and run the front end by running
    npm start:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 前端是一个名为 client-gui/verifai-ui 的文件夹，使用 React.js 编写，因此需要本地安装 Node.js 和 npm。然后，您可以通过运行
    npm install 安装依赖项，并通过运行 npm start 启动前端：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, things should look somehow like this:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，安装完成后，系统应该大致如下所示：
- en: '![](../Images/5e50d230e27c2b95425ca2d3766d55d1.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e50d230e27c2b95425ca2d3766d55d1.png)'
- en: One of the example questions, with verification turned on (note text in green)
    and reference to the file, which can be downloaded (screenshot by author)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 启用验证功能后的一个示例问题（绿色文本）并引用文件，文件可以下载（截图由作者提供）
- en: '![](../Images/dbfa4e8ee9292aac605f14c577b144db.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dbfa4e8ee9292aac605f14c577b144db.png)'
- en: Screenshot showcasing tooltip of the verified claim, with the most similar sentence
    from the article presented (screenshot by author)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 截图展示了已验证声明的工具提示，并呈现了文章中最相似的句子（截图由作者提供）
- en: Contributing and future direction
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贡献与未来方向
- en: So far, VerifAI has been started with the help of funding from the Next Generation
    Internet Search project as a subgrant of the European Union. It was started as
    a collaboration between The Institute for Artificial Intelligence Research and
    Development of Serbia and Bayer A.G.. The first version has been developed as
    a generative search engine for biomedicine. This product will continue to run
    at [https://app.verifai-project.com/](https://app.verifai-project.com/). However,
    lately, we decided to expand the project, so it can truly become an open-source
    generative search with verifiable answers for any files, that can be leveraged
    openly by different enterprises, small and medium companies, non-governmental
    organizations, or governments. These modifications have been developed by Natasa
    Radmilovic and me voluntarily (huge shout out to Natasa!).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，VerifAI 得到了来自欧盟资助的“下一代互联网搜索”项目的帮助。它由塞尔维亚人工智能研究与发展研究所和拜耳公司（Bayer A.G.）联合开发。第一版作为一个面向生物医学的生成搜索引擎开发。该产品将继续在
    [https://app.verifai-project.com/](https://app.verifai-project.com/) 上运行。然而，最近我们决定扩展该项目，使其能够真正成为一个开源的生成搜索引擎，能够为任何文件提供可验证的答案，且可以被不同的企业、中小型公司、非政府组织或政府广泛使用。这些修改是由
    Natasa Radmilovic 和我自愿开发的（特别感谢 Natasa！）。
- en: However, given this is an open-source project, available on GitHub ([https://github.com/nikolamilosevic86/verifAI](https://github.com/nikolamilosevic86/verifAI)),
    we are welcoming contributions by anyone, via pull requests, bug reports, feature
    requests, discussions, or anything else you can contribute with (feel free to
    get in touch — for both BioMed and Core (document generative search, as described
    here) versions website will remain the same — [https://verifai-project.com](https://verifai-project.com)).
    So we welcome you to contribute, start our project, and follow us in the future.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，鉴于这是一个开源项目，托管在 GitHub 上（[https://github.com/nikolamilosevic86/verifAI](https://github.com/nikolamilosevic86/verifAI)），我们欢迎任何人通过拉取请求、错误报告、功能请求、讨论或其他任何形式的贡献（欢迎随时联系我们——对于
    BioMed 和 Core 版本（如此处所述的文档生成搜索），网站将保持不变——[https://verifai-project.com](https://verifai-project.com)）。因此，我们欢迎您贡献代码、启动我们的项目，并在未来关注我们。
