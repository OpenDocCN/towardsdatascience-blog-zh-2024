<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>MIDI Files as Training Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>MIDI Files as Training Data</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/midi-files-as-training-data-b67852c8b291?source=collection_archive---------3-----------------------#2024-09-13">https://towardsdatascience.com/midi-files-as-training-data-b67852c8b291?source=collection_archive---------3-----------------------#2024-09-13</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="ea70" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A fundamental difference: MIDI scores vs MIDI performances</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@foscarin.francesco?source=post_page---byline--b67852c8b291--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Francesco Foscarin" class="l ep by dd de cx" src="../Images/f4d238b54771adc6d03c9a62f28d3152.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*x16nzM1V-sfBgOtA"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--b67852c8b291--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@foscarin.francesco?source=post_page---byline--b67852c8b291--------------------------------" rel="noopener follow">Francesco Foscarin</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--b67852c8b291--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 13, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mj"><div class="ab cb"><div class="lm mk ln ml lo mm cf mn cg mo ci bh"><figure class="ms mt mu mv mw mj mx my paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq mr"><img src="../Images/8cc863eae2ddaf0ad98de4390333a286.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*D4UEl39YY4n1LVDNE6w5Cw.png"/></div></div></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="5183" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Before starting any deep learning project with MIDI files, make sure you know the <strong class="ng fr">difference between MIDI scores and MIDI performances</strong>!</p><p id="ea7d" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">This article is for people planning or beginning to work with MIDI files. This format is widely used in the music community, and it caught the attention of computer music researchers due to the availability of datasets.</p><p id="a925" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">However, different types of information can be encoded in MIDI files. In particular, there is a big difference between MIDI scores and MIDI performances. Not being aware of this results in <strong class="ng fr">time wasted on a useless task</strong> or an incorrect choice <strong class="ng fr">of training data and approaches</strong>.</p><p id="078b" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">I will provide a basic introduction to the two formats and give hands-on examples of how to start working with them in Python.</p><h2 id="6efe" class="oa ob fq bf oc od oe of og oh oi oj ok nn ol om on nr oo op oq nv or os ot ou bk"><em class="ov">What is MIDI?</em></h2><p id="48fc" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">MIDI was introduced as a real-time communication protocol between synthesizers. The main idea is to <strong class="ng fr">send a message</strong> every time a <strong class="ng fr">note is pressed</strong> (note on) on a MIDI keyboard and another message when the <strong class="ng fr">note is released</strong> (note off). Then the synthesizer on the receiving end will know what sound to produce.</p><h2 id="3bc3" class="oa ob fq bf oc od oe of og oh oi oj ok nn ol om on nr oo op oq nv or os ot ou bk"><em class="ov">Welcome to MIDI files!</em></h2><p id="815f" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">If we collect and save all these messages (making sure to add their time position) then we have a MIDI file that we can use to reproduce a piece. Other than note-on and note-off, many other kinds of messages exist, for example specifying pedal information or other controllers. <br/>You can think of plotting this information with a<strong class="ng fr"> </strong><em class="pb">pianoroll</em>. <br/>Beware, this is not a MIDI file, but only a possible representation of its content! Some software (in this example <a class="af pc" href="https://www.reaper.fm/" rel="noopener ugc nofollow" target="_blank">Reaper</a>) adds a small piano keyboard next to the pianoroll to make it easier to visually interpret.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq pd"><img src="../Images/8017dddfc17763d1f6f5b970e6dcf361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a3BQLjBSELMn0HjsUHuqQQ.png"/></div></div></figure><h2 id="7cf3" class="oa ob fq bf oc od oe of og oh oi oj ok nn ol om on nr oo op oq nv or os ot ou bk"><em class="ov">How is a MIDI file created?</em></h2><p id="4c77" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">A MIDI file can be created mainly <strong class="ng fr">in two ways</strong>: 1) by playing on a MIDI instrument, 2) by manually writing into a sequencer (Reaper, Cubase, GarageBand, Logic) or a musical score editor (for example from MuseScore).</p><p id="0b91" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">With each way of producing MIDI files comes also a different kind of file:</p><ol class=""><li id="4e6c" class="ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz pe pf pg bk">playing on a MIDI instrument → <strong class="ng fr">MIDI performance</strong></li><li id="b647" class="ne nf fq ng b go ph ni nj gr pi nl nm nn pj np nq nr pk nt nu nv pl nx ny nz pe pf pg bk">manually writing the notes (sequencer or musical score) → <strong class="ng fr">MIDI score</strong></li></ol><p id="5369" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">We’ll now dive into each type, and then summarize their differences.</p><p id="4e09" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Before starting, a disclaimer: <strong class="ng fr">I will not focus specifically on how the information is encoded, but on what information can be extracted from the file</strong>. For example, when I say “ time is represented in seconds” it means that we can get seconds, even though the encoding itself is more complex.</p><h1 id="7847" class="pm ob fq bf oc pn po gq og pp pq gt ok pr ps pt pu pv pw px py pz qa qb qc qd bk">MIDI performances</h1><p id="982d" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">We can find 4 kinds of information in a MIDI performance:</p><ul class=""><li id="ad55" class="ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz qe pf pg bk">When the note start: note onset</li><li id="dd9b" class="ne nf fq ng b go ph ni nj gr pi nl nm nn pj np nq nr pk nt nu nv pl nx ny nz qe pf pg bk">When the note end: note offset (or note duration computed as offset -onset)</li><li id="eae9" class="ne nf fq ng b go ph ni nj gr pi nl nm nn pj np nq nr pk nt nu nv pl nx ny nz qe pf pg bk">Which note was played: note pitch</li><li id="670e" class="ne nf fq ng b go ph ni nj gr pi nl nm nn pj np nq nr pk nt nu nv pl nx ny nz qe pf pg bk">How “strong” was the key pressed: note velocity</li></ul><p id="136e" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk"><strong class="ng fr">Note onset and offset (and duration) </strong>are represented in seconds, corresponding to the seconds the notes were pressed and released by the person playing the MIDI instrument. <br/><strong class="ng fr">Note pitch</strong> is encoded with an integer from 0 (lowest) to 127 (highest); note that more notes can be represented than those that can be played by a piano; the piano range corresponds to 21–108. <br/><strong class="ng fr">Note velocity</strong> is also encoded with an integer from 0 (silence) to 127 (maximum intensity).</p><p id="cd9c" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The vast majority of MIDI performances are piano performances because most MIDI instruments are MIDI keyboards. Other MIDI instruments (for example MIDI saxophones, MIDI drums, and MIDI sensors for guitar) exist, but they are not as common.</p><p id="9ffa" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The biggest dataset of human MIDI performances (classical piano music) is the <a class="af pc" href="https://magenta.tensorflow.org/datasets/maestro" rel="noopener ugc nofollow" target="_blank">Maestro dataset</a> by Google Magenta.</p><h2 id="9b3d" class="oa ob fq bf oc od oe of og oh oi oj ok nn ol om on nr oo op oq nv or os ot ou bk">The main property of MIDI performances</h2><p id="a191" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">A fundamental characteristic of MIDI performances is that <strong class="ng fr">there are never notes with exactly the same onset or duration</strong> (this is, in theory, possible but, in practice, extremely unlikely).</p><p id="1ede" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Indeed, even if they really try, players won’t be able to press two (or more) notes exactly at the same time, since there is a limit to the precision humans can obtain. The same is true for note durations. Moreover, this is not even a priority for most musicians, since time deviation can help to produce a more expressive or groovy feeling. Finally, consecutive notes will have some silence in between or partially overlap.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qf"><img src="../Images/8683281fa2d944677d7994e066df482c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NI-bNileREOju87qMAMJsg.png"/></div></div></figure><p id="f725" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">For this reason, MIDI performances are sometimes also called<em class="pb"> unquantized MIDI</em>. Temporal positions are spread on a continuous time scale, and not quantized to discrete positions (for digital encoding reasons, it is technically a discrete scale, but extremely fine, thus we can consider it continuous).</p><h2 id="6667" class="oa ob fq bf oc od oe of og oh oi oj ok nn ol om on nr oo op oq nv or os ot ou bk">Hands-on example</h2><p id="06e5" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">Let us look at a MIDI performance. We will use the <a class="af pc" href="https://github.com/fosfrancesco/asap-dataset" rel="noopener ugc nofollow" target="_blank">ASAP dataset</a>, available on GitHub.</p><p id="42a5" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">In your favorite terminal (I’m using PowerShell on Windows), go to a convenient location and clone the repository.</p><pre class="ms mt mu mv mw qg qh qi bp qj bb bk"><span id="4c39" class="qk ob fq qh b bg ql qm l qn qo">git clone https://github.com/fosfrancesco/asap-dataset</span></pre><p id="bc8b" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">We will also use the Python library <a class="af pc" href="https://github.com/CPJKU/partitura" rel="noopener ugc nofollow" target="_blank">Partitura</a> to open the MIDI files, so you can install it in your Python environment.</p><pre class="ms mt mu mv mw qg qh qi bp qj bb bk"><span id="81a8" class="qk ob fq qh b bg ql qm l qn qo">pip install partitura</span></pre><p id="423a" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Now that everything is set, let’s open the MIDI file, and print the first 10 notes. Since this is a MIDI performance, we will use the <code class="cx qp qq qr qh b">load_midi_performance</code> function.</p><pre class="ms mt mu mv mw qg qh qi bp qj bb bk"><span id="785a" class="qk ob fq qh b bg ql qm l qn qo">from pathlib import Path<br/>import partitura as pt<br/><br/># set the path to the asap dataset (change it to your local path!)<br/>asap_basepath = Path('../asap-dataset/')<br/># select a performance, here we use Bach Prelude BWV 848 in C#<br/>performance_path = Path("Bach/Prelude/bwv_848/Denisova06M.mid")<br/>print("Loading midi file: ", asap_basepath/performance_path)<br/># load the performance<br/>performance = pt.load_performance_midi(asap_basepath/performance_path)<br/># extract the note array<br/>note_array = performance.note_array()<br/># print the dtype of the note array (helpful to know how to interpret it)<br/>print("Numpy dtype:")<br/>print(note_array.dtype)<br/># print the first 10 notes in the note array<br/>print("First 10 notes:")<br/>print(performance.note_array()[:10])</span></pre><p id="9145" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The output of this Python program should look like this:</p><pre class="ms mt mu mv mw qg qh qi bp qj bb bk"><span id="b1cb" class="qk ob fq qh b bg ql qm l qn qo">Numpy dtype:<br/>[('onset_sec', '&lt;f4'), ('duration_sec', '&lt;f4'), ('onset_tick', '&lt;i4'), ('duration_tick', '&lt;i4'), ('pitch', '&lt;i4'), ('velocity', '&lt;i4'), ('track', '&lt;i4'), ('channel', '&lt;i4'), ('id', '&lt;U256')]<br/>First 10 notes:<br/>[(1.0286459, 0.21354167,  790, 164, 49, 53, 0, 0, 'n0')<br/> (1.03125  , 0.09765625,  792,  75, 77, 69, 0, 0, 'n1')<br/> (1.1302084, 0.046875  ,  868,  36, 73, 64, 0, 0, 'n2')<br/> (1.21875  , 0.07942709,  936,  61, 68, 66, 0, 0, 'n3')<br/> (1.3541666, 0.04166667, 1040,  32, 73, 34, 0, 0, 'n4')<br/> (1.4361979, 0.0390625 , 1103,  30, 61, 62, 0, 0, 'n5')<br/> (1.4361979, 0.04296875, 1103,  33, 77, 48, 0, 0, 'n6')<br/> (1.5143229, 0.07421875, 1163,  57, 73, 69, 0, 0, 'n7')<br/> (1.6380209, 0.06380209, 1258,  49, 78, 75, 0, 0, 'n8')<br/> (1.6393229, 0.21484375, 1259, 165, 51, 54, 0, 0, 'n9')]</span></pre><p id="571b" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">You can see that we have the onset and durations in seconds, pitch and velocity. Other fields are not so relevant for MIDI performances.</p><p id="49af" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Onsets and durations are also represented in <em class="pb">ticks</em>. This is closer to the actual way this information is encoded in a MIDI file: a very short temporal duration (= 1 tick) is chosen, and all temporal information is encoded as a multiple of this duration. When you deal with music performances, you can typically ignore this information and use directly the information in seconds.</p><p id="e81d" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">You can verify that there are never two notes with exactly the same onset or the same duration!</p><h1 id="166b" class="pm ob fq bf oc pn po gq og pp pq gt ok pr ps pt pu pv pw px py pz qa qb qc qd bk">MIDI scores</h1><p id="4736" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">Midi scores use a <strong class="ng fr">much richer set of MIDI messages</strong> to encode information such as time signature, key signature, bar, and beat positions.</p><p id="578f" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">For this reason, <strong class="ng fr">they resemble musical scores</strong> (sheet music), even though <strong class="ng fr">they still miss some vital information</strong>, for example, pitch spelling, ties, dots, rests, beams, etc…</p><p id="f047" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The temporal information is not encoded in seconds but in more musically abstract units, like quarter notes.</p><h2 id="724c" class="oa ob fq bf oc od oe of og oh oi oj ok nn ol om on nr oo op oq nv or os ot ou bk">The main property of MIDI scores</h2><p id="4b6e" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">A fundamental characteristic of MIDI score is that <strong class="ng fr">all note onsets are aligned to a quantized grid</strong>, defined first by bar positions and then by recursive integer divisions (mainly by 2 and 3, but other divisions such as 5,7,11, etc…) are used for tuplets.</p><h2 id="3c52" class="oa ob fq bf oc od oe of og oh oi oj ok nn ol om on nr oo op oq nv or os ot ou bk">Hands-on example</h2><p id="de1c" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">We are now going to look at the score from Bach Prelude BWV 848 in C#, which is the score of the performance we loaded before. Partitura has a dedicated <code class="cx qp qq qr qh b">load_score_midi</code> function.</p><pre class="ms mt mu mv mw qg qh qi bp qj bb bk"><span id="ae68" class="qk ob fq qh b bg ql qm l qn qo">from pathlib import Path<br/>import partitura as pt<br/><br/># set the path to the asap dataset (change it to your local path!)<br/>asap_basepath = Path('../asap-dataset/')<br/># select a score, here we use Bach Prelude BWV 848 in C#<br/>score_path = Path("Bach/Prelude/bwv_848/midi_score.mid")<br/>print("Loading midi file: ", asap_basepath/score_path)<br/># load the score<br/>score = pt.load_score_midi(asap_basepath/score_path)<br/># extract the note array<br/>note_array = score.note_array()<br/># print the dtype of the note array (helpful to know how to interpret it)<br/>print("Numpy dtype:")<br/>print(note_array.dtype)<br/># print the first 10 notes in the note array<br/>print("First 10 notes:")<br/>print(score.note_array()[:10])</span></pre><p id="764a" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The output of this Python program should look like this:</p><pre class="ms mt mu mv mw qg qh qi bp qj bb bk"><span id="1e56" class="qk ob fq qh b bg ql qm l qn qo">Numpy dtype:<br/>[('onset_beat', '&lt;f4'), ('duration_beat', '&lt;f4'), ('onset_quarter', '&lt;f4'), ('duration_quarter', '&lt;f4'), ('onset_div', '&lt;i4'), ('duration_div', '&lt;i4'), ('pitch', '&lt;i4'), ('voice', '&lt;i4'), ('id', '&lt;U256'), ('divs_pq', '&lt;i4')]<br/>First 10 notes:<br/>[(0. , 1.9958333 , 0.  , 0.99791664,   0, 479, 49, 1, 'P01_n425', 480)<br/> (0. , 0.49583334, 0.  , 0.24791667,   0, 119, 77, 1, 'P00_n0', 480)<br/> (0.5, 0.49583334, 0.25, 0.24791667, 120, 119, 73, 1, 'P00_n1', 480)<br/> (1. , 0.49583334, 0.5 , 0.24791667, 240, 119, 68, 1, 'P00_n2', 480)<br/> (1.5, 0.49583334, 0.75, 0.24791667, 360, 119, 73, 1, 'P00_n3', 480)<br/> (2. , 0.99583334, 1.  , 0.49791667, 480, 239, 61, 1, 'P01_n426', 480)<br/> (2. , 0.49583334, 1.  , 0.24791667, 480, 119, 77, 1, 'P00_n4', 480)<br/> (2.5, 0.49583334, 1.25, 0.24791667, 600, 119, 73, 1, 'P00_n5', 480)<br/> (3. , 1.9958333 , 1.5 , 0.99791664, 720, 479, 51, 1, 'P01_n427', 480)<br/> (3. , 0.49583334, 1.5 , 0.24791667, 720, 119, 78, 1, 'P00_n6', 480)]</span></pre><p id="53df" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">You can see that the onsets of the notes are all falling exactly on a grid. If we consider <code class="cx qp qq qr qh b">onset_quarter</code> (the 3rd column) we can see that 16th notes fall every 0.25 quarters, as expected.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div class="mp mq qs"><img src="../Images/ca2dffd6524f8a72dd58c8dc6c7d411b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*hNV8FiuyY5IZnzn-_Cwe2g.png"/></div></figure><p id="32f8" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The duration is a bit more problematic. For example, in this score, a 16th note should have a <code class="cx qp qq qr qh b">quarter_duration</code> of 0.25. However, we can see from the Python output that the duration is actually 0.24791667. What happened is that MuseScore, which was used to generate this MIDI file, shortened a bit each note. Why? Just to make the audio rendition of this MIDI file sound a bit better. And it does indeed, at the cost of causing many problems to the people using these files for Computer Music research. Similar problems also exist in widely used datasets, such as the Lakh MIDI Dataset.</p><h1 id="f4fe" class="pm ob fq bf oc pn po gq og pp pq gt ok pr ps pt pu pv pw px py pz qa qb qc qd bk">MIDI scores vs MIDI performances</h1><p id="8a52" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">Given the differences between MIDI scores and MIDI performances we’ve seen, let me give you some generic guidelines that can help in correctly setting up your deep learning system.</p><p id="856c" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Prefer MIDI scores for music generation systems, since the quantized note positions can be represented with a pretty small vocabulary, and other simplifications are possible, like only considering monophonic melodies.</p><p id="a8b7" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Use MIDI performance for systems that target the way humans play and perceive music, for example, beat tracking systems, tempo estimators, and emotion recognition systems (focusing on expressive playing).</p><p id="3d53" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Use both kinds of data for tasks like score-following (input: performance, output: score) and expressive performance generation (input: score, output: performance).</p><h2 id="34a3" class="oa ob fq bf oc od oe of og oh oi oj ok nn ol om on nr oo op oq nv or os ot ou bk">Extra problems</h2><p id="c511" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">I have presented the main differences between MIDI scores and MIDI performances. However, as often happens, <strong class="ng fr">things may be more complex</strong>.</p><p id="affc" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">For example, some datasets, like the AMAPS datasets, are originally MIDI scores, but the authors introduced time changes at every note, <strong class="ng fr">to simulate the time deviation of real human players</strong> (note that this only happens between notes at different time positions; all notes in a chord will still be perfectly simultaneous).</p><p id="b174" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Moreover, some MIDI exports, like the one from MuseScore, will also try to make the MIDI score more similar to a MIDI performance, again by changing tempo indication if the piece changes tempo, by inserting a very small silence between consecutive notes (we saw this in the example before), and by playing grace notes as a very short note slightly before the reference note onset.</p><p id="c9db" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Indeed, grace notes constitute a very annoying problem in MIDI scores. Their duration is unspecified in musical terms, we just generically know that they should be “short”. And their onset is in the score the same one of the reference note, but this would sound very weird if we listed to an audio rendition of the MIDI file. Should we then shorten the previous note, or the next note to make space for the grace note?</p><p id="7556" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Other embellishments are also problematic since there are no unique rules on how to play them, for example, how many notes should a trill contains? Should a mordent start from the actual note or the upper note?</p><h1 id="134b" class="pm ob fq bf oc pn po gq og pp pq gt ok pr ps pt pu pv pw px py pz qa qb qc qd bk">Conclusion</h1><p id="ed68" class="pw-post-body-paragraph ne nf fq ng b go ow ni nj gr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz fj bk">MIDI files are great, because they explicitly provide information about the pitch, onset, and duration of every note. This means for example that, compared to audio files, models targeting MIDI data can be smaller and be trained with smaller datasets.</p><p id="40d3" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">This comes at a cost: MIDI files, and symbolically encoded music in general, are complex formats to use since they encode so many kinds of information in many different ways.</p><p id="cc89" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">To properly use MIDI data as training data, it is important to be aware of the kind of data that are encoded. I hope this article gave you a good starting point to learn more about this topic!</p><p id="0008" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">[All figures are from the author.]</p></div></div></div></div>    
</body>
</html>