- en: 'How to succeed with AI: Combining Kafka and AI Guardrails'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-succeed-with-ai-combining-kafka-and-ai-guardrails-536124d4fb54?source=collection_archive---------11-----------------------#2024-10-03](https://towardsdatascience.com/how-to-succeed-with-ai-combining-kafka-and-ai-guardrails-536124d4fb54?source=collection_archive---------11-----------------------#2024-10-03)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why real-time data and governance are non-negotiable for AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://sderosiaux.medium.com/?source=post_page---byline--536124d4fb54--------------------------------)[![Stéphane
    Derosiaux](../Images/ad0ec5762ad509bbcdd09a761853f5fb.png)](https://sderosiaux.medium.com/?source=post_page---byline--536124d4fb54--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--536124d4fb54--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--536124d4fb54--------------------------------)
    [Stéphane Derosiaux](https://sderosiaux.medium.com/?source=post_page---byline--536124d4fb54--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--536124d4fb54--------------------------------)
    ·5 min read·Oct 3, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6869b2dd383d74de382e445d719a5822.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Sid Verma](https://unsplash.com/@sidverma?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Kafka is great. AI is great. What happens when we combine both? **Continuity**.
  prefs: []
  type: TYPE_NORMAL
- en: —
  prefs: []
  type: TYPE_NORMAL
- en: 'AI is changing many things about our efficiency and how we operate: sublime
    translations, customer interactions, code builder, driving our cars etc. Even
    if we love cutting-edge things, we’re all having a hard time keeping up with it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a massive problem we tend to forget: AI can easily go off the rails
    without the right **guardrails**. And when it does, it’s not just a technical
    glitch, it can lead to disastrous consequences for the business.'
  prefs: []
  type: TYPE_NORMAL
- en: From my own experience as a CTO, I’ve seen firsthand that real AI success doesn’t
    come from speed alone. It comes from **control** — control over the data your
    AI consumes, how it operates, and ensuring it doesn’t deliver the wrong outputs
    (more on this below).
  prefs: []
  type: TYPE_NORMAL
- en: The other part of the success is about maximizing the potential and impact of
    AI. That’s where **Kafka** and data streaming enter the game
  prefs: []
  type: TYPE_NORMAL
- en: Both AI Guardrails and Kafka are key to scaling a safe, compliant, and reliable
    AI.
  prefs: []
  type: TYPE_NORMAL
- en: AI without Guardrails is an open book
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the biggest risks when dealing with AI is the absence of built-in governance.
    When you rely on AI/LLMs to automate processes, talk to customers, handle sensitive
    data, or make decisions, you’re opening the door to a range of risks:'
  prefs: []
  type: TYPE_NORMAL
- en: data leaks (and prompt leaks as we’re used to see)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: privacy breaches and compliance violations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: data bias and discrimination
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: out-of-domain prompting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: poor decision-making
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember March 2023? [OpenAI had an incident](https://openai.com/index/march-20-chatgpt-outage/)where
    a bug caused chat data to be exposed to other users. The bottom line is that LLMs
    don’t have built-in security, authentication, or authorization controls. An LLM
    is like a massive open book — anyone accessing it can potentially retrieve information
    they shouldn’t. That’s why you need a robust layer of control and context in between,
    to govern access, validate inputs, and ensure sensitive data remains protected.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is where AI guardrails, like [NeMo](https://github.com/NVIDIA/NeMo-Guardrails)
    (by Nvidia) and [LLM Guard](https://llm-guard.com/), come into the picture. They
    provide essential checks on the inputs and outputs of the LLM:'
  prefs: []
  type: TYPE_NORMAL
- en: prompt injections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: filtering out biased or toxic content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ensuring **personal data** isn’t slipping through the cracks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: out-of-context prompts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: jailbreaks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/29cc90f157428c2a1588146b29130bee.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/leondz/garak](https://github.com/leondz/garak/) is an LLM
    vulnerability scanner. It checks if an LLM can be made to fail in a way we don’t
    want. It probes for hallucination, data leakage, prompt injection, misinformation,
    toxicity generation, jailbreaks, and many other weaknesses.'
  prefs: []
  type: TYPE_NORMAL
- en: What’s the link with Kafka?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kafka is an open-source platform designed for handling real-time data streaming
    and sharing within organizations. And AI thrives on real-time data to remain useful!
  prefs: []
  type: TYPE_NORMAL
- en: Feeding AI static, outdated datasets is a recipe for failure — it will only
    function up to a certain point, after which it won’t have fresh information. Think
    about ChatGPT always having a ‘cut-off’ date in the past. AI becomes practically
    useless if, for example, during customer support, the AI don’t have the latest
    invoice of a customer asking things because the data isn’t up-to-date.
  prefs: []
  type: TYPE_NORMAL
- en: Methods like RAG (Retrieval Augmented Generation) fix this issue by providing
    AI with relevant, real-time information during interactions. RAG works by ‘augmenting’
    the prompt with additional context, which the LLM processes to generate more useful
    responses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Guess what is frequently paired with RAG? **Kafka**. What better solution to
    fetch real-time information and seamlessly integrate it with an LLM? Kafka continuously
    streams fresh data, which can be composed with an LLM through a simple HTTP API
    in front. One critical aspect is to ensure the quality of the data being streamed
    in Kafka is under control: no bad data should enter the pipeline (Data Validations)
    or it will spread throughout your AI processes: inaccurate outputs, biased decisions,
    security vulnerabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical streaming architecture combining Kafka, AI Guardrails, and RAG:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/073899fd0c5901f5891e4d9a029b0d60.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: '[Gartner predicts that by 2025](https://www.gartner.com/en/documents/3868267),
    organizations leveraging AI and automation will cut operational costs by up to
    30%. Faster, smarter.'
  prefs: []
  type: TYPE_NORMAL
- en: Should we care about AI Sovereignty? Yes.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AI sovereignty is about ensuring that you fully control where your AI runs,
    how data is ingested, processed, and who has access to it. It’s not just about
    the software, it’s about the hardware as well, and the physical place things are
    happening.
  prefs: []
  type: TYPE_NORMAL
- en: '**Sovereignty is about the virtual, physical infrastructure and geopolitical
    boundaries where your data resides.** We live in a physical world, and while AI
    might seem intangible, it’s bound by real-world regulations.'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, depending on where your AI infrastructure is hosted, different
    jurisdictions may demand access to your data (e.g. the States!), even if it’s
    processed by an AI model. That’s why ensuring sovereignty means controlling not
    just the code, but the physical hardware and the environment where the processing
    happens.
  prefs: []
  type: TYPE_NORMAL
- en: Technologies like **Intel SGX** (Software Guard Extensions) and **AMD SEV**
    (Secure Encrypted Virtualization) offer this kind of protection. They create isolated
    execution environments that protect sensitive data and code, even from potential
    threats inside the host system itself. And solutions like [Mithril Security](https://www.mithrilsecurity.io/)
    are also stepping up, providing Confidential AI where the AI provider cannot even
    access the data processed by their LLM.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dcc842626ebe0f9d2d6bb6885b0e7518.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s clear that AI guardrails and Kafka streaming are the foundation to make
    use-cases relying on AI successful. Without Kafka, AI models operate on stale
    data, making them unreliable and not very useful. And without AI guardrails, AI
    is at risk of making dangerous mistakes — compromising privacy, security, and
    decision quality.
  prefs: []
  type: TYPE_NORMAL
- en: This formula is what keeps AI on track and in control. The risks of operating
    without it are simply too high.
  prefs: []
  type: TYPE_NORMAL
