- en: Creating Task-Oriented Dialog systems with LangGraph and LangChain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LangGraph和LangChain创建任务导向对话系统
- en: 原文：[https://towardsdatascience.com/creating-task-oriented-dialog-systems-with-langgraph-and-langchain-fada6c9c4983?source=collection_archive---------2-----------------------#2024-09-14](https://towardsdatascience.com/creating-task-oriented-dialog-systems-with-langgraph-and-langchain-fada6c9c4983?source=collection_archive---------2-----------------------#2024-09-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/creating-task-oriented-dialog-systems-with-langgraph-and-langchain-fada6c9c4983?source=collection_archive---------2-----------------------#2024-09-14](https://towardsdatascience.com/creating-task-oriented-dialog-systems-with-langgraph-and-langchain-fada6c9c4983?source=collection_archive---------2-----------------------#2024-09-14)
- en: Yet another LangGraph tutorial
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 又一篇LangGraph教程
- en: '[](https://medium.com/@mesquitadeh?source=post_page---byline--fada6c9c4983--------------------------------)[![Déborah
    Mesquita](../Images/3b77b7eb569e24f2679875429173daf1.png)](https://medium.com/@mesquitadeh?source=post_page---byline--fada6c9c4983--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--fada6c9c4983--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--fada6c9c4983--------------------------------)
    [Déborah Mesquita](https://medium.com/@mesquitadeh?source=post_page---byline--fada6c9c4983--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mesquitadeh?source=post_page---byline--fada6c9c4983--------------------------------)[![Déborah
    Mesquita](../Images/3b77b7eb569e24f2679875429173daf1.png)](https://medium.com/@mesquitadeh?source=post_page---byline--fada6c9c4983--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--fada6c9c4983--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--fada6c9c4983--------------------------------)
    [Déborah Mesquita](https://medium.com/@mesquitadeh?source=post_page---byline--fada6c9c4983--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--fada6c9c4983--------------------------------)
    ·11 min read·Sep 14, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--fada6c9c4983--------------------------------)
    ·阅读时间11分钟·2024年9月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/df4dbf4e422ff2e27cc77246f75e6d94.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df4dbf4e422ff2e27cc77246f75e6d94.png)'
- en: Image by [Kaleidico](https://unsplash.com/pt-br/@kaleidico?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/pt-br/fotografias/duas-pessoas-desenhando-no-quadro-branco-26MJGnCM0Wc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Kaleidico](https://unsplash.com/pt-br/@kaleidico?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    于[Unsplash](https://unsplash.com/pt-br/fotografias/duas-pessoas-desenhando-no-quadro-branco-26MJGnCM0Wc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: A Task-Oriented Dialogue system (ToD) is a system that assists users in **achieving
    a particular task**, such as booking a restaurant, planning a travel itinerary
    or ordering delivery food.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 任务导向对话系统（ToD）是帮助用户**完成特定任务**的系统，例如预定餐厅、规划旅行行程或订餐。
- en: We know that we instruct LLMs using prompts, but how can we implement these
    ToD systems so that **the conversation always revolves around the task we want
    the users to achieve**? One way of doing that is by using **prompts**, **memory**
    and **tool calling.** FortunatelyLangChain + LangGraph can help us tie all these
    things together.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，使用提示语（prompts）来指导大型语言模型（LLMs），但我们如何实现这些任务导向对话系统（ToD），使得**对话始终围绕我们希望用户完成的任务**展开呢？一种方法是使用**提示语**、**记忆**和**工具调用**。幸运的是，LangChain
    + LangGraph可以帮助我们将这些要素结合起来。
- en: In this article, you’ll learn how to build a Task Oriented Dialogue System that
    helps users create User Stories with a high level of quality. The system is all
    based on LangGraph’s [Prompt Generation from User Requirements](https://langchain-ai.github.io/langgraph/tutorials/chatbots/information-gather-prompting/)
    tutorial.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，您将学习如何构建一个任务导向对话系统，帮助用户以高质量创建用户故事。该系统完全基于LangGraph的[根据用户需求生成提示](https://langchain-ai.github.io/langgraph/tutorials/chatbots/information-gather-prompting/)教程。
- en: Why do we need to use LangGraph?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我们需要使用LangGraph？
- en: In this tutorial we assume you already know how to use LangChain. A User Story
    has some components like objective, success criteria, plan of execution and deliverables.
    The user should provide each of them, and we need to “hold their hand” into providing
    them one by one. Doing that using only LangChain would require a lot of ifs and
    elses.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们假设您已经知道如何使用LangChain。用户故事包含一些组件，如目标、成功标准、执行计划和交付物。用户应提供每一个组件，而我们需要一步步地“引导”他们逐个提供。仅使用LangChain实现这一点会需要大量的条件判断语句（if/else）。
- en: With LangGraph we can use a graph abstraction to **create cycles** to control
    the dialogue. It also has **built-in persistence**, so we don’t need to worry
    about actively tracking the interactions that happen within the graph.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LangGraph，我们可以使用图抽象来**创建循环**来控制对话。它还具有**内置持久性**，因此我们无需担心主动追踪图内发生的交互。
- en: 'The main LangGraph abstraction is the [**StateGraph**](https://langchain-ai.github.io/langgraph/reference/graphs/#stategraph),
    which is used to create graph workflows. Each graph needs to be initialized with
    a **state_schema**: a schema class that each node of the graph uses to read and
    write information.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: LangGraph 的主要抽象是 [**StateGraph**](https://langchain-ai.github.io/langgraph/reference/graphs/#stategraph)，它用于创建图工作流。每个图都需要用**state_schema**
    初始化：一个每个节点使用的模式类，用于读取和写入信息。
- en: 'The flow of our system will consist of rounds of *LLM* and *user* messages.
    The main loop will contain these steps:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统的流程将由*LLM*和*用户*消息的轮次组成。主要循环包含以下步骤：
- en: User says something
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户说了些什么
- en: LLM reads the messages of the state and decides if it’s ready to create the
    User Story or if the user should respond again
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM 读取状态中的消息，并决定是否准备好创建用户故事，或者是否需要用户再次响应
- en: Our system is simple so the schema consists only of the messages that were exchanged
    in the dialogue.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的系统很简单，因此架构仅包含对话中交换的消息。
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The **add_messages** method is used to merge the output messages from each **node**
    into the existing list of messages in the graph’s state.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**add_messages** 方法用于将每个**节点**的输出消息合并到图中现有状态的消息列表中。'
- en: Speaking about nodes, another two main LangGraph concepts are **Nodes** and
    **Edges**. Each **node** of the graph runs a function and each **edge** controls
    the flow of one node to another. We also have **START** and **END** virtual nodes
    to tell the graph where to start the execution and where the execution should
    end.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 说到节点，另两个主要的 LangGraph 概念是**节点**和**边**。每个图的**节点**运行一个函数，每个**边**控制一个节点到另一个节点的流动。我们还有**START**和**END**虚拟节点，告诉图从哪里开始执行以及执行应该在哪里结束。
- en: 'To run the system we’ll use the `.stream()` method. After we build the graph
    and compile it, **each round of interaction will go through the START until the
    END of the graph** and the path it takes (which nodes should run or not) is controlled
    by our workflow combined with the state of the graph. The following code has the
    main flow of our system:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行系统，我们将使用 `.stream()` 方法。在构建并编译图后，**每一轮交互都会经过图的 START，直到 END**，它的路径（哪些节点应运行或不运行）由我们的工作流与图的状态共同控制。以下代码包含我们系统的主要流程：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: At each interaction (if the user didn’t type “q” or “Q” to quit) we run graph.stream()
    passing the message of the user using the “updates” stream_mode, which streams
    the updates of the state after each step of the graph ([https://langchain-ai.github.io/langgraph/concepts/low_level/#stream-and-astream](https://langchain-ai.github.io/langgraph/concepts/low_level/#stream-and-astream)).
    We then get this last message from the state_schema and print it.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次交互时（如果用户没有输入“q”或“Q”退出），我们运行 graph.stream()，传递用户消息，并使用“updates” stream_mode，它会流式传输图每一步后状态的更新（[https://langchain-ai.github.io/langgraph/concepts/low_level/#stream-and-astream](https://langchain-ai.github.io/langgraph/concepts/low_level/#stream-and-astream)）。然后我们从
    state_schema 获取最后一条消息并打印出来。
- en: In this tutorial we’ll still learn how to create the nodes and edges of the
    graph, but first let’s talk more about the architecture of ToD systems in general
    and learn how to implement one with **LLMs**, **prompts** and **tool calling**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们仍然会学习如何创建图的节点和边，但首先让我们更多地了解 ToD 系统的架构，并学习如何用**LLMs**、**提示**和**工具调用**实现一个系统。
- en: The Architecture of ToD systems
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ToD 系统的架构
- en: 'The main components of a framework to build **End-to-End Task-Oriented Dialogue
    systems** are [1]:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 构建**端到端任务导向对话系统**的框架的主要组件是 [1]：
- en: Natural Language Understanding (NLU) for **extracting the intent and key slots
    of users**
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自然语言理解（NLU）用于**提取用户的意图和关键信息**
- en: Dialogue State Tracking (DST) for **tracing users’ belief state** given dialogue
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对话状态跟踪（DST）用于**追踪用户在对话中的信念状态**
- en: Dialogue Policy Learning (DPL) to **determine the next step to take**
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对话策略学习（DPL）用于**确定下一步操作**
- en: Natural Language Generation (NLG) for **generating dialogue system response**
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自然语言生成（NLG）用于**生成对话系统响应**
- en: '![](../Images/a4be2cd1978b86ea567eaae32cea0cf2.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4be2cd1978b86ea567eaae32cea0cf2.png)'
- en: Main components of a ToD system (image from Qin, Libo, et al [1])
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ToD 系统的主要组件（图片来自秦立波等人 [1]）
- en: By using LLMs, we can combine some of these components into only one. The **NLP**
    and the **NLG** components are easy peasy to implement using LLMs since understanding
    and generating dialogue responses are their specialty.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用LLM，我们可以将这些组件中的一些组合成一个。**NLP**和**NLG**组件使用LLM实现起来轻而易举，因为理解和生成对话回应正是它们的专长。
- en: 'We can implement the Dialogue State Tracking (**DST**) and the Dialogue Policy
    Learning (**DPL**) by using LangChain’s **SystemMessage** to prime the AI behavior
    and always pass this message every time we interact with the LLM. The state of
    the dialogue should also always be passed to the LLM at every interaction with
    the model. This means that we will make sure the dialogue is always centered around
    the task we want the user to complete by **always telling the LLM what the goal
    of the dialogue is and how it should behave.** We’ll do that first by using a
    prompt:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用LangChain的**SystemMessage**来实现对话状态跟踪（**DST**）和对话策略学习（**DPL**），以引导AI行为，并在每次与LLM互动时始终传递此消息。对话的状态也应始终在每次与模型互动时传递给LLM。这意味着我们将确保对话始终围绕我们希望用户完成的任务进行，**通过始终告诉LLM对话的目标是什么以及它应如何行为**。我们首先通过使用提示来做到这一点：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And then appending this prompt everytime we send a message to the LLM:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后每次我们向LLM发送消息时，都附加这个提示：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Another important concept of our ToD system LLM implementation is **tool calling**.
    If you read the last sentence of the **prompt_system_task** again it says “*After
    you are able to discern all the information, call the relevant tool*”. This way,
    we are telling the LLM that when it decides that the user provided all the User
    Story parameters, **it should call the tool to create the User Story**. Our tool
    for that will be created using a Pydantic model with the User Story parameters.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们ToD系统LLM实现的另一个重要概念是**工具调用**。如果你再次阅读**prompt_system_task**的最后一句话，它说：“*在你能够辨识出所有信息后，调用相关工具*”。通过这种方式，我们在告诉LLM，当它判断用户提供了所有用户故事参数时，**它应该调用工具来创建用户故事**。我们为此创建的工具将使用Pydantic模型与用户故事参数来构建。
- en: By using only the prompt and tool calling, we can control our ToD system. Beautiful
    right? Actually we also need to use **the state of the graph** to make all this
    work. Let’s do it in the next section, where we’ll finally build the ToD system.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仅使用提示和工具调用，我们可以控制我们的ToD系统。很棒对吧？实际上，我们还需要使用**图的状态**来使这一切正常工作。我们将在下一节中完成这一部分，届时我们将最终构建ToD系统。
- en: Creating the dialogue system to build User Stories
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建对话系统以构建用户故事
- en: 'Alright, time to do some coding. First we’ll specify which LLM model we’ll
    use, then set the prompt and bind the tool to generate the User Story:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，开始编码吧。首先我们将指定使用哪个LLM模型，然后设置提示并绑定工具来生成用户故事：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As we were talking earlier, the state of our graph consists only of the messages
    exchanged and a flag to know if the user story was created or not. Let’s create
    the graph first using **StateGraph** and this schema:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所讨论的，我们图的状态仅包括交换的消息和一个标志，用于判断用户故事是否已创建。让我们首先使用**StateGraph**和这个模式来创建图：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The next image shows the structure of the final graph:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下一张图展示了最终图的结构：
- en: '![](../Images/a2eb92c3d942ba8fb79c921ee2362301.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2eb92c3d942ba8fb79c921ee2362301.png)'
- en: The structure of the ToD graph to create User Stories (image created by the
    author)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建用户故事的ToD图的结构（图像由作者创建）
- en: 'At the top we have a **talk_to_user** node. This node can either:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部我们有一个**talk_to_user**节点。这个节点可以是：
- en: Finalize the dialogue (go to the **finalize_dialogue** node)
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成对话（跳转到**finalize_dialogue**节点）
- en: Decide that it’s time to wait for the user input (go to the **END** node)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定是时候等待用户输入了（跳转到**END**节点）
- en: Since the main loop runs forever (*while True*), every time the graph reaches
    the END node, it waits for the user input again. This will become more clear when
    we create the loop.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于主循环是永远运行的（*while True*），每当图到达END节点时，它会再次等待用户输入。等到我们创建循环时，这一点会变得更加清晰。
- en: 'Let’s create the nodes of the graph, starting with the **talk_to_user** node.
    This node needs to keep track of the task (maintaing the main prompt during all
    the conversation) and also keep the message exchanges because it’s where the state
    of the dialogue is stored. This state also keeps which parameters of the User
    Story are already filled or not using the messages. So this node should add the
    SystemMessage every time and append the new message from the LLM:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从**talk_to_user**节点开始创建图中的节点。这个节点需要跟踪任务（在整个对话中保持主要提示），并且还需要保持消息交换，因为它是存储对话状态的地方。这个状态还会跟踪哪些用户故事的参数已经填写，哪些还没有，使用的是消息。因此，每次此节点应该添加**SystemMessage**并附加来自LLM的新消息：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now we can add the **talk_to_user** node to this graph. We’ll do that by giving
    it a name and then passing the function we’ve created:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将**talk_to_user**节点添加到此图中了。我们通过为它命名，然后传递我们创建的函数来完成这个操作：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This node should be the first node to run in the graph, so let’s specify that
    with an **edge**:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点应该是图中运行的第一个节点，所以我们通过**边**来指定这一点：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'So far the graph looks like this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，图是这样的：
- en: '![](../Images/da757765b057ce82f01f6af98a41e93b.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da757765b057ce82f01f6af98a41e93b.png)'
- en: Our graph with only one node (image created by the author)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是只有一个节点的图（由作者创建的图像）
- en: 'To control the flow of the graph, we’ll also use the message classes from LangChain.
    We have four types of messages:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了控制图的流程，我们还将使用LangChain中的消息类。我们有四种类型的消息：
- en: '**SystemMessage:** message for priming AI behavior'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SystemMessage：** 用于引导AI行为的消息'
- en: '**HumanMessage:** message from a human'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HumanMessage：** 来自人类的消息'
- en: '**AIMessage:** the message returned from a chat model as a response to a prompt'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AIMessage：** 从聊天模型返回的作为对提示的响应的消息'
- en: '**ToolMessage:** message containing the result of a tool invocation, used for
    passing the result of executing a tool back to a model'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ToolMessage：** 包含工具调用结果的消息，用于将执行工具的结果传递回模型'
- en: We’ll use **the type** of the last message of the **graph state** to control
    the flow on the **talk_to_user** node. If the last message is an ***AIMessage***
    and it has the ***tool_calls*** key, then we’ll go to the **finalize_dialogue**
    node because it’s time to create the User Story. Otherwise, we should go to the
    **END** node because we’ll restart the loop since it’s time for the user to answer.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**图状态**中最后一条消息的**类型**来控制**talk_to_user**节点的流程。如果最后一条消息是***AIMessage***并且它包含***tool_calls***键，那么我们将跳转到**finalize_dialogue**节点，因为该是创建用户故事的时候了。否则，我们应该跳转到**END**节点，因为该是用户回答的时候，应该重启循环。
- en: 'The **finalize_dialogue** node should build the **ToolMessage** to pass the
    result to the model. The **tool_call_id** field is used to associate the tool
    call request with the tool call response. Let’s create this node and add it to
    the graph:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**finalize_dialogue**节点应该构建**ToolMessage**来将结果传递给模型。**tool_call_id**字段用于将工具调用请求与工具调用响应关联。让我们创建这个节点并将它添加到图中：'
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now let’s create the last node, the **create_user_story** one. This node will
    call the LLM using the prompt to create the User Story and the information that
    was gathered during the conversation. If the model decided that it was time to
    call the tool then the values of the key **tool_calls** should have all the info
    to create the User Story.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建最后一个节点，**create_user_story**节点。此节点将使用提示调用LLM来创建用户故事，并将对话过程中收集到的信息包含在内。如果模型决定该是调用工具的时机，那么**tool_calls**键的值应该包含创建用户故事所需的所有信息。
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'With all the nodes are created, it’s time to add the **edges**. We’ll add a
    conditional edge to the **talk_to_user** node. Remember that this node can either:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 所有节点创建完成后，接下来是添加**边**。我们将向**talk_to_user**节点添加一个条件边。记住，这个节点可以：
- en: Finalize the dialogue if it’s time to call the tool (go to the **finalize_dialogue**
    node)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果该是调用工具的时机，就结束对话（跳转到**finalize_dialogue**节点）
- en: Decide that we need to gather user input (go to the **END** node)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定我们需要收集用户输入（跳转到**END**节点）
- en: 'This means that we’ll only check if the last message is an AIMessage and has
    the tool_calls key; otherwise we should go to the END node. Let’s create a function
    to check this and add it as an edge:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们只检查最后一条消息是否是AIMessage，并且是否包含tool_calls键；否则我们应该跳转到END节点。让我们创建一个函数来检查这个，并将它作为一条边添加：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now let’s add the other edges:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们添加其他边：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With that the graph workflow is done. Time to compile the graph and create
    the loop to run it:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这样图的工作流程就完成了。是时候编译图并创建循环来运行它了：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let’s finally test the system:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后让我们测试系统：
- en: '![](../Images/f88a5dbb64636f7ecc2afae4a90569d9.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f88a5dbb64636f7ecc2afae4a90569d9.png)'
- en: The assistant in action (image created by the author)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 助手在行动中（图片由作者创建）
- en: Final Thoughts
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的思考
- en: With LangGraph and LangChain we can build systems that guide users through structured
    interactions reducing the complexity to create them by using the LLMs to help
    us control the conditional logic.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有了 LangGraph 和 LangChain，我们可以构建引导用户通过结构化互动的系统，借助 LLMs 帮助我们控制条件逻辑，从而减少创建它们的复杂性。
- en: With the combination of prompts, memory management, and tool calling we can
    create intuitive and effective dialogue systems, opening new possibilities for
    user interaction and task automation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合提示、记忆管理和工具调用，我们可以创建直观且有效的对话系统，开启用户互动和任务自动化的新可能性。
- en: I hope that this tutorial help you better understand how to use LangGraph (I’ve
    spend a couple of days banging my head on the wall to understand how all the pieces
    of the library work together).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这个教程能帮助你更好地理解如何使用 LangGraph（我花了好几天时间琢磨如何让这个库的所有部分协同工作）。
- en: 'All the code of this tutorial can be found here: [dmesquita/task_oriented_dialogue_system_langgraph
    (github.com)](https://github.com/dmesquita/task_oriented_dialogue_system_langgraph)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的所有代码可以在这里找到：[dmesquita/task_oriented_dialogue_system_langgraph (github.com)](https://github.com/dmesquita/task_oriented_dialogue_system_langgraph)
- en: Thanks for reading!
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: References
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Qin, Libo, et al. “End-to-end task-oriented dialogue: A survey of tasks,
    methods, and future directions.” *arXiv preprint arXiv:2311.09008* (2023).'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Qin, Libo, 等人。“端到端任务导向对话：任务、方法及未来方向的调查。” *arXiv 预印本 arXiv:2311.09008* (2023)。'
- en: '[2] *Prompt generation from user requirements*. Available at: [https://langchain-ai.github.io/langgraph/tutorials/chatbots/information-gather-prompting](https://langchain-ai.github.io/langgraph/tutorials/chatbots/information-gather-prompting)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] *从用户需求生成提示*。可在以下地址查看：[https://langchain-ai.github.io/langgraph/tutorials/chatbots/information-gather-prompting](https://langchain-ai.github.io/langgraph/tutorials/chatbots/information-gather-prompting)'
