- en: Neural Network (MLP) for Time Series Forecasting in Practice
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络（MLP）在时间序列预测中的实践应用
- en: 原文：[https://towardsdatascience.com/neural-network-mlp-for-time-series-forecasting-in-practice-04c47c1e3711?source=collection_archive---------0-----------------------#2024-07-08](https://towardsdatascience.com/neural-network-mlp-for-time-series-forecasting-in-practice-04c47c1e3711?source=collection_archive---------0-----------------------#2024-07-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/neural-network-mlp-for-time-series-forecasting-in-practice-04c47c1e3711?source=collection_archive---------0-----------------------#2024-07-08](https://towardsdatascience.com/neural-network-mlp-for-time-series-forecasting-in-practice-04c47c1e3711?source=collection_archive---------0-----------------------#2024-07-08)
- en: A Practical Example for Feature Engineering and Constructing an MLP Model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程和构建 MLP 模型的实用示例
- en: '[](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)[![Daniel
    J. TOTH](../Images/a7fd7d723abdba92c493c3dd9aeb2273.png)](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)
    [Daniel J. TOTH](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)[![Daniel
    J. TOTH](../Images/a7fd7d723abdba92c493c3dd9aeb2273.png)](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)
    [Daniel J. TOTH](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)
    ·16 min read·Jul 8, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)
    ·阅读时长 16 分钟·2024 年 7 月 8 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '**Introduction**'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**介绍**'
- en: Time series and more specifically time series forecasting is a very well known
    data science problem among professionals and business users alike.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列，尤其是时间序列预测，是数据科学领域一个非常著名的问题，受专业人士和商业用户的广泛关注。
- en: Several forecasting methods exist, which may be grouped as statistical or machine
    learning methods for comprehension and a better overview, but as a matter of fact,
    the demand for forecasting is so high that the available options are abundant.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 存在多种预测方法，可以将它们归类为统计方法或机器学习方法，便于理解和概览，但实际上，预测需求如此之高，现有的选项种类繁多。
- en: Machine learning methods are considered state-of-the-art approach in time series
    forecasting and are increasing in popularity, due to the fact that they are able
    to capture complex non-linear relationships within the data and generally yield
    higher accuracy in forecasting [1]. One popular machine learning field is the
    landscape of neural networks. Specifically for time series analysis, recurrent
    neural networks have been developed and applied to solve forecasting problems
    [2].
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习方法被认为是时间序列预测中的最先进方法，并且因能够捕捉数据中的复杂非线性关系而越来越受欢迎，通常能提供更高的预测准确性[1]。其中，神经网络领域是一个广受关注的机器学习分支。特别是在时间序列分析中，循环神经网络已经被开发并应用于解决预测问题[2]。
- en: Data science enthusiasts might find the complexity behind such models intimidating
    and being one of you I can tell that I share that feeling. However, this article
    aims to show that
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学爱好者可能会觉得这些模型背后的复杂性令人望而生畏，作为其中的一员，我可以告诉你，我也有同样的感觉。然而，本文旨在展示
- en: despite the latest developments in machine learning methods, it is not necessarily
    worth pursuing the most complex application when looking for a solution for a
    particular problem. Well-established methods enhanced with powerful feature engineering
    techniques could still provide satisfactory results.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管机器学习方法的最新进展非常显著，但在寻求特定问题的解决方案时，并不一定需要追求最复杂的应用。经过强化的成熟方法与强大的特征工程技术结合，依然能够提供令人满意的结果。
- en: More specifically, I apply a Multi-Layer Perceptron model and share the code
    and results, so you can get a hands-on experience on engineering time series features
    and forecasting effectively.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我应用了多层感知器模型，并分享了代码和结果，让你能够亲自体验如何有效地进行时间序列特征工程和预测。
- en: '**Goal of the Article**'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**本文目标**'
- en: 'More precisely what I aim at to provide for fellow self-taught professionals,
    could be summarized in the following points:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 更准确地说，我想为自学的专业人士提供的内容可以总结为以下几点：
- en: forecasting based on real-world problem / data
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于实际问题/数据进行预测
- en: how to engineer time series features for capturing temporal patterns
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何为捕捉时间模式工程化时间序列特征
- en: 'build an MLP model capable of utilizing mixed variables: floats and integers
    (treated as categoricals via embedding)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个能够利用混合变量（浮动和整数，通过嵌入处理为类别变量）的MLP模型
- en: use MLP for point forecasting
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MLP进行点预测
- en: use MLP for multi-step forecasting
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MLP进行多步预测
- en: assess feature importance using permutation feature importance method
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用置换特征重要性方法评估特征重要性
- en: retrain model for a subset of grouped features (multiple groups, trained for
    individual groups) to refine the feature importance of grouped features
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 针对一组分组特征（多个组，分别针对每个组进行训练）重新训练模型，以细化分组特征的重要性
- en: evaluate the model by comparing to an `UnobservedComponents` model
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过与`UnobservedComponents`模型进行比较来评估模型
- en: '**Key Technical Terms**'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**关键技术术语**'
- en: 'Please note, that this article assumes the prior knowledge of some key technical
    terms and do not intend to explain them in details. Find those key terms below,
    with references provided, which could be checked for clarity:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，本文假定读者已经具备一些关键技术术语的基础知识，并不打算详细解释这些术语。以下列出了这些关键术语，并提供了参考，读者可查阅以便理解：
- en: '**Time Series** [3]'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**时间序列** [3]'
- en: '**Prediction** [4] — in this context it will be used to distinguish model outputs
    in the training period'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测** [4] — 在这种情况下，它将用于区分训练期间的模型输出'
- en: '**Forecast** [4] — in this context it will be used to distinguish model outputs
    in the test period'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测** [4] — 在这种情况下，它将用于区分测试期间的模型输出'
- en: '**Feature Engineering** [5]'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征工程** [5]'
- en: '**Autocorrelation** [6]'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自相关** [6]'
- en: '**Partial Autocorrelation** [6]'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**偏自相关** [6]'
- en: '**MLP (Multi-Layer Perceptron)** [7]'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**MLP（多层感知器）** [7]'
- en: '**Input Layer** [7]'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输入层** [7]'
- en: '**Hidden Layer** [7]'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**隐藏层** [7]'
- en: '**Output Layer** [7]'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输出层** [7]'
- en: '**Embedding** [8]'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入** [8]'
- en: '**State Space Models** [9]'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**状态空间模型** [9]'
- en: '**Unobserved Components Model** [9]'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**未观察到的组件模型** [9]'
- en: '**RMSE (Root Mean Squared Error)** [10]'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**RMSE（均方根误差）** [10]'
- en: '**Feature Importance** [11]'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征重要性** [11]'
- en: '**Permutation Feature Importance** [11]'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**置换特征重要性** [11]'
- en: '**Data Exploration**'
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**数据探索**'
- en: The essential packages used during the analysis are `numpy` and `pandas` for
    data manipulation, `plotly` for interactive charts, `statsmodels` for statistics
    and state space modeling and finally, `tensorflow` for MLP architcture.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析过程中使用的核心包包括：用于数据处理的`numpy`和`pandas`，用于交互式图表的`plotly`，用于统计和状态空间建模的`statsmodels`，以及用于MLP架构的`tensorflow`。
- en: '*Note: due to technical limitations, I will provide the code snippets for interactive
    plotting, but the figures will be static presented here.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：由于技术限制，我将提供交互式绘图的代码片段，但此处展示的图表将是静态的。*'
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The data is loaded automatically using `opendatasets`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据通过`opendatasets`自动加载。
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Keep in my mind, that data cleaning was an essential first step in order to
    progress with the analysis. If you are interested in the details and also in state
    space modeling, please refer to my previous article [here](https://medium.com/analytics-vidhya/multi-seasonal-time-series-analysis-decomposition-and-forecasting-with-python-609409570007).
    ☚📰 In a nutshell, the following steps were conducted:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，数据清理是分析的关键第一步。如果你对细节感兴趣，特别是状态空间建模，请参考我之前的文章[这里](https://medium.com/analytics-vidhya/multi-seasonal-time-series-analysis-decomposition-and-forecasting-with-python-609409570007)。☚📰
    简而言之，进行了以下步骤：
- en: Identifying gaps, when specific timestamps are missing (only single steps were
    identified)
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别缺失的时间戳（仅识别了单步缺失）
- en: Perform imputation (using mean of previous and next records)
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行插补（使用前后记录的均值）
- en: Identifying and dropping duplicates
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别并删除重复项
- en: Set timestamp column as index for dataframe
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将时间戳列设置为数据框的索引
- en: Set dataframe index frequency to hourly, because it is a requirement for further
    processing
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据框的索引频率设置为每小时，因为这是进一步处理的要求
- en: After preparing the data, let’s explore it by drawing 5 random timestamp samples
    and compare the time series at different scales.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备好数据后，我们通过绘制5个随机时间戳样本来探索数据，并比较不同尺度下的时间序列。
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/0a11e7108055273a11e5804af3946d3c.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a11e7108055273a11e5804af3946d3c.png)'
- en: 'Random sampling of dataset and visuals at different time scales. Source: author'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的随机抽样和不同时间尺度的可视化。来源：作者
- en: State Space Modeling
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 状态空间建模
- en: 'By closely examining this simple, yet effective plot, for me it is clearly
    visible, that the analysis should address several seasonal effects:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细分析这个简单但有效的图表，我可以清楚地看到，分析应该考虑几个季节性效应：
- en: energy consumption — in general — peak in mid summer and mid winter, regardless
    of the year selected
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 能源消耗——通常——在夏季和冬季的中期达到峰值，无论选择哪个年份
- en: a weekly minimum pattern seems to emerge on Mondays
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在周一似乎会出现每周最小值模式
- en: there is a daily minimum during the nights, maximum during the days
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在夜间有一个每日最低值，白天有一个每日最高值。
- en: 'Further analysis would reveal, that the yearly pattern of the dataset has 2
    harmonics, as the winter and summer peaks have different levels. As a result,
    the following state space model has been considered, where the periods are measured
    in hours (see model summary as well below):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步分析会揭示，数据集的年度模式有2个谐波，因为冬季和夏季的峰值水平不同。因此，考虑了以下状态空间模型，其中周期以小时为单位（见下文模型总结）：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Without getting too much ahead of myself, let me note, that this model approximates
    the total energy consumption for the last 365 days with an error of ~2%, which
    is fairly accurate from a business perspective I believe. The MLP model constructed
    below will be evaluated by comparing it to the abovementioned state space model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在不提前过多展开的情况下，我想指出，模型近似了过去365天的总能源消耗，误差约为~2%，从商业角度来看，我认为这是相当准确的。下面构建的MLP模型将通过与上述状态空间模型的比较来评估。
- en: Feature Engineering
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: 'Before constructing the MLP model, we should make the unique trend and seasonal
    effects available for the model to learn it. That is achieved by adding new features
    to the dataset, derived from the original 1D time series data. Derived features
    for capturing already identified or unidentified patterns include:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建MLP模型之前，我们应使模型能够学习到独特的趋势和季节性效应。这可以通过向数据集添加新特征来实现，这些特征是从原始的1D时间序列数据派生而来的。为捕捉已经识别或未识别的模式，派生特征包括：
- en: Lags
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滞后
- en: Differences
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 差异
- en: Rolling means
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动均值
- en: Rolling standard deviations
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动标准差
- en: Hour of the day
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一天中的小时
- en: Day of week
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一周中的天数
- en: Labeling weekends
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标记周末
- en: Such derived — and numerical — features could be considered in multiple intervals.
    In order to determine which intervals a model would benefit, it is highly recommended
    to check the autocorrelation properties of the dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些派生的——以及数值型——特征可以在多个时间间隔中进行考虑。为了确定模型在哪些时间间隔中能够获益，强烈建议检查数据集的自相关特性。
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/2db5e7d8a24a253430c45eadd4fb3031.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2db5e7d8a24a253430c45eadd4fb3031.png)'
- en: 'Autocorrelation and partial autocorrelation plots of time series. Source: author'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列的自相关和部分自相关图。来源：作者
- en: 'The dataset is highly autocorrelated, which makes sense as the values vary
    mostly between 10K MW and 20K MW with a smooth transition from hour to hour. However,
    focusing on partial autocorrelations as shown on the plot below, a significant
    correlation seems to be present in the multiples of 24 hours and in the last couple
    of hours. As a result, the derived features can be mainly classified as:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集具有很高的自相关性，这很合理，因为值大多在10K MW到20K MW之间波动，且从一个小时到下一个小时的过渡平滑。然而，专注于下图所示的部分自相关性，似乎在24小时的倍数以及最后几个小时中存在显著的相关性。因此，派生特征主要可以分类为：
- en: Daily (multiples of 24 hours),
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每日（24小时的倍数），
- en: Hourly (focusing on the last couple of hours) and
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每小时（专注于最后几个小时）和
- en: Categorical features
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类特征
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Constructing the MLP Model**'
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**构建MLP模型**'
- en: 'Generating the above detailed features, the input shapes are known and the
    MLP model can be constructed. It is important to notice, that we are dealing with
    mixed datatypes: floats and integers. Please also note, that while all features
    are of numerical type, the integer inputs are fundamentally categorical features
    and should be treated as such.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 生成上述详细特征后，输入形状已知，可以构建MLP模型。需要注意的是，我们处理的是混合数据类型：浮动型和整数型。还请注意，尽管所有特征都是数值类型，整数型输入本质上是分类特征，应当视为分类特征来处理。
- en: There is an option to encode the categories with e.g. one hot encoding technique,
    but that would significantly increase the number of features as each categorical
    column should be expanded to as many columns as many categories exist (minus one)
    [12]. I deliberately chose embedding instead to limit the number of features on
    the expense, that the model input layer will be more complex as the categoricals
    are converted to vectors via embedding first and then combined with the float
    inputs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种方法可以使用例如独热编码技术对类别进行编码，但这会显著增加特征的数量，因为每个类别列都应该扩展为与类别数相等的列数（减去一个）[12]。我故意选择了嵌入方法，以限制特征数量，虽然这样做会使得模型的输入层更加复杂，因为类别数据首先通过嵌入转换为向量，再与浮动输入结合。
- en: Please see the graph after the code section for clarity. The architecture has
    been built using rule of thumbs, as the hyperparameter tuning is out of scope
    for this article. However, if you are interested in a general framework how it
    can be done, please check 📰☛ [my previous article](https://medium.com/towards-data-science/binary-classification-xgboost-hyperparameter-tuning-scenarios-by-non-exhaustive-grid-search-and-c261f4ce098d)
    (I tuned an XGBoost model with Optuna as a tool for Bayesian search of optimal
    hyperparameter values).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看代码部分后的图表以获得更清晰的理解。该架构是使用经验法则构建的，因为超参数调优不在本文范围内。然而，如果你对如何进行超参数调优的通用框架感兴趣，请查看📰☛
    [我之前的文章](https://medium.com/towards-data-science/binary-classification-xgboost-hyperparameter-tuning-scenarios-by-non-exhaustive-grid-search-and-c261f4ce098d)（在这篇文章中，我使用Optuna作为贝叶斯搜索工具调优了XGBoost模型的最佳超参数）。
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/d1e93289f78adc2ad27fe54af42aa5d8.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1e93289f78adc2ad27fe54af42aa5d8.png)'
- en: 'MLP architecture created by using Tensorflow/Keras. Source: author'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Tensorflow/Keras创建的MLP架构。来源：作者
- en: As far as point forecasts goes, the results are ridiculously accurate. This
    is a good sign, that the feature engineering principles applied are correctly
    capturing the underlying patterns in the data and the model was able to generalize
    it.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 就点预测而言，结果非常准确。这是一个好兆头，说明所应用的特征工程原则正确地捕捉了数据中的潜在模式，模型能够将其泛化。
- en: '![](../Images/181dd0c122d63276258e6f6f5576e070.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/181dd0c122d63276258e6f6f5576e070.png)'
- en: 'Baseline MLP model point-forecasts vs. test data. Source: author'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 基准MLP模型的点预测与测试数据对比。来源：作者
- en: The point forecasts overlap with the test set and the two figure traces are
    indistinguishable from each other. More precisely, the RMSE of the predictions
    (training set) and forecasts (test set) are approx. 19.3 and 18.9 respectively
    (in the ballpark of 0.1% in relative terms).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 点预测与测试集重叠，且两个图形轨迹几乎无法区分。更精确地说，预测（训练集）和预测值（测试集）的RMSE分别约为19.3和18.9（相对误差约为0.1%）。
- en: '**Feature Importance**'
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**特征重要性**'
- en: 'What led the model to be accurate? Are all derived features equally important
    or is there a subset which has a greater weight in determining the outcome? These
    are valid questions for two distinct reasons:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 是什么使得模型准确？所有派生特征是否同样重要，还是有一个子集在决定结果时具有更大的权重？这两个问题有其有效性，原因有二：
- en: In real-world scenarios and in the case of big data, the resources for training
    the model is limited and the amount of data used could make a significant difference
    if the model could be trained at all
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实际场景中，尤其是在大数据情况下，训练模型的资源有限，所使用的数据量可能对是否能够训练模型产生重大影响。
- en: Without any explanation, the model works as a black box, which creates uncertainty
    regarding its perfomance. Neural Networks are especially prone to be black box
    models and interpreting them is a field of its own [11]
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有任何解释，模型就像一个黑箱，这会带来关于其性能的不确定性。神经网络尤其容易成为黑箱模型，解释它们是一个独立的领域[11]。
- en: There is an abundance of techniques to interpret models, each has its pros and
    cons. I selected the permutation feature importance method to give some insights
    on model interpretation however, a key takeway from my analysis is that such
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有大量的模型解释技术，每种方法都有其优缺点。我选择了排列特征重要性方法，以便为模型解释提供一些见解。然而，我分析中的一个关键结论是，
- en: model interpretation techniques are only interpreting the model in scope and
    not necessarily the underlying process itself. Reality could be very different
    from feature importance analysis, hence it should not be taken as ground truth
    of causal relationship between independent variables and the target variable.
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 模型解释技术仅仅是在特定范围内解释模型，而不一定是解释其背后的过程。现实可能与特征重要性分析大相径庭，因此不应将其视为自变量与目标变量之间因果关系的最终真相。
- en: Let me explain that with my analysis results. Permuting features one at a time,
    recalculating the RMSE score and recording the relative change in RMSE compared
    to forecasts using the original data will give the relative importance of features
    [13].
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我用我的分析结果来解释这一点。逐一置换特征，重新计算RMSE得分并记录相对于使用原始数据的预测RMSE的相对变化，将给出特征的相对重要性[13]。
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/2564e8b61f4fb48c7d19a4b671007da9.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2564e8b61f4fb48c7d19a4b671007da9.png)'
- en: 'Permutation feature importance histogram. Source: author'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 置换特征重要性直方图。来源：作者
- en: Hourly-, daily lags and differences seem important and maybe the hourly rolling
    means as well. However, the daily and hourly rolling standards just as well as
    the categorical features seem negligible, relative to the aforementioned features.
    One caveat of permutation feature importance is that it does not take into account
    multicollinearity and consequently may give inaccurate results. Remember, the
    features have been derived from a dataset with high autocorrelation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 每小时和每日滞后以及差异似乎很重要，也许每小时的滚动均值也很重要。然而，每日和每小时滚动标准以及分类特征似乎相对较小，可以忽略不计，与上述特征相比。置换特征重要性的一项警告是，它没有考虑多重共线性，因此可能会给出不准确的结果。请记住，这些特征是从具有高自相关的数据集中推导出来的。
- en: 'One possible way to handle the situation is following `scikit learn` ‘s guidance:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这种情况的一种可能方式是遵循`scikit learn`的指导：
- en: perform hierarchical clustering on the Spearman rank-order correlations, pick
    a threshold, and keep a single feature from each cluster. [13]
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对Spearman等级顺序相关性执行层次聚类，选择一个阈值，并从每个簇中保留一个特征。[13]
- en: 'However, I would like to focus on highlighting the inaccuracy and adding more
    insights to the dataset by training alternative models with the grouped features
    one group at a time. The same MLP architecture was used for this purpose with
    adjustments only applied on the input layer to accomodate a subset of data. The
    following groups were created in the feature engineering section and tested here
    (train/test dataset RMSE results also reported respectively):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我想专注于突出不准确之处，并通过逐一训练替代模型以分组特征来为数据集添加更多洞见。为此使用了相同的MLP架构，仅对输入层进行了调整，以适应数据的子集。以下组在特征工程部分创建并在此测试（训练/测试数据集的RMSE结果也分别报告）：
- en: daily lags (942 and 994)
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每日滞后（942 和 994）
- en: daily differences (1792 and 1952)
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每日差异（1792 和 1952）
- en: hourly lags (686 and 611)
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每小时滞后（686 和 611）
- en: daily rolling means and standard deviations (1710 and 1663)
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日常滚动均值和标准差（1710 和 1663）
- en: hourly rolling means and standard deviations (84.4 and 75.5)
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每小时滚动均值和标准差（84.4 和 75.5）
- en: 'It is clear that the alternative models show results not anticipated from simple
    permutation feature importance analysis, without handling multicollinearity: e.g.
    daily rolling features yielded better scores than daily differences and the model
    trained on hourly rolling features has the best performance out of the alternative
    models, close to the baseline model (RMSE reported in percentage ~0.5% vs. ~0.1%
    respectively).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，替代模型显示的结果与简单的置换特征重要性分析预期不同，且未处理多重共线性：例如，每日滚动特征的得分优于每日差异，且训练于每小时滚动特征的模型在所有替代模型中表现最佳，接近基线模型（RMSE分别为百分比~0.5%和~0.1%）。
- en: A Note on a Specific Anomaly in the Data
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据中的特定异常说明
- en: I would like to highlight a very specific case of anomaly observed at 14:00
    on 20th October 2008\. This is the highest ever recorded value with no apparent
    cause, no similar datapoints before or after in the dataset.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我想强调2008年10月20日14:00观察到的一个非常特殊的异常情况。 这是有史以来记录的最高值，且没有明显的原因，数据集中之前和之后没有类似的数据点。
- en: Yet, the baseline model powered by feature engineering was able to predict that
    datapoint and is not considered an outlier!
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 然而，由特征工程驱动的基线模型能够预测该数据点，并且不被认为是异常值！
- en: '![](../Images/fe5663c1e874d9c4bcbf0d8dd541ab3c.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe5663c1e874d9c4bcbf0d8dd541ab3c.png)'
- en: 'Baseline MLP model point-predictions and the observed potential anomaly. Source:
    author'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 基线MLP模型的点预测和观察到的潜在异常。来源：作者
- en: 'From which features the model was able to predict that point? Let’s use our
    alternative models for inference. The best alternative (hourly rolling features)
    seems extremely accurate in the vicinity, but could only explain the phenomenon
    partially:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是如何预测该数据点的呢？让我们使用替代模型进行推理。最佳的替代模型（每小时滚动特征）在该点附近似乎非常准确，但只能部分解释这一现象：
- en: '![](../Images/1d891089cfb4b6494f8ac7e5afc5959e.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d891089cfb4b6494f8ac7e5afc5959e.png)'
- en: 'Alternative MLP model (utilizing hourly rolling features) point-predictions
    and the observed potential anomaly. Source: author'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 替代的 MLP 模型（利用每小时滚动特征）点预测和观察到的潜在异常。来源：作者
- en: 'The second best alternative is the one utilizing hourly lags, but it has absolutely
    no answer why that happened:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 第二好的替代方案是利用每小时滞后的模型，但它完全没有解释为何会发生这种情况：
- en: '![](../Images/4d699078a9afb2b07b740af85194b30d.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d699078a9afb2b07b740af85194b30d.png)'
- en: 'Alternative MLP model (utilizing hourly lag features) point-predictions and
    the observed potential anomaly. Source: author'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 替代的 MLP 模型（利用每小时滞后特征）点预测和观察到的潜在异常。来源：作者
- en: Making a long story short, the daily differences might contain important information
    regarding the underlying patterns. Although utilizing the daily differences group
    solely gives higher predictions, the baseline model seemingly found a good balance
    of weights for the features.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，每日差异可能包含有关潜在模式的重要信息。尽管单独使用每日差异组会给出更高的预测值，但基准模型似乎找到了特征权重的良好平衡。
- en: '![](../Images/c0f627ebf8eb29789a55dda1e01f9faf.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0f627ebf8eb29789a55dda1e01f9faf.png)'
- en: 'Alternative MLP model (utilizing daily difference features) point-predictions
    and the observed potential anomaly. Source: author'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 替代的 MLP 模型（利用每日差异特征）点预测和观察到的潜在异常。来源：作者
- en: Multi-step Prediction Model
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多步预测模型
- en: Finally, the model architecture has been modified to yield multi-step predictions.
    The forecasting period is one year, as suggested by the dataset publisher [14].
    Given all uncertainties in such a process with special regard to weather conditions,
    it might not make sense to consider such a long forecasting period. However, it
    is an intersting exercise to evaluate the multi-step model’s performance to the
    state space model, which explicitly models the trend and seasonal effects observed
    across the year (see next section).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，模型架构已被修改，以生成多步预测。预测期为一年，如数据集发布者所建议的[14]。考虑到这种过程中的所有不确定性，特别是天气条件方面，考虑这么长的预测期可能没有意义。然而，这对于评估多步模型与状态空间模型的表现是一个有趣的练习，后者明确建模了跨年观察到的趋势和季节性效应（见下一节）。
- en: 'The key points for implementing a multi-step model are as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 实现多步模型的关键点如下：
- en: the target was a series of vectors (next 8766 hours defined for ech step)
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标是一个向量序列（为每个步骤定义的接下来的 8766 小时）
- en: as a result, the prediction or forecast is the next 8766 hours (approx. one
    year) for the last row of inputs
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果是，预测或预报是接下来 8766 小时（大约一年）的最后一行输入数据
- en: due to resource limitations I had to limit the training data for the last year
    of the former training dataset
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于资源限制，我不得不限制前一训练数据集的最后一年的训练数据。
- en: the output layer was modified accordingly, to give the desired vector output
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出层已相应修改，以给出所需的向量输出
- en: '[PRE9]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For a visual evaluation, one could see the model was trying to generalize the
    patterns:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可视化评估，可以看出模型试图对模式进行泛化：
- en: '![](../Images/2c6c7c1d334527dfc742b07d89445916.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c6c7c1d334527dfc742b07d89445916.png)'
- en: 'Multistep MLP model predictions and forecasts vs. original data. Source: author'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 多步 MLP 模型的预测与原始数据的对比。来源：作者
- en: MLP vs. State Space Model
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLP 与状态空间模型
- en: 'Due to generalization of the data, the RMSE score increased significantly:
    1982 and 2017 for the train and test dataset respectively. However, in order the
    properly evaluate the multi-step MLP, we should use another model for comparison.
    As I mentioned in the previous section, state space models gives fairly understandable
    approximations of the trend and seasonal effects observed across the year. This
    feature make them relatively easily interpretable, unlike neural networks. The
    primary reason is that hidden layers have many connections and understanding how
    they are activated is not a straightforward process. [11].'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据的泛化，RMSE 得分显著增加：训练集和测试集的得分分别为 1982 和 2017。然而，为了正确评估多步 MLP，我们应该使用另一个模型进行比较。正如我在前一节中提到的，状态空间模型提供了对跨年观察到的趋势和季节性效应的相当可理解的近似。这一特点使得它们相对容易解释，不像神经网络。主要原因是隐藏层有很多连接，理解它们是如何被激活的并不是一个直接的过程。[11]
- en: 'In [my previous article](https://medium.com/analytics-vidhya/multi-seasonal-time-series-analysis-decomposition-and-forecasting-with-python-609409570007),
    ☚📰 I used a simplified, yet meaningful evaluation method: comparing the total
    energy consumption within the last year. Practically, that is the area under the
    curve of the energy consumption time series. The values for the original data
    and model forecasts can be compared directly. For the `UnobservedComponents` model:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在[我之前的文章](https://medium.com/analytics-vidhya/multi-seasonal-time-series-analysis-decomposition-and-forecasting-with-python-609409570007)中，☚📰我使用了一种简化但有意义的评估方法：比较过去一年内的总能耗。实际上，这是能耗时间序列下的曲线面积。可以直接比较原始数据和模型预测的值。对于`UnobservedComponents`模型：
- en: '[PRE10]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For the MLP model:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 对于MLP模型：
- en: '[PRE12]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In short: it is -1.912% vs. -2.159% in favor of the MLP model. Please note,
    that this has been achieved by utilizing an MLP architecture using some simple
    rule of thumbs, not even considering hyperparameter tuning or some effective model
    training features, e.g. reducing the learning rate when the evaluation metric
    reaches a plateau or early stopping.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之：它是-1.912% vs. -2.159%，偏向于MLP模型。请注意，这是通过使用MLP架构并结合一些简单的经验法则实现的，甚至没有考虑超参数调优或某些有效的模型训练特征，例如在评估指标达到平台期时减少学习率或提前停止。
- en: The results should be fairly convincing that indeed, utilizing relatively simple
    neural network architectures combined with powerful feature engineering techniques,
    accurate forecasting tools are within reach for a data scientist early in his
    or her seniority level.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该是相当令人信服的，确实，通过利用相对简单的神经网络架构结合强大的特征工程技术，准确的预测工具已经在数据科学家的初级阶段触手可得。
- en: Resources
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: 'Data source:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来源：
- en: '[https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/)
    (CC0)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/)
    (CC0)'
- en: 'Notebook (only code, without outputs): [https://gist.github.com/danielandthelions/2e6f0edd30902113ad10fd9f20bda215](https://gist.github.com/danielandthelions/2e6f0edd30902113ad10fd9f20bda215)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本（仅代码，不包含输出）：[https://gist.github.com/danielandthelions/2e6f0edd30902113ad10fd9f20bda215](https://gist.github.com/danielandthelions/2e6f0edd30902113ad10fd9f20bda215)
- en: References
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [https://preset.io/blog/time-series-forecasting-a-complete-guide/](https://preset.io/blog/time-series-forecasting-a-complete-guide/)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://preset.io/blog/time-series-forecasting-a-complete-guide/](https://preset.io/blog/time-series-forecasting-a-complete-guide/)'
- en: '[2] [https://www.ibm.com/topics/recurrent-neural-networks](https://www.ibm.com/topics/recurrent-neural-networks)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://www.ibm.com/topics/recurrent-neural-networks](https://www.ibm.com/topics/recurrent-neural-networks)'
- en: '[3] [https://www.timescale.com/blog/time-series-analysis-what-is-it-how-to-use-it/](https://www.timescale.com/blog/time-series-analysis-what-is-it-how-to-use-it/)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://www.timescale.com/blog/time-series-analysis-what-is-it-how-to-use-it/](https://www.timescale.com/blog/time-series-analysis-what-is-it-how-to-use-it/)'
- en: '[4] [https://plat.ai/blog/difference-between-prediction-and-forecast/](https://plat.ai/blog/difference-between-prediction-and-forecast/)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://plat.ai/blog/difference-between-prediction-and-forecast/](https://plat.ai/blog/difference-between-prediction-and-forecast/)'
- en: '[5] [https://dotdata.com/blog/practical-guide-for-feature-engineering-of-time-series-data/](https://dotdata.com/blog/practical-guide-for-feature-engineering-of-time-series-data/)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [https://dotdata.com/blog/practical-guide-for-feature-engineering-of-time-series-data/](https://dotdata.com/blog/practical-guide-for-feature-engineering-of-time-series-data/)'
- en: '[6] [https://statisticsbyjim.com/time-series/autocorrelation-partial-autocorrelation/](https://statisticsbyjim.com/time-series/autocorrelation-partial-autocorrelation/)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [https://statisticsbyjim.com/time-series/autocorrelation-partial-autocorrelation/](https://statisticsbyjim.com/time-series/autocorrelation-partial-autocorrelation/)'
- en: '[7] [https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron](https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron](https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron)'
- en: '[8] [https://jina.ai/news/embeddings-in-depth/](https://jina.ai/news/embeddings-in-depth/)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [https://jina.ai/news/embeddings-in-depth/](https://jina.ai/news/embeddings-in-depth/)'
- en: '[9] Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and
    practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3\. Accessed
    on 7th July 2024'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Hyndman, R.J., & Athanasopoulos, G. (2021) 《Forecasting: principles and
    practice》，第三版，OTexts：澳大利亚墨尔本。OTexts.com/fpp3。访问时间：2024年7月7日'
- en: '[10] [https://statisticsbyjim.com/regression/root-mean-square-error-rmse/](https://statisticsbyjim.com/regression/root-mean-square-error-rmse/)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] [https://statisticsbyjim.com/regression/root-mean-square-error-rmse/](https://statisticsbyjim.com/regression/root-mean-square-error-rmse/)'
- en: '[11] [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
- en: '[12] [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)'
- en: '[13] [https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] [https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance)'
- en: '[14] [https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] [https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/)'
