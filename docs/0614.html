<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Navigating Cost-Complexity: Mixture of Thought LLM Cascades Illuminate a Path to Efficient Large Language Model Deployment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Navigating Cost-Complexity: Mixture of Thought LLM Cascades Illuminate a Path to Efficient Large Language Model Deployment</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/navigating-cost-complexity-mixture-of-thought-llm-cascades-illuminate-a-path-to-efficient-large-23291d1eda41?source=collection_archive---------5-----------------------#2024-03-06">https://towardsdatascience.com/navigating-cost-complexity-mixture-of-thought-llm-cascades-illuminate-a-path-to-efficient-large-23291d1eda41?source=collection_archive---------5-----------------------#2024-03-06</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="gr gs gt gu gv ab"><div><div class="ab gw"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@yuval_domino?source=post_page---byline--23291d1eda41--------------------------------" rel="noopener follow"><div class="l gx gy by gz ha"><div class="l ed"><img alt="Yuval Zukerman" class="l ep by dd de cx" src="../Images/b04d3068659ed79643398dc39f6ce950.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*cvfZpvq2oQeMNVApvKKXjA.jpeg"/><div class="hb by l dd de em n hc eo"/></div></div></a></div></div><div class="hd ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--23291d1eda41--------------------------------" rel="noopener follow"><div class="l he hf by gz hg"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hh cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hb by l br hh em n hc eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hi ab q"><div class="ab q hj"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hk hl bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hm" data-testid="authorName" href="https://medium.com/@yuval_domino?source=post_page---byline--23291d1eda41--------------------------------" rel="noopener follow">Yuval Zukerman</a></p></div></div></div><span class="hn ho" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hk hl dx"><button class="hp hq ah ai aj ak al am an ao ap aq ar hr hs ht" disabled="">Follow</button></p></div></div></span></div></div><div class="l hu"><span class="bf b bg z dx"><div class="ab cn hv hw hx"><div class="hy hz ab"><div class="bf b bg z dx ab ia"><span class="ib l hu">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hm ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--23291d1eda41--------------------------------" rel="noopener follow"><p class="bf b bg z ic id ie if ig ih ii ij bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hn ho" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">5 min read</span><div class="ik il l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 6, 2024</span></div></span></div></span></div></div></div><div class="ab cp im in io ip iq ir is it iu iv iw ix iy iz ja jb"><div class="h k w ea eb q"><div class="jr l"><div class="ab q js jt"><div class="pw-multi-vote-icon ed ib ju jv jw"><div class=""><div class="jx jy jz ka kb kc kd am ke kf kg jw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kh ki kj kk kl km kn"><p class="bf b dy z dx"><span class="jy">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao jx ko kp ab q ee kq kr" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="ks"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jc jd je jf jg jh ji jj jk jl jm jn jo jp jq"><div class="kt k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al ku an ao ap hr kv kw kx" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ky cn"><div class="l ae"><div class="ab cb"><div class="kz la lb lc ld le ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al ku an ao ap hr lf lg kr lh li lj lk ll s lm ln lo lp lq lr ls u lt lu lv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al ku an ao ap hr lf lg kr lh li lj lk ll s lm ln lo lp lq lr ls u lt lu lv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al ku an ao ap hr lf lg kr lh li lj lk ll s lm ln lo lp lq lr ls u lt lu lv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="lz ma mb mc md me lw lx paragraph-image"><div role="button" tabindex="0" class="mf mg ed mh bh mi"><div class="lw lx ly"><img src="../Images/535098db554b3f659cfd241166a5b1b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kFxJzQhuJvSBmQhsbAIheA.jpeg"/></div></div><figcaption class="mk ml mm lw lx mn mo bf b bg z dx">Photo by <a class="af mp" href="https://unsplash.com/@sortino" rel="noopener ugc nofollow" target="_blank">Joshua Sortino</a> on <a class="af mp" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="e4d2" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">What if I told you that you could save 60% or more off of the cost of your LLM API spending without compromising on accuracy? Surprisingly, now you can.</p><p id="5214" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Large Language Models (LLMs) are now part of our everyday lives. Companies use the technology to automate processes, improve customer experiences, build better products, save money, and more.</p><p id="b02e" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Hosting your own LLMs is very challenging. They offer broad capabilities but are often expensive to run. They often require complex infrastructure and massive amounts of data. Cost and complexity are why you use prompt engineering. You may even use retrieval-augmented generation (RAG) to improve context and reduce hallucinations. With both techniques, you offload running LLMs to the likes of OpenAI, Cohere, or Google. Yet, scaling LLM adoption to new use cases, especially with the latest powerful models, can drive up a new cost that was previously unaccounted for. Weaker models may be cheaper, but can you trust them with complex questions? Now, new research shows us how to save money and get as good, sometimes better, LLM results.</p><p id="3ce8" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Get to Know LLM Cascades</strong></p><p id="c386" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">In the search for lower LLM costs, researchers turned to the concept of LLM Cascades. In the dark ages, before the launch of ChatGPT, <a class="af mp" href="https://arxiv.org/pdf/2207.10342.pdf" rel="noopener ugc nofollow" target="_blank">a team from Google and The University of Toronto defined this term</a> as programs that use probability calculations to get the best results using multiple LLMs.</p><p id="6e93" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">More recently, the <a class="af mp" href="https://arxiv.org/abs/2305.05176" rel="noopener ugc nofollow" target="_blank">FrugalGPT paper</a> defined cascades as sending a user query to a list of LLMs, one after the other, from weaker to stronger LLMs, until the answer is good enough. FrugalGPT Cascades uses a dedicated model to determine when the answer is good enough against a quality threshold.</p><p id="477b" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">A recent paper titled <a class="af mp" href="https://arxiv.org/pdf/2310.03094.pdf" rel="noopener ugc nofollow" target="_blank">‘Large Language Model Cascades With Mixture of Thought Representations for Cost-Efficient Reasoning’</a> from George Mason University, Microsoft, and Virginia Tech offers an alternative: a function that can determine whether the answer is good enough without fine-tuning another model.</p><p id="9502" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">Mixture of Thought LLM Cascades</strong></p><p id="6d77" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Instead of using several LLMs, ‘Mixture of thought’ (MoT) reasoning uses just two — GPT 3.5 Turbo and GPT 4. The former model is regarded as the ‘weaker’ LLM, while the latter is the ‘strong’ LLM. The authors harnessed LLM ‘answer consistency’ to flag whether an LLM’s response is good enough. LLMs produce consistent answers to similar prompts when they are confident the answers are correct. Therefore, when weaker LLM answers are consistent, there is no need to call the stronger LLM. Conversely, these LLMs produce inconsistent answers when they lack confidence. That’s when you need a stronger LLM to answer the prompt. (Note: you can use a weaker/stronger LLM pair of your choice as well.)</p><p id="0e45" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The prompts themselves use few-shot in-context prompting to improve LLM answer quality. Such prompts guide the LLM’s response by giving examples of similar questions and answers.</p><p id="28d6" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">To improve model reasoning and simplify consistency measurement, the researchers introduce a new prompting technique for reasoning tasks by ‘mixing’ two prompting techniques:</p><ul class=""><li id="0bbf" class="mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq bk"><a class="af mp" href="https://openreview.net/forum?id=_VjQlMeSB_J" rel="noopener ugc nofollow" target="_blank">Chain of Thought</a> (CoT) Prompting encourages LLMs to generate intermediate steps or reasonings before arriving at a final answer. Generating these steps helps the model improve complicated task results. It also increases answer accuracy.</li><li id="f327" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn no np nq bk"><a class="af mp" href="https://arxiv.org/abs/2211.12588" rel="noopener ugc nofollow" target="_blank">Program of Thought</a> (PoT) extends Chain of Thought prompting and uses the model’s output as a new input for further prompts. Prompts using this technique often request the model to answer with code instead of human language.</li></ul><p id="a159" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The paper also introduces two methods to determine answer consistency:</p><ul class=""><li id="f497" class="mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq bk">Voting: This method samples multiple answers from LLM queries with similar prompts or by varying the response temperature option. It then measures how similar the LLM’s answers are to each other. The answer that agrees the most with all the other answers is assumed to be correct. The team also defined a flexible ‘threshold’ value that aligns answer consistency and budget constraints.</li><li id="eb81" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn no np nq bk">Verification: This approach compares the LLM’s most consistent answers across two distinct thought representations (e.g., CoT and PoT). The algorithm accepts the weaker LLM’s answer if the two prompt responses are identical.</li></ul><p id="bcc3" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Since voting requires multiple prompts, it may be more suitable when a budget exists to guide the threshold number.</p><p id="495f" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="ms fr">The Bottom Line: Mixture of Thought Saves You Money</strong></p><p id="7ed5" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Let’s look at how much money the MoT technique saves and its impact on answer accuracy.</p><p id="11f2" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The researchers used the following sum to calculate prompt cost:</p><ul class=""><li id="1299" class="mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq bk">The cost of prompting the weaker model (because we may prompt it several times)</li><li id="08a2" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn no np nq bk">The cost of the answer evaluation process</li><li id="4946" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn no np nq bk">If the evaluation process rejects the answer, we add the cost of prompting the strong model</li></ul><p id="d079" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The results were dramatic:</p><ul class=""><li id="9766" class="mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq bk">Using MoT variants — combining voting and verification with CoT and PoT — can lead to comparable performance at 40% of the cost of solely using GPT-4.</li><li id="c81c" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn no np nq bk">In testing against the <a class="af mp" href="https://github.com/velocityCavalry/CREPE" rel="noopener ugc nofollow" target="_blank">CREPE</a> Q&amp;A dataset, MoT outperformed GPT-4 at 47% of its cost.</li><li id="3b81" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn no np nq bk">Mixing PoT and CoT improves decision-making compared to using one of the techniques alone.</li><li id="0a57" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn no np nq bk">Increasing the threshold when using the voting method did not significantly impact quality despite the additional cost.</li><li id="76e2" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn no np nq bk">The consistency model proved itself in reliably identifying correct LLM answers. It successfully predicted when to resort to using the strong model to obtain the optimal results.</li></ul><p id="4051" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Hosting and managing Large Language Models (LLMs) in-house comes with significant challenges. They bring complexity, high costs, and the need for extensive infrastructure and data resources. As a result, LLMs present substantial hurdles for organizations seeking to harness their broad capabilities. That may lead you to turn to hosted LLMs. Yet, this approach presents companies with unforeseen cost increases and budget challenges as they expand to new use cases. That is particularly evident when integrating the latest powerful models. To avoid that fate, you face a new dilemma: Can you trust weaker, more affordable models? Can you overcome concerns about their accuracy in handling complex questions?</p><p id="16b6" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">LLM Cascades with Mixture of Thought (MoT) offers two significant steps forward:</p><ol class=""><li id="dfd4" class="mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn nw np nq bk">Substantial cost savings over exclusively using the latest models.</li><li id="fd00" class="mq mr fq ms b mt nr mv mw mx ns mz na nb nt nd ne nf nu nh ni nj nv nl nm nn nw np nq bk">Demonstrable results on par with the latest models.</li></ol><p id="b7ce" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">This breakthrough provides organizations with a practical and efficient approach to navigating the delicate balance between the powerful capabilities of LLMs and the imperative to manage costs effectively.</p><p id="8b8a" class="pw-post-body-paragraph mq mr fq ms b mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Domino Staff Software Engineer Subir Mansukhani contributed to this post.</p></div></div></div></div>    
</body>
</html>