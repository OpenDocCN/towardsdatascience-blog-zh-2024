# 对AI图像生成的批判性审视

> 原文：[https://towardsdatascience.com/a-critical-look-at-ai-image-generation-45001f410147?source=collection_archive---------4-----------------------#2024-10-17](https://towardsdatascience.com/a-critical-look-at-ai-image-generation-45001f410147?source=collection_archive---------4-----------------------#2024-10-17)

## 图像生成型AI究竟能告诉我们关于这个世界什么？

[](https://medium.com/@s.kirmer?source=post_page---byline--45001f410147--------------------------------)[![Stephanie Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page---byline--45001f410147--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--45001f410147--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--45001f410147--------------------------------) [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page---byline--45001f410147--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--45001f410147--------------------------------) ·阅读时间9分钟·2024年10月17日

--

![](../Images/6acab230e5de0801ddad5c6b19f9ddfe.png)

图片来源：[Math](https://unsplash.com/@builtbymath?utm_source=medium&utm_medium=referral)于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

我最近有机会对[一个有趣的项目](https://bit.ly/genaiSK)进行分析，并且我有更多的想法，超出了那篇文章所能包含的内容，所以今天我将进一步讨论我对这个项目的看法。

研究人员在这个项目中的方法是向不同的生成型AI图像生成工具提供一系列提示词：Stable Diffusion、Midjourney、YandexART 和 ERNIE-ViLG（由百度开发）。这些提示词特别围绕不同的代际群体——婴儿潮一代、X世代、千禧一代和Z世代，要求生成这些群体在不同场景下的图像，如“与家人在一起”，“度假”或“在工作中”。

尽管这些结果非常有趣，或许能揭示一些关于视觉表现的见解，但我认为我们也应该注意到这些图像无法告诉我们什么，或者它们的局限性在哪里。我将把我的讨论分为审美（图像的外观）和表现（图像中实际呈现的内容）两部分，并稍微偏离一下，谈谈这些图像是如何生成的，因为这一点对这两个话题都非常重要。

# 引言

不过在开始之前，先快速回顾一下这些图像生成模型。它们的创建方式是通过大量图像数据集（包括照片、艺术作品等）与简短的文本描述配对，目标是让模型学习词语和图像外观之间的关系，以便当给定一个词时，模型能够生成与之大致匹配的图像。模型的内部机制更为复杂，而且这些模型（像其他生成式 AI）内建了随机性，这样可以产生变化和惊喜。

当你使用这些托管模型时，你输入一个文本提示，然后模型会返回一张图像。然而，重要的是要注意，提示并不是模型接收到的唯一信息。模型还有一些内建的指令，有时我称之为预提示指令，这些指令会对输出结果产生影响。举例来说，可能会告诉模型拒绝创建某些类型的冒犯性图像，或者拒绝使用冒犯性语言的提示。

# 训练数据

这里一个重要的框架是，训练数据——那些与文本描述配对的大型图像集——是模型试图复制的对象。所以，我们应该对训练数据及其来源提出更多问题。为了训练这些模型，所需的图像数据量是巨大的。Midjourney 就是在 [https://laion.ai/](https://laion.ai/) 上进行训练的，该平台的更大数据集包含了跨多种语言的 50 亿对图像-文本配对，我们可以假设其他模型的内容量也相似。这意味着工程师不能对用于训练的图像挑剔太多，因为他们基本上需要尽可能多的内容。

好的，那么我们从哪里获取图像呢？它们是如何生成的？嗯，我们自己制作图像并通过社交媒体大量发布，所以这无疑会占据其中一部分。（从这些平台上获取也很容易。）媒体和广告也创造了大量的图像，从电影到广告，再到杂志等等。许多其他图像永远无法被这些模型访问，比如你奶奶的照片专辑没人数字化过，但可以用于训练的图像主要来自这两个来源：独立/个人创作者和媒体/广告。

那么，当你使用这些模型时，实际上会得到什么呢？

# 美学

如果你尝试这些不同的图像生成器，你会注意到它们之间的风格区别，以及风格内部的一致性。我认为这非常有趣，因为它们几乎像是有自己的个性！Midjourney 显得阴暗且情绪化，带有阴影元素，而 Stable Diffusion 则明亮且过度饱和，对比度极高。ERNIE-ViLG 似乎倾向于卡通风格，同样具有极高的对比度，且质感呈现出橡胶感或高度滤镜化的效果。YandexART 的颜色偏褪色，背景通常没有特征或非常模糊，并且有聚光灯效果（在某些情况下让我想起了在百货商店拍的家庭照）。多种不同的因素可能导致每个模型的独特风格。

正如我之前提到的，预先提示指令是在用户提供输入的基础上应用的。这些指令可能会指定输出应该始终具有的特定美学成分，例如色调、亮度和对比度等风格选择，或者指示模型避免遵循不当的指令等。这为模型提供者实现工具的某些限制和保护措施，防止滥用，也能创造出美学上的连贯性。

通过强化学习进行微调的过程也可能影响风格，其中人工观察员对返回模型的输出做出判断。人工观察员会接受培训，并被指示哪些图像特征应该被批准/接受，哪些应该被拒绝或降分，这可能涉及对某些类型的视觉效果给予更高的评分。

训练数据的类型也会产生影响。我们知道一些用于训练模型的大型数据集，但可能还有我们不知道的内容，因此我们必须从模型输出中推断。如果模型生成的是高对比度、明亮的图像，那么训练数据中很可能包含了大量具有这些特征的图像。

然而，在我们分析不同模型的输出时，重要的是要记住，这些风格可能是预先提示指令、训练数据和人工微调的结合。

除了图像的视觉吸引力/风格之外，图像中实际包含了什么内容？

# 表现形式

## 局限性

模型的能力将受限于它们的训练现实。这些模型是基于过去的图像进行训练的——一些是最近的图像，但有些则是更久远的图像。例如，考虑到：随着时间的推移，年轻一代的整个生活都将在线上有图像，但对于年长的群体来说，他们年轻或青少年时期的图像并没有大量数字化（或者是高质量的）可用于训练数据，因此我们可能永远不会看到这些模型将他们展现为年轻人。在这个项目中，这一点非常明显：对于Z世代和千禧一代，在这些数据中我们看到模型在输出中很难适当地“衰老”这些人像，以符合当今这些群体的实际年龄范围。大多数情况下，这两代人看起来年龄相仿，Z世代有时在（比如和学校相关的提示）中被展示为孩子。相比之下，婴儿潮一代和X世代主要显示为中年或老年，因为现有的训练数据不太可能有他们年轻时的照片扫描副本，这些照片大多来自1960年代到1990年代。如果你从训练数据的背景来看，这完全是合理的。

> [随着时间的推移，年轻一代的整个生活将在线上有图像，但对于年长的群体来说，他们年轻或青少年时期的图像并没有数字化用于训练数据，因此我们可能永远不会看到这些模型将他们展现为年轻人。]

## 身份

有鉴于此，我认为如果我们调查这些图像，能够从中得到的印象是A.不同年龄群体如何在图像中展示自己，尤其是年轻人自拍照的表现，B.这些群体在媒体中的表现如何。（有时很难将这两者分开，因为媒体和青少年文化是相互对立的。）

训练数据并非凭空产生——人类选择了创建、分享、标注和策划这些图像，因此这些人的选择影响了图像的所有内容。模型获取的是这些世代中有人选择展示的图像，且在所有情况下，这些展示背后都有原因和意图。

一个青少年或二十多岁的人自拍并将其发布到网上（以便它能够成为这些模型的训练数据）可能在选择发布到 Instagram 之前，已经拍了十张、二十张或者五十张。与此同时，一个专业摄影师在为广告活动挑选模特时，考虑的因素很多，包括产品、受众、品牌形象等等。因为专业广告并不免于种族主义、性别歧视、年龄歧视或其他任何“主义”，所以这些图像也不会例外，结果是这些模型生成的图像也带有这些社会负担。从这些图像中，你可以看到在一些模型（尤其是 Midjourney 和 Yandex）中，千禧一代和 Z 世代中更多的种族特征，而在同样的模型中，X 世代和婴儿潮一代几乎看不到这些种族特征。这可能至少部分是因为广告商在针对某些群体时，选择那些他们认为会吸引并让他们产生共鸣的种族、民族（以及年龄）代表，且他们预设认为，婴儿潮一代和 X 世代如果看到较老且白人的模特，更可能产生购买欲望。这些图像被创建出来，随后进入训练数据，因此模型学会了生成这些图像。

我想表达的观点是，这些数据并非不受文化和社会的影响——无论这种影响是好是坏。训练数据来源于人类创造，因此模型带着那些人类的社会负担。

> *我想表达的观点是，这些数据并非不受文化和社会的影响——无论这种影响是好是坏。训练数据来源于人类创造，因此模型带着那些人类的社会负担。*

因为这个现实，我认为问我们是否能从模型生成的图像中了解不同代际是一个错误的问题，或者至少是一个误导性的前提。我们可能偶然学到一些关于训练集中人类创造的东西，可能包括自拍，但我们更有可能学到关于更广泛社会的东西，形式上包括人们拍摄他人和自己的照片、媒体以及商业化。我们得到的一些（甚至是很多）内容，尤其是对于那些较少在线发布自创视觉媒体的老年群体，充其量是广告和媒体中的对该群体的刻板印象，而我们知道这些刻板印象本身就有固有缺陷。

从这些图像中是否可以获得*关于代际理解的任何*东西？或许可以。我认为这个项目可能有助于我们看到代际身份是如何通过媒体进行过滤的，尽管我怀疑这是否是进行这种分析的最方便或最简单的方式。毕竟，我们可以去直接了解源头——尽管这些模型进行的聚合可能在学术上很有趣。它对于年轻一代来说可能更有用，因为更多的训练数据是自我生成的，但即便如此，我依然认为我们应该记住，我们在发布的关于自己的图像中也会注入自己的偏见和议程。

顺便提一下，一些评论员有一种本能的冲动，要求对像这样的模型所生成的内容进行某种程度的美化——这就是我们得到[会生成各种种族和民族外貌的纳粹士兵图像的模型](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical)的原因。[正如我之前写的](https://medium.com/towards-data-science/seeing-our-reflection-in-llms-7b9505e901fd)，这在很大程度上是为了避免面对这些模型反馈给我们的社会现实。我们不喜欢镜子中的样子，所以我们涂抹镜面，而不是去审视我们自己的面容。

当然，这也并不完全正确——我们所有的规范和文化并不会在模型的输出中得到体现，只有那些我们付诸于图像并输入到训练数据中的内容才会被表示出来。我们只看到社会的一部分，而不是以完全真实、无所隐瞒的方式呈现整个社会。因此，我们必须根据这些模型的性质和它们的创建方式，现实地设定我们的期望。我们无法在这些模型中得到我们生活的纯粹图像，因为我们拍摄的照片（以及我们未拍摄的照片，或者未分享的照片），以及媒体创造和传播的图像，都不是没有偏见或客观性的。这就像我们不应该拿自己和生活与朋友们在 Instagram 上发布的图像做比较——那也不是他们生活的完整和准确的写照。除非我们进行一场大规模的摄影和图像标注活动，追求准确性和平等的代表性，并将这些用于训练数据，否则我们无法改变这个系统的运作方式。

# 结论

花时间思考这些想法对我来说非常有趣，我希望这个分析对那些经常使用这些类型模型的人有所帮助。使用生成型 AI 图像生成模型有许多问题，从[环境](https://medium.com/towards-data-science/environmental-implications-of-the-ai-boom-279300a24184)到[经济](https://medium.com/towards-data-science/the-coming-copyright-reckoning-for-generative-ai-b7fe0963c58f)，但我认为理解这些模型是什么（以及不是）以及它们实际做的事情，对于你选择是否在日常生活中使用这些模型是至关重要的。

阅读更多我的文章，请访问 [www.stephaniekirmer.com](http://www.stephaniekirmer.com)。

# 深入阅读

[](/seeing-our-reflection-in-llms-7b9505e901fd?source=post_page-----45001f410147--------------------------------) [## 在LLMs中看到我们的倒影

### 当LLMs给我们呈现出揭示人类社会缺陷的结果时，我们能否选择倾听它们所告诉我们的？

[towardsdatascience.com](/seeing-our-reflection-in-llms-7b9505e901fd?source=post_page-----45001f410147--------------------------------)

[https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical)

项目：[https://bit.ly/genaiSK](https://bit.ly/genaiSK)
