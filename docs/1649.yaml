- en: 'A Powerful EDA Tool: Group-By Aggregation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=collection_archive---------5-----------------------#2024-07-04](https://towardsdatascience.com/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=collection_archive---------5-----------------------#2024-07-04)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/691a811bf777523ac010794feed190fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Mourizal Zativa](https://unsplash.com/@mourimoto?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/lego-pieces?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to use group-by aggregation to uncover insights from your data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)[![Pararawendy
    Indarjo](../Images/afba0cb7f3af9554a187bbc7a3c00e60.png)](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)
    [Pararawendy Indarjo](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)
    ·7 min read·Jul 4, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory Data Analysis (EDA) is the core competency of a data analyst. Every
    day, data analysts are tasked with seeing the “unseen,” or extracting useful insights
    from a vast ocean of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this regard, I’d like share a technique that I find beneficial for extracting
    relevant insights from data: group-by aggregation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To this end, the rest of this article will be arranged as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Explanation of group-by aggregation in Pandas
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The dataset: Metro Interstate Traffic'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Metro Traffic EDA
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Group-By Aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Group-by aggregation is a data manipulation technique that consists of two steps.
    First, we group the data based on the values of specific columns. Second, we perform
    some aggregation operations (e.g., sum, average, median, count unique) on top
    of the grouped data.
  prefs: []
  type: TYPE_NORMAL
- en: Group-by aggregation is especially useful when our data is granular, as in typical
    fact tables (transactions data) and time series data with narrow intervals. By
    aggregating at a higher level than raw data granularity, we can represent the
    data in a more compact way — and may distill useful insights in the process.
  prefs: []
  type: TYPE_NORMAL
- en: In pandas, we can perform group-by aggregation using the following general syntax
    form.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Where `base_col` is the column whose values become the grouping basis, `agg_col`
    is the new column defined by taking `agg_func` aggregation on `ori_col` column.
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider the infamous Titanic dataset whose five rows are displayed
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/4868ab3226336b94d70b44529881f531.png)'
  prefs: []
  type: TYPE_IMG
- en: Titanic data’s first 5 rows (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: We can group this data by the `survived` column and then aggregate it by taking
    the median of the `fare` column to get the results below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/11515715275245f95bac895b569a7168.png)'
  prefs: []
  type: TYPE_IMG
- en: Median fare of titanic passengers, by survival status (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Suddenly, we see an interesting insight: survived passengers have a higher
    fare median, which has more than doubled. This could be related to prioritizing
    safety boats for higher cabin class passengers (i.e., passengers with higher fare
    tickets).'
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, this simple example demonstrates the potential of group by aggregation
    in gathering insights from data. Okay then, let’s try group-by-aggregation on
    a more interesting dataset!
  prefs: []
  type: TYPE_NORMAL
- en: The Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the Metro Interstate Traffic Volume dataset. It’s a publicly available
    dataset with a [Creative Common 4.0 license](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)
    (which allows for sharing and adaptation of the dataset for any purpose).
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains hourly Minneapolis-St Paul, MN traffic volume for westbound
    I-94, which also includes weather details from 2012–2018\. The data dictionary
    information can be found on its [UCI Machine Learning repo](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)
    page.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/32fdeb6df51b8acd7fcde2589ae5b6ff.png)'
  prefs: []
  type: TYPE_IMG
- en: Traffic data (df) head (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: For this blog demo, we will only use data from 2016 onwards, as there is missing
    traffic data from earlier periods (try to check yourself for exercise!).
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, we will add a new column `is_congested`, which will have a value
    of 1 if the `traffic_volume` exceeds 5000 and 0 otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Metro Traffic EDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using group-by aggregation as the main weapon, we will try to answer the following
    analysis questions.
  prefs: []
  type: TYPE_NORMAL
- en: How is the monthly progression of the traffic volume?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How is the traffic profile of each day in a week (Monday, Tuesday, etc)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are typical hourly traffic volume across 24 hours, broken down by weekday
    vs weekend?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the top weather conditions that correspond to higher congestion rates?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Monthly progression of traffic volume
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This question requires us to aggregate (sum) traffic volumes at month level.
    Because we don’t have the `month` column, we need to derive one based on `date_time`
    column.
  prefs: []
  type: TYPE_NORMAL
- en: With `month`column in place, we can group based on this column, and take the
    sum of `traffic_volume`. The codes are given below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/dae775c6786baf7cb6a9c5ecad22263a.png)'
  prefs: []
  type: TYPE_IMG
- en: monthly_traffic head (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: We can draw line plot from this dataframe!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6ab9165cf2cfe4d78db6ad1b200f250b.png)'
  prefs: []
  type: TYPE_IMG
- en: Monthly traffic volume (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The above visualization shows that traffic volume has generally increased over
    the months within the considered data period.
  prefs: []
  type: TYPE_NORMAL
- en: Daily traffic profile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To analyze this, we need to create two additional columns: `date` and `dayname`.
    The former is used as the primary group-by basis, whereas the latter is used as
    a breakdown when displaying the data.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following codes, we define `date` and `dayname` columns. Later on, we
    group-by based on both columns to get the sum of `traffic_volume`. Note that since
    `dayname` is more coarse (higher aggregation level) than `date` , it effectively
    means we aggregate based on `date` values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/276b382c99b6e35b87a65c410af1b682.png)'
  prefs: []
  type: TYPE_IMG
- en: daily_traffic head (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The above table contains different realizations of daily total traffic volume
    per day name. Box plot visualizations are appropriate to show those variations
    of traffic volume, allowing us to comprehend how traffic volumes differ on Monday,
    Tuesday, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f16f99935a28b55c6b2cb92e791c7921.png)'
  prefs: []
  type: TYPE_IMG
- en: The above plot shows that all weekdays (Mon-Fri) have roughly the same traffic
    density. Weekends (Saturday and Sunday) have lower traffic, with Sunday having
    the least of the two.
  prefs: []
  type: TYPE_NORMAL
- en: Hourly traffic patterns, broken down by weekend status
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar as previous questions, we need to engineer two new columns to answer
    this question, i.e., `hour` and `is_weekend`.
  prefs: []
  type: TYPE_NORMAL
- en: Using the same trick, we will group by `is_weekend` and `hour` columns to get
    averages of `traffic_volume`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d375c70aabf7ca5a524c4d0c70828ef4.png)'
  prefs: []
  type: TYPE_IMG
- en: hourly_traffic head (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: For the visualization, we can use bar chart with break down on `is_weekend`
    flag.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c34979eebbbc1661a4b9e0f846e0921b.png)'
  prefs: []
  type: TYPE_IMG
- en: Hourly traffic pattern, by weekend status (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Very interesting and rich visualization! Observations:'
  prefs: []
  type: TYPE_NORMAL
- en: Weekday traffic has a bimodal distribution pattern. It reaches its highest traffic
    between 6 and 8 a.m. and 16 and 17 p.m. This is somewhat intuitive because those
    time windows represent people going to work and returning home from work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Weekend traffic follows a completely different pattern. It has a unimodal shape
    with a large peak window (12–17). Despite being generally inferior (less traffic)
    to weekday equivalent hours, it is worth noting that weekend traffic is actually
    higher during late-night hours (22–2). This could be because people are staying
    out until late on weekend nights.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Top weather associated with congestion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To answer this question, we need to calculate congestion rate for each weather
    condition in the dataset (utilizing `is_congested` column). Can we calculate it
    using group-by aggregation? Yes we can!
  prefs: []
  type: TYPE_NORMAL
- en: The key observation to make is that the `is_congested` column is binary. Thus,
    the congestion rate can be calculated by simply averaging this column! Average
    of a binary column equals to `count(rows with value = 1)/count(all rows)` — which
    is the congestion rate definition.
  prefs: []
  type: TYPE_NORMAL
- en: Based on this neat observation, all we need to do is taking the average (mean)
    of `is_congested` grouped by `weather_description`. Following that, we sort the
    results descending by `congested_rate`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/dcb0a5842e7936cb2dee5f7fa295da63.png)'
  prefs: []
  type: TYPE_IMG
- en: congested_weather head (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b7b2ea4c435d20fdc4c0983da5822c05.png)'
  prefs: []
  type: TYPE_IMG
- en: Top weather based on congestion rate (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'From the graph:'
  prefs: []
  type: TYPE_NORMAL
- en: The top three weather conditions with the highest congestion rates are sleet,
    light shower snow, and very heavy rain.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Meanwhile, light rain and snow, thunderstorms with drizzle, freezing rain, and
    squalls have not caused any congestion. People must be staying indoors during
    such extreme weather!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Closing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog post, we covered how to use group-by-aggregation in EDA exercises.
    As we can see, this technique is highly effective in revealing interesting, useful
    insights from data, particularly when dealing with granular data.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you can practice doing group-by aggregation during your next EDA project!
    All in all, thanks for reading, and let’s connect with me on [LinkedIn](https://www.linkedin.com/in/pararawendy-indarjo/)!
    👋
  prefs: []
  type: TYPE_NORMAL
