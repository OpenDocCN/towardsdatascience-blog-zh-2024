- en: 'Ranking Basics: Pointwise, Pairwise, Listwise'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 排名基础：点对、成对、列表
- en: 原文：[https://towardsdatascience.com/ranking-basics-pointwise-pairwise-listwise-cd5318f86e1b?source=collection_archive---------3-----------------------#2024-12-14](https://towardsdatascience.com/ranking-basics-pointwise-pairwise-listwise-cd5318f86e1b?source=collection_archive---------3-----------------------#2024-12-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/ranking-basics-pointwise-pairwise-listwise-cd5318f86e1b?source=collection_archive---------3-----------------------#2024-12-14](https://towardsdatascience.com/ranking-basics-pointwise-pairwise-listwise-cd5318f86e1b?source=collection_archive---------3-----------------------#2024-12-14)
- en: Because thy neighbour matters
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 因为邻近的对象很重要
- en: '[](https://medium.com/@kunals726?source=post_page---byline--cd5318f86e1b--------------------------------)[![Kunal
    Santosh Sawant](../Images/f8689b4e61020ca714c28806d51f9b72.png)](https://medium.com/@kunals726?source=post_page---byline--cd5318f86e1b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--cd5318f86e1b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--cd5318f86e1b--------------------------------)
    [Kunal Santosh Sawant](https://medium.com/@kunals726?source=post_page---byline--cd5318f86e1b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@kunals726?source=post_page---byline--cd5318f86e1b--------------------------------)[![Kunal
    Santosh Sawant](../Images/f8689b4e61020ca714c28806d51f9b72.png)](https://medium.com/@kunals726?source=post_page---byline--cd5318f86e1b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--cd5318f86e1b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--cd5318f86e1b--------------------------------)
    [Kunal Santosh Sawant](https://medium.com/@kunals726?source=post_page---byline--cd5318f86e1b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--cd5318f86e1b--------------------------------)
    ·6 min read·Dec 14, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--cd5318f86e1b--------------------------------)
    ·6分钟阅读·2024年12月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/54cb29c9cdd0f38ae586510bb08af75b.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54cb29c9cdd0f38ae586510bb08af75b.png)'
- en: Image taken from unsplash.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 unsplash.com
- en: First, let’s talk about where ranking comes into play. Ranking is a big deal
    in e-commerce and search applications — essentially, any scenario where you need
    to organize documents based on a query. It’s a little different from classic classification
    or regression problems. For instance, in the Titanic dataset, you predict whether
    a passenger survives or not, and in house price prediction, you estimate the price
    of a house. But with ranking, the game changes. Instead of predicting a single
    value or category, you’re trying to order documents based on relevance.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们讨论排名的作用。排名在电子商务和搜索应用中非常重要——基本上是任何需要根据查询来组织文档的场景。这与经典的分类或回归问题有些不同。例如，在泰坦尼克号数据集中，你预测乘客是否幸存，在房价预测中，你估计房子的价格。但在排名中，情况不同。你不是在预测单一的值或类别，而是在尝试根据相关性对文档进行排序。
- en: 'Take an example: You search for “saree” on an e-commerce website like Amazon.
    You don’t just want a random list of sarees; you want the most relevant ones to
    appear at the top, right? That’s where Learning to Rank (LTR) steps in — it ranks
    documents (or products) based on how well they match your query.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子：你在像亚马逊这样的电子商务网站上搜索“纱丽”。你不想要一个随机的纱丽列表；你希望最相关的产品出现在顶部，对吧？这就是学习排序（LTR）的作用——它根据文档（或产品）与查询的匹配程度来对它们进行排名。
- en: Now that we know where ranking fits in, let’s dive into the nitty-gritty of
    different approaches and methods.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了排名的作用，让我们深入探讨不同的排名方法和技术。
- en: 'There are three main methods for Learning to Rank (LTR):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 学习排序（LTR）有三种主要方法：
- en: '**Pointwise**'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**点对（Pointwise）**'
- en: '**Pairwise**'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**成对（Pairwise）**'
- en: '**Listwise**'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**列表（Listwise）**'
- en: To make things easier to follow, let’s establish some notation that we’ll use
    to explain these methods.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易理解，让我们先定义一些符号，用于解释这些方法。
- en: 'We’ll work with a set of queries ***q1,q2,…,qn*** and each query has a corresponding
    set of documents ***d1,d2,d3,…,dm***​. For example:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理一组查询 ***q1, q2, …, qn***，每个查询都有对应的一组文档 ***d1, d2, d3, …, dm***。例如：
- en: Query ***q1*** is associated with documents ***d1***,***d2***,***d3***
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询 ***q1*** 与文档 ***d1***, ***d2***, ***d3*** 相关联。
- en: Query ***q2*** associated with documents ***d4***,***d5***.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询 ***q2*** 与文档 ***d4***, ***d5*** 相关联。
- en: With this setup in mind, let’s break down each method and how they approach
    the ranking problem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了排名的定位，让我们深入分析每种方法及其如何解决排名问题。
- en: Pointwise
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 点对（Pointwise）
- en: 'In the **pointwise approach**, we treat the ranking problem as a simple classification
    task. For each query-document pair, we assign a target label that indicates the
    relevance of the document to the query. For example:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在**点对点方法**中，我们将排名问题视为一个简单的分类任务。对于每个查询-文档对，我们分配一个目标标签，表示文档与查询的相关性。例如：
- en: Label `1` if the document is relevant.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签 `1` 表示文档相关。
- en: Label `0` if the document is not relevant.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签 `0` 表示文档不相关。
- en: 'Using our earlier example, the data would look like this:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以我们之前的例子为例，数据看起来是这样的：
- en: '***q1,d1***→label: 1'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1,d1***→标签: 1'
- en: '***q1,d2***→label: 0'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1,d2***→标签: 0'
- en: '***q1,d3***→label: 1'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1,d3***→标签: 1'
- en: '***q2,d4***→label: 0'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q2,d4***→标签: 0'
- en: '***q2,d5***→label: 1'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q2,d5***→标签: 1'
- en: We train the model using this labeled data, leveraging features from both the
    queries and the documents to predict the label. After training, the model predicts
    the relevance of each document to a given query as a probability (ranging from
    0 to 1). This probability can be interpreted as the relevance score.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这些标注数据训练模型，利用查询和文档中的特征来预测标签。训练完成后，模型会预测每个文档与给定查询的相关性作为一个概率值（范围从0到1）。这个概率值可以解释为相关性分数。
- en: 'For example, after training, the model might produce the following scores:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，训练后，模型可能会生成以下分数：
- en: '***q1​,d1***​→score: 0.6'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1​,d1***​→分数: 0.6'
- en: '***q1,d2***→score: 0.1'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1,d2***→分数: 0.1'
- en: '***q1,d3***→score: 0.4'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1,d3***→分数: 0.4'
- en: 'Using these scores, we re-rank the documents in descending order of relevance:
    ***d1,d3,d2***. This new ranking order is then presented to the user, ensuring
    the most relevant documents appear at the top.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些分数，我们将文档按相关性降序重新排序：***d1,d3,d2***。然后将这个新的排序呈现给用户，确保最相关的文档出现在最前面。
- en: '**Pairwise**'
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**成对比**'
- en: The main drawback of the **pointwise approach** is that it misses the **context**
    in which the user interacts with a document. When a user clicks on or finds a
    document relevant, there are often multiple factors at play — one of the most
    important being the **neighboring items**.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**点对点方法**的主要缺点是它忽略了用户与文档互动时的**上下文**。当用户点击或认为某个文档相关时，往往有多个因素在起作用——其中一个最重要的因素就是**邻近项**。'
- en: For instance, if a user clicks on a document, it might not necessarily mean
    that the document is highly relevant. It could simply be that the other documents
    presented were of poor quality. Similarly, if you had shown a different set of
    documents for the same query, the user’s interaction might have been entirely
    different.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果用户点击了某个文档，这并不一定意味着该文档非常相关。可能只是因为展示的其他文档质量较差。类似地，如果你为相同的查询展示了一组不同的文档，用户的互动可能会完全不同。
- en: Imagine presenting ***d4***​ for query ***q1***​. If ***d4​*** is more relevant
    than ***d1***​, the user might have clicked on ***d4​*** instead. This context
    — how documents compare to each other is completely overlooked in the pointwise
    approach.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，对于查询***q1***，我们展示了***d4***​。如果***d4***​比***d1***​更相关，用户可能会点击***d4***​而不是***d1***。在点对点方法中，这种文档之间的比较完全被忽视。
- en: To capture this **relative relevance**, we turn to the **pairwise approach**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉这种**相对相关性**，我们转向了**成对比方法**。
- en: In the pairwise method, instead of looking at query-document pairs in isolation,
    we focus on **pairs of documents** for the same query and try to predict which
    one is more relevant. This helps incorporate the context of comparison between
    documents.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在成对比方法中，我们不是单独看查询-文档对，而是聚焦于同一查询下的**文档对**，并尝试预测哪个文档更相关。这有助于结合文档之间的比较上下文。
- en: We’ll generate the data similarly for now, but the way we use it will be slightly
    more complex. Let’s break that down next.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在会类似地生成数据，但我们使用它的方式会稍微复杂一些。接下来我们将分解它。
- en: 'Imagine the training data for the **pairwise approach** structured as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，**成对比方法**的训练数据结构如下：
- en: '***q1,(d1,d2)***→label: 1(indicating ***d1***​ is more relevant than ***d2***​)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1,(d1,d2)***→标签: 1（表示***d1***​比***d2***​更相关）'
- en: '***q1,(d2,d3)***→label: 0 (indicating ***d2***​ is less relevant than ***d3***​)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1,(d2,d3)***→标签: 0（表示***d2***​比***d3***​不太相关）'
- en: '***q1,(d1,d3)***→label: 1 (indicating ***d1*** is more relevant than ***d3​***)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q1,(d1,d3)***→标签: 1（表示***d1***比***d3***​更相关）'
- en: '***q2,(d4,d5)***→label: 0(indicating ***d4*** is less relevant than ***d5***​)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***q2,(d4,d5)***→标签: 0（表示***d4***比***d5***​不太相关）'
- en: Here, we assign the labels based on user interactions. For instance, ***d1***​
    and ***d3***​ both being clicked indicates they are relevant, so we maintain their
    order for simplicity in this explanation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们根据用户的互动分配标签。例如，***d1*** 和 ***d3*** 都被点击表示它们相关，因此我们保持它们的顺序，便于在此解释。
- en: 'Model Training Process:'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练过程：
- en: Although the training data is in pairs, the model doesn’t directly process these
    pairs. Instead, we treat it similarly to a classification problem, where each
    **query-document pair** is passed to the model separately.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管训练数据是成对的，但模型并不会直接处理这些对。相反，我们将其类似于分类问题处理，每个**查询-文档对**都会单独传递给模型。
- en: 'For example:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '***s1 = f(q1,d1)***'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***s1 = f(q1,d1)***'
- en: '***s2 = f(q1,d2)***'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***s2 = f(q1,d2)***'
- en: '***s3 = f(q1,d3)***'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***s3 = f(q1,d3)***'
- en: The model generates scores ***s1,s2,s3***​ for the documents. These scores are
    used to compare the relevance of document pairs.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 模型为文档生成评分 ***s1,s2,s3***。这些评分用于比较文档对的相关性。
- en: '**Penalizing the Model:**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**惩罚模型：**'
- en: 'If the model predicts scores that violate the true order of relevance, it is
    penalized. For example:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型预测的评分违反了真实的相关性顺序，那么它会受到惩罚。例如：
- en: If ***s1<s2***, but the training data indicates ***d1>d2***​, the model is penalized
    because it failed to rank ***d1***​ higher than ***d2***​.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 ***s1<s2***，但训练数据表明 ***d1>d2***，则模型会受到惩罚，因为它未能将 ***d1*** 排在 ***d2*** 之前。
- en: If ***s2<s3***​, and the training data indicates ***d2<d3***​, the model did
    the right thing, so no penalty is applied.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 ***s2<s3***，并且训练数据表明 ***d2<d3***，那么模型做对了，因此不需要惩罚。
- en: '**This pairwise comparison helps the model learn the relative order of documents
    for a query, rather than just predicting a standalone relevance score like in
    the pointwise approach.**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**这种成对比较帮助模型学习文档的相对顺序，而不是像点对点方法那样仅预测独立的相关性评分。**'
- en: '**Challenges:**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**挑战：**'
- en: One of the main challenges of implementing pairwise models is the **computational
    complexity** — since we need to compare all possible pairs of documents, the process
    scales as O(n²). Additionally, pairwise methods don’t consider the **global ranking**
    of documents; they focus only on individual pairs during comparisons, which can
    lead to inconsistencies in the overall ranking.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 实现成对模型的主要挑战之一是**计算复杂度**——因为我们需要比较所有可能的文档对，这一过程的规模是 O(n²)。此外，成对方法并不考虑文档的**全局排序**；它们仅在比较过程中关注个别对，这可能导致整体排序的不一致。
- en: Listwise
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Listwise
- en: In listwise ranking, the goal is to optimize the entire list of documents based
    on their relevance to a query. Instead of treating individual documents separately,
    the focus is on the order in which they appear in the list.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Listwise 排序中，目标是基于文档与查询的相关性来优化整个文档列表。与其单独处理每个文档，不如专注于它们在列表中出现的顺序。
- en: 'Here’s a breakdown of how this works in ListNet and LambdaRank:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 ListNet 和 LambdaRank 中工作原理的分解：
- en: '**NDCG (Normalized Discounted Cumulative Gain)**: I’ll dive deeper into NDCG
    in another blog, but for now, think of it as a way to measure how well the ordering
    of items matches their relevance. It rewards relevant items appearing at the top
    of the list and normalizes the score for easier comparison.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**NDCG（归一化折扣累积增益）**：我将在另一篇博客中深入探讨 NDCG，但现在可以把它看作一种衡量项目排序与其相关性匹配程度的方式。它奖励相关项目出现在列表顶部，并对评分进行归一化，以便更容易进行比较。'
- en: 'In listwise ranking, if you have a list of documents (d1, d2, d3), the model
    considers all possible permutations of these documents:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Listwise 排序中，如果你有一个文档列表（d1, d2, d3），模型会考虑这些文档的所有可能排列：
- en: '***(d1, d2, d3)***'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***(d1, d2, d3)***'
- en: '***(d1, d3, d2)***'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***(d1, d3, d2)***'
- en: '***(d2, d1, d3)***'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***(d2, d1, d3)***'
- en: '***(d2, d3, d1)***'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***(d2, d3, d1)***'
- en: '***(d3, d1, d2)***'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***(d3, d1, d2)***'
- en: '***(d3, d2, d1)***'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***(d3, d2, d1)***'
- en: '**Training Process:**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练过程：**'
- en: '**Score Prediction**: The model predicts a score for each document in the list,
    and the documents are ranked according to these scores.For example: ***s1 = f(q1,d1),
    s2 = f(q1,d2)***'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评分预测**：模型为列表中的每个文档预测一个评分，文档将根据这些评分进行排序。例如： ***s1 = f(q1,d1), s2 = f(q1,d2)***'
- en: '**Ideal Ranking**: The ideal ranking is calculated by sorting the documents
    based on their **true relevance**. For example, ***d1*** might be the most relevant,
    followed by ***d2***, and then ***d3.***'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**理想排序**：理想排序是通过根据文档的**真实相关性**对其进行排序来计算的。例如，***d1*** 可能是最相关的，其次是 ***d2***，然后是
    ***d3***。'
- en: '**NDCG Calculation**: NDCG is calculated for each permutation of the document
    list. It checks how close the predicted ranking is to the ideal ranking, considering
    both relevance and the positions of the documents.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**NDCG计算**：NDCG是针对每个文档列表的排列进行计算的。它检查预测排序与理想排序的接近程度，同时考虑到文档的相关性和位置。'
- en: '**Penalizing Incorrect Rankings**: If the predicted ranking differs from the
    ideal, the NDCG score will drop. For example, if the ideal ranking is ***(d1,
    d3, d2)*** but the model ranks ***(d2, d1, d3)***, the NDCG score will be lower
    because the most relevant document (***d1***) isn’t ranked at the top.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**惩罚错误排序**：如果预测排序与理想排序不同，NDCG分数将下降。例如，如果理想排序是***(d1, d3, d2)***，而模型排序为***(d2,
    d1, d3)***，那么NDCG分数会较低，因为最相关的文档（***d1***)没有排在最前面。'
- en: '**Gradient Calculation**: The model calculates gradients based on how much
    the NDCG score would change if the order of documents was adjusted. These gradients
    guide the model on how to improve its predictions.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**梯度计算**：模型根据如果调整文档顺序，NDCG分数会发生的变化来计算梯度。这些梯度指引模型如何改进预测。'
- en: This process helps the model learn to optimize the entire ranking list, improving
    the relevance of documents presented to users.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程帮助模型学习如何优化整个排序列表，提高呈现给用户的文档的相关性。
- en: '**Summary**'
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**总结**'
- en: When it comes to Learning to Rank, there’s no one-size-fits-all approach. Pointwise
    models are super easy to set up and update, but they don’t always take into account
    how documents relate to each other. That said, if you need something simple and
    fast, they’re a great option.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习排序（Learning to Rank）中，并没有一种通用的解决方案。基于点的模型非常容易设置和更新，但它们并不总是考虑到文档之间的相互关系。也就是说，如果你需要一个简单且快速的方法，它们是一个很好的选择。
- en: On the other hand, ***pairwise*** and ***listwise*** methods are more powerful
    because they look at how documents compare to one another. But with that **power
    comes more complexity** 😛, and listwise can be a real challenge because of its
    high complexity in training.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，***成对排序（pairwise）***和***列表排序（listwise）***方法更为强大，因为它们考虑了文档之间的相互比较。但是，这种**力量带来了更多的复杂性**😛，而且列表排序由于训练的高复杂度，可能会成为一个真正的挑战。
- en: Personally, I find the ***pairwise*** approach to be the sweet spot. It strikes
    a good balance between complexity and performance, making it ideal for many situations.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 就我个人而言，我认为***成对排序（pairwise）***方法是一个很好的平衡点。它在复杂性和性能之间达到了良好的平衡，使其在许多情况下都很理想。
- en: At the end of the day, the method you choose really depends on your situation.
    How big and complicated is your dataset? Knowing the pros and cons of each method
    will help you pick the one that works best for what you’re trying to do.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你选择的方法确实取决于你的具体情况。你的数据集有多大且多复杂？了解每种方法的优缺点将帮助你选择最适合你需求的方法。
- en: That’s a wrap for today! Stay tuned for the next part, Until then happy ranking!
    😊
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的内容就到这里！敬请期待下一部分，在那之前祝你排序愉快！😊
- en: 'References:'
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[From RankNet to LambdaRank to LambdaMART: An Overview](https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[从RankNet到LambdaRank再到LambdaMART：概述](https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf)'
- en: '[Learning to Rank: From Pairwise Approach to Listwise Approach](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[学习排序：从成对排序方法到列表排序方法](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf)'
- en: '[Introduction to Learning to Rank](https://everdark.github.io/k9/notebooks/ml/learning_to_rank/learning_to_rank.html)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[学习排序简介](https://everdark.github.io/k9/notebooks/ml/learning_to_rank/learning_to_rank.html)'
