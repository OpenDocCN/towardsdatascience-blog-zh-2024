# å¾®è°ƒ Mistral-7b æ¨¡å‹ä¸ç›´æ¥åå¥½ä¼˜åŒ–

> åŸæ–‡ï¼š[`towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac?source=collection_archive---------0-----------------------#2024-01-01`](https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac?source=collection_archive---------0-----------------------#2024-01-01)

## æå‡ä½ ç›‘ç£å¾®è°ƒæ¨¡å‹çš„è¡¨ç°

[](https://medium.com/@mlabonne?source=post_page---byline--708042745aac--------------------------------)![Maxime Labonne](https://medium.com/@mlabonne?source=post_page---byline--708042745aac--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--708042745aac--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--708042745aac--------------------------------) [Maxime Labonne](https://medium.com/@mlabonne?source=post_page---byline--708042745aac--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--708042745aac--------------------------------) Â·é˜…è¯»æ—¶é—´ 10 åˆ†é’ŸÂ·2024 å¹´ 1 æœˆ 1 æ—¥

--

![](img/3d74f51ec0cdd912262edbd229c2e620.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åªèƒ½æ‰§è¡Œä¸‹ä¸€ä¸ª token çš„é¢„æµ‹ï¼Œè¿™ä½¿å¾—å®ƒä»¬æ— æ³•å›ç­”é—®é¢˜ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆè¿™äº›åŸºç¡€æ¨¡å‹éšåä¼šåœ¨æŒ‡ä»¤å’Œå›ç­”çš„é…å¯¹ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä»¥å……å½“æœ‰ç”¨çš„åŠ©æ‰‹ã€‚ç„¶è€Œï¼Œè¿™ä¸€è¿‡ç¨‹ä»ç„¶å¯èƒ½å­˜åœ¨ç¼ºé™·ï¼šå¾®è°ƒåçš„ LLM å¯èƒ½å­˜åœ¨åè§ã€æœ‰å®³ã€æ¯’æ€§ç­‰é—®é¢˜ã€‚è¿™æ—¶ï¼Œæ¥è‡ªäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ä¾¿å‘æŒ¥äº†ä½œç”¨ã€‚

RLHF ä¸º LLM æä¾›ä¸åŒçš„ç­”æ¡ˆï¼Œå¹¶æ ¹æ®æœŸæœ›çš„è¡Œä¸ºï¼ˆä¾‹å¦‚æœ‰ç”¨æ€§ã€æ¯’æ€§ç­‰ï¼‰å¯¹è¿™äº›ç­”æ¡ˆè¿›è¡Œæ’åºã€‚æ¨¡å‹å­¦ä¼šåœ¨è¿™äº›å€™é€‰ç­”æ¡ˆä¸­è¾“å‡ºæœ€ä½³ç­”æ¡ˆï¼Œä»è€Œæ¨¡ä»¿æˆ‘ä»¬å¸Œæœ›å…¶è¡¨ç°çš„è¡Œä¸ºã€‚è¿™ä¸ªè¿‡ç¨‹é€šå¸¸è¢«è§†ä¸ºä¸€ç§å®¡æŸ¥æ¨¡å‹çš„æ–¹æ³•ï¼Œä½†æœ€è¿‘å®ƒå·²æˆä¸ºä¸€ç§æ”¹å–„æ€§èƒ½çš„æµè¡Œæ–¹å¼ï¼Œå¦‚åœ¨[neural-chat-7b-v3â€“1](https://huggingface.co/Intel/neural-chat-7b-v3-1)ä¸­æ‰€ç¤ºã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä½¿ç”¨ç±»ä¼¼äºå¼ºåŒ–å­¦ä¹ çš„æŠ€æœ¯â€”â€”ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ¥å¾®è°ƒ[OpenHermes-2.5](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)ï¼Œä»è€Œåˆ›å»º[NeuralHermes-2.5](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B)ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å¼•å…¥ä¸€ä¸ªåå¥½æ•°æ®é›†ï¼Œæè¿° DPO ç®—æ³•çš„å·¥ä½œåŸç†ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­ã€‚æˆ‘ä»¬å°†çœ‹åˆ°ï¼Œè¿™æ˜¾è‘—æé«˜äº†åŸºç¡€æ¨¡å‹åœ¨å¼€æ”¾ LLM æ’è¡Œæ¦œä¸Šçš„è¡¨ç°ã€‚

å¦‚å¸¸ï¼Œä»£ç å¯åœ¨[GitHub](https://github.com/mlabonne/llm-course/blob/main/Fine_tune_a_Mistral_7b_model_with_DPO.ipynb)å’Œ[Google Colab](https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing)ä¸Šæ‰¾åˆ°ã€‚

***æ›´æ–°***ï¼š[*Jessie Davids*](https://www.linkedin.com/in/jesse-th-davids/)ï¼Œä¸€ä½ä½¿ç”¨æœ¬æ–‡åŠä»£ç çš„è¯»è€…ï¼ŒæˆåŠŸåˆ›å»ºäº†åœ¨ Open LLM æ’è¡Œæ¦œä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹ï¼Œçº¦ 7B å‚æ•°ã€‚æ­å–œä»–ï¼ğŸ‰

![](img/23a4f24817da40f445ad29a63c66869d.png)

å›¾ç‰‡æ¥æºï¼šä½œè€…

# ğŸ¥‡ åå¥½æ•°æ®é›†

åå¥½æ•°æ®é›†æ²¡æœ‰æ ‡å‡†åŒ–ï¼Œä½†å®ƒä»¬é€šå¸¸ç”±ä¸€ç»„ç»è¿‡äººå·¥æ’åºçš„ç­”æ¡ˆç»„æˆã€‚è¿™ä¸ªæ’åºéå¸¸å…³é”®ï¼Œå› ä¸º RLHF è¿‡ç¨‹ä¼šå¾®è°ƒ LLMï¼Œä½¿å…¶è¾“å‡ºä¼˜é€‰ç­”æ¡ˆã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªå¸¸è§çš„åå¥½æ•°æ®é›†ç¤ºä¾‹ï¼š[Anthropic/hh-rlhf](https://huggingface.co/datasets/Anthropic/hh-rlhf/viewer/default/train)ï¼š

![](img/9930d8bacb694aecb9e9556e101932ff.png)

å›¾ç‰‡æ¥æºï¼šä½œè€…

æ•°æ®é›†çš„ç»“æ„å¾ˆç®€å•ï¼šæ¯ä¸€è¡Œéƒ½æœ‰ä¸€ä¸ªé€‰å®šçš„ï¼ˆä¼˜é€‰çš„ï¼‰ç­”æ¡ˆå’Œä¸€ä¸ªè¢«æ‹’ç»çš„ç­”æ¡ˆã€‚RLHF çš„ç›®æ ‡æ˜¯å¼•å¯¼æ¨¡å‹è¾“å‡ºä¼˜é€‰çš„ç­”æ¡ˆã€‚

åå¥½æ•°æ®é›† notoriously æˆæœ¬é«˜ä¸”éš¾ä»¥åˆ¶ä½œï¼Œå› ä¸ºå®ƒä»¬éœ€è¦ä»äººç±»æ”¶é›†æ‰‹åŠ¨åé¦ˆã€‚è¿™äº›åé¦ˆå¾€å¾€å…·æœ‰ä¸»è§‚æ€§ï¼Œå®¹æ˜“å¯¹è‡ªä¿¡ï¼ˆä½†é”™è¯¯ï¼‰çš„ç­”æ¡ˆäº§ç”Ÿåè§ï¼Œæˆ–ç›¸äº’çŸ›ç›¾ï¼ˆä¸åŒçš„æ ‡æ³¨è€…å¯èƒ½æœ‰ä¸åŒçš„ä»·å€¼è§‚ï¼‰ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œå·²ç»æå‡ºäº†å‡ ç§è§£å†³è¿™äº›é—®é¢˜çš„æ–¹æ¡ˆï¼Œä¾‹å¦‚ç”¨ AI åé¦ˆæ›¿ä»£äººå·¥åé¦ˆï¼ˆ[RLAIF](https://arxiv.org/abs/2212.08073)ï¼‰ã€‚

è¿™äº›æ•°æ®é›†é€šå¸¸æ¯”å¾®è°ƒæ•°æ®é›†è¦å°å¾—å¤šã€‚ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œä¼˜ç§€çš„[neural-chat-7b-v3â€“1](https://huggingface.co/Intel/neural-chat-7b-v3-1)ï¼ˆå‘å¸ƒæ—¶åœ¨[Open LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)ä¸Šæ’åç¬¬ä¸€çš„ 7B LLMï¼‰ä½¿ç”¨äº† 518k ä¸ªæ ·æœ¬è¿›è¡Œå¾®è°ƒï¼ˆ[Open-Orca/SlimOrca](https://huggingface.co/datasets/Open-Orca/SlimOrca)ï¼‰ï¼Œä½†ä»…ä½¿ç”¨äº† 12.9k ä¸ªæ ·æœ¬è¿›è¡Œ RLHFï¼ˆ[Intel/orca_dpo_pairs](https://huggingface.co/datasets/Intel/orca_dpo_pairs)ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½œè€…ä½¿ç”¨ GPT-4/3.5 ç”Ÿæˆç­”æ¡ˆæ¥åˆ›å»ºä¼˜é€‰ç­”æ¡ˆï¼Œä½¿ç”¨[Llama 2 13b chat](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf)ç”Ÿæˆè¢«æ‹’ç»çš„å›ç­”ã€‚è¿™æ˜¯ä¸€ç§å·§å¦™çš„æ–¹æ³•ï¼Œé€šè¿‡ç»•è¿‡äººå·¥åé¦ˆï¼Œä»…ä¾èµ–äºä¸åŒæ€§èƒ½æ°´å¹³çš„æ¨¡å‹ã€‚

# ğŸ“ ç›´æ¥åå¥½ä¼˜åŒ–

è™½ç„¶ RLHF çš„æ¦‚å¿µåœ¨æœºå™¨äººæŠ€æœ¯ä¸­å·²ç»ä½¿ç”¨äº†å¾ˆé•¿æ—¶é—´ï¼Œä½†å®ƒåœ¨ LLM ä¸­çš„æµè¡Œèµ·æºäº OpenAI çš„è®ºæ–‡[ä»äººç±»åå¥½å¾®è°ƒè¯­è¨€æ¨¡å‹](https://arxiv.org/pdf/1909.08593.pdf)ã€‚åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªæ¡†æ¶ï¼Œé€šè¿‡è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹æ¥è¿‘ä¼¼äººç±»åé¦ˆã€‚ç„¶åï¼Œä½¿ç”¨è¿™ä¸ªå¥–åŠ±æ¨¡å‹é€šè¿‡[é‚»è¿‘ç­–ç•¥ä¼˜åŒ–](https://arxiv.org/abs/1707.06347)ï¼ˆPPOï¼‰ç®—æ³•ä¼˜åŒ–å¾®è°ƒåçš„æ¨¡å‹ç­–ç•¥ã€‚

![](img/4770f82fec81739184b15c998ee60ca5.png)

å›¾ç‰‡æ¥æºï¼šä½œè€…

PPO çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯å¯¹ç­–ç•¥è¿›è¡Œè¾ƒå°çš„ã€å¢é‡çš„æ›´æ–°ï¼Œå› ä¸ºè¾ƒå¤§çš„æ›´æ–°å¯èƒ½å¯¼è‡´ä¸ç¨³å®šæˆ–æ¬¡ä¼˜çš„è§£å†³æ–¹æ¡ˆã€‚ä»ç»éªŒæ¥çœ‹ï¼Œè¿™ç§æŠ€æœ¯ä¸å¹¸çš„æ˜¯ä»ç„¶ä¸ç¨³å®šï¼ˆæŸå¤±å‘æ•£ï¼‰ï¼Œéš¾ä»¥é‡ç°ï¼ˆæœ‰å¤§é‡è¶…å‚æ•°ï¼Œä¸”å¯¹éšæœºç§å­æ•æ„Ÿï¼‰ï¼Œè€Œä¸”è®¡ç®—å¼€é”€å¤§ã€‚

è¿™æ—¶ï¼Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å‘æŒ¥äº†ä½œç”¨ã€‚DPO é€šè¿‡å°†ä»»åŠ¡è§†ä¸ºåˆ†ç±»é—®é¢˜æ¥ç®€åŒ–æ§åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä½¿ç”¨äº†ä¸¤ä¸ªæ¨¡å‹ï¼š**è®­ç»ƒæ¨¡å‹**ï¼ˆæˆ–ç­–ç•¥æ¨¡å‹ï¼‰å’Œä¸€ä¸ªåä¸º **å‚è€ƒæ¨¡å‹** çš„å‰¯æœ¬ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç›®æ ‡æ˜¯ç¡®ä¿è®­ç»ƒæ¨¡å‹å¯¹äºä¼˜é€‰ç­”æ¡ˆè¾“å‡ºæ¯”å‚è€ƒæ¨¡å‹æ›´é«˜çš„æ¦‚ç‡ã€‚ç›¸åï¼Œæˆ‘ä»¬ä¹Ÿå¸Œæœ›å®ƒå¯¹æ‹’ç»çš„ç­”æ¡ˆè¾“å‡ºæ›´ä½çš„æ¦‚ç‡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬åœ¨æƒ©ç½šè¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»™å‡ºçš„ä¸è‰¯ç­”æ¡ˆï¼ŒåŒæ—¶å¥–åŠ±å®ƒç»™å‡ºçš„ä¼˜è´¨ç­”æ¡ˆã€‚

![](img/43f19625c49e94b7304ff1e6d521573a.png)

å›¾åƒæ¥è‡ªä½œè€…

é€šè¿‡å°† LLM æœ¬èº«ä½œä¸ºå¥–åŠ±æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨äºŒå…ƒäº¤å‰ç†µç›®æ ‡ï¼ŒDPO é«˜æ•ˆåœ°å°†æ¨¡å‹çš„è¾“å‡ºä¸äººç±»åå¥½å¯¹é½ï¼Œæ— éœ€å¹¿æ³›çš„é‡‡æ ·ã€å¥–åŠ±æ¨¡å‹æ‹Ÿåˆæˆ–å¤æ‚çš„è¶…å‚æ•°è°ƒæ•´ã€‚è¿™ä½¿å¾—è¯¥è¿‡ç¨‹æ›´åŠ ç¨³å®šã€é«˜æ•ˆä¸”è®¡ç®—éœ€æ±‚è¾ƒä½ã€‚

# ğŸ’¾ æ•°æ®æ ¼å¼åŒ–

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†å¾®è°ƒå‡ºè‰²çš„ [OpenHermes-2.5-Mistral-7B](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)ï¼Œè¿™æ˜¯ä¸€ä¸ªä»…ç»è¿‡ç›‘ç£å¾®è°ƒçš„ Mistral-7b æ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Intel/orca_dpo_pairs](https://huggingface.co/datasets/Intel/orca_dpo_pairs) æ•°æ®é›†æ¥å¯¹é½æˆ‘ä»¬çš„æ¨¡å‹å¹¶æé«˜å…¶æ€§èƒ½ã€‚æˆ‘ä»¬å°†è¿™ä¸ªæ–°æ¨¡å‹ç§°ä¸º NeuralHermes-2.5-Mistral-7Bã€‚

ç¬¬ä¸€é˜¶æ®µåŒ…æ‹¬å®‰è£…æ‰€éœ€çš„åº“ï¼Œå…·ä½“æ­¥éª¤å¦‚ä¸‹ã€‚

```py
pip install -q datasets trl peft bitsandbytes sentencepiece wandb
```

å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥å¯¼å…¥è¿™äº›åº“ã€‚æˆ‘è¿˜åœ¨ Google Colab çš„ç§˜å¯†æ ‡ç­¾ä¸­å­˜å‚¨äº†æˆ‘çš„ Hugging Face tokenã€‚

```py
import os
import gc
import torch

import transformers
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig
from datasets import load_dataset
from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training
from trl import DPOTrainer
import bitsandbytes as bnb
from google.colab import userdata
import wandb

# Defined in the secrets tab in Google Colab
hf_token = userdata.get('huggingface')
wb_token = userdata.get('wandb')
wandb.login(key=wb_token)

model_name = "teknium/OpenHermes-2.5-Mistral-7B"
new_model = "NeuralHermes-2.5-Mistral-7B"
```

OpenHermes-2.5-Mistral-7B ä½¿ç”¨äº†ä¸€ç§ç‰¹å®šçš„èŠå¤©æ¨¡æ¿ï¼Œç§°ä¸º [ChatML](https://huggingface.co/docs/transformers/chat_templating)ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨è¯¥æ¨¡æ¿æ ¼å¼åŒ–çš„å¯¹è¯ç¤ºä¾‹ï¼š

```py
<|im_start|>system
You are a helpful chatbot assistant.<|im_end|>
<|im_start|>user
Hi<|im_end|>
<|im_start|>assistant
Hi, how can I help you?<|im_end|>
```

å¦‚ä½ æ‰€è§ï¼ŒChatML å®šä¹‰äº†ä¸åŒçš„è§’è‰²ï¼ˆç³»ç»Ÿã€ç”¨æˆ·ã€åŠ©æ‰‹ï¼‰ï¼Œå¹¶é™„åŠ äº†ç‰¹æ®Šæ ‡è®°ï¼ˆ`<|im_start|>` å’Œ `<|im_end|>`ï¼‰æ¥åˆ†éš”å®ƒä»¬ã€‚æ­¤å¤–ï¼Œ`[DPOTrainer](https://huggingface.co/docs/trl/main/en/dpo_trainer)` è¿˜éœ€è¦ä¸€ä¸ªç‰¹å®šçš„æ ¼å¼ï¼ŒåŒ…å«ä¸‰åˆ—ï¼špromptã€chosen å’Œ rejectedã€‚

æˆ‘ä»¬çš„æ•°æ®é›†åŒ…å«å››åˆ—ï¼šsystemã€questionã€chatgpt å’Œ llama2â€“13b-chatã€‚æˆ‘ä»¬å°†ç®€å•åœ°å°† system å’Œ question åˆ—æ‹¼æ¥åˆ° prompt åˆ—ã€‚æˆ‘ä»¬è¿˜ä¼šå°† chatgpt åˆ—æ˜ å°„åˆ°â€œchosenâ€ï¼Œå°† llama2â€“13b-chat åˆ—æ˜ å°„åˆ°â€œrejectedâ€ã€‚ä¸ºäº†å¯é åœ°æ ¼å¼åŒ–æ•°æ®é›†ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åˆ†è¯å™¨çš„ `apply_chat_template()` å‡½æ•°ï¼Œè¯¥å‡½æ•°å·²ç»ä½¿ç”¨äº† ChatMLã€‚

```py
def chatml_format(example):
    # Format system
    if len(example['system']) > 0:
        message = {"role": "system", "content": example['system']}
        system = tokenizer.apply_chat_template([message], tokenize=False)
    else:
        system = ""

    # Format instruction
    message = {"role": "user", "content": example['question']}
    prompt = tokenizer.apply_chat_template([message], tokenize=False, add_generation_prompt=True)

    # Format chosen answer
    chosen = example['chosen'] + "<|im_end|>\n"

    # Format rejected answer
    rejected = example['rejected'] + "<|im_end|>\n"

    return {
        "prompt": system + prompt,
        "chosen": chosen,
        "rejected": rejected,
    }

# Load dataset
dataset = load_dataset("Intel/orca_dpo_pairs")['train']

# Save columns
original_columns = dataset.column_names

# Tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = "left"

# Format dataset
dataset = dataset.map(
    chatml_format,
    remove_columns=original_columns
)
```

è®©æˆ‘ä»¬æ‰“å°æ ¼å¼åŒ–æ•°æ®é›†çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œä»¥ç¡®è®¤ä¸€åˆ‡æŒ‰é¢„æœŸå·¥ä½œï¼š

```py
{'prompt': '<|im_start|>system\nYou are an AI assistant. You will be given a task. You must generate a detailed and long answer.<|im_end|>\n<|im_start|>user\nGenerate an approximately fifteen-word sentence that describes all this data: Midsummer House eatType restaurant; Midsummer House food Chinese; Midsummer House priceRange moderate; Midsummer House customer rating 3 out of 5; Midsummer House near All Bar One<|im_end|>\n<|im_start|>assistant\n',
'chosen': 'Midsummer House is a moderately priced Chinese restaurant with a 3/5 customer rating, located near All Bar One.<|im_end|>\n',
'rejected': ' Sure! Here\'s a sentence that describes all the data you provided:\n\n"Midsummer House is a moderately priced Chinese restaurant with a customer rating of 3 out of 5, located near All Bar One, offering a variety of delicious dishes."<|im_end|>\n'}
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæç¤ºè¯ç»“åˆäº†ç³»ç»Ÿå’Œç”¨æˆ·çš„æŒ‡ä»¤ã€‚æ„Ÿè°¢`add_generation_prompt=True`å‚æ•°ï¼Œå®ƒè¿˜é™„åŠ äº†åŠ©æ‰‹å›ç­”çš„å¼€å¤´ã€‚å¦‚æœä½ æƒ³è·³è¿‡è¿™ä¸€æ­¥ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨é¢„å¤„ç†è¿‡çš„æ•°æ®é›†ï¼Œä¾‹å¦‚[mlabonne/chatml_dpo_pairs](https://huggingface.co/datasets/mlabonne/chatml_dpo_pairs)ã€‚

# âš™ï¸ ä½¿ç”¨ DPO è®­ç»ƒæ¨¡å‹

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ LoRA é…ç½®æ¥è®­ç»ƒæ¨¡å‹ã€‚å¦‚[Intel çš„åšå®¢æ–‡ç« ](https://medium.com/intel-analytics-software/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3)ä¸­æ‰€è¿°ï¼Œæˆ‘ä»¬å°†ç§©å€¼è®¾ç½®ä¸ºç­‰äº`lora_alpha`ï¼Œè¿™æ˜¯ä¸å¸¸è§çš„ï¼ˆé€šå¸¸ä¸º 2 * `r`ï¼‰ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨é€‚é…å™¨æ¥é’ˆå¯¹æ‰€æœ‰çº¿æ€§æ¨¡å—ã€‚

```py
# LoRA configuration
peft_config = LoraConfig(
    r=16,
    lora_alpha=16,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=['k_proj', 'gate_proj', 'v_proj', 'up_proj', 'q_proj', 'o_proj', 'down_proj']
)
```

æˆ‘ä»¬ç°åœ¨å‡†å¤‡åŠ è½½è¦ç”¨ DPO è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œéœ€è¦ä¸¤ä¸ªæ¨¡å‹ï¼šä¸€ä¸ªç”¨äºå¾®è°ƒçš„æ¨¡å‹å’Œä¸€ä¸ªå‚è€ƒæ¨¡å‹ã€‚è¿™æ ·åšä¸»è¦æ˜¯ä¸ºäº†å¯è¯»æ€§ï¼Œå› ä¸º`DPOTrainer`å¯¹è±¡å¦‚æœæ²¡æœ‰æä¾›å‚è€ƒæ¨¡å‹ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªå‚è€ƒæ¨¡å‹ã€‚

```py
# Model to fine-tune
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    load_in_4bit=True
)
model.config.use_cache = False

# Reference model
ref_model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    load_in_4bit=True
)
```

æœ€ç»ˆæ­¥éª¤æ˜¯å°†æ‰€æœ‰è¶…å‚æ•°æä¾›ç»™`TrainingArguments`å’Œ`DPOTrainer`ï¼š

+   å…¶ä¸­ï¼Œ`beta`å‚æ•°æ˜¯ DPO ç‰¹æœ‰çš„ï¼Œå› ä¸ºå®ƒæ§åˆ¶äº†ä¸åˆå§‹ç­–ç•¥çš„åç¦»ï¼ˆ0.1 æ˜¯ä¸€ä¸ªå…¸å‹å€¼ï¼‰ã€‚

+   ä¸[Intel çš„åšå®¢æ–‡ç« ](https://medium.com/intel-analytics-software/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3)ä¸­æè¿°çš„å€¼ç›¸æ¯”ï¼Œæˆ‘ä»¬é™ä½äº†å­¦ä¹ ç‡ï¼ˆä» 5e-4 é™åˆ° 5e-5ï¼‰å’Œæ­¥æ•°ï¼ˆä» 1,000 é™åˆ° 200ï¼‰ã€‚åœ¨å‡ æ¬¡è¿è¡Œåï¼Œæˆ‘æ‰‹åŠ¨ä¼˜åŒ–äº†è¿™äº›å€¼ï¼Œä»¥ç¨³å®šè®­ç»ƒå¹¶è·å¾—æœ€ä½³ç»“æœã€‚

ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ã€‚è¯·æ³¨æ„ï¼Œå®ƒéœ€è¦ä¸€å— A100 GPUï¼Œå¹¶ä¸”è®­ç»ƒæ—¶é—´å¤§çº¦éœ€è¦ 1 å°æ—¶ã€‚

```py
# Training arguments
training_args = TrainingArguments(
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    gradient_checkpointing=True,
    learning_rate=5e-5,
    lr_scheduler_type="cosine",
    max_steps=200,
    save_strategy="no",
    logging_steps=1,
    output_dir=new_model,
    optim="paged_adamw_32bit",
    warmup_steps=100,
    bf16=True,
    report_to="wandb",
)

# Create DPO trainer
dpo_trainer = DPOTrainer(
    model,
    ref_model,
    args=training_args,
    train_dataset=dataset,
    tokenizer=tokenizer,
    peft_config=peft_config,
    beta=0.1,
    max_prompt_length=1024,
    max_length=1536,
)

# Fine-tune model with DPO
dpo_trainer.train()
```

æˆ‘ä»¬çš„æ¨¡å‹ç°åœ¨å·²ç»å®Œæˆå¾®è°ƒã€‚ä½ å¯ä»¥åœ¨ Weights & Biases ä¸ŠæŸ¥çœ‹è¯¥é¡¹ç›®ï¼Œ[åœ°å€å¦‚ä¸‹](https://wandb.ai/mlabonne/NeuralHermes-2-5-Mistral-7B/runs/axe71gr0?workspace=user-mlabonne)ã€‚è¿™é‡Œæœ‰ä¸€äº›æœ‰è¶£çš„æŒ‡æ ‡å¯ä»¥åˆ†æï¼š

![](img/a3622d152e976686a7e55807e80b371a.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

æœ‰è¶£çš„æ˜¯ï¼Œè®­ç»ƒæŸå¤±è¿…é€Ÿä¸‹é™åˆ°é›¶ï¼ˆåœ¨ 50 æ­¥ä¹‹å‰ï¼‰ï¼Œå°½ç®¡æœ‰ 100 æ­¥çš„çƒ­èº«æ­¥éª¤ã€‚ä¸æ­¤åŒæ—¶ï¼Œå…¶ä»–æŒ‡æ ‡æŒç»­æ¼”å˜ã€‚

train/rewards/chosen å’Œ train/rewards/rejected å›¾è¡¨å¯¹åº”çš„æ˜¯è®­ç»ƒæ¨¡å‹å’Œå‚è€ƒæ¨¡å‹è¾“å‡ºçš„å¯¹æ•°æ¦‚ç‡ä¹‹é—´çš„å¹³å‡å·®å¼‚ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œå®ƒä»¬çš„å·®å¼‚é€æ¸å¢å¤§ï¼Œå› ä¸ºæˆ‘ä»¬çš„è®­ç»ƒæ¨¡å‹å­¦ä¹ äº†é¦–é€‰ç­”æ¡ˆã€‚train/rewards/margins å›¾è¡¨ä¹Ÿæ˜¾ç¤ºäº†è¿™ä¸¤è€…ä¹‹é—´çš„å·®å¼‚ã€‚æœ€åï¼Œtrain/reward/accuracies å›¾è¡¨å±•ç¤ºäº†é€‰æ‹©é¦–é€‰ç­”æ¡ˆçš„é¢‘ç‡ã€‚è®­ç»ƒåçš„æ¨¡å‹è¿…é€Ÿè¾¾åˆ°äº†å®Œç¾çš„å‡†ç¡®ç‡ï¼Œè¿™è™½ç„¶æ˜¯ä¸€ä¸ªå¥½å…†å¤´ï¼Œä½†ä¹Ÿå¯èƒ½æ„å‘³ç€é¦–é€‰ç­”æ¡ˆä¸è¢«æ‹’ç»ç­”æ¡ˆä¹‹é—´çš„å·®å¼‚è¿‡äºæ˜æ˜¾ã€‚

ç°åœ¨æ¨¡å‹å·²ç»è®­ç»ƒå®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥å°†é€‚é…å™¨ä¸åŸå§‹æ¨¡å‹åˆå¹¶ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¿å­˜åˆå¹¶åçš„æ¨¡å‹å’Œæ ‡è®°å™¨ï¼Œç„¶åå°†å…¶æ¨é€åˆ° Hugging Face Hubã€‚

```py
# Save artifacts
dpo_trainer.model.save_pretrained("final_checkpoint")
tokenizer.save_pretrained("final_checkpoint")

# Flush memory
del dpo_trainer, model, ref_model
gc.collect()
torch.cuda.empty_cache()

# Reload model in FP16 (instead of NF4)
base_model = AutoModelForCausalLM.from_pretrained(
    model_name,
    return_dict=True,
    torch_dtype=torch.float16,
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Merge base model with the adapter
model = PeftModel.from_pretrained(base_model, "final_checkpoint")
model = model.merge_and_unload()

# Save model and tokenizer
model.save_pretrained(new_model)
tokenizer.save_pretrained(new_model)

# Push them to the HF Hub
model.push_to_hub(new_model, use_temp_dir=False, token=hf_token)
tokenizer.push_to_hub(new_model, use_temp_dir=False, token=hf_token)
```

è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„æ¨¡å‹åœ¨å®é™…æµ‹è¯•ä¸­çš„è¡¨ç°ã€‚æˆ‘ä»¬å°†æ ¼å¼åŒ–æç¤ºï¼Œæå‡ºä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼šâ€œä»€ä¹ˆæ˜¯å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Ÿâ€

```py
# Format prompt
message = [
    {"role": "system", "content": "You are a helpful assistant chatbot."},
    {"role": "user", "content": "What is a Large Language Model?"}
]
tokenizer = AutoTokenizer.from_pretrained(new_model)
prompt = tokenizer.apply_chat_template(message, add_generation_prompt=True, tokenize=False)

# Create pipeline
pipeline = transformers.pipeline(
    "text-generation",
    model=new_model,
    tokenizer=tokenizer
)

# Generate text
sequences = pipeline(
    prompt,
    do_sample=True,
    temperature=0.7,
    top_p=0.9,
    num_return_sequences=1,
    max_length=200,
)
print(sequences[0]['generated_text'])
```

è¿™æ˜¯æ¨¡å‹çš„å›ç­”ï¼š

```py
A large language model is a type of artificial intelligence (AI) system that has been trained on vast amounts of text data. These models are designed to understand and generate human language, allowing them to perform various natural language processing tasks, such as text generation, language translation, and question answering. Large language models typically use deep learning techniques, like recurrent neural networks (RNNs) or transformers, to learn patterns and relationships in the data, enabling them to generate coherent and contextually relevant responses. The size of these models, in terms of the number of parameters and the volume of data they are trained on, plays a significant role in their ability to comprehend and produce complex language structures.
```

ä¸€åˆ‡ä¼¼ä¹éƒ½åœ¨æ­£å¸¸å·¥ä½œï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥è¯„ä¼°åˆå¹¶åçš„æ¨¡å‹ã€‚ç”±äºè¿™æ˜¯ä¸€ä¸ªé€šç”¨æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) æ¥è¯„ä¼°å®ƒã€‚ç”±äºè¿™ä¸ªè¿‡ç¨‹ç›¸å½“èµ„æºå¯†é›†ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥å°†å…¶æäº¤åˆ° [Open LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)è¿›è¡Œè¯„ä¼°ã€‚è™½ç„¶èŠ±è´¹äº†å‡ å¤©æ—¶é—´ï¼Œä½†è¿™é‡Œæ˜¯ä¸å…¶ä»– OpenHermes æ¨¡å‹çš„å¯¹æ¯”ç»“æœï¼š

![](img/9e7444bfe5a4b31c4a4f1df2ed935365.png)

ä½œè€…æä¾›çš„å›¾ç‰‡

ä¸åŸå§‹æ¨¡å‹ç›¸æ¯”ï¼ŒNeuralHermes-2.5-Mistral-7B æ¨¡å‹å°†å¹³å‡å¾—åˆ†æé«˜äº† 6.7 åˆ†ï¼ˆå°¤å…¶æ˜¯åœ¨ GSM8K ä¸Šï¼‰ã€‚è¿™æ˜¯ä¸€æ¬¡å‡ºä¹æ„æ–™çš„å·¨å¤§æå‡ï¼Œå±•ç¤ºäº†ç›´æ¥åå¥½ä¼˜åŒ–çš„å¼ºå¤§åŠ›é‡ã€‚

# ç»“è®º

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ DPO å¾®è°ƒäº†ä¸€ä¸ªå·²ç»ç»è¿‡ç›‘ç£å¾®è°ƒçš„æ¨¡å‹ï¼Œå¹¶åˆ›å»ºäº†æˆ‘ä»¬è‡ªå·±çš„ [NeuralHermes-2.5](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B) æ¨¡å‹ã€‚é€šè¿‡åˆ©ç”¨é«˜è´¨é‡çš„åå¥½æ•°æ®é›†ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªé«˜æ•ˆçš„å¾®è°ƒæµç¨‹ï¼Œå¹¶åœ¨ Open LLM æ’è¡Œæ¦œä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚å¦‚æœä½ æƒ³å°è¯•ï¼Œå¯ä»¥æ‰¾åˆ°è¿™ä¸ªæ¨¡å‹çš„é‡åŒ–å˜ä½“ï¼Œæˆ–ä½¿ç”¨è¿™ä¸ª [Hugging Face Space](https://huggingface.co/spaces/zhangtao103239/NeuralHermes-2.5-Mistral-7B-GGUF-Chat)ã€‚

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬çš„å¾®è°ƒæµç¨‹ä»ç„¶å¯ä»¥é€šè¿‡ä¸åŒçš„æ–¹å¼è¿›è¡Œæ”¹è¿›ã€‚ä¾‹å¦‚ï¼Œåå¥½æ•°æ®é›†ä»ç„¶ç›¸å½“åŸå§‹ï¼Œå¯ä»¥é€šè¿‡æ›´å¤šçš„è¿‡æ»¤å’Œä½¿ç”¨ä¸åŒçš„æ¨¡å‹æ¥æ”¹è¿›ã€‚æ­¤å¤–ï¼Œè®¸å¤šè¶…å‚æ•°ä»ç„¶å¯ä»¥è¿›è¡Œè°ƒæ•´ï¼Œä»¥è·å¾—æ›´å¥½çš„ç»“æœã€‚ç‰¹åˆ«æ˜¯ï¼Œå­¦ä¹ ç‡ä»ç„¶å¯ä»¥é™ä½ï¼Œä»¥ä¾¿åœ¨æ›´å¤šçš„æ­¥éª¤ä¸Šè®­ç»ƒæ¨¡å‹å¹¶æ³¨å…¥æ›´å¤šçš„åå¥½æ•°æ®ã€‚

# å‚è€ƒæ–‡çŒ®

+   [é€šè¿‡ DPO å¾®è°ƒ Llama 2](https://huggingface.co/blog/dpo-trl) ä½œè€…ï¼šKashif Rasulã€Younes Belkada å’Œ Leandro von Werraã€‚

+   [åœ¨ Intel Gaudi2 ä¸Šçš„ç›‘ç£å¾®è°ƒå’Œç›´æ¥åå¥½ä¼˜åŒ–](https://medium.com/intel-analytics-software/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3) ä½œè€…ï¼šKaokao Lvã€Wenxin Zhang å’Œ Haihao Shenã€‚

+   [llama2-fine-tune](https://github.com/mzbac/llama2-fine-tune) ä½œè€…ï¼šmzbacã€‚

*äº†è§£æ›´å¤šå…³äºæœºå™¨å­¦ä¹ çš„çŸ¥è¯†ï¼Œå¹¶é€šè¿‡ä¸€æ¬¡ç‚¹å‡»æ”¯æŒæˆ‘çš„å·¥ä½œ â€”â€” åœ¨è¿™é‡Œæˆä¸º Medium ä¼šå‘˜ï¼š*

[](https://medium.com/@mlabonne/membership?source=post_page-----708042745aac--------------------------------) [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium - Maxime Labonne

### ä½œä¸º Medium çš„ä¼šå‘˜ï¼Œä½ çš„ä¸€éƒ¨åˆ†ä¼šå‘˜è´¹ç”¨ä¼šåˆ†é…ç»™ä½ é˜…è¯»çš„ä½œè€…ï¼Œå¹¶ä¸”ä½ å¯ä»¥å®Œå…¨è®¿é—®æ¯ç¯‡æ•…äº‹â€¦

medium.com](https://medium.com/@mlabonne/membership?source=post_page-----708042745aac--------------------------------)
