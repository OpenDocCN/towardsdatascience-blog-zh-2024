<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>An Agentic Approach to Reducing LLM Hallucinations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>An Agentic Approach to Reducing LLM Hallucinations</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-agentic-approach-to-reducing-llm-hallucinations-f7ffd6eedcf2?source=collection_archive---------1-----------------------#2024-12-22">https://towardsdatascience.com/an-agentic-approach-to-reducing-llm-hallucinations-f7ffd6eedcf2?source=collection_archive---------1-----------------------#2024-12-22</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="793a" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Simple techniques to alleviate LLM hallucinations using LangGraph</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@CVxTz?source=post_page---byline--f7ffd6eedcf2--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Youness Mansar" class="l ep by dd de cx" src="../Images/b68fe2cbbe219ab0231922c7165f2b6a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*qleZEabtiUsEZaUHvsaWTQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f7ffd6eedcf2--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@CVxTz?source=post_page---byline--f7ffd6eedcf2--------------------------------" rel="noopener follow">Youness Mansar</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f7ffd6eedcf2--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 22, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/630e9d5af9ca9f6e315c751334d7460c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fNRfvA4TOQuHOzfh"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@grakozy?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Greg Rakozy</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="650c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If you’ve worked with LLMs, you know they can sometimes hallucinate. This means they generate text that’s either nonsensical or contradicts the input data. It’s a common issue that can hurts the reliability of LLM-powered applications.</p><p id="8a34" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In this post, we’ll explore a few simple techniques to reduce the likelihood of hallucinations. By following these tips, you can (hopefully) improve the accuracy of your AI applications.</p><p id="f868" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">There are multiple types of hallucinations:</p><ul class=""><li id="ff78" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob bk"><a class="af nc" href="https://arxiv.org/pdf/2311.05232" rel="noopener ugc nofollow" target="_blank">Intrinsic hallucinations</a>: the LLM’s response contradicts the user-provided context. This is when the response is verifiably wrong withing the current context.</li><li id="cdcb" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk"><a class="af nc" href="https://arxiv.org/pdf/2311.05232" rel="noopener ugc nofollow" target="_blank">Extrinsic hallucinations</a>: the LLM’s response cannot be verified using the user-provided context. This is when the response may or may not be wrong but we have no way of confirming that using the current context.</li><li id="b749" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">Incoherent hallucinations: the LLM’s response does not answer the question or does not make sense. This is when the LLM is unable to follow the instructions.</li></ul><p id="d8a1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In this post, we will target all the types mentioned above.</p><p id="7599" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We will list out a set of tips and tricks that work in different ways in reducing hallucinations.</p><h2 id="9b3d" class="oh oi fq bf oj ok ol om on oo op oq or nm os ot ou nq ov ow ox nu oy oz pa pb bk">Tip 1: Use Grounding</h2><p id="09c0" class="pw-post-body-paragraph nd ne fq nf b go pc nh ni gr pd nk nl nm pe no np nq pf ns nt nu pg nw nx ny fj bk">Grounding is using in-domain relevant additional context in the input of the LLM when asking it to do a task. This gives the LLM the information it needs to correctly answer the question and reduces the likelihood of a hallucination. This is one the reason we use Retrieval augmented generation (RAG).</p><p id="5ff3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For example asking the LLM a math question OR asking it the same question while providing it with relevant sections of a math book will yield different results, with the second option being more likely to be right.</p><p id="618c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here is an example of such implementation in one of my previous tutorials where I provide document-extracted context when asking a question:</p><div class="ph pi pj pk pl pm"><a rel="noopener follow" target="_blank" href="/build-a-document-ai-pipeline-for-any-type-of-pdf-with-gemini-9221c8e143db?source=post_page-----f7ffd6eedcf2--------------------------------"><div class="pn ab ig"><div class="po ab co cb pp pq"><h2 class="bf fr hw z io pr iq ir ps it iv fp bk">Build a Document AI pipeline for ANY type of PDF With Gemini</h2><div class="pt l"><h3 class="bf b hw z io pr iq ir ps it iv dx">Tables, Images, figures or handwriting are not problem anymore ! Full Code provided.</h3></div><div class="pu l"><p class="bf b dy z io pr iq ir ps it iv dx">towardsdatascience.com</p></div></div><div class="pv l"><div class="pw l px py pz pv qa lr pm"/></div></div></a></div></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="9e13" class="oh oi fq bf oj ok ol om on oo op oq or nm os ot ou nq ov ow ox nu oy oz pa pb bk">Tip 2: Use structured outputs</h2><p id="52ba" class="pw-post-body-paragraph nd ne fq nf b go pc nh ni gr pd nk nl nm pe no np nq pf ns nt nu pg nw nx ny fj bk">Using structured outputs means forcing the LLM to output valid JSON or YAML text. This will allow you to reduce the useless ramblings and get “straight-to-the-point” answers about what you need from the LLM. It also will help with the next tips as it makes the LLM responses easier to verify.</p><p id="3b26" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here is how you can do this with Gemini’s API:</p><pre class="mm mn mo mp mq qj qk ql bp qm bb bk"><span id="5f4b" class="qn oi fq qk b bg qo qp l qq qr">import json<br/><br/>import google.generativeai as genai<br/>from pydantic import BaseModel, Field<br/><br/>from document_ai_agents.schema_utils import prepare_schema_for_gemini<br/><br/><br/>class Answer(BaseModel):<br/>    answer: str = Field(..., description="Your Answer.")<br/><br/><br/>model = genai.GenerativeModel("gemini-1.5-flash-002")<br/><br/>answer_schema = prepare_schema_for_gemini(Answer)<br/><br/><br/>question = "List all the reasons why LLM hallucinate"<br/><br/>context = (<br/>    "LLM hallucination refers to the phenomenon where large language models generate plausible-sounding but"<br/>    " factually incorrect or nonsensical information. This can occur due to various factors, including biases"<br/>    " in the training data, the inherent limitations of the model's understanding of the real world, and the "<br/>    "model's tendency to prioritize fluency and coherence over accuracy."<br/>)<br/><br/>messages = (<br/>    [context]<br/>    + [<br/>        f"Answer this question: {question}",<br/>    ]<br/>    + [<br/>        f"Use this schema for your answer: {answer_schema}",<br/>    ]<br/>)<br/><br/>response = model.generate_content(<br/>    messages,<br/>    generation_config={<br/>        "response_mime_type": "application/json",<br/>        "response_schema": answer_schema,<br/>        "temperature": 0.0,<br/>    },<br/>)<br/><br/>response = Answer(**json.loads(response.text))<br/><br/>print(f"{response.answer=}")</span></pre><p id="8c66" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Where “prepare_schema_for_gemini” is a utility function that prepares the schema to match Gemini’s weird requirements. You can find its definition here: <a class="af nc" href="https://github.com/CVxTz/document_ai_agents/blob/498d8ee6e8597f8ba43b336c64178d186461dba0/document_ai_agents/schema_utils.py#L38" rel="noopener ugc nofollow" target="_blank">code</a>.</p><p id="02a1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This code defines a Pydantic schema and sends this schema as part of the query in the field “response_schema”. This forces the LLM to follow this schema in its response and makes it easier to parse its output.</p><h2 id="1c8b" class="oh oi fq bf oj ok ol om on oo op oq or nm os ot ou nq ov ow ox nu oy oz pa pb bk">Tip 3: Use chain of thoughts and better prompting</h2><p id="af11" class="pw-post-body-paragraph nd ne fq nf b go pc nh ni gr pd nk nl nm pe no np nq pf ns nt nu pg nw nx ny fj bk">Sometimes, giving the LLM the space to work out its response, before committing to a final answer, can help produce better quality responses. This technique is called Chain-of-thoughts and is widely used as it is effective and very easy to implement.</p><p id="2770" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We can also explicitly ask the LLM to answer with “N/A” if it can’t find enough context to produce a quality response. This will give it an easy way out instead of trying to respond to questions it has no answer to.</p><p id="5280" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For example, lets look into this simple question and context:</p><p id="0d91" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Context</strong></p><blockquote class="qs qt qu"><p id="e2fb" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Thomas Jefferson (April 13 [O.S. April 2], 1743 — July 4, 1826) was an American statesman, planter, diplomat, lawyer, architect, philosopher, and Founding Father who served as the third president of the United States from 1801 to 1809.[6] He was the primary author of the Declaration of Independence. Following the American Revolutionary War and before becoming president in 1801, Jefferson was the nation’s first U.S. secretary of state under George Washington and then the nation’s second vice president under John Adams. Jefferson was a leading proponent of democracy, republicanism, and natural rights, and he produced formative documents and decisions at the state, national, and international levels. (Source: Wikipedia)</p></blockquote><p id="0a4a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Question</strong></p><blockquote class="qs qt qu"><p id="bf24" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">What year did davis jefferson die?</p></blockquote><p id="5747" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A naive approach yields:</p><p id="8a7b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Response</strong></p><blockquote class="qs qt qu"><p id="8bf3" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">answer=’1826'</p></blockquote><p id="51f8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Which is obviously false as Jefferson Davis is not even mentioned in the context at all. It was Thomas Jefferson that died in 1826.</p><p id="b7a1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If we change the schema of the response to use chain-of-thoughts to:</p><pre class="mm mn mo mp mq qj qk ql bp qm bb bk"><span id="630c" class="qn oi fq qk b bg qo qp l qq qr">class AnswerChainOfThoughts(BaseModel):<br/>    rationale: str = Field(<br/>        ...,<br/>        description="Justification of your answer.",<br/>    )<br/>    answer: str = Field(<br/>        ..., description="Your Answer. Answer with 'N/A' if answer is not found"<br/>    )</span></pre><p id="6351" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We are also adding more details about what we expect as output when the question is not answerable using the context “Answer with ‘N/A’ if answer is not found”</p><p id="9ef9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">With this new approach, we get the following <strong class="nf fr">rationale</strong> (remember, chain-of-thought):</p><blockquote class="qs qt qu"><p id="4c4d" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The provided text discusses Thomas Jefferson, not Jefferson Davis. No information about the death of Jefferson Davis is included.</p></blockquote><p id="0221" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And the final <strong class="nf fr">answer</strong>:</p><blockquote class="qs qt qu"><p id="4369" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">answer=’N/A’</p></blockquote><p id="d6ab" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Great ! But can we use a more general approach to hallucination detection?</p><p id="00b5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We can, with Agents!</p><h2 id="ab19" class="oh oi fq bf oj ok ol om on oo op oq or nm os ot ou nq ov ow ox nu oy oz pa pb bk">Tip 4: Use an Agentic approach</h2><p id="a87e" class="pw-post-body-paragraph nd ne fq nf b go pc nh ni gr pd nk nl nm pe no np nq pf ns nt nu pg nw nx ny fj bk">We will build a simple agent that implements a three-step process:</p><ul class=""><li id="100c" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob bk">The first step is to include the context and ask the question to the LLM in order to get the first candidate response and the relevant context that it had used for its answer.</li><li id="7bd3" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">The second step is to reformulate the question and the first candidate response as a declarative statement.</li><li id="3214" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny nz oa ob bk">The third step is to ask the LLM to verify whether or not the relevant context <strong class="nf fr">entails</strong> the candidate response. It is called “Self-verification”: <a class="af nc" href="https://arxiv.org/pdf/2212.09561" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2212.09561</a></li></ul><p id="f95f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In order to implement this, we define three nodes in LangGraph. The first node will ask the question while including the context, the second node will reformulate it using the LLM and the third node will check the entailment of the statement in relation to the input context.</p><p id="c4f5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The first node can be defined as follows:</p><pre class="mm mn mo mp mq qj qk ql bp qm bb bk"><span id="8828" class="qn oi fq qk b bg qo qp l qq qr">    def answer_question(self, state: DocumentQAState):<br/>        logger.info(f"Responding to question '{state.question}'")<br/>        assert (<br/>            state.pages_as_base64_jpeg_images or state.pages_as_text<br/>        ), "Input text or images"<br/>        messages = (<br/>            [<br/>                {"mime_type": "image/jpeg", "data": base64_jpeg}<br/>                for base64_jpeg in state.pages_as_base64_jpeg_images<br/>            ]<br/>            + state.pages_as_text<br/>            + [<br/>                f"Answer this question: {state.question}",<br/>            ]<br/>            + [<br/>                f"Use this schema for your answer: {self.answer_cot_schema}",<br/>            ]<br/>        )<br/><br/>        response = self.model.generate_content(<br/>            messages,<br/>            generation_config={<br/>                "response_mime_type": "application/json",<br/>                "response_schema": self.answer_cot_schema,<br/>                "temperature": 0.0,<br/>            },<br/>        )<br/><br/>        answer_cot = AnswerChainOfThoughts(**json.loads(response.text))<br/><br/>        return {"answer_cot": answer_cot}</span></pre><p id="11a5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And the second one as:</p><pre class="mm mn mo mp mq qj qk ql bp qm bb bk"><span id="2682" class="qn oi fq qk b bg qo qp l qq qr">    def reformulate_answer(self, state: DocumentQAState):<br/>        logger.info("Reformulating answer")<br/>        if state.answer_cot.answer == "N/A":<br/>            return<br/><br/>        messages = [<br/>            {<br/>                "role": "user",<br/>                "parts": [<br/>                    {<br/>                        "text": "Reformulate this question and its answer as a single assertion."<br/>                    },<br/>                    {"text": f"Question: {state.question}"},<br/>                    {"text": f"Answer: {state.answer_cot.answer}"},<br/>                ]<br/>                + [<br/>                    {<br/>                        "text": f"Use this schema for your answer: {self.declarative_answer_schema}"<br/>                    }<br/>                ],<br/>            }<br/>        ]<br/><br/>        response = self.model.generate_content(<br/>            messages,<br/>            generation_config={<br/>                "response_mime_type": "application/json",<br/>                "response_schema": self.declarative_answer_schema,<br/>                "temperature": 0.0,<br/>            },<br/>        )<br/><br/>        answer_reformulation = AnswerReformulation(**json.loads(response.text))<br/><br/>        return {"answer_reformulation": answer_reformulation}</span></pre><p id="35ed" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The third one as:</p><pre class="mm mn mo mp mq qj qk ql bp qm bb bk"><span id="ef72" class="qn oi fq qk b bg qo qp l qq qr">    def verify_answer(self, state: DocumentQAState):<br/>        logger.info(f"Verifying answer '{state.answer_cot.answer}'")<br/>        if state.answer_cot.answer == "N/A":<br/>            return<br/>        messages = [<br/>            {<br/>                "role": "user",<br/>                "parts": [<br/>                    {<br/>                        "text": "Analyse the following context and the assertion and decide whether the context "<br/>                        "entails the assertion or not."<br/>                    },<br/>                    {"text": f"Context: {state.answer_cot.relevant_context}"},<br/>                    {<br/>                        "text": f"Assertion: {state.answer_reformulation.declarative_answer}"<br/>                    },<br/>                    {<br/>                        "text": f"Use this schema for your answer: {self.verification_cot_schema}. Be Factual."<br/>                    },<br/>                ],<br/>            }<br/>        ]<br/>    <br/>        response = self.model.generate_content(<br/>            messages,<br/>            generation_config={<br/>                "response_mime_type": "application/json",<br/>                "response_schema": self.verification_cot_schema,<br/>                "temperature": 0.0,<br/>            },<br/>        )<br/>    <br/>        verification_cot = VerificationChainOfThoughts(**json.loads(response.text))<br/>    <br/>        return {"verification_cot": verification_cot}</span></pre><p id="7705" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Full code in <a class="af nc" href="https://github.com/CVxTz/document_ai_agents" rel="noopener ugc nofollow" target="_blank">https://github.com/CVxTz/document_ai_agents</a></p><p id="9b9a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Notice how each node uses its own schema for structured output and its own prompt. This is possible due to the flexibility of both Gemini’s API and LangGraph.</p><p id="f67c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Lets work through this code using the same example as above ➡️<br/><em class="qv">(Note: we are not using chain-of-thought on the first prompt so that the verification gets triggered for our tests.)</em></p><p id="3a10" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Context</strong></p><blockquote class="qs qt qu"><p id="9ff0" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Thomas Jefferson (April 13 [O.S. April 2], 1743 — July 4, 1826) was an American statesman, planter, diplomat, lawyer, architect, philosopher, and Founding Father who served as the third president of the United States from 1801 to 1809.[6] He was the primary author of the Declaration of Independence. Following the American Revolutionary War and before becoming president in 1801, Jefferson was the nation’s first U.S. secretary of state under George Washington and then the nation’s second vice president under John Adams. Jefferson was a leading proponent of democracy, republicanism, and natural rights, and he produced formative documents and decisions at the state, national, and international levels. (Source: Wikipedia)</p></blockquote><p id="3f78" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Question</strong></p><blockquote class="qs qt qu"><p id="9524" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">What year did davis jefferson die?</p></blockquote><p id="76e4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">First node result (First answer):</strong></p><blockquote class="qs qt qu"><p id="6e81" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">relevant_context</strong>=’Thomas Jefferson (April 13 [O.S. April 2], 1743 — July 4, 1826) was an American statesman, planter, diplomat, lawyer, architect, philosopher, and Founding Father who served as the third president of the United States from 1801 to 1809.’</p><p id="4e01" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">answer=’1826'</strong></p></blockquote><p id="89b9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Second node result (Answer Reformulation):</strong></p><blockquote class="qs qt qu"><p id="0761" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">declarative_answer</strong>=’Davis Jefferson died in 1826'</p></blockquote><p id="06cd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Third node result (Verification):</strong></p><blockquote class="qs qt qu"><p id="9f9c" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">rationale</strong>=’The context states that Thomas Jefferson died in 1826. The assertion states that Davis Jefferson died in 1826. The context does not mention Davis Jefferson, only Thomas Jefferson.’</p><p id="ec63" class="nd ne qv nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">entailment</strong>=’No’</p></blockquote><p id="b0c4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">So the verification step <strong class="nf fr">rejected</strong> (<em class="qv">No entailment between the two</em>) the initial answer. We can now avoid returning a hallucination to the user.</p><h2 id="a393" class="oh oi fq bf oj ok ol om on oo op oq or nm os ot ou nq ov ow ox nu oy oz pa pb bk">Bonus Tip : Use stronger models</h2><p id="e14d" class="pw-post-body-paragraph nd ne fq nf b go pc nh ni gr pd nk nl nm pe no np nq pf ns nt nu pg nw nx ny fj bk">This tip is not always easy to apply due to budget or latency limitations but you should know that stronger LLMs are less prone to hallucination. So, if possible, go for a more powerful LLM for your most sensitive use cases. You can check a benchmark of hallucinations here: <a class="af nc" href="https://github.com/vectara/hallucination-leaderboard" rel="noopener ugc nofollow" target="_blank">https://github.com/vectara/hallucination-leaderboard</a>. We can see that the top models in this benchmark (least hallucinations) also ranks at the top of conventional NLP leader boards.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/28143041199f3dd4c5130c62985a0f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0lHK7eiqTV6ESKQQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Source: <a class="af nc" href="https://github.com/vectara/hallucination-leaderboard" rel="noopener ugc nofollow" target="_blank">https://github.com/vectara/hallucination-leaderboard</a> Source License: Apache 2.0</figcaption></figure><h1 id="815d" class="qx oi fq bf oj qy qz gq on ra rb gt or rc rd re rf rg rh ri rj rk rl rm rn ro bk">Conclusion</h1><p id="5f1c" class="pw-post-body-paragraph nd ne fq nf b go pc nh ni gr pd nk nl nm pe no np nq pf ns nt nu pg nw nx ny fj bk">In this tutorial, we explored strategies to improve the reliability of LLM outputs by reducing the hallucination rate. The main recommendations include careful formatting and prompting to guide LLM calls and using a workflow based approach where Agents are designed to verify their own answers.</p><p id="801b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This involves multiple steps:</p><ol class=""><li id="2c90" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny rp oa ob bk">Retrieving the exact context elements used by the LLM to generate the answer.</li><li id="72ba" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny rp oa ob bk">Reformulating the answer for easier verification (In declarative form).</li><li id="a5fb" class="nd ne fq nf b go oc nh ni gr od nk nl nm oe no np nq of ns nt nu og nw nx ny rp oa ob bk">Instructing the LLM to check for consistency between the context and the reformulated answer.</li></ol><p id="fcbb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">While all these tips can significantly improve accuracy, you should remember that no method is foolproof. There’s always a risk of rejecting valid answers if the LLM is overly conservative during verification or missing real hallucination cases. Therefore, rigorous evaluation of your specific LLM workflows is still essential.</p><p id="a15f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Full code in <a class="af nc" href="https://github.com/CVxTz/document_ai_agents" rel="noopener ugc nofollow" target="_blank">https://github.com/CVxTz/document_ai_agents</a></p><h2 id="e5d5" class="oh oi fq bf oj ok ol om on oo op oq or nm os ot ou nq ov ow ox nu oy oz pa pb bk">Thank you for reading !</h2></div></div></div></div>    
</body>
</html>