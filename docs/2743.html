<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Calibrating Marketing Mix Models In Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Calibrating Marketing Mix Models In Python</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/calibrating-marketing-mix-models-in-python-49dce1a5b33d?source=collection_archive---------3-----------------------#2024-11-11">https://towardsdatascience.com/calibrating-marketing-mix-models-in-python-49dce1a5b33d?source=collection_archive---------3-----------------------#2024-11-11</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="9b35" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Part 2 of a hands-on guide to help you master MMM in pymc</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@raz1470?source=post_page---byline--49dce1a5b33d--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ryan O'Sullivan" class="l ep by dd de cx" src="../Images/7cd161d38d67d2c0b7da2d8f3e7d33fe.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*tAw1S072P0f0sUswKPN6VQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--49dce1a5b33d--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@raz1470?source=post_page---byline--49dce1a5b33d--------------------------------" rel="noopener follow">Ryan O'Sullivan</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--49dce1a5b33d--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 11, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/a0f58172d399a875389bad12c2003712.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P-Garsf2GYB6Iod2uXNNOQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image</figcaption></figure><h1 id="981f" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">What is this series about?</h1><p id="3391" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Welcome to part 2 of my series on marketing mix modeling (MMM), a hands-on guide to help you master MMM. Throughout this series, we’ll cover key topics such as model training, validation, calibration and budget optimisation, all using the powerful <strong class="nz fr">pymc-marketing</strong> python package. Whether you’re new to MMM or looking to sharpen your skills, this series will equip you with practical tools and insights to improve your marketing strategies.</p><p id="2461" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">If you missed part 1 check it out here:</p><div class="oy oz pa pb pc pd"><a rel="noopener follow" target="_blank" href="/mastering-marketing-mix-modelling-in-python-7bbfe31360f9?source=post_page-----49dce1a5b33d--------------------------------"><div class="pe ab ig"><div class="pf ab co cb pg ph"><h2 class="bf fr hw z io pi iq ir pj it iv fp bk">Mastering Marketing Mix Modelling In Python</h2><div class="pk l"><h3 class="bf b hw z io pi iq ir pj it iv dx">Part 1 of a hands-on guide to help you master MMM in pymc</h3></div><div class="pl l"><p class="bf b dy z io pi iq ir pj it iv dx">towardsdatascience.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr lq pd"/></div></div></a></div><h1 id="5975" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Introduction</h1><p id="635e" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">In the second instalment of this series we will shift our focus to calibrating our models using informative priors from experiments:</p><ul class=""><li id="76ff" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk">Why is it important to calibrate marketing mix models?</li><li id="779f" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk">How can we use Bayesian priors to calibrate our model?</li><li id="c72b" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk">What experiments can we run to inform our Bayesian priors?</li></ul><p id="ccdc" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">We will then finish off with a walkthrough in Python using the <strong class="nz fr">pymc-marketing </strong>package to calibrate the model we built in the first article.</p><p id="72f0" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">The full notebook can be found here:</p><div class="oy oz pa pb pc pd"><a href="https://github.com/raz1470/pymc_marketing/blob/main/notebooks/2.%20calibrating%20marketing%20mix%20models%20%28MMM%29%20in%20python.ipynb?source=post_page-----49dce1a5b33d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab ig"><div class="pf ab co cb pg ph"><h2 class="bf fr hw z io pi iq ir pj it iv fp bk">pymc_marketing/notebooks/2. calibrating marketing mix models (MMM) in python.ipynb at main ·…</h2><div class="pk l"><h3 class="bf b hw z io pi iq ir pj it iv dx">A demo of the MMM package pymc_marketing. Contribute to raz1470/pymc_marketing development by creating an account on…</h3></div><div class="pl l"><p class="bf b dy z io pi iq ir pj it iv dx">github.com</p></div></div><div class="pm l"><div class="qa l po pp pq pm pr lq pd"/></div></div></a></div><h1 id="e18e" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">1.0 Calibrating marketing mix models</h1><p id="1032" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Marketing mix modelling (MMM) is a statistical technique used to estimate the impact of various marketing channels (such as TV, social media, paid search) on sales. The goal of MMM is to understand the return on investment (ROI) of each channel and optimise future marketing spend.</p><p id="0eae" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">There are several reasons why we need to calibrate our models. Before we get into the python walkthrough let’s explore them a bit!</p><h2 id="38c0" class="qb nc fq bf nd qc qd qe ng qf qg qh nj og qi qj qk ok ql qm qn oo qo qp qq qr bk">1. 1 Why is it important to calibrate marketing mix models?</h2><p id="648b" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Calibrating MMM is crucial because, while they provide valuable insights, they are often limited by several factors:</p><ul class=""><li id="e63d" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk"><strong class="nz fr">Multi-collinearity:</strong> This occurs when different marketing channels are highly correlated, making it difficult to distinguish their individual effects. For example, TV and social may run simultaneously, causing overlap in their impacts. Calibration helps untangle the effects of these channels by incorporating additional data or constraints.</li><li id="0485" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk"><strong class="nz fr">Unobserved confounders:</strong> MMM models rely on observed data, but they may miss important variables that also affect both marketing and sales, such as seasonality or changes in market demand. Calibration can help adjust for these unobserved confounders.</li></ul><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qs"><img src="../Images/68daffe027c9c869f3578b756419d9d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*woOymu4XMcNHnFmgxEbF4w.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image (excalidraw)</figcaption></figure><ul class=""><li id="3410" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk"><strong class="nz fr">Re-targeting bias:</strong> Have you ever visited a website for a product and then found that all of your social media platforms are now suddenly “coincidently” showing you ads for that product? This isn’t a coincidence, it’s what we call retargeting and it can be effective. However, a number of prospects who get retargeted and then go on to purchase would have anyway!</li></ul><p id="0d43" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Without proper calibration, these issues can lead to inaccurate estimates of marketing channel performance, resulting in poor decision-making on marketing spend and strategy.</p><h2 id="7162" class="qb nc fq bf nd qc qd qe ng qf qg qh nj og qi qj qk ok ql qm qn oo qo qp qq qr bk">1.2 How can we use Bayesian priors to calibrate our models?</h2><p id="f001" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">In the last article we talked about how Bayesian priors represent our initial beliefs about the parameters in the model, such as the effect of TV spend on sales. We also covered how the default parameters in <strong class="nz fr">pymc-marketing</strong> were sensible choices but weakly informative. Supplying informative priors based on experiments can help calibrate our models and deal with the issues raised in the last section.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qt"><img src="../Images/09be29c95962045bad0dd42d193c19b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-XV-9ApDIDWQ8q1Avjd-w.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image (excalidraw)</figcaption></figure><p id="ce9a" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">There are a couple of ways in which we can supply priors in <strong class="nz fr">pymc-marketing</strong>:</p><ul class=""><li id="0483" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk">Change the default saturation_beta priors directly like in the example below using a truncated normal distribution to enforce positive values:</li></ul><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="f3e8" class="qy nc fq qv b bg qz ra l rb rc">model_config = {<br/>    'intercept': Prior("Normal", mu=0, sigma=2),<br/>    'likelihood': Prior("Normal", sigma=Prior("HalfNormal", sigma=2)),<br/>    'gamma_control': Prior("Normal", mu=0, sigma=2, dims="control"),<br/>    'gamma_fourier': Prior("Laplace", mu=0, b=1, dims="fourier_mode"),<br/>    'adstock_alpha': Prior("Beta", alpha=1, beta=3, dims="channel"),<br/>    'saturation_lam': Prior("Gamma", alpha=3, beta=1, dims="channel"),<br/>    'saturation_beta': Prior("TruncatedNormal", mu=[0.02, 0.04, 0.01], lower=0, sigma=0.1, dims=("channel"))<br/>}<br/><br/>mmm_with_priors = MMM(<br/>    model_config=model_config,    <br/>    adstock=GeometricAdstock(l_max=8),<br/>    saturation=LogisticSaturation(),<br/>    date_column=date_col,<br/>    channel_columns=channel_cols,<br/>    control_columns=control_cols,<br/>)</span></pre><ul class=""><li id="c04d" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk">Use the add_lift_test_measurements method, which adds a new likelihood term to the model which helps calibrate the saturation curve (don’t worry, we will cover this in more detail in the python walkthrough):</li></ul><div class="oy oz pa pb pc pd"><a href="https://www.pymc-marketing.io/en/stable/api/generated/pymc_marketing.mmm.lift_test.html?source=post_page-----49dce1a5b33d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab ig"><div class="pf ab co cb pg ph"><h2 class="bf fr hw z io pi iq ir pj it iv fp bk">lift_test - Open Source Marketing Analytics Solution</h2><div class="pk l"><h3 class="bf b hw z io pi iq ir pj it iv dx">Adding lift tests as observations of saturation function. This provides the inner workings of…</h3></div><div class="pl l"><p class="bf b dy z io pi iq ir pj it iv dx">www.pymc-marketing.io</p></div></div></div></a></div><p id="fffa" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">What if you aren’t comfortable with Bayesian analysis? Your alternative is running a constrained regression using a package like cvxpy. Below is an example of how you can do that using upper and lower bounds for the coefficients of variables:</p><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="22d7" class="qy nc fq qv b bg qz ra l rb rc">import cvxpy as cp<br/><br/>def train_model(X, y, reg_alpha, lower_bounds, upper_bounds):<br/>    """<br/>    Trains a linear regression model with L2 regularization (ridge regression) and bounded constraints on coefficients.<br/><br/>    Parameters:<br/>    -----------<br/>    X : numpy.ndarray or similar<br/>        Feature matrix where each row represents an observation and each column a feature.<br/>    y : numpy.ndarray or similar<br/>        Target vector for regression.<br/>    reg_alpha : float<br/>        Regularization strength for the ridge penalty term. Higher values enforce more penalty on large coefficients.<br/>    lower_bounds : list of floats or None<br/>        Lower bounds for each coefficient in the model. If a coefficient has no lower bound, specify as None.<br/>    upper_bounds : list of floats or None<br/>        Upper bounds for each coefficient in the model. If a coefficient has no upper bound, specify as None.<br/><br/>    Returns:<br/>    --------<br/>    numpy.ndarray<br/>        Array of fitted coefficients for the regression model.<br/><br/>    Example:<br/>    --------<br/>    &gt;&gt;&gt; coef = train_model(X, y, reg_alpha=1.0, lower_bounds=[0.2, 0.4], upper_bounds=[0.5, 1.0])<br/>    <br/>    """<br/><br/>    coef = cp.Variable(X.shape[1])<br/>    ridge_penalty = cp.norm(coef, 2)<br/>    objective = cp.Minimize(cp.sum_squares(X @ coef - y) + reg_alpha * ridge_penalty)<br/>    <br/>    # Create constraints based on provided bounds<br/>    constraints = (<br/>        [coef[i] &gt;= lower_bounds[i] for i in range(X.shape[1]) if lower_bounds[i] is not None] +<br/>        [coef[i] &lt;= upper_bounds[i] for i in range(X.shape[1]) if upper_bounds[i] is not None]<br/>    )<br/><br/>    # Define and solve the problem<br/>    problem = cp.Problem(objective, constraints)<br/>    problem.solve()<br/>    <br/>    # Print the optimization status<br/>    print(problem.status)<br/>    <br/>    return coef.value</span></pre><h2 id="bc09" class="qb nc fq bf nd qc qd qe ng qf qg qh nj og qi qj qk ok ql qm qn oo qo qp qq qr bk">1.3 What experiments can we run to inform our Bayesian priors?</h2><p id="cab8" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Experiments can provide strong evidence to inform the priors used in MMM. Some common experiments include:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rd"><img src="../Images/d28e5030229ad7f14f05a6b055c9363d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6n0_krejGAbY7t3jrPyydw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image (excalidraw)</figcaption></figure><ul class=""><li id="b90f" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk"><strong class="nz fr">Conversion lift tests — </strong>These tests are often run on platforms like Facebook, YouTube, Snapchat, TikTok and DV360, where users are randomly split into a test and control group. The test group is exposed to the marketing campaign, while the control group is not. The difference in conversion rates between the two groups informs the actual lift attributable to the channel.</li><li id="e2f2" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk"><strong class="nz fr">Geo-lift tests — </strong>In a geo-lift test, marketing efforts are turned off in certain geographic regions while continuing in others. By comparing the performance in test and control regions, you can measure the incremental impact of marketing in each region. The CausalPy python package has an easy to use implementation which is worth checking out:</li></ul><div class="oy oz pa pb pc pd"><a href="https://causalpy.readthedocs.io/en/stable/notebooks/geolift1.html?source=post_page-----49dce1a5b33d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab ig"><div class="pf ab co cb pg ph"><h2 class="bf fr hw z io pi iq ir pj it iv fp bk">Bayesian geolift with CausalPy - CausalPy 0.4.0 documentation</h2><div class="pk l"><h3 class="bf b hw z io pi iq ir pj it iv dx">This notebook covers how to use 's Bayesian synthetic control functionality to assess 'geolift'. Our hypothetical…</h3></div><div class="pl l"><p class="bf b dy z io pi iq ir pj it iv dx">causalpy.readthedocs.io</p></div></div><div class="pm l"><div class="re l po pp pq pm pr lq pd"/></div></div></a></div><ul class=""><li id="7228" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk"><strong class="nz fr">Switch-back testing — </strong>This method involves quickly switching marketing campaigns on and off over short intervals to observe changes in consumer behavior. It’s most applicable to channels with an immediate impact, like paid search.</li></ul><p id="6662" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">By using these experiments, you can gather strong empirical data to inform your Bayesian priors and further improve the accuracy and calibration of your Marketing Mix Model.</p><h1 id="9322" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">2.0 Python walkthrough</h1><p id="a350" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Now we understand why we need to calibrate our models, let’s calibrate our model from the first article! In this walkthrough we will cover:</p><ul class=""><li id="ffae" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk">Simulating data</li><li id="e436" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk">Simulating experimental results</li><li id="117b" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk">Pre-processing the experimental results</li><li id="1a78" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk">Calibrating the model</li><li id="166a" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk">Validating the model</li></ul><h2 id="f6cc" class="qb nc fq bf nd qc qd qe ng qf qg qh nj og qi qj qk ok ql qm qn oo qo qp qq qr bk">2.1 Simulating data</h2><p id="6ffc" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">We are going to start by simulating the data used in the first article. If you want to understand more about the data-generating-process take a look at the first article where we did a detailed walkthrough:</p><div class="oy oz pa pb pc pd"><a rel="noopener follow" target="_blank" href="/mastering-marketing-mix-modelling-in-python-7bbfe31360f9?source=post_page-----49dce1a5b33d--------------------------------"><div class="pe ab ig"><div class="pf ab co cb pg ph"><h2 class="bf fr hw z io pi iq ir pj it iv fp bk">Mastering Marketing Mix Modelling In Python</h2><div class="pk l"><h3 class="bf b hw z io pi iq ir pj it iv dx">Part 1 of a hands-on guide to help you master MMM in pymc</h3></div><div class="pl l"><p class="bf b dy z io pi iq ir pj it iv dx">towardsdatascience.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr lq pd"/></div></div></a></div><p id="89de" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">When we trained the model in the first article, the contribution of TV, social, and search were all overestimated. This appeared to be driven by the demand proxy not contributing as much as true demand. So let’s pick up where we left off and think about running an experiment to deal with this!</p><h2 id="241a" class="qb nc fq bf nd qc qd qe ng qf qg qh nj og qi qj qk ok ql qm qn oo qo qp qq qr bk">2.2 Simulating experimental results</h2><p id="82c0" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">To simulate some experimental results, we write a function which takes in the known parameters for a channel and outputs the true contribution for the channel. Remember, in reality we would not know these parameters, but this exercise will help us understand and test out the calibration method from <strong class="nz fr">pymc-marketing</strong>.</p><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="ca30" class="qy nc fq qv b bg qz ra l rb rc">def exp_generator(start_date, periods, channel, adstock_alpha, saturation_lamda, beta, weekly_spend, max_abs_spend, freq="W"):<br/>    """<br/>    Generate a time series of experiment results, incorporating adstock and saturation effects.<br/><br/>    Parameters:<br/>    ----------<br/>    start_date : str or datetime<br/>        The start date for the time series.<br/>    periods : int<br/>        The number of time periods (e.g. weeks) to generate in the time series.<br/>    channel : str<br/>        The name of the marketing channel.<br/>    adstock_alpha : float<br/>        The adstock decay rate, between 0 and 1..<br/>    saturation_lamda : float<br/>        The parameter for logistic saturation.<br/>    beta : float<br/>        The beta coefficient.<br/>    weekly_spend : float<br/>        The weekly raw spend amount for the channel.<br/>    max_abs_spend : float<br/>        The maximum absolute spend value for scaling the spend data, allowing the series to normalize between 0 and 1.<br/>    freq : str, optional<br/>        The frequency of the time series, default is 'W' for weekly. Follows pandas offset aliases<br/>    Returns:<br/>    -------<br/>    df_exp : pd.DataFrame<br/>        A DataFrame containing the generated time series with the following columns:<br/>        - date : The date for each time period in the series.<br/>        - {channel}_spend_raw : The unscaled, raw weekly spend for the channel.<br/>        - {channel}_spend : The scaled channel spend, normalized by `max_abs_spend`.<br/>        - {channel}_adstock : The adstock-transformed spend, incorporating decay over time based on `adstock_alpha`.<br/>        - {channel}_saturated : The adstock-transformed spend after applying logistic saturation based on `saturation_lamda`.<br/>        - {channel}_sales : The final sales contribution calculated as the saturated spend times `beta`.<br/><br/>    Example:<br/>    --------<br/>    &gt;&gt;&gt; df = exp_generator(<br/>    ...     start_date="2023-01-01",<br/>    ...     periods=52,<br/>    ...     channel="TV",<br/>    ...     adstock_alpha=0.7,<br/>    ...     saturation_lamda=1.5,<br/>    ...     beta=0.03,<br/>    ...     weekly_spend=50000,<br/>    ...     max_abs_spend=1000000<br/>    ... )<br/><br/>    """<br/>    # 0. Create time dimension<br/>    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)<br/>    df_exp = pd.DataFrame({'date': date_range})<br/><br/>    # 1. Create raw channel spend<br/>    df_exp[f"{channel}_spend_raw"] = weekly_spend<br/><br/>    # 2. Scale channel spend<br/>    df_exp[f"{channel}_spend"] = df_exp[f"{channel}_spend_raw"] / max_abs_spend<br/><br/>    # 3. Apply adstock transformation<br/>    df_exp[f"{channel}_adstock"] = geometric_adstock(<br/>        x=df_exp[f"{channel}_spend"].to_numpy(),<br/>        alpha=adstock_alpha,<br/>        l_max=8, normalize=True<br/>    ).eval().flatten()<br/><br/>    # 4. Apply saturation transformation<br/>    df_exp[f"{channel}_saturated"] = logistic_saturation(<br/>        x=df_exp[f"{channel}_adstock"].to_numpy(),<br/>        lam=saturation_lamda<br/>    ).eval()<br/><br/>    # 5. Calculate contribution to sales<br/>    df_exp[f"{channel}_sales"] = df_exp[f"{channel}_saturated"] * beta<br/>    <br/>    return df_exp</span></pre><p id="aadf" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Below we use the function to create results for an 8 week lift test on TV:</p><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="48eb" class="qy nc fq qv b bg qz ra l rb rc"># Set parameters for experiment generator<br/>start_date = "2024-10-01"<br/>periods = 8<br/>channel = "tv"<br/>adstock_alpha = adstock_alphas[0]<br/>saturation_lamda = saturation_lamdas[0]<br/>beta = betas[0]<br/>weekly_spend = df["tv_spend_raw"].mean()<br/>max_abs_spend = df["tv_spend_raw"].max()<br/><br/>df_exp_tv = exp_generator(start_date, periods, channel, adstock_alpha, saturation_lamda, beta, weekly_spend, max_abs_spend)<br/><br/>df_exp_tv</span></pre><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rf"><img src="../Images/82ca31f7bb5e906574175cff8124b1c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7t9eJmAZtHlpCZ7poIMszA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image</figcaption></figure><p id="1aa1" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Even though we spend the same amount on TV each week, the contribution of TV varies each week. This is driven by the adstock effect and our best option here is to take the average weekly contribution.</p><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="debf" class="qy nc fq qv b bg qz ra l rb rc">weekly_sales = df_exp_tv["tv_sales"].mean()<br/><br/>weekly_sales</span></pre><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj rg"><img src="../Images/b87fa975b77daba3d51a287bcb99f5a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*QSBSBfZWW5zZYsyQPushxg.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image</figcaption></figure><h2 id="32ff" class="qb nc fq bf nd qc qd qe ng qf qg qh nj og qi qj qk ok ql qm qn oo qo qp qq qr bk">2.3 Pre-processing the experimental results</h2><p id="3237" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Now we have collected the experimental results, we need to pre-process them to get them into the required format to add to our model. We will need to supply the model a dataframe with 1 row per experiment in the following format:</p><ul class=""><li id="15e7" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk"><code class="cx rh ri rj qv b">channel</code>: The channel that was tested</li><li id="323c" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk"><code class="cx rh ri rj qv b">x</code>: Pre-test channel spend</li><li id="6997" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk"><code class="cx rh ri rj qv b">delta_x</code>: Change made to <code class="cx rh ri rj qv b">x</code></li><li id="78c3" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk"><code class="cx rh ri rj qv b">delta_y</code>: Inferred change in sales due to <code class="cx rh ri rj qv b">delta_x</code></li><li id="9dba" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk"><code class="cx rh ri rj qv b">sigma</code>: Standard deviation of <code class="cx rh ri rj qv b">delta_y</code></li></ul><p id="25e0" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">We didn’t simulate experimental results with a measure of uncertainty, so to keep things simple we set sigma as 5% of lift.</p><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="1a06" class="qy nc fq qv b bg qz ra l rb rc">df_lift_test = pd.DataFrame({<br/>    "channel": ["tv_spend_raw"],<br/>    "x": [0],<br/>    "delta_x": weekly_spend,<br/>    "delta_y": weekly_sales,<br/>    "sigma": [weekly_sales * 0.05],<br/>    }<br/>)<br/><br/>df_lift_test</span></pre><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rk"><img src="../Images/31c7f7ff61f7e48e2004d04e86bcda7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G7I8qPWr15LMBBxYEafFwg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image</figcaption></figure><p id="9acb" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">In terms of sigma, ideally you would have a measure of uncertainty for your results (which you could get from most conversion lift or geo-lift tests).</p><h2 id="4c31" class="qb nc fq bf nd qc qd qe ng qf qg qh nj og qi qj qk ok ql qm qn oo qo qp qq qr bk">2.4 Calibrating the model</h2><p id="8b22" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">We are now going to re-train the model from the first article. We will prepare the training data in the same way as last time by:</p><ul class=""><li id="3771" class="nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os ps pt pu bk">Splitting data into features and target.</li><li id="7fdc" class="nx ny fq nz b go pv ob oc gr pw oe of og px oi oj ok py om on oo pz oq or os ps pt pu bk">Creating indices for train and out-of-time slices — The out-of-time slice will help us validate our model.</li></ul><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="b5b6" class="qy nc fq qv b bg qz ra l rb rc"># set date column<br/>date_col = "date"<br/><br/># set outcome column<br/>y_col = "sales"<br/><br/># set marketing variables<br/>channel_cols = ["tv_spend_raw",<br/>                "social_spend_raw",<br/>                "search_spend_raw"]<br/><br/># set control variables<br/>control_cols = ["demand_proxy"]<br/><br/># create arrays<br/>X = df[[date_col] + channel_cols + control_cols]<br/>y = df[y_col]<br/><br/># set test (out-of-sample) length<br/>test_len = 8<br/><br/># create train and test indexs<br/>train_idx = slice(0, len(df) - test_len)<br/>out_of_time_idx = slice(len(df) - test_len, len(df))</span></pre><p id="8951" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Then we load the model which we saved from the first article and re-train the model after adding the experimental results:</p><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="aee2" class="qy nc fq qv b bg qz ra l rb rc">mmm_default = MMM.load("./mmm_default.nc")<br/>mmm_default.add_lift_test_measurements(df_lift_test)<br/>mmm_default.fit(X[train_idx], y[train_idx])</span></pre><p id="14e7" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">We won’t focus on the model diagnostics this time round, but you can check out the notebook if you would like to go through it.</p><h2 id="14ac" class="qb nc fq bf nd qc qd qe ng qf qg qh nj og qi qj qk ok ql qm qn oo qo qp qq qr bk">2.5 Validating the model</h2><p id="c7ad" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">So let’s assess how our new model compares to the true contributions now. Below we inspect the true contributions:</p><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="7e2a" class="qy nc fq qv b bg qz ra l rb rc">channels = np.array(["tv", "social", "search", "demand"])<br/><br/>true_contributions = pd.DataFrame({'Channels': channels, 'Contributions': contributions})<br/>true_contributions= true_contributions.sort_values(by='Contributions', ascending=False).reset_index(drop=True)<br/>true_contributions = true_contributions.style.bar(subset=['Contributions'], color='lightblue')<br/><br/>true_contributions</span></pre><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj rl"><img src="../Images/775f5cc4b1d5e6bd935488919049ea2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*YKRs2k89kPGQT8zfjCYYKA.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image</figcaption></figure><p id="5190" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">When we compare the true contributions to our new model, we see that the contribution of TV is now very close (and much closer than the model from our first article where the contribution was 24%!).</p><pre class="ml mm mn mo mp qu qv qw bp qx bb bk"><span id="2f05" class="qy nc fq qv b bg qz ra l rb rc">mmm_default.plot_waterfall_components_decomposition(figsize=(10,6));</span></pre><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rm"><img src="../Images/2b659394dc0db5dcd50d4458f33da52e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3gQZEyVSXZfsOZhB2sVScQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">User generated image</figcaption></figure><p id="df63" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">The contribution for search and social is still overestimated, but we could also run experiments here to deal with this.</p><h1 id="258b" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Closing thoughts</h1><p id="b0d1" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Today we showed you how we can incorporate priors using experimental results. The <strong class="nz fr">pymc-marketing</strong> package makes things easy for the analyst running the model. If you want to go a little deeper into the working, checkout their tutorial:</p><div class="oy oz pa pb pc pd"><a href="https://www.pymc-marketing.io/en/stable/notebooks/mmm/mmm_lift_test.html?source=post_page-----49dce1a5b33d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab ig"><div class="pf ab co cb pg ph"><h2 class="bf fr hw z io pi iq ir pj it iv fp bk">Lift Test Calibration - Open Source Marketing Analytics Solution</h2><div class="pk l"><h3 class="bf b hw z io pi iq ir pj it iv dx">You may have heard of the phrase " All models are wrong but some are useful. " This is true in many areas, and it's…</h3></div><div class="pl l"><p class="bf b dy z io pi iq ir pj it iv dx">www.pymc-marketing.io</p></div></div><div class="pm l"><div class="rn l po pp pq pm pr lq pd"/></div></div></a></div><p id="5fc3" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">However, don’t be fooled….There are still some major challenges on your road to a well calibrated model!</p><p id="f74c" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Logistical challenges in terms of constraints around how many geographic regions vs channels you have or struggling to get buy-in for experiments from the marketing team are just a couple of those challenges.</p><p id="9473" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">One thing worth considering is running one complete blackout on marketing and using the results as priors to inform demand/base sales. This helps with the logistical challenge and also improves the power of your experiment (as the effect size increases).</p></div></div></div><div class="ab cb ro rp rq rr" role="separator"><span class="rs by bm rt ru rv"/><span class="rs by bm rt ru rv"/><span class="rs by bm rt ru"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="ad99" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">I hope you enjoyed the second instalment! Follow me if you want to continue this path towards mastering MMM— In the next article we will start to think about how we can optimise marketing budgets!</p></div></div></div></div>    
</body>
</html>