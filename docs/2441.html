<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Supercharge Your LLM Apps Using DSPy and Langfuse</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Supercharge Your LLM Apps Using DSPy and Langfuse</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/supercharge-your-llm-apps-using-dspy-and-langfuse-f83c02ba96a1?source=collection_archive---------2-----------------------#2024-10-07">https://towardsdatascience.com/supercharge-your-llm-apps-using-dspy-and-langfuse-f83c02ba96a1?source=collection_archive---------2-----------------------#2024-10-07</a></blockquote><div><div class="em ff fg fh fi fj"/><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><div/><div><h2 id="ca45" class="pw-subtitle-paragraph go fq fr bf b gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd cq dx">Build Production Grade LLM Apps with Ease</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Raghav Bali" class="l ep by dd de cx" src="../Images/49fea68f38f59d0bc39dab484b55684f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*6nRZK0-KCmkqu5I3auzK3w.png"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------" rel="noopener follow">Raghav Bali</a></p></div></div></div><div class="ia ib l"><div class="ab ic"><div class="ab"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewbox="0 0 16 16"><path fill="#437AFF" d="M15.163 8c0 .65-.459 1.144-.863 1.575-.232.244-.471.5-.563.719s-.086.543-.092.875c-.006.606-.018 1.3-.49 1.781-.47.481-1.15.494-1.744.5-.324.006-.655.013-.857.094s-.465.337-.704.575c-.422.412-.906.881-1.542.881-.637 0-1.12-.469-1.543-.881-.239-.238-.49-.482-.704-.575-.214-.094-.532-.088-.857-.094-.593-.006-1.273-.019-1.744-.5s-.484-1.175-.49-1.781c-.006-.332-.012-.669-.092-.875-.08-.207-.33-.475-.563-.719-.404-.431-.863-.925-.863-1.575s.46-1.144.863-1.575c.233-.244.472-.5.563-.719.092-.219.086-.544.092-.875.006-.606.019-1.3.49-1.781s1.15-.494 1.744-.5c.325-.006.655-.012.857-.094.202-.081.465-.337.704-.575C7.188 1.47 7.671 1 8.308 1s1.12.469 1.542.881c.239.238.49.481.704.575s.533.088.857.094c.594.006 1.273.019 1.745.5.47.481.483 1.175.49 1.781.005.331.011.669.091.875s.33.475.563.719c.404.431.863.925.863 1.575"/><path fill="#fff" d="M7.328 10.5c.195 0 .381.08.519.22.137.141.215.331.216.53 0 .066.026.13.072.177a.24.24 0 0 0 .346 0 .25.25 0 0 0 .071-.177c.001-.199.079-.389.216-.53a.73.73 0 0 1 .519-.22h1.959c.13 0 .254-.053.346-.146a.5.5 0 0 0 .143-.354V6a.5.5 0 0 0-.143-.354.49.49 0 0 0-.346-.146h-1.47c-.324 0-.635.132-.865.366-.23.235-.359.552-.359.884v2.5c0 .066-.025.13-.071.177a.24.24 0 0 1-.346 0 .25.25 0 0 1-.072-.177v-2.5c0-.332-.13-.65-.359-.884A1.21 1.21 0 0 0 6.84 5.5h-1.47a.49.49 0 0 0-.346.146A.5.5 0 0 0 4.88 6v4c0 .133.051.26.143.354a.49.49 0 0 0 .347.146z"/></svg></div></div></div><span class="id ie" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="if ig ah ai aj ak al am an ao ap aq ar ih ii ij" disabled="">Follow</button></p></div></div></span></div></div><div class="l ik"><span class="bf b bg z dx"><div class="ab cn il im in"><div class="io ip ab"><div class="bf b bg z dx ab iq"><span class="ir l ik">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------" rel="noopener follow"><p class="bf b bg z is it iu iv iw ix iy iz bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="id ie" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="ja jb l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 7, 2024</span></div></span></div></span></div></div></div><div class="ab cp jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr"><div class="h k w ea eb q"><div class="kh l"><div class="ab q ki kj"><div class="pw-multi-vote-icon ed ir kk kl km"><div class=""><div class="kn ko kp kq kr ks kt am ku kv kw km"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kx ky kz la lb lc ld"><p class="bf b dy z dx"><span class="ko">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kn le lf ab q ee lg lh" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="li"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q js jt ju jv jw jx jy jz ka kb kc kd ke kf kg"><div class="lj k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lk an ao ap ih ll lm ln" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lo cn"><div class="l ae"><div class="ab cb"><div class="lp lq lr ls lt lu ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lk an ao ap ih lv lw lh lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lk an ao ap ih lv lw lh lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lk an ao ap ih lv lw lh lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mm bh"><figure class="mn mo mp mq mr mm bh paragraph-image"><img src="../Images/03fee566222b05ecc08e045cd78395f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:4800/format:webp/0*FEaR7Tk2RBv_5Mw5"/><figcaption class="mt mu mv mw mx my mz bf b bg z dx">Photo by <a class="af na" href="https://unsplash.com/@glencarrie?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Glen Carrie</a> on <a class="af na" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="dc8b" class="nb nc fr bf nd ne nf gr ng nh ni gu nj nk nl nm nn no np nq nr ns nt nu nv nw bk"><strong class="al">The Rise of LLMs</strong></h1><p id="fe33" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Large Language Models (LLMs) have emerged as a transformative force, revolutionizing how we interact with and process information. These powerful AI models, capable of understanding and generating human-like text, have found applications in a wide array of fields, from chatbots and virtual assistants to content creation and data analysis.</p><figure class="mn mo mp mq mr mm mw mx paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="mw mx ot"><img src="../Images/ba0872bec49d5fb2b3f7ca3b00afd991.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p0UPfd0A5HcNF4stc58wPA.png"/></div></div><figcaption class="mt mu mv mw mx my mz bf b bg z dx">Usual Prompt based development workflow. Source: Author</figcaption></figure><p id="087d" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">However, building and maintaining effective LLM-powered applications is not without its challenges. Prompt engineering, <em class="pd">the art of crafting precise instructions for LLMs</em>, can be a time-consuming and iterative process. Debugging and troubleshooting LLM behavior can also be complex, given the inherent “black box” nature of these models. Additionally, gaining insights into the performance and cost implications of LLM applications is crucial for optimization and scalability (key components for any production grade setup).</p><h2 id="d18f" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">The LLM Ecosystem</strong></h2><p id="ca76" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">The ecosystem for LLMs is still in its nascent stages. To address some of these challenges, a number of innovative tools and frameworks are being developed. <a class="af na" href="https://dspy-docs.vercel.app/" rel="noopener ugc nofollow" target="_blank">DSPy</a> from Stanford University is one such unique take towards formalizing LLM-based app development. <a class="af na" href="https://langfuse.com/" rel="noopener ugc nofollow" target="_blank">Langfuse</a> on the other hand has emerged as an offering to streamline and operationalize aspects of LLM app maintenance. To put it in brief:</p><ul class=""><li id="b472" class="nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os pv pw px bk"><strong class="nz fs">DSPY</strong> provides a modular and composable framework for building LLM applications, abstracting away the complexities of prompt engineering and enabling developers to focus on the core logic of their applications.</li><li id="fb78" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Langfuse</strong> offers a comprehensive observability platform for LLM apps, providing deep insights into model performance, cost, and user interactions.</li></ul><p id="a255" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">By combining DSPy and Langfuse, developers can unlock the full potential of LLMs, building robust, scalable, and insightful applications that deliver exceptional user experiences.</p><h1 id="8867" class="nb nc fr bf nd ne nf gr ng nh ni gu nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Unlocking LLM Potential with DSPy</h1><p id="6db2" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Language Models are extremely complex machines with capabilities to retrieve and reformulate information from an extremely large latent space. To guide this search and achieve desired responses we heavily rely on complex, long and brittle prompts which (at times) are very specific to certain LLMs.</p><p id="acfb" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">Being an open area of research, teams are working from different perspectives to abstract and enable rapid development of LLM-enabled systems. DSPy is one such framework for algorithmically optimizing LLM prompts and <em class="pd">weights</em>.</p><h2 id="5767" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">Ok, You Got Me Intrigued, Tell Me More?</strong></h2><p id="d03a" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">The DSPy framework takes inspiration from deep learning frameworks such as <em class="pd">PyTorch.</em></p><p id="0336" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">For instance, to build a deep neural network using PyTorch we simply use standard layers such as <em class="pd">convolution</em>, <em class="pd">dropout</em>, <em class="pd">linear</em> and attach them to optimizers like <em class="pd">Adam</em> and train without worrying about implementing these from scratch every time.</p><p id="c843" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">Similarly, DSPy provides a a set of standard general purpose modules (such as <em class="pd">ChainOfThought</em>,<em class="pd">Predict</em>), optimizers (such as <em class="pd">BootstrapFewShotWithRandomSearch</em>) and helps us build systems by composing these components as layers into a <em class="pd">Program</em> without explicitly dealing with prompts! Neat isn’t it?</p><h2 id="8d27" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">The DSPy Building Blocks &amp; Workflow</strong></h2></div></div><div class="mm"><div class="ab cb"><div class="lp qd lq qe lr qf cf qg cg qh ci bh"><figure class="mn mo mp mq mr mm qj qk paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="mw mx qi"><img src="../Images/490f9851fac27b4b2ff35e95ad3565ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*oNTpRHEDAonoBjwelknAiQ.png"/></div></div><figcaption class="mt mu mv mw mx my mz bf b bg z dx">Figure 1: (left) DSPy Building Blocks consisting of Signatures, Modules, Optimizers. (right) DSPy Program workflow. Source: Author</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="8057" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">As illustrated in <em class="pd">figure 1</em>, DSPy is a pytorch-like/lego-like framework for building LLM-based apps. Out of the box, it comes with:</p><ul class=""><li id="6fdd" class="nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os pv pw px bk"><a class="af na" href="https://dspy-docs.vercel.app/docs/building-blocks/signatures" rel="noopener ugc nofollow" target="_blank"><strong class="nz fs">Signatures</strong></a>: These are specifications to define input and output behaviour of a DSPy program. These can be defined using <em class="pd">short-hand</em> notation (like “question -&gt; answer” where the framework automatically understands question is the input while answer is the output) or using <em class="pd">declarative specification </em>using python classes (more on this in later sections)</li><li id="02b4" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><a class="af na" href="https://dspy-docs.vercel.app/docs/building-blocks/modules" rel="noopener ugc nofollow" target="_blank"><strong class="nz fs">Modules</strong></a>: These are layers of predefined components for powerful concepts like <em class="pd">Chain of Thought</em>, <em class="pd">ReAct</em> or even the simple text completion (Predict). These modules abstract underlying brittle prompts while still providing extensibility through custom components.</li><li id="676e" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><a class="af na" href="https://dspy-docs.vercel.app/docs/building-blocks/optimizers" rel="noopener ugc nofollow" target="_blank"><strong class="nz fs">Optimizers</strong></a>: These are unique to DSPy framework and draw inspiration from PyTorch itself. These optimizers make use of annotated datasets and evaluation metrics to help tune/optimize our LLM-powered DSPy programs.</li><li id="58bc" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Data</strong>, <strong class="nz fs">Metrics</strong>, <a class="af na" href="https://dspy-docs.vercel.app/docs/building-blocks/assertions" rel="noopener ugc nofollow" target="_blank"><strong class="nz fs">Assertions</strong></a> and <strong class="nz fs">Trackers</strong> are some of the other components of this framework which act as glue and work behind the scenes to enrich this overall framework.</li></ul><p id="8191" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">To build an app/program using DSPy, we go through a modular yet step by step approach (as shown in <em class="pd">figure 1 (right)</em>). We first define our <em class="pd">task</em> to help us clearly define our program’s signature (input and output specifications). This is followed by building a <em class="pd">pipeline</em> program which makes use of one or more abstracted prompt modules, language model module as well as retrieval model modules. One we have all of this in place, we then proceed to have some <em class="pd">examples</em> along with required metrics to <em class="pd">evaluate</em> our setup which are used by <em class="pd">optimizers</em> and <em class="pd">assertion</em> components<em class="pd"> </em>to <em class="pd">compile</em> a powerful app.</p><h1 id="bb57" class="nb nc fr bf nd ne nf gr ng nh ni gu nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Gaining LLM Insights with Langfuse</h1><p id="e4ad" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Langfuse is an LLM Engineering platform designed to empower developers in building, managing, and optimizing LLM-powered applications. While it offers both managed and self-hosting solutions, we’ll focus on the self-hosting option in this post, providing you with complete control over your LLM infrastructure.</p><h2 id="adfe" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">Key Highlights of Langfuse Setup</strong></h2><p id="880b" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Langfuse equips you with a suite of powerful tools to streamline the LLM development workflow:</p><ul class=""><li id="3b40" class="nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os pv pw px bk"><strong class="nz fs">Prompt Management:</strong> Effortlessly version and retrieve prompts, ensuring reproducibility and facilitating experimentation.</li><li id="7449" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Tracing:</strong> Gain deep visibility into your LLM applications with detailed traces, enabling efficient debugging and troubleshooting. The intuitive UI out of the box enables teams to annotate model interactions to develop and evaluate training datasets.</li><li id="c66a" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Metrics:</strong> Track crucial metrics such as cost, latency, and token usage, empowering you to optimize performance and control expenses.</li><li id="4518" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Evaluation:</strong> Capture user feedback, annotate LLM responses, and even set up evaluation functions to continuously assess and improve your models.</li><li id="9f58" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Datasets:</strong> Manage and organize datasets derived from your LLM applications, facilitating further fine-tuning and model enhancement.</li></ul><h2 id="6cd9" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">Effortless Setup</strong></h2><p id="842d" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Langfuse’s self-hosting solution is remarkably easy to set up, leveraging a <em class="pd">docker</em>-based architecture that you can quickly spin up using <em class="pd">docker compose</em>. This streamlined approach minimizes deployment complexities and allows you to focus on building your LLM applications.</p><h2 id="659f" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">Framework Compatibility</strong></h2><p id="f6a5" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Langfuse seamlessly integrates with popular LLM frameworks like <a class="af na" href="https://www.langchain.com/" rel="noopener ugc nofollow" target="_blank">LangChain</a>, <a class="af na" href="https://www.llamaindex.ai/" rel="noopener ugc nofollow" target="_blank">LlamaIndex</a>, and, of course, DSPy, making it a versatile tool for a wide range of LLM development frameworks.</p><h1 id="fd8e" class="nb nc fr bf nd ne nf gr ng nh ni gu nj nk nl nm nn no np nq nr ns nt nu nv nw bk">The Power of DSPY + Langfuse</h1><p id="71a3" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">By integrating Langfuse into your DSPy applications, you unlock a wealth of observability capabilities that enable you to monitor, analyze, and optimize your models in real time.</p><h2 id="1e40" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">Integrating Langfuse into Your DSPy App</strong></h2><p id="d2a7" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">The integration process is straightforward and involves instrumenting your DSPy code with Langfuse’s SDK.</p><pre class="mn mo mp mq mr ql qm qn bp qo bb bk"><span id="ecc5" class="qp nc fr qm b bg qq qr l qs qt">import dspy<br/>from dsp.trackers.langfuse_tracker import LangfuseTracker<br/><br/># configure tracker <br/>langfuse = LangfuseTracker()<br/><br/># instantiate openai client<br/>openai = dspy.OpenAI(<br/>                      model='gpt-4o-mini', <br/>                      temperature=0.5, <br/>                      max_tokens=1500<br/>          )<br/><br/># dspy predict supercharged with automatic langfuse trackers <br/>openai("What is DSPy?")</span></pre><h2 id="6fa6" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">Gaining Insights with Langfuse</strong></h2><p id="b993" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Once integrated, Langfuse provides a number of actionable insights into your DSPy application’s behavior:</p><ul class=""><li id="f6e2" class="nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os pv pw px bk"><strong class="nz fs">Trace-Based Debugging:</strong> Follow the execution flow of your DSPY programs, pinpoint bottlenecks, and identify areas for improvement.</li><li id="9413" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Performance Monitoring:</strong> Track key metrics like latency and token usage to ensure optimal performance and cost-efficiency.</li><li id="8496" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">User Interaction Analysis:</strong> Understand how users interact with your LLM app, identify common queries, and opportunities for enhancement.</li><li id="f107" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Data Collection &amp; Fine-Tuning:</strong> Collect and annotate LLM responses, building valuable datasets for further fine-tuning and model refinement.</li></ul><h2 id="3da8" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">Use Cases Amplified</strong></h2><p id="089c" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">The combination of DSPy and Langfuse is particularly important in the following scenarios:</p><ul class=""><li id="f67f" class="nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os pv pw px bk"><strong class="nz fs">Complex Pipelines:</strong> When dealing with complex DSPy pipelines involving multiple modules, Langfuse’s tracing capabilities become indispensable for debugging and understanding the flow of information.</li><li id="09ed" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Production Environments:</strong> In production settings, Langfuse’s monitoring features ensure your LLM app runs smoothly, providing early warnings of potential issues while keeping an eye on costs involved.</li><li id="2bb0" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><strong class="nz fs">Iterative Development:</strong> Langfuse’s evaluation and dataset management tools facilitate data-driven iteration, allowing you to continuously refine your LLM app based on real-world usage.</li></ul><h1 id="7bbd" class="nb nc fr bf nd ne nf gr ng nh ni gu nj nk nl nm nn no np nq nr ns nt nu nv nw bk">The Meta Use Case: Q&amp;A Bot for my Workshop</h1><p id="5092" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">To truly showcase the power and versatility of DSPy combined with amazing monitoring capabilities of langfuse, I’ve recently applied them to a unique dataset: my recent <a class="af na" href="https://github.com/raghavbali/llm_workshop" rel="noopener ugc nofollow" target="_blank">LLM workshop GitHub repository</a>. This recent full day workshop contains a lot of material to get you started with LLMs. The aim of this Q&amp;A bot was to assist participants during and after the workshop with answers to a host NLP and LLM related topics covered in the workshop. This “meta” use case not only demonstrates the practical application of these tools but also adds a touch of self-reflection to our exploration.</p><h2 id="25e8" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">The Task: Building a Q&amp;A System</strong></h2><p id="23ec" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">For this exercise, we’ll leverage DSPy to build a Q&amp;A system capable of answering questions about the content of my workshop (notebooks, markdown files, etc.). This task highlights DSPy’s ability to process and extract information from textual data, a crucial capability for a wide range of LLM applications. Imagine having a personal AI assistant (or co-pilot) that can help you recall details from your past weeks, identify patterns in your work, or even surface forgotten insights! It also presents a strong case of how such a modular setup can be easily extended to any other textual dataset with little to no effort.</p><p id="9a42" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">Let us begin by setting up the required objects for our program.</p><pre class="mn mo mp mq mr ql qm qn bp qo bb bk"><span id="4e6a" class="qp nc fr qm b bg qq qr l qs qt">import os<br/>import dspy<br/>from dsp.trackers.langfuse_tracker import LangfuseTracker<br/><br/>config = {<br/>    'LANGFUSE_PUBLIC_KEY': 'XXXXXX',<br/>    'LANGFUSE_SECRET_KEY': 'XXXXXX',<br/>    'LANGFUSE_HOST': 'http://localhost:3000',<br/>    'OPENAI_API_KEY': 'XXXXXX',<br/>    'OPENAI_BASE_URL': 'XXXXXX',<br/>    'OPENAI_PROVIDER': 'XXXXXX',<br/>    'CHROMA_DB_PATH': './chromadb/',<br/>    'CHROMA_COLLECTION_NAME':"supercharged_workshop_collection",<br/>    'CHROMA_EMB_MODEL': 'all-MiniLM-L6-v2'<br/>}<br/><br/># setting config<br/>os.environ["LANGFUSE_PUBLIC_KEY"] = config.get('LANGFUSE_PUBLIC_KEY')<br/>os.environ["LANGFUSE_SECRET_KEY"] = config.get('LANGFUSE_SECRET_KEY')<br/>os.environ["LANGFUSE_HOST"] = config.get('LANGFUSE_HOST')<br/>os.environ["OPENAI_API_KEY"] = config.get('OPENAI_API_KEY')<br/><br/># setup Langfuse tracker<br/>langfuse_tracker = LangfuseTracker(session_id='supercharger001')<br/><br/># instantiate language-model for DSPY<br/>llm_model = dspy.OpenAI(<br/>    api_key=config.get('OPENAI_API_KEY'),<br/>    model='gpt-4o-mini'<br/>)<br/><br/># instantiate chromadb client<br/>chroma_emb_fn = embedding_functions.\<br/>                    SentenceTransformerEmbeddingFunction(<br/>                        model_name=config.get(<br/>                            'CHROMA_EMB_MODEL'<br/>                        )<br/>                    )<br/>client = chromadb.HttpClient()<br/><br/><br/># setup chromadb collection<br/>collection = client.create_collection(<br/>    config.get('CHROMA_COLLECTION_NAME'),<br/>    embedding_function=chroma_emb_fn,<br/>    metadata={"hnsw:space": "cosine"}<br/>)</span></pre><p id="6fa8" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">Once we have these clients and trackers in place, let us quickly add some documents to our collection (refer to this <a class="af na" href="https://github.com/raghavbali/llm_workshop/blob/main/module_04/06_supercharge_llm_apps.ipynb" rel="noopener ugc nofollow" target="_blank">notebook</a> for a detailed walk through of how I prepared this dataset in the first place).</p><pre class="mn mo mp mq mr ql qm qn bp qo bb bk"><span id="82c4" class="qp nc fr qm b bg qq qr l qs qt"># Add to collection<br/>collection.add(<br/>    documents=[v for _,v in nb_scraper.notebook_md_dict.items()], <br/>    ids=doc_ids, # must be unique for each doc<br/>)</span></pre><p id="4221" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">The next step is to simply connect our chromadb retriever to the DSPy framework. The following snippet created a RM object and tests if the retrieval works as intended.</p><pre class="mn mo mp mq mr ql qm qn bp qo bb bk"><span id="a532" class="qp nc fr qm b bg qq qr l qs qt">retriever_model = ChromadbRM(<br/>    config.get('CHROMA_COLLECTION_NAME'),<br/>    config.get('CHROMA_DB_PATH'),<br/>    embedding_function=chroma_emb_fn,<br/>    client=client,<br/>    k=5<br/>)<br/><br/># Test Retrieval<br/>results = retriever_model("RLHF")<br/>for result in results:<br/>    display(Markdown(f"__Document__::{result.long_text[:100]}... \n"))<br/>    display(Markdown(f"&gt;- __Document id__::{result.id} \n&gt;- __Document score__::{result.score}"))</span></pre><p id="2c33" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">The output looks promising given that without any intervention, Chromadb is able to fetch the most relevant documents.</p><pre class="mn mo mp mq mr ql qm qn bp qo bb bk"><span id="1fe0" class="qp nc fr qm b bg qq qr l qs qt">Document::# Quick Overview of RLFH<br/><br/>The performance of Language Models until GPT-3 was kind of amazing as-is. ...<br/><br/>- Document id::6_module_03_03_RLHF_phi2<br/>- Document score::0.6174977412306334<br/><br/>Document::# Getting Started : Text Representation Image<br/><br/>The NLP domain ...<br/><br/>- Document id::2_module_01_02_getting_started<br/>- Document score::0.8062083377747705<br/><br/>Document::# Text Generation &lt;a target="_blank" href="https://colab.research.google.com/github/raghavbali/llm_w" &gt; ...<br/><br/>- Document id::3_module_02_02_simple_text_generator<br/>- Document score::0.8826038964887366<br/><br/>Document::# Image DSPy: Beyond Prompting<br/>&lt;img src= "./assets/dspy_b" &gt; ...<br/><br/>- Document id::12_module_04_05_dspy_demo<br/>- Document score::0.9200280698248913</span></pre><p id="7609" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">The final step is to piece all of this together in preparing a DSPy program. For our simple Q&amp;A use-case we make prepare a standard RAG program leveraging Chromadb as our retriever and Langfuse as our tracker. The following snippet presents the pytorch-like approach of developing LLM based apps without worrying about brittle prompts!</p><pre class="mn mo mp mq mr ql qm qn bp qo bb bk"><span id="5345" class="qp nc fr qm b bg qq qr l qs qt"># RAG Signature<br/>class GenerateAnswer(dspy.Signature):<br/>    """Answer questions with short factoid answers."""<br/><br/>    context = dspy.InputField(desc="may contain relevant facts")<br/>    question = dspy.InputField()<br/>    answer = dspy.OutputField(desc="often less than 50 words")<br/><br/># RAG Program<br/>class RAG(dspy.Module):<br/>    def __init__(self, num_passages=3):<br/>        super().__init__()<br/><br/>        self.retrieve = dspy.Retrieve(k=num_passages)<br/>        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)<br/>    <br/>    def forward(self, question):<br/>        context = self.retrieve(question).passages<br/>        prediction = self.generate_answer(context=context, question=question)<br/>        return dspy.Prediction(context=context, answer=prediction.answer)<br/><br/><br/># compile a RAG<br/># note: we are not using any optimizers for this example<br/>compiled_rag = RAG()</span></pre><p id="317e" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">Phew! Wasn’t that quick and simple to do? Let us now put this into action using a few sample questions.</p><pre class="mn mo mp mq mr ql qm qn bp qo bb bk"><span id="92ef" class="qp nc fr qm b bg qq qr l qs qt">my_questions = [<br/>    "List the models covered in module03",<br/>    "Brief summary of module02",<br/>    "What is LLaMA?"<br/>]<br/><br/>for question in my_questions:<br/>    # Get the prediction. This contains `pred.context` and `pred.answer`.<br/>    pred = compiled_rag(question)<br/>    <br/>    display(Markdown(f"__Question__: {question}"))<br/>    display(Markdown(f"__Predicted Answer__: _{pred.answer}_"))<br/>    display(Markdown("__Retrieved Contexts (truncated):__"))<br/>    for idx,cont in enumerate(pred.context):<br/>        print(f"{idx+1}. {cont[:200]}..." )<br/>        print()<br/>    display(Markdown('---'))</span></pre><p id="ecdc" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">The output is indeed quite on point and serves the purpose of being an assistant to this workshop material answering questions and guiding the attendees nicely.</p></div></div><div class="mm"><div class="ab cb"><div class="lp qd lq qe lr qf cf qg cg qh ci bh"><figure class="mn mo mp mq mr mm qj qk paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="mw mx qu"><img src="../Images/12ca0eec049875f56d6d90960d5d0723.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*kXrIsae1iDWPQdr3rtU4ug.png"/></div></div><figcaption class="mt mu mv mw mx my mz bf b bg z dx">Figure 2: Output from the DSPy RAG program. Source: Author</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ew ex ey ez"><h2 id="4791" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">The Langfuse Advantage</strong></h2><p id="4ccc" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Earlier in this article we discussed how langfuse completes the picture by enabling us to monitor LLM usage and improve upon other aspects of the pipeline. The amazing integration of langfuse as a tracker glues everything behind the scenes with a nice and easy to use interface. For our current setting, the langfuse dashboard presents a quick summary of our LLM usage.</p></div></div><div class="mm"><div class="ab cb"><div class="lp qd lq qe lr qf cf qg cg qh ci bh"><figure class="mn mo mp mq mr mm qj qk paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="mw mx qv"><img src="../Images/3a36ba9137c9c67f2dd44f0ce7d93a6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*xs5l0iEp3Y1Fz-VN9w3iHw.png"/></div></div><figcaption class="mt mu mv mw mx my mz bf b bg z dx">Figure 3: Langfuse Dashboard. Source: Author</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="5e6e" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">The dashboard is complete with metrics such as number of traces, overall costs and even token usage (which is quite handy when it comes to optimize your pipelines).</p><h2 id="262c" class="pe nc fr bf nd pf pg ph ng pi pj pk nj og pl pm pn ok po pp pq oo pr ps pt pu bk"><strong class="al">Insights and Benefits</strong></h2><p id="c24f" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">Langfuse’s utility does not end with top-level dashboard of metrics. It provides trace level details (as shown in <em class="pd">figure 4</em>).</p></div></div><div class="mm"><div class="ab cb"><div class="lp qd lq qe lr qf cf qg cg qh ci bh"><figure class="mn mo mp mq mr mm qj qk paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="mw mx qv"><img src="../Images/f1112de13de787eefe9a218d498d391f.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*iuhQW2MeGMsaXyJ21B0mtQ.png"/></div></div><figcaption class="mt mu mv mw mx my mz bf b bg z dx">Figure 4: Langfuse trace detail complete with cost, token usage, prompt as well as the model response. Source: Author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="3e27" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">This interface is a gateway to a number of other aspects that are very useful in terms of iterating and improving LLM based apps. The first and foremost capability is to prepare datasets based on real world usage. These datasets can be used for fine-tuning LLMs, optimizing DSPy programs, etc. <em class="pd">Figure 5</em> illustrates how simple it is to define a dataset from the web-UI itself and then add traces (input request along with model’s response) as needed to the dataset.</p></div></div><div class="mm"><div class="ab cb"><div class="lp qd lq qe lr qf cf qg cg qh ci bh"><div class="mn mo mp mq mr ab ki"><figure class="li mm qw qx qj qk qy paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><img src="../Images/db0f7ed09c4a08f8a23720d6a454efbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*Edf9l-vQ_3wm3Y15J3bA5g.png"/></div></figure><figure class="li mm qz qx qj qk qy paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><img src="../Images/3f9796f949790f848308a49a81f1545c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*hyWOt3ByEzIME4f1H8Owjw.png"/></div><figcaption class="mt mu mv mw mx my mz bf b bg z dx ra ed rb rc">Figure 5: (left) Create a new dataset from the web UI directly by simply providing the required details such as dataset name and description. (right) traces can be added to datasets at the click of a button. Source: Author</figcaption></figure></div></div></div></div><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="b974" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">Similar to dataset creation and adding data points to it, langfuse simplifies creation of metrics and annotating datapoints. <em class="pd">Figure 6</em> illustrates how simple it is to do the same at the click of a couple of buttons.</p></div></div><div class="mm"><div class="ab cb"><div class="lp qd lq qe lr qf cf qg cg qh ci bh"><div class="mn mo mp mq mr ab ki"><figure class="li mm rd qx qj qk qy paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><img src="../Images/acf9c98a20ba18ecf4c51ad3fca07835.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*5A2qsbyLwqc_0OLrmoM8Gg.png"/></div></figure><figure class="li mm re qx qj qk qy paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><img src="../Images/e19a439a5374973c5f72cd3a492f60ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*KZ-K7lS9Yo_1eXce6m5L5w.png"/></div><figcaption class="mt mu mv mw mx my mz bf b bg z dx rf ed rg rc">Figure 6: Metric creation and annotation in Langfuse. Source: Author</figcaption></figure></div></div></div></div><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="e0e8" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">Once we have a dataset prepared, langfuse provides a straightforward SDK to use it in your language of of preference. The following snippet makes use of get_dataset utility from langfuse to get to a couple of traces we added to the sample dataset. We then use LLaMA 3.1 to power our DSPy RAG program with just one line change (talk about modularity ;) ).</p><pre class="mn mo mp mq mr ql qm qn bp qo bb bk"><span id="9b96" class="qp nc fr qm b bg qq qr l qs qt"># get annotated dataset<br/>annotated_dataset = langfuse.get_dataset("llm_workshop_rag")<br/><br/># ensure ollama is available in your environment<br/>ollama_dspy = dspy.OllamaLocal(model='llama3.1',temperature=0.5)<br/><br/># get langfuse client from the dspy tracker object<br/>langfuse =langfuse_tracker.langfuse<br/><br/># Set up the ollama as LM and RM<br/>dspy.settings.configure(lm=ollama_dspy,rm=retriever_model)<br/><br/># test rag using ollama<br/>ollama_rag = RAG()<br/><br/># iterate through samples from the annotated dataset<br/>for item in annotated_dataset.items:<br/>    question = item.input[0]['content'].split('Question: ')[-1].split('\n')[0]<br/>    answer = item.expected_output['content'].split('Answer: ')[-1]<br/>    o_pred = ollama_rag(question)<br/>    <br/>    # add observations to dataset related experiments<br/>    with item.observe(<br/>        run_name='ollama_experiment',<br/>        run_description='compare LLaMA3.1 RAG vs GPT4o-mini RAG ',<br/>        run_metadata={"model": "llama3.1"},<br/>    ) as trace_id:<br/>        langfuse.score(<br/>            name="visual-eval",<br/>            # any float value<br/>            value=1.0,<br/>            comment="LLaMA3.1 is very verbose",<br/>        )<br/>    # attach trace with new run<br/>    langfuse.trace(input=question,output=o_pred.answer,metadata={'model':'LLaMA3.1'})<br/>    display(Markdown(f"__Question__: {question}"))<br/>    display(Markdown(f"__Predicted Answer (LLaMA 3.1)__: {o_pred.answer}"))<br/>    display(Markdown(f"&gt;__Annotated Answer (GPT-4o-mini)__: _{answer}_"))</span></pre><p id="4e4c" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">As shown in the above snippet, we simply iterate through the datapoints in our dataset and visually compare the output from both models (see <em class="pd">figure 7</em>). Using Langfuse SDK we attach experiment observations along with new traces and evaluation scores very easily.</p></div></div><div class="mm"><div class="ab cb"><div class="lp qd lq qe lr qf cf qg cg qh ci bh"><div class="mn mo mp mq mr ab ki"><figure class="li mm rh qx qj qk qy paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><img src="../Images/5f7debc33c398b2935a9540b2ca759f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*5N6iXiINW2osygPtZA8B5Q.png"/></div></figure><figure class="li mm ri qx qj qk qy paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><img src="../Images/24ffbca1793fbdb95aea3c357b05b398.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*eyob5ISd2-OPN-LRHg-U8g.png"/></div><figcaption class="mt mu mv mw mx my mz bf b bg z dx rj ed rk rc">Figure 7: Output from LLaMA3.1 powered RAG using datapoints from dataset prepared using Langfuse</figcaption></figure></div></div></div></div><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="3f57" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">The output presented in figure 7 clearly shows how LLaMA3.1 powered RAG does answer the questions but strays from the instructions of being brief. This can be easily captured using DSPy assertions as well as scores can be tracked using langfuse SDK for further improvements.</p><h1 id="0d58" class="nb nc fr bf nd ne nf gr ng nh ni gu nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Conclusion</h1><p id="7c76" class="pw-post-body-paragraph nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os fk bk">In this rapidly evolving landscape of LLM applications, tools like DSPy and Langfuse emerge as invaluable allies for developers &amp; data scientists. DSPy streamlines the development process, empowering you to build sophisticated LLM applications with ease and efficiency. Meanwhile, Langfuse provides the crucial observability layer, enabling you to gain deep insights into your models’ performance, optimize resource utilization, and continuously improve your applications based on real-world data.</p><p id="148f" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">The combination of DSPY and Langfuse unlocks a world of possibilities, allowing you to harness the full potential of LLMs. Whether you’re building Q&amp;A systems, content generators, or any other LLM-powered application, these tools provide the foundation for creating robust, scalable, and insightful solutions.</p><p id="da13" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">As I’ve demonstrated through the meta usecase of answering questions for my recent LLM-workshop, DSPy and Langfuse can be applied creatively to extract valuable insights from even your own personal data. The possibilities are truly endless.</p><p id="1176" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk">I encourage you to explore these tools/frameworks in your own projects. Interested folks can leverage the comprehensive hands-on driven workshop material for more topics on my <a class="af na" href="https://github.com/raghavbali/llm_workshop" rel="noopener ugc nofollow" target="_blank">GitHub repository</a>. With these tools at your disposal, you’re well-equipped to <strong class="nz fs"><em class="pd">supercharge</em></strong> your LLM applications and stay ahead in the ever-evolving world of AI.</p></div></div></div><div class="ab cb rl rm rn ro" role="separator"><span class="rp by bm rq rr rs"/><span class="rp by bm rq rr rs"/><span class="rp by bm rq rr"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="f895" class="pw-post-body-paragraph nx ny fr nz b gp oy ob oc gs oz oe of og pa oi oj ok pb om on oo pc oq or os fk bk"><em class="pd">Disclaimer: I have no affiliations, financial or otherwise, with any of the tools, products, or companies mentioned in this article. The opinions and insights shared are based solely on personal experience and independent research.</em></p><h1 id="c355" class="nb nc fr bf nd ne nf gr ng nh ni gu nj nk nl nm nn no np nq nr ns nt nu nv nw bk">References</h1><ul class=""><li id="c4a5" class="nx ny fr nz b gp oa ob oc gs od oe of og oh oi oj ok ol om on oo op oq or os pv pw px bk"><a class="af na" href="https://dspy-docs.vercel.app/" rel="noopener ugc nofollow" target="_blank">DSPy</a></li><li id="5124" class="nx ny fr nz b gp py ob oc gs pz oe of og qa oi oj ok qb om on oo qc oq or os pv pw px bk"><a class="af na" href="https://langfuse.com/" rel="noopener ugc nofollow" target="_blank">Langfuse</a></li></ul><div class="rt ru rv rw rx ry"><a href="https://github.com/raghavbali/llm_workshop.git?source=post_page-----f83c02ba96a1--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="rz ab ik"><div class="sa ab co cb sb sc"><h2 class="bf fs hx z is sd iu iv se ix iz fq bk">GitHub - raghavbali/llm_workshop: LLM Workshop 2024</h2><div class="sf l"><h3 class="bf b hx z is sd iu iv se ix iz dx">LLM Workshop 2024. Contribute to raghavbali/llm_workshop development by creating an account on GitHub.</h3></div><div class="sg l"><p class="bf b dy z is sd iu iv se ix iz dx">github.com</p></div></div><div class="sh l"><div class="si l sj sk sl sh sm lu ry"/></div></div></a></div></div></div></div></div>    
</body>
</html>