- en: Implementing Anthropic’s Contextual Retrieval for Powerful RAG Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/implementing-anthropics-contextual-retrieval-for-powerful-rag-performance-b85173a65b83?source=collection_archive---------5-----------------------#2024-10-18](https://towardsdatascience.com/implementing-anthropics-contextual-retrieval-for-powerful-rag-performance-b85173a65b83?source=collection_archive---------5-----------------------#2024-10-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This article will show you how to implement the contextual retrieval idea proposed
    by Anthropic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)[![Eivind
    Kjosbakken](../Images/5f91b74428e1202fc4a176a3dd1cb1c7.png)](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)
    [Eivind Kjosbakken](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)
    ·13 min read·Oct 18, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval augmented generation (RAG) is a powerful technique that utilizes large
    language models (LLMs) and vector databases to create more accurate responses
    to user queries. RAG allows LLMs to utilize large knowledge bases when responding
    to user queries, improving the quality of the responses. However, RAG also has
    some downsides. One downside is that RAG utilizes vector similarity when retrieving
    context to respond to a user query. Vector similarity is not always consistent
    and can, for example, struggle with unique user keywords. Furthermore, RAG also
    struggles because the text is divided into smaller chunks, which prohibits the
    LLM from utilizing the full contexts of documents when responding to queries.
    [Anthropic’s article](https://www.anthropic.com/news/contextual-retrieval) on
    contextual retrieval attempts to solve both problems by using BM25 indexing and
    adding contexts to chunks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e1e2d5eb8de85511246ac0f031a1952.png)'
  prefs: []
  type: TYPE_IMG
- en: Learn how to implement Anthropic’s contextual retrieval RAG in this article.
    Image by ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: My motivation for this article is twofold. First, I would like to test out the
    newest models and techniques within machine learning. Keeping up to date with
    the latest trends within machine learning is critical for any ML engineer and
    data scientist to most…
  prefs: []
  type: TYPE_NORMAL
