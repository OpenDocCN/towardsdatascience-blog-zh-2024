- en: Implementing Anthropic’s Contextual Retrieval for Powerful RAG Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现Anthropic的上下文检索以提升强大的RAG性能
- en: 原文：[https://towardsdatascience.com/implementing-anthropics-contextual-retrieval-for-powerful-rag-performance-b85173a65b83?source=collection_archive---------5-----------------------#2024-10-18](https://towardsdatascience.com/implementing-anthropics-contextual-retrieval-for-powerful-rag-performance-b85173a65b83?source=collection_archive---------5-----------------------#2024-10-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/implementing-anthropics-contextual-retrieval-for-powerful-rag-performance-b85173a65b83?source=collection_archive---------5-----------------------#2024-10-18](https://towardsdatascience.com/implementing-anthropics-contextual-retrieval-for-powerful-rag-performance-b85173a65b83?source=collection_archive---------5-----------------------#2024-10-18)
- en: This article will show you how to implement the contextual retrieval idea proposed
    by Anthropic
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本文将向你展示如何实现Anthropic提出的上下文检索思想
- en: '[](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)[![Eivind
    Kjosbakken](../Images/5f91b74428e1202fc4a176a3dd1cb1c7.png)](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)
    [Eivind Kjosbakken](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)[![Eivind
    Kjosbakken](../Images/5f91b74428e1202fc4a176a3dd1cb1c7.png)](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)
    [Eivind Kjosbakken](https://oieivind.medium.com/?source=post_page---byline--b85173a65b83--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)
    ·13 min read·Oct 18, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b85173a65b83--------------------------------)
    ·13分钟阅读·2024年10月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Retrieval augmented generation (RAG) is a powerful technique that utilizes large
    language models (LLMs) and vector databases to create more accurate responses
    to user queries. RAG allows LLMs to utilize large knowledge bases when responding
    to user queries, improving the quality of the responses. However, RAG also has
    some downsides. One downside is that RAG utilizes vector similarity when retrieving
    context to respond to a user query. Vector similarity is not always consistent
    and can, for example, struggle with unique user keywords. Furthermore, RAG also
    struggles because the text is divided into smaller chunks, which prohibits the
    LLM from utilizing the full contexts of documents when responding to queries.
    [Anthropic’s article](https://www.anthropic.com/news/contextual-retrieval) on
    contextual retrieval attempts to solve both problems by using BM25 indexing and
    adding contexts to chunks.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）是一种强大的技术，利用大型语言模型（LLMs）和向量数据库来创建更准确的用户查询响应。RAG使LLMs在响应用户查询时能够利用大型知识库，从而提高响应质量。然而，RAG也有一些缺点。一个缺点是RAG在检索上下文以响应用户查询时，使用了向量相似性。向量相似性并非始终一致，例如，在处理独特的用户关键词时可能会遇到困难。此外，由于文本被分割成更小的块，RAG也面临困难，这限制了LLM在响应查询时无法充分利用文档的完整上下文。[Anthropic的文章](https://www.anthropic.com/news/contextual-retrieval)通过使用BM25索引并将上下文添加到块中，尝试解决这两个问题。
- en: '![](../Images/8e1e2d5eb8de85511246ac0f031a1952.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e1e2d5eb8de85511246ac0f031a1952.png)'
- en: Learn how to implement Anthropic’s contextual retrieval RAG in this article.
    Image by ChatGPT.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本文了解如何实现Anthropic的上下文检索RAG。图片来源：ChatGPT。
- en: Motivation
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机
- en: My motivation for this article is twofold. First, I would like to test out the
    newest models and techniques within machine learning. Keeping up to date with
    the latest trends within machine learning is critical for any ML engineer and
    data scientist to most…
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 写这篇文章的动机有两个。首先，我想测试机器学习中最新的模型和技术。跟上机器学习领域的最新趋势对于任何机器学习工程师和数据科学家来说都是至关重要的，尤其是在...
