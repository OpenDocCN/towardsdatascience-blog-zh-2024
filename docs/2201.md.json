["```py\n# https://www.youtube.com/watch?v=ErnWZxJovaM\nvideo_id = \"ErnWZxJovaM\" # MIT Introduction to Deep Learning - 2024\n\n# Retrieve transcript with the youtube_transcript_api library\nfrom youtube_transcript_api import YouTubeTranscriptApi\ntranscript = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n```", "```py\n[{'text': '[Music]', 'start': 1.17}, \n{'text': 'good afternoon everyone and welcome to',  'start': 10.28}, \n{'text': 'MIT sus1 191 my name is Alexander amini',  'start': 12.88}, \n{'text': \"and I'll be one of your instructors for\",  'start': 16.84},\n...]\n```", "```py\nfrom faster_whisper import WhisperModel\n\n# Load Whisper model\nwhisper_model = WhisperModel(\"large-v3\",\n                              device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n                              compute_type=\"float16\",\n                            )\n\n# Call the Whisper transcribe function on the audio file\ninitial_prompt = \"Use punctuation, like this.\"\nsegments, transcript_info = whisper_model.transcribe(audio_file,  initial_prompt=initial_prompt, language=\"en\")\n```", "```py\n[{'start': 0.0, 'text': ' Good afternoon, everyone, and welcome to MIT Success 191.'},\n {'start': 15.28, 'text': \" My name is Alexander Amini, and I'll be one of your instructors for the course this year\"},\n {'start': 19.32, 'duration': 2.08, 'text': ' along with Ava.'}\n...]\n```", "```py\n# Connect to Groq with a Groq API key\nllm_client = Groq(api_key=api_key)\nmodel = \"llama-8b-8192\"\n\n# Extract text from transcript\ntranscript_text = ' '.join([s['text'] for s in transcript])\n\n# Call LLM\nresponse = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": transcript_text\n            }\n        ],\n        model=model,\n        temperature=0,\n        seed=42\n    ) \n```", "```py\nresponse_content=response.choices[0].message.content\n\nprint(response_content)\n\"\"\"\n<answer>\nGood afternoon, everyone, and welcome to MIT 6.S191\\. My name is Alexander Amini, and I'll be one of your instructors for the course this year, along with Ava. We're really excited to welcome you to this incredible course.\n\nThis is a fast-paced and intense one-week course that we're about to go through together. We'll be covering the foundations of a rapidly changing field, and a field that has been revolutionizing many areas of science, mathematics, physics, and more.\n\nOver the past decade, AI and deep learning have been rapidly advancing and solving problems that we didn't think were solvable in our lifetimes. Today, AI is solving problems beyond human performance, and each year, this lecture is getting harder and harder to teach because it's supposed to cover the foundations of the field.\n</answer>\n\"\"\"\n```", "```py\nimport re\npattern = re.compile(r'<answer>(.*?)</answer>', re.DOTALL)\nresponse_content_edited =  pattern.findall(response_content)\nparagraphs = response_content_edited.strip().split('\\n\\n')\nparagraphs_dict = [{'paragraph_number': i, 'paragraph_text': paragraph} for i, paragraph in enumerate(paragraphs)\n\nprint(paragraph_dict)\n\n[{'paragraph_number': 0,\n  'paragraph_text': \"Good afternoon, everyone, and welcome to MIT 6.S191\\. My name is Alexander Amini, and I'll be one of your instructors for the course this year, along with Ava. We're really excited to welcome you to this incredible course.\"},\n {'paragraph_number': 1,\n  'paragraph_text': \"This is a fast-paced and intense one-week course that we're about to go through together. We'll be covering the foundations of a rapidly changing field, and a field that has been revolutionizing many areas of science, mathematics, physics, and more.\"},\n {'paragraph_number': 2,\n  'paragraph_text': \"Over the past decade, AI and deep learning have been rapidly advancing and solving problems that we didn't think were solvable in our lifetimes. Today, AI is solving problems beyond human performance, and each year, this lecture is getting harder and harder to teach because it's supposed to cover the foundations of the field.\"}]\n```", "```py\n num_words = 50\n\ntranscript_num_words = transform_text_segments(transcript, num_words=num_words)\nparagraphs_start_text = [{\"start\": p['paragraph_number'], \"text\": p['paragraph_text']} for p in paragraphs]\nparagraphs_num_words = transform_text_segments(paragraphs_start_text, num_words=num_words) \n```", "```py\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Paragraph for which to find the timestamp\nparagraph_i = 0\n\n# Create a TF-IDF vectorizer\nvectorizer = TfidfVectorizer().fit_transform(transcript_num_words + paragraphs_num_words)\n# Get the TF-IDF vectors for the transcript and the excerpt\nvectors = vectorizer.toarray()\n# Extract the TF-IDF vector for the paragraph\nparagraph_vector = vectors[len(transcript_num_words) + paragraph_i]\n\n# Calculate the cosine similarity between the paragraph vector and each transcript chunk\nsimilarities = cosine_similarity(vectors[:len(transcript_num_words)], paragraph_vector.reshape(1, -1))\n# Find the index of the most similar chunk\nbest_match_index = int(np.argmax(similarities))\n```", "```py\nparagraphs = add_timestamps_to_paragraphs(transcript, paragraphs, num_words=50)\n\n#Example of output for the first paragraph:\nprint(paragraphs[0])\n\n{'paragraph_number': 0,\n  'paragraph_text': \"Good afternoon, everyone, and welcome to MIT 6.S191\\. My name is Alexander Amini, and I'll be one of your instructors for the course this year, along with Ava. We're really excited to welcome you to this incredible course.\",\n  'matched_index': 1,\n  'matched_text': 'good afternoon everyone and welcome to',\n  'start_time': 10}\n```", "```py\nsystem_prompt_paragraphs_to_toc = \"\"\"\n\nYou are a helpful assistant.\n\n    You are given a transcript of a course in JSON format as a list of paragraphs, each containing 'paragraph_number' and 'paragraph_text' keys.\n\n    Your task is to group consecutive paragraphs in chapters for the course and identify meaningful chapter titles.\n\n    Here are the steps to follow:\n\n1\\. Read the transcript carefully to understand its general structure and the main topics covered.\n2\\. Look for clues that a new chapter is about to start. This could be a change of topic, a change of time or setting, the introduction of new themes or topics, or the speaker's explicit mention of a new part.\n3\\. For each chapter, keep track of the paragraph number that starts the chapter and identify a meaningful chapter title.\n4\\. Chapters should ideally be equally spaced throughout the transcript, and discuss a specific topic.\n\n    Format your result in JSON, with a list dictionaries for chapters, with 'start_paragraph_number':integer and 'title':string as key:value.\n\n    Example: \n    {\"chapters\": \n        [{\"start_paragraph_number\": 0, \"title\": \"Introduction\"}, \n         {\"start_paragraph_number\": 10, \"title\": \"Chapter 1\"}\n        ]\n    }\n\"\"\" \n```", "```py\n# Connect to OpenAI with an OpenAI API key\nllm_client_get_toc = OpenAI(api_key=api_key)\nmodel_get_toc = \"gpt-4o-mini-2024-07-18\"\n\n# Dump JSON paragraphs as text\nparagraphs_number_text = [{'paragraph_number': p['paragraph_number'], 'paragraph_text': p['paragraph_text']} for p in paragraphs]\nparagraphs_json_dump = json.dumps(paragraphs_number_text)\n\n# Call LLM\nresponse = client_get_toc.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt_paragraphs_to_toc\n            },\n            {\n                \"role\": \"user\",\n                \"content\": paragraphs_json_dump\n            }\n        ],\n        model=model_get_toc,\n        temperature=0,\n        seed=42\n    )\n```", "```py\nprint(response)\n\n{\n  \"chapters\": [\n    {\n      \"start_paragraph_number\": 0,\n      \"title\": \"Introduction to the Course\"\n    },\n    {\n      \"start_paragraph_number\": 17,\n      \"title\": \"Foundations of Intelligence and Deep Learning\"\n    },\n    {\n      \"start_paragraph_number\": 24,\n      \"title\": \"Course Structure and Expectations\"\n    }\n....\n  ]\n}\n```"]