- en: 'TE2Rules: Explaining “Why did my model say that?”'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TE2Rules：解释“为什么我的模型这么说？”
- en: 原文：[https://towardsdatascience.com/te2rules-explaining-why-did-my-model-say-that-54214941075b?source=collection_archive---------14-----------------------#2024-01-05](https://towardsdatascience.com/te2rules-explaining-why-did-my-model-say-that-54214941075b?source=collection_archive---------14-----------------------#2024-01-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/te2rules-explaining-why-did-my-model-say-that-54214941075b?source=collection_archive---------14-----------------------#2024-01-05](https://towardsdatascience.com/te2rules-explaining-why-did-my-model-say-that-54214941075b?source=collection_archive---------14-----------------------#2024-01-05)
- en: Taking model explainability beyond images and text
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将模型可解释性拓展到图像和文本之外
- en: '[](https://groshanlal.medium.com/?source=post_page---byline--54214941075b--------------------------------)[![G
    Roshan Lal](../Images/1a7f79310f75c32124a152fc36027bf4.png)](https://groshanlal.medium.com/?source=post_page---byline--54214941075b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--54214941075b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--54214941075b--------------------------------)
    [G Roshan Lal](https://groshanlal.medium.com/?source=post_page---byline--54214941075b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://groshanlal.medium.com/?source=post_page---byline--54214941075b--------------------------------)[![G
    Roshan Lal](../Images/1a7f79310f75c32124a152fc36027bf4.png)](https://groshanlal.medium.com/?source=post_page---byline--54214941075b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--54214941075b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--54214941075b--------------------------------)
    [G Roshan Lal](https://groshanlal.medium.com/?source=post_page---byline--54214941075b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--54214941075b--------------------------------)
    ·8 min read·Jan 5, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--54214941075b--------------------------------)
    ·阅读时间8分钟·2024年1月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In the rapidly evolving landscape of artificial intelligence, recent advancements
    have propelled the field to astonishing heights, enabling models to mimic human-like
    capabilities in handling both images and text. From crafting images with an artist’s
    finesse to generating captivating captions, answering questions and composing
    entire essays, AI has become an indispensable tool in our digital arsenal.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速发展的人工智能领域，最近的进展已将该领域推向了惊人的高度，使得模型能够模仿人类在处理图像和文本方面的能力。从以艺术家的技巧创作图像到生成引人入胜的标题、回答问题以及撰写完整的文章，人工智能已成为我们数字工具库中不可或缺的一部分。
- en: However, despite these extraordinary feats, the full-scale adoption of this
    potent technology is not universal. The black-box nature of AI models raises significant
    concerns, particularly in industries where transparency is paramount. The lack
    of insight into **“why did the model say that?”** introduces risks, such as toxicity
    and unfair biases, particularly against marginalized groups. In high-stakes domains
    like healthcare and finance, where the consequences of erroneous decisions are
    costly, the need for explainability becomes crucial. This means that it’s not
    enough for the model to arrive at the correct decision, but it’s also equally
    important to explain the rationale behind those decisions.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管这些非凡的成就已经取得，强大技术的全面采用仍然并非普及。人工智能模型的“黑箱”特性引发了重大关切，尤其是在那些对透明度要求极高的行业中。对于**“为什么模型会这么说？”**缺乏洞察引入了风险，例如毒性和不公平的偏见，特别是针对边缘群体。在医疗和金融等高风险领域，错误决策的后果代价高昂，因此可解释性变得至关重要。这意味着，模型不仅需要得出正确的决策，还同样重要的是能够解释这些决策背后的逻辑。
- en: The Tabular Data Challenge
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 表格数据挑战
- en: While models that can ingest, understand and generate more images or text has
    been the new frenzy among many people, many high-stake domains make decisions
    from data compiled into tables like user profile information, posts the user has
    liked, purchase history, watch history etc.,
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管能够处理、理解并生成更多图像或文本的模型已经成为许多人中的新热点，但许多高风险领域是基于如用户信息、用户点赞的帖子、购买历史、观看历史等数据表格来做决策的，
- en: Tabular data is no new phenomena. It has been around as long as internet has
    been there like user’s browser history with visited pages, click interactions,
    products viewed online, products bought online etc., These informations are often
    used by advertisers to show you relevant ads.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据并不是一个新现象。它自互联网诞生以来就存在，例如用户的浏览历史、访问的页面、点击的互动、在线浏览的产品、在线购买的产品等。这些信息通常被广告商用来向你展示相关广告。
- en: 'Many critical use cases in the high-stake domains like finance, healthcare,
    legal etc., also heavily rely on data organized in tabular format. Here are some
    examples:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融、医疗、法律等高风险领域，许多关键的应用案例也严重依赖以表格形式组织的数据。以下是一些例子：
- en: Consider a hospital trying to figure out the likelihood of a patient recovering
    well after a certain treatment. They might use tables of patient data, including
    factors like age, previous health issues, and treatment details. If the models
    used are too complex or “black-box,” doctors may have a hard time trusting or
    understanding the predictions.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设想一个医院试图判断某个病人在接受某种治疗后康复的可能性。医院可能会使用包含患者数据的表格，数据可能包括年龄、以往的健康问题和治疗详情等因素。如果使用的模型过于复杂或是“黑箱模型”，医生可能很难信任或理解预测结果。
- en: Similarly, in the financial world, banks analyze various factors in tables to
    decide if someone is eligible for a loan and what interest rate to offer. If the
    models they use are too complex, it becomes challenging to explain to customers
    why a decision was made, potentially leading to a lack of trust in the system.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，在金融领域，银行会分析表格中的各种因素来决定一个人是否符合贷款资格以及应该提供什么样的利率。如果使用的模型过于复杂，那么就很难向客户解释为何作出某个决策，这可能导致客户对系统失去信任。
- en: In the real world, many critical decision-making tasks like diagnosing illnesses
    from medical tests, approving loans based on financial statements, optimizing
    investments according to risk profiles on robo-advisors, identifying fake profiles
    on social media, and targeting the right audience for tailored advertisements
    all involve making decisions from tabular data. While deep neural networks, such
    as convolutional neural networks and transformer models like GPT, excel in grasping
    unstructured inputs like images, text, and voice, Tree Ensemble models like XGBoost
    still remain the unmatched champions for handling tabular data. This might be
    surprising in the era of deep neural networks, but it is true! Deep Models for
    tabular data like [TabTansformer](https://arxiv.org/abs/2012.06678), [TabNet](https://arxiv.org/abs/1908.07442)
    etc., only perform as good as XGBoost models, though they use lot more parameters.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，许多关键的决策任务，如通过医学检测诊断疾病、根据财务报表批准贷款、根据风险概况优化投资、在社交媒体上识别虚假个人资料以及为定制广告定位合适的受众，都涉及从表格数据中做出决策。尽管深度神经网络（如卷积神经网络和像
    GPT 这样的变换器模型）擅长处理图像、文本和语音等非结构化输入，但像 XGBoost 这样的树集成模型仍然是处理表格数据的无可匹敌的冠军。这可能在深度神经网络时代让人感到惊讶，但它确实是事实！用于表格数据的深度模型，如
    [TabTransformer](https://arxiv.org/abs/2012.06678)、[TabNet](https://arxiv.org/abs/1908.07442)
    等，表现与 XGBoost 模型相当，尽管它们使用了更多的参数。
- en: Explaining XGBoost models on Tabular Data
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释 XGBoost 模型在表格数据中的应用
- en: In this blog post, we take up explaining the binary classification decisions
    made by an XGBoost model. An intuitive approach to explain such models is by using
    human understandable rules. For instance, consider a model deciding whether a
    user account is that of a robot. If the model labels a user as “robot,” an interpretable
    explanation based on model features might be that the "number of connections with
    other robots ≥ 100 and number of API calls per day ≥ 10k".
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们将解释 XGBoost 模型所做的二元分类决策。解释这类模型的一种直观方法是使用人类可以理解的规则。例如，考虑一个模型用来判断一个用户账户是否属于机器人。如果模型将一个用户标记为“机器人”，那么基于模型特征的可解释性说明可能是“与其他机器人的连接数量
    ≥ 100 且每日 API 调用次数 ≥ 10k”。
- en: '[TE2Rules](https://arxiv.org/abs/2206.14359)is an algorithm designed exactly
    for this purpose. TE2Rules stands for Tree Ensembles to Rules, and its primary
    function is to explain any binary classification-oriented tree ensemble model
    by generating rules derived from combinations of input features. This algorithm
    combines decision paths extracted from multiple trees within the XGBoost Model,
    using a subset of unlabeled data. The data used for extracting rules from the
    XGBoost model need not be same as the training data and does not require any ground
    truth labels. The algorithm uses this data to uncover implicit correlations present
    in the dataset. Notably, the rules extracted by TE2Rules exhibit a high precision
    against the model predictions (with a default of 95%). The algorithm systematically
    identifies all potential rules from the XGBoost model to explain the positive
    instances and subsequently condenses them into a concise set of rules that effectively
    cover the majority of positive cases in the data. This condensed set of rules
    serves as a comprehensive global explainer for the model. Additionally, TE2Rules
    retains the longer set of all conceivable rules, which can be employed to explain
    specific instances through the use of succinct rules.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[TE2Rules](https://arxiv.org/abs/2206.14359)是专门为此目的设计的算法。TE2Rules代表树集成到规则（Tree
    Ensembles to Rules），其主要功能是通过生成从输入特征组合中衍生的规则，来解释任何面向二分类的树集成模型。该算法结合了从XGBoost模型中的多棵树提取的决策路径，使用的是未标记数据的子集。从XGBoost模型中提取规则所使用的数据不必与训练数据相同，也不需要任何真实标签。该算法利用这些数据揭示数据集中隐含的相关性。值得注意的是，TE2Rules提取的规则在模型预测中具有很高的精度（默认值为95%）。该算法系统地识别出XGBoost模型中的所有潜在规则，以解释正例实例，并随后将其浓缩为一组简明的规则，能够有效地覆盖数据中的大多数正例。这组简化的规则作为模型的全面全局解释器。此外，TE2Rules保留了所有可能规则的较长规则集，可以通过使用简洁规则来解释特定实例。'
- en: 'Demo: Show and Tell'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 演示：展示与讲解
- en: 'TE2Rules has demonstrated its effectiveness in various medical domains by providing
    insights into the decision-making process of models. Here are a few instances:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: TE2Rules通过提供模型决策过程的洞见，展示了其在各个医学领域的有效性。以下是一些实例：
- en: 'Multiple Sclerosis: [An Explainable AI model in the assessment of Multiple
    Sclerosis using clinical data and Brain MRI lesion texture features](https://ieeexplore.ieee.org/abstract/document/10313379)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多发性硬化症： [使用临床数据和脑部MRI病变纹理特征评估多发性硬化症的可解释AI模型](https://ieeexplore.ieee.org/abstract/document/10313379)
- en: 'Depression: [Using Machine Learning to identify profiles of individuals with
    depression](https://sol.sbc.org.br/index.php/kdmile/article/view/25576)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抑郁症：[使用机器学习识别抑郁症个体的特征](https://sol.sbc.org.br/index.php/kdmile/article/view/25576)
- en: 'In this section, we show how we can use TE2Rules to explain a model trained
    to predict whether an individual’s income exceeds $50,000\. The model is trained
    using [Adult Income Dataset](https://archive.ics.uci.edu/dataset/2/adult) from
    UCI Repository. The Jupyter notebook used in this blog is available here: [XGBoost-Model-Explanation-Demo](https://github.com/groshanlal/XGBoost-Model-Explanation-Demo).
    The dataset is covered by CC BY 4.0 license, permitting both academic and commercial
    use.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了如何使用TE2Rules解释一个预测个人收入是否超过50,000美元的模型。该模型使用了来自UCI库的[成人收入数据集](https://archive.ics.uci.edu/dataset/2/adult)进行训练。此博客中使用的Jupyter笔记本可以在此处获取：[XGBoost-Model-Explanation-Demo](https://github.com/groshanlal/XGBoost-Model-Explanation-Demo)。该数据集受CC
    BY 4.0许可协议保护，允许学术和商业用途。
- en: 'Step 1: Train the XGBoost model'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤1：训练XGBoost模型
- en: '![](../Images/6a1348e8c92cf549cb9eb29043d485d9.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a1348e8c92cf549cb9eb29043d485d9.png)'
- en: We train a XGBoost model with 50 trees each of depth 3 on Adult Income dataset.
    We note that the XGBoost Model, once trained, exhibits an accuracy of approximately
    86% and an AUC of 0.91 in both the training and testing datasets. This demonstrates
    the model’s effective training and its ability to generalize well across the test
    data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在成人收入数据集上训练了一个具有50棵深度为3的树的XGBoost模型。我们注意到，训练完成后，XGBoost模型在训练和测试数据集上的准确率约为86%，AUC为0.91。这证明了模型的有效训练及其在测试数据上良好的泛化能力。
- en: 'Step 2: Explain the model using TE2Rules'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤2：使用TE2Rules解释模型
- en: '![](../Images/b594c7076834270f8d7fa9a8a4d4fe0f.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b594c7076834270f8d7fa9a8a4d4fe0f.png)'
- en: Using TE2Rules, we derive rules from the trained XGBoost model. To guide TE2Rules
    in generating explanation rules, we employ 10% of the training data. Notably,
    TE2Rules identifies a total of 1138 rules, where each rule, when met, ensures
    a positive prediction from the model. For enhanced usability, TE2Rules consolidates
    these rules into a concise set of 16 rules, effectively explaining the model with
    50 trees, each having a depth of 3.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TE2Rules，我们从训练好的XGBoost模型中推导出规则。为了引导TE2Rules生成解释规则，我们使用了10%的训练数据。值得注意的是，TE2Rules总共识别出1138条规则，其中每条规则在满足时确保模型的正类预测。为了提高可用性，TE2Rules将这些规则整合为一组简洁的16条规则，有效地用50棵树（每棵树的深度为3）解释模型。
- en: 'Here are the 16 rules that explain the model entirely:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是完整解释该模型的16条规则：
- en: '![](../Images/1974b25efde23d30f3b59caa5e0200e7.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1974b25efde23d30f3b59caa5e0200e7.png)'
- en: Each of these rule has a precision of more than 95%. The rules are arranged
    in decreasing order of support in the data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每条规则的精度超过95%。这些规则按在数据中的支持度降序排列。
- en: 'Step 3: Explain specific input using TE2Rules'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步：使用TE2Rules解释特定输入
- en: '![](../Images/882135baffdc5a88a8f67d17d9fe0200.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/882135baffdc5a88a8f67d17d9fe0200.png)'
- en: Using TE2Rules, we explain a specific positive instance by collecting all rules
    from the 1138 rules that are satisfied by the input and hence can explain the
    positive instance. Among these rules, we select the most interpretable rule using
    a custom logic to rank the possible explanations and choosing the most interpretable
    rule among the explanations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TE2Rules，我们通过收集所有满足输入的1138条规则来解释一个特定的正类实例，从而解释该正类实例。在这些规则中，我们使用自定义逻辑对可能的解释进行排序，并选择最易理解的规则作为解释。
- en: 'Interpretability is highly subjective and can vary from one use case to another.
    In this example, we use the number of features used in a rule as a measure of
    interpretability of the rule. We choose the rule formed using the least number
    of features as the most interpretable explanation. Here is an example input with
    positive model prediction and an explanation behind the prediction generated by
    TE2Rules:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性是高度主观的，因使用场景的不同而有所不同。在本示例中，我们使用规则中所使用特征的数量作为该规则可解释性的衡量标准。我们选择使用最少特征的规则作为最易理解的解释。以下是一个正类模型预测的示例输入，以及TE2Rules生成的关于该预测的解释：
- en: '![](../Images/64031e557e745d25e4b29d7134210ac8.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64031e557e745d25e4b29d7134210ac8.png)'
- en: 'We note that in the above example, the model classified the input with 12 features
    to be a positive. TE2Rules explains this prediction with a rule with just 3 features:
    “capital_gain > 543 and education = Professional School and occupation != managerial”.
    Any other input that satisfies this rule (from the same data distribution) is
    guaranteed to be classified as positive by the model with probability > 95%.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，在上面的示例中，模型使用12个特征将输入分类为正类。TE2Rules通过一个只包含3个特征的规则来解释这一预测：“capital_gain
    > 543 且 education = 专业学校 且 occupation != 管理职位”。任何其他满足此规则的输入（来自相同的数据分布）都可以确保模型以超过95%的概率将其分类为正类。
- en: 'Step 4: Counterfactual Explanations using TE2Rules'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步：使用TE2Rules进行反事实解释
- en: TE2Rules extracts rules that, when fulfilled, lead to a positive prediction
    by the model. These rules can be used for pinpointing the minimal alterations
    required in a negatively classified input to ensure that the model classifies
    it as positive. Consequently, TE2Rules proves valuable in generating counterfactual
    explanations, represented as rules specifying the conditions necessary for transforming
    a negative instance into a positive one.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: TE2Rules提取出满足时能导致模型作出正类预测的规则。这些规则可以用来指出需要对负类分类输入进行的最小修改，以确保模型将其分类为正类。因此，TE2Rules在生成反事实解释时非常有价值，反事实解释以规则的形式呈现，指定将负实例转化为正实例所需的条件。
- en: Similar to the previous scenario, the acceptable minimal change varies depending
    on the context. In this example, certain features such as age, relationship status,
    and gender are deemed unalterable, while other features like education, occupation,
    and capital gain/loss are considered changeable. For any negative instance, we
    pinpoint a single feature among those deemed changeable, demonstrating the adjustment
    needed to prompt the model to score the instance positively.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一个场景类似，可接受的最小修改因上下文而异。在本示例中，某些特征（如年龄、关系状态和性别）被视为不可改变，而其他特征（如教育、职业和资本收益/损失）则被视为可改变的。对于任何负类实例，我们指出在这些可改变特征中单一的特征，展示所需的调整，以促使模型将该实例评分为正类。
- en: '![](../Images/f5f01524737d20b0bd8ede79ca1395dd.png)![](../Images/ff4c72f2a1476e5bf6be1dca49e7ddc3.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5f01524737d20b0bd8ede79ca1395dd.png)![](../Images/ff4c72f2a1476e5bf6be1dca49e7ddc3.png)'
- en: We note that in the above example, the model classified the input to be a negative.
    TE2Rules identifies 5 different rules such that satisfying any one of these 5
    rules is sufficient for the model to flip its prediction from negative to positive.
    Getting a different education like Professional School, Masters or Doctorate or
    getting more capital gains can help the individual make more money. However, it
    is surprising that the model has learnt that this individual would be rich even
    with high capital loss! This might be because such a change would result in a
    data sample that is very different from the data distribution of the training
    data, making the model not so reliable in such cases.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，在上述示例中，模型将输入分类为负面。TE2Rules识别出5条不同的规则，只要满足其中任何一条规则，就足以使模型将预测从负面转为正面。接受不同教育背景，如职业学校、硕士或博士学位，或获得更多资本收益，都有助于个人赚取更多的钱。然而，令人惊讶的是，模型已经学会了即使资本损失很大，这个人仍然会变得富有！这可能是因为这样的变化会导致数据样本与训练数据的分布差异很大，使得模型在这种情况下的可靠性降低。
- en: Conclusion
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Explainability is vital for developing trust in AI models, particularly in high-stakes
    scenarios where model decisions can profoundly impact people’s lives, such as
    in healthcare, legal, and finance. Many of these critical use cases involve making
    decisions based on data organized in tabular formats. XGBoost tends to be the
    most poular choice of AI model on tabular data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性对于建立对AI模型的信任至关重要，特别是在高风险场景中，模型的决策可能对人们的生活产生深远影响，比如在医疗、法律和金融领域。许多这些关键的应用场景都涉及基于表格格式的数据做出决策。XGBoost通常是表格数据中最受欢迎的AI模型选择。
- en: TE2Rules emerges as a versatile tool for explaining XGBoost models. TE2Rules
    has already gained traction in medical domains and is gradually gaining popularity
    in other fields as well. In this blog, we present a demonstration of how TE2Rules
    can effectively explain “Why did my model say that?”
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: TE2Rules作为一种多功能工具，用于解释XGBoost模型。TE2Rules在医学领域已经获得了广泛关注，并且逐渐在其他领域也开始受到欢迎。在这篇博客中，我们展示了TE2Rules如何有效地解释“为什么我的模型会这么说？”
- en: As an open-source research project co-created by the author, the source code
    of TE2Rules can be found at [[https://github.com/linkedin/TE2Rules](https://github.com/linkedin/TE2Rules)].
    Users are encouraged to integrate TE2Rules into their explainability projects.
    If you find TE2Rules useful for your projects, express your support by starring
    the repository. If any issues arise during the usage of TE2Rules, reach out to
    us at [[https://github.com/linkedin/TE2Rules/issues](https://github.com/linkedin/TE2Rules/issues)]
    and we will do our best to address your issues.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个由作者共同创建的开源研究项目，TE2Rules的源代码可以在[[https://github.com/linkedin/TE2Rules](https://github.com/linkedin/TE2Rules)]找到。我们鼓励用户将TE2Rules集成到他们的可解释性项目中。如果你发现TE2Rules对你的项目有帮助，请通过给仓库加星来表达支持。如果在使用TE2Rules过程中遇到任何问题，请通过[[https://github.com/linkedin/TE2Rules/issues](https://github.com/linkedin/TE2Rules/issues)]联系我们，我们会尽力解决你的问题。
