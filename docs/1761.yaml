- en: Asynchronous Machine Learning Inference with Celery, Redis, and Florence 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Celery、Redis和Florence 2进行异步机器学习推理
- en: 原文：[https://towardsdatascience.com/asynchronous-machine-learning-inference-with-celery-redis-and-florence-2-be18ebc0fbab?source=collection_archive---------3-----------------------#2024-07-19](https://towardsdatascience.com/asynchronous-machine-learning-inference-with-celery-redis-and-florence-2-be18ebc0fbab?source=collection_archive---------3-----------------------#2024-07-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/asynchronous-machine-learning-inference-with-celery-redis-and-florence-2-be18ebc0fbab?source=collection_archive---------3-----------------------#2024-07-19](https://towardsdatascience.com/asynchronous-machine-learning-inference-with-celery-redis-and-florence-2-be18ebc0fbab?source=collection_archive---------3-----------------------#2024-07-19)
- en: A simple tutorial to get you started on asynchronous ML inference
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一份简单的教程，帮助你入门异步机器学习推理
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)
    ·6 min read·Jul 19, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)
    ·阅读时间6分钟·2024年7月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/573d6ccd2ee339c929f687cba908cbf9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/573d6ccd2ee339c929f687cba908cbf9.png)'
- en: Photo by [Fabien BELLANGER](https://unsplash.com/@fabbel78?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Fabien BELLANGER](https://unsplash.com/@fabbel78?utm_source=medium&utm_medium=referral)
    提供，来源：[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Most machine learning serving tutorials focus on real-time synchronous serving,
    which allows for immediate responses to prediction requests. However, this approach
    can struggle with surges in traffic and is not ideal for long-running tasks. It
    also requires more powerful machines to respond quickly, and if the client or
    server fails, the prediction result is usually lost.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习服务教程都专注于实时同步服务，这种方式可以即时响应预测请求。然而，这种方法在面对流量激增时可能会遇到困难，并且不适合长时间运行的任务。它还需要更强大的机器来快速响应，如果客户端或服务器发生故障，预测结果通常会丢失。
- en: In this blog post, we will demonstrate how to run a machine learning model as
    an asynchronous worker using Celery and Redis. We will be using the Florence 2
    base model, a Vision language model known for its impressive performance. This
    tutorial will provide a minimal yet functional example that you can adapt and
    extend for your own use cases.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将演示如何使用Celery和Redis将机器学习模型作为异步工作者运行。我们将使用Florence 2基础模型，这是一个以其卓越表现而闻名的视觉语言模型。本教程将提供一个最小但功能完善的示例，您可以根据自己的用例进行调整和扩展。
- en: The core of our solution is based on Celery, a Python library that implements
    this client/worker logic for us. It allows us to distribute the compute work across
    many workers, improving the scalability of your ML inference use case to high
    and unpredictable loads.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决方案的核心基于Celery，这是一个Python库，它为我们实现了这种客户端/工作者逻辑。它允许我们将计算任务分配到多个工作者，提高机器学习推理应用在高负载和不可预测负载下的可扩展性。
- en: 'The process works as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程如下所示：
- en: The client submits a task with some parameters to a queue managed by the broker
    (Redis in our example).
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端将任务及一些参数提交到由中介（我们示例中是Redis）管理的队列中。
