- en: Asynchronous Machine Learning Inference with Celery, Redis, and Florence 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/asynchronous-machine-learning-inference-with-celery-redis-and-florence-2-be18ebc0fbab?source=collection_archive---------3-----------------------#2024-07-19](https://towardsdatascience.com/asynchronous-machine-learning-inference-with-celery-redis-and-florence-2-be18ebc0fbab?source=collection_archive---------3-----------------------#2024-07-19)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A simple tutorial to get you started on asynchronous ML inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--be18ebc0fbab--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--be18ebc0fbab--------------------------------)
    ·6 min read·Jul 19, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/573d6ccd2ee339c929f687cba908cbf9.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Fabien BELLANGER](https://unsplash.com/@fabbel78?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Most machine learning serving tutorials focus on real-time synchronous serving,
    which allows for immediate responses to prediction requests. However, this approach
    can struggle with surges in traffic and is not ideal for long-running tasks. It
    also requires more powerful machines to respond quickly, and if the client or
    server fails, the prediction result is usually lost.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog post, we will demonstrate how to run a machine learning model as
    an asynchronous worker using Celery and Redis. We will be using the Florence 2
    base model, a Vision language model known for its impressive performance. This
    tutorial will provide a minimal yet functional example that you can adapt and
    extend for your own use cases.
  prefs: []
  type: TYPE_NORMAL
- en: The core of our solution is based on Celery, a Python library that implements
    this client/worker logic for us. It allows us to distribute the compute work across
    many workers, improving the scalability of your ML inference use case to high
    and unpredictable loads.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The client submits a task with some parameters to a queue managed by the broker
    (Redis in our example).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
