# 如何为神经网络的输出编码约束

> 原文：[https://towardsdatascience.com/how-to-encode-constraints-to-the-output-of-neural-networks-9bce302b9687?source=collection_archive---------2-----------------------#2024-04-14](https://towardsdatascience.com/how-to-encode-constraints-to-the-output-of-neural-networks-9bce302b9687?source=collection_archive---------2-----------------------#2024-04-14)

## 可用方法总结

[](https://medium.com/@runzhong.wang1?source=post_page---byline--9bce302b9687--------------------------------)[![Runzhong Wang](../Images/964d8ff22734d69fea6bb7256fe5d84d.png)](https://medium.com/@runzhong.wang1?source=post_page---byline--9bce302b9687--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9bce302b9687--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9bce302b9687--------------------------------) [Runzhong Wang](https://medium.com/@runzhong.wang1?source=post_page---byline--9bce302b9687--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9bce302b9687--------------------------------) ·12分钟阅读·2024年4月14日

--

![](../Images/5e6583bd3bcbd023d68ee777d90bee66.png)

图片由ChatGPT根据本文内容生成。

神经网络确实非常强大。然而，随着神经网络应用范围从“标准”的分类和回归任务扩展到更复杂的决策和科学AI，逐渐显现出一个缺点：神经网络的输出通常是没有约束的，或者更准确地说，通常仅受简单的0-1范围（Sigmoid激活函数）、非负约束（ReLU激活函数）或加和为1的约束（Softmax激活函数）限制。这些“标准”激活层曾用于处理分类和回归问题，并见证了深度学习的蓬勃发展。然而，随着神经网络开始广泛应用于决策、优化求解以及其他复杂的科学问题，这些“标准”激活层显然已经不再足够。本文将简要讨论当前可以为神经网络的输出添加约束的现有方法，并包含一些个人见解。欢迎批评和讨论相关话题。

[[中文版本(知乎)]](https://zhuanlan.zhihu.com/p/667124121)

# 如果一次不行，尝试多次

如果你熟悉强化学习，你可能已经知道我在说什么。将约束应用于一个n维向量看似困难，但你可以将n维向量分解为n个输出。每次生成一个输出时，你可以手动编写代码，限制下一个变量的行动空间，以确保其值保持在一个可行的范围内。这种所谓的“自回归”方法有明显的优势：它简单并且能够处理各种约束（只要你能编写代码）。然而，它的缺点也很明显：一个n维向量需要进行n次网络前向计算调用，这效率较低；此外，这种方法通常需要建模为马尔可夫决策过程（MDP）并通过强化学习进行训练，因此强化学习中的常见挑战，如庞大的行动空间、稀疏奖励函数和长时间训练，也难以避免。

在使用神经网络解决组合优化问题的领域，自回归方法结合强化学习曾是主流，但目前正在被更高效的方法所取代。

# 或许…我们来学习一下约束条件吧？

在训练过程中，可以向目标函数中添加惩罚项，表示当前神经网络输出违反约束的程度。在传统的优化领域，拉格朗日对偶法也提供了类似的技巧。不幸的是，当应用到神经网络时，这些方法迄今为止只在一些简单的约束下得到了验证，目前尚不清楚它们是否适用于更复杂的约束。一个缺点是，模型的部分能力不得不用于学习如何满足相应的约束，从而限制了模型在其他方向（如优化求解）上的能力。

例如，[*Karalias和Loukas，NeurIPS’21“Erdo˝s Goes Neural: 一个无监督学习框架用于图上的组合优化”*](https://proceedings.neurips.cc/paper/2020/file/49f85a9ed090b20c8bed85a5923c669f-Paper.pdf)展示了所谓的“盒约束”，即变量值位于[a, b]之间，可以通过惩罚项学习，网络能够解决一些相对简单的组合优化问题。然而，我们的进一步研究发现，这种方法缺乏泛化能力。在训练集上，神经网络能够很好地维持约束；但是在测试集上，约束几乎完全丧失。此外，尽管在理论上添加惩罚项可以适用于任何约束，但它无法处理更复杂的约束。我们的论文[*Wang等，ICLR’23“朝向一次性神经组合优化求解器：基于基数约束的理论与实证分析”*](https://openreview.net/pdf?id=h21yJhdzbwz)讨论了上述现象并提供了理论分析。

另一方面，生成模型的设计理念要求输出符合特定分布，这似乎更适合“学习约束”方法。[*Sun和Yang, NeurIPS’23 “DIFUSCO: 基于图的扩散求解器用于组合优化”*](https://proceedings.neurips.cc/paper_files/paper/2023/file/0ba520d93c3df592c83a611961314c98-Paper-Conference.pdf)表明，扩散模型可以输出满足旅行商问题约束的解（即，能够输出完整的路径）。我们进一步展示了[*Li等人, NeurIPS’23 “T2T: 从训练中的分布学习到测试中的梯度搜索，用于组合优化”*](https://proceedings.neurips.cc/paper_files/paper/2023/file/0ba520d93c3df592c83a611961314c98-Paper-Conference.pdf)，其中生成模型（扩散模型）负责满足约束，另一个优化器则在扩散的逐步去噪过程中提供优化指导。这个策略在实验中表现得相当好，超越了所有之前的神经网络求解器。

# 另一个有趣的视角：求解一个凸优化问题

也许你担心自回归模型效率过低，而生成模型可能无法解决你的问题。你可能在考虑一个只进行一次前向传播的神经网络，而输出需要满足给定的约束——这可能吗？

答案是肯定的。我们可以求解一个凸优化问题，将神经网络的输出投影到由凸约束界定的可行域中。这种方法利用了凸优化问题在其KKT条件下可微的特性，因此这个投影步骤可以视为一个激活层，嵌入到端到端的神经网络中。这种方法由Zico Kolter的团队在CMU提出并推广，他们目前提供了[cvxpylayers包](https://github.com/cvxgrp/cvxpylayers)来简化实现步骤。相应的凸优化问题是

其中**y**是无约束的神经网络输出，**x**是有约束的神经网络输出。因为这一步的目的是仅仅进行投影，所以线性目标函数可以实现这一点（添加熵正则化也是合理的）。**Ax** ≤ **b**是你需要施加的线性约束，也可以是二次或其他凸约束。

这是个人的备注：似乎有一些[已知问题](https://github.com/cvxgrp/cvxpylayers/issues/147)，并且这个仓库似乎很长时间没有更新/维护了（04/2024）。如果有人愿意调查一下发生了什么，我将非常感激。

# 对于非凸问题：你更倾向于使用哪种梯度近似方法？

使用KKT条件推导梯度在理论上是可行的，但它无法解决非凸或不连续问题。事实上，对于不连续问题，当问题参数的变化导致解跳跃时，真实的梯度变成了一个δ函数（即在跳跃处无穷大），显然不能在神经网络训练中使用。幸运的是，有一些梯度近似方法可以解决这个问题。

马克斯·普朗克研究所的Georg Martius小组提出了一种黑箱近似方法[*Vlastelica 等人，ICLR 2020 “黑箱组合求解器的微分”*](https://openreview.net/pdf?id=BkevoJSYPB)，将求解器视为黑箱。它首先调用一次求解器，然后沿特定方向扰动问题参数，再次调用求解器。两次求解器调用的输出之间的残差作为近似梯度。如果将这种方法应用于神经网络的输出以强制执行约束，我们可以定义一个线性目标函数的优化问题：

其中**y**是未约束的神经网络输出，**x**是受约束的神经网络输出。你的下一步是实现一个算法来解决上述问题（不一定是最优的），然后可以将其集成到黑箱近似框架中。黑箱近似方法的一个缺点是它只能处理线性目标函数，但线性目标函数恰好在你寻找强制约束的方法时起作用；此外，由于它只是一个梯度近似方法，如果超参数没有调得很好，可能会遇到稀疏梯度和收敛问题。

另一种近似梯度的方法是使用大量随机噪声扰动，反复调用求解器来估计梯度，正如在[*Berthet 等人，NeurIPS 2020 “使用可微扰动优化器进行学习”*](https://papers.nips.cc/paper/2020/file/6bb56208f672af0dd65451f869fedfd9-Paper.pdf)中讨论的那样。从理论上讲，通过这种方式获得的梯度应该与通过LinSAT方法获得的梯度类似（将在下一节讨论），即一个熵正则化线性目标函数的梯度；然而，实际上，这种方法需要大量的随机样本，这在我的使用案例中有点不切实际。

# 自我推销时间：在不解决优化问题的情况下进行投影

无论是从KKT条件推导凸问题的梯度，还是近似非凸方法的梯度，都需要调用/编写求解器，因此CPU-GPU通信可能成为瓶颈，因为大多数求解器通常是为CPU设计和实现的。是否有一种方法可以像激活层一样直接在GPU上投影特定的约束，而不显式地解决优化问题？

答案是肯定的，我们的 [*Wang 等人, ICML'2023 “LinSATNet: 正线性可满足性神经网络”*](https://proceedings.mlr.press/v202/wang23at/wang23at.pdf) 论文提供了一条可行的路径，并推导了该算法的收敛性质。LinSAT 代表 **Lin**ear **SAT**isfiability Network（线性可满足性网络）。

LinSAT 可以看作是一个激活层，使您能够对神经网络的输出应用一般的正线性约束。

![](../Images/103e965ed6105a4a11aafc4e1a58ac6c.png)

图片由作者提供

LinSAT 层是完全可微的，真实的梯度通过自动求导计算，就像其他激活层一样。我们的实现现在支持 PyTorch。

您可以通过以下方式安装：

```py
pip install linsatnet
```

并开始使用

```py
from LinSATNet import linsat_layer
```

# 一个简单的示例

如果您下载并运行源代码，您会发现一个简单的示例。在这个示例中，我们对一个 3×3 的矩阵施加了双重随机约束。

要运行示例，首先克隆仓库：

```py
git clone https://github.com/Thinklab-SJTU/LinSATNet.git
```

进入仓库并运行示例代码：

```py
cd LinSATNet
python LinSATNet/linsat.py
```

在这个示例中，我们尝试对一个 3×3 的矩阵施加双重随机约束。双重随机约束意味着矩阵的所有行和列的和都应为 1。

3x3 矩阵被展平为一个向量，然后考虑以下正线性约束（对于 **Ex**=**f**）：

```py
E = torch.tensor(
    [[1, 1, 1, 0, 0, 0, 0, 0, 0],
     [0, 0, 0, 1, 1, 1, 0, 0, 0],
     [0, 0, 0, 0, 0, 0, 1, 1, 1],
     [1, 0, 0, 1, 0, 0, 1, 0, 0],
     [0, 1, 0, 0, 1, 0, 0, 1, 0],
     [0, 0, 1, 0, 0, 1, 0, 0, 1]], dtype=torch.float32
)
f = torch.tensor([1, 1, 1, 1, 1, 1], dtype=torch.float32)
```

我们随机初始化 **w**，并将其视为某些神经网络的输出：

```py
w = torch.rand(9) # w could be the output of neural network
w = w.requires_grad_(True)
```

我们还有一个“真实目标”，它是 linsat_layer 输出的目标，在这个示例中，它是一个对角矩阵：

```py
x_gt = torch.tensor(
    [1, 0, 0,
     0, 1, 0,
     0, 0, 1], dtype=torch.float32
)
```

LinSAT 的前向/反向传播遵循标准的 PyTorch 风格，可以轻松集成到现有的深度学习管道中。

前向传播：

```py
linsat_outp = linsat_layer(w, E=E, f=f, tau=0.1, max_iter=10, dummy_val=0)
```

反向传播：

```py
loss = ((linsat_outp — x_gt) ** 2).sum()
loss.backward()
```

您还可以将 E 设置为稀疏矩阵，以提高时间和内存效率（尤其是对于大尺寸输入）。以下是一个简单的示例（建议为了最佳效率构造稀疏形式的 E）：

```py
linsat_outp = linsat_layer(w, E=E.to_sparse(), f=f, tau=0.1, max_iter=10, dummy_val=0)
```

我们还可以对 w 进行基于梯度的优化，使得 linsat_layer 的输出更接近 x_gt。这就是您训练时发生的情况。

神经网络。

```py
niters = 10
opt = torch.optim.SGD([w], lr=0.1, momentum=0.9)
for i in range(niters):
 x = linsat_layer(w, E=E, f=f, tau=0.1, max_iter=10, dummy_val=0)
 cv = torch.matmul(E, x.t()).t() — f.unsqueeze(0)
 loss = ((x — x_gt) ** 2).sum()
 loss.backward()
 opt.step()
 opt.zero_grad()
 print(f’{i}/{niters}\n’
 f’ underlying obj={torch.sum(w * x)},\n’
 f’ loss={loss},\n’
 f’ sum(constraint violation)={torch.sum(cv[cv > 0])},\n’
 f’ x={x},\n’
 f’ constraint violation={cv}’)
```

在训练过程中，您可能会看到损失值逐步减小。

有关完整的 API 参考，请查看 [GitHub 仓库](https://github.com/Thinklab-SJTU/LinSATNet?tab=readme-ov-file#api-reference)。

# LinSAT 是如何工作的？

警告，接下来有大量数学内容！如果您只是使用 LinSAT，您可以安全跳过这一部分。

> 如果您想了解更多细节和证明，请参阅 [主论文](https://proceedings.mlr.press/v202/wang23at/wang23at.pdf)。

在这里，我们介绍 LinSAT 内部的机制。它通过将 Sinkhorn 算法扩展到多个集合的边际来工作（据我们所知，我们是第一个研究具有多集合边际的 Sinkhorn 算法的人）。然后，通过将约束转化为边际，来强制执行正线性约束。

## 经典 Sinkhorn 单集边际

让我们从经典的Sinkhorn算法开始。给定一个大小为*m×n*的非负评分矩阵**S**，以及一组行（大小为*m*的非负向量**v**）和列（大小为*n*的非负向量**u**）的边际分布，其中：

Sinkhorn算法输出一个标准化矩阵Γ，大小为*m×n*，值域在[0,1]之间，因此

从概念上讲，Γᵢ ⱼ表示**比例**，即从*u*ⱼ移动到*v*ᵢ的部分。

算法步骤如下：

> 注意，上述公式是对传统Sinkhorn公式的修改。Γᵢ ⱼ uⱼ等价于“运输”矩阵中的元素，如[(Cuturi 2013)](https://arxiv.org/pdf/1306.0895v1.pdf)等论文所示。我们更倾向于采用这种新的公式，因为它能够平滑地扩展到以下带有多集边际分布的Sinkhorn算法。
> 
> 为了更清晰的对比，[(Cuturi 2013)](https://arxiv.org/pdf/1306.0895v1.pdf)中的运输矩阵是**P**，大小为m×n，约束条件为：
> 
> Pᵢ ⱼ表示从uⱼ到vᵢ移动的**精确质量**。
> 
> 算法步骤如下：

## 扩展Sinkhorn算法与多集边际分布

我们发现Sinkhorn算法可以推广到多个边际分布集。回顾一下，Γᵢ ⱼ ∈ [0,1]表示从*u*ⱼ移动到*v*ᵢ的比例。有趣的是，如果我们简单地将**u**、**v**替换为另一个边际分布集，得到的公式是相同的，这表明Sinkhorn算法有潜力扩展到多个边际分布集。设有*k*个边际分布集，这些边际分布集被联合施加约束以适应更复杂的现实场景。这些边际分布集为：

然后我们得到：

假设存在一个标准化的**Z** ∈ [0,1]，大小为*m×n*，使得：

即，多个边际分布集有一个非空的可行区域（你可以在阅读下一节关于如何处理正线性约束时理解“非空可行区域”的含义）。通过遍历Sinkhorn迭代来联合执行多个边际分布集的约束，多个边际分布集可以共同施加约束。算法步骤如下：

在[我们的论文](https://proceedings.mlr.press/v202/wang23at/wang23at.pdf)中，我们证明了多集边际分布的Sinkhorn算法与经典Sinkhorn算法具有相同的收敛模式，且其基础公式也与经典Sinkhorn相似。

## 将正线性约束转换为边际分布

然后我们展示如何将正线性约束转换为边际分布，这些边际分布由我们提出的多集Sinkhorn处理。

**编码神经网络的输出** 对于一个长度为*l*的向量**y**（它可以是神经网络的输出，也可以是**linsat_layer**的输入），构建以下矩阵：

其中**W**的大小为2 × (*l* + 1)，β是虚拟变量，默认值为β = 0。**y**位于**W**的左上区域。然后，施加熵正则化器以控制离散性并处理潜在的负输入：

得分矩阵 **S** 被作为 Sinkhorn 算法的输入来处理多集合边际。

**从线性约束到边际**

**1）打包约束** **Ax** ≤ **b**。假设只有一个约束，我们将其重写为

遵循 Sinkhorn 的“运输”视角，输出 **x** *最多移动* *b* 单位的质量，从 *a*₁*, a₂*, …, aₗ*，并且虚拟维度允许通过 *移动* 质量来实现不等式。还确保 **u***ₚ* 的总和等于 **v***ₚ* 的总和。边际分布被定义为

**2）覆盖约束** **Cx** ≥ **d**。假设只有一个约束，我们将其重写为

我们引入了乘数

因为我们总是有

（否则约束是不可行的），如果没有这个乘数，我们无法得到一个可行的解，其中所有 **x** 中的元素都是 1。我们的公式确保至少 *d* 单位的质量通过 **x** 从 c₁*, c₂*, …, cₗ* 被 *移动*，从而表示“大于”的覆盖约束。还确保 **u_**c 的总和等于 **v**_c 的总和。边际分布被定义为

**3）等式约束** **Ex** = **f**。表示等式约束更加直接。假设只有一个约束，我们将其重写为

输出 **x** *移动* e₁*, e₂*, …, eₗ* 到 *f*，我们在 **u**ₑ 中不需要虚拟元素，因为这是一个等式约束。还确保 **u**ₑ 的总和等于 **v**ₑ 的总和。边际分布被定义为

在对所有约束进行编码并将它们堆叠为多个边际集合后，我们可以调用 Sinkhorn 算法来处理多集合边际，从而编码约束。

## LinSAT 实验验证

在我们的 ICML 论文中，我们验证了 LinSATNet 方法在路由约束方面的有效性，超出了普通情况（用于解决旅行商问题的变体）、部分图匹配约束（用于仅有部分图匹配的图匹配问题）和一般线性约束（用于特定的偏好与投资组合优化）。所有这些问题都可以用正线性约束表示，并通过 LinSATNet 方法处理。在实验中，神经网络能够学习如何解决这三种问题。

需要注意的是，LinSATNet 方法只能处理**正线性约束**，这意味着它无法处理像 *x*₁ — *x*₂ ≤ 0 这样包含负项的约束。然而，正线性约束已经涵盖了大量的场景。对于每个具体问题，数学建模往往不是唯一的，在许多情况下，可以找到合理的正线性表达式。除了上述提到的示例外，让网络输出有机分子（表示为图，忽略氢原子，只考虑骨架结构）时，可以考虑像 C 原子最多有 4 个键，O 原子最多有 2 个键这样的约束。

# 后记

向神经网络添加约束具有广泛的应用场景，目前已有几种方法可供选择。需要注意的是，没有一个公认的标准来判断它们之间的优劣——最好的方法通常与特定场景相关。

当然，我推荐尝试 LinSATNet！反正它和网络中的激活层一样简单。

如果你觉得这篇文章对你有帮助，欢迎随时引用：

```py
@inproceedings{WangICML23,
  title={LinSATNet: The Positive Linear Satisfiability Neural Networks},
  author={Wang, Runzhong and Zhang, Yunhao and Guo, Ziao and Chen, Tianyi and Yang, Xiaokang and Yan, Junchi},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2023}
}
```

所有前述内容已经在本文中讨论过。
