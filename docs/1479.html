<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A Python Engineer’s Introduction to 3D Gaussian Splatting (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>A Python Engineer’s Introduction to 3D Gaussian Splatting (Part 2)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-python-engineers-introduction-to-3d-gaussian-splatting-part-2-7e45b270c1df?source=collection_archive---------1-----------------------#2024-06-13">https://towardsdatascience.com/a-python-engineers-introduction-to-3d-gaussian-splatting-part-2-7e45b270c1df?source=collection_archive---------1-----------------------#2024-06-13</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="6e04" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Understanding and coding how Gaussians are used within 3D Gaussian Splatting</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@dcaustin33?source=post_page---byline--7e45b270c1df--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Derek Austin" class="l ep by dd de cx" src="../Images/1bcc5955f32cb798988af5713baae212.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*jO7ooF0USlA22GWVFwKkEw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--7e45b270c1df--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@dcaustin33?source=post_page---byline--7e45b270c1df--------------------------------" rel="noopener follow">Derek Austin</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--7e45b270c1df--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 13, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="de43" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Now on to gaussians! Everyone’s favorite distribution. If you are just joining us, we have covered how to take a 3D point and translate it to 2D given the location of the camera in <a class="af ne" rel="noopener" target="_blank" href="/a-python-engineers-introduction-to-3d-gaussian-splatting-part-1-e133b0449fc6">part 1</a>. For this article we will be moving onto dealing with the gaussian part of gaussian splatting. We will be using part_2.ipynb in our <a class="af ne" href="https://github.com/dcaustin33/intro_to_gaussian_splatting" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p><p id="d944" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">One slight change that we will make here is that we are going to use perspective projection that utilizes a different internal matrix than the one shown in the previous article. However, the two are equivalent when projecting a point to 2D and I find the first method introduced in part 1 far easier to understand, however we change our method in order to replicate, in python, as much of the author’s code as possible. Specifically our “internal” matrix will now be given by the OpenGL projection matrix shown here and the order of multiplication will now be points @ external.transpose() @ internal.</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div class="nf ng nh"><img src="../Images/c4e5dbf74788f7bb266d014014d1529f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/0*-wP_ZwCSOMbzWKgL"/></div><figcaption class="np nq nr nf ng ns nt bf b bg z dx">Internal perspective projection matrix. Parameters are explained in paragraph below.</figcaption></figure><p id="f2e4" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">For those curious to know about this new internal matrix (otherwise feel free to skip this paragraph) r and l are the clipping planes of the right and left sides, essentially what points could be in view with regards to the width of the photo, and t and b are the top and bottom clipping planes. N is the near clipping plane (where points will be projected to) and f is the far clipping plane. For more information I have found scratchapixel’s chapters here to be quite informative (<a class="af ne" href="https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix.html" rel="noopener ugc nofollow" target="_blank">https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix.html</a>). This also returns the points in normalized device coordinates (between -1 and 1) and which we then project to pixel coordinates. Digression aside the task remains the same, take the point in 3D and project onto a 2D image plane. However, in this part of the tutorial we are now using gaussians instead of a points.</p><pre class="ni nj nk nl nm nu nv nw bp nx bb bk"><span id="b62c" class="ny nz fq nv b bg oa ob l oc od">def getIntinsicMatrix(<br/>    focal_x: torch.Tensor,<br/>    focal_y: torch.Tensor,<br/>    height: torch.Tensor,<br/>    width: torch.Tensor,<br/>    znear: torch.Tensor = torch.Tensor([100.0]),<br/>    zfar: torch.Tensor = torch.Tensor([0.001]),,<br/>) -&gt; torch.Tensor:<br/>    """<br/>    Gets the internal perspective projection matrix<br/>    <br/>    znear: near plane set by user<br/>    zfar: far plane set by user<br/>    fovX: field of view in x, calculated from the focal length<br/>    fovY: field of view in y, calculated from the focal length<br/>    """<br/>    fovX = torch.Tensor([2 * math.atan(width / (2 * focal_x))])<br/>    fovY = torch.Tensor([2 * math.atan(height / (2 * focal_y))])<br/>    <br/>    tanHalfFovY = math.tan((fovY / 2))<br/>    tanHalfFovX = math.tan((fovX / 2))<br/><br/>    top = tanHalfFovY * znear<br/>    bottom = -top<br/>    right = tanHalfFovX * znear<br/>    left = -right<br/><br/>    P = torch.zeros(4, 4)<br/><br/>    z_sign = 1.0<br/><br/>    P[0, 0] = 2.0 * znear / (right - left)<br/>    P[1, 1] = 2.0 * znear / (top - bottom)<br/>    P[0, 2] = (right + left) / (right - left)<br/>    P[1, 2] = (top + bottom) / (top - bottom)<br/>    P[3, 2] = z_sign<br/>    P[2, 2] = z_sign * zfar / (zfar - znear)<br/>    P[2, 3] = -(zfar * znear) / (zfar - znear)<br/>    return P</span></pre><p id="8e0c" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">A 3D gaussian splat consists of x, y, and z coordinates as well as the associated covariance matrix. As noted by the authors: “An obvious approach would be to directly optimize the covariance matrix Σ to obtain 3D gaussians that represent the radiance field. However, covariance matrices have physical meaning only when they are positive semi-definite. For our optimization of all our parameters, we use gradient descent that cannot be easily constrained to produce such valid matrices, and update steps and gradients can very easily create invalid covariance matrices.”¹</p><p id="e068" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Therefore, the authors use a decomposition of the covariance matrix that will always produce positive semi definite covariance matrices. In particular they use 3 “scale” parameters and 4 quaternions that are turned into a 3x3 rotation matrix (R). The covariance matrix is then given by</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div class="nf ng oe"><img src="../Images/43f0fb2a98182c99e50f6164a9b75d00.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*-aCW5mnySZ4RRk9Cbmc7Qg.png"/></div><figcaption class="np nq nr nf ng ns nt bf b bg z dx">Equation for the covariance matrix where R represents the 3x3 rotation matrix derived from the 4 quaternions, and S are 3 scale parameters. Image by author.</figcaption></figure><p id="52b3" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Note one must normalize the quaternion vector before converting to a rotation matrix in order to obtain a valid rotation matrix. Therefore in our implementation a gaussian point consists of the following parameters, coordinates (3x1 vector), quaternions (4x1 vector), scale (3x1 vector) and a final float value relating to the opacity (how transparent the splat is). Now all we need to do is optimize these 11 parameters to get our scene — simple right!</p><p id="b190" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Well it turns out it is a little bit more complicated than that. If you remember from high school mathematics, the strength of a gaussian at a specific point is given by the equation:</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div class="nf ng of"><img src="../Images/0e54c4a7f7c119a7b8fbcf1364982fdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*5gC88BKMKrN81TyoJ0vDqw.png"/></div><figcaption class="np nq nr nf ng ns nt bf b bg z dx">Strength of a gaussian at a point x is given by the mean (mu) and the inverse of the covariance matrix. Image by author.</figcaption></figure><p id="0e66" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">However, we care about the strength of 3D gaussians in 2D, ie. in the image plane. But you might say, we know how to project points to 2D! Despite that, we have not yet gone over projecting the covariance matrix to 2D and so we could not possibly find the inverse of the 2D covariance matrix if we have yet to find the 2D covariance matrix.</p><p id="ddf8" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Now this is the fun part (depending on how you look at it). EWA Splatting, a paper reference by the 3D gaussian splatting authors, shows exactly how to project the 3D covariance matrix to 2D.² However, this assumes knowledge of a Jacobian affine transformation matrix, which we compute below. I find code most helpful when walking through a difficult concept and thus I have provided some below in order to exemplify how to go from a 3D covariance matrix to 2D.</p><pre class="ni nj nk nl nm nu nv nw bp nx bb bk"><span id="4a37" class="ny nz fq nv b bg oa ob l oc od">def compute_2d_covariance(<br/>    points: torch.Tensor,<br/>    external_matrix: torch.Tensor,<br/>    covariance_3d: torch.Tensor,<br/>    tan_fovY: torch.Tensor,<br/>    tan_fovX: torch.Tensor,<br/>    focal_x: torch.Tensor,<br/>    focal_y: torch.Tensor,<br/>) -&gt; torch.Tensor:<br/>    """<br/>    Compute the 2D covariance matrix for each gaussian<br/>    """<br/>    points = torch.cat(<br/>        [points, torch.ones(points.shape[0], 1, device=points.device)], dim=1<br/>    )<br/>    points_transformed = (points @ external_matrix)[:, :3]<br/>    limx = 1.3 * tan_fovX<br/>    limy = 1.3 * tan_fovY<br/>    x = points_transformed[:, 0] / points_transformed[:, 2]<br/>    y = points_transformed[:, 1] / points_transformed[:, 2]<br/>    z = points_transformed[:, 2]<br/>    x = torch.clamp(x, -limx, limx) * z<br/>    y = torch.clamp(y, -limy, limy) * z<br/><br/>    J = torch.zeros((points_transformed.shape[0], 3, 3), device=covariance_3d.device)<br/>    J[:, 0, 0] = focal_x / z<br/>    J[:, 0, 2] = -(focal_x * x) / (z**2)<br/>    J[:, 1, 1] = focal_y / z<br/>    J[:, 1, 2] = -(focal_y * y) / (z**2)<br/><br/>    # transpose as originally set up for perspective projection<br/>    # so we now transform back<br/>    W = external_matrix[:3, :3].T<br/><br/>    return (J @ W @ covariance_3d @ W.T @ J.transpose(1, 2))[:, :2, :2]</span></pre><p id="fc74" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">First off, tan_fovY and tan_fovX are the tangents of half the field of view angles. We use these values to clamp our projections, preventing any wild, off-screen projections from affecting our render. One can derive the jacobian from the transformation from 3D to 2D as given with our initial forward transform introduced in part 1, but I have saved you the trouble and show the expected derivation above. Lastly, if you remember we transposed our rotation matrix above in order to accommodate a reshuffling of terms and therefore we transpose back on the penultimate line before returning the final covariance calculation. As the EWA splatting paper notes, we can ignore the third row and column seeing as we only care about the 2D image plane. You might wonder, why couldn’t we do that from the start? Well, the covariance matrix parameters will vary depending on which angle you are viewing it from as in most cases it will not be a perfect sphere! Now that we’ve transformed to the correct viewpoint, the covariance z-axis info is useless and can be discarded.</p><p id="796c" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Given that we have the 2D covariance matrix we are close to being able to calculate the impact each gaussian has on any random pixel in our image, we just need to find the inverted covariance matrix. Recall again from linear algebra that to find the inverse of a 2x2 matrix you only need to find the determinant and then do some reshuffling of terms. Here is some code to help guide you through that process as well.</p><pre class="ni nj nk nl nm nu nv nw bp nx bb bk"><span id="dcb6" class="ny nz fq nv b bg oa ob l oc od">def compute_inverted_covariance(covariance_2d: torch.Tensor) -&gt; torch.Tensor:<br/>    """<br/>    Compute the inverse covariance matrix<br/><br/>    For a 2x2 matrix<br/>    given as<br/>    [[a, b],<br/>     [c, d]]<br/>     the determinant is ad - bc<br/><br/>    To get the inverse matrix reshuffle the terms like so<br/>    and multiply by 1/determinant<br/>    [[d, -b],<br/>     [-c, a]] * (1 / determinant)<br/>    """<br/>    determinant = (<br/>        covariance_2d[:, 0, 0] * covariance_2d[:, 1, 1]<br/>        - covariance_2d[:, 0, 1] * covariance_2d[:, 1, 0]<br/>    )<br/>    determinant = torch.clamp(determinant, min=1e-3)<br/>    inverse_covariance = torch.zeros_like(covariance_2d)<br/>    inverse_covariance[:, 0, 0] = covariance_2d[:, 1, 1] / determinant<br/>    inverse_covariance[:, 1, 1] = covariance_2d[:, 0, 0] / determinant<br/>    inverse_covariance[:, 0, 1] = -covariance_2d[:, 0, 1] / determinant<br/>    inverse_covariance[:, 1, 0] = -covariance_2d[:, 1, 0] / determinant<br/>    return inverse_covariance</span></pre><p id="cf42" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">And tada, now we can compute the pixel strength for every single pixel in an image. However, doing so is extremely slow and unnecessary. For example, we really don’t need to waste computing power figuring out how a splat at (0,0) affects a pixel at (1000, 1000), unless the covariance matrix is massive. Therefore, the authors make a choice to calculate what they call the “radius” of each splat. As seen in the code below we calculate the eigenvalues along each axis (remember, eigenvalues show variation). Then, we take the square root of the largest eigenvalue to get a standard deviation measure and multiply it by 3.0, which covers 99.7% of the distribution within 3 standard deviations. This radius helps us figure out the minimum and maximum x and y values that the splat touches. When rendering, we only compute the splat strength for pixels within these bounds, saving a ton of unnecessary calculations. Pretty smart, right?</p><pre class="ni nj nk nl nm nu nv nw bp nx bb bk"><span id="66e5" class="ny nz fq nv b bg oa ob l oc od">def compute_extent_and_radius(covariance_2d: torch.Tensor):<br/>    mid = 0.5 * (covariance_2d[:, 0, 0] + covariance_2d[:, 1, 1])<br/>    det = covariance_2d[:, 0, 0] * covariance_2d[:, 1, 1] - covariance_2d[:, 0, 1] ** 2<br/>    intermediate_matrix = (mid * mid - det).view(-1, 1)<br/>    intermediate_matrix = torch.cat(<br/>        [intermediate_matrix, torch.ones_like(intermediate_matrix) * 0.1], dim=1<br/>    )<br/><br/>    max_values = torch.max(intermediate_matrix, dim=1).values<br/>    lambda1 = mid + torch.sqrt(max_values)<br/>    lambda2 = mid - torch.sqrt(max_values)<br/>    # now we have the eigenvalues, we can calculate the max radius<br/>    max_radius = torch.ceil(3.0 * torch.sqrt(torch.max(lambda1, lambda2)))<br/><br/>    return max_radius</span></pre><p id="39c7" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">All of these steps above give us our preprocessed scene that can then be used in our render step. As a recap we now have the points in 2D, colors associated with those points, covariance in 2D, inverse covariance in 2D, sorted depth order, the minimum x, minimum y, maximum x, maximum y values for each splat, and the associated opacity. With all of these components we can finally move onto rendering an image!</p></div></div></div><div class="ab cb og oh oi oj" role="separator"><span class="ok by bm ol om on"/><span class="ok by bm ol om on"/><span class="ok by bm ol om"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><ol class=""><li id="bd7e" class="mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd oo op oq bk">Kerbl, Bernhard, et al. “3d gaussian splatting for real-time radiance field rendering.” <em class="or">ACM Transactions on Graphics</em> 42.4 (2023): 1–14.</li><li id="61cf" class="mi mj fq mk b go os mm mn gr ot mp mq mr ou mt mu mv ov mx my mz ow nb nc nd oo op oq bk">Zwicker, Matthias, et al. “EWA splatting.” <em class="or">IEEE Transactions on Visualization and Computer Graphics</em> 8.3 (2002): 223–238.</li></ol></div></div></div></div>    
</body>
</html>