- en: Cognitive Prompting in LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM中的认知提示
- en: 原文：[https://towardsdatascience.com/cognitive-prompting-in-llms-6234f6ab9a4b?source=collection_archive---------3-----------------------#2024-10-19](https://towardsdatascience.com/cognitive-prompting-in-llms-6234f6ab9a4b?source=collection_archive---------3-----------------------#2024-10-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/cognitive-prompting-in-llms-6234f6ab9a4b?source=collection_archive---------3-----------------------#2024-10-19](https://towardsdatascience.com/cognitive-prompting-in-llms-6234f6ab9a4b?source=collection_archive---------3-----------------------#2024-10-19)
- en: Can we teach machines to think like humans?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们能否教会机器像人类一样思考？
- en: '[](https://medium.com/@Oliver_Kramer?source=post_page---byline--6234f6ab9a4b--------------------------------)[![Oliver
    Kramer](../Images/1687be9e91f7e308df737b4d2c020116.png)](https://medium.com/@Oliver_Kramer?source=post_page---byline--6234f6ab9a4b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6234f6ab9a4b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6234f6ab9a4b--------------------------------)
    [Oliver Kramer](https://medium.com/@Oliver_Kramer?source=post_page---byline--6234f6ab9a4b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@Oliver_Kramer?source=post_page---byline--6234f6ab9a4b--------------------------------)[![Oliver
    Kramer](../Images/1687be9e91f7e308df737b4d2c020116.png)](https://medium.com/@Oliver_Kramer?source=post_page---byline--6234f6ab9a4b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6234f6ab9a4b--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6234f6ab9a4b--------------------------------)
    [Oliver Kramer](https://medium.com/@Oliver_Kramer?source=post_page---byline--6234f6ab9a4b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6234f6ab9a4b--------------------------------)
    ·8 min read·Oct 19, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学前沿](https://towardsdatascience.com/?source=post_page---byline--6234f6ab9a4b--------------------------------)
    ·8分钟阅读·2024年10月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3e0141f321233bbc647675321cf0a43d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e0141f321233bbc647675321cf0a43d.png)'
- en: Image created with GPT-4o
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由GPT-4o生成
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 'When I started to learn about AI one of the most fascinating ideas was that
    machines think like humans. But when taking a closer look at what AI and machine
    learning methods are actually doing, I was surprised there actually is a huge
    gap between what you can find in courses and books about how humans think, i.e.,
    human cognition, and the way machines do. Examples of these gaps for me were:
    how a perceptron works, which is often referred to as “inspired by its biological
    pendant” and how real neurons work. Or how fuzzy logic tries to model human concepts
    of information and inference and how human inference actually seems to work. Or
    how humans cluster a cloud of points by looking at it and drawing circles around
    point clouds on a board and how algorithms like DBSCAN and k-means perform this
    task.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始学习人工智能时，最吸引我注意的一个想法是机器像人类一样思考。但是，当我仔细研究人工智能和机器学习方法到底在做什么时，我感到惊讶的是，关于人类思维（即人类认知）与机器思维之间实际上存在巨大的差距。对于我来说，这些差距的例子包括：感知机是如何工作的，它常被称为“受其生物学对偶体启发”，以及真实神经元是如何工作的。又如模糊逻辑如何试图建模人类的信息和推理概念，而人类推理实际上又是如何运作的。或者，人与人是如何通过观察并在黑板上围绕点云画圈来聚类一团点云的，而像DBSCAN和k-means这样的算法是如何完成这项任务的。
- en: 'But now, LLMs like ChatGPT, Claude, and LLaMA have come into the spotlight.
    Based on billions or even trillions of these artificial neurons and mechanisms
    that also have an important part to play in cognition: attention (which is all
    you need obviously). We’ve come a long way, and meanwhile Nobel Prizes have been
    won to honor the early giants in this field. LLMs are insanely successful in summarizing
    articles, generating code, or even answering complex questions and being creative.
    A key point is — no doubts about it—the right prompt. The better you specify what
    you want from the model, the better is the outcome. Prompt engineering has become
    an evolving field, and it has even become a specialized job for humans (though
    I personally doubt the long-term future of this role). Numerous prompting strategies
    have been proposed: famous ones are Chain-of-thought (CoT) [2] or Tree-of-Thought
    (ToT) [3] that guide the language model reasoning step by step, mainly by providing
    the LLM steps of successful problem solving examples. But these steps are usually
    concrete examples and require an explicit design of a solution chain.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在，像ChatGPT、Claude和LLaMA这样的LLM已经成为焦点。它们基于数十亿甚至万亿的人工神经元和机制，而这些机制在认知中也起着重要作用：注意力（显然，这就是你所需要的一切）。我们已经走了很长一段路，同时诺贝尔奖也颁发给了该领域早期的伟大人物。LLM在总结文章、生成代码，甚至回答复杂问题和进行创造性思维方面取得了巨大的成功。关键点是——毫无疑问——正确的提示。你越明确地指定你希望模型做什么，结果就越好。提示工程已经成为一个不断发展的领域，甚至成为了一项专门的工作（尽管我个人怀疑这个角色的长期前景）。已经提出了许多提示策略：著名的有思维链（CoT）[2]或思维树（ToT）[3]，这些策略通过逐步提供成功问题解决的示例，来引导语言模型进行推理。但这些步骤通常是具体的示例，并且需要明确设计一个解决方案链。
- en: Other approaches try to optimize the prompting, for example with evolutionary
    algorithms (EAs) like PromptBreeder. Personally I think EAs are always a good
    idea. Very recently, a research team from Apple has shown that LLMs can easily
    be distracted from problem solving with different prompts [4]. As there are numerous
    good posts, also on TDS on CoT and prompt design (like [here](/create-your-own-prompt-enhancer-from-scratch-b870963a1ca0)
    recently), I feel no need to recap them here in more detail.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 其他方法试图优化提示，例如使用进化算法（EAs）如PromptBreeder。就我个人而言，我认为进化算法始终是一个好主意。最近，苹果的一支研究团队表明，LLM（大语言模型）很容易因为不同的提示而从解决问题的过程中分心[4]。由于关于CoT（思维链）和提示设计的许多优秀文章，尤其是在TDS上的文章（比如[这里](/create-your-own-prompt-enhancer-from-scratch-b870963a1ca0)的最新文章），我觉得没有必要在这里详细回顾。
- en: '**What Is Cognitive Prompting?**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**什么是认知提示？**'
- en: 'Something is still missing, as there is obviously a gap to cognitive science.
    That all got me thinking: can we help these models “think” more like humans, and
    how? What if they could be guided by what cognitive science refers to as cognitive
    operations? For example, approaching a problem by breaking it down step by step,
    to filter out unnecessary information, and to recognize patterns that are present
    in the available information. Sounds a bit like what we do when solving difficult
    puzzles.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然有一些东西缺失，因为显然与认知科学之间存在差距。这一切让我开始思考：我们能否帮助这些模型“更像人类一样思考”，如果可以，应该如何做？如果它们能够通过认知科学所称的认知操作来进行引导会怎样？例如，通过逐步拆解问题，过滤掉不必要的信息，并识别出在可用信息中存在的模式。这听起来有点像我们在解决难题时所做的事情。
- en: That’s where **cognitive prompting** comes in. Imagine the AI cannot only answer
    your questions but also guide itself — and you when you read its output — through
    complex problem-solving processes by “thinking” in structured steps.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是**认知提示**的作用所在。想象一下，人工智能不仅能够回答你的问题，还能通过“思考”结构化的步骤，指引自己——以及在你阅读它的输出时——通过复杂的解决问题的过程。
- en: 'Imagine you’re solving a math word problem. The first thing you do is probably
    to clarify your goal: What exactly do I need to figure out, what is the outcome
    we expect? Then, you break the problem into smaller steps, a promising way is
    to identify relevant information, and perhaps to notice patterns that help guiding
    your thoughts closer toward the desired solution. In this example, let’s refer
    to these steps as goal clarification, decomposition, filtering, and pattern recognition.
    They are all examples of **cognitive operations** (COPs) we perform instinctively
    (or which we are taught to follow by a teacher in the best case).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你正在解决一个数学应用题。你做的第一件事可能是明确你的目标：我究竟需要弄清楚什么，我们期望的结果是什么？接着，你将问题分解成更小的步骤，一种有前景的方法是识别相关信息，或许注意到一些有助于引导你思考的模式，帮助你更接近期望的解决方案。在这个示例中，我们将这些步骤称为目标明确、分解、过滤和模式识别。它们都是我们本能地执行的**认知操作**（COPs）的例子（或者在最好的情况下，我们被教师教导要遵循这些步骤）。
- en: '**But How Does This Actually Work?**'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**但这到底是如何工作的呢？**'
- en: 'Here’s how the process unfolded. We define a sequence of COPs and ask the LLM
    to follow the sequence. Figure 1 shows an example of what the prompt looks like.
    Example COPs that turn out to be important are:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是该过程的展开方式。我们定义了一个认知操作（COP）序列，并要求LLM按照这个序列进行操作。图1展示了提示的一个示例。以下是一些证明重要的COP示例：
- en: '**Goal Clarification**: The model first needed to restate the problem in a
    clear way — what exactly is it trying to solve, what is the desired outcome?'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标明确**：模型首先需要清晰地重述问题——它究竟在解决什么问题，期望的结果是什么？'
- en: '**Decomposition**: Next, break the problem into manageable chunks. Instead
    of getting overwhelmed by all the information available, the model should focus
    on solving smaller parts — one at a time.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分解**：接下来，将问题分解成可管理的小部分。模型不应该被所有可用的信息压倒，而应该集中精力解决小部分——一步一步来。'
- en: '**Filtering**: Ask the model to filter out unnecessary details, allowing it
    to focus on what really matters. This is often necessary to allow the model to
    put attention on the really important information.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤**：要求模型过滤掉不必要的细节，专注于真正重要的内容。这通常是必要的，可以帮助模型将注意力集中在真正重要的信息上。'
- en: '**Pattern Recognition**: Identify patterns to solve the problem efficiently.
    For example, if a problem involves repeated steps, ask the model to recognize
    a pattern and apply it.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式识别**：识别模式，以有效地解决问题。例如，如果一个问题涉及重复的步骤，可以让模型识别出一个模式并应用它。'
- en: '**Integration**: In the end it makes sense to synthesize all insights of the
    previous steps, in particular based on the last COPs and integrate them into a
    solution for the final answer.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**整合**：最终，结合前面步骤中的所有见解，特别是基于最后几个COP的见解，并将其整合成最终答案的解决方案是有意义的。'
- en: These structured steps mimic the way humans solve problems — logically, step
    by step. There are numerous further cognitive operations and the choice which
    to choose, which order and how to specify them for the prompt. This certainly
    leaves room for further improvement.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结构化的步骤模仿了人类解决问题的方式——逻辑地、一步步地进行。还有许多进一步的认知操作，以及在选择操作时，如何选择、选择的顺序和如何为提示指定它们。显然，这为进一步改进留下了空间。
- en: We already extended the approach in the following way. Instead of following
    a **deterministic** order of COPs, we give the model the freedom to choose its
    own sequence of COPs based on the provided list — called **self-adaptive** cognitive
    prompting. It turns out that this approach works pretty well. In the next paragraph
    we compare both variants on a benchmark problem set.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在以下方式上扩展了这一方法。我们不再遵循**确定性**的认知操作顺序，而是允许模型根据提供的列表自由选择认知操作的顺序——这被称为**自适应**认知提示。事实证明，这种方法效果相当不错。在下一段中，我们将比较两种变体在基准问题集上的表现。
- en: '![](../Images/2be503ad4f150dc29b7282ab83caafe5.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2be503ad4f150dc29b7282ab83caafe5.png)'
- en: 'Figure 1: Cognitive prompting: A general list of cognitive operations (COPs)
    to guide the LLM reasoning on the left, a specialized version adapted to arithmetic
    reasoning on the right.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：认知提示：左侧是指导LLM推理的认知操作（COPs）的一般列表，右侧是专门适用于算术推理的版本。
- en: What also turns out to improve the performance is adapting the COP descriptions
    to the specific problem domain. Figure 1, right, shows an example of a math-specific
    adaptation of the general COPs. They “unroll” to prompts like “Define each variable
    clearly” or “Solve the equations step by step”.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，证明可以提高性能的是将COP描述适应于特定的问题领域。图1右侧展示了一个将一般COPs适应于数学问题的示例。这些COP“展开”成类似“清晰定义每个变量”或“逐步解决方程式”的提示。
- en: In practice, it makes sense to advise the model to give the final answer as
    a JSON string. Some LLMs do not deliver a solution, but Python code to solve the
    problem. In our experimental analysis, we were fair and ran the code treating
    the answer as correct when the Python code returns the correct result.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，建议模型将最终答案以 JSON 字符串的形式输出是有意义的。一些大型语言模型（LLM）并不直接给出解决方案，而是提供用于解决问题的 Python
    代码。在我们的实验分析中，我们秉持公正的原则，运行代码并将 Python 代码返回正确结果时的答案视为正确。
- en: Example
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: Let’s give a short example asking LLaMA3.1 70B to solve one of the 8.5k arithmetic
    problems from GSM8K [5]. Figure 2 shows the request.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简短的示例，要求 LLaMA3.1 70B 解决来自 GSM8K [5] 的 8.5k 算术问题之一。图 2 显示了这个请求。
- en: '![](../Images/03d4b674bbf5dee7aa31b46322fb372e.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03d4b674bbf5dee7aa31b46322fb372e.png)'
- en: 'Figure 2: Here is an example for arithmetic reasoning using deterministic cognitive
    prompting.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：这是一个使用确定性认知提示进行算术推理的示例。
- en: Figure 3 shows the model’s output leading to a correct answer. It turns out
    the model systematically follows the sequence of COPs — even providing a nice
    problem-solving explanation for humans.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3 显示了模型的输出，得出了正确答案。事实证明，模型系统地遵循了 COP 的序列——甚至为人类提供了一个很好的问题解决解释。
- en: '![](../Images/faa60de9df990a31eeceea2dc90ee9c5.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/faa60de9df990a31eeceea2dc90ee9c5.png)'
- en: 'Figure 3: Output of LLaMA3.1 70B to the cognitive prompting-based problem solution
    request of Figure 3.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：LLaMA3.1 70B 对图 3 所示的基于认知提示的问题解决请求的输出。
- en: '**How Does Cognitive Prompting Perform — Scientifically?**'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**认知提示的表现如何——从科学角度看？**'
- en: Now, let’s become a little more systematic by testing cognitive prompting on
    a typical benchmark. We tested it on a set of math problems from the GSM8K [5]
    dataset — basically, a collection of math questions you’d find in grade school.
    Again, we used Meta’s LLaMA models to see if cognitive prompting could improve
    their problem-solving skills, appliying LLaMA with 8 billion parameters and the
    much larger version with 70 billion parameters.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过在一个典型的基准测试上测试认知提示，变得更加系统化。我们在 GSM8K [5] 数据集上的一组数学问题上进行了测试——这基本上是你在小学时会遇到的一些数学题。再次使用
    Meta 的 LLaMA 模型，看看认知提示是否能提升它们的解题能力，我们应用了具有 80 亿参数的 LLaMA 和具有 700 亿参数的更大版本。
- en: Figure 4 shows some results. The smaller model improved slightly with deterministic
    cognitive prompting. Maybe it is not big enough to handle the complexity of structured
    thinking. When it selects an own sequence of COPs, the win in performance is significantly.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4 显示了一些结果。较小的模型在确定性认知提示下略有改进。也许它的规模还不足以应对结构化思维的复杂性。当它选择自己的 COP 序列时，性能显著提升。
- en: '![](../Images/faf494200350f635af5db4e5a8998bbd.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/faf494200350f635af5db4e5a8998bbd.png)'
- en: 'Figure 4: Results of Cognitive Prompting on GSM8k benchmark on the left and
    a histogram of chosen COP sequences on the right (goal clarification (GC), decomposition
    (DC), pattern recognition (PR), generalization (GN), and reorganization (RE)).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：左侧为认知提示在 GSM8k 基准上的结果，右侧为所选 COP 序列的直方图（目标澄清 (GC)、分解 (DC)、模式识别 (PR)、归纳 (GN)
    和重组 (RE)）。
- en: Without cognitive prompting, the larger model scored about 87% on the math problems.
    When we added **deterministic cognitive prompting** (where the model followed
    a fixed sequence of cognitive steps), its score jumped to 89%. But when we allowed
    the model to adapt and choose the cognitive operations dynamically (self-adaptive
    prompting), the score shot up to 91%. Not bad for a machine getting quite general
    advice to reason like a human — without additional examples , right?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 没有认知提示时，较大的模型在数学问题上的得分大约为 87%。当我们加入了**确定性认知提示**（即模型遵循固定的认知步骤序列）时，得分跃升至 89%。但当我们允许模型动态调整并选择认知操作（自适应提示）时，得分飙升至
    91%。对于一台获得了相当一般的推理建议的机器——没有额外的示例，表现不错吧？
- en: '**Why Does This Matter?**'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**这为什么重要？**'
- en: Cognitive prompting is a method that organizes these human-like cognitive operations
    into a structured process and uses them to help LLMs solve complex problems. In
    essence, it’s like giving the model a structured “thinking strategy” to follow.
    While earlier approaches like CoT have been helpful, cognitive prompting offers
    even deeper reasoning layers by incorporating a variety of cognitive operations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 认知提示是一种将类似人类的认知操作组织成结构化过程的方法，并利用这些操作帮助 LLMs 解决复杂问题。从本质上讲，它就像是给模型提供了一个结构化的“思维策略”供其遵循。尽管像
    CoT 这样的早期方法已经提供了帮助，认知提示通过结合各种认知操作，提供了更深层次的推理。
- en: This has exciting implications beyond math problems! Think about areas like
    decision-making, logical reasoning, or even creativity — tasks that require more
    than just regurgitating facts or predicting the next word in a sentence. By teaching
    AI to think more like us, we open the door to models that can reason through problems
    in ways that are closer to human cognition.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这对数学问题之外的领域也有令人兴奋的意义！想想决策、逻辑推理，甚至创造力等领域——这些任务不仅仅是复述事实或预测句子中的下一个词。通过教会AI像我们一样思考，我们为模型能够以更接近人类认知的方式推理问题打开了大门。
- en: '**Where Do We Go From Here?**'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**我们从这里开始往哪里去？**'
- en: The results are promising, but this is just the beginning. Cognitive prompting
    could be adapted for other domains for sure, but it can also be combined with
    other ideas from AI. As we explore more advanced versions of cognitive prompting,
    the next big challenge will be figuring out how to optimize it across different
    problem types. Who knows? Maybe one day, we’ll have AI that can tackle anything
    from math problems to moral dilemmas, all while thinking as logically and creatively
    as we do. Have fun trying out cognitive prompting on your own!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 结果很有前景，但这只是一个开始。认知提示肯定可以适应其他领域，也可以与AI的其他思路结合。随着我们探索更先进的认知提示版本，下一个重大挑战将是如何优化它以应对不同类型的问题。谁知道呢？也许有一天，我们会拥有能够解决从数学问题到道德困境的AI，同时它的思维方式既合乎逻辑又充满创造力。自己尝试认知提示，享受其中的乐趣吧！
- en: References
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] O. Kramer, J. Baumann. [Unlocking Structured Thinking in Language Models
    with Cognitive Prompting](https://arxiv.org/abs/2410.02953) (arXiv)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] O. Kramer, J. Baumann. [通过认知提示解锁语言模型中的结构化思维](https://arxiv.org/abs/2410.02953)（arXiv）'
- en: '[2] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. H. Chi,
    Q. V. Le, and D. Zhou. Chain-of-thought prompting elicits reasoning in large language
    models. In S. Koyejo, S. Mohamed, A. Agarwal, D. Bel- grave, K. Cho, and A. Oh,
    editors, Neural Information Processing Systems (NeurIPS) Workshop, volume 35,
    pages 24824–24837, 2022'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. H. Chi,
    Q. V. Le, 和 D. Zhou. 链式思维提示引发大型语言模型中的推理。在 S. Koyejo, S. Mohamed, A. Agarwal, D.
    Belgrave, K. Cho 和 A. Oh 编辑的《神经信息处理系统（NeurIPS）》研讨会，卷 35，第 24824–24837 页，2022年'
- en: '[3] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y. Cao, and K. Narasimhan.
    Tree of thoughts: Deliberate problem solving with large language models. In Neural
    Information Processing Systems (NeurIPS), volume 36, pages 11809–11822, 2023'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y. Cao, 和 K. Narasimhan.
    思维树：使用大型语言模型进行深思熟虑的解决问题。在《神经信息处理系统（NeurIPS）》中，卷 36，第 11809–11822 页，2023年'
- en: '[4] I. Mirzadeh, K. Alizadeh, H. Shahrokhi, O. Tuzel, S. Bengio, and M. Farajtabar.
    [GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large
    Language Models.](https://arxiv.org/pdf/2410.05229) 2024.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] I. Mirzadeh, K. Alizadeh, H. Shahrokhi, O. Tuzel, S. Bengio, 和 M. Farajtabar.
    [GSM-Symbolic: 理解大型语言模型中数学推理的局限性。](https://arxiv.org/pdf/2410.05229) 2024年。'
- en: '[5] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plap-
    pert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and J. Schulman. Training verifiers
    to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert,
    J. Tworek, J. Hilton, R. Nakano, C. Hesse, 和 J. Schulman. 训练验证器解决数学文字题。arXiv预印本
    arXiv:2110.14168, 2021年。'
