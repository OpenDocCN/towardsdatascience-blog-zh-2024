- en: Multi-Agentic RAG with Hugging Face Code Agents
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Hugging Face 代码代理的多代理 RAG 系统
- en: 原文：[https://towardsdatascience.com/multi-agentic-rag-with-hugging-face-code-agents-005822122930?source=collection_archive---------0-----------------------#2024-12-31](https://towardsdatascience.com/multi-agentic-rag-with-hugging-face-code-agents-005822122930?source=collection_archive---------0-----------------------#2024-12-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/multi-agentic-rag-with-hugging-face-code-agents-005822122930?source=collection_archive---------0-----------------------#2024-12-31](https://towardsdatascience.com/multi-agentic-rag-with-hugging-face-code-agents-005822122930?source=collection_archive---------0-----------------------#2024-12-31)
- en: Using *Qwen2.5–7B-Instruct* powered code agents to create a local, open source,
    multi-agentic RAG system
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 *Qwen2.5–7B-Instruct* 驱动的代码代理创建一个本地的、开源的多代理 RAG 系统
- en: '[](https://medium.com/@gabrielesgroi94?source=post_page---byline--005822122930--------------------------------)[![Gabriele
    Sgroi, PhD](../Images/b81978d35e6238d160457de2affc2b0e.png)](https://medium.com/@gabrielesgroi94?source=post_page---byline--005822122930--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--005822122930--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--005822122930--------------------------------)
    [Gabriele Sgroi, PhD](https://medium.com/@gabrielesgroi94?source=post_page---byline--005822122930--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@gabrielesgroi94?source=post_page---byline--005822122930--------------------------------)[![Gabriele
    Sgroi, 博士](../Images/b81978d35e6238d160457de2affc2b0e.png)](https://medium.com/@gabrielesgroi94?source=post_page---byline--005822122930--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--005822122930--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--005822122930--------------------------------)
    [Gabriele Sgroi, 博士](https://medium.com/@gabrielesgroi94?source=post_page---byline--005822122930--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--005822122930--------------------------------)
    ·61 min read·4 days ago
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--005822122930--------------------------------)
    ·阅读时长：61分钟 ·4天前
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1ff9aca5ba93aaf9ae77e0a74be9e734.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ff9aca5ba93aaf9ae77e0a74be9e734.png)'
- en: Photo by [Jaredd Craig](https://unsplash.com/@jaredd?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Jaredd Craig](https://unsplash.com/@jaredd?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 上
- en: Large Language Models have shown impressive capabilities and they are still
    undergoing steady improvements with each new generation of models released. Applications
    such as chatbots and summarisation can directly exploit the language proficiency
    of LLMs as they are only required to produce textual outputs, which is their natural
    setting. Large Language Models have also shown impressive abilities to understand
    and solve complex tasks, but as long as their solution stays “on paper”, i.e.
    in pure textual form, they need an external user to act on their behalf and report
    back the results of the proposed actions. Agent systems solve this problem by
    letting the models act on their environment, usually via a set of tools that can
    perform specific operations. In this way, an LLM can find solutions iteratively
    by trial and error while interacting with the environment.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLM）展示了令人印象深刻的能力，并且随着每一代新模型的发布，它们仍在持续改进。像聊天机器人和摘要生成等应用可以直接利用 LLM 的语言能力，因为它们只需要生成文本输出，这是它们的自然环境。大语言模型还展示了理解和解决复杂任务的强大能力，但只要它们的解决方案停留在“纸面上”，即仅仅是纯文本形式，它们就需要外部用户代表它们采取行动，并反馈建议动作的结果。代理系统通过让模型在其环境中进行操作来解决这个问题，通常通过一组可以执行特定操作的工具。通过这种方式，LLM
    可以通过反复试验与环境互动，逐步找到解决方案。
- en: 'An interesting situation is when the tools that an LLM agent has access to
    are agents themselves: this is the core concept of multi-agentic systems. A multi-agentic
    system solves tasks by distributing and delegating duties to specialized models
    and putting their output together like puzzle pieces. A common way to implement
    such systems is by using a manager agent to orchestrate and coordinate other agents''
    workflow.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一种有趣的情况是，当一个大语言模型（LLM）代理可以访问的工具本身就是代理时：这就是多代理系统的核心概念。多代理系统通过将任务分配并委托给专门的模型，并像拼图一样将它们的输出组合在一起，从而解决任务。实现这种系统的常见方法是使用管理代理来协调和组织其他代理的工作流程。
- en: Agentic systems, and in particular multi-agentic systems, require a powerful
    LLM as a backbone to perform properly, as the underlying model needs to be able
    to understand the purpose and applicability of the various tools as well as break
    up the original problem into sub-problems that can be tackled by each tool. For
    this reason, proprietary models like ChatGpt or Anthropic’s Claude are generally
    the default go-to solution for agentic systems. Fortunately, open-source LLMs
    have continued to see huge improvements in performance so much so that some of
    them now rival proprietary models in some instances. Even more interestingly,
    modestly-sized open LLMs can now perform complex tasks that were unthinkable a
    couple of years ago.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 代理系统，特别是多代理系统，需要一个强大的 LLM 作为支撑才能正常运作，因为底层模型需要能够理解各种工具的目的和适用性，并将原始问题分解为每个工具可以处理的子问题。因此，像
    ChatGPT 或 Anthropic 的 Claude 这样的专有模型通常是代理系统的默认解决方案。幸运的是，开源的 LLM 在性能上持续取得了巨大进步，甚至在某些情况下，它们与专有模型的表现相媲美。更有趣的是，现在适度规模的开源
    LLM 已经能够执行一些几年前还难以想象的复杂任务。
- en: In this blog post, I will show how a “small” LLM that can run on consumer hardware
    is capable enough to power a multi-agentic system with good results. In particular,
    I will give a tutorial on how you can use *Qwen2.5–7B-Instruct* to create a multi-agentic
    RAG system. You can find the code implementation in the following [GitHub repo](https://github.com/GabrieleSgroi/multiagentic_rag)
    and an illustrative [Colab notebook](https://colab.research.google.com/drive/1ZxF-Fkv4QV31uo79FagZWFm8tvXgCtBN).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我将展示如何让一个可以运行在消费级硬件上的“小型”大语言模型（LLM）足够强大，以支持一个多代理系统并取得良好的结果。特别地，我将提供一个教程，教你如何使用*Qwen2.5–7B-Instruct*来创建一个多代理的
    RAG 系统。你可以在以下的[GitHub 仓库](https://github.com/GabrieleSgroi/multiagentic_rag)找到代码实现，以及一个说明性的[Colab
    笔记本](https://colab.research.google.com/drive/1ZxF-Fkv4QV31uo79FagZWFm8tvXgCtBN)。
- en: Before diving into the details of the system architecture, I will recall some
    basic notions regarding LLM agents that will be useful to better understand the
    framework.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入系统架构的细节之前，我将回顾一些关于 LLM 代理的基本概念，这些概念有助于更好地理解这个框架。
- en: ReAct
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ReAct
- en: 'ReAct, proposed in [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629),
    is a popular framework for building LLM agents. The main idea of the method is
    to incorporate the effectiveness of Chain of Thought prompting into an agent framework.
    ReACT consists of interleaved reasoning and action steps: the Large Language Model
    is prompted to provide a thought sequence before emitting an action. In this way
    the model can create dynamic reasoning traces to steer actions and update the
    high-level plan while incorporating information coming from the interaction with
    the environment. This allows for an iterative and incremental approach to solving
    the given task. In practice, the workflow of a ReAct agent is made up of Thought,
    Action, and Observation sequences: the model produces reasoning for a general
    plan and specific tool usage in the Thought step, then invokes the relevant tool
    in the Action step, and finally receives feedback from the environment in the
    Observation.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 'ReAct，提出于[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)，是一个用于构建
    LLM 代理的流行框架。该方法的主要思想是将“思维链”提示的有效性融入到代理框架中。ReACT 包含交替进行的推理和行动步骤：大语言模型在执行动作之前，首先被提示提供一系列思维过程。通过这种方式，模型可以创建动态的推理痕迹来引导行动，并在与环境互动的过程中更新高层次的计划。这使得解决给定任务的过程能够采取迭代和增量的方式。在实践中，ReAct
    代理的工作流程由思维、行动和观察三个步骤组成：模型在思维步骤中产生关于一般计划和具体工具使用的推理，然后在行动步骤中调用相关工具，最后在观察步骤中接收来自环境的反馈。'
- en: Below is an example of what the ReACT framework looks like.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 ReACT 框架的示例。
- en: '![](../Images/bb48e73b9eeef9ce664171f66c3b531d.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb48e73b9eeef9ce664171f66c3b531d.png)'
- en: 'Comparison between the ReACT, Chain-of-Thought, and Act-Only frameworks for
    a Question Answering task. Image from [ReAct: Synergizing Reasoning and Acting
    in Language Models](https://arxiv.org/abs/2210.03629).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 'ReACT、思维链和仅行动框架在问答任务中的比较。图片来源于[ReAct: Synergizing Reasoning and Acting in Language
    Models](https://arxiv.org/abs/2210.03629)。'
- en: Code Agents
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码代理
- en: Code agents are a particular type of LLM agents that use executable Python code
    to interact with the environment. They are based on the CodeAct framework proposed
    in the paper [Executable Code Actions Elicit Better LLM Agents](https://arxiv.org/abs/2402.01030).
    CodeAct is very similar to the ReAct framework, with the difference that each
    action consists of arbitrary executable code that can perform multiple operations.
    Hand-crafted tools are provided to the agent as regular Python functions that
    it can call in the code.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 代码代理是一种特定类型的LLM代理，使用可执行的Python代码与环境进行交互。它们基于论文[可执行代码操作能激发更好的LLM代理](https://arxiv.org/abs/2402.01030)中提出的CodeAct框架。CodeAct与ReAct框架非常相似，不同之处在于每个操作都由任意可执行代码组成，可以执行多个操作。手工制作的工具作为常规Python函数提供给代理，代理可以在代码中调用这些函数。
- en: 'Code agents come with a unique set of advantages over more traditional agents
    using JSON or other text formats to perform actions:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 代码代理相较于使用JSON或其他文本格式执行操作的传统代理具有一系列独特的优势：
- en: They can leverage existing software packages in combination with hand-crafted
    task-specific tools.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们可以结合现有的软件包和手工制作的特定任务工具来使用。
- en: They can self-debug the generated code by using the error messages returned
    after an error is raised.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们可以通过使用在发生错误后返回的错误信息来进行自我调试。
- en: LLMs are familiar with writing code as it is generally widely present in their
    pre-training data, making it a more natural format to write their actions.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs熟悉编写代码，因为代码通常广泛出现在它们的预训练数据中，使其成为编写操作的更自然格式。
- en: Code naturally allows for the storage of intermediate results and the composition
    of multiple operations in a single action, while JSON or other text formats may
    need multiple actions to accomplish the same.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码自然允许存储中间结果并在一次操作中组合多个操作，而JSON或其他文本格式可能需要多次操作才能完成相同的任务。
- en: For these reasons, Code Agents can offer improved performance and faster execution
    speed than agents using JSON or other text formats to execute actions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些原因，代码代理能够比使用JSON或其他文本格式执行操作的代理提供更好的性能和更快的执行速度。
- en: '![](../Images/a67f4047cd5299419a6fe7f81077f750.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a67f4047cd5299419a6fe7f81077f750.png)'
- en: Comparison between code agents and agents using JSON or text as actions. Image
    from [Executable Code Actions Elicit Better LLM Agents](https://arxiv.org/abs/2402.01030).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 代码代理与使用JSON或文本作为操作的代理对比。图片来源：[可执行代码操作能激发更好的LLM代理](https://arxiv.org/abs/2402.01030)。
- en: Below is a concrete example from the original paper that showcases how code
    agents can require fewer actions to solve certain tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是原始论文中的一个具体例子，展示了代码代理如何在解决某些任务时需要更少的操作。
- en: '![](../Images/0a96c18b5be55a21b4f23952aefcad2e.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a96c18b5be55a21b4f23952aefcad2e.png)'
- en: Code agents vs agents using JSON/text action format. Code agents can execute
    multiple operations in one action. Image from [Executable Code Actions Elicit
    Better LLM Agents](https://arxiv.org/abs/2402.01030). [RIVEDERE]
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 代码代理与使用JSON/文本操作格式的代理对比。代码代理可以在一次操作中执行多个操作。图片来源：[可执行代码操作能激发更好的LLM代理](https://arxiv.org/abs/2402.01030)。[RIVEDERE]
- en: 'The Hugging Face transformers library provides useful modules to build agents
    and, in particular, code agents. The Hugging Face transformer agents framework
    focuses on clarity and modularity as core design principles. These are particularly
    important when building an agent system: the complexity of the workflow makes
    it essential to have control over all the interconnected parts of the architecture.
    These design choices make Hugging Face agents a great tool for building custom
    and flexible agent systems. When using open-source models to power the agent engine,
    the Hugging Face agents framework has the further advantage of allowing easy access
    to the models and utilities present in the Hugging Face ecosystem.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face的transformers库提供了构建代理，特别是代码代理的有用模块。Hugging Face的transformer代理框架将清晰性和模块化作为核心设计原则。这些原则在构建代理系统时尤为重要：由于工作流的复杂性，必须对架构中的所有相互关联的部分进行控制。这些设计选择使得Hugging
    Face代理成为构建自定义和灵活代理系统的优秀工具。当使用开源模型为代理引擎提供支持时，Hugging Face代理框架还有一个额外的优势，即可以轻松访问Hugging
    Face生态系统中现有的模型和工具。
- en: 'Hugging Face code agents also tackle the issue of insecure code execution.
    In fact, letting an LLM generate code unrestrained can pose serious risks as it
    could perform undesired actions. For example, a hallucination could cause the
    agent to erase important files. In order to mitigate this risk, Hugging Face code
    agents implementation uses a ground-up approach to secure code execution: the
    code interpreter can only execute explicitly authorized operations. This is in
    contrast to the usual top-down paradigm that starts with a fully functional Python
    interpreter and then forbids actions that may be dangerous. The Hugging Face implementation
    includes a list of safe, authorized functions that can be executed and provides
    a list of safe modules that can be imported. Anything else is not executable unless
    it has been preemptively authorized by the user. You can read more about Hugging
    Face (code) agents in their blog posts:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face代码代理还解决了不安全代码执行的问题。事实上，让LLM不加限制地生成代码可能会带来严重风险，因为它可能执行不希望发生的操作。例如，一个幻觉可能导致代理删除重要文件。为了减轻这种风险，Hugging
    Face代码代理实现采用了从头开始的安全代码执行方法：代码解释器只能执行明确授权的操作。这与通常的自上而下的范式不同，后者从一个完全功能的Python解释器开始，然后禁止可能危险的操作。Hugging
    Face的实现包括一个可以执行的安全授权函数列表，并提供了一个可以导入的安全模块列表。除非已被用户预先授权，否则其他任何操作都不可执行。你可以在他们的博客文章中阅读更多关于Hugging
    Face（代码）代理的内容：
- en: '[License to Call: Introducing Transformers Agents 2.0](https://huggingface.co/blog/agents)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[许可调用：介绍Transformers Agents 2.0](https://huggingface.co/blog/agents)'
- en: '[Our Transformers Code Agent beats the GAIA benchmark!](https://huggingface.co/blog/beating-gaia)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我们的Transformers代码代理打破GAIA基准！](https://huggingface.co/blog/beating-gaia)'
- en: Agentic RAG
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理RAG
- en: Retrieval Augmented Generation has become the de facto standard for information
    retrieval tasks involving Large Language Models. It can help keep the LLM information
    up to date, give access to specific information, and reduce hallucinations. It
    can also enhance human interpretability and supervision by returning the sources
    the model used to generate its answer. The usual RAG workflow, consisting of a
    retrieval process based on semantic similarity to a user’s query and a model’s
    context enhancement with the retrieved information, is not adequate to solve some
    specific tasks. Some situations that are not suited for traditional RAG include
    tasks that need interactions with the information sources, queries needing multiple
    pieces of information to be answered, and complex queries requiring non-trivial
    manipulation to be connected with the actual information contained in the sources.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）已成为涉及大型语言模型（LLM）信息检索任务的事实标准。它可以帮助保持LLM的信息更新，提供特定信息的访问权限，并减少幻觉（hallucinations）。它还可以通过返回模型用来生成答案的来源，增强人类可解释性和监督性。传统的RAG工作流程包括基于与用户查询语义相似度的检索过程以及通过检索到的信息增强模型上下文，但这种方法无法解决一些特定任务。一些不适合传统RAG的情况包括需要与信息来源互动的任务、需要多个信息片段才能回答的查询以及需要复杂操作才能与来源中的实际信息连接的复杂查询。
- en: A concrete challenging example for traditional RAG systems is multi-hop question
    answering (MHQA). It involves extracting and combining multiple pieces of information,
    possibly requiring several iterative reasoning processes over the extracted information
    and what is still missing. For instance, if the model has been asked the question
    “Does birch plywood float in ethanol?”, even if the sources used for RAG contained
    information about the density of both materials, the standard RAG framework could
    fail if these two pieces of information are not directly linked.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于传统RAG系统的一个具体挑战性示例是多跳问答（MHQA）。它涉及提取和组合多个信息片段，可能需要多次迭代推理过程，以处理提取的信息和仍然缺失的部分。例如，如果模型被问到“桦木胶合板在乙醇中会浮吗？”，即使用于RAG的来源包含关于这两种材料密度的信息，如果这两条信息没有直接关联，标准的RAG框架也可能失败。
- en: A popular way to enhance RAG to avoid the abovementioned shortcomings is to
    use agentic systems. An LLM agent can break down the original query into a series
    of sub-queries and then use semantic search as a tool to retrieve passages for
    these generated sub-queries, changing and adjusting its plan as more information
    is collected. It can autonomously decide whether it has collected enough information
    to answer each query or if it should continue the search. The agentic RAG framework
    can be further enhanced by extending it to a multi-agentic system in which each
    agent has its own defined tasks and duties. This allows, for example, the separation
    between the high-level task planning and the interaction with the document sources.
    In the next section, I will describe a practical implementation of such a system.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的方式来增强RAG以避免上述不足，是使用代理系统。一个LLM代理可以将原始查询拆解成一系列子查询，然后使用语义搜索作为工具来检索这些生成的子查询的段落，随着更多信息的收集，它可以改变和调整计划。它可以自主决定是否已经收集到足够的信息来回答每个查询，或者是否应该继续搜索。代理RAG框架还可以通过扩展为多代理系统进一步增强，在该系统中，每个代理都有自己的任务和职责。这使得，例如，可以将高层任务规划与与文档源的交互分开。在下一节中，我将描述这种系统的实际实现。
- en: Multi-Agentic RAG with Code Agents
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有代码代理的多代理RAG
- en: In this section, I will discuss the general architectural choices I used to
    implement a Multi-Agentic RAG system based on code agents following the ReAct
    framework. You can find the remaining details in the full code implementation
    in the following [GitHub repo](https://github.com/GabrieleSgroi/multiagentic_rag).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我将讨论我用来基于代码代理实现多代理RAG系统的一般架构选择，该系统遵循ReAct框架。你可以在以下[GitHub仓库](https://github.com/GabrieleSgroi/multiagentic_rag)中找到完整代码实现的剩余细节。
- en: 'The goal of the multi-agentic system is to answer a question by searching the
    necessary information on Wikipedia. It is made up of 3 agents:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理系统的目标是通过在维基百科上搜索必要的信息来回答一个问题。它由3个代理组成：
- en: A manager agent whose job is to break down the task into sub-tasks and use their
    output to provide a final answer.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个管理代理，其工作是将任务拆解成子任务，并利用它们的输出提供最终答案。
- en: A Wikipedia search agent that finds relevant pages on Wikipedia and combines
    the information extracted from them.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个维基百科搜索代理，用于在维基百科上找到相关页面并将从中提取的信息结合起来。
- en: A page search agent to retrieve and summarize information relevant to a given
    query from the provided Wikipedia page.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个页面搜索代理，用于从提供的维基百科页面中检索并总结与给定查询相关的信息。
- en: 'These three agents are organized in a hierarchical fashion: each agent can
    use the agent immediately below in the hierarchy as a tool. In particular, the
    manager agent can call the Wikipedia search agent to find information about a
    query which, in turn, can use the page search agent to extract particular information
    from Wikipedia pages.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个代理以分层方式组织：每个代理可以将位于层次结构下方的代理作为工具使用。特别是，管理代理可以调用维基百科搜索代理来查找查询信息，而后者又可以使用页面搜索代理从维基百科页面中提取特定信息。
- en: Below is the diagram of the architecture, specifying which hand-crafted tools
    (including tools wrapping other agents) each agent can call. Notice that since
    code agents act using code execution, these are not actually the only tools they
    can use as any native Python operation and function (as long as it is authorized)
    can be used as well.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是架构图，指定了每个代理可以调用的手工工具（包括包装其他代理的工具）。请注意，由于代码代理通过代码执行来操作，这些并不是它们唯一可以使用的工具，因为任何本地Python操作和函数（只要获得授权）也可以使用。
- en: '![](../Images/54e5a02732eb01048ba8b64cc5648fc5.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54e5a02732eb01048ba8b64cc5648fc5.png)'
- en: Architecture diagram showing agents and hand-crafted tools. Image by the author.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 显示代理和手工工具的架构图。图片由作者提供。
- en: Let’s dive into the details of the workings of the agents involved in the architecture.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨架构中涉及的代理的工作细节。
- en: Manager agent
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理代理
- en: This is the top-level agent, it receives the user’s question and it is tasked
    to return an answer. It can use the Wikipedia search agent as a tool by prompting
    it with a query and receiving the final results of the search. Its purpose is
    to collect the necessary pieces of information from Wikipedia by dividing the
    user question into a series of sub-queries and putting together the result of
    the search.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是顶层代理，它接收用户的提问并负责返回答案。它可以通过向维基百科搜索代理发送查询并接收搜索的最终结果来使用该工具。它的目的是通过将用户问题拆解成一系列子查询并将搜索结果汇总，收集来自维基百科的必要信息。
- en: Below is the system prompt used for this agent. It is built upon the default
    Hugging Face default prompt template. Notice that the examples provided in the
    prompt follow the chat template of the model powering the agent, in this case,
    *Qwen2.5–7B-Instruct.*
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为此代理使用的系统提示符。它建立在默认的Hugging Face提示符模板之上。请注意，提示符中提供的示例遵循了支持此代理的模型的聊天模板，在这种情况下是*Qwen2.5–7B-Instruct*。
- en: '[PRE0]py'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE0]py'
- en: result = wikipedia_search_agent("Italy capital")
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: result = wikipedia_search_agent("意大利首都")
- en: print("Capital of Italy:", result)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: print("意大利的首都:", result)
- en: '[PRE1]py'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE1]py'
- en: result = wikipedia_search_agent("Rome foundation date")
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: result = wikipedia_search_agent("罗马创立日期")
- en: print("Rome foundation:", result)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: print("罗马创立时间:", result)
- en: '[PRE2]py'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE2]py'
- en: final_answer("According to the legend Rome was founded on 21 April 753 BCE,
    but archaeological evidence dates back its development during the Bronze Age.")
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("根据传说，罗马是在公元前753年4月21日建立的，但考古证据表明其发展可以追溯到青铜时代。")
- en: '[PRE3]py'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE3]py'
- en: population_guangzhou_info = wikipedia_search_agent("New York City population")
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: population_guangzhou_info = wikipedia_search_agent("纽约市人口")
- en: population_shanghai_info = wikipedia_search_agent("Shanghai population")
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: population_shanghai_info = wikipedia_search_agent("上海人口")
- en: print("Population Guangzhou:", population_guangzhou)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: print("广州人口:", population_guangzhou)
- en: print("Population Shanghai:", population_shanghai)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: print("上海人口:", population_shanghai)
- en: '[PRE4]py'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE4]py'
- en: population_difference = 24.87*1e6 - 8.25*1e6
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: population_difference = 24.87*1e6 - 8.25*1e6
- en: answer=f"The difference in population between Shanghai and New York is {population_difference}
    inhabitants."
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: answer=f"上海和纽约之间的人口差异是{population_difference}人。"
- en: final_answer(answer)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer(answer)
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Wikipedia search agent
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维基百科搜索代理
- en: 'This agent reports to the manager agent, it receives a query from it and it
    is tasked to return the information it has retrieved from Wikipedia. It can access
    two tools:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代理向经理代理报告，它从经理代理接收查询任务，并负责返回从维基百科检索到的信息。它可以访问两个工具：
- en: A Wikipedia search tool, using the built-in search function from the [wikipedia
    package](https://pypi.org/project/wikipedia/). It receives a query as input and
    returns a list of Wikipedia pages and their summaries.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个维基百科搜索工具，使用[wikipedia package](https://pypi.org/project/wikipedia/)中的内置搜索功能。它接收一个查询并返回维基百科页面及其摘要的列表。
- en: A page search agent that retrieves information about a query from a specific
    Wikipedia page.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个页面搜索代理，从特定的维基百科页面检索查询信息。
- en: 'This agent collects the information to answer the query, dividing it into further
    sub-queries, and combining information from multiple pages if needed. This is
    accomplished by using the search tool of the wikipedia package to identify potential
    pages that can contain the necessary information to answer the query: the agent
    can either use the reported page summaries or call the page search agent to extract
    more information from a specific page. After enough data has been collected, it
    returns an answer to the manager agent.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代理收集信息以回答查询，将其分解为更小的子查询，并在需要时结合多个页面的信息。这是通过使用维基百科包的搜索工具来识别可能包含必要信息的页面来实现的：代理可以使用报告的页面摘要或调用页面搜索代理，从特定页面提取更多信息。收集到足够的数据后，它会返回答案给经理代理。
- en: The system prompt is again a slight modification of the Hugging Face default
    prompt with some specific examples following the model’s chat template.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 系统提示符再次是对Hugging Face默认提示符的轻微修改，后面跟随了一些具体示例，遵循模型的聊天模板。
- en: '[PRE6]py'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE6]py'
- en: result = retrieve_passages("France capital")
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("法国首都")
- en: print("Capital of France:", result)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: print("法国的首都:", result)
- en: '[PRE7]py'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE7]py'
- en: final_answer("The capital of France is Paris.")
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("法国的首都是巴黎。")
- en: '[PRE8]py'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE8]py'
- en: result = retrieve_passages("highest mountain")
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("最高山脉")
- en: print(result)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE9]py'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE9]py'
- en: result = retrieve_passages("world's tallest mountain")
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("世界上最高的山")
- en: print(result)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE10]py'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE10]py'
- en: final_answer("Mauna Kea is the world's tallest mountain, rising about 10,203
    m (33,474 ft) from the Pacific Ocean floor.")
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("茂纳基阿是世界上最高的山脉，从太平洋海底升起约10,203米（33,474英尺）。")
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Page search agent
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 页面搜索代理
- en: This agent reports to the Wikipedia search agent, which provides it with a query
    and the title of a Wikipedia page, and it is tasked to retrieve the relevant information
    to answer the query from that page. This is, in essence, a single-agent RAG system.
    To perform the task, this agent generates custom queries and uses the semantic
    search tool to retrieve the passages that are more similar to them. The semantic
    search tool follows a simple implementation that splits the page contents into
    chunks and embeds them using the FAISS vector database provided by LangChain.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代理报告给维基百科搜索代理，后者为其提供查询和维基百科页面的标题，任务是从该页面中检索相关信息以回答查询。 本质上，这是一个单代理的RAG系统。 为了执行该任务，这个代理生成自定义查询，并使用语义搜索工具来检索与查询更为相似的段落。
    语义搜索工具的实现非常简单，将页面内容拆分成块，并使用LangChain提供的FAISS向量数据库进行嵌入。
- en: Below is the system prompt, still built upon the one provided by default by
    Hugging Face
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是系统提示，仍然基于Hugging Face默认提供的提示构建
- en: '[PRE12]py'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE12]py'
- en: result = search_wikipedia("Seneca philosopher birth")
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: result = search_wikipedia("塞内卡 哲学家 出生")
- en: print("result)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: print("result")
- en: '[PRE13]py'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE13]py'
- en: final_answer("According to the Wikipedia page 'Seneca the Younger', Seneca was
    born in 4 BC.")
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("根据维基百科页面《年轻塞内卡》中的内容，塞内卡生于公元前4年。")
- en: '[PRE14]py'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE14]py'
- en: result = search_wikipedia("Charlemagne predecessor")
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: result = search_wikipedia("查理曼的前任")
- en: print(result)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE15]py'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE15]py'
- en: result = search_info("Charlemagne predecessor", "Charlemagne")
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: result = search_info("查理曼的前任", "查理曼")
- en: print(result)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE16]py'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE16]py'
- en: final_answer("According to the information extracted from the Wikipedia page
    'Charlemagne', his predecessor was Pepin the Short.")
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("根据从维基百科页面《查理曼》提取的信息，他的前任是短小的佩平。")
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Implementation choices
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现选择
- en: In this subsection, I will outline the main points that differ from what could
    be a straightforward implementation of the architecture using Hugging Face agents.
    These are the results of limited trial and error before obtaining a solution that
    works reasonably well. I haven’t performed extensive testing and ablations so
    they may not be the optimal choices.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我将概述与使用Hugging Face代理的架构进行直观实现时的主要区别。这些是有限试错后得到的结果，解决方案效果尚可，但我尚未进行大量测试和消融，因此这些选择可能不是最优的。
- en: '**Prompting:** as explained in the previous sections, each agent has its own
    specialized system prompt that differs from the default one provided by Hugging
    Face Code Agents. I observed that, perhaps due to the limited size of the model
    used, the general standard system prompt was not giving good results. The model
    seems to work best with a system prompt that reflects closely the tasks it is
    asked to perform, including tailored examples of significant use cases. Since
    I used a chat model with the aim of improving instruction following behavior,
    the provided examples follow the model’s chat template to be as close as possible
    to the format encountered during a run.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示：** 如前所述，每个代理都有自己的专用系统提示，与Hugging Face代码代理提供的默认提示不同。我观察到，可能由于所使用的模型大小有限，一般的标准系统提示并没有给出好的结果。该模型似乎在系统提示
    closely 反映任务时效果最佳，包括量身定制的重大用例示例。由于我使用了一个聊天模型，旨在改善指令跟随行为，提供的示例遵循模型的聊天模板，尽可能接近运行时遇到的格式。'
- en: '**Summarizing history:** long execution histories have detrimental effects
    on both execution speed and task performance. The latter could be due to the limited
    ability of the model to retrieve the necessary information from a long context.
    Moreover, extremely long execution histories could exceed the maximum context
    length for the engine model. To mitigate these problems and speed up execution,
    I chose not to show all the details of the previous thought-action-observation
    steps, but instead collected only the previous observations. More specifically,
    at each step the model only receives the following chat history: the system message,
    the first message containing the task, its last action, and all the history of
    the previous observations. Furthermore, execution errors are present in the observation
    history only if they happen in the last step, previous errors that have been already
    solved are discarded.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**历史总结：** 长时间的执行历史对执行速度和任务表现都有不利影响。后者可能是由于模型从长上下文中提取必要信息的能力有限。此外，极长的执行历史可能超出引擎模型的最大上下文长度。为了缓解这些问题并加速执行，我选择不显示之前思考-行动-观察步骤的所有细节，而是仅收集之前的观察记录。更具体地说，在每一步中，模型只接收以下聊天历史：系统消息、包含任务的第一条消息、其最后一项行动和所有之前观察的历史。此外，执行错误仅在最后一步发生时出现在观察历史中，之前已经解决的错误会被丢弃。'
- en: '**Tools vs managed agents:** Hugging Face agents implementationhas native support
    for managed agents but wrapping them as tools allows for better control of the
    prompts and a more streamlined implementation. In particular, Hugging Face implementation
    adds particular prompts to both the managed agents and their managers. While I
    haven’t seen substantial differences in the ability to solve the given task, I
    preferred the second approach as it is more flexible and streamlined for the presented
    architecture, and it allows for easier control over the agents'' behavior. This
    also helps with reducing the prompt length, which is useful for speeding up computations.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工具与托管代理：** Hugging Face 代理实现本身支持托管代理，但将它们包装为工具可以更好地控制提示并实现更加简洁的实现。特别是，Hugging
    Face 实现向托管代理及其管理者添加了特定的提示。虽然我没有看到在解决给定任务的能力上有实质性的区别，但我更倾向于第二种方法，因为它对展示的架构更加灵活和简洁，并且便于更好地控制代理的行为。这也有助于减少提示的长度，从而加速计算。'
- en: '**Limit the maximum number of trials for the page search agent:** sometimes
    the page search agent keeps looking for information on a given page that doesn’t
    contain it. Reducing the maximum number of trials mitigated this issue: after
    reaching that number the agent execution is stopped and the tool returns the last
    observation from code execution.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**限制页面搜索代理的最大试验次数：** 有时页面搜索代理会不断在一个没有信息的页面上寻找信息。减少最大试验次数缓解了这个问题：达到该次数后，代理执行停止，工具返回代码执行的最后一次观察。'
- en: '**Changing tool response to user message:** this is more of a technical, implementation-specific
    point. Since the only supported roles for the chat template of *Qwen2.5–7B-Instruct*
    are system, user, and assistant, observations are returned as user messages.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**改变工具对用户消息的响应：** 这是一个更具技术性、与实现相关的点。由于*Qwen2.5–7B-Instruct*的聊天模板仅支持系统、用户和助手角色，因此观察结果作为用户消息返回。'
- en: Examples
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: In this section, I will collect some examples produced with the described architecture.
    I will also provide the detailed execution of all the agents involved in the task
    to showcase how they interact in some real cases. You can explore more examples
    using the illustrative [Colab notebook](https://colab.research.google.com/drive/1ZxF-Fkv4QV31uo79FagZWFm8tvXgCtBN).
    All the extracted passages are taken from the Wikipedia page specified in the
    execution.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我将收集一些使用所述架构生成的示例。我还将提供所有参与任务的代理的详细执行过程，以展示它们在一些实际案例中的互动。你可以使用插图[Colab笔记本](https://colab.research.google.com/drive/1ZxF-Fkv4QV31uo79FagZWFm8tvXgCtBN)探索更多示例。所有提取的段落都来自执行中指定的维基百科页面。
- en: Let’s start exploring a simple example that requires combining information from
    multiple sources and some basic arithmetic understanding.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始探索一个简单的示例，它需要结合来自多个来源的信息并进行一些基本的算术理解。
- en: '*Task: How many years passed between the construction of the Eiffel Tower and
    the construction of the Empire State Building?*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务：埃菲尔铁塔的建造和帝国大厦的建造之间相隔多少年？*'
- en: Below are the logs of the execution of the manager agent. It can correctly break
    up the task into finding the construction periods for both buildings and compute
    the year difference.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是管理员代理执行的日志。它能够正确地将任务分解为找到两个建筑物的建设周期，并计算出年份差异。
- en: '[PRE18]py'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE18]py'
- en: wikipedia_search_agent(query="Eiffel Tower construction year")
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: wikipedia_search_agent(query="埃菲尔铁塔建造年份")
- en: '[PRE19]py'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE19]py'
- en: wikipedia_search_agent(query="Empire State Building construction year")
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: wikipedia_search_agent(query="帝国大厦建造年份")
- en: '[PRE20]py'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE20]py'
- en: construction_eiffel_tower_start = 1887
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: construction_eiffel_tower_start = 1887
- en: construction_eiffel_tower_end = 1889
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: construction_eiffel_tower_end = 1889
- en: construction_empire_state_building_start = 1930
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: construction_empire_state_building_start = 1930
- en: construction_empire_state_building_end = 1931
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: construction_empire_state_building_end = 1931
- en: years_passed = construction_empire_state_building_start - construction_eiffel_tower_end
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: years_passed = construction_empire_state_building_start - construction_eiffel_tower_end
- en: answer = f"The number of years passed between the construction of the Eiffel
    Tower and the Empire State Building is {years_passed} years."
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: answer = f"从埃菲尔铁塔的建设到帝国大厦建设之间经过了 {years_passed} 年。"
- en: final_answer(answer)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer(answer)
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Let’s now visualize the execution of the Wikipedia search agent. It correctly
    searches and reports the construction periods found in the summary of the pages,
    without needing to inspect the individual pages. It is interesting to note that
    despite being asked generically about the “construction year”, it reports the
    entire construction period as it is not clear if the year refers to the start
    or the end of the construction works.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们可视化维基百科搜索代理的执行过程。它能够正确搜索并报告在页面摘要中找到的建设期间，而无需检查单独的页面。有趣的是，尽管被泛泛地询问“建造年份”，它报告了整个建设期间，因为不清楚问题中的年份指的是建设的开始还是结束。
- en: '[PRE22]py'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE22]py'
- en: search_wikipedia('Eiffel Tower construction year')
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: search_wikipedia('埃菲尔铁塔建造年份')
- en: '[PRE23]py'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE23]py'
- en: final_answer("According to the information extracted from the Wikipedia page
    'Eiffel Tower', the construction of the Eiffel Tower took place from 1887 to 1889.")
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("根据从维基百科页面 '埃菲尔铁塔' 提取的信息，埃菲尔铁塔的建设发生在1887年至1889年之间。")
- en: '[PRE24]py'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE24]py'
- en: search_wikipedia('Empire State Building construction year')
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: search_wikipedia('帝国大厦建造年份')
- en: '[PRE25]py'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE25]py'
- en: final_answer("According to the information extracted from the Wikipedia page
    'Empire State Building', the construction of the Empire State Building started
    in 1930 and ended in 1931.")
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("根据从维基百科页面 '帝国大厦' 提取的信息，帝国大厦的建设始于1930年，结束于1931年。")
- en: '[PRE26]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The passage retrieval agent was not used as all the information was already
    found in the summaries of the pages.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有信息都已经在页面摘要中找到，因此没有使用段落检索代理。
- en: Let’s now try a more complicated example asking if birch plywood floats in alcohol.
    This question requires basic physics understanding and arithmetic abilities, combined
    with non-trivial retrieval tasks.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试一个更复杂的例子，询问桦木胶合板是否会在酒精中浮起来。这个问题需要基本的物理知识和算术能力，并结合非平凡的检索任务。
- en: '*Task: Does birch plywood float in ethanol?*'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务：桦木胶合板在乙醇中会浮起来吗？*'
- en: Let’s first visualize the logs of the various agents.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们可视化各个代理的日志。
- en: Manager agent logs
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员代理日志
- en: '[PRE27]py'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE27]py'
- en: birch_plywood_density_info = wikipedia_search_agent("density of birch plywood")
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: birch_plywood_density_info = wikipedia_search_agent("桦木胶合板的密度")
- en: ethanol_density_info = wikipedia_search_agent("density of ethanol")
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ethanol_density_info = wikipedia_search_agent("乙醇的密度")
- en: print(birch_plywood_density_info)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: print(birch_plywood_density_info)
- en: print(ethanol_density_info)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: print(ethanol_density_info)
- en: '[PRE28]py'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE28]py'
- en: final_answer("Birch plywood will float in ethanol because its density (680 kg/m³)
    is less than the density of ethanol (789.4 kg/m³).")
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("桦木胶合板在乙醇中会浮起来，因为它的密度（680 kg/m³）小于乙醇的密度（789.4 kg/m³）。")
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Wikipedia search agent logs
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Wikipedia 搜索代理日志
- en: '[PRE30]py'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE30]py'
- en: search_wikipedia('birch plywood')
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: search_wikipedia('桦木胶合板')
- en: '[PRE31]py'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE31]py'
- en: search_info('density of birch plywood', 'Plywood')
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: search_info('桦木胶合板的密度', '胶合板')
- en: '[PRE32]py'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE32]py'
- en: final_answer("The density of birch plywood is approximately 680 kg/m³.")
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("桦木胶合板的密度大约是680 kg/m³。")
- en: '[PRE33]py'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE33]py'
- en: search_wikipedia('density of ethanol')
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: search_wikipedia('乙醇的密度')
- en: '[PRE34]py'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE34]py'
- en: search_info('density of ethanol', 'Ethanol (data page)')
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: search_info('乙醇的密度', '乙醇（数据页面）')
- en: '[PRE35]py'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE35]py'
- en: final_answer("The density of ethanol at 20°C is approximately 0.7894 g/cm³.")
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("乙醇在20°C时的密度大约是0.7894 g/cm³。")
- en: '[PRE36]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Page search agent logs
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 页面搜索代理日志
- en: '[PRE37]py'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE37]py'
- en: result = retrieve_passages("density of birch plywood")
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("桦木胶合板的密度")
- en: print(result)
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE38]py'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE38]py'
- en: final_answer("The density of birch plywood is approximately 680 kg/m³.")
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("桦木胶合板的密度约为680 kg/m³。")
- en: '[PRE39]py'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE39]py'
- en: result = retrieve_passages("density of ethanol")
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("乙醇的密度")
- en: print(result)
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE40]py'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE40]py'
- en: Extract the coefficients from the equation
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从方程中提取系数
- en: a = -8.461834e-4
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: a = -8.461834e-4
- en: b = 0.8063372
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: b = 0.8063372
- en: Calculate the density at a specific temperature, let's take 20°C as an example
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算特定温度下的密度，我们以20°C为例
- en: temperature = 20
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: temperature = 20
- en: density = a * temperature + b
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: density = a * temperature + b
- en: print(density)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: print(density)
- en: '[PRE41]py'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE41]py'
- en: final_answer(f"The density of ethanol at 20°C is approximately {round(0.789413532,
    4)} g/cm³.")
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer(f"20°C下乙醇的密度约为{round(0.789413532, 4)} g/cm³。")
- en: '[PRE42]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The model correctly identifies density difference as the cause of floating/sinking,
    breaks up the task into finding the density of both substances, and is able to
    draw the correct conclusion from the retrieved data despite them being in different
    units of measurement.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型正确地识别出密度差异是浮沉的原因，将任务分解为查找两种物质的密度，并能够从检索到的数据中得出正确的结论，尽管这些数据的单位不同。
- en: Limitations
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制
- en: 'The discussed system has impressive capabilities, especially considering the
    limited size of the engine model used, but of course, it has its own limitations.
    The bigger one seems to be related to the power of the engine model itself: while
    it seems able to understand and follow complex and long instructions as well as
    to use the provided tools correctly, sometimes it fails to comply with simple
    guidelines and it tends to repeat unfruitful actions without changes. This is
    particularly prominent when the information the agent is looking for is not present
    (or not easily extractible using the semantic search tool) from the provided pages.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论的系统具有令人印象深刻的能力，特别是考虑到使用的引擎模型的有限规模，但当然，它也有自己的局限性。最大的局限似乎与引擎模型本身的能力有关：虽然它似乎能够理解并执行复杂且冗长的指令，以及正确使用提供的工具，但有时它未能遵循简单的指南，并且往往会重复无效的操作而没有变化。当代理寻找的信息不存在（或无法通过语义搜索工具轻松提取）时，这种情况尤为突出。
- en: Another drawback, intrinsic to agentic and even more prominent in multi-agentic
    systems, is the computation time needed for the various agents' execution. In
    some simple cases where the standard RAG workflow would have been enough to answer
    the question, this could produce an unnecessary computational overhead.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个缺点是，代理系统本身固有的，尤其是在多代理系统中更为突出的是，各个代理执行所需的计算时间。在一些简单的案例中，标准的RAG工作流足以回答问题，但这可能会产生不必要的计算开销。
- en: Finally, having multiple agents interacting with each other can amplify the
    risk of hallucinations, as a hallucination made by one agent could propagate over
    the execution chain, making it also very difficult to track.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，多个代理之间的相互作用可能会放大幻觉的风险，因为一个代理产生的幻觉可能会在执行链中传播，使得追踪变得非常困难。
- en: Let’s visualize an example in which the system, while still providing the correct
    answer, made excessive use of tool calls (with some repeated actions) unnecessarily
    extending the execution time.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个示例来可视化，系统虽然仍然提供了正确答案，但在没有必要的情况下过度使用了工具调用（并重复某些操作），不必要地延长了执行时间。
- en: '*Task: Which dynasty was ruling China at the time of the fall of Constantinople?*'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务：君士坦丁堡陷落时，中国正由哪个朝代统治？*'
- en: The task requires a good level of abstraction since the two events are not related
    and the exact year of the fall of Constantinople may not be reported on the page
    of the corresponding dynasty.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 该任务要求较高的抽象能力，因为这两件事没有直接关系，且君士坦丁堡陷落的确切年份可能没有出现在相应朝代的页面上。
- en: The manager agent execution is still lean and on point, solving the task correctly
    by first retrieving the date of the fall of Constantinople and then looking for
    Chinese dynasties in that year. However, we can already see that the search results,
    while still containing the required information, seem a bit strange.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员代理的执行仍然简洁且精准，通过首先检索君士坦丁堡陷落的日期，再查找该年份的中国朝代，正确解决了任务。然而，我们已经可以看到，尽管搜索结果仍包含所需的信息，但看起来有些奇怪。
- en: '[PRE43]py'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE43]py'
- en: wikipedia_search_agent(query="Fall of Constantinople")
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: wikipedia_search_agent(query="君士坦丁堡陷落")
- en: '[PRE44]py'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE44]py'
- en: wikipedia_search_agent(query="Chinese dynasties 1453")
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: wikipedia_search_agent(query="1453年中国朝代")
- en: '[PRE45]py'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE45]py'
- en: final_answer("The dynasty ruling China when Constantinople fell in 1453 was
    the Ming dynasty.")
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("1453年君士坦丁堡陷落时，中国的统治朝代是明朝。")
- en: '[PRE46]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Let’s thus inspect the corresponding Wikipedia search agent tasks and their
    execution. We can see that, possibly due to the broad task “Fall of Constantinople”,
    the agent looks at other specific information after having found the correct date.
    The same happens when retrieving information about the Chinese dynasties, with
    the further problem that some tool calls were repeated identically.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们检查相应的维基百科搜索代理任务及其执行情况。我们可以看到，可能由于“君士坦丁堡的陷落”这一广泛的任务，代理在找到正确日期后，查看了其他具体信息。检索关于中国朝代的信息时也发生了类似情况，此外还出现了某些工具调用被重复执行的问题。
- en: '[PRE47]py'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE47]py'
- en: search_wikipedia("Fall of Constantinople")
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: search_wikipedia("君士坦丁堡的陷落")
- en: '[PRE48]py'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE48]py'
- en: search_info("leader of the Ottoman Empire in 1453", "Fall of Constantinople")
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: search_info("奥斯曼帝国领导人 1453", "君士坦丁堡的陷落")
- en: '[PRE49]py'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE49]py'
- en: final_answer("The leader of the Ottoman Empire in 1453, during the fall of Constantinople,
    was Mehmed II, also known as Mehmed the Conqueror.")
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("1453年，君士坦丁堡陷落时，奥斯曼帝国的领导人是穆罕默德二世，也称为征服者穆罕默德。")
- en: '[PRE50]py'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE50]py'
- en: search_wikipedia('Chinese dynasties 1453')
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: search_wikipedia('中国朝代 1453')
- en: '[PRE51]py'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE51]py'
- en: search_info('1453', 'Ming dynasty')
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: search_info('1453', '明朝')
- en: '[PRE52]py'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE52]py'
- en: search_info('1453', 'Ming dynasty')
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: search_info('1453', '明朝')
- en: '[PRE53]py'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE53]py'
- en: search_info('1453', 'Ming dynasty')
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: search_info('1453', '明朝')
- en: '[PRE54]py'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE54]py'
- en: search_info('1453', 'Ming dynasty')
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: search_info('1453', '明朝')
- en: '[PRE55]py'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE55]py'
- en: final_answer("In 1453, the Ming dynasty was in full control of China. No specific
    events related to 1453 are mentioned in the information provided.")
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("1453年，明朝完全控制了中国。提供的信息中没有提及与1453年相关的具体事件。")
- en: '[PRE56]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Diving deeper into the page search agent execution, we see that this also repeated
    multiple tool calls with the same parameters.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 深入分析页面搜索代理执行情况，我们看到这也重复了多次使用相同参数的工具调用。
- en: '[PRE57]py'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE57]py'
- en: result = retrieve_passages("leader of the Ottoman Empire in 1453")
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("奥斯曼帝国领导人 1453")
- en: print(result)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE58]py'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE58]py'
- en: final_answer("The leader of the Ottoman Empire in 1453 was Mehmed II, also known
    as Mehmed the Conqueror.")
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("1453年，奥斯曼帝国的领导人是穆罕默德二世，也称为征服者穆罕默德。")
- en: '[PRE59]py'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE59]py'
- en: result = retrieve_passages("1453 Ming dynasty")
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("1453 明朝")
- en: print(result)
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE60]py'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE60]py'
- en: final_answer("The year 1453 falls within the period of the Ming dynasty, which
    ruled from 1368 to 1644\. During this time, the Ming dynasty was in full control
    of China and experienced significant developments such as the construction of
    the Forbidden City and the expansion of the Great Wall of China.")
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("1453年属于明朝时期，明朝统治时间为1368年到1644年。在这段时间里，明朝完全控制了中国，并经历了如紫禁城的建造和长城扩建等重要发展。")
- en: '[PRE61]py'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE61]py'
- en: result = retrieve_passages("1453 Ming dynasty")
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("1453 明朝")
- en: print(result)
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE62]py'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE62]py'
- en: final_answer("The year 1453 falls within the period of the Ming dynasty, which
    ruled from 1368 to 1644\. During this time, the Ming dynasty was in full control
    of China and experienced significant developments such as the construction of
    the Forbidden City and the expansion of the Great Wall of China.")
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("1453年属于明朝时期，明朝统治时间为1368年到1644年。在这段时间里，明朝完全控制了中国，并经历了如紫禁城的建造和长城扩建等重要发展。")
- en: '[PRE63]py'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE63]py'
- en: result = retrieve_passages("1453 Ming dynasty")
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("1453 明朝")
- en: print(result)
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE64]py'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE64]py'
- en: final_answer("The year 1453 falls within the period of the Ming dynasty, which
    ruled from 1368 to 1644\. During this time, the Ming dynasty was in full control
    of China and experienced significant developments such as the construction of
    the Forbidden City and the expansion of the Great Wall of China.")
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("1453年属于明朝时期，明朝统治时间为1368年到1644年。在这段时间里，明朝完全控制了中国，并经历了如紫禁城的建造和长城扩建等重要发展。")
- en: '[PRE65]py'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE65]py'
- en: result = retrieve_passages("1453 Ming dynasty")
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: result = retrieve_passages("1453 明朝")
- en: print(result)
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE66]py'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE66]py'
- en: final_answer("The year 1453 falls within the period of the Ming dynasty, which
    ruled from 1368 to 1644\. During this time, the Ming dynasty was in full control
    of China and experienced significant developments such as the construction of
    the Forbidden City and the expansion of the Great Wall of China.")
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: final_answer("1453年属于明朝时期，明朝自1368年到1644年统治中国。在此期间，明朝完全控制了中国，并经历了重要的历史发展，例如紫禁城的建设和长城的扩展。")
- en: '[PRE67]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Conclusion
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this blog post, I explained how to create a multi-agentic RAG system using
    code agents and a “small” open-source LLM like *Qwen2.5–7B-Instruct*. I have discussed
    the main architectural features and some specific choices relative to the Hugging
    Face code agent implementation that I made to improve the result. The full code
    details are available in the following [GitHub repo](https://github.com/GabrieleSgroi/multiagentic_rag).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我解释了如何使用代码智能体和一个“小型”开源LLM（如*Qwen2.5–7B-Instruct*）创建一个多智能体RAG系统。我讨论了主要的架构特征以及我在实现Hugging
    Face代码智能体时做出的一些具体选择，以提高结果。完整的代码细节可在以下[GitHub仓库](https://github.com/GabrieleSgroi/multiagentic_rag)中找到。
- en: 'The multi-agentic system described, despite being powered by a small model
    running on consumer-grade hardware, can solve multi-hop question-answering tasks
    related to complex queries. In particular:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管该多智能体系统由一个运行在消费级硬件上的小型模型驱动，但它能够解决与复杂查询相关的多跳问答任务。特别是：
- en: It can break down the query into manageable sub-tasks;
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以将查询分解为可管理的子任务；
- en: It can identify the Wikipedia pages containing the necessary information;
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以识别包含必要信息的维基百科页面；
- en: It can combine information coming from multiple pages;
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以将来自多个页面的信息进行整合；
- en: It can search for detailed information on a Wikipedia page;
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以在维基百科页面上搜索详细信息；
- en: It can determine whether it needs more information and tries to find it;
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以判断是否需要更多的信息并尝试去寻找；
- en: It can successfully fix small bugs in the code it produces and handle tool errors
    (like Wikipedia disambiguation errors).
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以成功修复它生成的代码中的小错误，并处理工具错误（如维基百科的歧义错误）。
- en: I have also outlined some limitations of the system, such as increased computation
    time, repetitive actions, and the potential propagation of hallucinations. The
    latter could be mitigated by including in the system a “proofreader” agent that
    checks that the reported information is in agreement with the retrieved sources.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我还概述了该系统的一些局限性，例如增加的计算时间、重复的操作以及潜在的幻觉传播。后者可以通过在系统中加入一个“校对员”智能体来缓解，确保报告的信息与检索到的来源一致。
- en: It is also worth noting that, since the agentic system has a standard RAG approach
    at its core, all the usual techniques used to improve the efficiency and accuracy
    of the latter can be implemented in the framework.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得注意的是，由于该智能体系统的核心采用了标准的RAG方法，因此可以在框架中实现所有通常用于提高RAG效率和准确性的技术。
- en: Another possible improvement is to use techniques to increase test time computation
    to give the model more “time to think” similar to OpenAI o1/o3 models. It is however
    important to note that this modification will further increase execution time.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能的改进是使用技术来增加测试时间计算，给予模型更多的“思考时间”，类似于OpenAI的o1/o3模型。然而，值得注意的是，这一修改将进一步增加执行时间。
- en: Finally, since the multi-agentic system is made up of agents specialized in
    a single task, using a different model engine for each of them could improve the
    performance. In particular, it is possible to fine-tune a different model for
    each task in the system for further performance gains. This could be particularly
    beneficial for small models. It is worth mentioning that fine-tuning data can
    be collected by running the system on a set of predetermined tasks and saving
    the agents' output when the system produces the correct answer, thus eliminating
    the need for expensive manual data annotation.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于多智能体系统由专注于单一任务的智能体组成，因此为每个智能体使用不同的模型引擎可能会提升性能。特别是，可以针对系统中的每个任务对不同的模型进行微调，从而进一步提高性能。这对于小型模型尤其有利。值得一提的是，微调数据可以通过在一组预定任务上运行系统并保存智能体在系统给出正确答案时的输出，从而收集，这样可以避免昂贵的人工数据标注。
- en: I hope you found this tutorial useful, you can find the full code implementation
    in the [GitHub repo](https://github.com/GabrieleSgroi/multiagentic_rag) and try
    it yourself in the [Colab notebook](https://colab.research.google.com/drive/1ZxF-Fkv4QV31uo79FagZWFm8tvXgCtBN).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你觉得这个教程有用，你可以在[GitHub 仓库](https://github.com/GabrieleSgroi/multiagentic_rag)中找到完整的代码实现，并在[Colab
    笔记本](https://colab.research.google.com/drive/1ZxF-Fkv4QV31uo79FagZWFm8tvXgCtBN)中亲自尝试。
