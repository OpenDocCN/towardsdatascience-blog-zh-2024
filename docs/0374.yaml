- en: ECCCos from the Black Box
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ecccos-from-the-black-box-c4bd6ef20263?source=collection_archive---------4-----------------------#2024-02-08](https://towardsdatascience.com/ecccos-from-the-black-box-c4bd6ef20263?source=collection_archive---------4-----------------------#2024-02-08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@patrick.altmeyer?source=post_page---byline--c4bd6ef20263--------------------------------)[![Patrick
    Altmeyer](../Images/b4c0bd875390f6dc8b81480f0712fea5.png)](https://medium.com/@patrick.altmeyer?source=post_page---byline--c4bd6ef20263--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c4bd6ef20263--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c4bd6ef20263--------------------------------)
    [Patrick Altmeyer](https://medium.com/@patrick.altmeyer?source=post_page---byline--c4bd6ef20263--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c4bd6ef20263--------------------------------)
    ·15 min read·Feb 8, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Counterfactual explanations offer an intuitive and straightforward way to explain
    opaque machine learning (ML) models. They work under the premise of perturbing
    inputs to achieve a desired change in the predicted output.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have not heard about counterfactual explanations before, feel free to
    also check out my introductory posts: 1) [Individual Recourse for Black Box Models](https://medium.com/towards-data-science/individual-recourse-for-black-box-models-5e9ed1e4b4cc)
    and 2) [A new tool for explainable AI](https://medium.com/towards-data-science/a-new-tool-for-explainable-ai-65834e757c28).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are typically many ways to achieve this, in other words, many different
    counterfactuals may yield the same desired outcome. A key challenge for researchers
    has therefore been to, firstly, define certain desirable characteristics of counterfactual
    explanations and, secondly, come up with efficient ways to achieve them.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the most important and studied characteristics of counterfactual explanations
    is ‘plausibility’: explanations should look realistic to humans. Plausibility
    is positively associated with actionability, robustness (Artelt et al. 2021) and
    causal validity (Mahajan, Tan, and Sharma 2020). To achieve plausibility, many
    existing approaches rely on surrogate models. This is straightforward but it also
    convolutes things further: it essentially reallocates the task of learning plausible
    explanations for the data from the model itself to the surrogate.'
  prefs: []
  type: TYPE_NORMAL
