<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A Visual Exploration of Semantic Text Chunking</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>A Visual Exploration of Semantic Text Chunking</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-visual-exploration-of-semantic-text-chunking-6bb46f728e30?source=collection_archive---------1-----------------------#2024-09-19">https://towardsdatascience.com/a-visual-exploration-of-semantic-text-chunking-6bb46f728e30?source=collection_archive---------1-----------------------#2024-09-19</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="fr fs ft fu fv fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/f3920b86cf68505cb2d81e429fb627c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UgytjYbLWEIIp-wl1N8qRw.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Dalle3’s interpretation of “Semantic Chunking”. Image generated by the author.</figcaption></figure><div/><div><h2 id="181f" class="pw-subtitle-paragraph hh gj gk bf b hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw cq dx">Use embeddings and visualization tools to split text into meaningful chunks</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hx hy hz ia ib ab"><div><div class="ab ic"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@rmartinshort?source=post_page---byline--6bb46f728e30--------------------------------" rel="noopener follow"><div class="l id ie by if ig"><div class="l ed"><img alt="Robert Martin-Short" class="l ep by dd de cx" src="../Images/e3910071b72a914255b185b850579a5a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*-jfunT2ldyjlLaMX0t8PDA.jpeg"/><div class="ih by l dd de em n ii eo"/></div></div></a></div></div><div class="ij ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--6bb46f728e30--------------------------------" rel="noopener follow"><div class="l ik il by if im"><div class="l ed"><img alt="Towards Data Science" class="l ep by br in cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ih by l br in em n ii eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="io ab q"><div class="ab q ip"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b iq ir bk"><a class="af ag ah ai aj ak al am an ao ap aq ar is" data-testid="authorName" href="https://medium.com/@rmartinshort?source=post_page---byline--6bb46f728e30--------------------------------" rel="noopener follow">Robert Martin-Short</a></p></div></div></div><span class="it iu" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b iq ir dx"><button class="iv iw ah ai aj ak al am an ao ap aq ar ix iy iz" disabled="">Follow</button></p></div></div></span></div></div><div class="l ja"><span class="bf b bg z dx"><div class="ab cn jb jc jd"><div class="je jf ab"><div class="bf b bg z dx ab jg"><span class="jh l ja">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar is ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--6bb46f728e30--------------------------------" rel="noopener follow"><p class="bf b bg z ji jj jk jl jm jn jo jp bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="it iu" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">18 min read</span><div class="jq jr l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 19, 2024</span></div></span></div></span></div></div></div><div class="ab cp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="h k w ea eb q"><div class="kx l"><div class="ab q ky kz"><div class="pw-multi-vote-icon ed jh la lb lc"><div class=""><div class="ld le lf lg lh li lj am lk ll lm lc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ln lo lp lq lr ls lt"><p class="bf b dy z dx"><span class="le">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ld lw lx ab q ee ly lz" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lv"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lu lv">3</span></p></button></div></div></div><div class="ab q ki kj kk kl km kn ko kp kq kr ks kt ku kv kw"><div class="ma k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al mb an ao ap ix mc md me" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep mf cn"><div class="l ae"><div class="ab cb"><div class="mg mh mi mj mk gb ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al mb an ao ap ix ml mm lz mn mo mp mq mr s ms mt mu mv mw mx my u mz na nb"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al mb an ao ap ix ml mm lz mn mo mp mq mr s ms mt mu mv mw mx my u mz na nb"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al mb an ao ap ix ml mm lz mn mo mp mq mr s ms mt mu mv mw mx my u mz na nb"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="a613" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><strong class="nm gl"><em class="og">This article offers an explanation of semantic text chunking, a technique designed to automatically group similar pieces of text that can be employed as part of the pre-processing stage of a pipeline for Retrieval Augmented Generation (RAG) or a similar applications. We use visualizations to understand what the chunking is doing, and we explore some extensions that involve clustering and LLM-powered labeling. Check out the full code </em></strong><a class="af oh" href="https://github.com/rmartinshort/text_chunking" rel="noopener ugc nofollow" target="_blank"><strong class="nm gl"><em class="og">here</em></strong></a><strong class="nm gl"><em class="og">.</em></strong></p></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="ed8f" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Automatic information retrieval and summarization of large volumes of text has many useful applications. One of the most well developed is Retrieval Augmented Generation (RAG), which involves extraction of relevant chunks of text from a large corpus — typically via semantic search or some other filtering step — in response to a user question. Then, the chunks are interpreted or summarized by an LLM with the aim of providing a high quality, accurate answer. In order for the extracted chunks to be as relevant as possible to the question its very helpful for them to be semantically coherent, meaning that each chunk is “about” a specific concept and contains a useful packet of information in it’s own right.</p><p id="7c97" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Chunking has applications beyond RAG too. Imagine we have a complex document like a book or journal article and want to quickly understand what key concepts it contains. If the text can be clustered into semantically coherent groups and then each cluster summarized in some way, this can really help speed up time to insights. The excellent package <a class="af oh" href="https://maartengr.github.io/BERTopic/index.html" rel="noopener ugc nofollow" target="_blank">BertTopic</a> (see <a class="af oh" rel="noopener" target="_blank" href="/topics-per-class-using-bertopic-252314f2640">this article</a> for a nice overview) can help here.</p><p id="93fe" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Visualization of the chunks can also be insightful, both as a final product and during development. Humans are visual learners in that our brains are much faster at gleaning information from graphs and images rather than streams of text. In my experience, it’s quite difficult to understand what a chunking algorithm has done to the text — and what the optimal parameters might be — without visualizing the chunks in some way or reading them all, which is impractical in the case of large documents.</p><p id="023f" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">In this article, we’re going to explore a method to split text into semantically meaningful chunks with an emphasis on using graphs and plots to understand what’s going on. In doing so, we’ll touch on dimensionality reduction and hierarchical clustering of embedding vectors, in addition to the use of LLMs to summarize the chunks so that we can quickly see what information is present. My hope is that this might spark further ideas for anyone researching semantic chunking as a potential tool in their application. I’ll be using Python 3.9, LangChain and Seaborn here, with full details in the <a class="af oh" href="https://github.com/rmartinshort/text_chunking" rel="noopener ugc nofollow" target="_blank">repo</a>.</p><h2 id="d729" class="oi oj gk bf ok ol om on oo op oq or os nt ot ou ov nx ow ox oy ob oz pa pb pc bk"><strong class="al">1. What is semantic chunking?</strong></h2><p id="38a2" class="pw-post-body-paragraph nk nl gk nm b hi pd no np hl pe nr ns nt pf nv nw nx pg nz oa ob ph od oe of fj bk">There are a few standard types of chunking and to learn more about them I recommend <a class="af oh" href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb" rel="noopener ugc nofollow" target="_blank">this excellent tutorial</a>, which also provided inspiration for this article. Assuming we are dealing with English text, the simplest form of chunking is character based, where we choose a fixed window of characters and simply break up the text into chunks of that length. Optionally we can add an overlap between the chunks to preserve some indication of the sequential relationship between them. This is computationally straightforward but there is no guarantee that the chunks will be semantically meaningful or even complete sentences.</p><p id="68c0" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Recursive chunking is typically more useful and is seen as the go-to first algorithm for many applications. The process takes in hierarchical list of separators (the default in LangChain is <code class="cx pi pj pk pl b">[“\n\n”, “\n”, “ ”, “”]</code> ) and a target length. It then splits up the text using the separators in a recursive way, advancing down the list until each chunk is less than or equal to the target length. This is much better at preserving full paragraphs and sentences, which is good because it makes the chunks much more likely to be coherent. However it does not consider semantics: If one sentence follows on from the last and happens to be at the end of the chunk window, the sentences will be separated.</p><p id="d546" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">In semantic chunking, which has implementations in both <a class="af oh" href="https://python.langchain.com/v0.2/docs/how_to/semantic-chunker/" rel="noopener ugc nofollow" target="_blank">LangChain</a> and <a class="af oh" href="https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/semantic_splitter/#llama_index.core.node_parser.SemanticSplitterNodeParser" rel="noopener ugc nofollow" target="_blank">LlamaIndex</a>, the splits are made based on the cosine distance between embeddings of sequential chunks. So we start by dividing the text into small but coherent groups, perhaps using a recursive chunker.</p><p id="d6b0" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Next we take vectorize each chunk using a model that has been trained to generate meaningful embeddings. Typically this takes the form of a transformer-based bi-encoder (see the <a class="af oh" href="https://sbert.net/" rel="noopener ugc nofollow" target="_blank">SentenceTransformers</a> library for details and examples), or an <a class="af oh" href="https://platform.openai.com/docs/guides/embeddings" rel="noopener ugc nofollow" target="_blank">endpoint such as OpenAI’s </a><code class="cx pi pj pk pl b"><a class="af oh" href="https://platform.openai.com/docs/guides/embeddings" rel="noopener ugc nofollow" target="_blank">text-embeddings-3-small</a></code> , which is what we use here. Finally, we look at the cosine distances between the embeddings of subsequent chunks and choose breakpoints where the distances are large. Ideally, this helps to create groups of text that are both coherent and semantically distinct.</p><p id="2e52" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">A recent extension of this called <a class="af oh" href="https://docs.llamaindex.ai/en/stable/examples/node_parsers/semantic_double_merging_chunking/" rel="noopener ugc nofollow" target="_blank">semantic double chunk merging</a> (see <a class="af oh" href="https://bitpeak.pl/chunking-methods-in-rag-methods-comparison/" rel="noopener ugc nofollow" target="_blank">this article</a> for details) attempts to extend this by doing a second pass and using some re-grouping logic. So for example if the first pass has put a break between chunks 1 and 2, but chunks 1 and 3 are very similar, it will make a new group that includes chunks 1, 2 and 3. This proves useful if chunk 2 was, for example, a mathematical formula or a code block.</p><p id="0725" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">However, when it comes to any type of semantic chunking some key questions remain: How large can the distance between chunk embeddings get before we make a breakpoint, and what do these chunks actually represent? Do we care about that? Answers to these questions depend on the application and the text in question.</p><h1 id="1ddd" class="pm oj gk bf ok pn po hk oo pp pq hn os pr ps pt pu pv pw px py pz qa qb qc qd bk"><strong class="al">2. Exploring the breakpoints</strong></h1><p id="2022" class="pw-post-body-paragraph nk nl gk nm b hi pd no np hl pe nr ns nt pf nv nw nx pg nz oa ob ph od oe of fj bk">Let’s use an example to illustrate the generation of breakpoints using semantic chunking. We will implement our own version of this algorithm, though out of the box implementations are also available as described above. Our demo text is <a class="af oh" href="https://github.com/rmartinshort/text_chunking/blob/main/text_chunking/datasets/test_text_dataset.py" rel="noopener ugc nofollow" target="_blank">here</a> and it consists of three short, factual essays written by GPT-4o and appended together. The first is about the general importance of preserving trees, the second is about the history of Namibia and the third is a deeper exploration of the importance of protecting trees for medical purposes. The topic choice doesn’t really matter, but the corpus represents an interesting test because the first and third essays are somewhat similar, yet separated by the second which is very different. Each essay is also broken into sections focussing on different things.</p><p id="1a22" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">We can use a basic <code class="cx pi pj pk pl b">RecursiveCharacterTextSplitter</code> to make the initial chunks. The most important parameters here are the chunk size and separators list, and we typically don’t know what they should be without some subject knowledge of the text. Here I chose a relatively small chunk size because I want the initial chunks to be at most a few sentences long. I also chose the separators such that we avoid splitting sentences.</p><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="5bcc" class="qm oj gk pl b bg qn qo l qp qq"># tools from the text chunking package mentioned in this article<br/>from text_chunking.SemanticClusterVisualizer import SemanticClusterVisualizer<br/># put your open ai api key in a .env file in the top level of the package<br/>from text_chunking.utils.secrets import load_secrets<br/># the example text we're talking about <br/>from text_chunking.datasets.test_text_dataset import TestText<br/><br/># basic splitter<br/>from langchain_text_splitters import RecursiveCharacterTextSplitter<br/>import seaborn as sns</span></pre><pre class="qr qj pl qk bp ql bb bk"><span id="8f3a" class="qm oj gk pl b bg qn qo l qp qq">splitter = RecursiveCharacterTextSplitter(<br/>        chunk_size=250,<br/>        chunk_overlap=0,<br/>        separators=["\n\n", "\n", "."],<br/>        is_separator_regex=False<br/>)</span></pre><p id="a0e4" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Next we can split the text. The <code class="cx pi pj pk pl b">min_chunk_len</code> parameter comes into play if any of the chunks generated by the splitter are smaller than this value. If that happens, that chunk just gets appended to the end of the previous one.</p><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="5095" class="qm oj gk pl b bg qn qo l qp qq">original_split_texts = semantic_chunker.split_documents(<br/>    splitter, <br/>    TestText.testing_text, <br/>    min_chunk_len=100, <br/>    verbose=True<br/>)<br/><br/>### Output<br/># 2024-09-14 16:17:55,014 - Splitting text with original splitter<br/># 2024-09-14 16:17:55,014 - Creating 53 chunks<br/># Mean len: 178.88679245283018<br/># Max len: 245<br/># Min len: 103</span></pre><p id="2997" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Now we can embed the splits using the embeddings model. You’ll see in the class for <code class="cx pi pj pk pl b"><a class="af oh" href="https://github.com/rmartinshort/text_chunking/blob/main/text_chunking/SemanticClusterVisualizer.py" rel="noopener ugc nofollow" target="_blank">SemanticClusterVisualizer</a></code> that by default we’re using <code class="cx pi pj pk pl b">text-embeddings-3-small</code> . This will create a list of 53 vectors, each of length 1536. Intuitively, this means that the semantic meaning of each chunk is represented in a 1536 dimensional space. Not great for visualization, which is why we’ll turn to dimensionality reduction later.</p><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="b86e" class="qm oj gk pl b bg qn qo l qp qq">original_split_text_embeddings = semantic_chunker.embed_original_document_splits(original_split_texts)<br/></span></pre><p id="77a8" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Running the semantic chunker generates a graph like this. We can think of it like a time series, where the x-axis represents distance through the entire text in terms of characters. The y axis represents the cosine distance between the embeddings of subsequent chunks. The break points occur at distances values above the 95th percentile.</p></div></div><div class="fw"><div class="ab cb"><div class="mg qs mh qt mi qu cf qv cg qw ci bh"><figure class="qe qf qg qh qi fw qy qz paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qx"><img src="../Images/e940488f2fe8a7b5a4510091e7ffd230.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*uxTfrIHJhHeWjDRhi-yhhQ.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Graph showing the cosine distance between subsequent chunks of text generated by the RecursiveCharacterTextSplitter. We can use these distances to establish breakpoints for semantic chunking. Image generated by the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="b439" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The pattern makes sense given what we know about the text — there are three big subjects, each of which has a few different sections. Aside from the two large spikes though, it’s not clear where the other breakpoints should be.</p><p id="0a91" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">This is where the subjectivity and iteration comes in — depending on our application, we may want larger or smaller chunks and it’s important to use the graph to help guide our eye towards which chunks to actually read.</p><p id="1744" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">There are a few ways we could break the text into more granular chunks. The first is just to decrease the percentile threshold to make a breakpoint.</p></div></div><div class="fw"><div class="ab cb"><div class="mg qs mh qt mi qu cf qv cg qw ci bh"><figure class="qe qf qg qh qi fw qy qz paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp ra"><img src="../Images/9cd03a729e49f3b62d411890e66325a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*5A9pmoRX5_r7hEmRo7nAmg.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Breakpoints generated by choosing a lower percentile threshold on the cosine distances array. Image generated by the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="5368" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">This creates 4 really small chunks and 8 larger ones. If we look at the first 4 chunks, for example, the splits seem semantically reasonable although I would argue that the 4th chunk is a bit too long, given that it contains most of the “economic importance”, “social importance” and “conclusions” sections of the first essay.</p><figure class="qe qf qg qh qi fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp rb"><img src="../Images/4c8f630c99b29e79fa59ddc8b45793df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zOD-8KoGzfTY6OfNlJ1Uvg.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">The first four semantic chunks generated by setting percentile threshold at 0.8. Image generated by the author.</figcaption></figure><p id="abaf" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Instead of just changing the percentile threshold, an alternative idea is to apply the same threshold recursively. We start by creating breakpoints on the whole text. Then for each newly created chunk, if the chunk is above some length threshold, we create breakpoints just within that chunk. This happens until all the chunks are below the length threshold. Although somewhat subjective, I think this more closely mirrors what a human would do in that they would first identify very different groups of text and then iteratively reduce the size of each one.</p><p id="68e9" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">It can be implemented with a stack, as shown below.</p><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="3865" class="qm oj gk pl b bg qn qo l qp qq">def get_breakpoints(<br/>    embeddings: List[np.ndarray],<br/>    start: int = 0,<br/>    end: int = None,<br/>    threshold: float = 0.95,<br/>) -&gt; np.ndarray:<br/>    """<br/>    Identifies breakpoints in embeddings based on cosine distance threshold.<br/><br/>    Args:<br/>        embeddings (List[np.ndarray]): A list of embeddings.<br/>        start (int, optional): The starting index for processing. Defaults to 0.<br/>        end (int, optional): The ending index for processing. Defaults to None.<br/>        threshold (float, optional): The percentile threshold for determining significant distance changes. Defaults to 0.95.<br/><br/>    Returns:<br/>        np.ndarray: An array of indices where breakpoints occur.<br/>    """<br/>    if end is not None:<br/>        embeddings_windowed = embeddings[start:end]<br/>    else:<br/>        embeddings_windowed = embeddings[start:]<br/><br/>    len_embeddings = len(embeddings_windowed)<br/>    cdists = np.empty(len_embeddings - 1)<br/>    <br/>    # get the cosine distances between each chunk and the next one<br/>    for i in range(1, len_embeddings):<br/>        cdists[i - 1] = cosine(embeddings_windowed[i], embeddings_windowed[i - 1])<br/>    <br/>    # get the breakpoints<br/>    difference_threshold = np.percentile(cdists, 100 * threshold, axis=0)<br/>    difference_exceeding = np.argwhere(cdists &gt;= difference_threshold).ravel()<br/><br/>    return difference_exceeding<br/><br/>def build_chunks_stack(<br/>    self, length_threshold: int = 20000, cosine_distance_percentile_threshold: float = 0.95<br/>) -&gt; np.ndarray:<br/>    """<br/>    Builds a stack of text chunks based on length and cosine distance thresholds.<br/><br/>    Args:<br/>        length_threshold (int, optional): Minimum length for a text chunk to be considered valid. Defaults to 20000.<br/>        cosine_distance_percentile_threshold (float, optional): Cosine distance percentile threshold for determining breakpoints. Defaults to 0.95.<br/><br/>    Returns:<br/>        np.ndarray: An array of indices representing the breakpoints of the chunks.<br/>    """<br/>    <br/>    # self.split texts are the original split texts <br/>    # self.split text embeddings are their embeddings <br/>    S = [(0, len(self.split_texts))]<br/>    all_breakpoints = set()<br/>    while S:<br/>        # get the start and end of this chunk<br/>        id_start, id_end = S.pop()<br/><br/>        # get the breakpoints for this chunk<br/>        updated_breakpoints = self.get_breakpoints(<br/>            self.split_text_embeddings,<br/>            start=id_start,<br/>            end=id_end,<br/>            threshold=cosine_distance_percentile_threshold,<br/>        )<br/>        updated_breakpoints += id_start<br/><br/>        # add the updated breakpoints to the set<br/>        updated_breakpoints = np.concatenate(<br/>            (np.array([id_start - 1]), updated_breakpoints, np.array([id_end]))<br/>        )<br/>        <br/>        # for each updated breakpoint, add its bounds to the set and<br/>        # to the stack if it is long enough<br/>        for index in updated_breakpoints:<br/>            text_group = self.split_texts[id_start : index + 1]<br/>            if (len(text_group) &gt; 2) and (<br/>                self.get_text_length(text_group) &gt;= length_threshold<br/>            ):<br/>                S.append((id_start, index))<br/>            id_start = index + 1<br/>        all_breakpoints.update(updated_breakpoints)<br/>    <br/>    # get all the breakpoints except the start and end (which will correspond to the start<br/>    # and end of the text splits)<br/>    return np.array(sorted(all_breakpoints))[1:-1]</span></pre><p id="8afd" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Our choice of <code class="cx pi pj pk pl b">length_threshold</code> is also subjective and can be informed by the plot. In this case, a threshold of 1000 appears to work well. It divides the essays quite nicely into short and meaningfully different chunks.</p></div></div><div class="fw"><div class="ab cb"><div class="mg qs mh qt mi qu cf qv cg qw ci bh"><figure class="qe qf qg qh qi fw qy qz paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp rc"><img src="../Images/8763d5ba09fe12415629a54ce769f603.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*s4ng60mS_7zwxfdb3UXr-Q.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Breakpoints generated by running a recursive semantic splitter on the cosine distance timeseries from the original chunk embeddings. Image generated by the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="3c6d" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Looking at the chunks corresponding to the first essay, we see that they are closely aligned with the different sections that GPT4-o created when it wrote the essay. Obviously in the case of this particular essay we could have just split on <code class="cx pi pj pk pl b">"\n\n"</code> and been done here, but we want a more general approach.</p></div></div><div class="fw"><div class="ab cb"><div class="mg qs mh qt mi qu cf qv cg qw ci bh"><figure class="qe qf qg qh qi fw qy qz paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp rd"><img src="../Images/83ac1c17b0fd7cdb3753d47489b91938.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*ZwPK0VBMGljsY72uUMufIA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">The first six semantic chunks generated by the recursive breakpoint generation approach described above. Image generated by the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="191b" class="pm oj gk bf ok pn po hk oo pp pq hn os pr ps pt pu pv pw px py pz qa qb qc qd bk"><strong class="al">2. Clustering the semantic splits</strong></h1><p id="d70c" class="pw-post-body-paragraph nk nl gk nm b hi pd no np hl pe nr ns nt pf nv nw nx pg nz oa ob ph od oe of fj bk">Now that we have made some candidate semantic chunks, it might be useful to see how similar they are to one another. This will help us get a sense for what information they contain. We will proceed by embedding the semantic chunks, and then use UMAP to reduce the dimensionality of the resulting embeddings to 2D so that we can plot them.</p><p id="6c0f" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">UMAP stands for Uniform Manifold Approximation and Projection, and is a powerful, general dimensionality reduction technique that can capture non-linear relationships. A full explanation of how it works can be found <a class="af oh" href="https://umap-learn.readthedocs.io/en/latest/how_umap_works.html" rel="noopener ugc nofollow" target="_blank">here</a>. The purpose of using it here is to capture something of the relationships that exist between the embedded chunks in 1536-D space in a 2-D plot</p><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="78de" class="qm oj gk pl b bg qn qo l qp qq">from umap import UMAP<br/><br/>dimension_reducer = UMAP(<br/>            n_neighbors=5, <br/>            n_components=2, <br/>            min_dist=0.0, <br/>            metric="cosine", <br/>            random_state=0<br/>)<br/>reduced_embeddings = dimension_reducer.fit_transform(semantic_embeddings)<br/><br/>splits_df = pd.DataFrame(<br/>            {<br/>                "reduced_embeddings_x": reduced_embeddings[:, 0],<br/>                "reduced_embeddings_y": reduced_embeddings[:, 1],<br/>                "idx": np.arange(len(reduced_embeddings[:, 0])),<br/>            }<br/>)<br/><br/>splits_df["chunk_end"] = np.cumsum([len(x) for x in semantic_text_groups])<br/><br/>ax = splits_df.plot.scatter(<br/>            x="reduced_embeddings_x", <br/>            y="reduced_embeddings_y", <br/>            c="idx", <br/>            cmap="viridis"<br/>)<br/><br/>ax.plot(<br/>            reduced_embeddings[:, 0],<br/>            reduced_embeddings[:, 1],<br/>            "r-",<br/>            linewidth=0.5,<br/>            alpha=0.5,<br/>)</span></pre><p id="93bf" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">UMAP is quite sensitive to the <code class="cx pi pj pk pl b">n_neighbors</code> parameter. Generally the smaller the value of <code class="cx pi pj pk pl b">n_neighbors</code>, the more the algorithm focuses on the use of local structure to learn how to project the data into lower dimensions. Setting this value too small can lead to projections that don’t do a great job of capturing the large scale structure of the data, and it should generally increase as the number of datapoints grows.</p><p id="e4b2" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">A projection of our data is shown below and its quite informative: Clearly we have three clusters of similar meaning, with the 1st and 3rd being more similar to each other than either is to the 2nd. The <code class="cx pi pj pk pl b">idx</code> color bar in the plot above shows the chunk number, while the red line gives us an indication of the sequence of the chunks.</p><figure class="qe qf qg qh qi fw fo fp paragraph-image"><div class="fo fp re"><img src="../Images/6690eb5aad72ac6f82942ee770779a9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*vddEFYN0YzB-k_4l09JSIQ.png"/></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Plot of UMAP projection of the embeddings of the semantic splits generated in the previous section. idx refers to the index of the chunk in the order that they are generated by looping through the text. Image generated by the author.</figcaption></figure><p id="6e41" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">What about automatic clustering? This would be helpful if we wanted to group the chunks into larger segments or topics, which could serve as useful metadata to filter on in a RAG application with hybrid search, for example. We also might be able to group chunks that are far apart in the text (and therefore would not have been grouped by the standard semantic chunking in section 1) but have similar meanings.</p><p id="7057" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">There are many clustering approaches that could be used here. HDBSCAN is a possibility, and is the default method recommended by the <a class="af oh" href="https://maartengr.github.io/BERTopic/getting_started/clustering/clustering.html" rel="noopener ugc nofollow" target="_blank">BERTopic</a> package. However, in this case hierarchical clustering seems more useful since it can give us a sense of the relative importance of whatever groups emerge. To run hierarchical clustering, we first use UMAP to reduce the dimensionality of the dataset to a smaller number of components. So long as UMAP is working well here, the exact number of components shouldn’t significantly affect the clusters that get generated. Then we use the <a class="af oh" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html" rel="noopener ugc nofollow" target="_blank">hierarchy module from scipy</a> to perform the clustering and plot the result using seaborn</p><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="707b" class="qm oj gk pl b bg qn qo l qp qq">from scipy.cluster import hierarchy<br/>from scipy.spatial.distance import pdist<br/>from umap import UMAP<br/>import seaborn as sns<br/><br/># set up the UMAP<br/>dimension_reducer_clustering = UMAP(<br/>            n_neighbors=umap_neighbors,<br/>            n_components=n_components_reduced,<br/>            min_dist=0.0,<br/>            metric="cosine",<br/>            random_state=0<br/>)<br/>reduced_embeddings_clustering = dimension_reducer_clustering.fit_transform(<br/>    semantic_group_embeddings<br/>)<br/><br/># create the hierarchy<br/>row_linkage = hierarchy.linkage(<br/>    pdist(reduced_embeddings_clustering),<br/>    method="average",<br/>    optimal_ordering=True,<br/>)<br/><br/># plot the heatmap and dendogram<br/>g = sns.clustermap(<br/>    pd.DataFrame(reduced_embeddings_clustering),<br/>    row_linkage=row_linkage,<br/>    row_cluster=True,<br/>    col_cluster=False,<br/>    annot=True,<br/>    linewidth=0.5,<br/>    annot_kws={"size": 8, "color": "white"},<br/>    cbar_pos=None,<br/>    dendrogram_ratio=0.5<br/>)<br/><br/>g.ax_heatmap.set_yticklabels(<br/>  g.ax_heatmap.get_yticklabels(), rotation=0, size=8<br/>)</span></pre><p id="8e2a" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The result is also quite informative. Here <code class="cx pi pj pk pl b">n_components_reduced</code> was 4, so we reduced the dimensionality of the embeddings to 4D, therefore making a matrix with 4 features where each row represents one of the semantic chunks. Hierarchical clustering has identified the two major groups (i.e. trees and Namibia), two large subgroup within trees (i.e. medical uses vs. other) and an number of other groups that might be worth exploring.</p><figure class="qe qf qg qh qi fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp rf"><img src="../Images/fee5033190b5b9077467ad2d0ed75e7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0_u50ty4q6fFB-dEpJ5nbQ.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Hierarchical clustering of the UMAP projections of the embeddings of the semantic clunks generated. Image generated by the author.</figcaption></figure><p id="c887" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Note that <a class="af oh" href="https://maartengr.github.io/BERTopic/getting_started/hierarchicaltopics/hierarchicaltopics.html" rel="noopener ugc nofollow" target="_blank">BERTopic uses a similar technique for topic visualization</a>, which could be seen as an extension of what’s being presented here.</p><p id="7eef" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">How is this useful in our exploration of semantic chunking? Depending on the results, we may choose to group some of the chunks together. This is again quite subjective and it might be important to try out a few different types of grouping. Let’s say we looked at the dendrogram and decided we wanted 8 distinct groups. We could then cut the hierarchy accordingly, return the cluster labels associated with each group and plot them.</p><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="0e63" class="qm oj gk pl b bg qn qo l qp qq">cluster_labels = hierarchy.cut_tree(linkage, n_clusters=n_clusters).ravel()<br/>dimension_reducer = UMAP(<br/>  n_neighbors=umap_neighbors, <br/>  n_components=2, <br/>  min_dist=0.0, <br/>  metric="cosine", <br/>  random_state=0<br/>)<br/>reduced_embeddings = dimension_reducer.fit_transform(semantic_embeddings)<br/><br/>splits_df = pd.DataFrame(<br/>            {<br/>                "reduced_embeddings_x": reduced_embeddings[:, 0],<br/>                "reduced_embeddings_y": reduced_embeddings[:, 1],<br/>                "cluster_label": cluster_labels,<br/>            }<br/>        )<br/><br/>splits_df["chunk_end"] = np.cumsum(<br/>            [len(x) for x in semantic_text_groups]<br/>        ).reshape(-1, 1)<br/><br/>ax = splits_df.plot.scatter(<br/>            x="reduced_embeddings_x",<br/>            y="reduced_embeddings_y",<br/>            c="cluster_label",<br/>            cmap="rainbow",<br/>        )<br/><br/>ax.plot(<br/>  reduced_embeddings[:, 0],<br/>  reduced_embeddings[:, 1],<br/>  "r-",  <br/>  linewidth=0.5,<br/>  alpha=0.5,<br/>)</span></pre><p id="fa70" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The resulting plot is shown below. We have 8 clusters, and their distribution in the 2D space looks reasonable. This again demonstrates the importance of visualization: Depending on the text, application and stakeholders, the right number and distribution of groups will likely be different and the only way to check what the algorithm is doing is by plotting graphs like this.</p><figure class="qe qf qg qh qi fw fo fp paragraph-image"><div class="fo fp rg"><img src="../Images/dc1a6edcaacd42723c107f27e11b02d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*0V6eEZynPK6P7feOMIx9mA.png"/></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Cluster ids of the semantic chunks used to color the UMAP-projected embeddings of the semantic chunks. Image generated by the author.</figcaption></figure><h1 id="bda2" class="pm oj gk bf ok pn po hk oo pp pq hn os pr ps pt pu pv pw px py pz qa qb qc qd bk"><strong class="al">3. Labeling the clusters</strong></h1><p id="e479" class="pw-post-body-paragraph nk nl gk nm b hi pd no np hl pe nr ns nt pf nv nw nx pg nz oa ob ph od oe of fj bk">Assume after a few iterations of the steps above, we’ve settled on semantic splits and clusters that we’re happy with. It then makes sense to ask what these clusters actually represent? Obviously we could read the text and find out, but for a large corpus this is impractical. Instead, let’s use an LLM to help. Specifically, we will feed the text associated with each cluster to GPT-4o-mini and ask it to generate a summary. This is a relatively simple task with LangChain, and the core aspects of the code are shown below</p><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="2dd8" class="qm oj gk pl b bg qn qo l qp qq">import langchain<br/>from langchain.prompts import PromptTemplate<br/>from langchain_core.output_parsers.string import StrOutputParser<br/>from langchain.callbacks import get_openai_callback<br/>from dataclasses import dataclass<br/><br/><br/>@dataclass<br/>class ChunkSummaryPrompt:<br/>    system_prompt: str = """<br/>        You are an expert at summarization and information extraction from text. You will be given a chunk of text from a document and your<br/>        task is to summarize what's happening in this chunk using fewer than 10 words. <br/><br/>        Read through the entire chunk first and think carefully about the main points. Then produce your summary.<br/><br/>        Chunk to summarize: {current_chunk}<br/>    """<br/><br/>    prompt: langchain.prompts.PromptTemplate = PromptTemplate(<br/>        input_variables=["current_chunk"],<br/>        template=system_prompt,<br/>    )<br/><br/>class ChunkSummarizer(object):<br/>    def __init__(self, llm):<br/>        self.prompt = ChunkSummaryPrompt()<br/>        self.llm = llm<br/>        self.chain = self._set_up_chain()<br/><br/>    def _set_up_chain(self):<br/>        return self.prompt.prompt | self.llm | StrOutputParser()<br/><br/>    def run_and_count_tokens(self, input_dict):<br/>        with get_openai_callback() as cb:<br/>            result = self.chain.invoke(input_dict)<br/><br/>        return result, cb<br/><br/>llm_model = "gpt-4o-mini"<br/>llm = ChatOpenAI(model=llm_model, temperature=0, api_key=api_key)<br/>summarizer = ChunkSummarizer(llm)</span></pre><p id="37a4" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Running this on our 8 clusters and plotting the result with <a class="af oh" href="https://datamapplot.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">datamapplot </a>gives the following</p></div></div><div class="fw"><div class="ab cb"><div class="mg qs mh qt mi qu cf qv cg qw ci bh"><figure class="qe qf qg qh qi fw qy qz paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp rh"><img src="../Images/d03ea790b2958ab89a786710fcccbec6.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*6-IVPh24q1cJfveR2N5fJA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Labels generated by running GPT-4o-mini for the semantic clusters. Image generated by the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="4fc0" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">An alternative way of visualizing these groups is similar to the graphs shown in section 2, where we plot cumulative character number on the x axis and show the boundaries between the groups. Recall that we had 18 semantic chunks and have now grouped them further into 8 clusters. Plotting them like this shows how the semantic content of the text changes from beginning to end, highlights the fact that similar content is not always adjacent and gives a visual indication of the relative size of the chunks.</p></div></div><div class="fw"><div class="ab cb"><div class="mg qs mh qt mi qu cf qv cg qw ci bh"><figure class="qe qf qg qh qi fw qy qz paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp ri"><img src="../Images/af3cec1f961f5b5a507553dc5cf843e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*WBvqOrBExjcaRoSy1CG8uA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Graph showing the text segmented by semantic cluster and the names of the clusters. Image generated by the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="9ce3" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The code used to produce these figures can be found <a class="af oh" href="https://github.com/rmartinshort/text_chunking/blob/main/text_chunking/utils/SemanticGroupUtils.py" rel="noopener ugc nofollow" target="_blank">here</a>.</p><h1 id="405b" class="pm oj gk bf ok pn po hk oo pp pq hn os pr ps pt pu pv pw px py pz qa qb qc qd bk"><strong class="al">4. Testing on a larger corpus</strong></h1><p id="f839" class="pw-post-body-paragraph nk nl gk nm b hi pd no np hl pe nr ns nt pf nv nw nx pg nz oa ob ph od oe of fj bk">So far we’ve tested this workflow on a relatively small amount of text for demo purposes. Ideally it would also be useful on a larger corpus without significant modification. To test this, let’s try it out on a book downloaded from <a class="af oh" href="https://www.gutenberg.org/" rel="noopener ugc nofollow" target="_blank">Project Gutenberg</a>, and I’ve chosen the Wizard of Oz here. This is a much more difficult task because novels are typically not arranged in clear semantically distinct sections like factual essays. Although they are commonly arranged in chapters, the story line may “arch” in a continuous fashion, or skip around between different subjects. It would be very interesting to see if semantic chunk analysis could be used to learn something about the style of different authors from their work.</p><h2 id="8164" class="oi oj gk bf ok ol om on oo op oq or os nt ot ou ov nx ow ox oy ob oz pa pb pc bk"><strong class="al">Step 1: Embed and generate breakpoints</strong></h2><pre class="qe qf qg qh qi qj pl qk bp ql bb bk"><span id="7756" class="qm oj gk pl b bg qn qo l qp qq">from text_chunking.SemanticClusterVisualizer import SemanticClusterVisualizer<br/>from text_chunking.utils.secrets import load_secrets<br/>from text_chunking.datasets.test_text_dataset import TestText, TestTextNovel<br/>from langchain_text_splitters import RecursiveCharacterTextSplitter<br/><br/>secrets = load_secrets()<br/>semantic_chunker = SemanticClusterVisualizer(api_key=secrets["OPENAI_API_KEY"])<br/><br/>splitter = RecursiveCharacterTextSplitter(<br/>        chunk_size=250,<br/>        chunk_overlap=0,<br/>        separators=["\n\n", "\n", "."],<br/>        is_separator_regex=False<br/>)<br/><br/>original_split_texts = semantic_chunker.split_documents(<br/>    splitter, <br/>    TestTextNovel.testing_text, <br/>    min_chunk_len=100, <br/>    verbose=True<br/>)<br/>original_split_text_embeddings = semantic_chunker.embed_original_document_splits(original_split_texts)<br/><br/>breakpoints, semantic_groups = semantic_chunker.generate_breakpoints(<br/>    original_split_texts,<br/>    original_split_text_embeddings,<br/>    length_threshold=10000 #may need some iteration to find a good value for this parameter<br/>)</span></pre><p id="e851" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">This generates 77 semantic chunks of varying size. Doing some spot checks here led me to feel confident that it was working relatively well and many of the chunks end up being divided on or close to chapter boundaries, which makes a lot of sense.</p></div></div><div class="fw"><div class="ab cb"><div class="mg qs mh qt mi qu cf qv cg qw ci bh"><figure class="qe qf qg qh qi fw qy qz paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp rj"><img src="../Images/a81a54829db8050a2620be382d653dc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*FwxY7SEpLtZKKcHGGW97CQ.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Semantic splits from the Wizard of Oz. Image generated by the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="4877" class="oi oj gk bf ok ol om on oo op oq or os nt ot ou ov nx ow ox oy ob oz pa pb pc bk">Step 2 : Cluster and generate labels</h2><p id="ff8f" class="pw-post-body-paragraph nk nl gk nm b hi pd no np hl pe nr ns nt pf nv nw nx pg nz oa ob ph od oe of fj bk">On looking at the hierarchical clustering dendrogram, I decided to experiment with reduction to 35 clusters. The result reveals an outlier in the top left of the plot below (cluster id 34), which turns out to be a group of chunks at the very end of the text that contain a lengthy description of the terms under which the book is distributed.</p><figure class="qe qf qg qh qi fw fo fp paragraph-image"><div class="fo fp rk"><img src="../Images/c2b807ca8401d2438bc1a26d2cd9c16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*vtqDZjWxB8UyrzcqepMlWw.png"/></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">2D plot of UMAP projections of semantic chunks from the Wizard of Oz, and their cluster labels. Image generated by the author</figcaption></figure><p id="9a7c" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The descriptions given to each of the clusters are shown below and, with the exception of the first one, they provide a nice overview of the main events of the novel. A quick check on the actual texts associated with each one confirms that they are reasonably accurate summaries, although again, a determination of where the boundaries of the clusters should be is very subjective.</p><figure class="qe qf qg qh qi fw fo fp paragraph-image"><div class="fo fp rl"><img src="../Images/76695daf7c6e6e49b67108db231e91fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*-WQ9ssO710Gh9t7Pdj7xtw.png"/></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Names automatically chosen for each of the 40 semantic clusters from the Wizard of Oz. This list provides a quick overview of the storyline. Image generated by the author.</figcaption></figure><p id="6931" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">GPT-4o-mini labeled the outlier cluster “Project Gutenberg allows free distribution of unprotected works”. The text associated with this label is not particularly interesting to us, so let’s remove it and re-plot the result. This will make the structure in the novel easier to see.</p><p id="408e" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">What if we are interested in larger clusters? If we were to focus on high level structure, the dendrogram suggests approximately six clusters of semantic chunks, which are plotted below.</p><figure class="qe qf qg qh qi fw fo fp paragraph-image"><div class="fo fp rm"><img src="../Images/dbc6c75ea91fc60aec528016e258f437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*awLv3GmJbY5CcJt7hUbzOQ.png"/></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Searching for high level structure — if we choose to make 6 clusters from the semantic chunks of the Wizard of Oz, this is the pattern we get. Image generated by the author.</figcaption></figure><p id="5053" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">There’s a lot of jumping back and forth between points that are somewhat distant in this semantic space, suggesting frequent sudden changes in subject. It’s also interesting to consider the connectivity between the various clusters: 4 and 5 have no links between them for example, while there’s a lot of back and forth between 0 and 1.</p><p id="f640" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Can we summarize these larger clusters? It turns out that our prompt doesn’t seem well suited for chunks of this size, producing descriptions that seem either too specific to one part of the cluster (i.e. clusters 0 and 4) or too vague to be very helpful. Improved prompt engineering — possibly involving multiple summarization steps — would probably improve the results here.</p></div></div><div class="fw"><div class="ab cb"><div class="mg qs mh qt mi qu cf qv cg qw ci bh"><figure class="qe qf qg qh qi fw qy qz paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp rn"><img src="../Images/c38aff26c65af18a4f901652af0cde32.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*dly-4K-rkhQ5T4qpDEiWDg.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Graph showing the text segmented by semantic cluster id and the names of the six clusters identified above. Image generated by the author.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="3620" class="pw-post-body-paragraph nk nl gk nm b hi nn no np hl nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Despite the unhelpful names, this plot of the text segments colored by cluster is still informative as a guide to selective reading of the text. We see that the book starts and ends on the same cluster, which likely is about descriptions of Dorothy, Toto and their home — and aligns with the story arch of the Wizard of Oz as a journey and subsequent return. Cluster 1 is mainly about meeting new characters, which happens mainly near the beginning but also periodically throughout the book. Clusters 2 and 3 are concerned with Emerald City and the Wizard, while clusters 4 and 5 are broadly about journeying and fighting respectively.</p><h1 id="a912" class="pm oj gk bf ok pn po hk oo pp pq hn os pr ps pt pu pv pw px py pz qa qb qc qd bk"><strong class="al">5. Concluding thoughts</strong></h1><p id="f4d9" class="pw-post-body-paragraph nk nl gk nm b hi pd no np hl pe nr ns nt pf nv nw nx pg nz oa ob ph od oe of fj bk">Thanks for making it to the end! Here we took a deep dive into the idea of semantic chunking, and how it can be complimented by dimensionality reduction, clustering and visualization. The major takeaway is the importance of systematically exploring the effects of different chunking techniques and a parameters on your text before deciding on the most suitable approach. My hope is that this article will spark new ideas about how we can use AI and visualization tools to advance semantic chunking and quickly extract insights from large bodies of text. Please feel free to explore the full codebase here <a class="af oh" href="https://github.com/rmartinshort/text_chunking" rel="noopener ugc nofollow" target="_blank">https://github.com/rmartinshort/text_chunking</a>.</p></div></div></div></div>    
</body>
</html>