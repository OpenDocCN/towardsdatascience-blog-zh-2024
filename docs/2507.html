<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Choose the Best ML Deployment Strategy: Cloud vs. Edge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Choose the Best ML Deployment Strategy: Cloud vs. Edge</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-choose-the-best-ml-deployment-strategy-cloud-vs-edge-7b62d9db9b20?source=collection_archive---------3-----------------------#2024-10-14">https://towardsdatascience.com/how-to-choose-the-best-ml-deployment-strategy-cloud-vs-edge-7b62d9db9b20?source=collection_archive---------3-----------------------#2024-10-14</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="faa3" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">The choice between cloud and edge deployment could make or break your project</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Vincent Vandenbussche" class="l ep by dd de cx" src="../Images/b2febfc63ca0efbda0af5501f6080ab7.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*pyfH31oWD78ckKpLyzMCEg.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------" rel="noopener follow">Vincent Vandenbussche</a></p></div></div></div><div class="hz ia l"><div class="ab ib"><div class="ab"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewbox="0 0 16 16"><path fill="#437AFF" d="M15.163 8c0 .65-.459 1.144-.863 1.575-.232.244-.471.5-.563.719s-.086.543-.092.875c-.006.606-.018 1.3-.49 1.781-.47.481-1.15.494-1.744.5-.324.006-.655.013-.857.094s-.465.337-.704.575c-.422.412-.906.881-1.542.881-.637 0-1.12-.469-1.543-.881-.239-.238-.49-.482-.704-.575-.214-.094-.532-.088-.857-.094-.593-.006-1.273-.019-1.744-.5s-.484-1.175-.49-1.781c-.006-.332-.012-.669-.092-.875-.08-.207-.33-.475-.563-.719-.404-.431-.863-.925-.863-1.575s.46-1.144.863-1.575c.233-.244.472-.5.563-.719.092-.219.086-.544.092-.875.006-.606.019-1.3.49-1.781s1.15-.494 1.744-.5c.325-.006.655-.012.857-.094.202-.081.465-.337.704-.575C7.188 1.47 7.671 1 8.308 1s1.12.469 1.542.881c.239.238.49.481.704.575s.533.088.857.094c.594.006 1.273.019 1.745.5.47.481.483 1.175.49 1.781.005.331.011.669.091.875s.33.475.563.719c.404.431.863.925.863 1.575"/><path fill="#fff" d="M7.328 10.5c.195 0 .381.08.519.22.137.141.215.331.216.53 0 .066.026.13.072.177a.24.24 0 0 0 .346 0 .25.25 0 0 0 .071-.177c.001-.199.079-.389.216-.53a.73.73 0 0 1 .519-.22h1.959c.13 0 .254-.053.346-.146a.5.5 0 0 0 .143-.354V6a.5.5 0 0 0-.143-.354.49.49 0 0 0-.346-.146h-1.47c-.324 0-.635.132-.865.366-.23.235-.359.552-.359.884v2.5c0 .066-.025.13-.071.177a.24.24 0 0 1-.346 0 .25.25 0 0 1-.072-.177v-2.5c0-.332-.13-.65-.359-.884A1.21 1.21 0 0 0 6.84 5.5h-1.47a.49.49 0 0 0-.346.146A.5.5 0 0 0 4.88 6v4c0 .133.051.26.143.354a.49.49 0 0 0 .347.146z"/></svg></div></div></div><span class="ic id" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ie if ah ai aj ak al am an ao ap aq ar ig ih ii" disabled="">Follow</button></p></div></div></span></div></div><div class="l ij"><span class="bf b bg z dx"><div class="ab cn ik il im"><div class="in io ab"><div class="bf b bg z dx ab ip"><span class="iq l ij">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------" rel="noopener follow"><p class="bf b bg z ir is it iu iv iw ix iy bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ic id" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="iz ja l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 14, 2024</span></div></span></div></span></div></div></div><div class="ab cp jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq"><div class="h k w ea eb q"><div class="kg l"><div class="ab q kh ki"><div class="pw-multi-vote-icon ed iq kj kk kl"><div class=""><div class="km kn ko kp kq kr ks am kt ku kv kl"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kw kx ky kz la lb lc"><p class="bf b dy z dx"><span class="kn">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao km lf lg ab q ee lh li" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count ld le">3</span></p></button></div></div></div><div class="ab q jr js jt ju jv jw jx jy jz ka kb kc kd ke kf"><div class="lj k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lk an ao ap ig ll lm ln" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lo cn"><div class="l ae"><div class="ab cb"><div class="lp lq lr ls lt lu ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lk an ao ap ig lv lw li lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mp mq mr ms mt mu mm mn paragraph-image"><div role="button" tabindex="0" class="mv mw ed mx bh my"><div class="mm mn mo"><img src="../Images/670dca37200cce7a7304957e014758b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gQVgsmasdk-zbSW9"/></div></div><figcaption class="na nb nc mm mn nd ne bf b bg z dx">Photo by <a class="af nf" href="https://unsplash.com/@jakobowens1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jakob Owens</a> on <a class="af nf" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1119" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">As a machine learning engineer, I frequently see discussions on social media emphasizing the importance of deploying ML models. I completely agree — model deployment is a critical component of MLOps. As ML adoption grows, there’s a rising demand for scalable and efficient deployment methods, yet specifics often remain unclear.</p><p id="8366" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">So, does that mean model deployment is always the same, no matter the context? In fact, quite the opposite: I’ve been deploying ML models for about a decade now, and it can be quite different from one project to another. There are many ways to deploy a ML model, and having experience with one method doesn’t necessarily make you proficient with others.</p><p id="4cc0" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">The remaining question is: <strong class="ni fr">what are the methods to deploy a ML model</strong>, and<strong class="ni fr"> how do we choose the right method</strong>?</p><p id="b29d" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Models can be deployed in various ways, but they typically fall into two main categories:</p><ul class=""><li id="af3f" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Cloud deployment</li><li id="1954" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Edge deployment</li></ul><p id="7efa" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">It may sound easy, but there’s a catch. For both categories, there are actually many subcategories. Here is a non-exhaustive diagram of deployments that we will explore in this article:</p><figure class="mp mq mr ms mt mu mm mn paragraph-image"><div role="button" tabindex="0" class="mv mw ed mx bh my"><div class="mm mn ok"><img src="../Images/70f0d9d6cbcae7b724cde834f082013a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Daoam--d03GZjcOiMadVrQ.png"/></div></div><figcaption class="na nb nc mm mn nd ne bf b bg z dx">Diagram of the explored subcategories of deployment in this article. Image by author.</figcaption></figure><p id="1b8c" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Before talking about how to choose the right method,<strong class="ni fr"> let’s explore each category: what it is, the pros, the cons, the typical tech stack, and I will also share some personal examples</strong> of deployments I did in that context. Let’s dig in!</p><h1 id="56bd" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Cloud Deployment</h1><p id="fc67" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">From what I can see, it seems cloud deployment is by far <strong class="ni fr">the most popular choice</strong> when it comes to ML deployment. This is what is usually expected to master for model deployment. But cloud deployment usually means one of these, depending on the context:</p><ul class=""><li id="d7a9" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">API deployment</li><li id="abac" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Serverless deployment</li><li id="fbcc" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Batch processing</li></ul><p id="2d90" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Even in those sub-categories, one could have another level of categorization but we won’t go that far in that post. Let’s have a look at what they mean, their pros and cons and a typical associated tech stack.</p><h2 id="38a1" class="pm om fq bf on pn po pp oq pq pr ps ot np pt pu pv nt pw px py nx pz qa qb qc bk">API Deployment</h2><p id="95a3" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">API stands for Application Programming Interface. This is a very popular way to deploy a model on the cloud. Some of the most popular ML models are deployed as APIs: Google Maps and OpenAI’s ChatGPT can be queried through their APIs for examples.</p><p id="5f19" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">If you’re not familiar with APIs, know that it’s usually called with a simple query. For example, type the following command in your terminal to get the 20 first Pokémon names:</p><pre class="mp mq mr ms mt qd qe qf bp qg bb bk"><span id="4c3a" class="qh om fq qe b bg qi qj l qk ql">curl -X GET https://pokeapi.co/api/v2/pokemon</span></pre><p id="2977" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Under the hood, what happens when calling an API might be a bit more complex. API deployments usually involve a standard tech stack including load balancers, autoscalers and interactions with a database:</p><figure class="mp mq mr ms mt mu mm mn paragraph-image"><div role="button" tabindex="0" class="mv mw ed mx bh my"><div class="mm mn qm"><img src="../Images/e6dd59aa3082e1c70e16efd4f871e817.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GULFJrMuGo1QYyrMz0Pr0g.png"/></div></div><figcaption class="na nb nc mm mn nd ne bf b bg z dx">A typical example of an API deployment within a cloud infrastructure. Image by author.</figcaption></figure><p id="52d6" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><em class="qn">Note: APIs may have different needs and infrastructure, this example is simplified for clarity.</em></p><p id="f539" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">API deployments are popular for several reasons:</p><ul class=""><li id="567a" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Easy to implement and to integrate into various tech stacks</li><li id="c1e9" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">It’s easy to scale: using horizontal scaling in clouds allow to scale efficiently; moreover managed services of cloud providers may reduce the need for manual intervention</li><li id="b0e7" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">It allows centralized management of model versions and logging, thus efficient tracking and reproducibility</li></ul><p id="f03f" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">While APIs are a really popular option, there are some cons too:</p><ul class=""><li id="e212" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">There might be latency challenges with potential network overhead or geographical distance; and of course it requires a good internet connection</li><li id="f8ca" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">The cost can climb up pretty quickly with high traffic (assuming automatic scaling)</li><li id="d7b2" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Maintenance overhead can get expensive, either with managed services cost of infra team</li></ul><p id="546b" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">To sum up, <strong class="ni fr">API deployment is largely used</strong> in many startups and tech companies <strong class="ni fr">because of its flexibility</strong> and a rather short time to market. But the <strong class="ni fr">cost can climb up quite fast for high traffic</strong>, and the maintenance cost can also be significant.</p><p id="4cc7" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">About the tech stack: there are many ways to develop APIs, but the most common ones in Machine Learning are probably <a class="af nf" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank">FastAPI</a> and <a class="af nf" href="https://flask.palletsprojects.com/en/3.0.x/" rel="noopener ugc nofollow" target="_blank">Flask</a>. They can then be deployed quite easily on the main cloud providers (AWS, GCP, Azure…), preferably through docker images. The orchestration can be done through managed services or with Kubernetes, depending on the team’s choice, its size, and skills.</p><p id="baa6" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">As an example of API cloud deployment, I once deployed a ML solution to automate the pricing of an electric vehicle charging station for a customer-facing web app. You can have a look at this project here if you want to know more about it:</p><div class="qo qp qq qr qs qt"><a href="https://pub.towardsai.net/how-renault-leveraged-machine-learning-to-scale-electric-vehicles-sales-4f42bee34a12?source=post_page-----7b62d9db9b20--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qu ab ij"><div class="qv ab co cb qw qx"><h2 class="bf fr hw z ir qy it iu qz iw iy fp bk">How Renault Leveraged Machine Learning to Scale Electric Vehicle Sales</h2><div class="ra l"><h3 class="bf b hw z ir qy it iu qz iw iy dx">How I built and deployed a machine learning-based solution in a few months that allowed Renault to scale the sale of…</h3></div><div class="rb l"><p class="bf b dy z ir qy it iu qz iw iy dx">pub.towardsai.net</p></div></div><div class="rc l"><div class="rd l re rf rg rc rh lu qt"/></div></div></a></div><p id="de67" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Even if this post does not get into the code, it can give you a good idea of what can be done with API deployment.</p><p id="c409" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">API deployment is very popular for its simplicity to integrate to any project. But some projects may need even more flexibility and less maintenance cost: this is where serverless deployment may be a solution.</p><h2 id="38c4" class="pm om fq bf on pn po pp oq pq pr ps ot np pt pu pv nt pw px py nx pz qa qb qc bk">Serverless Deployment</h2><p id="08cf" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">Another popular, but probably less frequently used option is serverless deployment. Serverless computing means that <strong class="ni fr">you run your model</strong> (or any code actually)<strong class="ni fr"> without owning nor provisioning any server</strong>.</p><p id="af40" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Serverless deployment offers several significant advantages and is quite easy to set up:</p><ul class=""><li id="a2f8" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">No need to manage nor to maintain servers</li><li id="7e14" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">No need to handle scaling in case of higher traffic</li><li id="cfd9" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">You only pay for what you use: no traffic means virtually no cost, so no overhead cost at all</li></ul><p id="9742" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">But it has some limitations as well:</p><ul class=""><li id="545c" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">It is usually not cost effective for large number of queries compared to managed APIs</li><li id="2fef" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Cold start latency is a potential issue, as a server might need to be spawned, leading to delays</li><li id="ff41" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">The memory footprint is usually limited by design: you can’t always run large models</li><li id="53fd" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">The execution time is limited too: it’s not possible to run jobs for more than a few minutes (15 minutes for AWS Lambda for example)</li></ul><p id="11aa" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">In a nutshell, I would say that serverless deployment is a <strong class="ni fr">good option when you’re launching something new, don’t expect large traffic and don’t want to spend much on infra management</strong>.</p><p id="a399" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Serverless computing is proposed by all major cloud providers under different names: <a class="af nf" href="https://aws.amazon.com/lambda/" rel="noopener ugc nofollow" target="_blank">AWS Lambda</a>, <a class="af nf" href="https://azure.microsoft.com/en-us/products/functions/" rel="noopener ugc nofollow" target="_blank">Azure Functions</a> and <a class="af nf" href="https://cloud.google.com/functions" rel="noopener ugc nofollow" target="_blank">Google Cloud Functions</a> for the most popular ones.</p><p id="8b2e" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">I personally have never deployed a serverless solution (working mostly with deep learning, I usually found myself limited by the serverless constraints mentioned above), but there is lots of documentation about how to do it properly, such as <a class="af nf" href="https://aws.amazon.com/blogs/compute/deploying-machine-learning-models-with-serverless-templates/" rel="noopener ugc nofollow" target="_blank">this one from AWS</a>.</p><p id="d224" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">While serverless deployment offers a flexible, on-demand solution, some applications may require a more scheduled approach, like batch processing.</p><h2 id="c80d" class="pm om fq bf on pn po pp oq pq pr ps ot np pt pu pv nt pw px py nx pz qa qb qc bk">Batch Processing</h2><p id="d79b" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">Another way to deploy on the cloud is through scheduled batch processing. While serverless and APIs are mostly used for live predictions, in some cases batch predictions makes more sense.</p><p id="60b8" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Whether it be database updates, dashboard updates, caching predictions… as soon as there is <strong class="ni fr">no need to have a real-time prediction, batch processing is usually the best option</strong>:</p><ul class=""><li id="8c94" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Processing large batches of data is more resource-efficient and reduce overhead compared to live processing</li><li id="95b7" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Processing can be scheduled during off-peak hours, allowing to reduce the overall charge and thus the cost</li></ul><p id="c212" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Of course, it comes with associated drawbacks:</p><ul class=""><li id="05c4" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Batch processing creates a spike in resource usage, which can lead to system overload if not properly planned</li><li id="ed45" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Handling errors is critical in batch processing, as you need to process a full batch gracefully at once</li></ul><p id="8d0b" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><strong class="ni fr">Batch processing should be considered for any task that does not required real-time results</strong>: it is usually more cost effective. But of course, for any real-time application, it is not a viable option.</p><p id="2c0e" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">It is used widely in many companies, mostly within ETL (Extract, Transform, Load) pipelines that may or may not contain ML. Some of the most popular tools are:</p><ul class=""><li id="836c" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Apache Airflow for workflow orchestration and task scheduling</li><li id="1a10" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Apache Spark for fast, massive data processing</li></ul><p id="b9d5" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">As an example of batch processing, I used to work on a YouTube video revenue forecasting. Based on the first data points of the video revenue, we would forecast the revenue over up to 5 years, using a multi-target regression and curve fitting:</p><figure class="mp mq mr ms mt mu mm mn paragraph-image"><div role="button" tabindex="0" class="mv mw ed mx bh my"><div class="mm mn ri"><img src="../Images/5e891c0b723fb52a7b5e9269012dfedd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ew1bq1ezAX3SyCIFHZ2V4Q.png"/></div></div><figcaption class="na nb nc mm mn nd ne bf b bg z dx">Plot representing the initial data, multi-target regression predictions and curve fitting. Image by author.</figcaption></figure><p id="1b22" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">For this project, we had to re-forecast on a monthly basis all our data to ensure there was no drifting between our initial forecasting and the most recent ones. For that, we used a managed Airflow, so that every month it would automatically trigger a new forecasting based on the most recent data, and store those into our databases. If you want to know more about this project, you can have a look at this article:</p><div class="qo qp qq qr qs qt"><a href="https://medium.datadriveninvestor.com/how-to-forecast-youtube-video-revenue-e35c60bd1105?source=post_page-----7b62d9db9b20--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qu ab ij"><div class="qv ab co cb qw qx"><h2 class="bf fr hw z ir qy it iu qz iw iy fp bk">How to Forecast YouTube Video Revenue</h2><div class="ra l"><h3 class="bf b hw z ir qy it iu qz iw iy dx">This method achieved an error rate of less than 6% in revenue forecasting over a portfolio of dozens of YouTubers</h3></div><div class="rb l"><p class="bf b dy z ir qy it iu qz iw iy dx">medium.datadriveninvestor.com</p></div></div><div class="rc l"><div class="rj l re rf rg rc rh lu qt"/></div></div></a></div><p id="8cfb" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">After exploring the various strategies and tools available for cloud deployment, it’s clear that this approach offers significant flexibility and scalability. However, cloud deployment is not always the best fit for every ML application, particularly when real-time processing, privacy concerns, or financial resource constraints come into play.</p><figure class="mp mq mr ms mt mu mm mn paragraph-image"><div role="button" tabindex="0" class="mv mw ed mx bh my"><div class="mm mn rk"><img src="../Images/578ee44791128a7decddea53afe8da55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mOHNFDEaJfsHcF3_IGrFUg.png"/></div></div><figcaption class="na nb nc mm mn nd ne bf b bg z dx">A list of pros and cons for cloud deployment. Image by author.</figcaption></figure><p id="1885" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">This is where edge deployment comes into focus as a viable option. Let’s now delve into edge deployment to understand when it might be the best option.</p><h1 id="23ba" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Edge Deployment</h1><p id="08ac" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">From my own experience, edge deployment is rarely considered as the main way of deployment. A few years ago, even I thought it was not really an interesting option for deployment. With more perspective and experience now, I think <strong class="ni fr">it must be considered as the first option</strong> for deployment anytime you can.</p><p id="5e33" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Just like cloud deployment, edge deployment covers a wide range of cases:</p><ul class=""><li id="4a54" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Native phone applications</li><li id="698e" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Web applications</li><li id="5c83" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Edge server and specific devices</li></ul><p id="b381" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">While they all share some similar properties, such as limited resources and horizontal scaling limitations, each deployment choice may have their own characteristics. Let’s have a look.</p><h2 id="3b04" class="pm om fq bf on pn po pp oq pq pr ps ot np pt pu pv nt pw px py nx pz qa qb qc bk">Native Application</h2><p id="76fc" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">We see more and more smartphone apps with integrated AI nowadays, and it will probably keep growing even more in the future. While some Big Tech companies such as OpenAI or Google have chosen the API deployment approach for their LLMs, Apple is currently working on the iOS app deployment model with solutions such as <a class="af nf" href="https://machinelearning.apple.com/research/openelm" rel="noopener ugc nofollow" target="_blank">OpenELM</a>, a tini LLM. Indeed, this option has several advantages:</p><ul class=""><li id="8f23" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">The infra cost if virtually zero: no cloud to maintain, it all runs on the device</li><li id="b904" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Better privacy: you don’t have to send any data to an API, it can all run locally</li><li id="4727" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Your model is directly integrated to your app, no need to maintain several codebases</li></ul><p id="ede7" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><em class="qn">Moreover, Apple has built a fantastic ecosystem for model deployment in iOS: you can run very efficiently ML models with Core ML on their Apple chips (M1, M2, etc…) and take advantage of the neural engine for really fast inferences. To my knowledge, Android is slightly lagging behind, but also has a great ecosystem.</em></p><p id="43ab" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">While this can be a really beneficial approach in many cases, there are still some limitations:</p><ul class=""><li id="2743" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Phone resources limit model size and performance, and are shared with other apps</li><li id="25c2" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Heavy models may drain the battery pretty fast, which can be deceptive for the user experience overall</li><li id="d3dd" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Device fragmentation, as well as iOS and Android apps make it hard to cover the whole market</li><li id="7285" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Decentralized model updates can be challenging compared to cloud</li></ul><p id="016c" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Despite its drawbacks, native app deployment is often a strong choice for ML solutions that run in an app. It <strong class="ni fr">may seem more complex during the development phase</strong>, but it will turn out to be <strong class="ni fr">much cheaper</strong> as soon as it’s deployed compared to a cloud deployment.</p><p id="cb95" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">When it comes to the tech stack, there are actually two main ways to deploy: iOS and Android. They both have their own stacks, but they share the same properties:</p><ul class=""><li id="8abf" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">App development: Swift for iOS, Kotlin for Android</li><li id="dc58" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Model format: Core ML for iOS, TensorFlow Lite for Android</li><li id="45c5" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Hardware accelerator: Apple Neural Engine for iOS, Neural Network API for Android</li></ul><p id="0798" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><em class="qn">Note: This is a mere simplification of the tech stack. This non-exhaustive overview only aims to cover the essentials and let you dig in from there if interested.</em></p><p id="1a7f" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">As a personal example of such deployment, I once worked on a book reading app for Android, in which they wanted to let the user navigate through the book with phone movements. For example, shake left to go to the previous page, shake right for the next page, and a few more movements for specific commands. For that, I trained a model on accelerometer’s features from the phone for movement recognition with a rather small model. It was then deployed directly in the app as a TensorFlow Lite model.</p><p id="ba45" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Native application has strong advantages but is limited to one type of device, and would not work on laptops for example. A web application could overcome those limitations.</p><h2 id="19ac" class="pm om fq bf on pn po pp oq pq pr ps ot np pt pu pv nt pw px py nx pz qa qb qc bk">Web Application</h2><p id="517c" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">Web application deployment means running the model on the client side. Basically, it means <strong class="ni fr">running the model inference on the device</strong> used by that browser, whether it be a tablet, a smartphone or a laptop (and the list goes on…). This kind of deployment can be really convenient:</p><ul class=""><li id="b4f3" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Your deployment is working on any device that can run a web browser</li><li id="3846" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">The inference cost is virtually zero: no server, no infra to maintain… Just the customer’s device</li><li id="1629" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Only one codebase for all possible devices: no need to maintain an iOS app and an Android app simultaneously</li></ul><p id="cbdc" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><em class="qn">Note: Running the model on the server side would be equivalent to one of the cloud deployment options above.</em></p><p id="6027" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">While web deployment offers appealing benefits, it also has significant limitations:</p><ul class=""><li id="dccd" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Proper resource utilization, especially GPU inference, can be challenging with TensorFlow.js</li><li id="fe74" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Your web app must work with all devices and browsers: whether is has a GPU or not, Safari or Chrome, a Apple M1 chip or not, etc… This can be a heavy burden with a high maintenance cost</li><li id="052b" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">You may need a backup plan for slower and older devices: what if the device can’t handle your model because it’s too slow?</li></ul><p id="2a0a" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><em class="qn">Unlike for a native app, there is no official size limitation for a model. However, a small model will be downloaded faster, making it overall experience smoother and must be a priority. And a very large model may just not work at all anyway.</em></p><p id="1a41" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">In summary, while web deployment is powerful, it comes with significant limitations and must be used cautiously. One more advantage is that it might be a door to another kind of deployment that I did not mention: WeChat Mini Programs.</p><p id="9558" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">The tech stack is usually the same as for web development: HTML, CSS, JavaScript (and any frameworks you want), and of course TensorFlow Lite for model deployment. If you’re curious about an example of how to deploy ML in the browser, you can have a look at this post where I run a real time face recognition model in the browser from scratch:</p><div class="qo qp qq qr qs qt"><a rel="noopener follow" target="_blank" href="/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75?source=post_page-----7b62d9db9b20--------------------------------"><div class="qu ab ij"><div class="qv ab co cb qw qx"><h2 class="bf fr hw z ir qy it iu qz iw iy fp bk">BlazeFace: How to Run Real-time Object Detection in the Browser</h2><div class="ra l"><h3 class="bf b hw z ir qy it iu qz iw iy dx">A step-by-step guide to training a BlazeFace model, from the Python training pipeline to the JavaScript demo through…</h3></div><div class="rb l"><p class="bf b dy z ir qy it iu qz iw iy dx">towardsdatascience.com</p></div></div><div class="rc l"><div class="rl l re rf rg rc rh lu qt"/></div></div></a></div><p id="e529" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">This article goes from a model training in PyTorch to up to a working web app and might be informative about this specific kind of deployment.</p><p id="61d4" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">In some cases, native and web apps are not a viable option: we may have no such device, no connectivity, or some other constraints. This is where edge servers and specific devices come into play.</p><h2 id="4c09" class="pm om fq bf on pn po pp oq pq pr ps ot np pt pu pv nt pw px py nx pz qa qb qc bk">Edge Servers and Specific Devices</h2><p id="0cd5" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">Besides native and web apps, edge deployment also includes other cases:</p><ul class=""><li id="4b23" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Deployment on edge servers: in some cases, there are local servers running models, such as in some factory production lines, CCTVs, etc…Mostly because of privacy requirements, this solution is sometimes the only available</li><li id="fe9e" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Deployment on specific device: either a sensor, a microcontroller, a smartwatch, earplugs, autonomous vehicle, etc… may run ML models internally</li></ul><p id="fd99" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Deployment on edge servers can be really close to a deployment on cloud with API, and the tech stack may be quite close.</p><p id="5a05" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk"><em class="qn">Note: It is also possible to run batch processing on an edge server, as well as just having a monolithic script that does it all.</em></p><p id="82b4" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">But deployment on specific devices may involve using <a class="af nf" href="https://en.wikipedia.org/wiki/Field-programmable_gate_array" rel="noopener ugc nofollow" target="_blank">FPGA</a>s or low-level languages. This is another, very different skillset, that may differ for each type of device. It is sometimes referred to as TinyML and is a very interesting, growing topic.</p><p id="1713" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">On both cases, they share some challenges with other edge deployment methods:</p><ul class=""><li id="4f08" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Resources are limited, and horizontal scaling is usually not an option</li><li id="074c" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">The battery may be a limitation, as well as the model size and memory footprint</li></ul><p id="eda8" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Even with these limitations and challenges, in some cases it’s the only viable solution, or the most cost effective one.</p><p id="3c5a" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">An example of an edge server deployment I did was for a company that wanted to automatically check whether the orders were valid in fast food restaurants. A camera with a top down view would look at the plateau, compare what is sees on it (with computer vision and object detection) with the actual order and raise an alert in case of mismatch. For some reason, the company wanted to make that on edge servers, that were within the fast food restaurant.</p><p id="ea62" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">To recap, here is a big picture of what are the main types of deployment and their pros and cons:</p><figure class="mp mq mr ms mt mu mm mn paragraph-image"><div role="button" tabindex="0" class="mv mw ed mx bh my"><div class="mm mn rm"><img src="../Images/03465e3c6a42058a4aafcc2c9d2269fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sqdprgroIbDC4vvFqojW6g.png"/></div></div><figcaption class="na nb nc mm mn nd ne bf b bg z dx">A list of pros and cons for cloud deployment. Image by author.</figcaption></figure><p id="f8d3" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">With that in mind, <strong class="ni fr">how to actually choose the right deployment method?</strong> There’s no single answer to that question, but let’s try to give some rules in the next section to make it easier.</p><h1 id="c2d9" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">How to Choose the Right Deployment</h1><p id="19b2" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">Before jumping to the conclusion, let’s make a decision tree to help you choose the solution that fits your needs.</p><p id="c6dd" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Choosing the right deployment requires understanding specific needs and constraints, often through discussions with stakeholders. Remember that each case is specific and might be a edge case. But in the diagram below I tried to outline the most common cases to help you out:</p><figure class="mp mq mr ms mt mu mm mn paragraph-image"><div role="button" tabindex="0" class="mv mw ed mx bh my"><div class="mm mn rn"><img src="../Images/6f7ccb5214d4bfecc3380b38a08cf0ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*98pdTmtNyfJSCzorzM-CEQ.png"/></div></div><figcaption class="na nb nc mm mn nd ne bf b bg z dx">Deployment decision diagram. Note that each use case is specific. Image by author.</figcaption></figure><p id="3332" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">This diagram, while being quite simplistic, can be reduced to a few questions that would allow you go in the right direction:</p><ul class=""><li id="cb27" class="ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe bk">Do you need real-time? If no, look for batch processing first; if yes, think about edge deployment</li><li id="75b6" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Is your solution running on a phone or in the web? Explore these deployments method whenever possible</li><li id="7b4a" class="ng nh fq ni b go of nk nl gr og nn no np oh nr ns nt oi nv nw nx oj nz oa ob oc od oe bk">Is the processing quite complex and heavy? If yes, consider cloud deployment</li></ul><p id="5bb3" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Again, that’s quite simplistic but helpful in many cases. Also, note that a few questions were omitted for clarity but are actually more than important in some context: Do you have privacy constraints? Do you have connectivity constraints? What is the skillset of your team?</p><p id="ea31" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">Other questions may arise depending on the use case; with experience and knowledge of your ecosystem, they will come more and more naturally. But hopefully this may help you navigate more easily in deployment of ML models.</p><h1 id="7ee1" class="ol om fq bf on oo op gq oq or os gt ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Conclusion and Final Thoughts</h1><p id="f2e3" class="pw-post-body-paragraph ng nh fq ni b go ph nk nl gr pi nn no np pj nr ns nt pk nv nw nx pl nz oa ob fj bk">While cloud deployment is often the default for ML models, edge deployment can offer significant advantages: cost-effectiveness and better privacy control. Despite challenges such as processing power, memory, and energy constraints, I believe edge deployment is a compelling option for many cases. Ultimately, the best deployment strategy aligns with your business goals, resource constraints and specific needs.</p><p id="cf34" class="pw-post-body-paragraph ng nh fq ni b go nj nk nl gr nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob fj bk">If you’ve made it this far, I’d love to hear your thoughts on the deployment approaches you used for your projects.</p></div></div></div></div>    
</body>
</html>