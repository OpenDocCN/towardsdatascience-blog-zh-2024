<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Enhancing NPS Measurement with LLMs and Statistical Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Enhancing NPS Measurement with LLMs and Statistical Inference</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/enhancing-nps-measurement-with-llms-and-statistical-inference-a0ed0ce9c6cf?source=collection_archive---------6-----------------------#2024-03-06">https://towardsdatascience.com/enhancing-nps-measurement-with-llms-and-statistical-inference-a0ed0ce9c6cf?source=collection_archive---------6-----------------------#2024-03-06</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="e78e" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Combining LLMs with human judgement through Prediction-Powered Inference (PPI)</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@smsmith714?source=post_page---byline--a0ed0ce9c6cf--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Sean Smith" class="l ep by dd de cx" src="../Images/611395d113b10ec4bbfaf781301139c7.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*tCT7FPsaR-As3bFYRTJbvg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--a0ed0ce9c6cf--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@smsmith714?source=post_page---byline--a0ed0ce9c6cf--------------------------------" rel="noopener follow">Sean Smith</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--a0ed0ce9c6cf--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 6, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/170d3aaa0bfc5e6f90d90cd4a4b39b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AT1fmgqHNfdTMnKylmbxYg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Robot solving complicated mathematics, digital art. Generated by Dall-E 2.</figcaption></figure><h1 id="2174" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Introduction</h1><p id="6b40" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">In business analytics, calculating the Net Promoter Score (NPS) typically involves manual data annotation from employees. Some may think to use machine learning models to label the data, however this does not have the theoretical guarantees we get from human labeled data. Enter Prediction-Powered Inference (PPI), a new statistical technique that combines human and machine labeled data to create confidence intervals that are data efficient and theoretically guaranteed.</p><p id="ba01" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">This article explores the intuition behind PPI and emphasizes why you would want to use it. We then jump into a code walkthrough of how to use it for two metrics: NPS and customer recommendations.</p><h1 id="faa5" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Prediction-Powered Inference (PPI)</h1><p id="ecf2" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">PPI is a statistical technique proposed by Angelopoulos et al. [1]. The goal is to enhance confidence intervals by combining human and machine labeled data. Let’s walk through some steps to motivate its usefulness.</p><p id="8824" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">In our use case we want to estimate the true NPS score given a set of customer reviews. Typically, an employee will manually read each review and assign a score from 1 to 10, a reliable but time-inefficient method. When dealing with numerous reviews it would be convenient to have a more automatic method.</p><p id="3826" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">To address this, we can leverage a machine learning model. A Large Language Model (LLM) is a good candidate to solve this problem because they generalize well to new tasks. The model is prompted to read the review and output a score. This is convenient, but the model comes with errors and imperfections. When making a decision, we need to make sure our data is aligned with human judgement.</p><p id="383b" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Considering the limitations of both approaches, what if we could combine them? We can with Prediction-Powered Inference (PPI)! PPI is a framework that leverages the theoretical guarantees of human-labeled data for confidence intervals and the efficiency of machine-labeled data. With PPI, we aim to benefit from the strengths of both techniques.</p><h2 id="7f46" class="oy nc fq bf nd oz pa pb ng pc pd pe nj og pf pg ph ok pi pj pk oo pl pm pn po bk">How it Works</h2><p id="4275" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">The core of PPI falls on something called the rectifier. We use the rectifier to account for the prediction error of our machine learning model. Using the rectifier, we can construct confidence intervals combining both the human and machine labeled data.</p><p id="0d92" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Here’s the algorithm proposed for constructing the confidence intervals:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj pp"><img src="../Images/f2cd98a6b898eea3d7582fce12847fce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*322JdLwYR3i-rZiC1b9sXQ.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Algorithm 1 from [1].</figcaption></figure><p id="8c12" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">This approach enjoys a simple code implementation. Here is a short snippet to make this work:</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="6b6d" class="pu nc fq pr b bg pv pw l px py">def pp_mean_iid_asymptotic(Y_labeled, Yhat_labeled, Yhat_unlabeled, alpha):<br/>    n = Y_labeled.shape[0]<br/>    N = Yhat_unlabeled.shape[0]<br/>    tildethetaf = Yhat_unlabeled.mean()<br/>    rechat = (Yhat_labeled - Y_labeled).mean() # rectifier (delta hat)<br/>    thetahatPP = tildethetaf - rechat # Prediction-Powered Estimator<br/>    sigmaftilde = np.std(Yhat_unlabeled)  # imputed std dev<br/>    sigmarec = np.std(Yhat_labeled -  Y_labeled) # rectifier std dev<br/>    hw = norm.ppf(1-alpha/2)*np.sqrt((sigmaftilde**2/N) + (sigmarec**2/n)) # normal approximation<br/>    <br/>    return [thetahatPP - hw, thetahatPP + hw] # confidence interval</span></pre><p id="8118" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">If you want to go deeper I recommend this <a class="af pz" href="https://www.youtube.com/watch?v=FW5l5xEYETY&amp;t=515s" rel="noopener ugc nofollow" target="_blank">YouTube</a> video with Clara Wong-Fannjiang (one of the authors) or looking at the <a class="af pz" href="https://arxiv.org/pdf/2301.09633.pdf" rel="noopener ugc nofollow" target="_blank">paper</a>. These resources do a much better job of explaining the concepts than I could accomplish here.</p><p id="4c37" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">What’s important to understand is that PPI has tighter confidence intervals than human only construction and has theoretical guarantees absent in prediction based confidence intervals. Understanding this fact is enough to work through the coding exercise.</p><h1 id="7ced" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">The Approach</h1><p id="73a1" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">The link to the full notebook can be found <a class="af pz" href="https://colab.research.google.com/drive/1anlksDq2LI6Mshk7tO_yxFnSsOp-D366?usp=sharing" rel="noopener ugc nofollow" target="_blank">here</a>. I’ll walk through the key steps with some commentary. A lot of this code is credited to the authors of the PPI library.</p><p id="654d" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">In our example we are going to use PPI to estimate the mean value. It is also possible to estimate other parameters, such as quantiles, logistic/linear regression coefficients, and others. After working through this example you can find more <a class="af pz" href="https://github.com/aangelopoulos/ppi_py/tree/main/examples" rel="noopener ugc nofollow" target="_blank">here</a>.</p><h2 id="8947" class="oy nc fq bf nd oz pa pb ng pc pd pe nj og pf pg ph ok pi pj pk oo pl pm pn po bk">Setting things up</h2><p id="3304" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">First let’s install the PPI library. To see more information about the library check out the repo <a class="af pz" href="https://github.com/aangelopoulos/ppi_py" rel="noopener ugc nofollow" target="_blank">here</a>.</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="0528" class="pu nc fq pr b bg pv pw l px py">pip install ppi-python</span></pre><p id="aede" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">For this example we will simulate data. It is hard to find data for NPS scores that are publicly available, so I've created the following code. The approach is still the same regardless of where the data comes from. We will create a DataFrame with the columns<code class="cx qa qb qc pr b">Overall_Rating</code> (NPS scores) and <code class="cx qa qb qc pr b">Recommended</code> (a boolean value.)</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="c58a" class="pu nc fq pr b bg pv pw l px py">def simulate_nps_scores(n, mu=3, mu2=9, std_dev=1):<br/><br/>    # simulate each aspect of bimodal distribution<br/>    X1 = np.random.normal(mu, std_dev, n // 3)<br/>    X2 = np.random.normal(mu2, std_dev, n // 3)<br/><br/>    X = np.concatenate([X1, X2])<br/>    X3 = np.ones(n - X.shape[0])  # make 1-inflated<br/>    X = np.concatenate([X, X3])<br/><br/>    X = np.clip(X, a_min=1, a_max=10)  # fix to 1-10 range for NPS<br/><br/>    return X<br/><br/><br/>def simulate_recommended(mean, n):<br/>    return np.array([1 if random.uniform(0,1) &lt;= mean else 0 for _ in range(n)])</span></pre><p id="9fee" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Using these functions we can construct the DataFrame:</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="adc5" class="pu nc fq pr b bg pv pw l px py">N = 20000<br/>data = pd.DataFrame({<br/>    'Overall_Rating': simulate_nps_scores(N), <br/>    'Recommended': simulate_recommended(0.34, N)<br/>})</span></pre><h2 id="4e82" class="oy nc fq bf nd oz pa pb ng pc pd pe nj og pf pg ph ok pi pj pk oo pl pm pn po bk">Simulating LLM Predictions</h2><p id="0512" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">To make a more flexible demo I have given two options for creating predictions. The first is to create a simulated error for the predictions. This allows you to experiment with PPI and see how it works for different theoretical models. Here’s an example of what this looks like:</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="dd12" class="pu nc fq pr b bg pv pw l px py">if target_response == 'NPS':<br/>    Y_total = data.Overall_Rating.to_numpy()<br/>    Yhat_total = np.array([random.normalvariate(x, error_std_dev) for x in Y_total])<br/>    Yhat_total = np.array([max(min(x, 10), 1) for x in Yhat_total])<br/><br/>elif target_response == 'reccomended':<br/>    Y_total = data.Recommended.to_numpy()<br/><br/>    Yhat_total = np.array([<br/>        x if random.uniform(0, 1) &gt;= error_prob else int(not x)<br/>        for x in Y_total<br/>    ])<br/><br/>else:<br/>    raise Exception('Invalid target_response')</span></pre><h2 id="5182" class="oy nc fq bf nd oz pa pb ng pc pd pe nj og pf pg ph ok pi pj pk oo pl pm pn po bk">LLM Predictions</h2><p id="fe77" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">If you have data with customer reviews, then it is easy to score them with a LLM. Here are some prompts you can use to do this:</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="cc42" class="pu nc fq pr b bg pv pw l px py">NPS_prompt_template = lambda review: f"""Given the following review please return the Net Promoter Score (NPS).<br/>Return only the integer value from 1-10 and nothing else.<br/><br/>Review: <br/>{review}<br/><br/>NPS:"""<br/><br/>recommended_prompt_template = lambda review: f"""Given the following review please determine if the customer would recommend the business.<br/>Return only 'True' or 'False'.<br/><br/>Review: {review}<br/>Recommended:"""</span></pre><p id="e656" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">You may wish to use recommended over NPS since the boolean classification problem is much easier. Some businesses prefer NPS because it’s more industry standard. Depending on your problem you can choose which makes more sense.</p><p id="47c4" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">With the LLM you can also check scores for different categories. These could be different products or services mentioned that you want to measure. This is a great benefit of using the LLM, since it is flexible for many problems, but we also account for the error by using PPI in our reporting.</p><h2 id="a8a8" class="oy nc fq bf nd oz pa pb ng pc pd pe nj og pf pg ph ok pi pj pk oo pl pm pn po bk">Run PPI</h2><p id="567f" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Now it’s time to construct confidence intervals. Here is a snippet of the code that does the heavy lifting:</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="f34c" class="pu nc fq pr b bg pv pw l px py">for i in tqdm(range(ns.shape[0])):<br/>    for j in range(num_trials):<br/>        # Prediction-Powered Inference<br/>        n = ns[i]<br/>        rand_idx = np.random.permutation(n_total)<br/>        _Yhat = Yhat_total[rand_idx[:n]]<br/>        _Y = Y_total[rand_idx[:n]]<br/>        _Yhat_unlabeled = Yhat_total[n:]<br/><br/>        ppi_ci = ppi_mean_ci(_Y, _Yhat, _Yhat_unlabeled, alpha=alpha)<br/><br/>        classical_ci = classical_mean_ci(_Y, alpha=alpha)</span></pre><p id="4690" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">What we are doing here is simulating PPI vs classical confidence intervals for different numbers of human responses (n). We can plot this information which is shown below.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj qd"><img src="../Images/6582044f5a3a85c482fd613fbb3f56e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*r-K_MZTHO9V3WbWM5pXS4w.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">PPI vs Classical for NPS Score. Green is PPI, Grey is Classical, Yellow is Machine labeled, and the dashed line is the true population parameter. Image by Author.</figcaption></figure><p id="bfed" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">You can see in this diagram comparing different values for n, the number of human labels used. PPI always has tighter confidence intervals than the confidence intervals using human labeled data alone. This demonstrates the key value of PPI: <strong class="nz fr">even though we have a flawed ML model, we still generate better confidence intervals than if we hadn’t used it by combing them with human data.</strong></p><p id="cafd" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">We can see similar results for recommended below.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj qe"><img src="../Images/bb38f4ec241dd0df1e36f98562465db8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*WiV5D36aUWx1FOvy6THKig.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">PPI vs Classical for Recommended. Green is PPI, Grey is Classical, Yellow is Machine labeled, and the dashed line is the true population parameter. Image by author.</figcaption></figure><p id="02ab" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">In this case we are looking at the true percentage of customers that recommend using the business out of all customers. Again we see that using PPI we are able to build tighter confidence intervals than if we had only used the human labeled data.</p><p id="403c" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">You’ll also notice the confidence interval for the machine predictions in yellow. These predictions are not perfectly accurate so the confidence interval is way off. This is why we need some human labeled data and cannot use machine labeled data only.</p><h2 id="0a7e" class="oy nc fq bf nd oz pa pb ng pc pd pe nj og pf pg ph ok pi pj pk oo pl pm pn po bk">Decision Making</h2><p id="e56e" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">Now let’s consider how many human labels are needed to make a decision for the PPI and classical approaches.</p><p id="0b90" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Starting with NPS. Suppose we want to simulate how many human labeled examples we need to reject a null hypothesis that NPS is less than or equal to 4. We can run the following code to find the minimum value:</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="9fdf" class="pu nc fq pr b bg pv pw l px py">def _to_invert_ppi(n):<br/>    n = int(n)<br/>    nulls_rejected = 0<br/>    # Data setup<br/>    for i in range(num_experiments):<br/>        rand_idx = list_rand_idx[i]<br/>        _Yhat = Yhat_total[rand_idx[:n]]<br/>        _Y = Y_total[rand_idx[:n]]<br/>        _Yhat_unlabeled = Yhat_total[rand_idx[n:]]<br/><br/>        ppi_ci = ppi_mean_ci(_Y, _Yhat, _Yhat_unlabeled, alpha=alpha)<br/>        if target_response == 'NPS' and  ppi_ci[0] &gt; null_hypothesis:<br/>            nulls_rejected += 1<br/>        elif target_response == 'recommended' and  ppi_ci[0] &gt; null_hypothesis:<br/>            nulls_rejected += 1<br/><br/>    return nulls_rejected / num_experiments - statistical_power<br/><br/>n_ppi = int(brentq(_to_invert_ppi, 100, 1000, xtol=1))</span></pre><p id="a15e" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">This simulates the minimum number of examples needed to reject the null hypothesis for PPI. The code for the classical example follows similarly. See the <a class="af pz" href="https://colab.research.google.com/drive/1anlksDq2LI6Mshk7tO_yxFnSsOp-D366?usp=sharing" rel="noopener ugc nofollow" target="_blank">notebook</a> for full details.</p><p id="450a" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Let’s look at the output here:</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="a3b4" class="pu nc fq pr b bg pv pw l px py">The PPI test requires n=334 labeled data points to reject the null.<br/>The classical test requires n=987 labeled data points to reject the null.</span></pre><p id="9cda" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">The interpretation is that PPI requires 653 less human labeled observations to reject the null hypothesis than using only human labeled examples.</p><p id="dc9a" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">We can repeat this process for recommended. The only change we make is the value of the null hypothesis. We run a test for the null hypothesis that the true percent of customers that recommend the business is less than or equal to 0.3.</p><pre class="ml mm mn mo mp pq pr ps bp pt bb bk"><span id="b3a9" class="pu nc fq pr b bg pv pw l px py">The PPI test requires n=461 labeled data points to reject the null.<br/>The classical test requires n=1000 labeled data points to reject the null.</span></pre><p id="686d" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Here we can see that 539 more observations are needed to draw a conclusion with the classical approach than the human approach.</p><h2 id="9e47" class="oy nc fq bf nd oz pa pb ng pc pd pe nj og pf pg ph ok pi pj pk oo pl pm pn po bk">Are these results meaningful?</h2><p id="cc5c" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">653 or 539 observations may not seem like a lot, but in the world of internal data labeling it is. Suppose it’s Friday afternoon and your boss asks you to determine what the NPS score is from a group of surveys that just came in. To make this determination you need to manually label some observations.</p><p id="c738" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">Suppose you can label 4 comments per minute. This implies you can label 240 comments per hour. If you use PPI, you would get to leave 2–3 hours earlier than if you used classical confidence intervals. Reducing mundane tasks has great benefits for employee happiness so this approach is worth investing in, since the overhead is simple.</p><h1 id="5f5f" class="nb nc fq bf nd ne nf gq ng nh ni gt nj nk nl nm nn no np nq nr ns nt nu nv nw bk">Conclusion</h1><p id="ad82" class="pw-post-body-paragraph nx ny fq nz b go oa ob oc gr od oe of og oh oi oj ok ol om on oo op oq or os fj bk">This was a quick overview of how to use PPI to solve basic statistical inference problems. We saw how to calculate a population mean from a sample dataset for two different types of variables. This approach results in a meaningful time savings for very little extra work.</p><p id="9a6d" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">For more examples of how to use PPI, check out this <a class="af pz" href="https://github.com/aangelopoulos/ppi_py/tree/main/examples" rel="noopener ugc nofollow" target="_blank">examples</a> folder from the repo. They cover many more interesting use cases. Happy coding!</p></div></div></div><div class="ab cb qf qg qh qi" role="separator"><span class="qj by bm qk ql qm"/><span class="qj by bm qk ql qm"/><span class="qj by bm qk ql"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="3c6c" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk"><em class="qn">Thank you for reading the article! If you have additional questions or something was unclear, leave a comment and I will get back to you. If you want to see more articles like this one, please follow me on </em><a class="af pz" href="https://medium.com/@smsmith714" rel="noopener"><em class="qn">Medium</em></a><em class="qn"> and on </em><a class="af pz" href="https://www.linkedin.com/in/sms714/" rel="noopener ugc nofollow" target="_blank"><em class="qn">LinkedIn</em></a><em class="qn">.</em></p><p id="7a54" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk"><em class="qn">If you found a technical error in this article, please let me know ASAP! I strive to make sure the information I publish is as correct as possible, but no one is perfect.</em></p></div></div></div><div class="ab cb qf qg qh qi" role="separator"><span class="qj by bm qk ql qm"/><span class="qj by bm qk ql qm"/><span class="qj by bm qk ql"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="57b3" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">References:</p><p id="5766" class="pw-post-body-paragraph nx ny fq nz b go ot ob oc gr ou oe of og ov oi oj ok ow om on oo ox oq or os fj bk">[1] Anastasios N. Angelopoulos, Stephen Bates, Clara Fannjiang, Michael I. Jordan, &amp; Tĳana Zrnic. (2023). Prediction-Powered Inference.</p></div></div></div></div>    
</body>
</html>