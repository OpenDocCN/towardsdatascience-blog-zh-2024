- en: 'ASCVIT V1: Automatic Statistical Calculation, Visualization, and Interpretation
    Tool'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ascvit-v1-automatic-statistical-calculation-visualization-and-interpretation-tool-aa910001a3a7?source=collection_archive---------2-----------------------#2024-09-16](https://towardsdatascience.com/ascvit-v1-automatic-statistical-calculation-visualization-and-interpretation-tool-aa910001a3a7?source=collection_archive---------2-----------------------#2024-09-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Automated data analysis made easy: The first version of ASCVIT, the tool for
    statistical calculation, visualization, and interpretation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@stefanpietrusky?source=post_page---byline--aa910001a3a7--------------------------------)[![Stefan
    Pietrusky](../Images/f5abf75db277f3aec8d8e56877daafe4.png)](https://medium.com/@stefanpietrusky?source=post_page---byline--aa910001a3a7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--aa910001a3a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--aa910001a3a7--------------------------------)
    [Stefan Pietrusky](https://medium.com/@stefanpietrusky?source=post_page---byline--aa910001a3a7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--aa910001a3a7--------------------------------)
    ·30 min read·Sep 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: During my studies, I attended a data science seminar and came into contact with
    the statistical programming language R for the first time. At the time, I was
    fascinated by the resulting potential uses. In the meantime, the statistical evaluation
    of data has become easier thanks to developments in the field of machine learning.
    Of course, a certain level of technical understanding is required, and you need
    to know what certain methods actually do. It is also necessary to know what data
    or input is required for certain methods to work at all or deliver meaningful
    results. In this article, I would like to discuss the development of a first version
    (V1) of a local app that can be used to automatically apply various statistical
    methods to any datasets. This is an open source project for educational and research
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: The data can be uploaded in either .csv or .xlsx format. The first version of
    the app provides a general data overview (data preview, data description, number
    of data points and categorization of variables), analyses in the field of descriptive
    statistics (histogram, boxplot, pairplot and correlation matrix), various hypothesis
    tests (t-test, ANOVA and chi-square test), regression analyses (linear, logistic
    and multivariate), time series analysis and supports various clustering methods
    (k-means, hierarchical and DBSCAN). The app is created using the Python framework
    Streamlit.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2aeaafcbbff406fea620a84e506c2e8b.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Overview of analysis methods (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Due to the modular structure of the code, further statistical procedures can
    be easily implemented. The code is commented, which makes it easier to find your
    way around. When the app is executed, the interface looks like this after a dataset
    has been uploaded.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e7b5a06c2d4276d7fc811f32eb999b4f.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Streamlit App (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the automatic analysis in the various areas mentioned, a function
    has also been integrated that automatically analyses the statistically recorded
    values. The *“query_llm_via_cli”* function enables an exchange via CLI (command
    line interface) with an LLM using Ollama.
  prefs: []
  type: TYPE_NORMAL
- en: I have already explained this principle in an article published on [**Towards
    Data Science**](https://medium.com/towards-data-science/how-to-talk-to-a-pdf-file-without-using-proprietary-models-cli-streamlit-ollama-6c22437ed932)
    [1]. In the first version of the app, this functionality is only limited to the
    descriptive statistical analyses, but can also be transferred to the others. In
    concrete terms, this means that in addition to the automatic statistical calculation,
    the app also automatically interprets the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/72272ad4d80906cdb2f175181563da74.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 CLI + OLLAMA + LMS (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: DATASET FOR TESTING THE APP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you do not have your own data available, there are various sites on the
    internet that provide datasets free of charge. The dataset used for the development
    and testing of the app comes from [**Maven Analytics**](https://mavenanalytics.io/data-playground?accessType=open&order=date_added%2Cdesc&page=1&pageSize=5)(License:
    ODC-BY) [2].'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/544d667fb9fd8ddd3896b0d2c5920415.png)'
  prefs: []
  type: TYPE_IMG
- en: MAVEN Analytics Data Playground (Screenshot by author)
  prefs: []
  type: TYPE_NORMAL
- en: There are numerous free datasets on the site. The data I have examined deals
    with the sales figures of video games in the period from 1976 to 2024\. Specifically,
    it is the sales figures from North America, Japan, the EU, Africa and the rest
    of the world. A total of 64016 titles and their rating, genre, console, etc. are
    recorded.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, not all information is available for all titles. There are many
    NaN (Not a Number) values that cause problems when analysed in Python or distort
    specific statistical analyses. I will briefly discuss the cleansing of data records
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/193f5b427ac3d2335be5cdf1d3387001.png)'
  prefs: []
  type: TYPE_IMG
- en: Video Games Sales data from MAVEN Analytics (Screenshot by author)
  prefs: []
  type: TYPE_NORMAL
- en: CLEAN UP THE DATASET
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can either clean the dataset before loading it into the app using a separate
    script, or you can perform the cleanup directly in the app. For the application
    in this article, I have implemented data cleansing directly in the app. If you
    want to clean up data records beforehand, you can do this using the following
    script.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The file is read using *“pd.read_csv(‘.csv’)”* and the data is saved in the
    DataFrame “df”. df.dropna()” removes all lines in the DataFrame that contain missing
    values ‘NaN’. The cleaned DataFrame is then saved in the variable *“df_cleaned”*.
    The data is saved in a new .csv file using *“df_cleaned.to_csv(‘cleaned_file.csv’,
    index=False)”*. Line indices are not saved. This is followed by an output for
    the successfully completed process *“print(…)”*. The code for this dataset cleanup
    can be found in the file *“clean.py”* and can also be downloaded later. Next,
    let’s move on to the actual code of the app.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ede7322dd5c84e374c7cc838afe3d6cb.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Python Code snippet (GIF by author)
  prefs: []
  type: TYPE_NORMAL
- en: LIBRARIES AND MODULES THAT ARE REQUIRED
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To use the app, various libraries and modules are required, which in combination
    perform data visualization, statistical analysis and machine learning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**A note regarding the representation of the diagrams.** Some use *“pyplot”*
    (Matplotlib) and others use *“plotly”* (e.g. Boxplot). Even if the use of *“plotly”*
    leads to more interactive graphics, it does not make sense to use it for every
    type of diagram. Ultimately, the user must decide individually how the diagrams
    should be displayed. The code must be adapted accordingly.'
  prefs: []
  type: TYPE_NORMAL
- en: The required libraries for the application can be installed using the requirements.txt
    file in the ZIP directory with the following command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: THE DATA OVERVIEW
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The function *“display_data_info()”* specifically analyses the Pandas DataFrame
    *“df”* and outputs statistical key figures (mean value, standard deviation, etc.)
    *“df.describe()”*. The total number of data points (rows) of the DataFrame is
    output *“len(df)”*. Likewise, the numerical *“numerical_columns”* and categorical
    *“categorical_columns”* (strings) variables of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ebc74d3ca69d370554105df06d51e84.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 App Data Overviews (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: The dataset has a total of 64016 data points and 6 numerical and 8 categorical
    variables. Before you start with certain statistical procedures, you should first
    look at the data. In the *“Data overview”* section, you can obtain various information
    to draw conclusions whether certain tests can be carried out at all.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if there is no date variable in the dataset, no time series analysis
    can be carried out. If there is no binary variable, no logistic regression can
    be carried out. The app is already designed to ask for certain variable categories
    or to display error messages if incorrect values are transmitted. Next, let’s
    move on to descriptive statistics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: DESCRIPTIVE STATISTICS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *“descriptive_statistics()”* function allows the user to select different
    chart types (histogram, boxplot, pairplot and correlation matrix). A brief explanation
    of the type follows via *“st.markdown(”“”…“”“)”*. One or more numerical variables
    must then be selected “selected_vars”. The option whether logarithmic scaling
    *“apply_log_scale”* should be applied is available, except for the correlation
    matrix. Applying logarithmic scaling to a variable is particularly useful if the
    data is heavily distorted. The visualization is created using the corresponding
    diagram function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: THE HISTOGRAM FUNCTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *“plot_histogram()”* function is used to create the histogram depending
    on the variable selected by the user. At the beginning, all NaN values are removed
    from the variable *“cleaned_data”*. Various statistical key figures (mean value
    *“mean_value”*, median *“median_value”*, standard deviation *“std_value”*, minimum
    *“min_value”* and maximum *“max_value”* and the upper and lower end of the standard
    deviation) are calculated.
  prefs: []
  type: TYPE_NORMAL
- en: Since the data is interpreted by an LLM, as mentioned at the beginning, the
    dispersion (standard deviation in relation to the range of the data) and distribution
    (difference between mean and median) of the data is classified. The histogram
    is created *“fix, ax = plt.subplots()”*, vertical lines are added to increase
    the informative value and finally the histogram is displayed *“st.pyplot(fig)”*.
    In the case of distorted or exponential data, logarithmic scaling can be activated,
    whereupon the y-axis of the histogram is adjusted. The graph then looks as follows
    [3].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/474b62510e5c5d8f8e38a129f663484f.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Histogram (pyplot) of critic_score and LLM interpretation (Image by
    author)
  prefs: []
  type: TYPE_NORMAL
- en: As there are no models that can read out graphics directly, we create a universal
    context for the analysis by the LLM. The context contains the results of the statistical
    calculation and additional instructions or the desired interpretation. This means
    that the context, which serves as input for the LLM, can be applied to any dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, the input includes the aforementioned statistical key figures,
    an analysis of the distribution (symmetrical, right-skewed or left-skewed), an
    estimate of the spread (low, moderate or high) and an interpretation formatted
    for the LLM. Depending on the desired output, the context can be individually
    adapted and further specified.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/33136ad371a7207a0887e3d72893bdcb.png)'
  prefs: []
  type: TYPE_IMG
- en: LLM context example (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: The analysis is sent to the LLM *“response = query_llm_via_cli(context)”*, whereupon
    an interpretation of the histogram takes place after a short time interval, depending
    on the performance of the local system *“st.write(f”**Histogram Interpretation:**
    {response}”)”*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: THE BOXPLOT FUNCTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *“plot_boxplot()”* function creates a boxplot for a variable selected by
    the user. Statistical key figures are calculated from the DataFrame based on the
    variable in order to display the distribution of the data in the diagram and to
    enable an analysis of the central tendency and dispersion using an LLM. In addition
    to the mean value, the median and the standard deviation, as with the histogram,
    the lower *“q1”*, upper *“q3”*, the interquartile range *“iqr”* (Q3 — Q1) and
    the lower or upper whisker “lower_whisker” and *“upper_whisker”*, which are based
    on the interquartile range (1.5 * IQR), are also determined for the boxplot.
  prefs: []
  type: TYPE_NORMAL
- en: 'The latter plays a role in identifying outliers and the other parameters where
    data is above or below a certain value. The boxplot is created using the Plotly
    library *“fig = px.box(df, y=variable)”* and finally displayed in the app *“st.plotly_chart(fig)”*.
    Logarithmic scaling can also be used for this chart type [4]. The chart then looks
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1240490defa061076c18513fa0716b84.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Boxplot (plotly) of critic_score and LLM interpretation (Image by
    author)
  prefs: []
  type: TYPE_NORMAL
- en: As with the histogram, a context is also created for the boxplot, which is forwarded
    to the LLM. The statistical key figures are transmitted as well as information
    about potential outliers that lie outside the whisker values. The text sent to
    the LLM is formatted so that the analysis is performed on these metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: THE PAIRPLOT FUNCTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *“plot_pairplot()”* function creates a pairplot based on the variables selected
    by the user. If less than two variables are selected, an error message is displayed.
    Scatter plots for all possible combinations of the variables and a linear regression
    line are displayed to show the relationships between the variables. For this to
    work, the regression statistics are calculated for all possible pairs of the selected
    variables using the *“calculate_regression_stats”* function. The NaN values are
    removed from the selected variables *“selected_vars”*.
  prefs: []
  type: TYPE_NORMAL
- en: A linear regression is performed between the two variables. Here, *“var1”* is
    the independent variable x and *“var2”* is the dependent variable y. The slope
    and the R2 value *“r_squared”* are calculated. The results are returned as a list
    of tuples (var1, var2, slope, r_squared). If three variables are selected [*“A”,
    “B”, “C”*], the function will calculate the regression statistics for the pairs
    (A, B), (A, C), (B, A), (B, C), etc. [5].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: KDE (Kernel Density Estimation) is used in the *“plot_pairplot()”* function
    for the diagonal to display the distribution of each individual variable. As with
    the previous functions, a context is again created for the analysis by the LLM.
    For this type of diagram, the LLM receives the data from the correlation and regression
    analysis. The text is formatted in such a way that a detailed interpretation of
    the relationship between the variables is generated.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6d2bd3af562582c6074c5c389c746db9.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Pairplot (pyplot) of critic_score, na_sales, pal_sales and LLM interpretation
    (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: THE CORRELATION MATRIX FUNCTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *“plot_correlation_matrix”* function is used to create a correlation matrix
    based on the variables selected by the user *“if len(selected_vars) > 1”*. If
    only one variable is selected, an error message is displayed. The visualization
    is done as a heatmap. The cells of the matrix are colored to show the strength
    and direction of the correlation. Correlations that are significant are automatically
    sent to the LLM for further analysis *“if var1 != var2 and abs(corr_matrix.at[var1,
    var2]) >= 0.5”*.
  prefs: []
  type: TYPE_NORMAL
- en: The linear correlation between the selected variables is displayed as the correlation
    coefficient (value between -1 and +1) *“corr_matrix = df[selected_vars].cor()”*.
    With a value of 0, there is no linear correlation. A value close to -1 indicates
    a strong negative correlation and a value close to +1 indicates a strong positive
    correlation. The pairs of variables and their correlation values are saved in
    *“high_correlations”* [4].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6729066db61d5785023c97f0e3cc5af7.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Correlation Matrix (pyplot) with all variables and LLM interpretation
    (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: A context is created for the LLM. The existing significant correlations are
    classified for the textual description *“correlation_list”*. A strong correlation
    (positive or negative) is present with a value greater than 0.7\. If the value
    is between 0.5 and 0.7, there is a moderate correlation and if the value is only
    just above 0.5, the correlation is weak. If no significant correlations were found,
    a corresponding message is displayed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the following statistical procedures, the interpretation of the respective
    key figures recorded by an LLM is not available. However, based on the previous
    procedure, independent implementation should not be a problem. Let us now turn
    to the various hypothesis tests.
  prefs: []
  type: TYPE_NORMAL
- en: HYPOTHESIS TESTS SELECTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the current version, three different tests (t-test, ANOVA and chi-square
    test) can be carried out *“test_type = st.selectbox()”*. Depending on the test
    selected, a brief explanation of its purpose appears. Depending on the area of
    application, this description can be expanded or removed. The t-test is used to
    compare the mean values of two groups. The analysis of variance (ANOVA) compares
    the mean value of more than two groups. The chi-square test tests the independence
    between two categorical variables. Depending on which test is selected, the corresponding
    function is performed.
  prefs: []
  type: TYPE_NORMAL
- en: T-TEST
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the user has opted for the t-test, they must select a group variable (categorical)
    *“group_col”* and a value variable (numerical) *“value_col”*. The group variable
    defines the two groups to be compared. The value variable compares the mean value
    between the two groups. Once the selection has been made, the names of the two
    groups *“group1”* and *“group2”* must be entered in a text field *“st.text_input()”*.
    The two groups should appear in the selected categorical variable. The logarithmic
    scaling *“apply_log_scale”*, which is applied to the value variable, is also available
    here. When the test is performed, the data of the groups is extracted and the
    number of data points (after the NaN values have been removed) is output. The
    t-statistic and the p-value are displayed.
  prefs: []
  type: TYPE_NORMAL
- en: The first value indicates the difference in the mean values between the two
    groups relative to the spread of the data. Whether the difference between the
    groups is statistically significant is indicated by the p-value. If it is less
    than 0.05, it is significant. To visually highlight the distribution of the two
    groups *“filtered_df = df[df[group_col].isin([group1, group2])]”*, a boxplot is
    created *“fig, ax = plt.subplots()”*. Here *“pyplot”* is used, alternatively you
    can also use *“plotly”* [6].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0281425b6d6f039c3e18eac9de239395.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Boxplot with genre (Action/Shooter) and critic_score (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: In this example, *“genre”* was selected as the group variable and *“critic_score”*
    as the value variable. Action (group 1) and Shooter (group 2) were defined as
    groups. The function also calculates whether there are significant outliers in
    the groups. An outlier is defined as a data point exceeding the upper quartile
    by more than 1.5 times the interquartile range *“outliers_group1/2”*. Finally,
    the outliers found are displayed to confirm the validity of the t-test. If the
    distortion is too large, this must be taken into account accordingly in order
    to better classify the reliability and interpretability of the test results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**ANOVA-TEST**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *“anova_test()”* function integrates the option of performing an ANOVA test.
    This test checks whether there are significant differences in the mean values
    of several groups. The data is first cleaned *“df_clean”*. If the ANOVA test is
    significant, a Tukey’s HSD test (Honestly Significant Difference) is also carried
    out. At the beginning, a group variable and a value variable are again defined.
    If a group has fewer than 2 data points, it is excluded *“valid_groups = group_sizes[group_sizes
    >= 2].index”*.
  prefs: []
  type: TYPE_NORMAL
- en: If less than two groups remain after the adjustment, an error message is displayed
    and the test is not performed. The ANOVA test calculates the F-value and the p-value.
    The variability between the groups compared to the variability within the group
    is measured by the F-value. Whether the difference between the mean values of
    the group is significant is indicated by the p-value. If the value is less than
    0.05, at least one group is significantly different. To visualize the results,
    a boxplot is created using *“pyplot”* [7].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6cf3791fda75bcdaa972c48cde52e76f.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Boxplot with console and critic_score (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: If the ANOVA test produces significant results, a Tukey’s test is carried out
    to examine the differences between the individual group pairs in concrete terms.
    The ANOVA test therefore does not show which groups differ from each other. A
    diagram is created that shows the pairwise mean differences between the groups
    and their confidence interval *“st.pyplot(tukey.plot_simultaneous())”*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/97edb4e4c3fa24a8ce648df77b1cba45.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Result of the Tukey Test (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Below the diagram, the results are displayed in a table *“st.dataframe(tukey_results_df,
    height=400)”*. The table contains the two groups, the mean difference *“meandiff”*,
    the adjusted p-value *“p-adj”*, the confidence interval and whether the null hypothesis
    can be rejected or not *“reject”* (True = significant, Fals = not significant).
    A brief example of the confidence interval. For the 3DS and GBA consoles, the
    interval lies between -0.9319 and -0.0061 and is therefore completely below zero.
    The difference in the mean value is significant.
  prefs: []
  type: TYPE_NORMAL
- en: The key figures can be used to have the results interpreted by an LLM. There
    is also an option to download the data as a .csv file for further statistical
    analyses (e.g. regression analyses) [7].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**CHI-QUADRAT-TEST**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *“chi_square_test()”* function checks whether there is a statistically significant
    relationship between two categorical variables. As only categorical variables
    can be used, the option to activate logarithmic scaling is not required. Specifically,
    whether the frequency of observations in the categories is independent of each
    other or whether there is a correlation. The user selects two of the existing
    categorical variables. The NaN values are removed and only the top 10 most frequent
    categories are selected for each variable in order to keep the analysis manageable
    *“value_counts().nlargest(10).index”*.
  prefs: []
  type: TYPE_NORMAL
- en: A crosstab *“contingency_table”* is created, which shows the frequencies of
    the combinations of categories in the two selected variables using a heatmap.
    If the crosstab is not valid (too little data or only one category), the test
    is not performed [8].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef33476baee433f6277b1754200bb8ba.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Heatmap with genre and console (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: The test calculates various values. The chi-square value *“chi2”* determines
    the measure of the difference between the observed and expected frequencies. A
    strong difference is present with high values. As with the other analyses, the
    p-value *“p”* shows whether the difference is significant. The number of degrees
    of freedom of the test *“dof”* is indicated as well as the expected frequencies
    *“expected”*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: REGRESSION ANALYSIS SELECTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The selection of the available regression analyses (linear, logistic and multivariate)
    is similar to the selection of the various hypothesis tests. Once an analysis
    method has been selected, a brief explanation is displayed and the corresponding
    function is called up.
  prefs: []
  type: TYPE_NORMAL
- en: LINEAR REGRESSION ANALYSIS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the beginning of the *“linear_regression()”* function, a correlation matrix
    is created from all available numerical variables in the uploaded dataset *“corr_matrix
    = df[numerical_columns].corr()”*. The matrix is intended to help the user understand
    the relationships between the variables in order to identify the variables for
    which regression analyses are appropriate and those for which they are not (multicollinearity).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the dependent variable and one or more independent variables are selected.
    The data is cleaned and a linear regression model is created for all selected
    independent variables *“model = LinearRegression()”*. The regression coefficient
    and the intercept are specified. After the overall model has been run, a separate
    linear regression model is created for each independent variable and represented
    by a scatterplot [9].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/81dfffeb6570fce448f25ce65a1210d6.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Lineare Regression pal_sales, na_sales and total_sales (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: The regression coefficient shown indicates the extent to which the dependent
    variable is changed when the respective independent variable is changed by one
    unit. Assuming that all other variables remain constant. The value that the dependent
    variable assumes when all independent variables are zero is indicated by the intercept.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: THE LOGISTIC REGRESSION ANALYSIS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with the other functions, the user selects dependent and independent variables
    at the beginning. In this analysis method, the dependent variable must be binary
    (0/1). To demonstrate the function, I have created some data that has nothing
    to do with the dataset used so far. Alternatively, you can also manually adjust
    the values of variables, as long as there are not too many categories. If an incorrect
    variable is selected, a corresponding error message is displayed.
  prefs: []
  type: TYPE_NORMAL
- en: If everything is defined correctly, the logistic regression is performed and
    the model uses the independent variables to model the probability for the target
    variable. Specifically, this is the probability that an event will occur. The
    coefficients are specified for each independent variable and the logistic function
    is visualized. This shows how the probability of the target result (1 instead
    of 0) changes when the independent variable changes [10].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e7d6e5009edd8c76de604785d349d750.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Logistic regression with fictitious values ​​for demonstration purposes
    (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: In the scatterplot, the red line represents the prediction probability for the
    target result, i.e. the probability that result 1 will occur. The independent
    variable varies. The *“logistic_regression()”* function is very well suited to
    binary classification problems where you want to predict the occurrence of an
    event based on several factors.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: MULTIVARIATE REGRESSION ANALYSIS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In multivariate regression analysis, the user must select several dependent
    variables and one or more independent variables. The analysis examines how the
    dependent variables are influenced by the independent variables. After the variable
    selection, the NaN values are removed again and an error message is displayed
    if necessary. The model outputs the regression coefficient and the intercept for
    all dependent variables.
  prefs: []
  type: TYPE_NORMAL
- en: A scatterplot with regression line is created for all combinations of independent
    and dependent variables. This function makes it possible to analyze several target
    variables simultaneously and to model their relationship to several predictors
    [11].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8338266ad3f6ce75729c046c2603e435.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Multivariate regression (plotly) example (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: THE TIME SERIES ANALYSIS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This analysis method performs an analysis over time. For this purpose, a given
    time series is grouped by year and the annual average of a value is calculated
    and displayed. A time variable is required for the analysis; if the dataset used
    does not contain one, it cannot be performed. In the dataset I have selected,
    there is the variable *“release_date”*, which contains the release date of the
    respective game.
  prefs: []
  type: TYPE_NORMAL
- en: The selected time variable is converted to the date format *“df[time_var]”*.
    If the data points are invalid, they are converted to NaN values and removed *“df
    = df.dropna(subset=[time_var])”*. The data is then grouped by year *“df[‘year’]
    = df[time_var].dt.year”* and the annual average for the specified value variable
    “value_var” is calculated *“yearly_avg”*. The minimum and maximum annual average
    values of the value variable are calculated as well as the overall average across
    all data points *“overall_avg”*. The annual average of the value variable per
    year is then displayed via a line chart. The overall average is integrated on
    the horizontal line. The values are displayed alternately above and below the
    data points to improve readability [12].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/72c72193d79e866f168e57599dc1d787.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Time series analysis with year and critic_score (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Important statistical key figures are displayed below the diagram, which can
    be easily interpreted as in the descriptive analysis using an LLM. Specifically,
    the standard deviation, the variance and the minimum and maximum of the value
    variable as well as the year are displayed. The *“perform_time_series_analysis()”*
    function is suitable for analyzing time trends in a data series. This allows an
    initial analysis of the variability over time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: CLUSTERING METHOD SELECTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with the hypothesis tests and regression analyses, there are also various
    options to choose from in the area of clustering methods. The selection function
    has a similar structure to the others. A method is selected and the corresponding
    function is executed. A brief explanation of the method is also shown here. Depending
    on the method, the number of clusters must be defined. For k-Means and hierarchical
    clustering, a maximum of 10 clusters can be defined. For DBSCAN, the radius *“eps”*
    and the minimum number of points per cluster *“min_samples”* are queried. At least
    two numerical variables must be selected for each method.
  prefs: []
  type: TYPE_NORMAL
- en: k-MEANS CLUSTERING
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The k-Means algorithm divides the data into *“n_clusters”*. The points are grouped
    in such a way that the distance between the points within the cluster is minimized.
    The number of clusters is determined by the user. Depending on the number, the
    algorithm calculates which data points belong to which cluster. The result is
    sent to the *“visualize_clusters()”* function for visualization [13].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/bf09602a745cb7788a25d666df0efdf2.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 k-Means Clustering with PCA reduction (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: HIERARCHICAL CLUSTERING
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A hierarchy of clusters is created here, whereby agglomerative or divisive methods
    can be used. Agglomerative clustering is used in the function, whereby each data
    point is initially considered as a separate cluster before they are successively
    merged. The number of clusters is determined by the user and the algorithm divides
    the data according to the number. The same function as for k-Means is used for
    visualization *“visualize_clusters(X, ‘Hierarchical Clustering’)”* [14].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/8b1934c74ae21d70a6c215720b73422e.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 Hierarchical Clustering with PCA reduction (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: DBSCAN CLUSTERING
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this method, data points are grouped based on the density of their surroundings.
    The method is well suited to detecting outliers (noise) and finding clusters of
    any shape. Here, the user does not specify the number of clusters, but the maximum
    distance *“eps”* between two points before they are considered neighbors. The
    minimum number of points that occur in a cluster *“min_samples”* is also defined.
    The visualization is also created by *“visualize_clusters()”* [15].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/912638c2ef5cec406ef2be9277455bfc.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCVIT V1 DBSCAN Clustering with PCA reduction (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: CLUSTER VISUALIZATION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The results of the three different clustering methods are visualized in the
    *“visualize_clusters”* function using Principal Component Analysis (PCA). The
    dimensions of the data are reduced by PCA to two components *“n_components”* in
    order to be able to display the clusters. It is checked whether there are enough
    data points and variables *“num_samples”*; if this is not the case, an error message
    is displayed. The clusters are visualized by a scatterplot that shows the data
    points in the first two PCA components.
  prefs: []
  type: TYPE_NORMAL
- en: The clusters are displayed in different colors *“cmap=‘tab10’”*. In the diagrams,
    the axis label *“ax.set_x/ylabel”* and the legend *“legend_labels”* are adapted
    for better interpretation. The size of the data points “s” and the transparency
    *“alpha”* have also been adjusted to improve visibility. Outliers are automatically
    assigned to cluster -1 in DBSCAN. A table with the average values of the variable
    for each cluster is displayed below the visualization *“st.dataframe(cluster_means)”*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: COMMUNICATION WITH THE LLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this first version of the app, the output of the statistical calculations
    is only analyzed in the descriptive area. The key figures are interpreted using
    the *“query_llm_via_cli”* function. Specifically, the function is used to communicate
    with the LLM via a command line (CLI). To achieve this, the Python module *“subprocess”*
    is used to start the process via the command line. The LLM is started via the
    command [*“ollama”, “run”, “llama3.1”*]. The input is stored in *“stdin”*, the
    output in *“stout”*.
  prefs: []
  type: TYPE_NORMAL
- en: Errors and warnings are stored in *“stderr”*, which hopefully do not occur.
    The input is sent to the model via *“process.communicate”*. Specifically, the
    created *“context”* is sent to the function to communicate with the LLM. If there
    is no response from the model, a timeout mechanism *“timeout=40”* is included,
    which stops the execution after 40 seconds. Depending on the computing power of
    the system used, a response from the model should be displayed much earlier. The
    model’s response is cleaned up and passed to *“extract_relevant_answer”* in order
    to extract relevant information [1].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: MAIN FUNCTION OF THE APP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The structure of the app is defined by the *“main()”* function. The title is
    set *“st.title()”* and the sidebar for uploading the dataset in CSV or Excel format
    *“uploaded_file”* is submitted. Once a file has been uploaded, it is analyzed
    and the numerical and categorical variables are extracted. Here and in many other
    situations, *“session_state”* is used by Streamlit to store certain parameters
    that are relevant for the selection in the analysis methods.
  prefs: []
  type: TYPE_NORMAL
- en: The variables *“numerical_columns”* and *“categorical_columns”* are updated
    as soon as a new dataset is uploaded. Once data is available, the user can select
    from the various analysis methods. Once a method has been selected, it is displayed
    and can be carried out after the corresponding variables have been defined. The
    main function controls the interactive statistical analysis of the app.
  prefs: []
  type: TYPE_NORMAL
- en: CUSTOMIZATION OPTIONS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As already mentioned, the app can be expanded to include other analysis methods
    due to the modular structure of the code. The functionality of interpreting statistical
    key figures using an LLM can also be transferred to other methods. Llama3.1 (8B)
    from Meta is currently used, but another LLM (e.g. Mistral) from Ollama can also
    be used. The command in the *“query_llm_via_cli”* function must then be adapted
    accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the available power, models with more parameters can also be used.
    The design of the diagrams can be further refined, as can the transmitted contexts,
    in order to improve the output of the LLM. Alternatively, you can also create
    a new model file to adjust certain parameters (e.g. parameters) of the LLM and
    thereby improve the interpretation of the data.
  prefs: []
  type: TYPE_NORMAL
- en: ASCVIT V1 PYTHON SCRIPT [GITHUB]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The app code can be downloaded from the following [**GitHub repository**](https://github.com/stefanpietrusky/ASCVITV1).
    The app is started in the corresponding directory using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: CONCLUSION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this article, I showed how Streamlit can be used to create an app that can
    be used to analyze datasets using various methods. I also showed how an interpretation
    can be integrated into the app using an LLM, which results in real added value.
    Data is not only automatically visualized and statistical parameters are output,
    but also classified. The application offers a lot of potential for further development.
    I have listed some suggestions in the penultimate section. Have fun using and
    customizing the app.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6986252b10d7723e67c0529d265a19a5.png)'
  prefs: []
  type: TYPE_IMG
- en: You can clap up to 50 times!
  prefs: []
  type: TYPE_NORMAL
- en: '[1] Pietrusky, S. (2024, August 21). *How to talk to a PDF file without using
    proprietary models: CLI, Streamlit, Ollama.* *Towards Data Science*. [URL](https://medium.com/towards-data-science/how-to-talk-to-a-pdf-file-without-using-proprietary-models-cli-streamlit-ollama-6c22437ed932)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Maven Analytics. (2024, Juni 10.). *Data Playground, Video Game Sales.*
    [URL](https://mavenanalytics.io/data-playground?accessType=open&order=date_added%2Cdesc&search=game)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The elements of statistical
    learning: Data mining, inference, and prediction* (2nd ed.). Stanford University.
    [URL](https://hastie.su.domains/Papers/ESLII.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Bruce, P., Bruce, A., & Gedeck, P. (2021). *Praktische Statistik für Data
    Scientists: 50+ essenzielle Konzepte mit R und Python*(2nd ed.). O’Reilly.'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] VanderPlas J. (2017). *Python Data Science Handbook: Essential Tools for
    Working with Data*. O’Reilly. URL'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] Fahrmeir, L., Künstler, R., Pigeot, I., & Tutz, G. (2016). *Statistik:
    Der Weg zur Datenanalyse* (8th ed.). Springer.'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] Montgomery, D. C. (2012). *Design and analysis of experiments* (8th ed.).
    Wiley. [URL](https://faculty.ksu.edu.sa/sites/default/files/douglas_c._montgomery-design_and_analysis_of_experiments-wiley_2012_edition_8.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] Moore, D. S., McCabe, G. P., Craig, B. A., & Duckworth, W. M. (2021). *Introduction
    to the practice of statistics* (10th ed.). W. H. Freeman.'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] Montgomery, D. C., Peck, E. A., & Vining, G. G. (2012). *Introduction to
    linear regression analysis* (5th ed.). Wiley. [URL](https://ocd.lcwu.edu.pk/cfiles/Statistics/Stat-503/IntroductiontoLinearRegressionAnalysisbyDouglasC.MontgomeryElizabethA.PeckG.GeoffreyViningz-lib.org.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] Hosmer, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). *Applied logistic
    regression* (3rd ed.). Wiley.'
  prefs: []
  type: TYPE_NORMAL
- en: '[11] Johnson, R. A., & Wichern, D. W. (2007). *Applied multivariate statistical
    analysis* (6th ed.). Pearson. [URL](https://alimoradi.iut.ac.ir/sites/alimoradi.iut.ac.ir/files/file_basepage/richard_arnold_johnson_dean_w._wichern_applied_bookzz.org_.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[12] Box, G. E. P., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M. (2015).
    *Time series analysis: Forecasting and control* (5th ed.). Wiley. [URL](http://repo.darmajaya.ac.id/4781/1/Time%20Series%20Analysis_%20Forecasting%20and%20Control%20%28%20PDFDrive%20%29.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[13] Witten, I. H., & Frank, E. (2005). *Data mining: Practical machine learning
    tools and techniques* (2nd ed.). Morgan Kaufmann.[URL](http://academia.dk/BiologiskAntropologi/Epidemiologi/DataMining/Witten_and_Frank_DataMining_Weka_2nd_Ed_2005.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[14] Everitt, B. S., Landau, S., Leese, M., & Stahl, D. (2011). *Cluster analysis*
    (5th ed.). Wiley. [URL](https://cicerocq.wordpress.com/wp-content/uploads/2019/05/cluster-analysis_5ed_everitt.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[15] Aggarwal, C. C., & Reddy, C. K. (2014). *Data Clustering: Algorithms and
    Applications*. CRC Press [URL](https://people.cs.vt.edu/~reddy/papers/DCBOOK.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1eb59c043d8bcab8d8e926430e0f308d.png)'
  prefs: []
  type: TYPE_IMG
- en: Just for the thumbnail (Image by author)
  prefs: []
  type: TYPE_NORMAL
