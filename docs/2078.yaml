- en: 'Missing Value Imputation, Explained: A Visual Guide with Code Examples for
    Beginners'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺失值填充，解释：适合初学者的视觉指南与代码示例
- en: 原文：[https://towardsdatascience.com/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb?source=collection_archive---------0-----------------------#2024-08-27](https://towardsdatascience.com/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb?source=collection_archive---------0-----------------------#2024-08-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb?source=collection_archive---------0-----------------------#2024-08-27](https://towardsdatascience.com/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb?source=collection_archive---------0-----------------------#2024-08-27)
- en: DATA PREPROCESSING
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: One (tiny) dataset, six imputation methods?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一组（微小的）数据集，六种填充方法？
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--93e0726284eb--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--93e0726284eb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--93e0726284eb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--93e0726284eb--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--93e0726284eb--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--93e0726284eb--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--93e0726284eb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--93e0726284eb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--93e0726284eb--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--93e0726284eb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--93e0726284eb--------------------------------)
    ·13 min read·Aug 27, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--93e0726284eb--------------------------------)
    ·阅读时间13分钟·2024年8月27日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f42d507518dfcdd0f8722ea80b8fec0e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f42d507518dfcdd0f8722ea80b8fec0e.png)'
- en: '`⛳️ More [DATA PREPROCESSING](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4),
    explained: ▶ [Missing Value Imputation](/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb)
    · [Categorical Encoding](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    · [Data Scaling](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    · [Discretization](/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?gi=c1bf25229f86)
    · [Oversampling & Undersampling](/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091)
    · [Data Leakage in Preprocessing](/data-leakage-in-preprocessing-explained-a-visual-guide-with-code-examples-33cbf07507b7)`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`⛳️ 更多 [数据预处理](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4)
    解释： ▶ [缺失值填充](/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb)
    · [类别编码](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    · [数据缩放](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    · [离散化](/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?gi=c1bf25229f86)
    · [过采样与欠采样](/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091)
    · [数据泄露与预处理](https://towardsdatascience.com/data-leakage-in-preprocessing-explained-a-visual-guide-with-code-examples-33cbf07507b7)`'
- en: 'Let’s talk about something that every data scientist, analyst, or curious number-cruncher
    has to deal with sooner or later: missing values. Now, I know what you’re thinking
    — “Oh great, another missing value guide.” But hear me out. I’m going to show
    you how to tackle this problem using not one, not two, but six different imputation
    methods, all on a single dataset (with helpful visuals as well!). By the end of
    this, you’ll see why domain knowledge is worth its weight in gold (something even
    our AI friends might struggle to replicate).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来谈谈每个数据科学家、分析师或好奇的数字分析师最终都需要面对的问题：缺失值。现在，我知道你在想什么——“哦，太好了，又一个关于缺失值的指南。”但是请听我说完。我将展示如何使用六种不同的填充方法来解决这个问题，且所有方法都应用于同一个数据集（并且附有有用的可视化效果！）。通过这篇文章，你将明白为什么领域知识的价值不可估量（甚至是我们AI朋友可能也难以复制的）。
- en: '![](../Images/29c4e53115cb3858f193adc68a724447.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29c4e53115cb3858f193adc68a724447.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可视化图像：作者使用 Canva Pro 创建。优化适配移动设备，可能在桌面端显示过大。
- en: What Are Missing Values and Why Do They Occur?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是缺失值以及为什么会出现？
- en: Before we get into our dataset and imputation methods, let’s take a moment to
    understand what missing values are and why they’re such a common headache in data
    science.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论我们的数据集和填补方法之前，让我们先花一点时间理解缺失值是什么以及它们为什么在数据科学中如此常见。
- en: What Are Missing Values?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是缺失值？
- en: Missing values, often represented as NaN (Not a Number) in pandas or NULL in
    databases, are essentially *holes in your dataset*. They’re the empty cells in
    your spreadsheet, the blanks in your survey responses, the data points that got
    away. In the world of data, not all absences are created equal, and understanding
    the nature of your missing values is crucial for deciding how to handle them.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值，通常在 pandas 中表示为 NaN（非数字），在数据库中表示为 NULL，实质上是*数据集中的空洞*。它们是你电子表格中的空白单元格、调查问卷中的空白回答、失去的数据点。在数据的世界里，并非所有缺失都相同，理解缺失值的性质对于决定如何处理它们至关重要。
- en: '![](../Images/77e04b185445651e16249a07fbddc447.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77e04b185445651e16249a07fbddc447.png)'
- en: Image by author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Why Do Missing Values Occur?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么会出现缺失值？
- en: 'Missing values can sneak into your data for a variety of reasons. Here are
    some common reasons:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值可能因为多种原因悄悄进入你的数据。以下是一些常见的原因：
- en: '**Data Entry Errors**: Sometimes, it’s just human error. Someone might forget
    to input a value or accidentally delete one.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据输入错误**：有时，纯粹是人为错误。有人可能忘记输入一个值或不小心删除了某个值。'
- en: '**Sensor Malfunctions**: In IoT or scientific experiments, a faulty sensor
    might fail to record data at certain times.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**传感器故障**：在物联网或科学实验中，故障的传感器可能会在某些时刻无法记录数据。'
- en: '**Survey Non-Response**: In surveys, respondents might skip questions they’re
    uncomfortable answering or don’t understand.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**调查非响应**：在调查中，受访者可能会跳过他们不愿回答或不理解的问题。'
- en: '**Merged Datasets**: When combining data from multiple sources, some entries
    might not have corresponding values in all datasets.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**合并数据集**：当从多个来源合并数据时，某些条目可能在所有数据集中没有对应的值。'
- en: '**Data Corruption**: During data transfer or storage, some values might get
    corrupted and become unreadable.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据损坏**：在数据传输或存储过程中，某些值可能会被损坏并变得无法读取。'
- en: '**Intentional Omissions**: Some data might be intentionally left out due to
    privacy concerns or irrelevance.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**故意省略**：由于隐私问题或不相关，某些数据可能被故意省略。'
- en: '**Sampling Issues**: The data collection method might systematically miss certain
    types of data.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**采样问题**：数据收集方法可能系统性地遗漏某些类型的数据。'
- en: '**Time-Sensitive Data**: In time series data, values might be missing for periods
    when data wasn’t collected (e.g., weekends, holidays).'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**时效性数据**：在时间序列数据中，可能会在数据未收集的期间（如周末、假期）缺失值。'
- en: Types of Missing Data
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失数据的类型
- en: 'Understanding the type of missing data you’re dealing with can help you choose
    the most appropriate imputation method. Statisticians generally categorize missing
    data into three types:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 理解你所处理的缺失数据类型可以帮助你选择最合适的填补方法。统计学家通常将缺失数据分为三种类型：
- en: '**Missing Completely at Random (MCAR)**: The missingness is *totally random*
    and doesn’t depend on any other variable. For example, if a lab sample was accidentally
    dropped.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**完全随机缺失（MCAR）**：缺失情况是*完全随机的*，不依赖于任何其他变量。例如，如果一个实验室样本不小心掉落。'
- en: '**Missing at Random (MAR)**: The probability of missing data *depends on other
    observed variables* but not on the missing data itself. For example, men might
    be less likely to answer questions about emotions in a survey.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**随机缺失（MAR）**：缺失数据的概率*取决于其他观测到的变量*，而不是缺失数据本身。例如，男性可能不太愿意在调查中回答有关情感的问题。'
- en: '**Missing Not at Random (MNAR)**: The missingness *depends on the value of
    the missing data itself*. For example, people with high incomes might be less
    likely to report their income in a survey.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**非随机缺失（MNAR）**：缺失情况*取决于缺失数据本身的值*。例如，高收入的人可能不太愿意在调查中报告他们的收入。'
- en: '![](../Images/4cc65a492703a3c1624d09b257c15bbf.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4cc65a492703a3c1624d09b257c15bbf.png)'
- en: Why Care About Missing Values?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要关心缺失值？
- en: 'Missing values can significantly impact your analysis:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值可能会显著影响你的分析：
- en: They can introduce bias if not handled properly.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果处理不当，它们可能会引入偏差。
- en: Many machine learning algorithms can’t handle missing values out of the box.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 许多机器学习算法无法直接处理缺失值。
- en: They can lead to loss of important information if instances with missing values
    are simply discarded.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果简单地丢弃带有缺失值的实例，可能会导致重要信息的丧失。
- en: Improperly handled missing values can lead to incorrect conclusions or predictions.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不当处理缺失值可能导致错误的结论或预测。
- en: That’s why it’s crucial to have a solid strategy for dealing with missing values.
    And that’s exactly what we’re going to explore in this article!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么拥有处理缺失值的可靠策略至关重要的原因。而这正是我们将在本文中探讨的内容！
- en: The Dataset
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: First things first, let’s introduce our dataset. We’ll be working with a golf
    course dataset that tracks various factors affecting the crowdedness of the course.
    This dataset has a bit of everything — numerical data, categorical data, and yes,
    plenty of missing values.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们介绍一下数据集。我们将使用一个高尔夫球场的数据集，跟踪影响球场拥挤度的各种因素。这个数据集包含了几乎所有内容——数值型数据、分类数据，当然还有大量缺失值。
- en: '![](../Images/8c57995a7970551a87f83242506716ab.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c57995a7970551a87f83242506716ab.png)'
- en: This dataset is artificially made by the author (inspired by [1]) to promote
    learning.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集是由作者人工制作的（灵感来源于[1]），旨在促进学习。
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As we can see, our dataset contains 20 rows and 8 columns:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，数据集中有20行和8列：
- en: 'Date: The date of the observation'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期：观察日期
- en: 'Weekday: Day of the week (0–6, where 0 is Monday)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期几：一周中的天数（0–6，其中0表示星期一）
- en: 'Holiday: Boolean indicating if it’s a holiday (0 or 1)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假期：布尔值，表示是否为假期（0或1）
- en: 'Temp: Temperature in Celsius'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 温度：摄氏温度
- en: 'Humidity: Humidity percentage'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 湿度：湿度百分比
- en: 'Wind: Wind condition (0 or 1, possibly indicating calm or windy)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 风速：风速情况（0或1，可能表示平静或有风）
- en: 'Outlook: Weather outlook (sunny, overcast, or rainy)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天气预报：天气预报（晴天、阴天或雨天）
- en: 'Crowdedness: Percentage of course occupancy'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥挤度：课程占用百分比
- en: And look at that! We’ve got missing values in every column except Date and Weekday.
    Perfect for our imputation party.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 看看这个！除了日期和星期几，其他每一列都有缺失值。非常适合我们的插补工作。
- en: Now that we have our dataset loaded, let’s tackle these missing values with
    six different imputation methods. We’ll use a different strategy for each type
    of data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载了数据集，让我们通过六种不同的插补方法来处理这些缺失值。我们会针对每种数据类型使用不同的策略。
- en: 'Method 1: Listwise Deletion'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法1：逐行删除
- en: Listwise deletion, also known as complete case analysis, involves removing entire
    rows that contain any missing values. This method is simple and preserves the
    distribution of the data, but it can lead to a significant loss of information
    if many rows contain missing values.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 逐行删除，也称为完全案例分析，涉及删除包含任何缺失值的整行数据。此方法简单，并能保持数据分布，但如果许多行包含缺失值，它可能会导致信息的显著丢失。
- en: '**👍 Common Use**: Listwise deletion is often used when the number of missing
    values is small and the data is missing completely at random (MCAR). It’s also
    useful when you need a complete dataset for certain analyses that can’t handle
    missing values.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**👍 常见使用**：逐行删除通常用于缺失值较少且数据完全随机缺失（MCAR）的情况。它也适用于需要完整数据集的分析，而这些分析不能处理缺失值。'
- en: '**In Our Case**: We’re using listwise deletion for rows that have at least
    4 missing values. These rows might not provide enough reliable information, and
    removing them can help us focus on the more complete data points. However, we’re
    being cautious and only removing rows with significant missing data to preserve
    as much information as possible.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**在我们案例中**：我们使用逐行删除处理至少有4个缺失值的行。这些行可能没有足够可靠的信息，删除它们可以帮助我们集中在更完整的数据点上。不过，我们会小心操作，只删除缺失数据较多的行，以尽量保留更多信息。'
- en: '![](../Images/ac3d3f78bea999b4a77b406489df405b.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac3d3f78bea999b4a77b406489df405b.png)'
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We’ve removed 2 rows that had too many missing values. Now let’s move on to
    imputing the remaining missing data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经删除了2行缺失值过多的数据。现在让我们继续处理剩余的缺失数据。
- en: 'Method 2: Simple Imputation — Mean and Mode'
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法2：简单插补 — 均值和众数
- en: Simple imputation involves replacing missing values with a summary statistic
    of the observed values. Common approaches include using the mean, median, or mode
    of the non-missing values in a column.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 简单插补是指用观测值的汇总统计量来替代缺失值。常见的做法包括使用列中非缺失值的均值、中位数或众数。
- en: '**👍 Common Use**: Mean imputation is often used for continuous variables when
    the data is missing at random and the distribution is roughly symmetric. Mode
    imputation is typically used for categorical variables.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**👍 常见使用**：均值插补通常用于连续变量，当数据随机缺失且分布大致对称时。众数插补通常用于分类变量。'
- en: '**In Our Case**: We’re using mean imputation for Humidity and mode imputation
    for Holiday. For Humidity, assuming the missing values are random, the mean provides
    a reasonable estimate of the typical humidity. For Holiday, since it’s a binary
    variable (holiday or not), the mode gives us the most common state, which is a
    sensible guess for missing values.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**在我们的案例中**：我们对Humidity使用了均值填充，对Holiday使用了众数填充。对于Humidity，假设缺失值是随机的，均值提供了一个合理的典型湿度估算。对于Holiday，由于它是一个二元变量（假期与否），众数给出了最常见的状态，这是一个合理的缺失值猜测。'
- en: '![](../Images/cb3cbf0666616f5ece9d7ebafe1801bc.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cb3cbf0666616f5ece9d7ebafe1801bc.png)'
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Method 3: Linear Interpolation'
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法 3：线性插值
- en: Linear interpolation estimates missing values by assuming a linear relationship
    between known data points. It’s particularly useful for time series data or data
    with a natural ordering.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 线性插值通过假设已知数据点之间存在线性关系来估算缺失值。它特别适用于时间序列数据或具有自然顺序的数据。
- en: '**👍 Common Use**: Linear interpolation is often used for time series data,
    where missing values can be estimated based on the values before and after them.
    It’s also useful for any data where there’s expected to be a roughly linear relationship
    between adjacent points.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**👍 常见用法**：线性插值通常用于时间序列数据，在这种情况下，缺失值可以根据前后数据点的值进行估算。它也适用于任何预期相邻数据点之间存在大致线性关系的数据。'
- en: '**In Our Case**: We’re using linear interpolation for Temperature. Since temperature
    tends to change gradually over time and our data is ordered by date, linear interpolation
    can provide reasonable estimates for the missing temperature values based on the
    temperatures recorded on nearby days.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**在我们的案例中**：我们对Temperature使用了线性插值。由于温度通常随时间逐渐变化，并且我们的数据按日期排序，线性插值可以根据附近几天的温度值来合理估算缺失的温度值。'
- en: '![](../Images/99ad8cebf6fd2d63877900c2f3b71339.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99ad8cebf6fd2d63877900c2f3b71339.png)'
- en: '[PRE4]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Method 4: Forward/Backward Fill'
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法 4：前向/后向填充
- en: Forward fill (or “last observation carried forward”) propagates the last known
    value forward to fill gaps, while backward fill does the opposite. This method
    assumes that the missing value is likely to be similar to the nearest known value.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 前向填充（或“上次观察值前移”）将最后一个已知值前推填补空缺，而后向填充则执行相反的操作。这种方法假设缺失值可能与最近已知的值相似。
- en: '**👍 Common Use**: Forward/backward fill is often used for time series data,
    especially when the value is likely to remain constant until changed (like in
    financial data) or when the most recent known value is the best guess for the
    current state.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**👍 常见用法**：前向/后向填充常用于时间序列数据，尤其是当数据值在改变之前可能保持不变时（例如金融数据），或者当最新的已知值是当前状态的最佳猜测时。'
- en: '**In Our Case**: We’re using a combination of forward and backward fill for
    Outlook. Weather conditions often persist for several days, so it’s reasonable
    to assume that a missing Outlook value might be similar to the Outlook of the
    previous or following day.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**在我们的案例中**：我们对Outlook使用了前向和后向填充的组合。天气状况通常会持续好几天，因此可以合理假设缺失的Outlook值可能与前一天或后一天的Outlook值相似。'
- en: '![](../Images/f76370e6ad62f0c847556ff0e1e83395.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f76370e6ad62f0c847556ff0e1e83395.png)'
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Method 5: Constant Value Imputation'
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法 5：常数值填充
- en: This method involves replacing all missing values in a variable with a specific
    constant value. This constant could be chosen based on domain knowledge or a safe
    default value.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法涉及用特定的常数值替换变量中的所有缺失值。这个常数值可以根据领域知识或一个安全的默认值来选择。
- en: '**👍 Common Use**: Constant value imputation is often used when there’s a logical
    default value for missing data, or when you want to explicitly flag that a value
    was missing (by using a value outside the normal range of the data).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**👍 常见用法**：常数值填充通常在缺失数据有逻辑默认值的情况下使用，或者当你想明确标记某个值缺失时（通过使用一个超出数据正常范围的值）。'
- en: '**In Our Case**: We’re using constant value imputation for the Wind column,
    replacing missing values with -1\. This approach explicitly flags imputed values
    (since -1 is outside the normal 0–1 range for Wind) and it preserves the information
    that these values were originally missing.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**在我们的案例中**：我们对Wind列使用了常数值填充，将缺失值替换为-1\。这种方法明确标记了填充的值（因为-1超出了Wind列的正常0-1范围），同时保留了这些值最初缺失的信息。'
- en: '![](../Images/bc42e0bc88d6142a226e70ec4a52840e.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc42e0bc88d6142a226e70ec4a52840e.png)'
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Method 6: KNN Imputation'
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法 6：KNN填充
- en: '[K-Nearest Neighbors](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    (KNN) imputation estimates missing values by finding the K most similar samples
    in the dataset (just like KNN as Classification Algorithm) and using their values
    to impute the missing data. This method can capture complex relationships between
    variables.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[K近邻](https://example.org/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)（KNN）填补通过找到数据集中最相似的K个样本来估算缺失值（就像KNN作为分类算法一样），并使用它们的值来填补缺失数据。这种方法可以捕捉变量之间的复杂关系。'
- en: '**👍 Common Use**: KNN imputation is versatile and can be used for both continuous
    and categorical variables. It’s particularly useful when there are expected to
    be complex relationships between variables that simpler methods might miss.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**👍 常见用途**：KNN填补方法非常灵活，可以用于连续变量和分类变量。特别是在变量之间可能存在复杂关系，而简单方法可能忽略这些关系时，它尤其有用。'
- en: '**In Our Case**: We’re using KNN imputation for Crowdedness. Crowdedness likely
    depends on a combination of factors (like temperature, holiday status, etc.),
    and KNN can capture these complex relationships to provide more accurate estimates
    of missing crowdedness values.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**在我们的案例中**：我们使用KNN填补来估算拥挤度。拥挤度可能依赖于多个因素（如温度、假期状态等），而KNN能够捕捉这些复杂的关系，提供更准确的缺失拥挤度值估算。'
- en: '![](../Images/a053cca0cd994e3d358188a79e82229d.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a053cca0cd994e3d358188a79e82229d.png)'
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Conclusion: The Power of Choice (and Knowledge)'
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论：选择的力量（与知识）
- en: So, there you have it! Six different ways to handle missing values, all applied
    to our golf course dataset.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，结果就是这样！六种不同的缺失值处理方法，都应用于我们的高尔夫球场数据集。
- en: '![](../Images/512ea00ed33319c250f4dc0e98dc11f9.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/512ea00ed33319c250f4dc0e98dc11f9.png)'
- en: 'Let’s recap how each method tackled our data:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下每种方法是如何处理我们的数据的：
- en: '**Listwise Deletion**: Helped us focus on more complete data points by removing
    rows with extensive missing values.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**列表删除法**：通过删除包含大量缺失值的行，帮助我们集中处理更完整的数据点。'
- en: '**Simple Imputation**: Filled in Humidity with average values and Holiday with
    the most common occurrence.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**简单填补**：用平均值填补湿度，且用最常见的值填补假期。'
- en: '**Linear Interpolation**: Estimated missing Temperature values based on the
    trend of surrounding days.'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**线性插值**：根据周围天数的趋势估算缺失的温度值。'
- en: '**Forward/Backward Fill**: Guessed missing Outlook values from adjacent days,
    reflecting the persistence of weather patterns.'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**前向/后向填补**：根据相邻天的数据猜测缺失的天气预报值，反映天气模式的持续性。'
- en: '**Constant Value Imputation**: Flagged missing Wind data with -1, preserving
    the fact that these values were originally unknown.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**常数值填补**：用-1标记缺失的风速数据，保留这些值原本是未知的事实。'
- en: '**KNN Imputation**: Estimated Crowdedness based on similar days, capturing
    complex relationships between variables.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**KNN填补**：根据相似的日子估算拥挤度，捕捉变量之间的复杂关系。'
- en: Each method tells a different story about our missing data, and the “right”
    choice depends on what we know about our golf course operations and what questions
    we’re trying to answer.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 每种方法讲述了关于我们缺失数据的不同故事，而“正确”的选择取决于我们对高尔夫球场运营的了解以及我们想要回答的问题。
- en: The key takeaway? Don’t just blindly apply imputation methods. Understand your
    data, consider the context, and choose the method that makes the most sense for
    your specific situation.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 关键要点？不要盲目地应用填补方法。理解你的数据，考虑背景，并选择最适合你特定情况的方法。
- en: '⚠️ Warning: The Purpose and Limitations of Missing Value Imputation'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ⚠️ 警告：缺失值填补的目的与局限性
- en: 'While we’ve explored various imputation techniques, we need to understand their
    purpose and limitations:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经探讨了各种填补技术，但我们需要理解它们的目的和局限性：
- en: '**Not a Magic Solution**: Imputation is not a cure-all for missing data. It’s
    a tool to make your data usable, **not to create perfect data**.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不是万能解决方案**：填补方法并非解决缺失数据的灵丹妙药。它是让你的数据可用的工具，**而不是用来创造完美数据的工具**。'
- en: '**Potential for Bias**: Imputed values are educated guesses. They can introduce
    bias if not done carefully, especially if the data is Not Missing At Random (NMAR).'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**偏差的潜在可能性**：填补的值是经过推测的估计。如果不小心进行，尤其是在数据是非随机缺失（NMAR）的情况下，可能会引入偏差。'
- en: '**Loss of Uncertainty**: Most simple imputation methods don’t account for the
    uncertainty in the missing values, which can lead to overconfident models.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不确定性的丧失**：大多数简单的填补方法没有考虑缺失值的不确定性，这可能导致过于自信的模型。'
- en: '**Data Distortion**: Aggressive imputation can distort relationships in your
    data. Always check if imputation has significantly altered your data’s distribution
    or correlations.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据扭曲**：激进的插补可能会扭曲数据中的关系。始终检查插补是否显著改变了数据的分布或相关性。'
- en: '**Document Your Process**: Always clearly document your imputation methods.
    This transparency is crucial for reproducibility and for others to understand
    potential biases in your results.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**记录您的过程**：始终清晰地记录您的插补方法。这种透明度对于可重复性至关重要，也有助于他人理解您结果中潜在的偏差。'
- en: Again, the goal of imputation is to make your data usable while minimizing bias
    and information loss. It’s not about creating perfect data, but about making the
    best use of the information you have. Always approach imputation with caution
    and critical thinking.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，插补的目标是使您的数据可用，同时最小化偏差和信息丢失。这不是为了创建完美的数据，而是为了最大限度地利用您已有的信息。始终以谨慎和批判性思维来处理插补。
- en: 🌟 Missing Value Imputation Summarized
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🌟 缺失值插补概述
- en: '[PRE8]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Further Reading
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入阅读
- en: For a detailed explanation of the [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)
    and its implementation in scikit-learn, readers can refer to the official documentation,
    which provides comprehensive information on its usage and parameters.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 有关[KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)及其在scikit-learn中实现的详细解释，读者可以参考官方文档，其中提供了关于其使用和参数的全面信息。
- en: Technical Environment
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术环境
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用 Python 3.7 和 scikit-learn 1.5。尽管所讨论的概念具有普遍适用性，但不同版本之间的具体代码实现可能会略有不同。
- en: About the Illustrations
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于插图
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，否则所有图片均由作者创作，并结合了 Canva Pro 的授权设计元素。
- en: '![](../Images/81e368a2e5f6c346e3d721bd30cf1575.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81e368a2e5f6c346e3d721bd30cf1575.png)'
- en: For a concise visual summary of Missing Values Imputation, check out [the companion
    Instagram post.](https://www.instagram.com/p/C_Kh78qSzoz/)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 若想了解缺失值插补的简明视觉总结，请查看[相关 Instagram 帖子。](https://www.instagram.com/p/C_Kh78qSzoz/)
- en: Reference
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] T. M. Mitchell, [Machine Learning](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)
    (1997), McGraw-Hill Science/Engineering/Math, pp. 59'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] T. M. Mitchell, [机器学习](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)（1997），McGraw-Hill
    科学/工程/数学， 第59页'
- en: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘿𝙖𝙩𝙖 𝙋𝙧𝙚𝙥𝙧𝙤𝙘𝙚𝙨𝙨𝙞𝙣𝙜 𝙢𝙚𝙩𝙝𝙤𝙙𝙨 𝙝𝙚𝙧𝙚:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘿𝙖𝙩𝙖 𝙋𝙧𝙚𝙥𝙧𝙤𝙘𝙚𝙨𝙨𝙞𝙣𝙜 𝙢𝙚𝙩𝙝𝙤𝙙𝙨 𝙝𝙚𝙧𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----93e0726284eb--------------------------------)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----93e0726284eb--------------------------------)'
- en: Data Preprocessing
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: '[View list](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4?source=post_page-----93e0726284eb--------------------------------)6
    stories![](../Images/f7ead0fb9a8dc2823d7a43d67a1c6932.png)![Cartoon illustration
    of two figures embracing, with letters ‘A’, ‘B’, ‘C’ and numbers ‘1’, ‘2’, ‘3’
    floating around them. A pink heart hovers above, symbolizing affection. The background
    is a pixelated pattern of blue and green squares, representing data or encoding.
    This image metaphorically depicts the concept of encoding categorical data, where
    categories (ABC) are transformed into numerical representations (123).](../Images/72bb3a287a9ca4c5e7a3871e234bcc4b.png)![A
    cartoon illustration representing data scaling in machine learning. A tall woman
    (representing a numerical feature with a large range) is shown shrinking into
    a child (representing the same feature after scaling to a smaller range). A red
    arrow indicates the shrinking process, and yellow sparkles around the child signify
    the positive impact of scaling.](../Images/d261b2c52a3cafe266d1962d4dbabdbd.png)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4?source=post_page-----93e0726284eb--------------------------------)6
    个故事![](../Images/f7ead0fb9a8dc2823d7a43d67a1c6932.png)![两个人物相互拥抱的卡通插图，字母‘A’、‘B’、‘C’和数字‘1’、‘2’、‘3’在他们周围漂浮。上方有一个粉色的心形，象征着情感。背景是蓝色和绿色方块组成的像素化图案，代表数据或编码。这幅图形象地描绘了类别数据编码的概念，其中类别（ABC）被转化为数字表示（123）。](../Images/72bb3a287a9ca4c5e7a3871e234bcc4b.png)![代表机器学习中数据缩放的卡通插图。一位高大的女性（代表具有大范围的数值特征）正在变小成一个儿童（代表该特征经过缩放后的较小范围）。红色箭头指示缩小过程，黄色的闪光表示缩放的积极影响。](../Images/d261b2c52a3cafe266d1962d4dbabdbd.png)'
- en: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----93e0726284eb--------------------------------)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----93e0726284eb--------------------------------)'
- en: Classification Algorithms
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----93e0726284eb--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----93e0726284eb--------------------------------)8
    个故事![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----93e0726284eb--------------------------------)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----93e0726284eb--------------------------------)'
- en: Regression Algorithms
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归算法
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----93e0726284eb--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This “dummy” doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----93e0726284eb--------------------------------)5
    个故事![一个带有辫子和粉色帽子的卡通娃娃。这个“假人”娃娃，凭借其简单的设计和心形装饰的衬衫，形象地代表了机器中的假回归器概念。就像这个玩具一样的形象是一个简化的、静态的人物表现，假回归器是一种基础模型，用作更复杂分析的基准。](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
