- en: How to Use Re-Ranking for Better LLM RAG Retrieval
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用重新排序提高 LLM RAG 检索效果
- en: 原文：[https://towardsdatascience.com/how-to-use-re-ranking-for-better-llm-rag-retrieval-243f89414266?source=collection_archive---------0-----------------------#2024-05-02](https://towardsdatascience.com/how-to-use-re-ranking-for-better-llm-rag-retrieval-243f89414266?source=collection_archive---------0-----------------------#2024-05-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-use-re-ranking-for-better-llm-rag-retrieval-243f89414266?source=collection_archive---------0-----------------------#2024-05-02](https://towardsdatascience.com/how-to-use-re-ranking-for-better-llm-rag-retrieval-243f89414266?source=collection_archive---------0-----------------------#2024-05-02)
- en: Building an advanced local LLM RAG pipeline with two-step retrieval using open-source
    bi-encoders and cross-encoders
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用开源双编码器和交叉编码器构建一个先进的本地 LLM RAG 流水线，采用两步检索
- en: '[](https://medium.com/@leoneversberg?source=post_page---byline--243f89414266--------------------------------)[![Dr.
    Leon Eversberg](../Images/56dc3579a29933f7047a9ce60be4697a.png)](https://medium.com/@leoneversberg?source=post_page---byline--243f89414266--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--243f89414266--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--243f89414266--------------------------------)
    [Dr. Leon Eversberg](https://medium.com/@leoneversberg?source=post_page---byline--243f89414266--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@leoneversberg?source=post_page---byline--243f89414266--------------------------------)[![Dr.
    Leon Eversberg](../Images/56dc3579a29933f7047a9ce60be4697a.png)](https://medium.com/@leoneversberg?source=post_page---byline--243f89414266--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--243f89414266--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--243f89414266--------------------------------)
    [Dr. Leon Eversberg](https://medium.com/@leoneversberg?source=post_page---byline--243f89414266--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--243f89414266--------------------------------)
    ·9 min read·May 2, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--243f89414266--------------------------------)
    ·阅读时间：9分钟·2024年5月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/451f8f4e1cb91219a3a0449a305140d9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/451f8f4e1cb91219a3a0449a305140d9.png)'
- en: The LLM chatbot with two-stage RAG retrieval I built with access to Wikipedia.
    Image by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我构建的具有两阶段 RAG 检索的 LLM 聊天机器人，可以访问 Wikipedia。图片来自作者
- en: Chatbots based on Large Language Models (LLMs) can be improved by providing
    external knowledge through Retrieval Augmented Generation (RAG).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大型语言模型（LLM）的聊天机器人可以通过检索增强生成（RAG）提供外部知识来进行改进。
- en: This external knowledge can reduce wrong answers (hallucinations) and also give
    the model access to information that was not part of its training data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些外部知识可以减少错误答案（幻觉），并且还可以让模型访问到其训练数据中没有的信息。
- en: With RAG, we feed our LLM information, such as PDF documents, or Wikipedia articles,
    as additional context in our prompt.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 RAG，我们将信息（如 PDF 文档或 Wikipedia 文章）作为额外的上下文输入到提示中，提供给 LLM。
- en: '![](../Images/031cb1f48b211c1e5d5d74b73112aa54.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/031cb1f48b211c1e5d5d74b73112aa54.png)'
- en: 'The basic RAG pipeline: an encoder model and a vector database are used to
    efficiently search for relevant document chunks. Image from my article [How to
    Build a Local Open-Source LLM Chatbot With RAG](https://medium.com/towards-data-science/how-to-build-a-local-open-source-llm-chatbot-with-rag-f01f73e2a131)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的 RAG 流水线：编码器模型和向量数据库用于高效地搜索相关的文档片段。图片来自我的文章 [如何构建本地开源 LLM 聊天机器人与 RAG](https://medium.com/towards-data-science/how-to-build-a-local-open-source-llm-chatbot-with-rag-f01f73e2a131)
- en: 'However, RAG chatbots follow the old principle of data science: **garbage in,
    garbage out**. If the document retrieval fails, the LLM model has no chance of
    providing a good answer.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，RAG 聊天机器人遵循数据科学的老原则：**垃圾进，垃圾出**。如果文档检索失败，LLM 模型就没有机会提供好的答案。
- en: An improvement to the basic RAG pipeline is the use of a **re-ranker**. A re-ranker
    takes the user’s question and all the initially retrieved documents as input and
    re-ranks these documents based on how closely they match the question.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对基本 RAG 流水线的改进是使用 **重新排序器**。重新排序器将用户的问题和所有最初检索到的文档作为输入，并根据这些文档与问题的匹配程度重新排序。
