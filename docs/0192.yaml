- en: Generating Images with Stable Diffusion and OnnxStream on the Raspberry Pi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/generating-images-with-stable-diffusion-and-onnxstream-on-the-raspberry-pi-f126636b6c0c?source=collection_archive---------4-----------------------#2024-01-20](https://towardsdatascience.com/generating-images-with-stable-diffusion-and-onnxstream-on-the-raspberry-pi-f126636b6c0c?source=collection_archive---------4-----------------------#2024-01-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Learn how to use OnnxStream to generate images with Stable Diffusion XL Turbo
    on the Raspberry Pi!**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)[![Pye
    Sone Kyaw](../Images/907574a7d2de57a4cc0ce36d73234a7a.png)](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)
    [Pye Sone Kyaw](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)
    ·5 min read·Jan 20, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9dea536f7bcfc9ad472de762c24c95ad.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Images generated using SDXL Turbo on the Raspberry Pi, each taking ~3 minutes
    | Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: '[In my last article, I shared how to run large language models and vision language
    models on the Raspberry Pi](/running-local-llms-and-vlms-on-the-raspberry-pi-57bd0059c41a).
    This time around, instead of LLMs and VLMs, we shall run an image generation model
    — [Stable Diffusion XL (SDXL) Turbo](https://stability.ai/news/stability-ai-sdxl-turbo)
    — on the Raspberry Pi 5\. It’s another impossible sounding feat, but open-source
    wonders do exist, and running a SDXL Turbo model on a very resource constrained
    environment is one of them.'
  prefs: []
  type: TYPE_NORMAL
- en: '**OnnxStream**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[OnnxStream](https://github.com/vitoplantamura/OnnxStream#stable-diffusion-xl-10-base)
    is an open-source project created by Vito Plantamura with the original intention
    of running Stable Diffusion 1.5 (SD1.5) on a Raspberry Pi Zero 2 by minimising
    memory consumption as much as possible, albeit at the cost of increased inference
    latency/throughput.'
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, it has expanded to support not only Stable Diffusion
    1.5 but also Stable Diffusion XL 1.0 Base (SDXL) and Stable Diffusion XL Turbo
    1.0\. I won’t go into detail about how exactly this amazing feat is being achieved
    since the [GitHub repository](https://github.com/vitoplantamura/OnnxStream) already
    explains it very well.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, let’s just jump right into getting it working.
  prefs: []
  type: TYPE_NORMAL
- en: '**Technical Requirements**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All you need is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Raspberry Pi 5 — Or Raspberry Pi 4 or any other Raspberry Pi, just expect it
    to be slower
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SD Card — Minimally 16GB, with Raspbian or some Linux distro already setup.
    The SDXL Turbo weights are around 8GB.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An internet connection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/e96b30f0366c093aa74449de91faba28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Images generated in a single diffusion step on the Raspberry Pi | Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: '**Setting Up OnnxStream**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The instructions here are from the GitHub repository, but I’m breaking it down
    and explaining it a bit more.
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Building XNNPack**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we have to install [XNNPack](https://github.com/google/XNNPACK), which
    is a library from Google that provides “high-efficiency floating-point neural
    network inference operators”. But we can’t just get the latest version in case
    of any breaking changes. Instead, we shall get the version that the OnnxStream
    creator has verified to be working at the time of writing. In a terminal, run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: XNNPack will take a couple of minutes to build. Go get coffee or something.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Building OnnxStream**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we have to build OnnxStream. In a terminal, run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Make sure to replace <DIRECTORY_WHERE_XNNPACK_WAS_CLONED> with the path at which
    XNNPack was cloned to (not the build folder). In my case, it was at /home/admin/XNNPACK/.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Downloading Model Weights**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we need to download the model weights for SDXL Turbo. In a terminal, run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If you have not installed git-lfs yet, do so first. This will take even longer
    than the step before since the model weights are quite big. Go get lunch!
  prefs: []
  type: TYPE_NORMAL
- en: You can also run the other two models supported — Stable Diffusion 1.5 and Stable
    Diffusion XL 1.0 Base by downloading their weights from the links provided in
    [OnnxStream’s GitHub repository](https://github.com/vitoplantamura/OnnxStream#how-to-build-the-stable-diffusion-example-on-linuxmacwindowstermux).
    Make sure your SD card has enough space if you are downloading all these models!
  prefs: []
  type: TYPE_NORMAL
- en: Once done, that’s it! We are ready to generate images on a Raspberry Pi!
  prefs: []
  type: TYPE_NORMAL
- en: '**Generating Images**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To generate images, run the code block below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Replace the prompt with what you want to generate. I’m just using the go-to
    classic astronaut prompt here. I set steps to just 1 as SDXL Turbo doesn’t need
    many steps to generate a good-looking image.
  prefs: []
  type: TYPE_NORMAL
- en: There are other arguments you can pass too, such as — neg-prompt for negative
    prompts (SDXL Turbo does not support negative prompts but you can use it for the
    other two models), — steps to set the number of generative steps and — seed to
    set the random seed.
  prefs: []
  type: TYPE_NORMAL
- en: The arguments required will change according to the type of model used, so please
    take a look at [OnnxStream’s GitHub repository](https://github.com/vitoplantamura/OnnxStream#how-to-build-the-stable-diffusion-example-on-linuxmacwindowstermux)
    for the full list of arguments to pass if you’re using something other than SDXL
    Turbo.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c6bae00f3eaaaede4564ee9063047aad.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You should get an output like this | Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the image above, on the Raspberry Pi 5, each diffusion step
    takes around 1 minute, and in total with pre-processing and decoding, it around
    3 minutes to generate a single image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a016aa96a094a749b8c3aac1a8ac117d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image with 1, 2, 5, and 10 steps respectively, using the same seed and prompt
    | Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a comparison and progression of the same prompt with the same seed from
    step 1 to 10\. You can see that even with a single step with refinement, the generated
    image is already really well-done. This is in contrast to SDXL or SD1.5 which
    requires quite a few steps to reach that quality.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With it taking around at least a couple of minutes to generate an image, the
    question of use cases for it comes begging.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b138fcad68e649f781cde62d61d153ab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Obligatory shot of my Raspberry Pi 5 | Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: The most obvious and fun use case to me is an ever-changing photo frame that
    will generate a new image every few minutes. There is actually a [project along
    this tangent](https://github.com/rvdveen/epaper-slow-generative-art) that uses
    OnnxStream, by rvdveen on GitHub, where he uses OnnxStream on a Raspberry Pi Zero
    2 W to generate images for news articles and shows it on a photo frame using an
    e-ink display. It takes around 5 hours to generate an image on the Pi Zero 2 W
    with what should be SD1.5, but hey it’s not like you need a photo frame to be
    changing what it’s showing in real-time.
  prefs: []
  type: TYPE_NORMAL
- en: Or maybe you just want your own locally hosted image generator which can produce
    decent quality images while not hogging any major compute devices on your network.
  prefs: []
  type: TYPE_NORMAL
- en: Have fun playing around with SDXL Turbo on the Raspberry Pi!
  prefs: []
  type: TYPE_NORMAL
- en: '**Disclaimer**: I have no affiliation with OnnxStream or StabilityAI. All views
    and opinions are my own and do not represent any organisation.'
  prefs: []
  type: TYPE_NORMAL
