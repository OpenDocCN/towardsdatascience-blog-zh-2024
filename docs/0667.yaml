- en: 'Quantum Machine Learning with Python: Kernel Methods and Neural Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/quantum-machine-learning-with-python-kernel-methods-and-neural-networks-d60738aa99e1?source=collection_archive---------3-----------------------#2024-03-12](https://towardsdatascience.com/quantum-machine-learning-with-python-kernel-methods-and-neural-networks-d60738aa99e1?source=collection_archive---------3-----------------------#2024-03-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)[![Xavier
    Vasques](../Images/5517ccd82bb4744fc0bff5be9ba399e4.png)](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)
    [Xavier Vasques](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)
    ·15 min read·Mar 12, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6926b4f6dbcce2f545ddac86fa1016d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by Annamária Borsos (used with permission)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Quantum Machine Learning (QML) represents a fascinating convergence of quantum
    computing and machine learning technologies. With quantum computing’s potential
    in mathematics and data processing with complex structure, QML could revolutionize
    areas like drug discovery, finance, and beyond. This blog delves into the innovative
    realms of quantum neural networks (QNNs) and quantum kernel techniques, showcasing
    their unique capabilities through practical Python examples. The blog will not
    detail the mathematical concepts. For more information do not hesitate to read
    my latest book *Machine Learning Theory and Applications: Hands-on Use Cases with
    Python on Classical and Quantum Machines,* Wiley, 2024.'
  prefs: []
  type: TYPE_NORMAL
- en: Quantum kernel methods, introduce a quantum-enhanced way of processing data.
    By mapping classical data into quantum feature space, these methods utilize the
    superposition and entanglement properties of quantum mechanics to perform classifications
    or regression tasks. The use of quantum kernel estimator and quantum variational
    classifier examples illustrates the practical application of these concepts. QNNs,
    leveraging quantum states for computation, offer a novel approach to neural network
    architecture. The Qiskit framework facilitates the implementation of both quantum
    kernel methods and QNNs, enabling the exploration of quantum algorithms’ efficiency
    in learning and pattern recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating Python code examples, this blog aims to provide comprehensive
    code examples of QML for readers to explore its promising applications, and the
    challenges it faces. Through these examples, readers can start practicing and
    gain an appreciation for the transformative potential of quantum computing in
    machine learning and the exciting possibilities that lie ahead.
  prefs: []
  type: TYPE_NORMAL
- en: First, install qiskit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the open-source SDK Qiskit ([https://qiskit.org](https://qiskit.org/))
    which allows working with quantum computers. Qiskit supports Python version 3.6
    or later.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our environment, we can install Qiskit with pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also install qiskit-machine-learning using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Documentation can be found on GitHub: [https://github.com/Qiskit/qiskit-machine-learning/](https://github.com/Qiskit/qiskit-machine-learning/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To run our code, we can use either simulators or real hardware even if I strongly
    recommend the use of hardware or push the limits of simulators to improve research
    in this field. While studying the Qiskit documentation, you will encounter references
    to the Qiskit Runtime primitives, which serve as implementations of the Sampler
    and Estimator interfaces found in the qiskit.primitives module. These interfaces
    facilitate the seamless interchangeability of primitive implementations with minimal
    code modifications. The initial release of Qiskit Runtime comprises two essential
    primitives:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sampler: This primitive generates quasi-probabilities based on input circuits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Estimator: This primitive calculates expectation values derived from input
    circuits and observables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For more comprehensive insights, detailed information is available in the following
    resource: [https://qiskit.org/ecosystem/ibm-runtime/tutorials/how-to-getting-started-with-sampler.html.](https://qiskit.org/ecosystem/ibm-runtime/tutorials/how-to-getting-started-with-sampler.html.)'
  prefs: []
  type: TYPE_NORMAL
- en: Quantum Kernel Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Venturing into quantum approaches for supervised machine learning poses a novel
    research direction. Classical machine learning extensively utilizes kernel methods,
    among which the support vector machine (SVM) for classification stands out for
    its widespread application.
  prefs: []
  type: TYPE_NORMAL
- en: SVMs, known for their role in binary classification, have increasingly been
    applied to multiclass problems. The essence of binary SVM involves devising a
    hyperplane to linearly separate n-dimensional data points into two groups, aiming
    for an optimal margin that distinctively classifies the data into its respective
    categories. This hyperplane, effective in either the original feature space or
    a transformed higher-dimensional kernel space, is selected for its capacity to
    maximize the separation between classes, which involves an optimization problem
    to maximize the margin, defined as the distance from the nearest data point to
    the hyperplane on either side. This leads to the formulation of a maximum-margin
    classifier. The critical data points on the boundary are termed support vectors,
    and the margin represents a zone typically devoid of data points. An optimal hyperplane
    too proximate to the data points, indicating a slender margin, undermines the
    model’s predictive robustness and generalization capability.
  prefs: []
  type: TYPE_NORMAL
- en: To navigate multiclass SVM challenges, methods like the all-pair strategy, which
    conducts a binary classification for each pair of classes, have been introduced.
    Beyond straightforward linear classification, nonlinear classifications can be
    achieved through the kernel trick. This technique employs a kernel function to
    elevate inputs into a more expansive, higher-dimensional feature space, facilitating
    the separation of data that is not linearly separable in the input space. The
    kernel function essentially performs an inner product in a potentially vast Euclidian
    space, known as the feature space. The goal of nonlinear SVM is to achieve this
    separation by mapping data to a higher dimension using a suitable mapping. Selecting
    an appropriate feature map becomes crucial for data that cannot be addressed by
    linear methods alone. This is where quantum can jump into it. Quantum kernel methods,
    blending classical kernel strategies with quantum innovations, carve out new avenues
    in machine learning. Early quantum kernel approaches have focused on encoding
    data points into inner products or amplitudes in Hilbert space through quantum
    feature maps. The complexity of the quantum circuit implementing the feature map
    scales linearly or polylogarithmically with the dataset size.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum Kernel with ZZFeatureMaps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this first example, we will use the ZZFeatureMap with linear entanglement,
    we will repeat the data encoding step two times, and we will use feature reduction
    with principal component analysis. You can of course use other feature reduction,
    data rescaling or feature selection techniques to improve the accuracy of your
    models. We will use the breast cancer dataset that you can find here: [https://github.com/xaviervasques/hephaistos/blob/main/data/datasets/breastcancer.csv](https://github.com/xaviervasques/hephaistos/blob/main/data/datasets/breastcancer.csv)'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s describe the steps of the Python script below. This Python script demonstrates
    an application of integrating quantum computing techniques with traditional machine
    learning to classify breast cancer data. It represents a hybrid approach, where
    quantum-enhanced features are used within a classical machine learning workflow.
    The goal is to predict breast cancer diagnosis (benign or malignant) based on
    a set of features extracted from the breast mass characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: The way of doing quantum kernel machine learning is very similar to what we
    do classically as data scientists. We import the necessary libraries (Pandas,
    NumPy, scikit-learn) and Qiskit for quantum computing and kernel estimation, we
    load the data, preprocess the data and separate the data into features (X) and
    target labels (y). A specific step is the quantum feature mapping. The script
    sets up a quantum feature map using the ZZFeatureMap from Qiskit, configured with
    specified parameters for feature dimension, repetitions, and entanglement type.
    Quantum feature maps are critical for translating classical data into quantum
    states, enabling the application of quantum computing principles for data analysis.
    Then, the quantum kernel setup consists in configuring a quantum kernel with a
    fidelity-based approach. It serves as a new method to compute the similarity between
    data points in the feature space defined by quantum states and potentially capturing
    complex patterns. The last step comes back to a classic machine learning pipeline
    with data rescaling with standard scaler, dimension reduction using principal
    component analysis and the use of support vector classifier (SVC) which utilizes
    the quantum kernel for classification. We evaluate the model using 5-fold cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We will obtain a mean score validation score of 0.63.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code is executed with the local simulator. To run on real hardware, replace
    the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: by
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Quantum Kernel Training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part will explore the method of Quantum Kernel Alignment (QKA) for the
    purpose of binary classification. QKA iteratively adjusts a quantum kernel that’s
    parameterized to fit a dataset, aiming for the largest possible margin in Support
    Vector Machines (SVM). For further details on QKA, reference is made to the preprint
    titled “Covariant quantum kernels for data with group structure.” The Python script
    below is a comprehensive example of integrating traditional machine learning techniques
    with quantum computing for the prediction accuracy in classifying breast cancer
    diagnosis. It employs a dataset of breast cancer characteristics to predict the
    diagnosis (benign or malignant).
  prefs: []
  type: TYPE_NORMAL
- en: The machine learning pipeline is similar to the one used in the quantum kernel
    with ZZFeatureMaps section. The difference is that we will constructs a custom
    quantum circuit, integrating a rotational layer with a ZZFeatureMap, to prepare
    the quantum state representations of the data. The quantum kernel estimation step
    utilizes Qiskit primitives and algorithms for optimizing the quantum kernel’s
    parameters using a quantum kernel trained (QKT) and an optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We will obtain the following output: 0.6526315789473685'
  prefs: []
  type: TYPE_NORMAL
- en: As you certainly observed, there is time differences in execution between QKT
    and using a quantum kernel with a predefined feature map like ZZFeatureMap even
    if we reduced the dataframe size by sampling 1/3 of the data and setting the maximum
    iteration for SPSA to 10\. QKT involves not only the use of a quantum kernel but
    also the optimization of parameters within the quantum feature map or the kernel
    itself to improve model performance. This optimization process requires iterative
    adjustments to the parameters, where each iteration involves running quantum computations
    to evaluate the performance of the current parameter set. This iterative nature
    significantly increases computational time. When using a predefined quantum kernel
    like the ZZFeatureMap, the feature mapping is fixed, and there’s no iterative
    optimization of quantum parameters involved. The quantum computations are performed
    to evaluate the kernel between data points, but without the added overhead of
    adjusting and optimizing quantum circuit parameters. This approach is more straightforward
    and requires fewer quantum computations, making it faster. Each step of the optimization
    process in QKT requires evaluating the model’s performance with the current quantum
    kernel, which depends on the quantum feature map parameters at that step. This
    means multiple evaluations of the kernel matrix, each of which requires a substantial
    number of quantum computations.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This Python script below incorporates quantum neural networks (QNNs) into a
    machine learning pipeline. In the script, we need to configure the quantum feature
    map and ansatz (a quantum circuit structure), construct a quantum circuit by appending
    the feature map and ansatz to a base quantum circuit (this setup is crucial for
    creating quantum neural networks that process input data quantum mechanically)
    and create a QNN using the quantum circuit designed for binary classification.
    Before coming back to the classic machine learning pipeline with data rescaling,
    data reduction and model evaluation, we employ a quantum classifier which integrates
    the QNN with a classical optimization algorithm (COBYLA) for training. A callback
    function is defined to visualize the optimization process, tracking the objective
    function value across iterations.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We obtain the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cross-validation scores: [0.34210526 0.4122807 0.42982456 0.21929825 0.50442478]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mean cross-validation score: 0.3815867101381773'
  prefs: []
  type: TYPE_NORMAL
- en: 'Standard deviation of cross-validation scores: 0.09618163326986424'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/194a9fd37a05cf66d9a3ee867de7e44a.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, in this specific dataset, QNN doesn’t provide a very good classification
    score.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This idea of this blog is to make it easy to start using quantum machine learning.
    Quantum Machine Learning is an emerging field at the intersection of quantum computing
    and machine learning that holds the potential to revolutionize how we process
    and analyze vast datasets by leveraging the inherent advantages of quantum mechanics.
    As we showed in our paper *Application of quantum machine learning using quantum
    kernel algorithms on multiclass neuron M-type classification* published in Nature
    Scientific Report, a crucial aspect of optimizing QML models, including Quantum
    Neural Networks (QNNs), involves pre-processing techniques such as feature rescaling,
    feature extraction, and feature selection.
  prefs: []
  type: TYPE_NORMAL
- en: These techniques are not only essential in classical machine learning but also
    present significant benefits when applied within the quantum computing framework,
    enhancing the performance and efficiency of quantum machine learning algorithms.
    In the quantum realm, feature extraction techniques like Principal Component Analysis
    (PCA) can be quantum-enhanced to reduce the dimensionality of the data while retaining
    most of its significant information. This reduction is vital for QML models due
    to the limited number of qubits available on current quantum hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum feature extraction can efficiently map high-dimensional data into a
    lower-dimensional quantum space, enabling quantum models to process complex datasets
    with fewer resources. Selecting the most relevant features is also a way for optimizing
    quantum circuit complexity and resource allocation. In quantum machine learning,
    feature selection helps in identifying and utilizing the most informative features,
    reducing the need for extensive quantum resources.
  prefs: []
  type: TYPE_NORMAL
- en: This process not only simplifies the quantum models but also enhances their
    performance by focusing the computational efforts on the features that contribute
    the most to the predictive accuracy of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Sources**'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Machine Learning Theory and Applications: Hands-on Use Cases with Python
    on Classical and Quantum Machines,* Wiley, 2024](https://www.amazon.fr/Machine-Learning-Theory-Applications-Hands-ebook/dp/B0CS8MMSB4/ref=sr_1_2?__mk_fr_FR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1SIBDYLGUX7XR&dib=eyJ2IjoiMSJ9.IV7g17el89GNQznK4WE3TFa0RaOwsRf3n53jTAydpJXjqj4juibAmhXCmZv4JjLLjmbjY0nFBPuzH_p0TYDq_8QTq6SXsh_o3U9b6VT2U_FD5takpiI6ctH05JelH-XQ2mItrIX02LcvRu2jHDE6RDe20qR9DNLG5lY5gi93vbYlPY2ahKtCH5imnzLE4jgLSuU81s5qAaRPPD13MwhwPofgaJ9FqbYbtxrHFAKjPfE.VdY_00svNarbBN4C07OopzZlgOZEVb3AIKSlz_hDA2Y&dib_tag=se&keywords=xavier+vasques&qid=1710253907&sprefix=xavier+vasques%2Caps%2C104&sr=8-2)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Vasques, X., Paik, H. & Cif, L. Application of quantum machine learning using
    quantum kernel algorithms on multiclass neuron M-type classification. Sci Rep
    13, 11541 (2023).* [*https://doi.org/10.1038/s41598-023-38558-z*](https://doi.org/10.1038/s41598-023-38558-z)'
  prefs: []
  type: TYPE_NORMAL
- en: This dataset used is licensed under a Creative Commons Attribution 4.0 International
    (CC BY 4.0) license.
  prefs: []
  type: TYPE_NORMAL
