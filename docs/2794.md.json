["```py\nGOOGLE_API_KEY=your_api_key_here\n```", "```py\nexport GOOGLE_API_KEY=your_api_key_here\n```", "```py\npip install langchain-google-genai~=2.0.4 langchain~=0.3.6\n```", "```py\nimport os\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nGOOGLE_MODEL_NAME = os.environ.get(\"GOOGLE_MODEL_NAME\", \"gemini-1.5-flash-002\")\n\nllm_google_client = ChatGoogleGenerativeAI(\n    model=GOOGLE_MODEL_NAME,\n    temperature=0,\n    max_retries=10,\n)\n```", "```py\nfrom typing import List, Literal\nfrom pydantic import BaseModel, field_validator\n\ndef generate_multi_label_classification_model(list_classes: list[str]):\n    assert list_classes  # Ensure classes are provided\n\n    class ClassificationOutput(BaseModel):\n        category: List[Literal[tuple(list_classes)]]\n\n        @field_validator(\"category\", mode=\"before\")\n        def filter_invalid_categories(cls, value):\n            if isinstance(value, list):\n                return [v for v in value if v in list_classes]\n            return []  # Return an empty list if input is invalid\n\n    return ClassificationOutput\n```", "```py\nlist_classes = [\n    \"shelter\", \"mesa\", \"dune\", \"cave\", \"metropolis\",\n    \"reef\", \"finger\", \"moss\", \"pollen\", \"daisy\",\n    \"fire\", \"daisies\", \"tree trunk\",  # Add more classes as needed\n]\n\ncategories_model = generate_multi_label_classification_model(list_classes)\nllm_classifier = llm_google_client.with_structured_output(categories_model)\n```", "```py\n...\n    def predict(self, text: str = None, image_url: str = None) -> list:\n        assert text or image_url, \"Provide either text or an image URL.\"\n\n        content = []\n\n        if text:\n            content.append({\"type\": \"text\", \"text\": text})\n\n        if image_url:\n            image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n            content.append(\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n                }\n            )\n\n        prediction = self.llm_classifier.invoke(\n            [SystemMessage(content=self.system_prompt), HumanMessage(content=content)]\n        )\n\n        return prediction.category\n```", "```py\n['transportation', 'vehicle', 'road', 'landscape', 'desert', 'rock', 'mountain']\n```", "```py\n['transportation', 'vehicle', 'road']\n```", "```py\n['animal', 'mammal', 'dog', 'pet', 'canine', 'wildlife']\n```", "```py\n['animal', 'mammal', 'canine', 'dog', 'pet']\n```"]