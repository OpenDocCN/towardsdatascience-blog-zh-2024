# 生成式AI的80/20问题 — 一项用户体验研究洞察

> 原文：[https://towardsdatascience.com/the-80-20-problem-of-generative-ai-a-ux-research-insight-445e8aa3bbd3?source=collection_archive---------1-----------------------#2024-12-21](https://towardsdatascience.com/the-80-20-problem-of-generative-ai-a-ux-research-insight-445e8aa3bbd3?source=collection_archive---------1-----------------------#2024-12-21)

![](../Images/eb4b5aab6bb53ea2b5f2d12e9d16fdea.png)

*图片由作者提供*

## 当大型语言模型（LLM）解决任务的正确率达到80%时，往往只代表用户价值的20%。

[](https://medium.com/@zombor?source=post_page---byline--445e8aa3bbd3--------------------------------)[![Zombor Varnagy-Toth](../Images/9e982d75a5aa08ce96e559aca6fe050c.png)](https://medium.com/@zombor?source=post_page---byline--445e8aa3bbd3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--445e8aa3bbd3--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--445e8aa3bbd3--------------------------------) [Zombor Varnagy-Toth](https://medium.com/@zombor?source=post_page---byline--445e8aa3bbd3--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--445e8aa3bbd3--------------------------------) ·阅读时间：3分钟·2024年12月21日

--

帕累托原则认为，如果你解决问题的程度达到20%，你就能获得80%的价值。对于生成式AI来说，似乎情况正好相反。

> 关于作者：Zsombor Varnagy-Toth 是 SAP 的高级用户体验研究员，拥有机器学习和认知科学背景。专注于使用定性和定量数据进行产品开发。

我第一次意识到这一点是当我研究专业人士使用大型语言模型（LLMs）撰写营销文案时。我观察到，当这些专业人士开始使用LLMs时，他们的热情迅速消退，大多数人最终还是回到了手动编写内容的老路。

这是一个令人完全惊讶的研究发现，因为这些专业人士承认，AI生成的内容并不差。事实上，他们觉得它出乎意料的好，差不多有80%的质量。但是，如果是这样，为什么他们还会选择手动创建内容呢？为什么不直接拿80%好的AI生成内容，再手动加上最后的20%？

这里是直观的解释：

*如果你有一首平庸的诗歌，你不能通过换几个词把它变成一首伟大的诗歌。*

*假设你有一座房子，建得80%好。它基本上还可以，但墙壁不直，基础也很弱。你无法通过一些额外的工作来修复它。你必须将其拆除，从头开始建造。*

我们进一步调查了这一现象，并找到了其根源。对于这些营销专业人士来说，如果一篇文案只有80%的效果，那么在文本中没有哪个单独的部分可以替换，从而使其达到100%的效果。为此，整篇文案需要逐段逐句地重新编写。因此，从AI的80%到100%几乎需要花费与从0%到100%手动完成相同的精力。

现在，这带来了一个有趣的启示。对于此类任务，**LLM的价值是“全有或全无”**的。它要么做得非常出色，要么就没用。没有中间状态。

我们查看了几种不同类型的用户任务，并发现这种逆帕累托原则影响着特定类型的任务。

+   **不容易分解**，并且

+   **任务规模大**，以及

+   **期望100%的质量**

如果这些条件中的任何一个没有得到满足，逆帕累托效应就不适用了。

写代码，例如，比写散文更具可组合性。代码有其独立的部分：命令和函数，可以单独挑出并独立修复。如果AI将代码完成到80%，实际上只需要额外花费约20%的努力，就能达到100%的结果。

就任务规模而言，LLM在写短文案（例如社交媒体帖子）方面非常有用。LLM生成的短内容仍然是“全有或全无”——要么很好，要么毫无价值。然而，由于这些文案的简短性，用户可以一次生成十个，并在几秒钟内找出最好的一个。换句话说，用户无需处理80%到100%的问题——他们只需选择最初生成的100%的变体。

至于质量，有些使用场景并不要求专业级的质量。例如，一个内容工厂可能满足于80%质量的文章。

# 这对产品开发意味着什么？

如果你正在构建一个处理**大任务**且**难以分解**的LLM驱动产品，而用户又要求输出**100%质量**，你必须围绕LLM构建某些东西，将其80%的表现提升到100%。这可以是后端的复杂提示方法、额外的微调层，或者是多种工具和代理共同协作的认知架构，用以完善输出。不论这个包装层做什么，它就是带来80%客户价值的所在。宝藏就埋在那里，LLM只贡献了20%。

这一结论与红杉资本的[Sonya Huang和Pat Grady的论述](https://www.sequoiacap.com/article/generative-ais-act-o1/)一致，即AI领域的下一个价值浪潮将由这些“最后一公里应用提供商”创造——这些包装公司弄清楚如何跨越最后一公里，从而创造80%的价值。
