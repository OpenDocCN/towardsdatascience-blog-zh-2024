- en: Memory-Efficient Embeddings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/memory-efficient-embeddings-d637cba7f006?source=collection_archive---------2-----------------------#2024-01-01](https://towardsdatascience.com/memory-efficient-embeddings-d637cba7f006?source=collection_archive---------2-----------------------#2024-01-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Creating smaller models with a new kind of embedding layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://dr-robert-kuebler.medium.com/?source=post_page---byline--d637cba7f006--------------------------------)[![Dr.
    Robert Kübler](../Images/3b8d8b88f76c0c43d9c305e3885e7ab9.png)](https://dr-robert-kuebler.medium.com/?source=post_page---byline--d637cba7f006--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d637cba7f006--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d637cba7f006--------------------------------)
    [Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=post_page---byline--d637cba7f006--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d637cba7f006--------------------------------)
    ·13 min read·Jan 1, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be9ce0d107f6dfeafcb4558c8006314d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kostiantyn Vierkieiev](https://unsplash.com/@kostiantynvierkieiev?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever dealing with categorical data, beginners resort to **one-hot encoding**.
    This is often okay, but if you are dealing with thousands or even millions of
    categories, this approach becomes **infeasible**. This has the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increased dimensionality:** For each category, you get an additional feature.
    This can lead to the *curse of dimensionality*. The data becomes more sparse,
    and the model may suffer from increased computational complexity and decreased
    generalization performance.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Loss of semantics:** One-hot encoding treats each category as an independent
    feature, ignoring any potential semantic relationships between categories. We
    lose meaningful relationships present in the original categorical variable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These problems occur in the area of natural language processing (we have a bunch
    of words) or recommendation systems (we have a bunch of customers and/or articles)
    and can be overcome with the help of **embeddings**. However, if you have many
    of these embeddings, the memory requirements for your model can skyrocket to several
    gigabytes.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I want to show you several ways to decrease this memory footprint.
    One of these ways comes from an interesting paper [Compositional Embeddings](https://arxiv.org/abs/1909.02107)…
  prefs: []
  type: TYPE_NORMAL
