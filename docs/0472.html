<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Interpreting R²: a Narrative Guide for the Perplexed</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Interpreting R²: a Narrative Guide for the Perplexed</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/interpreting-r%C2%B2-a-narrative-guide-for-the-perplexed-086a9a69c1ec?source=collection_archive---------3-----------------------#2024-02-19">https://towardsdatascience.com/interpreting-r%C2%B2-a-narrative-guide-for-the-perplexed-086a9a69c1ec?source=collection_archive---------3-----------------------#2024-02-19</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="45d9" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">An accessible walkthrough of fundamental properties of this popular, yet often misunderstood metric from a predictive modeling perspective</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@rbrrcc?source=post_page---byline--086a9a69c1ec--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Roberta Rocca" class="l ep by dd de cx" src="../Images/dca9384fdc5d7c8aa9c01ee2aeccb787.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*jBwqSxqZ8mIXe8lPSzCUCg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--086a9a69c1ec--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@rbrrcc?source=post_page---byline--086a9a69c1ec--------------------------------" rel="noopener follow">Roberta Rocca</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--086a9a69c1ec--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">15 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 19, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">8</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/bf7c9d2b9af55c745a8b08153db33da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NQrkY-R8WydzIULb"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@joshrako?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Josh Rakower</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c46a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">R² (R-squared), also known as the <em class="nz">coefficient of determination</em>, is widely used as a metric to evaluate the performance of regression models. It is commonly used to quantify <em class="nz">goodness of fit</em> in statistical modeling, and it is a default scoring metric for regression models both in popular statistical modeling and machine learning frameworks, from <em class="nz">statsmodels</em> to <em class="nz">scikit-learn</em>.</p><p id="8b8e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Despite its omnipresence, there is a surprising amount of confusion on what R² truly means, and it is not uncommon to encounter conflicting information (for example, concerning the upper or lower bounds of this metric, and its interpretation). At the root of this confusion is a “culture clash” between the explanatory and predictive modeling tradition. In fact, in predictive modeling — where evaluation is conducted out-of-sample and any modeling approach that increases performance is desirable — many properties of R² that do apply in the narrow context of explanation-oriented linear modeling no longer hold.</p><p id="3bcb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To help navigate this confusing landscape, this post provides an accessible narrative primer to some basic properties of R² from a predictive modeling perspective, highlighting and dispelling common confusions and misconceptions about this metric. With this, I hope to help the reader to converge on a unified intuition of what R² truly captures as a measure of fit in predictive modeling and machine learning, and to highlight some of this metric’s strengths and limitations. Aiming for a broad audience which includes Stats 101 students and predictive modellers alike, I will keep the language simple and ground my arguments into concrete visualizations.</p><p id="a67a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Ready? Let’s get started!</p><h2 id="a61a" class="oa ob fq bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk">What is R²?</h2><p id="196b" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Let’s start from a working verbal definition of R². To keep things simple, let’s take the first high-level definition given by <a class="af nc" href="https://en.wikipedia.org/wiki/Coefficient_of_determination" rel="noopener ugc nofollow" target="_blank">Wikipedia</a>, which is a good reflection of definitions found in many pedagogical resources on statistics, including authoritative textbooks:</p><blockquote class="pa pb pc"><p id="33a6" class="nd ne nz nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">the proportion of the variation in the dependent variable that is predictable from the independent variable(s)</p></blockquote><p id="d139" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Anecdotally, this is also what the vast majority of students trained in using statistics for inferential purposes would probably say, if you asked them to define R². But, as we will see in a moment, this common way of defining R² is the source of many of the misconceptions and confusions related to R². Let’s dive deeper into it.</p><p id="d6a7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Calling R² a <em class="nz">proportion</em> implies that R² will be a number between 0 and 1, where 1 corresponds to a model that explains <em class="nz">all the variation</em> in the outcome variable, and 0 corresponds to a model that explains <em class="nz">no variation </em>in the outcome variable. Note: your model might also include no predictors (e.g., an intercept-only model is still a model), that’s why I am focusing on variation predicted by a model rather than by independent variables.</p><p id="0848" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s verify if this intuition on the range of possible values is correct. To do so, let’s recall the mathematical definition of R²:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pd"><img src="../Images/9af1218a8d2199939b3793b5be762441.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*Wvpznxoo0Ld2yH2rf2vSRA.png"/></div></figure><p id="458b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here, RSS is the residual sum of squares, which is defined as:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pe"><img src="../Images/7667e41ecf0e08350840411951cc42c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*WTd_JS__cf2xp8JTx_Qw3g.png"/></div></figure><p id="83b7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This is simply the <strong class="nf fr">sum of squared errors of the model</strong>, that is the sum of squared differences between true values <em class="nz">y </em>and corresponding model predictions <em class="nz">ŷ</em>.</p><p id="b106" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">On the other hand, TSS, the total sum of squares, is defined as follows:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pf"><img src="../Images/416903b5803d98b4196af1ef52f2e22d.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*rqGR2e-kbKM7tdhludYOsA.png"/></div></figure><p id="d04a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As you might notice, this term has a similar “form” than the residual sum of squares, but this time, we are looking at the squared differences between the true values of the outcome variables <em class="nz">y</em> and <em class="nz">the mean of the outcome variable </em>ȳ. This is technically the <em class="nz">variance </em>of the outcome variable. But a more intuitive way to look at this in a predictive modeling context is the following: this term is the residual sum of squares of a model that always predicts the mean of the outcome variable. Hence, <strong class="nf fr">the ratio of RSS and TSS is a ratio between the sum of squared errors of your model, and the sum of squared errors of a “reference” model predicting the mean of the outcome variable</strong>.</p><p id="81a3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">With this in mind, let’s go on to analyse what the range of possible values for this metric is, and to verify our intuition that these should, indeed, range between 0 and 1.</p><h2 id="39a9" class="oa ob fq bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk">What is the best possible R²?</h2><p id="c346" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">As we have seen so far, R² is computed by subtracting the ratio of RSS and TSS from 1. Can this ever be higher than 1? Or, in other words, is it true that 1 is the largest possible value of R²? Let’s think this through by looking back at the formula.</p><p id="84e8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The only scenario in which<em class="nz"> </em>1 minus <em class="nz">something</em> can be higher than 1 is if that <em class="nz">something</em> is a <em class="nz">negative </em>number. But here, RSS and TSS are both sums of squared values, that is, sums of positive values. The ratio of RSS and TSS will thus <em class="nz">always </em>be positive. The largest possible R² must therefore be 1.</p><p id="1f69" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now that we have established that R² cannot be higher than 1, let’s try to visualize what needs to happen for our model to have the maximum possible R². For R² to be 1, RSS / TSS must be zero. This can happen if RSS = 0, that is, if the model predicts all data points <em class="nz">perfectly.</em></p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pg"><img src="../Images/38ec206d4b5fc43ebe9200e04346a8a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X_0SOwNNacfh2mimAAcZaw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Examples illustrating hypothetical models with R² ≈ 1 using simulated data. In all cases, the true underlying model is y = 2x + 3. The first two models fit the data perfectly, in the first case because the data has no noise and a linear model can retrieve perfectly the relation between x and y (left) and in the second because the model is very <em class="ph">flexible and overfits the data (center). These are extreme cases which are hardly found in reality. In fact, the largest possible </em>R² will often be defined by the amount of noise if the data<em class="ph">. This is illustrated by the third plot, where due to the presence of random noise, even the true model can only achieve </em>R² = 0.458.</figcaption></figure><p id="a4ab" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In practice, this will never happen, unless you are <em class="nz">wildly</em> overfitting your data with an overly complex model, or you are computing R² on a ridiculously low number of data points that your model can fit perfectly. All datasets will have <em class="nz">some </em>amount of noise that <em class="nz">cannot</em> be accounted for by the data. In practice, the largest possible R² will be defined by the amount of unexplainable noise in your outcome variable.</p><h2 id="ef9d" class="oa ob fq bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk">What is the worst possible R²?</h2><p id="910e" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">So far so good. If the largest possible value of R² is 1, we can still think of R² as the proportion of variation in the outcome variable explained by the model. But let’s now move on to looking at the lowest possible value. If we buy into the definition of R² we presented above, then we must assume that the lowest possible R² is 0.</p><p id="c1eb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When is R² = 0? For R² to be null, RSS/TSS must be equal to 1. This is the case if RSS = TSS, that is, if the sum of squared errors of our model is equal to the sum of squared errors of a model predicting the mean. If you are better off just predicting the mean, then your model is really not doing a terribly good job. There are infinitely many reasons why this can happen, one of these being an issue with your choice of model — if, for example, if you are trying to model really non-linear data with a linear model. Or it can be a consequence of your data. If your outcome variable is very noisy, then a model predicting the mean might be the best you can do.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pi"><img src="../Images/2e8e0bdb87e615aa2723926b1987aba4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Jztq0giztpLHTYhw6MgGQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Two cases where the mean model might be the best <em class="ph">possible</em> (linear) models because: a) data is pure Gaussian noise (left); b) the data is highly non-linear, as it is <em class="ph">generated using a periodic function (right).</em></figcaption></figure><p id="2000" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">But is R² = 0 truly the lowest possible R²? Or, in other words, can R² ever be negative? Let’s look back at the formula. R² &lt; 0 is only possible if RSS/TSS &gt; 1, that is, if RSS &gt; TSS. Can this ever be the case?</p><p id="9fe0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This is where things start getting interesting, as the answer to this question depends very much on contextual information that we have not<em class="nz"> </em>yet specified, namely which type of models we are considering, and which data<em class="nz"> </em>we are computing R² on. As we will see, whether our interpretation of R² as the proportion of variance explained holds depends on our answer to these questions.</p><h2 id="4a65" class="oa ob fq bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk">The bottomless pit of negative R²</h2><p id="6481" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Let’s looks at a concrete case. Let’s generate some data using the following model <em class="nz">y = 3 + 2x</em>, and added Gaussian noise.</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="8745" class="pn ob fq pk b bg po pp l pq pr">import numpy as np<br/><br/>x = np.arange(0, 1000, 10)<br/>y = [3 + 2*i for i in x] <br/>noise = np.random.normal(loc=0, scale=600, size=x.shape[0])<br/>true_y = noise + y</span></pre><p id="43ee" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The figure below displays three models that make predictions for <em class="nz">y </em>based on values of <em class="nz">x </em>for different, randomly sampled subsets of this data. These models are not made-up models, as we will see in a moment, but let’s ignore this right now. Let’s focus simply on the sign of their R².</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ps"><img src="../Images/2482ed6e603f62a8d97c8d4bec1c8f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B__BZdYb2totQZes8RMMHA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Three examples of models for data generated using the function: y = 3 + 2x, with added Gaussian noise.</figcaption></figure><p id="0b20" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s start from the first model, a simple model that predicts a constant, which in this case is lower than the mean of the outcome variable. Here, our RSS will be the sum of squared distances between each of the dots and the orange line, while TSS will be the sum of squared distances between each of the dots and the blue line (the mean<em class="nz"> </em>model). It is easy to see that for most of the data points, the distance between the dots and the orange line will be higher than the distance between the dots and the blue line. Hence, our RSS will be higher than our TSS. If this is the case, we will have RSS/TSS &gt; 1, and, therefore: 1 — RSS/TSS &lt; 0, that is, R²&lt;0.</p><p id="6037" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In fact, if we compute R² for this model on this data, we obtain R² = -2.263. If you want to check that it is in fact realistic, you can run the code below (due to randomness, you will likely get a similarly negative value, but not exactly the same value):</p><pre class="mm mn mo mp mq pj pk pl bp pm bb bk"><span id="23e4" class="pn ob fq pk b bg po pp l pq pr">from sklearn.metrics import r2_score<br/><br/># get a subset of the data<br/>x_tr, x_ts, y_tr, y_ts = train_test_split(x, true_y, train_size=.5)<br/># compute the mean of one of the subsets <br/>model = np.mean(y_tr)<br/># evaluate on the subset of data that is plotted<br/>print(r2_score(y_ts, [model]*y_ts.shape[0]))</span></pre><p id="5e5c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s now move on to the second model. Here, too, it is easy to see that distances between the data points and the red line (our target model) will be larger than distances between data points and the blue line (the mean model). In fact, here: R²= -3.341. Note that our target model is different from the <em class="nz">true</em> model (the orange line) because we have fitted it on a subset of the data that also includes noise. We will return to this in the next paragraph.</p><p id="7e2f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Finally, let’s look at the last model. Here, we fit a 5-degree polynomial model to a subset of the data generated above. The distance between data points and the fitted function, here, is <em class="nz">dramatically </em>higher than the distance between the data points and the mean model. In fact, our fitted model yields R² = -1540919.225.</p><p id="c573" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Clearly, as this example shows, models <em class="nz">can</em> have a negative R². In fact, there is no limit to how low R² can be. Make the model bad enough, and your R² can approach minus infinity. This can also happen with a simple linear model: further increase the value of the slope of the linear model in the second example, and your R² will keep going down. So, where does this leave us with respect to our initial question, namely whether R² is in fact that proportion of variance in the outcome variable that can be accounted for by the model?</p><p id="ae2e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Well, we don’t tend to think of proportions as arbitrarily large negative values. If are really attached to the original definition, we could, with a creative leap of imagination, extend this definition to covering scenarios where arbitrarily bad models can <em class="nz">add</em> variance<em class="nz"> </em>to your outcome variable. The inverse proportion of variance <em class="nz">added </em>by your model (e.g., as a consequence of poor model choices, or overfitting to different data) is what is reflected in arbitrarily low negative values.</p><p id="6820" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">But this is more of a metaphor than a definition. Literary thinking aside, the most literal and most productive way of thinking about R² is as a comparative<em class="nz"> </em>metric, which says something about how much better (on a scale from 0 to 1) or worse<em class="nz"> </em>(on a scale from 0 to infinity) your model is at predicting the data <em class="nz">compared to a model which always predicts the mean of the outcome variable</em>.</p><p id="9cd6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Importantly, what this suggests, is that while R² can be a tempting way to evaluate your model in a scale-independent fashion, and while it might makes sense to use it as a comparative metric, it is a far from transparent metric. The value of R² will not provide explicit information of how wrong your model is in absolute terms; the best possible value will always be dependent on the amount of noise present in the data; and good or bad R² can come about from a wide variety of reasons that can be hard to disambiguate without the aid of additional metrics.</p><h2 id="afa6" class="oa ob fq bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk">Alright, R² can be negative. But does this ever happen, in practice?</h2><p id="4116" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">A very legitimate objection, here, is whether any of the scenarios displayed above is actually plausible. I mean, which modeller in their right mind would actually fit such <em class="nz">poor </em>models to such simple data? These might just look like <em class="nz">ad hoc </em>models, made up for the purpose of this example and not actually fit to any data.</p><p id="8580" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This is an excellent point, and one that brings us to another crucial point related to R² and its interpretation. As we highlighted above, all these models <em class="nz">have</em>, in fact, been fit to data which are generated from the same true underlying function as the data in the figures. This corresponds to the practice, foundational to predictive modeling, of splitting data intro a <em class="nz">training set</em> and a <em class="nz">test set</em>, where the former is used to estimate the model, and the latter for evaluation on unseen data — which is a “fairer” proxy for how well the model generally performs in its prediction task.</p><p id="1516" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In fact, if we display the models introduced in the previous section against the data used to estimate them, we see that they are not <em class="nz">unreasonable</em> models in relation to their training data. In fact, R² values for the training set are, at least, non-negative (and, in the case of the linear model, very close to the R² of the true model on the test data).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pt"><img src="../Images/129d5a1dd5d05a54ad94720c75a90e82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v9ktcTrSsDOtb9ixJSUmIA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Same functions displayed in the previous figure, this time displayed against the data they were fit on, which were generated with the same true function y = 3 + 2x. For the first model, which predicts a constant, model “fitting” simply consists of calculating the mean of the training set.</figcaption></figure><p id="b6d2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Why, then, is there such a big difference between the previous data and this data? What we are observing are cases of <em class="nz">overfitting</em>. The model is mistaking sample-specific noise in the training data for signal and modeling that — which is not at all an uncommon scenario. As a result, models’ predictions on new data samples will be poor.</p><p id="2c0d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Avoiding overfitting is perhaps the biggest challenge in predictive modeling. Thus, it is not at all uncommon to observe negative R² values when (as one should always do to ensure that the model is generalizable and robust ) R² is computed <em class="nz">out-of-sample</em>, that is, on data that differ “randomly” from those on which the model was estimated.</p><p id="9e35" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Thus, the answer to the question posed in the title of this section is, in fact, a resounding <em class="nz">yes</em>: negative R² do happen in common modeling scenarios, even when models have been properly estimated. In fact, they happen all the time.</p><h2 id="844b" class="oa ob fq bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk">So, is everyone just wrong?</h2><p id="ca52" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">If R² is <em class="nz">not </em>a proportion, and its interpretation as variance explained clashes with some basic facts about its behavior, do we have to conclude that our initial definition is wrong? Are Wikipedia and all those textbooks presenting a similar definition wrong? Was my Stats 101 teacher wrong? Well. Yes, and no. It depends hugely<em class="nz"> </em>on the context in which R² is presented, and on the modeling tradition we are embracing.</p><p id="dbc7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If we simply analyse the definition of R² and try to describe its general behavior, <em class="nz">regardless</em> of which type of model we are using to make predictions, and assuming we will want to compute this metrics out-of-sample, then yes, they are all wrong. Interpreting R² as the proportion of variance explained is misleading, and it conflicts with basic facts on the behavior of this metric.</p><p id="3e86" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Yet, the answer changes slightly if we constrain ourselves to a narrower set of scenarios, namely <em class="nz">linear models</em>, and especially linear models <em class="nz">estimated with least squares methods</em>. Here, R² <em class="nz">will</em> behave as a proportion. In fact, it can be shown that, due to properties of least squares estimation, a linear model can <em class="nz">never </em>do worse than a model predicting the mean of the outcome variable. Which means, that a linear model can never have a negative R² — or at least, it cannot have a negative R² on the same data on which it was estimated (a debatable practice if you are interested in a generalizable model). For a <em class="nz">linear regression</em> scenario with in-sample evaluation, the definition discussed can therefore be considered correct. Additional fun fact: this is also the only scenario where R² is equivalent to the squared correlation between model predictions and the true outcomes.</p><p id="5132" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The reason why many misconceptions about R² arise is that this metric is often first introduced in the context of linear regression and with a focus on <em class="nz">inference </em>rather than prediction. But in predictive modeling, where <em class="nz">in-sample</em> evaluation is a no-go and linear models are just one of many possible models, interpreting R² as the proportion of variation explained by the model is at best unproductive, and at worst deeply misleading.</p><h2 id="b94f" class="oa ob fq bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk">Should I still use R²?</h2><p id="49e1" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">We have touched upon quite a few points, so let’s sum them up. We have observed that:</p><ul class=""><li id="9450" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pu pv pw bk">R² cannot be interpreted as a proportion, as its values can range from -∞ to 1</li><li id="3703" class="nd ne fq nf b go px nh ni gr py nk nl nm pz no np nq qa ns nt nu qb nw nx ny pu pv pw bk">Its interpretation as “variance explained” is also misleading (you can imagine models that <em class="nz">add </em>variance to your data, or that combined explained existing variance and variance “hallucinated” by a model)</li><li id="ea61" class="nd ne fq nf b go px nh ni gr py nk nl nm pz no np nq qa ns nt nu qb nw nx ny pu pv pw bk">In general, R² is a “relative” metric, which compares the errors of your model with those of a simple model always predicting the mean</li><li id="79f4" class="nd ne fq nf b go px nh ni gr py nk nl nm pz no np nq qa ns nt nu qb nw nx ny pu pv pw bk">It is, however, accurate to describe R² as the proportion of variance explained <em class="nz">in the context of linear modeling with least squares estimation </em>and <em class="nz">when the R² of a least-squares linear model is computed in-sample</em>.</li></ul><p id="6403" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Given all these caveats, should we still use R²? Or should we give up?</p><p id="9650" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here, we enter the territory of more subjective observations. In general, if you are doing predictive modeling and you want to get a concrete sense for <em class="nz">how wrong </em>your predictions are in absolute terms, R² is <em class="nz">not</em> a useful metric. Metrics like MAE or RMSE will definitely do a better job in providing information on the magnitude of errors your model makes. This is useful in absolute terms but also in a model comparison context, where you might want to know by how much, concretely, the precision of your predictions differs across models. If knowing something about precision matters (it hardly ever does not), you might at least want to complement R² with metrics that says something meaningful about how wrong each of your individual predictions is likely to be.</p><p id="1c64" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">More generally, as we have highlighted, there are a number of caveats to keep in mind if you decide to use R². Some of these concern the “practical” upper bounds for R² (your noise ceiling), and its literal interpretation as a <em class="nz">relative</em>, rather than absolute measure of fit compared to the mean model. Furthermore, good or bad R² values, as we have observed, can be driven by many factors, from overfitting to the amount of noise in your data.</p><p id="24fe" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">On the other hand, while there are very few predictive modeling contexts where I have found R² particularly informative in isolation, having a measure of fit relative to a “dummy” model (the mean<em class="nz"> </em>model) can be a productive way to think critically about your model. Unrealistically high R² on your training set, or a negative R² on your test set might, respectively, help you entertain the possibility that you might be going for an overly complex model or for an inappropriate modeling approach (e.g., a linear model for non-linear data), or that your outcome variable might contain, mostly, noise. This is, again, more of a “pragmatic” personal take here, but while I would resist fully discarding R² (there aren’t many good global and scale-independent measures of fit), in a predictive modeling context I would consider it most useful as a complement to scale-dependent metrics such as RMSE/MAE, or as a “diagnostic” tool, rather than a target itself.</p><h2 id="41b0" class="oa ob fq bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk">Concluding remarks</h2><p id="d622" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">R² is everywhere. Yet, especially in fields that are biased towards explanatory, rather than predictive modelling traditions, many misconceptions about its interpretation as a model evaluation tool flourish and persist.</p><p id="db64" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In this post, I have tried to provide a narrative primer to some basic properties of R² in order to dispel common misconceptions, and help the reader get a grasp of what R² generally measures beyond the narrow context of in-sample evaluation of linear models.</p><p id="d47b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Far from being a complete and definitive guide, I hope this can be a pragmatic and agile resource to clarify some very justified confusion. Cheers!</p><p id="fe27" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="nz">Unless otherwise states in the caption, images in this article are by the author</em></p></div></div></div></div>    
</body>
</html>