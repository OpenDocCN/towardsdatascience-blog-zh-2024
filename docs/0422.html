<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Evaluating Synthetic Data — The Million Dollar Question</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Evaluating Synthetic Data — The Million Dollar Question</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluating-synthetic-data-the-million-dollar-question-a54701d1b621?source=collection_archive---------0-----------------------#2024-02-14">https://towardsdatascience.com/evaluating-synthetic-data-the-million-dollar-question-a54701d1b621?source=collection_archive---------0-----------------------#2024-02-14</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="4b02" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><strong class="al">Are my real and synthetic datasets random samples from the same parent distribution?</strong></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@a.skabar_60534?source=post_page---byline--a54701d1b621--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Andrew Skabar, PhD" class="l ep by dd de cx" src="../Images/75e090a35d3e5823d2148ddde6d36501.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*WsZop9gbqScaOCUPyPNQ8Q.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--a54701d1b621--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@a.skabar_60534?source=post_page---byline--a54701d1b621--------------------------------" rel="noopener follow">Andrew Skabar, PhD</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--a54701d1b621--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 14, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/ec002249f3e365145e39f17fcd6d6da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1iIghEOkkagHXq4u"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@edge2edgemedia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Edge2Edge Media</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="17b5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When we perform synthetic data generation, we typically create a model for our real (or ‘observed’) data, and then use this model to generate synthetic data. This observed data is usually compiled from real world experiences, such as measurements of the physical characteristics of irises or details about individuals who have defaulted on credit or acquired some medical condition. We can think of the observed data as having come from some ‘parent distribution’ — the true underlying distribution from which the observed data is a random sample. Of course, we never know this parent distribution — it must be estimated, and this is the purpose of our model.</p><p id="dd28" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">But if our model can produce synthetic data that can be considered to be a random sample from the same parent distribution, then we’ve hit the jackpot: the synthetic data will possess the same statistical properties and patterns as the observed data (<em class="nz">fidelity</em>); it will be just as useful when put to tasks such as regression or classification (<em class="nz">utility</em>); and, because it is a random sample, there is no risk of it identifying the observed data (<em class="nz">privacy</em>). But how can we know if we have met this elusive goal?</p><p id="2b5f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In the first part of this story, we will conduct some simple experiments to gain a better understanding of the problem and motivate a solution. In the second part we will evaluate performance of a variety of synthetic data generators on a collection of well-known datasets.</p><h1 id="9d4d" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Part 1 — Some Simple Experiments</h1><p id="ab8f" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Consider the following two datasets and try to answer this question:</p><blockquote class="pb pc pd"><p id="c58f" class="nd ne nz nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Are the datasets random samples from the same parent distribution, or has one been derived from the other by applying small random perturbations?</p></blockquote><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pe"><img src="../Images/b221d50e80cd00415f1e7e7b3e061a41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZlbBVCVC0fP6LAmVQmU_4A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Two datasets. Are both datasets random samples from the same parent distribution, or has one been derived from the other by small random perturbations? [Image by Author]</figcaption></figure><p id="e008" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The datasets clearly display similar statistical properties, such as marginal distributions and covariances. They would also perform similarly on a classification task in which a classifier trained on one dataset is tested on the other. So, fidelity and utility alone are inconclusive.</p><p id="f08d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">But suppose we were to plot the data points from each dataset on the same graph. If the datasets are random samples from the same parent distribution, we would intuitively expect the points from one dataset to be interspersed with those from the other in such a manner that, on average, points from one set are as close to — or ‘as similar to’ — their closest neighbors in that set as they are to their closest neighbors in the other set. However, if one dataset is a slight random perturbation of the other, then points from one set will be more similar to their closest neighbors in the other set than they are to their closest neighbors in the same set. This leads to the following test.</p><p id="fe61" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">The Maximum Similarity Test</strong></p><blockquote class="pb pc pd"><p id="b1d9" class="nd ne nz nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For each dataset, calculate the similarity between each instance and its closest neighbor in the <strong class="nf fr">same</strong> dataset. Call these the ‘maximum intra-set similarities’. If the datasets have the same distributional characteristics, then the distribution of intra-set similarities should be similar for each dataset. Now calculate the similarity between each instance of one dataset and its closest neighbor in the <strong class="nf fr">other </strong>dataset and call these the<em class="fq"> ‘</em>maximum cross-set similarities’<em class="fq">.</em> If the distribution of maximum cross-set similarities is the same as the distribution of maximum intra-set similarities, then the datasets can be considered random samples from the same parent distribution. For the test to be valid, each dataset should contain the same number of examples.</p></blockquote><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pf"><img src="../Images/65dea4a02e1150564e532854b23ddc76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p3BAUH_J5GAOSePVYSHcnw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Two datasets: one red, one black. Black arrows indicate the closest (or ‘most similar’) black neighbor (head) to each black point (tail) — the similarities between these pairs are the ‘maximum intra-set similarities’ for black. Red arrows indicate the closest black neighbor (head) to each red point (tail) — similarities between these pairs are the ‘maximum cross-set similarities’. [Image by Author]</figcaption></figure><p id="f9b7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Since the datasets we deal with in this story all contain a mixture of numerical and categorical variables, we need a similarity measure which can accommodate this. We use Gower Similarity¹.</p><p id="7f11" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The table and histograms below show the means and distributions of the maximum intra- and cross-set similarities for Datasets 1 and 2.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pg"><img src="../Images/45a1e7f4d7f4e370686f3d4487a6783f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2qieZHSXv6jGcEUdDkZoZw.png"/></div></div></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/bfe8aff280d359a980af91cc5ff8ad06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZMJlsaEEzecCR535-WpJ_A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of maximum intra- and cross-set similarities for Datasets 1 and 2. [Image by Author]</figcaption></figure><p id="245b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">On average, the instances in one data set are more similar to their closest neighbors in the other dataset than they are to their closest neighbors in the same dataset. This indicates that the datasets are more likely to be perturbations of each other than random samples from the same parent distribution. <strong class="nf fr">And indeed, they are perturbations! </strong>Dataset 1 was generated from a Gaussian mixture model; Dataset 2 was generated by selecting (without replacement) an instance from Dataset 1 and applying a small random perturbation.</p><p id="7b04" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Ultimately, we will be using the Maximum Similarity Test to compare synthetic datasets with observed datasets. The biggest danger with synthetic data points being too close to observed points is privacy; i.e., being able to identify points in the observed set from points in the synthetic set. In fact, if you examine Datasets 1 and 2 carefully, you might actually be able to identify some such pairs. And this is for a case in which the average maximum cross-set similarity is only 0.3% larger than the average maximum intra-set similarity!</p><h2 id="e2bf" class="pi ob fq bf oc pj pk pl of pm pn po oi nm pp pq pr nq ps pt pu nu pv pw px py bk">Modeling and Synthesizing</h2><p id="83a7" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">To end this first part of the story, let’s create a model for a dataset and use the model to generate synthetic data. We can then use the Maximum Similarity Test to compare the synthetic and observed sets.</p><p id="0ef5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The dataset on the left in the figure below is just Dataset 1 from above. The dataset on the right (Dataset 3) is the synthetic dataset. (We have estimated the distribution as a Gaussian mixture, but that’s not important).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pe"><img src="../Images/e0d1395f3b49804e009ebb8a8c087b9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZmyJekhIMdg59EjavWS51A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Observed dataset (left) and Synthetic dataset (right). [Image by Author]</figcaption></figure><p id="c860" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here are the average similarities and histograms:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pg"><img src="../Images/c4ede021357af3a6cc3d7034d54917fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQqWCq0mSC4ztLtkdNGgJw.png"/></div></div></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ph"><img src="../Images/72606529778dc8f73c303643f77290c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rorom6lAOwKfcF-ILD_W_g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of maximum intra- and cross-set similarities for Datasets 1 and 3. [Image by Author]</figcaption></figure><p id="e12f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The three averages are identical to three significant figures, and the three histograms are very similar. Therefore, according to the Maximum Similarity Test, both datasets can reasonably be considered random samples from the same parent distribution. Our synthetic data generation exercise has been a success, and we have achieved the hat-trick — fidelity, utility, and privacy.</p><p id="aed5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[<em class="nz">Python code used to produce the datasets, plots and histograms from Part 1 is available from </em><a class="af nc" href="https://github.com/a-skabar/TDS-EvalSynthData" rel="noopener ugc nofollow" target="_blank"><em class="nz">https://github.com/a-skabar/TDS-EvalSynthData</em></a>]</p></div></div></div><div class="ab cb pz qa qb qc" role="separator"><span class="qd by bm qe qf qg"/><span class="qd by bm qe qf qg"/><span class="qd by bm qe qf"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="2afb" class="oa ob fq bf oc od qh gq of og qi gt oi oj qj ol om on qk op oq or ql ot ou ov bk">Part 2— Real Datasets<strong class="al">, Real Generators</strong></h1><p id="cc37" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">The dataset used in Part 1 is simple and can be easily modeled with just a mixture of Gaussians. However, most real-world datasets are far more complex. In this part of the story, we will apply several synthetic data generators to some popular real-world datasets. Our primary focus is on comparing the distributions of maximum similarities within and between the observed and synthetic datasets to understand the extent to which they can be considered random samples from the same parent distribution.</p><p id="e74a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The six datasets originate from the UCI repository² and are all popular datasets that have been widely used in the machine learning literature for decades. All are mixed-type datasets, and were chosen because they vary in their balance of categorical and numerical features.</p><p id="a8ff" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The six generators are representative of the major approaches used in synthetic data generation: copula-based, GAN-based, VAE-based, and approaches using sequential imputation. CopulaGAN³, GaussianCopula, CTGAN³ and TVAE³ are all available from the <em class="nz">Synthetic Data Vault</em> libraries⁴, synthpop⁵ is available as an open-source R package, and ‘UNCRi’ refers to the synthetic data generation tool developed under the proprietary <em class="nz">Unified Numeric/Categorical Representation and Inference </em>(UNCRi) framework⁶. All generators were used with their default settings.</p><p id="b044" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The table below shows the average maximum intra- and cross-set similarities for each generator applied to each dataset. Entries highlighted in red are those in which privacy has been compromised (i.e., the average maximum cross-set similarity exceeds the average maximum intra-set similarity on the observed data). Entries highlighted in green are those with the highest average maximum cross-set similarity (not including those in red). The last column shows the result of performing a <em class="nz">Train on Synthetic, Test on Real</em> (TSTR) test, where a classifier or regressor is trained on the synthetic examples and tested on the real (observed) examples. The Boston Housing dataset is a regression task, and the mean absolute error (MAE) is reported; all other tasks are classification tasks, and the reported value is the area under ROC curve (AUC).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qm"><img src="../Images/236c38f14f83cc3f10fbbe41754f8463.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uETjVOQNsU9Sb7GcJ7F_Ow.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Average maximum similarities and TSTR result for six generators on six datasets. The values for TSTR are MAE for Boston Housing, and AUC for all other datasets. [Image by Author]</figcaption></figure><p id="7f95" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The figures below display, for each dataset, the distributions of maximum intra- and cross-set similarities corresponding to the generator that attained the highest average maximum cross-set similarity (excluding those highlighted in red above).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qn"><img src="../Images/ee698dc20e60b805783144dc48314f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gUUs-S5pvHjW69ZZo-8KQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of maximum similarities for synthpop on <strong class="bf oc">Boston Housing</strong> dataset. [Image by Author]</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qn"><img src="../Images/01f8522e452605230b41ba4af4de2c20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XhRzn-bE0pzCX9vkqIBeaQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of maximum similarities for synthpop <strong class="bf oc">Census Income</strong> dataset. [Image by Author]</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qo"><img src="../Images/1e57e31f05336dca4c0cf537987dcc12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L_JbCg8H_392jQCXoElVgg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of maximum similarities for UNCRi on <strong class="bf oc">Cleveland Heart Disease</strong> dataset. [Image by Author]</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qn"><img src="../Images/a7b4f349510973ae15e8b6f37672286b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtaQVASCyANto_9FIGE-6g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of maximum similarities for UNCRi on <strong class="bf oc">Credit Approval</strong> dataset. [Image by Author]</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qn"><img src="../Images/e00d7f8bb0824240b99951a0f24943d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CACxrICKkozyyBrLiX2r5g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of maximum similarities for UNCRi on<strong class="bf oc"> Iris </strong>dataset. [Image by Author]</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qn"><img src="../Images/2e02ff72c2f41939e874ff72d53594a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tM8E5lB5dHQObDtYugOVDA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of average similarities for TVAE on <strong class="bf oc">Wisconsin Breast Cancer </strong>dataset. [Image by Author]</figcaption></figure><p id="5c7e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">From the table, we can see that for those generators that did not breach privacy, the average maximum cross-set similarity is very close to the average maximum intra-set similarity on observed data. The histograms show us the distributions of these maximum similarities, and we can see that in most cases the distributions are clearly similar — strikingly so for datasets such as the Census Income dataset. The table also shows that the generator that achieved the highest average maximum cross-set similarity for each dataset (excluding those highlighted in red) also demonstrated best performance on the TSTR test (again excluding those in red). Thus, while we can never claim to have discovered the ‘true’ underlying distribution, these results demonstrate that the most effective generator for each dataset has captured the crucial features of the underlying distribution.</p><p id="768a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Privacy</strong></p><p id="839f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Only two of the seven generators displayed issues with privacy: synthpop and TVAE. Each of these breached privacy on three out of the six datasets. In two instances, specifically TVAE on Cleveland Heart Disease and TVAE on Credit Approval, the breach was particularly severe. The histograms for TVAE on Credit Approval are shown below and demonstrate that the synthetic examples are far too similar to each other, and also to their closest neighbors in the observed data. The model is a particularly poor representation of the underlying parent distribution. The reason for this may be that the Credit Approval dataset contains several numerical features that are extremely highly skewed.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qp"><img src="../Images/3d9bbbcc9b5073587e51d25b9764f85a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vEuT99AEYucZ0lNVCdfrSg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Distribution of average maximum similarities for TVAE on Credit Approval dataset. [Image by Author]</figcaption></figure><p id="f1cb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Other observations and comments</strong></p><p id="2416" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The two GAN-based generators — CopulaGAN and CTGAN — were consistently among the worst performing generators. This was somewhat surprising given the immense popularity of GANs.</p><p id="0a0a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The performance of GaussianCopula was mediocre on all datasets except Wisconsin Breast Cancer, for which it attained the equal-highest average maximum cross-set similarity. Its unimpressive performance on the Iris dataset was particularly surprising, given that this is a very simple dataset that can easily be modeled using a mixture of Gaussians, and which we expected would be well-matched to Copula-based methods.</p><p id="0bcc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The generators which perform most consistently well across all datasets are synthpop and UNCRi, which both operate by sequential imputation. This means that they only ever need to estimate and sample from a univariate conditional distribution (e.g., <em class="nz">P</em>(<em class="nz">x</em>₇|<em class="nz">x</em>₁, <em class="nz">x</em>₂, …)), and this is typically much easier than modeling and sampling from a multivariate distribution (e.g., <em class="nz">P</em>(<em class="nz">x</em>₁, <em class="nz">x</em>₂, <em class="nz">x</em>₃, …)), which is (implicitly) what GANs and VAEs do. Whereas synthpop estimates distributions using decision trees (which are the source of the overfitting that synthpop is prone to), the UNCRi generator estimates distributions using a nearest neighbor-based approach, with hyper-parameters optimized using a cross-validation procedure that prevents overfitting.</p><h1 id="5949" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Conclusion</h1><p id="464b" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Synthetic data generation is a new and evolving field, and while there are still no standard evaluation techniques, there is consensus that tests should cover fidelity, utility and privacy. But while each of these is important, they are not on an equal footing. For example, a synthetic dataset may achieve good performance on fidelity and utility but fail on privacy. This does not give it a ‘two out of three’: if the synthetic examples are too close to the observed examples (thus failing the privacy test), the model has been overfitted, rendering the fidelity and utility tests meaningless. There has been a tendency among some vendors of synthetic data generation software to propose single-score measures of performance that combine results from a multitude of tests. This is essentially based on the same ‘two out of three’ logic.</p><p id="a6fb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If a synthetic dataset can be considered a random sample from the same parent distribution as the observed data, then we cannot do any better — we have achieved maximum fidelity, utility and privacy. The Maximum Similarity Test provides a measure of the extent to which two datasets can be considered random samples from the same parent distribution. It is based on the simple and intuitive notion that if an observed and a synthetic dataset are random samples from the same parent distribution, instances should be distributed such that a synthetic instance is as similar on average to its closest observed instance as an observed instance is similar on average to its closest observed instance.</p><p id="4cf3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We propose the following single-score measure of synthetic dataset quality:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qq"><img src="../Images/7fb86797e2c4f852309e970bfd3b55af.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*xQTkni0RoxNOzRSs4OtVag.gif"/></div></figure><p id="bc3d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The closer this ratio is to 1 — without exceeding 1 — the better the quality of the synthetic data. It should, of course, be accompanied by a sanity check of the histograms.</p></div></div></div><div class="ab cb pz qa qb qc" role="separator"><span class="qd by bm qe qf qg"/><span class="qd by bm qe qf qg"/><span class="qd by bm qe qf"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="2b30" class="oa ob fq bf oc od qh gq of og qi gt oi oj qj ol om on qk op oq or ql ot ou ov bk">References</h1><p id="78f8" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">[1] Gower, J. C. (1971). A general coefficient of similarity and some of its properties. Biometrics, 27(4), 857–871.</p><p id="04aa" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[2] Dua, D. &amp; Graff, C., (2017). <em class="nz">UCI Machine Learning Repository</em>, Available at: <a class="af nc" href="http://archive.ics.uci.edu/ml." rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml.</a></p><p id="9064" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[3] Xu, L., Skoularidou, M., Cuesta-Infante, A. and Veeramachaneni., K. Modeling Tabular data using Conditional GAN. NeurIPS, 2019.</p><p id="ae9f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[4] Patki, N., Wedge, R., &amp; Veeramachaneni, K. (2016). The synthetic data vault. In <em class="nz">2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)</em> (pp. 399–410). IEEE.</p><p id="4253" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[5] Nowok, B., Raab G.M., Dibben, C. (2016). “synthpop: Bespoke Creation of Synthetic Data in R.” <em class="nz">Journal of Statistical Software</em>, <strong class="nf fr">74</strong>(11), 1–26. <a class="af nc" href="https://doi.org/10.18637/jss.v074.i11" rel="noopener ugc nofollow" target="_blank">doi:10.18637/jss.v074.i11</a>.</p><p id="93ec" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[6] <a class="af nc" href="https://skanalytix.com/uncri-framework/" rel="noopener ugc nofollow" target="_blank">http://skanalytix.com/uncri-framework</a></p><p id="1547" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[7] Harrison, D., &amp; Rubinfeld, D.L. (1978). Boston Housing Dataset. Kaggle. <a class="af nc" href="https://www.kaggle.com/c/boston-housing" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/boston-housing</a>. Licensed for commercial use under the CC: Public Domain license.</p><p id="c572" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[8] Kohavi, R. (1996). Census Income. UCI Machine Learning Repository. <a class="af nc" href="https://doi.org/10.24432/C5GP7S." rel="noopener ugc nofollow" target="_blank">https://doi.org/10.24432/C5GP7S.</a> Licensed for commercial use under a <a class="af nc" href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="noopener ugc nofollow" target="_blank">Creative Commons Attribution 4.0 International</a> (CC BY 4.0) license.</p><p id="e807" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[9] Janosi, A., Steinbrunn, W., Pfisterer, M. and Detrano, R. (1988). Heart Disease. UCI Machine Learning Repository. <a class="af nc" href="https://doi.org/10.24432/C52P4X." rel="noopener ugc nofollow" target="_blank">https://doi.org/10.24432/C52P4X.</a> Licensed for commercial use under a <a class="af nc" href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="noopener ugc nofollow" target="_blank">Creative Commons Attribution 4.0 International</a> (CC BY 4.0) license.</p><p id="f87e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[10] Quinlan, J.R. (1987). Credit Approval. UCI Machine Learning Repository. <a class="af nc" href="https://doi.org/10.24432/C5FS30." rel="noopener ugc nofollow" target="_blank">https://doi.org/10.24432/C5FS30.</a> Licensed for commercial use under a <a class="af nc" href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="noopener ugc nofollow" target="_blank">Creative Commons Attribution 4.0 International</a> (CC BY 4.0) license.</p><p id="5413" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[11] Fisher, R.A. (1988). Iris. UCI Machine Learning Repository. <a class="af nc" href="https://doi.org/10.24432/C56C76." rel="noopener ugc nofollow" target="_blank">https://doi.org/10.24432/C56C76.</a> Licensed for commercial use under a <a class="af nc" href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="noopener ugc nofollow" target="_blank">Creative Commons Attribution 4.0 International</a> (CC BY 4.0) license.</p><p id="a82d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">[12] Wolberg, W., Mangasarian, O., Street, N. and Street,W. (1995). Breast Cancer Wisconsin (Diagnostic). UCI Machine Learning Repository. <a class="af nc" href="https://doi.org/10.24432/C5DW2B." rel="noopener ugc nofollow" target="_blank">https://doi.org/10.24432/C5DW2B.</a> Licensed for commercial use under a <a class="af nc" href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="noopener ugc nofollow" target="_blank">Creative Commons Attribution 4.0 International</a> (CC BY 4.0) license.</p></div></div></div></div>    
</body>
</html>