- en: Achieve Better Classification Results with ClassificationThresholdTuner
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用**ClassificationThresholdTuner**实现更好的分类结果
- en: 原文：[https://towardsdatascience.com/achieve-better-classification-results-with-classificationthresholdtuner-39c5d454637e?source=collection_archive---------0-----------------------#2024-09-07](https://towardsdatascience.com/achieve-better-classification-results-with-classificationthresholdtuner-39c5d454637e?source=collection_archive---------0-----------------------#2024-09-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/achieve-better-classification-results-with-classificationthresholdtuner-39c5d454637e?source=collection_archive---------0-----------------------#2024-09-07](https://towardsdatascience.com/achieve-better-classification-results-with-classificationthresholdtuner-39c5d454637e?source=collection_archive---------0-----------------------#2024-09-07)
- en: A python tool to tune and visualize the threshold choices for binary and multi-class
    classification problems
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一款用于调整和可视化二分类和多分类问题阈值选择的 Python 工具
- en: '[](https://medium.com/@wkennedy934?source=post_page---byline--39c5d454637e--------------------------------)[![W
    Brett Kennedy](../Images/b3ce55ffd028167326c117d47c64c467.png)](https://medium.com/@wkennedy934?source=post_page---byline--39c5d454637e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--39c5d454637e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--39c5d454637e--------------------------------)
    [W Brett Kennedy](https://medium.com/@wkennedy934?source=post_page---byline--39c5d454637e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@wkennedy934?source=post_page---byline--39c5d454637e--------------------------------)[![W
    Brett Kennedy](../Images/b3ce55ffd028167326c117d47c64c467.png)](https://medium.com/@wkennedy934?source=post_page---byline--39c5d454637e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--39c5d454637e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--39c5d454637e--------------------------------)
    [W Brett Kennedy](https://medium.com/@wkennedy934?source=post_page---byline--39c5d454637e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--39c5d454637e--------------------------------)
    ·30 min read·Sep 7, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--39c5d454637e--------------------------------)
    ·阅读时长30分钟·2024年9月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Adjusting the thresholds used in classification problems (that is, adjusting
    the cut-offs in the probabilities used to decide between predicting one class
    or another) is a step that’s sometimes forgotten, but is quite easy to do and
    can significantly improve the quality of a model. It’s a step that should be performed
    with most classification problems (with some exceptions depending on what we wish
    to optimize for, described below).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类问题中调整阈值（即调整用于决定预测属于某一类别还是另一类别的概率临界值）是一个有时会被忽略的步骤，但其实它非常简单，而且可以显著提高模型的质量。这是一个应该在大多数分类问题中执行的步骤（根据我们希望优化的内容，下面会描述一些例外情况）。
- en: In this article, we look closer at what’s actually happening when we do this
    — with multi-class classification particularly, this can be a bit nuanced. And
    we look at an open source tool, written by myself, called [ClassificationThesholdTuner](https://github.com/Brett-Kennedy/ClassificationThresholdTuner),
    that automates and describes the process to users.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将更深入地了解在进行此操作时实际发生了什么——特别是对于多分类问题，这可能有些微妙。我们还将介绍一款由我自己编写的开源工具——[ClassificationThresholdTuner](https://github.com/Brett-Kennedy/ClassificationThresholdTuner)，它自动化并向用户描述了这一过程。
- en: Given how common the task of tuning the thresholds is with classification problems,
    and how similar the process usually is from one project to another, I’ve been
    able to use this tool on many projects. It eliminates a lot of (nearly duplicate)
    code I was adding for most classification problems and provides much more information
    about tuning the threshold that I would have otherwise.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在分类问题中调整阈值任务的普遍性，以及这个过程通常在不同项目之间的相似性，我已经能够在许多项目中使用这个工具。它消除了我为大多数分类问题添加的许多（几乎是重复的）代码，并提供了更多关于调整阈值的信息，这些是我以前无法得到的。
- en: Although ClassificationThesholdTuner is a useful tool, you may find the ideas
    behind the tool described in this article more relevant — they’re easy enough
    to replicate where useful for your classification projects.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管**ClassificationThresholdTuner**是一个有用的工具，但你可能会发现本文中描述的工具背后的思想更为相关——它们足够简单，可以在你的分类项目中按需复制。
- en: 'In a nutshell, [ClassificationThesholdTuner](https://github.com/Brett-Kennedy/ClassificationThresholdTuner)
    is a tool to optimally set the thresholds used for classification problems and
    to present clearly the effects of different thresholds. Compared to most other
    available options (and the code we would most likely develop ourselves for optimizing
    the threshold), it has two major advantages:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，[ClassificationThesholdTuner](https://github.com/Brett-Kennedy/ClassificationThresholdTuner)是一个用于优化分类问题中阈值设置的工具，并清晰展示不同阈值的效果。与大多数其他可用选项（以及我们最有可能自行开发的优化阈值的代码）相比，它有两个主要优势：
- en: It provides visualizations, which help data scientists understand the implications
    of using the optimal threshold that’s discovered, as well as alternative thresholds
    that may be selected. This can also be very valuable when presenting the modeling
    decisions to other stakeholders, for example where it’s necessary to find a good
    balance between false positives and false negatives. Frequently business understanding,
    as well as data modeling knowledge, is necessary for this, and having a clear
    and full understanding of the choices for threshold can facilitate discussing
    and deciding on the best balance.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它提供了可视化工具，帮助数据科学家理解使用已发现的最优阈值的含义，以及可能选择的替代阈值。当向其他利益相关者展示建模决策时，这也非常有价值，例如在需要找到假阳性和假阴性之间的良好平衡时。通常，这需要业务理解和数据建模知识，并且对阈值选择有清晰全面的理解，可以促进讨论并决定最佳平衡。
- en: It supports multi-class classification, which is a common type of problem in
    machine learning, but is more complicated with respect to tuning the thresholds
    than binary classification (for example, it requires identifying multiple thresholds).
    Optimizing the thresholds used for multi-class classification is, unfortunately,
    not well-supported by other tools of this type.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它支持多类分类，这是机器学习中的常见问题类型，但与二分类相比，调整阈值更为复杂（例如，它需要识别多个阈值）。不幸的是，优化多类分类所使用的阈值并没有得到其他同类工具的良好支持。
- en: Although supporting multi-class classification is one of the important properties
    of [ClassificationThesholdTuner](https://github.com/Brett-Kennedy/ClassificationThresholdTuner),
    binary classification is easier to understand, so we’ll begin by describing this.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然支持多类分类是[ClassificationThesholdTuner](https://github.com/Brett-Kennedy/ClassificationThresholdTuner)的一个重要特性，但由于二分类更易于理解，因此我们将从描述二分类开始。
- en: What are the thresholds used in classification?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类中使用的阈值是什么？
- en: Almost all modern classifiers (including those in scikit-learn, CatBoost, LGBM,
    XGBoost, and most others) support producing both predictions and probabilities.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有现代分类器（包括 scikit-learn、CatBoost、LGBM、XGBoost 以及大多数其他分类器）都支持同时生成预测和概率。
- en: For example, if we create a binary classifier to predict which clients will
    churn in the next year, then for each client we can generally produce either a
    binary prediction (a Yes or a No for each client), or can produce a probability
    for each client (e.g. one client may be estimated to have a probability of 0.862
    of leaving in that time frame).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们创建一个二分类器来预测哪些客户将在明年流失，那么对于每个客户，我们通常可以生成一个二分类预测（对于每个客户，预测为“是”或“否”），或者可以为每个客户生成一个概率（例如，一个客户可能被估计在该时间范围内流失的概率为
    0.862）。
- en: Given a classifier that can produce probabilities, even where we ask for binary
    predictions, behind the scenes it will generally actually produce a probability
    for each record. It will then convert the probabilities to class predictions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个能够生成概率的分类器，即使我们请求二分类预测，它通常在后台仍然会为每条记录生成一个概率。然后，它会将这些概率转换为类预测。
- en: By default, binary classifiers will predict the positive class where the predicted
    probability of the positive class is greater than or equal to 0.5, and the negative
    class where the probability is under 0.5\. In this example (predicting churn),
    it would, by default, predict Yes if the predicted probability of churn is ≥ 0.5
    and No otherwise.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，二分类器将在正类的预测概率大于或等于 0.5 时预测为正类，而在预测概率低于 0.5 时预测为负类。在这个例子中（预测流失），默认情况下，如果预测流失的概率≥0.5，它会预测为“是”，否则预测为“否”。
- en: However, this may not be the ideal behavior, and often a threshold other than
    0.5 can work preferably, possibly a threshold somewhat lower or somewhat higher,
    and sometimes a threshold substantially different from 0.5\. This can depend on
    the data, the classifier built, and the relative importance of false positives
    vs false negatives.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这可能不是理想的行为，通常一个非0.5的阈值可能会更好用，可能是稍微低一点或稍微高一点，有时甚至可能是与0.5差距较大的阈值。这取决于数据、构建的分类器以及假阳性与假阴性之间的相对重要性。
- en: In order to create a strong model (including balancing well the false positives
    and false negatives), we will often wish to optimize for some metric, such as
    F1 Score, F2 Score (or others in the family of f-beta metrics), Matthews Correlation
    Coefficient (MCC), Kappa Score, or another. If so, a major part of optimizing
    for these metrics is setting the threshold appropriately, which will most often
    set it to a value other than 0.5\. We’ll describe soon how this works.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一个强大的模型（包括平衡好假阳性和假阴性），我们通常希望优化某个指标，如F1分数、F2分数（或f-beta系列中的其他指标）、马修斯相关系数（MCC）、卡帕分数或其他指标。如果是这样，优化这些指标的一个关键部分是适当地设置阈值，这通常会将阈值设置为非0.5的值。我们很快会描述这个过程是如何工作的。
- en: This is a key point. It’s not generally immediately clear where to best set
    the threshold, but we can usually determine the best metric to optimize for. An
    example is using the F2 or F3 scores where we wish to place more emphasis on the
    recall of the positive class.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个关键点。通常并不容易立即清楚地知道最佳的阈值设置在哪里，但我们通常可以确定最适合优化的指标。一个例子是使用F2或F3分数，在这种情况下我们希望更强调正类的召回率。
- en: Support in Scikit-learn for threshold tuning
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scikit-learn对阈值调优的支持
- en: 'Scikit-learn provides good background on the idea of threshold tuning in its
    [Tuning the decision threshold for class prediction](https://scikit-learn.org/stable/modules/classification_threshold.html)
    page. Scikit-learn also provides two tools: [FixedThresholdClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.FixedThresholdClassifier.html)
    and [TunedThresholdClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TunedThresholdClassifierCV.html#sklearn.model_selection.TunedThresholdClassifierCV)
    (introduced in version 1.5 of scikit-learn) to assist with tuning the threshold.
    They work quite similarly to ClassificationThesholdTuner.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn在其[调整分类预测决策阈值](https://scikit-learn.org/stable/modules/classification_threshold.html)页面中提供了关于阈值调优的良好背景信息。Scikit-learn还提供了两个工具：[FixedThresholdClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.FixedThresholdClassifier.html)和[TunedThresholdClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TunedThresholdClassifierCV.html#sklearn.model_selection.TunedThresholdClassifierCV)（在scikit-learn
    1.5版本中引入），用于帮助调节阈值。它们的工作原理与ClassificationThresholdTuner非常相似。
- en: Scikit-learn’s tools can be considered convenience methods, as they’re not strictly
    necessary; as indicated, tuning is fairly straightforward in any case (at least
    for the binary classification case, which is what these tools support). But, having
    them is convenient — it is still quite a bit easier to call these than to code
    the process yourself.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn的工具可以视为便捷的方法，因为它们并不是严格必要的；正如所示，调优在任何情况下都相对简单（至少对于支持二分类的这些工具来说是这样的）。但有这些工具是很方便的——调用它们比自己编写代码要容易得多。
- en: ClassificationThresholdTuner was created as an alternative to these, but where
    scikit-learn’s tools work well, they are very good choices as well. Specifically,
    where you have a binary classification problem, and don’t require any explanations
    or descriptions of the threshold discovered, scikit-learn’s tools can work perfectly,
    and may even be slightly more convenient, as they allow us to skip the small step
    of installing ClassificationThresholdTuner.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ClassificationThresholdTuner作为这些工具的替代方案被创建，但当Scikit-learn的工具效果良好时，它们也是非常好的选择。特别是在你有一个二分类问题，并且不需要对找到的阈值进行任何解释或描述的情况下，Scikit-learn的工具可以完美地工作，甚至可能略微更方便，因为它们让我们跳过了安装ClassificationThresholdTuner这个小步骤。
- en: ClassificationThresholdTuner may be more valuable where explanations of the
    thresholds found (including some context related to alternative values for the
    threshold) are necessary, or where you have a multi-class classification problem.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要对找到的阈值（包括有关阈值替代值的一些背景信息）进行解释，或者你有多分类问题时，ClassificationThresholdTuner可能更有价值。
- en: As indicated, it also may at times be the case that the *ideas* described in
    this article are what is most valuable, not the specific tools, and you may be
    best to develop your own code — perhaps along similar lines, but possibly optimized
    in terms of execution time to more efficiently handle the data you have, possibly
    more able support other metrics to optimize for, or possibly providing other plots
    and descriptions of the threshold-tuning process, to provide the information relevant
    for your projects.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，有时可能是本文中描述的*思想*最为宝贵，而不是具体的工具，您可能最好开发自己的代码——也许是沿着类似的思路，但在执行时间方面进行优化，以更高效地处理您的数据，可能能够支持更多需要优化的其他指标，或者可能提供其他图表和阈值调优过程的描述，从而为您的项目提供相关信息。
- en: Thresholds in Binary Classification
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二分类中的阈值
- en: 'With most scikit-learn classifiers, as well as CatBoost, XGBoost, and LGBM,
    the probabilities for each record are returned by calling predict_proba(). The
    function outputs a probability for each class for each record. In a binary classification
    problem, they will output two probabilities for each record, for example:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数 scikit-learn 分类器，以及 CatBoost、XGBoost 和 LGBM，可以通过调用 `predict_proba()` 来返回每个记录的概率。该函数输出每个记录每个类别的概率。在二分类问题中，它们将为每个记录输出两个概率，例如：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For each pair of probabilities, we can take the first as the probability of
    the negative class and the second as the probability of the positive class.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一对概率，我们可以将第一个视为负类的概率，第二个视为正类的概率。
- en: 'However, with binary classification, one probability is simply 1.0 minus the
    other, so only the probabilities of one of the classes are strictly necessary.
    In fact, when working with class probabilities in binary classification problems,
    we often use only the probabilities of the positive class, so could work with
    an array such as: [0.4, 0.7, 0.9, …].'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在二分类问题中，一个类别的概率仅仅是另一个类别概率的 1.0 减去，因此严格来说，只需要一个类别的概率。事实上，在处理二分类问题中的类别概率时，我们通常只使用正类的概率，因此可以使用如下的数组：[0.4,
    0.7, 0.9, …]。
- en: 'Thresholds are easy to understand in the binary case, as they can be viewed
    simply as the minimum predicted probability needed for the positive class to actually
    predict the positive class (in the churn example, to predict customer churn).
    If we have a threshold of, say, 0.6, it’s then easy to convert the array of probabilities
    above to predictions, in this case, to: [No, Yes, Yes, ….].'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在二分类中，阈值容易理解，因为它们可以简单地视为需要的最小预测概率，以便正类被预测为正类（在流失的例子中，就是预测客户流失）。如果我们设定阈值为 0.6，那么就可以轻松地将上面的概率数组转换为预测结果，在这个例子中就是：[否，
    是， 是， …]。
- en: By using different thresholds, we allow the model to be more, or less, eager
    to predict the positive class. If a relatively low threshold, say, 0.3 is used,
    then the model will predict the positive class even when there’s only a moderate
    chance this is correct. Compared to using 0.5 as the threshold, more predictions
    of the positive class will be made, increasing both true positives and false positives,
    and also reducing both true negatives and false negatives.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用不同的阈值，我们可以使模型更积极或更保守地预测正类。如果使用一个相对较低的阈值，比如 0.3，那么即使只有中等概率正确，模型也会预测为正类。与使用
    0.5 作为阈值相比，更多的正类预测将会被做出，从而增加真正的正类和假正类，同时减少真正的负类和假负类。
- en: In the case of churn, this can be useful if we want to focus on catching most
    cases of churn, even though doing so, we also predict that many clients will churn
    when they will not. That is, a low threshold is good where false negatives (missing
    churn) is more of a problem than false positives (erroneously predicting churn).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在客户流失的情况下，如果我们希望重点关注捕捉大多数流失案例，即使这样做时，我们也预测许多客户会流失，但实际上他们并不会。也就是说，当漏报（漏掉流失）比误报（错误地预测流失）更为重要时，较低的阈值是有用的。
- en: 'Setting the threshold higher, say to 0.8, will have the opposite effect: fewer
    clients will be predicted to churn, but of those that are predicted to churn,
    a large portion will quite likely actually churn. We will increase the false negatives
    (miss some who will actually churn), but decrease the false positives. This can
    be appropriate where we can only follow up with a small number of potentially-churning
    clients, and want to label only those that are most likely to churn.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 将阈值设置得更高，例如0.8，将产生相反的效果：预测流失的客户会减少，但在那些被预测为流失的客户中，很多很可能真的会流失。我们会增加假阴性（漏掉一些实际上会流失的客户），但减少假阳性。这在只能跟进少量潜在流失客户并且希望只标记那些最可能流失的客户时是合适的。
- en: There’s almost always a strong business component to the decision of where to
    set the threshold. Tools such as ClassificationThresholdTuner can make these decisions
    more clear, as there’s otherwise not usually an obvious point for the threshold.
    Picking a threshold, for example, simply based on intuition (possibly determining
    0.7 feels about right) will not likely work optimally, and generally no better
    than simply using the default of 0.5.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在设定阈值时，几乎总是涉及到强烈的业务因素。像ClassificationThresholdTuner这样的工具可以使这些决策更加清晰，否则通常没有明显的阈值选择点。例如，单纯根据直觉选择阈值（可能认为0.7差不多合适）通常不会得到最优的结果，且一般不比直接使用默认值0.5更好。
- en: 'Setting the threshold can be a bit unintuitive: adjusting it a bit up or down
    can often help or hurt the model more than would be expected. Often, for example,
    increasing the threshold can greatly decrease false positives, with only a small
    effect on false negatives; in other cases the opposite may be true. Using a Receiver
    Operator Curve (ROC) is a good way to help visualize these trade-offs. We’ll see
    some examples below.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 设置阈值可能有点不直观：上下调整阈值一点，往往会比预期更大程度地影响模型。有时，例如，增加阈值可以大幅减少假阳性，而对假阴性只有小的影响；在其他情况下，情况可能正好相反。使用接收器操作特征曲线（ROC）是一种很好的方式，能够帮助可视化这些权衡。我们将在下面看到一些例子。
- en: Ultimately, we’ll set the threshold so as to optimize for some metric (such
    as F1 score). ClassificationThresholdTuner is simply a tool to automate and describe
    that process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们会设置一个阈值，以优化某些指标（例如F1得分）。ClassificationThresholdTuner只是一个自动化并描述该过程的工具。
- en: AUROC and F1 Scores
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AUROC和F1得分
- en: 'In general, we can view the metrics used for classification as being of three
    main types:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们可以将用于分类的度量指标分为三种主要类型：
- en: 'Those that examine how well-ranked the prediction probabilities are, for example:
    Area Under Receiver Operator Curve (AUROC), Area Under Precision Recall Curve
    (AUPRC)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那些评估预测概率排名情况的指标，例如：接收器操作特征曲线下的面积（AUROC）、精确度-召回率曲线下的面积（AUPRC）。
- en: 'Those that examine how well-calibrated the prediction probabilities are, for
    example: Brier Score, Log Loss'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那些评估预测概率校准程度的指标，例如：Brier得分、对数损失。
- en: 'Those that look at how correct the predicted labels are, for example: F1 Score,
    F2 Score, MCC, Kappa Score, Balanced Accuracy'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那些评估预测标签正确性的指标，例如：F1得分、F2得分、MCC、Kappa得分、平衡准确率。
- en: The first two categories of metric listed here work based on predicted probabilities,
    and the last works with predicted labels.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出的前两类度量指标基于预测的概率，而最后一类则基于预测的标签。
- en: While there are numerous metrics within each of these categories, for simplicity,
    we will consider for the moment just two of the more common, the Area Under Receiver
    Operator Curve (AUROC) and the F1 score.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管每类指标中有很多不同的度量方式，但为了简便起见，我们暂时只考虑其中两种较为常见的度量方式，即接收器操作特征曲线下的面积（AUROC）和F1得分。
- en: These two metrics have an interesting relationship (as does AUROC with other
    metrics based on predicted labels), which ClassificationThresholdTuner takes advantage
    of to tune and to explain the optimal thresholds.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这两类指标之间有一个有趣的关系（就像AUROC与基于预测标签的其他指标之间的关系一样），ClassificationThresholdTuner利用这一关系来调节和解释最佳阈值。
- en: The idea behind ClassificationThresholdTuner is to, once the model is well-tuned
    to have a strong AUROC, take advantage of this to optimize for other metrics —
    metrics that are based on predicted labels, such as the F1 score.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ClassificationThresholdTuner背后的理念是，在模型已调优到具有强AUROC之后，利用这一点来优化其他指标——这些指标基于预测标签，例如F1得分。
- en: Metrics Based on Predicted Labels
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于预测标签的度量指标
- en: Very often metrics that look at how correct the predicted labels are are the
    most relevant for classification. This is in cases where the model will be used
    to assign predicted labels to records and what’s relevant is the number of true
    positives, true negatives, false positives, and false negatives. That is, if it’s
    the predicted labels that are used downstream, then once the labels are assigned,
    it’s no longer relevant what the underlying predicted probabilities were, just
    these final label predictions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 很多时候，衡量预测标签正确性的指标是分类中最相关的。这种情况发生在模型用于为记录分配预测标签时，相关的是正确的正例、负例、假阳性和假阴性的数量。也就是说，如果下游使用的是预测标签，那么一旦标签被分配，基础预测概率的具体数值就不再重要，重要的只是最终的标签预测。
- en: For example, if the model assigns labels of Yes and No to clients indicating
    if they’re expected to churn in the next year and the clients with a prediction
    of Yes receive some treatment and those with a prediction of No do not, what’s
    most relevant is how correct these labels are, not in the end, how well-ranked
    or well-calibrated the prediction probabilities (that these class predications
    are based on) were. Though, how well-ranked the predicted probabilities are is
    relevant, as we’ll see, to assign predicted labels accurately.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果模型为客户分配“是”或“否”标签，以表示他们是否预计在下一年会流失，而那些预测为“是”的客户接受一些处理，而那些预测为“否”的客户不接受，那么最相关的是这些标签的正确性，而不是最终预测概率的排序或校准程度（这些类预测是基于这些概率的）。不过，预测概率的排序如何，正如我们所看到的，对于准确分配预测标签是相关的。
- en: 'This isn’t true for every project: often metrics such as AUROC or AUPRC that
    look at how well the predicted probabilities are ranked are the most relevant;
    and often metrics such as Brier Score and Log Loss that look at how accurate the
    predicted probabilities are most relevant.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不适用于每个项目：通常，像AUROC或AUPRC这样的指标，衡量预测概率排序如何，才是最相关的；而像Brier Score和Log Loss这样的指标，衡量预测概率的准确性，通常也最为重要。
- en: Tuning the thresholds will not affect these metrics and, where these metrics
    are the most relevant, there is no reason to tune the thresholds. But, for this
    article, we’ll consider cases where the F1 score, or another metric based on the
    predicted labels, is what we wish to optimize.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 调整阈值不会影响这些指标，而在这些指标最为相关的情况下，调整阈值没有必要。但对于本文来说，我们将考虑那些我们希望优化的基于预测标签的指标，例如F1得分或其他指标。
- en: ClassificationThresholdTuner starts with the predicted probabilities (the quality
    of which can be assessed with the AUROC) and then works to optimize the specified
    metric (where the specified metric is based on predicted labels).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ClassificationThresholdTuner从预测的概率开始（其质量可以通过AUROC来评估），然后致力于优化指定的指标（其中指定的指标基于预测标签）。
- en: Metrics based on the correctness of the predicted labels are all, in different
    ways, calculated from the confusion matrix. The confusion matrix, in turn, is
    based on the threshold selected, and can look quite quite different depending
    if a low or high threshold is used.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 基于预测标签正确性的指标，都是通过不同方式从混淆矩阵中计算得出的。混淆矩阵又基于选择的阈值，如果使用低阈值或高阈值，其结果可能会大不相同。
- en: Adjusting the Threshold
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整阈值
- en: The AUROC metric is, as the name implies, based on the ROC, a curve showing
    how the true positive rate relates to the false positive rate. An ROC curve doesn’t
    assume any specific threshold is used. But, each point on the curve corresponds
    to a specific threshold.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: AUROC指标顾名思义是基于ROC曲线的，ROC曲线展示了真正例率与假正例率的关系。ROC曲线并不假设使用任何特定的阈值，但曲线上的每一个点都对应一个特定的阈值。
- en: 'In the plot below, the blue curve is the ROC. The area under this curve (the
    AUROC) measures how strong the model is generally, averaged over all potential
    thresholds. It measures how well ranked the probabilities are: if the probabilities
    are well-ranked, records that are assigned higher predicted probabilities of being
    in the positive class are, in fact, more likely to be in the positive class.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，蓝色曲线是ROC曲线。该曲线下方的面积（AUROC）衡量了模型的一般强度，基于所有潜在阈值的平均值。它衡量了概率的排序效果：如果概率排序良好，则分配给正类的高预测概率的记录，实际上更有可能属于正类。
- en: For example, an AUROC of 0.95 means a random positive sample has a 95% chance
    of being ranked higher than random negative sample.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，AUROC为0.95意味着随机正样本有95%的概率被排在随机负样本之前。
- en: '![](../Images/4f6b09a80e830f53671f89b2bb7cf940.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f6b09a80e830f53671f89b2bb7cf940.png)'
- en: First, having a model with a strong AUROC is important — this is the job of
    the model tuning process (which may actually optimize for other metrics). This
    is done before we begin tuning the threshold, and coming out of this, it’s important
    to have well-ranked probabilities, which implies a high AUROC score.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，拥有一个强大的 AUROC 模型非常重要 — 这是模型调优过程的工作（该过程可能会优化其他指标）。这在我们开始调整阈值之前完成，完成后，重要的是要有良好排名的概率，这意味着
    AUROC 得分很高。
- en: Then, where the project requires class predictions for all records, it’s necessary
    to select a threshold (though the default of 0.5 can be used, but likely with
    sub-optimal results), which is equivalent to picking a point on the ROC curve.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果项目需要为所有记录做出类别预测，则必须选择一个阈值（尽管可以使用默认值 0.5，但可能会得到次优结果），这相当于在 ROC 曲线上选择一个点。
- en: The figure above shows two points on the ROC. For each, a vertical and a horizonal
    line are drawn to the x & y-axes to indicate the associated True Positive Rates
    and False Positive Rates.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 上图展示了 ROC 曲线上的两个点。对于每个点，都画了垂直线和水平线，分别指示关联的真正例率和假正例率。
- en: Given an ROC curve, as we go left and down, we are using a higher threshold
    (for example from the green to the red line). Less records will be predicted positive,
    so there will be both less true positives and less false positives.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 给定 ROC 曲线，当我们向左和向下移动时，表示使用更高的阈值（例如，从绿色线到红色线）。预测为正的记录会减少，因此真正例和假正例都会减少。
- en: As we move right and up (for example, from the red to the green line), we are
    using a lower threshold. More records will be predicted positive, so there will
    be both more true positives and more false positives.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们向右和向上移动时（例如，从红线到绿线），表示使用更低的阈值。更多的记录会被预测为正例，因此真正例和假正例都会增加。
- en: That is, in the plot here, the red and green lines represent two possible thresholds.
    Moving from the green line to the red, we see a small drop in the true positive
    rate, but a larger drop in the false positive rate, making this quite likely a
    better choice of threshold than that where the green line is situated. But not
    necessarily — we also need to consider the relative cost of false positives and
    false negatives.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，在这里的图中，红线和绿线代表两个可能的阈值。从绿线移动到红线，我们看到真正例率略有下降，但假正例率大幅下降，这使得这个阈值选择比绿线所在的阈值更有可能是更好的选择。但这并不一定
    — 我们还需要考虑假正例和假负例的相对成本。
- en: What’s important, though, is that moving from one threshold to another can often
    adjust the False Positive Rate much more or much less than the True Positive Rate.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 但需要注意的是，从一个阈值移动到另一个阈值通常会比真正例率更大或更小地调整假正例率。
- en: The following presents a set of thresholds with a given ROC curve. We can see
    where moving from one threshold to another can affect the true positive and false
    positive rates to significantly different extents.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下展示了一组给定 ROC 曲线的阈值。我们可以看到，从一个阈值移动到另一个阈值时，真正例率和假正例率的变化程度可能会大不相同。
- en: '![](../Images/fdb58fb5016981a701c926b0da9ed734.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdb58fb5016981a701c926b0da9ed734.png)'
- en: 'This is the main idea behind adjusting the threshold: it’s often possible to
    achieve a large gain in one sense, while taking only a small loss in the other.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是调整阈值背后的主要思路：通常可以在一个方面获得较大增益，同时在另一个方面仅遭受小幅损失。
- en: It’s possible to look at the ROC curve and see the effect of moving the thresholds
    up and down. Given that, it’s possible, to an extent, to eye-ball the process
    and pick a point that appears to best balance true positives and false positives
    (which also effectively balances false positives and false negatives). In some
    sense, this is what ClassificationThesholdTuner does, but it does so in a principled
    way, in order to optimize for a certain, specified metric (such as the F1 score).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 可以查看 ROC 曲线，观察上下调整阈值的效果。基于这一点，我们在一定程度上可以凭目测选择一个看起来最佳平衡真正例和假正例的点（这也有效地平衡了假正例和假负例）。在某种意义上，这就是
    ClassificationThesholdTuner 的作用，但它以一种有原则的方式进行，从而优化某一指定的指标（如 F1 分数）。
- en: Moving the threshold to different points on the ROC generates different confusion
    matrixes, which can then be converted to metrics (F1 Score, F2 score, MCC etc.).
    We can then take the point that optimizes this score.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 将阈值移动到 ROC 曲线上的不同点会生成不同的混淆矩阵，然后可以将其转换为评估指标（如 F1 分数、F2 分数、MCC 等）。然后，我们可以选择优化该指标的点。
- en: So long as a model is trained to have a strong AUROC, we can usually find a
    good threshold to achieve a high F1 score (or other such metric).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 只要模型经过训练，能够获得强大的AUROC值，我们通常可以找到一个好的阈值来获得高F1得分（或其他类似的度量）。
- en: '![](../Images/eabef9883aa792d33898de49b0ff719e.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eabef9883aa792d33898de49b0ff719e.png)'
- en: In this ROC plot, the model is very accurate, with an AUROC of 0.98\. It will,
    then, be possible to select a threshold that results in a high F1 score, though
    it is still necessary to select a good threshold, and the optimal may easily not
    be 0.5.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个ROC图中，模型非常准确，AUROC为0.98。因此，可以选择一个能产生高F1得分的阈值，尽管仍然需要选择一个好的阈值，且最优阈值可能并不一定是0.5。
- en: 'Being well-ranked, the model is not necessarily also well-calibrated, but this
    isn’t necessary: so long as records that are in the positive class tend to get
    higher predicted probabilities than those in the negative class, we can find a
    good threshold where we separate those predicted to be positive from those predicted
    to be negative.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 排名良好的模型不一定是良好校准的，但这并不是必须的：只要正类记录的预测概率普遍高于负类记录的预测概率，我们就能找到一个合适的阈值，将预测为正类的记录与预测为负类的记录分开。
- en: 'Looking at this another way, we can view the distribution of probabilities
    in a binary classification problem with two histograms, as shown here (actually
    using KDE plots). The blue curve shows the distribution of probabilities for the
    negative class and the orange for the positive class. The model is not likely
    well-calibrated: the probabilities for the positive class are consistently well
    below 1.0\. But, they are well-ranked: the probabilities for the positive class
    tend to be higher than those for the negative class, which means the model would
    have a high AUROC and the model can assign labels well if using an appropriate
    threshold, in this case, likely about 0.25 or 0.3\. Given that there is overlap
    in the distributions, though, it’s not possible to have a perfect system to label
    the records, and the F1 score can never be quite 1.0.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从另一个角度看，我们可以通过两个直方图来查看二元分类问题中概率的分布，如下所示（实际上使用的是KDE图）。蓝色曲线表示负类的概率分布，橙色曲线表示正类的概率分布。模型可能没有很好地校准：正类的概率始终远低于1.0。但是，它们排名良好：正类的概率通常高于负类的概率，这意味着模型的AUROC值较高，并且如果使用适当的阈值（在这种情况下，可能是0.25或0.3），模型能够很好地分配标签。尽管分布之间存在重叠，但无法实现完美的记录标签系统，F1得分也永远不能达到1.0。
- en: '![](../Images/51b21f477acb1721e97fdd4c126e8e07.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51b21f477acb1721e97fdd4c126e8e07.png)'
- en: 'It is possible to have, even with a high AUROC score, a low F1 score: where
    there is a poor choice of threshold. This can occur, for example, where the ROC
    hugs the axis as in the ROC shown above — a very low or very high threshold may
    work poorly. Hugging the y-axis can also occur where the data is imbalanced.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 即使AUROC得分很高，也有可能F1得分很低：这通常发生在阈值选择不当时。例如，ROC曲线可能像上面所示那样贴近轴线——非常低或非常高的阈值可能表现不好。数据不平衡时也可能出现ROC曲线紧贴y轴的情况。
- en: In the case of the histograms shown here, though the model is well-calibrated
    and would have a high AUROC score, a poor choice of threshold (such as 0.5 or
    0.6, which would result in everything being predicted as the negative class) would
    result in a very low F1 score.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这里展示的直方图，尽管模型校准良好并且AUROC得分很高，但如果选择不合适的阈值（如0.5或0.6，这会导致所有预测都为负类），则会导致F1得分非常低。
- en: It’s also possible (though less likely) to have a low AUROC and high F1 Score.
    This is possible with a particularly good choice of threshold (where most thresholds
    would perform poorly).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 即使AUROC较低，也可能出现高F1得分的情况。通过选择一个特别好的阈值（在大多数阈值下表现都很差），也可以实现这一点。
- en: As well, it’s not common, but possible to have ROC curves that are asymmetrical,
    which can greatly affect where it is best to place the threshold.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，虽然不常见，但可能会有不对称的ROC曲线，这可能会大大影响最合适的阈值位置。
- en: Example using ClassificationThresholdTuner for Binary Classification
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ClassificationThresholdTuner进行二元分类示例
- en: This is taken from a [notebook](https://github.com/Brett-Kennedy/ClassificationThresholdTuner/blob/main/notebooks/binary_classification_threshold_demo.ipynb)
    available on the github site (where it’s possible to see the full code). We’ll
    go over the main points here. For this example, we first generate a test dataset.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从一个[notebook](https://github.com/Brett-Kennedy/ClassificationThresholdTuner/blob/main/notebooks/binary_classification_threshold_demo.ipynb)中提取的，可以在GitHub网站上查看完整的代码。我们将在这里讨论主要的内容。对于这个例子，我们首先生成一个测试数据集。
- en: '[PRE1]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, for simplicity, we don’t generate the original data or the classifier
    that produced the predicted probabilities, just a test dataset containing the
    true labels and the predicted probabilities, as this is what ClassificationThresholdTuner
    works with and is all that is necessary to select the best threshold.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这里为了简便，我们不生成原始数据或产生预测概率的分类器，而是仅使用一个包含真实标签和预测概率的测试数据集，因为`ClassificationThresholdTuner`正是处理这些内容，而这些内容足以选择最佳的阈值。
- en: '![](../Images/3277acbd53468e2b584a86c1f20a5360.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3277acbd53468e2b584a86c1f20a5360.png)'
- en: There’s actually also code in the notebook to scale the probabilities, to ensure
    they are between 0.0 and 1.0, but for here, we’ll just assume the probabilities
    are well-scaled.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，笔记本中还有一段代码用于对概率进行缩放，确保它们在0.0到1.0之间，但在这里，我们将假设概率已经很好地进行了缩放。
- en: 'We can then set the Pred column using a threshold of 0.5:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用0.5的阈值来设置`Pred`列：
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/ea3ac56911fab0f8dad15da7e4f2e786.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea3ac56911fab0f8dad15da7e4f2e786.png)'
- en: This simulates what’s normally done with classifiers, simply using 0.5 as the
    threshold. This is the baseline we will try to beat.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这模拟了分类器通常的做法，即简单地使用0.5作为阈值。这是我们将尝试超越的基准。
- en: We then create a ClassificationThresholdTuner object and use this, to start,
    just to see how strong the current predictions are, calling one of it’s APIs,
    print_stats_lables().
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建一个`ClassificationThresholdTuner`对象，并使用它来开始，仅仅是为了查看当前预测的强度，调用其API之一`print_stats_lables()`。
- en: '[PRE3]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This indicates the precision, recall, and F1 scores for both classes (was well
    as the macro scores for these) and presents the confusion matrix.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这会显示两个类别的精确度、召回率和F1分数（以及这些分数的宏平均），并呈现混淆矩阵。
- en: '![](../Images/b80a327ff35d0606256f110bb7070bca.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b80a327ff35d0606256f110bb7070bca.png)'
- en: This API assumes the labels have been predicted already; where only the probabilities
    are available, this method cannot be used, though we can always, as in this example,
    select a threshold and set the labels based on this.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这个API假定标签已经被预测；如果只有概率而没有标签，则无法使用此方法，尽管我们总是可以像这个例子一样选择一个阈值，并根据这个阈值设置标签。
- en: 'We can also call the print_stats_proba() method, which also presents some metrics,
    in this case related to the predicted probabilities. It shows: the Brier Score,
    AUROC, and several plots. The plots require a threshold, though 0.5 is used if
    not specified, as in this example:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以调用`print_stats_proba()`方法，它也会展示一些指标，在这个例子中与预测概率相关。它显示：Brier分数、AUROC和几个图表。图表需要一个阈值，若未指定，则使用0.5，如本例所示：
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This displays the effects of a threshold of 0.5\. It shows the ROC curve, which
    itself does not require a threshold, but draws the threshold on the curve. It
    then presents how the data is split into two predicted classes based on the threshold,
    first as a histogram, and second as a swarm plot. Here there are two classes,
    with class A in green and class B (the positive class in this example) in blue.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了0.5的阈值效果。它展示了ROC曲线，ROC曲线本身不需要阈值，但会在曲线上标出该阈值。然后，它展示了数据如何根据阈值被分成两个预测类别，首先以直方图显示，其次以群体图显示。这里有两个类别，类别A为绿色，类别B（在这个例子中为正类）为蓝色。
- en: '![](../Images/bd0be7a84dad55c1c7c7b73c4e11435c.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd0be7a84dad55c1c7c7b73c4e11435c.png)'
- en: In the swarm plot, any misclassified records are shown in red. These are those
    where the true class is A but the predicted probability of B is above the threshold
    (so the model would predict B), and those where the true class is B but the predicted
    probability of B is below the threshold (so the model would predict A).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在群体图中，任何被错误分类的记录都显示为红色。这些是那些真实类别为A但B的预测概率高于阈值（因此模型会预测为B），以及那些真实类别为B但B的预测概率低于阈值（因此模型会预测为A）的记录。
- en: 'We can then examine the effects of different thresholds using plot_by_threshold():'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`plot_by_threshold()`来检查不同阈值的效果：
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this example, we use the default set of potential thresholds: 0.1, 0.2,
    0.3, … up to 0.9\. For each threshold, it will predict any records with predicted
    probabilities over the threshold as the positive class and anything lower as the
    negative class. Misclassified records are shown in red.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用默认的潜在阈值集合：0.1、0.2、0.3，……直到0.9。对于每个阈值，模型会将预测概率超过该阈值的记录预测为正类，将低于该阈值的记录预测为负类。错误分类的记录显示为红色。
- en: '![](../Images/1869104b0c54c931020dc23e4b476f30.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1869104b0c54c931020dc23e4b476f30.png)'
- en: 'To save space in this article, this image shows just three potential thresholds:
    0.2, 0.3, and 0.4\. For each we see: the position on the ROC curve this threshold
    represents, the split in the data it leads to, and the resulting confusion matrix
    (along with the F1 macro score associated with that confusion matrix).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省本文的篇幅，这张图片仅展示了三个潜在阈值：0.2、0.3和0.4。对于每个阈值，我们可以看到：该阈值在ROC曲线上的位置、它导致的数据划分，以及由此产生的混淆矩阵（以及与该混淆矩阵相关的F1宏评分）。
- en: 'We can see that setting the threshold to 0.2 results in almost everything being
    predicted as B (the positive class) — almost all records of class A are misclassified
    and so drawn in red. As the threshold is increased, more records are predicted
    to be A and less as B (though at 0.4 most records that are truly B are correctly
    predicted as B; it is not until a threshold of about 0.8 where almost all records
    that are truly class B are erroneously predicted as A: very few have predicted
    probability over 0.8).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，将阈值设为0.2时几乎所有的预测结果都是B（正类）——几乎所有A类的记录都被误分类，因此用红色标出。随着阈值的增加，更多记录被预测为A，B类的预测减少（尽管在阈值为0.4时，大多数真实B类记录被正确预测为B；直到阈值接近0.8时，几乎所有真实的B类记录都被错误预测为A：很少有记录的预测概率超过0.8）。
- en: 'Examining this for nine possible values from 0.1 to 0.9 gives a good overview
    of the possible thresholds, but it may be more useful to call this function to
    display a narrower, and more realistic, range of possible values, for example:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对从0.1到0.9的九个可能值进行检查，可以很好地概览潜在的阈值范围，但调用此函数显示一个更窄且更现实的可能值范围可能更有用，例如：
- en: '[PRE6]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will show each threshold from 0.50 to 0.55\. Showing the first two of
    these:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这将展示从0.50到0.55的每个阈值。展示其中的前两个：
- en: '![](../Images/398801066ab07d8afc4c9e286fc044b8.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/398801066ab07d8afc4c9e286fc044b8.png)'
- en: The API helps present the implications of different thresholds.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这个API有助于展示不同阈值的影响。
- en: We can also view this calling describe_slices(), which describes the data between
    pairs of potential thresholds (i.e., within slices of the data) in order to see
    more clearly what the specific changes will be of moving the threshold from one
    potential location to the next (we see how many of each true class will be re-classified).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看这个调用`describe_slices()`，它描述了潜在阈值对之间的数据（即数据的切片），以便更清楚地看到将阈值从一个潜在位置移动到下一个位置时的具体变化（我们可以看到每个真实类别会有多少被重新分类）。
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This shows each slice visually and in table format:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这将以视觉和表格格式显示每个切片：
- en: '![](../Images/97914fa63002cc3fe5fb03ca6ec8d0c2.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97914fa63002cc3fe5fb03ca6ec8d0c2.png)'
- en: Here, the slices are fairly thin, so we see plots both showing them in context
    of the full range of probabilities (the left plot) and zoomed in (the right plot).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的切片相对较薄，因此我们可以看到两个图，一个展示了它们在完整概率范围内的上下文（左图），另一个则是放大的（右图）。
- en: We can see, for example, that moving the threshold from 0.38 to 0.46 we would
    re-classify the points in the 3rd slice, which has 17,529 true instances of class
    A and 1,464 true instances of class B. This is evident both in the rightmost swarm
    plot and in the table (in the swarm plot, there are far more green than blue points
    within slice 3).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，例如，将阈值从0.38调整到0.46时，我们会重新分类第3个切片中的点，该切片中有17,529个真实的A类实例和1,464个真实的B类实例。这在最右侧的散点图和表格中都有明显体现（在散点图中，第3个切片内的绿色点比蓝色点多得多）。
- en: 'This API can also be called for a narrower, and more realistic, range of potential
    thresholds:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个API也可以用于更窄且更现实的潜在阈值范围：
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This produces:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成：
- en: '![](../Images/da5ab6866d1b86849bc9353e632302ca.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da5ab6866d1b86849bc9353e632302ca.png)'
- en: Having called these (or another useful API, print_stats_table(), skipped here
    for brevity, but described on the github page and in the example notebooks), we
    can have some idea of the effects of moving the threshold.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 调用这些（或其他有用的API，如`print_stats_table()`，这里为了简洁略过，但在github页面和示例笔记本中有描述）之后，我们可以对移动阈值的效果有所了解。
- en: We can then move to the main task, searching for the optimal threshold, using
    the tune_threshold() API. With some projects, this may actually be the only API
    called. Or it may be called first, with the above APIs being called later to provide
    context for the optimal threshold discovered.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以进入主要任务，使用`tune_threshold()` API寻找最优阈值。对于一些项目来说，这可能是唯一会被调用的API，或者它可能首先被调用，随后使用上述API来提供关于发现的最优阈值的上下文。
- en: In this example, we optimize the F1 macro score, though any metric supported
    by scikit-learn and based on class labels is possible. Some metrics require additional
    parameters, which can be passed here as well. In this example, scikit-learn’s
    f1_score() requires the ‘average’ parameter, passed here as a parameter to tune_threshold().
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们优化F1宏评分，尽管任何由scikit-learn支持并基于类别标签的指标都是可以的。某些指标需要额外的参数，这些参数也可以在此传递。在此示例中，scikit-learn的f1_score()需要‘average’参数，该参数作为tune_threshold()的参数传递。
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This, optionally, displays a set of plots demonstrating how the method over
    five iterations (in this example max_iterations is specified as 5) narrows in
    on the threshold value that optimizes the specified metric.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这将可选地显示一组图表，演示该方法在五次迭代过程中（在此示例中，max_iterations指定为5）如何逐步收敛到优化指定指标的阈值。
- en: The first iteration considers the full range of potential thresholds between
    0.0 and 1.0\. It then narrows in on the range 0.5 to 0.6, which is examined closer
    in the next iteration and so on. In the end a threshold of 0.51991 is selected.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 第一轮考虑了0.0到1.0之间的所有潜在阈值范围。然后它将范围缩小到0.5到0.6，并在下一轮中更详细地检查该范围，依此类推。最后选择了0.51991作为阈值。
- en: '![](../Images/388aed8adf00e382e0b6b6e832540151.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/388aed8adf00e382e0b6b6e832540151.png)'
- en: 'After this, we can call print_stats_labels() again, which shows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们可以再次调用print_stats_labels()，它会显示：
- en: '![](../Images/f97102f666acca6171907243366fb74b.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f97102f666acca6171907243366fb74b.png)'
- en: We can see, in this example, an increase in Macro F1 score from 0.875 to 0.881\.
    In this case, the gain is small, but comes for almost free. In other cases, the
    gain may be smaller or larger, sometimes much larger. It’s also never counter-productive;
    at worst the optimal threshold found will be the default, 0.5000, in any case.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在此示例中，宏F1得分从0.875提高到0.881。在这种情况下，提升很小，但几乎是免费的。在其他情况下，提升可能更小或更大，有时甚至更大。它也从不会适得其反；最坏的情况是，找到的最佳阈值仍然是默认值0.5000。
- en: Thresholds in Multi-class Classification
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多类分类中的阈值
- en: As indicated, multi-class classification is a bit more complicated. In the binary
    classification case, a single threshold is selected, but with multi-class classification,
    ClassificationThesholdTuner identifies an optimal threshold per class.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如所示，多类分类要比二类分类稍微复杂。在二类分类的情况下，选择一个单一的阈值，而在多类分类中，ClassificationThesholdTuner会为每个类别识别一个最佳阈值。
- en: Also different from the binary case, we need to specify one of the classes to
    be the default class. Going through an example should make it more clear why this
    is the case.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 与二类情况不同，我们需要指定一个类别作为默认类别。通过一个示例可以更清楚地了解为什么需要这样做。
- en: In many cases, having a default class can be fairly natural. For example, if
    the target column represents various possible medical conditions, the default
    class may be “No Issue” and the other classes may each relate to specific conditions.
    For each of these conditions, we’d have a minimum predicted probability we’d require
    to actually predict that condition.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，拥有一个默认类别是相当自然的。例如，如果目标列代表各种可能的医疗状况，默认类别可能是“无问题”，其他类别则分别与特定的疾病相关。对于这些疾病中的每一种，我们都会设定一个最低预测概率，要求该条件的预测需要达到此概率。
- en: Or, if the data represents network logs and the target column relates to various
    intrusion types, then the default may be “Normal Behavior”, with the other classes
    each relating to specific network attacks.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果数据表示网络日志，并且目标列涉及各种入侵类型，那么默认类别可能是“正常行为”，其他类别则分别与特定的网络攻击相关。
- en: 'In the example of network attacks, we may have a dataset with four distinct
    target values, with the target column containing the classes: “Normal Behavior”,
    “Buffer Overflow”, “Port Scan”, and “Phishing”. For any record for which we run
    prediction, we will get a probability of each class, and these will sum to 1.0\.
    We may get, for example: [0.3, 0.4, 0.1, 0.2] (the probabilities for each of the
    four classes, in the order above).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络攻击的示例中，我们可能有一个数据集，包含四个不同的目标值，目标列包含类别：“正常行为”、“缓冲区溢出”、“端口扫描”和“网络钓鱼”。对于我们运行预测的任何记录，都会得到每个类别的概率，这些概率的总和为1.0。例如，我们可能会得到：[0.3,
    0.4, 0.1, 0.2]（按照上述顺序，每个类别的概率）。
- en: Normally, we would predict “Buffer Overflow” as this has the highest probability,
    0.4\. However, we can set a threshold in order to modify this behavior, which
    will then affect the rate of false negatives and false positives for this class.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们会预测“缓冲区溢出”，因为它具有最高的概率0.4。然而，我们可以设置一个阈值，以修改这一行为，这将影响该类别的假阴性和假阳性率。
- en: 'We may specify, for example that: the default class is ‘Normal Behavior”; the
    threshold for “Buffer Overflow” is 0.5; for “Port Scan” is 0.55; and for “Phishing”
    is 0.45\. By convention, the threshold for the default class is set to 0.0, as
    it does not actually use a threshold. So, the set of thresholds here would be:
    0.0, 0.5, 0.55, 0.45.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以指定，例如：默认类是“正常行为”；“缓冲区溢出”的阈值是0.5；“端口扫描”的阈值是0.55；“钓鱼攻击”的阈值是0.45。按照惯例，默认类的阈值设为0.0，因为它实际上不使用阈值。因此，这里阈值的集合将是：0.0，0.5，0.55，0.45。
- en: Then to make a prediction for any given record, we consider only the classes
    where the probability is over the relevant threshold. In this example (with predictions
    [0.3, 0.4, 0.1, 0.2]), none of the probabilities are over their thresholds, so
    the default class, “Normal Behavior” is predicted.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了对任何给定记录做出预测，我们仅考虑那些概率超过相关阈值的类。在这个示例中（预测值为[0.3, 0.4, 0.1, 0.2]），没有任何概率超过其阈值，因此预测为默认类“正常行为”。
- en: 'If the predicted probabilities were instead: [0.1, 0.6, 0.2, 0.1], then we
    would predict “Buffer Overflow”: the probability (0.6) is the highest prediction
    and is over its threshold (0.5).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预测概率为：[0.1, 0.6, 0.2, 0.1]，那么我们将预测为“缓冲区溢出”：概率（0.6）是最高的预测，并且超过其阈值（0.5）。
- en: 'If the predicted probabilities were: [0.1, 0.2, 0.7, 0.0], then we would predict
    “Port Scan”: the probability (0.7) is over its threshold (0.55) and this is the
    highest prediction.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预测概率为：[0.1, 0.2, 0.7, 0.0]，那么我们将预测为“端口扫描”：概率（0.7）超过其阈值（0.55），这是最高的预测。
- en: 'This means: if one or more classes have predicted probabilities over their
    threshold, we take the one of these with the highest predicted probability. If
    none are over their threshold, we take the default class. And, if the default
    class has the highest predicted probability, it will be predicted.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着：如果一个或多个类的预测概率超过其阈值，我们将选择其中预测概率最高的类。如果没有类超过其阈值，则选择默认类。而且，如果默认类的预测概率最高，那么将预测为默认类。
- en: So, a default class is needed to cover the case where none of the predictions
    are over the the threshold for that class.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，需要一个默认类来覆盖当没有任何预测值超过该类阈值的情况。
- en: 'If the predictions are: [0.1, 0.3, 0.4, 0.2] and the thresholds are: 0.0, 0.55,
    0.5, 0.45, another way to look at this is: the third class would normally be predicted:
    it has the highest predicted probability (0.4). But, if the threshold for that
    class is 0.5, then a prediction of 0.4 is not high enough, so we go to the next
    highest prediction, which is the second class, with a predicted probability of
    0.3\. That is below its threshold, so we go again to the next highest predicted
    probability, which is the forth class with a predicted probability of 0.2\. It
    is also below the threshold for that target class. Here, we have all classes with
    predictions that are fairly high, but not sufficiently high, so the default class
    is used.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预测值为：[0.1, 0.3, 0.4, 0.2]，阈值为：[0.0, 0.55, 0.5, 0.45]，另一种看法是：通常会预测第三类：它具有最高的预测概率（0.4）。但是，如果该类的阈值是0.5，那么0.4的预测值不够高，因此我们选择下一个最高的预测值，即第二类，预测概率为0.3。这低于其阈值，所以我们继续选择下一个最高的预测值，即第四类，预测概率为0.2。它也低于该目标类的阈值。在这里，我们所有类的预测值都相对较高，但都不够高，因此使用默认类。
- en: This also highlights why it’s convenient to use 0.0 as the threshold for the
    default class — when examining the prediction for the default class, we do not
    need to consider if its prediction is under or over the threshold for that class;
    we can always make a prediction of the default class.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这也突出了为何使用0.0作为默认类阈值是方便的——当检查默认类的预测时，我们无需考虑其预测是否低于或超过该类的阈值；我们总是可以做出默认类的预测。
- en: It’s actually, in principle, also possible to have more complex policies — not
    just using a single default class, but instead having multiple classes that can
    be selected under different conditions. But these are beyond the scope of this
    article, are often unnecessary, and are not supported by ClassificationThresholdTuner,
    at least at present. For the remainder of this article, we’ll assume there’s a
    single default class specified.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，原则上也可以有更复杂的策略——不仅使用单一的默认类，而是根据不同的条件选择多个类。但这些超出了本文的范围，通常是多余的，并且当前版本的ClassificationThresholdTuner不支持这些策略。在本文的其余部分，我们将假设指定了单一的默认类。
- en: Example using ClassificationThresholdTuner for Multi-class Classification
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ClassificationThresholdTuner进行多类分类的示例
- en: 'Again, we’ll start by creating the test data (using one of the test data sets
    provided in the [example notebook](https://github.com/Brett-Kennedy/ClassificationThresholdTuner/blob/main/notebooks/multiclass_classification_threshold_demo.ipynb)
    for multi-class classification on the github page), in this case, having three,
    instead of just two, target classes:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们将从创建测试数据开始（使用[示例笔记本](https://github.com/Brett-Kennedy/ClassificationThresholdTuner/blob/main/notebooks/multiclass_classification_threshold_demo.ipynb)中提供的一个测试数据集，进行多类分类），在这种情况下，有三个目标类别，而不仅仅是两个：
- en: '[PRE10]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: There’s some code in the notebook to scale the scores and ensure they sum to
    1.0, but for here, we can just assume this is done and that we have a set of well-formed
    probabilities for each class for each record.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本中有一些代码用于缩放分数并确保它们的和为1.0，但在这里，我们可以假设这已经完成，并且我们为每条记录准备了一组结构良好的每个类别的概率。
- en: As is common with real-world data, one of the classes (the ‘No Attack’ class)
    is much more frequent than the others; the dataset in imbalanced.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 正如真实世界数据中常见的那样，其中一个类别（‘无攻击’类别）比其他类别频繁得多；该数据集是不平衡的。
- en: 'We then set the target predictions, for now just taking the class with the
    highest predicted probability:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们设置目标预测，目前只是选择概率最高的类别：
- en: '[PRE11]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This produces:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成：
- en: '![](../Images/08bf1dae2829cd7aa9d1b78704229122.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08bf1dae2829cd7aa9d1b78704229122.png)'
- en: Taking the class with the highest probability is the default behaviour, and
    in this example, the baseline we wish to beat.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 选择概率最高的类别是默认行为，在这个例子中，这是我们希望超越的基准。
- en: 'We can, as with the binary case, call print_stats_labels(), which works similarly,
    handling any number of classes:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像处理二分类情况一样，调用`print_stats_labels()`，其功能类似，处理任意数量的类别：
- en: '[PRE12]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This outputs:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这会输出：
- en: '![](../Images/89efe0526a77487ebcefdbc27f89ccc7.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89efe0526a77487ebcefdbc27f89ccc7.png)'
- en: Using these labels, we get an F1 macro score of only 0.447.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些标签，我们得到的F1宏观评分仅为0.447。
- en: 'Calling print_stats_proba(), we also get the output related to the prediction
    probabilities:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`print_stats_proba()`，我们还可以获得与预测概率相关的输出：
- en: '![](../Images/82488ef664db4d967a261c772e6c5cda.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82488ef664db4d967a261c772e6c5cda.png)'
- en: 'This is a bit more involved than the binary case, since we have three probabilities
    to consider: the probabilities of each class. So, we first show how the data lines
    up relative to the probabilities of each class. In this case, there are three
    target classes, so three plots in the first row.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这比二分类情况更为复杂，因为我们需要考虑三个概率：每个类别的概率。因此，我们首先展示数据如何相对于每个类别的概率对齐。在这种情况下，有三个目标类别，所以第一行有三个图表。
- en: As would be hoped, when plotting the data based on the predicted probability
    of ‘No Attack’ (the left-most plot), the records for ‘No Attack’ are given a higher
    probabilities of this class than for other classes. Similar for ‘Attack A’ (the
    middle plot) and ‘Attack B’ (the right-most plot).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，当基于‘无攻击’的预测概率绘制数据时（最左侧的图表），‘无攻击’记录被赋予了比其他类别更高的概率。对于‘攻击A’（中间图表）和‘攻击B’（最右侧的图表）也是类似的。
- en: We can also see that the classes are not perfectly separated, so there is no
    set of thresholds that can result in a perfect confusion matrix. We will need
    to chose a set of thresholds that best balances correct and incorrect predictions
    for each class.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到，类别之间并未完全分离，因此没有一组阈值能产生完美的混淆矩阵。我们需要选择一组阈值，最好能够平衡每个类别的正确预测和错误预测。
- en: In the figure above, the bottom plot shows each point based on the probability
    of its true class. So for the the records where the true class is ‘No Attack’
    (the green points), we plot these by their predicted probability of ‘No Attack’,
    for the records where the true class is ‘Attack A’, (in dark blue) we plot these
    by their predicted probability of ‘Attack A’, and similar for Attack B (in dark
    yellow). We see that the model has similar probabilities for Attack A and Attack
    B, and higher probabilities for these than for No Attack.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，底部的图表显示每个点的真实类别的概率。对于真实类别为‘无攻击’的记录（绿色点），我们根据它们的‘无攻击’预测概率绘制这些点；对于真实类别为‘攻击A’的记录（深蓝色），我们根据它们的‘攻击A’预测概率绘制这些点；‘攻击B’（深黄色）也是类似的。我们可以看到，模型对‘攻击A’和‘攻击B’的概率相似，并且这些类别的概率高于‘无攻击’。
- en: 'The above plots did not consider any specific thresholds that may be used.
    We can also, optionally, generate more output, passing a set of thresholds (one
    per class, using 0.0 for the default class):'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表未考虑任何可能使用的特定阈值。我们还可以选择性地生成更多输出，传入一组阈值（每个类别一个，使用0.0表示默认类别）：
- en: '[PRE13]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This may be most useful to plot the set of thresholds discovered as optimal
    by the tool, but can also be used to view other potential sets of thresholds.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于绘制工具发现的最优阈值集可能最为有用，但也可以用于查看其他潜在的阈值集。
- en: 'This produces a report for each class. To save space, we just show one here,
    for class Attack A (the full report is shown in the example notebook; viewing
    the reports for the other two classes as well is helpful to understand the full
    implications of using, in this example, [0.0, 0.4, 0.4] as the thresholds):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这为每个类别生成报告。为了节省空间，这里只展示Class Attack A的报告（完整的报告可以在示例笔记本中查看；查看其他两个类别的报告也有助于理解在此示例中使用[0.0,
    0.4, 0.4]作为阈值的全部影响）：
- en: '![](../Images/b4fb08fda5476d5559a4847801913976.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4fb08fda5476d5559a4847801913976.png)'
- en: As we have a set of thresholds specified here, we can see the implications of
    using these thresholds, including how many of each class will be correctly and
    incorrectly classified.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这里指定了一组阈值，我们可以看到使用这些阈值的影响，包括每个类别会被正确和错误分类的数量。
- en: We see first where the threshold appears on the ROC curve. In this case, we
    are viewing the report for Class A so see a threshold of 0.4 (0.4 was specified
    for class A in the API call above).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先查看阈值在ROC曲线上的位置。在这种情况下，我们查看的是Class A的报告，所以看到阈值为0.4（0.4在上面的API调用中为Class A指定）。
- en: The AUROC score is also shown. This metric applies only to binary prediction,
    but in a multi-class problem we can calculate the AUROC score for each class by
    treating the problem as a series of one-vs-all problems. Here we can treat the
    problem as ‘Attack A’ vs not ‘Attack A’ (and similarly for the other reports).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 还展示了AUROC分数。这个指标仅适用于二分类预测，但在多分类问题中，我们可以通过将问题视为一系列的“一个对其他”问题，来为每个类别计算AUROC分数。在这里，我们可以将问题视为‘Attack
    A’与非‘Attack A’（对其他报告也可以做类似处理）。
- en: 'The next plots show the distribution of each class with respect to the predicted
    probabilities of Attack A. As there are different counts of the different classes,
    these are shown two ways: one showing the actual distributions, and one showing
    them scaled to be more comparable. The former is more relevant, but the latter
    can allow all classes to be seen clearly where some classes are much more rare
    than others.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的图显示了每个类别相对于预测概率的分布。由于不同类别的数量不同，这里展示了两种方式：一种展示实际分布，另一种展示经缩放后便于比较的分布。前者更为相关，但后者可以让所有类别清晰可见，尤其是当某些类别远比其他类别稀有时。
- en: We can see that records where the true class is ‘Attack A’ (in dark blue) do
    have higher predicted probabilities of ‘Attack A’, but there is some decision
    to be made as to where the threshold is specifically placed. We see here the effect
    using 0.4 for this class. It appears that 0.4 is likely close to ideal, if not
    exactly.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，真实类别为‘Attack A’（深蓝色）的记录确实具有更高的‘Attack A’预测概率，但仍然需要决定具体设置阈值的位置。这里我们看到了使用0.4作为该类别阈值的效果。看起来0.4可能接近理想值，甚至可能就是理想值。
- en: We also see this in the form a swarm plot (the right-most plot), with the misclassified
    points in red. We can see that using a higher threshold (say 0.45 or 0.5), we
    would have more records where the true class is Attack A misclassified, but less
    records where the true class is ‘No Attack’ misclassified. And, using a lower
    threshold (say 0.3 or 0.35) would have the opposite effect.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以以群体图的形式看到这一点（最右侧的图），误分类的点用红色表示。我们可以看到，使用更高的阈值（例如0.45或0.5），会有更多的记录将真实类别为Attack
    A的误分类，但对于真实类别为‘No Attack’的误分类记录则较少。而使用更低的阈值（例如0.3或0.35）则会产生相反的效果。
- en: 'We can also call plot_by_threshold() to look at different potential thresholds:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以调用plot_by_threshold()来查看不同的潜在阈值：
- en: '[PRE14]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This API is simply for explanation and not tuning, so for simplicity uses (for
    each potential threshold), the same threshold for each class (other than the default
    class). Showing this for the potential thresholds 0.2, 0.3, and 0.4:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这个API只是为了说明，并非用于调优，因此为了简便起见（对于每个潜在阈值），每个类别使用相同的阈值（默认类别除外）。展示这三个潜在阈值0.2、0.3和0.4：
- en: '![](../Images/8d9a904beadcd0d787ce82839fa9206d.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d9a904beadcd0d787ce82839fa9206d.png)'
- en: The first row of figures shows the implication of using 0.2 for the threshold
    for all classes other than the default (that is not predicting Attack A unless
    the estimated probability of Attack A is at least 0.2; and not predicting Attack
    B unless the predicted probability of Attack B is at least 0.2 — though always
    otherwise taking the class with the highest predicted probability). Similarly
    in the next two rows for thresholds of 0.3 and 0.4.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行数字显示了使用 0.2 作为所有类别（默认类别除外）的阈值的含义（即，只有当攻击 A 的估计概率至少为 0.2 时才预测攻击 A；只有当攻击 B
    的预测概率至少为 0.2 时才预测攻击 B——否则始终选择预测概率最高的类别）。类似地，第二行和第三行分别对应于 0.3 和 0.4 的阈值。
- en: We can see here the trade-offs to using lower or higher thresholds for each
    class, and the confusion matrixes that will result (along with the F1 score associated
    with these confusion matrixes).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里看到，使用较低或较高阈值对每个类别的权衡，以及由此产生的混淆矩阵（以及与这些混淆矩阵相关的 F1 分数）。
- en: In this example, moving from 0.2 to 0.3 to 0.4, we can see how the model will
    less often predict Attack A or Attack B (raising the thresholds, we will less
    and less often predict anything other than the default) and more often No Attack,
    which results in less misclassifications where the true class is No Attack, but
    more where the true class is Attack A or Attack B.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，从 0.2 移动到 0.3，再到 0.4，我们可以看到模型越来越少地预测攻击 A 或攻击 B（提高阈值后，除了默认类别外，我们越来越少预测其他任何类别），而更多地预测“无攻击”，这导致真实类别为“无攻击”的误分类减少，但真实类别为攻击
    A 或攻击 B 的误分类增加。
- en: When the threshold is quite low, such as 0.2, then of those records where the
    true class is the default, only those with the highest predicted probability of
    the class being No Attack (about the top half) were predicted correctly.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当阈值非常低时，比如 0.2，那么在真实类别为默认类别的记录中，只有那些预测为“无攻击”（No Attack）类别的概率最高的记录（大约是前半部分）被正确预测。
- en: Once the threshold is set above about 0.6, nearly everything is predicted as
    the default class, so all cases where the ground truth is the default class are
    correct and all others are incorrect.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦阈值设置在 0.6 以上，几乎所有的预测都会是默认类别，因此所有真实类别为默认类别的情况都是正确的，而其他情况都是错误的。
- en: As expected, setting the thresholds higher means predicting the default class
    more often and missing less of these, though missing more of the other classes.
    Attack A and B are generally predicted correctly when using low thresholds, but
    mostly incorrectly when using higher thresholds.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，设置较高的阈值意味着更频繁地预测默认类别，错过这些的情况较少，尽管错过其他类别的情况增多。使用较低阈值时，攻击 A 和攻击 B 通常会被正确预测，而使用较高阈值时则大多预测错误。
- en: 'To tune the thresholds, we again use tune_threshold(), with code such as:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 为了调整阈值，我们再次使用 tune_threshold()，代码如下：
- en: '[PRE15]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This outputs: [0.0, 0.41257, 0.47142]. That is, it found a threshold of about
    0.413 for Attack A, and 0.471 for Attack B works best to optimize for the specified
    metric, macro F1 score in this case.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这输出： [0.0, 0.41257, 0.47142]。也就是说，它找到了大约 0.413 的阈值对于攻击 A 最为合适，而 0.471 对于攻击 B
    最适合，以优化指定的指标——在这种情况下为宏 F1 分数。
- en: 'Calling print_stats_proba() again, we get:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 再次调用 print_stats_proba()，我们得到：
- en: '[PRE16]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Which outputs:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 其输出为：
- en: '![](../Images/055dbacf61aea08921cc545007ada920.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/055dbacf61aea08921cc545007ada920.png)'
- en: The macro F1 score, using the thresholds discovered here, has improved from
    about 0.44 to 0.68 (results will vary slightly from run to run).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这里发现的阈值，宏 F1 分数从大约 0.44 提高到 0.68（结果会随着每次运行略有不同）。
- en: Get_predictions()
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: get_predictions()
- en: 'One additional API is provided which can be very convenient, get_predictions(),
    to get label predictions given a set of predictions and thresholds. This can be
    called such as:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一个额外的 API，非常方便，即 get_predictions()，用于根据一组预测和阈值获取标签预测。它的调用方式如下：
- en: '[PRE17]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Tests with Real Datasets
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用真实数据集进行测试
- en: Testing has been performed with many real datasets as well. Often the thresholds
    discovered work no better than the defaults, but more often they work noticeably
    better. One [notebook](https://github.com/Brett-Kennedy/ClassificationThresholdTuner/blob/main/notebooks/Real_Datasets.ipynb)
    is included on the github page covering a small number (four) real datasets. This
    was provided more to provide real examples of using the tool and the plots it
    generates (as opposed to the synthetic data used to explain the tool), but also
    gives some examples where the tool does, in fact, improve the F1 macro scores.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 还在许多真实数据集上进行了测试。通常情况下，发现的阈值与默认值差不多，但更常见的是，发现的阈值明显更有效。在 GitHub 页面上包括了一个[笔记本](https://github.com/Brett-Kennedy/ClassificationThresholdTuner/blob/main/notebooks/Real_Datasets.ipynb)，涵盖了少量（四个）真实数据集。这个笔记本的提供更多是为了展示如何使用该工具及其生成的图表（与解释工具时使用的合成数据不同），但也提供了一些例子，说明该工具确实能提高
    F1 宏观得分。
- en: 'To summarize these quickly, in terms of the thresholds discovered and the gain
    in F1 macro scores:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 简单总结一下，就发现的阈值和 F1 宏观得分的提升而言：
- en: 'Breast cancer: discovered an optimal threshold of 0.5465, which improved the
    macro F1 score from 0.928 to 0.953.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺癌：发现了一个最佳阈值 0.5465，令宏观 F1 分数从 0.928 提升到 0.953。
- en: 'Steel plates fault: discovered an optimal threshold of 0.451, which improved
    the macro F1 score from 0.788 to 0.956.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 钢板故障：发现了一个最佳阈值 0.451，令宏观 F1 分数从 0.788 提升到 0.956。
- en: Phenome discovered an optimal threshold of 0.444, which improved the macro F1
    score from 0.75 to 0.78.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Phenome 发现了一个最佳阈值 0.444，令宏观 F1 分数从 0.75 提升到 0.78。
- en: With the digits dataset, no improvement over the default was found, though may
    be with different classifiers or otherwise different conditions.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在数字数据集上，没有发现比默认阈值更好的结果，但使用不同的分类器或在其他不同条件下可能会有所不同。
- en: Installation
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装
- en: This project uses a [single .py file](https://github.com/Brett-Kennedy/ClassificationThresholdTuner/blob/main/threshold_tuner.py).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目使用了一个[单一 .py 文件](https://github.com/Brett-Kennedy/ClassificationThresholdTuner/blob/main/threshold_tuner.py)。
- en: 'This must be copied into your project and imported. For example:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这必须复制到你的项目中并进行导入。例如：
- en: '[PRE18]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Implications of Setting the Thresholds in multi-class problems
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在多类别问题中设置阈值的影响
- en: There are some subtle points about setting thresholds in multi-class settings,
    which may or may not be relevant for any given project. This may get more into
    the weeds than is necessary for your work, and this articles is already quite
    long, but a section is provided on the main github page to cover cases where this
    is relevant. In particular, thresholds set above 0.5 can behave slightly differently
    than those below 0.5.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类别设置中设置阈值有一些微妙的点，这些点可能与任何特定项目相关，也可能无关。这些细节可能会超出你的工作需求，而且这篇文章已经相当长了，但在主 GitHub
    页面上有一个部分专门讨论了这些相关情况。特别地，阈值设置在 0.5 以上时，与 0.5 以下的阈值相比，可能会有些不同的表现。
- en: Conclusions
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: While tuning the thresholds used for classification projects won’t always improve
    the quality of the model, it quite often will, and often significantly. This is
    easy enough to do, but using ClassificationThesholdTuner makes this a bit easier,
    and with multi-class classification, it can be particularly useful.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然调整分类项目中使用的阈值并不总是能提高模型的质量，但通常情况下确实能提高，而且提高的幅度往往很大。这很容易做到，但使用 ClassificationThresholdTuner
    可以让这个过程更轻松，特别是在多类别分类中，它可以特别有用。
- en: It also provides visualizations that explain the choices for threshold, which
    can be helpful, either in understanding and accepting the threshold(s) it discovers,
    or in selecting other thresholds to better match the goals of the project.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 它还提供了阈值选择的可视化图表，这对于理解和接受它发现的阈值，或选择其他阈值以更好地符合项目目标，都是很有帮助的。
- en: With multi-class classification, it can still take a bit of effort to understand
    well the effects of moving the thresholds, but this is much easier with tools
    such as this than without, and in many cases, simply tuning the thresholds and
    testing the results will be sufficient in any case.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类别分类中，理解调整阈值的效果可能仍然需要一些努力，但有了像这样的工具，理解起来比没有工具要容易得多，而且在许多情况下，简单地调整阈值并测试结果就足够了。
- en: All images are by the author
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 所有图片均由作者提供
