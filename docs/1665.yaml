- en: 'NLP: Text Summarization and Keyword Extraction on Property Rental Listings
    — Part 1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NLP：房地产出租房源的文本摘要与关键词提取——第1部分
- en: 原文：[https://towardsdatascience.com/nlp-text-summarization-and-keyword-extraction-on-property-rental-listings-part-1-f1b760cc7bbb?source=collection_archive---------1-----------------------#2024-07-08](https://towardsdatascience.com/nlp-text-summarization-and-keyword-extraction-on-property-rental-listings-part-1-f1b760cc7bbb?source=collection_archive---------1-----------------------#2024-07-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/nlp-text-summarization-and-keyword-extraction-on-property-rental-listings-part-1-f1b760cc7bbb?source=collection_archive---------1-----------------------#2024-07-08](https://towardsdatascience.com/nlp-text-summarization-and-keyword-extraction-on-property-rental-listings-part-1-f1b760cc7bbb?source=collection_archive---------1-----------------------#2024-07-08)
- en: A practical implementation of NLP techniques such as text summarization, NER,
    topic modeling, and text classification on rental listing data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在出租房源数据上实施NLP技术的实际应用，例如文本摘要、NER、主题建模和文本分类
- en: '[](https://medium.com/@kristiyanto_?source=post_page---byline--f1b760cc7bbb--------------------------------)[![Daniel
    Kristiyanto](../Images/b9e0fea509c17ef9507f5a9998f7ba5b.png)](https://medium.com/@kristiyanto_?source=post_page---byline--f1b760cc7bbb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f1b760cc7bbb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f1b760cc7bbb--------------------------------)
    [Daniel Kristiyanto](https://medium.com/@kristiyanto_?source=post_page---byline--f1b760cc7bbb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@kristiyanto_?source=post_page---byline--f1b760cc7bbb--------------------------------)[![Daniel
    Kristiyanto](../Images/b9e0fea509c17ef9507f5a9998f7ba5b.png)](https://medium.com/@kristiyanto_?source=post_page---byline--f1b760cc7bbb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f1b760cc7bbb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f1b760cc7bbb--------------------------------)
    [Daniel Kristiyanto](https://medium.com/@kristiyanto_?source=post_page---byline--f1b760cc7bbb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f1b760cc7bbb--------------------------------)
    ·10 min read·Jul 8, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f1b760cc7bbb--------------------------------)
    ·阅读时间10分钟·2024年7月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Natural Language Processing (NLP) can significantly enhance the analysis and
    usability of rental listing descriptions. In this exercise, we’ll explore the
    practical application of NLP techniques such as text summarization, Named Entity
    Recognition (NER), and topic modeling to extract insights and enrich the listing
    description on Airbnb listing data in Tokyo. Using publicly available data and
    tools like spaCy and SciKit-Learn, you can follow along, reproduce the results,
    or apply these techniques to your own text data with minimal adjustments. The
    codebase is available on [GitHub](https://github.com/kristiyanto/nlp_on_airbnb_dataset)
    for you to fork and experiment with.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）可以显著提升出租房源描述的分析和可用性。在本次实践中，我们将探索NLP技术的实际应用，例如文本摘要、命名实体识别（NER）和主题建模，以提取洞察并丰富东京Airbnb房源数据的描述。使用公开的可用数据和像spaCy与SciKit-Learn这样的工具，您可以跟随教程，复制结果，或将这些技术应用于自己的文本数据，只需进行最小的调整。代码库可在[GitHub](https://github.com/kristiyanto/nlp_on_airbnb_dataset)上获取，您可以进行分叉并进行实验。
- en: '![](../Images/264198623a04de117747b2f69f02975b.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/264198623a04de117747b2f69f02975b.png)'
- en: This article demonstrates the use of various NLP techniques to extract information
    from property listing description (left) data written by property owner, into
    more informative description (right). All images in this article are produced
    by the author. Codes and Jupyter notebook is available on [GitHub](https://github.com/kristiyanto/nlp_on_airbnb_dataset),
    and the data is available under creative common attribution from [*insideairbnb.com*](https://insideairbnb.com/get-the-data/).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文展示了使用多种NLP技术，从房产出租描述数据（左）中提取信息，并将其转化为更具信息量的描述（右）。文中的所有图片均由作者制作。代码和Jupyter笔记本可在[GitHub](https://github.com/kristiyanto/nlp_on_airbnb_dataset)上找到，数据可以在[*insideairbnb.com*](https://insideairbnb.com/get-the-data/)上获取，并遵循创意共享署名协议。
- en: '**Part 1 (this article) covers the basics:** the goal, the data and its preparation,
    and the methods used to extract keywords and text summaries using various techniques
    such as named entity recognition (NER), TF-IDF / sentence scoring, and Google’s
    T5 (Text-to-Text Transformer). We’ll also touch on leveraging these insights to
    improve user experience — serving suggestions included.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**第一部分（本文）涵盖基础内容：** 目标、数据及其准备工作，以及用于提取关键词和文本摘要的各种技术，如命名实体识别（NER）、TF-IDF / 句子评分、以及谷歌的T5（文本到文本的转换器）。我们还将涉及如何利用这些见解来提升用户体验
    — 包括服务建议。'
- en: '**Part 2 (coming soon)** **covers topic modeling and text prediction**: Part
    2 will demonstrate how to perform topic modeling on unlabeled data. This upcoming
    article will discuss techniques like clustering to uncover hidden themes and building
    a predictive model to classify property rentals based on their categories and
    themes.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**第二部分（即将发布）** **涵盖主题建模和文本预测**：第二部分将展示如何在无标签数据上执行主题建模。即将发布的文章将讨论诸如聚类等技术，帮助揭示隐藏的主题，并构建一个预测模型，以根据房源类别和主题对租赁房源进行分类。'
- en: Goal
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标
- en: 'The task is straightforward:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 任务很简单：
- en: '**Given an example input:** The rental description'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**给定的示例输入：** 租赁描述'
- en: '**Generate output:**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成输出：**'
- en: '**Keywords:** “*commercial street*”, “*stores*”, or “*near station*”'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键词：** “*商业街*”、”*商店*”、或 “*靠近车站*”'
- en: Keywords help visualize data, uncover themes, identify similarities, and improve
    search functionality on the front end. Suggestions to serve these keywords are
    included at the bottom of this article.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关键词有助于可视化数据、揭示主题、识别相似性，并改善前端的搜索功能。有关如何使用这些关键词的建议，请参见本文底部。
- en: '**Summary:** A sentence or two, roughly about 80 characters.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摘要：** 一到两句话，约80个字符。'
- en: Summaries provide concise information, enhancing the user experience by quickly
    conveying the most essential aspects of a listing.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 摘要提供简洁的信息，通过快速传达列表中的最重要方面，提升用户体验。
- en: '**Theme/Topic:** “*Excellent Access*”, “*Family Friendly*.”'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主题/话题：** “*优越的交通连接*”、”*适合家庭入住*”'
- en: Categorizing listings that share the same theme can serve as a recommender system,
    aiding users in finding properties that match their preferences. Unlike individual
    keywords, these themes can cover a group of multiple keywords (kitchen, desk,
    queen bed, long-term => “Digital-Nomad Friendly”). We will deep-dive this in Part
    2 (upcoming article).
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对共享相同主题的房源进行分类可以作为推荐系统，帮助用户找到符合他们偏好的房源。与单个关键词不同，这些主题可以涵盖多个关键词（如厨房、桌子、单人床、长期出租
    => “数字游牧者友好”）。我们将在第二部分（即将发布的文章）深入讨论这个问题。
- en: '**Chapters:**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**章节：**'
- en: '**Data and Preparation**'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据与准备**'
- en: Getting the data, cleaning, custom lemma
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 获取数据、清理数据、定制词形还原
- en: '**Text Summarization**'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文本摘要**'
- en: TFIDF/sentence scoring, Deep-Learning, LLM (T5), evaluation
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: TFIDF/句子评分、深度学习、LLM（T5）、评估
- en: '**Keyword Extraction using NER**'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用NER提取关键词**'
- en: Regex, Matcher, Deep-Learning
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正则表达式、匹配器、深度学习
- en: '**Serving Suggestion**'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**服务建议**'
- en: 1\. Data and Preparation
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 数据与准备
- en: Our dataset consists of rental listing descriptions sourced from [*insideairbnb.com*](https://insideairbnb.com/get-the-data/)*,*
    licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).
    We focus on the text written by property owners. The data contains nearly 15,000
    rental descriptions, mainly in English. Records written in Japanese (surprisingly,
    only a handful of them!) were removed as part of the data cleaning task, which
    also involved removing duplicates and HTML artifacts left by the scraper. Due
    to a lot of data deduplication, which could be the byproduct of the web scraper,
    or possibly even more complex issues (such as owners posting multiple identical
    listings), data cleaning removed about half of the original size.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集由来自[*insideairbnb.com*](https://insideairbnb.com/get-the-data/)的租赁房源描述组成，遵循[创意共享署名
    4.0 国际许可证](http://creativecommons.org/licenses/by/4.0/)。我们专注于物业所有者撰写的文本。数据包含近15,000个租赁描述，主要为英文。用日文书写的记录（令人惊讶的是，只有少数几条！）在数据清理过程中已被移除，数据清理还包括去除重复记录和刮取器留下的HTML残余。由于大量数据去重，可能是由于网络抓取工具的副产品，或者可能是更复杂的问题（例如，房东发布了多个相同的房源），数据清理使得原始数据量减少了约一半。
- en: 1a. spaCy Pipeline
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1a. spaCy 流水线
- en: 'Once the data is clean, we can start building the spaCy pipeline. We can begin
    with a blank slate or use a pre-trained model like en_core_web_sm to process documents
    in English. This model includes a robust pipeline with:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据清洗完成，我们就可以开始构建spaCy管道。我们可以从一个空白模板开始，或者使用像en_core_web_sm这样的预训练模型来处理英文文档。这个模型包含一个强大的管道，包含：
- en: '**Tokenization:** Splitting text into words, punctuation marks, etc.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分词（Tokenization）：** 将文本拆分为单词、标点符号等。'
- en: '**Part-of-Speech Tagging:** Tagging words as nouns, verbs, etc.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词性标注（Part-of-Speech Tagging）：** 将单词标记为名词、动词等。'
- en: '**Dependency Parsing:** Identifying relationships between words.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依存句法分析（Dependency Parsing）：** 识别单词之间的关系。'
- en: '**Sentencizer**: Breaking down the documents into sentences.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**句子分割器（Sentencizer）：** 将文档拆分为句子。'
- en: '**Lemmatization:** Reducing words to their base forms (e.g., seeing, see, saw,
    seen).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词形还原（Lemmatization）：** 将词汇简化为其基本形式（例如，seeing、see、saw、seen）。'
- en: '**Attribute Ruler:** Adding, removing, or changing token attributes.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性规则（Attribute Ruler）：** 添加、删除或更改标记的属性。'
- en: '**Named Entity Recognition:** Identifying categories of named entities (persons,
    locations, etc.).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命名实体识别（NER）：** 识别命名实体的类别（人名、地名等）。'
- en: 1b. Custom Lemmatization
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1b. 自定义词形还原
- en: Even with a battle-tested pipeline like en_core_web_sm, adjustments are often
    needed to cover specific use cases. For example, abbreviations commonly used in
    the rental industry (e.g., br for bedroom, apt for apartment, st for street) could
    be introduced into the pipeline through custom lemmatization. To evaluate this,
    we can count the number of `token.lemma_` between pipeline with and without the
    custom lemma. If needed, other more robust pre-made pipeline, such as en_core_web_md
    (medium), or en_core_web_lg (large), are also available.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是像en_core_web_sm这样的经过严格测试的管道，通常也需要进行调整以涵盖特定的用例。例如，租赁行业中常用的缩写（例如，br代表卧室，apt代表公寓，st代表街道）可以通过自定义词形还原引入到管道中。为了评估这一点，我们可以比较在有和没有自定义词形还原的管道中，`token.lemma_`的数量。如果需要，还可以使用其他更强大的预制管道，如en_core_web_md（中型）或en_core_web_lg（大型）。
- en: In production-level projects, a more thorough list is needed and more rigorous
    data cleaning might be required. For example, emojis and emoji-like symbols are
    frequently included in culturally influenced writing, like by Japanese users.
    These symbols can introduce noise and require specific handling, such as removal
    or transformation. Other data pre-processing, such as a more robust proper sentence
    boundary detector may also be necessary to address sentences with missing spaces,
    such as *“This is a sentence.This is too. And also this.and this. But, no, this
    Next.js is a valid term and not two sentences!”*
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产级项目中，需要更全面的列表，可能还需要更严格的数据清洗。例如，表情符号和类似表情符号的符号经常出现在受文化影响的写作中，如日本用户的写作中。这些符号可能会引入噪音，需要特定的处理，如删除或转换。其他数据预处理，如更强大的句子边界检测器，也可能是必要的，以处理缺少空格的句子，例如*“这是一个句子。这也是。还有这个。还有这个。但是，不，这个Next.js是一个有效的术语，而不是两个句子！”*
- en: 2\. Text Summarization
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 文本摘要
- en: Navigating rental options in Tokyo can be overwhelming. Each listing promises
    to be the ideal home. Still, the data suggests that the property descriptions
    often fall short — they can be overly long, frustratingly brief, or muddled with
    irrelevant details; this is why text summarization can come in handy.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在东京选择租赁选项可能让人不知所措。每个房源都声称是理想的家。然而，数据显示，房产描述常常不尽如人意——它们可能过于冗长，令人沮丧地简短，或者被不相关的细节弄得杂乱无章；这就是为什么文本摘要技术非常有用的原因。
- en: '![](../Images/a24a755fb9b1d8b693867f92b9a33236.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a24a755fb9b1d8b693867f92b9a33236.png)'
- en: Sentence scoring to select the most informative sentences as the summary (right)
    from the description (left).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 句子评分，以选择最具信息量的句子作为摘要（右图），来自描述（左图）。
- en: '2a. Level: Easy — TF-IDF'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2a. 难度级别：简单 — TF-IDF
- en: One typical approach to text summarization involves leveraging a technique called
    TF-IDF (Term Frequency-Inverse Document Frequency). TF-IDF considers both how
    frequently a word appears in a specific document (the rental listing) and how
    uncommon it is across the entire dataset of listings or corpus. This technique
    is also helpful for various text analysis tasks, such as indexing, similarity
    detection, and clustering (which we will explore in Part 2).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一种典型的文本摘要方法是使用TF-IDF（词频-逆文档频率）技术。TF-IDF同时考虑一个单词在特定文档（例如租赁列表）中的出现频率以及它在整个数据集或语料库中出现的稀有程度。这项技术对于各种文本分析任务也非常有用，如索引、相似度检测和聚类（我们将在第二部分中探讨）。
- en: Calculating the sentence ranking based on the relevance of detected keywords.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 根据检测到的关键词的相关性计算句子的排名。
- en: Another variation of the technique is sentence scoring based on word co-occurrence.
    Like TF-IDF, this method calculates scores by comparing word occurrences within
    the document. This approach is fast and easy and requires no additional tools
    or even awareness of other documents. You can even do this on the fly at the front
    end using typescript, although it is not recommended.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术的另一种变体是基于词共现的句子评分。与 TF-IDF 类似，这种方法通过比较文档中的单词出现情况来计算得分。该方法快速且简单，不需要额外的工具或其他文档的意识。即使在前端使用
    TypeScript，你也可以随时执行此操作，尽管不推荐这样做。
- en: 'However, *extractive summarization* techniques like these have a pitfall: they
    only find the best sentence in the document, which means that typos or other issues
    in the chosen sentence will appear in the summary. These typos also affect the
    scoring, making this model less forgiving of mistakes and important information
    not included in the selected sentence (or sentences) might be missed.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，像这样的*抽取式摘要*技术有一个缺陷：它们只找到文档中的最佳句子，这意味着所选句子中的拼写错误或其他问题会出现在摘要中。这些拼写错误还会影响评分，使得该模型对错误不够宽容，而没有包括在所选句子（或句子）中的重要信息可能会被遗漏。
- en: '2b. Level: Intermediate — Deep Learning'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2b. 级别：中级 — 深度学习
- en: Beyond frequency-based methods, we can leverage the power of deep learning for
    text summarization. Sequence-to-sequence (Seq2Seq) models are a neural network
    architecture designed to translate sequences from one form to another. In text
    summarization tasks, these models act like complex translators.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基于频率的方法，我们还可以利用深度学习的力量进行文本摘要。序列到序列（Seq2Seq）模型是一种神经网络架构，旨在将序列从一种形式转换为另一种形式。在文本摘要任务中，这些模型充当复杂的翻译器。
- en: 'A Seq2Seq model typically consists of two parts: an encoder and a decoder.
    The encoder processes the entire input text, capturing its meaning and structure.
    This information is then compressed into a hidden representation. Then, the decoder
    takes this hidden representation from the encoder to generate a new sequence —
    the text summary. During training, the decoder learns to translate the encoded
    representation that captures the key points of the original text. Unlike extractive
    methods, these models perform *abstractive summarization:* generating summaries
    in their own words rather than extracting sentences directly from the text.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Seq2Seq 模型通常由两部分组成：编码器和解码器。编码器处理整个输入文本，捕捉其含义和结构。然后，这些信息被压缩成一个隐藏的表示。接下来，解码器使用来自编码器的隐藏表示生成新的序列——文本摘要。在训练过程中，解码器学习如何将捕捉原始文本关键信息的编码表示进行转换。与抽取式方法不同，这些模型执行*抽象式摘要*：用自己的话生成摘要，而不是直接从文本中提取句子。
- en: '2c. Level: Advanced — Pre-Trained Language Models'
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2c. 级别：高级 — 预训练语言模型
- en: For abstractive summarization, consider using T5 (Text-To-Text Transfer Transformer)
    models. While the `t5-small` offers a good starting point, you might achieve superior
    results with a larger model like `t5-base` or `t5-large`. Be aware that larger
    models may require more computational resources and take longer to run.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于抽象式摘要，可以考虑使用 T5（Text-To-Text Transfer Transformer）模型。虽然 `t5-small` 提供了一个不错的起点，但你可能会通过更大的模型，如
    `t5-base` 或 `t5-large`，获得更好的结果。请注意，较大的模型可能需要更多的计算资源，并且运行时间较长。
- en: '![](../Images/5fa0b7994b8c847d53c02bf4cd7aba2e.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5fa0b7994b8c847d53c02bf4cd7aba2e.png)'
- en: LLMs can summarize documents in a creative way (going beyond just copying sentences),
    but getting the best results might involve additional steps before, during, and
    after the summarization process, including proper prompt engineering.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）能够以富有创意的方式进行文档总结（不仅仅是复制句子），但要获得最佳效果，可能需要在摘要过程中、摘要前后进行额外的步骤，包括适当的提示工程。
- en: Pre-trained language models like T5 (Text-To-Text Transfer Transformer) or BERT
    (Bidirectional Encoder Representations from Transformers) can significantly enhance
    summarization for those with the resources and setup capabilities. However, while
    these models can be effective for large text, they might be overkill for this
    specific use case. Not only does it require more setup to function optimally,
    but it also includes the need for prompt engineering (pre-processing), retraining
    or fine-tuning, and post-processing (such as grammar, text capitalization, or
    even fact-checking and sanity check) to guide the model toward the desired output.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 像T5（Text-To-Text Transfer Transformer）或BERT（Bidirectional Encoder Representations
    from Transformers）这样的预训练语言模型，可以显著提升摘要效果，适用于那些拥有资源和设置能力的人。然而，尽管这些模型对于大文本有效，但它们可能对于这个特定的用例来说有些过于复杂。它不仅需要更多的设置来发挥最佳效果，还包括提示工程（预处理）、重新训练或微调，以及后处理（如语法、文本大写，甚至事实检查和合理性检查），以引导模型达到期望的输出。
- en: 2.d Evaluating Text Summarization
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.d 评估文本摘要
- en: '![](../Images/696b776edf6bd88cb54cc7a5d59a6675.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/696b776edf6bd88cb54cc7a5d59a6675.png)'
- en: Extractive (left) versus Abstractive (right) text summarization. Given that
    the quality of summaries is subjective, the winner is not always definitive. Comparison
    gets even more complex by factoring the efforts, cost and computing power needed.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 提取式（左）与抽象式（右）文本摘要。鉴于摘要质量是主观的，哪种摘要更优并不总是明确的。考虑到所需的努力、成本和计算能力，比较变得更加复杂。
- en: As seen from the picture above, when comparing “simple” model using TFIDF versus
    complex model using LLM, the winner isn’t always clear. Evaluating the quality
    of a text summarization system is a complicated challenge. Unlike tasks with a
    single, definitive answer, there’s no single perfect summary for a given text.
    Humans can prioritize different aspects of the original content, which further
    makes it hard to design automatic metrics that perfectly align with human judgment.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图片可以看到，当比较使用TFIDF的“简单”模型与使用LLM的复杂模型时，哪种模型更优并不总是显而易见的。评估文本摘要系统的质量是一个复杂的挑战。与有明确单一答案的任务不同，对于给定文本，并没有一个完美的摘要。人类可以优先考虑原始内容的不同方面，这使得设计与人类判断完全一致的自动化评估指标变得更加困难。
- en: Evaluation metrics like ROUGE (Recall-Oriented Understudy for Gisting Evaluation)
    attempt to do just this. By comparing the overlaps between n-grams (sequences
    of words) between generated summaries and human-written summaries, ROUGE systematically
    scores the quality of the summaries. This method relies on a collection of human-written
    summaries as a baseline for evaluation, which often not available.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 像ROUGE（召回导向总结评估指标）这样的评估指标旨在实现这一点。通过比较生成的摘要与人工编写的摘要之间的n-gram（词组序列）重叠，ROUGE系统地评分摘要的质量。该方法依赖于一组人工编写的摘要作为评估的基准，但这些人工摘要通常并不总是可用的。
- en: 3\. Keyword Extraction Using Named Entity Recognition (NER)
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 使用命名实体识别（NER）进行关键词提取
- en: While summaries are helpful, keywords have different purposes. Keywords capture
    the most essential aspects that potential renters might be looking for. To extract
    keywords, we can use NLP techniques such as Named Entity Recognition (NER). This
    process goes beyond just identifying frequent words. We can extract critical information
    by considering factors like word co-occurrence and relevance to the domain of
    rental listings. This information can be a single word, such as ‘luxurious’ (adjective),
    ‘Ginza’ (location), or a phrase like ‘quiet environment’ (noun phrases) or ‘near
    to Shinjuku’ (proximity).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管摘要很有帮助，但关键词有不同的用途。关键词捕捉了潜在租客可能关注的最关键方面。为了提取关键词，我们可以使用NLP技术，例如命名实体识别（NER）。这个过程不仅仅是识别频繁出现的词汇。通过考虑诸如词语共现和与租赁列表领域相关性等因素，我们可以提取出关键信息。这些信息可以是单个词，例如‘豪华的’（形容词）、‘银座’（地点），或者像‘安静的环境’（名词短语）或‘靠近新宿’（接近性）这样的短语。
- en: '![](../Images/e5d3925865319e0c06d69ec78b94d253.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5d3925865319e0c06d69ec78b94d253.png)'
- en: 'Evaluating NER: SpaCy’s built-in NER performs well, but certain entity types
    might require additional training data for optimal accuracy. (NER stands for Named
    Entity Recognition, GPE: Geo Political Entity)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 评估NER：SpaCy内置的命名实体识别（NER）表现良好，但某些实体类型可能需要额外的训练数据以达到最佳准确度。（NER代表命名实体识别，GPE：地理政治实体）
- en: '3a. Level: Easy — Regex'
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3a. 难度：简单 — 正则表达式
- en: The ‘find’ function in string operations, along with regular expressions, can
    do the job of finding keywords. However, this approach requires an exhaustive
    list of words and patterns, which is sometimes not practical. If an exhaustive
    list of keywords to look for is available (like stock exchange abbreviations for
    finance-related projects), regex might be the simplest way to do it.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串操作中的“find”函数，加上正则表达式，可以完成关键词查找的工作。然而，这种方法需要一个详尽的单词和模式列表，而这在某些情况下并不实际。如果有一个详尽的关键词列表可供查找（例如，金融相关项目中的股票交易所缩写），正则表达式可能是最简单的方式。
- en: '3b. Level: Intermediate — The Matcher'
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3b. 水平：中级 — 匹配器
- en: While regular expressions can be used for simple keyword extraction, the need
    for extensive lists of rules makes it hard to cover all bases. Fortunately, most
    NLP tools have this NER capability that is out of the box. For example, Natural
    Language Toolkit (NLTK) has Named Entity Chunkers, and spaCy has Matcher.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然正则表达式可以用于简单的关键词提取，但由于需要大量的规则列表，覆盖所有情况变得非常困难。幸运的是，大多数自然语言处理（NLP）工具都具备开箱即用的命名实体识别（NER）功能。例如，Natural
    Language Toolkit（NLTK）有命名实体分块器，而spaCy则有匹配器（Matcher）。
- en: Matcher allows you to define patterns based on linguistic features like part-of-speech
    tags or specific keywords. These patterns can be matched against the rental descriptions
    to identify relevant keywords and phrases. This approach captures single words
    (like, Tokyo) and meaningful phrases (like, beautiful house) that better represent
    the selling points of a property.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配器允许你根据语言特征，如词性标签或特定关键词，定义模式。这些模式可以与租赁描述进行匹配，从而识别相关的关键词和短语。这种方法能够捕捉单个词（如东京）和有意义的短语（如美丽的房子），这些更能代表房产的卖点。
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '3c. Level: Advanced — Deep Learning-Based Matcher'
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3c. 水平：高级 — 基于深度学习的匹配器
- en: Even with Matcher, some terms may not be captured by rule-based matching due
    to the context of the words in the sentence. For example, the Matcher might miss
    a term like ‘a stone’s throw away from Ueno Park’ since it won’t pass any predefined
    patterns, or mistake “Shinjuku Kabukicho” as a person (it’s a neighborhood, or
    LOC).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用匹配器，一些术语也可能由于句子中单词的上下文未被规则匹配捕获。例如，匹配器可能会漏掉像“离上野公园一箭之遥”这样的术语，因为它无法通过任何预定义的模式，或者将“新宿歌舞伎町”误认为是一个人名（它是一个区域，或者是地点（LOC））。
- en: In such cases, deep-learning-based approaches can be more effective. By training
    on a large corpus of rental listing with associated keywords these model learn
    the semantic relationships between words. This makes this method more adaptable
    to evolving language use and can uncover hidden insights.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，基于深度学习的方法可能更为有效。通过在包含相关关键词的大量租赁列表上进行训练，这些模型能够学习单词之间的语义关系。这使得这种方法更能适应不断变化的语言使用，并能够揭示潜在的洞察。
- en: 'Using spaCy, performing deep-learning-based NER is straightforward. However,
    the major building block for this method is usually the availability of the labeled
    training data, as also the case for this exercise. The label is a pair of the
    target terms and the entity name (example: ‘a stone throw away’ is a noun phrase
    — or as shown in picture: Shinjuku Kabukicho is a LOC, not a person), formatted
    in a certain way. Unlike rule-based where we describe the terms into noun, location,
    and others from the built-in functionality, data exploration or domain expert
    are needed to discover the target terms that we want to identify.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用spaCy进行基于深度学习的NER非常简便。然而，这种方法的主要构建块通常是标注的训练数据，正如本次练习中的情况一样。标签是目标术语和实体名称的配对（例如：“a
    stone throw away”是名词短语——或者如图所示：新宿歌舞伎町是一个地点（LOC），而非人名），并以特定的方式格式化。与基于规则的方法不同，基于规则的方法是通过内置功能将术语描述为名词、地点等，而在此方法中，需要数据探索或领域专家来发现我们想要识别的目标术语。
- en: Part 2 of the article will discuss this technique of discovering themes or labels
    from the data for topic modeling using clustering, bootstrapping, and other methods.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的第二部分将讨论使用聚类、引导法和其他方法从数据中发现主题或标签的技术，以进行主题建模。
- en: 4\. Serving Suggestions
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 食用建议
- en: '**Extracted keywords** are valuable for both backend and frontend applications.
    We can use them for various downstream analyses, such as theme and topic exploration
    (discussed in Part 2). On the front end, these keywords can empower users to find
    listings with similar characteristics — think of them like hashtags on Instagram
    or Twitter (but automatic!). You can also highlight and display these keywords
    or make them clickable. For example, named entity recognition (NER) can identify
    locations like “Iidabashi” or “Asakusa.” When a user hovers over these keywords,
    a pop-up can display relevant information about those places.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**提取的关键词**对后台和前端应用都非常有价值。我们可以利用它们进行各种后续分析，如主题和话题探索（将在第二部分讨论）。在前端，这些关键词可以帮助用户找到具有相似特征的列表——可以将它们视为Instagram或Twitter上的标签（但这是自动的！）。你还可以突出显示这些关键词，或者让它们成为可点击的链接。例如，命名实体识别（NER）可以识别出诸如“Iidabashi”或“Asakusa”这样的地点。当用户将鼠标悬停在这些关键词上时，弹出窗口可以显示有关这些地点的相关信息。'
- en: '**Summaries** provide a concise overview of the listing, making them ideal
    for quickly grasping the key details, or for mobile displays.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**摘要**提供了列表的简洁概述，非常适合快速掌握关键信息，或用于移动设备显示。'
- en: '![](../Images/7edfd94e96e80f98979310e6250eedf4.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7edfd94e96e80f98979310e6250eedf4.png)'
- en: Keywords and text summaries can enrich user experience. In this example, we
    use the extracted text summary to provide quick overview of the listing description.
    The select keywords (example, LOC) are also used to provide more context of the
    listing description. This process can be done either at the back end (for faster
    load), or at the front end (for more convenience).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词和文本摘要可以丰富用户体验。在这个例子中，我们使用提取的文本摘要来快速概览列表描述。选择的关键词（例如LOC）也被用来提供更多列表描述的背景。这一过程可以在后台进行（以提高加载速度），也可以在前端进行（以提高便利性）。
- en: Moving Forward
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向前迈进
- en: In this article, we demonstrated the practical implementation of various NLP
    techniques, such as text summarization and named entity recognition (NER) on a
    rental listing dataset. These techniques can significantly improve user experience
    by providing concise, informative, and easily searchable rental listings.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们展示了各种自然语言处理（NLP）技术的实际应用，如文本摘要和命名实体识别（NER）在租赁列表数据集上的应用。这些技术通过提供简洁、信息丰富且易于搜索的租赁列表，能够显著改善用户体验。
- en: In the upcoming article (Part 2), we will use methods like clustering to discover
    hidden themes and labels. This will allow us to build a robust model that can
    act as a recommender engine. We will also explore advanced NLP techniques like
    topic modeling and text classification further to enhance the analysis and usability
    of rental listing descriptions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的文章（第二部分）中，我们将使用聚类等方法来发现隐藏的主题和标签。这将使我们能够构建一个强大的模型，充当推荐引擎。我们还将进一步探索像主题建模和文本分类等高级NLP技术，以增强租赁列表描述的分析和可用性。
- en: 以上です★これからもうよろしくおねがいします☆また今度｡
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以上です★これからもうよろしくおねがいします☆また今度｡
- en: '**Note:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：'
- en: 1) Github Repository:** [**https://github.com/kristiyanto/nlp_on_airbnb_dataset**](https://github.com/kristiyanto/nlp_on_airbnb_dataset)
    **2) Data (**[**Creative Commons Attribution 4.0 International License**](http://creativecommons.org/licenses/by/4.0/)**):**
    [**https://insideairbnb.com/get-the-data/**](https://insideairbnb.com/get-the-data/)
    **3) All images in this article are produced by the author.**
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 1) Github 仓库：**[**https://github.com/kristiyanto/nlp_on_airbnb_dataset**](https://github.com/kristiyanto/nlp_on_airbnb_dataset)
    **2) 数据 (**[**创作共用 4.0 国际许可协议**](http://creativecommons.org/licenses/by/4.0/)**)：**
    [**https://insideairbnb.com/get-the-data/**](https://insideairbnb.com/get-the-data/)
    **3) 本文中的所有图片由作者制作。**
