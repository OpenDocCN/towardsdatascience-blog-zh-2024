- en: Why Most Cross-Validation Visualizations Are Wrong (And How to Fix Them)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/why-most-cross-validation-visualizations-are-wrong-and-how-to-fix-them-bdbbba74e263?source=collection_archive---------0-----------------------#2024-11-16](https://towardsdatascience.com/why-most-cross-validation-visualizations-are-wrong-and-how-to-fix-them-bdbbba74e263?source=collection_archive---------0-----------------------#2024-11-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: BETTER ML VISUALS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stop using moving boxes!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--bdbbba74e263--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--bdbbba74e263--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bdbbba74e263--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bdbbba74e263--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--bdbbba74e263--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bdbbba74e263--------------------------------)
    ·10 min read·Nov 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: 'You know those cross-validation diagrams in every data science tutorial? The
    ones showing boxes in different colors moving around to explain how we split data
    for training and testing? Like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7310960c11e4e979706ce2dea8eedfbf.png)'
  prefs: []
  type: TYPE_IMG
- en: Have you seen that? Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve seen them too — one too many times. These diagrams are common — they’ve
    become the go-to way to explain cross-validation. But here’s something interesting
    I noticed while looking at them as both a designer and data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at a yellow box moving to different spots, our brain automatically
    sees it as one box moving around.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s just how our brains work — when we see something similar move to a new
    spot, we think it’s the same thing. (This is actually why cartoons and animations
    work!)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/293776fe285e9c1651b9ca1c65706411.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You might think the animated version is better, but now you can’t help following
    the blue box and starting to forget that this should represent how cross-validation
    works. Source: [Wikipedia](https://commons.wikimedia.org/wiki/File:LOOCV.gif)'
  prefs: []
  type: TYPE_NORMAL
- en: 'But here’s the thing: In these diagrams, each box in a new position is **supposed
    to show a different chunk of data**. So while our brain naturally wants to track
    the boxes, we have to tell our brain, “No, no, that’s not one box moving — they’re
    different boxes!” It’s like we’re fighting against how our brain naturally works,
    just to understand what the diagram means.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at this as someone who works with both design and data, I started thinking:
    maybe there’s a better way? What if we could show cross-validation in a way that
    actually works with how our brain processes information?'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a213cf03718d755a88bb08470f7d3abb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  prefs: []
  type: TYPE_NORMAL
- en: What’s Cross-Validation Really About?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cross-validation is about making sure machine learning models work well in the
    real world. Instead of testing a model once, we test it multiple times using different
    parts of our data. This helps us understand how the model will perform with new,
    unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: We take our data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divide it into groups
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use some groups for training, others for testing
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat this process with different groupings
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The goal is to get a reliable understanding of our model’s performance. That’s
    the core idea — simple and practical.
  prefs: []
  type: TYPE_NORMAL
- en: '(Note: We’ll discuss different validation techniques and their applications
    in another article. For now, let’s focus on understanding the basic concept and
    why current visualization methods need improvement.)'
  prefs: []
  type: TYPE_NORMAL
- en: What’s Wrong with Current Cross-validation Diagrams?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open up any machine learning tutorial, and you’ll probably see these types
    of diagrams:'
  prefs: []
  type: TYPE_NORMAL
- en: Long boxes split into different sections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arrows showing parts moving around
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different colors showing training and testing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple versions of the same diagram side by side
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/11bdeccff9e5426a2f8669b317c7faab.png)'
  prefs: []
  type: TYPE_IMG
- en: Currently, this is similar to the first image you’ll see if you look up “Cross
    Validation.” (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the issues with such diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Not Everyone Sees Colors the Same Way**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Colors create practical problems when showing data splits. Some people can’t
    differentiate certain colors, while others may not see colors at all. The visualization
    fails when printed in black and white or viewed on different screens where colors
    vary. Using color as the primary way to distinguish data parts means some people
    miss important information due to their color perception.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e3c7aea8baea654253fbedde5e3dd811.png)'
  prefs: []
  type: TYPE_IMG
- en: Not everyone see the same colors. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Colors Make Things Harder to Remember**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another thing about colors is that it might look like they help explain things,
    but they actually create extra work for our brain. When we use different colors
    for different parts of the data, we have to actively remember what each color
    represents. This becomes a memory task instead of helping us understand the actual
    concept. The connection between colors and data splits isn’t natural or obvious
    — it’s something we have to learn and keep track of while trying to understand
    cross-validation itself.
  prefs: []
  type: TYPE_NORMAL
- en: Our brain doesn’t naturally connect colors with data splits.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e4690d7c50d8de5d8855975b40cd0424.png)'
  prefs: []
  type: TYPE_IMG
- en: These are the colors we used in the previous diagrams. Why original dataset
    is green? Then split into blue and red?
  prefs: []
  type: TYPE_NORMAL
- en: '**Too Much Information at Once**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The current diagrams also suffer from information overload. They attempt to
    display the entire cross-validation process in a single visualization, which creates
    unnecessary complexity. Multiple arrows, extensive labeling, all competing for
    attention. When we try to show every aspect of the process at the same time, we
    make it harder to focus on understanding each individual part. Instead of clarifying
    the concept, this approach adds an extra layer of complexity that we need to decode
    first.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3860f294e42aad31e7ef34a9bdaf9ccf.png)'
  prefs: []
  type: TYPE_IMG
- en: Too many labels, too many colors, too many arrows and it is too hard to focus.
  prefs: []
  type: TYPE_NORMAL
- en: Movement That Misleads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Movement in these diagrams creates a fundamental misunderstanding of how cross-validation
    actually works. When we show arrows and flowing elements, we’re suggesting a sequential
    process that doesn’t exist in reality. Cross-validation splits don’t need to happen
    in any particular order — the order of splits doesn’t affect the results at all.
  prefs: []
  type: TYPE_NORMAL
- en: These diagrams also give the wrong impression that data physically moves during
    cross-validation. In reality, we’re simply selecting different rows from our original
    dataset each time. The data stays exactly where it is, and we just change which
    rows we use for testing in each split. When diagrams show data flowing between
    splits, they add unnecessary complexity to what should be a straightforward process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d8fa4ea0c53cc2aa618406d0c99e6f09.png)'
  prefs: []
  type: TYPE_IMG
- en: While diagrams typically flow from top to bottom, it’s hard to follow the sequence
    of operations. The timing of model training and the calculation results remain
    unclear. When does the training happen? What results come from each calculation?
  prefs: []
  type: TYPE_NORMAL
- en: What We Need Instead
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need diagrams that:'
  prefs: []
  type: TYPE_NORMAL
- en: Don’t just rely on colors to explain things
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Show information in clear, separate chunks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make it obvious that different test groups are independent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t use unnecessary arrows and movement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s fix this. Instead of trying to make our brains work differently, why don’t
    we create something that feels natural to look at?
  prefs: []
  type: TYPE_NORMAL
- en: A Better Way to Visualize Cross-validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s try something different. First, this is how data looks like to most people
    — rows and columns of numbers with index.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/08da329b59c04831295fa503a37cb6e4.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the common dataset I used for [my articles on classification algorithms](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c).
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by that structure, here’s a diagram that make more sense.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e1633734844646b0c9a447fea09fde60.png)'
  prefs: []
  type: TYPE_IMG
- en: Simpler but clear depiction of cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s why this design makes more sense logically:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Data Structure:** It matches how data actually works in cross-validation.
    In practice, we’re selecting different portions of our dataset — not moving data
    around. Each column shows exactly which splits we’re using for testing each time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Independent Splits:** Each split explicitly shows it’s different data. Unlike
    moving boxes that might make you think “it’s the same test set moving around,”
    this shows that Split 2 is using completely different data from Split 1\. This
    matches what’s actually happening in your code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data Conservation:** By keeping the column height the same throughout all
    folds, we’re showing an important rule of cross-validation: you always use your
    entire dataset. Some portions for testing, the rest for training. Every piece
    of data gets used, nothing is left out.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Complete Coverage:** Looking left to right, you can easily check an important
    cross-validation principle: every portion of your dataset will be used as test
    data exactly once.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Three-Fold Simplicity:** We specifically use 3-fold cross-validation here
    because:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. It clearly demonstrates the key concepts without overwhelming detail
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b. The pattern is easy to follow: three distinct folds, three test sets. Simple
    enough to mentally track which portions are being used for training vs testing
    in each fold'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Perfect for educational purposes — adding more folds (like 5 or 10) would
    make the visualization more cluttered without adding conceptual value
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '(Note: While 5-fold or 10-fold cross-validation might be more common in practice,
    3-fold serves perfectly to illustrate the core concepts of the technique.)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adding Indices for Clarity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While the concept above is correct, thinking about actual row indices makes
    it even clearer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/00368eec59269afee2665564b9803290.png)'
  prefs: []
  type: TYPE_IMG
- en: An enhanced variation with subtle index, making it easier to see which part
    of the dataset each fold belong to. The dashed lines help in separating the indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some reasons of improvements of this visual:'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of just “different portions,” we can see that Fold 1 tests on rows 1–4,
    Fold 2 on rows 5–7, and Fold 3 on rows 8–10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“Complete coverage” becomes more concrete: rows 1–10 each appear exactly once
    in test sets'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training sets are explicit: when testing on rows 1–4, we’re training on rows
    5–10'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data independence is obvious: test sets use different row ranges (1–3, 4–6,
    7–10)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This index-based view doesn’t change the concepts — it just makes them more
    concrete and easier to implement in code. Whether you think about it as portions
    or specific row numbers, the key principles remain the same: independent folds,
    complete coverage, and using all your data.'
  prefs: []
  type: TYPE_NORMAL
- en: Adding Some Colors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you feel the black-and-white version is too plain, this is also another
    acceptable options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cb7cf250b229c7400f322b84366f03c4.png)'
  prefs: []
  type: TYPE_IMG
- en: A variation of the simple diagram, adding color to each fold’s number.
  prefs: []
  type: TYPE_NORMAL
- en: While using colors in this version might seem problematic given the issues with
    color blindness and memory load mentioned before, it can still work as a helpful
    teaching tool alongside the simpler version.
  prefs: []
  type: TYPE_NORMAL
- en: The main reason is that it **doesn’t only use colors to show the information**
    — the row numbers (1–10) and fold numbers tell you everything you need to know,
    with colors just being a nice extra touch.
  prefs: []
  type: TYPE_NORMAL
- en: This means that even if someone can’t see the colors properly or prints it in
    black and white, they can still understand everything through the numbers. And
    while having to remember what each color means can make things harder to learn,
    in this case you don’t have to remember the colors — they’re just there as an
    extra help for people who find them useful, but you can totally understand the
    diagram without them.
  prefs: []
  type: TYPE_NORMAL
- en: Just like the previous version, the row numbers also help by showing exactly
    how the data is being split up, making it easier to understand how cross-validation
    works in practice whether you pay attention to the colors or not.
  prefs: []
  type: TYPE_NORMAL
- en: The visualization remains fully functional and understandable even if you ignore
    the colors completely.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/96381337f14683b33da41d5110ce0bcf.png)'
  prefs: []
  type: TYPE_IMG
- en: Try the challenge above. For limited number of colors, it aids in tracking the
    changes of the position faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Why This Works Better: From Design to Data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s look at why our new designs makes sense not just from a UX view, but also
    from a data science perspective.
  prefs: []
  type: TYPE_NORMAL
- en: '**Matching Mental Models:** Think about how you explain cross-validation to
    someone. You probably say “we take these rows for testing, then these rows, then
    these rows.” Our visualization now matches exactly how we think and talk about
    the process. We’re not just making it pretty, we’re making it match reality.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Structure Clarity:** By showing data as columns with indices, we’re
    revealing the actual structure of our dataset. Each row has a number, each number
    appears in exactly one test set. This isn’t just good design, it’s accurate to
    how our data is organized in code.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a1a6c60195236d8940224e07615342ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Even with shuffling, which is the default way to do cross validation, we can
    just change the index so people understand that it is being shuffled.
  prefs: []
  type: TYPE_NORMAL
- en: '**Focus on What Matters:** Our old way of showing cross-validation had us thinking
    about moving parts. But that’s not what matters in cross-validation. What matters
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: Which rows are we testing on?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are we using all our data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is each row used for testing exactly once?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our new design answers these questions at a glance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Index-Based Understanding:** Instead of abstract colored boxes, we’re showing
    actual row indices. When you write cross-validation code, you’re working with
    these indices. Now the visualization matches your code — Fold 1 uses rows 1–4,
    Fold 2 uses 5–7, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/043d42a32e5df5fd0f4bc6f3d408ba2a.png)'
  prefs: []
  type: TYPE_IMG
- en: Using similar diagram, we can also show how leave-on-out cross validation works.
    Only one data point is used in the test set! The split numbering and the chosen
    index for the test set are also nicely matched.
  prefs: []
  type: TYPE_NORMAL
- en: '**Clear Data Flow:** The layout shows data flowing from left to right: here’s
    your dataset, here’s how it’s split, here’s what each split looks like. It matches
    the logical steps of cross-validation and it’s also easier to look at.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c23f34808ce42cb3b8f8f14364010915.png)'
  prefs: []
  type: TYPE_IMG
- en: Clarifying the purpose of the arrows to denote the train & test process can
    make it clearer on how many models and what are the outputs of the cross-validation.
    You may note that there’s no arrow connecting elements between splits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusion: When Visualization Matches Your Code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here’s what we’ve learned about the whole redrawing of the cross-validation
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Match Your Code, Not Conventions:** We usually stick to traditional ways
    of showing things just because that’s how everyone does it. But cross-validation
    is really about selecting different rows of data for testing, so why not show
    exactly that? When your visualization matches your code, understanding follows
    naturally.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Structure Matters:** By showing indices and actual data splits, we’re
    revealing how cross-validation really works while also make a clearer picture.
    Each row has its place, each split has its purpose, and you can trace exactly
    what’s happening in each step.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simplicity Has It Purpose:** It turns out that showing less can actually
    explain more. By focusing on the essential parts — which rows are being used for
    testing, and when — we’re not just simplifying the visualization but we’re also
    highlighting what actually matters in cross-validation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking ahead, this thinking can apply to many data science concepts. Before
    making another visualization, ask yourself:'
  prefs: []
  type: TYPE_NORMAL
- en: Does this show what’s actually happening in the code?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can someone trace the data flow?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are we showing structure, or just following tradition?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Good visualization isn’t about following rules — it’s about showing truth. And
    sometimes, the clearest truth is also the simplest.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: About the Illustrations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  prefs: []
  type: TYPE_NORMAL
- en: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝙈𝙤𝙙𝙚𝙡 𝙀𝙫𝙖𝙡𝙪𝙖𝙩𝙞𝙤𝙣 & 𝙊𝙥𝙩𝙞𝙢𝙞𝙯𝙖𝙩𝙞𝙤𝙣 𝙝𝙚𝙧𝙚:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----bdbbba74e263--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Model Evaluation & Optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/model-evaluation-optimization-331287896864?source=post_page-----bdbbba74e263--------------------------------)3
    stories![](../Images/18fa82b1435fa7d5571ee54ae93a6c62.png)![](../Images/c95e89d05d1de700c631c342cd008de0.png)![](../Images/30e20e1a8ba3ced1e77644b706acd18d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----bdbbba74e263--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Classification Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----bdbbba74e263--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  prefs: []
  type: TYPE_NORMAL
