- en: Why Most Cross-Validation Visualizations Are Wrong (And How to Fix Them)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/why-most-cross-validation-visualizations-are-wrong-and-how-to-fix-them-bdbbba74e263?source=collection_archive---------0-----------------------#2024-11-16](https://towardsdatascience.com/why-most-cross-validation-visualizations-are-wrong-and-how-to-fix-them-bdbbba74e263?source=collection_archive---------0-----------------------#2024-11-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: BETTER ML VISUALS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stop using moving boxes!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--bdbbba74e263--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--bdbbba74e263--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bdbbba74e263--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bdbbba74e263--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--bdbbba74e263--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bdbbba74e263--------------------------------)
    Â·10 min readÂ·Nov 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: 'You know those cross-validation diagrams in every data science tutorial? The
    ones showing boxes in different colors moving around to explain how we split data
    for training and testing? Like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7310960c11e4e979706ce2dea8eedfbf.png)'
  prefs: []
  type: TYPE_IMG
- en: Have you seen that? Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Iâ€™ve seen them too â€” one too many times. These diagrams are common â€” theyâ€™ve
    become the go-to way to explain cross-validation. But hereâ€™s something interesting
    I noticed while looking at them as both a designer and data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at a yellow box moving to different spots, our brain automatically
    sees it as one box moving around.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Itâ€™s just how our brains work â€” when we see something similar move to a new
    spot, we think itâ€™s the same thing. (This is actually why cartoons and animations
    work!)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/293776fe285e9c1651b9ca1c65706411.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You might think the animated version is better, but now you canâ€™t help following
    the blue box and starting to forget that this should represent how cross-validation
    works. Source: [Wikipedia](https://commons.wikimedia.org/wiki/File:LOOCV.gif)'
  prefs: []
  type: TYPE_NORMAL
- en: 'But hereâ€™s the thing: In these diagrams, each box in a new position is **supposed
    to show a different chunk of data**. So while our brain naturally wants to track
    the boxes, we have to tell our brain, â€œNo, no, thatâ€™s not one box moving â€” theyâ€™re
    different boxes!â€ Itâ€™s like weâ€™re fighting against how our brain naturally works,
    just to understand what the diagram means.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at this as someone who works with both design and data, I started thinking:
    maybe thereâ€™s a better way? What if we could show cross-validation in a way that
    actually works with how our brain processes information?'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a213cf03718d755a88bb08470f7d3abb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  prefs: []
  type: TYPE_NORMAL
- en: Whatâ€™s Cross-Validation Really About?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cross-validation is about making sure machine learning models work well in the
    real world. Instead of testing a model once, we test it multiple times using different
    parts of our data. This helps us understand how the model will perform with new,
    unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hereâ€™s what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: We take our data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divide it into groups
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use some groups for training, others for testing
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat this process with different groupings
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The goal is to get a reliable understanding of our modelâ€™s performance. Thatâ€™s
    the core idea â€” simple and practical.
  prefs: []
  type: TYPE_NORMAL
- en: '(Note: Weâ€™ll discuss different validation techniques and their applications
    in another article. For now, letâ€™s focus on understanding the basic concept and
    why current visualization methods need improvement.)'
  prefs: []
  type: TYPE_NORMAL
- en: Whatâ€™s Wrong with Current Cross-validation Diagrams?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open up any machine learning tutorial, and youâ€™ll probably see these types
    of diagrams:'
  prefs: []
  type: TYPE_NORMAL
- en: Long boxes split into different sections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arrows showing parts moving around
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different colors showing training and testing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple versions of the same diagram side by side
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/11bdeccff9e5426a2f8669b317c7faab.png)'
  prefs: []
  type: TYPE_IMG
- en: Currently, this is similar to the first image youâ€™ll see if you look up â€œCross
    Validation.â€ (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the issues with such diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Not Everyone Sees Colors the Same Way**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Colors create practical problems when showing data splits. Some people canâ€™t
    differentiate certain colors, while others may not see colors at all. The visualization
    fails when printed in black and white or viewed on different screens where colors
    vary. Using color as the primary way to distinguish data parts means some people
    miss important information due to their color perception.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e3c7aea8baea654253fbedde5e3dd811.png)'
  prefs: []
  type: TYPE_IMG
- en: Not everyone see the same colors. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Colors Make Things Harder to Remember**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another thing about colors is that it might look like they help explain things,
    but they actually create extra work for our brain. When we use different colors
    for different parts of the data, we have to actively remember what each color
    represents. This becomes a memory task instead of helping us understand the actual
    concept. The connection between colors and data splits isnâ€™t natural or obvious
    â€” itâ€™s something we have to learn and keep track of while trying to understand
    cross-validation itself.
  prefs: []
  type: TYPE_NORMAL
- en: Our brain doesnâ€™t naturally connect colors with data splits.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e4690d7c50d8de5d8855975b40cd0424.png)'
  prefs: []
  type: TYPE_IMG
- en: These are the colors we used in the previous diagrams. Why original dataset
    is green? Then split into blue and red?
  prefs: []
  type: TYPE_NORMAL
- en: '**Too Much Information at Once**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The current diagrams also suffer from information overload. They attempt to
    display the entire cross-validation process in a single visualization, which creates
    unnecessary complexity. Multiple arrows, extensive labeling, all competing for
    attention. When we try to show every aspect of the process at the same time, we
    make it harder to focus on understanding each individual part. Instead of clarifying
    the concept, this approach adds an extra layer of complexity that we need to decode
    first.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3860f294e42aad31e7ef34a9bdaf9ccf.png)'
  prefs: []
  type: TYPE_IMG
- en: Too many labels, too many colors, too many arrows and it is too hard to focus.
  prefs: []
  type: TYPE_NORMAL
- en: Movement That Misleads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Movement in these diagrams creates a fundamental misunderstanding of how cross-validation
    actually works. When we show arrows and flowing elements, weâ€™re suggesting a sequential
    process that doesnâ€™t exist in reality. Cross-validation splits donâ€™t need to happen
    in any particular order â€” the order of splits doesnâ€™t affect the results at all.
  prefs: []
  type: TYPE_NORMAL
- en: These diagrams also give the wrong impression that data physically moves during
    cross-validation. In reality, weâ€™re simply selecting different rows from our original
    dataset each time. The data stays exactly where it is, and we just change which
    rows we use for testing in each split. When diagrams show data flowing between
    splits, they add unnecessary complexity to what should be a straightforward process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d8fa4ea0c53cc2aa618406d0c99e6f09.png)'
  prefs: []
  type: TYPE_IMG
- en: While diagrams typically flow from top to bottom, itâ€™s hard to follow the sequence
    of operations. The timing of model training and the calculation results remain
    unclear. When does the training happen? What results come from each calculation?
  prefs: []
  type: TYPE_NORMAL
- en: What We Need Instead
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need diagrams that:'
  prefs: []
  type: TYPE_NORMAL
- en: Donâ€™t just rely on colors to explain things
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Show information in clear, separate chunks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make it obvious that different test groups are independent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Donâ€™t use unnecessary arrows and movement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Letâ€™s fix this. Instead of trying to make our brains work differently, why donâ€™t
    we create something that feels natural to look at?
  prefs: []
  type: TYPE_NORMAL
- en: A Better Way to Visualize Cross-validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Letâ€™s try something different. First, this is how data looks like to most people
    â€” rows and columns of numbers with index.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/08da329b59c04831295fa503a37cb6e4.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the common dataset I used for [my articles on classification algorithms](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c).
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by that structure, hereâ€™s a diagram that make more sense.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e1633734844646b0c9a447fea09fde60.png)'
  prefs: []
  type: TYPE_IMG
- en: Simpler but clear depiction of cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hereâ€™s why this design makes more sense logically:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Data Structure:** It matches how data actually works in cross-validation.
    In practice, weâ€™re selecting different portions of our dataset â€” not moving data
    around. Each column shows exactly which splits weâ€™re using for testing each time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Independent Splits:** Each split explicitly shows itâ€™s different data. Unlike
    moving boxes that might make you think â€œitâ€™s the same test set moving around,â€
    this shows that Split 2 is using completely different data from Split 1\. This
    matches whatâ€™s actually happening in your code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data Conservation:** By keeping the column height the same throughout all
    folds, weâ€™re showing an important rule of cross-validation: you always use your
    entire dataset. Some portions for testing, the rest for training. Every piece
    of data gets used, nothing is left out.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Complete Coverage:** Looking left to right, you can easily check an important
    cross-validation principle: every portion of your dataset will be used as test
    data exactly once.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Three-Fold Simplicity:** We specifically use 3-fold cross-validation here
    because:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. It clearly demonstrates the key concepts without overwhelming detail
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b. The pattern is easy to follow: three distinct folds, three test sets. Simple
    enough to mentally track which portions are being used for training vs testing
    in each fold'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Perfect for educational purposes â€” adding more folds (like 5 or 10) would
    make the visualization more cluttered without adding conceptual value
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '(Note: While 5-fold or 10-fold cross-validation might be more common in practice,
    3-fold serves perfectly to illustrate the core concepts of the technique.)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adding Indices for Clarity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While the concept above is correct, thinking about actual row indices makes
    it even clearer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/00368eec59269afee2665564b9803290.png)'
  prefs: []
  type: TYPE_IMG
- en: An enhanced variation with subtle index, making it easier to see which part
    of the dataset each fold belong to. The dashed lines help in separating the indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some reasons of improvements of this visual:'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of just â€œdifferent portions,â€ we can see that Fold 1 tests on rows 1â€“4,
    Fold 2 on rows 5â€“7, and Fold 3 on rows 8â€“10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'â€œComplete coverageâ€ becomes more concrete: rows 1â€“10 each appear exactly once
    in test sets'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training sets are explicit: when testing on rows 1â€“4, weâ€™re training on rows
    5â€“10'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data independence is obvious: test sets use different row ranges (1â€“3, 4â€“6,
    7â€“10)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This index-based view doesnâ€™t change the concepts â€” it just makes them more
    concrete and easier to implement in code. Whether you think about it as portions
    or specific row numbers, the key principles remain the same: independent folds,
    complete coverage, and using all your data.'
  prefs: []
  type: TYPE_NORMAL
- en: Adding Some Colors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you feel the black-and-white version is too plain, this is also another
    acceptable options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cb7cf250b229c7400f322b84366f03c4.png)'
  prefs: []
  type: TYPE_IMG
- en: A variation of the simple diagram, adding color to each foldâ€™s number.
  prefs: []
  type: TYPE_NORMAL
- en: While using colors in this version might seem problematic given the issues with
    color blindness and memory load mentioned before, it can still work as a helpful
    teaching tool alongside the simpler version.
  prefs: []
  type: TYPE_NORMAL
- en: The main reason is that it **doesnâ€™t only use colors to show the information**
    â€” the row numbers (1â€“10) and fold numbers tell you everything you need to know,
    with colors just being a nice extra touch.
  prefs: []
  type: TYPE_NORMAL
- en: This means that even if someone canâ€™t see the colors properly or prints it in
    black and white, they can still understand everything through the numbers. And
    while having to remember what each color means can make things harder to learn,
    in this case you donâ€™t have to remember the colors â€” theyâ€™re just there as an
    extra help for people who find them useful, but you can totally understand the
    diagram without them.
  prefs: []
  type: TYPE_NORMAL
- en: Just like the previous version, the row numbers also help by showing exactly
    how the data is being split up, making it easier to understand how cross-validation
    works in practice whether you pay attention to the colors or not.
  prefs: []
  type: TYPE_NORMAL
- en: The visualization remains fully functional and understandable even if you ignore
    the colors completely.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/96381337f14683b33da41d5110ce0bcf.png)'
  prefs: []
  type: TYPE_IMG
- en: Try the challenge above. For limited number of colors, it aids in tracking the
    changes of the position faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Why This Works Better: From Design to Data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Letâ€™s look at why our new designs makes sense not just from a UX view, but also
    from a data science perspective.
  prefs: []
  type: TYPE_NORMAL
- en: '**Matching Mental Models:** Think about how you explain cross-validation to
    someone. You probably say â€œwe take these rows for testing, then these rows, then
    these rows.â€ Our visualization now matches exactly how we think and talk about
    the process. Weâ€™re not just making it pretty, weâ€™re making it match reality.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Structure Clarity:** By showing data as columns with indices, weâ€™re
    revealing the actual structure of our dataset. Each row has a number, each number
    appears in exactly one test set. This isnâ€™t just good design, itâ€™s accurate to
    how our data is organized in code.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a1a6c60195236d8940224e07615342ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Even with shuffling, which is the default way to do cross validation, we can
    just change the index so people understand that it is being shuffled.
  prefs: []
  type: TYPE_NORMAL
- en: '**Focus on What Matters:** Our old way of showing cross-validation had us thinking
    about moving parts. But thatâ€™s not what matters in cross-validation. What matters
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: Which rows are we testing on?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are we using all our data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is each row used for testing exactly once?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our new design answers these questions at a glance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Index-Based Understanding:** Instead of abstract colored boxes, weâ€™re showing
    actual row indices. When you write cross-validation code, youâ€™re working with
    these indices. Now the visualization matches your code â€” Fold 1 uses rows 1â€“4,
    Fold 2 uses 5â€“7, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/043d42a32e5df5fd0f4bc6f3d408ba2a.png)'
  prefs: []
  type: TYPE_IMG
- en: Using similar diagram, we can also show how leave-on-out cross validation works.
    Only one data point is used in the test set! The split numbering and the chosen
    index for the test set are also nicely matched.
  prefs: []
  type: TYPE_NORMAL
- en: '**Clear Data Flow:** The layout shows data flowing from left to right: hereâ€™s
    your dataset, hereâ€™s how itâ€™s split, hereâ€™s what each split looks like. It matches
    the logical steps of cross-validation and itâ€™s also easier to look at.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c23f34808ce42cb3b8f8f14364010915.png)'
  prefs: []
  type: TYPE_IMG
- en: Clarifying the purpose of the arrows to denote the train & test process can
    make it clearer on how many models and what are the outputs of the cross-validation.
    You may note that thereâ€™s no arrow connecting elements between splits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusion: When Visualization Matches Your Code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Hereâ€™s what weâ€™ve learned about the whole redrawing of the cross-validation
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Match Your Code, Not Conventions:** We usually stick to traditional ways
    of showing things just because thatâ€™s how everyone does it. But cross-validation
    is really about selecting different rows of data for testing, so why not show
    exactly that? When your visualization matches your code, understanding follows
    naturally.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Structure Matters:** By showing indices and actual data splits, weâ€™re
    revealing how cross-validation really works while also make a clearer picture.
    Each row has its place, each split has its purpose, and you can trace exactly
    whatâ€™s happening in each step.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simplicity Has It Purpose:** It turns out that showing less can actually
    explain more. By focusing on the essential parts â€” which rows are being used for
    testing, and when â€” weâ€™re not just simplifying the visualization but weâ€™re also
    highlighting what actually matters in cross-validation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking ahead, this thinking can apply to many data science concepts. Before
    making another visualization, ask yourself:'
  prefs: []
  type: TYPE_NORMAL
- en: Does this show whatâ€™s actually happening in the code?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can someone trace the data flow?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are we showing structure, or just following tradition?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Good visualization isnâ€™t about following rules â€” itâ€™s about showing truth. And
    sometimes, the clearest truth is also the simplest.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: About the Illustrations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  prefs: []
  type: TYPE_NORMAL
- en: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ™ˆğ™¤ğ™™ğ™šğ™¡ ğ™€ğ™«ğ™–ğ™¡ğ™ªğ™–ğ™©ğ™ğ™¤ğ™£ & ğ™Šğ™¥ğ™©ğ™ğ™¢ğ™ğ™¯ğ™–ğ™©ğ™ğ™¤ğ™£ ğ™ğ™šğ™§ğ™š:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----bdbbba74e263--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Model Evaluation & Optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/model-evaluation-optimization-331287896864?source=post_page-----bdbbba74e263--------------------------------)3
    stories![](../Images/18fa82b1435fa7d5571ee54ae93a6c62.png)![](../Images/c95e89d05d1de700c631c342cd008de0.png)![](../Images/30e20e1a8ba3ced1e77644b706acd18d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----bdbbba74e263--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Classification Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----bdbbba74e263--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  prefs: []
  type: TYPE_NORMAL
