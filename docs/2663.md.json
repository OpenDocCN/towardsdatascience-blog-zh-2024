["```py\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import AutoTokenizer\nfrom transformers import pipeline\n\nnli_model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\", model_max_length=512)\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\nclassifier = pipeline(\"zero-shot-classification\", device=\"cpu\", model=nli_model, tokenizer=tokenizer)\n\nlabel_list = ['News', 'Science', 'Art']\n\nall_results = []\nfor text in list_of_texts:\n    prob = self.classifier(text, label_list, multi_label=True, use_fast=True)\n    results_dict = {x: y for x, y in zip(prob[\"labels\"], prob[\"scores\"])}\n    all_results.append(results_dict)\n```", "```py\ndef run_zero_shot_classifier(text, label):\n    hypothesis = f\"This example is related to {label}.\"\n\n    x = tokenizer.encode(\n        text, \n        hypothesis, \n        return_tensors=\"pt\", \n        truncation_strategy=\"only_first\"\n    )\n\n    logits = nli_model(x.to(\"cpu\"))[0]\n\n    entail_contradiction_logits = logits[:, [0, 2]]\n    probs = entail_contradiction_logits.softmax(dim=1)\n    prob_label_is_true = probs[:, 1]\n\n    return prob_label_is_true.item()\n\nlabel_list = ['News', 'Science', 'Art']\nall_results = []\nfor text in list_of_texts:\n    for label in label_list:\n        result = run_zero_shot_classifier(text, label)\n\t    all_results.append(result)\n```"]