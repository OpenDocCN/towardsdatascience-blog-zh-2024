- en: What to Study if you Want to Master LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如果你想掌握LLM，应该学习什么？
- en: 原文：[https://towardsdatascience.com/what-to-study-if-you-want-to-master-llms-8d720f16c559?source=collection_archive---------2-----------------------#2024-08-12](https://towardsdatascience.com/what-to-study-if-you-want-to-master-llms-8d720f16c559?source=collection_archive---------2-----------------------#2024-08-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-to-study-if-you-want-to-master-llms-8d720f16c559?source=collection_archive---------2-----------------------#2024-08-12](https://towardsdatascience.com/what-to-study-if-you-want-to-master-llms-8d720f16c559?source=collection_archive---------2-----------------------#2024-08-12)
- en: What foundational concepts should you study if you want to understand Large
    Language Models?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果你想理解大规模语言模型，应该学习哪些基础概念？
- en: '[](https://ivopbernardo.medium.com/?source=post_page---byline--8d720f16c559--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page---byline--8d720f16c559--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8d720f16c559--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8d720f16c559--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page---byline--8d720f16c559--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ivopbernardo.medium.com/?source=post_page---byline--8d720f16c559--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page---byline--8d720f16c559--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8d720f16c559--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8d720f16c559--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page---byline--8d720f16c559--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8d720f16c559--------------------------------)
    ·6 min read·Aug 12, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8d720f16c559--------------------------------)
    ·阅读时间：6分钟·2024年8月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/0817e20fc1920752094db9e6e3176415.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0817e20fc1920752094db9e6e3176415.png)'
- en: Image by [solenfeyissa](https://unsplash.com/pt-br/@solenfeyissa) @ Unsplash.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[solenfeyissa](https://unsplash.com/pt-br/@solenfeyissa) @ Unsplash.com
- en: Most of the code we use to interact with LLMs (Large Language Models) is hidden
    behind several APIs — and that’s a good thing.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用来与LLM（大规模语言模型）互动的大部分代码都隐藏在多个API之后——这其实是件好事。
- en: 'But if you are like me, and want to understand the *ins* and *outs* of these
    magical models, there’s still hope for you. Currently, apart from the researchers
    working on developing and training new LLMs, there’s mostly two types of people
    playing with these types of models:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你像我一样，想要理解这些神奇模型的*内*和*外*，那么你仍然有希望。现在，除了从事开发和训练新LLM的研究人员之外，主要有两类人正在使用这些模型：
- en: Users, that interact via applications such as *ChatGPT* or *Gemini*.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过应用程序与之互动的用户，比如*ChatGPT*或*Gemini*。
- en: Data scientists and developers that work with different libraries, such as *llangchain*,
    *llama-index* or even using *Gemini* or *OpenAI* apis, that simplify the process
    of building on top of these models.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家和开发人员，他们使用不同的库，如*llangchain*、*llama-index*，甚至使用*Gemini*或*OpenAI*的API，这些库简化了在这些模型上构建应用的过程。
- en: The problem is — and you may have felt it — that there is a fundamental knowledge
    in text mining and natural language processing that is completely hidden away
    in consumer products or APIs. And don’t take me wrong — they are great for developing
    cool use cases around these technologies. But, if you want to a have deeper knowledge
    to build complex use cases or manipulate LLMs a bit better, you’ll need to check
    the fundamentals — particularly when the models behave as you…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是——你可能已经感觉到了——在文本挖掘和自然语言处理领域，有些基础知识完全被隐藏在消费者产品或API中。别误会我的意思——它们对于围绕这些技术开发有趣的用例非常棒。但是，如果你想深入了解、构建复杂的用例，或者更好地操控LLM，你需要学习基础知识——尤其是当模型表现得像你想象的那样……
