- en: 'The Evolution of Llama: From Llama 1 to Llama 3.1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258?source=collection_archive---------5-----------------------#2024-09-06](https://towardsdatascience.com/the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258?source=collection_archive---------5-----------------------#2024-09-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Comprehensive Guide to the Advancements and Innovations in the Family of Llama
    Models from Meta AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@luisroque?source=post_page---byline--13c4ebe96258--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page---byline--13c4ebe96258--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--13c4ebe96258--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--13c4ebe96258--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page---byline--13c4ebe96258--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--13c4ebe96258--------------------------------)
    ·15 min read·Sep 6, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*This post was co-authored with Rafael Guedes.*'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Meta has released three major versions of its large language model (LLM), Llama,
    along with a minor (if we can call it that) update (version 3.1). The initial
    release of Llama in early 2023 marked a significant step forward for the open-source
    community in natural language processing (NLP). Meta has consistently contributed
    to this community by sharing its latest LLM versions.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure correctness, we should distinguish between open and open-source LLMs.
    Open-source software traditionally makes its source code available under specific
    public use and modification licenses. In the context of LLMs, open LLMs typically
    disclose model weights and initial code. At the same time, open-source LLMs would
    also share the entire training process, including training data, with a permissive
    license. Most models today, including Meta’s Llama, fall under the open LLMs category
    since they do not release the datasets used for training.
  prefs: []
  type: TYPE_NORMAL
- en: Llama has undergone three key architectural iterations. Version 1 introduced
    several enhancements to the original Transformer architecture. Version 2 implemented
    Grouped-Query Attention (GQA) in larger models. Version 3 extended GQA to smaller
    models, introduced a more efficient…
  prefs: []
  type: TYPE_NORMAL
