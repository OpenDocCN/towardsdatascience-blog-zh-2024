- en: 'Intro to LLM Agents with Langchain: When RAG is Not Enough'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/intro-to-llm-agents-with-langchain-when-rag-is-not-enough-7d8c08145834?source=collection_archive---------0-----------------------#2024-03-15](https://towardsdatascience.com/intro-to-llm-agents-with-langchain-when-rag-is-not-enough-7d8c08145834?source=collection_archive---------0-----------------------#2024-03-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: First-order principles of brain structure for AI assistants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://alexhonchar.medium.com/?source=post_page---byline--7d8c08145834--------------------------------)[![Alex
    Honchar](../Images/fd30740a0ee12701b0d8670143ba7a9b.png)](https://alexhonchar.medium.com/?source=post_page---byline--7d8c08145834--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7d8c08145834--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7d8c08145834--------------------------------)
    [Alex Honchar](https://alexhonchar.medium.com/?source=post_page---byline--7d8c08145834--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7d8c08145834--------------------------------)
    ·7 min read·Mar 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: 'Hello everyone, this article is a written form of a tutorial I conducted two
    weeks ago with [Neurons Lab](https://neurons-lab.com/). If you prefer a narrative
    walkthrough, you can find the YouTube video here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As always, you can find [the code on GitHub](https://github.com/Rachnog/intro_to_llm_agents),
    and here are separate Colab Notebooks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Planning and reasoning](https://colab.research.google.com/drive/1SplDwEIbVfo9zNt6JOK0gJlV0wCNuz0F?usp=sharing)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Different types of memories](https://colab.research.google.com/drive/13b_pD27aqcNXYI2M7fBxK1fRIO2pygZJ?usp=sharing)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Various types of tools](https://colab.research.google.com/drive/1-VpwkmSvzA-zQ_iVK-xjOQf5kA-Lzwg9?usp=sharing)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Building complete agents](https://colab.research.google.com/drive/1aC9AUNNYYz36atE8BUJH4fZIfknHa9Pk?usp=sharing)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Introduction to the agents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/e9d979f7bddb7cefa7b8a51fed6ea16f.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration by author. LLMs are often augmented with external memory via RAG
    architecture. Agents extend this concept to memory, reasoning, tools, answers,
    and actions
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin the lecture by exploring various examples of LLM agents. While
    the topic is widely discussed, few are actively utilizing agents; often, what
    we perceive as agents are simply large language models. Let’s consider such a
    simple task as **searching for football game results and saving them as a CSV
    file**. We can compare several available tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**GPT-4 with search and plugins**: as you will find in the [chat history here](https://chat.openai.com/share/2ecd61a9-dbd9-4287-aa75-14618106a34c),
    GPT-4 failed to do the task due to code errors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AutoGPT** through [https://evo.ninja/](https://evo.ninja/) at least could
    generate some kind of CSV (not ideal though):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/bf2d41707b6fd266beb26e4f705cd0ca.png)'
  prefs: []
  type: TYPE_IMG
- en: '**AgentGPT** through [https://agentgpt.reworkd.ai/](https://agentgpt.reworkd.ai/):
    decided to treat this task as a synthetic data generator which is not what we
    asked about, check the [chat history here](https://agentgpt.reworkd.ai/agent?id=clsyfh1t101t9jv08yaof890k)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Since the available tools are not great**, let’s learn from the first principles
    of how to build agents from scratch. I am using amazing [Lilian’s blog article](https://lilianweng.github.io/posts/2023-06-23-agent/)
    as a structure reference but adding more examples on my own.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Planning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/571a9bacf9092b0cc86e2cf8fa5d34ed.png)'
  prefs: []
  type: TYPE_IMG
- en: The visual difference between simple “input-output” LLM usage and such techniques
    as a chain of thought, a chain of thought with self-consistency, a tree of thought
  prefs: []
  type: TYPE_NORMAL
- en: You might have come across various techniques aimed at improving the performance
    of large language models, such as [offering tips](https://twitter.com/literallydenis/status/1730965217125839142)
    or even jokingly threatening them. One popular technique is called “[chain of
    thought](https://www.promptingguide.ai/techniques/cot),” where the **model is
    asked to think step by step, enabling self-correction**. This approach has evolved
    into more advanced versions like the “[chain of thought with self-consistency](https://www.promptingguide.ai/techniques/consistency)”
    and the generalized “[tree of thoughts](https://medium.com/@astropomeai/implementing-the-tree-of-thoughts-in-langchains-chain-f2ebc5864fac),”
    **where multiple thoughts are created, re-evaluated, and consolidated to provide
    an output**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this tutorial, I am using heavily [Langsmith](https://www.langchain.com/langsmith),
    a platform for productionizing LLM applications. For example, while building the
    tree of thoughts prompts, I save my sub-prompts in the **prompts repository**
    and load them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see in [this notebook](https://github.com/Rachnog/intro_to_llm_agents/blob/main/1_planning.ipynb)
    the result of such reasoning, the point I want to make here is the right process
    for defining your reasoning steps and versioning them in such **an LLMOps system
    like Langsmith**. Also, you can see other examples of popular reasoning techniques
    in public repositories like ReAct or Self-ask with search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Other notable approaches are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reflexion** ([Shinn & Labash 2023](https://arxiv.org/abs/2303.11366)) is
    a framework to equip agents with dynamic memory and self-reflection capabilities
    to improve reasoning skills.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chain of Hindsight** (CoH; [Liu et al. 2023](https://arxiv.org/abs/2302.02676))
    encourages the model to improve on its own outputs by explicitly presenting it
    with a sequence of past outputs, each annotated with feedback.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 2: Memory'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/e3c6c61abf60034387cbdcb5f7007f75.png)'
  prefs: []
  type: TYPE_IMG
- en: We can map different types of memories in our brain to the components of the
    LLM agents' architecture
  prefs: []
  type: TYPE_NORMAL
- en: '**Sensory Memory:** This component of memory captures immediate sensory inputs,
    like what we see, hear or feel. In the context of prompt engineering and AI models,
    a prompt serves as a transient input, similar to a momentary touch or sensation.
    It’s the initial stimulus that triggers the model’s processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Short-Term Memory:** Short-term memory holds information temporarily, typically
    related to the ongoing task or conversation. In prompt engineering, this equates
    to retaining the recent chat history. This memory enables the agent to maintain
    context and coherence throughout the interaction, ensuring that responses align
    with the current dialogue. **In code, you typically add it as conversation history**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Long-Term Memory:** Long-term memory stores both factual knowledge and procedural
    instructions. In AI models, this is represented by the data used for training
    and fine-tuning. Additionally, long-term memory supports the operation of RAG
    frameworks, allowing agents to access and integrate learned information into their
    responses. It’s like the comprehensive knowledge repository that agents draw upon
    to generate informed and relevant outputs. **In code, you typically add it as
    a vectorized database**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 3: Tools'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/6585f6b90c5882221fd42d4f294545e9.png)'
  prefs: []
  type: TYPE_IMG
- en: In practice, you want to augment your agent with a separate line of reasoning
    (which can be another LLM, i.e. domain-specific or another ML model for image
    classification) or with something more rule-based or API-based
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT [Plugins](https://openai.com/blog/chatgpt-plugins) and **OpenAI API**
    [function calling](https://platform.openai.com/docs/guides/gpt/function-calling)
    are good examples of LLMs augmented with tool use capability working in practice.
  prefs: []
  type: TYPE_NORMAL
- en: '**Built-in Langchain tools**: Langchain has a [pleiad of built-in tools](https://python.langchain.com/docs/integrations/tools/)
    ranging from internet search and Arxiv toolkit to Zapier and Yahoo Finance. For
    this simple tutorial, we will experiment with the internet search provided by
    [Tavily](https://tavily.com/):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**Custom tools**: it’s also very easy to define your own tools. Let’s dissect
    the simple example of a tool that calculates the length of the string. You need
    to use the `@tool`decorator to make Langchain know about it. Then, don’t forget
    about the type of input and the output. But the most important part will be the
    function comment between `""" """` — this is how your agent will know what this
    tool does and will compare this description to descriptions of the other tools:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You can find examples of how it works [in this script](https://github.com/Rachnog/intro_to_llm_agents/blob/main/3_tools.ipynb),
    **but you also can see an error** — it doesn't pull the correct description of
    the Neurons Lab company and despite calling the right custom function of length
    calculation, the final result is wrong. Let’s try to fix it!
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: All together'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I am providing a clean version of combining all the pieces of architecture
    together [in this script](https://github.com/Rachnog/intro_to_llm_agents/blob/main/4_agents.ipynb).
    Notice, how we can easily decompose and define separately:'
  prefs: []
  type: TYPE_NORMAL
- en: All kinds of **tools** (search, custom tools, etc)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All kinds of **memories** (**sensory** as a prompt, **short-term** as runnable
    message history, and as a sketchpad within the prompt, and **long-term** as a
    retrieval from the vector database)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any kind of **planning strategy** (as a **part of a prompt** pulled from the
    LLMOps system)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The final definition of the agent will look as simple as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the [outputs of the script](https://github.com/Rachnog/intro_to_llm_agents/blob/main/4_agents.ipynb)
    (or you can run it yourself), it solves the issue in the previous part related
    to tools. What changed? We defined a **complete architecture**, where short-term
    memory plays a crucial role. Our agent obtained **message history and a sketchpad
    as a part of the reasoning structure** which allowed it to pull the correct website
    description and calculate its length.
  prefs: []
  type: TYPE_NORMAL
- en: Outro
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope this walkthrough through the core elements of the LLM agent architecture
    will help you design functional bots for the cognitive tasks you aim to automate.
    To complete, I would like to emphasize again the importance of having all elements
    of the agent in place. As we can see, missing short-term memory or having an incomplete
    description of a tool can mess with the agent’s reasoning and provide incorrect
    answers even for very simple tasks like summary generation and its length calculation.
    Good luck with your AI projects and don’t hesitate [to reach out](https://linktr.ee/alexhonchar)
    if you need help at your company!
  prefs: []
  type: TYPE_NORMAL
