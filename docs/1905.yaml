- en: Addressing Concerns of Model Collapse from Synthetic Data in AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决人工智能中来自合成数据的模型崩溃问题
- en: 原文：[https://towardsdatascience.com/addressing-concerns-of-model-collapse-from-synthetic-data-in-ai-7cd380208d14?source=collection_archive---------4-----------------------#2024-08-05](https://towardsdatascience.com/addressing-concerns-of-model-collapse-from-synthetic-data-in-ai-7cd380208d14?source=collection_archive---------4-----------------------#2024-08-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/addressing-concerns-of-model-collapse-from-synthetic-data-in-ai-7cd380208d14?source=collection_archive---------4-----------------------#2024-08-05](https://towardsdatascience.com/addressing-concerns-of-model-collapse-from-synthetic-data-in-ai-7cd380208d14?source=collection_archive---------4-----------------------#2024-08-05)
- en: '[](https://medium.com/@zredlined?source=post_page---byline--7cd380208d14--------------------------------)[![Alexander
    Watson](../Images/aea574d9652ea8b1b91d4ec8a9c88ef8.png)](https://medium.com/@zredlined?source=post_page---byline--7cd380208d14--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7cd380208d14--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7cd380208d14--------------------------------)
    [Alexander Watson](https://medium.com/@zredlined?source=post_page---byline--7cd380208d14--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@zredlined?source=post_page---byline--7cd380208d14--------------------------------)[![Alexander
    Watson](../Images/aea574d9652ea8b1b91d4ec8a9c88ef8.png)](https://medium.com/@zredlined?source=post_page---byline--7cd380208d14--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7cd380208d14--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7cd380208d14--------------------------------)
    [Alexander Watson](https://medium.com/@zredlined?source=post_page---byline--7cd380208d14--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7cd380208d14--------------------------------)
    ·8 min read·Aug 5, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7cd380208d14--------------------------------)
    ·阅读时间8分钟·2024年8月5日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The AI landscape is rapidly evolving, with synthetic data emerging as a powerful
    tool for model development. While it offers immense potential, recent concerns
    about model collapse have sparked debate. Let’s dive into the reality of synthetic
    data use and its impact on AI development.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域正在快速发展，合成数据作为模型开发的有力工具应运而生。虽然它提供了巨大的潜力，但关于模型崩溃的近期关注引发了争论。让我们深入探讨合成数据的使用现实及其对人工智能发展的影响。
- en: '![](../Images/5997391275bdce6dfd9c5486678a2034.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5997391275bdce6dfd9c5486678a2034.png)'
- en: '*Image generated by DALL-E*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*由DALL-E生成的图像*'
- en: Addressing the Model Collapse Concern
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决模型崩溃问题
- en: 'The Nature paper “[AI models collapse when trained on recursively generated
    data](https://www.nature.com/articles/s41586-024-07566-y)” by Shumailov et al.
    raised important questions about the use of synthetic data:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 《自然》期刊上Shumailov等人发表的论文[“AI模型在递归生成数据的训练下崩溃”](https://www.nature.com/articles/s41586-024-07566-y)提出了关于使用合成数据的重要问题：
- en: '*“We find that* ***indiscriminate use*** *of model-generated content in training
    causes irreversible defects in the resulting models, in which tails of the original
    content distribution disappear.” [1]*'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“我们发现，* ***不加区分地使用*** *模型生成的内容进行训练会导致结果模型中的不可逆缺陷，在这些模型中，原始内容分布的尾部消失。” [1]*'
- en: '*“We argue that the process of model collapse is universal among generative
    models that* ***recursively train*** *on data generated by previous generations”
    [1]*'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“我们认为模型崩溃的过程在所有生成模型中都是普遍存在的，这些模型* ***递归训练*** *于由前一代生成的数据” [1]*'
- en: 'However, it’s essential to note that this extreme scenario of recursive training
    on purely synthetic data is not representative of real-world AI development practices.
    The authors themselves acknowledge:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，这种纯粹基于合成数据的递归训练极端情境并不代表现实世界中的人工智能开发实践。作者们自己也承认：
- en: '*“Here we explore what happens with language models when they are sequentially
    fine-tuned with data generated by other models… We evaluate the most common setting
    of training a language model — a fine-tuning setting for which each of the training
    cycles starts from a pre-trained model with recent data” [1]*'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“在这里，我们探讨当语言模型被顺序微调，且使用由其他模型生成的数据时，会发生什么…我们评估了训练语言模型的最常见设置——一个微调设置，其中每个训练周期都从一个预训练模型开始，使用最新的数据”
    [1]*'
- en: Key Points
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键要点
- en: The study’s methodology does not account for the **continuous influx of new,
    diverse data** that characterizes real-world AI model training. This limitation
    may lead to an overestimation of model collapse in practical scenarios, where
    fresh data serves as a potential corrective mechanism against degradation.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该研究的方法论未考虑到**源源不断的新数据流入**，这一特点是现实世界AI模型训练的一个重要特征。这一局限性可能导致在实际场景中对模型崩溃的高估，而在这些场景中，新的数据可以作为潜在的纠正机制，防止模型退化。
- en: The experimental design, which **discards data from previous generations**,
    diverges from common practices in AI development that involve cumulative learning
    and sophisticated data curation. This approach may not accurately represent the
    knowledge retention and building processes typical in industry applications.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实验设计中**丢弃前代数据**的做法与AI开发中的常规实践相悖，后者涉及到累积学习和复杂的数据策划。这种做法可能无法准确反映行业应用中典型的知识保持和积累过程。
- en: The use of a **single, static model architecture (OPT-125m)** throughout the
    generations does not reflect the **rapid evolution of AI architectures** in practice.
    This simplification may exaggerate the observed model collapse by not accounting
    for how architectural advancements potentially mitigate such issues. In reality,
    the field has seen rapid progression (e.g., **from GPT-3 to GPT-3.5 to GPT-4**,
    or from **Phi-1 to Phi-2 to Phi-3**), with each iteration introducing significant
    improvements in model capacity, generalization capabilities, and emergent behaviors.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在各代之间使用**单一静态模型架构（OPT-125m）**并未反映出实际中**AI架构的快速演变**。这种简化可能夸大了观察到的模型崩溃，因为它没有考虑到架构进展如何潜在地缓解这些问题。实际上，该领域已见证了快速的发展（例如，**从GPT-3到GPT-3.5再到GPT-4**，或**从Phi-1到Phi-2再到Phi-3**），每一次迭代都在模型容量、泛化能力和突现行为上带来了显著的改进。
- en: While the paper acknowledges catastrophic forgetting, it does not incorporate
    **standard mitigation techniques** used in industry, such as elastic weight consolidation
    or experience replay. This omission may amplify the observed model collapse effect
    and limits the study’s applicability to real-world scenarios.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽管论文承认灾难性遗忘问题，但并未采用行业中常用的**标准缓解技术**，如弹性权重整合（Elastic Weight Consolidation）或经验回放。这一遗漏可能加剧了观察到的模型崩溃效应，限制了研究在实际场景中的适用性。
- en: The approach to synthetic data generation and usage in the study lacks the **quality
    control measures and integration practices** commonly employed in industry. This
    methodological choice may lead to an overestimation of model collapse risks in
    practical applications where synthetic data is more carefully curated and combined
    with real-world data.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 研究中合成数据生成和使用的方法缺乏行业中常用的**质量控制措施和整合实践**。这一方法选择可能导致在实际应用中对模型崩溃风险的高估，而在实际应用中，合成数据通常会更仔细地进行筛选并与真实世界的数据结合。
- en: '**Supporting Quotes from the Paper**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**论文中的支持性引述**'
- en: '*“We also briefly mention two close concepts to model collapse from the existing
    literature: catastrophic forgetting arising in the framework of task-free continual
    learning and data poisoning maliciously leading to unintended behaviour”* [1]'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“我们还简要提到现有文献中与模型崩溃相关的两个相近概念：任务无关的持续学习中的灾难性遗忘和恶意数据中毒导致的非预期行为”* [1]'
- en: In practice, the goal of synthetic data is to augment and extend the existing
    datasets, including the implicit data baked into base models. When teams are fine-tuning
    or continuing pre-training, the objective is to provide additional data to improve
    the model’s robustness and performance.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，合成数据的目标是扩充和扩展现有数据集，包括基础模型中内嵌的隐式数据。当团队进行微调或继续预训练时，目标是提供额外的数据以提高模型的鲁棒性和性能。
- en: Counterpoints from Academia and Research
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来自学术界和研究领域的反驳
- en: 'The paper[“Is Model Collapse Inevitable? Breaking the Curse of Recursion by
    Accumulating Real and Synthetic Data”](https://arxiv.org/pdf/2404.01413) by Gerstgrasser
    et al., researchers from Stanford, MIT, and Constellation presents significant
    counterpoints to concerns about AI model collapse:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 由Gerstgrasser等人（斯坦福大学、麻省理工学院和Constitution的研究人员）撰写的论文[《模型崩溃是不可避免的吗？通过积累真实和合成数据打破递归的诅咒》](https://arxiv.org/pdf/2404.01413)提出了对AI模型崩溃担忧的显著反驳：
- en: “[Our work provides consistent empirical and theoretical evidence that data
    accumulation avoids model collapse](https://arxiv.org/pdf/2404.01413).” [2]
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “[我们的工作提供了一致的实证和理论证据，表明数据积累避免了模型崩溃](https://arxiv.org/pdf/2404.01413).” [2]
- en: '![](../Images/92bfb503b5fad3f2a16c5b5c4f867649.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92bfb503b5fad3f2a16c5b5c4f867649.png)'
- en: 'Source: [Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating
    Real and Synthetic Data](https://arxiv.org/pdf/2404.01413). [2]'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[《模型崩溃是否不可避免？通过积累真实与合成数据打破递归的诅咒》](https://arxiv.org/pdf/2404.01413)。 [2]
- en: This work has shown that combining synthetic data with real-world data can prevent
    model degradation.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作表明，将合成数据与现实世界数据结合可以防止模型退化。
- en: '**Quality Over Quantity**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**质量重于数量**'
- en: 'As highlighted in [Microsoft’s Phi-3 technical report](https://arxiv.org/abs/2404.14219):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在[微软的Phi-3技术报告](https://arxiv.org/abs/2404.14219)中强调的：
- en: '*“The creation of a robust and comprehensive dataset demands more than raw
    computational power: It requires intricate iterations, strategic topic selection,
    and a deep understanding of knowledge gaps to ensure quality and diversity of
    the data.” [3]*'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“构建一个强大且全面的数据集不仅仅依赖于原始计算能力：它需要复杂的迭代、战略性的主题选择，并深刻理解知识空白，以确保数据的质量和多样性。”[3]*'
- en: This emphasizes the importance of thoughtful synthetic data generation rather
    than indiscriminate use.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这强调了深思熟虑的合成数据生成的重要性，而不是盲目使用。
- en: 'And [Apple in training their new device and foundation models](https://machinelearning.apple.com/research/introducing-apple-foundation-models):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以及[苹果在训练其新设备和基础模型时](https://machinelearning.apple.com/research/introducing-apple-foundation-models)：
- en: '*“We find that data quality is essential to model success, so we utilize a
    hybrid data strategy in our training pipeline, incorporating both human-annotated
    and synthetic data, and conduct thorough data curation and filtering procedures.“
    [10]*'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“我们发现数据质量对于模型的成功至关重要，因此我们在训练管道中采用混合数据策略，结合人工标注数据和合成数据，并进行彻底的数据策划和过滤程序。”[10]*'
- en: This emphasizes the importance of thoughtful synthetic data generation rather
    than indiscriminate use.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这强调了深思熟虑的合成数据生成的重要性，而不是盲目使用。
- en: '**Iterative Improvement, Not Recursive Training**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**迭代改进，而非递归训练**'
- en: As highlighted in Gretel Navigator, NVIDIA’s Nemotron, and the AgentInstruct
    architecture, cutting edge synthetic data is generated by agents iteratively simulating,
    evaluating, and improving outputs- not simply recursively training on their own
    output. Below is an example of syntheticexample synthetic data generation architecture
    used in AgentInstruct.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在Gretel Navigator、NVIDIA的Nemotron和AgentInstruct架构中所强调的，前沿的合成数据是通过代理人迭代地模拟、评估和改进输出生成的——而不是仅仅递归地在自己的输出上进行训练。以下是AgentInstruct中使用的合成数据生成架构示例。
- en: '![](../Images/c61af22e9c00e2667c93400f26d0c05e.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c61af22e9c00e2667c93400f26d0c05e.png)'
- en: 'Source: AgentInstruct synthetic data generation architecture [11]'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：AgentInstruct合成数据生成架构[11]
- en: On Synthetic Data Improving Model Performance
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据改善模型性能
- en: 'Here are some example results from recent synthetic data releases:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是最近合成数据发布的一些示例结果：
- en: 'AgentInstruct: “[40% improvement on AGIEval, 19% on MMLU, 54% on GSM8K](https://arxiv.org/abs/2407.03502).”'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AgentInstruct：“[AGIEval上提高了40%，MMLU上提高了19%，GSM8K上提高了54%](https://arxiv.org/abs/2407.03502)。”
- en: 'NVIDIA Nemotron-4 340B Instruct: Currently [first place on the Hugging Face
    RewardBench](https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/#:~:text=It%E2%80%99s%20currently%20first%20place%20on%20the%20Hugging%20Face%20RewardBench%20leaderboard%2C%20created%20by%20AI2%2C%20for%20evaluating%20the%20capabilities%2C%20safety%20and%20pitfalls%20of%20reward%20models.)
    leaderboard, created by [AI2](https://allenai.org/), for evaluating the capabilities,
    safety and pitfalls of reward models.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA Nemotron-4 340B指令：目前在[Hugging Face RewardBench排行榜上位居第一](https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/#:~:text=It%E2%80%99s%20currently%20first%20place%20on%20the%20Hugging%20Face%20RewardBench%20leaderboard%2C%20created%20by%20AI2%2C%20for%20evaluating%20the%20capabilities%2C%20safety%20and%20pitfalls%20of%20reward%20models.)，该排行榜由[AI2](https://allenai.org/)创建，用于评估奖励模型的能力、安全性和潜在风险。
- en: 'Gretel Navigator: [73.6% win rate against human experts](https://gretel.ai/blog/how-to-create-high-quality-synthetic-data-for-fine-tuning-llms)
    on synthetic data generation, including a 25.6% lift over OpenAI GPT-4 performance.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gretel Navigator：[在合成数据生成中以73.6%的胜率战胜人类专家](https://gretel.ai/blog/how-to-create-high-quality-synthetic-data-for-fine-tuning-llms)，比OpenAI
    GPT-4的表现提高了25.6%。
- en: Industry Advances with Synthetic Data
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行业通过合成数据的进展
- en: 'Synthetic data is driving significant advancements across various industries:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据正在推动各行业的重大进展：
- en: '**Healthcare:** Rhys Parker, Chief Clinical Officer at SA Health, stated:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**医疗保健：** SA Health的首席临床官Rhys Parker表示：'
- en: “[Our synthetic data approach with Gretel has transformed how we handle sensitive
    patient information](https://startups.microsoft.com/blog/south-australian-health-synthetic-data-safe-ehr-data-sharing/).
    Data requests that previously took months or years are now achievable in days.
    This isn’t just a technological advance; it’s a fundamental shift in managing
    health data that significantly improves patient care while ensuring privacy. We
    predict synthetic data will become routine in medical research within the next
    few years, opening new frontiers in healthcare innovation.” [9]
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “[我们与 Gretel 合作的合成数据方法，已经彻底改变了我们处理敏感病患信息的方式](https://startups.microsoft.com/blog/south-australian-health-synthetic-data-safe-ehr-data-sharing/)。以往需要几个月甚至几年的数据请求，现在几天内就能完成。这不仅仅是技术的进步，更是健康数据管理的根本变革，在确保隐私的同时，显著改善了病患护理。我们预测，合成数据将在未来几年内成为医学研究中的常规工具，为医疗创新开辟新天地。”
    [9]
- en: '**Mathematical Reasoning**: DeepMind’s AlphaProof and AlphaGeometry 2 systems,'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**数学推理**：DeepMind 的 AlphaProof 和 AlphaGeometry 2 系统，'
- en: “AlphaGeometry 2, based on Gemini and trained with an order of magnitude more
    data than its predecessor”, achieved a silver-medal level at the International
    Mathematical Olympiad by solving complex mathematical problems, demonstrating
    the power of synthetic data in enhancing AI capabilities in specialized fields
    [5].
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “AlphaGeometry 2 基于 Gemini，且使用比前一版本多一个数量级的数据进行训练”，通过解决复杂的数学问题，在国际数学奥林匹克中获得了银牌，展示了合成数据在提升
    AI 能力、应对专业领域挑战中的强大作用 [5]。
- en: '**Life Sciences Research**: Nvidia’s research team reported:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**生命科学研究**：Nvidia 的研究团队报告称：'
- en: “*Synthetic data also provides an ethical alternative to using sensitive patient
    data, which helps with education and training* [*without compromising patient
    privacy*](https://developer.nvidia.com/blog/addressing-medical-imaging-limitations-with-synthetic-data-generation)”
    [4]
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “*合成数据还为使用敏感病患数据提供了一个伦理替代方案，有助于教育和培训* [*而不妥协病患隐私*](https://developer.nvidia.com/blog/addressing-medical-imaging-limitations-with-synthetic-data-generation)”
    [4]
- en: Democratizing AI Development
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 普及 AI 开发
- en: One of the most powerful aspects of synthetic data is its potential to level
    the playing field in AI development.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据最强大的一个方面是它有潜力在 AI 开发中实现公平竞争。
- en: '**Empowering Data-Poor Industries**: Empowering Data-Poor Industries: Synthetic
    data allows industries with limited access to large datasets to compete in AI
    development. This is particularly crucial for sectors where data collection is
    challenging due to privacy concerns or resource limitations.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**赋能数据匮乏行业**：合成数据使得数据较少的行业也能参与到 AI 开发中。这对于数据收集因隐私问题或资源限制而困难的行业尤为重要。'
- en: '**Customization at Scale**: Even large tech companies are leveraging synthetic
    data for customization. Microsoft’s research on the Phi-3 model demonstrates how
    synthetic data can be used to create highly specialized models:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**大规模定制化**：即使是大型科技公司也在利用合成数据进行定制化。微软对 Phi-3 模型的研究展示了如何使用合成数据创建高度专业化的模型：'
- en: “We speculate that the creation of synthetic datasets will become, in the near
    future, an important technical skill and a central topic of research in AI.” [3]
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们推测，合成数据集的创建将在不久的将来成为一项重要的技术技能，并且会成为 AI 研究的核心主题。” [3]
- en: '**Tailored Learning for AI Models**: Andrej Karpathy, former Director of AI
    at Tesla, suggests a future where we create custom “textbooks” for teaching language
    models:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**针对 AI 模型的定制化学习**：特斯拉前 AI 总监 Andrej Karpathy 提出了一个未来愿景，我们为语言模型创建定制化的“教科书”：'
- en: '**Scaling Up with Synthetic Data**: Jim Fan, an AI researcher, highlights the
    potential of synthetic data to provide the next frontier of training data:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**借助合成数据进行扩展**：AI 研究员 Jim Fan 强调了合成数据为下一阶段训练数据提供潜力：'
- en: Fan also points out that embodied agents, such as robots like Tesla’s Optimus,
    could be a significant source of synthetic data if simulated at scale.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Fan 还指出，具身代理（如特斯拉的 Optimus 机器人）如果进行大规模模拟，也可以成为合成数据的重要来源。
- en: Economics of Synthetic Data
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据的经济学
- en: 'Cost Savings and Resource Efficiency:'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本节约与资源效率：
- en: The Hugging Face blog shows that fine-tuning a custom small language model using
    synthetic data costs around $2.7 to fine-tune, compared to $3,061 with GPT-4 on
    real-world data, while emitting significantly less CO2 and offering faster inference
    speeds.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face 的博客显示，使用合成数据对定制的小型语言模型进行微调的成本约为 2.7 美元，而使用 GPT-4 处理真实世界数据则需要 3,061
    美元，同时合成数据还显著减少了 CO2 排放并提供更快的推理速度。
- en: 'Here’s a nice visualization from Hugging Face that shows the benefits across
    use cases:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Hugging Face的一幅很好的可视化图，展示了在不同使用场景中的好处：
- en: '![](../Images/6b424f898dee4b69f6883eaa4cb7613c.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b424f898dee4b69f6883eaa4cb7613c.png)'
- en: 'Source: Hugging Face Blog [6]'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Hugging Face博客 [6]
- en: 'Conclusion: A Balanced Approach'
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论：一种平衡的方式
- en: While the potential risks of model collapse should not be ignored, the real-world
    applications and benefits of synthetic data are too significant to dismiss. As
    we continue to advance in this field, a balanced approach that combines synthetic
    data with rigorous real-world validation and thoughtful generation practices will
    be key to maximize its potential.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管模型崩溃的潜在风险不应被忽视，但合成数据的实际应用和好处是如此重要，无法轻易忽视。随着我们在这一领域的不断进步，一种结合合成数据、严格的真实世界验证和深思熟虑的生成实践的平衡方法，将是最大化其潜力的关键。
- en: Synthetic data, when used responsibly and in conjunction with real-world data,
    has the potential to dramatically accelerate AI development across all sectors.
    **It’s not about replacing real data, but augmenting and extending our capabilities
    in ways we’re only beginning to explore.** By enhancing datasets with synthetic
    data, we can fill critical data gaps, address biases, and create more robust models.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据在负责任地使用并与真实数据结合时，有可能显著加速各个领域的AI发展。**这并不是要取代真实数据，而是通过扩展和增强我们的能力，探索我们尚在起步阶段的方式。**
    通过用合成数据增强数据集，我们可以填补关键的数据空白，解决偏差问题，并创建更强大的模型。
- en: By leveraging synthetic data responsibly, we can democratize AI development,
    drive innovation in data-poor sectors, and push the boundaries of what’s possible
    in machine learning — all while maintaining the integrity and reliability of our
    AI systems.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通过负责任地使用合成数据，我们可以实现AI开发的普及，推动数据贫乏领域的创新，并推动机器学习领域的边界——同时保持我们AI系统的完整性和可靠性。
- en: References
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot, N., & Anderson,
    R. (2023). The curse of recursion: Training on generated data makes models forget.
    arXiv preprint [arXiv:2305.17493](https://arxiv.org/pdf/2305.17493).'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot, N., & Anderson, R.
    (2023). 递归的诅咒：在生成数据上训练使模型遗忘。arXiv预印本 [arXiv:2305.17493](https://arxiv.org/pdf/2305.17493).
- en: Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes,
    J., … & Zhang, C. (2023). Is model collapse inevitable? Breaking the curse of
    recursion by accumulating real and synthetic data. arXiv preprint [arXiv:2404.01413](https://arxiv.org/pdf/2404.01413).
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes,
    J., … & Zhang, C. (2023). 模型崩溃是否不可避免？通过积累真实和合成数据打破递归的诅咒。arXiv预印本 [arXiv:2404.01413](https://arxiv.org/pdf/2404.01413).
- en: 'Li, Y., Bubeck, S., Eldan, R., Del Giorno, A., Gunasekar, S., & Lee, Y. T.
    (2023). Textbooks are all you need II: phi-1.5 technical report. arXiv preprint
    [arXiv:2309.05463](https://arxiv.org/pdf/2309.05463).'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Li, Y., Bubeck, S., Eldan, R., Del Giorno, A., Gunasekar, S., & Lee, Y. T. (2023).
    教科书就是你所需要的一切II：phi-1.5技术报告。arXiv预印本 [arXiv:2309.05463](https://arxiv.org/pdf/2309.05463).
- en: Nvidia Research Team. (2024). Addressing Medical Imaging Limitations with Synthetic
    Data Generation. [Nvidia Blog.](https://developer.nvidia.com/blog/addressing-medical-imaging-limitations-with-synthetic-data-generation/)
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nvidia研究团队. (2024). 通过合成数据生成解决医学影像的局限性. [Nvidia博客.](https://developer.nvidia.com/blog/addressing-medical-imaging-limitations-with-synthetic-data-generation/)
- en: DeepMind Blog. (2024). AI achieves silver-medal standard solving International
    Mathematical Olympiad problems. [DeepMind](https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level).
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DeepMind博客. (2024). AI达到银牌水平，解决国际数学奥林匹克问题. [DeepMind](https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level).
- en: 'Hugging Face Blog on Synthetic Data. (2024). Synthetic data: save money, time
    and carbon with open source. [Hugging Face](https://huggingface.co/blog/synthetic-data-save-costs).'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hugging Face博客关于合成数据的内容. (2024). 合成数据：通过开源节省成本、时间和碳排放. [Hugging Face](https://huggingface.co/blog/synthetic-data-save-costs).
- en: Karpathy, A. (2024). Custom Textbooks for Language Models. [Twitter](https://x.com/karpathy/status/1509289133637832705).
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Karpathy, A. (2024). 语言模型的定制教科书. [Twitter](https://x.com/karpathy/status/1509289133637832705).
- en: Fan, J. (2024). Synthetic Data and the Future of AI Training. [Twitter](https://x.com/DrJimFan/status/1727505774514180188).
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Fan, J. (2024). 合成数据与AI训练的未来. [Twitter](https://x.com/DrJimFan/status/1727505774514180188).
- en: South Australian Health. (2024). South Australian Health Partners with Gretel
    to Pioneer State-Wide Synthetic Data Initiative for Safe EHR Data Sharing. [Microsoft
    for Startups Blog](https://startups.microsoft.com/blog/south-australian-health-synthetic-data-safe-ehr-data-sharing/).
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 南澳大利亚卫生部。（2024年）。南澳大利亚卫生部与Gretel合作，开创全州范围的合成数据倡议，以确保安全的电子健康记录（EHR）数据共享。[Microsoft
    for Startups Blog](https://startups.microsoft.com/blog/south-australian-health-synthetic-data-safe-ehr-data-sharing/)。
- en: Introducing Apple’s On-Device and Server Foundation Models. [https://machinelearning.apple.com/research/introducing-apple-foundation-models](https://machinelearning.apple.com/research/introducing-apple-foundation-models)
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 介绍苹果的设备端和服务器基础模型。[https://machinelearning.apple.com/research/introducing-apple-foundation-models](https://machinelearning.apple.com/research/introducing-apple-foundation-models)
- en: 'AgentInstruct: Toward Generative Teaching with Agentic Flows. [https://arxiv.org/abs/2407.03502](https://arxiv.org/abs/2407.03502)'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'AgentInstruct: 面向生成性教学的代理流。[https://arxiv.org/abs/2407.03502](https://arxiv.org/abs/2407.03502)'
- en: Gerstgrasser, M. (2024). Comment on LinkedIn post by Yev Meyer, Ph.D. LinkedIn.
    [https://www.linkedin.com/feed/update/urn:li:activity:7223028230444785664](https://www.linkedin.com/feed/update/urn:li:activity:7223028230444785664?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7223028230444785664%2C7223050680641425411%29&replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7223028230444785664%2C7223361473706651648%29)
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gerstgrasser, M.（2024年）。评论Yev Meyer博士在LinkedIn上的帖子。LinkedIn。[https://www.linkedin.com/feed/update/urn:li:activity:7223028230444785664](https://www.linkedin.com/feed/update/urn:li:activity:7223028230444785664?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7223028230444785664%2C7223050680641425411%29&replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7223028230444785664%2C7223361473706651648%29)
