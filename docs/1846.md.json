["```py\nimport matplotlib.pyplot as plt\n\nimport torchvision.transforms as transforms\n\nfrom FashionMNIST import FashionMNIST\n\ntrain_dataset = FashionMNIST(\"./FashionMNIST\", \n                             train=True, \n                             transform=transforms.ToTensor(), \n                             download=True,\n                             )\ntest_dataset = FashionMNIST(\"./FashionMNIST\", \n                            train=False, \n                            transform=transforms.ToTensor(), \n                            download=True,\n                            )\nfinetune_dataset = FashionMNIST(\"./FashionMNIST\", \n                                train=True, \n                                transform=transforms.ToTensor(), \n                                download=True, \n                                first_k=1000,\n                                )\n\n# Create a subplot with 4x4 grid\nfig, axs = plt.subplots(4, 4, figsize=(8, 8))\n\n# Loop through each subplot and plot an image\nfor i in range(4):\n    for j in range(4):\n        image, label = train_dataset[i * 4 + j]  # Get image and label\n        image_numpy = image.numpy().squeeze()    # Convert image tensor to numpy array\n        axs[i, j].imshow(image_numpy, cmap='gray')  # Plot the image\n        axs[i, j].axis('off')  # Turn off axis\n        axs[i, j].set_title(f\"Label: {label}\")  # Set title with label\n\nplt.tight_layout()  # Adjust layout\nplt.show()  # Show plot\n```", "```py\nimport torch.nn as nn\n\nclass supervised_classification(nn.Module):\n\n    def __init__(self):\n        super(supervised_classification, self).__init__()\n\n        self.backbone = nn.Sequential(\n                                nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n                                nn.ReLU(),\n                                nn.BatchNorm2d(32),\n                                nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n                                nn.ReLU(),\n                                nn.BatchNorm2d(64),\n                                nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n                                nn.ReLU(),\n                                nn.BatchNorm2d(128),\n        )\n\n        self.fc = nn.Sequential(\n                                nn.Linear(128*4*4, 32),\n                                nn.ReLU(),\n                                nn.Linear(32, 10),\n        )\n\n    def forward(self, x):\n        x = self.backbone(x).view(-1, 128 * 4 * 4)\n\n        return self.fc(x)\n```", "```py\nimport tqdm\n\nimport torch\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nimport wandb\n\nwandb_config = {\n    \"learning_rate\": 0.001,\n    \"architecture\": \"fashion mnist classification full training\",\n    \"dataset\": \"FashionMNIST\",\n    \"epochs\": 10,\n    \"batch_size\": 64,\n    }\n\nwandb.init(\n    # set the wandb project where this run will be logged\n    project=\"supervised_classification\",\n    # track hyperparameters and run metadata\n    config=wandb_config,\n)\n\n# Initialize model and optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nsupervised = supervised_classification()\n\noptimizer = optim.SGD(supervised.parameters(), \n                      lr=wandb_config[\"learning_rate\"], \n                      momentum=0.9, \n                      weight_decay=1e-5,\n                      )\n\ntrain_dataloader = DataLoader(train_dataset, \n                              batch_size=wandb_config[\"batch_size\"], \n                              shuffle=True,\n                              )\n\n# Training loop\nloss_fun = nn.CrossEntropyLoss()\nfor epoch in range(wandb_config[\"epochs\"]):\n    supervised.train()\n\n    train_loss = 0\n    for batch_idx, (image, target) in enumerate(tqdm.tqdm(train_dataloader, total=len(train_dataloader))):\n        optimizer.zero_grad()\n\n        prediction = supervised(image)\n\n        loss = loss_fun(prediction, target)\n        loss.backward()\n        optimizer.step()\n\n        wandb.log({\"training loss\": loss})\n\ntorch.save(supervised.state_dict(), \"weights/fully_supervised.pt\")\n```", "```py\nfrom sklearn.metrics import classification_report\n\nsupervised = supervised_classification()\n\nsupervised.load_state_dict(torch.load(\"weights/fully_supervised.pt\"))\nsupervised.eval()\nsupervised.to(device)\n\ntarget_list = []\nprediction_list = []\nfor batch_idx, (image, target) in enumerate(tqdm.tqdm(test_dataloader, total=len(test_dataloader))):\n    with torch.no_grad():\n        prediction = supervised(image.to(device))\n\n    prediction_list.extend(torch.argmax(prediction, dim=1).detach().cpu().numpy())\n    target_list.extend(target.detach().cpu().numpy())\n\nprint(classification_report(target_list, prediction_list))\n\n# Create a subplot with 4x4 grid\nfig, axs = plt.subplots(4, 4, figsize=(8, 8))\n\n# Loop through each subplot and plot an image\nfor i in range(4):\n    for j in range(4):\n        image, label = test_dataset[i * 4 + j]  # Get image and label\n        image_numpy = image.numpy().squeeze()    # Convert image tensor to numpy array\n        prediction = supervised(torch.unsqueeze(image, dim=0).to(device))\n        prediction = torch.argmax(prediction, dim=1).detach().cpu().numpy()\n        axs[i, j].imshow(image_numpy, cmap='gray')  # Plot the image\n        axs[i, j].axis('off')  # Turn off axis\n        axs[i, j].set_title(f\"Label: {label}, Pred: {prediction}\")  # Set title with label\n\nplt.tight_layout()  # Adjust layout\nplt.show()  # Show plot\n```", "```py\nimport tqdm\n\nimport torch\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nimport wandb\n\nwandb_config = {\n    \"learning_rate\": 0.001,\n    \"architecture\": \"fashion mnist classification full training on finetune set\",\n    \"dataset\": \"FashionMNIST\",\n    \"epochs\": 100,\n    \"batch_size\": 64,\n    }\n\nwandb.init(\n    # set the wandb project where this run will be logged\n    project=\"supervised_classification\",\n    # track hyperparameters and run metadata\n    config=wandb_config,\n)\n\n# Initialize model and optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nsupervised = supervised_classification()\n\noptimizer = optim.SGD(supervised.parameters(), \n                      lr=wandb_config[\"learning_rate\"], \n                      momentum=0.9, \n                      weight_decay=1e-5,\n                      )\n\nfinetune_dataloader = DataLoader(finetune_dataset, \n                                 batch_size=wandb_config[\"batch_size\"], \n                                 shuffle=True,\n                                 )\n\n# Training loop\nloss_fun = nn.CrossEntropyLoss()\nfor epoch in range(wandb_config[\"epochs\"]):\n    supervised.train()\n\n    train_loss = 0\n    for batch_idx, (image, target) in enumerate(tqdm.tqdm(finetune_dataloader, total=len(finetune_dataloader))):\n        optimizer.zero_grad()\n\n        prediction = supervised(image)\n\n        loss = loss_fun(prediction, target)\n        loss.backward()\n        optimizer.step()\n\n        wandb.log({\"training loss\": loss})\n\ntorch.save(supervised.state_dict(), \"weights/fully_supervised_finetunedataset.pt\")\n```", "```py\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nclass SimSiam(nn.Module):\n\n    def __init__(self):\n\n        super(SimSiam, self).__init__()\n\n        self.backbone = nn.Sequential(\n                                nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n                                nn.ReLU(),\n                                nn.BatchNorm2d(32),\n                                nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n                                nn.ReLU(),\n                                nn.BatchNorm2d(64),\n                                nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n                                nn.ReLU(),\n                                nn.BatchNorm2d(128),\n        )\n\n        self.prediction_mlp = nn.Sequential(nn.Linear(128*4*4, 64),\n                               nn.BatchNorm1d(64),\n                               nn.ReLU(),\n                               nn.Linear(64, 128*4*4),\n        )\n\n    def forward(self, x):\n        x = self.backbone(x)\n\n        x = x.view(-1, 128 * 4 * 4)\n        pred_output = self.prediction_mlp(x)\n        return x, pred_output\n\ncos = nn.CosineSimilarity(dim=1, eps=1e-6)\ndef negative_cosine_similarity_stopgradient(pred, proj):\n    return -cos(pred, proj.detach()).mean()\n```", "```py\nimport tqdm\n\nimport torch\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import RandAugment\n\nimport wandb\n\nwandb_config = {\n    \"learning_rate\": 0.0001,\n    \"architecture\": \"simsiam\",\n    \"dataset\": \"FashionMNIST\",\n    \"epochs\": 100,\n    \"batch_size\": 256,\n    }\n\nwandb.init(\n    # set the wandb project where this run will be logged\n    project=\"simsiam\",\n    # track hyperparameters and run metadata\n    config=wandb_config,\n)\n\n# Initialize model and optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nsimsiam = SimSiam()\n\nrandom_augmenter = RandAugment(num_ops=5)\n\noptimizer = optim.SGD(simsiam.parameters(), \n                      lr=wandb_config[\"learning_rate\"], \n                      momentum=0.9, \n                      weight_decay=1e-5,\n                      )\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=wandb_config[\"batch_size\"], shuffle=True)\n\n# Training loop\nfor epoch in range(wandb_config[\"epochs\"]):\n    simsiam.train()\n\n    print(f\"Epoch {epoch}\")\n    train_loss = 0\n    for batch_idx, (image, _) in enumerate(tqdm.tqdm(train_dataloader, total=len(train_dataloader))):\n        optimizer.zero_grad()\n\n        aug1, aug2 = random_augmenter((image*255).to(dtype=torch.uint8)).to(dtype=torch.float32) / 255.0, \\\n                        random_augmenter((image*255).to(dtype=torch.uint8)).to(dtype=torch.float32) / 255.0\n\n        proj1, pred1 = simsiam(aug1)\n        proj2, pred2 = simsiam(aug2)\n\n        loss = negative_cosine_similarity_stopgradient(pred1, proj2) / 2 + negative_cosine_similarity_stopgradient(pred2, proj1) / 2\n        loss.backward()\n        optimizer.step()\n\n        wandb.log({\"training loss\": loss})\n\n    if (epoch+1) % 10 == 0:\n        torch.save(simsiam.state_dict(), f\"weights/simsiam_epoch{epoch+1}.pt\")\n```", "```py\nimport tqdm\nimport numpy as np\n\nimport torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nsimsiam = SimSiam()                      \n\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\nsimsiam.load_state_dict(torch.load(\"weights/simsiam_epoch100.pt\"))\n\nsimsiam.eval()\nsimsiam.to(device)\n\nfeatures = []\nlabels = []\nfor batch_idx, (image, target) in enumerate(tqdm.tqdm(test_dataloader, total=len(test_dataloader))):\n\n    with torch.no_grad():\n\n        proj, pred = simsiam(image.to(device))\n\n    features.extend(np.squeeze(pred.detach().cpu().numpy()).tolist())\n    labels.extend(target.detach().cpu().numpy().tolist())\n\nimport plotly.express as px\nimport umap.umap_ as umap\n\nreducer = umap.UMAP(n_components=3, n_neighbors=10, metric=\"cosine\")\nprojections = reducer.fit_transform(np.array(features))\n\npx.scatter(projections, x=0, y=1,\n    color=labels, labels={'color': 'Fashion MNIST Labels'}\n)\n```", "```py\nimport tqdm\n\nimport torch\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nimport wandb\n\nwandb_config = {\n    \"learning_rate\": 0.001,\n    \"architecture\": \"supervised learning with simsiam backbone\",\n    \"dataset\": \"FashionMNIST\",\n    \"epochs\": 100,\n    \"batch_size\": 64,\n    }\nwandb.init(\n    # set the wandb project where this run will be logged\n    project=\"simsiam-finetune\",\n    # track hyperparameters and run metadata\n    config=wandb_config,\n)\n\n# Initialize model and optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nsupervised = supervised_classification()\n\nmodel_dict = supervised.state_dict()\nsimsiam_dict = {k: v for k, v in model_dict.items() if k in torch.load(\"simsiam.pt\")}\nsupervised.load_state_dict(simsiam_dict, strict=False)\n\nfinetune_dataloader = DataLoader(finetune_dataset, batch_size=32, shuffle=True)\n\nfor param in supervised.backbone.parameters():\n    param.requires_grad = False\nparameters = [para for para in supervised.parameters() if para.requires_grad]\noptimizer = optim.SGD(parameters, \n                      lr=wandb_config[\"learning_rate\"], \n                      momentum=0.9, \n                      weight_decay=1e-5,\n                      )\n\n# Training loop\nfor epoch in range(wandb_config[\"epochs\"]):\n    supervised.train()\n\n    train_loss = 0\n    for batch_idx, (image, target) in enumerate(tqdm.tqdm(finetune_dataloader)):\n        optimizer.zero_grad()\n\n        prediction = supervised(image)\n\n        loss = nn.CrossEntropyLoss()(prediction, target)\n        loss.backward()\n        optimizer.step()\n\n        wandb.log({\"training loss\": loss})\n\ntorch.save(supervised.state_dict(), \"weights/supervised_with_simsiam.pt\")\n```"]