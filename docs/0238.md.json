["```py\nimport numpy as np\n\nfrom mapie._machine_precision import EPSILON\nfrom mapie.conformity_scores import ConformityScore\nfrom mapie._typing import ArrayLike, NDArray\n\nclass PoissonConformityScore(ConformityScore):\n    \"\"\"\n    Poisson conformity score.\n\n    The signed conformity score = (y - y_pred) / y_pred**(1/2).\n    The conformity score is not symmetrical.\n    y must be positive\n    y_pred must be strictly positive\n\n    This is appropriate when the confidence interval is not symmetrical and\n    its range depends on the predicted values.\n    \"\"\"\n\n    def __init__(\n        self,\n    ) -> None:\n        super().__init__(sym=False, consistency_check=False, eps=EPSILON)\n\n    def _check_observed_data(\n        self,\n        y: ArrayLike,\n    ) -> None:\n        if not self._all_positive(y):\n            raise ValueError(\n                f\"At least one of the observed target is strictly negative \"\n                f\"which is incompatible with {self.__class__.__name__}. \"\n                \"All values must be positive.\"\n            )\n\n    def _check_predicted_data(\n        self,\n        y_pred: ArrayLike,\n    ) -> None:\n        if not self._all_strictly_positive(y_pred):\n            raise ValueError(\n                f\"At least one of the predicted target is negative \"\n                f\"which is incompatible with {self.__class__.__name__}. \"\n                \"All values must be strictly positive.\"\n            )\n\n    @staticmethod\n    def _all_positive(\n        y: ArrayLike,\n    ) -> bool:\n        return np.all(np.greater_equal(y, 0))\n\n    @staticmethod\n    def _all_strictly_positive(\n        y: ArrayLike,\n    ) -> bool:\n        return np.all(np.greater(y, 0))\n\n    def get_signed_conformity_scores(\n        self,\n        X: ArrayLike,\n        y: ArrayLike,\n        y_pred: ArrayLike,\n    ) -> NDArray:\n        \"\"\"\n        Compute the signed conformity scores from the observed values\n        and the predicted ones, from the following formula:\n        signed conformity score = (y - y_pred) / y_pred**(1/2)\n        \"\"\"\n        self._check_observed_data(y)\n        self._check_predicted_data(y_pred)\n        return np.divide(np.subtract(y, y_pred), np.power(y_pred, 1 / 2))\n\n    def get_estimation_distribution(\n        self, X: ArrayLike, y_pred: ArrayLike, conformity_scores: ArrayLike\n    ) -> NDArray:\n        \"\"\"\n        Compute samples of the estimation distribution from the predicted\n        values and the conformity scores, from the following formula:\n        signed conformity score = (y - y_pred) / y_pred**(1/2)\n        <=> y = y_pred + y_pred**(1/2) * signed conformity score\n\n        ``conformity_scores`` can be either the conformity scores or\n        the quantile of the conformity scores.\n        \"\"\"\n        self._check_predicted_data(y_pred)\n        return np.add(y_pred, np.multiply(np.power(y_pred, 1 / 2), conformity_scores))\n```", "```py\nclass TweedieConformityScore(ConformityScore):\n    \"\"\"\n    Tweedie conformity score.\n\n    The signed conformity score = (y - y_pred) / y_pred**(p/2).\n    The conformity score is not symmetrical.\n    y must be positive\n    y_pred must be strictly positive\n\n    This is appropriate when the confidence interval is not symmetrical and\n    its range depends on the predicted values.\n    \"\"\"\n\n    def __init__(self, p) -> None:\n        self.p = p\n        super().__init__(sym=False, consistency_check=False, eps=EPSILON)\n\n    def _check_observed_data(\n        self,\n        y: ArrayLike,\n    ) -> None:\n        if not self._all_positive(y):\n            raise ValueError(\n                f\"At least one of the observed target is strictly negative \"\n                f\"which is incompatible with {self.__class__.__name__}. \"\n                \"All values must be positive.\"\n            )\n\n    def _check_predicted_data(\n        self,\n        y_pred: ArrayLike,\n    ) -> None:\n        if not self._all_strictly_positive(y_pred):\n            raise ValueError(\n                f\"At least one of the predicted target is negative \"\n                f\"which is incompatible with {self.__class__.__name__}. \"\n                \"All values must be strictly positive.\"\n            )\n\n    @staticmethod\n    def _all_positive(\n        y: ArrayLike,\n    ) -> bool:\n        return np.all(np.greater_equal(y, 0))\n\n    @staticmethod\n    def _all_strictly_positive(\n        y: ArrayLike,\n    ) -> bool:\n        return np.all(np.greater(y, 0))\n\n    def get_signed_conformity_scores(\n        self,\n        X: ArrayLike,\n        y: ArrayLike,\n        y_pred: ArrayLike,\n    ) -> NDArray:\n        \"\"\"\n        Compute the signed conformity scores from the observed values\n        and the predicted ones, from the following formula:\n        signed conformity score = (y - y_pred) / y_pred**(1/2)\n        \"\"\"\n        self._check_observed_data(y)\n        self._check_predicted_data(y_pred)\n        return np.divide(np.subtract(y, y_pred), np.power(y_pred, self.p / 2))\n\n    def get_estimation_distribution(\n        self, X: ArrayLike, y_pred: ArrayLike, conformity_scores: ArrayLike\n    ) -> NDArray:\n        \"\"\"\n        Compute samples of the estimation distribution from the predicted\n        values and the conformity scores, from the following formula:\n        signed conformity score = (y - y_pred) / y_pred**(1/2)\n        <=> y = y_pred + y_pred**(1/2) * signed conformity score\n\n        ``conformity_scores`` can be either the conformity scores or\n        the quantile of the conformity scores.\n        \"\"\"\n        self._check_predicted_data(y_pred)\n        return np.add(\n            y_pred, np.multiply(np.power(y_pred, self.p / 2), conformity_scores)\n        )\n```"]