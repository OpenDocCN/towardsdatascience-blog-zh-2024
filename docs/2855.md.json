["```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Data preparation\ndataset_dict = {\n    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'overcast', 'sunny', 'overcast', 'rain', 'sunny', 'overcast', 'rain', 'sunny', 'rain',\n                'sunny', 'overcast', 'rain', 'sunny', 'rain', 'overcast', 'sunny', 'rain', 'overcast', 'sunny', 'overcast', 'rain', 'sunny', 'rain'],\n    'Temp.': [92.0, 78.0, 75.0, 70.0, 62.0, 68.0, 85.0, 73.0, 65.0, 88.0, 76.0, 63.0, 83.0, 66.0,\n              91.0, 77.0, 64.0, 79.0, 61.0, 72.0, 86.0, 67.0, 74.0, 89.0, 75.0, 65.0, 82.0, 63.0],\n    'Humid.': [95.0, 65.0, 82.0, 90.0, 75.0, 70.0, 88.0, 78.0, 95.0, 72.0, 80.0, 85.0, 68.0, 92.0,\n               93.0, 80.0, 88.0, 70.0, 78.0, 75.0, 85.0, 92.0, 77.0, 68.0, 83.0, 90.0, 65.0, 87.0],\n    'Wind': [False, False, False, True, False, False, False, True, False, False, True, True, False, True,\n             True, True, False, False, True, False, True, True, False, False, True, False, False, True],\n    'Num_Players': [25, 85, 80, 30, 17, 82, 45, 78, 32, 65, 70, 20, 87, 24,\n                   28, 68, 35, 75, 25, 72, 55, 32, 70, 80, 65, 24, 85, 25]\n}\n\n# Data preprocessing\ndf = pd.DataFrame(dataset_dict)\ndf = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)\ndf['Wind'] = df['Wind'].astype(int)\n```", "```py\n# Split features and target\nX, y = df.drop('Num_Players', axis=1), df['Num_Players']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\n```", "```py\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Define constants\nRANDOM_STATE = 3 # As regression tree can be sensitive, setting this parameter assures that we always get the same tree\nMAX_DEPTH = 5\n\n# Initialize models\ntrees = {depth: DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_STATE).fit(X_train, y_train) \n         for depth in range(1, MAX_DEPTH + 1)}\n```", "```py\n import matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\n\n# Plot trees\nfor depth in range(1, MAX_DEPTH + 1):\n    plt.figure(figsize=(12, 0.5*depth+1.5), dpi=300)\n    plot_tree(trees[depth], feature_names=X_train.columns.tolist(), \n              filled=True, rounded=True, impurity=False, precision=1, fontsize=8)\n    plt.title(f'Depth {depth}')\n    plt.show()\n```", "```py\n# Create training predictions DataFrame\ntrain_predictions = pd.DataFrame({\n    f'Depth_{i}': trees[i].predict(X_train) for i in range(1, MAX_DEPTH + 1)\n})\n#train_predictions['Actual'] = y_train.values\ntrain_predictions.index = X_train.index\n\n# Create test predictions DataFrame\ntest_predictions = pd.DataFrame({\n    f'Depth_{i}': trees[i].predict(X_test) for i in range(1, MAX_DEPTH + 1)\n})\n#test_predictions['Actual'] = y_test.values\ntest_predictions.index = X_test.index\n\nprint(\"\\nTraining Predictions:\")\nprint(train_predictions.round(1))\nprint(\"\\nTest Predictions:\")\nprint(test_predictions.round(1))\n```", "```py\nfrom sklearn.metrics import root_mean_squared_error\n\n# Calculate RMSE values\ntrain_rmse = {depth: root_mean_squared_error(y_train, tree.predict(X_train))\n              for depth, tree in trees.items()}\ntest_rmse = {depth: root_mean_squared_error(y_test, tree.predict(X_test))\n             for depth, tree in trees.items()}\n\n# Print RMSE summary as DataFrame\nsummary_df = pd.DataFrame({\n    'Train RMSE': train_rmse.values(),\n    'Test RMSE': test_rmse.values()\n}, index=range(1, MAX_DEPTH + 1))\nsummary_df.index.name = 'max_depth'\n\nprint(\"\\nSummary of RMSE values:\")\nprint(summary_df.round(2))\n```", "```py\n# Create figure\nplt.figure(figsize=(4, 3), dpi=300)\nax = plt.gca()\n\n# Plot main lines\nplt.plot(summary_df.index, summary_df['Train RMSE'], marker='o', label='Train RMSE', \n         linestyle='-', color='crimson', alpha=0.1)\nplt.plot(summary_df.index, summary_df['Test RMSE'], marker='o', label='Test RMSE', \n         linestyle='-', color='crimson', alpha=0.6)\n\n# Add vertical lines and difference labels\nfor depth in summary_df.index:\n    train_val = summary_df.loc[depth, 'Train RMSE']\n    test_val = summary_df.loc[depth, 'Test RMSE']\n    diff = abs(test_val - train_val)\n\n    # Draw vertical line\n    plt.vlines(x=depth, ymin=min(train_val, test_val), ymax=max(train_val, test_val), \n               colors='black', linestyles='-', lw=0.5)\n\n    # Add white box behind text\n    bbox_props = dict(boxstyle=\"round,pad=0.1\", fc=\"white\", ec=\"white\")\n    plt.text(depth - 0.15, (train_val + test_val) / 2, f'{diff:.1f}', \n             verticalalignment='center', fontsize=9, fontweight='bold',\n             bbox=bbox_props)\n\n# Customize plot\nplt.xlabel('Max Depth')\nplt.ylabel('RMSE')\nplt.title('Train vs Test RMSE by Tree Depth')\nplt.grid(True, linestyle='--', alpha=0.2)\nplt.legend()\n\n# Remove spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Set limits\nplt.xlim(0.8, 5.2)\nplt.ylim(0, summary_df['Train RMSE'].max() * 1.1)\n\nplt.tight_layout()\nplt.show()\n```", "```py\nfrom sklearn.model_selection import KFold\n\ndef evaluate_model(X_train, y_train, X_test, y_test, n_splits=7, random_state=42):\n   kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n   depths = range(1, 6)\n   results = []\n\n   for depth in depths:\n       # Cross-validation scores\n       cv_scores = []\n       for train_idx, val_idx in kf.split(X_train):\n           # Split data\n           X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n           y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n           # Train and evaluate\n           model = DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_STATE)\n           model.fit(X_tr, y_tr)\n           val_pred = model.predict(X_val)\n           cv_scores.append(np.sqrt(mean_squared_error(y_val, val_pred)))\n\n       # Test set performance\n       model = DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_STATE)\n       model.fit(X_train, y_train)\n       test_pred = model.predict(X_test)\n       test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n\n       # Store results\n       results.append({\n           'CV Mean RMSE': np.mean(cv_scores),\n           'CV Std': np.std(cv_scores),\n           'Test RMSE': test_rmse\n       })\n\n   return pd.DataFrame(results, index=pd.Index(depths, name='Depth')).round(2)\n\n# Usage:\ncv_df = evaluate_model(X_train, y_train, X_test, y_test)\nprint(cv_df)\n```"]