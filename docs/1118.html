<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Extracting Information from Natural Language Using Generative AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Extracting Information from Natural Language Using Generative AI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/extracting-information-from-natural-language-using-generative-ai-ed64dcf1de66?source=collection_archive---------5-----------------------#2024-05-03">https://towardsdatascience.com/extracting-information-from-natural-language-using-generative-ai-ed64dcf1de66?source=collection_archive---------5-----------------------#2024-05-03</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="4c87" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Extracting and structuring text elements with high accuracy using small models</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@orenmatar?source=post_page---byline--ed64dcf1de66--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Oren Matar" class="l ep by dd de cx" src="../Images/8b1fa6aa3585fc283d51828b53a0754c.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*oq69-9-IJCBKnNzJYPqnXA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--ed64dcf1de66--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@orenmatar?source=post_page---byline--ed64dcf1de66--------------------------------" rel="noopener follow">Oren Matar</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--ed64dcf1de66--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 3, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/12de85af31069135ae128e15c4e03a46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*od9dPkAkn590f6abA7D7Hg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image generated by an AI by the author</figcaption></figure><p id="e9e2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In this post, I’ll introduce a paradigm recently developed at Anaplan for extracting temporal information from natural language text, as part of an NLQ (natural language query) project. While I will focus on time extraction, the paradigm is versatile and applicable for parsing various unstructured texts and extracting diverse patterns of information. This includes named entity recognition, text-to-SQL conversion, quantity extraction, and more.</p><p id="16d4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The paradigm's core lies in constructing a flexible pipeline, which provides maximal flexibility, making it easy to fine-tune a model to extract the meaning from any conceivable expression in the language. It is based on a deep learning model (transformers) but for us, it achieved a 99.98% accuracy which is relatively rare for ML methods. Additionally, it does not utilize LLMs (large language models), in fact, it requires a minimal transformer model. This yields a compact, adaptable ML model, exhibiting the precision of rule-based systems.</p><p id="a001" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For those seeking time, numerical value, or phone number extraction, Facebook’s <a class="af nx" href="https://github.com/facebook/duckling" rel="noopener ugc nofollow" target="_blank">Duckling package</a> offers a rule-based solution. However, if Duckling falls short of your requirements or you’re eager to explore a new ML paradigm, read on.</p><h2 id="a30e" class="ny nz fq bf oa ob oc od oe of og oh oi nk oj ok ol no om on oo ns op oq or os bk">Can LLMs capture the meaning?</h2><p id="5a44" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">LLMs, despite their capabilities, face challenges in parsing such phrases and extracting their meaning comprehensively. Consider the expression “the first 15 weeks of last year.” Converting this to a date range necessitates the model to determine the current year, subtract one, and calculate the position of the 15th week as it adjusts for leap years. Language models were not built for this kind of computation.</p><p id="7deb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In my experience, LLMs can accurately output the correct date range around 90–95% of the time but struggle with the remaining 5–10%, no matter the prompting techniques you use. Not to mention: LLMs are resource-intensive and slow.</p><p id="4305" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Thankfully, by following three principles, compact transformers can successfully accomplish the task</p><ol class=""><li id="549d" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw oy oz pa bk">Separate information extraction from logical deduction.</li><li id="a962" class="nb nc fq nd b go pb nf ng gr pc ni nj nk pd nm nn no pe nq nr ns pf nu nv nw oy oz pa bk">Auto-generate a dataset using structured patterns.</li><li id="417f" class="nb nc fq nd b go pb nf ng gr pc ni nj nk pd nm nn no pe nq nr ns pf nu nv nw oy oz pa bk">Constrain the generative AI to the required structure.</li></ol><p id="319b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In this post, I will cover the first two, as the third one I covered in <a class="af nx" href="https://medium.com/towards-data-science/structured-generative-ai-e772123428e4" rel="noopener">a previous post</a>.</p><h2 id="3798" class="ny nz fq bf oa ob oc od oe of og oh oi nk oj ok ol no om on oo ns op oq or os bk">Separate information extraction from logical deduction</h2><p id="8602" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">The first principle is to ensure that the language model’s role is to extract information from free text, rather than to make any logical deduction: logical deductions can easily be implemented in code.</p><p id="f466" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Consider the phrase: “How many movies came out two years ago?” The language model’s task should be to identify that the relevant year is: <code class="cx pg ph pi pj b"><strong class="nd fr">this_year - 2</strong></code>, without calculating the actual year (which means it doesn’t need to know the current year). Its focus is parsing the meaning and structuring unstructured language. Once that formula is extracted, we can implement its calculation in code.</p><p id="6f48" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For this to work, we introduce a Structured Time Language (STL) capable of expressing time elements. For instance, “on 2020” translates to “TIME.year==2020,” and “three months from now” becomes “NOW.month==3.” While the entire STL language isn’t detailed here, it should be relatively intuitive: you can reference attributes like year, quarter, and month for an absolute time or relative to NOW. The translation of “the last 12 weeks of last year” is “NOW.year==-1 AND TIME.week&gt;=-12”</p><p id="b2ad" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">By removing any logical deduction or calculation from the task, we take a huge burden off the language model and allow it to focus on information extraction. This division of labor will improve its accuracy significantly. After the translation process is complete, it is straightforward to develop code for a parser that reads the structured language and retrieves the necessary date range.</p><p id="956b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Since this is a translation task — from natural language to STL — we used an encoder-decoder transformer. We used the <a class="af nx" href="https://huggingface.co/docs/transformers/en/model_doc/bart" rel="noopener ugc nofollow" target="_blank">Bart model from Hugging Face</a>, which can easily be fine-tuned for this task.</p><p id="a674" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">But how do we get the data for training the model?</p><h2 id="8869" class="ny nz fq bf oa ob oc od oe of og oh oi nk oj ok ol no om on oo ns op oq or os bk"><strong class="al">Auto-generate a dataset using structured patterns</strong></h2><p id="13e0" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Since a training dataset for this translation task does not exist, we must generate it ourselves. This was done by following these steps:</p><p id="56eb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="pk">Step one</em>: Write functions to map datetime objects to both “natural language” and STL formats:</p><pre class="ml mm mn mo mp pl pj pm bp pn bb bk"><span id="f3bf" class="po nz fq pj b bg pp pq l pr ps">def since_year(datetime):<br/>     free_text = f“since  {datetime.year}”<br/>     answer = f”TIME.year &gt;= {datetime.year}”<br/>     return free_text, answer<br/><br/>def half_literal(datetime):<br/>     free_text = datetime.strftime(“%-d, %B %Y”) <br/>     answer = f”TIME.date &gt;= {datetime}”<br/>     return free_text, answer<br/><br/>def until_quarter_year(datetime):<br/>    q = datetime.month//3<br/>    free_text = f”until Q{q}-{datetime.year}”<br/>    answer = f”TIME.year=={datetime.year} AND TIME.quarter=={q}”<br/>    return free_text, answer</span></pre><p id="325a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Given a datetime object, these functions return a tuple of free text and its corresponding STL, for instance: “since 2020”, “TIME.year &gt;= 2020”.</p><p id="fad5" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="pk">Step two</em>: Sample a random function, and sample a random date within a specified range:</p><pre class="ml mm mn mo mp pl pj pm bp pn bb bk"><span id="7a1e" class="po nz fq pj b bg pp pq l pr ps">date = np.random.choice(pd.date_range('1970/1/1', '2040/12/31'))</span></pre><p id="557b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">now insert the datetime to the function.</p><p id="0325" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="pk">Step three</em>: Append the free text to a random question (we can easily randomly generate questions or draw them from some question dataset, their quality and meaning is not very important).</p><p id="3502" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">With this pipeline, we can quickly generate 1000s of text-STL pairs, for example:</p><ul class=""><li id="94e6" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw pt oz pa bk">“What was the GDP growth in Q2–2019?”, “TIME.quarter==2 AND TIME.year==2019”</li><li id="a0f2" class="nb nc fq nd b go pb nf ng gr pc ni nj nk pd nm nn no pe nq nr ns pf nu nv nw pt oz pa bk">“Since 2017, who won the most Oscars?”, “TIME.year&gt;=2017”</li><li id="0ca0" class="nb nc fq nd b go pb nf ng gr pc ni nj nk pd nm nn no pe nq nr ns pf nu nv nw pt oz pa bk">“Who was the president on 3 May 2020?”, “TIME.date==2020/05/03”</li></ul><p id="27d1" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This approach ensures flexibility in adding new patterns effortlessly. If you find a time expression that is not covered by one of these functions (e.g. “In N years”), you can write a function that will generate examples for this pattern within seconds.</p><p id="5a67" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In practice, we can optimize the code efficiency further. Rather than separate functions for each pattern like “since 2020” and “until 2020,” we can randomly sample connective words like “since,” “until,” “on,” etc. This initial batch of functions may require some time to develop, but you can quickly scale to 100s of patterns. Subsequently, addressing any missing expressions becomes trivial, as the pipeline is already established. With a few iterations, nearly all relevant expressions can be covered.</p><p id="0db3" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Moreover, we don’t need to cover all the expressions</strong>: Since the transformer model we used is pre-trained on a huge corpus of text, it will generalize from the provided patterns to new ones.</p><p id="c596" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Finally, we can use an LLM to generate more examples</strong>. Simply ask an LLM:</p><pre class="ml mm mn mo mp pl pj pm bp pn bb bk"><span id="7f2b" class="po nz fq pj b bg pp pq l pr ps">Hey, what's another way to write "What was the revenue until Aug 23"</span></pre><p id="e7c2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">And it may return:</p><pre class="ml mm mn mo mp pl pj pm bp pn bb bk"><span id="ac09" class="po nz fq pj b bg pp pq l pr ps">"How much did we make before August 2023".</span></pre><p id="5daf" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This data augmentation process can be automated too: sending numerous examples to an LLM, thus adding variety to our dataset. Given that the LLM’s role is solely in dataset creation, considerations of cost and speed become inconsequential.</p><p id="656b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Combining the flexibility of adding new patterns, the generalization of the pre-trained model, and data augmentation using an LLM, we can effectively cover almost any expression.</strong></p><p id="75c9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The final principle of this paradigm is to constrain the generative AI to produce only STL queries, ensuring adherence to the required structure. The method to achieve this, as well as a method for optimizing the tokenization process, was discussed <a class="af nx" href="https://medium.com/towards-data-science/structured-generative-ai-e772123428e4" rel="noopener">in a previous post</a>.</p><p id="2706" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">By adhering to these three principles, we achieved an impressive accuracy of 99.98% on our test dataset. Moreover, this paradigm gave us the flexibility to address new, unsupported, time expressions swiftly.</p><h2 id="b79d" class="ny nz fq bf oa ob oc od oe of og oh oi nk oj ok ol no om on oo ns op oq or os bk"><strong class="al">Summary</strong></h2><p id="c893" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Large Language Models (LLMs) aren’t always the optimal solution for language tasks. With the right approach, shallower transformer models can efficiently extract information from natural language with high accuracy and flexibility, at a reduced time and cost.</p><p id="f0e7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The key principles to remember are:</p><ol class=""><li id="0b23" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw oy oz pa bk">Focusing the model only on information extraction, avoiding complex logical deductions. This may require generating a mediating language and implementing a parser and logical deduction in code.</li><li id="d048" class="nb nc fq nd b go pb nf ng gr pc ni nj nk pd nm nn no pe nq nr ns pf nu nv nw oy oz pa bk">Establishing a pipeline for generating a dataset and training a model, so that adding new functionality (new language patterns) is straightforward and fast. This pipeline can include the use of an LLM, adding more variety to the dataset.</li><li id="9df1" class="nb nc fq nd b go pb nf ng gr pc ni nj nk pd nm nn no pe nq nr ns pf nu nv nw oy oz pa bk">Confining the model generation to the constraints of a structured language.</li></ol><p id="038a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">While this post focused on extracting time elements, the paradigm applies to extracting any information from free text and structuring it into various formats. With this paradigm, you can achieve the accuracy of a rule-based engine, with the flexibility of a machine learning model.</p></div></div></div></div>    
</body>
</html>