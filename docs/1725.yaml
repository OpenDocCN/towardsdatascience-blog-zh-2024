- en: 'PySpark Explained: User-Defined Functions'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PySpark 解析：用户定义函数
- en: 原文：[https://towardsdatascience.com/pyspark-explained-user-defined-functions-40a71f924b1a?source=collection_archive---------6-----------------------#2024-07-15](https://towardsdatascience.com/pyspark-explained-user-defined-functions-40a71f924b1a?source=collection_archive---------6-----------------------#2024-07-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pyspark-explained-user-defined-functions-40a71f924b1a?source=collection_archive---------6-----------------------#2024-07-15](https://towardsdatascience.com/pyspark-explained-user-defined-functions-40a71f924b1a?source=collection_archive---------6-----------------------#2024-07-15)
- en: '![](../Images/54123ff2074aa3399ee679449273534e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54123ff2074aa3399ee679449273534e.png)'
- en: Image by AI (Dalle-3)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 AI（Dalle-3）生成
- en: What are they, and how do you use them?
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它们是什么？你又该如何使用它们呢？
- en: '[](https://medium.com/@thomas_reid?source=post_page---byline--40a71f924b1a--------------------------------)[![Thomas
    Reid](../Images/c1b4e5f577272633ba07e5dbfd21c02d.png)](https://medium.com/@thomas_reid?source=post_page---byline--40a71f924b1a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--40a71f924b1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--40a71f924b1a--------------------------------)
    [Thomas Reid](https://medium.com/@thomas_reid?source=post_page---byline--40a71f924b1a--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@thomas_reid?source=post_page---byline--40a71f924b1a--------------------------------)[![Thomas
    Reid](../Images/c1b4e5f577272633ba07e5dbfd21c02d.png)](https://medium.com/@thomas_reid?source=post_page---byline--40a71f924b1a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--40a71f924b1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--40a71f924b1a--------------------------------)
    [Thomas Reid](https://medium.com/@thomas_reid?source=post_page---byline--40a71f924b1a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--40a71f924b1a--------------------------------)
    ·10 min read·Jul 15, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--40a71f924b1a--------------------------------)
    ·阅读时间 10 分钟·2024年7月15日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This article is about User Defined Functions (UDFs) in Spark. I’ll go through
    what they are and how you use them, and show you how to implement them using examples
    written in PySpark.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍的是 Spark 中的用户定义函数（UDF）。我将讲解它们是什么，如何使用它们，并通过在 PySpark 中编写的示例演示如何实现它们。
- en: Incidentally, when I talk about PySpark, I just mean that the underlying language
    being used when programming with Spark is Python. The OG language for development
    using Spark ***was*** Scala, but with Python’s meteoric rise in popularity, it’s
    now the main language people use when programming in Spark even though Spark itself
    is written in Scala.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，当我谈论 PySpark 时，我指的是编写 Spark 程序时使用的底层语言是 Python。Spark 最初的开发语言是 ***Scala***，但随着
    Python 的迅猛流行，现在即便 Spark 本身是用 Scala 编写的，Python 已成为人们在 Spark 中编程时主要使用的语言。
- en: What is Spark?
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 Spark？
- en: If you haven’t used or heard of Spark before, the TL;DR is that it is a powerful
    tool for processing and analysing large amounts of data quickly. It’s a distributed
    computing engine, designed to handle big data tasks by breaking them into smaller
    pieces and working on them in parallel. This makes it much faster and more efficient
    than many other methods, especially for complex tasks like data analysis, machine
    learning, and real-time data processing.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前没有使用过 Spark 或者听说过 Spark，简而言之，它是一个用于快速处理和分析大量数据的强大工具。它是一个分布式计算引擎，旨在通过将任务拆分成较小的部分并并行处理它们来处理大数据任务。这使得它比许多其他方法更快、更高效，特别是在数据分析、机器学习和实时数据处理等复杂任务中。
- en: Now part of the Apache Software Federation, Spark has several key aspects that
    cater to different aspects of data processing and analysis, including components
    for Machine Learning, SQL operations and handling…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在作为 Apache 软件基金会的一部分，Spark 拥有多个关键组件，涵盖了数据处理和分析的不同方面，包括机器学习、SQL 操作和数据处理等…
