["```py\n# Import libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport numpy as np\n\n# Load data\ndataset_dict = {\n    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy', 'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast', 'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],\n    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],\n    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],\n    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']\n}\ndf = pd.DataFrame(dataset_dict)\n\n# Preprocess data\ndf = pd.get_dummies(df, columns=['Outlook'],  prefix='', prefix_sep='', dtype=int)\ndf['Wind'] = df['Wind'].astype(int)\ndf['Play'] = (df['Play'] == 'Yes').astype(int)\n\n# Reorder the columns\ndf = df[['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind', 'Play']]\n\n# Prepare features and target\nX, y = df.drop(columns='Play'), df['Play']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\n\n# Display results\nprint(pd.concat([X_train, y_train], axis=1), '\\n')\nprint(pd.concat([X_test, y_test], axis=1))\n```", "```py\ndef potential_split_points(attr_name, attr_values):\n    sorted_attr = np.sort(attr_values)\n    unique_values = np.unique(sorted_attr)\n    split_points = [(unique_values[i] + unique_values[i+1]) / 2 for i in range(len(unique_values) - 1)]\n    return {attr_name: split_points}\n\n# Calculate and display potential split points for all columns\nfor column in X_train.columns:\n    splits = potential_split_points(column, X_train[column])\n    for attr, points in splits.items():\n        print(f\"{attr:11}: {points}\")\n```", "```py\ndef gini_impurity(y):\n    p = np.bincount(y) / len(y)\n    return 1 - np.sum(p**2)\n\ndef weighted_average_impurity(y, split_index):\n    n = len(y)\n    left_impurity = gini_impurity(y[:split_index])\n    right_impurity = gini_impurity(y[split_index:])\n    return (split_index * left_impurity + (n - split_index) * right_impurity) / n\n\n# Sort 'sunny' feature and corresponding labels\nsunny = X_train['sunny']\nsorted_indices = np.argsort(sunny)\nsorted_sunny = sunny.iloc[sorted_indices]\nsorted_labels = y_train.iloc[sorted_indices]\n\n# Find split index for 0.5\nsplit_index = np.searchsorted(sorted_sunny, 0.5, side='right')\n\n# Calculate impurity\nimpurity = weighted_average_impurity(sorted_labels, split_index)\n\nprint(f\"Weighted average impurity for 'sunny' at split point 0.5: {impurity:.3f}\")\n```", "```py\ndef calculate_split_impurities(X, y):\n    split_data = []\n\n    for feature in X.columns:\n        sorted_indices = np.argsort(X[feature])\n        sorted_feature = X[feature].iloc[sorted_indices]\n        sorted_y = y.iloc[sorted_indices]\n\n        unique_values = sorted_feature.unique()\n        split_points = (unique_values[1:] + unique_values[:-1]) / 2\n\n        for split in split_points:\n            split_index = np.searchsorted(sorted_feature, split, side='right')\n            impurity = weighted_average_impurity(sorted_y, split_index)\n            split_data.append({\n                'feature': feature,\n                'split_point': split,\n                'weighted_avg_impurity': impurity\n            })\n\n    return pd.DataFrame(split_data)\n\n# Calculate split impurities for all features\ncalculate_split_impurities(X_train, y_train).round(3)\n```", "```py\n# Calculate split impurities forselected index\nselected_index = [4,8,3,13,7,9,10] # Change it depending on which indices you want to check\ncalculate_split_impurities(X_train.iloc[selected_index], y_train.iloc[selected_index]).round(3)\n```", "```py\nfrom sklearn.tree import DecisionTreeClassifier\n\n# The whole Training Phase above is done inside sklearn like this\ndt_clf = DecisionTreeClassifier()\ndt_clf.fit(X_train, y_train)\n```", "```py\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\n# Plot the decision tree\nplt.figure(figsize=(20, 10))\nplot_tree(dt_clf, filled=True, feature_names=X.columns, class_names=['Not Play', 'Play'])\nplt.show()\n```", "```py\n# Make predictions\ny_pred = dt_clf.predict(X_test)\nprint(y_pred)\n```", "```py\n# Evaluate the classifier\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\n# Import libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.tree import plot_tree, DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load data\ndataset_dict = {\n    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy', 'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast', 'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],\n    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],\n    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],\n    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']\n}\ndf = pd.DataFrame(dataset_dict)\n\n# Prepare data\ndf = pd.get_dummies(df, columns=['Outlook'],  prefix='', prefix_sep='', dtype=int)\ndf['Wind'] = df['Wind'].astype(int)\ndf['Play'] = (df['Play'] == 'Yes').astype(int)\n\n# Split data\nX, y = df.drop(columns='Play'), df['Play']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\n\n# Train model\ndt_clf = DecisionTreeClassifier(\n    max_depth=None,           # Maximum depth of the tree\n    min_samples_split=2,      # Minimum number of samples required to split an internal node\n    min_samples_leaf=1,       # Minimum number of samples required to be at a leaf node\n    criterion='gini'          # Function to measure the quality of a split\n)\ndt_clf.fit(X_train, y_train)\n\n# Make predictions\ny_pred = dt_clf.predict(X_test)\n\n# Evaluate model\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n\n# Visualize tree\nplt.figure(figsize=(20, 10))\nplot_tree(dt_clf, filled=True, feature_names=X.columns,\n          class_names=['Not Play', 'Play'], impurity=False)\nplt.show()\n```"]