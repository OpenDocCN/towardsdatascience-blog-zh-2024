- en: The Ultimate Guide to Vision Transformers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-ultimate-guide-to-vision-transformers-0a6df32cb248?source=collection_archive---------8-----------------------#2024-08-30](https://towardsdatascience.com/the-ultimate-guide-to-vision-transformers-0a6df32cb248?source=collection_archive---------8-----------------------#2024-08-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A comprehensive guide to the Vision Transformer (ViT) that revolutionized computer
    vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@francoisporcher?source=post_page---byline--0a6df32cb248--------------------------------)[![François
    Porcher](../Images/9ddb233f8cadbd69026bd79e2bd62dea.png)](https://medium.com/@francoisporcher?source=post_page---byline--0a6df32cb248--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0a6df32cb248--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0a6df32cb248--------------------------------)
    [François Porcher](https://medium.com/@francoisporcher?source=post_page---byline--0a6df32cb248--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0a6df32cb248--------------------------------)
    ·7 min read·Aug 30, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Hi everyone! For those who do not know me yet, my name is Francois, I am a Research
    Scientist at Meta. I have a passion for explaining advanced AI concepts and making
    them more accessible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Today, let’s dive into one of the most significant contribution in the field
    of Computer Vision: the **Vision Transformer (ViT).**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2008420b7885ebccbdfac2394b8c4f6d.png)'
  prefs: []
  type: TYPE_IMG
- en: Converting an image into patches, image by author
  prefs: []
  type: TYPE_NORMAL
- en: A bit of history first..
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Vision Transformer was introduced by Alexey Dosovitskiy and al. (Google
    Brain) in 2021 in the paper [An Image is worth 16×16 words](https://arxiv.org/abs/2010.11929).
    At the time, Transformers had shown to be the key to unlock great performance
    on NLP tasks, introduced in the must paper [Attention is All you Need](https://arxiv.org/abs/1706.03762)
    in 2017.
  prefs: []
  type: TYPE_NORMAL
- en: Between 2017 and 2021, there were several attempts to integrate the attention
    mechanism into Convolutional Neural Networks (CNNs). However, these were mostly
    hybrid models (combining CNN layers with attention layers) and lacked scalability.
    Google addressed this by completely eliminating convolutions and leveraging their
    computational power to scale the model.
  prefs: []
  type: TYPE_NORMAL
- en: The million-dollar question this article answered is..
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
