- en: Unraveling Unstructured Movie Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/unraveling-unstructured-movie-data-04d5ff787600?source=collection_archive---------8-----------------------#2024-02-09](https://towardsdatascience.com/unraveling-unstructured-movie-data-04d5ff787600?source=collection_archive---------8-----------------------#2024-02-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/9bcaa0e799d0ad12c1c54169c510968f.png)'
  prefs: []
  type: TYPE_IMG
- en: How to Use LLMs and Controlled Vocabularies for Enhanced Similarity Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://stevehedden.medium.com/?source=post_page---byline--04d5ff787600--------------------------------)[![Steve
    Hedden](../Images/af7bec4a191ab857eccd885dd89e88b4.png)](https://stevehedden.medium.com/?source=post_page---byline--04d5ff787600--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04d5ff787600--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04d5ff787600--------------------------------)
    [Steve Hedden](https://stevehedden.medium.com/?source=post_page---byline--04d5ff787600--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04d5ff787600--------------------------------)
    ·16 min read·Feb 9, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*The accompanying code for this tutorial is* [*here.*](https://github.com/SteveHedden/kg_llm)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recommender systems](https://en.wikipedia.org/wiki/Recommender_system) are
    how we find much of the content and products we consume, probably including this
    article. A recommender system is:'
  prefs: []
  type: TYPE_NORMAL
- en: “a subclass of information filtering system that provides suggestions for items
    that are most pertinent to a particular user.” — Wikipedia
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Some examples of recommender systems we interact with regularly are on Netflix,
    Spotify, Amazon, and social media. All of these recommender systems are attempting
    to answer the same question: given a user’s past behavior, what other products
    or content are they most likely to like? These systems generate a lot of money
    — [a 2013 study from McKinsey](https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers)
    found that, “35 percent of what consumers purchase on Amazon and 75 percent of
    what they watch on Netflix come from product recommendations.” Netflix famously
    started an open competition in 2006 offering a [one million dollar prize](https://en.wikipedia.org/wiki/Netflix_Prize)
    to anyone who could significantly improve their recommendation system. For more
    information on recommender systems see [this](/the-remarkable-world-of-recommender-systems-bff4b9cbe6a7)
    article.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, there are three kinds of recommender systems: content based, collaborative,
    and a hybrid of content based and collaborative. Collaborative recommender systems
    focus on users’ behavior and preferences to predict what they will like based
    on what other similar users like. Content based filtering systems focus on similarity
    between the products themselves rather than the users. For more info on these
    systems see [this Nvidia piece.](https://www.nvidia.com/en-us/glossary/recommendation-system/#:~:text=A%20recommendation%20system%20is%20an,demographic%20information%2C%20and%20other%20factors)'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating similarity between products that are well-defined in a structured
    dataset is relatively straightforward. We could identify which properties of the
    products we think are most important, and measure the ‘distance’ between any two
    products given the difference between those properties. But what if we want to
    compare items when the only data we have is unstructured text? For example, given
    a dataset of movie and TV show descriptions, how can we calculate which are most
    similar?
  prefs: []
  type: TYPE_NORMAL
- en: 'In this tutorial, I will:'
  prefs: []
  type: TYPE_NORMAL
- en: Show a basic similarity model (no controlled vocabulary) of unstructured text
    using natural language processing (NLP) techniques
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a genre list using an LLM
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the genre list to tag films with genres
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the genre tags to build a similarity model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the genre tags to create a network visualization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The goal, for me, in writing this, was to learn two things: whether a taxonomy
    (controlled vocabulary) significantly improved the outcomes of a similarity model
    of unstructured data, and whether an LLM can significantly improve the quality
    and/or time required to construct that controlled vocabulary.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don’t feel like reading the whole thing, here are my main findings:'
  prefs: []
  type: TYPE_NORMAL
- en: The basic NLP model (without a controlled vocabulary) certainly has some problems
    — it sometimes uses words for identifying similar movies that are not relevant
    (like the protagonists’ first name or the location).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a controlled vocabulary does significantly improve the outcomes of the
    similarity model, at least based on some of the examples I have been using to
    test the models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a simple, basic genre list using an LLM is easy — building a useful
    and/or detailed genre taxonomy is hard i.e. it would take more iterations or more
    descriptive prompts. I ended up building a quick and dirty list of about 200 genres
    without definitions, which worked good enough for doing simple similarity calculations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even this very basic genre list built using an LLM has issues, however. There
    are duplicate genres with minor spelling differences, for example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an LLM to tag the movies and TV shows took a very long time. This might
    just be a problem in the way I have structured my code though.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perhaps not surprisingly, the depth and breadth of the taxonomy matters. Like
    I said above, building a detailed and descriptive taxonomy of movie genres is
    difficult and would require a lot more work than I am willing to do for this tutorial.
    But depending on the use case, that level of detail might not be necessary. I
    started by building a taxonomy of thousands of genres with synonyms and definitions
    but that had drawbacks — the tagging became harder and the similarity calculations
    were often not as good. Because I was only looking at a couple thousand movies,
    having a genre list of thousands of genres just made every movie unique and similar
    to almost nothing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing movies and genres as graphs is awesome, as always.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic Similarity Model of Unstructured Text Using NLP Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We could use natural language processing (NLP) to extract key words from the
    text, identify how important these words are, and then find matching words in
    other descriptions. [Here](https://medium.com/mlearning-ai/basic-content-based-recommendation-system-with-python-code-be920b412067)
    is a tutorial on how to do that in Python. I won’t recreate that entire tutorial
    here but here is a brief synopsis:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we extract key words from a plot description. For example, here is the
    description for the movie, ‘Indiana Jones and the Raiders of the Lost Ark.’
  prefs: []
  type: TYPE_NORMAL
- en: “When Indiana Jones is hired by the government to locate the legendary Ark of
    the Covenant, he finds himself up against the entire Nazi regime.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We then use out-of-the-box libraries from sklearn to extract key words and rank
    their ‘importance’. To calculate importance, we use term-frequency-inverse document
    frequency (tf-idf). The idea is to balance the frequency of the term in the individual
    film’s description with how common the word is across all film descriptions in
    our dataset. The word ‘finds,’ for example, appears in this description, but it
    is a common word and appears in many other movie descriptions, so it is less important
    than ‘covenant’.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/26363683659234d8de294e2a80095aaa.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'This model actually works very well for films that have a uniquely identifiable
    protagonist. If we run the similarity model on this film, the most similar movies
    are: ‘Indiana Jones and the Temple of Doom’, ‘Indiana Jones and the Last Crusade’,
    and ‘Indiana Jones and the Kingdom of the Crystal Skull’. This is because the
    descriptions for each of these movies contains the words, ‘Indiana’ and ‘Jones’.'
  prefs: []
  type: TYPE_NORMAL
- en: But there are problems here. How do we know the words that are extracted and
    used in the similarity model are relevant? For example, if I run this model to
    find movies or TV shows similar to ‘Beavis and Butt-head Do America,” the top
    result is “Army of the Dead.” If you’re not a sophisticated film and TV buff like
    me, you may not be familiar with the animated series ‘[Beavis and Butt-Head](https://en.wikipedia.org/wiki/Beavis_and_Butt-Head),’
    featuring ‘unintelligent teenage boys [who] spend time watching television, drinking
    unhealthy beverages, eating, and embarking on mundane, sordid adventures, which
    often involve vandalism, abuse, violence, or animal cruelty.’ The description
    of their movie, ‘Beavis and Butt-head Do America,’ reads, ‘After realizing that
    their boob tube is gone, Beavis and Butt-head set off on an expedition that takes
    them from Las Vegas to the nation’s capital.’ ‘Army of the Dead,’ on the other
    hand, is a Zack Snyder-directed ‘[post-apocalyptic zombie heist film](https://en.wikipedia.org/wiki/Army_of_the_Dead)’.
    Why is Army of the Dead considered similar then? Because it takes place in Las
    Vegas — both movie descriptions contain the words ‘Las Vegas’.
  prefs: []
  type: TYPE_NORMAL
- en: Another example of where this model fails is that if I want to find movies or
    TV shows similar to ‘Eat Pray Love,’ the top result is, ‘Extremely Wicked, Shockingly
    Evil and Vile.’ ‘Eat Pray Love’ is a romantic comedy starring Julia Roberts as
    Liz Gilbert, a recently divorced woman traveling the world in a journey of self-discovery.
    ‘Extremely Wicked, Shockingly Evil and Vile,’ is a true crime drama about serial
    killer Ted Bundy. What do these films have in common? Ted Bundy’s love interest
    is also named Liz.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7bed12ca5db9daac58186a0cc548d848.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: These are, of course, cherry-picked examples of cases where this model doesn’t
    work. There are plenty of cases where extracting key words from text can be a
    useful way of finding similar products. As shown above, text that contains uniquely
    identifiable names like Power Rangers, Indiana Jones, or James Bond can be used
    to find other titles with those same names in their descriptions. Likewise, if
    the description contains information about the genre of the title, like ‘thriller’
    or ‘mystery’, then those words can link the film to other films of the same genre.
    This has limitations too, however. Some films may use the word ‘dramatic’ in their
    description, but using this methodology, we would not match these films with film
    descriptions containing the word ‘drama’ — we are not accounting for synonyms.
    What we really want is to only use relevant words and their synonyms.
  prefs: []
  type: TYPE_NORMAL
- en: How can we ensure that the words extracted are relevant? This is where a taxonomy
    can help. What is a taxonomy?
  prefs: []
  type: TYPE_NORMAL
- en: Create a genre taxonomy using an LLM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “A taxonomy (or taxonomic classification) is a scheme of classification, especially
    a hierarchical classification, in which things are organized into groups or types.”
    — [Wikipedia](https://en.wikipedia.org/wiki/Taxonomy)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Perhaps the most famous example of a taxonomy is the one used in biology to
    categorize all living organisms — remember domain, kingdom, phylum class, order,
    family, genus, and species? All living creatures can be categorized into this
    hierarchical taxonomy.
  prefs: []
  type: TYPE_NORMAL
- en: '***A note on terminology:*** *ontologies are similar to taxonomies but different.
    As* [*this*](https://www.forbes.com/sites/cognitiveworld/2019/03/24/taxonomies-vs-ontologies/?sh=35eb9c327d53)
    *article explains, taxonomies classify while ontologies specify. “An ontology
    is the system of classes and relationships that describe the structure of data,
    the rules, if you will, that prescribe how a new category or entity is created,
    how attributes are defined, and how constraints are established.” Since we are
    focused on classifying movies, we are going to build a taxonomy. However, for
    the purposes of this tutorial, I just need a very basic list of genres, which
    can’t even really be described as a taxonomy. A list of genres is just a tag set,
    or a controlled vocabulary.*'
  prefs: []
  type: TYPE_NORMAL
- en: For this tutorial, we will focus only on genre. What we need is a list of genres
    that we can use to ‘tag’ each movie. Imagine that instead of having the movie,
    ‘Eat Pray Love’ tagged with the words ‘Liz’ and ‘true’, it were tagged with ‘romantic
    comedy’, ‘drama’, and ‘travel/adventure’. We could then use these genres to find
    other movies similar to Eat Pray Love, even if the protagonist is not named Liz.
    Below is a diagram of what we are doing. We use a subset of the unstructured movie
    data, along with GPT 3.5, to create a list of genres. Then we use the genre list
    and GPT 3.5 to tag the unstructured movie data. Once our data is tagged, we can
    run a similarity model using the tags as inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a57c3870bee7f19b01f99cd7029a0148.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: I couldn’t find any free movie genre taxonomies online, so I built my own using
    a large language model (LLM). I started with [this](https://medium.com/@elias_69893/an-llm-agent-that-builds-and-maintains-a-job-title-taxonomy-77d02c4c6100)
    tutorial, which used an LLM agent to build a taxonomy of job titles. That LLM
    agent looks for job titles from job descriptions, creates definitions and responsibilities
    for each of these job titles, and synonyms. I used that tutorial to create a movie
    genre taxonomy, but it was overkill — we don’t really need to do all of that for
    the purposes of this tutorial. We just need a very basic list of genres that we
    can use to tag movies. Here is the code I used to create that genre list.
  prefs: []
  type: TYPE_NORMAL
- en: 'I used Netflix movie and TV show description data available [here](https://www.kaggle.com/datasets/shivamb/netflix-shows?resource=download)
    (License [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)).'
  prefs: []
  type: TYPE_NORMAL
- en: Import required packages and load english language NLP model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then we need to set up our connection with OpenAI (or whatever LLM you want
    to use).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Read in the Netflix movie data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a function to predict the genre of a title given its description:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now we iterate through our DataFrame of movie descriptions, use the function
    above to predict the genres associated with the movie, then add them to our list
    of established unique genres.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now turn this list into a DataFrame and save to a csv file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Like I said, this is a quick and dirty way to generate this list of genres.
  prefs: []
  type: TYPE_NORMAL
- en: Use the genre list to tag films with genres
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a list of genres, we need to tag each of the movies and TV
    shows in our dataset (over 8,000) with them. To be able to use these tags to calculate
    similarity between two entities, we need to tag each movie and TV show with more
    than one genre. If we only used one genre, then all action movies will be equally
    similar, even though some may be more about sports and others, horror.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we read in our genre list and movie dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We already have a function for predicting genres. Now we need to define two
    more functions: one for filtering the predictions to ensure that the predictions
    are in our established genre list, and one for adding those filtered predictions
    to the movie DataFrame.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have these functions defined, we can run them on our movies dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we do some data cleaning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If we print the head of the DataFrame it should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1eecf770581a33e10b76f6d2a77063de.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Use the genre tags to build a similarity model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we turn the genre columns into dummy variables — each genre becomes its
    own column and if the movie or TV show is tagged with that genre then the column
    gets a 1, otherwise the value is 0.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If we print the head of this DataFrame, this is what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a403777c5b4922440ac69a840305ede.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to use these dummy variables to build a matrix and run a similarity
    model across all pairs of movies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can define a function that calculates the most similar movies to a given
    title:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see if this model finds movies more similar to ‘Eat Pray Love,’ than
    the previous model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from this query, for me, were, ‘The Big Day’, ‘Love Dot Com: The
    Social Experiment’, and ’50 First Dates’. All of these movies are tagged as romantic
    comedies and dramas, just like Eat Pray Love.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c760e9f8b5ef45a4bcb4df301050b036.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: '‘Extremely Wicked, Shockingly Evil and Vile,’ the movie about a woman in love
    with Ted Bundy, is tagged with the genres romance, drama, and crime. The most
    similar movies are, ‘The Fury of a Patient Man’, ‘Much Loved’, and ‘Loving You’,
    all of which are also tagged with romance, drama, and crime. ‘Beavis and Butt-head
    Do America’ is tagged with the genres comedy, adventure and road trip. The most
    similar movies are ‘Pee-wee’s Big Holiday’, ‘A Shaun the Sheep Movie: Farmageddon’,
    and ‘The Secret Life of Pets 2.’ All of these movies are also tagged with the
    genres adventure and comedy — there are no other movies in this dataset (at least
    the portion I tagged) that match all three genres from Beavis and Butt-head.'
  prefs: []
  type: TYPE_NORMAL
- en: Use the genre tags to create a network visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can’t link data together without building a cool network visualization.
    There are a few ways to turn this data into a graph — we could look at how movies
    are conneted via genres, how genres are connected via movies, or a combination
    of the two. Because there are so many movies in this dataset, I just made a graph
    using genres as nodes and movies as edges.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is my code to turn the data into nodes and edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces a DataFrame that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8a3894ceaabed0ec7f86dba4bfeeae78.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Each row in this DataFrame represents a movie that has been tagged with these
    two genres. We did not remove duplicates so there will be, presumably, many rows
    that look like row 1 above — there are many movies that are tagged as both romance
    and drama.
  prefs: []
  type: TYPE_NORMAL
- en: 'I used [Gephi](https://gephi.org/) to build a visualization that looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9bcaa0e799d0ad12c1c54169c510968f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The size of the nodes here represents the number of movies tagged with that
    genre. The color of the nodes is a function of a community detection algorithm
    — clusters that have closer connections amongst themselves than with nodes outside
    their cluster are colored the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is fascinating to me. Drama, comedy, and documentary are the three largest
    nodes meaning more movies are tagged with those genres than any others. The genres
    also naturally form clusters that make intuitive sense. The genres most aligned
    with ‘documentary’ are colored pink and are mostly some kind of documentary sub-genre:
    nature/wildlife, reality TV, travel/adventure, history, educational, biography,
    etc. There are a core cluster of genres in green: drama, comedy, romance, coming
    of age, family, etc. One issue here is that we have multiple spellings of the
    ‘coming of age’ genre — a problem I would fix in future versions. There is a cluster
    in blue that includes action/adventure, fantasy, sci-fi, and animation. Again,
    we have duplicates and overlapping genres here which is a problem. There is also
    a small genre in brown that includes thriller, mystery, and horror — adult genres
    often present in the same film. The lack of connections between certain genres
    is also interesting — there are no films tagged with both ‘stand-up’ and ‘horror’,
    for example.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This project has shown me how even the most basic controlled vocabulary is useful,
    and potentially necessary, when building a content-based recommendation system.
    With just a list of genres we were able to tag movies and find other similar movies
    in a more explainable way than using just NLP. This could obviously be improved
    immensely through a more detailed and description genre taxonomy, but also through
    additional taxonomies including the cast and crew of films, the locations, etc.
  prefs: []
  type: TYPE_NORMAL
- en: As is usually the case when using LLMs, I was very impressed at first at how
    well it could perform this task, only to be disappointed when I viewed and tried
    to improve the results. Building taxonomies, ontologies, or any controlled vocabulary
    requires human engagement — there needs to be a human in the loop to ensure the
    vocabulary makes sense and will be useful in satisfying a particular use case.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs and knowledge graphs (KGs) naturally fit together. One way they can be
    used together is that LLMs can help facilitate KG creation. LLMs can’t build a
    KG themselves but they can certainly help you create one.
  prefs: []
  type: TYPE_NORMAL
