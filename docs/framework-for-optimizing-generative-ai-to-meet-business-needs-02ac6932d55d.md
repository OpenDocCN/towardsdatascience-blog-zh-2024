# 优化生成式AI以满足业务需求的框架

> 原文：[https://towardsdatascience.com/framework-for-optimizing-generative-ai-to-meet-business-needs-02ac6932d55d?source=collection_archive---------2-----------------------#2024-03-04](https://towardsdatascience.com/framework-for-optimizing-generative-ai-to-meet-business-needs-02ac6932d55d?source=collection_archive---------2-----------------------#2024-03-04)

## 选择正确优化策略的手册，旨在通过明确的业务目标更好地满足客户需求。

[](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)[![Sarthak Handa](../Images/0c75ba0f085fdb22a221705450047c40.png)](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------) [Sarthak Handa](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------) ·阅读时间11分钟·2024年3月4日

--

![](../Images/087c9599cd2cdaa90b7b4119bf0d4642.png)

来源：Dalle3

生成类人文本和语音曾经仅存在于科幻小说中。但像GPT-3和PaLM这样的语言大模型的快速发展，将这一愿景拉近了现实，解锁了一系列有前景的商业应用，从聊天机器人到内容创作。

然而，通用基础模型通常无法满足行业应用的需求。企业在生成式AI应用上有不同的要求——从**性能**、**成本**、**延迟**到**可解释性**。此外，用于模型训练的数据的性质和数量可能会有很大不同。因此，产品团队需要明确生成式AI应用的关键业务标准，并选择合适的优化技术工具包，以满足这些需求。

在本文中，我们概述了一个框架，用于识别和优先考虑生成式AI应用的战略重点领域。我们还将探讨流行的优化方法，并讨论它们在满足应用需求时的独特优势、理想应用场景和权衡取舍。在明确的业务目标指导下，采用正确的优化策略，企业可以开发定制的AI解决方案，平衡成功所需的关键优先事项。让我们开始吧！

# 评估业务需求和约束的框架

为了有效地量身定制优化大型语言模型的策略，产品团队应该首先深入了解业务目标以及操作的约束条件。评估并优先考虑以下列出的关键维度，适用于您的业务场景：

![](../Images/9208171a2136d7bb407d35336b95456d.png)

来源：作者

**1\. 性能目标**：定义您的 AI 需要达到的性能衡量标准和水平。这可以是事实准确性、与人类价值观的一致性，或其他特定任务的指标。

> **需要考虑的问题**：*衡量性能的最佳维度是什么？最低可接受的性能标准是什么？性能如何与您所在行业的用户期望相匹配？*

**2\. 延迟目标**：确定您的应用能够承受的最大响应时间，而不会对用户体验产生负面影响。在需要在时间敏感或资源受限的场景（例如语音助手、边缘设备）中部署大型语言模型时，这一点尤为重要。

> **需要考虑的问题**：*延迟如何影响用户满意度和留存率？行业标准的响应时间是什么？*

**3\. 成本效益**：评估运营 AI 的成本与预期的投资回报率。较高的初始成本可能是合理的，当它们能够带来可观的节省、收入增长或战略性收益，超过了投资成本时。

> **需要考虑的问题**：*运营大型语言模型的成本如何影响您的预算？AI 部署的投资回报率与成本如何比较？*

**4\. 可解释性与信任：** 确定是否需要确保 AI 决策易于用户理解，这对于建立信任至关重要，尤其是在有严格监管要求的领域。

> **需要考虑的问题**：*您的行业是否受到监管，要求 AI 决策透明？可解释性如何影响用户信任与采纳？*

**5\. 外部知识**：评估您的 AI 是否需要访问外部数据源，以保持其相关性并提供准确的响应。

> **需要考虑的问题**：*您的 AI 是否需要实时数据来做出决策？*

**6\. 数据可用性**：可用于训练 AI 的数据的性质和数量可能会广泛影响优化策略。

> **需要考虑的问题**：*您是否有一个大规模的数据集用于训练，还是需要使用合成数据或增强数据？您需要多频繁地更新训练数据以保持 AI 的相关性？*

以下是一个表格，概述了生成性 AI 应用的**三个不同使用场景**，并对每个维度在框架中的优先级进行了相应评估：

![](../Images/68e86d6781466a2dd27403007758c812.png)

来源：作者

如您所见，优先级和限制在不同的使用场景之间可能会有所不同。

例如，考虑一个公司旨在开发一个*客户支持聊天机器人*以减轻人类员工的工作负担。在这种情况下，**准确性表现**和**外部数据集成**是高优先级的，以提供既事实正确又及时的响应。虽然**延迟**具有一定的重要性，但用户可能愿意容忍短暂的延迟。通常，类似的公司会拥有一个**庞大的历史记录**，其中包含过去的客户支持互动，可以用来训练模型。

相比之下，人工智能在*评估软件代码质量和风险*中的关键应用要求更加关注**事实准确性**和**可解释性**，通常是由于错误可能带来的后果。在这种情况下，**成本**和**延迟**是次要考虑因素。某些情况下，这个用例可能会从**外部数据集成**中受益，但通常会面临关于丰富训练数据集可用性的限制。

对与用例相关的战略优先事项和限制有清晰的理解，有助于团队制定量身定制的策略，优化大规模语言模型（LLMs）以满足用户的独特需求。

# 深入探索LLM优化技术

本节探讨了各种优化技术，突出了它们的目标、理想的使用场景以及固有的权衡，特别是在平衡上述业务目标的背景下。

**技术表格解析：**

![](../Images/b2a403e1382512ae0bca1ffd4ed8cd8d.png)

来源：作者

# 1\. 提示工程：

**执行复杂性**：低

**何时使用**：用于重塑回应并快速改进，而不改变模型。开始时使用此技术，以最大化预训练模型的效能，然后再尝试更复杂的优化方法。

**其内容**：提示工程涉及以某种方式设计输入查询，促使模型产生所需的输出。它需要理解模型如何响应不同类型的指令，但不需要重新训练模型或更改其架构。这种方法仅优化现有模型如何访问和应用其预训练知识，并不会增强模型的内在能力。

*“这就像调整你向一个知识渊博的朋友提问的方式，以获得最佳答案。”*

**示例：**

+   要求语言模型“以莎士比亚的风格写一首诗”与“写一首诗”来引出特定文学风格的回应。

+   提供一个详细的场景提示给对话型人工智能，确保模型理解其作为客服代理的角色。

**权衡**：

+   **试错法**：设计最有效的提示需要多次迭代，因为提示与人工智能输出之间的关系并非总是直观的。

+   **输出质量：** 输出的质量高度依赖于提示的设计，并且通过这种方法可以实现的改进水平是有限的。

# 2. 微调：

**执行复杂度：** 中

**何时使用：** 当你需要模型适应一个基础预训练模型可能无法很好覆盖的特定领域或任务时，应考虑使用微调。这是提高领域特定准确性并创建一个能够处理领域特定数据和术语的更专业化模型的一步。

**其包含内容：** 微调是将预训练模型在一个新的数据集上继续训练的过程，该数据集代表目标任务或领域。这个新数据集由输入-输出对组成，提供了期望行为的示例。在微调过程中，模型的权重会被更新，以最小化在这个新数据集上的损失，从而有效地将模型适应新的领域。

*“可以把它当作是给你的朋友进行一个快速课程，帮助他们成为某个主题的专家；给他们展示一些可能会出现在考试中的问题，并告诉他们预期的回答。”*

**示例：**

+   一个通用的语言模型可以通过法律文件进行微调，以提高其审查此类文件的性能。

+   图像识别模型可以通过医学影像数据集进行微调，以更好地识别 X 光片或 MRI 中的特定疾病。

**权衡：**

+   **数据要求：** 微调需要一个与任务相关的标注数据集，创建该数据集可能会消耗大量资源。

+   **过拟合风险：** 模型可能会过于专注于微调数据，从而降低其在其他上下文或数据集上的泛化能力。

# 3. 检索增强生成（RAG）：

**执行复杂度：** 高

**何时使用：** 当 AI 模型需要访问并结合外部信息来生成响应时，应考虑使用 RAG。特别是在模型需要提供最新的或高度特定的信息，而这些信息并不包含在其预训练知识库中时，RAG 更为相关。

**其包含内容：** RAG 将大语言模型（LLM）的生成能力与检索系统相结合。检索系统会查询数据库、知识库或互联网，以查找与输入提示相关的信息。然后，将检索到的信息提供给语言模型，后者将这些上下文信息纳入生成更丰富、更准确的响应中。通过引用 RAG 系统在生成响应时所使用的来源，生成式 AI 应用可以为用户提供更好的可解释性。

预计在未来几年，这种优化技术将获得广泛的应用，越来越多的产品将寻求利用其最新的商业数据来为客户定制体验。

*“这类似于你的朋友能够在线查找信息，以回答超出自己专业领域的问题。这就像是开卷考试。”*

**示例：**

+   在基于 RAG 的在线聊天机器人中，检索器可以从数据库或互联网中提取相关信息，以提供最新的答案。

+   作业助手 AI 可以使用 RAG 获取最新的科学数据，以回答学生关于气候变化的问题。

**权衡：**

+   **复杂实现：** RAG 系统需要一个良好集成的检索系统，这可能会增加设置和维护的难度。

+   **信息质量：** 生成响应的有用性高度依赖于检索信息的相关性和准确性。如果检索系统的来源过时或不正确，响应也会反映这一点。

+   **响应时间慢：** 从外部来源检索信息以生成响应可能会增加延迟。

# 4\. 来自人类反馈的强化学习（RLHF）：

**执行复杂性：** 非常高

**何时使用：** RLHF 应在模型输出需要与复杂的人类判断和偏好紧密对齐时使用。

**其内容：** RLHF 是一种复杂的强化学习技术，通过将人类评估直接融入训练过程，来优化模型的行为。这个过程通常包括收集来自人类操作员的数据，这些数据通过各种质量指标（如相关性、帮助性、语气等）对 AI 输出进行排名。这些数据信号随后用于训练奖励模型，指导强化学习过程生成与人类偏好更加一致的输出。

*“这类似于你的朋友从过去的对话中学习，了解什么使讨论变得愉快，并利用这些知识改善未来的互动。”*

**示例：**

+   社交媒体平台可以使用 RLHF 来训练一个审查机器人，这个机器人不仅能识别不当内容，还能以建设性和对上下文敏感的方式回应用户。

+   虚拟助手可以通过 RLHF 进行微调，以便提供更个性化且具有上下文意识的用户请求响应。

**权衡：**

+   **高复杂性：** RLHF 涉及复杂且资源密集的过程，包括人类反馈收集、奖励建模和强化学习。

+   **质量风险：** 反馈数据可能存在偏差，这可能会影响模型质量。确保人类反馈的一致性和将奖励模型与期望结果对齐可能会很困难。

# 5\. 知识蒸馏

**执行复杂性：** 中等到高

**何时使用：** 知识蒸馏在需要在计算能力有限的设备上部署复杂模型或在响应时间至关重要的应用中使用。

**它包含的内容**: 这是一种压缩技术，其中一个较小、更高效的模型（称为学生模型）被训练来复制一个较大、更复杂的模型（称为教师模型）的表现。训练不仅仅是学习正确的答案（硬目标），还包括学生模型尝试产生与教师预测相似的概率（软目标）。这种方法使得学生模型能够捕捉教师模型已学到的细微模式和洞察。

*“这类似于将一位经验丰富的专家的智慧提炼成一本简明的指南，初学者可以利用它做出专家级决策，而不需要经历多年的经验。”*

**示例**:

+   一个大规模语言模型可以被提炼成一个较小的模型，在智能手机上高效运行，用于实时语言翻译。

+   用于自动驾驶汽车的图像识别系统可以被提炼成一个轻量级模型，能够在车辆的车载计算机上运行。

**权衡**:

+   **性能与规模**: 提炼后的模型可能无法始终匹配教师模型的性能，从而可能导致准确性或质量的下降。

+   **训练复杂性**: 提炼过程耗时，并需要仔细的实验以确保学生模型能够有效学习。它需要对模型架构有深入的理解，并能够将知识从一个模型转移到另一个模型。

现在让我们看一个实际应用中的例子。

# 示例：客户支持聊天机器人

让我们重新审视构建客户支持聊天机器人以减轻人工支持工作人员工作量的用例。

![](../Images/a9afcbd5ed94718665a3356efa82af4f.png)

来源：Dalle

包括的要求/限制条件有：

1.  **性能**: 高优先级（强调事实准确性）

1.  **外部知识**: 高优先级

1.  **延迟目标**: 中优先级

1.  **成本效率**: 低优先级

1.  **可解释性与信任**: 中优先级

1.  **数据可用性**: 丰富（过去对话数据）

在明确了解业务背景和优先级后，产品开发者可以制定最有效的优化策略。

**大规模语言模型优化决策步骤**:

1.  **提示工程**应作为改善聊天机器人初步理解和响应能力的第一步。然而，仅此一步可能不足以确保专门领域的准确性。

1.  **微调**模型，利用历史客户对话数据，对于提高聊天机器人的准确性表现至关重要，并使模型能够熟练处理细化的行业特定问题。

1.  纳入**检索增强生成（RAG）**对提供最新的产品信息和相关网站链接至关重要。

1.  尽管在一定程度的延迟是可以容忍的，但监控并可能**优化响应时间**仍然是明智的。这里的优化策略可能包括缓存常见查询以加速响应，以及战略性地使用提示工程来减少不必要的外部数据检索。

如您所见，通常需要多种策略的结合才能满足特定用例的需求。优化策略的灵活性至关重要，因为需求可能会随时间变化，系统需要同时平衡多个需求。

# 结论

针对商业用例优化大语言模型既是一门艺术，也是一门科学，这需要对底层技术和当前目标有深刻的理解。随着人工智能的不断发展，优化技术的选择将变得越来越具有战略性，影响的不仅是单个应用的性能，还包括人工智能在社会中角色的整体发展方向。

无论您是针对速度、准确性、成本还是透明度进行优化，上述讨论的技巧都为增强大语言模型（LLM）以满足未来生成型人工智能驱动的商业应用需求提供了工具包。通过深思熟虑地应用这些方法，我们可以创造出不仅有效，而且负责任、能够精准满足用户需求的人工智能。

*感谢您的阅读！如果这些见解与您产生共鸣或激发了新的想法，欢迎继续交流。请在下方评论分享您的观点，或通过* [***LinkedIn***](https://www.linkedin.com/) *与我联系。*
