- en: 'LangChain’s Built-In Eval Metrics for AI Output: How Are They Different?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain 的内置 AI 输出评估指标：它们有何不同？
- en: 原文：[https://towardsdatascience.com/langchains-built-in-eval-metrics-for-ai-output-how-are-they-different-f9dd75e2de08?source=collection_archive---------9-----------------------#2024-05-22](https://towardsdatascience.com/langchains-built-in-eval-metrics-for-ai-output-how-are-they-different-f9dd75e2de08?source=collection_archive---------9-----------------------#2024-05-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/langchains-built-in-eval-metrics-for-ai-output-how-are-they-different-f9dd75e2de08?source=collection_archive---------9-----------------------#2024-05-22](https://towardsdatascience.com/langchains-built-in-eval-metrics-for-ai-output-how-are-they-different-f9dd75e2de08?source=collection_archive---------9-----------------------#2024-05-22)
- en: '[](https://medium.com/@jonathan.bennion?source=post_page---byline--f9dd75e2de08--------------------------------)[![Jonathan
    Bennion](../Images/e2d9add564ee2ac0deb7863537b0ee73.png)](https://medium.com/@jonathan.bennion?source=post_page---byline--f9dd75e2de08--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f9dd75e2de08--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f9dd75e2de08--------------------------------)
    [Jonathan Bennion](https://medium.com/@jonathan.bennion?source=post_page---byline--f9dd75e2de08--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jonathan.bennion?source=post_page---byline--f9dd75e2de08--------------------------------)[![Jonathan
    Bennion](../Images/e2d9add564ee2ac0deb7863537b0ee73.png)](https://medium.com/@jonathan.bennion?source=post_page---byline--f9dd75e2de08--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f9dd75e2de08--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f9dd75e2de08--------------------------------)
    [Jonathan Bennion](https://medium.com/@jonathan.bennion?source=post_page---byline--f9dd75e2de08--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f9dd75e2de08--------------------------------)
    ·5 min read·May 22, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f9dd75e2de08--------------------------------)
    ·5 分钟阅读·2024年5月22日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: I’ve created custom metrics most often for my own use cases, but have come across
    these built-in metrics for AI tools in LangChain repeatedly before I’d started
    using RAGAS and/or DeepEval for RAG evaluation, so finally was curious on how
    these metrics are created and ran a quick analysis (with all inherent bias of
    course).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常为自己的使用案例创建自定义指标，但在开始使用 RAGAS 和/或 DeepEval 进行 RAG 评估之前，反复遇到 LangChain 内置的这些
    AI 工具评估指标，所以最终对这些指标是如何创建的产生了好奇，并进行了快速分析（当然有所有固有的偏见）。
- en: '***TLDR is from the correlation matrix below:***'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '***TLDR 来自以下的相关性矩阵：***'
- en: '***Helpfulness and Coherence (0.46 correlation)****: This strong correlation
    suggests that the LLM (and by proxy, users) could find coherent responses more
    helpful, emphasizing the importance of logical structuring in responses. It is
    just correlation, but this relationship opens the possibility for this takeaway.*'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***有用性与一致性（0.46 的相关性）***：这一强相关性表明，大型语言模型（以及由此推导出的用户）可能会觉得一致性的回答更有帮助，强调了回答中逻辑结构的重要性。这只是相关性，但这一关系揭示了这一结论的可能性。*'
- en: '***Controversiality and Criminality (0.44 correlation)****: This indicates
    that even controversial content could be deemed criminal, and vice versa, perhaps
    reflecting a user preference for engaging and thought-provoking material.*'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***争议性与犯罪性（0.44 的相关性）***：这表明，即使是有争议的内容也可能被视为犯罪，反之亦然，或许反映了用户偏好那些具有吸引力和发人深省的内容。*'
- en: '***Coherence vs. Depth:*** *Despite coherence correlating with helpfulness,
    depth does not. This might suggest that users (again, assuming user preferences
    are inherent in the output of the LLM — this alone is a presumption and a bias
    that is important to be concious of) could prefer clear and concise answers over
    detailed ones, particularly in contexts where quick solutions are valued over
    comprehensive ones.*'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***一致性与深度：*** *尽管一致性与有用性相关，但深度并不相关。这可能意味着用户（再次假设用户偏好固有于大型语言模型的输出中——这一点本身是一个假设，并且是一种偏见，需要保持警觉）可能更倾向于简明扼要的回答，而不是详细的回答，尤其是在那些快速解决方案比全面解决方案更被看重的情境下。*'
- en: '![](../Images/2934a7023672ad3ffd5a80c6b8bfbe3a.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2934a7023672ad3ffd5a80c6b8bfbe3a.png)'
- en: 'The built-in metrics are found here (removing one that relates to ground truth
    and better handled elsewhere):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 内置指标可以在这里找到（移除一个与地面真相相关且更适合在其他地方处理的指标）：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The metrics:'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这些指标：
- en: Conciseness
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简洁性
- en: Detail
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 细节
- en: Relevance
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关性
- en: Coherence
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一致性
- en: Harmfulness
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有害性
- en: Insensitivity
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冷漠性
- en: Helpfulness
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有用性
- en: Controversiality
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 争议性
- en: Criminality
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 犯罪性
- en: Depth
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度
- en: Creativity
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创造力
- en: First, what do these mean, and why were they created?
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 首先，这些意味着什么，为什么要创建这些？
- en: 'The hypothesis:'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假设是：
- en: These were created in an attempt to define metrics that could explain output
    in relation to theoretical use case goals, and any correlation could be accidental
    but was generally avoided where possible.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些是为了尝试定义可以解释输出与理论用例目标之间关系的度量标准，任何相关性可能是偶然的，但通常尽可能避免。
- en: I have this hypothesis after seeing [this source code here](https://api.python.langchain.com/en/latest/_modules/langchain/evaluation/criteria/eval_chain.html).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到[这里的源代码](https://api.python.langchain.com/en/latest/_modules/langchain/evaluation/criteria/eval_chain.html)后，我得出了这个假设。
- en: Second, some of these seem similar and/or vague — so how are these different?
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第二，一些这些似乎相似和/或模糊——那么它们是如何区分的呢？
- en: I used a standard SQuAD dataset as a baseline to evaluate the differences (if
    any) between output from OpenAI’s GPT-3-Turbo model and the ground truth in this
    dataset, and compare.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了标准的SQuAD数据集作为基准，评估OpenAI的GPT-3-Turbo模型输出与该数据集中的真实值之间的差异（如果有的话），并进行比较。
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: I obtained a randomized set of rows for evaluation (could not afford timewise
    and compute for the whole thing), so this could be an entrypoint for more noise
    and/or bias.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我获取了一组随机化的行进行评估（由于时间和计算限制，无法对整个数据集进行评估），因此这可能是更多噪音和/或偏差的切入点。
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: I defined an llm using ChatGPT 3.5 Turbo (to save on cost here, this is quick).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我定义了一个LLM，使用了ChatGPT 3.5 Turbo（为了节省成本，这个过程很快）。
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Then iterated through the sampled rows to gather a comparison — there were unknown
    thresholds that LangChain used for ‘score’ in the evaluation criteria, but the
    assumption is that they are defined the same for all metrics.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然后迭代遍历抽样行以进行比较——LangChain在评估标准中使用了未知的‘评分’阈值，但假设这些阈值在所有度量中是相同的。
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then I calculated means and CI at 95% confidence intervals.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我计算了均值和95%置信区间的置信区间。
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: And plotted the results.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后绘制了结果。
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is possibly intuitive that ‘Relevance’ is so much higher than the others,
    but interesting that overall they are so low (maybe thanks to GPT 3.5!), and that
    ‘Helpfulness’ is next highest metric (possibly reflecting RL techniques and optimizations).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 可能直观地认为‘相关性’比其他指标要高得多，但有趣的是，总体而言它们都很低（可能要感谢GPT 3.5！），而‘有用性’是下一个最高的指标（可能反映了强化学习技术和优化）。
- en: '![](../Images/06c0aec539a408ad7380c763433a4d69.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06c0aec539a408ad7380c763433a4d69.png)'
- en: To answer my question on correlation, I’d calculated a simple correlation matrix
    with the raw comparison dataframe.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答我关于相关性的问题，我计算了一个简单的相关矩阵，使用了原始的比较数据框。
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Then plotted the results (p values are created [further down in my code](https://github.com/j-space-b/eval_analysis/blob/main/evaluation_metrics_corrplot.ipynb)
    and were all under .05)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然后绘制了结果（p值是通过[我的代码中的进一步部分](https://github.com/j-space-b/eval_analysis/blob/main/evaluation_metrics_corrplot.ipynb)创建的，且均小于0.05）
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Was surprising that most do not correlate, given the nature of the descriptions
    in the LangChain codebase — this lends to something a bit more thought out, and
    am glad these are built-in for use.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，大多数没有相关性，考虑到LangChain代码库中描述的性质——这表明这些内容是经过深思熟虑的，我很高兴这些是内建的可以使用的。
- en: '![](../Images/2934a7023672ad3ffd5a80c6b8bfbe3a.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2934a7023672ad3ffd5a80c6b8bfbe3a.png)'
- en: 'From the correlation matrix, notable relationships emerge:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 从相关矩阵中，显现出一些显著的关系：
- en: '*Helpfulness and Coherence (0.46 correlation):* This strong correlation suggests
    that the LLM (as it is a proxy for users) could find coherent responses more helpful,
    emphasizing the importance of logical structuring in responses. Even though this
    is correlation, this relationship paves the way for this.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*有用性与一致性（0.46 相关性）：* 这一强相关性表明，LLM（作为用户的代理）可能会发现一致的回应更有帮助，这强调了回应中逻辑结构的重要性。尽管这只是相关性，但这种关系为此铺平了道路。'
- en: '*Controversiality and Criminality (0.44 correlation):* This indicates that
    even controversial content could be deemed criminal, and vice versa, perhaps reflecting
    a user preference for engaging and thought-provoking material. Again, this is
    only correlation.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*争议性与犯罪性（0.44 相关性）：* 这表明，即使是有争议的内容也可能被视为犯罪，反之亦然，这也许反映了用户对引人深思且富有启发性的材料的偏好。同样，这只是相关性。'
- en: 'Takeaways:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 主要结论：
- en: '**Coherence vs. Depth in Helpfulness:** Despite coherence correlating with
    helpfulness, depth does not. This might suggest that users could prefer clear
    and concise answers over detailed ones, particularly in contexts where quick solutions
    are valued over comprehensive ones.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**连贯性与深度在帮助性中的对比：** 尽管连贯性与帮助性相关，但深度却没有。这可能意味着用户更倾向于简洁明了的答案而非详细的答案，特别是在那些快速解决方案比全面方案更受重视的场景中。'
- en: '**Leveraging Controversiality:** The positive correlation between controversiality
    and criminality poses an interesting question: Can controversial topics be discussed
    in a way that is not criminal? This could potentially increase user engagement
    without compromising on content quality.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**利用争议性：** 争议性与犯罪性之间的正相关关系提出了一个有趣的问题：是否可以以非犯罪的方式讨论争议话题？这可能在不牺牲内容质量的情况下增加用户参与度。'
- en: '**Impact of Bias and Model Choice:** The use of GPT-3.5 Turbo and the inherent
    biases in metric design could influence these correlations. Acknowledging these
    biases is essential for accurate interpretation and application of these metrics.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**偏见与模型选择的影响：** 使用GPT-3.5 Turbo以及度量设计中固有的偏见可能会影响这些相关性。承认这些偏见对于准确解读和应用这些度量标准至关重要。'
- en: Unless otherwise noted, all images in this article created by the author.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，本文中的所有图片均由作者创作。
