- en: What‚Äôs Inside a Neural Network?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/whats-inside-a-neural-network-799daf235463?source=collection_archive---------1-----------------------#2024-09-29](https://towardsdatascience.com/whats-inside-a-neural-network-799daf235463?source=collection_archive---------1-----------------------#2024-09-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Plotting surface of error in 3D using PyTorchüî•
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alexroz?source=post_page---byline--799daf235463--------------------------------)[![Aleksei
    Rozanov](../Images/748b69bfaccf39c9aa568a9e6f41eec3.png)](https://medium.com/@alexroz?source=post_page---byline--799daf235463--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--799daf235463--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--799daf235463--------------------------------)
    [Aleksei Rozanov](https://medium.com/@alexroz?source=post_page---byline--799daf235463--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--799daf235463--------------------------------)
    ¬∑6 min read¬∑Sep 29, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e665c5a7cca94323cffcd6c08b98fb71.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: In my senior year of undergrad, like many other students, I had to choose a
    topic for my bachelor‚Äôs thesis. My major was hydrometeorology, so I initially
    considered researching a problem related to climate modeling. Fortunately, my
    advisor, [Dr. Gribanov](https://scholar.google.com/citations?user=RpUAogkAAAAJ&hl=en),
    suggested exploring a completely new direction I knew nothing about at the time
    ‚Äî applying Neural Networks to upscale terrestrial carbon fluxes. Back then, the
    word ‚Äúneural‚Äù made me think of surgery, and ‚Äúnetwork‚Äù of transportation. However,
    he gave me one of the clearest and most intuitive explanations of neural networks
    I‚Äôve ever heard. One of the highlights was his description of the optimization
    process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine a piece of blank paper like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fb7b70e385d3498cef464408e64daf4c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [GPT](https://openai.com/index/gpt-4/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now I ask you to aggressively (it‚Äôs important) crumple it to a ball:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8955b8b7d4f32cb203fc145d0dc32176.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [GPT](https://openai.com/index/gpt-4/).
  prefs: []
  type: TYPE_NORMAL
- en: 'After straightening it back you‚Äôll see something like an earth surface or some
    kind of a landscape with its peaks and depressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7f6aa185047f64bbca138a6b0fc969b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [GPT](https://openai.com/index/gpt-4/).
  prefs: []
  type: TYPE_NORMAL
- en: Now, if we introduce three dimensions ‚Äî weight 1 , weight 2, and mean squared
    error (MSE) instead of latitude, longitude and elevation ‚Äî we can think of this
    image as representing the error surface of a neural network. The goal of optimization
    is **to find the lowest point on this surface**, which corresponds to the minimum
    error. As you can see from the image there is a multitude of local minima and
    maxima, that‚Äôs why it‚Äôs always a challenging task.
  prefs: []
  type: TYPE_NORMAL
- en: So in this article, we will create such a surface in **3D** and use the [*plotly*](https://plotly.com/)
    Python library to interactively illustrate it, along with the steps of Stochastic
    Gradient Descent (SGD).
  prefs: []
  type: TYPE_NORMAL
- en: '*As always the code of this article you can find on my* [***GitHub***](https://github.com/alexxxroz/Medium/blob/main/Error_surface_NN.ipynb)*.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Data**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First and foremost, we need synthetic data to work with. The data should exhibit
    some non-linear dependency. Let‚Äôs define it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/23ffa0073c771ab4cb5e68fa80e69d85.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: 'In python it will have the following shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'After visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f9e827e1f4c93a3196111a509687adb5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: Neural Net
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we are visualizing a 3D space, our neural network will only have 2 weights.
    This means the ANN will consist of a single hidden neuron. Implementing this in
    PyTorch is quite intuitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Important!** Don‚Äôt forget to turn off the biases in your layers, otherwise
    you‚Äôll end up having **x2** more parameters.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Changing weights**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/cf88d0421295fcd318f41797d5f15671.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the error surface, we first need to create a grid of possible values
    for W1 and W2\. Then, for each weight combination, we will update the parameters
    of the network and calculate the error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: It may take some time. If you make the resolution of this grid too coarse (i.e.,
    the step size between possible weight values), you might miss local minima and
    maxima. Remember how the learning rate is often schedule to decrease over time?
    When we do this, the absolute change in weight values can be as small as 1e-3
    or less. A grid with a 0.5 step simply won‚Äôt capture these fine details of the
    error surface!
  prefs: []
  type: TYPE_NORMAL
- en: '**Training the model**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, we don‚Äôt care at all about the quality of the trained model.
    However, we do want to pay attention to the learning rate, so let‚Äôs keep it between
    1e-1 and 1e-2\. We‚Äôll simply collect the weight values and errors during the training
    process and store them in separate lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c29a4134d350c741b87e453875476377.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: '**Visualization**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, we can visualize the data we have collected using plotly. The plot
    will have two scenes: surface and SGD trajectory. One of the ways to do the first
    part is to create a figure with a plotly *surface*. After that we will style it
    a little by updating a layout.'
  prefs: []
  type: TYPE_NORMAL
- en: The second part is as simple as it is ‚Äî just use *Scatter3d* function and specify
    all three axes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Running it in Google Colab or locally in Jupyter Notebook will allow you to
    investigate the error surface more closely. Honestly, I spent a buch of time just
    looking at this figure:)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7722d9fedc5d08bfd935f0ab7f62996f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [author](https://medium.com/@alexroz).
  prefs: []
  type: TYPE_NORMAL
- en: I‚Äôd love to see you surfaces, so please feel free to share it in comments. I
    strongly believe that the more imperfect the surface is the more interesting it
    is to investigate it!
  prefs: []
  type: TYPE_NORMAL
- en: ===========================================
  prefs: []
  type: TYPE_NORMAL
- en: '*All my publications on Medium are free and open-access, that‚Äôs why I‚Äôd really
    appreciate if you followed me here!*'
  prefs: []
  type: TYPE_NORMAL
- en: P.s. I‚Äôm extremely passionate about (Geo)Data Science, ML/AI and Climate Change.
    So if you want to work together on some project pls contact me in [LinkedIn](https://www.linkedin.com/in/alexxxroz/)
    and check out [my website](https://alexxxroz.github.io/)!
  prefs: []
  type: TYPE_NORMAL
- en: üõ∞Ô∏èFollow for moreüõ∞Ô∏è
  prefs: []
  type: TYPE_NORMAL
