<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Dask DataFrame Is Fast Now</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Dask DataFrame Is Fast Now</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://towardsdatascience.com/dask-dataframe-is-fast-now-ec930181c97a?source=collection_archive---------4-----------------------#2024-05-27">https://towardsdatascience.com/dask-dataframe-is-fast-now-ec930181c97a?source=collection_archive---------4-----------------------#2024-05-27</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="6d3a" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How Dask enables processing data at terabyte scale efficiently</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@patrick_hoefler?source=post_page---byline--ec930181c97a--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Patrick Hoefler" class="l ep by dd de cx" src="../Images/35ca9ef1100d8c93dbadd374f0569fe1.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*76Pqx0N9lf0k9Q-Ttor8Yg.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--ec930181c97a--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@patrick_hoefler?source=post_page---byline--ec930181c97a--------------------------------" rel="noopener follow">Patrick Hoefler</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--ec930181c97a--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div><span data-testid="storyPublishDate">May 27, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/308b0407b24987f46372d5b56e3cf07d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wFT9QkKhnr0Q76wILZFmTg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">Performance Improvements for Dask DataFrames ‚Äî All Images created by the Author</code></figcaption></figure><h2 id="48ce" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">Introduction</h2><p id="5030" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">Dask DataFrame scales out pandas DataFrames to operate at the 100GB-100TB scale.</p><p id="c0b1" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Historically, Dask was pretty slow compared to other tools in this space (like Spark). Due to a number of improvements focused on performance, it‚Äôs now pretty fast (about 20x faster than before). The new implementation moved Dask from getting destroyed by Spark on every benchmark to regularly outperforming Spark on TPC-H queries by a significant margin.</p><p id="db07" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Dask DataFrame workloads struggled with many things. Performance and memory usage were commonly seen pain points, shuffling was unstable for bigger datasets, making scaling out hard. Writing efficient code required understanding too much of the internals of Dask.</p><p id="497f" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The new implementation changed all of this. Things that didn‚Äôt work were completely rewritten from scratch and existing implementations were improved upon. This puts Dask DataFrames on a solid foundation that allows faster iteration cycles in the future.</p><p id="27c4" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">We‚Äôll go through the three most prominent changes, covering how they impact performance and make it easier to use Dask efficiently, even for users that are new to distributed computing. We‚Äôll also discuss plans for future improvements.</p><p id="7c30" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">I am part of the core team of Dask. I am an open source engineer for <a class="af pb" href="https://www.coiled.io" rel="noopener ugc nofollow" target="_blank">Coiled</a> and was involved in implementing some of the improvements discussed in this post.</p><h2 id="ca27" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">1. Apache Arrow Support: Efficient String Datatype</h2><p id="a061" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">A Dask DataFrame consists of many pandas DataFrames. Historically, pandas used NumPy for numeric data, but Python objects for text data, which are inefficient and blow up memory usage. Operations on object data also hold the GIL, which doesn‚Äôt matter much for pandas, but is a catastrophy for performance with a parallel system like Dask.</p><p id="9b3c" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The pandas 2.0 release introduced support for general-purpose Arrow datatypes, so Dask now uses PyArrow-backed strings by default. These are <em class="pc">much</em> better. PyArrow strings reduce memory usage by up to 80% and unlock multi-threading for string operations. Workloads that previously struggled with available memory now fit comfortably in much less space, and are a lot faster because they no longer constantly spill excess data to disk.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pd"><img src="../Images/d84c32d3800a76ea017400b5c0439f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvIY-QitpcMWDke78j19bQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">Memory Usage of the Legacy DataFrames compared with Arrow Strings</code></figcaption></figure><p id="66ef" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">I wrote a post about this that <a class="af pb" href="https://docs.coiled.io/blog/pyarrow-in-pandas-and-dask.html" rel="noopener ugc nofollow" target="_blank">investigates Arrow integrations</a> in more detail if you want to learn more.</p><h2 id="e27c" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">2. Faster Joins with a New Shuffle Algorithm</h2><p id="f2ca" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">Shuffling is an essential component of distributed systems to enable sorting, joins, and complex group by operations. It is an all-to-all, network-intensive operation that‚Äôs often the most expensive component in a workflow. We rewrote Dask‚Äôs shuffling system, which greatly impacts overall performance, especially on complex, data-intensive workloads.</p><p id="efad" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">A shuffle operation is intrinsically an all-to-all communication operation where every input partition has to provide a tiny slice of data to every output partition. Dask was already using it‚Äôs own task-based algorithm that managed to reduce the <code class="cx nb nc nd ne b">O(n * n)</code> task complexity to <code class="cx nb nc nd ne b">O(log(n) * n)</code> where <code class="cx nb nc nd ne b">n</code> is the number of partitions. This was a drastic reduction in the number of tasks, but the non-linear scaling ultimately did not allow Dask to process arbitrarily large datasets.</p><p id="e5e5" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Dask introduced a new P2P (peer-to-peer) shuffle method that reduced the task complexity to <code class="cx nb nc nd ne b">O(n)</code> which scales linearly with the size of the dataset and the size of the cluster. It also incorporates an efficient disk integration which allows easily shuffling datasets which are much larger than memory. The new system is extremely stable and "just works" across any scale of data.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pe"><img src="../Images/06eeae42ba346f26d229371a3f1d9e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*maii_gA6EqByjwsylNyPNg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">Memory Usage of the Legacy Shuffle compared with P2P</code></figcaption></figure><p id="a3dc" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">One of my colleagues wrote <a class="af pb" href="https://docs.coiled.io/blog/shuffling-large-data-at-constant-memory.html" rel="noopener ugc nofollow" target="_blank">a post about this</a> that includes a more extensive explanation and a lot of technical details.</p><h2 id="7142" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">3. Optimizer</h2><p id="6f4c" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">Dask itself is lazy, which means that it registers your whole query before doing any actual work. This is a powerful concept that enables a lot of optimizations, but historically Dask wasn‚Äôt taking advantage of this knowledge in the past. Dask also did a bad job of hiding internal complexities and left users on their own while navigating the difficulties of distributed computing and running large scale queries. It made writing efficient code painful for non-experts.</p><p id="1c85" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk"><a class="af pb" href="https://docs.dask.org/en/stable/changelog.html#query-planning" rel="noopener ugc nofollow" target="_blank">The Dask release in March</a> includes a complete re-implementation of the DataFrame API to support query optimization. This is a big deal. The new engine centers around a query optimizer that rewrites our code to make it more efficient and better tailored to Dask‚Äôs strengths. Let‚Äôs dive into some optimization strategies, how they make our code run faster and scale better.</p><p id="a1be" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">We will start with a couple of general purpose optimizations that are useful for every DataFrame-like tool before we dive into more specific techniques that are tailored to distributed systems generally and Dask more specifically.</p><h2 id="2d78" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">3.1 Column Projection</h2><p id="0ade" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">Most datasets have more columns than what we actually need. Dropping them requires foresight (‚ÄúWhat columns will I need for this query? ü§î‚Äù) so most people don‚Äôt think about this when loading data. This is bad for performance because we carry around lots of data that we don‚Äôt need, slowing everything down. Column Projection drops columns as soon as they aren‚Äôt needed anymore. It‚Äôs a straightforward optimization, but highly beneficial.</p><p id="a0e3" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The legacy implementation always reads all columns from storage and only drops columns if we actively ask for it. Simply operating on less data is a big win for performance and memory usage.</p><p id="9572" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The optimizer looks at the query and figures out which columns are needed for each operation. We can imagine this as looking at the final step of our query and then working backwards step by step to the data source and injecting drop operations to get rid of unnecessary columns.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pf"><img src="../Images/a84cc99cdcd2f59bd804a4137b77b521.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YKnDIuVO9umeA1bFN8-dIw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">We only require a subset of columns in the end. Replace doesn't need access to all columns, so we can drop unnecessary columns directly in the IO step.</code></figcaption></figure><h2 id="df9f" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">3.2 Filter Pushdown</h2><p id="9847" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">Filter pushdown is another general-purpose optimization with the same goal as column projection: operate on less data. The legacy implementation just keeps filters where we put them. The new implementation executes filter operations as early as possible while maintaining the same results.</p><p id="cadb" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The optimizer identifies every filter in our query and looks at the previous operation to see if we can move the filter closer to the data source. It will repeat this until it finds an operation that can‚Äôt be switched with a filter. This is a bit harder than column projections, because we have to make sure that the operations don‚Äôt change the values of our DataFrame. For example, switching a filter and a merge operation is fine (values don‚Äôt change), but switching a filter and a replace operation is invalid, because our values might change and rows that would previously have been filtered out now won‚Äôt be, or vice versa.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pf"><img src="../Images/cf3fab96fed4a7b19ba76286970b9b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HGv9k4aHNJ539Ctdq3iDDQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">Initially, the filter happens after the Dropna, but we can execute the filter before Dropna without changing the result. This allows us to push the filter into the IO step.</code></figcaption></figure><p id="3461" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Additionally, if our filter is strong enough then we can potentially drop complete files in the IO step. This is a best-case scenario, where an earlier filter brings a huge performance improvement and even requires reading less data from remote storage.</p><h2 id="1a26" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">3.3 Automatically Resizing Partitions</h2><p id="b6ef" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">In addition to implementing the common optimization techniques described above, we‚Äôve also improved a common pain point specific to distributed systems genereally and Dask users specifically: optimal partition sizes.</p><p id="962c" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Dask DataFrames consist of many small pandas DataFrames called <em class="pc">partitions</em>. Often, the number of partitions is decided for you and Dask users are advised to manually ‚Äúrepartition‚Äù after reducing or expanding their data (for example by dropping columns, filtering data, or expanding with joins) (see the <a class="af pb" href="https://docs.dask.org/en/stable/dataframe-best-practices.html#repartition-to-reduce-overhead" rel="noopener ugc nofollow" target="_blank">Dask docs</a>). Without this extra step, the (usually small) overhead from Dask can become a bottleneck if the pandas DataFrames become too small, making Dask workflows painfully slow.</p><p id="d03b" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Manually controlling the partition size is a difficult task that we, as Dask users, shouldn‚Äôt have to worry about. It is also slow because it requires network transfer of some partitions. Dask DataFrame now automatically does two things to help when the partitions get too small:</p><ul class=""><li id="3cac" class="od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov pg ph pi bk">Keeps the size of each partition constant, based on the ratio of data you want to compute vs. the original file size. If, for example, you filter out 80% of the original dataset, Dask will automatically combine the resulting smaller partitions into fewer, larger partitions.</li><li id="b5f8" class="od oe fq of b go pj oh oi gr pk ok ol nq pl on oo nu pm oq or ny pn ot ou ov pg ph pi bk">Combines too-small partitions into larger partitions, based on an absolute minimum (default is 75 MB). If, for example, your original dataset is split into many tiny files, Dask will automatically combine them.</li></ul><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj po"><img src="../Images/29a069b1cef38c8590db87fd8c1d8acc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xlYiH2Bze0JQbejse9tCBA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">We select two columns that take up 40 MB of memory out of the 200 MB from the whole file.</code></figcaption></figure><p id="c2aa" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The optimizer will look at the number of columns and the size of the data within those. It calculates a ratio that is used to combine multiple files into one partition.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pp"><img src="../Images/34dd0149f27adf9b8b3dc472e87ba4a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLHdyercnwn5Y5ieQAY3og.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">The ratio of 40/200 results in combining five files into a single partition.</code></figcaption></figure><p id="7adb" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">This step is currently limited to IO operations (like reading in a Parquet dataset), but we plan to extend it to other operations that allow cheaply combining partitions.</p><h2 id="1a56" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">3.4 Trivial Merge and Join Operations</h2><p id="8462" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">Merge and join operations are typically cheap on a single machine with pandas but expensive in a distributed setting. Merging data in shared memory is cheap, while merging data across a network is quite slow, due to the shuffle operations explained earlier.</p><p id="f367" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">This is one of the most expensive operations in a distributed system. The legacy implementation triggered a network transfer of both input DataFrames for every merge operation. This is sometimes necessary, but very expensive.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pq"><img src="../Images/a51a432975c2076cfb5712349c8db866.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0OgDqhcduK_Op_3lOaCJLA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">Both joins are performed on the same column. The left DataFrame is already properly partitioned after the first join, so we can avoid shuffling again with the new implementation.</code></figcaption></figure><p id="3c7f" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The optimizer will determine when shuffling is necessary versus when a trivial join is sufficient because the data is already aligned properly. This can make individual merges an order of magnitude faster. This also applies to other operations that normally require a shuffle like <code class="cx nb nc nd ne b">groupby().apply()</code>.</p><p id="3efe" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Dask merges used to be inefficient, which caused long runtimes. The optimizer fixes this for the trivial case where these operations happen after each other, but the technique isn‚Äôt very advanced yet. There is still a lot of potential for improvement.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pr"><img src="../Images/cc5ea176270a4da971f228de933a3f7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yl_Kr7PZLBbUv-JQwkw-LQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">The current implementation shuffles both branches that originate from the same table. Injecting a shuffle node further up avoids one of the expensive operations.</code></figcaption></figure><p id="a62a" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The optimizer will look at the expression and inject shuffle nodes where necessary to avoid unnecessary shuffles.</p><h2 id="bb84" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">How do the improvements stack up compared to the legacy implementation?</h2><p id="5e8a" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">Dask is now 20x faster than before. This improvement applies to the entire DataFrame API (not just isolated components), with no known performance regressions. Dask now runs workloads that were impossible to complete in an acceptable timeframe before. This performance boost is due to many improvements all layered on top of each other. It‚Äôs not about doing one thing especially well, but about doing nothing especially poorly.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/308b0407b24987f46372d5b56e3cf07d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wFT9QkKhnr0Q76wILZFmTg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx"><code class="cx nb nc nd ne b">Performance improvements on Query 3 of the TPC-H Benchmarks from <a class="af pb" href="https://github.com/coiled/benchmarks/tree/main/tests/tpch_" rel="noopener ugc nofollow" target="_blank">https://github.com/coiled/benchmarks/tree/main/tests/tpch</a></code></figcaption></figure><p id="73ad" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Performance, while the most enticing improvement, is not the only thing that got better. The optimizer hides a lot of complexity from the user and makes the transition from pandas to Dask a lot easier because it‚Äôs now much more difficult to write poorly performing code. The whole system is more robust.</p><p id="8d7b" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">The new architecture of the API is a lot easier to work with as well. The legacy implementation leaked a lot of internal complexities into high-level API implementations, making changes cumbersome. Improvements are almost trivial to add now.</p><h2 id="067f" class="nf ng fq bf nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc bk">What‚Äôs to come?</h2><p id="9623" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">Dask DataFrame changed a lot over the last 18 months. The legacy API was often difficult to work with and struggled with scaling out. The new implementation dropped things that didn‚Äôt work and improved existing implementations. The heavy lifting is finished now, which allows for faster iteration cycles to improve upon the status quo. Incremental improvements are now trivial to add.</p><p id="6344" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">A few things that are on the immediate roadmap:</p><ul class=""><li id="d1af" class="od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov pg ph pi bk"><strong class="of fr">Auto repartitioning:</strong> this is partially implemented, but there is more potential to choose a more efficient partition size during optimization.</li><li id="5281" class="od oe fq of b go pj oh oi gr pk ok ol nq pl on oo nu pm oq or ny pn ot ou ov pg ph pi bk"><strong class="of fr">Faster Joins:</strong> there‚Äôs still lots of fine-tuning to be done here. For example, we have a PR in flight with a 30‚Äì40% improvement.</li><li id="9f9b" class="od oe fq of b go pj oh oi gr pk ok ol nq pl on oo nu pm oq or ny pn ot ou ov pg ph pi bk"><strong class="of fr">Join Reordering:</strong> we don‚Äôt do this yet, but it‚Äôs on the immediate roadmap</li></ul><h1 id="6119" class="ps ng fq bf nh pt pu gq nl pv pw gt np px py pz qa qb qc qd qe qf qg qh qi qj bk"><strong class="al">Learn More</strong></h1><p id="20b4" class="pw-post-body-paragraph od oe fq of b go og oh oi gr oj ok ol nq om on oo nu op oq or ny os ot ou ov fj bk">This article focuses on a number of improvements to Dask DataFrame and how much faster and more reliable it is as a result. If you‚Äôre choosing between Dask and other popular DataFrame tools, you might also consider:</p><ul class=""><li id="1939" class="od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov pg ph pi bk"><a class="af pb" href="https://docs.coiled.io/blog/tpch.html" rel="noopener ugc nofollow" target="_blank"><strong class="of fr">DataFrames at Scale Comparison:</strong> TPC-H</a> which compares Dask, Spark, Polars, and DuckDB performance on datasets ranging from 10 GB to 10 TB both locally and on the cloud.</li></ul><p id="14da" class="pw-post-body-paragraph od oe fq of b go ow oh oi gr ox ok ol nq oy on oo nu oz oq or ny pa ot ou ov fj bk">Thank you for reading. Feel free to reach out to share your thoughts and feedback.</p></div></div></div></div>    
</body>
</html>