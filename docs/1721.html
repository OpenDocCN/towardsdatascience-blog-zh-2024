<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A Sanity Check on ‘Emergent Properties’ in Large Language Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>A Sanity Check on ‘Emergent Properties’ in Large Language Models</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-sanity-check-on-emergent-properties-in-large-language-models-46c1735e111c?source=collection_archive---------2-----------------------#2024-07-15">https://towardsdatascience.com/a-sanity-check-on-emergent-properties-in-large-language-models-46c1735e111c?source=collection_archive---------2-----------------------#2024-07-15</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="c9c7" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">LLMs are often said to have ‘emergent properties’. But what do we even mean by that, and what evidence do we have?</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@anna.rogers?source=post_page---byline--46c1735e111c--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Anna Rogers" class="l ep by dd de cx" src="../Images/6a6422381ad09cabeff96abe776cc4b5.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*y3cm4DdT8spt6RdlgUixVQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--46c1735e111c--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@anna.rogers?source=post_page---byline--46c1735e111c--------------------------------" rel="noopener follow">Anna Rogers</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--46c1735e111c--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">15</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/57e91e506e2928bae4b9a95da2b994b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NzYQDnV2y_M_dbu7z2wuFg.png"/></div></div></figure><p id="0969" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">One of the often-repeated claims about Large Language Models (LLMs), discussed in our <a class="af nt" href="https://openreview.net/forum?id=M2cwkGleRL" rel="noopener ugc nofollow" target="_blank">ICML’24 position paper</a>, is that they have ‘emergent properties’. Unfortunately, in most cases the speaker/writer does not clarify what they mean by ‘emergence’. But misunderstandings on this issue can have big implications for the research agenda, as well as public policy.</p><p id="16c7" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">From what I’ve seen in academic papers, there are at least 4 senses in which NLP researchers use this term:</p><blockquote class="nu nv nw"><p id="13a8" class="mx my nx mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">1. A property that a model exhibits despite not being explicitly trained for it. E.g. <a class="af nt" href="https://arxiv.org/abs/2108.07258" rel="noopener ugc nofollow" target="_blank">Bommasani et al. (2021, p. 5)</a> refer to few-shot performance of GPT-3 <a class="af nt" href="https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" rel="noopener ugc nofollow" target="_blank">(Brown et al., 2020)</a> as “an emergent property that was neither specifically trained for nor anticipated to arise’”.</p><p id="3df9" class="mx my nx mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">2. (Opposite to def. 1): a property that the model learned from the training data. E.g. <a class="af nt" href="https://aclanthology.org/2023.findings-acl.326/" rel="noopener ugc nofollow" target="_blank">Deshpande et al. (2023, p. 8)</a> discuss emergence as evidence of “the advantages of pre-training’’.</p><p id="fda3" class="mx my nx mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">3. A property “is emergent if it is not present in smaller models but is present in larger models.’’ (<a class="af nt" href="https://openreview.net/pdf?id=yzkSU5zdwD" rel="noopener ugc nofollow" target="_blank">Wei et al., 2022, p. 2</a>).</p><p id="b192" class="mx my nx mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">4. A version of def. 3, where what makes emergent properties “intriguing’’ is “their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales” <a class="af nt" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/adc98a266f45005c403b8311ca7e8bd7-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank">(Schaeffer, Miranda, &amp; Koyejo, 2023, p. 1)</a></p></blockquote><p id="7bfa" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For a technical term, this kind of fuzziness is unfortunate. If many people repeat the claim “LLLs have emergent properties” without clarifying what they mean, a reader could infer that there is a broad scientific consensus that this statement is true, according to the <em class="nx">reader’s</em> own definition.</p><p id="01b4" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">I am writing this post after giving many talks about this in NLP research groups all over the world — Amherst and Georgetown (USA), Cambridge, Cardiff and London (UK), Copenhagen (Denmark), Gothenburg (Sweden), Milan (Italy), Genbench workshop (EMNLP’23 @ Singapore) (thanks to everybody in the audience!). This gave me a chance to poll a lot of NLP researchers about what they thought of emergence. Based on the responses from 220 NLP researchers and PhD students, by far the most popular definition is (1), with (4) being the second most popular.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ny"><img src="../Images/8d035a27fecb81b1dded9b2b0c973667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rO2xrU5JnjyU9tP7.png"/></div></div></figure><p id="c641" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The idea expressed in definition (1) also often gets invoked in public discourse. For example, you can see it in the <a class="af nt" href="https://www.buzzfeednews.com/article/pranavdixit/google-60-minutes-ai-claims-challenged" rel="noopener ugc nofollow" target="_blank">claim that Google’s PaLM model ‘knew’ a language it wasn’t trained on</a> (which is almost certainly false). The same idea also provoked the following public exchange between a US senator and Melanie Mitchell (a prominent AI researcher, professor at Santa Fe Institute):</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="oa ob l"/></div></figure><p id="a9d5" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">What this exchange shows is the idea of LLM ‘emergent properties’ per definition (1) has implications outside the research world. It contributes to the <a class="af nt" href="https://x.com/BasedNorthmathr/status/1797142896069488857" rel="noopener ugc nofollow" target="_blank">anxiety about the imminent takeover by super-AGI</a>, to <a class="af nt" href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/" rel="noopener ugc nofollow" target="_blank">calls for pausing research</a>. It could push the policy-makers in the wrong directions, such as banning open-source research — which would further consolidate resources in the hands of a few big tech labs, and ensure they won’t have much competition. It also creates the impression of LLMs as entities independent on the choices of their developers and deployers — which has huge implications for <em class="nx">who</em> is accountable for any harms coming from these models. With such high stakes for the research community and society, shouldn’t we at least make sure that the science is sound?</p><h1 id="93d0" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">How much do these notions of ‘emergence’ contribute to the scientific understanding of LLMs?</h1><p id="daa4" class="pw-post-body-paragraph mx my fq mz b go oy nb nc gr oz ne nf ng pa ni nj nk pb nm nn no pc nq nr ns fj bk">Much in the above versions of ‘emergence’ in LLMs is still debatable: how much do they actually advance the scientific discussion, with respect to other terms and known principles that are already in use? I would like to stress that this discussion is completely orthogonal to the question of whether LLMs are useful or valuable. Countless models have been and will be practically useful without claims of emergence.</p><p id="46ca" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Let us start with definition 2: <em class="nx">something that a model learned from the training data</em>. Since this is exactly what a machine learning model is supposed to do, does this version of ‘emergence’ add much to ‘learning’?</p><p id="4e15" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For the definition (3) (<em class="nx">something that only large models do</em>), the better performance of larger models is to be expected, given basic machine learning principles: the larger model simply has more capacity to learn the patterns in its training data. Hence, this version of ‘emergence’ also does not add much. Unless we expect that the larger models, but not the small ones, do something they weren’t trained for — but then this definition depends on definition (1).</p><p id="24fa" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For the definition (4), the phenomenon of <em class="nx">sharp</em> change in performance turned out to be attributable to non-continuous evaluation metrics (e.g. for classification tasks like multi-choice question answering), rather than LLMs themselves <a class="af nt" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/adc98a266f45005c403b8311ca7e8bd7-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank">(Schaeffer, Miranda, &amp; Koyejo, 2023)</a>. Furthermore, J. Wei himself acknowledges that the current claims of sharp changes are based on results from models that are only available in relatively few sizes (1B, 7B, 13B, 70B, 150B…), and if we had more results for intermediate model sizes, the increase in performance would likely turn out to be smooth <a class="af nt" href="https://www.jasonwei.net/blog/common-arguments-regarding-emergent-abilities" rel="noopener ugc nofollow" target="_blank">(Wei, 2023)</a>.</p><p id="2fca" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The <em class="nx">unpredictability</em> part of definition (4) was reiterated by <a class="af nt" href="https://www.jasonwei.net/blog/common-arguments-regarding-emergent-abilities" rel="noopener ugc nofollow" target="_blank">J. Wei (2023)</a> as follows: “the “emergence” phenomenon is still interesting if there are large differences in predictability: for some problems, performance of large models can easily be extrapolated from performance of models 1000x less in size, whereas for others, even it cannot be extrapolated even from 2x less size.”</p><p id="e4b6" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">However, the cited predictability at 1,000x less compute refers to the GPT-4 report <a class="af nt" href="https://arxiv.org/abs/2303.08774" rel="noopener ugc nofollow" target="_blank">(OpenAI, 2023)</a>, where the developers knew the target evaluation in advance, and specifically optimized for it. Given that, predictable scaling is hardly surprising theoretically (though still impressive from the engineering point of view). This is in contrast with the unpredictability at 2x less compute for unplanned BIG-Bench evaluation in <a class="af nt" href="https://openreview.net/pdf?id=yzkSU5zdwD" rel="noopener ugc nofollow" target="_blank">(Wei et al., 2022)</a>. This unpredictability is expected, simply due to the unknown interaction between (a) the presence of training data that is similar to test data, and (b) sufficient model capacity to learn some specific patterns.</p><p id="bee2" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Hence, we are left with the definition (1): emergent properties are properties that the model was not explicitly trained for. This can be interpreted in two ways:</p><blockquote class="nu nv nw"><p id="9be2" class="mx my nx mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">5. A property is emergent if the model was not exposed to training data for that property.</p><p id="2a24" class="mx my nx mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">6. A property is emergent even if the model was exposed to the relevant training data — as long as the model developers were unaware of it.</p></blockquote><p id="d870" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Per def. 6, it would appear that the research question is actually ‘what data exists on the Web?’ (or in proprietary training datasets of generative AI companies), and we are training LLMs as a very expensive method to answer that question. For example, <a class="af nt" href="https://reddit.com/r/AnarchyChess/comments/10ydnbb/i_placed_stockfish_white_against_chatgpt_black/" rel="noopener ugc nofollow" target="_blank">ChatGPT can generate chess moves that are plausible-looking (but often illegal)</a>. This is surprising if we think of ChatGPT as a <em class="nx">language</em> model, but not if we know that it is a model trained on a web corpus, because such a corpus would likely include not only texts in a natural language, but also materials like chess transcripts, ascii art, midi music, programming code etc. The term ‘language model’ is actually a misnomer — they are rather <em class="nx">corpus</em> models <a class="af nt" href="https://doi.org/10.1109/ACCESS.2022.3182505" rel="noopener ugc nofollow" target="_blank">(Veres, 2022)</a>.</p><p id="711d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Per def. 5, we can prove that some property is emergent only by showing that the model was not exposed to evidence that could have been the basis for the model outputs in the training data. And it cannot be due to lucky sampling in the latent space of the continuous representations. If we are allowed to generate as many samples as we want and cherry-pick, we are eventually going to get some fluent text even from a randomly initialized model — but this should arguably not count as an ‘emergent property’ on definition (5).</p><p id="5d93" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For commercial models with undisclosed training data such as ChatGPT, such a proof is out of the question. But even for the “open” LLMs this is only a hypothesis (if not wishful thinking), because so far we are lacking detailed studies (or even a methodology) to consider the exact relation between the amount and kinds of evidence in the training text data for a particular model output. On definition 5, emergent properties are a machine learning equivalent of alchemy — and the bar for postulating that should be quite high.</p><p id="af06" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Especially in the face of evidence to the contrary.</p><h1 id="01e9" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">Counter-evidence to ‘emergent properties’ in LLMs</h1><p id="2d21" class="pw-post-body-paragraph mx my fq mz b go oy nb nc gr oz ne nf ng pa ni nj nk pb nm nn no pc nq nr ns fj bk">Here are some of the empirical results that make it dubious that LLMs have ‘emergent properties’ by definition (5) (the model was not exposed to training data for that property):</p><ul class=""><li id="c028" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns pd pe pf bk">Phenomenon of prompt sensitivity (<a class="af nt" href="https://aclanthology.org/2022.acl-long.556/" rel="noopener ugc nofollow" target="_blank">Lu, Bartolo, Moore, Riedel, &amp; Stenetorp, 2022</a>; <a class="af nt" href="https://proceedings.mlr.press/v139/zhao21c.html" rel="noopener ugc nofollow" target="_blank">Zhao, Wallace, Feng, Klein, &amp; Singh, 2021</a>): LLMs responding differently to prompts that should be semantically equivalent. If we say that models have an emergent property of answering questions, slightly different ways of posing these questions, and especially different order of few-shot examples, should not matter. The most likely explanation for the prompt sensitivity is that the model responds better to prompts that are more similar to its training data in some way that helps the model.</li><li id="dc2f" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk">Liang et. al evaluate 30 LLMs and conclude that “regurgitation (of copyrighted materials) risk clearly correlates with model accuracy’’ <a class="af nt" href="https://arxiv.org/abs/2211.09110" rel="noopener ugc nofollow" target="_blank">(2022, p. 12)</a>. This suggests that models which ‘remember’ more of training data perform better.</li><li id="4e86" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk"><a class="af nt" href="https://arxiv.org/abs/2309.13638" rel="noopener ugc nofollow" target="_blank">McCoy, Yao, Friedman, Hardy, &amp; Griffiths (2023)</a> show that LLM performance depends on probabilities of output word sequences in web texts.</li><li id="1c93" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk"><a class="af nt" href="https://aclanthology.org/2024.acl-long.279.pdf" rel="noopener ugc nofollow" target="_blank">Lu, Bigoulaeva, Sachdeva, Madabushi, &amp; Gurevych (2024)</a> show that the ‘emergent’ abilities of 18 LLMs can be ascribed mostly to in-context learning. Instruction tuning facilitates in-context learning, but does not seem to have an independent effect.</li><li id="8eb5" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk">For in-context learning itself (first shown in GPT-3 <a class="af nt" href="https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" rel="noopener ugc nofollow" target="_blank">(Brown et al., 2020)</a>, and used as the example of ‘emergence’ by Bommasani et al. <a class="af nt" href="https://arxiv.org/abs/2108.07258" rel="noopener ugc nofollow" target="_blank">(2021, p. 5)</a>, the results of <a class="af nt" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/77c6ccacfd9962e2307fc64680fc5ace-Abstract-Conference.html" rel="noopener ugc nofollow" target="_blank">Chen, Santoro et al. (2022)</a> suggest that it happens only in Transformers trained on sequences, structurally similar to the sequences in which in-context learning would be tested.</li><li id="ed52" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk"><a class="af nt" href="https://arxiv.org/abs/2304.03439" rel="noopener ugc nofollow" target="_blank">Liu et al. (2023)</a> report that ChatGPT and GPT-4 perform better on older compared to newly released benchmarks, suggesting that many evaluation results may be inflated due to data contamination. OpenAI itself went to great lengths in the GPT-3 paper <a class="af nt" href="https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" rel="noopener ugc nofollow" target="_blank">(Brown et al., 2020)</a> showing how difficult it is to mitigate this problem. Since we know nothing about the training data of the latest models, external evaluation results may not be meaningful, and internal reports by companies that sell their models as a commercial service have a clear conflict of interest.</li></ul><p id="c33e" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">A well-known effort to propose a methodology that would avoid at least the data contamination problem is the ‘sparks of AGI’ study <a class="af nt" href="http://arxiv.org/abs/2303.12712" rel="noopener ugc nofollow" target="_blank">(Bubeck et al., 2023)</a>. Using the methodology of newly constructed test cases, checked against public web data, and their perturbations, the authors notably concluded that GPT-4 possesses “a very advanced theory of mind’’. At least two studies have come to the opposite conclusion (<a class="af nt" href="https://aclanthology.org/2022.emnlp-main.248" rel="noopener ugc nofollow" target="_blank">Sap, Le Bras, Fried, &amp; Choi, 2022</a>; <a class="af nt" href="https://aclanthology.org/2024.eacl-long.138/" rel="noopener ugc nofollow" target="_blank">Shapira et al., 2024</a>). The most likely reason for the failure of this methodology is that while we can check for direct matches on the web, we could still miss some highly similar cases (e.g. the well-known example of unicorn drawn in tikz from that paper <a class="af nt" href="https://twitter.com/DimitrisPapail/status/1644809234431848450?s=20" rel="noopener ugc nofollow" target="_blank">could be based on the stackoverflow community drawing other animals in tikz</a>). Furthermore, the commercial LLMs such as GPT-4 could also be trained on data that is not publicly available. In the case of OpenAI, hundreds of researchers and other users of GPT-3 have submitted a lot of data though the API, before OpenAI changed their terms of service to not use such data for training by default.</p><p id="ef69" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This is not to say that it is absolutely impossible that LLMs could work well out of their training distribution. Some degree of generalization is happening, and the best-case scenario is that it is due to interpolation of patterns that were observed in training data individually, but not together. But at what point we would say that the result is something qualitatively new, what kind of similarity to training data matters, and how we could identify it — these are all still-unresolved research questions.</p><h1 id="c549" class="oc od fq bf oe of og gq oh oi oj gt ok ol om on oo op oq or os ot ou ov ow ox bk">NLP researchers are actually NOT convinced about LLM ‘emergent properties’</h1><p id="a059" class="pw-post-body-paragraph mx my fq mz b go oy nb nc gr oz ne nf ng pa ni nj nk pb nm nn no pc nq nr ns fj bk">As I mentioned, I had a chance to give a talk about this in several NLP research groups. In the very beginning of these talks, <em class="nx">before</em> I presented the above discussion, I asked the audience a few questions, including whether they personally believed that LLMs had emergent properties (according to their preferred definition, which, as shown above, was predominantly (1)). I also asked them about their perception of the consensus in the field — what did they think that most other NLP researchers thought about this? For the first question I have answers from 259 researchers and PhD students, and for the second — from 360 (note to self: give people more time to connect to the poll).</p><p id="7099" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The results were striking: while most respondents were skeptical or unsure about LLM emergent properties themselves (only 39% agreed with that statement), 70% thought that most <em class="nx">other</em> researchers did believe this.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pl"><img src="../Images/1500c1639ea258df983856d2791205a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/0*RAZBRj5q5avJxOpf.png"/></div></figure><p id="114d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This is in line with several other false sociological beliefs: e.g. many NLP researchers don’t think that NLP leaderboards are particularly meaningful, or that scaling will solve everything, but they do think that <em class="nx">other</em> NLP researchers believe that <a class="af nt" href="https://aclanthology.org/2023.acl-long.903/" rel="noopener ugc nofollow" target="_blank">(Michael et al., 2023)</a>. In my sample, the idea that LLM have emergent properties is similarly held by a minority of researchers, but it is misperceived to be the majority. And even for that minority the conviction is not very firm. In four of my talks, after presenting the above discussion, I also asked the audience what they thought now. In this sample of 70 responses, 83% of those who originally agreed with the statement “LLMs have emergent properties”, changed their belief to either disagreeing (13.9%) or being unsure (69.4%).</p><p id="3105" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In retrospect, “agree/disagree/unsure” is not the best choice of options for this poll. As scientists, we can hardly ever be 100% sure: as Yann LeCun put it in the <a class="af nt" href="https://munkdebates.com/debates/artificial-intelligence/" rel="noopener ugc nofollow" target="_blank">Munk debate</a>, we cannot even prove that there is no teapot orbiting Jupiter right now. Our job is not to fall into such distracting rabbit holes, but to formulate and test hypotheses that would advance our understanding of the phenomenon we are studying. For ‘emergence’ in LLMs, I think we are still at the ‘formulation’ stage — since even after all the above work with clarifying ‘emergence’ we still don’t have a research question, for which it is clear how to obtain empirical evidence.</p><p id="0325" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The key unresolved question is what kind of interpolation of existing patterns would even count as something new enough to qualify as an ‘emergent phenomenon’ in the domain of natural language data. This domain is particularly hard, because it mixes different kinds of information (linguistic, social, factual, commonsense), and that information may be present differently (explicit in context, implicit, or requiring reasoning over long contexts). See <a class="af nt" href="https://arxiv.org/abs/2107.12708" rel="noopener ugc nofollow" target="_blank">Rogers, Gardner, &amp; Augenstein (2023, pp. sec. 8.2)</a> for a discussion of different skills involved in just the question answering task.</p><blockquote class="nu nv nw"><p id="7cd7" class="mx my nx mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><em class="fq">📢 </em>If the relationship between LLM output and its training data is a problem that you (or someone you know) would like to figure out — there are funded <a class="af nt" href="https://candidate.hr-manager.net/ApplicationInit.aspx?cid=119&amp;ProjectId=181730&amp;DepartmentId=3439&amp;MediaId=5" rel="noopener ugc nofollow" target="_blank">postdoc</a> / <a class="af nt" href="https://candidate.hr-manager.net/ApplicationInit.aspx?cid=119&amp;ProjectId=181734&amp;DepartmentId=3439&amp;MediaId=5" rel="noopener ugc nofollow" target="_blank">PhD</a> positions to work on it in beautiful Copenhagen! (apply by Nov 15/22 2024)</p></blockquote></div></div></div><div class="ab cb pm pn po pp" role="separator"><span class="pq by bm pr ps pt"/><span class="pq by bm pr ps pt"/><span class="pq by bm pr ps"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="831e" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">If you’d like to cite this post: most of the above points, except for poll results, are based on a part of this <a class="af nt" href="https://openreview.net/forum?id=M2cwkGleRL" rel="noopener ugc nofollow" target="_blank">ICML 2024 position paper</a>, which also considers the philosophy-of-science sense of ‘emergence’, and its applicability to LLMs. We also discuss <strong class="mz fr">what we even mean by ‘large language model’</strong> (as opposed to ‘foundation’ and ‘frontier’ models), and several other often-repeated claims that come with a lot of footnotes: <strong class="mz fr">LLMs are robust</strong>, <strong class="mz fr">LLMs are state-of-the-art</strong>, <strong class="mz fr">(LLM) scale is all you need</strong>, <strong class="mz fr">LLMs are general-purpose-technologies</strong>.</p><p id="174d" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Acknowledgements:</p><ul class=""><li id="55fa" class="mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns pd pe pf bk">my brilliant co-author Sasha Luccioni</li><li id="234d" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk">all the anonymous reviewers of the above paper</li><li id="a39d" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk">Rob van der Goot, Christian Hardmeier, Yacine Jernite, Margaret Mitchell, Dennis Ulmer, who read the early versions of the paper and provided feedback</li><li id="2ef4" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk">Ryan Cotterell, Ishita Dasgupta, Laura Gwilliams, Julia Haas, Anna Ivanova, Tal Linzen, Ben Lipkin, Asad Sayeed for their insights and discussion</li><li id="68dc" class="mx my fq mz b go pg nb nc gr ph ne nf ng pi ni nj nk pj nm nn no pk nq nr ns pd pe pf bk">everybody responding to my polls at <a class="af nt" href="https://talks.cam.ac.uk/show/archive/60438" rel="noopener ugc nofollow" target="_blank">Cambridge LTL</a>, <a class="af nt" href="https://cardiffnlp.github.io/" rel="noopener ugc nofollow" target="_blank">Cardiff NLP</a>, <a class="af nt" href="https://cst.ku.dk/kalender/sprogteknologisk-konference-2023/" rel="noopener ugc nofollow" target="_blank">Center for Language Technology @ Copenhagen University</a>, <a class="af nt" href="https://www.gu.se/en/clasp" rel="noopener ugc nofollow" target="_blank">CLASP</a>, <a class="af nt" href="https://gucl.georgetown.edu/" rel="noopener ugc nofollow" target="_blank">CL@Georgetown</a>, <a class="af nt" href="https://genbench.org/workshop/" rel="noopener ugc nofollow" target="_blank">Genbench @ EMNLP23</a>, <a class="af nt" href="https://milanlproc.github.io/" rel="noopener ugc nofollow" target="_blank">Milan NLP</a>, <a class="af nt" href="https://www.responsible-ai.science/" rel="noopener ugc nofollow" target="_blank">QMUL</a>, and <a class="af nt" href="https://people.cs.umass.edu/~miyyer/nlpseminar/index.html" rel="noopener ugc nofollow" target="_blank">UMass Amherst</a>.</li></ul></div></div></div><div class="ab cb pm pn po pp" role="separator"><span class="pq by bm pr ps pt"/><span class="pq by bm pr ps pt"/><span class="pq by bm pr ps"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="8e7c" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><em class="nx">Originally published at </em><a class="af nt" href="https://hackingsemantics.xyz/2024/emergence/" rel="noopener ugc nofollow" target="_blank"><em class="nx">https://hackingsemantics.xyz</em></a><em class="nx"> on July 15, 2024.</em></p><p id="7451" class="pw-post-body-paragraph mx my fq mz b go na nb nc gr nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><em class="nx">All images in the story were created by the author. The header image includes the </em><a class="af nt" href="https://commons.wikimedia.org/wiki/File:Alasti_keiser,_Edward_von_L%C3%B5nguse_t%C3%B6%C3%B6_Tartus.JPG" rel="noopener ugc nofollow" target="_blank"><em class="nx">stencil graffiti “The naked emperor” by Edward von Lõngus, used under CC-BY-SA 4.0</em></a><em class="nx">.</em></p></div></div></div></div>    
</body>
</html>