- en: Text to Knowledge Graph Made Easy with Graph Maker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/text-to-knowledge-graph-made-easy-with-graph-maker-f3f890c0dbe8?source=collection_archive---------0-----------------------#2024-05-07](https://towardsdatascience.com/text-to-knowledge-graph-made-easy-with-graph-maker-f3f890c0dbe8?source=collection_archive---------0-----------------------#2024-05-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An open-source library for building knowledge graphs from text corpus using
    open-source LLMs like Llama 3 and Mixtral.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)[![Rahul
    Nayak](../Images/9f8aa2f9af4e02b31c114222756489e5.png)](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)
    [Rahul Nayak](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)
    ·11 min read·May 7, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f16f965b89f5a55a880765fbab232f08.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the Author using Adobe Photoshop
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will share a Python library — the Graph Maker — that can
    create a Knowledge Graph from a corpus of text as per a given Ontology. The Graph
    Maker uses open-source LLMs like Llama3, Mistral, Mixtral or Gemma to extract
    the KG.
  prefs: []
  type: TYPE_NORMAL
- en: We will go through the basics of ‘Why’ and ‘What’ of the Graph Maker, a brief
    recap of the previous article, and how the current approach addresses some of
    its challenges. I will share the GitHub repository at the end of this article.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This article is a sequel to the article I wrote a few months ago about how to
    convert any text into a Graph.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a?source=post_page-----f3f890c0dbe8--------------------------------)
    [## How to Convert Any Text Into a Graph of Concepts'
  prefs: []
  type: TYPE_NORMAL
- en: A method to convert any text corpus into a Knowledge Graph using Mistral 7B.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a?source=post_page-----f3f890c0dbe8--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The article received an overwhelming response. The GitHub repository shared
    in the article has more than 180 Forks and more than 900 Stars. The article itself
    was read by more than 80K readers on the Medium. Recently the article was attributed
    in the following paper published by Prof Markus J. Buehler at MIT.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://arxiv.org/abs/2403.11996?source=post_page-----f3f890c0dbe8--------------------------------)
    [## Accelerating Scientific Discovery with Generative Knowledge Extraction, Graph-Based
    Representation…'
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging generative Artificial Intelligence (AI), we have transformed a dataset
    comprising 1,000 scientific papers…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2403.11996?source=post_page-----f3f890c0dbe8--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: This is a fascinating paper that demonstrates the gigantic potential of Knowledge
    Graphs in the era of AI. It demonstrates how KGs can be used, not only to retrieve
    knowledge but also to discover new knowledge. Here is one of my favourite excerpts
    from this paper.
  prefs: []
  type: TYPE_NORMAL
- en: “For instance, we will show how this approach can relate seemingly disparate
    concepts such as Beethoven’s 9th symphony with bio-inspired materials science”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: These developments are a big reaffirmation of the ideas I presented in the previous
    article and encouraged me to develop the ideas further.
  prefs: []
  type: TYPE_NORMAL
- en: I also received numerous feedback from fellow techies about the challenges they
    encountered while using the repository, and suggestions for improving the idea.
    I incorporated some of these suggestions into a new Python package I share here.
  prefs: []
  type: TYPE_NORMAL
- en: Before we discuss the working of the package — The Graph Maker — let us discuss
    the ‘Why’ and the ‘What’ of it.
  prefs: []
  type: TYPE_NORMAL
- en: A Brief Recap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should probably start with ‘Why Graphs’. However, We discussed this briefly
    in my [previous article](https://medium.com/towards-data-science/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a).
    Feel free to hop onto that article for a refresher. However, let us briefly discuss
    the key concepts that are relevant to our current discussion here.
  prefs: []
  type: TYPE_NORMAL
- en: '**TL;DR this section if you are already well versed in the lore of Knowledge
    Graphs.**'
  prefs: []
  type: TYPE_NORMAL
- en: Here is an illustration that sums up the idea of Knowledge Graphs neatly.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/59d71971200611f5a682adfa61e54a89.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://arxiv.org/abs/2403.11996](https://arxiv.org/abs/2403.11996)'
  prefs: []
  type: TYPE_NORMAL
- en: To create a KG, we need two pieces of information.
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge Base**: This can be a corpus of text, a code base, a collection
    of articles, etc.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Ontology**: The categories of the entities, and the types of their relationships
    we care about. I am probably oversimplifying the definition of ontology here but
    it works for our purpose.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here is a simple ontology
  prefs: []
  type: TYPE_NORMAL
- en: '**Entities**: *Person, Place*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Relationships:**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Person —* related to → *Person*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Person* — lives in → *Place'
  prefs: []
  type: TYPE_NORMAL
- en: Person* — visits → *Place*
  prefs: []
  type: TYPE_NORMAL
- en: Given these two pieces of information, we can build a KG from a text that mentions
    people and places. However, let’s say our knowledge base is about a clinical study
    of prescription drugs and their interactions. We might use a different ontology
    where Compounds, Usage, Effects, Reactions etc may form our ontology.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous article, we discussed [**How we can extract a Knowledge Graph
    using an LLM, without supplying it with an ontology**](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a).
    The idea was to let the LLM discover the ontology best suited for the given corpus
    of text by itself.
  prefs: []
  type: TYPE_NORMAL
- en: Although this approach lacks the rigour of the traditional methods of generating
    KGs, it has its merits. It can generate KGs with unstructured data more easily
    than traditional methods. The KGs that it generates are, in some sense, also unstructured.
    However, they are easier to build and are richer in information. They are well
    suited for GRAG (Graph Retrieval Augmented Generation) like applications.
  prefs: []
  type: TYPE_NORMAL
- en: Why The Graph Maker?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let me list a few challenges and observations I received in the feedback for
    my previous article. It will help us understand the challenges in creating KGs
    with LLMs. Let us use the Wikipedia summary of the **Lord of the Rings** books.
    One cant not love the Lord of the Rings after all!
  prefs: []
  type: TYPE_NORMAL
- en: Meaningful Entities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given a free run, the entities that the LLM extracts can be too diverse in their
    categories. It mistakes by marking abstract concepts as entities. For example
    in the text “Bilbo Baggins celebrates his birthday and leaves the Ring to Frodo”,
    the LLM may extract “Bilbo Baggins celebrates his birthday” or “Celebrates his
    birthday” as ‘Action’. But it may be more useful if it extracts “Birthday” as
    an ‘Event’.
  prefs: []
  type: TYPE_NORMAL
- en: '**Consistent Entities**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It can also mistake marking the same entity differently in different contexts.
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**‘*Sauron’***, **‘*the Dark Lord Sauron’***and***‘the Dark Lord’***Should
    not be extracted as different entities. Or if they are extracted as different
    entities, they should be connected with an equivalence relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resilience in parsing**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The output of the LLMs is, by nature, indeterministic. To extract the KG from
    a large document, we must split the corpus into smaller text chunks and then generate
    subgraphs for every chunk. To build a consistent graph, the LLM must output JSON
    objects as per the given schema consistently for every subgraph. Missing even
    one may affect the connectivity of the entire graph adversely.
  prefs: []
  type: TYPE_NORMAL
- en: Although LLMs are getting better at responding with well-formatted JSON objects,
    It is still far from perfect. LLMs with limited context windows may also generate
    incomplete responses.
  prefs: []
  type: TYPE_NORMAL
- en: '**Categorisation of the Entities**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs can error generously when recognising entities. This is a bigger problem
    when the context is domain-specific, or when the entities are not named in standard
    English. NER models can do better at that, but they too are limited to the data
    they are trained on. Moreover, they can’t understand the relations between the
    entities.
  prefs: []
  type: TYPE_NORMAL
- en: To coerce an LLM to be consistent with categories is an art in prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: '**Implied relations**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Relations can be explicitly mentioned, or implied by the context. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '“Bilbo Baggins celebrates his birthday and leaves the Ring to Frodo” implies
    the relationships:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Bilbo Baggins* → Owner → *Ring*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Bilbo Baggins* → heir → *Frodo*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Frodo* → Owner → *Ring*'
  prefs: []
  type: TYPE_NORMAL
- en: Here I think LLMs at some point in time will become better than any traditional
    method of extracting relationships. But as of now, this is a challenge that needs
    clever prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: The Graph Maker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The graph maker library I share here improves upon the previous approach by
    travelling halfway between the rigour and the ease — halfway between the structure
    and the lack of it. It does remarkably better than the previous approach I discussed
    on most of the above challenges.
  prefs: []
  type: TYPE_NORMAL
- en: As opposed to the previous approach, where the LLM is free to discover the ontology
    by itself, the graph maker tries to coerce the LLM to use a user-defined ontology.
  prefs: []
  type: TYPE_NORMAL
- en: We can install the knowledge graph maker library with a simple pip command
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[](https://pypi.org/project/knowledge-graph-maker/?source=post_page-----f3f890c0dbe8--------------------------------)
    [## knowledge-graph-maker'
  prefs: []
  type: TYPE_NORMAL
- en: Create a knowledge graph out of any text using a given ontology
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pypi.org](https://pypi.org/project/knowledge-graph-maker/?source=post_page-----f3f890c0dbe8--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Here is how it works in 5 easy steps.
  prefs: []
  type: TYPE_NORMAL
- en: These steps are coded in a notebook that I share at the end of this article.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 1\. Define the Ontology of your Graph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The library understands the following schema for the Ontology. Behind the scenes,
    ontology is a pydantic model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: I have tuned the prompts to yield results that are consistent with the given
    ontology. I think it does a pretty good job at it. However, it is still not 100%
    accurate. The accuracy depends on the model we choose to generate the graph, the
    application, the ontology, and the quality of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Split the text into chunks.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use as large a corpus of text as we want to create large knowledge graphs.
    However, LLMs have a finite context window right now. So we need to chunk the
    text appropriately and create the graph one chunk at a time. The chunk size that
    we should use depends on the model context window. The prompts that are used in
    this project eat up around 500 tokens. The rest of the context can be divided
    into input text and output graph. In my experience, smaller chunks of 200 to 500
    tokens generate a more detailed graph.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Convert these chunks into Documents.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The document is a pydantic model with the following schema
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The metadata we add to the document here is tagged to every relation that is
    extracted out of the document.
  prefs: []
  type: TYPE_NORMAL
- en: We can add the context of the relation, for example, the page number, chapter,
    the name of the article, etc. into the metadata. More often than not, Each node
    pairs have multiple relations with each other across multiple documents. The metadata
    helps contextualise these relationships.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Run the Graph Maker.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Graph Maker directly takes a list of documents and iterates over each of
    them to create one subgraph per document. The final output is the complete graph
    of all the documents.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a simple example of how to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The Graph Makers run each document through the LLM and parse the response to
    create the complete graph. The final graph is as a list of edges, where every
    edge is a pydantic model like the following.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: I have tuned the prompts so they generate fairly consistent JSONs now. In case
    the JSON response fails to parse, the graph maker also tries to manually split
    the JSON string into multiple strings of edges and then tries to salvage whatever
    it can.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Save to Neo4j
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can save the model to Neo4j either to create an RAG application, run Network
    algorithms, or maybe just visualise the graph using [the Bloom](https://neo4j.com/product/bloom/)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Each edge of the graph is saved to the database as a transaction. If you are
    running this code for the first time, then set the `create_indices` to true. This
    prepares the database by setting up the uniqueness constraints on the nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '***5.1 Visualise, just for fun if nothing else*** In the previous article,
    we visualised the graph using networkx and pyvis libraries. Here, because we are
    already saving the graph to Neo4J, we can leverage Bloom directly to visualise
    the graph.'
  prefs: []
  type: TYPE_NORMAL
- en: To avoid repeating ourselves, let us generate a different visualisation from
    what we did in the previous article.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say we like to see how the relations between the characters evolve through
    the book.
  prefs: []
  type: TYPE_NORMAL
- en: We can do this by tracking how the edges are added to the graph incrementally
    while the graph maker traverses through the book. To enable this, the Edge model
    has an attribute called ‘order’. This attribute can be used to add a temporal
    or chronological dimension to the graph.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, the graph maker automatically adds the sequence number in which
    a particular text chunk occurs in the document list, to every edge it extracts
    from that chunk. So to see how the relations between the characters evolve, we
    just have to cross section the graph by the order of the edges.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an animation of these cross-sections.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef0062beb0ec37c82d0bcaa3403679f3.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation generated by the Author
  prefs: []
  type: TYPE_NORMAL
- en: Graph and RAG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The best application of this kind of KG is probably in RAG. There are umpteen
    articles on Medium on how to augment your RAG applications with Graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially Graphs offer a plethora of different ways to retrieve knowledge.
    Depending on how we design the Graph and our application, some of these techniques
    can be more powerful than simple semantic search.
  prefs: []
  type: TYPE_NORMAL
- en: At the very basic, we can add embedding vectors into our nodes and relationships,
    and run a semantic search against the vector index for retrieval. However, I feel
    the real power of the Graphs for RAG applications is when we mix Cypher queries
    and Network algorithms with Semantic Search.
  prefs: []
  type: TYPE_NORMAL
- en: I have been exploring some of these techniques myself. I am hoping to write
    about them in my next article.
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here is the GitHub Repository. Please feel free to take it for a spin. I have
    also included an example Python notebook in the repository that can help you get
    started quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that you will need to add your [GROQ credentials](https://console.groq.com/keys)
    in the ***.env*** file before you can get started.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://github.com/rahulnyk/graph_maker?source=post_page-----f3f890c0dbe8--------------------------------)
    [## GitHub - rahulnyk/graph_maker'
  prefs: []
  type: TYPE_NORMAL
- en: Contribute to rahulnyk/graph_maker development by creating an account on GitHub.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/rahulnyk/graph_maker?source=post_page-----f3f890c0dbe8--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Initially, I developed this codebase for a few of my pet projects. I feel it
    can be helpful for many more applications. If you use this library for your applications,
    please share it with me. I would love to learn about your use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Also if you feel you can contribute to this open source project, please do so
    and make it your own.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you find the graph maker useful. Thanks for reading.
  prefs: []
  type: TYPE_NORMAL
- en: I am a learner of architecture (not the buildings… the tech kind). In the past,
    I have worked with Semiconductor modelling, Digital circuit design, Electronic
    Interface modelling, and the Internet of Things.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, Data and Consumer Analytics @Walmart Keeps me busy.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks
  prefs: []
  type: TYPE_NORMAL
