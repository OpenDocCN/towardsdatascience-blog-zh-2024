["```py\nimport os\nfrom googleapiclient.discovery import build\nfrom oauth2client.service_account import ServiceAccountCredentials\n\nclass GoogleDriveService:\n\n    SCOPES = [\"https://www.googleapis.com/auth/drive\"]\n\n    def __init__(self):\n        # the directory where your credentials are stored\n        base_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\n\n        # The name of the file containing your credentials\n        credential_path = os.path.join(base_path, \"gdrive_credential.json\")\n        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credential_path\n\n    def build(self):\n\n        # Get credentials into the desired format\n        creds = ServiceAccountCredentials.from_json_keyfile_name(\n            os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"), self.SCOPES\n        )  \n\n        # Set up the Gdrive service object\n        service = build(\"drive\", \"v3\", credentials=creds, cache_discovery=False)\n\n        return service\n```", "```py\nimport io\nfrom googleapiclient.errors import HttpError\nfrom googleapiclient.http import MediaIoBaseDownload\nimport googleapiclient.discovery\nfrom typing import List\n\nclass GoogleDriveLoader:\n\n    # These are the types of files we want to download\n    VALID_EXTENSIONS = [\".pdf\", \".jpeg\"]\n\n    def __init__(self, service: googleapiclient.discovery.Resource):\n\n        self.service = service\n\n    def search_for_files(self) -> List:\n        \"\"\"\n        See https://developers.google.com/drive/api/guides/search-files#python\n        \"\"\"\n\n        # This query searches for objects that are not folders and \n        # contain the valid extensions\n        query = \"mimeType != 'application/vnd.google-apps.folder' and (\"\n        for i, ext in enumerate(self.VALID_EXTENSIONS):\n            if i == 0:\n                query += \"name contains '{}' \".format(ext)\n            else:\n                query += \"or name contains '{}' \".format(ext)\n        query = query.rstrip()\n        query += \")\"\n\n        # create drive api client\n        files = []\n        page_token = None\n        try:\n            while True:\n                response = (\n                    self.service.files()\n                    .list(\n                        q=query,\n                        spaces=\"drive\",\n                        fields=\"nextPageToken, files(id, name)\",\n                        pageToken=page_token,\n                    )\n                    .execute()\n                )\n                for file in response.get(\"files\"):\n                    # Process change\n                    print(f'Found file: {file.get(\"name\")}, {file.get(\"id\")}')\n\n                    file_id = file.get(\"id\")\n                    file_name = file.get(\"name\")\n\n                    files.append(\n                        {\n                            \"id\": file_id,\n                            \"name\": file_name,\n                        }\n                    )\n\n                page_token = response.get(\"nextPageToken\", None)\n                if page_token is None:\n                    break\n\n        except HttpError as error:\n            print(f\"An error occurred: {error}\")\n            files = None\n\n        return files\n\n    def download_file(self, real_file_id: str) -> bytes:\n        \"\"\"\n        Downloads a single file\n        \"\"\"\n\n        try:\n            file_id = real_file_id\n            request = self.service.files().get_media(fileId=file_id)\n            file = io.BytesIO()\n            downloader = MediaIoBaseDownload(file, request)\n            done = False\n            while done is False:\n                status, done = downloader.next_chunk()\n                print(f\"Download {int(status.progress() * 100)}.\")\n\n        except HttpError as error:\n            print(f\"An error occurred: {error}\")\n            file = None\n\n        return file.getvalue()\n```", "```py\nservice = GoogleDriveService().build()\nloader = GoogleDriveLoader(service)\nall_files loader.search_for_files() #returns a list of unqiue file ids and names \npdf_bytes = loader.download_file({some_id}) #returns bytes for that file\n```", "```py\nfrom abc import ABC, abstractmethod\nfrom pdf2image import convert_from_bytes\nimport numpy as np\nfrom PyPDF2 import PdfReader\nfrom PIL import Image\nimport pytesseract\nimport io\n\nDEFAULT_DPI = 50\n\nclass FileBytesToImage(ABC):\n\n    @staticmethod\n    @abstractmethod\n    def convert_bytes_to_jpeg(file_bytes):\n        raise NotImplementedError\n\n    @staticmethod\n    @abstractmethod\n    def convert_bytes_to_text(file_bytes):\n        raise NotImplementedError\n\nclass PDFBytesToImage(FileBytesToImage):\n\n    @staticmethod\n    def convert_bytes_to_jpeg(file_bytes, dpi=DEFAULT_DPI, return_array=False):\n        jpeg_data = convert_from_bytes(file_bytes, fmt=\"jpeg\", dpi=dpi)[0]\n        if return_array:\n            jpeg_data = np.asarray(jpeg_data)\n        return jpeg_data\n\n    @staticmethod\n    def convert_bytes_to_text(file_bytes):\n        pdf_data = PdfReader(\n            stream=io.BytesIO(initial_bytes=file_bytes) \n        )\n        # receipt data should only have one page\n        page = pdf_data.pages[0]\n        return page.extract_text()\n\nclass JpegBytesToImage(FileBytesToImage):\n\n    @staticmethod\n    def convert_bytes_to_jpeg(file_bytes, dpi=DEFAULT_DPI, return_array=False):\n        jpeg_data = Image.open(io.BytesIO(file_bytes))\n        if return_array:\n            jpeg_data = np.array(jpeg_data)\n        return jpeg_data\n\n    @staticmethod\n    def convert_bytes_to_text(file_bytes):\n        jpeg_data = Image.open(io.BytesIO(file_bytes))\n        text_data = pytesseract.image_to_string(image=jpeg_data, nice=1)\n        return text_data\n```", "```py\nbytes_to_image = PDFBytesToImage()\nimage = PDFBytesToImage.convert_bytes_to_jpeg(pdf_bytes)\ntext = PDFBytesToImage.convert_bytes_to_jpeg(pdf_bytes)\n```", "```py\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom typing import List\n\nclass ReceiptItem(BaseModel):\n    \"\"\"Information about a single item on a reciept\"\"\"\n\n    item_name: str = Field(\"The name of the purchased item\")\n    item_cost: str = Field(\"The cost of the item\")\n\nclass ReceiptInformation(BaseModel):\n    \"\"\"Information extracted from a receipt\"\"\"\n\n    vendor_name: str = Field(\n        description=\"The name of the company who issued the reciept\"\n    )\n    vendor_address: str = Field(\n        description=\"The street address of the company who issued the reciept\"\n    )\n    datetime: str = Field(\n        description=\"The date and time that the receipt was printed in MM/DD/YY HH:MM format\"\n    )\n    items_purchased: List[ReceiptItem] = Field(description=\"List of purchased items\")\n    subtotal: str = Field(description=\"The total cost before tax was applied\")\n    tax_rate: str = Field(description=\"The tax rate applied\")\n    total_after_tax: str = Field(description=\"The total cost after tax\")\n```", "```py\nfrom dataclasses import dataclass\n\n@dataclass\nclass VisionReceiptExtractionPrompt:\n    template: str = \"\"\"\n       You are an expert at information extraction from images of receipts.\n\n       Given this of a receipt, extract the following information:\n       - The name and address of the vendor\n       - The names and costs of each of the items that were purchased\n       - The date and time that the receipt was issued. This must be formatted like 'MM/DD/YY HH:MM'\n       - The subtotal (i.e. the total cost before tax)\n       - The tax rate\n       - The total cost after tax\n\n       Do not guess. If some information is missing just return \"N/A\" in the relevant field.\n       If you determine that the image is not of a receipt, just set all the fields in the formatting instructions to \"N/A\". \n\n       You must obey the output format under all circumstances. Please follow the formatting instructions exactly.\n       Do not return any additional comments or explanation. \n       \"\"\"\n```", "```py\nfrom langchain.chains import TransformChain\nfrom langchain_core.messages import HumanMessage\nfrom langchain_core.runnables import chain\nfrom langchain_core.output_parsers import JsonOutputParser\nimport base64\nfrom langchain.callbacks import get_openai_callback\n\nclass VisionReceiptExtractionChain:\n\n    def __init__(self, llm):\n        self.llm = llm\n        self.chain = self.set_up_chain()\n\n    @staticmethod\n    def load_image(path: dict) -> dict:\n        \"\"\"Load image and encode it as base64.\"\"\"\n\n        def encode_image(path):\n            with open(path, \"rb\") as image_file:\n                return base64.b64encode(image_file.read()).decode(\"utf-8\")\n\n        image_base64 = encode_image(path[\"image_path\"])\n        return {\"image\": image_base64}\n\n    def set_up_chain(self):\n        extraction_model = self.llm\n        prompt = VisionReceiptExtractionPrompt()\n        parser = JsonOutputParser(pydantic_object=ReceiptInformation)\n\n        load_image_chain = TransformChain(\n            input_variables=[\"image_path\"],\n            output_variables=[\"image\"],\n            transform=self.load_image,\n        )\n\n        # build custom chain that includes an image\n        @chain\n        def receipt_model_chain(inputs: dict) -> dict:\n            \"\"\"Invoke model\"\"\"\n            msg = extraction_model.invoke(\n                [\n                    HumanMessage(\n                        content=[\n                            {\"type\": \"text\", \"text\": prompt.template},\n                            {\"type\": \"text\", \"text\": parser.get_format_instructions()},\n                            {\n                                \"type\": \"image_url\",\n                                \"image_url\": {\n                                    \"url\": f\"data:image/jpeg;base64,{inputs['image']}\"\n                                },\n                            },\n                        ]\n                    )\n                ]\n            )\n            return msg.content\n\n        return load_image_chain | receipt_model_chain | JsonOutputParser()\n\n    def run_and_count_tokens(self, input_dict: dict):\n        with get_openai_callback() as cb:\n            result = self.chain.invoke(input_dict)\n\n        return result, cb\n```", "```py\nfrom langchain_openai import ChatOpenAI\nfrom tempfile import NamedTemporaryFile\n\nmodel = ChatOpenAI(\n  api_key={your open_ai api key},\n  temperature=0, model=\"gpt-4-vision-preview\", \n  max_tokens=1024\n)\n\nextractor = VisionReceiptExtractionChain(model)\n\n# image from PDFBytesToImage.convert_bytes_to_jpeg()\nprepared_data = {\n    \"image\": image\n}\n\nwith NamedTemporaryFile(suffix=\".jpeg\") as temp_file:\n    prepared_data[\"image\"].save(temp_file.name)\n    res, cb = extractor.run_and_count_tokens(\n        {\"image_path\": temp_file.name}\n    )\n```", "```py\n{'vendor_name': 'N/A',\n 'vendor_address': 'N/A',\n 'datetime': 'N/A',\n 'items_purchased': [],\n 'subtotal': 'N/A',\n 'tax_rate': 'N/A',\n 'total_after_tax': 'N/A'}\n```", "```py\nTokens Used: 1170\nPrompt Tokens: 1104\nCompletion Tokens: 66\nSuccessful Requests: 1\nTotal Cost (USD): $0.01302\n```", "```py\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n\n@dataclass\nclass TextReceiptExtractionPrompt:\n    system: str = \"\"\"\n       You are an expert at information extraction from images of receipts.\n\n       Given this of a receipt, extract the following information:\n       - The name and address of the vendor\n       - The names and costs of each of the items that were purchased\n       - The date and time that the receipt was issued. This must be formatted like 'MM/DD/YY HH:MM'\n       - The subtotal (i.e. the total cost before tax)\n       - The tax rate\n       - The total cost after tax\n\n       Do not guess. If some information is missing just return \"N/A\" in the relevant field.\n       If you determine that the image is not of a receipt, just set all the fields in the formatting instructions to \"N/A\". \n\n       You must obey the output format under all circumstances. Please follow the formatting instructions exactly.\n       Do not return any additional comments or explanation.\n       \"\"\"\n\n    prompt: ChatPromptTemplate = ChatPromptTemplate.from_messages(\n        [\n            (\n                \"system\",\n                system,\n            ),\n            MessagesPlaceholder(\"examples\"),\n            (\"human\", \"{input}\"),\n        ]\n    )\n```", "```py\nclass Example(TypedDict):\n    \"\"\"A representation of an example consisting of text input and expected tool calls.\n\n    For extraction, the tool calls are represented as instances of pydantic model.\n    \"\"\"\n\n    input: str\n    tool_calls: List[BaseModel]\n\nclass TextReceiptExtractionChain:\n\n    def __init__(self, llm, examples: List):\n\n        self.llm = llm\n        self.raw_examples = examples\n        self.prompt = TextReceiptExtractionPrompt()\n        self.chain, self.examples = self.set_up_chain()\n\n    @staticmethod\n    def tool_example_to_messages(example: Example) -> List[BaseMessage]:\n        \"\"\"Convert an example into a list of messages that can be fed into an LLM.\n\n        This code is an adapter that converts our example to a list of messages\n        that can be fed into a chat model.\n\n        The list of messages per example corresponds to:\n\n        1) HumanMessage: contains the content from which content should be extracted.\n        2) AIMessage: contains the extracted information from the model\n        3) ToolMessage: contains confirmation to the model that the model requested a tool correctly.\n\n        The ToolMessage is required because some of the chat models are hyper-optimized for agents\n        rather than for an extraction use case.\n        \"\"\"\n        messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n        openai_tool_calls = []\n        for tool_call in example[\"tool_calls\"]:\n            openai_tool_calls.append(\n                {\n                    \"id\": str(uuid.uuid4()),\n                    \"type\": \"function\",\n                    \"function\": {\n                        # The name of the function right now corresponds\n                        # to the name of the pydantic model\n                        # This is implicit in the API right now,\n                        # and will be improved over time.\n                        \"name\": tool_call.__class__.__name__,\n                        \"arguments\": tool_call.json(),\n                    },\n                }\n            )\n        messages.append(\n            AIMessage(content=\"\", additional_kwargs={\"tool_calls\": openai_tool_calls})\n        )\n        tool_outputs = example.get(\"tool_outputs\") or [\n            \"You have correctly called this tool.\"\n        ] * len(openai_tool_calls)\n        for output, tool_call in zip(tool_outputs, openai_tool_calls):\n            messages.append(ToolMessage(content=output, tool_call_id=tool_call[\"id\"]))\n        return messages\n\n    def set_up_examples(self):\n\n        examples = [\n            (\n                example[\"input\"],\n                ReceiptInformation(\n                    vendor_name=example[\"output\"][\"vendor_name\"],\n                    vendor_address=example[\"output\"][\"vendor_address\"],\n                    datetime=example[\"output\"][\"datetime\"],\n                    items_purchased=[\n                        ReceiptItem(\n                            item_name=example[\"output\"][\"items_purchased\"][i][\n                                \"item_name\"\n                            ],\n                            item_cost=example[\"output\"][\"items_purchased\"][i][\n                                \"item_cost\"\n                            ],\n                        )\n                        for i in range(len(example[\"output\"][\"items_purchased\"]))\n                    ],\n                    subtotal=example[\"output\"][\"subtotal\"],\n                    tax_rate=example[\"output\"][\"tax_rate\"],\n                    total_after_tax=example[\"output\"][\"total_after_tax\"],\n                ),\n            )\n            for example in self.raw_examples\n        ]\n\n        messages = []\n\n        for text, tool_call in examples:\n            messages.extend(\n                self.tool_example_to_messages(\n                    {\"input\": text, \"tool_calls\": [tool_call]}\n                )\n            )\n\n        return messages\n\n    def set_up_chain(self):\n\n        extraction_model = self.llm\n        prompt = self.prompt.prompt\n        examples = self.set_up_examples()\n        runnable = prompt | extraction_model.with_structured_output(\n            schema=ReceiptInformation,\n            method=\"function_calling\",\n            include_raw=False,\n        )\n\n        return runnable, examples\n\n    def run_and_count_tokens(self, input_dict: dict):\n\n        # inject the examples here\n        input_dict[\"examples\"] = self.examples\n        with get_openai_callback() as cb:\n            result = self.chain.invoke(input_dict)\n\n        return result, cb\n```", "```py\n# Load the examples \nEXAMPLES_PATH = \"receiptchat/datasets/example_extractions.json\"\nwith open(EXAMPLES_PATH) as f:\n    loaded_examples = json.load(f)\n\nloaded_examples = [\n    {\"input\": x[\"file_details\"][\"extracted_text\"], \"output\": x}\n    for x in loaded_examples\n]\n\n# Set up the LLM caller\nllm = ChatOpenAI(\n  api_key=secrets[\"OPENAI_API_KEY\"], \n  temperature=0, \n  model=\"gpt-3.5-turbo\"\n)\nextractor = TextReceiptExtractionChain(llm, loaded_examples)\n\n# convert a PDF file form Google Drive into text\ntext = PDFBytesToImage.convert_bytes_to_text(downloaded_data)\n\nextracted_information, cb = extractor.run_and_count_tokens(\n            {\"input\": text}\n)\n```"]