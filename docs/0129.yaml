- en: 'LLMs for Everyone: Running the HuggingFace Text Generation Inference in Google
    Colab'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs 为每个人：在 Google Colab 上运行 HuggingFace 文本生成推理
- en: 原文：[https://towardsdatascience.com/llms-for-everyone-running-the-huggingface-text-generation-inference-in-google-colab-5adb3218a137?source=collection_archive---------3-----------------------#2024-01-13](https://towardsdatascience.com/llms-for-everyone-running-the-huggingface-text-generation-inference-in-google-colab-5adb3218a137?source=collection_archive---------3-----------------------#2024-01-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/llms-for-everyone-running-the-huggingface-text-generation-inference-in-google-colab-5adb3218a137?source=collection_archive---------3-----------------------#2024-01-13](https://towardsdatascience.com/llms-for-everyone-running-the-huggingface-text-generation-inference-in-google-colab-5adb3218a137?source=collection_archive---------3-----------------------#2024-01-13)
- en: Experimenting with Large Language Models for free (Part 3)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 免费试验大语言模型（第三部分）
- en: '[](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)
    ·7 min read·Jan 13, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)
    ·阅读时长 7 分钟·2024年1月13日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c7f6ab5d005b7e9089c8aa882f7f43e4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7f6ab5d005b7e9089c8aa882f7f43e4.png)'
- en: Image by Markus Spiske, [Unsplash](https://unsplash.com/@markusspiske)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Markus Spiske，[Unsplash](https://unsplash.com/@markusspiske)
- en: In the [first part](/llms-for-everyone-running-langchain-and-a-mistralai-7b-model-in-google-colab-246ca94d7c4d)
    of the story, we used a free Google Colab instance to run a Mistral-7B model and
    extract information using the FAISS (Facebook AI Similarity Search) database.
    In the [second part](/llms-for-everyone-running-the-llama-13b-model-and-langchain-in-google-colab-68d88021cf0b)
    of the story, we used a LLaMA-13B model and a LangChain library to make a chat
    with text summarization and other features. In this part, I will show how to use
    a HuggingFace 🤗 [Text Generation Inference](https://huggingface.co/docs/text-generation-inference/index)
    (TGI). TGI is a toolkit that allows us to run a large language model (LLM) as
    a service. As in the previous parts, we will test it in the Google Colab instance,
    completely for free.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一部分](/llms-for-everyone-running-langchain-and-a-mistralai-7b-model-in-google-colab-246ca94d7c4d)中，我们使用免费的
    Google Colab 实例运行了 Mistral-7B 模型，并通过 FAISS（Facebook AI 相似度搜索）数据库提取信息。在[第二部分](/llms-for-everyone-running-the-llama-13b-model-and-langchain-in-google-colab-68d88021cf0b)中，我们使用了
    LLaMA-13B 模型和 LangChain 库进行聊天，并实现了文本摘要及其他功能。在本部分中，我将展示如何使用 HuggingFace 🤗 [文本生成推理](https://huggingface.co/docs/text-generation-inference/index)（TGI）。TGI
    是一个工具包，允许我们将大语言模型（LLM）作为服务运行。与之前的部分一样，我们将在 Google Colab 实例中测试它，完全免费。
- en: Text Generation Inference
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本生成推理
- en: 'Text Generation Inference (TGI) is a production-ready toolkit for deploying
    and serving large language models (LLMs). Running LLM as a service allows us to
    use it with different clients, from Python notebooks to mobile apps. It is interesting
    to test the TGI’s functionality, but it turned out that its system requirements
    are pretty high, and not everything works as smoothly as expected:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成推理（TGI）是一个适用于大语言模型（LLMs）的生产级工具包，用于部署和提供服务。将 LLM 作为服务运行，允许我们在不同的客户端之间使用它，从
    Python 笔记本到移动应用程序。测试 TGI 的功能非常有趣，但事实证明，它的系统要求相当高，并且并非一切都如预期般顺利：
- en: A free Google Colab instance provides only 12.7 GB of RAM, which is often not
    enough to load a 13B or even 7B model “in one piece.”…
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 免费的 Google Colab 实例仅提供 12.7 GB 的 RAM，这通常不足以一次性加载 13B 甚至 7B 模型……
