- en: 'LLMs for Everyone: Running the HuggingFace Text Generation Inference in Google
    Colab'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs ä¸ºæ¯ä¸ªäººï¼šåœ¨ Google Colab ä¸Šè¿è¡Œ HuggingFace æ–‡æœ¬ç”Ÿæˆæ¨ç†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/llms-for-everyone-running-the-huggingface-text-generation-inference-in-google-colab-5adb3218a137?source=collection_archive---------3-----------------------#2024-01-13](https://towardsdatascience.com/llms-for-everyone-running-the-huggingface-text-generation-inference-in-google-colab-5adb3218a137?source=collection_archive---------3-----------------------#2024-01-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/llms-for-everyone-running-the-huggingface-text-generation-inference-in-google-colab-5adb3218a137?source=collection_archive---------3-----------------------#2024-01-13](https://towardsdatascience.com/llms-for-everyone-running-the-huggingface-text-generation-inference-in-google-colab-5adb3218a137?source=collection_archive---------3-----------------------#2024-01-13)
- en: Experimenting with Large Language Models for free (Part 3)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…è´¹è¯•éªŒå¤§è¯­è¨€æ¨¡å‹ï¼ˆç¬¬ä¸‰éƒ¨åˆ†ï¼‰
- en: '[](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--5adb3218a137--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)
    Â·7 min readÂ·Jan 13, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5adb3218a137--------------------------------)
    Â·é˜…è¯»æ—¶é•¿ 7 åˆ†é’ŸÂ·2024å¹´1æœˆ13æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c7f6ab5d005b7e9089c8aa882f7f43e4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7f6ab5d005b7e9089c8aa882f7f43e4.png)'
- en: Image by Markus Spiske, [Unsplash](https://unsplash.com/@markusspiske)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼šMarkus Spiskeï¼Œ[Unsplash](https://unsplash.com/@markusspiske)
- en: In the [first part](/llms-for-everyone-running-langchain-and-a-mistralai-7b-model-in-google-colab-246ca94d7c4d)
    of the story, we used a free Google Colab instance to run a Mistral-7B model and
    extract information using the FAISS (Facebook AI Similarity Search) database.
    In the [second part](/llms-for-everyone-running-the-llama-13b-model-and-langchain-in-google-colab-68d88021cf0b)
    of the story, we used a LLaMA-13B model and a LangChain library to make a chat
    with text summarization and other features. In this part, I will show how to use
    a HuggingFace ğŸ¤— [Text Generation Inference](https://huggingface.co/docs/text-generation-inference/index)
    (TGI). TGI is a toolkit that allows us to run a large language model (LLM) as
    a service. As in the previous parts, we will test it in the Google Colab instance,
    completely for free.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[ç¬¬ä¸€éƒ¨åˆ†](/llms-for-everyone-running-langchain-and-a-mistralai-7b-model-in-google-colab-246ca94d7c4d)ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å…è´¹çš„
    Google Colab å®ä¾‹è¿è¡Œäº† Mistral-7B æ¨¡å‹ï¼Œå¹¶é€šè¿‡ FAISSï¼ˆFacebook AI ç›¸ä¼¼åº¦æœç´¢ï¼‰æ•°æ®åº“æå–ä¿¡æ¯ã€‚åœ¨[ç¬¬äºŒéƒ¨åˆ†](/llms-for-everyone-running-the-llama-13b-model-and-langchain-in-google-colab-68d88021cf0b)ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†
    LLaMA-13B æ¨¡å‹å’Œ LangChain åº“è¿›è¡ŒèŠå¤©ï¼Œå¹¶å®ç°äº†æ–‡æœ¬æ‘˜è¦åŠå…¶ä»–åŠŸèƒ½ã€‚åœ¨æœ¬éƒ¨åˆ†ä¸­ï¼Œæˆ‘å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ HuggingFace ğŸ¤— [æ–‡æœ¬ç”Ÿæˆæ¨ç†](https://huggingface.co/docs/text-generation-inference/index)ï¼ˆTGIï¼‰ã€‚TGI
    æ˜¯ä¸€ä¸ªå·¥å…·åŒ…ï¼Œå…è®¸æˆ‘ä»¬å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºæœåŠ¡è¿è¡Œã€‚ä¸ä¹‹å‰çš„éƒ¨åˆ†ä¸€æ ·ï¼Œæˆ‘ä»¬å°†åœ¨ Google Colab å®ä¾‹ä¸­æµ‹è¯•å®ƒï¼Œå®Œå…¨å…è´¹ã€‚
- en: Text Generation Inference
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ–‡æœ¬ç”Ÿæˆæ¨ç†
- en: 'Text Generation Inference (TGI) is a production-ready toolkit for deploying
    and serving large language models (LLMs). Running LLM as a service allows us to
    use it with different clients, from Python notebooks to mobile apps. It is interesting
    to test the TGIâ€™s functionality, but it turned out that its system requirements
    are pretty high, and not everything works as smoothly as expected:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬ç”Ÿæˆæ¨ç†ï¼ˆTGIï¼‰æ˜¯ä¸€ä¸ªé€‚ç”¨äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç”Ÿäº§çº§å·¥å…·åŒ…ï¼Œç”¨äºéƒ¨ç½²å’Œæä¾›æœåŠ¡ã€‚å°† LLM ä½œä¸ºæœåŠ¡è¿è¡Œï¼Œå…è®¸æˆ‘ä»¬åœ¨ä¸åŒçš„å®¢æˆ·ç«¯ä¹‹é—´ä½¿ç”¨å®ƒï¼Œä»
    Python ç¬”è®°æœ¬åˆ°ç§»åŠ¨åº”ç”¨ç¨‹åºã€‚æµ‹è¯• TGI çš„åŠŸèƒ½éå¸¸æœ‰è¶£ï¼Œä½†äº‹å®è¯æ˜ï¼Œå®ƒçš„ç³»ç»Ÿè¦æ±‚ç›¸å½“é«˜ï¼Œå¹¶ä¸”å¹¶éä¸€åˆ‡éƒ½å¦‚é¢„æœŸèˆ¬é¡ºåˆ©ï¼š
- en: A free Google Colab instance provides only 12.7 GB of RAM, which is often not
    enough to load a 13B or even 7B model â€œin one piece.â€â€¦
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…è´¹çš„ Google Colab å®ä¾‹ä»…æä¾› 12.7 GB çš„ RAMï¼Œè¿™é€šå¸¸ä¸è¶³ä»¥ä¸€æ¬¡æ€§åŠ è½½ 13B ç”šè‡³ 7B æ¨¡å‹â€¦â€¦
