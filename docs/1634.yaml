- en: How Much Energy Do LLMs Consume?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-much-energy-do-llms-consume-23c09fe3f545?source=collection_archive---------4-----------------------#2024-07-02](https://towardsdatascience.com/how-much-energy-do-llms-consume-23c09fe3f545?source=collection_archive---------4-----------------------#2024-07-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We use EnergyMeter, a Python tool, to measure the energy consumption of different
    LLMs including Llama, Dolly, and BLOOM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mauriciofadelargerich?source=post_page---byline--23c09fe3f545--------------------------------)[![Mauricio
    Fadel Argerich](../Images/0e84f1a168a436821894c0e13b4e0c53.png)](https://medium.com/@mauriciofadelargerich?source=post_page---byline--23c09fe3f545--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--23c09fe3f545--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--23c09fe3f545--------------------------------)
    [Mauricio Fadel Argerich](https://medium.com/@mauriciofadelargerich?source=post_page---byline--23c09fe3f545--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--23c09fe3f545--------------------------------)
    ·12 min read·Jul 2, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5630ac576e53b591e0392028054cfb64.png)'
  prefs: []
  type: TYPE_IMG
- en: Replying to all those questions requires a lot of energy! [made with AI by [Designer](https://www.bing.com/images/create?form=SBCATT).]
  prefs: []
  type: TYPE_NORMAL
- en: 'Large Language Models (LLMs) are becoming the new mainstream for several tasks
    we perform everyday: searching answers to our everyday questions, summarizing
    texts, creating slides or creating images for this article; LLMs are powerful
    tools and its safe to say their use will increase in the years to come. Their
    amazing power was achieved in part thanks to the (really) large number of trainable
    parameters they have; just as an example, the model behind ChatGPT (GPT-3) has
    more than 175 billion parameters. Training such large models requires incredibly
    powerful computing resources (in particular GPUs), which is translated into really
    high costs for buying or even renting the resources and, in turn, this is translated
    into a high energy demand, needed to power those resources. For instance, it is
    estimated that training GPT-3 required 1287 MWh, equivalent to the mean yearly
    energy consumption of 420 persons [1].'
  prefs: []
  type: TYPE_NORMAL
- en: But even more energy is used to keep these LLMs running, for their inference.
    In fact, OpenAI announced that 100 million people are using ChatGPT weekly [2],
    so even if we assume each user only asks four question per week, this means that
    ChatGPT has at least…
  prefs: []
  type: TYPE_NORMAL
