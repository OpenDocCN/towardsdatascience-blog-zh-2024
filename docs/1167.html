<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Time Series Forecasting: A Practical Guide to Exploratory Data Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Time Series Forecasting: A Practical Guide to Exploratory Data Analysis</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/time-series-forecasting-a-practical-guide-to-exploratory-data-analysis-a101dc5f85b1?source=collection_archive---------0-----------------------#2024-05-09">https://towardsdatascience.com/time-series-forecasting-a-practical-guide-to-exploratory-data-analysis-a101dc5f85b1?source=collection_archive---------0-----------------------#2024-05-09</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="3262" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How to use Exploratory Data Analysis to drive information from time series data and enhance feature engineering using Python</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@maicolnicolini96?source=post_page---byline--a101dc5f85b1--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Maicol Nicolini" class="l ep by dd de cx" src="../Images/97e78725ba70c95e340b76527c358498.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*A9FrUqxMdKqwC62PYr9fyQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--a101dc5f85b1--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@maicolnicolini96?source=post_page---byline--a101dc5f85b1--------------------------------" rel="noopener follow">Maicol Nicolini</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--a101dc5f85b1--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">15 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 9, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">6</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/32bbea6cf3c9513a36265783549ae925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_4XJDFxzoPez8m4i"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@aleskrivec?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ales Krivec</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="9c14" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Introduction</h1><p id="84c6" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Time series analysis certainly represents one of the most widespread topics in the field of data science and machine learning: whether predicting financial events, energy consumption, product sales or stock market trends, this field has always been of great interest to businesses.</p><p id="37d0" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Obviously, the great increase in data availability, combined with the constant progress in machine learning models, has made this topic even more interesting today. Alongside traditional forecasting methods derived from statistics (e.g. regressive models, ARIMA models, exponential smoothing), techniques relating to machine learning (e.g. tree-based models) and deep learning (e.g. LSTM Networks, CNNs, Transformer-based Models) have emerged for some time now.</p><p id="c810" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Despite the huge differences between these techniques, there is a preliminary step that must be done, no matter what the model is: <em class="pa">Exploratory Data Analysis.</em></p><p id="1fc6" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In statistics, <strong class="ob fr">Exploratory Data Analysis</strong> (EDA) is a discipline consisting in analyzing and visualizing data in order to summarize their main characteristics and gain relevant information from them. This is of considerable importance in the data science field because it allows to lay the foundations to another important step: <em class="pa">feature engineering</em>. That is, the practice that consists on creating, transforming and extracting features from the dataset so that the model can work to the best of its possibilities.</p><p id="4ab7" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The objective of this article is therefore to define a clear exploratory data analysis template, focused on time series, which can summarize and highlight the most important characteristics of the dataset. To do this, we will use some common Python libraries such as <em class="pa">Pandas</em>, <em class="pa">Seaborn </em>and S<em class="pa">tatsmodel</em>.</p><h1 id="415f" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Data</h1><p id="ac81" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s first define the dataset: for the purposes of this article, we will take Kaggle’s <a class="af nc" href="https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption" rel="noopener ugc nofollow" target="_blank"><strong class="ob fr">Hourly Energy Consumption</strong></a><strong class="ob fr"> </strong>data. This dataset relates to PJM Hourly Energy Consumption data, a regional transmission organization in the United States, that serves electricity to Delaware, Illinois, Indiana, Kentucky, Maryland, Michigan, New Jersey, North Carolina, Ohio, Pennsylvania, Tennessee, Virginia, West Virginia, and the District of Columbia.</p><p id="e1b3" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The hourly power consumption data comes from PJM’s website and are in megawatts (MW).</p><h1 id="8afd" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Exploratory Data Analysis</h1><p id="7622" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s now define which are the most significant analyses to be performed when dealing with time series.</p><p id="7193" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">For sure, one of the most important thing is to plot the data: graphs can highlight many features, such as patterns, unusual observations, changes over time, and relationships between variables. As already said, the insight that emerge from these plots must then be taken into consideration, as much as possible, into the forecasting model. Moreover, some mathematical tools such as descriptive statistics and time series decomposition, will also be very useful.</p><p id="3718" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Said that, the EDA I’m proposing in this article consists on six steps: Descriptive Statistics, Time Plot, Seasonal Plots, Box Plots, Time Series Decomposition, Lag Analysis.</p><h2 id="4141" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">1. Descriptive Statistics</h2><p id="779a" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Descriptive statistic is a summary statistic that quantitatively describes or summarizes features from a collection of structured data.</p><p id="737f" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Some metrics that are commonly used to describe a dataset are: measures of central tendency (e.g. <em class="pa">mean</em>, <em class="pa">median</em>), measures of dispersion (e.g. <em class="pa">range</em>, <em class="pa">standard deviation</em>), and measure of position (e.g. <em class="pa">percentiles</em>, <em class="pa">quartile</em>). All of them can be summarized by the so called <strong class="ob fr">five number summary</strong>, which include: minimum, first quartile (Q1), median or second quartile (Q2), third quartile (Q3) and maximum of a distribution.</p><p id="c5ab" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In Python, these information can be easily retrieved using the well know <code class="cx ps pt pu pv b">describe</code> method from Pandas:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="7aeb" class="pz ne fq pv b bg qa qb l qc qd">import pandas as pd<br/><br/># Loading and preprocessing steps<br/>df = pd.read_csv('../input/hourly-energy-consumption/PJME_hourly.csv')<br/>df = df.set_index('Datetime')<br/>df.index = pd.to_datetime(df.index)<br/><br/>df.describe()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qe"><img src="../Images/569c28931bca7ee75e4366dbbd6b91db.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/1*qjr-DpqKI4W2MZc1M3tRrQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">1. PJME statistic summary.</figcaption></figure><h2 id="ef6a" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">2. Time plot</h2><p id="ffb2" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">The obvious graph to start with is the time plot. That is, the observations are plotted against the time they were observed, with consecutive observations joined by lines.</p><p id="df6b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In Python , we can use Pandas and Matplotlib:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="451d" class="pz ne fq pv b bg qa qb l qc qd">import matplotlib.pyplot as plt<br/> <br/># Set pyplot style<br/>plt.style.use("seaborn")<br/><br/># Plot<br/>df['PJME_MW'].plot(title='PJME - Time Plot', figsize=(10,6))<br/>plt.ylabel('Consumption [MW]')<br/>plt.xlabel('Date')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qf"><img src="../Images/d9bd55add95ba151a92842566151524f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_vR7hFcqn7DrLWAeOiDEQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">2.1 PJME Consumption Time Plot.</figcaption></figure><p id="b313" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">This plot already provides several information:</p><ol class=""><li id="9db5" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qg qh qi bk">As we could expect, the pattern shows yearly seasonality.</li><li id="f2f3" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">Focusing on a single year, it seems that more pattern emerges. Likely, the consumptions will have a peak in winter and one another in summer, due to the greater electricity consumption.</li><li id="ddb5" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">The series does not exhibit a clear increasing/decreasing trend over the years, the average consumptions remains stationary.</li><li id="cbd0" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">There is an anomalous value around 2023, probably it should be imputed when implementing the model.</li></ol><h2 id="ca54" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">3. Seasonal Plots</h2><p id="c59d" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">A seasonal plot is fundamentally a time plot where data are plotted against the individual “seasons” of the series they belong.</p><p id="68de" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Regarding energy consumption, we usually have hourly data available, so there could be several seasonality: <em class="pa">yearly</em>, <em class="pa">weekly</em>, <em class="pa">daily</em>. Before going deep into these plots, let’s first set up some variables in our Pandas dataframe:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="e05c" class="pz ne fq pv b bg qa qb l qc qd"># Defining required fields<br/>df['year'] = [x for x in df.index.year]<br/>df['month'] = [x for x in df.index.month]<br/>df = df.reset_index()<br/>df['week'] = df['Datetime'].apply(lambda x:x.week)<br/>df = df.set_index('Datetime')<br/>df['hour'] = [x for x in df.index.hour]<br/>df['day'] = [x for x in df.index.day_of_week]<br/>df['day_str'] = [x.strftime('%a') for x in df.index]<br/>df['year_month'] = [str(x.year) + '_' + str(x.month) for x in df.index]</span></pre><h2 id="5980" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">3.1 Seasonal plot — Yearly consumption</h2><p id="6758" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">A very interesting plot is the one referring to the energy consumption grouped by year over months, this highlights yearly seasonality and can inform us about ascending/descending trends over the years.</p><p id="dccd" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Here is the Python code:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="9f4d" class="pz ne fq pv b bg qa qb l qc qd">import numpy as np<br/><br/># Defining colors palette<br/>np.random.seed(42)<br/>df_plot = df[['month', 'year', 'PJME_MW']].dropna().groupby(['month', 'year']).mean()[['PJME_MW']].reset_index()<br/>years = df_plot['year'].unique()<br/>colors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), len(years), replace=False)<br/><br/># Plot<br/>plt.figure(figsize=(16,12))<br/>for i, y in enumerate(years):<br/>    if i &gt; 0:        <br/>        plt.plot('month', 'PJME_MW', data=df_plot[df_plot['year'] == y], color=colors[i], label=y)<br/>        if y == 2018:<br/>            plt.text(df_plot.loc[df_plot.year==y, :].shape[0]+0.3, df_plot.loc[df_plot.year==y, 'PJME_MW'][-1:].values[0], y, fontsize=12, color=colors[i])<br/>        else:<br/>            plt.text(df_plot.loc[df_plot.year==y, :].shape[0]+0.1, df_plot.loc[df_plot.year==y, 'PJME_MW'][-1:].values[0], y, fontsize=12, color=colors[i])<br/><br/># Setting labels<br/>plt.gca().set(ylabel= 'PJME_MW', xlabel = 'Month')<br/>plt.yticks(fontsize=12, alpha=.7)<br/>plt.title("Seasonal Plot - Monthly Consumption", fontsize=20)<br/>plt.ylabel('Consumption [MW]')<br/>plt.xlabel('Month')<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qo"><img src="../Images/d81109dc87e66d8794e60ec39136e05a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vItcKtPe46aIS2Xnbu4lZg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">3.1 PJME Yearly Seasonal Plot</figcaption></figure><p id="ddb7" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">This plot shows every year has actually a very predefined pattern: the consumption increases significantly during winter and has a peak in summer (due to heating/cooling systems), while has a minima in spring and in autumn when no heating or cooling is usually required.</p><p id="3ac7" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Furthermore, this plot tells us that’s not a clear increasing/decreasing pattern in the overall consumptions across years.</p><h2 id="9ca7" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">3.2 Seasonal plot — Weekly consumption</h2><p id="ec38" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Another useful plot is the weekly plot, it depicts the consumptions during the week over months and can also suggest if and how weekly consumptions are changing over a single year.</p><p id="34ae" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Let’s see how to figure it out with Python:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="3eaa" class="pz ne fq pv b bg qa qb l qc qd"># Defining colors palette<br/>np.random.seed(42)<br/>df_plot = df[['month', 'day_str', 'PJME_MW', 'day']].dropna().groupby(['day_str', 'month', 'day']).mean()[['PJME_MW']].reset_index()<br/>df_plot = df_plot.sort_values(by='day', ascending=True)<br/><br/>months = df_plot['month'].unique()<br/>colors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), len(months), replace=False)<br/><br/># Plot<br/>plt.figure(figsize=(16,12))<br/>for i, y in enumerate(months):<br/>    if i &gt; 0:        <br/>        plt.plot('day_str', 'PJME_MW', data=df_plot[df_plot['month'] == y], color=colors[i], label=y)<br/>        if y == 2018:<br/>            plt.text(df_plot.loc[df_plot.month==y, :].shape[0]-.9, df_plot.loc[df_plot.month==y, 'PJME_MW'][-1:].values[0], y, fontsize=12, color=colors[i])<br/>        else:<br/>            plt.text(df_plot.loc[df_plot.month==y, :].shape[0]-.9, df_plot.loc[df_plot.month==y, 'PJME_MW'][-1:].values[0], y, fontsize=12, color=colors[i])<br/><br/><br/># Setting Labels<br/>plt.gca().set(ylabel= 'PJME_MW', xlabel = 'Month')<br/>plt.yticks(fontsize=12, alpha=.7)<br/>plt.title("Seasonal Plot - Weekly Consumption", fontsize=20)<br/>plt.ylabel('Consumption [MW]')<br/>plt.xlabel('Month')<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qo"><img src="../Images/072c928e8b54ab3ce70e7607a0e5f7f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ZenhM272ugjj-ErGDQk6A.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">3.2 PJME Weekly Seasonal Plot</figcaption></figure><h2 id="6a53" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">3.3 Seasonal plot — Daily consumption</h2><p id="3e3e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Finally, the last seasonal plot I want to show is the daily consumption plot. As you can guess, it represents how consumption change over the day. In this case, data are first grouped by day of week and then aggregated taking the mean.</p><p id="89e7" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Here’s the code:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="a7f0" class="pz ne fq pv b bg qa qb l qc qd">import seaborn as sns<br/><br/># Defining the dataframe<br/>df_plot = df[['hour', 'day_str', 'PJME_MW']].dropna().groupby(['hour', 'day_str']).mean()[['PJME_MW']].reset_index()<br/><br/># Plot using Seaborn<br/>plt.figure(figsize=(10,8))<br/>sns.lineplot(data = df_plot, x='hour', y='PJME_MW', hue='day_str', legend=True)<br/>plt.locator_params(axis='x', nbins=24)<br/>plt.title("Seasonal Plot - Daily Consumption", fontsize=20)<br/>plt.ylabel('Consumption [MW]')<br/>plt.xlabel('Hour')<br/>plt.legend()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qp"><img src="../Images/9e0cc04edfadccf0216f2b1c90e5e291.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5UkeyoUqkhzmjHa5z11zdQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">3.3 PJME Daily Seasonal Plot</figcaption></figure><p id="270f" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Often, this plot show a very typical pattern, someone calls it “M profile” since consumptions seems to depict an “M” during the day. Sometimes this pattern is clear, others not (like in this case).</p><p id="f4d6" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">However, this plots usually shows a relative peak in the middle of the day (from 10 am to 2 pm), then a relative minima (from 2 pm to 6 pm) and another peak (from 6 pm to 8 pm). Finally, it also shows the difference in consumptions from weekends and other days.</p><h2 id="5cc7" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">3.4 Seasonal plot — Feature Engineering</h2><p id="bdae" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s now see how to use this information for feature engineering. Let’s suppose we are using some ML model that requires good quality features (e.g. ARIMA models or tree-based models).</p><p id="aa67" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">These are the main evidences coming from seasonal plots:</p><ol class=""><li id="2e91" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qg qh qi bk">Yearly consumptions do not change a lot over years: this suggests the possibility to use, when available, yearly seasonality features coming from lag or exogenous variables.</li><li id="ab9b" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">Weekly consumptions follow the same pattern across months: this suggests to use weekly features coming from lag or exogenous variables.</li><li id="b8e1" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">Daily consumption differs from normal days and weekends: this suggest to use categorical features able to identify when a day is a normal day and when it is not.</li></ol><h2 id="d33d" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">4. Box Plots</h2><p id="73a1" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Boxplot are a useful way to identify how data are distributed. Briefly, boxplots depict percentiles, which represent 1st (Q1), 2nd (Q2/median) and 3rd (Q3) quartile of a distribution and whiskers, which represent the range of the data. Every value beyond the whiskers can be thought as an <em class="pa">outlier</em>, more in depth, whiskers are often computed as:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qq"><img src="../Images/06e5f1fe1b65dbcd7f018e268cf2ba24.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/0*QW0DTZgJ3HXiHMPD.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">4. Whiskers Formula</figcaption></figure><h2 id="8d2d" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">4.1 Box Plots — Total consumption</h2><p id="3957" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s first compute the box plot regarding the total consumption, this can be easily done with <em class="pa">Seaborn</em>:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="794e" class="pz ne fq pv b bg qa qb l qc qd">plt.figure(figsize=(8,5))<br/>sns.boxplot(data=df, x='PJME_MW')<br/>plt.xlabel('Consumption [MW]')<br/>plt.title(f'Boxplot - Consumption Distribution');</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qr"><img src="../Images/bcb675b3d2364e13ed03d36cc3cbc140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*jsZ3PKVpFNoIVBNrPF4Ikw.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">4.1 PJME Boxplot</figcaption></figure><p id="f16e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Even if this plot seems not to be much informative, it tells us we are dealing with a Gaussian-like distribution, with a tail more accentuated towards the right.</p><h2 id="8e46" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">4.2 Box Plots — Day month distribution</h2><p id="4cc7" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">A very interesting plot is the day/month box plot. It is obtained creating a “day month” variable and grouping consumptions by it. Here is the code, referring only from year 2017:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="d6a3" class="pz ne fq pv b bg qa qb l qc qd">df['year'] = [x for x in df.index.year]<br/>df['month'] = [x for x in df.index.month]<br/>df['year_month'] = [str(x.year) + '_' + str(x.month) for x in df.index]<br/><br/>df_plot = df[df['year'] &gt;= 2017].reset_index().sort_values(by='Datetime').set_index('Datetime')<br/>plt.title(f'Boxplot Year Month Distribution');<br/>plt.xticks(rotation=90)<br/>plt.xlabel('Year Month')<br/>plt.ylabel('MW')<br/><br/>sns.boxplot(x='year_month', y='PJME_MW', data=df_plot)<br/>plt.ylabel('Consumption [MW]')<br/>plt.xlabel('Year Month')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qs"><img src="../Images/6ebf1b885874f81ddd75c7a79a975425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AjdlfZTA5uqxm9vZyvIZMg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">4.2 PJME Year/Month Boxplot</figcaption></figure><p id="6c5e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">It can be seen that consumption are less uncertain in summer/winter months (i.e. when we have peaks) while are more dispersed in spring/autumn (i.e. when temperatures are more variable). Finally, consumption in summer 2018 are higher than 2017, maybe due to a warmer summer. When feature engineering, remember to include (if available) the temperature curve, probably it can be used as an exogenous variable.</p><h2 id="31fa" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">4.3 Box Plots — Day distribution</h2><p id="9b2f" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Another useful plot is the one referring consumption distribution over the week, this is similar to the weekly consumption seasonal plot.</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="92da" class="pz ne fq pv b bg qa qb l qc qd">df_plot = df[['day_str', 'day', 'PJME_MW']].sort_values(by='day')<br/>plt.title(f'Boxplot Day Distribution')<br/>plt.xlabel('Day of week')<br/>plt.ylabel('MW')<br/>sns.boxplot(x='day_str', y='PJME_MW', data=df_plot)<br/>plt.ylabel('Consumption [MW]')<br/>plt.xlabel('Day of week')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qs"><img src="../Images/ad9f40a6f45d4957e36315b08229a7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y56hSDyXyumNeyEnUIQ6Vw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">4.3 PJME Day Boxplot</figcaption></figure><p id="b395" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">As seen before, consumptions are noticeably lower on weekends. Anyway, there are several outliers pointing out that calendar features like “day of week” for sure are useful but could not fully explain the series.</p><h2 id="f9f0" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">4.4 Box Plots — Hour distribution</h2><p id="5164" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s finally see hour distribution box plot. It is similar to the daily consumption seasonal plot since it provides how consumptions are distributed over the day. Following, the code:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="0f37" class="pz ne fq pv b bg qa qb l qc qd">plt.title(f'Boxplot Hour Distribution');<br/>plt.xlabel('Hour')<br/>plt.ylabel('MW')<br/>sns.boxplot(x='hour', y='PJME_MW', data=df)<br/>plt.ylabel('Consumption [MW]')<br/>plt.xlabel('Hour')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qs"><img src="../Images/807ad6d26cec4a5520a05176ff392043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7_4j93v-Uo--z8dOPSWqPA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">4.4 PJME Hour Boxplot</figcaption></figure><p id="0446" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Note that the “M” shape seen before is now much more crushed. Furthermore there are a lot of outliers, this tells us data not only relies on daily seasonality (e.g. the consumption on today’s 12 am is similar to the consumption of yesterday 12 am) but also on something else, probably some exogenous climatic feature like temperature or humidity.</p><h2 id="52b7" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">5. Time Series Decomposition</h2><p id="9ea8" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">As already said, time series data can exhibit a variety of patterns. Often, it is helpful to split a time series into several components, each representing an underlying pattern category.</p><p id="1cf6" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We can think of a time series as comprising three components: a <em class="pa">trend</em> component, a <em class="pa">seasonal </em>component and a <em class="pa">remainder </em>component (containing anything else in the time series). For some time series (e.g., energy consumption series), there can be more than one seasonal component, corresponding to different seasonal periods (daily, weekly, monthly, yearly).</p><p id="6c6b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">There are two main type of decomposition: <em class="pa">additive</em> and <em class="pa">multiplicative</em>.</p><p id="2d88" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">For the additive decomposition, we represent a series (𝑦) as the sum of a seasonal component (𝑆), a trend (𝑇) and a remainder (𝑅):</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qt"><img src="../Images/e17ee10b8116c19d217f65fd55260dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/0*gDj55UE7Bemilxhl.png"/></div></figure><p id="c8aa" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Similarly, a multiplicative decomposition can be written as:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qt"><img src="../Images/e242c6a97fc1dad2ad2fc5598e1b1ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/0*rsepm97zulrZKWfX.png"/></div></figure><p id="8c65" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Generally speaking, additive decomposition best represent series with constant variance while multiplicative decomposition best suits time series with non-stationary variances.</p><p id="5426" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In Python, time series decomposition can be easily fulfilled with <em class="pa">Statsmodel </em>library:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="0117" class="pz ne fq pv b bg qa qb l qc qd">df_plot = df[df['year'] == 2017].reset_index()<br/>df_plot = df_plot.drop_duplicates(subset=['Datetime']).sort_values(by='Datetime')<br/>df_plot = df_plot.set_index('Datetime')<br/>df_plot['PJME_MW - Multiplicative Decompose'] = df_plot['PJME_MW']<br/>df_plot['PJME_MW - Additive Decompose'] = df_plot['PJME_MW']<br/><br/># Additive Decomposition<br/>result_add = seasonal_decompose(df_plot['PJME_MW - Additive Decompose'], model='additive', period=24*7)<br/><br/># Multiplicative Decomposition <br/>result_mul = seasonal_decompose(df_plot['PJME_MW - Multiplicative Decompose'], model='multiplicative', period=24*7)<br/><br/># Plot<br/>result_add.plot().suptitle('', fontsize=22)<br/>plt.xticks(rotation=45)<br/>result_mul.plot().suptitle('', fontsize=22)<br/>plt.xticks(rotation=45)<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qu"><img src="../Images/1e6aac354ac11d476f1aa4d7b27c75ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zxJdVfYW1_e50uMyxpIfyw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">5.1 PJME Series Decomposition — Additive Decompose.</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qu"><img src="../Images/ce50a9bfc23a07acefea8bb56927df5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q_MZakE2mHReJBupMTdLGA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">5.2 PJME Series Decomposition — Multiplicative Decompose.</figcaption></figure><p id="ba77" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The above plots refers to 2017. In both cases, we see the trend has several local peaks, with higher values in summer. From the seasonal component, we can see the series actually has several periodicities, this plot highlights more the weekly one, but if we focus on a particular month (January) of the same year, daily seasonality emerges too:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="552a" class="pz ne fq pv b bg qa qb l qc qd">df_plot = df[(df['year'] == 2017)].reset_index()<br/>df_plot = df_plot[df_plot['month'] == 1]<br/>df_plot['PJME_MW - Multiplicative Decompose'] = df_plot['PJME_MW']<br/>df_plot['PJME_MW - Additive Decompose'] = df_plot['PJME_MW']<br/><br/>df_plot = df_plot.drop_duplicates(subset=['Datetime']).sort_values(by='Datetime')<br/>df_plot = df_plot.set_index('Datetime')<br/><br/># Additive Decomposition<br/>result_add = seasonal_decompose(df_plot['PJME_MW - Additive Decompose'], model='additive', period=24*7)<br/><br/># Multiplicative Decomposition <br/>result_mul = seasonal_decompose(df_plot['PJME_MW - Multiplicative Decompose'], model='multiplicative', period=24*7)<br/><br/># Plot<br/>result_add.plot().suptitle('', fontsize=22)<br/>plt.xticks(rotation=45)<br/>result_mul.plot().suptitle('', fontsize=22)<br/>plt.xticks(rotation=45)<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qu"><img src="../Images/38852e4d20f443b471e67673aa590562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ma47XHTQF_mrUnxzkIQAAw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">5.3 PJME Series Decomposition — Additive Decompose, focus on January 2017.</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qu"><img src="../Images/c81aba4ff062cc4f588cb56dc5a7fe2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OKs3z7Gxy-8pVJp_JQjnFw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">5.4 PJME Series Decomposition — Multiplicative Decompose, focus on January 2017.</figcaption></figure><h2 id="5c12" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">6. Lag Analysis</h2><p id="e82a" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">In time series forecasting, a lag is simply a past value of the series. For example, for daily series, the first lag refers to the value the series had the previous day, the second to the value of the day before and so on.</p><p id="e0c8" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Lag analysis is based on computing correlations between the series and a lagged version of the series itself, this is also called <em class="pa">autocorrelation. </em>For a k-lagged version of a series, we define the autocorrelation coefficient as:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qv"><img src="../Images/012a2b1804fb4a04bed04ce8fa487838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*TB59DjyKh343lYl9X4rxeg.png"/></div></figure><p id="d428" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Where <em class="pa">y </em>bar represent the mean value of the series and <em class="pa">k</em> the lag.</p><p id="45ef" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The autocorrelation coefficients make up the <em class="pa">autocorrelation function </em>(ACF) for the series, this is simply a plot depicting the auto-correlation coefficient versus the number of lags taken into consideration.</p><p id="b7ef" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">When data has a trend, the autocorrelations for small lags are usually large and positive because observations close in time are also nearby in value. When data show seasonality, autocorrelation values will be larger in correspondence of seasonal lags (and multiples of the seasonal period) than for other lags. Data with both trend and seasonality will show a combination of these effects.</p><p id="3c51" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In practice, a more useful function is the <em class="pa">partial autocorrelation function</em> (PACF). It is similar to the ACF, except that it shows only the direct autocorrelation between two lags. For example, the partial autocorrelation for lag 3 refers to the only correlation lag 1 and 2 do not explain. In other words, the partial correlation refers to the direct effect a certain lag has on the current time value.</p><p id="969f" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Before moving to the Python code, it is important to highlight that autocorrelation coefficient emerges more clearly if the series is <em class="pa">stationary, </em>so often is better to first differentiate the series to stabilize the signal.</p><p id="015b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Said that, here is the code to plot PACF for different hours of the day:</p><pre class="mm mn mo mp mq pw pv px bp py bb bk"><span id="d3ee" class="pz ne fq pv b bg qa qb l qc qd">from statsmodels.graphics.tsaplots import plot_pacf<br/><br/>actual = df['PJME_MW']<br/>hours = range(0, 24, 4)<br/><br/>for hour in hours:<br/>    plot_pacf(actual[actual.index.hour == hour].diff().dropna(), lags=30, alpha=0.01)<br/>    plt.title(f'PACF - h = {hour}')<br/>    plt.ylabel('Correlation')<br/>    plt.xlabel('Lags')<br/>    plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/44dbff41f17b2e610d813960ecfb0c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QDA8IbzpFA3Prje2feEvWA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">6.1 PJME Lag Analysis — Partial Auto Correlation Function (h=0).</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/d7d2d2e6976b720b7bff2e0a9c82c8e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K82kFl7e6QqFwh1tgaq_Mw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">6.2 PJME Lag Analysis — Partial Auto Correlation Function (h=4).</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/a32acfd15df172f5e3ace8d54843d633.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-N6XAjYctJdc2_Ky3LkAA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">6.3 PJME Lag Analysis — Partial Auto Correlation Function (h=8).</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/30eaf2c891649106e9ec2e6a1ce93aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pyV1WI3G4rlAk22Mb3insw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">6.4 PJME Lag Analysis — Partial Auto Correlation Function (h=12).</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/9337dca06ee8f7ca5b4ff221128e89f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8sUpAAY7ljoMZuit0BGsQA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">6.5 PJME Lag Analysis — Partial Auto Correlation Function (h=16).</figcaption></figure><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/9f5f6bfa3c2cba4da0413c467eac4548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*prensTQCmEisWTI0Mow_Yg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">6.6 PJME Lag Analysis — Partial Auto Correlation Function (h=20).</figcaption></figure><p id="87da" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">As you can see, the PACF simply consists on plotting Pearson partial auto-correlation coefficients for different lags. Of course, the non-lagged series shows a perfect auto-correlation with itself, so lag 0 will always be 1. The blue band represent the <em class="pa">confidence interval: </em>if a lag exceed that band, then it is statistically significant and we can assert it is has great importance.</p><h2 id="e924" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">6.1 Lag analysis — Feature Engineering</h2><p id="78f5" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Lag analysis is one of the most impactful study on time series feature engineering. As already said, a lag with high correlation is an important lag for the series, then it should be taken into consideration.</p><p id="561a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">A widely used feature engineering technique consists on making an <strong class="ob fr">hourly division </strong>of the dataset. That is, splitting data in 24 subset, each one referring to an hour of the day. This has the effect to regularize and smooth the signal, making it more simple to forecast.</p><p id="ac6a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Each subset should then be feature engineered, trained and fine-tuned. The final forecast will be achieved combining the results of these 24 models. Said that, every hourly model will have its peculiarities, most of them will regard important lags.</p><p id="fff6" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Before moving on, let’s define two types of lag we can deal with when doing lag analysis:</p><ol class=""><li id="b6ad" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qg qh qi bk"><strong class="ob fr">Auto-regressive lags</strong>: lags close to lag 0, for which we expect high values (recent lags are more likely to predict the present value). They are a representation on how much trend the series shows.</li><li id="33ab" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk"><strong class="ob fr">Seasonal lags</strong>: lags referring to seasonal periods. When hourly splitting the data, they usually represent weekly seasonality.</li></ol><p id="d12a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Note that auto-regressive lag 1 can also be taught as a <em class="pa">daily seasonal lag</em> for the series.</p><p id="beeb" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Let’s now discuss about the PACF plots printed above.</p><h2 id="9027" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">Night Hours</h2><p id="2609" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Consumption on night hours (0, 4) relies more on auto-regressive than on weekly lags, since the most important are all localized on the first five. Seasonal periods such as 7, 14, 21, 28 seems not to be too much important, this advises us to pay particular attention on lag 1 to 5 when feature engineering.</p><h2 id="8e05" class="pb ne fq bf nf pc pd pe ni pf pg ph nl oi pi pj pk om pl pm pn oq po pp pq pr bk">Day Hours</h2><p id="59d3" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Consumption on day hours (8, 12, 16, 20) exhibit both auto-regressive and seasonal lags. This particularly true for hours 8 and 12 - when consumption is particularly high — while seasonal lags become less important approaching the night. For these subsets we should also include seasonal lag as well as auto-regressive ones.</p><p id="bab5" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Finally, here are some tips when feature engineering lags:</p><ul class=""><li id="1e66" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou qx qh qi bk">Do not to take into consideration too many lags since this will probably lead to over fitting. Generally, auto-regressive lags goes from 1 to 7, while weekly lags should be 7, 14, 21 and 28. But it’s not mandatory to take each of them as features.</li><li id="2223" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qx qh qi bk">Taking into consideration lags that are not auto-regressive or seasonal is usually a bad idea since they could bring to overfitting as well. Rather, try to understand while a certain lag is important.</li><li id="8af2" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qx qh qi bk">Transforming lags can often lead to more powerful features. For example, seasonal lags can be aggregated using a weighted mean to create a single feature representing the seasonality of the series.</li></ul><h1 id="ec0b" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Free Resources</h1><p id="a138" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Finally, I would like to mention a very useful (and free) book explaining time series, which I have personally used a lot: <a class="af nc" href="https://otexts.com/fpp3/" rel="noopener ugc nofollow" target="_blank">Forecasting: Principles and Practice</a>.</p><p id="e440" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Even though it is meant to use R instead of Python, this textbook provides a great introduction to forecasting methods, covering the most important aspects of time series analysis.</p><h1 id="a1dd" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Conclusion</h1><p id="11f7" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">The aim of this article was to present a comprehensive Exploratory Data Analysis template for time series forecasting.</p><p id="d62b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">EDA is a fundamental step in any type of data science study since it allows to understand the nature and the peculiarities of the data and lays the foundation to feature engineering, which in turn can dramatically improve model performance.</p><p id="f09d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We have then described some of the most used analysis for time series EDA, these can be both statistical/mathematical and graphical. Obviously, the intention of this work was only to give a practical framework to start with, subsequent investigations need to be carried out based on the type of historical series being examined and the business context.</p><p id="0a1b" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Thanks for having followed me until the end.</p><p id="2d54" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><em class="pa">Unless otherwise noted, all images are by the author.</em></p></div></div></div></div>    
</body>
</html>