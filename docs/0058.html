<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Streamline Data Pipelines: How to Use WhyLogs with PySpark for Effective Data Profiling and Validation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Streamline Data Pipelines: How to Use WhyLogs with PySpark for Effective Data Profiling and Validation</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/streamline-data-pipelines-how-to-use-whylogs-with-pyspark-for-data-profiling-and-validation-544efa36c5ad?source=collection_archive---------3-----------------------#2024-01-07">https://towardsdatascience.com/streamline-data-pipelines-how-to-use-whylogs-with-pyspark-for-data-profiling-and-validation-544efa36c5ad?source=collection_archive---------3-----------------------#2024-01-07</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="gr gs gt gu gv ab"><div><div class="ab gw"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@sarbahi.sarthak?source=post_page---byline--544efa36c5ad--------------------------------" rel="noopener follow"><div class="l gx gy by gz ha"><div class="l ed"><img alt="Sarthak Sarbahi" class="l ep by dd de cx" src="../Images/b2ee093e0bcb95d515f10eac906f9890.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*aysMaWbCGfiUNqfVLeusCQ.jpeg"/><div class="hb by l dd de em n hc eo"/></div></div></a></div></div><div class="hd ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--544efa36c5ad--------------------------------" rel="noopener follow"><div class="l he hf by gz hg"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hh cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hb by l br hh em n hc eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hi ab q"><div class="ab q hj"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hk hl bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hm" data-testid="authorName" href="https://medium.com/@sarbahi.sarthak?source=post_page---byline--544efa36c5ad--------------------------------" rel="noopener follow">Sarthak Sarbahi</a></p></div></div></div><div class="hn ho l"><div class="ab hp"><div class="ab"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewbox="0 0 16 16"><path fill="#437AFF" d="M15.163 8c0 .65-.459 1.144-.863 1.575-.232.244-.471.5-.563.719s-.086.543-.092.875c-.006.606-.018 1.3-.49 1.781-.47.481-1.15.494-1.744.5-.324.006-.655.013-.857.094s-.465.337-.704.575c-.422.412-.906.881-1.542.881-.637 0-1.12-.469-1.543-.881-.239-.238-.49-.482-.704-.575-.214-.094-.532-.088-.857-.094-.593-.006-1.273-.019-1.744-.5s-.484-1.175-.49-1.781c-.006-.332-.012-.669-.092-.875-.08-.207-.33-.475-.563-.719-.404-.431-.863-.925-.863-1.575s.46-1.144.863-1.575c.233-.244.472-.5.563-.719.092-.219.086-.544.092-.875.006-.606.019-1.3.49-1.781s1.15-.494 1.744-.5c.325-.006.655-.012.857-.094.202-.081.465-.337.704-.575C7.188 1.47 7.671 1 8.308 1s1.12.469 1.542.881c.239.238.49.481.704.575s.533.088.857.094c.594.006 1.273.019 1.745.5.47.481.483 1.175.49 1.781.005.331.011.669.091.875s.33.475.563.719c.404.431.863.925.863 1.575"/><path fill="#fff" d="M7.328 10.5c.195 0 .381.08.519.22.137.141.215.331.216.53 0 .066.026.13.072.177a.24.24 0 0 0 .346 0 .25.25 0 0 0 .071-.177c.001-.199.079-.389.216-.53a.73.73 0 0 1 .519-.22h1.959c.13 0 .254-.053.346-.146a.5.5 0 0 0 .143-.354V6a.5.5 0 0 0-.143-.354.49.49 0 0 0-.346-.146h-1.47c-.324 0-.635.132-.865.366-.23.235-.359.552-.359.884v2.5c0 .066-.025.13-.071.177a.24.24 0 0 1-.346 0 .25.25 0 0 1-.072-.177v-2.5c0-.332-.13-.65-.359-.884A1.21 1.21 0 0 0 6.84 5.5h-1.47a.49.49 0 0 0-.346.146A.5.5 0 0 0 4.88 6v4c0 .133.051.26.143.354a.49.49 0 0 0 .347.146z"/></svg></div></div></div><span class="hq hr" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hk hl dx"><button class="hs ht ah ai aj ak al am an ao ap aq ar hu hv hw" disabled="">Follow</button></p></div></div></span></div></div><div class="l hx"><span class="bf b bg z dx"><div class="ab cn hy hz ia"><div class="ib ic ab"><div class="bf b bg z dx ab id"><span class="ie l hx">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hm ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--544efa36c5ad--------------------------------" rel="noopener follow"><p class="bf b bg z if ig ih ii ij ik il im bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hq hr" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="in io l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 7, 2024</span></div></span></div></span></div></div></div><div class="ab cp ip iq ir is it iu iv iw ix iy iz ja jb jc jd je"><div class="h k w ea eb q"><div class="ju l"><div class="ab q jv jw"><div class="pw-multi-vote-icon ed ie jx jy jz"><div class=""><div class="ka kb kc kd ke kf kg am kh ki kj jz"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kk kl km kn ko kp kq"><p class="bf b dy z dx"><span class="kb">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ka kr ks ab q ee kt ku" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="kv"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jf jg jh ji jj jk jl jm jn jo jp jq jr js jt"><div class="kw k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al kx an ao ap hu ky kz la" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lb cn"><div class="l ae"><div class="ab cb"><div class="lc ld le lf lg lh ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al kx an ao ap hu li lj ku lk ll lm ln lo s lp lq lr ls lt lu lv u lw lx ly"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al kx an ao ap hu li lj ku lk ll lm ln lo s lp lq lr ls lt lu lv u lw lx ly"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al kx an ao ap hu li lj ku lk ll lm ln lo s lp lq lr ls lt lu lv u lw lx ly"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mc md me mf mg mh lz ma paragraph-image"><div role="button" tabindex="0" class="mi mj ed mk bh ml"><div class="lz ma mb"><img src="../Images/30d8f37b895178790b25f83e1ab4662b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GnezEHbFH2CdFUGG"/></div></div><figcaption class="mn mo mp lz ma mq mr bf b bg z dx">Photo by <a class="af ms" href="https://unsplash.com/@evan__bray?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Evan Dennis</a> on <a class="af ms" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1b80" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Data pipelines, made by data engineers or machine learning engineers, do more than just prepare data for reports or training models. It’s crucial to not only process the data but also ensure its quality. If the data changes over time, you might end up with results you didn’t expect, which is not good.</p><p id="6d93" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">To avoid this, we often use data profiling and data validation techniques. Data profiling gives us statistics about different columns in our dataset. Data validation checks for errors, comparing what we have with what we expect.</p><p id="1adb" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">A great tool for this is <a class="af ms" href="https://github.com/whylabs/whylogs" rel="noopener ugc nofollow" target="_blank">whylogs</a>. It lets you log all sorts of data. After logging, you can create <strong class="mv fr"><em class="nr">whylogs profiles</em></strong>. These profiles help you track changes in your data, set rules to make sure the data is correct, and show you summary statistics in an easy way.</p><p id="b85d" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">In this blog, you’ll learn how to use whylogs with PySpark. We’ll go through a practical guide on how to do data profiling and validation. So let’s dive in!</p><h2 id="f0e4" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">Table of contents</h2><ol class=""><li id="ec42" class="mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq os ot ou bk"><a class="af ms" href="#01be" rel="noopener ugc nofollow">Components of whylogs</a></li><li id="b9cf" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq os ot ou bk"><a class="af ms" href="#9222" rel="noopener ugc nofollow">Environment setup</a></li><li id="665e" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq os ot ou bk"><a class="af ms" href="#c70c" rel="noopener ugc nofollow">Understanding the dataset</a></li><li id="aad7" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq os ot ou bk"><a class="af ms" href="#5554" rel="noopener ugc nofollow">Getting started with PySpark</a></li><li id="a6a6" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq os ot ou bk"><a class="af ms" href="#81e9" rel="noopener ugc nofollow">Data profiling with whylogs</a></li><li id="2756" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq os ot ou bk"><a class="af ms" href="#4b1f" rel="noopener ugc nofollow">Data validation with whylogs</a></li></ol></div></div></div><div class="ab cb pa pb pc pd" role="separator"><span class="pe by bm pf pg ph"/><span class="pe by bm pf pg ph"/><span class="pe by bm pf pg"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="01be" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">Components of whylogs</h2><p id="469d" class="pw-post-body-paragraph mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq fj bk">Let’s begin by understanding the important characteristics of whylogs.</p><ul class=""><li id="c4e0" class="mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq pi ot ou bk"><strong class="mv fr">Logging data</strong>: The core of whylogs is its ability to log data. Think of it like keeping a detailed diary of your data’s characteristics. It records various aspects of your data, such as how many rows you have, the range of values in each column, and other statistical details.</li><li id="7012" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><strong class="mv fr">Whylogs profiles</strong>: Once data is logged, whylogs creates “profiles”. These profiles are like snapshots that summarize your data. They include statistics like averages, counts, and distributions. This is handy for understanding your data at a glance and tracking how it changes over time.</li><li id="f324" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><strong class="mv fr">Data tracking</strong>: With whylogs, you can track changes in your data over time. This is important because data often evolves, and what was true last month might not be true today. Tracking helps you catch these changes and understand their impact.</li><li id="1314" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><strong class="mv fr">Data validation</strong>: Whylogs allows you to set up rules or constraints to ensure your data is as expected. For example, if you know a certain column should only have positive numbers, you can set a rule for that. If something doesn’t match your rules, you’ll know there might be an issue.</li><li id="0517" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><strong class="mv fr">Visualization</strong>: It’s easier to understand data through visuals. Whylogs can create graphs and charts to help you see what’s going on in your data, making it more accessible, especially for those who are not data experts.</li><li id="537f" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><strong class="mv fr">Integrations</strong>: Whylogs supports integrations with a variety of tools, frameworks and languages — Spark, Kafka, Pandas, MLFlow, GitHub actions, RAPIDS, Java, Docker, AWS S3 and more.</li></ul><p id="308f" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">This is all we need to know about whylogs. If you’re curious to know more, I encourage you to check the <a class="af ms" href="https://docs.whylabs.ai/docs/whylogs-overview/" rel="noopener ugc nofollow" target="_blank">documentation</a>. Next, let’s work to set things up for the tutorial.</p><h2 id="9222" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">Environment setup</h2><p id="932c" class="pw-post-body-paragraph mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq fj bk">We’ll use a Jupyter notebook for this tutorial. To make our code work anywhere, we’ll use JupyterLab in Docker. This setup installs all needed libraries and gets the sample data ready. If you’re new to Docker and want to learn how to set it up, check out this <a class="af ms" rel="noopener" target="_blank" href="/seamless-data-analytics-workflow-from-dockerized-jupyterlab-and-minio-to-insights-with-spark-sql-3c5556a18ce6#fa16">link</a>.</p><div class="pj pk pl pm pn po"><a href="https://github.com/sarthak-sarbahi/whylogs-pyspark/tree/main?source=post_page-----544efa36c5ad--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pp ab hx"><div class="pq ab co cb pr ps"><h2 class="bf fr hk z if pt ih ii pu ik im fp bk">GitHub - sarthak-sarbahi/whylogs-pyspark</h2><div class="pv l"><h3 class="bf b hk z if pt ih ii pu ik im dx">Contribute to sarthak-sarbahi/whylogs-pyspark development by creating an account on GitHub.</h3></div><div class="pw l"><p class="bf b dy z if pt ih ii pu ik im dx">github.com</p></div></div></div></a></div><p id="ffe1" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Start by downloading the sample data (CSV) from <a class="af ms" href="https://github.com/sarthak-sarbahi/whylogs-pyspark/blob/main/data/patient_data.csv" rel="noopener ugc nofollow" target="_blank">here</a>. This data is what we’ll use for profiling and validation. Create a <code class="cx px py pz qa b">data</code> folder in your project root directory and save the CSV file there. Next, create a <code class="cx px py pz qa b">Dockerfile</code> in the same root directory.</p><figure class="qb qc qd qe qf mh"><div class="qg if l ed"><div class="qh qi l"/></div><figcaption class="mn mo mp lz ma mq mr bf b bg z dx">Dockerfile for this tutorial (Image by author)</figcaption></figure><p id="66b6" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">This Dockerfile is a set of instructions to create a specific environment for the tutorial. Let’s break it down:</p><ul class=""><li id="32b1" class="mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq pi ot ou bk">The first line <code class="cx px py pz qa b">FROM quay.io/jupyter/pyspark-notebook</code> tells Docker to use an existing image as the starting point. This image is a Jupyter notebook that already has PySpark set up.</li><li id="def0" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk">The <code class="cx px py pz qa b">RUN pip install whylogs whylogs[viz] whylogs[spark]</code> line is about adding the necessary libraries to this environment. It uses <code class="cx px py pz qa b">pip</code> to add <code class="cx px py pz qa b">whylogs</code> and its additional features for visualization (<code class="cx px py pz qa b">viz</code>) and for working with Spark (<code class="cx px py pz qa b">spark</code>).</li><li id="6341" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk">The last line, <code class="cx px py pz qa b">COPY data/patient_data.csv /home/patient_data.csv</code>, is about moving your data file into this environment. It takes the CSV file <code class="cx px py pz qa b">patient_data.csv</code> from the <code class="cx px py pz qa b">data</code> folder on your project directory and puts it in the <code class="cx px py pz qa b">/home/</code> directory inside the Docker environment.</li></ul><p id="ff0c" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">By now your project directory should look something like this.</p><figure class="qb qc qd qe qf mh lz ma paragraph-image"><div class="lz ma qj"><img src="../Images/d46865880372332c87ffd2efd2e6fc44.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*VtL2PrsUVLrI3ulTdnsv1w.png"/></div><figcaption class="mn mo mp lz ma mq mr bf b bg z dx">Project directory in VS Code (Image by author)</figcaption></figure><p id="479b" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Awesome! Now, let’s build a Docker image. To do this, type the following command in your terminal, making sure you’re in your project’s root folder.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="589c" class="qn nt fq qa b bg qo qp l qq qr">docker build -t pyspark-whylogs .</span></pre><p id="f8f5" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">This command creates a Docker image named <code class="cx px py pz qa b">pyspark-whylogs</code>. You can see it in the ‘Images’ tab of your <strong class="mv fr">Docker Desktop</strong> app.</p><figure class="qb qc qd qe qf mh lz ma paragraph-image"><div role="button" tabindex="0" class="mi mj ed mk bh ml"><div class="lz ma qs"><img src="../Images/b227c143a7d68aa6f704308ea8bb051f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4r2TC6B4lkz3Qi0_OETduw.jpeg"/></div></div><figcaption class="mn mo mp lz ma mq mr bf b bg z dx">Docker image built (Image by author)</figcaption></figure><p id="513a" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Next step: let’s run this image to start JupyterLab. Type another command in your terminal.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="de6e" class="qn nt fq qa b bg qo qp l qq qr">docker run -p 8888:8888 pyspark-whylogs</span></pre><p id="6952" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">This command launches a container from the <code class="cx px py pz qa b">pyspark-whylogs</code> image. It makes sure you can access JupyterLab through port 8888 on your computer.</p><p id="7603" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">After running this command, you’ll see a URL in the logs that looks like this: <code class="cx px py pz qa b">http://127.0.0.1:8888/lab?token=your_token</code>. Click on it to open the JupyterLab web interface.</p><figure class="qb qc qd qe qf mh lz ma paragraph-image"><div role="button" tabindex="0" class="mi mj ed mk bh ml"><div class="lz ma qt"><img src="../Images/a6b6590371d0150b205222e6f1e10cf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDrryVnbEVFXxx1r5D9Iew.png"/></div></div><figcaption class="mn mo mp lz ma mq mr bf b bg z dx">Docker container logs (Image by author)</figcaption></figure><p id="4952" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Great! Everything’s set up for using whylogs. Now, let’s get to know the dataset we’ll be working with.</p><h2 id="c70c" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">Understanding the dataset</h2><p id="2e7e" class="pw-post-body-paragraph mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq fj bk">We’ll use a dataset about hospital patients. The file, named <code class="cx px py pz qa b">patient_data.csv</code>, includes 100k rows with these columns:</p><ul class=""><li id="2e1c" class="mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq pi ot ou bk"><code class="cx px py pz qa b">patient_id</code>: Each patient’s unique ID. Remember, you might see the same patient ID more than once in the dataset.</li><li id="3fb5" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><code class="cx px py pz qa b">patient_name</code>: The name of the patient. Different patients can have the same name.</li><li id="1760" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><code class="cx px py pz qa b">height</code>: The patient’s height in <em class="nr">centimeters</em>. Each patient has the same height listed for every hospital visit.</li><li id="20c3" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><code class="cx px py pz qa b">weight</code>: The patient’s weight in <em class="nr">kilograms</em>. It’s always more than zero.</li><li id="58dc" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><code class="cx px py pz qa b">visit_date</code>: The date the patient visited the hospital, in the format <code class="cx px py pz qa b">YYYY-MM-DD</code>.</li></ul><p id="3fe8" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">As for where this dataset came from, don’t worry. It was created by ChatGPT. Next, let’s start writing some code.</p><h2 id="5554" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">Getting started with PySpark</h2><p id="716d" class="pw-post-body-paragraph mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq fj bk">First, open a new notebook in JupyterLab. Remember to save it before you start working.</p><div class="pj pk pl pm pn po"><a href="https://github.com/sarthak-sarbahi/whylogs-pyspark/blob/main/whylogs_pyspark.ipynb?source=post_page-----544efa36c5ad--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pp ab hx"><div class="pq ab co cb pr ps"><h2 class="bf fr hk z if pt ih ii pu ik im fp bk">whylogs-pyspark/whylogs_pyspark.ipynb at main · sarthak-sarbahi/whylogs-pyspark</h2><div class="pv l"><h3 class="bf b hk z if pt ih ii pu ik im dx">Contribute to sarthak-sarbahi/whylogs-pyspark development by creating an account on GitHub.</h3></div><div class="pw l"><p class="bf b dy z if pt ih ii pu ik im dx">github.com</p></div></div></div></a></div><p id="26e7" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">We’ll begin by importing the needed libraries.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="c84d" class="qn nt fq qa b bg qo qp l qq qr"># Import libraries<br/>from typing import Any<br/>import pyspark<br/>from pyspark.sql import SparkSession<br/>import pyspark.sql.functions as F<br/>from whylogs.api.pyspark.experimental import collect_column_profile_views<br/>from whylogs.api.pyspark.experimental import collect_dataset_profile_view<br/>from whylogs.core.metrics.condition_count_metric import Condition<br/>from whylogs.core.relations import Predicate<br/>from whylogs.core.schema import DeclarativeSchema<br/>from whylogs.core.resolvers import STANDARD_RESOLVER<br/>from whylogs.core.specialized_resolvers import ConditionCountMetricSpec<br/>from whylogs.core.constraints.factories import condition_meets<br/>from whylogs.core.constraints import ConstraintsBuilder<br/>from whylogs.core.constraints.factories import no_missing_values<br/>from whylogs.core.constraints.factories import greater_than_number<br/>from whylogs.viz import NotebookProfileVisualizer<br/>import pandas as pd<br/>import datetime</span></pre><p id="bce6" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Then, we’ll set up a SparkSession. This lets us run PySpark code.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="1108" class="qn nt fq qa b bg qo qp l qq qr"># Initialize a SparkSession<br/>spark = SparkSession.builder.appName('whylogs').getOrCreate()<br/>spark.conf.set("spark.sql.execution.arrow.pyspark.enabled","true")</span></pre><p id="7fda" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">After that, we’ll make a Spark dataframe by reading the CSV file. We’ll also check out its schema.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="d8f9" class="qn nt fq qa b bg qo qp l qq qr"># Create a dataframe from CSV file<br/>df = spark.read.option("header",True).option("inferSchema",True).csv("/home/patient_data.csv")<br/>df.printSchema()</span></pre><p id="ac80" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Next, let’s peek at the data. We’ll view the first row in the dataframe.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="3fb3" class="qn nt fq qa b bg qo qp l qq qr"># First row from dataframe<br/>df.show(n=1, vertical=True)</span></pre><p id="3a52" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Now that we’ve seen the data, it’s time to start data profiling with whylogs.</p><h2 id="81e9" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">Data profiling with whylogs</h2><p id="88b2" class="pw-post-body-paragraph mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq fj bk">To profile our data, we will use two functions. First, there’s <code class="cx px py pz qa b">collect_column_profile_views</code>. This function collects detailed profiles for each column in the dataframe. These profiles give us stats like counts, distributions, and more, depending on how we set up whylogs.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="0643" class="qn nt fq qa b bg qo qp l qq qr"># Profile the data with whylogs<br/>df_profile = collect_column_profile_views(df)<br/>print(df_profile)</span></pre><p id="ecd3" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Each column in the dataset gets its own <code class="cx px py pz qa b">ColumnProfileView</code> object in a dictionary. We can examine various metrics for each column, like their mean values.</p><blockquote class="qu"><p id="8a37" class="qv qw fq bf qx qy qz ra rb rc rd nq dx">whylogs will look at every data point and statistically decide wether or not that data point is relevant to the final calculation</p></blockquote><p id="3de0" class="pw-post-body-paragraph mt mu fq mv b mw re my mz na rf nc nd ne rg ng nh ni rh nk nl nm ri no np nq fj bk">For example, let’s look at the average <code class="cx px py pz qa b">height</code>.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="a612" class="qn nt fq qa b bg qo qp l qq qr">df_profile["height"].get_metric("distribution").mean.value</span></pre><p id="a45a" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Next, we’ll also calculate the mean directly from the dataframe for comparison.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="9568" class="qn nt fq qa b bg qo qp l qq qr"># Compare with mean from dataframe<br/>df.select(F.mean(F.col("height"))).show()</span></pre><p id="4ac4" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">But, profiling columns one by one isn’t always enough. So, we use another function, <code class="cx px py pz qa b">collect_dataset_profile_view</code>. This function profiles the whole dataset, not just single columns. We can combine it with Pandas to analyze all the metrics from the profile.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="85e7" class="qn nt fq qa b bg qo qp l qq qr"># Putting everything together<br/>df_profile_view = collect_dataset_profile_view(input_df=df)<br/>df_profile_view.to_pandas().head()</span></pre><p id="7dca" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">We can also save this profile as a CSV file for later use.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="5d8f" class="qn nt fq qa b bg qo qp l qq qr"># Persist profile as a file<br/>df_profile_view.to_pandas().reset_index().to_csv("/home/jovyan/patint_profile.csv",header = True,index = False)</span></pre><p id="63c4" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">The folder <code class="cx px py pz qa b">/home/jovyan</code> in our Docker container is from <strong class="mv fr">Jupyter's Docker Stacks</strong> (ready-to-use Docker images containing Jupyter applications). In these Docker setups, 'jovyan' is the default user for running Jupyter. The <code class="cx px py pz qa b">/home/jovyan</code> folder is where Jupyter notebooks usually start and where you should put files to access them in Jupyter.</p><p id="01cc" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">And that’s how we profile data with whylogs. Next, we’ll explore data validation.</p><h2 id="4b1f" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">Data validation with whylogs</h2><p id="015c" class="pw-post-body-paragraph mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq fj bk">For our data validation, we’ll perform these checks:</p><ul class=""><li id="8a24" class="mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq pi ot ou bk"><code class="cx px py pz qa b">patient_id</code>: Make sure there are no missing values.</li><li id="04ad" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><code class="cx px py pz qa b">weight</code>: Ensure every value is more than zero.</li><li id="18fa" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk"><code class="cx px py pz qa b">visit_date</code>: Check if dates are in the <code class="cx px py pz qa b">YYYY-MM-DD</code> format.</li></ul><p id="ffe9" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Now, let’s start. Data validation in whylogs starts from data profiling. We can use the <code class="cx px py pz qa b">collect_dataset_profile_view</code> function to create a profile, like we saw before.</p><p id="fad6" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">However, this function usually makes a profile with standard metrics like average and count. But what if we need to check <strong class="mv fr">individual values</strong> in a column as opposed to the other constraints, that can be checked against aggregate metrics? That’s where condition count metrics come in. It’s like adding a custom metric to our profile.</p><p id="4887" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Let’s create one for the <code class="cx px py pz qa b">visit_date</code> column to validate each row.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="1c26" class="qn nt fq qa b bg qo qp l qq qr">def check_date_format(date_value: Any) -&gt; bool:<br/>    date_format = '%Y-%m-%d'<br/>    try:<br/>        datetime.datetime.strptime(date_value, date_format)<br/>        return True<br/>    except ValueError:<br/>        return False<br/><br/>visit_date_condition = {"is_date_format": Condition(Predicate().is_(check_date_format))}</span></pre><p id="36a0" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Once we have our condition, we add it to the profile. We use a <strong class="mv fr">Standard Schema</strong> and add our custom check.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="5697" class="qn nt fq qa b bg qo qp l qq qr"># Create condition count metric<br/>schema = DeclarativeSchema(STANDARD_RESOLVER)<br/>schema.add_resolver_spec(column_name="visit_date", metrics=[ConditionCountMetricSpec(visit_date_condition)])</span></pre><p id="2b76" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Then we re-create the profile with both standard metrics and our new custom metric for the <code class="cx px py pz qa b">visit_date</code> column.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="97a5" class="qn nt fq qa b bg qo qp l qq qr"># Use the schema to pass to logger with collect_dataset_profile_view<br/># This creates profile with standard metrics as well as condition count metrics<br/>df_profile_view_v2 = collect_dataset_profile_view(input_df=df, schema=schema)</span></pre><p id="472d" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">With our profile ready, we can now set up our validation checks for each column.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="34f2" class="qn nt fq qa b bg qo qp l qq qr">builder = ConstraintsBuilder(dataset_profile_view=df_profile_view_v2)<br/>builder.add_constraint(no_missing_values(column_name="patient_id"))<br/>builder.add_constraint(condition_meets(column_name="visit_date", condition_name="is_date_format"))<br/>builder.add_constraint(greater_than_number(column_name="weight",number=0))<br/><br/>constraints = builder.build()<br/>constraints.generate_constraints_report()</span></pre><p id="2409" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">We can also use whylogs to show a report of these checks.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="3651" class="qn nt fq qa b bg qo qp l qq qr"># Visualize constraints report using Notebook Profile Visualizer<br/>visualization = NotebookProfileVisualizer()<br/>visualization.constraints_report(constraints, cell_height=300)</span></pre><p id="446f" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">It’ll be an HTML report showing which checks passed or failed.</p><figure class="qb qc qd qe qf mh lz ma paragraph-image"><div role="button" tabindex="0" class="mi mj ed mk bh ml"><div class="lz ma rj"><img src="../Images/92e9b55579654c4f34af3e2310e9ad42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wN6uQsaUxfJ72x0rcFWK7g.png"/></div></div><figcaption class="mn mo mp lz ma mq mr bf b bg z dx">whylogs constraints report (Image by author)</figcaption></figure><p id="44f1" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Here’s what we find:</p><ul class=""><li id="d573" class="mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq pi ot ou bk">The <code class="cx px py pz qa b">patient_id</code> column has no missing values. Good!</li><li id="70d5" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk">Some <code class="cx px py pz qa b">visit_date</code> values don’t match the <code class="cx px py pz qa b">YYYY-MM-DD</code> format.</li><li id="def7" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk">A few <code class="cx px py pz qa b">weight</code> values are zero.</li></ul><p id="1e8b" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Let’s double-check these findings in our dataframe. First, we check the <code class="cx px py pz qa b">visit_date</code> format with PySpark code.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="8b4f" class="qn nt fq qa b bg qo qp l qq qr"># Validate visit_date column<br/>df \<br/>.withColumn("check_visit_date",F.to_date(F.col("visit_date"),"yyyy-MM-dd")) \<br/>.withColumn("null_check",F.when(F.col("check_visit_date").isNull(),"null").otherwise("not_null")) \<br/>.groupBy("null_check") \<br/>.count() \<br/>.show(truncate = False)<br/><br/>+----------+-----+<br/>|null_check|count|<br/>+----------+-----+<br/>|not_null  |98977|<br/>|null      |1023 |<br/>+----------+-----+</span></pre><p id="9932" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">It shows that 1023 out of 100,000 rows don’t match our date format. Next, the <code class="cx px py pz qa b">weight</code> column.</p><pre class="qb qc qd qe qf qk qa ql bp qm bb bk"><span id="6df7" class="qn nt fq qa b bg qo qp l qq qr"># Validate weight column<br/>df \<br/>.select("weight") \<br/>.groupBy("weight") \<br/>.count() \<br/>.orderBy(F.col("weight")) \<br/>.limit(1) \<br/>.show(truncate = False)<br/><br/>+------+-----+<br/>|weight|count|<br/>+------+-----+<br/>|0     |2039 |<br/>+------+-----+</span></pre><p id="f64a" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">Again, our findings match whylogs. Almost 2,000 rows have a weight of zero. And that wraps up our tutorial. You can find the notebook for this tutorial <a class="af ms" href="https://github.com/sarthak-sarbahi/whylogs-pyspark/blob/main/whylogs_pyspark.ipynb" rel="noopener ugc nofollow" target="_blank">here</a>.</p></div></div></div><div class="ab cb pa pb pc pd" role="separator"><span class="pe by bm pf pg ph"/><span class="pe by bm pf pg ph"/><span class="pe by bm pf pg"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="7393" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">Conclusion</h2><p id="231b" class="pw-post-body-paragraph mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq fj bk">In this tutorial, we’ve covered how to use whylogs with PySpark. We began by preparing our environment using Docker, and then we did data profiling and validation on our dataset. Remember, this is just the beginning. Whylogs offers a lot more, from tracking data changes (data drift) in machine learning to checking data quality in real-time streams.</p><p id="bf75" class="pw-post-body-paragraph mt mu fq mv b mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq fj bk">I sincerely hope this guide was beneficial for you. Should you have any questions, please don’t hesitate to drop them in the comments below.</p><h2 id="8fc1" class="ns nt fq bf nu nv nw nx ny nz oa ob oc ne od oe of ni og oh oi nm oj ok ol om bk">References</h2><ul class=""><li id="5edc" class="mt mu fq mv b mw on my mz na oo nc nd ne op ng nh ni oq nk nl nm or no np nq pi ot ou bk">GitHub repository for tutorial: <a class="af ms" href="https://github.com/sarthak-sarbahi/whylogs-pyspark/tree/main" rel="noopener ugc nofollow" target="_blank">https://github.com/sarthak-sarbahi/whylogs-pyspark/tree/main</a></li><li id="dd5d" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk">Whylogs Docs: <a class="af ms" href="https://docs.whylabs.ai/docs/whylogs-overview/" rel="noopener ugc nofollow" target="_blank">https://docs.whylabs.ai/docs/whylogs-overview/</a></li><li id="8596" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk">GitHub for whylogs: <a class="af ms" href="https://github.com/whylabs/whylogs/tree/mainline" rel="noopener ugc nofollow" target="_blank">https://github.com/whylabs/whylogs/tree/mainline</a></li><li id="f29f" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk">Profiling in PySpark: <a class="af ms" href="https://github.com/whylabs/whylogs/blob/mainline/python/examples/integrations/Pyspark_Profiling.ipynb" rel="noopener ugc nofollow" target="_blank">https://github.com/whylabs/whylogs/blob/mainline/python/examples/integrations/Pyspark_Profiling.ipynb</a></li><li id="c300" class="mt mu fq mv b mw ov my mz na ow nc nd ne ox ng nh ni oy nk nl nm oz no np nq pi ot ou bk">Whylogs constraints for PySpark: <a class="af ms" href="https://github.com/whylabs/whylogs/blob/mainline/python/examples/tutorials/Pyspark_and_Constraints.ipynb" rel="noopener ugc nofollow" target="_blank">https://github.com/whylabs/whylogs/blob/mainline/python/examples/tutorials/Pyspark_and_Constraints.ipynb</a></li></ul></div></div></div></div>    
</body>
</html>