- en: 'Autoencoders: An Ultimate Guide for Data Scientists'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自编码器：数据科学家的终极指南
- en: 原文：[https://towardsdatascience.com/autoencoders-an-ultimate-guide-for-data-scientists-dca3e56a070e?source=collection_archive---------2-----------------------#2024-10-17](https://towardsdatascience.com/autoencoders-an-ultimate-guide-for-data-scientists-dca3e56a070e?source=collection_archive---------2-----------------------#2024-10-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/autoencoders-an-ultimate-guide-for-data-scientists-dca3e56a070e?source=collection_archive---------2-----------------------#2024-10-17](https://towardsdatascience.com/autoencoders-an-ultimate-guide-for-data-scientists-dca3e56a070e?source=collection_archive---------2-----------------------#2024-10-17)
- en: A beginner’s guide to the architecture, Python implementation, and a glimpse
    into the future
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面向初学者的架构指南、Python实现及对未来的展望
- en: '[](https://medium.com/@niklas_lang?source=post_page---byline--dca3e56a070e--------------------------------)[![Niklas
    Lang](../Images/5fa71386db00d248438c588c5ae79c67.png)](https://medium.com/@niklas_lang?source=post_page---byline--dca3e56a070e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dca3e56a070e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dca3e56a070e--------------------------------)
    [Niklas Lang](https://medium.com/@niklas_lang?source=post_page---byline--dca3e56a070e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@niklas_lang?source=post_page---byline--dca3e56a070e--------------------------------)[![Niklas
    Lang](../Images/5fa71386db00d248438c588c5ae79c67.png)](https://medium.com/@niklas_lang?source=post_page---byline--dca3e56a070e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dca3e56a070e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dca3e56a070e--------------------------------)
    [Niklas Lang](https://medium.com/@niklas_lang?source=post_page---byline--dca3e56a070e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dca3e56a070e--------------------------------)
    ·19 min read·Oct 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dca3e56a070e--------------------------------)
    ·阅读时间19分钟·2024年10月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a10009dfa3fe19f15c9bb9c886bf57ac.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a10009dfa3fe19f15c9bb9c886bf57ac.png)'
- en: Photo by [Clark Van Der Beken](https://unsplash.com/@snapsbyclark?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Clark Van Der Beken](https://unsplash.com/@snapsbyclark?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Autoencoders are a special form of deep neural networks primarily used for
    feature extraction or dimension reduction. As they can work with unlabeled data,
    they belong to the field of unsupervised learning. The architecture consists of
    two main components: the encoder, which compresses the input data into a low-dimensional
    representation, and the decoder, trained to reconstruct the original data from
    this representation.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一种特殊形式的深度神经网络，主要用于特征提取或降维。由于它们可以处理未标注的数据，因此属于无监督学习领域。其架构由两个主要组成部分构成：编码器，它将输入数据压缩成低维表示；解码器，经过训练后能够从这一表示中重建原始数据。
- en: This article provides a detailed overview of the structure of autoencoders and
    explains the individual components of the architecture. We also look at the challenges
    that can arise during training and the applications that build on this model.
    Finally, we take a closer look at the advantages and disadvantages of the method
    and compare it with other dimension reduction algorithms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文详细概述了自编码器的结构，并解释了架构中各个组件的作用。我们还探讨了在训练过程中可能遇到的挑战，以及基于这一模型的应用。最后，我们将深入探讨该方法的优缺点，并与其他降维算法进行比较。
- en: What is an Autoencoder?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是自编码器？
- en: An autoencoder is a special form of [artificial neural network](https://databasecamp.de/en/ml/artificial-neural-networks)
    trained to represent the input data in a compressed form and then reconstruct
    the original data from this compressed form. What initially sounds like an unnecessary
    transformation is an integral part of [dimensionality reduction](https://databasecamp.de/en/ml/dimensionality-reduction),
    as it…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一种特殊形式的[人工神经网络](https://databasecamp.de/en/ml/artificial-neural-networks)，经过训练用于将输入数据表示为压缩形式，然后从这种压缩形式中重建原始数据。最初听起来似乎是一次不必要的转换，但它是[降维](https://databasecamp.de/en/ml/dimensionality-reduction)的一个核心部分，因为它…
