- en: 'SQL vs. Calculators: Building Champion/Challenger Tests from Scratch'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/sql-vs-calculators-building-champion-challenger-tests-from-scratch-b457dc43d784?source=collection_archive---------9-----------------------#2024-12-04](https://towardsdatascience.com/sql-vs-calculators-building-champion-challenger-tests-from-scratch-b457dc43d784?source=collection_archive---------9-----------------------#2024-12-04)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'CODE OR CLICK: WHAT IS BETTER FOR A/B TESTING'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In depth SQL code for creating your own statistical test design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@govadaharika?source=post_page---byline--b457dc43d784--------------------------------)[![Harika
    Govada](../Images/fdcd28b36eacb5538bb72b59e02a176f.png)](https://medium.com/@govadaharika?source=post_page---byline--b457dc43d784--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b457dc43d784--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b457dc43d784--------------------------------)
    [Harika Govada](https://medium.com/@govadaharika?source=post_page---byline--b457dc43d784--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b457dc43d784--------------------------------)
    ·13 min read·Dec 4, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f5f74f94090bf8c9dd7891e7f469c217.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from Imagen 3
  prefs: []
  type: TYPE_NORMAL
- en: 'The $300 Million Button: How A/B Testing Changed E-Commerce Forever'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I am sure a lot of people are aware of the $300 million button story. For those
    that are not aware of the story, it is about a major e-commerce platform losing
    millions in potential revenue due to customer drop-offs at checkout. This was
    a large online retailer, and a single button labeled “Register” when changed to
    “Continue,” with an option to register later, the company saw a $300 million increase
    in annual revenue. This case study was documented by UX expert Jared Spool )[Source:
    UIE, Jared Spool, “The $300 Million Button”](https://articles.centercentre.com/three_hund_million_button/)),
    showing how a minor change can drastically impact business outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yet surprisingly, 58% of executives still rely on intuition when making business
    decisions, according to a PwC report ([Source: PwC Global Data and Analytics Survey](https://www.pwc.com/im/en/assets/document/big-decisions-data-analytics-sept-2014.pdf)).
    I always believe that folks with industry knowledge and well-versed with business
    processes intuition is important but adds more value when combined with observed
    evidence of data and numbers in decision making. Champion-challenger testing is
    one such approach to decision-making that changes guesswork into scientific validation.'
  prefs: []
  type: TYPE_NORMAL
- en: What Is Champion/Challenger Testing?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Champion/challenger testing (A/B testing) is a technique used in businesses
    to optimize processes and business operations by selecting best options that improve
    performance by increasing revenue, reduce costs, and enhance decision making.
    Champion here is the current operation or methodology that works best while challenger
    is the method or a new strategy you want to test against your champion to see
    if it works better or worse than your current process or strategy. Your champion
    challenger should have the same type of setup, like similar type of accounts or
    customer segments, to ensure you have an apples-to-apples comparison. It is important
    to know, what is the goal you are trying to achieve and know what your key performance
    indicators should be to measure the success of the test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Implementation Through Oracle SQL: A Practical Guide'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When implementing champion-challenger testing, I always wondered whether to
    rely on online calculators or invest in a database-driven SQL implementation.
    The answer depends on various factors but let us explore an SQL approach through
    a practical example. While going through the example, I will also be walking you
    through the importance of some of the variables and conditions to consider ensuring
    we have a solid champion-challenger testing created.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a collection agency wanting to test the effectiveness of leaving voicemail
    versus not leaving them. The current strategy involves no voicemails, and some
    believe leaving voicemails could improve metrics like contact rate and payment
    rate, but implementing this change across all accounts carries risks like potential
    reduction in contact rates, compliance considerations with leaving messages, resource
    costs of leaving voicemails, and a possible decrease in payment rates. Let us
    design a rigorous test to evaluate the hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin our implementation, we need to create a structured foundation that
    will track our test from start to finish. I used Oracle SQL developer to write
    my SQL and for illustration purpose in the voicemail testing context, I assumed
    some of the key component values as mentioned below to generate voicemail champion-challenger
    test. Below are the details of what each of these key components mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Baseline Conversion Rate**: Your current conversion rate for the metric you’re
    testing. In this specific voicemail test example, we are assuming 8% current payment
    rate as baseline conversion rate.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Minimum Detectable Effect (MDE)**: The smallest improvement in conversion
    rate you care about detecting. For voicemails, we want to see if we can improve
    the current conversion rate by 10% which is increasing to 8.8% (8% * (1 + 0.10)
    = 8.8%).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Statistical Significance Level**: Typically set at 95%, meaning you’re 95%
    confident that your results are not due to chance.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Statistical Power**: Often set at 80%, this is a measure of whether the test
    has enough data to reach a conclusive result.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hypothesis / Tail type:** a statement that predicts whether changing a certain
    variable will affect customer behavior. There are two types of hypotheses to consider
    or more known as tail tests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) **One-tail test:** This test is recommended only when you are testing if
    something is either only better than current performance or only worse than current
    performance. Voicemail testing with one-tail test means we only want to know if
    voicemails improve payment rates.
  prefs: []
  type: TYPE_NORMAL
- en: b) **Two-tail test:** This test is recommended in scenarios where you need to
    understand any change in performance. You are testing if something is either better
    or worse than current performance. Voicemail testing with two -tail test means
    we want to know if voicemails will increase or decrease payment rates.
  prefs: []
  type: TYPE_NORMAL
- en: As we do not know whether voicemails will increase or decrease payment rates,
    we will be going with a two-tailed test.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3ab019c8fca2fcfc19c9df2740eb6e16.png)'
  prefs: []
  type: TYPE_IMG
- en: SQL prompt for monthly volume input
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e9a3b9462406490abfb0bc9eecbaf09a.png)'
  prefs: []
  type: TYPE_IMG
- en: Output Result
  prefs: []
  type: TYPE_NORMAL
- en: This above configuration is important because it records what we are testing
    and why. These metrics are the key components in sample size calculation. I will
    show you the sample size calculation, split ratio, months and days needed to run
    your test and finally the recommendation results for different monthly volumes
    available.
  prefs: []
  type: TYPE_NORMAL
- en: Sample Size Calculation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the right sample size is important to make sure your test results are
    statistically significant. A sample size that’s too small may result in inaccurate
    results. Larger sample sizes will give you more accurate average values, identify
    outliers in data and provide smaller margins of error. The question here ultimately
    is what too small vs large sample sizes is. You will find out the answers to it
    as you go through the article.
  prefs: []
  type: TYPE_NORMAL
- en: The below oracle script shows how to calculate sample size. I am using a CTE
    and partitioned them into multiple sections of snapshots to explain the code better.
    If you want to use the script, you need to put all sections of code together.
    Now, I am going to set up our statistical parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This conversion converts the confidence levels into statistical values used
    in sample size calculations. For collections, 95% confidence means there is a
    possibility of 5% of the time results being wrong or when voicemails don’t help.
  prefs: []
  type: TYPE_NORMAL
- en: In statistical terms, z-alpha represents our confidence level, with different
    values based on both confidence level and tail-type test. Typically, two tailed
    test values are higher than one tailed test values because of the error rate split
    in both directions for a two-tailed test. In voicemail testing scenario, 5% chance
    of being wrong indicates error rate split evenly (0.025 chance probability for
    payments going lower and 0.025 for payments going higher) whereas a one-tailed
    test concentrates the entire 0.05 probability in one direction, as we’re only
    interested in payments going either up or down, not both.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical power is known as z-beta. When we set 80% statistical power (z-beta
    = 0.84), we are saying we want to catch real changes 80% of the time and will
    accept missing them 20% of the time.
  prefs: []
  type: TYPE_NORMAL
- en: Z-alpha and Z-beta put together means, if voicemails truly help improve payment
    rates, we will detect this improvement 80% of the time, and when we do detect
    it, we can be 95% confident it is a real improvement and not due to a chance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/09909b414d2adfca86aa48c1122d2f98.png)'
  prefs: []
  type: TYPE_IMG
- en: Output Result
  prefs: []
  type: TYPE_NORMAL
- en: Let us now move into the calculation of the sample size volume needed. This
    calculation determines how many accounts we need to test. In our voicemail scenario,
    if we’re looking to improve from 8% to 8.8% payment rate, this tells us how many
    accounts we need to be confident that the payment rate will increase, or decrease
    is real and not just by chance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e0ee03c6e7646e3b10b8975d007e5b27.png)'
  prefs: []
  type: TYPE_IMG
- en: Output Result
  prefs: []
  type: TYPE_NORMAL
- en: Split Ratios and Test Duration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Split ratios determine how you divide your dataset between the champion (your
    current version) and the challenger(s) (your test versions). Common split ratios
    include two way (like 50/50, 80/20 or 90/10 splits) or multi-way splits like 50/25/25
    or 70/10/10/10\. These multi-way tests are used to test different variations while
    we still have a control group.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a split ratio should not be random or solely depend on volume availability
    but also consider other factors like confidence level in the challenger, impact
    of the change especially if it hurts the current metrics, and ensure the test
    meets the minimum sample size needed requirement.
  prefs: []
  type: TYPE_NORMAL
- en: This below analysis translates statistical requirements into business terms
    and shows how different split ratios affect test duration. It also shows risk
    level based on split ratio. Split ratios represent how we divide accounts between
    champion and challenger.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Conservative risk only impacts 10–20% of accounts getting new treatment and
    80–90% accounts from potential negative impacts. This split ratio takes longer
    to gather enough data. Balanced risk will impact one third of the accounts and
    protect the rest while it gathers data faster. Aggressive risk impacts up to half
    the accounts though it gathers data quickly, it exposes more accounts to risk.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b6f04b5e2a90eb18f00fe202e00b5a1.png)'
  prefs: []
  type: TYPE_IMG
- en: Part of the output result
  prefs: []
  type: TYPE_NORMAL
- en: It is important to know how long a champion/challenger test should be run. Run
    a test for too short of a time, and you risk making decisions based on incomplete
    or misleading data. Run it too long, you may waste resources and delay decision
    making. To maintain the balance, generally, tests should run for a minimum of
    one full business cycle. Tests typically shouldn’t run for more than 4–8 weeks
    and this way we don’t mix up our results with other operational or seasonal changes
    taking place.
  prefs: []
  type: TYPE_NORMAL
- en: Risk Assessment and Volume Requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I observe analysts new to champion/challenger testing do not know what split
    ratio to opt for. We can decide on which split ratio to opt for by considering
    the risks associated in choosing for a certain split ratio and what volume is
    needed for that split ratio.
  prefs: []
  type: TYPE_NORMAL
- en: Worst-case scenario must be calculated to assess the risk level.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b93e366073006185c8625c50b795046c.png)'
  prefs: []
  type: TYPE_IMG
- en: Part of the output result
  prefs: []
  type: TYPE_NORMAL
- en: Let us say we opt for 30/70 split ratio which is showing a ‘balanced’ split
    for voicemails. With 10,000 monthly accounts, 3000 accounts will receive voicemails
    while 7000 accounts continue as normal. If voicemails perform poorly, it affects
    3,000 accounts and the maximum exposure will be 240 payments at risk (3,000 *
    8%). In the scenario, voicemails test decrease payment rates by 10% instead of
    improving them, we would only receive 216 payments (3,000 * 8% * (1–10%)). This
    means we lose 24 payments which we would have otherwise received.
  prefs: []
  type: TYPE_NORMAL
- en: This worst-case calculation helps us understand what’s at risk. With a more
    aggressive 50/50 split, we would have 5,000 accounts in the test group, risking
    a potential loss of 40 payments under worse-case conditions. A conservative 20/80
    split would only risk 16 payments, though it would take longer to complete the
    test.
  prefs: []
  type: TYPE_NORMAL
- en: With a 50/50 split, we need a total volume of 36k accounts to get our required
    18k accounts in the test group. Since we only have 10k accounts monthly, this
    means our test would take approximately 3.6 months to complete. Moving to the
    most conservative 10/90 split would require 180k accounts, making the test duration
    impractically long at 18 months.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/8fecf030e015184a225092c33a664011.png)'
  prefs: []
  type: TYPE_IMG
- en: Part of the output result for 10k monthly volume
  prefs: []
  type: TYPE_NORMAL
- en: 'If monthly volume is 50,000 accounts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b168f019846bd9c2500f2e4637868840.png)'
  prefs: []
  type: TYPE_IMG
- en: Part of the output result for 50k monthly volume
  prefs: []
  type: TYPE_NORMAL
- en: Certain questions need to be thought of in order to decide which split ratio
    to choose and risk level is acceptable and eventually understand the volume available
    to test voicemails. Can the business accept potentially losing 40 payments monthly
    in exchange for completing the test in 3.6 months or would it be better to risk
    only 16 payments monthly but extend the test duration? By carefully choosing your
    split ratios and understand what sample sizes are appropriate, you can design
    tests that provide accurate and actionable insights.
  prefs: []
  type: TYPE_NORMAL
- en: Calculators versus SQL Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Online calculators like [Evan Miller](https://www.evanmiller.org/ab-testing/sample-size.html)
    and [Optimizely](https://www.optimizely.com/sample-size-calculator/#/?conversion=8&effect=10&significance=95)
    are valuable tools, typically defaulting to a 50/50 split ratio or two-tailed
    tests. Another online tool, [Statsig](https://www.statsig.com/calculator), doesn’t
    default to anything but at the same time doesn’t provide additional details like
    what we just coded with our SQL implementation. The SQL implementation becomes
    valuable here as it helps track not just basic metrics, but also monitor risk
    exposure and test duration based on your actual monthly volume. This comprehensive
    view helps especially when you need to deviate from standard 50/50 splits or want
    to understand different split ratios on your test design and business risks.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Champion/challenger testing is not a one-time effort but a continuous cycle
    of improvement. Create performance reports and continuously monitor the results.
    Adapt to the changing conditions including seasonal shifts and economic changes.
    By integrating this approach into your strategy testing, you are creating a systematic
    approach to decision-making that drives innovation, mitigates risk, and most importantly
    intuition can be backed up with solid data evidence.
  prefs: []
  type: TYPE_NORMAL
- en: '***Note****:* *All images, unless otherwise noted, are by the author.*'
  prefs: []
  type: TYPE_NORMAL
