<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Generative AI is a Gamble Enterprises Should Take in 2024</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Generative AI is a Gamble Enterprises Should Take in 2024</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-ai-is-a-gamble-enterprises-should-take-in-2024-9120e54f6349?source=collection_archive---------15-----------------------#2024-01-04">https://towardsdatascience.com/generative-ai-is-a-gamble-enterprises-should-take-in-2024-9120e54f6349?source=collection_archive---------15-----------------------#2024-01-04</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="4488" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">LLMs today suffer from inaccuracies at scale, but that doesn’t mean you should cede competitive ground by waiting to adopt generative AI.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://databrett.medium.com/?source=post_page---byline--9120e54f6349--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Brett A. Hurt" class="l ep by dd de cx" src="../Images/d120f98c1d5e06b14add6b5b9f4eb936.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/0*GVmYylB8UGgEXDpI.jpg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--9120e54f6349--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://databrett.medium.com/?source=post_page---byline--9120e54f6349--------------------------------" rel="noopener follow">Brett A. Hurt</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--9120e54f6349--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 4, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/69c21cf26e4eac65662be8762774c3a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M8FR8SDbvAnppHXhnQh-NQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Building an AI-ready workforce with data.world OWLs, as imagined by OpenAI’s GPT-4</figcaption></figure><p id="29fb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Every enterprise technology has a purpose or it wouldn’t exist. Generative AI’s enterprise purpose is to produce human-usable output from technical, business, and language data rapidly and at scale to drive productivity, efficiency, and business gains. But this primary function of generative AI — to provide a witty answer — is also the source of large language models’ (LLMs) biggest barrier to enterprise adoption: so-called “hallucinations”.</p><p id="393e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Why do hallucinations happen at all? Because, at their core, LLMs are complex statistical matching systems. They analyze billions of data points in an effort to determine patterns and predict the most likely response to any given prompt. But while these models may impress us with the usefulness, depth, and creativity of their answers, seducing us to trust them each time, they are far from reliable. New <a class="af ny" href="https://vectara.com/measuring-hallucinations-in-rag-systems/" rel="noopener ugc nofollow" target="_blank">research</a> from Vectara found that chatbots can “invent” new information <em class="nz">up to 27% of the time</em>. In an enterprise setting where question complexity can vary greatly, that number climbs even higher. A <a class="af ny" href="https://arxiv.org/pdf/2311.07509.pdf" rel="noopener ugc nofollow" target="_blank">recent benchmark</a> from data.world’s AI Lab using real business data found that when deployed as a standalone solution, LLMs return accurate responses to most basic business queries <em class="nz">only 25.5% of the time</em>. When it comes to intermediate or expert level queries, which are still well within the bounds of typical, data-driven enterprise queries, <em class="nz">accuracy dropped to ZERO percent</em>!</p><p id="2b59" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The tendency to hallucinate may be inconsequential for individuals playing around with ChatGPT for small or novelty use cases. But when it comes to enterprise deployment, hallucinations present a systemic risk. The consequences range from inconvenient (a service chatbot sharing irrelevant information in a customer interaction) to catastrophic, such as inputting the wrong numeral on an SEC filing.</p><p id="9b73" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As it stands, generative AI is still a gamble for the enterprise. However, it’s also a necessary one. As we learned at OpenAI’s first developer conference, <a class="af ny" href="https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference" rel="noopener ugc nofollow" target="_blank">92% of Fortune 500 companies</a> are using OpenAI APIs. The potential of this technology in the enterprise is so transformative that the path forward is resoundingly clear: start adopting generative AI — knowing that the rewards come with serious risks. The alternative is to insulate yourself from the risks, and swiftly fall behind the competition. The <a class="af ny" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321" rel="noopener ugc nofollow" target="_blank">inevitable productivity lift</a> is so obvious now that to not take advantage of it could be existential to an enterprise’s survival. So, faced with this illusion of choice, how can organizations go about integrating generative AI into their workflows, while simultaneously mitigating risk?</p><p id="4141" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">First, you need to prioritize your data foundation.</strong> Like any modern enterprise technology, generative AI solutions are only as good as the data they’re built on top of — and according to Cisco’s recent <a class="af ny" href="https://www.cisco.com/c/dam/m/en_us/solutions/ai/readiness-index/documents/cisco-global-ai-readiness-index.pdf" rel="noopener ugc nofollow" target="_blank">AI Readiness Index</a>, intention is outpacing ability, particularly on the data front. Cisco found that while 84% of companies worldwide believe AI will have a significant impact on their business, 81% lack the data centralization needed to leverage AI tools to their full potential, and only 21% say their network has ‘optimal’ latency to support demanding AI workloads. It’s a similar story when it comes to data governance as well; just three out of ten respondents currently have comprehensive AI policies and protocols, while only four out of ten have systematic processes for AI bias and fairness corrections.</p><p id="7785" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As benchmarking demonstrates, LLMs have a hard enough time already retrieving factual answers reliably. Combine that with poor data quality, a lack of data centralization / management capabilities, and limited governance policies, and the risk of hallucinations — and accompanying consequences — <em class="nz">skyrockets</em>. Put simply, companies with a strong data architecture have better and more accurate information available to them and, by extension, their AI solutions are equipped to make better decisions. Working with a data catalog or evaluating internal governance and data entry processes may not feel like the most exciting part of adopting generative AI. But it’s those considerations — data governance, lineage, and quality — that could make or break the success of a generative AI Initiative. It not only enables organizations to deploy enterprise AI solutions faster and more responsibly, but also allows them to keep pace with the market as the technology evolves.</p><p id="35f4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Second, you need to build an AI-educated workforce.</strong> Research points to the fact that techniques like <a class="af ny" href="https://amatriain.net/blog/hallucinations#advancedprompting" rel="noopener ugc nofollow" target="_blank">advanced prompt engineering</a> can prove useful in identifying and mitigating hallucinations. Other methods, such as fine-tuning, have been shown to dramatically improve LLM accuracy, even to the point of outperforming larger, more advanced general purpose models. However, employees can only deploy these tactics if they’re empowered with the latest training and education to do so. And let’s be honest: most employees aren’t. We are just over the one-year mark since the launch of ChatGPT on November 30, 2022!</p><p id="d293" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">When a major vendor such as Databricks or Snowflake releases new capabilities, organizations flock to webinars, conferences, and workshops to ensure they can take advantage of the latest features. Generative AI should be no different. Create a culture in 2024 where educating your team on AI best practices is your default; for example, by providing stipends for AI-specific L&amp;D programs or bringing in an outside training consultant, such as the work we’ve done at data.world with <span class="ia"><span class="ia" aria-hidden="false"><a class="oa ib ob" href="https://medium.com/u/4c866ecaad84?source=post_page---user_mention--9120e54f6349--------------------------------" rel="noopener" target="_blank">Rachel Woods</a></span></span>, who serves on our Advisory Board and founded and leads The AI Exchange. We also promoted <span class="ia"><span class="ia" aria-hidden="false"><a class="oa ib ob" href="https://medium.com/u/fa1e06871025?source=post_page---user_mention--9120e54f6349--------------------------------" rel="noopener" target="_blank">Brandon Gadoci</a></span></span>, our first data.world employee outside of me and my co-founders, to be our VP of AI Operations. The staggering lift we’ve already had in our internal productivity is nothing short of inspirational (I wrote about it in <a class="af ny" href="https://data.world/blog/meet-archie-who-is-helping-all-of-us-get-smarter-than-any-of-us-at-the-speed-of-ai/" rel="noopener ugc nofollow" target="_blank">this three-part series</a>.) Brandon <a class="af ny" href="https://bgadoci.com/thoughts/my-new-adventure-vp-of-ai-ops" rel="noopener ugc nofollow" target="_blank">just reported yesterday</a> that we’ve seen an astounding 25% increase in our team’s productivity through the use of our internal AI tools across all job roles in 2023! Adopting this type of culture will go a long way toward ensuring your organization is equipped to understand, recognize, and mitigate the threat of hallucinations.</p><p id="aa44" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">Third, you need to stay on top of the burgeoning AI ecosystem.</strong> As with any new paradigm-shifting tech, AI is surrounded by a proliferation of emerging practices, software, and processes to minimize risk and maximize value. As transformative as LLMs may become, the wonderful truth is that we’re just at the start of the long arc of AI’s evolution.</p><p id="153d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Technologies once foreign to your organization may become critical. The aforementioned <a class="af ny" href="https://data.world/blog/generative-ai-benchmark-increasing-the-accuracy-of-llms-in-the-enterprise-with-a-knowledge-graph/" rel="noopener ugc nofollow" target="_blank">benchmark</a> we released saw LLMs backed by a knowledge graph — a decades-old architecture for contextualizing data in three dimensions (mapping and relating data much like a human brain works) <em class="nz">— can improve accuracy by 300%</em>!<em class="nz"> </em>Likewise, technologies like vector databases and retrieval augmented generation (RAG) have also risen to prominence given their ability to help address the hallucination problem with LLMs. Long-term, the ambitions of AI extend far beyond the APIs of the major LLM providers available today, so remain curious and nimble in your enterprise AI investments.</p><p id="f14f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Like any new technology, generative AI solutions are not perfect, and their tendency to hallucinate poses a very real threat to their current viability for widespread enterprise deployment. However, these hallucinations shouldn’t stop organizations from experimenting and integrating these models into their workflows. Quite the opposite, in fact, as so eloquently <a class="af ny" href="https://x.com/emollick/status/1716156085445239265?s=20" rel="noopener ugc nofollow" target="_blank">stated</a> by AI pioneer and Wharton entrepreneurship professor Ethan Mollick: “…understanding comes from experimentation.” Rather, the risk hallucinations impose should act as a forcing function for enterprise decision-makers to recognize what’s at stake, take steps to mitigate that risk accordingly, and reap the early benefits of LLMs in the process. 2024 is the year that your enterprise should take the leap.</p></div></div></div></div>    
</body>
</html>