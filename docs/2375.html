<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The AI Developer’s Dilemma: Proprietary AI vs. Open Source Ecosystem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>The AI Developer’s Dilemma: Proprietary AI vs. Open Source Ecosystem</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-ai-developers-dilemma-proprietary-ai-vs-open-source-ecosystem-453ac735b760?source=collection_archive---------6-----------------------#2024-09-30">https://towardsdatascience.com/the-ai-developers-dilemma-proprietary-ai-vs-open-source-ecosystem-453ac735b760?source=collection_archive---------6-----------------------#2024-09-30</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="fr fs ft fu fv fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/f2eb22a33aaa38f31c7baa594e4409d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qk4WeIf8CzaRjVc07CWFhg.jpeg"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx"><em class="gi">Image credit: Adobe Stock.</em></figcaption></figure><div/><div><h2 id="fb7c" class="pw-subtitle-paragraph hi gk gl bf b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx cq dx"><strong class="al"><em class="gi">Fundamental choices impacting integration and deployment at scale of GenAI into businesses</em></strong></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hy hz ia ib ic ab"><div><div class="ab id"><div><div class="bm" aria-hidden="false"><a href="https://gadi-singer.medium.com/?source=post_page---byline--453ac735b760--------------------------------" rel="noopener follow"><div class="l ie if by ig ih"><div class="l ed"><img alt="Gadi Singer" class="l ep by dd de cx" src="../Images/293941f11306a6e2100c2375ccb1a85a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*eqqpUSvAcIKc79FQ"/><div class="ii by l dd de em n ij eo"/></div></div></a></div></div><div class="ik ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--453ac735b760--------------------------------" rel="noopener follow"><div class="l il im by ig in"><div class="l ed"><img alt="Towards Data Science" class="l ep by br io cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ii by l br io em n ij eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ip ab q"><div class="ab q iq"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ir is bk"><a class="af ag ah ai aj ak al am an ao ap aq ar it" data-testid="authorName" href="https://gadi-singer.medium.com/?source=post_page---byline--453ac735b760--------------------------------" rel="noopener follow">Gadi Singer</a></p></div></div></div><span class="iu iv" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ir is dx"><button class="iw ix ah ai aj ak al am an ao ap aq ar iy iz ja" disabled="">Follow</button></p></div></div></span></div></div><div class="l jb"><span class="bf b bg z dx"><div class="ab cn jc jd je"><div class="jf jg ab"><div class="bf b bg z dx ab jh"><span class="ji l jb">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar it ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--453ac735b760--------------------------------" rel="noopener follow"><p class="bf b bg z jj jk jl jm jn jo jp jq bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="iu iv" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">17 min read</span><div class="jr js l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 30, 2024</span></div></span></div></span></div></div></div><div class="ab cp jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki"><div class="h k w ea eb q"><div class="ky l"><div class="ab q kz la"><div class="pw-multi-vote-icon ed ji lb lc ld"><div class=""><div class="le lf lg lh li lj lk am ll lm ln ld"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l lo lp lq lr ls lt lu"><p class="bf b dy z dx"><span class="lf">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao le lx ly ab q ee lz ma" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lw"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lv lw">2</span></p></button></div></div></div><div class="ab q kj kk kl km kn ko kp kq kr ks kt ku kv kw kx"><div class="mb k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al mc an ao ap iy md me mf" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep mg cn"><div class="l ae"><div class="ab cb"><div class="mh mi mj mk ml gb ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al mc an ao ap iy mm mn ma mo mp mq mr ms s mt mu mv mw mx my mz u na nb nc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al mc an ao ap iy mm mn ma mo mp mq mr ms s mt mu mv mw mx my mz u na nb nc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al mc an ao ap iy mm mn ma mo mp mq mr ms s mt mu mv mw mx my mz u na nb nc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="64ff" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Before a company or a developer adopts generative artificial intelligence (GenAI), they often wonder how to get business value from the integration of AI into their business. With this in mind, a fundamental question arises: Which approach will deliver the best value on investment — a large all-encompassing proprietary model or an open source AI model that can be molded and fine-tuned for a company’s needs? AI adoption strategies fall within a wide spectrum, from accessing a cloud service from a large proprietary frontier model like <a class="af nz" href="https://openai.com/index/hello-gpt-4o/" rel="noopener ugc nofollow" target="_blank">OpenAI’s GPT-4o</a> to building an internal solution in the company’s compute environment with an open source small model using indexed company data for a targeted set of tasks. Current AI solutions go well beyond the model itself, with a whole ecosystem of retrieval systems, agents, and other functional components such as AI accelerators, which are beneficial for both large and small models. Emergence of cross-industry collaborations like the <a class="af nz" href="https://opea.dev/" rel="noopener ugc nofollow" target="_blank">Open Platform for Enterprise AI (OPEA)</a> further the promise of streamlining the access and structuring of end-to-end open source solutions.</p><p id="4d64" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This basic choice between the open source ecosystem and a proprietary setting impacts countless business and technical decisions, making it “the AI developer’s dilemma.” I believe that for most enterprise and other business deployments, it makes sense to initially use proprietary models to learn about AI’s potential and minimize early capital expenditure (CapEx). However, for broad sustained deployment, in many cases companies would use ecosystem-based open source targeted solutions, which allows for a cost-effective, adaptable strategy that aligns with evolving business needs and industry trends.</p><h2 id="c965" class="oa ob gl bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk"><strong class="al">GenAI Transition from Consumer to Business Deployment</strong></h2><p id="511f" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">When GenAI burst onto the scene in late 2022 with Open AI’s GPT-3 and ChatGPT 3.5, it mainly garnered consumer interest. As businesses began investigating GenAI, two approaches to deploying GenAI quickly emerged in 2023 — using giant frontier models like ChatGPT vs. the newly introduced small, open source models originally inspired by Meta’s LLaMa model. By early 2024, two basic approaches have solidified, as shown in the columns in Figure 1. With the proprietary AI approach, the company relies on a large closed model to provide all the needed technology value. For example, taking GPT-4o as a proxy for the left column, AI developers would use OpenAI technology for the model, data, security, and compute. With the open source ecosystem AI approach, the company or developer may opt for the right-sized open source model, using corporate or private data, customized functionality, and the necessary compute and security.</p><p id="8b83" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Both directions are valid and have advantages and disadvantages. It is not an absolute partition and developers can choose components from either approach, but taking either a proprietary or ecosystem-based open source AI path provides the company with a strategy with high internal consistency. While it is expected that both approaches will be broadly deployed, I believe that after an initial learning and transition period, most companies will follow the open source approach. Depending on the usage and setting, open source internal AI may provide significant benefits, including the ability to fine-tune the model and drive deployment using the company’s current infrastructure to run the model at the edge, on the client, in the data center, or as a dedicated service. With new AI fine-tuning tools, deep expertise is less of a barrier.</p><figure class="pb pc pd pe pf fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pa"><img src="../Images/94deab0e4f8037a024f2d918e341385c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GX8paB0ZR20Hsk54HE-DlA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx"><em class="gi">Figure 1. Base approaches to the AI developer’s dilemma. Image credit: Intel Labs.</em></figcaption></figure><p id="18d0" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Across all industries, AI developers are using GenAI for a variety of applications. An October 2023 <a class="af nz" href="https://www.gartner.com/en/newsroom/press-releases/2023-10-03-gartner-poll-finds-55-percent-of-organizations-are-in-piloting-or-production-mode-with-generative-ai" rel="noopener ugc nofollow" target="_blank">poll by Gartner</a> found that 55% of organizations reported increasing investment in GenAI since early 2023, and many companies are in pilot or production mode for the growing technology. As of the time of the survey, companies were mainly investing in using GenAI for software development, followed closely by marketing and customer service functions. Clearly, the range of AI applications is growing rapidly.</p><h2 id="7007" class="oa ob gl bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk"><strong class="al">Large Proprietary Models vs. Small and Large Open Source Models</strong></h2><figure class="pb pc pd pe pf fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pg"><img src="../Images/aae966aaa55c7c687bb93089d425b2fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QYYLFTdMxT7yg2e6UZYSzA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx"><em class="gi">Figure 2: Advantages of large proprietary models, and small and large open source models. For business considerations, see Figure 7 for CapEx and OpEx aspects. Image credit: Intel Labs.</em></figcaption></figure><p id="60b0" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In my blog <a class="af nz" rel="noopener" target="_blank" href="/survival-of-the-fittest-compact-generative-ai-models-are-the-future-for-cost-effective-ai-at-scale-6bbdc138f618">Survival of the Fittest: Compact Generative AI Models Are the Future for Cost-Effective AI at Scale</a>, I provide a detailed evaluation of large models vs. small models. In essence, following the introduction of <a class="af nz" href="https://ai.meta.com/blog/large-language-model-llama-meta-ai/" rel="noopener ugc nofollow" target="_blank">Meta’s LLaMa open source model in February 2023</a>, there has been a virtuous cycle of innovation and rapid improvement where the academia and broad-base ecosystem are creating highly effective models that are 10x to 100x smaller than the large frontier models. A crop of small models, which in 2024 were mostly less than 30 billion parameters, could <a class="af nz" href="https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/" rel="noopener ugc nofollow" target="_blank">closely match</a> the capabilities of ChatGPT-style large models containing well over 100B parameters, especially when targeted for particular domains. While GenAI is already being deployed throughout industries for a wide range of business usages, the use of compact models is rising.</p><p id="e859" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In addition, open source models are mostly lagging <a class="af nz" href="https://ark-invest.com/newsletter_item/1-openais-improved-chatgpt-should-delight-both-expert-and-novice-developers" rel="noopener ugc nofollow" target="_blank">only six to 12 months behind</a> the performance of proprietary models. Using the broad language benchmark MMLU, the improvement pace of the open source models is faster and the gap seems to be closing with proprietary models. For example, OpenAI’s <a class="af nz" href="https://openai.com/index/hello-gpt-4o/" rel="noopener ugc nofollow" target="_blank">GPT-4o</a> came out this year on May 13 with major multimodal features while Microsoft’s small open source <a class="af nz" href="https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/" rel="noopener ugc nofollow" target="_blank">Phi-3-vision</a> was introduced just a week later on May 21. In <a class="af nz" href="https://youtu.be/PZaNL6igONU?si=jCvhwvWBoZFnRG5X" rel="noopener ugc nofollow" target="_blank">rudimentary comparisons</a> done on visual recognition and understanding, the models showed some similar competencies, with several tests even favoring the Phi-3-vision model. <a class="af nz" href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" rel="noopener ugc nofollow" target="_blank">Initial evaluations of Meta’s Llama 3.2 open source release</a> suggest that its “vision models are competitive with leading foundation models, Claude 3 Haiku and GPT4o-mini on image recognition and a range of visual understanding tasks.”</p><p id="237a" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Large models have incredible all-in-one versatility. Developers can choose from a variety of large commercially available proprietary GenAI models, including OpenAI’s GPT-4o multimodal model. Google’s <a class="af nz" href="https://deepmind.google/technologies/gemini/#introduction" rel="noopener ugc nofollow" target="_blank">Gemini 1.5</a> natively multimodal model is available in four sizes: Nano for mobile device app development, Flash small model for specific tasks, Pro for a wide range of tasks, and Ultra for highly complex tasks. And Anthropic’s <a class="af nz" href="https://www.anthropic.com/news/claude-3-family" rel="noopener ugc nofollow" target="_blank">Claude 3 Opus</a>, rumored to have <a class="af nz" href="https://lifearchitect.substack.com/p/the-memo-special-edition-claude-3" rel="noopener ugc nofollow" target="_blank">approximately 2 trillion parameters</a>, has a 200K token context window, allowing users to upload large amounts of information. There’s also another category of out-of-the-box large GenAI models that businesses can use for employee productivity and creative development. <a class="af nz" href="https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/" rel="noopener ugc nofollow" target="_blank">Microsoft 365 Copilot</a> integrates the Microsoft 365 Apps suite, Microsoft Graph (content and context from emails, files, meetings, chats, calendars, and contacts), and GPT-4.</p><p id="03fc" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Most large and small open source models are often more transparent about application frameworks, tool ecosystem, training data, and evaluation platforms. Model architecture, hyperparameters, response quality, input modalities, context window size, and inference cost are partially or fully disclosed. These models often provide information on the dataset so that developers can determine if it meets copyright or quality expectations. This transparency allows developers to easily interchange models for future versions. Among the growing number of small commercially available open source models, Meta’s <a class="af nz" href="https://ai.meta.com/blog/meta-llama-3-1/" rel="noopener ugc nofollow" target="_blank">Llama 3 and 3.1</a> are based on transformer architecture and available in 8B, 70B, and 405B parameters. Llama 3.2 multimodal model has 11B and 90B, with smaller versions at 1B and 3B parameters. Built in collaboration with NVIDIA, Mistral AI’s <a class="af nz" href="https://mistral.ai/news/mistral-nemo/" rel="noopener ugc nofollow" target="_blank">Mistral NeMo</a> is a 12B model that features a large 128k context window while Microsoft’s <a class="af nz" href="https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/" rel="noopener ugc nofollow" target="_blank">Phi-3</a> (3.8B, 7B, and 14B) offers Transformer models for reasoning and language understanding tasks. Microsoft highlights Phi models as an example of “<a class="af nz" href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/" rel="noopener ugc nofollow" target="_blank">the surprising power of small language models</a>” while investing heavily in OpenAI’s very large models. Microsoft’s diverse interest in GenAI indicates that it’s not a one-size-fits-all market.</p><h2 id="927a" class="oa ob gl bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk"><strong class="al">Model-Incorporated Data (with RAG) vs. Retrieval-Centric Generation (RCG)</strong></h2><p id="7f42" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">The next key question that AI developers need to address is where to find the data used during inference — within the model parametric memory or outside the model (accessible by retrieval). It might be hard to believe, but the first ChatGPT launched in November 2022 did not have any access to data outside the model. It was trained on September 21, 2022 and notoriously had no inclination of events and data past its training date. This major oversight was addressed in 2023 when retrieval plug-ins where added. Today, most models are coupled with a retrieval front-end with exceptions in cases where there is no expectation of accessing large or continuously updating information, such as dedicated programming models.</p><p id="744a" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Current models have made significant progress on this issue by enhancing the solution platforms with a retrieval-augmented generation (RAG) front-end to allow for extracting information external to the model. An efficient and secure RAG is a requirement in enterprise GenAI deployment, as shown by Microsoft’s introduction of <a class="af nz" href="https://github.com/Azure/GPT-RAG/" rel="noopener ugc nofollow" target="_blank">GPT-RAG</a> in late 2023. Furthermore, in the blog <a class="af nz" rel="noopener" target="_blank" href="/knowledge-retrieval-takes-center-stage-183be733c6e8">Knowledge Retrieval Takes Center Stage</a>, I cover how in the transition from consumer to business deployment for GenAI, solutions should be built primarily around information external to the model using retrieval-centric generation (RCG).</p><figure class="pb pc pd pe pf fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pg"><img src="../Images/0be3876b1e8c780ab5400ce962cc804f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GmCPpetb_IvrsLOYayDMig.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Figure 3. Advantage of RAG vs. RCG. Image credit: Intel Labs.</figcaption></figure><p id="38bc" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">RCG models can be defined as a special case of RAG GenAI solutions designed for systems where the vast majority of data resides outside the model parametric memory and is mostly not seen in pre-training or fine-tuning. With RCG, the primary role of the GenAI model is to interpret rich retrieved information from a company’s indexed data corpus or other curated content. Rather than memorizing data, the model focuses on fine-tuning for targeted constructs, relationships, and functionality. The quality of data in generated output is expected to approach 100% accuracy and timeliness.</p><figure class="pb pc pd pe pf fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp ph"><img src="../Images/591e4dc8864d1884a1e060c397f19d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PCzPlqrtEwM6zHO5_j14QQ.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx"><em class="gi">Figure 4. How retrieval works in GenAI platforms. Image credit: Intel Labs.</em></figcaption></figure><p id="6345" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><a class="af nz" href="https://www.intel.com/content/www/us/en/developer/articles/news/introducing-the-open-platform-for-enterprise-ai.html" rel="noopener ugc nofollow" target="_blank">OPEA</a> is a cross-ecosystem effort to ease the adoption and tuning of GenAI systems. Using this composable framework, developers can create and evaluate “open, multi-provider, robust, and composable GenAI solutions that harness the best innovation across the ecosystem.” OPEA is expected to simplify the implementation of enterprise-grade composite GenAI solutions, including RAG, agents, and memory systems.</p><figure class="pb pc pd pe pf fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pi"><img src="../Images/51f3053a21ba51004ef80aa91d0c16d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JX0ez08uxTQ-urFbU2yxGw.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx"><em class="gi">Figure 5. OPEA core principles for GenAI implementation.</em> <em class="gi">Image credit: OPEA.</em></figcaption></figure><h2 id="f249" class="oa ob gl bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk"><strong class="al">All-in-One General Purpose vs. Targeted Customized Models</strong></h2><p id="c8b5" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Models like GPT-4o, Claude 3, and Gemini 1.5 are general purpose all-in-one foundation models. They are designed to perform a broad range of GenAI from coding to chat to summarization. The latest models have rapidly expanded to perform vision/image tasks, changing their function from just large language models to large multimodal models or vision language models (VLMs). Open source foundation models are headed in the same direction as integrated multimodalities.</p><figure class="pb pc pd pe pf fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pg"><img src="../Images/2016c69e41178f63411396e9836e74cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*grtawDbVYcTt5YLGX-6vgA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx"><em class="gi">Figure 6. Advantages of general purpose vs. targeted customized models. Image credit: Intel Labs.</em></figcaption></figure><p id="e469" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">However, rather than adopting the first wave of consumer-oriented GenAI models in this general-purpose form, most businesses are electing to use some form of specialization. When a healthcare company deploys GenAI technology, they would not use one general model for managing the supply chain, coding in the IT department, and deep medical analytics for managing patient care. Businesses deploy more specialized versions of the technology for each use case. There are several different ways that companies can build specialized GenAI solutions, including domain-specific models, targeted models, customized models, and optimized models.</p><p id="3529" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="pj">Domain-specific models</em> are specialized for a particular field of business or an area of interest. There are both proprietary and open source domain-specific models. For example, BloombergGPT, a 50B parameter proprietary large language model specialized for finance, <a class="af nz" href="https://arxiv.org/pdf/2303.17564.pdf" rel="noopener ugc nofollow" target="_blank">beats the larger GPT-3 175B parameter model</a> on various financial benchmarks. However, small open source domain-specific models can provide an excellent alternative, as demonstrated by <a class="af nz" href="https://arxiv.org/pdf/2306.06031.pdf" rel="noopener ugc nofollow" target="_blank">FinGPT</a>, which provides accessible and transparent resources to develop FinLLMs. FinGPT 3.3 uses Llama 2 13B as a base model targeted for the financial sector. <a class="af nz" href="https://github.com/AI4Finance-Foundation/FinGPT" rel="noopener ugc nofollow" target="_blank">In recent benchmarks</a>, FinGPT surpassed BloombergGPT on a variety of tasks and beat GPT-4 handily on financial benchmark tasks like FPB, FiQA-SA, and TFNS. To understand the tremendous potential of this small open source model, it should be noted that FinGPT can be fine-tuned to incorporate new data for less than $300 per fine-tuning.</p><p id="9d9d" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="pj">Targeted models</em> specialize in a family of tasks or functions, such as separate targeted models for <a class="af nz" href="https://huggingface.co/docs/transformers/v4.39.0/en/model_doc/starcoder2" rel="noopener ugc nofollow" target="_blank">coding</a>, image generation, question answering, or sentiment analysis. A recent example of a targeted model is <a class="af nz" href="https://huggingface.co/blog/setfit" rel="noopener ugc nofollow" target="_blank">SetFit</a> from Intel Labs, Hugging Face, and the UKP Lab. This few-shot text classification approach for fine-tuning Sentence Transformers is faster at inference and training, achieving high accuracy with a small number of labeled training data, such as only eight labeled examples per class on the Customer Reviews (CR) sentiment dataset. This small 355M parameter model can best the GPT-3 175B parameter model on the diverse RAFT benchmark.</p><p id="d505" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">It’s important to note that targeted models are independent from domain-specific models. For example, a sentiment analysis solution like <a class="af nz" href="https://huggingface.co/blog/setfit-absa" rel="noopener ugc nofollow" target="_blank">SetFitABSA</a> has targeted functionality and can be applied to various domains like industrial, entertainment, or hospitality. However, models that are both targeted and domain specialized can be more effective.</p><p id="4b9d" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="pj">Customized models</em> are further fine-tuned and refined to meet particular needs and preferences of companies, organizations, or individuals. By indexing particular content for retrieval, the resulting system becomes highly specific and effective on tasks related to this data (private or public). The open source field offers an array of options to customize the model. For example, Intel Labs used direct preference optimization (DPO) to improve on a Mistral 7B model to create the open source <a class="af nz" href="https://huggingface.co/Intel/neural-chat-7b-v3-1" rel="noopener ugc nofollow" target="_blank">Intel NeuralChat</a>. Developers also can fine-tune and customize models by using low-rank adaptation of large language (<a class="af nz" href="https://arxiv.org/abs/2106.09685" rel="noopener ugc nofollow" target="_blank">LoRA</a>) models and its more memory-efficient version, <a class="af nz" href="https://arxiv.org/abs/2305.14314" rel="noopener ugc nofollow" target="_blank">QLoRA</a>.</p><p id="de60" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="pj">Optimization capabilities</em> are available for open source models. The objective of optimization is to retain the functionality and accuracy of a model while substantially reducing its execution footprint, which can significantly improve cost, latency, and optimal execution of an intended platform. Some techniques used for model optimization include distillation, pruning, compression, and quantization (to 8-bit and even 4-bit). Some methods like mixture of experts (MoE) and <a class="af nz" href="https://arxiv.org/pdf/2211.17192.pdf" rel="noopener ugc nofollow" target="_blank">speculative decoding</a> can be considered as forms of execution optimization. For example, <a class="af nz" href="https://the-decoder.com/gpt-4-has-a-trillion-parameters/" rel="noopener ugc nofollow" target="_blank">GPT-4 is reportedly comprised</a> of eight smaller MoE models with 220B parameters. The execution only activates parts of the model, allowing for much more economical inference.</p><h2 id="d3bd" class="oa ob gl bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk"><strong class="al">Generative-as-a-Service Cloud Execution vs. Managed Execution Environment for Inference</strong></h2><figure class="pb pc pd pe pf fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pg"><img src="../Images/8292f287c7dbbac24afcde2430ef2789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eu7lv14XuCM4sBQCnGqn2g.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx"><em class="gi">Figure 7. Advantages of GaaS vs. managed execution. Image credit: Intel Labs.</em></figcaption></figure><p id="b040" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Another key choice for developers to consider is the execution environment. If the company chooses a proprietary model direction, inference execution is done through API or query calls to an abstracted and obscured image of the model running in the cloud. The size of the model and other implementation details are insignificant, except when translated to availability and the cost charged by some key (per token, per query, or unlimited compute license). This approach, sometimes referred to as a <a class="af nz" href="https://www.forbes.com/sites/steveandriole/2023/07/26/llama-chatgpt-bard-co-pilot--all-the-rest--how-large-language-models-will-become-huge-cloud-services-with-massive-ecosystems/?sh=78764e1175b7" rel="noopener ugc nofollow" target="_blank">generative-as-a-service (GaaS)</a> cloud offering, is the principle way for companies to consume very large proprietary models like GPT-4o, Gemini Ultra, and Claude 3. However, GaaS can also be offered for smaller models like Llama 3.2.</p><p id="cce8" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">There are clear positive aspects to using GaaS for the outsourced intelligence approach. For example, the access is usually instantaneous and easy to use out-of-the-box, alleviating in-house development efforts. There is also the implied promise that when the models or their environment get upgraded, the AI solution developers have access to the latest updates without substantial effort or changes to their setup. Also, the costs are almost entirely operational expenditures (OpEx), which is preferred if the workload is initial or limited. For early-stage adoption and intermittent use, GaaS offers more support.</p><p id="cf34" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In contrast, when companies choose an internal intelligence approach, the model inference cycle is incorporated and managed within the compute environment and the existing business software setting. This is a viable solution for relatively small models (approximately 30B parameters or less in 2024) and potentially even medium models (50B to 70B parameters in 2024) on a client device, network, on-prem data center, or on-cloud cycles in an environment set with a service provider such as a virtual private cloud (VPC).</p><p id="2676" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Models like Llama 3.1 8B or similar can run on the <a class="af nz" href="https://www.forbes.com/sites/steveandriole/2023/07/26/llama-chatgpt-bard-co-pilot--all-the-rest--how-large-language-models-will-become-huge-cloud-services-with-massive-ecosystems/?sh=78764e1175b7" rel="noopener ugc nofollow" target="_blank">developer’s local machine</a> (Mac or PC). Using optimization techniques like <a class="af nz" href="https://www.intel.com/content/www/us/en/developer/articles/case-study/q8-chat-efficient-generative-ai-experience-xeon.html#gs.36q4lk" rel="noopener ugc nofollow" target="_blank">quantization</a>, the needed user experience can be achieved while operating within the local setting. Using a tool and framework like <a class="af nz" href="https://ollama.ai/" rel="noopener ugc nofollow" target="_blank">Ollama</a>, developers can manage inference execution locally. Inference cycles can be run on legacy GPUs, <a class="af nz" href="https://www.intel.com/content/www/us/en/products/docs/processors/xeon-accelerated/ai-accelerators-product-brief.html" rel="noopener ugc nofollow" target="_blank">Intel Xeon</a>, or <a class="af nz" href="https://www.intel.com/content/www/us/en/products/details/processors/ai-accelerators/gaudi-overview.html" rel="noopener ugc nofollow" target="_blank">Intel Gaudi AI accelerators</a> in the company’s data center. If inference is run on the model at a service provider, it will be billed as infrastructure-as-a-service (IaaS), using the company’s own setting and execution choices.</p><p id="2222" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When inference execution is done in the company compute environment (client, edge, on-prem, or IaaS), there is a higher requirement for CapEx for ownership of the computer equipment if it goes beyond adding a workload to existing hardware. While the comparison of OpEx vs. CapEx is complex and depends on many variables, CapEx is preferable when deployment requires broad, continuous, stable usage. This is especially true as smaller models and optimization technologies allow for running advanced open source models on mainstream devices and processors and even local notebooks/desktops.</p><p id="7ca9" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Running inference in the company compute environment allows for tighter control over aspects of security and privacy. Reducing data movement and exposure can be valuable in preserving privacy. Furthermore, a retrieval-based AI solution run in a local setting can be supported with fine controls to address potential privacy concerns by giving user-controlled access to information. Security is frequently mentioned as one of the top concerns of companies deploying GenAI and <a class="af nz" href="https://www.intel.com/content/dam/www/public/us/en/documents/solution-briefs/intro-to-confidential-computing-solution-brief.pdf" rel="noopener ugc nofollow" target="_blank">confidential computing</a> is a primary ask. Confidential computing protects data in use by computing in an attested hardware-based <a class="af nz" href="https://www.intel.com/content/www/us/en/content-details/788130/what-is-a-trusted-execution-environment.html" rel="noopener ugc nofollow" target="_blank">Trusted Execution Environment (TEE)</a>.</p><p id="50d0" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Smaller, open source models can run within a company’s most secure application setting. For example, a model running on Xeon can be fully executed within a TEE with limited overhead. As shown in Figure 8, encrypted data remains protected while not in compute. The model is checked for provenance and integrity to protect against tampering. The actual execution is protected from any breach, including by the operating system or other applications, preventing viewing or alteration by untrusted entities.</p><figure class="pb pc pd pe pf fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pg"><img src="../Images/918a31fbc46ec6dc9d1ca7a229f2ca46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iESqm-hxcVZYQJL-CRoGxg.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Figure 8. Security requirements for GenAI. Image credit: Intel Labs.</figcaption></figure><h2 id="90c9" class="oa ob gl bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk"><strong class="al">Summary</strong></h2><p id="94ba" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Generative AI is a transformative technology now under evaluation or active adoption by most companies across all industries and sectors. As AI developers consider their options for the best solution, one of the most important questions they need to address is whether to use external proprietary models or rely on the open source ecosystem. One path is to rely on a large proprietary black-box GaaS solution using RAG, such as GPT-4o or Gemini Ultra. The other path uses a more adaptive and integrative approach — small, selected, and exchanged as needed from a large open source model pool, mainly utilizing company information, customized and optimized based on particular needs, and executed within the existing infrastructure of the company. As mentioned, there could be a combination of choices within these two base strategies.</p><p id="f641" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">I believe that as numerous AI solution developers face this essential dilemma, most will eventually (after a learning period) choose to embed open source GenAI models in their internal compute environment, data, and business setting. They will ride the incredible advancement of the open source and broad ecosystem virtuous cycle of AI innovation, while maintaining control over their costs and destiny.</p><p id="e4ed" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s give AI the final word in solving the AI developer’s dilemma. In a <a class="af nz" href="https://pub.aimind.so/gpt-4-debates-open-orca-2-13b-with-surprising-results-b4ada53845ba" rel="noopener ugc nofollow" target="_blank">staged AI debate</a>, OpenAI’s GPT-4 argued with Microsoft’s open source Orca 2 13B on the merits of using proprietary vs. open source GenAI for future development. Using GPT-4 Turbo as the judge, open source GenAI won the debate. The <a class="af nz" href="https://youtu.be/JuwJLeVlB-w?t=774" rel="noopener ugc nofollow" target="_blank">winning argument</a>? Orca 2 called for a “more distributed, open, collaborative future of AI development that leverages worldwide talent and aims for collective advancements. This model promises to accelerate innovation and democratize access to AI, and ensure ethical and transparent practices through community governance.”</p><h2 id="11a7" class="oa ob gl bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk"><strong class="al">Learn More: GenAI Series</strong></h2><p id="c5a5" class="pw-post-body-paragraph nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk"><a class="af nz" rel="noopener" target="_blank" href="/knowledge-retrieval-takes-center-stage-183be733c6e8">Knowledge Retrieval Takes Center Stage: GenAI Architecture Shifting from RAG Toward Interpretive Retrieval-Centric Generation (RCG) Models</a></p><p id="75a7" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><a class="af nz" rel="noopener" target="_blank" href="/survival-of-the-fittest-compact-generative-ai-models-are-the-future-for-cost-effective-ai-at-scale-6bbdc138f618">Survival of the Fittest: Compact Generative AI Models Are the Future for Cost-Effective AI at Scale</a></p><p id="f532" class="pw-post-body-paragraph nd ne gl nf b hj ng nh ni hm nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><a class="af nz" rel="noopener" target="_blank" href="/have-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4">Have Machines Just Made an Evolutionary Leap to Speak in Human Language?</a></p><h2 id="3cee" class="oa ob gl bf oc od oe of og oh oi oj ok nm ol om on nq oo op oq nu or os ot ou bk"><strong class="al">References</strong></h2><ol class=""><li id="6760" class="nd ne gl nf b hj ov nh ni hm ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny pk pl pm bk">Hello GPT-4o. (2024, May 13). <a class="af nz" href="https://openai.com/index/hello-gpt-4o/" rel="noopener ugc nofollow" target="_blank">https://openai.com/index/hello-gpt-4o/</a></li><li id="7c70" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Open platform for enterprise AI. (n.d.). Open Platform for Enterprise AI (OPEA). <a class="af nz" href="https://opea.dev/" rel="noopener ugc nofollow" target="_blank">https://opea.dev/</a></li><li id="272e" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Gartner Poll Finds 55% of Organizations are in Piloting or Production. (2023, October 3). Gartner. <a class="af nz" href="https://www.gartner.com/en/newsroom/press-releases/2023-10-03-gartner-poll-finds-55-percent-of-organizations-are-in-piloting-or-production-mode-with-generative-ai" rel="noopener ugc nofollow" target="_blank">https://www.gartner.com/en/newsroom/press-releases/2023-10-03-gartner-poll-finds-55-percent-of-organizations-are-in-piloting-or-production-mode-with-generative-ai</a></li><li id="1ac7" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Singer, G. (2023, July 28). Survival of the fittest: Compact generative AI models are the future for Cost-Effective AI at scale. <em class="pj">Medium</em>. <a class="af nz" rel="noopener" target="_blank" href="/survival-of-the-fittest-compact-generative-ai-models-are-the-future-for-cost-effective-ai-at-scale-6bbdc138f618">https://towardsdatascience.com/survival-of-the-fittest-compact-generative-ai-models-are-the-future-for-cost-effective-ai-at-scale-6bbdc138f618</a></li><li id="05c9" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Introducing LLaMA: A foundational, 65-billion-parameter language model. (n.d.). <a class="af nz" href="https://ai.meta.com/blog/large-language-model-llama-meta-ai/" rel="noopener ugc nofollow" target="_blank">https://ai.meta.com/blog/large-language-model-llama-meta-ai/</a></li><li id="0b41" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">#392: OpenAI’s improved ChatGPT should delight both expert and novice developers, &amp; more — ARK Invest. (n.d.). Ark Invest. <a class="af nz" href="https://ark-invest.com/newsletter_item/1-openais-improved-chatgpt-should-delight-both-expert-and-novice-developers" rel="noopener ugc nofollow" target="_blank">https://ark-invest.com/newsletter_item/1-openais-improved-chatgpt-should-delight-both-expert-and-novice-developers</a></li><li id="b699" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Bilenko, M. (2024, May 22). New models added to the Phi-3 family, available on Microsoft Azure. Microsoft Azure Blog. <a class="af nz" href="https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/" rel="noopener ugc nofollow" target="_blank">https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/</a></li><li id="00b1" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Matthew Berman. (2024, June 2). Open-Source Vision AI — Surprising Results! (Phi3 Vision vs LLaMA 3 Vision vs GPT4o) [Video]. YouTube. <a class="af nz" href="https://www.youtube.com/watch?v=PZaNL6igONU" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=PZaNL6igONU</a></li><li id="9a3e" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Llama 3.2: Revolutionizing edge AI and vision with open, customizable models. (n.d.). <a class="af nz" href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" rel="noopener ugc nofollow" target="_blank">https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/</a></li><li id="131e" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Gemini — Google DeepMind. (n.d.). <a class="af nz" href="https://deepmind.google/technologies/gemini/#introduction" rel="noopener ugc nofollow" target="_blank">https://deepmind.google/technologies/gemini/#introduction</a></li><li id="a7a6" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Introducing the next generation of Claude \ Anthropic. (n.d.). <a class="af nz" href="https://www.anthropic.com/news/claude-3-family" rel="noopener ugc nofollow" target="_blank">https://www.anthropic.com/news/claude-3-family</a></li><li id="9f1c" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Thompson, A. D. (2024, March 4). The Memo — Special edition: Claude 3 Opus. The Memo by LifeArchitect.ai. <a class="af nz" href="https://lifearchitect.substack.com/p/the-memo-special-edition-claude-3" rel="noopener ugc nofollow" target="_blank">https://lifearchitect.substack.com/p/the-memo-special-edition-claude-3</a></li><li id="3645" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Spataro, J. (2023, May 16). Introducing Microsoft 365 Copilot — your copilot for work — The Official Microsoft Blog. The Official Microsoft Blog. <a class="af nz" href="https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/" rel="noopener ugc nofollow" target="_blank">https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/</a></li><li id="1101" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Introducing Llama 3.1: Our most capable models to date. (n.d.). <a class="af nz" href="https://ai.meta.com/blog/meta-llama-3-1/" rel="noopener ugc nofollow" target="_blank">https://ai.meta.com/blog/meta-llama-3-1/</a></li><li id="bd01" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Mistral AI. (2024, March 4). Mistral Nemo. Mistral AI | Frontier AI in Your Hands. <a class="af nz" href="https://mistral.ai/news/mistral-nemo/" rel="noopener ugc nofollow" target="_blank">https://mistral.ai/news/mistral-nemo/</a></li><li id="cf30" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Beatty, S. (2024, April 29). Tiny but mighty: The Phi-3 small language models with big potential. Microsoft Research. <a class="af nz" href="https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/" rel="noopener ugc nofollow" target="_blank">https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/</a></li><li id="0d03" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Hughes, A. (2023, December 16). Phi-2: The surprising power of small language models. Microsoft Research. <a class="af nz" href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/" rel="noopener ugc nofollow" target="_blank">https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/</a></li><li id="5c40" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Azure. (n.d.). GitHub — Azure/GPT-RAG. GitHub. <a class="af nz" href="https://github.com/Azure/GPT-RAG/" rel="noopener ugc nofollow" target="_blank">https://github.com/Azure/GPT-RAG/</a></li><li id="cae0" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Singer, G. (2023, November 16). Knowledge Retrieval Takes Center Stage — Towards Data Science. Medium. <a class="af nz" rel="noopener" target="_blank" href="/knowledge-retrieval-takes-center-stage-183be733c6e8">https://towardsdatascience.com/knowledge-retrieval-takes-center-stage-183be733c6e8</a></li><li id="0253" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Introducing the open platform for enterprise AI. (n.d.). Intel. <a class="af nz" href="https://www.intel.com/content/www/us/en/developer/articles/news/introducing-the-open-platform-for-enterprise-ai.html" rel="noopener ugc nofollow" target="_blank">https://www.intel.com/content/www/us/en/developer/articles/news/introducing-the-open-platform-for-enterprise-ai.html</a></li><li id="d531" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Wu, S., Irsoy, O., Lu, S., Dabravolski, V., Dredze, M., Gehrmann, S., Kambadur, P., Rosenberg, D., &amp; Mann, G. (2023, March 30). BloombergGPT: A large language model for finance. arXiv.org. <a class="af nz" href="https://arxiv.org/abs/2303.17564" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2303.17564</a></li><li id="e20e" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Yang, H., Liu, X., &amp; Wang, C. D. (2023, June 9). FINGPT: Open-Source Financial Large Language Models. arXiv.org. <a class="af nz" href="https://arxiv.org/abs/2306.06031" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2306.06031</a></li><li id="9cfe" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">AI4Finance-Foundation. (n.d.). FinGPT. GitHub. <a class="af nz" href="https://github.com/AI4Finance-Foundation/FinGPT" rel="noopener ugc nofollow" target="_blank">https://github.com/AI4Finance-Foundation/FinGPT</a></li><li id="cd30" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Starcoder2. (n.d.). GitHub. <a class="af nz" href="https://huggingface.co/docs/transformers/v4.39.0/en/model_doc/starcoder2" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/docs/transformers/v4.39.0/en/model_doc/starcoder2</a></li><li id="4328" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">SetFit: Efficient Few-Shot Learning Without Prompts. (n.d.). <a class="af nz" href="https://huggingface.co/blog/setfit" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/setfit</a></li><li id="72f2" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">SetFitABSA: Few-Shot Aspect Based Sentiment Analysis Using SetFit. (n.d.). <a class="af nz" href="https://huggingface.co/blog/setfit-absa" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/setfit-absa</a></li><li id="33e5" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Intel/neural-chat-7b-v3–1. Hugging Face. (2023, October 12). <a class="af nz" href="https://huggingface.co/Intel/neural-chat-7b-v3-1" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/Intel/neural-chat-7b-v3-1</a></li><li id="0a94" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., &amp; Chen, W. (2021, June 17). LORA: Low-Rank adaptation of Large Language Models. arXiv.org. <a class="af nz" href="https://arxiv.org/abs/2106.09685" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2106.09685</a></li><li id="0d42" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Dettmers, T., Pagnoni, A., Holtzman, A., &amp; Zettlemoyer, L. (2023, May 23). QLORA: Efficient Finetuning of Quantized LLMS. arXiv.org. <a class="af nz" href="https://arxiv.org/abs/2305.14314" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2305.14314</a></li><li id="c6d1" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Leviathan, Y., Kalman, M., &amp; Matias, Y. (2022, November 30). Fast Inference from Transformers via Speculative Decoding. arXiv.org. <a class="af nz" href="https://arxiv.org/abs/2211.17192" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2211.17192</a></li><li id="5872" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Bastian, M. (2023, July 3). GPT-4 has more than a trillion parameters — Report. THE DECODER. <a class="af nz" href="https://the-decoder.com/gpt-4-has-a-trillion-parameters/" rel="noopener ugc nofollow" target="_blank">https://the-decoder.com/gpt-4-has-a-trillion-parameters/</a></li><li id="0761" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Andriole, S. (2023, September 12). LLAMA, ChatGPT, Bard, Co-Pilot &amp; all the rest. How large language models will become huge cloud services with massive ecosystems. Forbes. <a class="af nz" href="https://www.forbes.com/sites/steveandriole/2023/07/26/llama-chatgpt-bard-co-pilot--all-the-rest--how-large-language-models-will-become-huge-cloud-services-with-massive-ecosystems/?sh=78764e1175b7" rel="noopener ugc nofollow" target="_blank">https://www.forbes.com/sites/steveandriole/2023/07/26/llama-chatgpt-bard-co-pilot--all-the-rest--how-large-language-models-will-become-huge-cloud-services-with-massive-ecosystems/?sh=78764e1175b7</a></li><li id="47e6" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Q8-Chat LLM: An efficient generative AI experience on Intel® CPUs. (n.d.). Intel. <a class="af nz" href="https://www.intel.com/content/www/us/en/developer/articles/case-study/q8-chat-efficient-generative-ai-experience-xeon.html#gs.36q4lk" rel="noopener ugc nofollow" target="_blank">https://www.intel.com/content/www/us/en/developer/articles/case-study/q8-chat-efficient-generative-ai-experience-xeon.html#gs.36q4lk</a></li><li id="4f4d" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Ollama. (n.d.). Ollama. <a class="af nz" href="https://ollama.com/" rel="noopener ugc nofollow" target="_blank">https://ollama.com/</a></li><li id="f14a" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">AI Accelerated Intel® Xeon® Scalable Processors Product Brief. (n.d.). Intel. <a class="af nz" href="https://www.intel.com/content/www/us/en/products/docs/processors/xeon-accelerated/ai-accelerators-product-brief.html" rel="noopener ugc nofollow" target="_blank">https://www.intel.com/content/www/us/en/products/docs/processors/xeon-accelerated/ai-accelerators-product-brief.html</a></li><li id="3d83" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Intel® Gaudi® AI Accelerator products. (n.d.). Intel. <a class="af nz" href="https://www.intel.com/content/www/us/en/products/details/processors/ai-accelerators/gaudi-overview.html" rel="noopener ugc nofollow" target="_blank">https://www.intel.com/content/www/us/en/products/details/processors/ai-accelerators/gaudi-overview.html</a></li><li id="7c46" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Confidential Computing Solutions — Intel. (n.d.). Intel. <a class="af nz" href="https://www.intel.com/content/www/us/en/security/confidential-computing.html" rel="noopener ugc nofollow" target="_blank">https://www.intel.com/content/www/us/en/security/confidential-computing.html</a></li><li id="57cc" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">What is a Trusted Execution Environment? (n.d.). Intel. <a class="af nz" href="https://www.intel.com/content/www/us/en/content-details/788130/what-is-a-trusted-execution-environment.html" rel="noopener ugc nofollow" target="_blank">https://www.intel.com/content/www/us/en/content-details/788130/what-is-a-trusted-execution-environment.html</a></li><li id="1095" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Adeojo, J. (2023, December 3). GPT-4 Debates Open Orca-2–13B with Surprising Results! Medium. <a class="af nz" href="https://pub.aimind.so/gpt-4-debates-open-orca-2-13b-with-surprising-results-b4ada53845ba" rel="noopener ugc nofollow" target="_blank">https://pub.aimind.so/gpt-4-debates-open-orca-2-13b-with-surprising-results-b4ada53845ba</a></li><li id="b34a" class="nd ne gl nf b hj pn nh ni hm po nk nl nm pp no np nq pq ns nt nu pr nw nx ny pk pl pm bk">Data Centric. (2023, November 30). Surprising Debate Showdown: GPT-4 Turbo vs. Orca-2–13B — Programmed with AutoGen! [Video]. YouTube. <a class="af nz" href="https://www.youtube.com/watch?v=JuwJLeVlB-w" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=JuwJLeVlB-w</a></li></ol></div></div></div></div>    
</body>
</html>