["```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Create and prepare dataset\ndataset_dict = {\n    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', \n                'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy',\n                'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast',\n                'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],\n    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,\n                   72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,\n                   88.0, 77.0, 79.0, 80.0, 66.0, 84.0],\n    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,\n                 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,\n                 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n    'Wind': [False, True, False, False, False, True, True, False, False, False, True,\n             True, False, True, True, False, False, True, False, True, True, False,\n             True, False, False, True, False, False],\n    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',\n             'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',\n             'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']\n}\n\n# Prepare data\ndf = pd.DataFrame(dataset_dict)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\ndf = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)\ndf['Wind'] = df['Wind'].astype(int)\ndf['Play'] = (df['Play'] == 'Yes').astype(int)\n\n# Rearrange columns\ncolumn_order = ['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind', 'Play']\ndf = df[column_order]\n\n# Prepare features and target\nX,y = df.drop('Play', axis=1), df['Play']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\n\n# Scale numerical features\nscaler = StandardScaler()\nX_train[['Temperature', 'Humidity']] = scaler.fit_transform(X_train[['Temperature', 'Humidity']])\nX_test[['Temperature', 'Humidity']] = scaler.transform(X_test[['Temperature', 'Humidity']])\n```", "```py\nfrom sklearn.dummy import DummyClassifier\nimport pandas as pd\nimport numpy as np\n\n# Train the model\ndummy_clf = DummyClassifier(strategy='stratified', random_state=42)\ndummy_clf.fit(X_train, y_train)\n\n# Print the \"model\" - which is just the class probabilities\nprint(\"THE MODEL:\")\nprint(f\"Probability of not playing (class 0): {dummy_clf.class_prior_[0]:.3f}\")\nprint(f\"Probability of playing (class 1): {dummy_clf.class_prior_[1]:.3f}\")\nprint(\"\\nNOTE: These probabilities are used for ALL predictions, regardless of input features!\")\n\n# Make predictions and get probabilities\ny_pred = dummy_clf.predict(X_test)\ny_prob = dummy_clf.predict_proba(X_test)\n\n# Create results dataframe\nresults_df = pd.DataFrame({\n    'True Label': y_test,\n    'Prediction': y_pred,\n    'Probability of Play': y_prob[:, 1]\n})\n\nprint(\"\\nPrediction Results:\")\nprint(results_df)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\nfrom sklearn.neighbors import KNeighborsClassifier\nimport pandas as pd\nimport numpy as np\n\n# Train the model\nk = 3  # number of neighbors\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train, y_train)\n\n# Print the \"model\"\nprint(\"THE MODEL:\")\nprint(f\"Number of neighbors (k): {k}\")\nprint(f\"Training data points stored: {len(X_train)}\")\n\n# Make predictions and get probabilities\ny_pred = knn.predict(X_test)\ny_prob = knn.predict_proba(X_test)\n\n# Create results dataframe\nresults_df = pd.DataFrame({\n   'True Label': y_test,\n   'Prediction': y_pred,\n   'Probability of Play': y_prob[:, 1]\n})\n\nprint(\"\\nPrediction Results:\")\nprint(results_df)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\nfrom sklearn.naive_bayes import BernoulliNB\nimport pandas as pd\n\n# Train the model\nnb = BernoulliNB()\nnb.fit(X_train, y_train)\n\n# Print the \"model\"\nprint(\"THE MODEL:\")\ndf = pd.DataFrame(\n   nb.feature_log_prob_.T, \n   columns=['Log Prob (No Play)', 'Log Prob (Play)'], \n   index=['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind']\n)\ndf = df.round(3)\nprint(\"\\nFeature Log-Probabilities:\")\nprint(df)\n\nprint(\"\\nClass Priors:\")\npriors = pd.Series(nb.class_log_prior_, index=['No Play', 'Play']).round(3)\nprint(priors)\n\n# Make predictions and get probabilities\ny_pred = nb.predict(X_test)\ny_prob = nb.predict_proba(X_test)\n\n# Create results dataframe\nresults_df = pd.DataFrame({\n   'True Label': y_test,\n   'Prediction': y_pred,\n   'Probability of Play': y_prob[:, 1]\n})\n\nprint(\"\\nPrediction Results:\")\nprint(results_df)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Train the model\ndt = DecisionTreeClassifier(random_state=42, max_depth=3)  # limiting depth for visibility\ndt.fit(X_train, y_train)\n\n# Print the \"model\" - visualize the decision tree\nprint(\"THE MODEL (DECISION TREE STRUCTURE):\")\nplt.figure(figsize=(20,10))\nplot_tree(dt, feature_names=['sunny', 'overcast', 'rainy', 'Temperature', \n                           'Humidity', 'Wind'], \n         class_names=['No Play', 'Play'],\n         filled=True, rounded=True, fontsize=10)\nplt.show()\n\n# Make predictions and get probabilities\ny_pred = dt.predict(X_test)\ny_prob = dt.predict_proba(X_test)\n\n# Create results dataframe\nresults_df = pd.DataFrame({\n   'True Label': y_test,\n   'Prediction': y_pred,\n   'Probability of Play': y_prob[:, 1]\n})\n\nprint(\"\\nPrediction Results:\")\nprint(results_df)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nimport pandas as pd\n\n# Train the model\nlr = LogisticRegression(random_state=42)\nlr.fit(X_train, y_train)\n\n# Print the \"model\"\nprint(\"THE MODEL:\")\nmodel_df = pd.DataFrame({\n   'Feature': ['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind'],\n   'Coefficient': lr.coef_[0]\n})\nmodel_df['Coefficient'] = model_df['Coefficient'].round(3)\nprint(\"Coefficients (weights):\")\nprint(model_df)\n\nprint(f\"\\nIntercept (bias): {lr.intercept_[0]:.3f}\")\nprint(\"\\nPrediction = sigmoid(intercept + sum(coefficient * feature_value))\")\n\n# Make predictions and get probabilities\ny_pred = lr.predict(X_test)\ny_prob = lr.predict_proba(X_test)\n\n# Create results dataframe\nresults_df = pd.DataFrame({\n   'True Label': y_test,\n   'Prediction': y_pred,\n   'Probability of Play': y_prob[:, 1]\n})\n\nprint(\"\\nPrediction Results:\")\nprint(results_df)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\nfrom sklearn.svm import SVC\nimport pandas as pd\nimport numpy as np\n\n# Train the model\nsvm = SVC(kernel='rbf', probability=True, random_state=42)\nsvm.fit(X_train, y_train)\n\n# Print the \"model\"\nprint(\"THE MODEL:\")\nprint(f\"Kernel: {svm.kernel}\")\nprint(f\"Number of support vectors: {svm.n_support_}\")\nprint(\"\\nSupport Vectors (showing first 5 rows):\")\n\n# Create dataframe of support vectors\nsv_df = pd.DataFrame(\n   svm.support_vectors_,\n   columns=['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind']\n)\nprint(sv_df.head().round(3))\n\n# Show which classes these support vectors belong to\nprint(\"\\nSupport vector classes:\")\nfor i, count in enumerate(svm.n_support_):\n   print(f\"Class {i}: {count} support vectors\")\n\n# Make predictions and get probabilities\ny_pred = svm.predict(X_test)\ny_prob = svm.predict_proba(X_test)\n\n# Create results dataframe\nresults_df = pd.DataFrame({\n   'True Label': y_test,\n   'Prediction': y_pred,\n   'Probability of Play': y_prob[:, 1]\n})\n\nprint(\"\\nPrediction Results:\")\nprint(results_df)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\nfrom sklearn.neural_network import MLPClassifier\nimport pandas as pd\nimport numpy as np\n\n# Train the model with a simple architecture\nmlp = MLPClassifier(hidden_layer_sizes=(4,2), random_state=42)\nmlp.fit(X_train, y_train)\n\n# Print the \"model\"\nprint(\"THE MODEL:\")\nprint(\"Network Architecture:\")\nprint(f\"Input Layer: {mlp.n_features_in_} neurons (features)\")\nfor i, layer_size in enumerate(mlp.hidden_layer_sizes):\n   print(f\"Hidden Layer {i+1}: {layer_size} neurons\")\nprint(f\"Output Layer: {mlp.n_outputs_} neurons (classes)\")\n\n# Show weights for first hidden layer\nprint(\"\\nWeights from Input to First Hidden Layer:\")\nweights_df = pd.DataFrame(\n   mlp.coefs_[0],\n   columns=[f'Hidden_{i+1}' for i in range(mlp.hidden_layer_sizes[0])],\n   index=['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind']\n)\nprint(weights_df.round(3))\n\nprint(\"\\nNote: Additional weights and biases exist between subsequent layers\")\n\n# Make predictions and get probabilities\ny_pred = mlp.predict(X_test)\ny_prob = mlp.predict_proba(X_test)\n\n# Create results dataframe\nresults_df = pd.DataFrame({\n   'True Label': y_test,\n   'Prediction': y_pred,\n   'Probability of Play': y_prob[:, 1]\n})\n\nprint(\"\\nPrediction Results:\")\nprint(results_df)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```", "```py\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\n\n# The models\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\n\n# Load and prepare data\ndataset_dict = {\n    'Outlook': ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy', 'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast', 'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'],\n    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],\n    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],\n    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']\n}\ndf = pd.DataFrame(dataset_dict)\ndf = pd.get_dummies(df, columns=['Outlook'], prefix='', prefix_sep='', dtype=int)\ndf['Wind'] = df['Wind'].astype(int)\ndf['Play'] = (df['Play'] == 'Yes').astype(int)\n\n# Prepare features and target\nX,y = df.drop('Play', axis=1), df['Play']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\n\n# Scale numerical features\nscaler = StandardScaler()\nX_train[['Temperature', 'Humidity']] = scaler.fit_transform(X_train[['Temperature', 'Humidity']])\nX_test[['Temperature', 'Humidity']] = scaler.transform(X_test[['Temperature', 'Humidity']])\n\n# Train the model\nclf = DummyClassifier(strategy='stratified', random_state=42)\n# clf = KNeighborsClassifier(n_neighbors=3)\n# clf = BernoulliNB()\n# clf = DecisionTreeClassifier(random_state=42, max_depth=3)\n# clf = LogisticRegression(random_state=42)\n# clf = SVC(kernel='rbf', probability=True, random_state=42)\n# clf = MLPClassifier(hidden_layer_sizes=(4,2), random_state=42)\n\n# Fit and predict\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\ny_prob = clf.predict_proba(X_test)\n\n# Create results dataframe\nresults_df = pd.DataFrame({\n   'True Label': y_test,\n   'Prediction': y_pred,\n   'Probability of Play': y_prob[:, 1]\n})\n\nprint(\"\\nPrediction Results:\")\nprint(results_df)\n\n# Print accuracy\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n```"]