# 语言模型是基准测试天才还是现实世界问题解决者？

> 原文：[https://towardsdatascience.com/are-language-models-benchmark-savants-or-real-world-problem-solvers-725a7e1524e1?source=collection_archive---------3-----------------------#2024-03-23](https://towardsdatascience.com/are-language-models-benchmark-savants-or-real-world-problem-solvers-725a7e1524e1?source=collection_archive---------3-----------------------#2024-03-23)

## 评估语言模型在现实任务中的演变与应用

[](https://medium.com/@tula.masterman?source=post_page---byline--725a7e1524e1--------------------------------)[![Tula Masterman](../Images/c36b3740befd5dfdb8719dc6596f1a99.png)](https://medium.com/@tula.masterman?source=post_page---byline--725a7e1524e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--725a7e1524e1--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--725a7e1524e1--------------------------------) [Tula Masterman](https://medium.com/@tula.masterman?source=post_page---byline--725a7e1524e1--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--725a7e1524e1--------------------------------) ·7分钟阅读·2024年3月23日

--

![](../Images/8483c5c420a71c5927d514fabe9195bc.png)

AI学生在教室里参加考试。图片由作者和DALL-E 3创作。

在教育领域，最好的考试是那些挑战学生将所学知识应用于新的和不可预测的方式的考试，这种考试不仅仅是让学生记住事实，而是展示他们的真正理解。我们对语言模型的评估也应遵循相同的模式。随着我们每天看到新的模型涌入AI领域，无论是来自像OpenAI和Anthropic这样的巨头，还是来自较小的研究团队和大学，至关重要的是，我们的模型评估应深入到标准基准测试的表现之上。新兴研究表明，我们一直以来用来衡量模型能力的基准并不像我们曾经认为的那样可靠。为了能够适当地支持新模型，我们的基准必须发展成为与我们要求这些模型和新兴AI代理架构解决的现实世界挑战一样动态和复杂。

在本文中，我们将通过回答以下问题来探讨语言模型评估的复杂性：

1.  目前语言模型是如何评估的？

1.  在基准测试中表现优秀的语言模型有多可靠？

1.  语言模型和AI代理能否将知识转化为行动？

1.  为什么语言模型（或基础模型）需要掌握的不仅仅是文本？

## 那么，今天语言模型是如何评估的？

今天，大多数模型，无论是大型语言模型（LLM）还是小型语言模型（SLM），都在一组共同的基准上进行评估，包括大规模多任务语言理解（MMLU）、小学数学（GSM8K）和Big-Bench Hard（BBH）数据集等。

为了更深入地理解每个基准评估的任务类型，以下是来自每个数据集的一些示例问题：

+   **MMLU**：旨在通过多项选择题衡量模型在预训练过程中学习到的关于STEM和人文学科各个学科以及从小学到高级专业理解的各个难度水平的信息。

    *MMLU中的医学类大学问题示例：“在对新生儿进行基因检测时，发现了一种罕见的遗传病，该病具有X连锁隐性遗传方式。以下哪项陈述可能是关于该病家族系谱的正确描述？ A. 所有母系后代都会患此病 B. 女性的发病率大约是男性的两倍 C. 所有患病男性的女儿都会患病 D. 男性和女性的发病率将相等。”（正确答案是C）* [[2](https://arxiv.org/pdf/2009.03300.pdf)]

+   **GSM8K**：语言模型通常难以解答数学问题，GSM8K数据集评估模型在解答8.5k个多样化的小学数学问题时的推理能力和解题能力。

    *示例：“Dean的母亲给了他28美元去杂货店。Dean买了6辆玩具车和5只泰迪熊。每辆玩具车的价格是12美元，每只泰迪熊的价格是1美元。之后，他的母亲心情好，决定再给他10美元。那么Dean剩下多少钱？”* [[3](https://arxiv.org/pdf/2110.14168.pdf)]

+   **BBH**：该数据集由23个任务组成，这些任务来自Big Bench数据集，语言模型通常难以解决这些任务。这些任务通常需要多步推理才能成功完成。

    *示例：“如果你按照这些指示走，你是否会回到起点？左转。右转。走5步。走4步。转身。走9步。选项：— 是 — 否”* [[4](https://arxiv.org/pdf/2210.09261.pdf)]

Anthropic最近宣布，Claude-3模型凭借其Opus版本在大多数常见基准上超越了GPT-4，成为领先的模型。例如，Claude-3 Opus在MMLU上取得了86.8%的成绩，略微超越了GPT-4的86.4%。Claude-3 Opus还在GSM8K上得到了95%的成绩，在BBH上得到了86.8%，而GPT-4分别为92%和83.1% [[1](https://www.anthropic.com/news/claude-3-family)]。

尽管像GPT-4和Claude这样的模型在这些基准测试中的表现令人印象深刻，但这些任务并不总是代表企业想要解决的挑战类型。此外，越来越多的研究表明，模型正在记住基准问题，而不是理解它们。这并不意味着这些模型不能推广到新任务，我们每天都看到LLM和SLM完成惊人的任务，但这意味着我们应该重新考虑如何评估、打分和推广模型。

## 在基准测试中表现出色的语言模型有多可靠？

来自微软、自动化研究所（中国科学院）和中国科学技术大学的研究表明，当向不同的语言模型提问经过改写或修改的基准问题时，这些模型的表现明显比直接提问相同基准问题时差。为了展示他们研究的目的，研究人员在论文中展示了DyVal 2，研究者从像MMLU这样的基准中取出问题，通过改写问题、为问题添加额外的答案、改写答案、排列答案顺序或为问题增加额外内容等方式进行修改。在比较“原始”数据集与修改后问题的模型表现时，他们发现性能下降，例如**GPT-4在原始MMLU问题上的得分为84.4，在修改后的MMLU问题上的得分为68.86** [[5](https://arxiv.org/pdf/2402.14865.pdf)]。

![](../Images/41500bee6584b0de079e580d3a307132.png)

来源：[DyVal2](https://arxiv.org/abs/2402.14865)，原始基准与探测基准上模型表现比较

同样，来自亚利桑那大学计算机科学系的研究表明，语言模型中存在**大量数据污染** [[6](https://arxiv.org/pdf/2308.08493.pdf)]。这意味着基准中的信息正成为模型训练数据的一部分，实际上使得基准得分变得无关紧要，因为模型是在自己已被训练过的信息上进行测试的。

来自复旦大学、同济大学和阿里巴巴的额外研究强调了需要为AI代理设计自我进化的动态评估，以应对数据污染和基准记忆化的问题 [[7](https://arxiv.org/pdf/2402.11443.pdf)]。这些动态基准将有助于防止模型在预训练过程中记住或学习它们后续将被测试的信息。尽管不断增加新的基准可能会在将旧模型与新模型进行比较时带来挑战，但理想情况下，这些基准将减轻数据污染问题，并使得评估模型理解训练中话题的能力变得更容易。

在评估模型在特定问题上的能力时，我们需要理解模型在预训练过程中学到的信息的理解程度，以及它能多好地将这些知识推广到新的任务或概念，超越它的训练数据。

## 语言模型和AI智能体能否将知识转化为行动？

当我们考虑使用模型作为AI智能体代表我们执行任务时，无论是预订假期、写报告，还是为我们研究新话题，我们都需要额外的基准或评估机制来评估这些智能体的可靠性和准确性。大多数希望利用基础模型力量的企业需要允许模型访问集成其独特数据源的各种工具，并要求模型推理和规划何时以及如何有效地使用这些工具。这些类型的任务在许多传统的LLM基准中并未得到体现。

![](../Images/6a6714bd97ae18064002f1df083eaeb8.png)

来源：[AgentVerse](https://arxiv.org/pdf/2308.10848.pdf)，智能体团队与单一智能体在涉及工具调用和代码执行的软件开发任务中的比较结果

为了解决这个问题，许多研究团队正在创建自己的基准和框架，用于评估智能体在涉及工具使用和超出模型训练数据的知识任务中的表现。例如，AgentVerse的作者评估了智能体团队在执行现实世界任务（如活动策划、软件开发和咨询）方面的表现。研究人员创建了自己的一套10个测试任务，并通过人工评估来判断智能体是否执行了正确的操作、使用了合适的工具，并得出了准确的结果。他们发现，采用包含明确阶段（智能体招募、任务规划、独立执行任务和后续评估）周期的智能体团队，比独立智能体的表现更优秀 [[8](https://arxiv.org/pdf/2308.10848.pdf)]。

## 超越单一模态，走向现实世界。为什么语言模型（或基础模型）要掌握文本之外的内容？

在我看来，正在出现的智能体架构和基准是理解语言模型在商业问题上表现如何的重要一步，但一个限制是，大多数仍然集中于文本。随着我们考虑到世界及大多数工作的动态性，我们需要评估模型在文本任务、视觉和听觉任务上表现的智能体系统和模型。AlgoPuzzleVQA数据集就是一个评估模型是否能够推理、阅读和视觉解读数学和算法谜题的例子 [[9](https://arxiv.org/pdf/2403.03864.pdf)]。

![](../Images/0a3192fb9ddedba0e539d342e9d20688.png)

来源：[语言模型是谜题天才吗？](https://arxiv.org/pdf/2403.03864.pdf) 来自AlgoPuzzleVQA数据集的示例问题

尽管企业可能不关心模型能多好地解答难题，但这仍然是理解模型如何推理多模态信息的一个正确方向。

## 结论

随着我们在日常生活和职业工作中不断采用基础模型，我们需要更多能够反映现实世界问题的评估选项。动态和多模态基准是其中的一个关键组成部分。然而，随着我们引入更多的代理框架和架构，多个AI代理协同解决问题，跨模型和框架的评估与比较变得更加具有挑战性。基础模型的真正衡量标准，不在于它们能否征服标准化测试，而在于它们在复杂且往往不可预测的现实世界中理解、适应和行动的能力。通过改变我们对语言模型的评估方式，我们挑战这些模型从基于文本的智力和基准测试专家，发展成为能够应对多方面（和多模态）挑战的全面思考者。

*有兴趣进一步讨论或合作？请通过* [*LinkedIn*](https://www.linkedin.com/in/tula-masterman/)*联系！*
