- en: Making News Recommendations Explainable with Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½¿æ–°é—»æ¨èå˜å¾—å¯è§£é‡Š
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30](https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30](https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30)
- en: A prompt-based experiment to improve both accuracy and transparent reasoning
    in content personalization.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é€šè¿‡åŸºäºæç¤ºçš„å®éªŒï¼Œæå‡å†…å®¹ä¸ªæ€§åŒ–æ¨èçš„å‡†ç¡®æ€§å’Œé€æ˜æ¨ç†ã€‚
- en: '[](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)[![Alex
    Held](../Images/be76f042807c4816944531780d14a73d.png)](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)
    [Alex Held](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)[![Alex
    Held](../Images/be76f042807c4816944531780d14a73d.png)](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)
    [Alex Held](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)
    Â·7 min readÂ·Nov 30, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)
    Â·é˜…è¯»æ—¶é—´ï¼š7åˆ†é’ŸÂ·2024å¹´11æœˆ30æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ff1026c0fe89bf7dceb16a6d47f1dc3f.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff1026c0fe89bf7dceb16a6d47f1dc3f.png)'
- en: Deliver relevant content to readers at the right time. Image by author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åˆé€‚çš„æ—¶é—´å‘è¯»è€…æä¾›ç›¸å…³å†…å®¹ã€‚å›¾ç‰‡æ¥è‡ªä½œè€…ã€‚
- en: At [DER SPIEGEL](https://www.spiegel.de/), we are continually exploring ways
    to improve how we recommend news articles to our readers. In our latest (offline)
    experiment, we investigated whether [Large Language Models](https://vickiboykis.com/what_are_embeddings/)
    (LLMs) could effectively predict which articles a reader would be interested in,
    based on their reading history.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ [DER SPIEGEL](https://www.spiegel.de/) ï¼Œæˆ‘ä»¬ä¸æ–­æ¢ç´¢æ”¹è¿›å¦‚ä½•å‘è¯»è€…æ¨èæ–°é—»æ–‡ç« çš„æ–¹æ³•ã€‚åœ¨æˆ‘ä»¬æœ€æ–°çš„ï¼ˆç¦»çº¿ï¼‰å®éªŒä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†
    [å¤§å‹è¯­è¨€æ¨¡å‹](https://vickiboykis.com/what_are_embeddings/)ï¼ˆLLMsï¼‰æ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆåœ°æ ¹æ®è¯»è€…çš„é˜…è¯»å†å²é¢„æµ‹ä»–ä»¬å¯èƒ½æ„Ÿå…´è¶£çš„æ–‡ç« ã€‚
- en: '**Our Approach**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬çš„æ–¹æ³•**'
- en: 'We conducted a study with readers who participated in a survey where they rated
    their interest in various news articles. This gave us a ground truth of reader
    preferences. For each participant, we had two key pieces of information: their
    actual reading history (which articles they had read before taking the survey)
    and their ratings of a set of new articles in the survey. Read more about this
    mixed-methods approach to offline evaluation of news recommender systems here:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹ç ”ç©¶ï¼Œé‚€è¯·å‚ä¸è€…å¡«å†™è°ƒæŸ¥é—®å·ï¼Œè¯„ä¼°ä»–ä»¬å¯¹å„ç§æ–°é—»æ–‡ç« çš„å…´è¶£ã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†å…³äºè¯»è€…åå¥½çš„çœŸå®æ•°æ®ã€‚å¯¹äºæ¯ä¸ªå‚ä¸è€…ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªå…³é”®ä¿¡æ¯ï¼šä»–ä»¬çš„å®é™…é˜…è¯»å†å²ï¼ˆå³åœ¨å¡«å†™è°ƒæŸ¥é—®å·å‰ä»–ä»¬é˜…è¯»è¿‡å“ªäº›æ–‡ç« ï¼‰ä»¥åŠä»–ä»¬åœ¨è°ƒæŸ¥ä¸­å¯¹ä¸€ç»„æ–°æ–‡ç« çš„è¯„åˆ†ã€‚äº†è§£æ›´å¤šå…³äºè¿™ç§æ··åˆæ–¹æ³•çš„ç¦»çº¿æ–°é—»æ¨èç³»ç»Ÿè¯„ä¼°æ–¹æ³•ï¼Œè¯·ç‚¹å‡»è¿™é‡Œï¼š
- en: '[](/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------)
    [## A Mixed-Methods Approach to Offline Evaluation of News Recommender Systems'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------)
    [## æ··åˆæ–¹æ³•ç¦»çº¿è¯„ä¼°æ–°é—»æ¨èç³»ç»Ÿ'
- en: Combining reader feedback from surveys with behavioral click data to optimize
    content personalization.
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»“åˆè°ƒæŸ¥åé¦ˆä¸è¡Œä¸ºç‚¹å‡»æ•°æ®ï¼Œä¼˜åŒ–å†…å®¹ä¸ªæ€§åŒ–æ¨èã€‚
- en: towardsdatascience.com](/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------)
- en: 'We then used the [Anthropic API](https://github.com/anthropics/anthropic-sdk-python)
    to access [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet),
    a state-of-the-art language model, as our recommendation engine. For each reader,
    we provided the model with their reading history (news title and article summary)
    and asked it to predict how interested they would be in the articles from the
    survey. Here is the prompt we used:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ä½¿ç”¨äº†[Anthropic API](https://github.com/anthropics/anthropic-sdk-python)æ¥è®¿é—®[Claude
    3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)ï¼Œä¸€ä¸ªæœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹ï¼Œä½œä¸ºæˆ‘ä»¬çš„æ¨èå¼•æ“ã€‚å¯¹äºæ¯ä¸ªè¯»è€…ï¼Œæˆ‘ä»¬ä¸ºæ¨¡å‹æä¾›äº†ä»–ä»¬çš„é˜…è¯»å†å²ï¼ˆæ–°é—»æ ‡é¢˜å’Œæ–‡ç« æ‘˜è¦ï¼‰ï¼Œå¹¶è¦æ±‚æ¨¡å‹é¢„æµ‹ä»–ä»¬å¯¹è°ƒæŸ¥ä¸­è¿™äº›æ–‡ç« çš„å…´è¶£ç¨‹åº¦ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„æç¤ºï¼š
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With this approach, we can now compare the actual ratings from the survey against
    the score predictions from the LLM. This comparison provides an ideal dataset
    for evaluating the language modelâ€™s ability to predict reader interests.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥å°†è°ƒæŸ¥ä¸­çš„å®é™…è¯„åˆ†ä¸LLMçš„é¢„æµ‹åˆ†æ•°è¿›è¡Œæ¯”è¾ƒã€‚è¿™ä¸€æ¯”è¾ƒæä¾›äº†ä¸€ä¸ªç†æƒ³çš„æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹é¢„æµ‹è¯»è€…å…´è¶£çš„èƒ½åŠ›ã€‚
- en: '**Results and Key Findings**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç»“æœä¸å…³é”®å‘ç°**'
- en: 'The findings were impressively strong. To understand the performance, we can
    look at two key metrics. First, the [Precision@5](https://www.evidentlyai.com/ranking-metrics/precision-recall-at-k):
    the LLM achieved a score of 56%, which means that when the system recommended
    its top 5 articles for a user (out of 15), on average (almost) 3 out of these
    5 articles were actually among the articles that user rated highest in our survey.
    Looking at the distribution of these predictions reveals even more impressive
    results: for 24% of users, the system correctly identified at least 4 or 5 of
    their top articles. For another 41% of users, it correctly identified 3 out of
    their top 5 articles.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç ”ç©¶ç»“æœä»¤äººå°è±¡æ·±åˆ»ã€‚ä¸ºäº†ç†è§£è¡¨ç°ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹ä¸¤ä¸ªå…³é”®æŒ‡æ ‡ã€‚é¦–å…ˆæ˜¯[Precision@5](https://www.evidentlyai.com/ranking-metrics/precision-recall-at-k)ï¼šLLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰è·å¾—äº†56%çš„å¾—åˆ†ï¼Œè¿™æ„å‘³ç€å½“ç³»ç»Ÿå‘ç”¨æˆ·æ¨èå‰5ç¯‡æ–‡ç« æ—¶ï¼ˆä»15ç¯‡ä¸­é€‰å‡ºï¼‰ï¼Œå¹³å‡ï¼ˆå‡ ä¹ï¼‰æœ‰3ç¯‡æ˜¯ç”¨æˆ·åœ¨è°ƒæŸ¥ä¸­è¯„åˆ†æœ€é«˜çš„æ–‡ç« ã€‚æŸ¥çœ‹è¿™äº›é¢„æµ‹çš„åˆ†å¸ƒå¯ä»¥æ­ç¤ºå‡ºæ›´åŠ ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼šå¯¹äº24%çš„ç”¨æˆ·ï¼Œç³»ç»Ÿæ­£ç¡®è¯†åˆ«å‡ºè‡³å°‘4æˆ–5ç¯‡ä»–ä»¬æœ€å–œæ¬¢çš„æ–‡ç« ï¼›å¯¹äºå¦å¤–41%çš„ç”¨æˆ·ï¼Œç³»ç»Ÿæ­£ç¡®è¯†åˆ«å‡ºä»–ä»¬å‰5ç¯‡æ–‡ç« ä¸­çš„3ç¯‡ã€‚
- en: To put this in perspective, if we were to recommend articles randomly, we would
    only achieve 38.8% precision (see previous [medium article](https://medium.com/towards-data-science/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501)
    for details). Even recommendations based purely on article popularity (recommending
    what most people read) only reach 42.1%, and our previous approach using an embedding-based
    technique achieved 45.4%.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†å…¶ç½®äºæ­£ç¡®çš„è§†è§’ä¸­ï¼Œå¦‚æœæˆ‘ä»¬éšæœºæ¨èæ–‡ç« ï¼Œæˆ‘ä»¬çš„ç²¾å‡†åº¦å°†ä»…ä¸º38.8%ï¼ˆè¯¦ç»†ä¿¡æ¯è¯·å‚è§ä¹‹å‰çš„[mediumæ–‡ç« ](https://medium.com/towards-data-science/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501)ï¼‰ã€‚å³ä½¿æ˜¯åŸºäºæ–‡ç« æµè¡Œåº¦çš„æ¨èï¼ˆæ¨èå¤§å¤šæ•°äººé˜…è¯»çš„å†…å®¹ï¼‰ä¹Ÿåªæœ‰42.1%ï¼Œè€Œæˆ‘ä»¬ä¹‹å‰ä½¿ç”¨åŸºäºåµŒå…¥çš„æ–¹æ³•çš„ç²¾å‡†åº¦ä¸º45.4%ã€‚
- en: '![](../Images/73b93682f37bf1eb4cdc35c9c5a9c262.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73b93682f37bf1eb4cdc35c9c5a9c262.png)'
- en: Graphic by author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…å›¾è¡¨
- en: 'The graphic below shows the uplift: While having any kind of knowledge about
    the users is better than guessing (random model), the LLM-based approach shows
    the strongest performance. Even compared to our sophisticated embedding-based
    logic, the LLM achieves a significant uplift in prediction accuracy.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å›¾è¡¨å±•ç¤ºäº†æå‡æ•ˆæœï¼šå°½ç®¡äº†è§£ç”¨æˆ·çš„ä»»ä½•ä¿¡æ¯æ¯”çº¯ç²¹çŒœæµ‹ï¼ˆéšæœºæ¨¡å‹ï¼‰è¦å¥½ï¼Œä½†åŸºäºLLMçš„æ–¹æ³•å±•ç¤ºäº†æœ€å¼ºçš„è¡¨ç°ã€‚å³ä½¿ä¸æˆ‘ä»¬å¤æ‚çš„åŸºäºåµŒå…¥çš„é€»è¾‘ç›¸æ¯”ï¼ŒLLMåœ¨é¢„æµ‹å‡†ç¡®æ€§ä¸Šä¹Ÿå®ç°äº†æ˜¾è‘—æå‡ã€‚
- en: '![](../Images/944e6bf25ecad03090641f39d1448a3b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/944e6bf25ecad03090641f39d1448a3b.png)'
- en: Graphic by author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…å›¾è¡¨
- en: As a second evaluation metric, we use [Spearman correlation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html).
    At 0.41, it represents a substantial improvement over our embedding-based approach
    (0.17). This also shows that the LLM is not just better at finding relevant articles,
    but also at understanding how much a reader might prefer one article over another.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºç¬¬äºŒä¸ªè¯„ä¼°æŒ‡æ ‡ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†[Spearmanç›¸å…³ç³»æ•°](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html)ã€‚å…¶å€¼ä¸º0.41ï¼Œæ˜¾è‘—é«˜äºæˆ‘ä»¬åŸºäºåµŒå…¥çš„æ–¹æ³•ï¼ˆ0.17ï¼‰ã€‚è¿™ä¹Ÿè¡¨æ˜ï¼ŒLLMä¸ä»…åœ¨æ‰¾åˆ°ç›¸å…³æ–‡ç« æ–¹é¢è¡¨ç°æ›´å¥½ï¼Œè¿˜èƒ½æ›´å¥½åœ°ç†è§£è¯»è€…å¯èƒ½åçˆ±æŸç¯‡æ–‡ç« è¶…è¿‡å¦ä¸€ç¯‡æ–‡ç« çš„ç¨‹åº¦ã€‚
- en: '**Beyond Performance: The Power of Explainability**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¶…è¶Šè¡¨ç°ï¼šå¯è§£é‡Šæ€§çš„åŠ›é‡**'
- en: 'What sets LLM-based recommendations apart is not just their performance but
    their ability to explain their decisions in natural language. Here is an example
    of how our system analyzes a userâ€™s reading patterns and explains its recommendations
    (prompt not shown):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºLLMçš„æ¨èä¸ä¼—ä¸åŒä¹‹å¤„ä¸ä»…åœ¨äºå…¶è¡¨ç°ï¼Œè¿˜åœ¨äºå®ƒä»¬èƒ½å¤Ÿä»¥è‡ªç„¶è¯­è¨€è§£é‡Šå…¶å†³ç­–ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„ç³»ç»Ÿå¦‚ä½•åˆ†æç”¨æˆ·é˜…è¯»æ¨¡å¼å¹¶è§£é‡Šå…¶æ¨èçš„ä¸€ä¸ªç¤ºä¾‹ï¼ˆæç¤ºæœªå±•ç¤ºï¼‰ï¼š
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Rather than operating as a black box, the system could articulate why it thinks
    a particular article might be interesting to a reader: *Because you frequently
    read articles about practical advice and economic matters, you might find this
    analysis about the cost-effectiveness of balcony solar storage particularly relevant.*
    This kind of transparent reasoning could make recommendations feel more personal
    and trustworthy.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç³»ç»Ÿå¹¶éä½œä¸ºä¸€ä¸ªé»‘ç›’è¿è¡Œï¼Œè€Œæ˜¯å¯ä»¥é˜æ˜ä¸ºä½•è®¤ä¸ºæŸç¯‡æ–‡ç« å¯èƒ½å¯¹è¯»è€…æ„Ÿå…´è¶£ï¼š*å› ä¸ºä½ ç»å¸¸é˜…è¯»å…³äºå®ç”¨å»ºè®®å’Œç»æµé—®é¢˜çš„æ–‡ç« ï¼Œä½ å¯èƒ½ä¼šå‘ç°è¿™ç¯‡å…³äºé˜³å°å¤ªé˜³èƒ½å‚¨èƒ½æ€§ä»·æ¯”åˆ†æçš„æ–‡ç« ç‰¹åˆ«ç›¸å…³ã€‚*
    è¿™ç§é€æ˜çš„æ¨ç†å¯ä»¥è®©æ¨èçœ‹èµ·æ¥æ›´åŠ ä¸ªæ€§åŒ–å’Œå€¼å¾—ä¿¡èµ–ã€‚
- en: '**Conclusion**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç»“è®º**'
- en: While our results are promising, several challenges need to be addressed. Due
    to long prompts (hundreds of article summaries per user), the most significant
    is cost. At about $0.21 per user for a single recommendation run, scaling this
    to full readerships would be irresponsibly expensive. Testing high-performing
    [open-source models](https://ai.meta.com/blog/meta-llama-3-1/), could potentially
    reduce these costs. Additionally, the current implementation is relatively slow,
    taking several seconds per user. For a news platform where content updates frequently
    and reader interests evolve sometimes even throughout a single day, we would need
    to run these recommendations multiple times daily to stay relevant.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æˆ‘ä»¬çš„ç»“æœå¾ˆæœ‰å‰æ™¯ï¼Œä½†ä»ç„¶éœ€è¦è§£å†³è‹¥å¹²æŒ‘æˆ˜ã€‚ç”±äºé•¿ç¯‡æç¤ºï¼ˆæ¯ä¸ªç”¨æˆ·åŒ…å«æ•°ç™¾ä¸ªæ–‡ç« æ‘˜è¦ï¼‰ï¼Œæœ€å¤§çš„æŒ‘æˆ˜æ˜¯æˆæœ¬ã€‚æ¯ä¸ªç”¨æˆ·çš„å•æ¬¡æ¨èè¿è¡Œè´¹ç”¨çº¦ä¸º$0.21ï¼Œè‹¥å°†å…¶æ‰©å±•åˆ°å…¨éƒ¨è¯»è€…ç¾¤ä½“ï¼Œå°†å˜å¾—æä¸ºæ˜‚è´µã€‚æµ‹è¯•é«˜æ•ˆçš„[å¼€æºæ¨¡å‹](https://ai.meta.com/blog/meta-llama-3-1/)ï¼Œå¯èƒ½ä¼šå‡å°‘è¿™äº›æˆæœ¬ã€‚æ­¤å¤–ï¼Œå½“å‰çš„å®ç°ç›¸å¯¹è¾ƒæ…¢ï¼Œæ¯ä¸ªç”¨æˆ·éœ€è¦å‡ ç§’é’Ÿçš„æ—¶é—´ã€‚å¯¹äºä¸€ä¸ªå†…å®¹æ›´æ–°é¢‘ç¹ã€è¯»è€…å…´è¶£å¯èƒ½åœ¨ä¸€å¤©å†…å‘ç”Ÿå˜åŒ–çš„æ–°é—»å¹³å°ï¼Œæˆ‘ä»¬éœ€è¦æ¯å¤©å¤šæ¬¡è¿è¡Œè¿™äº›æ¨èï¼Œæ‰èƒ½ä¿æŒå…¶ç›¸å…³æ€§ã€‚
- en: Furthermore, we used a single, straightforward prompt without any prompt engineering
    or optimization. There is likely (significant) room for improvement through systematic
    prompt refinement.[1] Additionally, our current implementation only uses article
    titles and summaries, without leveraging available metadata. We could potentially
    increase the performance by incorporating additional signals such as reading time
    per article (how long users spent reading each piece) or overall article popularity.
    Anyhow, due to high API costs, running iterative evaluation pipelines is currently
    not an option.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªç®€å•ç›´æ¥çš„æç¤ºï¼Œæ²¡æœ‰è¿›è¡Œä»»ä½•æç¤ºå·¥ç¨‹æˆ–ä¼˜åŒ–ã€‚é€šè¿‡ç³»ç»Ÿæ€§çš„æç¤ºä¼˜åŒ–ï¼Œå¯èƒ½ä¼šæœ‰ï¼ˆæ˜¾è‘—çš„ï¼‰æå‡ç©ºé—´ã€‚[1] æ­¤å¤–ï¼Œæˆ‘ä»¬ç›®å‰çš„å®ç°ä»…ä½¿ç”¨äº†æ–‡ç« æ ‡é¢˜å’Œæ‘˜è¦ï¼Œæœªåˆ©ç”¨ç°æœ‰çš„å…ƒæ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å¼•å…¥å…¶ä»–ä¿¡å·ï¼Œå¦‚æ¯ç¯‡æ–‡ç« çš„é˜…è¯»æ—¶é—´ï¼ˆç”¨æˆ·æ¯ç¯‡æ–‡ç« çš„é˜…è¯»æ—¶é•¿ï¼‰æˆ–æ•´ä½“æ–‡ç« çš„å—æ¬¢è¿ç¨‹åº¦ï¼Œæ½œåœ¨åœ°æé«˜æ€§èƒ½ã€‚ä¸è¿‡ï¼Œç”±äºé«˜æ˜‚çš„APIè´¹ç”¨ï¼Œç›®å‰è¿›è¡Œè¿­ä»£è¯„ä¼°ç®¡é“å¹¶ä¸æ˜¯ä¸€ä¸ªå¯è¡Œçš„é€‰é¡¹ã€‚
- en: 'All in all, the combination of strong predictive performance and natural language
    explanations suggests that LLMs will be a valuable tool in news recommendation
    systems. And beyond recommendations, they add a new way on how we analyze user
    journeys in digital news. Their ability to process and interpret reading histories
    alongside metadata opens up exciting possibilities: from understanding content
    journeys and topic progressions to creating personalized review summaries.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»çš„æ¥è¯´ï¼Œå¼ºå¤§çš„é¢„æµ‹æ€§èƒ½å’Œè‡ªç„¶è¯­è¨€è§£é‡Šç›¸ç»“åˆï¼Œè¡¨æ˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å°†åœ¨æ–°é—»æ¨èç³»ç»Ÿä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚è€Œä¸”ï¼Œé™¤äº†æ¨èï¼Œå®ƒä»¬è¿˜ä¸ºæˆ‘ä»¬åˆ†ææ•°å­—æ–°é—»ä¸­çš„ç”¨æˆ·æ—…ç¨‹æä¾›äº†å…¨æ–°çš„æ–¹å¼ã€‚å®ƒä»¬èƒ½å¤Ÿå¤„ç†å¹¶è§£é‡Šé˜…è¯»å†å²ä¸å…ƒæ•°æ®çš„ç»“åˆï¼Œæ‰“å¼€äº†ä»¤äººå…´å¥‹çš„å¯èƒ½æ€§ï¼šä»ç†è§£å†…å®¹çš„æµå‘å’Œä¸»é¢˜çš„è¿›å±•ï¼Œåˆ°åˆ›å»ºä¸ªæ€§åŒ–çš„å›é¡¾æ€»ç»“ã€‚
- en: '**Thanks for reading ğŸ™**'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ„Ÿè°¢é˜…è¯» ğŸ™**'
- en: I hope you liked it, if so, just make it clap. Please do not hesitate to [connect
    with me on LinkedIn](https://www.linkedin.com/in/alex-held-1193b9234/) for further
    discussion or questions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢å®ƒï¼Œå¦‚æœå–œæ¬¢ï¼Œå°±ç»™å®ƒç‚¹ä¸ªèµå§ã€‚å¦‚æœæœ‰è¿›ä¸€æ­¥çš„è®¨è®ºæˆ–é—®é¢˜ï¼Œè¯·éšæ—¶é€šè¿‡[LinkedInä¸æˆ‘è”ç³»](https://www.linkedin.com/in/alex-held-1193b9234/)ã€‚
- en: As a data scientist at [DER SPIEGEL](https://www.spiegel.de/), I have authorized
    access to proprietary user data and click histories, which form the basis of this
    study. This data is not publicly available. All presented results are aggregated
    and anonymized to protect user privacy while showcasing our methodological approach
    to news recommendation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸º[DER SPIEGEL](https://www.spiegel.de/)çš„ æ•°æ®ç§‘å­¦å®¶ï¼Œæˆ‘å·²è·å¾—å¯¹ä¸“æœ‰ç”¨æˆ·æ•°æ®å’Œç‚¹å‡»å†å²çš„æˆæƒè®¿é—®æƒé™ï¼Œè¿™äº›æ•°æ®æ„æˆäº†æœ¬ç ”ç©¶çš„åŸºç¡€ã€‚æ­¤æ•°æ®ä¸å…¬å¼€ã€‚æ‰€æœ‰å±•ç¤ºçš„ç»“æœå‡å·²æ±‡æ€»å’ŒåŒ¿ååŒ–ï¼Œä»¥ä¿æŠ¤ç”¨æˆ·éšç§ï¼ŒåŒæ—¶å±•ç¤ºæˆ‘ä»¬åœ¨æ–°é—»æ¨èä¸­çš„æ–¹æ³•è®ºã€‚
- en: References
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] Dairui, Liu & Yang, Boming & Du, Honghui & Greene, Derek & Hurley, Neil
    & Lawlor, Aonghus & Dong, Ruihai & Li, Irene. (2024). RecPrompt: A Self-tuning
    Prompting Framework for News Recommendation Using Large Language Models.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Dairui, Liu & Yang, Boming & Du, Honghui & Greene, Derek & Hurley, Neil
    & Lawlor, Aonghus & Dong, Ruihai & Li, Irene. (2024). RecPrompt: ä¸€ç§è‡ªè°ƒèŠ‚æç¤ºæ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ–°é—»æ¨èã€‚'
