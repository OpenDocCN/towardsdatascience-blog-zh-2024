- en: Visualizing Dynamical Behavior in Agent-Based Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/visualizing-dynamical-behavior-in-agent-based-models-70bb81dc0e93?source=collection_archive---------9-----------------------#2024-03-05](https://towardsdatascience.com/visualizing-dynamical-behavior-in-agent-based-models-70bb81dc0e93?source=collection_archive---------9-----------------------#2024-03-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/535063d1630e3ce67be8af53598f0beb.png)'
  prefs: []
  type: TYPE_IMG
- en: And encountering emergent complexity along the way
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@Dani_Lisle?source=post_page---byline--70bb81dc0e93--------------------------------)[![Dani
    Lisle](../Images/2933bbbca26cf198e7964547a91b2751.png)](https://medium.com/@Dani_Lisle?source=post_page---byline--70bb81dc0e93--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--70bb81dc0e93--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--70bb81dc0e93--------------------------------)
    [Dani Lisle](https://medium.com/@Dani_Lisle?source=post_page---byline--70bb81dc0e93--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--70bb81dc0e93--------------------------------)
    ·9 min read·Mar 5, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: In my research into streamlining strategic knowledge extraction in game theoretic
    problems, I recently realized that I needed a better way to simply and intuitively
    visualize the behavior of agents with defined dynamical behavior.
  prefs: []
  type: TYPE_NORMAL
- en: This led me to build a simple library for visualizing agent behavior as an animation
    using PyPlot. But before jumping into the tutorial, here’s a quick catch-up on
    the core concepts at play here.
  prefs: []
  type: TYPE_NORMAL
- en: A Quick Primer on Dynamical Agent-Based Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Agent based modeling (ABM) offers an excellent way to simulate players in many
    game theoretic environments. It lets us model and study the behavior and cognitive
    processes of each individual player, rather than just analyzing trends. When it
    isn’t practical to represent agents using simplistic binary state machines like
    cellular automata grids, ABM lets us capture scenarios by representing the agents’
    positions in a dimensional space, where each dimension has its own unique rules.
  prefs: []
  type: TYPE_NORMAL
- en: Agents in Position and State Space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By utilizing both spatial and state dimensions we can accurately model proximity
    as well as incorporate attributes that allow for subtle interactions, such as
    similarity in characteristics. Furthermore, storing the “positions” of agents
    in state space allow us to keep track of and compare detailed and dynamic state
    information about agents (i.e. a player’s fatigue in a model of football).
  prefs: []
  type: TYPE_NORMAL
- en: Compared to network models, wherein the existence of connections between two
    objects indicate relationships, position-state-space information lets us to define
    and explore more complex and higher-dimensional relationships between agents.
    In this paradigm, Euclidean distance in state-space could represent a strong measure
    of the state similarity between two agents.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamical Systems Theory for Behavior and Interaction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can make such a model even more powerful by using dynamical systems theory
    to describe how the state of one agent influences those of others. It provides
    a robust way to define rules a system’s evolution over time.
  prefs: []
  type: TYPE_NORMAL
- en: In socioeconomic systems, differential equations can be used to model communication,
    mimicry, and more complex adaptive processes, as well as describe how individual
    actions can produce group dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: Visualization Needs in Time and Space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For my problem, I wanted to be able see the position of each agent and its movement
    over time at a glance, and some basic state information (i.e. one or two variables
    per agent).
  prefs: []
  type: TYPE_NORMAL
- en: There are currently several libraries that meet the need for visualizing ABMs,
    including NetLogo and Mesa (for Python). However, they are built primarily for
    visualizing discrete-space, rather than continuous-space models. For my purposes,
    I was interested in the latter, and so began the side quest. If you’d like to
    follow along or test out the code for yourself, it’s all stored at [github.com/dreamchef/abm-viz](https://github.com/dreamchef/abm-dynamics-viz).
  prefs: []
  type: TYPE_NORMAL
- en: Building the Classes and Animation in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For starters, I needed to represent and store the agents and the world, and
    their state and dynamics. I chose to do this using Python classes. I defined an
    Agent class with a set of variables that I thought might be relevant to many possible
    modeling tasks. I also defined a plottable circle object (with PyPlot) for each
    agent within the class structure.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, after a bit of experimentation, I found that it in the spirit of good
    objected-oriented programming principles, it would be best to define a World (think
    game or system) class as well. In included both the state information for the
    world and the information for the plots and axes in the class structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: I wrote this class so that the programmer can simply specify the desired number
    of agents (along with other parameters such as a world size and spawn area size)
    rather than manually creating and adding agents in the main section.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this basic structure defined and agents being generated with randomized
    positions and initial velocities in the world, I then used PyPlot library’s animation
    features to create a method which would begin the visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This function references the figure, stored in the World instance, some specifications
    for the speed and length of the animation, and an update function, which is also
    defined in the World class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The World.updatePosition function simply added each agent’s static velocity
    to the current position. This preliminary work was able to generate simple animations
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/62630e7bd868ec7c0f0e00b752b71c05.png)'
  prefs: []
  type: TYPE_IMG
- en: Constant Velocities
  prefs: []
  type: TYPE_NORMAL
- en: With this basic functionality, we’d now like to be able to visualize more interesting
    dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing “Social” Dynamic Behavior
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I first chose to define a dynamic where each agent would change its direction
    of movement based on the average direction of movement of other agents around
    it. In equation form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a277f060187732ccbdba91e6e82777d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'I encoded the dynamic in Python via an Agent.updatePosition() and an Agent.updateVelocity()
    method, which are run on each animation frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the PyPlot animation below, the agents begin with very different velocities,
    but quickly adjust and begin traveling in the same direction. In this case, the
    average direction was roughly upward in the Y-direction at first.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c71a52a10d0d946ff5df87bb544bff4b.png)'
  prefs: []
  type: TYPE_IMG
- en: Converging Upward
  prefs: []
  type: TYPE_NORMAL
- en: This time, the group had initialized with a roughly leftward velocity with one
    “straggling”, who quickly adjusts.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fc77372a07139faeff1b8014388fb0f4.png)'
  prefs: []
  type: TYPE_IMG
- en: Single Straggler to Leftward Convergence
  prefs: []
  type: TYPE_NORMAL
- en: Displaying Velocity Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next I realized it would be helpful to see the velocity of the agents more
    clearly, so I implemented arrows to show each agent’s magnitude and direction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: That modification gave more helpful animations like this one. We can still notice
    the converging-velocities dynamic at a glance, but see the rates of acceleration
    more clearly now as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8322d6407c8d74f5dbba398bd6d03b5a.png)'
  prefs: []
  type: TYPE_IMG
- en: Velocity Arrows
  prefs: []
  type: TYPE_NORMAL
- en: For the animation above, I also adjusting the dynamic to be dependent on a sight
    range variable. In other words, agents only adjust their velocities to match agents
    that are nearby (within 300 units in this case).
  prefs: []
  type: TYPE_NORMAL
- en: I also modified the code so that each agent would only modify its direction
    of movement, not its speed. Keep this in mind for the next section.
  prefs: []
  type: TYPE_NORMAL
- en: More Complex, State-Wise Dynamics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until this point, I had only implemented dynamics which considered the positions
    and velocities of each agent. But as I alluded to in the overview section, consider
    non-spatial, state information as well can make our modeling approach much more
    generalizable.
  prefs: []
  type: TYPE_NORMAL
- en: Using Agent Hue and Saturation To Represent State Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I made use an auxiliary state tied to the RGB color of each agent. Foreshadowing
    the evolutionary game theoretic goals of my research, I call this the agent “species”,
    and implement it as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Agent.__init__ method, I added random species generation and individual
    mapping to the color of the agent’s marker on the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Specifically, I assigned this to the hue of the object, to reserve the saturation
    (roughly grey-ness) for other variables of potential interest (i.e. remaining
    lifespan or health). This practice of dividing hue and saturation has precedent
    in the visualization of complex-valued functions, which I go into in [this article](https://medium.com/towards-data-science/today-i-was-pouring-through-my-complex-variables-and-analytic-functions-book-written-by-the-e9205f71485d).
  prefs: []
  type: TYPE_NORMAL
- en: Dependence of Acceleration on Species State Variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With examples of herding behavior in nature that occurs between animals of the
    same species, but not between those of differing species, I decided to change
    our toy dynamics to consider species. This change meant that each agent will only
    modify its direction for agents that are sufficiently close in the world and sufficiently
    similar in species (i.e. similarly colored circles).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, this is where things, began to get **very, very interesting**. Before
    you continue reading, ask yourself:'
  prefs: []
  type: TYPE_NORMAL
- en: '*What behavior do you expect to see in the next animation?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A relatively naive experimenter (such as myself most of the time) would expect
    agents to organize themselves by species and travel in herds, with each herd tending
    to travel in different directions and mostly ignoring each other. To see if either
    of us is right, let’s continue.
  prefs: []
  type: TYPE_NORMAL
- en: 'To encode this behavior I modified the calculation of herd velocity with respect
    to an agent in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: That change resulted in animations like this one. To see the interesting behavior
    here, I started recording this about 20 seconds into the animation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/72c034b975c1a23e2db32ccf1cc87b42.png)'
  prefs: []
  type: TYPE_IMG
- en: Emergent Behavior
  prefs: []
  type: TYPE_NORMAL
- en: It’s okay if the behavior isn’t immediately obvious. It’s subtle. And if you
    think you predicted it correctly, great job!
  prefs: []
  type: TYPE_NORMAL
- en: As it turned out, the agents didn’t organize themselves into herds by species
    very well at all. Instead, the only agents who seem to stick together are the
    ones who have both similar species and similar travel speed. You can see this
    happening most often with the slower green agents, the pair of blue agents, and
    the fast blue and purple agents shooting across the bottom of the screen. Notably,
    the agents seem to prioritize speed over species similarity when “choosing” who
    to travel with. You can see this most often with the light, dark blue, and even
    purple agents.
  prefs: []
  type: TYPE_NORMAL
- en: This makes perfect sense in the dynamics we defined, since each agent’s speed
    is constant, and agents with different speeds will ultimately fall behind or run
    away from their comrades. And yet, its somewhat surprising.
  prefs: []
  type: TYPE_NORMAL
- en: Fundamentally, this is because the behavior is emergent. In other words, we
    didn’t explicitly tell the agents to behave in this way as a group. Rather, they
    “derived” this behavior from the simple set of instructions, which we gave to
    each individual agent in an identical encoded format.
  prefs: []
  type: TYPE_NORMAL
- en: Visualization, Emergence, and Data Insights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We began this journey with the simple goal of visualizing an ABM to make sure
    on a high level that the dynamics we would set up would work as intended. But
    in addition to accomplishing this, we stumbled upon an emergent behavior which
    we may not have even considered when creating the model.
  prefs: []
  type: TYPE_NORMAL
- en: This illustrates an important partnership with respect to visualization in data
    science, simulations, and modeling across the board. Discovering emergent behavior
    in complex systems can be accelerated by new perspectives on the model or dataset.
    This isn’t only true for agent-based modeling. It applies to obtaining insights
    across the rest of data science as well. And creating new and creative visualizations
    provides a sure-fire way to get such perspectives.
  prefs: []
  type: TYPE_NORMAL
- en: If you’d like to play around with this model and visualization further, you
    can get the code at [github.com/dreamchef/abm-viz](https://github.com/dreamchef/abm-dynamics-viz).
    I’d love to hear what else you may find, or your thoughts on my work, in the comments!
    Feel free to reach out to me on [Twitter](https://twitter.com/dani_lisle) and
    [LinkedIn](https://www.linkedin.com/in/danilisle/) as well. Have a great day!
  prefs: []
  type: TYPE_NORMAL
- en: '*Unless otherwise noted, all images and animations were created by the author.*'
  prefs: []
  type: TYPE_NORMAL
