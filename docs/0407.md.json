["```py\nfrom nltk.stem import SnowballStemmer\nfrom nltk.tokenize import word_tokenize\n\ntext = 'We are lucky to live in an age in which we are still making discoveries'\n\n# tokenization - splitting text into words\nwords = word_tokenize(text)\nprint(words)\n# ['We', 'are', 'lucky', 'to', 'live', 'in', 'an', 'age', 'in', 'which',\n#  'we', 'are', 'still', 'making', 'discoveries']\n\nstemmer = SnowballStemmer(language = \"english\")\nstemmed_words = list(map(lambda x: stemmer.stem(x), words))\nprint(stemmed_words)\n# ['we', 'are', 'lucki', 'to', 'live', 'in', 'an', 'age', 'in', 'which', \n#  'we', 'are', 'still', 'make', 'discoveri']\n```", "```py\nimport collections\nbag_of_words = collections.Counter(stemmed_words)\nprint(bag_of_words)\n# {'we': 2, 'are': 2, 'in': 2, 'lucki': 1, 'to': 1, 'live': 1, \n# 'an': 1, 'age': 1, 'which': 1, 'still': 1, 'make': 1, 'discoveri': 1}\n```", "```py\nfrom openai import OpenAI\nclient = OpenAI()\n\ndef get_embedding(text, model=\"text-embedding-3-small\"):\n   text = text.replace(\"\\n\", \" \")\n   return client.embeddings.create(input = [text], model=model)\\\n       .data[0].embedding\n\nget_embedding(\"We are lucky to live in an age in which we are still making discoveries.\") \n```", "```py\nvector1 = [1, 4]\nvector2 = [2, 2]\n```", "```py\nimport numpy as np\n\nsum(list(map(lambda x, y: (x - y) ** 2, vector1, vector2))) ** 0.5\n# 2.2361\n\nnp.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 2)\n# 2.2361\n```", "```py\nsum(list(map(lambda x, y: abs(x - y), vector1, vector2)))\n# 3\n\nnp.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 1)\n# 3.0\n```", "```py\nsum(list(map(lambda x, y: x*y, vector1, vector2)))\n# 11\n\nnp.dot(vector1, vector2)\n# 11\n```", "```py\ndot_product = sum(list(map(lambda x, y: x*y, vector1, vector2)))\nnorm_vector1 = sum(list(map(lambda x: x ** 2, vector1))) ** 0.5\nnorm_vector2 = sum(list(map(lambda x: x ** 2, vector2))) ** 0.5\n\ndot_product/norm_vector1/norm_vector2\n\n# 0.8575\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_similarity(\n  np.array(vector1).reshape(1, -1), \n  np.array(vector2).reshape(1, -1))[0][0]\n\n# 0.8575\n```", "```py\nimport math\nmath.degrees(math.acos(0.8575))\n\n# 30.96\n```", "```py\nimport numpy as np\nembeddings_array = np.array(df.embedding.values.tolist())\nprint(embeddings_array.shape)\n# (1400, 1536)\n```", "```py\nfrom sklearn.decomposition import PCA\n\npca_model = PCA(n_components = 2)\npca_model.fit(embeddings_array)\n\npca_embeddings_values = pca_model.transform(embeddings_array)\nprint(pca_embeddings_values.shape)\n# (1400, 2) \n```", "```py\nfig = px.scatter(\n    x = pca_embeddings_values[:,0], \n    y = pca_embeddings_values[:,1],\n    color = df.topic.values,\n    hover_name = df.full_text.values,\n    title = 'PCA embeddings', width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n)\n\nfig.update_layout(\n    xaxis_title = 'first component', \n    yaxis_title = 'second component')\nfig.show()\n```", "```py\nfrom sklearn.manifold import TSNE\ntsne_model = TSNE(n_components=2, random_state=42)\ntsne_embeddings_values = tsne_model.fit_transform(embeddings_array)\n\nfig = px.scatter(\n    x = tsne_embeddings_values[:,0], \n    y = tsne_embeddings_values[:,1],\n    color = df.topic.values,\n    hover_name = df.full_text.values,\n    title = 't-SNE embeddings', width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n)\n\nfig.update_layout(\n    xaxis_title = 'first component', \n    yaxis_title = 'second component')\nfig.show()\n```", "```py\ntsne_model_3d = TSNE(n_components=3, random_state=42)\ntsne_3d_embeddings_values = tsne_model_3d.fit_transform(embeddings_array)\n\nfig = px.scatter_3d(\n    x = tsne_3d_embeddings_values[:,0], \n    y = tsne_3d_embeddings_values[:,1],\n    z = tsne_3d_embeddings_values[:,2],\n    color = df.topic.values,\n    hover_name = df.full_text.values,\n    title = 't-SNE embeddings', width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r,\n    opacity = 0.7\n)\nfig.update_layout(xaxis_title = 'first component', yaxis_title = 'second component')\nfig.show()\n```", "```py\nembedding1 = df.loc[1].embedding\nembedding2 = df.loc[616].embedding\nembedding3 = df.loc[749].embedding\n```", "```py\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nembed_len_thr = 1536\n\nsns.heatmap(np.array(embedding1[:embed_len_thr]).reshape(-1, embed_len_thr),\n    cmap = \"Greys\", center = 0, square = False, \n    xticklabels = False, cbar = False)\nplt.gcf().set_size_inches(15,1)\nplt.yticks([0.5], labels = ['AI'])\nplt.show()\n\nsns.heatmap(np.array(embedding3[:embed_len_thr]).reshape(-1, embed_len_thr),\n    cmap = \"Greys\", center = 0, square = False, \n    xticklabels = False, cbar = False)\nplt.gcf().set_size_inches(15,1)\nplt.yticks([0.5], labels = ['AI'])\nplt.show()\n\nsns.heatmap(np.array(embedding2[:embed_len_thr]).reshape(-1, embed_len_thr),\n    cmap = \"Greys\", center = 0, square = False, \n    xticklabels = False, cbar = False)\nplt.gcf().set_size_inches(15,1)\nplt.yticks([0.5], labels = ['Bioinformatics'])\nplt.show()\n```", "```py\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport tqdm\n\nsilhouette_scores = []\nfor k in tqdm.tqdm(range(2, 51)):\n    kmeans = KMeans(n_clusters=k, \n                    random_state=42, \n                    n_init = 'auto').fit(embeddings_array)\n    kmeans_labels = kmeans.labels_\n    silhouette_scores.append(\n        {\n            'k': k,\n            'silhouette_score': silhouette_score(embeddings_array, \n                kmeans_labels, metric = 'cosine')\n        }\n    )\n\nfig = px.line(pd.DataFrame(silhouette_scores).set_index('k'),\n       title = '<b>Silhouette scores for K-means clustering</b>',\n       labels = {'value': 'silhoutte score'}, \n       color_discrete_sequence = plotly.colors.qualitative.Alphabet)\nfig.update_layout(showlegend = False)\n```", "```py\ntsne_model = TSNE(n_components=2, random_state=42)\ntsne_embeddings_values = tsne_model.fit_transform(embeddings_array)\n\nfig = px.scatter(\n    x = tsne_embeddings_values[:,0], \n    y = tsne_embeddings_values[:,1],\n    color = list(map(lambda x: 'cluster %s' % x, kmeans_labels)),\n    hover_name = df.full_text.values,\n    title = 't-SNE embeddings for clustering', width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n)\nfig.update_layout(\n    xaxis_title = 'first component', \n    yaxis_title = 'second component')\nfig.show()\n```", "```py\ndf['cluster'] = list(map(lambda x: 'cluster %s' % x, kmeans_labels))\ncluster_stats_df = df.reset_index().pivot_table(\n    index = 'cluster', values = 'id', \n    aggfunc = 'count', columns = 'topic').fillna(0).applymap(int)\n\ncluster_stats_df = cluster_stats_df.apply(\n  lambda x: 100*x/cluster_stats_df.sum(axis = 1))\n\nfig = px.imshow(\n    cluster_stats_df.values, \n    x = cluster_stats_df.columns,\n    y = cluster_stats_df.index,\n    text_auto = '.2f', aspect = \"auto\",\n    labels=dict(x=\"cluster\", y=\"fact topic\", color=\"share, %\"), \n    color_continuous_scale='pubugn',\n    title = '<b>Share of topics in each cluster</b>', height = 550)\n\nfig.show()\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nclass_model = RandomForestClassifier(max_depth = 10)\n\n# defining features and target\nX = embeddings_array\ny = df.topic\n\n# splitting data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, random_state = 42, test_size=0.2, stratify=y\n)\n\n# fit & predict \nclass_model.fit(X_train, y_train)\ny_pred = class_model.predict(X_test)\n```", "```py\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\nfig = px.imshow(\n  cm, x = class_model.classes_,\n  y = class_model.classes_, text_auto='d', \n  aspect=\"auto\", \n  labels=dict(\n      x=\"predicted label\", y=\"true label\", \n      color=\"cases\"), \n  color_continuous_scale='pubugn',\n  title = '<b>Confusion matrix</b>', height = 550)\n\nfig.show()\n```", "```py\nfrom sklearn.ensemble import IsolationForest\n\ntopic_df = df[df.topic == 'travel']\ntopic_embeddings_array = np.array(topic_df.embedding.values.tolist())\n\nclf = IsolationForest(contamination = 0.03, random_state = 42) \ntopic_df['is_anomaly'] = clf.fit_predict(topic_embeddings_array)\n\ntopic_df[topic_df.is_anomaly == -1][['full_text']]\n```", "```py\nIs it safe to drink the water from the fountains found all over \nthe older parts of Rome?\n\nWhen I visited Rome and walked around the older sections, I saw many \ndifferent types of fountains that were constantly running with water. \nSome went into the ground, some collected in basins, etc.\n\nIs the water coming out of these fountains potable? Safe for visitors \nto drink from? Any etiquette regarding their use that a visitor \nshould know about?\n```"]