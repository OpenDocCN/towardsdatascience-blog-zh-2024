- en: Exploring How the New OpenAI Realtime API Simplifies Voice Agent Flows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/exploring-how-the-new-openai-realtime-api-simplifies-voice-agent-flows-7b136ef8483d?source=collection_archive---------7-----------------------#2024-10-03](https://towardsdatascience.com/exploring-how-the-new-openai-realtime-api-simplifies-voice-agent-flows-7b136ef8483d?source=collection_archive---------7-----------------------#2024-10-03)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Setting up a Voice Agent using Twilio and the OpenAI Realtime API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)[![Sami
    Maameri](../Images/9e9892fe7d3cc53ad1c4d165145878ef.png)](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)
    [Sami Maameri](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)
    ·8 min read·Oct 3, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the recent OpenAI Dev Day on October 1st, 2024, OpenAI’s biggest release
    was the reveal of their Realtime API:'
  prefs: []
  type: TYPE_NORMAL
- en: “Today, we’re introducing a public beta of the Realtime API, enabling all paid
    developers to build low-latency, multimodal experiences in their apps.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Similar to ChatGPT’s Advanced Voice Mode, the Realtime API supports natural
    speech-to-speech conversations using the [six preset voices](https://platform.openai.com/docs/guides/text-to-speech)
    already supported in the API.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '(source: OpenAI website)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As per their message, some of its key benefits include low latency, and its
    speech to speech capabilities. Let’s see how that plays out in practice in terms
    of building out voice AI agents.
  prefs: []
  type: TYPE_NORMAL
- en: It also has an interruption handling feature, so that the realtime stream will
    stop sending audio if it detects you are trying to speak over it, a useful feature
    for sure when building voice agents.
  prefs: []
  type: TYPE_NORMAL
- en: Contents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this article we will:'
  prefs: []
  type: TYPE_NORMAL
- en: Compare what a phone voice agent flow might have looked like before the Realtime
    API, and what it looks like now,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Review a GitHub project from Twilio that sets up a voice agent using the new
    Realtime API, so we can see what the implementation looks like in practice, and
    get an idea how the websockets and connections are setup for such an application,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quickly review the React demo project from OpenAI that uses the Realtime API,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compare the pricing of these various options.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voice Agent Flows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before the OpenAI Realtime API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get a phone voice agent service working, there are some key services we require
  prefs: []
  type: TYPE_NORMAL
- en: Speech to Text ( e.g Deepgram),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLM/Agent ( e.g OpenAI),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text to Speech (e.g ElevenLabs).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These services are illustrated in the diagram below
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8dd1f33ba5808328d984fbd791914750.png)'
  prefs: []
  type: TYPE_IMG
- en: (source [https://github.com/twilio-labs/call-gpt](https://github.com/twilio-labs/call-gpt),
    MIT license)
  prefs: []
  type: TYPE_NORMAL
- en: That of course means integration with a number of services, and separate API
    requests for each parts.
  prefs: []
  type: TYPE_NORMAL
- en: The new OpenAI Realtime API allows us to bundle all of those together into a
    single request, hence the term, speech to speech.
  prefs: []
  type: TYPE_NORMAL
- en: After the OpenAI Realtime API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is what the flow diagram would look like for a similar new flow using the
    new OpenAI Realtime API.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b46168112d4e112560181c037971de44.png)'
  prefs: []
  type: TYPE_IMG
- en: Obviously this is a much simpler flow. What is happening is we are just passing
    the speech/audio from the phone call directly to the OpenAI Realtime API. No need
    for a speech to text intermediary service.
  prefs: []
  type: TYPE_NORMAL
- en: And on the response side, the Realtime API is again providing an audio stream
    as the response, which we can send right back to Twilio (i.e to the phone call
    response). So again, no need for an extra text to speech service, as it is all
    taken care of by the OpenAI Realtime API.
  prefs: []
  type: TYPE_NORMAL
- en: Source code review for a Twilio and Realtime API voice agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s look at some code samples for this. Twilio has provided a great github
    repository example for setting up this Twilio and OpenAI Realtime API flow. You
    can find it here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/twilio-samples/speech-assistant-openai-realtime-api-node?source=post_page-----7b136ef8483d--------------------------------)
    [## GitHub - twilio-samples/speech-assistant-openai-realtime-api-node'
  prefs: []
  type: TYPE_NORMAL
- en: Contribute to twilio-samples/speech-assistant-openai-realtime-api-node development
    by creating an account on GitHub.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/twilio-samples/speech-assistant-openai-realtime-api-node?source=post_page-----7b136ef8483d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Here are some excerpts from key parts of the code related to setting up
  prefs: []
  type: TYPE_NORMAL
- en: the websockets connection from Twilio to our application, so that we can receive
    audio from the caller, and send audio back,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and the websockets connection to the OpenAI Realtime API from our application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I have added some comments in the source code below to try and explain what
    is going on, expecially regarding the websocket connection between Twilio and
    our applicaion, and the websocket connection from our application to OpenAI. The
    triple dots (…) refere to sections of the source code that have been removed for
    brevity, since they are not critical to understanding the core features of how
    the flow works.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: So, that is how the new OpenAI Realtime API flow plays out in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the Twilio MediaStreams, you can read more about them [here](https://www.twilio.com/docs/voice/media-streams).
    They are a way to setup a websockets connection between a call to a Twilio phone
    number and your application. This allows streaming of audio from the call to and
    from you application, allowing you to build programmable voice applications over
    the phone.
  prefs: []
  type: TYPE_NORMAL
- en: To get to the code above running, you will need to setup a Twilio number and
    ngrok also. You can check out my other article over here for help setting those
    up.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://levelup.gitconnected.com/ai-voice-agent-with-twilio-express-and-openai-96e19c1e8035?source=post_page-----7b136ef8483d--------------------------------)
    [## AI Voice Agent with Twilio, Express and OpenAI'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get ChatGPT over the phone
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/ai-voice-agent-with-twilio-express-and-openai-96e19c1e8035?source=post_page-----7b136ef8483d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Since access to the OpenAI Realtime API has just been rolled, not everyone may
    have access just yet. I intially was not able to access it. Running the application
    worked, but as soon as it tries to connect to the OpenAI Realtime API I got a
    403 error. So in case you see the same issue, it could be related to not having
    access yet also.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef320cbbdec8e19721b97fe4e4cb01b7.png)'
  prefs: []
  type: TYPE_IMG
- en: React OpenAI Realtime API Demo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAI have also provided a great demo for testing out their Realtime API in
    the browser using a React app. I tested this out myself, and was very impressed
    with the speed of response from the voice agent coming from the Realtime API.
    The response is instant, there is no latency, and makes for a great user experience.
    I was definitley impressed when testing it out.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing a link to the source code here. It has intructions in the README.md
    for how to get setup
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/openai/openai-realtime-console?source=post_page-----7b136ef8483d--------------------------------)
    [## GitHub - openai/openai-realtime-console: React app for inspecting, building
    and debugging with the…'
  prefs: []
  type: TYPE_NORMAL
- en: React app for inspecting, building and debugging with the Realtime API - openai/openai-realtime-console
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/openai/openai-realtime-console?source=post_page-----7b136ef8483d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: This is a picture of what the application looks like once you get it running
    on local
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7c66d5839aa9c80f702df45586fc6195.png)'
  prefs: []
  type: TYPE_IMG
- en: (source [https://github.com/openai/openai-realtime-console](https://github.com/openai/openai-realtime-console),
    MIT license)
  prefs: []
  type: TYPE_NORMAL
- en: Pricing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s compare the cost the of using the OpenAI Realtime API versus a more conventional
    approach using Deepagram for speech to text (STT) and text to speech (TTS) and
    using OpenAI GPT-4o for the LLM part.
  prefs: []
  type: TYPE_NORMAL
- en: Comparison using the prices from their websites shows that for a 1 minute conversation,
    with the caller speaking half the time, and the AI agent speaking the other half,
    the cost per minute using Deepgram and GPT-4o would be $0.0117/minute, whereas
    using the OpenAI Realtime API would be $0.15/minute.
  prefs: []
  type: TYPE_NORMAL
- en: That means using the OpenAI Realtime API would be just over 10x the price per
    minute.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/27e7d126e7f638d7166645bb22c3464c.png)'
  prefs: []
  type: TYPE_IMG
- en: It does sound like a fair amount more expensive, though we should balance that
    with some of the benefits the OpenAI Realtime API could provide, including
  prefs: []
  type: TYPE_NORMAL
- en: reduced latencies, crucial for having a good voice experience,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ease of setup due to fewer moving parts,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: conversation interruption handling provided out of the box.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, please do be aware that prices can change over time, so the prices you
    find at the time of reading this article, may not be the same as those reflected
    above.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hope that was helpful! What do you think of the new OpenAI Realtime API? Think
    you will be using it in any upcoming projects?
  prefs: []
  type: TYPE_NORMAL
- en: While we are here, are there any other tutorials or articles around voice agents
    andvoice AI you would be interested in? I am deep diving into that field a bit
    just now, so would be happy to look into anything people find interesting.
  prefs: []
  type: TYPE_NORMAL
- en: Happy hacking!
  prefs: []
  type: TYPE_NORMAL
- en: '*All image provided are by the author, unless stated otherwise*'
  prefs: []
  type: TYPE_NORMAL
