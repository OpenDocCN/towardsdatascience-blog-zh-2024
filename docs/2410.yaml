- en: Exploring How the New OpenAI Realtime API Simplifies Voice Agent Flows
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探讨新的 OpenAI 实时 API 如何简化语音代理流程
- en: 原文：[https://towardsdatascience.com/exploring-how-the-new-openai-realtime-api-simplifies-voice-agent-flows-7b136ef8483d?source=collection_archive---------7-----------------------#2024-10-03](https://towardsdatascience.com/exploring-how-the-new-openai-realtime-api-simplifies-voice-agent-flows-7b136ef8483d?source=collection_archive---------7-----------------------#2024-10-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/exploring-how-the-new-openai-realtime-api-simplifies-voice-agent-flows-7b136ef8483d?source=collection_archive---------7-----------------------#2024-10-03](https://towardsdatascience.com/exploring-how-the-new-openai-realtime-api-simplifies-voice-agent-flows-7b136ef8483d?source=collection_archive---------7-----------------------#2024-10-03)
- en: Setting up a Voice Agent using Twilio and the OpenAI Realtime API
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Twilio 和 OpenAI 实时 API 设置语音代理
- en: '[](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)[![Sami
    Maameri](../Images/9e9892fe7d3cc53ad1c4d165145878ef.png)](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)
    [Sami Maameri](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)[![Sami
    Maameri](../Images/9e9892fe7d3cc53ad1c4d165145878ef.png)](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)
    [Sami Maameri](https://medium.com/@ssmaameri?source=post_page---byline--7b136ef8483d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)
    ·8 min read·Oct 3, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7b136ef8483d--------------------------------)
    ·8 分钟阅读·2024 年 10 月 3 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'At the recent OpenAI Dev Day on October 1st, 2024, OpenAI’s biggest release
    was the reveal of their Realtime API:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2024 年 10 月 1 日的 OpenAI 开发者日活动上，OpenAI 最大的发布是他们的实时 API 的揭晓：
- en: “Today, we’re introducing a public beta of the Realtime API, enabling all paid
    developers to build low-latency, multimodal experiences in their apps.
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “今天，我们发布了实时 API 的公共 Beta 版本，使所有付费开发者能够在他们的应用中构建低延迟、多模态体验。
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Similar to ChatGPT’s Advanced Voice Mode, the Realtime API supports natural
    speech-to-speech conversations using the [six preset voices](https://platform.openai.com/docs/guides/text-to-speech)
    already supported in the API.”
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 类似于 ChatGPT 的高级语音模式，实时 API 支持使用 [六种预设语音](https://platform.openai.com/docs/guides/text-to-speech)进行自然的语音对语音对话，这些语音已经在
    API 中得到支持。”
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '(source: OpenAI website)'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: （来源：OpenAI 网站）
- en: As per their message, some of its key benefits include low latency, and its
    speech to speech capabilities. Let’s see how that plays out in practice in terms
    of building out voice AI agents.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 根据他们的信息，它的主要优势包括低延迟和语音对语音功能。让我们看看在实践中，构建语音 AI 代理时它如何发挥作用。
- en: It also has an interruption handling feature, so that the realtime stream will
    stop sending audio if it detects you are trying to speak over it, a useful feature
    for sure when building voice agents.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 它还具备中断处理功能，能够检测到你试图插话时停止发送音频，这对于构建语音代理来说无疑是一个非常有用的功能。
- en: Contents
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: 'In this article we will:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将：
- en: Compare what a phone voice agent flow might have looked like before the Realtime
    API, and what it looks like now,
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较在实时 API 出现之前和现在电话语音代理流程的不同，
- en: Review a GitHub project from Twilio that sets up a voice agent using the new
    Realtime API, so we can see what the implementation looks like in practice, and
    get an idea how the websockets and connections are setup for such an application,
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审查 Twilio 提供的 GitHub 项目，该项目使用新的实时 API 设置语音代理，帮助我们了解实际实现的样子，并了解 websockets 和连接如何为此类应用程序进行设置，
- en: Quickly review the React demo project from OpenAI that uses the Realtime API,
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速回顾 OpenAI 使用实时 API 的 React 演示项目，
- en: Compare the pricing of these various options.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较这些不同选项的定价。
- en: Voice Agent Flows
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音代理流程
- en: Before the OpenAI Realtime API
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 OpenAI 实时 API 之前
- en: To get a phone voice agent service working, there are some key services we require
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要使电话语音代理服务正常工作，我们需要一些关键的服务
- en: Speech to Text ( e.g Deepgram),
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音转文本（例如 Deepgram），
- en: LLM/Agent ( e.g OpenAI),
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM/代理（例如 OpenAI），
- en: Text to Speech (e.g ElevenLabs).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本转语音（例如 ElevenLabs）。
- en: These services are illustrated in the diagram below
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这些服务在下面的图示中进行了说明
- en: '![](../Images/8dd1f33ba5808328d984fbd791914750.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8dd1f33ba5808328d984fbd791914750.png)'
- en: (source [https://github.com/twilio-labs/call-gpt](https://github.com/twilio-labs/call-gpt),
    MIT license)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: （来源 [https://github.com/twilio-labs/call-gpt](https://github.com/twilio-labs/call-gpt)，MIT
    许可）
- en: That of course means integration with a number of services, and separate API
    requests for each parts.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这当然意味着与多个服务的集成，并为每个部分发送独立的 API 请求。
- en: The new OpenAI Realtime API allows us to bundle all of those together into a
    single request, hence the term, speech to speech.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 新的 OpenAI Realtime API 允许我们将所有这些请求捆绑成一个单一的请求，因此称之为语音到语音。
- en: After the OpenAI Realtime API
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 OpenAI Realtime API 之后
- en: This is what the flow diagram would look like for a similar new flow using the
    new OpenAI Realtime API.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用新的 OpenAI Realtime API 时，类似的新流程的流程图。
- en: '![](../Images/b46168112d4e112560181c037971de44.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b46168112d4e112560181c037971de44.png)'
- en: Obviously this is a much simpler flow. What is happening is we are just passing
    the speech/audio from the phone call directly to the OpenAI Realtime API. No need
    for a speech to text intermediary service.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这是一个更简单的流程。发生的情况是，我们将电话中的语音/音频直接传送到 OpenAI Realtime API。不需要语音转文本的中介服务。
- en: And on the response side, the Realtime API is again providing an audio stream
    as the response, which we can send right back to Twilio (i.e to the phone call
    response). So again, no need for an extra text to speech service, as it is all
    taken care of by the OpenAI Realtime API.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在响应端，Realtime API 再次提供一个音频流作为响应，我们可以将其直接发送回 Twilio（即发送给电话响应）。因此，再次无需额外的文本转语音服务，因为这一切都由
    OpenAI Realtime API 处理。
- en: Source code review for a Twilio and Realtime API voice agent
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Twilio 和 Realtime API 语音代理的源代码审查
- en: 'Let’s look at some code samples for this. Twilio has provided a great github
    repository example for setting up this Twilio and OpenAI Realtime API flow. You
    can find it here:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些代码示例。Twilio 提供了一个很好的 GitHub 仓库示例，用于设置 Twilio 和 OpenAI Realtime API 流程。你可以在这里找到它：
- en: '[](https://github.com/twilio-samples/speech-assistant-openai-realtime-api-node?source=post_page-----7b136ef8483d--------------------------------)
    [## GitHub - twilio-samples/speech-assistant-openai-realtime-api-node'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/twilio-samples/speech-assistant-openai-realtime-api-node?source=post_page-----7b136ef8483d--------------------------------)
    [## GitHub - twilio-samples/speech-assistant-openai-realtime-api-node'
- en: Contribute to twilio-samples/speech-assistant-openai-realtime-api-node development
    by creating an account on GitHub.
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过在 GitHub 上创建一个账户，参与 twilio-samples/speech-assistant-openai-realtime-api-node
    开发。
- en: github.com](https://github.com/twilio-samples/speech-assistant-openai-realtime-api-node?source=post_page-----7b136ef8483d--------------------------------)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/twilio-samples/speech-assistant-openai-realtime-api-node?source=post_page-----7b136ef8483d--------------------------------)
- en: Here are some excerpts from key parts of the code related to setting up
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是与设置相关的代码关键部分的摘录
- en: the websockets connection from Twilio to our application, so that we can receive
    audio from the caller, and send audio back,
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Twilio 到我们应用程序的 websockets 连接，这样我们就可以接收来电者的音频，并将音频发送回去，
- en: and the websockets connection to the OpenAI Realtime API from our application.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及我们应用程序与 OpenAI Realtime API 之间的 websockets 连接。
- en: I have added some comments in the source code below to try and explain what
    is going on, expecially regarding the websocket connection between Twilio and
    our applicaion, and the websocket connection from our application to OpenAI. The
    triple dots (…) refere to sections of the source code that have been removed for
    brevity, since they are not critical to understanding the core features of how
    the flow works.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我在下面的源代码中添加了一些注释，以尝试解释发生了什么，特别是关于 Twilio 与我们应用程序之间的 websocket 连接，以及我们应用程序与 OpenAI
    之间的 websocket 连接。省略号 (…) 表示已删除的源代码部分，目的是为了简化展示，因为这些部分对于理解流程的核心功能并不关键。
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: So, that is how the new OpenAI Realtime API flow plays out in practice.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这就是新 OpenAI Realtime API 流程在实际中的应用方式。
- en: Regarding the Twilio MediaStreams, you can read more about them [here](https://www.twilio.com/docs/voice/media-streams).
    They are a way to setup a websockets connection between a call to a Twilio phone
    number and your application. This allows streaming of audio from the call to and
    from you application, allowing you to build programmable voice applications over
    the phone.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Twilio MediaStreams，你可以在 [这里](https://www.twilio.com/docs/voice/media-streams)
    阅读更多内容。它们是建立电话与 Twilio 电话号码之间以及与应用程序之间 websockets 连接的一种方式。这允许从电话中将音频流传输到你的应用程序，允许你在电话上构建可编程语音应用程序。
- en: To get to the code above running, you will need to setup a Twilio number and
    ngrok also. You can check out my other article over here for help setting those
    up.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让上面的代码运行，你需要设置一个 Twilio 号码，并且需要使用 ngrok。你可以查看我其他的文章，了解如何设置这些内容。
- en: '[](https://levelup.gitconnected.com/ai-voice-agent-with-twilio-express-and-openai-96e19c1e8035?source=post_page-----7b136ef8483d--------------------------------)
    [## AI Voice Agent with Twilio, Express and OpenAI'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://levelup.gitconnected.com/ai-voice-agent-with-twilio-express-and-openai-96e19c1e8035?source=post_page-----7b136ef8483d--------------------------------)
    [## 使用 Twilio、Express 和 OpenAI 构建 AI 语音代理'
- en: Let’s get ChatGPT over the phone
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 让我们通过电话来使用 ChatGPT
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/ai-voice-agent-with-twilio-express-and-openai-96e19c1e8035?source=post_page-----7b136ef8483d--------------------------------)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[levelup.gitconnected.com](https://levelup.gitconnected.com/ai-voice-agent-with-twilio-express-and-openai-96e19c1e8035?source=post_page-----7b136ef8483d--------------------------------)'
- en: Since access to the OpenAI Realtime API has just been rolled, not everyone may
    have access just yet. I intially was not able to access it. Running the application
    worked, but as soon as it tries to connect to the OpenAI Realtime API I got a
    403 error. So in case you see the same issue, it could be related to not having
    access yet also.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 OpenAI 实时 API 刚刚发布，可能并非所有人都能访问。我最初也无法访问它。运行应用程序是可以的，但一旦尝试连接 OpenAI 实时 API，就会出现
    403 错误。因此，如果你遇到相同的问题，可能也是因为暂时没有权限访问。
- en: '![](../Images/ef320cbbdec8e19721b97fe4e4cb01b7.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef320cbbdec8e19721b97fe4e4cb01b7.png)'
- en: React OpenAI Realtime API Demo
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: React OpenAI 实时 API 演示
- en: OpenAI have also provided a great demo for testing out their Realtime API in
    the browser using a React app. I tested this out myself, and was very impressed
    with the speed of response from the voice agent coming from the Realtime API.
    The response is instant, there is no latency, and makes for a great user experience.
    I was definitley impressed when testing it out.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 还提供了一个很棒的演示，可以通过 React 应用程序在浏览器中测试他们的实时 API。我自己也测试了一下，对语音代理从实时 API 中获得的响应速度印象深刻。响应是即时的，没有延迟，带来了极好的用户体验。我在测试时绝对感到印象深刻。
- en: Sharing a link to the source code here. It has intructions in the README.md
    for how to get setup
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这里分享一个源代码的链接，README.md 中有关于如何进行设置的说明。
- en: '[](https://github.com/openai/openai-realtime-console?source=post_page-----7b136ef8483d--------------------------------)
    [## GitHub - openai/openai-realtime-console: React app for inspecting, building
    and debugging with the…'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/openai/openai-realtime-console?source=post_page-----7b136ef8483d--------------------------------)
    [## GitHub - openai/openai-realtime-console：用于检查、构建和调试的 React 应用程序…]'
- en: React app for inspecting, building and debugging with the Realtime API - openai/openai-realtime-console
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用于检查、构建和调试实时 API 的 React 应用程序 - openai/openai-realtime-console
- en: github.com](https://github.com/openai/openai-realtime-console?source=post_page-----7b136ef8483d--------------------------------)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/openai/openai-realtime-console?source=post_page-----7b136ef8483d--------------------------------)'
- en: This is a picture of what the application looks like once you get it running
    on local
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是运行在本地后的应用程序界面截图。
- en: '![](../Images/7c66d5839aa9c80f702df45586fc6195.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c66d5839aa9c80f702df45586fc6195.png)'
- en: (source [https://github.com/openai/openai-realtime-console](https://github.com/openai/openai-realtime-console),
    MIT license)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: （来源 [https://github.com/openai/openai-realtime-console](https://github.com/openai/openai-realtime-console)，MIT
    许可证）
- en: Pricing
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定价
- en: Let’s compare the cost the of using the OpenAI Realtime API versus a more conventional
    approach using Deepagram for speech to text (STT) and text to speech (TTS) and
    using OpenAI GPT-4o for the LLM part.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下使用 OpenAI 实时 API 与采用传统方法的成本，传统方法使用 Deepgram 进行语音转文本（STT）和文本转语音（TTS），并使用
    OpenAI GPT-4o 作为大型语言模型（LLM）部分。
- en: Comparison using the prices from their websites shows that for a 1 minute conversation,
    with the caller speaking half the time, and the AI agent speaking the other half,
    the cost per minute using Deepgram and GPT-4o would be $0.0117/minute, whereas
    using the OpenAI Realtime API would be $0.15/minute.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 根据他们网站上的价格进行比较，假设进行 1 分钟的对话，来电者说话一半时间，AI 代理说话另一半时间，使用 Deepgram 和 GPT-4o 的每分钟费用为
    $0.0117，而使用 OpenAI 实时 API 的费用为 $0.15/分钟。
- en: That means using the OpenAI Realtime API would be just over 10x the price per
    minute.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着使用 OpenAI 实时 API 的费用将是每分钟价格的 10 倍多一点。
- en: '![](../Images/27e7d126e7f638d7166645bb22c3464c.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27e7d126e7f638d7166645bb22c3464c.png)'
- en: It does sound like a fair amount more expensive, though we should balance that
    with some of the benefits the OpenAI Realtime API could provide, including
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来确实更贵了一些，尽管我们应该权衡一下 OpenAI 实时 API 所提供的一些好处，包括
- en: reduced latencies, crucial for having a good voice experience,
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少延迟，对于提供良好的语音体验至关重要，
- en: ease of setup due to fewer moving parts,
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于部件更少，设置更加简便，
- en: conversation interruption handling provided out of the box.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供的对话中断处理功能是开箱即用的。
- en: Also, please do be aware that prices can change over time, so the prices you
    find at the time of reading this article, may not be the same as those reflected
    above.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请注意，价格可能随时间变化，因此你在阅读本文时看到的价格，可能与上述价格有所不同。
- en: Conclusion
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Hope that was helpful! What do you think of the new OpenAI Realtime API? Think
    you will be using it in any upcoming projects?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这对你有帮助！你怎么看待新的 OpenAI 实时 API？你认为自己会在即将到来的项目中使用它吗？
- en: While we are here, are there any other tutorials or articles around voice agents
    andvoice AI you would be interested in? I am deep diving into that field a bit
    just now, so would be happy to look into anything people find interesting.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 既然在这里，你是否对语音代理和语音 AI 相关的其他教程或文章感兴趣？我目前正深入研究这一领域，因此如果有人对某些内容感兴趣，我会很高兴进一步了解。
- en: Happy hacking!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 祝你编程愉快！
- en: '*All image provided are by the author, unless stated otherwise*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*所有图片均由作者提供，除非另有说明*'
