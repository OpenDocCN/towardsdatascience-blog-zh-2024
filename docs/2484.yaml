- en: What Goes Into AI? Exploring the GenAI Technology Stack
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么构成了AI？探索GenAI技术栈
- en: 原文：[https://towardsdatascience.com/what-goes-into-ai-exploring-the-genai-technology-stack-7147d147997b?source=collection_archive---------1-----------------------#2024-10-11](https://towardsdatascience.com/what-goes-into-ai-exploring-the-genai-technology-stack-7147d147997b?source=collection_archive---------1-----------------------#2024-10-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-goes-into-ai-exploring-the-genai-technology-stack-7147d147997b?source=collection_archive---------1-----------------------#2024-10-11](https://towardsdatascience.com/what-goes-into-ai-exploring-the-genai-technology-stack-7147d147997b?source=collection_archive---------1-----------------------#2024-10-11)
- en: You’ve heard of OpenAI and Nvidia, but do you know who else is involved in the
    AI wave and how they all fit together?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你听说过OpenAI和Nvidia，但你知道还有谁参与了AI浪潮以及它们是如何互相配合的吗？
- en: '[](https://medium.com/@charles.ide?source=post_page---byline--7147d147997b--------------------------------)[![Charles
    Ide](../Images/75087ff0756ad8667558dabe1d5e13d2.png)](https://medium.com/@charles.ide?source=post_page---byline--7147d147997b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7147d147997b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7147d147997b--------------------------------)
    [Charles Ide](https://medium.com/@charles.ide?source=post_page---byline--7147d147997b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@charles.ide?source=post_page---byline--7147d147997b--------------------------------)[![Charles
    Ide](../Images/75087ff0756ad8667558dabe1d5e13d2.png)](https://medium.com/@charles.ide?source=post_page---byline--7147d147997b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7147d147997b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7147d147997b--------------------------------)
    [Charles Ide](https://medium.com/@charles.ide?source=post_page---byline--7147d147997b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7147d147997b--------------------------------)
    ·16 min read·Oct 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7147d147997b--------------------------------)
    ·阅读时长16分钟·2024年10月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/4f18907f17593d8b33222dfd55947307.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f18907f17593d8b33222dfd55947307.png)'
- en: Image by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Several months ago, I visited the MoMA in NYC and saw the [work *Anatomy of
    an AI System* by Kate Crawford and Vladan Joler](https://www.moma.org/collection/works/401279).
    The work examines the Amazon Alexa supply chain from raw resource extraction to
    devise disposal. This made me to think about everything that goes into producing
    today’s generative AI (GenAI) powered applications. By digging into this question,
    I came to understand the many layers of physical and digital engineering that
    GenAI applications are built upon.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 几个月前，我参观了纽约的MoMA，并看到了Kate Crawford和Vladan Joler的[作品*《AI系统的解剖》*](https://www.moma.org/collection/works/401279)。这件作品探讨了亚马逊Alexa的供应链，从原材料的提取到设备的处理。这让我开始思考当今生成性AI（GenAI）应用的生产过程。通过深入挖掘这个问题，我开始理解构成GenAI应用的多层次物理和数字工程。
- en: I’ve written this piece to introduce readers to the major components of the
    GenAI value chain, what role each plays, and who the major players are at each
    stage. Along the way, I hope to illustrate the range of businesses powering the
    growth of AI, how different technologies build upon each other, and where vulnerabilities
    and bottlenecks exist. Starting with the user-facing applications emerging from
    technology giants like Google and the latest batch of startups, we’ll work backward
    through the value chain down to the sand and rare earth metals that go into computer
    chips.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我写这篇文章是为了向读者介绍GenAI价值链的主要组成部分，每个环节扮演的角色，以及每个阶段的主要参与者。在此过程中，我希望能够展示推动AI增长的各种业务，技术如何互相依赖，以及在哪里存在脆弱性和瓶颈。从面向用户的应用开始，这些应用来自像Google这样的科技巨头和最新一批初创公司，我们将向后追溯整个价值链，直到计算机芯片所需的沙子和稀土金属。
- en: End Application Builders
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终应用构建者
- en: '![](../Images/64a4e7fc1642b601380c833c9c0b5af3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64a4e7fc1642b601380c833c9c0b5af3.png)'
- en: From scaled startups like Palantir to tech giants like Apple and non-technology
    companies like Goldman Sachs, everyone is developing AI solutions. Image by the
    author.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从像Palantir这样的扩展型初创公司，到像Apple这样的科技巨头，再到像Goldman Sachs这样的非科技公司，每个人都在开发AI解决方案。图片来源：作者。
- en: Technology giants, corporate IT departments, and legions of new startups are
    in the early phases of experimenting with potential use cases for GenAI. These
    applications may be the start of a new paradigm in computer applications, marked
    by radical new systems of human-computer interaction and unprecedented capabilities
    to understand and leverage unstructured and previously untapped data sources (e.g.,
    audio).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 科技巨头、企业IT部门和大量新兴初创公司目前正处于实验GenAI潜在应用场景的初期阶段。这些应用程序可能是计算机应用中新范式的开端，其特点是人机交互系统的根本性创新以及理解和利用非结构化和此前未开发的数据源（如音频）的前所未有的能力。
- en: 'Many of the most impactful advances in computing have come from advances in
    human-computer interaction (HCI). From the development of the GUI to the mouse
    to the touch screen, these advances have greatly expanded the leverage users gain
    from computing tools. GenAI models will further remove friction from this interface
    by equipping computers with the power and flexibility of human language. Users
    will be able to issue instructions and tasks to computers just as they might a
    reliable human assistant. Some examples of products innovating in the HCI space
    are:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机领域一些最具影响力的进步来自于人机交互（HCI）的发展。从图形用户界面（GUI）的开发到鼠标，再到触摸屏，这些进步大大扩展了用户从计算工具中获得的杠杆效应。GenAI模型将进一步消除这一界面的摩擦，通过赋予计算机与人类语言相同的能力和灵活性，使用户能够像向可靠的人类助手发出指令一样向计算机发布指令和任务。以下是一些在人机交互领域创新的产品示例：
- en: '[**Siri**](https://www.apple.com/siri/) **(AI Voice Assistant) —** Enhances
    Apple’s mobile assistant with the capability to understand broader requests and
    questions'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Siri**](https://www.apple.com/siri/) **（AI语音助手）—** 增强了苹果移动助手的能力，可以理解更广泛的请求和问题'
- en: '[**Palantir’s AIP**](https://www.palantir.com/platforms/aip/) **(Autonomous
    Agents) —** Strips complexity from large powerful tools through a chat interface
    that directs users to the desired functionality and actions'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Palantir’s AIP**](https://www.palantir.com/platforms/aip/) **（自主代理）—** 通过一个聊天界面，简化了大型强大工具的复杂性，引导用户执行所需功能和操作'
- en: '[**Lilac Labs**](https://www.ycombinator.com/companies/lilac-labs) **(Customer
    Service Automation) —** Automates drive-through customer ordering with voice AI'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Lilac Labs**](https://www.ycombinator.com/companies/lilac-labs) **（客户服务自动化）—**
    通过语音AI自动化驾车自取客户的点餐'
- en: 'GenAI equips computer systems with agency and flexibility that was previously
    impossible when sets of preprogrammed procedures guided their functionality and
    their data inputs needed to fit well-defined rules established by the programmer.
    This flexibility allows applications to perform more complex and open ended knowledge
    tasks that were previously strictly in the human domain. Some examples of new
    applications leveraging this flexibility are:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI赋予计算机系统以前无法实现的自主性和灵活性，传统的计算机功能是由一组预编程的程序指导，并且其数据输入需要符合程序员设定的明确规则。这种灵活性使得应用程序能够执行更复杂和开放的知识任务，这些任务之前仅限于人类领域。一些利用这种灵活性的新的应用示例如下：
- en: '[**GitHub Copilot**](https://github.com/features/copilot) **(Coding Assistant)
    —** Amplifies programmer productivity by implementing code based on the user’s
    intent and existing code base'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**GitHub Copilot**](https://github.com/features/copilot) **（编码助手）—** 通过根据用户的意图和现有代码库实现代码，从而提高程序员的生产力'
- en: '[**LenAI**](https://www.oliverwyman.com/our-expertise/insights/2023/sep/approaching-generative-ai-lenai.html)
    **(Knowledge Assistant) —** Saves knowledge workers time by summarizing meetings,
    extracting critical insights from discussions, and drafting communications'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**LenAI**](https://www.oliverwyman.com/our-expertise/insights/2023/sep/approaching-generative-ai-lenai.html)
    **（知识助手）—** 通过总结会议、提取讨论中的关键见解和草拟通信，节省知识工作者的时间'
- en: '[**Perplexity**](https://www.perplexity.ai/) **(AI Search) —** Answers user
    questions reliably with citations by synthesizing traditional internet searches
    with AI-generated summaries of internet sources'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Perplexity**](https://www.perplexity.ai/) **（AI搜索）—** 通过综合传统的互联网搜索和AI生成的互联网来源摘要，可靠地回答用户的问题并提供引用'
- en: A diverse group of players is driving the development of these use cases. Hordes
    of startups are springing up, [with 86 of Y Combinator’s W24 batch focused on
    AI technologies](https://techcrunch.com/2024/04/03/y-combinator-winter-2024-demo-day-ai-startups-standouts/).
    Major tech companies like Google have also introduced GenAI products and features.
    For instance, Google is leveraging its Gemini LLM to summarize results in its
    core search products. Traditional enterprises are launching major initiatives
    to understand how GenAI can complement their strategy and operations. [JP Morgan
    CEO Jamie Dimon said](https://www.entrepreneur.com/business-news/ceo-jamie-dimon-how-jpmorgan-chase-uses-ai-in-the-workplace/477036)
    AI is “unbelievable for marketing, risk, fraud. It’ll help you do your job better.”
    As companies understand how AI can solve problems and drive value, use cases and
    demand for GenAI will multiply.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个多元化的玩家群体正在推动这些应用案例的发展。大量初创公司如雨后春笋般涌现，[其中86家来自Y Combinator W24批次专注于AI技术](https://techcrunch.com/2024/04/03/y-combinator-winter-2024-demo-day-ai-startups-standouts/)。像谷歌这样的主要科技公司也推出了生成式AI产品和功能。例如，谷歌正在利用其Gemini大语言模型在其核心搜索产品中总结结果。传统企业也在推出重要举措，旨在理解生成式AI如何补充他们的战略和运营。[摩根大通CEO
    Jamie Dimon表示](https://www.entrepreneur.com/business-news/ceo-jamie-dimon-how-jpmorgan-chase-uses-ai-in-the-workplace/477036)，AI在“市场营销、风险管理、欺诈方面是不可思议的，它将帮助你更好地完成工作。”随着企业逐渐理解AI如何解决问题并创造价值，生成式AI的应用案例和需求将成倍增长。
- en: AI Model Builders
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能模型构建者
- en: '![](../Images/a3f2f947eea3bca56c3fddd3347112cd.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a3f2f947eea3bca56c3fddd3347112cd.png)'
- en: Illustration of the transformer AI architecture. Image by [Sing et. al](https://www.researchgate.net/publication/342045332_NLP-Based_Approach_for_Predicting_HMI_State_Sequences_Towards_Monitoring_Operator_Situational_Awareness)
    used under Creative Commons 4.0 license.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器AI架构示意图。图片由[Sing等人](https://www.researchgate.net/publication/342045332_NLP-Based_Approach_for_Predicting_HMI_State_Sequences_Towards_Monitoring_Operator_Situational_Awareness)提供，并根据Creative
    Commons 4.0许可证使用。
- en: 'With the release of OpenAI’s ChatGPT (powered by the GPT-3.5 model) in late
    2022, GenAI [exploded into the public consciousness](https://www.nytimes.com/2023/02/03/technology/chatgpt-openai-artificial-intelligence.html).
    Today, models like Claude (Anthropic), Gemini (Google), and Llama (Meta) have
    challenged GPT for supremacy. The model provider market and development landscape
    are still in their infancy, and many open questions remain, such as:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 随着OpenAI的ChatGPT（由GPT-3.5模型提供支持）在2022年底发布，生成式AI[迅速进入了公众视野](https://www.nytimes.com/2023/02/03/technology/chatgpt-openai-artificial-intelligence.html)。如今，像Claude（Anthropic）、Gemini（谷歌）和Llama（Meta）这样的模型已挑战GPT的主导地位。模型提供商市场和开发格局仍处于初期阶段，许多未解之谜仍然存在，例如：
- en: Will smaller domain/task-specific models proliferate, or will large models handle
    all tasks?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型领域/任务特定的模型会大量涌现，还是大型模型将处理所有任务？
- en: How far can model sophistication and capability advance under the current transformer
    architecture?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在当前的变压器架构下，模型的复杂性和能力能够发展到何种程度？
- en: How will capabilities advance as model training approaches the limit of all
    human-created text data?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着模型训练接近所有人类创作文本数据的极限，能力将如何发展？
- en: Which players will challenge the current supremacy of OpenAI?
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些玩家将挑战当前OpenAI的主导地位？
- en: While speculating about the capability limits of artificial intelligence is
    beyond the scope of this discussion, the market for GenAI models is likely large
    ([many prominent investors certainly value it highly](https://www.wsj.com/tech/ai/openai-nearly-doubles-valuation-to-157-billion-in-funding-round-ee220607)).
    What do model builders do to justify such high valuations and so much excitement?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然关于人工智能能力极限的猜测超出了本讨论的范围，但生成式AI模型的市场可能非常庞大（[许多知名投资者确实高度重视它](https://www.wsj.com/tech/ai/openai-nearly-doubles-valuation-to-157-billion-in-funding-round-ee220607)）。模型构建者做了什么来证明如此高的估值和如此巨大的兴奋？
- en: The research teams at companies like OpenAI are responsible for making architectural
    choices, compiling and preprocessing training datasets, managing training infrastructure,
    and more. Research scientists in this field are rare and highly valued; with the
    [average engineer at OpenAI earning over $900k](https://news.ycombinator.com/item?id=36460082).
    Not many companies can attract and retain people with this highly specialized
    skillset required to do this work.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 像OpenAI这样的公司的研究团队负责做出架构选择、编制和预处理训练数据集、管理训练基础设施等工作。该领域的研究科学家非常稀缺且高度重视；[OpenAI的平均工程师年薪超过90万美元](https://news.ycombinator.com/item?id=36460082)。并非许多公司能够吸引和留住拥有这种高度专业技能的人才来完成这些工作。
- en: Compiling the training datasets involves crawling, compiling, and processing
    all text (or audio or visual) data available on the internet and other sources
    (e.g., digitized libraries). After compiling these raw datasets, engineers layer
    in relevant metadata (e.g., tagging categories), tokenize data into chunks for
    model processing, format data into efficient training file formats, and impose
    quality control measures.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 编译训练数据集涉及爬取、编译和处理所有可用的文本（或音频或视觉）数据，这些数据来自互联网和其他来源（例如数字化图书馆）。在编译这些原始数据集之后，工程师会加入相关的元数据（例如标记分类），将数据分割成适合模型处理的块，格式化数据为高效的训练文件格式，并实施质量控制措施。
- en: While the market for AI model-powered products and services [may be worth trillions
    within a decade](https://www.grandviewresearch.com/industry-analysis/artificial-intelligence-ai-market),
    many barriers to entry prevent all but the most well-resourced companies from
    building cutting-edge models. The highest barrier to entry is the millions to
    billions of capital investment required for model training. To train the latest
    models, companies must either construct their own data centers or make significant
    purchases from cloud service providers to leverage their data centers. While Moore’s
    law continues to rapidly lower the price of computing power, this is more than
    offset by the rapid scale up in model sizes and computation requirements. Training
    the latest cutting-edge models requires billions in data center investment (in
    March 2024, media reports described an [investment of $100B by OpenAI and Microsoft](https://www.reuters.com/technology/microsoft-openai-planning-100-billion-data-center-project-information-reports-2024-03-29/)
    on data centers to train next gen models). Few companies can afford to allocate
    billions toward training an AI model (only tech giants or exceedingly well-funded
    startups like Anthropic and [Safe Superintelligence](https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/)).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管由人工智能模型驱动的产品和服务的市场[可能在十年内达到数万亿美元的规模](https://www.grandviewresearch.com/industry-analysis/artificial-intelligence-ai-market)，但许多进入壁垒使得除了资源雄厚的公司之外，几乎没有公司能够构建尖端模型。进入的最大壁垒是训练模型所需的数百万到数十亿美元的资本投资。为了训练最新的模型，公司必须自行建设数据中心，或者从云服务提供商那里进行大量采购，以利用他们的数据中心。尽管摩尔定律持续快速降低计算能力的价格，但这被模型规模和计算需求的迅速扩大所抵消。训练最新的尖端模型需要数十亿美元的数据中心投资（2024年3月，媒体报道了[OpenAI和微软计划投入1000亿美元建设数据中心，以训练下一代模型](https://www.reuters.com/technology/microsoft-openai-planning-100-billion-data-center-project-information-reports-2024-03-29/)）。很少有公司能够负担得起将数十亿美元用于训练AI模型（只有科技巨头或资金极为充足的初创公司如Anthropic和[Safe
    Superintelligence](https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/)）。
- en: Finding the right talent is also incredibly difficult. Attracting this specialized
    talent requires more than a 7-figure compensation package; it requires connections
    with the right fields and academic communities, and a compelling value proposition
    and vision for the technology’s future. Existing players’ high access to capital
    and domination of the specialized talent market will make it difficult for new
    entrants to challenge their position.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找合适的人才也非常困难。吸引这些专业人才不仅需要超过七位数的薪酬包，还需要与相关领域和学术社区建立联系，并提供有吸引力的价值主张以及对技术未来的愿景。现有企业在资金的高访问性和专门人才市场的主导地位，将使新进入者很难挑战其地位。
- en: Knowing a bit about the history of the AI model market helps us understand the
    current landscape and how the market may evolve. When ChatGPT burst onto the scene,
    it felt like a breakthrough revolution to many, but was it? Or was it another
    incremental (albeit impressive) improvement in a long series of advances that
    were invisible outside of the development world? The team that developed ChatGPT
    built upon decades of research and publicly available tools from industry, academia,
    and the open-source community. Most notable is the transformer architecture itself
    — the critical insight driving not just ChatGPT, but most AI breakthroughs in
    the past five years. First proposed by Google in their 2017 paper [Attention is
    All You Need](https://research.google/pubs/attention-is-all-you-need/), the transformer
    architecture is the foundation for models like Stable Diffusion, GPT-4, and Midjourney.
    The [authors of that 2017 paper have founded some of the most prominent AI startups](https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/)
    (e.g., CharacterAI, Cohere).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 了解一点关于AI模型市场的历史，有助于我们理解当前的格局以及市场可能的发展趋势。当ChatGPT首次登场时，许多人觉得它是一次突破性的革命，但真的是这样吗？还是说它只是长期以来发展过程中不可见的（尽管令人印象深刻的）进步之一？开发ChatGPT的团队是在几十年的研究和来自工业界、学术界以及开源社区的公开工具基础上构建的。最显著的是变换器架构本身——这一关键的洞察力不仅推动了ChatGPT，也推动了过去五年里大多数AI突破的发展。该架构最早由谷歌在2017年的论文《Attention
    is All You Need》中提出，[变换器架构](https://research.google/pubs/attention-is-all-you-need/)是如Stable
    Diffusion、GPT-4和Midjourney等模型的基础。那篇2017年论文的[作者们创办了一些最著名的AI初创公司](https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/)，例如CharacterAI和Cohere。
- en: Given the common transformer architecture, what will enable some models to “win”
    against others? Variables like model size, input data quality/quantity, and proprietary
    research differentiate models. Model size has shown to correlate with improved
    performance, and the best funded players could differentiate by investing more
    in model training to further scale up their models. Proprietary data sources (such
    as those possessed by Meta from its user base and Elon Musk’s xAI from Tesla’s
    driving videos) could help some models learn what other models don’t have access
    to. GenAI is still a highly active area of ongoing research — research breakthroughs
    at companies with the best talent will partially determine the pace of advancement.
    It’s also unclear how strategies and use cases will create opportunities for different
    players. Perhaps application builders leverage multiple models to reduce dependency
    risk or to align a model’s unique strengths with specific use cases (e.g., research,
    interpersonal communications).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于常见的变换器架构，是什么因素使某些模型能“胜过”其他模型？诸如模型大小、输入数据的质量/数量以及专有研究等变量是区分不同模型的关键。研究表明，模型大小与性能的提升相关，资金最充足的参与者可能通过投入更多资金进行模型训练，进一步扩展其模型，从而实现差异化。专有数据源（如Meta基于其用户群体的数据和埃隆·马斯克的xAI基于特斯拉驾驶视频的数据）可以帮助某些模型学习其他模型无法访问的内容。生成性人工智能（GenAI）仍然是一个高度活跃的研究领域——拥有最佳人才的公司在研究突破方面将部分决定进展的速度。同时，目前尚不清楚策略和应用场景将如何为不同的参与者创造机会。也许，应用开发者会利用多个模型来降低依赖风险，或将模型的独特优势与特定应用场景对接（例如，研究、人际沟通）。
- en: Cloud Service Providers & Data Center Operators
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云服务提供商与数据中心运营商
- en: '![](../Images/19b04dbc454892064f55210498e4e7bb.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19b04dbc454892064f55210498e4e7bb.png)'
- en: Cloud infrastructure market share. Image by [Statistica](https://www.statista.com/chart/18819/worldwide-market-share-of-leading-cloud-infrastructure-service-providers/)
    licensed under Creative Commons.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 云基础设施市场份额。图像来源：[Statistica](https://www.statista.com/chart/18819/worldwide-market-share-of-leading-cloud-infrastructure-service-providers/)，并根据创意共享许可使用。
- en: We discussed how model providers invest billions to build or rent computing
    resources to train these models. Where is that spending going? Much of it goes
    to cloud service providers like Microsoft’s Azure (used by OpenAI for GPT) and
    Amazon Web Services (used by Anthropic for Claude).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了模型提供商如何投资数十亿美元来建立或租赁计算资源以训练这些模型。这些支出都去哪了？其中大部分流向了像微软的Azure（OpenAI用于GPT）和亚马逊云服务（Anthropic用于Claude）这样的云服务提供商。
- en: Cloud service providers (CSPs) play a crucial role in the GenAI value chain
    by providing the necessary infrastructure for model training (they also often
    provide infrastructure to the end application builders, but this section will
    focus on their interactions with the model builders). Major model builders primarily
    do not own and operate their own computing facilities (known as data centers).
    Instead, they rent vast amounts of computing power from the hyper-scaler CSPs
    (AWS, Azure, and Google Cloud) and other providers.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商（CSPs）在生成型AI（GenAI）价值链中扮演着至关重要的角色，通过提供模型训练所需的基础设施（它们通常还为最终的应用程序构建者提供基础设施，但本节将重点讨论它们与模型构建者的互动）。主要的模型构建者通常不拥有和运营自己的计算设施（即数据中心）。相反，他们从超大规模CSP（如AWS、Azure和Google
    Cloud）以及其他提供商那里租用大量计算能力。
- en: CSPs produce the resource computing power (manufactured by inputting electricity
    to a specialized microchip, thousands of which comprise a data center). To train
    their models, engineers provide the computers operated by CSPs with instructions
    to make computationally expensive matrix calculations over their input datasets
    to calculate billions of parameters of model weights. This model training phase
    is responsible for the high upfront cost of investment. Once these weights are
    calculated (i.e., the model is trained), model providers use these parameters
    to respond to user queries (i.e., make predictions on a novel dataset). This is
    a less computationally expensive process known as inference, also done using CSP
    computing power.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: CSP提供计算能力这一资源（通过向专门的微芯片输入电力来生产，数千个这样的微芯片组成一个数据中心）。为了训练他们的模型，工程师向由CSP运营的计算机提供指令，进行计算密集型的矩阵计算，以计算模型权重的数十亿个参数。这个模型训练阶段是投资高昂的前期成本的主要来源。一旦这些权重被计算出来（即模型被训练好），模型提供商就使用这些参数来响应用户查询（即对新的数据集进行预测）。这是一种计算消耗较低的过程，称为推理，仍然需要使用CSP的计算能力。
- en: The cloud service provider’s role is building, maintaining, and administering
    data centers where this “computing power” resource is produced and used by model
    builders. CSP activities include acquiring computer chips from suppliers like
    Nvidia, “racking and stacking” server units in specialized facilities, and performing
    regular physical and digital maintenance. They also develop the entire software
    stack to manage these servers and provide developers with an interface to access
    the computing power and deploy their applications.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商的角色是建设、维护和管理数据中心，在这些数据中心中，“计算能力”资源被模型构建者生产并使用。CSP的活动包括从像Nvidia这样的供应商获取计算芯片，在专业设施中“架设和堆叠”服务器单元，以及进行定期的物理和数字维护。他们还开发整个软件堆栈来管理这些服务器，并为开发者提供接口，以访问计算能力并部署他们的应用程序。
- en: The principal operating expense for data centers is electricity, with AI-fueled
    data center expansion likely to drive a significant increase in electricity usage
    in the coming decades. For perspective, a standard query to ChatGPT uses ten times
    as much energy as an average Google Search. Goldman Sachs estimates that [AI demand
    will double the data center’s share of global electricity usage](https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand)
    by the decade’s end. Just as significant investments must be made in computing
    infrastructure to support AI, similar investments must be made to power this computing
    infrastructure.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心的主要运营费用是电力，随着AI驱动的数据中心扩展，预计未来几十年电力使用量将大幅增加。为了提供一些背景信息，标准的ChatGPT查询消耗的能源是普通Google搜索的十倍。高盛预计，[AI需求将使数据中心在全球电力使用中的份额到本世纪末翻倍](https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand)。正如必须对计算基础设施进行重大投资以支持AI一样，同样也必须对这些计算基础设施的电力供应进行类似的投资。
- en: Looking ahead, cloud service providers and their model builder partners are
    in a race to construct the largest and most powerful data centers capable of training
    the next generation models. The data centers of the future, like those under development
    by the partnership of Microsoft and OpenAI, will require thousands to millions
    of new cutting-edge microchips. The substantial capital expenditures by cloud
    service providers to construct these facilities are now driving record profits
    at the companies that help build those microchips, notably Nvidia (design) and
    TSMC (manufacturing).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，云服务提供商及其模型构建伙伴正在竞相构建最大的、最强大的数据中心，以支持下一代模型的训练。未来的数据中心，例如微软与OpenAI的合作开发的那些，将需要成千上万甚至百万个新型尖端微芯片。云服务提供商在建设这些设施时的巨大资本支出，正推动着帮助制造这些微芯片的公司创下纪录的利润，尤其是英伟达（设计）和台积电（制造）。
- en: Microchip Designers
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微芯片设计师
- en: '![](../Images/ee7289876c32a48708490648f06de2a1.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ee7289876c32a48708490648f06de2a1.png)'
- en: Image by [Laura Ockel on Unsplash](https://unsplash.com/photos/brown-wooden-framed-glass-window-ziFuECDh8hc)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Laura Ockel on Unsplash](https://unsplash.com/photos/brown-wooden-framed-glass-window-ziFuECDh8hc)
- en: At this point, everyone’s likely heard of Nvidia and its meteoric, AI-fueled
    stock market rise. It’s become a cliche to say that the tech giants are locked
    in an arms race and Nvidia is the only supplier, but is it true? For now, it is.
    Nvidia designs a form of [computer microchip](https://en.wikipedia.org/wiki/Microchip_Technology)
    known as a graphical processing unit (GPU) that is critical for AI model training.
    What is a GPU, and why is it so crucial for GenAI? Why are most conversations
    in AI chip design centered around Nvidia and not other microchip designers like
    Intel, AMD, or Qualcomm?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，大家可能都听说过英伟达及其由人工智能驱动的股市飙升。说科技巨头们陷入军备竞赛，而英伟达是唯一的供应商，这已经成了一个老生常谈的说法，但这是真的吗？目前来看，是的。英伟达设计了一种被称为[图形处理单元（GPU）](https://en.wikipedia.org/wiki/Microchip_Technology)的计算机微芯片，这对人工智能模型训练至关重要。那么，GPU是什么，它为何对生成式人工智能如此关键？为什么人工智能芯片设计领域的大多数讨论都集中在英伟达，而不是其他微芯片设计公司，如英特尔、AMD或高通？
- en: Graphical processing units (as the name suggests) were initially used to serve
    the computer graphics market. Graphics for CGI movies like Jurassic Park and video
    games like Doom require expensive matrix computations, but these computations
    can be done in parallel rather than in series. Standard computer processors (CPUs)
    are optimized for fast sequential computation (where the input to one step could
    be output from a prior step), but they cannot do large numbers of calculations
    in parallel. This optimization for “horizontally” scaled parallel computation
    rather than accelerated sequential computation was well-suited for computer graphics,
    and it also came to be perfect for AI training.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图形处理单元（GPU）（顾名思义）最初用于服务计算机图形市场。像《侏罗纪公园》这样的CGI电影和《毁灭战士》这样的电子游戏需要昂贵的矩阵运算，但这些运算可以并行进行，而不是串行。标准计算机处理器（CPU）优化的是快速的串行计算（其中一个步骤的输入可能是前一步的输出），但它们无法并行处理大量计算。这种优化的“横向”并行计算而非加速的串行计算，正好适用于计算机图形，也最终成为了人工智能训练的理想选择。
- en: Given GPUs served a niche market until the rise of video games in the late 90s,
    how did they come to dominate the AI hardware market, and how did GPU makers displace
    Silicon Valley’s original titans like Intel? In 2012, the program [AlexNet](https://en.wikipedia.org/wiki/AlexNet)
    won the ImageNet machine learning competition by using Nvidia GPUs to accelerate
    model training. They showed that the parallel computation power of GPUs was perfect
    for training ML models because like computer graphics, ML model training relied
    on highly parallel matrix computations. Today’s LLMs have expanded upon AlexNet’s
    initial breakthrough to scale up to quadrillions of arithmetic computations and
    billions of model parameters. With this explosion in parallel computing demand
    since AlexNet, Nvidia has positioned itself as the only potential chip for machine
    learning and AI model training thanks to heavy upfront investment and clever lock-in
    strategies.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 给定 GPU 直到 90 年代末视频游戏的兴起才进入细分市场，它们是如何主导 AI 硬件市场的？GPU 制造商又是如何取代硅谷原有巨头，如英特尔的？2012
    年，[AlexNet](https://en.wikipedia.org/wiki/AlexNet) 在 ImageNet 机器学习竞赛中获胜，通过使用 Nvidia
    的 GPU 加速模型训练。它们展示了 GPU 的并行计算能力非常适合训练 ML 模型，因为像计算机图形一样，ML 模型训练依赖于高度并行的矩阵运算。今天的
    LLMs 基于 AlexNet 的初步突破，进一步扩展，规模达到数万亿次算术运算和数十亿个模型参数。自 AlexNet 以来，随着并行计算需求的激增，Nvidia
    通过大量前期投资和巧妙的锁定策略，将自己定位为机器学习和 AI 模型训练的唯一潜在芯片。
- en: Given the huge marketing opportunity in GPU design, it is reasonable to ask
    why Nvidia has no significant challengers (at the time of this writing, [Nvidia
    holds 70–95% of the AI chip market share)](https://www.cnbc.com/2024/06/02/nvidia-dominates-the-ai-chip-market-but-theres-rising-competition-.html).
    Nvidia’s early investments in the ML and AI market before ChatGPT and before even
    AlexNet were key in establishing a hefty lead over other chipmakers like AMD.
    Nvidia allocated significant investment in research and development for the scientific
    computing (to become ML and AI) market segment before there was a clear commercial
    use case. Because of these early investments, Nvidia had already developed the
    best supplier and customer relationships, engineering talent, and GPU technology
    when the AI market took off.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于 GPU 设计中巨大的市场机会，合理的疑问是，为什么 Nvidia 没有面临重要的竞争者（截至本文撰写时，[Nvidia 占据了 70-95% 的
    AI 芯片市场份额](https://www.cnbc.com/2024/06/02/nvidia-dominates-the-ai-chip-market-but-theres-rising-competition-.html)）。Nvidia
    在 ChatGPT 之前，甚至在 AlexNet 之前对 ML 和 AI 市场的早期投资，是其领先其他芯片制造商（如 AMD）的关键因素。Nvidia 在科学计算（以后成为
    ML 和 AI）市场领域进行了大量的研究与开发投资，当时还没有明确的商业用例。正因为这些早期的投资，Nvidia 在 AI 市场蓬勃发展时，已经建立了最佳的供应商和客户关系、工程人才和
    GPU 技术。
- en: Perhaps Nvidia’s most significant early investment and now its deepest moat
    against competitors is its [CUDA programming platform](https://developer.nvidia.com/cuda-toolkit).
    CUDA is a low-level software tool that enables engineers to interface with Nvidia’s
    chips and write parallel native algorithms. Many models, such as LlaMa, leverage
    higher-level Python libraries built upon these foundational CUDA tools. These
    lower level tools enable model designers to focus on higher-level architecture
    design choices without worrying about the complexities of executing calculations
    at the GPU processor core level. With CUDA, Nvidia built a software solution to
    strategically complement their hardware GPU products by solving many software
    challenges AI builders face.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 也许 Nvidia 最重要的早期投资，也是目前它对抗竞争对手的最大护城河，是其 [CUDA 编程平台](https://developer.nvidia.com/cuda-toolkit)。CUDA
    是一个低级软件工具，使工程师能够与 Nvidia 的芯片进行交互，并编写并行本地算法。许多模型，如 LlaMa，都利用基于这些基础 CUDA 工具构建的更高级的
    Python 库。这些低级工具使得模型设计师能够专注于更高级的架构设计选择，而无需担心在 GPU 处理器核心级别执行计算的复杂性。通过 CUDA，Nvidia
    构建了一种软件解决方案，战略性地补充了他们的硬件 GPU 产品，解决了 AI 开发者面临的许多软件挑战。
- en: CUDA not only simplifies the process of building parallelized AI and machine
    learning models on Nvidia chips, it also locks developers onto the Nvidia system,
    raising significant barriers to exit for any companies looking to switch to Nvidia’s
    competitors. Programs written in CUDA cannot run on competitor chips, which means
    that to switch off Nvidia chips, companies must rebuild not just the functionality
    of the CUDA platform, they must also rebuild any parts of their tech stack dependent
    on CUDA outputs. Given the massive stack of AI software built upon CUDA over the
    past decade, there is a substantial switching cost for anyone looking to move
    to competitors’ chips.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA不仅简化了在Nvidia芯片上构建并行化AI和机器学习模型的过程，还将开发者锁定在Nvidia系统上，为任何想要切换到Nvidia竞争对手的公司设立了重大的退出障碍。用CUDA编写的程序无法在竞争对手的芯片上运行，这意味着要从Nvidia芯片切换，企业不仅必须重建CUDA平台的功能，还必须重建任何依赖CUDA输出的技术栈的部分。鉴于过去十年中围绕CUDA构建的大量AI软件，任何想要转向竞争对手芯片的人都会面临相当高的转换成本。
- en: Microchip Manufacturers (Foundries)
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微芯片制造商（晶圆厂）
- en: '![](../Images/d553a9e3acbeacfdef8ff78ec1ed9132.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d553a9e3acbeacfdef8ff78ec1ed9132.png)'
- en: Image by [Louis Reed on Unsplash](https://unsplash.com/photos/gray-industrial-machine-wSTCaQpiLtc)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Louis Reed在Unsplash](https://unsplash.com/photos/gray-industrial-machine-wSTCaQpiLtc)提供
- en: Companies like Nvidia and AMD design chips, but they do not manufacture them.
    Instead, they rely on semiconductor manufacturing specialists known as foundries.
    Modern semiconductor manufacturing is one of the most complex engineering processes
    ever invented, and these foundries are a long way from most people’s image of
    a traditional factory. To illustrate, transistors on the latest chips are only
    12 Silicon atoms long, shorter than the wavelength of visible light. Modern microchips
    have trillions of these transistors packed onto small silicon wafers and etched
    into atom-scale integrated circuits.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 像Nvidia和AMD这样的公司设计芯片，但它们并不制造芯片。相反，它们依赖于被称为晶圆厂的半导体制造专家。现代半导体制造是人类发明的最复杂的工程过程之一，这些晶圆厂与大多数人对传统工厂的印象相差甚远。举个例子，最新芯片上的晶体管仅有12个硅原子长，甚至比可见光的波长还短。现代微芯片将数万亿个这样的晶体管压缩到小小的硅晶圆上，并刻蚀成原子级的集成电路。
- en: The key to manufacturing semiconductors is a process known as [photolithography](https://www.youtube.com/watch?v=Bu52CE55BN0).
    Photolithography involves etching intricate patterns on a silicon wafer, a crystalized
    form of the element silicon used as the base for the microchip. The process involves
    coating the wafer with a light-sensitive chemical called photoresist and then
    exposing it to ultraviolet light through a mask that contains the desired circuit.
    The exposed areas of the photoresist are then developed, leaving a pattern that
    can be etched into the wafer. The most critical machines for this process are
    developed by the Dutch company ASML, which produces [extreme ultraviolet (EUV)
    lithography systems](https://www.youtube.com/watch?v=RmgkV83OhHA) and holds a
    similar stranglehold to Nvidia in its segment of the AI value chain.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 制造半导体的关键是一个叫做[光刻](https://www.youtube.com/watch?v=Bu52CE55BN0)的过程。光刻过程涉及在硅晶圆上刻蚀复杂的图案，硅晶圆是一种结晶形式的硅元素，作为微芯片的基础。该过程包括在晶圆上涂上一种称为光刻胶的光敏化学物质，然后通过包含所需电路的掩模将其暴露于紫外光中。暴露的光刻胶区域会被显影，留下可以刻蚀到晶圆上的图案。该过程最关键的机器由荷兰公司ASML开发，该公司生产[极紫外（EUV）光刻系统](https://www.youtube.com/watch?v=RmgkV83OhHA)，并在其AI价值链细分市场中拥有类似Nvidia的垄断地位。
- en: Just as Nvidia came to dominate the GPU design market, its primary manufacturing
    partner, Taiwan Semiconductor Manufacturing Company (TSMC), holds a similarly
    large share of the manufacturing market for the most advanced AI chips. To understand
    TSMC’s place in the semiconductor manufacturing landscape, it is helpful to understand
    the broader foundry landscape.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Nvidia主导了GPU设计市场一样，其主要制造合作伙伴台湾半导体制造公司（TSMC）在最先进AI芯片的制造市场中也占有类似的份额。要理解TSMC在半导体制造领域中的地位，了解更广泛的晶圆厂格局是很有帮助的。
- en: 'Semiconductor manufacturers are split between two main foundry models: pure-play
    and integrated. Pure-play foundries, such as TSMC and GlobalFoundries, focus exclusively
    on manufacturing microchips for other companies without designing their own chips
    (the complement to fabless companies like Nvidia and AMD, who design but do not
    manufacture their chips). These foundries specialize in fabrication services,
    allowing fabless semiconductor companies to design microchips without heavy capital
    expenditures in manufacturing facilities. In contrast, integrated device manufacturers
    (IDMs) like Intel and Samsung design, manufacture, and sell their chips. The integrated
    model provides greater control over the entire production process but requires
    significant investment in both design and manufacturing capabilities. The pure-play
    model has gained popularity in recent decades due to the flexibility and capital
    efficiency it offers fabless designers, while the integrated model continues to
    be advantageous for companies with the resources to maintain design and fabrication
    expertise.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 半导体制造商分为两种主要的铸造模式：纯铸造和集成式。像台积电和全球晶圆代工（GlobalFoundries）这样的纯铸造厂专注于为其他公司制造微芯片，而不设计自己的芯片（与无厂公司如英伟达和AMD相辅相成，后者设计但不制造芯片）。这些铸造厂专门提供制造服务，使无厂半导体公司能够设计微芯片，而无需在制造设施上进行大量资本支出。相比之下，像英特尔和三星这样的集成器件制造商（IDM）设计、制造并销售自己的芯片。集成模式对整个生产过程提供更大的控制，但需要在设计和制造能力方面进行大量投资。由于为无厂设计师提供的灵活性和资本效率，纯铸造模式在近年来越来越受欢迎，而集成模式仍然对那些具备设计和制造技术的公司具有优势。
- en: It is impossible to discuss semiconductor manufacturing without considering
    the vital role of Taiwan and the consequent geopolitical risks. In the late 20th
    century, Taiwan transformed itself from a low-margin, low-skilled manufacturing
    island into a semiconductor powerhouse, largely due to strategic government investments
    and a focus on high-tech industries. The establishment and growth of TSMC have
    been central to this transformation, positioning Taiwan at the heart of the global
    technology supply chain and leading to the outgrowth of many smaller companies
    to support manufacturing. However, this dominance has also made Taiwan a critical
    focal point in the ongoing geopolitical struggle, as China views the island as
    a breakaway province and seeks greater control. Any escalation of tensions could
    disrupt the global supply of semiconductors, with far-reaching consequences for
    the global economy, particularly in AI.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论半导体制造时，无法忽视台湾的关键作用以及由此带来的地缘政治风险。在20世纪末，台湾从一个低利润、低技能的制造岛屿转变为半导体强国，这主要得益于政府的战略投资以及对高科技产业的关注。台积电的成立和发展在这一转型中起到了核心作用，使台湾处于全球技术供应链的中心，并促使许多小型公司涌现以支持制造业。然而，这种主导地位也使台湾成为持续地缘政治斗争中的关键焦点，中国将台湾视为一个分裂省份，并寻求更大的控制权。任何紧张局势的升级都可能扰乱全球半导体供应，给全球经济带来深远影响，尤其是在人工智能领域。
- en: Silicon and Metal Miners
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 硅和金属矿商
- en: '![](../Images/757219ebb37090acbe237412c495a0d0.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/757219ebb37090acbe237412c495a0d0.png)'
- en: Image by [Getty Images on Unsplash](https://unsplash.com/photos/aerial-view-of-a-excavator-loading-a-truck-in-the-mine-mining-from-above-industrial-background-with-drone-photography-nNatLdVBnjo)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Getty Images on Unsplash](https://unsplash.com/photos/aerial-view-of-a-excavator-loading-a-truck-in-the-mine-mining-from-above-industrial-background-with-drone-photography-nNatLdVBnjo)
- en: At the most basic level, all manufactured objects are created from raw materials
    extracted from the earth. For microchips used to train AI models, silicon and
    metals are their primary constituents. These and the chemicals used in the photolithography
    process are the primary inputs used by foundries to manufacture semiconductors.
    While the United States and its allies have come to dominate many parts of the
    value chain, its AI rival, China, has a firmer grasp on raw metals and other inputs.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从最基本的层面来看，所有制造物品都来自从地球中提取的原材料。用于训练人工智能模型的微芯片，其主要成分是硅和金属。这些原材料以及光刻过程中的化学品是铸造厂用于制造半导体的主要输入。尽管美国及其盟国已经主导了价值链的许多部分，但它的人工智能对手中国对原材料和其他输入的掌握更为牢固。
- en: The primary ingredient in any microchip is silicon (hence the name Silicon Valley).
    Silicon is one of the most abundant minerals in the earth’s crust and is commonly
    mined as Silica Dioxide (i.e., quartz or silica sand). Producing silicon wafers
    involves mining mineral quartzite, crushing it, and then extracting and purifying
    the elemental silicon. Next, chemical companies such as Sumco and Shin-Etsu Chemical
    convert pure silicon to wafers using a process called Czochralski growth, in which
    a seed crystal is dipped into molten high-purity silicon and slowly pulled upwards
    while rotating. This process creates a sizeable single-crystal silicon ingot sliced
    into thin wafers, which form the substrate for semiconductor manufacturing.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 任何微芯片的主要成分是硅（因此有了“硅谷”这个名字）。硅是地壳中最丰富的矿物之一，通常以二氧化硅（即石英或硅砂）形式开采。生产硅晶圆的过程包括开采矿石石英岩、将其粉碎，然后提取和净化元素硅。接下来，像Sumco和新日铁化学等化学公司通过一种叫做Czochralski生长法的工艺将纯硅转化为晶圆，在该过程中，一个种晶被浸入熔融的高纯度硅中，并在旋转的同时缓慢向上拉取。这个过程制造出一个大型的单晶硅锭，随后被切割成薄晶圆，作为半导体制造的基底。
- en: Beyond Silicon, computer chips also require trace amounts of rare earth metals.
    A critical step in semiconductor manufacturing is [doping](https://www.youtube.com/watch?v=k12GMjtN8aA),
    in which impurities are added to the silicon to control conductivity. Doping is
    typically done with rare earth metals like Germanium, Arsenic, Gallium, and Copper.
    China dominates the global rare earth metal production, [accounting for over 60%
    of mining and 85% of processing](https://www.forbes.com/sites/miltonezrati/2023/12/11/how-much-control-does-china-have-over-rare-earth-elements/).
    Other significant rare earth metals producers include Australia, the United States,
    Myanmar, and the Democratic Republic of the Congo. The United States’ heavy reliance
    on China for rare earth metals poses significant geopolitical risks, as supply
    disruptions could severely impact the semiconductor industry and other high-tech
    sectors. This dependence has prompted efforts to diversify supply chains and develop
    domestic rare earth production capabilities in the US and other countries, though
    progress has been slow due to environmental concerns and the complex nature of
    rare earth processing.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 除了硅以外，计算机芯片还需要微量的稀土金属。半导体制造中的一个关键步骤是[掺杂](https://www.youtube.com/watch?v=k12GMjtN8aA)，其中通过向硅中加入杂质来控制其导电性。掺杂通常使用像锗、砷、镓和铜这样的稀土金属。中国主导着全球稀土金属的生产，[占全球矿产和加工量的60%以上和85%](https://www.forbes.com/sites/miltonezrati/2023/12/11/how-much-control-does-china-have-over-rare-earth-elements/)。其他重要的稀土金属生产国包括澳大利亚、美国、缅甸和刚果民主共和国。美国对中国稀土金属的高度依赖带来了重大的地缘政治风险，因为供应中断可能会严重影响半导体行业和其他高科技领域。这种依赖促使美国和其他国家努力多元化供应链并发展国内稀土生产能力，尽管由于环境问题和稀土加工的复杂性，进展缓慢。
- en: Conclusion
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The physical and digital technology stacks and value chains that support the
    development of AI are intricate and built upon decades of academic and industrial
    advances. The value chain encompasses end application builders, AI model builders,
    cloud service providers, chip designers, chip fabricators, and raw material suppliers,
    among many other key contributors. While much of the attention has been on major
    players like OpenAI, Nvidia, and TSMC, significant opportunities and bottlenecks
    exist at all points along the value chain. Thousands of new companies will be
    born to solve these problems. While companies like Nvidia and OpenAI might be
    the Intel and Google of their generation, the personal computing and internet
    booms produced thousands of other unicorns to fill niches and solve issues that
    came with inventing a new economy. The opportunities created by the shift to AI
    will take decades to be understood and realized, much as in personal computing
    in the 70s and 80s and the internet in the 90s and 00s.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 支撑AI发展所需的物理和数字技术堆栈以及价值链错综复杂，建立在数十年的学术和工业进展之上。这个价值链涵盖了最终应用构建者、AI模型构建者、云服务提供商、芯片设计师、芯片制造商和原材料供应商等众多关键参与者。尽管大部分关注集中在OpenAI、Nvidia和台积电等主要玩家上，但在价值链的各个环节中，仍存在着重要的机会和瓶颈。成千上万的新公司将会应运而生，以解决这些问题。尽管像Nvidia和OpenAI这样的公司可能是这一代的英特尔和谷歌，但个人计算和互联网的繁荣曾创造出成千上万的独角兽企业，填补了利基市场并解决了发明新经济所带来的问题。转向AI所创造的机会需要数十年才能理解和实现，就像70年代和80年代的个人计算以及90年代和00年代的互联网一样。
- en: While entrepreneurship and crafty engineering may solve many problems in the
    AI market, some problems involve far greater forces. No challenge is greater than
    rising geopolitical tension with China, which owns (or claims to own) most of
    the raw materials and manufacturing markets. This contrasts with the United States
    and its allies, who control most downstream phases of the chain, including chip
    design and model training. The struggle for AI dominance is especially vital because
    the opportunity unlocked by AI is not just economic but also military. Semi-autonomous
    weapons systems and cyberwarfare agents leveraging AI capabilities may play decisive
    roles in conflicts of the coming decades. Modern defense technology startups like
    [Palantir](https://www.palantir.com/) and [Anduril](https://www.anduril.com/)
    already show how AI capabilities can expand battlefield visibility and accelerate
    decision loops to gain potentially decisive advantage. Given AI’s high potential
    for disruption to the global order and the delicate balance of power between the
    United States and China, it is imperative that the two nations seek to maintain
    a cooperative relationship aimed at mutually beneficial development of AI technology
    for the betterment of global prosperity. Only by solving problems across the supply
    chain, from the scientific to the industrial to the geopolitical, can the promise
    of AI to supercharge humanity’s capabilities be realized.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管创业精神和巧妙的工程技术能够解决AI市场中的许多问题，但有些问题涉及到更为强大的力量。没有什么挑战比与中国的地缘政治紧张局势更为严峻，中国拥有（或声称拥有）大多数原材料和制造市场。这与美国及其盟友形成对比，后者控制着链条的大多数下游阶段，包括芯片设计和模型训练。争夺AI主导地位尤为重要，因为AI所带来的机会不仅是经济性的，还具有军事意义。利用AI能力的半自主武器系统和网络战争代理人可能在未来几十年的冲突中发挥决定性作用。像[Palantir](https://www.palantir.com/)和[Anduril](https://www.anduril.com/)这样的现代防务科技初创公司已经展示了AI能力如何扩展战场可视性并加速决策循环，从而获得潜在的决定性优势。考虑到AI对全球秩序的高潜力破坏性以及美国与中国之间微妙的权力平衡，两国必须努力保持合作关系，旨在共同发展AI技术，以促进全球繁荣。只有通过解决从科学到工业再到地缘政治的整个供应链问题，才能实现AI在增强人类能力方面的承诺。
