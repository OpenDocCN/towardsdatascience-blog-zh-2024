<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>End-to-End Machine Learning in Azure</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>End-to-End Machine Learning in Azure</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/end-to-end-machine-learning-in-azure-1429528ecbe5?source=collection_archive---------3-----------------------#2024-02-20">https://towardsdatascience.com/end-to-end-machine-learning-in-azure-1429528ecbe5?source=collection_archive---------3-----------------------#2024-02-20</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="ca0b" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How to train and deploy a machine learning model in Azure</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@jonathanbogerd?source=post_page---byline--1429528ecbe5--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Jonathan Bogerd" class="l ep by dd de cx" src="../Images/e844961c6ea9766476d3d520dd993ae2.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*16ecuQumJiH06Z8McXHNtQ.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--1429528ecbe5--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@jonathanbogerd?source=post_page---byline--1429528ecbe5--------------------------------" rel="noopener follow">Jonathan Bogerd</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--1429528ecbe5--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 20, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><h2 id="75b8" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Introduction</strong></h2><p id="5252" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">In this article, we will go through an end-to-end example of a machine learning use case in Azure. We will discuss how to transform the data such that we can use it to train a model using Azure Synapse Analytics. Then we will train a model in Azure Machine Learning and score some test data with it. The purpose of this article is to give you an overview of what techniques and tools you need in Azure to do this and to show exactly how you do this. In researching this article, I found many conflicting code snippets of which most are outdated and contain bugs. Therefore, I hope this article gives you a good overview of techniques and tooling and a set of code snippets that help you to quickly start your machine learning journey in Azure.</p><figure class="od oe of og oh oi oa ob paragraph-image"><div role="button" tabindex="0" class="oj ok ed ol bh om"><div class="oa ob oc"><img src="../Images/6e71e88a1216c4c2de900afb5686dd31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*No1UsP3fsA5Sm0eL"/></div></div><figcaption class="oo op oq oa ob or os bf b bg z dx">Photo by <a class="af ot" href="https://unsplash.com/@omilaev?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Igor Omilaev</a> on <a class="af ot" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="02de" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Data and Objective</strong></h2><p id="4d15" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">To build a Machine Learning example for this article, we need data. We will use a dataset I created on ice cream sales for every state in the US from 2017 to 2022. This dataset can be found <a class="af ot" href="https://github.com/jonathanbogerd/icecreamdata" rel="noopener ugc nofollow" target="_blank">here</a>. You are free to use it for your own machine learning test projects. The objective is to train a model to forecast the number of ice creams sold on a given day in a state. To achieve this goal, we will combine this dataset with population data from each state, sourced from <a class="af ot" href="https://usafacts.org/data/topics/people-society/population-and-demographics/population-data/population/" rel="noopener ugc nofollow" target="_blank">USAFacts</a>. It is shared under a Creative Commons license, which can be found <a class="af ot" href="https://usafacts.org/faq/" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="5013" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">To build a machine learning model, several data transformation steps are required. First, data formats need to be aligned and both data sets have to be combined. We will perform these steps in Azure Synapse Analytics in the next section. Then we will split the data into train and test data to train and evaluate the machine learning model.</p><h2 id="c974" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Azure</strong></h2><p id="c0d5" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Microsoft Azure is a suite of cloud computing services offered by Microsoft to build and manage applications in the cloud. It includes many different services, including storage, computing, and analytics services. Specifically for machine learning, Azure provides a Machine Learning Service which we will use in this article. Next to that, Azure also contains Azure Synapse Analytics, a tool for data orchestration, storage, and transformation. Therefore, a typical machine learning workflow in Azure uses Synapse to retrieve, store, and transform data and to call the model for inference and uses Azure Machine Learning to train, save, and deploy machine learning models. This workflow will be demonstrated in this article.</p><h2 id="a1bd" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Synapse</strong></h2><p id="8cf4" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">As already mentioned, Azure Synapse Analytics is a tool for data pipelines and storage. I assume you have already created a Synapse workspace and a Spark cluster. Details on how to do this can be found <a class="af ot" href="https://learn.microsoft.com/en-us/azure/synapse-analytics/get-started-create-workspace" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="0739" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">Before making any transformation on the data, we first have to upload it to the storage account of Azure Synapse. Then, we create integration datasets for both source datasets. Integration datasets are references to your dataset and can be used in other activities. Let’s also create two integration datasets for the data when the transformations are done, such that we can use them as storage locations after transforming the data.</p><p id="9598" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">Now we can start transforming the data. We will use two steps for this: The first step is to clean both datasets and save the cleaned versions, and the second step is to combine both datasets into one. This setup follows the standard bronze, silver, and gold procedure.</p><h2 id="16cb" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Data Flow</strong></h2><p id="7d20" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">For the first step, we will use Azure Data Flow. Data Flow is a no-code option for data transformations in Synapse. You can find it under the Develop tab. There, create a data flow Icecream with the source integration dataset of the ice cream data as a source and the sink integration data set as a sink. The only transformation we will do here is to create the date column with the standard toDate function. This casts the date to the correct format. In the sink data set, you can also rename columns under the mapping tab.</p><p id="eb19" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">For the population data set, we will rename some columns and unpivot the columns. Note that you can do all this without writing code, making it an easy solution for quick data transformation and cleaning.</p><h2 id="e2e8" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Spark</strong></h2><p id="8da7" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Now, we will use a Spark notebook to join the two datasets and save the result to be used by Azure Machine Learning. Notebooks can be used in several programming languages, all use the Spark API. In this example, we will use PySpark, the Python API for Spark as it is complete. After reading the file, we join the population data per year on the ice creamdata, split it into a train and test data set, and write the result to our storage account. The details can be found in the script below:</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="a21e" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">Note that for using AutoML in Machine Learning, it is required to save the data sets as mltable format instead of parquet files. To do this, you can convert the parquets using the provided code snippet. You might need to authenticate with your Microsoft account in order to run this.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><h2 id="e747" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Pipelines</strong></h2><p id="3197" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Now that we have created all activities, we have to create a pipeline to run these activities. Pipelines in Synapse are used to execute activities in a specified order and trigger. This makes it possible to retrieve data for instance daily or to retrain your model automatically every month. Let’s create a pipeline with three activities, two dataflow activities, and a Notebook activity. The result should be something similar to this:</p><figure class="od oe of og oh oi oa ob paragraph-image"><div class="oa ob pc"><img src="../Images/ae8f1e10c440d137b9315c94526ed5e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*rTnIgdVcjeNoki4KWuVlww.png"/></div><figcaption class="oo op oq oa ob or os bf b bg z dx">Image by Author</figcaption></figure><h2 id="0791" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Machine Learning</strong></h2><p id="e25c" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Azure Machine Learning (AML) is a tool that enables the training, testing, and deploying of machine learning models. The tool has a UI in which you can run machine learning workloads without programming. However, it is often more convenient to build and train models using the Python SDK (v2). It allows for more control and allows you to work in your favorite programming environment. So, let’s first install all packages required to do this. You can simply pip install this requirements.txt file to follow along with this example. Note that we will use lightgbm to create a model. You do not need this package if you are going to use a different model.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="a3e2" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">Now let’s start using the Python SDK to train a model. First, we have to authenticate to Azure Machine Learning using either the default or interactive credential class to get an MLClient. This will lazily authenticate to AML, whenever you need access to it.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><h2 id="1b0d" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Compute</strong></h2><p id="e5a9" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">The next step is to create a compute, something to run the actual workload. AML has several types of compute you can use. Compute instances are well suited as a development environment or for training runs. Compute clusters are for larger training runs or inference. We will create both a compute instance and a compute cluster in this article: the first for training, and the second for inferencing. The code to create a compute instance can be found below, the compute cluster will be created when we deploy a model to an endpoint.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="fbdc" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">It is also possible to use external clusters from for instance Databricks or Synapse. However, currently, Spark clusters from Synapse do not run a supported version for Azure Machine Learning. More information on clusters can be found <a class="af ot" href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target?view=azureml-api-2" rel="noopener ugc nofollow" target="_blank">here</a>.</p><h2 id="b5c3" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Environment</strong></h2><p id="def7" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Training Machine Learning models on different machines can be challenging if you do not have a proper environment setup to run them. It is easy to miss a few dependencies or have slightly different versions. To solve this, AML uses the concept of a Environment, a Docker-backed Python environment to run your workloads. You can use existing Environments or create your own by selecting a Docker base image (or creating one yourself) and adding a conda.yaml file with all dependencies. For this article, we will create our environment from a Microsoft base image. The conda.yaml file and code to create an environment are provided.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="f74a" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">Do not forget to include the azureml-inference-server-http package. You do not need it to train a model, however it is required for inferencing. If you forget it now, you will get errors during scoring and you have to start from here again. In the AML UI, you can inspect the progress and the underlying Docker image. Environments are also versioned, such that you can always revert to the previous version if required.</p><h2 id="5c1d" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Data</strong></h2><p id="6fb8" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Now that we have an environment to run our machine learning workload, we need access to our dataset. In AML there are several ways to add data to the training run. We will use the option to register our training dataset before using it to train a model. In this way, we again have versioning of our data. Doing this is quite straightforward by using the following script:</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><h2 id="afb9" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Training</strong></h2><p id="c2bf" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Finally, we can start building the training script for our lightgbm model. In AML, this training script runs in a command with all the required parameters. So, let’s set up the structure of this training script first. We will use MLFlow for logging, saving and packaging of the model. The main advantage of using MLFlow, is that all dependencies will be packaged in the model file. Therefore, when deploying, we do not need to specify any dependencies as they are part of the model. Following an example script for an MLFlow model provided by Microsoft, this is the basic structure of a training script:</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="2c35" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">Filling in this template, we start with adding the parameters of the lightgbm model. This includes the number of leaves and the number of iterations and we parse them in the parse_args method. Then we will read the provided parquet file in the data set that we registered above. For this example, we will drop the date and state columns, although you can use them to improve your model. Then we will create and train the model using a part of the data as our validation set. In the end, we save the model such that we can use it later to deploy it in AML. The full script can be found below:</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="3481" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">Now we have to upload this script to AML together with the dataset reference, environment, and the compute to use. In AML, this is done by creating a command with all these components and sending it to AML.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="0bf1" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">This will yield a URL to the training job. You can follow the status of training and the logging in the AML UI. Note that the cluster will not always start on its own. This at least happened to me sometimes. In that case, you can just manually start the compute instance via the UI. Training this model will take roughly a minute.</p><h2 id="9067" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Endpoints</strong></h2><p id="2694" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">To use the model, we first need to create an endpoint for it. AML has two different types of endpoints. One, called an online endpoint is used for real-time inferencing. The other type is a batch endpoint, used for scoring batches of data. In this article, we will deploy the same model both to an online and a batch endpoint. To do this, we first need to create the endpoints. The code for creating an online endpoint is quite simple. This yields the following code for creating the endpoint:</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="6c55" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">We only need a small change to create the batch endpoint:</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><h2 id="d5f4" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Deployment</strong></h2><p id="8a1a" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Now that we have an endpoint, we need to deploy the model to this endpoint. Because we created an MLFlow model, the deployment is easier, because all requirements are packaged inside the model. The model needs to run on a compute cluster, we can create one while deploying the model to the endpoint. Deploying the model to the online endpoint will take roughly ten minutes. After the deployment, all traffic needs to be pointed to this deployment. This is done in the last lines of this code:</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="1d9b" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">To deploy the same model to the batch endpoint, we first need to create a compute target. This target is then used to run the model on. Next, we create a deployment with deployment settings. In these settings, you can specify the batch size, concurrency settings, and the location for the output. After you have specified this, the steps are similar to deployment to an online endpoint.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><h2 id="1deb" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Scoring with the Online Endpoint</strong></h2><p id="7a56" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Everything is now ready to use our model via the endpoints. Let’s first consume the model from the online endpoint. AML provides a sample scoring script that you can find in the endpoint section. However, creating the right format for the sample data can be slightly frustrating. The data needs to be sent in a nested JSON with the column indices, the indices of the sample, and the actual data. You can find a quick and dirty approach to do this in the example below. After you encode the data, you have to send it to the URL of the endpoint with the API key. You can find both in the endpoint menu. Note that you should <strong class="nj fr">never </strong>save the API key of your endpoint in your code. Azure provides a Key vault to save secrets. You can then reference the secret in your code to avoid saving it there directly. For more information see this link to the <a class="af ot" href="https://learn.microsoft.com/en-us/azure/key-vault/general/overview" rel="noopener ugc nofollow" target="_blank">Microsoft documentation</a>. The result variable will contain the predictions of your model.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><h2 id="4bed" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Scoring with the Batch Endpoint</strong></h2><p id="af6e" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">Scoring data via the batch endpoint works a bit differently. Typically, it involves more data, therefore it can be useful to register a dataset for this in AML. We have done this before in this article for the training data. We will then create a scoring job with all the information and send this to our endpoint. During scoring, we can review the progress of the job and poll for instance its status. After the job is completed, we can download the results from the output location that we specified when creating the batch endpoint. In this case, we saved the results in a CSV file.</p><figure class="od oe of og oh oi"><div class="oz io l ed"><div class="pa pb l"/></div></figure><p id="7cf2" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk">Although we scored the data and received the output locally, we can run the same code in Azure Synapse Analytics to score the data from there. However, in most cases, I find it easier to first test everything locally before running it in Synapse.</p><h2 id="0400" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Conclusion</strong></h2><p id="86f1" class="pw-post-body-paragraph nh ni fq nj b go nk nl nm gr nn no np mu nq nr ns my nt nu nv nc nw nx ny nz fj bk">We have reached the end of this article. To summarize, we imported data in Azure using Azure Synapse Analytics, transformed it using Synapse, and trained and deployed a machine learning model with this data in Azure Machine Learning. Last, we scored a dataset with both endpoints. I hope this article helped create an understanding of how to use Machine Learning in Azure. If you followed along, do not forget to delete endpoints, container registries and other resources you have created to avoid incurring costs for them.</p><h2 id="ff31" class="mj mk fq bf ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bk"><strong class="al">Sources</strong></h2><div class="pd pe pf pg ph pi"><a href="https://usafacts.org/data/topics/people-society/population-and-demographics/population-data/population/?source=post_page-----1429528ecbe5--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab ig"><div class="pk ab co cb pl pm"><h2 class="bf fr hw z io pn iq ir po it iv fp bk">US population over time</h2><div class="pp l"><h3 class="bf b hw z io pn iq ir po it iv dx">Explore government data on the demographics of the US population year over year. Download the data or use our…</h3></div><div class="pq l"><p class="bf b dy z io pn iq ir po it iv dx">usafacts.org</p></div></div><div class="pr l"><div class="ps l pt pu pv pr pw lr pi"/></div></div></a></div><div class="pd pe pf pg ph pi"><a href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/endpoints/batch/deploy-models/heart-classifier-mlflow/mlflow-for-batch-tabular.ipynb?source=post_page-----1429528ecbe5--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab ig"><div class="pk ab co cb pl pm"><h2 class="bf fr hw z io pn iq ir po it iv fp bk">azureml-examples/sdk/python/endpoints/batch/deploy-models/heart-classifier-mlflow/mlflow-for-batch-t…</h2><div class="pp l"><h3 class="bf b hw z io pn iq ir po it iv dx">Official community-driven Azure Machine Learning examples, tested with GitHub Actions. …</h3></div><div class="pq l"><p class="bf b dy z io pn iq ir po it iv dx">github.com</p></div></div><div class="pr l"><div class="px l pt pu pv pr pw lr pi"/></div></div></a></div><div class="pd pe pf pg ph pi"><a href="https://github.com/Azure/azureml-examples/blob/main/tutorials/get-started-notebooks/quickstart.ipynb?source=post_page-----1429528ecbe5--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab ig"><div class="pk ab co cb pl pm"><h2 class="bf fr hw z io pn iq ir po it iv fp bk">azureml-examples/tutorials/get-started-notebooks/quickstart.ipynb at main · Azure/azureml-examples</h2><div class="pp l"><h3 class="bf b hw z io pn iq ir po it iv dx">Official community-driven Azure Machine Learning examples, tested with GitHub Actions. …</h3></div><div class="pq l"><p class="bf b dy z io pn iq ir po it iv dx">github.com</p></div></div><div class="pr l"><div class="py l pt pu pv pr pw lr pi"/></div></div></a></div><p id="78e4" class="pw-post-body-paragraph nh ni fq nj b go ou nl nm gr ov no np mu ow nr ns my ox nu nv nc oy nx ny nz fj bk"><a class="af ot" href="https://learn.microsoft.com/en-us/azure/machine-learning" rel="noopener ugc nofollow" target="_blank">https://learn.microsoft.com/en-us/azure/machine-learning</a>/</p></div></div></div></div>    
</body>
</html>