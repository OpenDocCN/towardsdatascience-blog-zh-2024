# ä½¿ç”¨Prefectã€Weaveå’ŒRAGASå®ç°RAGåº”ç”¨çš„ç”Ÿäº§åŒ–

> åŸæ–‡ï¼š[https://towardsdatascience.com/productionizing-a-rag-app-04c857e0966e?source=collection_archive---------7-----------------------#2024-08-03](https://towardsdatascience.com/productionizing-a-rag-app-04c857e0966e?source=collection_archive---------7-----------------------#2024-08-03)

## æ·»åŠ è¯„ä¼°ã€è‡ªåŠ¨åŒ–æ•°æ®æå–åŠå…¶ä»–æ”¹è¿›ã€‚

[](https://medium.com/@ed.izaguirre?source=post_page---byline--04c857e0966e--------------------------------)[![Ed Izaguirre](../Images/c9eded1f06c47571baa662107428483f.png)](https://medium.com/@ed.izaguirre?source=post_page---byline--04c857e0966e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04c857e0966e--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04c857e0966e--------------------------------) [Ed Izaguirre](https://medium.com/@ed.izaguirre?source=post_page---byline--04c857e0966e--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04c857e0966e--------------------------------) Â·é˜…è¯»æ—¶é•¿12åˆ†é’ŸÂ·2024å¹´8æœˆ3æ—¥

--

![](../Images/105f6f4816994872796a36639b99148d.png)

ä»ç”µå½±æœç´¢åˆ°â€œç«ç‘°budâ€ğŸŒ¹ã€‚å›¾ç‰‡æ¥è‡ªUnsplashã€‚

**ç›®å½•**

1.  [ä»‹ç»](#d4f8)

1.  [ç¦»çº¿è¯„ä¼°](#fdde)

1.  [åœ¨çº¿è¯„ä¼°](#9988)

1.  [ä½¿ç”¨Prefectè¿›è¡Œè‡ªåŠ¨åŒ–æ•°æ®æå–](#690c)

1.  [æ‘˜è¦](#0875)

**ç›¸å…³é“¾æ¥**

+   [GitHubä»“åº“](https://github.com/EdIzaguirre/Rosebud)

+   [é“¾æ¥åˆ°ä¹‹å‰è®¨è®ºç”µå½±æœç´¢çš„æ–‡ç« ï¼Œè¿™æ˜¯è¯¥é¡¹ç›®çš„å¼€å‘ç‰ˆ](https://medium.com/towards-data-science/how-to-build-a-rag-system-with-a-self-querying-retriever-in-langchain-16b4fa23e9ad)

+   [å°è¯•è¯¥åº”ç”¨](https://filmsearch.azurewebsites.net/)ï¼ˆç°åœ¨100%å…è´¹ï¼ğŸ¤‘ï¼‰

# ä»‹ç»

å‡ ä¸ªæœˆå‰ï¼Œæˆ‘å‘å¸ƒäº†*ç”µå½±æœç´¢*åº”ç”¨ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºç”¨æˆ·æŸ¥è¯¢æ¨èç”µå½±çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åº”ç”¨ç¨‹åºã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯èƒ½ä¼šé—®ï¼šâ€œ*å¸®æˆ‘æ‰¾åˆ°å°‘äº2å°æ—¶ã€è‹±è¯­ç”µå½±å¹¶ä¸”æœ‰ç‹—çš„å‰§æƒ…ç‰‡*ã€‚â€ç„¶åä¼šæ”¶åˆ°ç±»ä¼¼çš„æ¨èï¼š

> ç”µå½±æ ‡é¢˜ï¼šã€Šå¿ çŠ¬å…«å…¬çš„æ•…äº‹ã€‹
> 
> è¿è¡Œæ—¶ï¼š93åˆ†é’Ÿ
> 
> å‘è¡Œå¹´ä»½ï¼š2009
> 
> æµåª’ä½“ï¼šæ— æ³•åœ¨çº¿è§‚çœ‹
> 
> è¿™éƒ¨ç”µå½±è®²è¿°äº†å¿ è¯šäºä¸»äººçš„ç§‹ç”°çŠ¬å…«å…¬çš„æ„ŸäººçœŸå®æ•…äº‹ã€‚ç”µå½±æ·±åˆ»çš„æƒ…æ„Ÿè¡¨è¾¾ä»¥åŠå‹è°Šå’Œå¿ è¯šçš„ä¸»é¢˜äº§ç”Ÿäº†å¼ºçƒˆå…±é¸£ï¼Œä½¿å…¶æˆä¸ºä¸€éƒ¨æ„Ÿäººçš„å‰§ä½œï¼Œå±•ç°äº†äººç±»ä¸ç‹—ä¹‹é—´æ·±åšçš„çº½å¸¦ã€‚å¯¹äºä»»ä½•å¯»æ±‚ä¸€æ®µçªæ˜¾é™ªä¼´é‡è¦æ€§çš„çœŸæŒšæ•…äº‹çš„äººæ¥è¯´ï¼Œè¿™éƒ¨ç”µå½±éƒ½æ˜¯å®Œç¾çš„é€‰æ‹©ã€‚
> 
> â€¦

ç„¶è€Œï¼Œè¿™ä¸ä»…ä»…æ˜¯ä¸€ä¸ªç®€å•çš„ RAG åº”ç”¨ã€‚å®ƒåŒ…æ‹¬äº†è¢«ç§°ä¸º **è‡ªæŸ¥è¯¢æ£€ç´¢** çš„åŠŸèƒ½ã€‚è¿™æ„å‘³ç€æœºå™¨äººä¼šè·å–ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œå¹¶é€šè¿‡æ·»åŠ å…ƒæ•°æ®è¿‡æ»¤å™¨æ¥è½¬æ¢å®ƒã€‚è¿™ç¡®ä¿äº†ä»»ä½•æ‹‰å–åˆ°èŠå¤©æ¨¡å‹ä¸Šä¸‹æ–‡ä¸­çš„æ–‡æ¡£éƒ½éµå®ˆç”¨æˆ·æŸ¥è¯¢è®¾ç½®çš„çº¦æŸæ¡ä»¶ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œå»ºè®®æŸ¥é˜…æˆ‘ä¹‹å‰çš„æ–‡ç« é“¾æ¥ã€‚

ä¸å¹¸çš„æ˜¯ï¼Œåº”ç”¨ç¨‹åºå­˜åœ¨ä¸€äº›é—®é¢˜ï¼š

+   é™¤äº†é€šè¿‡â€œçœ¼ç›æµ‹è¯•â€ä¹‹å¤–ï¼Œæ²¡æœ‰è¿›è¡Œç¦»çº¿è¯„ä¼°ã€‚è¿™ä¸ªæµ‹è¯•æ˜¯å¿…è¦çš„ï¼Œä½†ä¸è¶³å¤Ÿã€‚

+   å¯è§‚å¯Ÿæ€§å‡ ä¹ä¸å­˜åœ¨ã€‚å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œä½ å¿…é¡»æ‰‹åŠ¨æ‰“å¼€é¡¹ç›®å¹¶è¿è¡Œä¸€äº›ä¸´æ—¶è„šæœ¬ï¼Œè¯•å›¾æŸ¥çœ‹å‡ºäº†ä»€ä¹ˆé—®é¢˜ã€‚

+   Pinecone å‘é‡æ•°æ®åº“å¿…é¡»æ‰‹åŠ¨æ‹‰å–ã€‚è¿™æ„å‘³ç€å¦‚æœæŸéƒ¨ç”µå½±è¢«ä»æµåª’ä½“æœåŠ¡ä¸­ä¸‹æ¶ï¼Œæ–‡æ¡£ä¼šè¿…é€Ÿè¿‡æ—¶ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ç®€è¦ä»‹ç»ä¸€äº›å¯¹ç”µå½±æœç´¢åº”ç”¨ç¨‹åºæ‰€åšçš„æ”¹è¿›ã€‚å†…å®¹åŒ…æ‹¬ï¼š

+   **ä½¿ç”¨ RAGAS å’Œ Weave çš„ç¦»çº¿è¯„ä¼°**

+   **åœ¨çº¿è¯„ä¼°ä¸å¯è§‚å¯Ÿæ€§**

+   **ä½¿ç”¨ Prefect çš„è‡ªåŠ¨åŒ–æ•°æ®æ‹‰å–**

åœ¨æˆ‘ä»¬æ·±å…¥è®¨è®ºä¹‹å‰ï¼Œæˆ‘å‘ç°â€œç”µå½±æœç´¢â€è¿™ä¸ªåå­—æœ‰äº›æ™®é€šï¼Œå› æ­¤æˆ‘å°†åº”ç”¨é‡æ–°å‘½åä¸º *Rosebud* ğŸŒ¹ï¼Œå› æ­¤ä¸Šé¢æ˜¾ç¤ºçš„æ˜¯è¯¥å›¾åƒã€‚çœŸæ­£çš„ç”µå½±è¿·ä¼š [ç†è§£è¿™ä¸ªå¼•ç”¨](https://www.youtube.com/watch?v=O4mQqVqRB7I)ã€‚

# ç¦»çº¿è¯„ä¼°

èƒ½å¤Ÿåˆ¤æ–­å¯¹ LLM åº”ç”¨æ‰€åšçš„æ›´æ”¹æ˜¯æå‡äº†æ€§èƒ½è¿˜æ˜¯é™ä½äº†æ€§èƒ½éå¸¸é‡è¦ã€‚ä¸å¹¸çš„æ˜¯ï¼ŒLLM åº”ç”¨çš„è¯„ä¼°æ˜¯ä¸€ä¸ªå¤æ‚ä¸”å…¨æ–°çš„é¢†åŸŸã€‚å¯¹äºä»€ä¹ˆæ„æˆä¸€ä¸ªå¥½çš„è¯„ä¼°ï¼Œç›®å‰å‡ ä¹æ²¡æœ‰ä¸€è‡´çš„æ„è§ã€‚

å¯¹äº RosebudğŸŒ¹ï¼Œæˆ‘å†³å®šå¤„ç†è¢«ç§°ä¸º [RAG ä¸‰åˆä¸€æ–¹æ³•](https://www.trulens.org/trulens_eval/getting_started/core_concepts/rag_triad/) çš„é—®é¢˜ã€‚è¿™ç§æ–¹æ³•æ˜¯ç”± TruLens æ¨å¹¿çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªè¯„ä¼°å’Œè·Ÿè¸ª LLM åº”ç”¨çš„å¹³å°ã€‚

![](../Images/d536e3e20215d54bdf6e350f4f06a994.png)

RAG ä¸‰åˆä¸€æ–¹æ³•ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

ä¸‰åˆä¸€æ–¹æ³•æ¶µç›–äº† RAG åº”ç”¨çš„ä¸‰ä¸ªæ–¹é¢ï¼š

+   **ä¸Šä¸‹æ–‡ç›¸å…³æ€§**ï¼šå½“ç”¨æˆ·å‘å‡ºæŸ¥è¯¢æ—¶ï¼Œæ–‡æ¡£å¡«å……äº†èŠå¤©æ¨¡å‹çš„ä¸Šä¸‹æ–‡ã€‚æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å®é™…ä¸Šæœ‰ç”¨å—ï¼Ÿå¦‚æœæ²¡æœ‰ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æ–‡æ¡£åµŒå…¥ã€åˆ†å—æˆ–å…ƒæ•°æ®è¿‡æ»¤ç­‰æ–¹é¢ã€‚

+   **å‡†ç¡®æ€§**ï¼šæ¨¡å‹çš„å›ç­”æ˜¯å¦ç¡®å®åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Ÿä½ ä¸å¸Œæœ›æ¨¡å‹ç¼–é€ äº‹å®ï¼›RAG çš„å…³é”®å°±åœ¨äºé€šè¿‡ä½¿ç”¨æ£€ç´¢åˆ°çš„æ–‡æ¡£æ¥å‡å°‘å¹»è§‰ã€‚

+   **å›ç­”ç›¸å…³æ€§**ï¼šæ¨¡å‹çš„å›ç­”æ˜¯å¦çœŸçš„è§£ç­”äº†ç”¨æˆ·çš„æŸ¥è¯¢ï¼Ÿå¦‚æœç”¨æˆ·è¯¢é—®â€œ*1990å¹´ä»£çš„å–œå‰§ç”µå½±*â€ï¼Œæ¨¡å‹çš„å›ç­”æœ€å¥½åªåŒ…å«1990å¹´ä»£çš„å–œå‰§ç”µå½±ã€‚

è¯„ä¼° RAG åº”ç”¨çš„è¿™ä¸‰ä¸ªåŠŸèƒ½æœ‰å‡ ç§æ–¹å¼ã€‚ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨äººç±»ä¸“å®¶è¯„ä¼°å‘˜ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™æ ·åšä¼šå¾ˆæ˜‚è´µï¼Œå¹¶ä¸”éš¾ä»¥æ‰©å±•ã€‚å¯¹äº RosebudğŸŒ¹ï¼Œæˆ‘å†³å®šä½¿ç”¨ **LLMs ä½œä¸ºè¯„å®¡å‘˜**ã€‚è¿™æ„å‘³ç€ä½¿ç”¨èŠå¤©æ¨¡å‹æ¥æŸ¥çœ‹ä¸Šè¿°ä¸‰ä¸ªæ ‡å‡†ä¸­çš„æ¯ä¸€ä¸ªï¼Œå¹¶ä¸ºæ¯ä¸ªæ ‡å‡†æ‰“åˆ†ï¼ŒèŒƒå›´ä» 0 åˆ° 1ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯æˆæœ¬ä½ä¸”æ˜“äºæ‰©å±•ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä½¿ç”¨äº† [RAGAS](https://github.com/explodinggradients/ragas)ï¼Œè¿™æ˜¯ä¸€ä¸ªæµè¡Œçš„æ¡†æ¶ï¼Œå¸®åŠ©ä½ è¯„ä¼° RAG åº”ç”¨ã€‚RAGAS æ¡†æ¶åŒ…æ‹¬ä¸Šé¢æåˆ°çš„ä¸‰ä¸ªæŒ‡æ ‡ï¼Œå¹¶ä½¿ä½ èƒ½å¤Ÿç›¸å¯¹å®¹æ˜“åœ°ä½¿ç”¨å®ƒä»¬æ¥è¯„ä¼°åº”ç”¨ã€‚ä¸‹é¢æ˜¯æˆ‘è¿›è¡Œç¦»çº¿è¯„ä¼°æ—¶ä½¿ç”¨çš„ä»£ç ç‰‡æ®µï¼š

```py
from ragas import evaluate
from ragas.metrics import AnswerRelevancy, ContextRelevancy, Faithfulness
import weave

@weave.op()
def evaluate_with_ragas(query, model_output):
    # Put data into a Dataset object
    data = {
        "question": [query],
        "contexts": [[model_output['context']]],
        "answer": [model_output['answer']]
    }
    dataset = Dataset.from_dict(data)

    # Define metrics to judge
    metrics = [
        AnswerRelevancy(),
        ContextRelevancy(),
        Faithfulness(),
    ]

    judge_model = ChatOpenAI(model=config['JUDGE_MODEL_NAME'])
    embeddings_model = OpenAIEmbeddings(model=config['EMBEDDING_MODEL_NAME'])

    evaluation = evaluate(dataset=dataset, metrics=metrics, llm=judge_model, embeddings=embeddings_model)

    return {
        "answer_relevancy": float(evaluation['answer_relevancy']),
        "context_relevancy": float(evaluation['context_relevancy']),
        "faithfulness": float(evaluation['faithfulness']),
    }

def run_evaluation():
    # Initialize chat model
    model = rosebud_chat_model()

    # Define evaluation questions
    questions = [
        {"query": "Suggest a good movie based on a book."},  # Adaptations
        {"query": "Suggest a film for a cozy night in."},  # Mood-Based
        {"query": "What are some must-watch horror movies?"},  # Genre-Specific
        ...
        # Total of 20 questions
    ]

    # Create Weave Evaluation object
    evaluation = weave.Evaluation(dataset=questions, scorers=[evaluate_with_ragas])

    # Run the evaluation
    asyncio.run(evaluation.evaluate(model))

if __name__ == "__main__":
    weave.init('film-search')
    run_evaluation()
```

å‡ ç‚¹è¯´æ˜ï¼š

+   æœ‰äºŒåä¸ªé—®é¢˜å’Œä¸‰ä¸ªè¯„åˆ¤æ ‡å‡†ï¼Œä½ éœ€è¦è¿›è¡Œå…­åæ¬¡ LLM è°ƒç”¨æ¥å®Œæˆä¸€æ¬¡è¯„ä¼°ï¼ä¸è¿‡æƒ…å†µæ›´ç³Ÿï¼›ä½¿ç”¨ `rosebud_chat_model` æ—¶ï¼Œæ¯ä¸ªæŸ¥è¯¢éœ€è¦ä¸¤æ¬¡è°ƒç”¨ï¼šä¸€æ¬¡æ„å»ºå…ƒæ•°æ®è¿‡æ»¤å™¨ï¼Œå¦ä¸€æ¬¡æä¾›ç­”æ¡ˆï¼Œå› æ­¤ä¸€æ¬¡è¯„ä¼°å®é™…ä¸Šéœ€è¦ 120 æ¬¡è°ƒç”¨ï¼æœ¬æ¬¡è¯„ä¼°ä¸­ä½¿ç”¨çš„æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯æ–°çš„ `gpt-4o-mini`ï¼Œæˆ‘å¼ºçƒˆæ¨èä½¿ç”¨ã€‚åœ¨æˆ‘çš„ç»éªŒä¸­ï¼Œæ¯æ¬¡è¯„ä¼°çš„è°ƒç”¨è´¹ç”¨ä¸º $0.05ã€‚

+   è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† `asyncio.run` æ¥è¿è¡Œè¯„ä¼°ã€‚ä½¿ç”¨å¼‚æ­¥è°ƒç”¨æ˜¯ç†æƒ³çš„ï¼Œå› ä¸ºä½ ä¸æƒ³è®©æ¯ä¸ªé—®é¢˜æŒ‰é¡ºåºä¸€ä¸ªæ¥ä¸€ä¸ªåœ°è¯„ä¼°ã€‚ç›¸åï¼Œä½¿ç”¨ `asyncio` æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ç­‰å¾…å‰ä¸€ä¸ª I/O æ“ä½œå®Œæˆæ—¶ï¼Œå¼€å§‹è¯„ä¼°å…¶ä»–é—®é¢˜ã€‚

+   æ¯æ¬¡è¯„ä¼°å…±æœ‰äºŒåä¸ªé—®é¢˜ã€‚è¿™äº›é—®é¢˜æ¶µç›–äº†ç”¨æˆ·å¯èƒ½æå‡ºçš„å„ç§å…¸å‹ç”µå½±æŸ¥è¯¢ã€‚æˆ‘å¤§éƒ¨åˆ†æ˜¯è‡ªå·±æƒ³å‡ºæ¥çš„ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæœ€å¥½ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒä¸­å®é™…ç”±ç”¨æˆ·æå‡ºçš„æŸ¥è¯¢ã€‚

+   æ³¨æ„ä½¿ç”¨çš„ `weave.init` å’Œ `@weave.op` è£…é¥°å™¨ã€‚è¿™äº›æ˜¯æ¥è‡ª Weights & Biases (W&B) çš„æ–° [Weave åº“](https://wandb.ai/site/weave/) çš„ä¸€éƒ¨åˆ†ã€‚Weave æ˜¯ä¼ ç»Ÿ W&B åº“çš„è¡¥å……ï¼Œä¸“æ³¨äº LLM åº”ç”¨ã€‚å®ƒé€šè¿‡ç®€å•çš„ `@weave.op` è£…é¥°å™¨ï¼Œå…è®¸ä½ æ•è· LLM çš„è¾“å…¥å’Œè¾“å‡ºã€‚å®ƒè¿˜å…è®¸ä½ ä½¿ç”¨ `weave.Evaluation(â€¦)` æ•è·è¯„ä¼°ç»“æœã€‚é€šè¿‡é›†æˆ RAGAS è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä½¿ç”¨ Weave æ•è·å’Œè®°å½•è¿™äº›è¯„ä¼°ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªå¼ºå¤§çš„ç»„åˆï¼Œå¸®åŠ© GenAI å¼€å‘è€…é€æ­¥æ”¹è¿›ä»–ä»¬çš„åº”ç”¨ã€‚ä½ è¿˜å¯ä»¥è®°å½•æ¨¡å‹çš„å»¶è¿Ÿã€æˆæœ¬ç­‰ä¿¡æ¯ã€‚

![](../Images/ec7f61849ae276bbcc97508920e22e5b.png)

Weave + RAGAS é›†æˆç¤ºä¾‹ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

ç†è®ºä¸Šï¼Œç°åœ¨å¯ä»¥è°ƒæ•´ä¸€ä¸ªè¶…å‚æ•°ï¼ˆä¾‹å¦‚æ¸©åº¦ï¼‰ï¼Œé‡æ–°è¿è¡Œè¯„ä¼°ï¼Œç„¶åæŸ¥çœ‹è°ƒæ•´æ˜¯å¦äº§ç”Ÿæ­£é¢æˆ–è´Ÿé¢å½±å“ã€‚ä¸å¹¸çš„æ˜¯ï¼Œå®é™…æ“ä½œä¸­æˆ‘å‘ç°LLMåˆ¤æ–­æœ‰äº›æŒ‘å‰”ï¼Œæˆ‘[å¹¶éå”¯ä¸€ä¸€ä¸ª](https://x.com/aparnadhinak/status/1748368364395721128)ã€‚LLMè¯„åˆ¤ä¼¼ä¹å¾ˆéš¾ä½¿ç”¨æµ®ç‚¹å€¼æ¥è¯„ä¼°è¿™äº›æŒ‡æ ‡ã€‚ç›¸åï¼Œå®ƒä»¬ä¼¼ä¹åœ¨åˆ†ç±»ä»»åŠ¡ä¸Šè¡¨ç°å¾—æ›´å¥½ï¼Œä¾‹å¦‚èµæˆ–è¸©ã€‚RAGASå°šä¸æ”¯æŒLLMè¯„åˆ¤è¿›è¡Œåˆ†ç±»ã€‚æ‰‹åŠ¨ç¼–å†™è¿™ä¸ªåŠŸèƒ½ä¼¼ä¹ä¸éš¾ï¼Œä¹Ÿè®¸åœ¨æœªæ¥çš„æ›´æ–°ä¸­ï¼Œæˆ‘ä¼šå°è¯•è‡ªå·±å®ç°ã€‚

# **åœ¨çº¿è¯„ä¼°**

ç¦»çº¿è¯„ä¼°æœ‰åŠ©äºæŸ¥çœ‹è°ƒæ•´è¶…å‚æ•°å¦‚ä½•å½±å“æ€§èƒ½ï¼Œä½†åœ¨æˆ‘çœ‹æ¥ï¼Œåœ¨çº¿è¯„ä¼°è¦æ›´æœ‰ç”¨ã€‚åœ¨RosebudğŸŒ¹ä¸­ï¼Œæˆ‘ç°åœ¨å·²ç»åœ¨æ¯ä¸ªå“åº”çš„åº•éƒ¨åŠ å…¥äº†ğŸ‘/ğŸ‘æŒ‰é’®æ¥æä¾›åé¦ˆã€‚

![](../Images/c9351c7a2914be0e13e6295426c304fd.png)

åœ¨çº¿åé¦ˆç¤ºä¾‹ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

å½“ç”¨æˆ·ç‚¹å‡»ä»»ä¸€æŒ‰é’®æ—¶ï¼Œä»–ä»¬ä¼šè¢«å‘ŠçŸ¥åé¦ˆå·²è®°å½•ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨ Streamlit ç•Œé¢ä¸­å®ç°è¿™ä¸€åŠŸèƒ½çš„ä»£ç ç‰‡æ®µï¼š

```py
def start_log_feedback(feedback):
    print("Logging feedback.")
    st.session_state.feedback_given = True
    st.session_state.sentiment = feedback
    thread = threading.Thread(target=log_feedback, args=(st.session_state.sentiment,
                                                         st.session_state.query,
                                                         st.session_state.query_constructor,
                                                         st.session_state.context,
                                                         st.session_state.response))
    thread.start()

def log_feedback(sentiment, query, query_constructor, context, response):
    ct = datetime.datetime.now()
    wandb.init(project="film-search",
               name=f"query: {ct}")
    table = wandb.Table(columns=["sentiment", "query", "query_constructor", "context", "response"])
    table.add_data(sentiment,
                   query,
                   query_constructor,
                   context,
                   response
                   )
    wandb.log({"Query Log": table})
    wandb.finish()
```

è¯·æ³¨æ„ï¼Œå‘é€åé¦ˆåˆ°W&Bçš„è¿‡ç¨‹æ˜¯é€šè¿‡ä¸€ä¸ªç‹¬ç«‹çš„çº¿ç¨‹æ‰§è¡Œçš„ï¼Œè€Œä¸æ˜¯åœ¨ä¸»çº¿ç¨‹ä¸Šè¿è¡Œã€‚è¿™æ˜¯ä¸ºäº†é¿å…ç”¨æˆ·åœ¨ç­‰å¾…æ—¥å¿—å®Œæˆæ—¶è¢«å¡ä½ã€‚

ä½¿ç”¨W&Bè¡¨æ ¼æ¥å­˜å‚¨åé¦ˆã€‚è¡¨æ ¼ä¸­è®°å½•äº†äº”ä¸ªæ•°é‡ï¼š

+   **æƒ…æ„Ÿ:** ç”¨æˆ·ç‚¹å‡»äº†èµè¿˜æ˜¯è¸©

+   **æŸ¥è¯¢:** ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œä¾‹å¦‚ *æ‰¾æˆ‘ä¸€äº›è‹±æ–‡çš„ç‹—ç‹—é¢˜æçš„å‰§æƒ…ç‰‡ï¼Œæ—¶é•¿ä¸åˆ°2å°æ—¶ã€‚*

+   **æŸ¥è¯¢æ„é€ å™¨:** æŸ¥è¯¢æ„é€ å™¨çš„ç»“æœï¼Œå®ƒé‡å†™äº†ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œå¹¶åœ¨å¿…è¦æ—¶åŒ…æ‹¬å…ƒæ•°æ®è¿‡æ»¤ï¼Œä¾‹å¦‚

```py
{
    "query": "drama English dogs", 
    "filter": {
        "operator": "and", 
        "arguments": [
            {
                "comparator": "eq", "attribute": "Genre", "value": "Drama"
            }, 
            {
                "comparator": "eq", "attribute": "Language", "value": "English"
            }, 

            {
                "comparator": "lt", "attribute": "Runtime (minutes)", "value": 120
            }
        ]
    },
}
```

+   **ä¸Šä¸‹æ–‡:** åŸºäºé‡æ„åçš„æŸ¥è¯¢æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼Œä¾‹å¦‚ *æ ‡é¢˜: å“ˆå¥‡ï¼šä¸€åªç‹—çš„æ•…äº‹ã€‚æ¦‚è¿°: åŸºäºä¸€ä½å¤§å­¦æ•™æˆçœŸå®æ•…äº‹çš„å‰§æƒ…ç‰‡â€¦â€¦*

+   **å“åº”:** æ¨¡å‹çš„å“åº”

æ‰€æœ‰è¿™äº›éƒ½æ–¹ä¾¿åœ°è®°å½•åœ¨ä¸å…ˆå‰å±•ç¤ºçš„Weaveè¯„ä¼°ç›¸åŒçš„é¡¹ç›®ä¸­ã€‚ç°åœ¨ï¼Œå½“æŸ¥è¯¢å‡ºé”™æ—¶ï¼Œåªéœ€ç‚¹å‡»è¸©æŒ‰é’®ï¼Œå°±å¯ä»¥çœ‹åˆ°å…·ä½“å‘ç”Ÿäº†ä»€ä¹ˆã€‚è¿™å°†å¤§å¤§åŠ é€ŸRosebudğŸŒ¹æ¨èåº”ç”¨çš„è¿­ä»£å’Œæ”¹è¿›ã€‚

![](../Images/f1ec5605b853d379a932d40b1012a4c2.png)

æ˜¾ç¤ºæ¨¡å‹å“åº”å¯è§‚å¯Ÿæ€§çš„å›¾åƒã€‚æ³¨æ„å·¦ä¾§å¦‚ä½•åœ¨W&Bå’ŒWeaveä¹‹é—´æ— ç¼åˆ‡æ¢ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

# **ä½¿ç”¨Prefectè‡ªåŠ¨åŒ–æ•°æ®æ‹‰å–**

ä¸ºäº†ç¡®ä¿RosebudğŸŒ¹çš„æ¨èæŒç»­å‡†ç¡®ï¼Œè‡ªåŠ¨åŒ–æ‹‰å–æ•°æ®å¹¶ä¸Šä¼ åˆ°Pineconeçš„è¿‡ç¨‹å˜å¾—å°¤ä¸ºé‡è¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘é€‰æ‹©äº†[Prefect](https://www.prefect.io/)ã€‚Prefectæ˜¯ä¸€ä¸ªæµè¡Œçš„å·¥ä½œæµç¼–æ’å·¥å…·ã€‚æˆ‘æ­£åœ¨å¯»æ‰¾ä¸€ä¸ªè½»é‡ã€æ˜“å­¦ä¸”ç¬¦åˆPythoné£æ ¼çš„å·¥å…·ï¼Œè€ŒPrefectæ­£ç¬¦åˆè¿™äº›è¦æ±‚ã€‚

![](../Images/74bf21e667d7580aa0f0a410a2ac3d9f.png)

Prefect æä¾›çš„è‡ªåŠ¨åŒ–æµç¨‹ç”¨äºæ‹‰å–å’Œæ›´æ–° Pinecone å‘é‡å­˜å‚¨ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

Prefect æä¾›å¤šç§æ–¹å¼æ¥è°ƒåº¦æ‚¨çš„å·¥ä½œæµã€‚æˆ‘å†³å®šä½¿ç”¨[å¸¦è‡ªåŠ¨åŸºç¡€è®¾æ–½é…ç½®çš„æ¨é€å·¥ä½œæ± ](https://docs.prefect.io/latest/tutorial/work-pools/#push-work-pools-with-automatic-infrastructure-provisioning)ã€‚æˆ‘å‘ç°è¿™ç§è®¾ç½®åœ¨ç®€æ˜“æ€§ä¸å¯é…ç½®æ€§ä¹‹é—´è¾¾åˆ°äº†å¹³è¡¡ã€‚å®ƒå…è®¸ç”¨æˆ·å°† Prefect ä»»åŠ¡å§”æ‰˜ç»™è‡ªåŠ¨é…ç½®è¿è¡Œæ‚¨å·¥ä½œæµæ‰€éœ€çš„æ‰€æœ‰åŸºç¡€è®¾æ–½ï¼Œéƒ¨ç½²åˆ°æ‚¨é€‰æ‹©çš„äº‘æä¾›å•†ã€‚æˆ‘é€‰æ‹©äº†åœ¨ Azure ä¸Šè¿›è¡Œéƒ¨ç½²ï¼Œä½†åœ¨ GCP æˆ– AWS ä¸Šéƒ¨ç½²åªéœ€æ›´æ”¹å‡ è¡Œä»£ç ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ `pinecone_flow.py` æ–‡ä»¶ã€‚ä»¥ä¸‹æ˜¯ç®€åŒ–åçš„æµç¨‹ï¼š

```py
@task
def start():
    """
    Start-up: check everything works or fail fast!
    """

    # Print out some debug info
    print("Starting flow!")

    # Ensure user has set the appropriate env variables
    assert os.environ['LANGCHAIN_API_KEY']
    assert os.environ['OPENAI_API_KEY']
    ...

@task(retries=3, retry_delay_seconds=[1, 10, 100])
def pull_data_to_csv(config):
    TMBD_API_KEY = os.getenv('TMBD_API_KEY')
    YEARS = range(config["years"][0], config["years"][-1] + 1)
    CSV_HEADER = ['Title', 'Runtime (minutes)', 'Language', 'Overview', ...]

    for year in YEARS:
        # Grab list of ids for all films made in {YEAR}
        movie_list = list(set(get_id_list(TMBD_API_KEY, year)))

        FILE_NAME = f'./data/{year}_movie_collection_data.csv'

        # Creating file
        with open(FILE_NAME, 'w') as f:
            writer = csv.writer(f)
            writer.writerow(CSV_HEADER)

        ...

    print("Successfully pulled data from TMDB and created csv files in data/")

@task
def convert_csv_to_docs():
    # Loading in data from all csv files
    loader = DirectoryLoader(
        ...
        show_progress=True)

    docs = loader.load()

    metadata_field_info = [
        AttributeInfo(name="Title",
                      description="The title of the movie", type="string"),
        AttributeInfo(name="Runtime (minutes)",
                      description="The runtime of the movie in minutes", type="integer"),
        ...
    ]

    def convert_to_list(doc, field):
        if field in doc.metadata and doc.metadata[field] is not None:
            doc.metadata[field] = [item.strip()
                                   for item in doc.metadata[field].split(',')]

    ...

    fields_to_convert_list = ['Genre', 'Actors', 'Directors',
                              'Production Companies', 'Stream', 'Buy', 'Rent']
    ...

    # Set 'overview' and 'keywords' as 'page_content' and other fields as 'metadata'
    for doc in docs:
        # Parse the page_content string into a dictionary
        page_content_dict = dict(line.split(": ", 1)
                                 for line in doc.page_content.split("\n") if ": " in line)

        doc.page_content = (
            'Title: ' + page_content_dict.get('Title') +
            '. Overview: ' + page_content_dict.get('Overview') +
            ...
        )

        ...

    print("Successfully took csv files and created docs")

    return docs

@task
def upload_docs_to_pinecone(docs, config):
    # Create empty index
    PINECONE_KEY, PINECONE_INDEX_NAME = os.getenv(
        'PINECONE_API_KEY'), os.getenv('PINECONE_INDEX_NAME')

    pc = Pinecone(api_key=PINECONE_KEY)

    # Target index and check status
    pc_index = pc.Index(PINECONE_INDEX_NAME)
    print(pc_index.describe_index_stats())

    embeddings = OpenAIEmbeddings(model=config['EMBEDDING_MODEL_NAME'])
    namespace = "film_search_prod"

    PineconeVectorStore.from_documents(
        docs,
        ...
    )

    print("Successfully uploaded docs to Pinecone vector store")

@task
def publish_dataset_to_weave(docs):
    # Initialize Weave
    weave.init('film-search')

    rows = []
    for doc in docs:
        row = {
            'Title': doc.metadata.get('Title'),
            'Runtime (minutes)': doc.metadata.get('Runtime (minutes)'),
             ...
        }
        rows.append(row)

    dataset = Dataset(name='Movie Collection', rows=rows)
    weave.publish(dataset)
    print("Successfully published dataset to Weave")

@flow(log_prints=True)
def pinecone_flow():
    with open('./config.json') as f:
        config = json.load(f)

    start()
    pull_data_to_csv(config)
    docs = convert_csv_to_docs()
    upload_docs_to_pinecone(docs, config)
    publish_dataset_to_weave(docs)

if __name__ == "__main__":
    pinecone_flow.deploy(
        name="pinecone-flow-deployment",
        work_pool_name="my-aci-pool",
        cron="0 0 * * 0",
        image=DeploymentImage(
            name="prefect-flows:latest",
            platform="linux/amd64",
        )
    )
```

æ³¨æ„å°† Python å‡½æ•°è½¬æ¢ä¸º Prefect æµç¨‹æ˜¯å¤šä¹ˆç®€å•ã€‚æ‚¨åªéœ€è¦ä¸€äº›ä½¿ç”¨ `@task` è£…é¥°å™¨çš„å­å‡½æ•°ï¼Œä»¥åŠåœ¨ä¸»å‡½æ•°ä¸Šä½¿ç”¨ `@flow` è£…é¥°å™¨ã€‚è¿˜è¦æ³¨æ„ï¼Œåœ¨å°†æ–‡æ¡£ä¸Šä¼ åˆ° Pinecone åï¼Œæˆ‘ä»¬çš„æµç¨‹çš„æœ€åä¸€æ­¥ä¼šå°†æ•°æ®é›†å‘å¸ƒåˆ° Weaveã€‚è¿™å¯¹äºå¯é‡å¤æ€§éå¸¸é‡è¦ã€‚è¦äº†è§£ Prefect çš„åŸºæœ¬çŸ¥è¯†ï¼Œå»ºè®®æµè§ˆ[ä»–ä»¬ç½‘ç«™ä¸Šçš„æ•™ç¨‹](https://docs.prefect.io/latest/tutorial/)ã€‚

åœ¨è„šæœ¬çš„åº•éƒ¨ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¦‚ä½•åœ¨ Prefect ä¸­è¿›è¡Œéƒ¨ç½²ã€‚

+   æˆ‘ä»¬éœ€è¦ä¸ºéƒ¨ç½²æä¾›ä¸€ä¸ª `name` ã€‚è¿™ä¸ªåç§°å¯ä»¥éšæ„ã€‚

+   æˆ‘ä»¬è¿˜éœ€è¦æŒ‡å®šä¸€ä¸ª `work_pool_name` ã€‚Prefect ä¸­çš„æ¨é€å·¥ä½œæ± ä¼šè‡ªåŠ¨å°†ä»»åŠ¡å‘é€åˆ°æ— æœåŠ¡å™¨è®¡ç®—æœºï¼Œè€Œæ— éœ€ä¸­ä»‹ã€‚è¿™ä¸ªåç§°éœ€è¦ä¸åˆ›å»ºæ± æ—¶ä½¿ç”¨çš„åç§°åŒ¹é…ï¼Œä¸‹é¢æˆ‘ä»¬å°†çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚

+   æ‚¨è¿˜éœ€è¦æŒ‡å®šä¸€ä¸ª `cron` ï¼Œå³è®¡æ—¶å™¨çš„ç®€å†™ã€‚å®ƒå…è®¸æ‚¨æŒ‡å®šé‡å¤å·¥ä½œæµçš„é¢‘ç‡ã€‚å€¼ä¸º `"0 0 * * 0"` æ„å‘³ç€æ¯å‘¨é‡å¤æ­¤å·¥ä½œæµã€‚æœ‰å…³ `cron` è¯­æ³•å¦‚ä½•å·¥ä½œçš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[è¿™ä¸ªç½‘ç«™](https://cloud.google.com/scheduler/docs/configuring/cron-job-schedules)ã€‚

+   æœ€åï¼Œæ‚¨éœ€è¦æŒ‡å®šä¸€ä¸ª `DeploymentImage` ã€‚åœ¨æ­¤å¤„ï¼Œæ‚¨éœ€è¦æŒ‡å®š `name` å’Œ `platform` ã€‚åç§°å¯ä»¥éšæ„ï¼Œä½†å¹³å°ä¸è¡Œã€‚å› ä¸ºæˆ‘æƒ³éƒ¨ç½²åˆ° Azure è®¡ç®—å®ä¾‹ï¼Œå¹¶ä¸”è¿™äº›å®ä¾‹è¿è¡Œ Linuxï¼Œæ‰€ä»¥åœ¨ `DeploymentImage` ä¸­æŒ‡å®šè¿™ä¸€ç‚¹éå¸¸é‡è¦ã€‚

è¦ä½¿ç”¨ CLI åœ¨ Azure ä¸Šéƒ¨ç½²æ­¤å·¥ä½œæµï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```py
prefect work-pool create --type azure-container-instance:push --provision-infra my-aci-pool
prefect deployment run 'get_repo_info/my-deployment'
```

è¿™äº›å‘½ä»¤å°†è‡ªåŠ¨é…ç½® Azure ä¸Šæ‰€éœ€çš„æ‰€æœ‰åŸºç¡€è®¾æ–½ã€‚å…¶ä¸­åŒ…æ‹¬ä¸€ä¸ª Azure å®¹å™¨æ³¨å†Œè¡¨ (ACR)ï¼Œå®ƒå°†ä¿å­˜åŒ…å«æ‚¨ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„ Docker é•œåƒä»¥åŠåœ¨ `requirements.txt` ä¸­åˆ—å‡ºçš„ä»»ä½•å¿…è¦åº“ã€‚å®ƒè¿˜å°†åŒ…æ‹¬ä¸€ä¸ª Azure å®¹å™¨å®ä¾‹ (ACI) èº«ä»½ï¼Œè¯¥èº«ä»½å°†å…·æœ‰éƒ¨ç½²ä¸Šè¿° Docker é•œåƒå®¹å™¨æ‰€éœ€çš„æƒé™ã€‚æœ€åï¼Œ`deployment run` å‘½ä»¤å°†æ¯å‘¨è°ƒåº¦ä¸€æ¬¡ä»£ç è¿è¡Œã€‚æ‚¨å¯ä»¥æŸ¥çœ‹ Prefect ä»ªè¡¨æ¿ï¼ŒæŸ¥çœ‹æ‚¨çš„å·¥ä½œæµè¿è¡Œæƒ…å†µï¼š

![](../Images/fd1b54cdc71bbf012184a5f21cddd770.png)

Prefectæµç¨‹æˆåŠŸè¿è¡Œçš„å›¾åƒã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

é€šè¿‡æ¯å‘¨æ›´æ–°æˆ‘çš„Pineconeå‘é‡å­˜å‚¨ï¼Œæˆ‘å¯ä»¥ç¡®ä¿Rosebud ğŸŒ¹çš„æ¨èç»“æœä¿æŒå‡†ç¡®ã€‚

# æ‘˜è¦

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘è®¨è®ºäº†æˆ‘åœ¨æ”¹è¿›Rosebud ğŸŒ¹åº”ç”¨ç¨‹åºæ–¹é¢çš„ç»éªŒã€‚è¿™åŒ…æ‹¬äº†æ•´åˆç¦»çº¿å’Œåœ¨çº¿è¯„ä¼°çš„è¿‡ç¨‹ï¼Œä»¥åŠè‡ªåŠ¨æ›´æ–°æˆ‘çš„Pineconeå‘é‡å­˜å‚¨ã€‚

å…¶ä»–ä¸€äº›æœªåœ¨æœ¬æ–‡ä¸­æåŠçš„æ”¹è¿›ï¼š

+   åœ¨ç”µå½±æ•°æ®ä¸­åŠ å…¥äº†[ç”µå½±æ•°æ®åº“](https://www.themoviedb.org/?language=en-US)çš„è¯„åˆ†ã€‚ç°åœ¨ä½ å¯ä»¥è¦æ±‚â€œ*é«˜è¯„åˆ†ç”µå½±*â€ï¼ŒèŠå¤©æ¨¡å‹å°†ç­›é€‰å‡ºè¯„åˆ†é«˜äº7/10çš„ç”µå½±ã€‚

+   å‡çº§ç‰ˆèŠå¤©æ¨¡å‹ã€‚ç°åœ¨æŸ¥è¯¢å’Œæ‘˜è¦æ¨¡å‹ä½¿ç”¨çš„æ˜¯`gpt-4o-mini`ã€‚è¯·è®°ä½ï¼ŒLLM åˆ¤æ–­æ¨¡å‹ä¹Ÿåœ¨ä½¿ç”¨`gpt-4o-mini`ã€‚

+   åµŒå…¥æ¨¡å‹å·²ä»`text-embedding-ada-002`å‡çº§ä¸º`text-embedding-3-small`ã€‚

+   ç°åœ¨çš„å¹´ä»½è·¨åº¦ä¸º1950â€“2023å¹´ï¼Œè€Œä¸æ˜¯ä»1920å¹´å¼€å§‹ã€‚1920â€“1950å¹´çš„ç”µå½±æ•°æ®è´¨é‡è¾ƒå·®ï¼Œåªä¼šå¯¼è‡´æ¨èç»“æœæ··ä¹±ã€‚

+   ç”¨æˆ·ç•Œé¢æ›´åŠ ç®€æ´ï¼Œæ‰€æœ‰é¡¹ç›®ç›¸å…³çš„ç»†èŠ‚éƒ½è¢«ç§»åˆ°äº†ä¾§è¾¹æ ã€‚

+   GitHubä¸Šçš„æ–‡æ¡£å¤§å¹…æ”¹è¿›ã€‚

+   é”™è¯¯ä¿®å¤ã€‚

å¦‚æœ¬æ–‡å¼€å¤´æ‰€è¿°ï¼Œè¯¥åº”ç”¨ç°åœ¨å®Œå…¨å…è´¹ä½¿ç”¨ï¼æˆ‘å°†åœ¨å¯é¢„è§çš„æœªæ¥æ‰¿æ‹…æŸ¥è¯¢è´¹ç”¨ï¼ˆå› æ­¤é€‰æ‹©äº†`gpt-4o-mini`è€Œä¸æ˜¯æ›´æ˜‚è´µçš„`gpt-4o`ï¼‰ã€‚æˆ‘éå¸¸å¸Œæœ›èƒ½å¤Ÿè·å¾—è¿è¥ä¸€ä¸ªç”Ÿäº§ç¯å¢ƒåº”ç”¨çš„ç»éªŒï¼Œè®©è¯»è€…ä»¬è¯•ç”¨RosebudğŸŒ¹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ–¹å¼ã€‚å¦‚æœåº”ç”¨çœŸçš„çˆ†ç«ï¼Œå°½ç®¡è¿™ä¸å¤ªå¯èƒ½ï¼Œæˆ‘å°†éœ€è¦æ‰¾åˆ°å…¶ä»–çš„èµ„é‡‘æ¨¡å¼ã€‚ä½†å¦‚æœçœŸæœ‰è¿™ç§é—®é¢˜ï¼Œé‚£å°†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚

äº«å—å‘ç°ç²¾å½©ç”µå½±çš„ä¹è¶£ï¼ğŸ¥
