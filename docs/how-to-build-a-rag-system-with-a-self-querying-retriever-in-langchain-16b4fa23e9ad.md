# å¦‚ä½•æ„å»ºä¸€ä¸ªå¸¦è‡ªæŸ¥è¯¢æ£€ç´¢å™¨çš„ RAG ç³»ç»Ÿ

> åŸæ–‡ï¼š[`towardsdatascience.com/how-to-build-a-rag-system-with-a-self-querying-retriever-in-langchain-16b4fa23e9ad?source=collection_archive---------0-----------------------#2024-04-25`](https://towardsdatascience.com/how-to-build-a-rag-system-with-a-self-querying-retriever-in-langchain-16b4fa23e9ad?source=collection_archive---------0-----------------------#2024-04-25)

## RAG + å…ƒæ•°æ®è¿‡æ»¤ = æå¥½çš„ç”µå½±æ¨è ğŸ¿

[](https://medium.com/@ed.izaguirre?source=post_page---byline--16b4fa23e9ad--------------------------------)![Ed Izaguirre](https://medium.com/@ed.izaguirre?source=post_page---byline--16b4fa23e9ad--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--16b4fa23e9ad--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16b4fa23e9ad--------------------------------) [Ed Izaguirre](https://medium.com/@ed.izaguirre?source=post_page---byline--16b4fa23e9ad--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16b4fa23e9ad--------------------------------) Â·é˜…è¯»æ—¶é—´ 12 åˆ†é’ŸÂ·2024 å¹´ 4 æœˆ 25 æ—¥

--

![](img/f25989e1bd8f991ca2ce6d84a27ab9ef.png)

ç”µè§†è§‚çœ‹è€…çš„å›¾ç‰‡ã€‚å›¾ç‰‡ç”± DALLÂ·E 3 åˆ›å»ºã€‚

## ç›®å½•

+   æ£€ç´¢æ•°æ®

+   å°†æ–‡æ¡£ä¸Šä¼ åˆ° Pinecone

+   åˆ›å»ºè‡ªæŸ¥è¯¢æ£€ç´¢å™¨

+   åˆ›å»ºèŠå¤©æ¨¡å‹

+   æ¼”ç¤º

## é“¾æ¥

+   ç¼–è¾‘ï¼šæˆ‘æ›´æ–°äº†ç”µå½±æœç´¢ï¼Œå¹¶å°†å…¶é‡æ–°å‘½åä¸º Rosebudã€‚æˆ‘è¿˜å°†å…¶æ”¹ä¸ºå…è´¹ä½¿ç”¨ï¼ [åœ¨è¿™é‡ŒæŸ¥çœ‹ç½‘ç«™ã€‚](https://filmsearch.azurewebsites.net/)

+   è¿˜å¯ä»¥æŸ¥çœ‹æˆ‘å…³äºæ”¹è¿›è¿™ä¸ªåº”ç”¨ç¨‹åºçš„æ–°æ–‡ç« ï¼ é“¾æ¥.

+   [GitHub ä¸Šçš„ä»£ç é“¾æ¥](https://github.com/EdIzaguirre/Rosebud)

æœ€è¿‘ï¼Œæˆ‘åœ¨æµè§ˆ Maxï¼Œè¯•å›¾æ‰¾åˆ°ä¸€éƒ¨ç”µå½±è§‚çœ‹ã€‚é€šå¸¸è¿™åŒ…æ‹¬æµè§ˆå‘ˆç°ç»™æˆ‘çš„å„ç§åˆ—è¡¨ï¼Œé˜…è¯»å‡ ä¸ªæè¿°ï¼Œç„¶åæŒ‘é€‰å‡ºå¬èµ·æ¥ç•¥å¾®æœ‰è¶£çš„ä¸œè¥¿ã€‚æœ‰æ—¶å€™è¿™æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ï¼Œæœ‰æ—¶å€™åˆ™ä¸å°½å¦‚äººæ„ã€‚å¦‚æœæˆ‘çŸ¥é“è‡ªå·±æƒ³çœ‹çš„ç”µå½±æ ‡é¢˜æˆ–æ¼”å‘˜çš„åå­—ï¼Œæˆ‘é€šå¸¸æ‰ä¼šä½¿ç”¨æœç´¢åŠŸèƒ½ã€‚å¦åˆ™ï¼Œæœç´¢åŠŸèƒ½å°±ä¸å¤ªæœ‰ç”¨äº†ã€‚

æˆ‘çªç„¶æœ‰äº†ä¸€ä¸ªæƒ³æ³•ï¼šä¸ºä»€ä¹ˆæˆ‘ä¸èƒ½ä½¿ç”¨è‡ªç„¶è¯­è¨€ï¼Œæ ¹æ®ç”µå½±çš„*æ°›å›´*æˆ–*å†…å®¹*æ¥æŸ¥è¯¢ç”µå½±ï¼Œè€Œä¸ä»…ä»…æ˜¯åŸºäºæ ‡é¢˜æˆ–æ¼”å‘˜å‘¢ï¼Ÿä¾‹å¦‚ï¼Œä¸ºä»€ä¹ˆæˆ‘ä¸èƒ½æ‰“å¼€ Maxã€Netflix æˆ– Huluï¼Œç„¶ååœ¨æœç´¢æ ä¸­è¾“å…¥ä»¥ä¸‹æŸ¥è¯¢ä¹‹ä¸€ï¼š

+   *å¸®æˆ‘æ‰¾ä¸€äº›è‹±æ–‡çš„æˆå‰§ç”µå½±ï¼Œæ—¶é•¿ä¸è¶…è¿‡ 2 å°æ—¶ï¼Œå¹¶ä¸”æœ‰å® ç‰©ã€‚*

+   *æ¨èåƒµå°¸ç”µå½±ï¼Œä½†è¦ç¡®ä¿å®ƒä»¬æ˜¯æœ‰è¶£çš„ã€‚*

+   *æˆ‘å–œæ¬¢ã€Šç¬æ¯å…¨å®‡å®™ã€‹ã€‚ç»™æˆ‘ä¸€éƒ¨ç±»ä¼¼çš„ç”µå½±ï¼Œä½†æ›´é»‘æš—ä¸€äº›ã€‚*

è¿™ç§æ–¹æ³•çš„ç¾å¦™ä¹‹å¤„ä¸ä»…ä»…åœ¨äºæä¾›äº†æ›´è‡ªç„¶çš„æœç´¢ç”µå½±æ–¹å¼ã€‚è¿™ç§æ–¹æ³•è¿˜ä¿æŠ¤äº†ç”¨æˆ·çš„éšç§ã€‚**è¿™ä¸ªç³»ç»Ÿå®Œå…¨ä¸ä½¿ç”¨ä»»ä½•ç”¨æˆ·æ•°æ®**ã€‚æ‰€éœ€çš„å”¯ä¸€å†…å®¹å°±æ˜¯ä¸€ä¸ªæŸ¥è¯¢ã€‚

æ‰€ä»¥æˆ‘æ„å»ºäº†ç”µå½±æœç´¢ç³»ç»Ÿã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäº RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰çš„ç³»ç»Ÿï¼Œå®ƒæ¥æ”¶ç”¨æˆ·æŸ¥è¯¢ï¼Œå°†å…¶åµŒå…¥å¹¶è¿›è¡Œç›¸ä¼¼æ€§æœç´¢ï¼Œæ‰¾åˆ°ç±»ä¼¼çš„ç”µå½±ã€‚ä½†å®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ªæ™®é€šçš„ RAG ç³»ç»Ÿã€‚è¿™ä¸ªç³»ç»Ÿä½¿ç”¨äº†æ‰€è°“çš„**è‡ªæŸ¥è¯¢æ£€ç´¢å™¨**ã€‚è¿™ä½¿å¾—åœ¨è¿›è¡Œç›¸ä¼¼æ€§æœç´¢ä¹‹å‰ï¼Œèƒ½å¤Ÿé€šè¿‡ç”µå½±çš„å…ƒæ•°æ®å¯¹å…¶è¿›è¡Œç­›é€‰ã€‚æ‰€ä»¥ï¼Œå¦‚æœç”¨æˆ·çš„æŸ¥è¯¢æ˜¯â€œ*æ¨è 1980 å¹´ååˆ¶ä½œçš„ææ€–ç”µå½±ï¼Œå¹¶ä¸”åŒ…å«å¤§é‡çˆ†ç‚¸åœºé¢*â€ï¼Œæœç´¢ä¼šé¦–å…ˆè¿‡æ»¤æ‰æ‰€æœ‰ä¸æ˜¯â€œ1980 å¹´ååˆ¶ä½œçš„ææ€–ç”µå½±â€çš„å½±ç‰‡ï¼Œç„¶åå†è¿›è¡Œå…³äºâ€œåŒ…å«å¤§é‡çˆ†ç‚¸åœºé¢â€çš„ç›¸ä¼¼æ€§æœç´¢ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†æä¾›ä¸€ä¸ªå…³äºå¦‚ä½•æ„å»ºè¿™ä¸ªç³»ç»Ÿçš„é«˜å±‚æ¬¡æ¦‚è¿°ã€‚å¦‚æœä½ æƒ³æ·±å…¥äº†è§£ï¼Œå®Œæ•´çš„ä»£ç å¯ä»¥é€šè¿‡ä¸Šé¢çš„é“¾æ¥è·å–ã€‚

è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ã€‚

# è·å–æ•°æ®

è¿™ä¸ªé¡¹ç›®çš„æ•°æ®æ¥è‡ªäº[The Movie Database (TMDB)](https://developer.themoviedb.org/docs/getting-started)ï¼Œå¹¶ä¸”å¾—åˆ°äº†æ‰€æœ‰è€…çš„è®¸å¯ã€‚ä»–ä»¬çš„ API ç®€å•æ˜“ç”¨ï¼Œç»´æŠ¤è‰¯å¥½ï¼Œå¹¶ä¸”é™åˆ¶ä¸å¤šã€‚æˆ‘ä»ä»–ä»¬çš„ API ä¸­æå–äº†ä»¥ä¸‹ç”µå½±å±æ€§ï¼š

+   ç‰‡å

+   ç‰‡é•¿ï¼ˆåˆ†é’Ÿï¼‰

+   è¯­è¨€

+   æ¦‚è¿°

+   ä¸Šæ˜ å¹´ä»½

+   ç±»å‹

+   æè¿°ç”µå½±çš„å…³é”®è¯

+   æ¼”å‘˜

+   å¯¼æ¼”

+   æµåª’ä½“æ’­æ”¾åœ°ç‚¹

+   è´­ä¹°åœ°ç‚¹

+   ç§Ÿèµåœ°ç‚¹

+   åˆ¶ä½œå…¬å¸åˆ—è¡¨

ä»¥ä¸‹æ˜¯å¦‚ä½•ä½¿ç”¨ TMDB API å’Œ Python çš„å“åº”åº“æå–æ•°æ®çš„ç‰‡æ®µï¼š

```py
def get_data(API_key, Movie_ID, max_retries=5):
    """
    Function to pull details of your film of interest in JSON format.

    parameters:
    API_key (str): Your API key for TMBD
    Movie_ID (str): TMDB id for film of interest

    returns:
    dict: JSON formatted dictionary containing all details of your film of
    interest
    """

    query = 'https://api.themoviedb.org/3/movie/' + Movie_ID + \
        '?api_key='+API_key + '&append_to_response=keywords,' + \
            'watch/providers,credits'
    for i in range(max_retries):
        response = requests.get(query)
        if response.status_code == 429:
            # If the response was a 429, wait and then try again
            print(
                f"Request limit reached. Waiting and retrying ({i+1}/{
                    max_retries})")
            time.sleep(2 ** i)  # Exponential backoff
        else:
            dict = response.json()
            return dict
```

è¯·æ³¨æ„ï¼ŒæŸ¥è¯¢éœ€è¦ç”µå½± IDï¼ˆè¿™äº› ID ä¹Ÿæ˜¯é€šè¿‡ TMDB è·å¾—çš„ï¼‰ï¼Œä»¥åŠ`append_to_response`ï¼Œå®ƒå…è®¸æˆ‘æ‹‰å–å¤šç§ç±»å‹çš„æ•°æ®ï¼Œä¾‹å¦‚å…³é”®è¯ã€è§‚çœ‹æä¾›è€…ã€ä¿¡ç”¨ä¿¡æ¯ï¼ˆå¯¼æ¼”å’Œæ¼”å‘˜ï¼‰ä»¥åŠä¸€äº›å…³äºç”µå½±çš„åŸºæœ¬ä¿¡æ¯ã€‚è¿™é‡Œè¿˜åŒ…æ‹¬ä¸€äº›åŸºæœ¬çš„æ¡†æ¶ä»£ç ï¼Œä»¥é˜²æˆ‘é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œå°½ç®¡æˆ‘ä»æœªé‡åˆ°è¿‡è¿™ç§æƒ…å†µã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦è§£æ JSON å“åº”ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç‰‡æ®µï¼Œå±•ç¤ºäº†å¦‚ä½•è§£æå‚ä¸ç”µå½±åˆ¶ä½œçš„æ¼”å‘˜å’Œå¯¼æ¼”ä¿¡æ¯ï¼š

```py
credits = dict[â€˜creditsâ€™]
actor_list, director_list = [], []

# Parsing cast
cast = credits['cast']
NUM_ACTORS = 5
for member in cast[:NUM_ACTORS]:
    actor_list.append(member["name"])

# Parsing crew
crew = credits['crew']
for member in crew:
    if member['job'] == 'Director':
        director_list.append(member["name"])

actor_str = ', '.join(list(set(actor_list)))
director_str = ', '.join(list(set(director_list)))
```

è¯·æ³¨æ„ï¼Œæˆ‘å°†æ¯éƒ¨ç”µå½±çš„æ¼”å‘˜æ•°é‡é™åˆ¶åœ¨å‰äº”åã€‚æˆ‘è¿˜å¿…é¡»æŒ‡å®šåªå…³å¿ƒå¯¼æ¼”ï¼Œå› ä¸ºå“åº”ä¸­è¿˜åŒ…å«äº†å…¶ä»–ç±»å‹çš„å·¥ä½œäººå‘˜ï¼Œæ¯”å¦‚å‰ªè¾‘å¸ˆã€æœè£…è®¾è®¡å¸ˆç­‰ã€‚

æ‰€æœ‰è¿™äº›æ•°æ®éšåè¢«æ±‡æ€»æˆäº† CSV æ–‡ä»¶ã€‚ä¸Šé¢åˆ—å‡ºçš„æ¯ä¸ªå±æ€§éƒ½å˜æˆäº†ä¸€ä¸ªåˆ—ï¼Œè€Œæ¯ä¸€è¡Œç°åœ¨ä»£è¡¨ä¸€éƒ¨ç‰¹å®šçš„ç”µå½±ã€‚ä»¥ä¸‹æ˜¯ä»`2008_movie_collection_data.csv`æ–‡ä»¶ä¸­æå–çš„ä¸€å°æ®µç”µå½±æ•°æ®ï¼Œè¿™ä¸ªæ–‡ä»¶æ˜¯é€šè¿‡ç¼–ç¨‹ç”Ÿæˆçš„ã€‚åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘å¤§çº¦è·å–äº† 1920 å¹´è‡³ 2023 å¹´é—´çš„ 100 éƒ¨é¡¶çº§ç”µå½±ã€‚

ç”¨äºæ¼”ç¤ºçš„ç”µå½±æ•°æ®ç‰‡æ®µã€‚ä½œè€…æä¾›ã€‚

ä¿¡ä¸ä¿¡ç”±ä½ ï¼Œæˆ‘è‡³ä»Šè¿˜æ²¡æœ‰çœ‹è¿‡ã€ŠåŠŸå¤«ç†ŠçŒ«ã€‹ã€‚æˆ–è®¸åœ¨è¿™ä¸ªé¡¹ç›®ä¹‹åæˆ‘å¾—å»çœ‹ä¸€çœ‹ã€‚

# ä¸Šä¼ æ–‡æ¡£åˆ° Pinecone

æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦å°† csv æ•°æ®ä¸Šä¼ åˆ° Pineconeã€‚åœ¨ RAG ç³»ç»Ÿä¸­ï¼Œé€šå¸¸éœ€è¦å¯¹æ•°æ®è¿›è¡Œåˆ†å—ï¼Œä½†è¿™é‡Œæ¯ä¸ªâ€œæ–‡æ¡£â€ï¼ˆCSV æ–‡ä»¶ä¸­çš„ä¸€è¡Œï¼‰éƒ½ç›¸å¯¹è¾ƒçŸ­ï¼Œå› æ­¤ä¸éœ€è¦åˆ†å—ã€‚æˆ‘é¦–å…ˆå°†æ¯ä¸ª CSV æ–‡ä»¶è½¬æ¢ä¸º LangChain æ–‡æ¡£ï¼Œç„¶åæŒ‡å®šå“ªäº›å­—æ®µåº”è¯¥æ˜¯ä¸»è¦å†…å®¹ï¼Œå“ªäº›å­—æ®µåº”è¯¥æ˜¯ metadataã€‚

ä¸‹é¢æ˜¯ç”¨äºæ„å»ºè¿™äº›æ–‡æ¡£çš„ä»£ç ç‰‡æ®µï¼š

```py
# Loading in data from all csv files
loader = DirectoryLoader(
    path="./data",
    glob="*.csv",
    loader_cls=CSVLoader,
    show_progress=True)

docs = loader.load()

metadata_field_info = [
    AttributeInfo(
        name="Title", description="The title of the movie", type="string"),
    AttributeInfo(name="Runtime (minutes)",
                  description="The runtime of the movie in minutes", type="integer"),
    AttributeInfo(name="Language",
                  description="The language of the movie", type="string"),
    ...
]

for doc in docs:
    # Parse the page_content string into a dictionary
    page_content_dict = dict(line.split(": ", 1)
                             for line in doc.page_content.split("\n") if ": " in line)

    doc.page_content = 'Overview: ' + page_content_dict.get(
        'Overview') + '. Keywords: ' + page_content_dict.get('Keywords')
    doc.metadata = {field.name: page_content_dict.get(
        field.name) for field in metadata_field_info}

    # Convert fields from string to list of strings
    for field in fields_to_convert_list:
        convert_to_list(doc, field)      

    # Convert fields from string to integers
    for field in fields_to_convert_int:
        convert_to_int(doc, field)
```

æ¥è‡ª LangChain çš„`DirectoryLoader`è´Ÿè´£å°†æ‰€æœ‰ csv æ–‡ä»¶åŠ è½½ä¸ºæ–‡æ¡£ã€‚ç„¶åï¼Œæˆ‘éœ€è¦æŒ‡å®šä»€ä¹ˆå†…å®¹åº”è¯¥æ˜¯`page_content`ï¼Œä»€ä¹ˆå†…å®¹åº”è¯¥æ˜¯`metadata`ã€‚è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„å†³å®šã€‚`page_content`å°†è¢«åµŒå…¥å¹¶åœ¨æ£€ç´¢é˜¶æ®µç”¨äºç›¸ä¼¼åº¦æœç´¢ã€‚`metadata`ä»…åœ¨ç›¸ä¼¼åº¦æœç´¢ä¹‹å‰ç”¨äºè¿‡æ»¤ã€‚ æˆ‘å†³å®šå°†`overview`å’Œ`keywords`å±æ€§åµŒå…¥åˆ°`page_content`ä¸­ï¼Œè€Œå…¶ä»–å±æ€§åˆ™ä½œä¸º metadataã€‚è¿›ä¸€æ­¥è°ƒæ•´åº”è€ƒè™‘æ˜¯å¦å°†`title`ä¹ŸåŒ…å«åœ¨`page_content`ä¸­ï¼Œä½†æˆ‘å‘ç°è¿™ä¸ªé…ç½®å¯¹äºå¤§å¤šæ•°ç”¨æˆ·æŸ¥è¯¢æ•ˆæœå¾ˆå¥½ã€‚

ç„¶åï¼Œæ–‡æ¡£éœ€è¦ä¸Šä¼ åˆ° Pineconeã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å½“ç›´æ¥çš„è¿‡ç¨‹ï¼š

```py
# Create empty index
PINECONE_KEY, PINECONE_INDEX_NAME = os.getenv(
    'PINECONE_API_KEY'), os.getenv('PINECONE_INDEX_NAME')

pc = Pinecone(api_key=PINECONE_KEY)

# Uncomment if index is not created already
pc.create_index(
    name=PINECONE_INDEX_NAME,
    dimension=1536,
    metric="cosine",
    spec=PodSpec(
        environment="gcp-starter"
    )
)

# Target index and check status
pc_index = pc.Index(PINECONE_INDEX_NAME)
print(pc_index.describe_index_stats())

embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')

vectorstore = PineconeVectorStore(
    pc_index, embeddings
)

# Create record manager
namespace = f"pinecone/{PINECONE_INDEX_NAME}"
record_manager = SQLRecordManager(
    namespace, db_url="sqlite:///record_manager_cache.sql"
)

record_manager.create_schema()

# Upload documents to pinecome
index(docs, record_manager, vectorstore,
      cleanup="full", source_id_key="Website")
```

åœ¨è¿™é‡Œï¼Œæˆ‘åªæƒ³å¼ºè°ƒå‡ ç‚¹ï¼š

+   ä½¿ç”¨`SQLRecordManager`å¯ä»¥ç¡®ä¿å¦‚æœè¿™æ®µä»£ç è¿è¡Œå¤šæ¬¡ï¼Œé‡å¤çš„æ–‡æ¡£ä¸ä¼šè¢«ä¸Šä¼ åˆ° Pineconeã€‚å¦‚æœæ–‡æ¡£è¢«ä¿®æ”¹ï¼Œåªæœ‰è¯¥æ–‡æ¡£ä¼šåœ¨å‘é‡å­˜å‚¨ä¸­è¢«æ›´æ–°ã€‚

+   æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ OpenAI çš„ç»å…¸`text-embedding-ada-002`åµŒå…¥æ¨¡å‹ã€‚

# åˆ›å»ºè‡ªæŸ¥è¯¢æ£€ç´¢å™¨

è‡ªæŸ¥è¯¢æ£€ç´¢å™¨å°†å…è®¸æˆ‘ä»¬é€šè¿‡ä¹‹å‰å®šä¹‰çš„ metadata è¿‡æ»¤åœ¨ RAG è¿‡ç¨‹ä¸­æ£€ç´¢çš„ç”µå½±ã€‚è¿™å°†å¤§å¤§æé«˜æˆ‘ä»¬ç”µå½±æ¨èç³»ç»Ÿçš„å®ç”¨æ€§ã€‚

é€‰æ‹©å‘é‡å­˜å‚¨æ—¶ï¼Œä¸€ä¸ªé‡è¦çš„è€ƒè™‘å› ç´ æ˜¯ç¡®ä¿å®ƒæ”¯æŒé€šè¿‡ metadata è¿›è¡Œè¿‡æ»¤ï¼Œå› ä¸ºå¹¶éæ‰€æœ‰å‘é‡å­˜å‚¨éƒ½æ”¯æŒã€‚[è¿™æ˜¯ LangChain æ”¯æŒè‡ªæŸ¥è¯¢æ£€ç´¢çš„æ•°æ®åº“åˆ—è¡¨](https://python.langchain.com/docs/integrations/retrievers/self_query)ã€‚å¦ä¸€ä¸ªé‡è¦çš„è€ƒè™‘å› ç´ æ˜¯æ¯ä¸ªå‘é‡å­˜å‚¨å…è®¸å“ªäº›ç±»å‹çš„æ¯”è¾ƒå™¨ã€‚æ¯”è¾ƒå™¨æ˜¯æˆ‘ä»¬é€šè¿‡ metadata è¿›è¡Œè¿‡æ»¤çš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`eq`æ¯”è¾ƒå™¨æ¥ç¡®ä¿æˆ‘ä»¬çš„ç”µå½±å±äºç§‘å¹»ç±»å‹ï¼š`eq('Genre', 'Science Fiction')`ã€‚å¹¶éæ‰€æœ‰å‘é‡å­˜å‚¨éƒ½å…è®¸æ‰€æœ‰æ¯”è¾ƒå™¨ã€‚ä½œä¸ºä¾‹å­ï¼Œè¯·æŸ¥çœ‹[Weaviate ä¸­å…è®¸çš„æ¯”è¾ƒå™¨](https://weaviate.io/developers/weaviate/api/graphql/filters#filter-structure)ï¼Œä»¥åŠå®ƒä»¬ä¸[Pinecone ä¸­çš„æ¯”è¾ƒå™¨](https://docs.pinecone.io/guides/data/filtering-with-metadata#metadata-query-language)çš„å·®å¼‚ã€‚æˆ‘ä»¬éœ€è¦å‘Šè¯‰æ¨¡å‹å…è®¸å“ªäº›æ¯”è¾ƒå™¨ï¼Œä»¥é˜²æ­¢å®ƒæ„å¤–åœ°å†™å‡ºä¸å…è®¸çš„æŸ¥è¯¢ã€‚

é™¤äº†å‘Šè¯‰æ¨¡å‹å­˜åœ¨å“ªäº›æ¯”è¾ƒå™¨ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ç»™æ¨¡å‹æä¾›ä¸€äº›ç”¨æˆ·æŸ¥è¯¢çš„ç¤ºä¾‹å’Œç›¸åº”çš„ç­›é€‰æ¡ä»¶ã€‚è¿™è¢«ç§°ä¸º**å°‘é‡æ ·æœ¬å­¦ä¹ **ï¼Œå®ƒå¯¹äºå¸®åŠ©æŒ‡å¯¼ä½ çš„æ¨¡å‹éå¸¸å®è´µã€‚

ä¸ºäº†çœ‹çœ‹è¿™æœ‰ä»€ä¹ˆå¸®åŠ©ï¼Œçœ‹çœ‹ä»¥ä¸‹ä¸¤ä¸ªç”¨æˆ·æŸ¥è¯¢ï¼š

+   *â€œæ¨èä¸€äº›ç”±çº¦å°”æˆˆæ–¯Â·å…°è¥¿è«æ–¯å¯¼æ¼”çš„ç”µå½±ã€‚â€*

+   *â€œç±»ä¼¼äºçº¦å°”æˆˆæ–¯Â·å…°è¥¿è«æ–¯ç”µå½±çš„ç”µå½±ã€‚â€*

å¯¹äºæˆ‘çš„å…ƒæ•°æ®ç­›é€‰æ¨¡å‹æ¥è¯´ï¼Œå³ä½¿æˆ‘å¸Œæœ›å®ƒä»¬è¢«ä¸åŒå¯¹å¾…ï¼Œä¹Ÿå¾ˆå®¹æ˜“ä¸ºæ¯ä¸ªç¤ºä¾‹ç¼–å†™ç›¸åŒçš„ç­›é€‰æŸ¥è¯¢ã€‚ç¬¬ä¸€ä¸ªåº”è¯¥åªè¿”å›ç”±**å…°è¥¿è«æ–¯**å¯¼æ¼”çš„ç”µå½±ï¼Œè€Œç¬¬äºŒä¸ªåˆ™åº”è¯¥è¿”å›ä¸å…°è¥¿è«æ–¯ç”µå½±æœ‰ç›¸ä¼¼**æ°›å›´**çš„ç”µå½±ã€‚ä¸ºäº†ç¡®ä¿è¿™ç§è¡Œä¸ºï¼Œæˆ‘å‘æ¨¡å‹æä¾›äº†æˆ‘æœŸæœ›çš„è¡Œä¸ºç¤ºä¾‹ã€‚è¯­è¨€æ¨¡å‹çš„ç¾å¦™ä¹‹å¤„åœ¨äºï¼Œå®ƒä»¬å¯ä»¥åˆ©ç”¨å…¶â€œæ¨ç†â€èƒ½åŠ›å’Œä¸–ç•ŒçŸ¥è¯†ï¼Œä»è¿™äº›å°‘é‡çš„ç¤ºä¾‹ä¸­æ¨å¹¿åˆ°å…¶ä»–ç”¨æˆ·æŸ¥è¯¢ã€‚

```py
document_content_description = "Brief overview of a movie, along with keywords"

        # Define allowed comparators list
        allowed_comparators = [
            "$eq",  # Equal to (number, string, boolean)
            "$ne",  # Not equal to (number, string, boolean)
            "$gt",  # Greater than (number)
            "$gte",  # Greater than or equal to (number)
            "$lt",  # Less than (number)
            "$lte",  # Less than or equal to (number)
            "$in",  # In array (string or number)
            "$nin",  # Not in array (string or number)
            "$exists", # Has the specified metadata field (boolean)
        ]

        examples = [
            (
                "Recommend some films by Yorgos Lanthimos.",
                {
                    "query": "Yorgos Lanthimos",
                    "filter": 'in("Directors", ["Yorgos Lanthimos]")',
                },
            ),
            (
                "Films similar to Yorgos Lanthmios movies.",
                {
                    "query": "Dark comedy, absurd, Greek Weird Wave",
                    "filter": 'NO_FILTER',
                },
            ),
            ...
        ]

        metadata_field_info = [
            AttributeInfo(
                name="Title", description="The title of the movie", type="string"),
            AttributeInfo(name="Runtime (minutes)",
                          description="The runtime of the movie in minutes", type="integer"),
            AttributeInfo(name="Language",
                          description="The language of the movie", type="string"),
            ...
        ]

        constructor_prompt = get_query_constructor_prompt(
            document_content_description,
            metadata_field_info,
            allowed_comparators=allowed_comparators,
            examples=examples,
        )

        output_parser = StructuredQueryOutputParser.from_components()
        query_constructor = constructor_prompt | query_model | output_parser

        retriever = SelfQueryRetriever(
            query_constructor=query_constructor,
            vectorstore=vectorstore,
            structured_query_translator=PineconeTranslator(),
            search_kwargs={'k': 10}
        )
```

é™¤äº†ç¤ºä¾‹ï¼Œæ¨¡å‹è¿˜å¿…é¡»äº†è§£æ¯ä¸ªå…ƒæ•°æ®å­—æ®µçš„æè¿°ã€‚è¿™æœ‰åŠ©äºå®ƒç†è§£å¯èƒ½çš„å…ƒæ•°æ®ç­›é€‰ã€‚

æœ€åï¼Œæˆ‘ä»¬æ„å»ºæˆ‘ä»¬çš„é“¾æ¡ã€‚è¿™é‡Œçš„`query_model`æ˜¯ä½¿ç”¨ OpenAI API çš„ GPT-4 Turbo å®ä¾‹ã€‚æˆ‘å»ºè®®ä½¿ç”¨ GPT-4 è€Œä¸æ˜¯ 3.5 æ¥ç¼–å†™è¿™äº›å…ƒæ•°æ®ç­›é€‰æŸ¥è¯¢ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼Œè€Œ 3.5 åœ¨è¿™ä¸€ç‚¹ä¸Šæ›´å®¹æ˜“å‡ºé”™ã€‚`search_kwargs={'k':10}`å‘Šè¯‰æ£€ç´¢å™¨æ ¹æ®ç”¨æˆ·æŸ¥è¯¢æ‹‰å–æœ€ç›¸ä¼¼çš„ 10 éƒ¨ç”µå½±ã€‚

# åˆ›å»ºèŠå¤©æ¨¡å‹

æœ€åï¼Œåœ¨æ„å»ºè‡ªæŸ¥è¯¢æ£€ç´¢å™¨ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å…¶åŸºç¡€ä¸Šæ„å»ºæ ‡å‡†çš„ RAG æ¨¡å‹ã€‚æˆ‘ä»¬ä»å®šä¹‰èŠå¤©æ¨¡å‹å¼€å§‹ã€‚æˆ‘ç§°ä¹‹ä¸ºæ€»ç»“æ¨¡å‹ï¼Œå› ä¸ºå®ƒæ¥å—ä¸€ä¸ªä¸Šä¸‹æ–‡ï¼ˆæ£€ç´¢åˆ°çš„ç”µå½± + ç³»ç»Ÿæ¶ˆæ¯ï¼‰ï¼Œå¹¶ä»¥æ¯ä¸ªæ¨èçš„æ‘˜è¦è¿›è¡Œå›åº”ã€‚å¦‚æœä½ æƒ³é™ä½æˆæœ¬ï¼Œå¯ä»¥ä½¿ç”¨ GPT-3.5 Turboï¼Œæˆ–è€…å¦‚æœä½ æƒ³è¦æœ€å¥½çš„ç»“æœï¼Œå¯ä»¥ä½¿ç”¨ GPT-4 Turboã€‚

åœ¨ç³»ç»Ÿæ¶ˆæ¯ä¸­ï¼Œæˆ‘å‘Šè¯‰æœºå™¨äººå®ƒçš„ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Œå¹¶æä¾›ä¸€ç³»åˆ—å»ºè®®å’Œé™åˆ¶ï¼Œå…¶ä¸­**æœ€é‡è¦çš„æ˜¯ä¸è¦æ¨èä»»ä½•æ²¡æœ‰é€šè¿‡è‡ªæŸ¥è¯¢æ£€ç´¢å™¨æä¾›çš„ç”µå½±**ã€‚åœ¨æµ‹è¯•ä¸­ï¼Œå½“ç”¨æˆ·æŸ¥è¯¢æ²¡æœ‰ä»æ•°æ®åº“ä¸­æ£€ç´¢åˆ°ç”µå½±æ—¶ï¼Œæˆ‘é‡åˆ°äº†é—®é¢˜ã€‚ä¾‹å¦‚ï¼ŒæŸ¥è¯¢ï¼š*â€œæ¨èä¸€äº›ç”±é©¬ç‰¹Â·è¾¾è’™ä¸»æ¼”ã€éŸ¦æ–¯Â·å®‰å¾·æ£®å¯¼æ¼”çš„ææ€–ç‰‡ï¼Œä¸”æ˜¯åœ¨ 1980 å¹´ä¹‹å‰åˆ¶ä½œçš„â€*ä¼šå¯¼è‡´è‡ªæŸ¥è¯¢æ£€ç´¢å™¨æ— æ³•æ£€ç´¢åˆ°ä»»ä½•ç”µå½±ï¼ˆå› ä¸ºè™½ç„¶å¬èµ·æ¥å¾ˆæ£’ï¼Œä½†è¿™æ ·çš„ç”µå½±å¹¶ä¸å­˜åœ¨ï¼‰ã€‚åœ¨æ²¡æœ‰ç”µå½±æ•°æ®çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæ¨¡å‹ä¼šä½¿ç”¨å®ƒè‡ªå·±çš„ï¼ˆé”™è¯¯çš„ï¼‰è®°å¿†æ¥å°è¯•æ¨èä¸€äº›ç”µå½±ã€‚è¿™ç§è¡Œä¸ºä¸å¥½ã€‚æˆ‘ä¸å¸Œæœ› Netflix æ¨èç³»ç»Ÿè®¨è®ºæ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„ç”µå½±ã€‚ä¸‹é¢çš„ç³»ç»Ÿæ¶ˆæ¯æˆåŠŸé˜»æ­¢äº†è¿™ç§è¡Œä¸ºã€‚æˆ‘ç¡®å®æ³¨æ„åˆ°ï¼ŒGPT-4 æ¯” GPT-3.5 æ›´å–„äºéµå¾ªæŒ‡ä»¤ï¼Œè¿™æ˜¯é¢„æœŸä¹‹ä¸­çš„ã€‚

```py
chat_model = ChatOpenAI(
    model=SUMMARY_MODEL_NAME,
    temperature=0,
    streaming=True,
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            'system',
            """
            Your goal is to recommend films to users based on their 
            query and the retrieved context. If a retrieved film doesn't seem 
            relevant, omit it from your response. If your context is empty
            or none of the retrieved films are relevant, do not recommend films
            , but instead tell the user you couldn't find any films 
            that match their query. Aim for three to five film recommendations,
            as long as the films are relevant. You cannot recommend more than 
            five films. Your recommendation should be relevant, original, and 
            at least two to three sentences long.

            YOU CANNOT RECOMMEND A FILM IF IT DOES NOT APPEAR IN YOUR 
            CONTEXT.

            # TEMPLATE FOR OUTPUT
            - **Title of Film**:
                - Runtime:
                - Release Year:
                - Streaming:
                - (Your reasoning for recommending this film)

            Question: {question} 
            Context: {context} 
            """
        ),
    ]
)

def format_docs(docs):
    return "\n\n".join(f"{doc.page_content}\n\nMetadata: {doc.metadata}" for doc in docs)

# Create a chatbot Question & Answer chain from the retriever
rag_chain_from_docs = (
    RunnablePassthrough.assign(
        context=(lambda x: format_docs(x["context"])))
    | prompt
    | chat_model
    | StrOutputParser()
)

rag_chain_with_source = RunnableParallel(
    {"context": retriever, "question": RunnablePassthrough()}
).assign(answer=rag_chain_from_docs)
```

`format_docs` ç”¨äºæ ¼å¼åŒ–å‘ˆç°ç»™æ¨¡å‹çš„ä¿¡æ¯ï¼Œä»¥ä¾¿å®ƒæ˜“äºç†è§£å’Œè§£æã€‚æˆ‘ä»¬å°† `page_content`ï¼ˆæ¦‚è¿°å’Œå…³é”®è¯ï¼‰ä»¥åŠ `metadata`ï¼ˆæ‰€æœ‰å…¶ä»–ç”µå½±å±æ€§ï¼‰åŒæ—¶å‘ˆç°ç»™æ¨¡å‹ï¼›ä»»ä½•å®ƒå¯èƒ½éœ€è¦çš„ä¿¡æ¯ï¼Œä»¥ä¾¿æ›´å¥½åœ°å‘ç”¨æˆ·æ¨èç”µå½±ã€‚

`rag_chain_from_docs` æ˜¯ä¸€ä¸ªé“¾æ¡ï¼Œå®ƒæ¥å—æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œé€šè¿‡ `format_docs` æ ¼å¼åŒ–ï¼Œç„¶åå°†æ ¼å¼åŒ–åçš„æ–‡æ¡£è¾“å…¥æ¨¡å‹ä¸Šä¸‹æ–‡ä¸­ï¼Œæ¨¡å‹åŸºäºè¿™äº›å†…å®¹å›ç­”é—®é¢˜ã€‚æœ€åï¼Œæˆ‘ä»¬åˆ›å»ºäº† `rag_chain_with_source`ï¼Œè¿™æ˜¯ä¸€ä¸ª `RunnableParallel`ï¼Œé¡¾åæ€ä¹‰ï¼Œå®ƒåŒæ—¶æ‰§è¡Œä¸¤ä¸ªæ“ä½œï¼šè‡ªæŸ¥è¯¢æ£€ç´¢å™¨å»æ£€ç´¢ç›¸ä¼¼çš„æ–‡æ¡£ï¼Œè€ŒæŸ¥è¯¢åˆ™é€šè¿‡ `RunnablePassthrough()` ç›´æ¥ä¼ é€’ç»™æ¨¡å‹ã€‚ç„¶åï¼Œæ¥è‡ªå¹¶è¡Œç»„ä»¶çš„ç»“æœè¢«ç»„åˆï¼Œ`rag_chain_from_docs` ç”¨æ¥ç”Ÿæˆç­”æ¡ˆã€‚è¿™é‡Œçš„ `source` æŒ‡çš„æ˜¯æ£€ç´¢å™¨ï¼Œå®ƒè®¿é—®æ‰€æœ‰çš„â€˜æºâ€™æ–‡æ¡£ã€‚

å› ä¸ºæˆ‘å¸Œæœ›ç­”æ¡ˆæ˜¯é€æ­¥æµå¼ä¼ è¾“çš„ï¼ˆä¾‹å¦‚ï¼Œåƒ ChatGPT ä¸€æ ·é€å—å±•ç¤ºç»™ç”¨æˆ·ï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š

```py
for chunk in rag_chain_with_source.stream(query):
    for key in chunk:
        if key == 'answer':
            yield chunk[key]
```

# æ¼”ç¤º

ç°åœ¨æ˜¯æœ‰è¶£çš„éƒ¨åˆ†ï¼šä¸æ¨¡å‹äº’åŠ¨ã€‚å¦‚å‰æ‰€è¿°ï¼ŒStreamlit è¢«ç”¨æ¥åˆ›å»ºå‰ç«¯å¹¶æ‰˜ç®¡åº”ç”¨ç¨‹åºã€‚æˆ‘åœ¨è¿™é‡Œä¸è®¨è®º UI çš„ä»£ç ï¼›æœ‰å…³å®ç°çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§åŸå§‹ä»£ç ã€‚å®ƒç›¸å½“ç›´æ¥ï¼Œè€Œä¸”åœ¨[Streamlit ç½‘ç«™](https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps)ä¸Šæœ‰å¾ˆå¤šå…¶ä»–ç¤ºä¾‹ã€‚

![](img/02b3a62862751b327a753fd250ba3e74.png)

ç”µå½±æœç´¢ç•Œé¢ã€‚ä½œè€…æä¾›ã€‚

æœ‰å‡ ä¸ªå»ºè®®å¯ä»¥ä½¿ç”¨ï¼Œä½†è®©æˆ‘ä»¬å°è¯•æˆ‘ä»¬è‡ªå·±çš„æŸ¥è¯¢ï¼š

![](img/7ad4d1b3125c7faf549f71d8c1afbacf.png)

ç¤ºä¾‹æŸ¥è¯¢å’Œæ¨¡å‹å“åº”ã€‚ä½œè€…æä¾›ã€‚

åœ¨åå°ï¼Œè‡ªæŸ¥è¯¢æ£€ç´¢å™¨ç¡®ä¿è¿‡æ»¤æ‰ä»»ä½•éæ³•è¯­çš„ç”µå½±ã€‚ç„¶åï¼Œå®ƒæ‰§è¡Œäº†ä¸€ä¸ªâ€œæˆé•¿æ•…äº‹â€çš„ç›¸ä¼¼æ€§æœç´¢ï¼Œç»“æœæ˜¯ä¸Šä¸‹æ–‡ä¸­æœ‰åéƒ¨ç”µå½±ã€‚æœ€åï¼Œæ‘˜è¦æœºå™¨äººé€‰æ‹©äº†äº”éƒ¨ç”µå½±è¿›è¡Œæ¨èã€‚è¯·æ³¨æ„æ¨èçš„ç”µå½±èŒƒå›´ï¼šä¸€äº›ç”µå½±çš„ä¸Šæ˜ æ—¥æœŸæ—©è‡³ 1959 å¹´ï¼Œæœ€æ™šçš„ä¸º 2012 å¹´ã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ç¡®ä¿æœºå™¨äººåŒ…æ‹¬ç”µå½±çš„ç‰‡é•¿ã€ä¸Šæ˜ å¹´ä»½ã€æµåª’ä½“æä¾›å•†ï¼Œä»¥åŠç”±æœºå™¨äººç²¾å¿ƒåˆ¶ä½œçš„ç®€çŸ­æ¨èã€‚

*(é™„æ³¨ï¼šå¦‚æœä½ è¿˜æ²¡æœ‰çœ‹è¿‡* [*400 å‡»*](https://en.wikipedia.org/wiki/The_400_Blows)*ï¼Œç«‹åˆ»åœä¸‹ä½ æ­£åœ¨åšçš„äº‹æƒ…ï¼Œå»* [*ç«‹å³è§‚çœ‹*](https://www.youtube.com/watch?v=PvjUhgtn_-U)*ã€‚)*

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ï¼Œé€šå¸¸è¢«è§†ä¸ºè´Ÿé¢çš„ç‰¹æ€§ï¼Œæ¯”å¦‚å…¶å“åº”çš„éç¡®å®šæ€§ï¼Œç°åœ¨å˜æˆäº†ç§¯æçš„ã€‚ä½ å¦‚æœå‘æ¨¡å‹é—®åŒä¸€ä¸ªé—®é¢˜ä¸¤æ¬¡ï¼Œå¯èƒ½ä¼šå¾—åˆ°ç•¥æœ‰ä¸åŒçš„æ¨èã€‚

éœ€è¦æ³¨æ„å½“å‰å®ç°çš„ä¸€äº›é™åˆ¶ï¼š

+   ä¸æ”¯æŒä¿å­˜æ¨èã€‚ç”¨æˆ·å¯èƒ½å¸Œæœ›é‡æ–°è®¿é—®ä»¥å‰çš„æ¨èã€‚

+   æ‰‹åŠ¨æ›´æ–°æ¥è‡ªç”µå½±æ•°æ®åº“çš„åŸå§‹æ•°æ®ã€‚å°†å…¶è‡ªåŠ¨åŒ–å¹¶æ¯å‘¨æ›´æ–°ä¸€æ¬¡æ˜¯ä¸€ä¸ªä¸é”™çš„ä¸»æ„ã€‚

+   è‡ªæŸ¥è¯¢æ£€ç´¢ä¸­çš„å…ƒæ•°æ®è¿‡æ»¤ä¸å‡†ç¡®ã€‚ä¾‹å¦‚ï¼ŒæŸ¥è¯¢â€œBen Affleck filmsâ€å¯èƒ½ä¼šå‡ºç°é—®é¢˜ã€‚è¿™å¯èƒ½æŒ‡çš„æ˜¯ç”±æœ¬Â·é˜¿å¼—è±å…‹**ä¸»æ¼”**çš„ç”µå½±ï¼Œæˆ–è€…æ˜¯ç”±æœ¬Â·é˜¿å¼—è±å…‹**æ‰§å¯¼**çš„ç”µå½±ã€‚è¿™æ˜¯ä¸€ä¸ªéœ€è¦æ¾„æ¸…æŸ¥è¯¢çš„ä¾‹å­ã€‚

å¯¹è¿™ä¸ªé¡¹ç›®çš„å¯èƒ½æ”¹è¿›ä¹‹ä¸€æ˜¯åœ¨æ£€ç´¢åè¿›è¡Œ[æ–‡æ¡£é‡æ–°æ’åº](https://python.langchain.com/docs/integrations/retrievers/cohere-reranker)ã€‚è¿˜å¯ä»¥æœ‰ä¸€ä¸ªèŠå¤©æ¨¡å‹ï¼Œå¯ä»¥è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªé—®ç­”æœºå™¨äººã€‚è¿˜å¯ä»¥åˆ›å»ºä¸€ä¸ª[æ¨èä»£ç†](https://python.langchain.com/docs/integrations/tools/human_tools)ï¼Œå¦‚æœæŸ¥è¯¢ä¸æ˜ç¡®ï¼Œå¯ä»¥å‘ç”¨æˆ·æå‡ºæ¾„æ¸…é—®é¢˜ã€‚

ç©å¾—å¼€å¿ƒï¼Œæœç´¢ç”µå½±å§ï¼
