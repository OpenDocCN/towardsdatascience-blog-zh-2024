- en: 'Support Vector Classifier, Explained: A Visual Guide with Mini 2D Dataset'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ”¯æŒå‘é‡åˆ†ç±»å™¨ï¼Œè§£é‡Šï¼šå¸¦æœ‰è¿·ä½  2D æ•°æ®é›†çš„è§†è§‰æŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9?source=collection_archive---------3-----------------------#2024-10-01](https://towardsdatascience.com/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9?source=collection_archive---------3-----------------------#2024-10-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9?source=collection_archive---------3-----------------------#2024-10-01](https://towardsdatascience.com/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9?source=collection_archive---------3-----------------------#2024-10-01)
- en: CLASSIFICATION ALGORITHM
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ†ç±»ç®—æ³•
- en: Finding the best â€œlineâ€ to separate the classes? Yeah, sure...
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°æœ€ä½³çš„â€œåˆ†éš”çº¿â€æ¥åŒºåˆ†ä¸åŒçš„ç±»åˆ«ï¼Ÿå—¯ï¼Œå½“ç„¶â€¦â€¦
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--62e831e7b9e9--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--62e831e7b9e9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--62e831e7b9e9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--62e831e7b9e9--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--62e831e7b9e9--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--62e831e7b9e9--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--62e831e7b9e9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--62e831e7b9e9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--62e831e7b9e9--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--62e831e7b9e9--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--62e831e7b9e9--------------------------------)
    Â·14 min readÂ·Oct 1, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--62e831e7b9e9--------------------------------)
    Â·14åˆ†é’Ÿé˜…è¯»Â·2024å¹´10æœˆ1æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/5a473769a53d065bc213ca926988bd11.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a473769a53d065bc213ca926988bd11.png)'
- en: '`â›³ï¸ More [CLASSIFICATION ALGORITHM](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c),
    explained: Â· [Dummy Classifier](/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    Â· [K Nearest Neighbor Classifier](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    Â· [Bernoulli Naive Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)
    Â· [Gaussian Naive Bayes](/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c)
    Â· [Decision Tree Classifier](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    Â· [Logistic Regression](/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505)
    â–¶ [Support Vector Classifier](/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9)
    Â· [Multilayer Perceptron](/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c)`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`â›³ï¸ æ›´å¤š [åˆ†ç±»ç®—æ³•](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c)ï¼Œè§£é‡Šå¦‚ä¸‹ï¼š
    Â· [è™šæ‹Ÿåˆ†ç±»å™¨](/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    Â· [K æœ€è¿‘é‚»åˆ†ç±»å™¨](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    Â· [ä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)
    Â· [é«˜æ–¯æœ´ç´ è´å¶æ–¯](/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c)
    Â· [å†³ç­–æ ‘åˆ†ç±»å™¨](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    Â· [é€»è¾‘å›å½’](/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505)
    â–¶ [æ”¯æŒå‘é‡åˆ†ç±»å™¨](/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9)
    Â· [å¤šå±‚æ„ŸçŸ¥å™¨](/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c)`'
- en: â€œSupport Vector Machine (SVM) for classification works on a very basic principle
    â€” it tries to find the best line that separates the two classes.â€ But if I hear
    that oversimplified explanation **one more time**, I might just scream into a
    pillow.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: â€œç”¨äºåˆ†ç±»çš„æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰éµå¾ªä¸€ä¸ªéå¸¸åŸºç¡€çš„åŸåˆ™â€”â€”å®ƒè¯•å›¾æ‰¾åˆ°ä¸€æ¡æœ€ä¼˜çš„åˆ†éš”çº¿ï¼Œå°†ä¸¤ä¸ªç±»åˆ«åˆ†å¼€ã€‚â€ä½†å¦‚æœæˆ‘å†å¬åˆ°è¿™ç§è¿‡äºç®€åŒ–çš„è§£é‡Š**ä¸€æ¬¡**ï¼Œæˆ‘å¯èƒ½çœŸä¼šæŠŠå¤´åŸ‹è¿›æ•å¤´é‡Œå°–å«ã€‚
- en: While the premise sounds simple, SVM is one of those algorithms packed with
    mathematical gymnastics that took me an absurd amount of time to grasp. Why is
    it even called a â€˜machineâ€™? Why do we need support vectors? Why are some points
    suddenly not important? And why does it have to be a straight line â€” oh wait,
    a **straight hyperplane**??? Then thereâ€™s the optimization formula, which is apparently
    so tricky that we need another version called the dual form. But hold on, now
    we need **another** algorithm called SMO to solve that? Whatâ€™s with all the dual
    coefficients that scikit-learn just spits out? And if thatâ€™s not enough, weâ€™re
    suddenly pulling off this magic â€˜kernel tricksâ€™ when a straight line doesnâ€™t cut
    it? Why do we even need these tricks? And why do none of the tutorials ever show
    the actual numbers?!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰æçœ‹èµ·æ¥å¾ˆç®€å•ï¼Œä½†SVMæ˜¯é‚£ç§åŒ…å«å¤æ‚æ•°å­¦è¿ç®—çš„ç®—æ³•ï¼Œæˆ‘èŠ±è´¹äº†å¤§é‡æ—¶é—´æ‰ææ‡‚ã€‚ä¸ºä»€ä¹ˆå®ƒå«åšâ€œæœºå™¨â€ï¼Ÿæˆ‘ä»¬ä¸ºä»€ä¹ˆéœ€è¦æ”¯æŒå‘é‡ï¼Ÿä¸ºä»€ä¹ˆæœ‰äº›ç‚¹çªç„¶å˜å¾—ä¸é‡è¦ï¼Ÿä¸ºä»€ä¹ˆå®ƒå¿…é¡»æ˜¯ç›´çº¿â€”â€”å“¦ï¼Œç­‰ç­‰ï¼Œæ˜¯**ç›´è¶…å¹³é¢**???
    ç„¶åè¿˜æœ‰ä¼˜åŒ–å…¬å¼ï¼Œè¿™ä¸ªå…¬å¼ apparently éš¾å¾—éœ€è¦ä¸€ä¸ªå«åšå¯¹å¶å½¢å¼çš„ç‰ˆæœ¬æ¥å¤„ç†ã€‚ç­‰ç­‰ï¼Œç°åœ¨æˆ‘ä»¬è¿˜éœ€è¦**å¦ä¸€ä¸ª**ç®—æ³•å«åšSMOæ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Ÿé‚£äº›scikit-learnè‡ªåŠ¨è¾“å‡ºçš„å¯¹å¶ç³»æ•°åˆæ˜¯æ€ä¹ˆå›äº‹ï¼Ÿå¦‚æœè¿™è¿˜ä¸å¤Ÿï¼Œå½“ä¸€æ¡ç›´çº¿ä¸å¤Ÿç”¨æ—¶ï¼Œæˆ‘ä»¬åˆå¼€å§‹ä½¿ç”¨ç¥å¥‡çš„â€œæ ¸æŠ€å·§â€ï¼Ÿæˆ‘ä»¬ä¸ºä»€ä¹ˆéœ€è¦è¿™äº›æŠ€å·§ï¼Ÿè€Œä¸”ä¸ºä»€ä¹ˆæ²¡æœ‰æ•™ç¨‹å±•ç¤ºå®é™…çš„æ•°å­—ï¼Ÿï¼
- en: In this article, Iâ€™m trying to stop this Support Vector Madness. After hours
    and hours trying to really understand this algorithm, I will try to explain whatâ€™s
    ACTUALLY going on with ACTUAL numbers (and of course, its visualization too) but
    without the complicated maths, perfect for beginners.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘è¯•å›¾åœæ­¢è¿™ç§æ”¯æŒå‘é‡æœºçš„ç–¯ç‹‚ã€‚åœ¨èŠ±äº†å‡ ä¸ªå°æ—¶å°è¯•çœŸæ­£ç†è§£è¿™ä¸ªç®—æ³•åï¼Œæˆ‘å°†å°è¯•ç”¨**å®é™…**çš„æ•°å­—ï¼ˆå½“ç„¶ï¼Œè¿˜æœ‰å…¶å¯è§†åŒ–ï¼‰æ¥è§£é‡Šå®é™…å‘ç”Ÿäº†ä»€ä¹ˆï¼Œè€Œä¸æ¶‰åŠå¤æ‚çš„æ•°å­¦ï¼Œé€‚åˆåˆå­¦è€…ã€‚
- en: '![](../Images/073bec34540009054f6bb609f371fa8b.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/073bec34540009054f6bb609f371fa8b.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å¯è§†åŒ–ï¼šä½œè€…ä½¿ç”¨Canva Proåˆ›å»ºã€‚å·²ä¼˜åŒ–ä¸ºé€‚åˆç§»åŠ¨ç«¯ï¼›åœ¨æ¡Œé¢ç«¯å¯èƒ½ä¼šæ˜¾å¾—è¿‡å¤§ã€‚
- en: Definition
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®šä¹‰
- en: Support Vector Machines are supervised learning models used mainly for classification
    tasks, though they can be adapted for regression as well. SVMs aim to find the
    line that best divides a dataset into classes (*sighâ€¦*), maximizing the margin
    between these classes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰æ˜¯ç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œä¸»è¦ç”¨äºåˆ†ç±»ä»»åŠ¡ï¼Œå°½ç®¡å®ƒä»¬ä¹Ÿå¯ä»¥é€‚åº”å›å½’ä»»åŠ¡ã€‚SVMæ—¨åœ¨æ‰¾åˆ°èƒ½å¤Ÿæœ€å¥½åœ°å°†æ•°æ®é›†åˆ†æˆä¸åŒç±»åˆ«çš„é‚£æ¡çº¿ï¼ˆ*å”‰â€¦*ï¼‰ï¼Œå¹¶æœ€å¤§åŒ–è¿™äº›ç±»åˆ«ä¹‹é—´çš„é—´éš”ã€‚
- en: '![](../Images/0926d86dbc53835cc82cdbc41023c182.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0926d86dbc53835cc82cdbc41023c182.png)'
- en: Despite its complexities, SVM can be considered one of the fundamental algorithms
    in machine learning.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡SVMå¾ˆå¤æ‚ï¼Œä½†å®ƒä»ç„¶å¯ä»¥è¢«è§†ä¸ºæœºå™¨å­¦ä¹ ä¸­çš„åŸºç¡€ç®—æ³•ä¹‹ä¸€ã€‚
- en: â€œSupport vectorsâ€ are the data points that lie closest to the line and can actually
    define that line as well. And, whatâ€™s with the â€œMachineâ€ then ? While other machine
    learning algorithms could include â€œMachine,â€ SVMâ€™s naming may be partly due to
    historical context when it was developed. Thatâ€™s it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: â€œæ”¯æŒå‘é‡â€æ˜¯é‚£äº›è·ç¦»å†³ç­–è¾¹ç•Œæœ€è¿‘çš„ç‚¹ï¼Œå®ƒä»¬å®é™…ä¸Šå¯ä»¥å®šä¹‰è¿™æ¡çº¿ã€‚é‚£ä¹ˆï¼Œé‚£ä¸ªâ€œæœºå™¨â€åˆæ˜¯ä»€ä¹ˆï¼Ÿè™½ç„¶å…¶ä»–æœºå™¨å­¦ä¹ ç®—æ³•ä¹Ÿå¯ä»¥åŒ…æ‹¬â€œæœºå™¨â€ï¼Œä½†SVMçš„å‘½åå¯èƒ½éƒ¨åˆ†æ¥æºäºå®ƒè¢«å¼€å‘æ—¶çš„å†å²èƒŒæ™¯ã€‚å°±è¿™æ ·ã€‚
- en: ğŸ“Š Dataset Used
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- en: To understand how SVM works, it is a good idea to start from a dataset with
    few samples and smaller dimension. Weâ€™ll use this simple mini 2D dataset (inspired
    by [1]) as an example.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç†è§£SVMçš„å·¥ä½œåŸç†ï¼Œæœ€å¥½ä»ä¸€ä¸ªæ ·æœ¬è¾ƒå°‘ã€ç»´åº¦è¾ƒå°çš„æ•°æ®é›†å¼€å§‹ã€‚æˆ‘ä»¬å°†ä»¥è¿™ä¸ªç®€å•çš„äºŒç»´å°æ•°æ®é›†ï¼ˆçµæ„Ÿæ¥è‡ª[1]ï¼‰ä½œä¸ºç¤ºä¾‹ã€‚
- en: '![](../Images/608af2d7d2e1d635cd2f830d7902f83a.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/608af2d7d2e1d635cd2f830d7902f83a.png)'
- en: 'Columns: Temperature (0â€“3), Humidity (0â€“3), Play Golf (Yes/No). The training
    dataset has 2 dimensions and 8 samples.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—ï¼šæ¸©åº¦ï¼ˆ0â€“3ï¼‰ã€æ¹¿åº¦ï¼ˆ0â€“3ï¼‰ã€æ‰“é«˜å°”å¤«ï¼ˆæ˜¯/å¦ï¼‰ã€‚è®­ç»ƒæ•°æ®é›†æœ‰2ä¸ªç»´åº¦å’Œ8ä¸ªæ ·æœ¬ã€‚
- en: 'Instead of explaining the steps of the training process itself, we will walk
    from keyword to keyword and see how SVM actually works:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ä¼šç›´æ¥è§£é‡Šè®­ç»ƒè¿‡ç¨‹çš„æ­¥éª¤ï¼Œè€Œæ˜¯å°†ä»å…³é”®å­—åˆ°å…³é”®å­—ï¼Œçœ‹çœ‹SVMå®é™…ä¸Šæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼š
- en: 'Part 1: Basic Components'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬1éƒ¨åˆ†ï¼šåŸºæœ¬ç»„ä»¶
- en: Decision Boundary
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å†³ç­–è¾¹ç•Œ
- en: The decision boundary in SVM is the line (or called â€œhyperplaneâ€ in higher dimensions)
    that the algorithm determines to best separate different classes of data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SVMä¸­çš„å†³ç­–è¾¹ç•Œæ˜¯ç®—æ³•ç¡®å®šçš„æœ€ä½³åˆ†éš”ä¸åŒç±»åˆ«æ•°æ®çš„çº¿ï¼ˆæˆ–åœ¨é«˜ç»´ä¸­ç§°ä¸ºâ€œè¶…å¹³é¢â€ï¼‰ã€‚
- en: This line would attempt to keep most â€œYESâ€ points on one side and most â€œNOâ€
    points on the other. However, because for data that isnâ€™t linearly separable,
    this boundary wonâ€™t be perfect â€” some points might be on the â€œwrongâ€ side.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ¡çº¿ä¼šå°½åŠ›æŠŠå¤§å¤šæ•°â€œæ˜¯â€ç±»ç‚¹æ”¾åœ¨ä¸€è¾¹ï¼Œå¤§å¤šæ•°â€œå¦â€ç±»ç‚¹æ”¾åœ¨å¦ä¸€è¾¹ã€‚ç„¶è€Œï¼Œå¯¹äºé‚£äº›ä¸èƒ½çº¿æ€§åˆ†å‰²çš„æ•°æ®ï¼Œè¿™æ¡è¾¹ç•Œä¸ä¼šæ˜¯å®Œç¾çš„â€”â€”ä¸€äº›ç‚¹å¯èƒ½ä¼šå‡ºç°åœ¨â€œé”™è¯¯â€çš„ä¸€ä¾§ã€‚
- en: Once this line is established, any new data can be classified depending on which
    side of the boundary it falls.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ç¡®å®šäº†è¿™æ¡çº¿ï¼Œä»»ä½•æ–°çš„æ•°æ®éƒ½å¯ä»¥æ ¹æ®å®ƒä½äºå†³ç­–è¾¹ç•Œçš„å“ªä¸€ä¾§æ¥è¿›è¡Œåˆ†ç±»ã€‚
- en: '![](../Images/475eed31b224801da296d616dfd81eb8.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/475eed31b224801da296d616dfd81eb8.png)'
- en: In our golf example, it would be the line that tries to separate the â€œYESâ€ (play
    golf) points from the â€œNOâ€ points. SVM would try to position this line even though
    a perfect separation isnâ€™t possible with a straight line. At this point, using
    our eyes, this seems to be a nice line that make a good separator.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„é«˜å°”å¤«ä¾‹å­ä¸­ï¼Œå†³ç­–è¾¹ç•Œå°†è¯•å›¾å°†â€œYESâ€ï¼ˆæ‰“é«˜å°”å¤«ï¼‰å’Œâ€œNOâ€ä¸¤ç±»æ•°æ®ç‚¹åˆ†å¼€ã€‚SVMä¼šå°è¯•å®šä½è¿™æ¡çº¿ï¼Œå°½ç®¡ç”¨ä¸€æ¡ç›´çº¿æ— æ³•åšåˆ°å®Œç¾åˆ†éš”ã€‚æ­¤æ—¶ï¼Œå‡­å€Ÿæˆ‘ä»¬çš„çœ¼å…‰ï¼Œè¿™æ¡çº¿çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªä¸é”™çš„åˆ†éš”çº¿ã€‚
- en: Linear Separability
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: çº¿æ€§å¯åˆ†æ€§
- en: Linear separability refers to whether we can draw a straight line that perfectly
    separates two classes of data points. If data is linearly separable, SVM can find
    a clear, hard boundary between classes. However, when data isnâ€™t linearly separable
    (as in our case) SVM needs to use more advanced techniques.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§å¯åˆ†æ€§æŒ‡çš„æ˜¯æˆ‘ä»¬æ˜¯å¦å¯ä»¥ç”»å‡ºä¸€æ¡ç›´çº¿ï¼Œå®Œç¾åœ°å°†ä¸¤ä¸ªç±»åˆ«çš„æ•°æ®ç‚¹åˆ†å¼€ã€‚å¦‚æœæ•°æ®æ˜¯çº¿æ€§å¯åˆ†çš„ï¼ŒSVMå¯ä»¥æ‰¾åˆ°ä¸€ä¸ªæ¸…æ™°çš„ã€ç¡¬çš„è¾¹ç•Œæ¥åŒºåˆ†ä¸åŒç±»åˆ«ã€‚ç„¶è€Œï¼Œå½“æ•°æ®ä¸æ˜¯çº¿æ€§å¯åˆ†çš„ï¼ˆå¦‚æˆ‘ä»¬çš„æƒ…å†µï¼‰æ—¶ï¼ŒSVMéœ€è¦ä½¿ç”¨æ›´å…ˆè¿›çš„æŠ€æœ¯ã€‚
- en: '![](../Images/c464c383be7459c488a79148a52e09e4.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c464c383be7459c488a79148a52e09e4.png)'
- en: In the training set, no matter how we draw the line, we cannot separate the
    two classes. If we omit index 1 & 8, now we can.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒé›†é‡Œï¼Œä¸è®ºæˆ‘ä»¬å¦‚ä½•ç”»çº¿ï¼Œéƒ½æ— æ³•å°†ä¸¤ç±»æ•°æ®å®Œå…¨åˆ†å¼€ã€‚å¦‚æœæˆ‘ä»¬å¿½ç•¥ç´¢å¼•1å’Œ8ï¼Œç°åœ¨å°±èƒ½åˆ†å¼€å®ƒä»¬äº†ã€‚
- en: Margin
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é—´éš”
- en: The margin in SVM is the distance between the decision boundary and the closest
    data points from each class. These closest points are called support vectors.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨SVMä¸­ï¼Œé—´éš”æ˜¯æŒ‡å†³ç­–è¾¹ç•Œåˆ°æ¯ä¸ªç±»åˆ«çš„æœ€è¿‘æ•°æ®ç‚¹ä¹‹é—´çš„è·ç¦»ã€‚è¿™äº›æœ€è¿‘çš„ç‚¹ç§°ä¸ºæ”¯æŒå‘é‡ã€‚
- en: SVM aims to maximize this margin. A larger margin generally leads to better
    generalization â€” the ability to correctly classify new, unseen data points.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: SVMçš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–è¿™ä¸ªé—´éš”ã€‚è¾ƒå¤§çš„é—´éš”é€šå¸¸èƒ½å¸¦æ¥æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›â€”â€”å³èƒ½å¤Ÿæ­£ç¡®åˆ†ç±»æ–°çš„ã€æœªè§è¿‡çš„æ•°æ®ç‚¹ã€‚
- en: However, because data in general isnâ€™t perfectly separable, SVM might use a
    soft margin approach. This allows some points to be within the margin or even
    on the wrong side of the boundary, trading off perfect separation for a more robust
    overall classifier.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œç”±äºæ•°æ®é€šå¸¸å¹¶ä¸æ˜¯å®Œå…¨å¯åˆ†çš„ï¼ŒSVMå¯èƒ½ä¼šé‡‡ç”¨è½¯é—´éš”çš„æ–¹æ³•ã€‚è¿™å…è®¸ä¸€äº›ç‚¹ä½äºé—´éš”å†…ï¼Œç”šè‡³å¤„äºå†³ç­–è¾¹ç•Œçš„é”™è¯¯ä¸€ä¾§ï¼Œä»è€Œåœ¨å®Œç¾åˆ†éš”ä¸æ„å»ºæ›´å¼ºå¥çš„åˆ†ç±»å™¨ä¹‹é—´åšå‡ºæƒè¡¡ã€‚
- en: '![](../Images/07c9ddad0a6f5df06001f200fdab8947.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07c9ddad0a6f5df06001f200fdab8947.png)'
- en: SVM would try to position the decision boundary to create the widest possible
    margin while still separating most â€œYESâ€ and â€œNOâ€ instances.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: SVMä¼šå°è¯•å°†å†³ç­–è¾¹ç•Œå®šä½ï¼Œåˆ›é€ å‡ºå°½å¯èƒ½å®½çš„é—´éš”ï¼ŒåŒæ—¶å°½é‡å°†å¤§éƒ¨åˆ†â€œYESâ€å’Œâ€œNOâ€å®ä¾‹åˆ†å¼€ã€‚
- en: Hard Margin vs Soft Margin
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¡¬é—´éš”ä¸è½¯é—´éš”
- en: Hard Margin SVM is the ideal scenario where all data points can be perfectly
    separated by the decision boundary, with no misclassifications. In this case,
    the margin is â€œhardâ€ because it doesnâ€™t allow any data points to be on the wrong
    side of the boundary or within the margin.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡¬é—´éš”SVMæ˜¯ç†æƒ³æƒ…å†µï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ•°æ®ç‚¹éƒ½èƒ½è¢«å†³ç­–è¾¹ç•Œå®Œç¾åœ°åˆ†å¼€ï¼Œä¸ä¼šå‡ºç°ä»»ä½•è¯¯åˆ†ç±»ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé—´éš”æ˜¯â€œç¡¬â€çš„ï¼Œå› ä¸ºå®ƒä¸å…è®¸ä»»ä½•æ•°æ®ç‚¹å¤„äºå†³ç­–è¾¹ç•Œçš„é”™è¯¯ä¸€ä¾§æˆ–é—´éš”å†…ã€‚
- en: 'Soft Margin SVM, on the other hand, allows some flexibility. It permits some
    data points to be misclassified or to lie within the margin. This allows the SVM
    to find a good balance between:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œè½¯é—´éš”SVMå…è®¸ä¸€å®šçš„çµæ´»æ€§ã€‚å®ƒå…è®¸ä¸€äº›æ•°æ®ç‚¹è¢«è¯¯åˆ†ç±»ï¼Œæˆ–ä½äºé—´éš”å†…ã€‚è¿™ä½¿å¾—SVMèƒ½å¤Ÿåœ¨ä»¥ä¸‹ä¸¤è€…ä¹‹é—´æ‰¾åˆ°ä¸€ä¸ªè‰¯å¥½çš„å¹³è¡¡ï¼š
- en: Maximizing the margin
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€å¤§åŒ–é—´éš”
- en: Minimizing classification errors
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€å°åŒ–åˆ†ç±»é”™è¯¯
- en: '![](../Images/ebe390809fdb8c6f9f23aaf70d39dd80.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebe390809fdb8c6f9f23aaf70d39dd80.png)'
- en: In our case, a Hard Margin approach isnâ€™t possible because the data isnâ€™t linearly
    separable. Therefore, a Soft Margin approach is necessary for our dataset. With
    Soft Margin SVM, you might allow points like ID 1 & ID 8 to be on the â€œwrongâ€
    side of the boundary if it results in a better overall classifier.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œç¡¬é—´éš”æ–¹æ³•ä¸å¯è¡Œï¼Œå› ä¸ºæ•°æ®ä¸æ˜¯çº¿æ€§å¯åˆ†çš„ã€‚å› æ­¤ï¼Œå¯¹äºæˆ‘ä»¬çš„æ•°æ®é›†ï¼Œå¿…é¡»é‡‡ç”¨è½¯é—´éš”æ–¹æ³•ã€‚åœ¨è½¯é—´éš”SVMä¸­ï¼Œå¯èƒ½å…è®¸åƒID 1å’ŒID 8è¿™æ ·çš„ç‚¹å¤„äºå†³ç­–è¾¹ç•Œçš„â€œé”™è¯¯â€ä¸€ä¾§ï¼Œå¦‚æœè¿™èƒ½å¸¦æ¥æ›´å¥½çš„æ€»ä½“åˆ†ç±»å™¨ã€‚
- en: '**Distance Calculation**'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è·ç¦»è®¡ç®—**'
- en: 'In SVM, distance calculations play an important role in both training and classification.
    The distance of a point *x* from the decision boundary is given by:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨SVMä¸­ï¼Œè·ç¦»è®¡ç®—åœ¨è®­ç»ƒå’Œåˆ†ç±»ä¸­éƒ½èµ·ç€é‡è¦ä½œç”¨ã€‚ç‚¹*x*åˆ°å†³ç­–è¾¹ç•Œçš„è·ç¦»ç”±ä»¥ä¸‹å…¬å¼ç»™å‡ºï¼š
- en: '|*w* Â· *x* + *b*| / ||*w*||'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '|*w* Â· *x* + *b*| / ||*w*||'
- en: where *w* is the weight vector perpendicular to the hyperplane, *b* is the bias
    term, and ||*w*|| is the Euclidean norm of *w*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ*w*æ˜¯å‚ç›´äºè¶…å¹³é¢çš„æƒé‡å‘é‡ï¼Œ*b*æ˜¯åç½®é¡¹ï¼Œ||*w*||æ˜¯*w*çš„æ¬§å‡ é‡Œå¾—èŒƒæ•°ã€‚
- en: '![](../Images/5db8a3f8f5972e138ee8ea808db49c62.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5db8a3f8f5972e138ee8ea808db49c62.png)'
- en: This way, we can see which points are the closest to the hyperplane without
    drawing it.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸ç”»å‡ºè¶…å¹³é¢çš„æƒ…å†µä¸‹ï¼Œçœ‹åˆ°å“ªäº›ç‚¹ç¦»è¶…å¹³é¢æœ€è¿‘ã€‚
- en: Support Vectors
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ”¯æŒå‘é‡
- en: 'Support vectors are the data points with closest distance to the hyperplane.
    They are important because: They â€œsupportâ€ the hyperplane, defining its position.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¯æŒå‘é‡æ˜¯è·ç¦»è¶…å¹³é¢æœ€è¿‘çš„æ•°æ®ç‚¹ã€‚å®ƒä»¬ä¹‹æ‰€ä»¥é‡è¦ï¼Œæ˜¯å› ä¸ºï¼šå®ƒä»¬â€œæ”¯æŒâ€è¶…å¹³é¢ï¼Œå®šä¹‰äº†å…¶ä½ç½®ã€‚
- en: What makes Support Vectors special is that they are the only points that matter
    for determining the decision boundary. All other points could be removed without
    changing the boundaryâ€™s position. This is a key feature of SVM â€” it bases its
    decision on the most critical points rather than all data points.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¯æŒå‘é‡ä¹‹æ‰€ä»¥ç‰¹åˆ«ï¼Œæ˜¯å› ä¸ºå®ƒä»¬æ˜¯ç¡®å®šå†³ç­–è¾¹ç•Œçš„å”¯ä¸€å…³é”®ç‚¹ã€‚å…¶ä»–æ‰€æœ‰ç‚¹å¯ä»¥ç§»é™¤è€Œä¸æ”¹å˜è¾¹ç•Œçš„ä½ç½®ã€‚è¿™æ˜¯æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§â€”â€”å®ƒä¾æ®æœ€å…³é”®çš„ç‚¹æ¥åšå‡ºå†³ç­–ï¼Œè€Œä¸æ˜¯æ‰€æœ‰çš„æ•°æ®ç‚¹ã€‚
- en: '![](../Images/93e911910f9e0a7e061da7e7c7ed4412.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93e911910f9e0a7e061da7e7c7ed4412.png)'
- en: For this hyperplane, we have 3 support vectors that lies on the margin. The
    2 misclassified data points can be regarded as support vectors as well in some
    situations.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªè¶…å¹³é¢ï¼Œæˆ‘ä»¬æœ‰ 3 ä¸ªæ”¯æŒå‘é‡ä½äºè¾¹ç¼˜ä¸Šã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œ2 ä¸ªè¢«é”™è¯¯åˆ†ç±»çš„æ•°æ®ç‚¹ä¹Ÿå¯ä»¥è§†ä¸ºæ”¯æŒå‘é‡ã€‚
- en: Slack Variables
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¾å¼›å˜é‡
- en: Slack Variables are introduced in Soft Margin SVM to quantify the degree of
    misclassification or margin violation for each data point. Theyâ€™re called â€œslackâ€
    because they give the model some slack or flexibility in fitting the data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è½¯é—´éš” SVM ä¸­å¼•å…¥äº†æ¾å¼›å˜é‡ï¼Œç”¨ä»¥é‡åŒ–æ¯ä¸ªæ•°æ®ç‚¹çš„è¯¯åˆ†ç±»æˆ–è¾¹ç¼˜è¿èƒŒç¨‹åº¦ã€‚å®ƒä»¬è¢«ç§°ä¸ºâ€œæ¾å¼›â€å˜é‡ï¼Œå› ä¸ºå®ƒä»¬ä¸ºæ¨¡å‹æä¾›äº†ä¸€äº›æ¾å¼›æˆ–çµæ´»æ€§æ¥æ‹Ÿåˆæ•°æ®ã€‚
- en: 'In SVMs, slack variables *Î¾áµ¢* can be calculated as:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ SVM ä¸­ï¼Œæ¾å¼›å˜é‡ *Î¾áµ¢* å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¡ç®—ï¼š
- en: '*Î¾áµ¢* = max(0, 1 â€” *yáµ¢*(*w* Â· *xáµ¢* + *b*))'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*Î¾áµ¢* = max(0, 1 â€” *yáµ¢*(*w* Â· *xáµ¢* + *b*))'
- en: where
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­
- en: Â· *w* is the weight vector
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *w* æ˜¯æƒé‡å‘é‡
- en: Â· *b* is the bias term
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *b* æ˜¯åç½®é¡¹
- en: Â· *xáµ¢* are the input vectors
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *xáµ¢* æ˜¯è¾“å…¥å‘é‡
- en: Â· *yáµ¢* are the corresponding labels
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *yáµ¢* æ˜¯ç›¸åº”çš„æ ‡ç­¾
- en: 'This formula only works when class labels *yáµ¢* are in {-1, +1} format. It elegantly
    handles both classes:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå…¬å¼ä»…åœ¨ç±»æ ‡ç­¾ *yáµ¢* ä¸º {-1, +1} æ ¼å¼æ—¶æœ‰æ•ˆã€‚å®ƒä¼˜é›…åœ°å¤„ç†äº†ä¸¤ç±»é—®é¢˜ï¼š
- en: 'Â· Correctly classified points beyond margin: *Î¾áµ¢* = 0'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Â· æ­£ç¡®åˆ†ç±»ä¸”ä½äºè¾¹ç¼˜ä¹‹å¤–çš„ç‚¹ï¼š*Î¾áµ¢* = 0
- en: 'Â· Misclassified or margin-violating points: *Î¾áµ¢* > 0'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Â· è¢«é”™è¯¯åˆ†ç±»æˆ–è¿åè¾¹ç¼˜çš„ç‚¹ï¼š*Î¾áµ¢* > 0
- en: Using {-1, +1} labels maintains SVMâ€™s mathematical symmetry and simplifies optimization,
    unlike {0, 1} labels which would require separate cases for each class.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ {-1, +1} æ ‡ç­¾ä¿æŒäº† SVM çš„æ•°å­¦å¯¹ç§°æ€§å¹¶ç®€åŒ–äº†ä¼˜åŒ–ï¼Œä¸ {0, 1} æ ‡ç­¾ä¸åŒï¼Œåè€…éœ€è¦ä¸ºæ¯ä¸€ç±»åˆ›å»ºå•ç‹¬çš„æƒ…å†µã€‚
- en: '![](../Images/178df04c97f876c284556ca61937ee1a.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/178df04c97f876c284556ca61937ee1a.png)'
- en: In our golf dataset, the point (3,3) â€” NO ends up on the â€œYESâ€ side of our boundary.
    Weâ€™d assign a slack variable to this point to measure how far it is on the wrong
    side. Similarly, if (2,0) â€” NO is correctly classified but falls within the margin,
    it would also get a slack variable.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„é«˜å°”å¤«æ•°æ®é›†ä¸­ï¼Œç‚¹ (3,3) â€” NO æœ€ç»ˆä½äºæˆ‘ä»¬çš„è¾¹ç•Œçš„â€œYESâ€ä¸€ä¾§ã€‚æˆ‘ä»¬ä¼šä¸ºè¯¥ç‚¹åˆ†é…ä¸€ä¸ªæ¾å¼›å˜é‡ï¼Œä»¥è¡¡é‡å®ƒåç¦»é”™è¯¯ä¸€ä¾§çš„è·ç¦»ã€‚åŒæ ·ï¼Œå¦‚æœ
    (2,0) â€” NO è¢«æ­£ç¡®åˆ†ç±»ä½†ä½äºè¾¹ç¼˜å†…ï¼Œå®ƒä¹Ÿä¼šå¾—åˆ°ä¸€ä¸ªæ¾å¼›å˜é‡ã€‚
- en: '![](../Images/52dbed69530ef9c8757c2de48abc398c.png)![](../Images/b5f6ebc65cc316f3365fe3231a85f146.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52dbed69530ef9c8757c2de48abc398c.png)![](../Images/b5f6ebc65cc316f3365fe3231a85f146.png)'
- en: In our golf dataset, the point (3,3) â€” NO ends up on the â€œYESâ€ side of our boundary.
    Weâ€™d assign a slack variable to this point to measure how far it is on the wrong
    side. Similarly, if (2,0) â€” NO is correctly classified but falls within the margin,
    it would also get a slack variable.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„é«˜å°”å¤«æ•°æ®é›†ä¸­ï¼Œç‚¹ (3,3) â€” NO æœ€ç»ˆä½äºæˆ‘ä»¬çš„è¾¹ç•Œçš„â€œYESâ€ä¸€ä¾§ã€‚æˆ‘ä»¬ä¼šä¸ºè¯¥ç‚¹åˆ†é…ä¸€ä¸ªæ¾å¼›å˜é‡ï¼Œä»¥è¡¡é‡å®ƒåç¦»é”™è¯¯ä¸€ä¾§çš„è·ç¦»ã€‚åŒæ ·ï¼Œå¦‚æœ
    (2,0) â€” NO è¢«æ­£ç¡®åˆ†ç±»ä½†ä½äºè¾¹ç¼˜å†…ï¼Œå®ƒä¹Ÿä¼šå¾—åˆ°ä¸€ä¸ªæ¾å¼›å˜é‡ã€‚
- en: Primal Form for Hard Margin
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¡¬é—´éš”çš„åŸå§‹å½¢å¼
- en: The primal form is the original optimization problem formulation for SVMs. It
    directly expresses the goal of finding the maximum margin hyperplane in the feature
    space.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹å½¢å¼æ˜¯æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰ä¼˜åŒ–é—®é¢˜çš„åŸå§‹è¡¨è¿°ã€‚å®ƒç›´æ¥è¡¨è¾¾äº†åœ¨ç‰¹å¾ç©ºé—´ä¸­å¯»æ‰¾æœ€å¤§é—´éš”è¶…å¹³é¢çš„ç›®æ ‡ã€‚
- en: 'In simple terms, the primal form seeks to:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€å•æ¥è¯´ï¼ŒåŸå§‹å½¢å¼çš„ç›®æ ‡æ˜¯ï¼š
- en: Find a hyperplane that correctly classifies all data points.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ä¸€ä¸ªèƒ½æ­£ç¡®åˆ†ç±»æ‰€æœ‰æ•°æ®ç‚¹çš„è¶…å¹³é¢ã€‚
- en: Maximize the distance between this hyperplane and the nearest data points from
    each class.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€å¤§åŒ–è¯¥è¶…å¹³é¢ä¸æ¥è‡ªæ¯ä¸ªç±»åˆ«çš„æœ€è¿‘æ•°æ®ç‚¹ä¹‹é—´çš„è·ç¦»ã€‚
- en: 'Primal form is:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹å½¢å¼æ˜¯ï¼š
- en: '**minimize**: (1/2) ||*w*||Â²'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ€å°åŒ–**: (1/2) ||*w*||Â²'
- en: '**subject to**: *yáµ¢*(*w* Â· *xáµ¢* + *b*) â‰¥ 1 for all i'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**å—é™æ¡ä»¶**: *yáµ¢*(*w* Â· *xáµ¢* + *b*) â‰¥ 1 å¯¹æ‰€æœ‰ i éƒ½æˆç«‹'
- en: where
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­
- en: Â· *w* is the weight vector
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *w* æ˜¯æƒé‡å‘é‡
- en: Â· *b* is the bias term
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *b* æ˜¯åç½®é¡¹
- en: Â· *xáµ¢* are the input vectors
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *xáµ¢* æ˜¯è¾“å…¥å‘é‡
- en: Â· *yáµ¢* are the corresponding labels (+1 or -1)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *yáµ¢* æ˜¯ç›¸åº”çš„æ ‡ç­¾ï¼ˆ+1 æˆ– -1ï¼‰
- en: Â· ||*w*||Â² is the squared Euclidean norm of *w*
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Â· ||*w*||Â² æ˜¯ *w* çš„å¹³æ–¹æ¬§å‡ é‡Œå¾—èŒƒæ•°
- en: '![](../Images/5a4e7ae7769876a41d594239f7a087e0.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a4e7ae7769876a41d594239f7a087e0.png)'
- en: In the case of index 1 & 8 omitted, we are trying to find the best line that
    has the bigger the margin.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çœç•¥ç´¢å¼• 1 å’Œ 8 çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ­£åœ¨å°è¯•æ‰¾åˆ°æœ€ä½³çš„è¾¹ç•Œï¼Œä»¥ä¾¿è·å¾—æ›´å¤§çš„è¾¹è·ã€‚
- en: '![](../Images/b2f596443ba8eac5e03ae7421a9580e6.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2f596443ba8eac5e03ae7421a9580e6.png)'
- en: If we choose hyperplane with smaller margin, it gives higher value of the objective
    function, which is not what we want.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬é€‰æ‹©å…·æœ‰è¾ƒå°è¾¹è·çš„è¶…å¹³é¢ï¼Œå®ƒä¼šä½¿ç›®æ ‡å‡½æ•°çš„å€¼æ›´é«˜ï¼Œè€Œè¿™ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚
- en: Primal Form for Soft Margin
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è½¯è¾¹è·çš„åŸå§‹å½¢å¼
- en: 'Remember that the soft margin SVM is an extension of the original (hard margin)
    SVM that allows for some misclassification? This change is reflected in the primal
    form. The soft margin SVM primal form becomes:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œè½¯è¾¹è· SVM æ˜¯åŸå§‹ï¼ˆç¡¬è¾¹è·ï¼‰SVM çš„æ‰©å±•ï¼Œå®ƒå…è®¸ä¸€äº›è¯¯åˆ†ç±»ï¼Ÿè¿™ä¸€å˜åŒ–åœ¨åŸå§‹å½¢å¼ä¸­æœ‰æ‰€ä½“ç°ã€‚è½¯è¾¹è· SVM çš„åŸå§‹å½¢å¼å˜ä¸ºï¼š
- en: '**minimize**: (1/2) ||*w|*|Â² + *C* Î£*áµ¢ Î¾áµ¢*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ€å°åŒ–**ï¼š (1/2) ||*w|*|Â² + *C* Î£*áµ¢ Î¾áµ¢*'
- en: '**subject to**: *yáµ¢*(*w* Â· *xáµ¢* + *b*) â‰¥ 1 â€” *Î¾áµ¢* for all *i*, *Î¾áµ¢* â‰¥ 0 for
    all *i*'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**çº¦æŸæ¡ä»¶**ï¼š*yáµ¢*(*w* Â· *xáµ¢* + *b*) â‰¥ 1 â€” *Î¾áµ¢* å¯¹æ‰€æœ‰ *i*ï¼Œ*Î¾áµ¢* â‰¥ 0 å¯¹æ‰€æœ‰ *i*'
- en: where
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­
- en: Â· *C* is the penalty parameter
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *C* æ˜¯æƒ©ç½šå‚æ•°
- en: Â· *Î¾áµ¢* are the slack variables
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *Î¾áµ¢* æ˜¯æ¾å¼›å˜é‡
- en: Â· All other variables are the same as in the hard margin case
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Â· æ‰€æœ‰å…¶ä»–å˜é‡ä¸ç¡¬è¾¹è·æƒ…å†µä¸‹ç›¸åŒ
- en: '![](../Images/bb835b40fcb1eed9a834078010114b8e.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb835b40fcb1eed9a834078010114b8e.png)'
- en: The penalty of the wrongly classified data points contributes to the objective
    function as extra values to minimize.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¯åˆ†ç±»æ•°æ®ç‚¹çš„æƒ©ç½šä½œä¸ºé¢å¤–å€¼è´¡çŒ®åˆ°ç›®æ ‡å‡½æ•°ä¸­ï¼Œä»¥ä¾¿æœ€å°åŒ–ã€‚
- en: '![](../Images/e0a2b3cf3521173665282aab8c4280b5.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0a2b3cf3521173665282aab8c4280b5.png)'
- en: Say we choose another hyperplane that is a bit closer to index 8\. The objective
    value is now higher. The more balance the distance from the wrongly classified
    ones, the smaller the total penalty.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬é€‰æ‹©äº†å¦ä¸€ä¸ªç¨å¾®é è¿‘ç´¢å¼• 8 çš„è¶…å¹³é¢ã€‚ç›®æ ‡å€¼ç°åœ¨å˜å¾—æ›´é«˜ã€‚ä»è¯¯åˆ†ç±»ç‚¹çš„è·ç¦»è¶Šå¹³è¡¡ï¼Œæ€»çš„æƒ©ç½šå°±è¶Šå°ã€‚
- en: Dual Form
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯¹å¶å½¢å¼
- en: 'Hereâ€™s the bad news: The primal form can be slow and hard to solve, especially
    for complex data.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸ªåæ¶ˆæ¯ï¼šåŸå§‹å½¢å¼å¯èƒ½æ±‚è§£è¾ƒæ…¢ä¸”éš¾ä»¥è§£å†³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚æ•°æ®æ—¶ã€‚
- en: 'The dual form provides an alternative way to solve the SVM optimization problem,
    often leading to computational advantages. Itâ€™s formulated as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹å¶å½¢å¼æä¾›äº†è§£å†³ SVM ä¼˜åŒ–é—®é¢˜çš„æ›¿ä»£æ–¹æ³•ï¼Œé€šå¸¸èƒ½å¤Ÿå¸¦æ¥è®¡ç®—ä¸Šçš„ä¼˜åŠ¿ã€‚å…¶å½¢å¼å¦‚ä¸‹ï¼š
- en: '**maximize**: *Î£áµ¢,â±¼(Î±áµ¢yáµ¢) - Â½Î£áµ¢Î£â±¼(Î±áµ¢Î±â±¼yáµ¢yâ±¼(xáµ¢* Â· *xâ±¼))* **subject to:** 0 â‰¤
    *Î±áµ¢* â‰¤ C for all i, Î£*áµ¢Î±áµ¢yáµ¢* = 0'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ€å¤§åŒ–**ï¼š*Î£áµ¢,â±¼(Î±áµ¢yáµ¢) - Â½Î£áµ¢Î£â±¼(Î±áµ¢Î±â±¼yáµ¢yâ±¼(xáµ¢* Â· *xâ±¼))* **çº¦æŸæ¡ä»¶**ï¼š0 â‰¤ *Î±áµ¢* â‰¤ C å¯¹æ‰€æœ‰
    iï¼ŒÎ£*áµ¢Î±áµ¢yáµ¢* = 0'
- en: 'Where:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼š
- en: Â· *Î±áµ¢* are the Lagrange multipliers (dual variables)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *Î±áµ¢* æ˜¯æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼ˆå¯¹å¶å˜é‡ï¼‰
- en: Â· *yáµ¢* are the class labels (+1 or -1)
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *yáµ¢* æ˜¯ç±»æ ‡ç­¾ï¼ˆ+1 æˆ– -1ï¼‰
- en: Â· *xáµ¢* are the input vectors
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *xáµ¢* æ˜¯è¾“å…¥å‘é‡
- en: Â· *C* is the regularization parameter (upper bound for *Î±áµ¢*)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Â· *C* æ˜¯æ­£åˆ™åŒ–å‚æ•°ï¼ˆ*Î±áµ¢* çš„ä¸Šç•Œï¼‰
- en: Â· (*xáµ¢* Â· *xâ±¼*) denotes the dot product between *xáµ¢* and *xâ±¼*
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Â· (*xáµ¢* Â· *xâ±¼*) è¡¨ç¤º *xáµ¢* å’Œ *xâ±¼* ä¹‹é—´çš„ç‚¹ç§¯
- en: '![](../Images/2e91b4c99d88023d6532f3cdb94d9fe3.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e91b4c99d88023d6532f3cdb94d9fe3.png)'
- en: Other than the training data itself, the only other components in this dual
    form is the Lagrange multipliers (*Î±áµ¢*).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†è®­ç»ƒæ•°æ®æœ¬èº«ï¼Œå”¯ä¸€å‡ºç°åœ¨å¯¹å¶å½¢å¼ä¸­çš„å…¶ä»–æˆåˆ†æ˜¯æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼ˆ*Î±áµ¢*ï¼‰ã€‚
- en: Lagrange Multipliers
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‹‰æ ¼æœ—æ—¥ä¹˜å­
- en: As we notice in the dual form, Lagrange multipliers (*Î±áµ¢*) show up when we transform
    the primal problem into its dual form (thatâ€™s why they also known as the dual
    coefficients). If you noticed, the weights & bias are no longer there!
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨å¯¹å¶å½¢å¼ä¸­çœ‹åˆ°çš„ï¼Œå½“æˆ‘ä»¬å°†åŸå§‹é—®é¢˜è½¬æ¢ä¸ºå¯¹å¶å½¢å¼æ—¶ï¼Œæ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼ˆ*Î±áµ¢*ï¼‰å°±ä¼šå‡ºç°ï¼ˆè¿™ä¹Ÿæ˜¯å®ƒä»¬è¢«ç§°ä¸ºå¯¹å¶ç³»æ•°çš„åŸå› ï¼‰ã€‚å¦‚æœä½ æ³¨æ„åˆ°äº†ï¼Œæƒé‡å’Œåç½®ä¸å†å­˜åœ¨ï¼
- en: 'Each data point in the training set has an associated Lagrange multiplier.
    The good thing is Lagrange multipliers make things much easier to understand:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªè®­ç»ƒé›†ä¸­çš„æ•°æ®ç‚¹éƒ½æœ‰ä¸€ä¸ªå…³è”çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­ã€‚å¥½å¤„æ˜¯ï¼Œæ‹‰æ ¼æœ—æ—¥ä¹˜å­ä½¿å¾—ç†è§£é—®é¢˜å˜å¾—æ›´åŠ å®¹æ˜“ï¼š
- en: '**Interpretation**:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è§£é‡Š**ï¼š'
- en: '- *Î±áµ¢* = 0: The point is correctly classified and outside the margin. This
    point does not influence the decision boundary.'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- *Î±áµ¢* = 0ï¼šè¯¥ç‚¹è¢«æ­£ç¡®åˆ†ç±»å¹¶ä¸”ä½äºè¾¹è·å¤–ã€‚è¿™ä¸ªç‚¹ä¸ä¼šå½±å“å†³ç­–è¾¹ç•Œã€‚'
- en: '- 0 < *Î±áµ¢* < *C*: The point is on the margin boundary. These are called â€œfreeâ€
    or â€œunboundedâ€ support vectors.'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 0 < *Î±áµ¢* < *C*ï¼šè¯¥ç‚¹ä½äºè¾¹è·è¾¹ç•Œä¸Šã€‚è¿™äº›ç‚¹è¢«ç§°ä¸ºâ€œè‡ªç”±â€æˆ–â€œæ— ç•Œâ€æ”¯æŒå‘é‡ã€‚'
- en: '- *Î±áµ¢* = *C*: The point is either on or inside the margin (including misclassified
    points). These are called â€œboundâ€ support vectors.'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- *Î±áµ¢* = *C*ï¼šè¯¥ç‚¹è¦ä¹ˆä½äºè¾¹ç•Œä¸Šï¼Œè¦ä¹ˆä½äºè¾¹ç•Œå†…éƒ¨ï¼ˆåŒ…æ‹¬è¯¯åˆ†ç±»ç‚¹ï¼‰ã€‚è¿™äº›ç‚¹è¢«ç§°ä¸ºâ€œè¾¹ç•Œâ€æ”¯æŒå‘é‡ã€‚'
- en: '**Relationship to decision boundary**:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¸å†³ç­–è¾¹ç•Œçš„å…³ç³»**ï¼š'
- en: '*w* = Î£*áµ¢*(*Î±áµ¢* *yáµ¢* *xáµ¢*),'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*w* = Î£*áµ¢*(*Î±áµ¢* *yáµ¢* *xáµ¢*),'
- en: '*b* = *yáµ¢* â€” Î£*â±¼*(*Î±áµ¢* *yâ±¼*(*xâ±¼* Â· *xáµ¢*))'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*b* = *yáµ¢* â€” Î£*â±¼*(*Î±áµ¢* *yâ±¼*(*xâ±¼* Â· *xáµ¢*))'
- en: where *yáµ¢* is the label of any (unbounded) support vector.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ*yáµ¢*æ˜¯ä»»ä½•ï¼ˆæ— ç•Œï¼‰æ”¯æŒå‘é‡çš„æ ‡ç­¾ã€‚
- en: This means the final decision boundary is determined only by points with non-zero
    *Î±áµ¢* !
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€æœ€ç»ˆçš„å†³ç­–è¾¹ç•Œä»…ç”±å…·æœ‰éé›¶*Î±áµ¢*çš„ç‚¹å†³å®šï¼
- en: '![](../Images/7cb56db83ca8224714cf4cf1d2faf3b5.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7cb56db83ca8224714cf4cf1d2faf3b5.png)'
- en: It turns out the algorithm decides that our original hyperplane is somehow the
    best, it just need bigger margin by halving all the weights. This makes all points
    support vectors somehow, but itâ€™s ok since the dataset itself is small. ğŸ˜…
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœè¡¨æ˜ï¼Œç®—æ³•å†³å®šæˆ‘ä»¬åŸæ¥çš„è¶…å¹³é¢æ˜¯æœ€ä¼˜çš„ï¼Œåªæ˜¯éœ€è¦é€šè¿‡å°†æ‰€æœ‰æƒé‡å‡åŠæ¥å¢å¤§é—´éš”ã€‚è¿™ä½¿å¾—æ‰€æœ‰ç‚¹éƒ½å˜æˆäº†æ”¯æŒå‘é‡ï¼Œä½†ç”±äºæ•°æ®é›†æœ¬èº«è¾ƒå°ï¼Œè¿™æ²¡æœ‰é—®é¢˜ã€‚ğŸ˜…
- en: Sequential Minimal Optimization
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é¡ºåºæœ€å°ä¼˜åŒ–ï¼ˆSequential Minimal Optimizationï¼‰
- en: 'Remember that we havenâ€™t really shown how to get the optimal Lagrange multipliers
    (*Î±áµ¢*)? The algorithm to solve this is called Sequential Minimal Optimization
    (SMO). Hereâ€™s a simplified view of how we get these values:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰çœŸæ­£å±•ç¤ºå¦‚ä½•è·å¾—æœ€ä¼˜çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼ˆ*Î±áµ¢*ï¼‰ï¼Ÿè§£å†³è¿™ä¸ªé—®é¢˜çš„ç®—æ³•ç§°ä¸ºé¡ºåºæœ€å°ä¼˜åŒ–ï¼ˆSMOï¼‰ã€‚ä¸‹é¢æ˜¯æˆ‘ä»¬å¦‚ä½•è·å¾—è¿™äº›å€¼çš„ç®€åŒ–è§†å›¾ï¼š
- en: Start with all Î±áµ¢ at zero.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»æ‰€æœ‰Î±áµ¢ä¸ºé›¶å¼€å§‹ã€‚
- en: Repeatedly select and adjust two Î±áµ¢ at a time to improve the solution.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤é€‰æ‹©å¹¶è°ƒæ•´ä¸¤ä¸ª*Î±áµ¢*ä»¥æ”¹è¿›è§£ã€‚
- en: Update these pairs quickly using simple math.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç®€å•çš„æ•°å­¦å¿«é€Ÿæ›´æ–°è¿™äº›å¯¹ã€‚
- en: Ensure all updates follow SVM constraints.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¡®ä¿æ‰€æœ‰æ›´æ–°éµå¾ªæ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰çº¦æŸã€‚
- en: Repeat until all *Î±áµ¢* are â€œgood enough.â€
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤ç›´åˆ°æ‰€æœ‰*Î±áµ¢*éƒ½â€œè¶³å¤Ÿå¥½â€ä¸ºæ­¢ã€‚
- en: Points with Î±áµ¢ > 0 become support vectors.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å…·æœ‰Î±áµ¢ > 0çš„ç‚¹æˆä¸ºæ”¯æŒå‘é‡ã€‚
- en: This approach efficiently solves the SVM optimization without heavy computations,
    making it practical for large datasets.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•é«˜æ•ˆåœ°è§£å†³äº†SVMä¼˜åŒ–é—®é¢˜ï¼Œæ— éœ€ç¹é‡çš„è®¡ç®—ï¼Œä½¿å…¶åœ¨å¤§æ•°æ®é›†ä¸Šå…·æœ‰å®ç”¨æ€§ã€‚
- en: '![](../Images/6795f2deb4d5b41da832a23ec3a3cd74.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6795f2deb4d5b41da832a23ec3a3cd74.png)'
- en: Decision Function
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å†³ç­–å‡½æ•°
- en: After solving the SVM optimization problem using the dual form and obtaining
    the Lagrange multipliers, we can define the decision function. This function determines
    how new, unseen data points are classified by the trained SVM model.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä½¿ç”¨å¯¹å¶å½¢å¼æ±‚è§£SVMä¼˜åŒ–é—®é¢˜å¹¶è·å¾—æ‹‰æ ¼æœ—æ—¥ä¹˜å­åï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰å†³ç­–å‡½æ•°ã€‚è¯¥å‡½æ•°å†³å®šäº†è®­ç»ƒåçš„SVMæ¨¡å‹å¦‚ä½•å¯¹æ–°çš„ã€æœªè§è¿‡çš„æ•°æ®ç‚¹è¿›è¡Œåˆ†ç±»ã€‚
- en: '*f*(*x*) = Î£*áµ¢*(*Î±áµ¢yáµ¢*(*xáµ¢* Â· *x*)) + *b*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*(*x*) = Î£*áµ¢*(*Î±áµ¢yáµ¢*(*xáµ¢* Â· *x*)) + *b*'
- en: Here, *Î±áµ¢* are the Lagrange multipliers, *y*áµ¢ are the class labels (+1 or -1),
    *xáµ¢* are the support vectors, and *x* is the input vector to be classified. The
    final classification for a new point x is determined by the sign of *f*(*x*) (either
    â€œ+â€ or â€œ-â€).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*Î±áµ¢*æ˜¯æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼Œ*yáµ¢*æ˜¯ç±»åˆ«æ ‡ç­¾ï¼ˆ+1æˆ–-1ï¼‰ï¼Œ*xáµ¢*æ˜¯æ”¯æŒå‘é‡ï¼Œ*x*æ˜¯å¾…åˆ†ç±»çš„è¾“å…¥å‘é‡ã€‚æ–°ç‚¹xçš„æœ€ç»ˆåˆ†ç±»ç”±*f*(*x*)çš„ç¬¦å·å†³å®šï¼ˆå³â€œ+â€æˆ–â€œ-â€ï¼‰ã€‚
- en: Note that this decision function uses only the support vectors (data points
    with non-zero *Î±áµ¢*) to classify new inputs, which is the core principle of the
    SVM algorithm!
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œè¿™ä¸ªå†³ç­–å‡½æ•°ä»…ä½¿ç”¨æ”¯æŒå‘é‡ï¼ˆå…·æœ‰éé›¶*Î±áµ¢*çš„æ•°æ®ç‚¹ï¼‰æ¥åˆ†ç±»æ–°çš„è¾“å…¥æ•°æ®ï¼Œè¿™å°±æ˜¯SVMç®—æ³•çš„æ ¸å¿ƒåŸç†ï¼
- en: '![](../Images/7233f435dd2070b0750e1ef60f117705.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7233f435dd2070b0750e1ef60f117705.png)'
- en: ğŸŒŸ Support Vector Classifier Code
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŒŸ æ”¯æŒå‘é‡åˆ†ç±»å™¨ä»£ç 
- en: 'The results above can be obtained using the following code:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°ç»“æœå¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç è·å¾—ï¼š
- en: '[PRE0]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/dd57dff98a95c2298a2b2520aee3f336.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd57dff98a95c2298a2b2520aee3f336.png)'
- en: 'Part 2: Kernel Trick'
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸æŠ€å·§
- en: As we have seen so far, no matter how we set up the hyperplane, we never could
    make a perfect separation between the two classes. There are actually some â€œtrickâ€
    that we can do to make it separableâ€¦ even though it is not linearly anymore.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæ— è®ºå¦‚ä½•è®¾ç½®è¶…å¹³é¢ï¼Œæˆ‘ä»¬å§‹ç»ˆæ— æ³•å®Œç¾åœ°å°†ä¸¤ç±»æ•°æ®åˆ†å¼€ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥åšä¸€äº›â€œæŠ€å·§â€ï¼Œä½¿å¾—æ•°æ®å¯ä»¥è¢«åˆ†å¼€â€¦â€¦å°½ç®¡å®ƒä¸å†æ˜¯çº¿æ€§å¯åˆ†çš„ã€‚
- en: Input Space vs Feature Space
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¾“å…¥ç©ºé—´ä¸ç‰¹å¾ç©ºé—´
- en: Input Space refers to the original space of your data features. In our golf
    dataset, the Input Space is two-dimensional, consisting of temperature and humidity.
    Each data point in this space represents a specific weather condition where someone
    decided to play golf or not.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å…¥ç©ºé—´æŒ‡çš„æ˜¯æ•°æ®ç‰¹å¾çš„åŸå§‹ç©ºé—´ã€‚åœ¨æˆ‘ä»¬çš„é«˜å°”å¤«æ•°æ®é›†ä¸­ï¼Œè¾“å…¥ç©ºé—´æ˜¯äºŒç»´çš„ï¼Œç”±æ¸©åº¦å’Œæ¹¿åº¦ç»„æˆã€‚æ­¤ç©ºé—´ä¸­çš„æ¯ä¸ªæ•°æ®ç‚¹ä»£è¡¨æŸä¸ªå…·ä½“å¤©æ°”æ¡ä»¶ä¸‹ï¼Œæ˜¯å¦æœ‰äººå†³å®šæ‰“é«˜å°”å¤«ã€‚
- en: Feature Space, on the other hand, is a transformed version of the Input Space
    where the SVM actually performs the classification. Sometimes, data that isnâ€™t
    linearly separable in the Input Space becomes separable when mapped to a higher-dimensional
    Feature Space.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾ç©ºé—´åˆ™æ˜¯è¾“å…¥ç©ºé—´çš„ä¸€ä¸ªè½¬æ¢ç‰ˆæœ¬ï¼ŒSVMå®é™…ä¸Šåœ¨ç‰¹å¾ç©ºé—´ä¸­æ‰§è¡Œåˆ†ç±»ã€‚æœ‰æ—¶ï¼Œåœ¨çº¿æ€§ä¸å¯åˆ†çš„è¾“å…¥ç©ºé—´ä¸­ï¼Œæ•°æ®æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´åå˜å¾—å¯åˆ†ã€‚
- en: '![](../Images/67548459823e251356184cf343374b7a.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67548459823e251356184cf343374b7a.png)'
- en: As we have tried so far, no matter what hyperplane we choose, we couldnâ€™t separate
    the two classes linearly. Instead of just using ğŸŒ and ğŸ’§, the Feature Space might
    include combinations like ğŸŒÂ², ğŸ’§Â², ğŸŒÃ—ğŸ’§. This would turn our 2D Input Space into
    a 5D Feature Space. If you notice, we can find a hyperplane that now can separate
    the two classes perfectly!
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢æ‰€å°è¯•çš„ï¼Œæ— è®ºé€‰æ‹©ä»€ä¹ˆè¶…å¹³é¢ï¼Œæˆ‘ä»¬éƒ½æ— æ³•å°†è¿™ä¸¤ä¸ªç±»åˆ«çº¿æ€§åˆ†å¼€ã€‚é™¤äº†ä½¿ç”¨ğŸŒå’ŒğŸ’§ï¼Œç‰¹å¾ç©ºé—´å¯èƒ½è¿˜åŒ…æ‹¬ç±»ä¼¼ğŸŒÂ²ã€ğŸ’§Â²ã€ğŸŒÃ—ğŸ’§çš„ç»„åˆã€‚è¿™å°†æŠŠæˆ‘ä»¬çš„äºŒç»´è¾“å…¥ç©ºé—´è½¬å˜ä¸ºäº”ç»´ç‰¹å¾ç©ºé—´ã€‚å¦‚æœä½ æ³¨æ„åˆ°çš„è¯ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥æ‰¾åˆ°ä¸€ä¸ªè¶…å¹³é¢ï¼Œèƒ½å¤Ÿå®Œç¾åœ°åˆ†å¼€è¿™ä¸¤ä¸ªç±»åˆ«ï¼
- en: Kernel and Implicit Transformation
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ¸åŠéšå¼å˜æ¢
- en: A kernel is a function that computes the similarity between two data points,
    implicitly representing them in a higher-dimensional space (the feature space).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¸æ˜¯ä¸€ä¸ªè®¡ç®—ä¸¤ä¸ªæ•°æ®ç‚¹ä¹‹é—´ç›¸ä¼¼æ€§çš„å‡½æ•°ï¼Œéšå¼åœ°å°†å®ƒä»¬è¡¨ç¤ºåœ¨ä¸€ä¸ªæ›´é«˜ç»´çš„ç©ºé—´ï¼ˆç‰¹å¾ç©ºé—´ï¼‰ä¸­ã€‚
- en: 'Say, thereâ€™s a function *Ï†*(*x*) that transforms each input point *x* to a
    higher-dimensional space. For example: *Ï†* : â„Â² â†’ â„Â³, *Ï†*(*x*,*y*) = (*x*, *y*,
    *x*Â² + *y*Â²)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 'å‡è®¾æœ‰ä¸€ä¸ªå‡½æ•° *Ï†*(*x*)ï¼Œå®ƒå°†æ¯ä¸ªè¾“å…¥ç‚¹ *x* è½¬æ¢åˆ°ä¸€ä¸ªæ›´é«˜ç»´çš„ç©ºé—´ã€‚ä¾‹å¦‚ï¼š*Ï†* : â„Â² â†’ â„Â³, *Ï†*(*x*,*y*) = (*x*,
    *y*, *x*Â² + *y*Â²)'
- en: '**Common Kernels and Their Implicit Transformations:**'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¸¸è§æ ¸åŠå…¶éšå¼å˜æ¢ï¼š**'
- en: '**a. Linear Kernel**: *K*(*x*,*y*) = *x* Â· *y*'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**a. çº¿æ€§æ ¸**ï¼š*K*(*x*,*y*) = *x* Â· *y*'
- en: '- Transformation:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '- å˜æ¢ï¼š'
- en: '*Ï†*(*x*) = *x* (identity)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*Ï†*(*x*) = *x* ï¼ˆæ’ç­‰å˜æ¢ï¼‰'
- en: '- This doesnâ€™t actually change the space but is useful for linearly separable
    data.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '- è¿™å®é™…ä¸Šå¹¶ä¸ä¼šæ”¹å˜ç©ºé—´ï¼Œä½†å¯¹äºçº¿æ€§å¯åˆ†çš„æ•°æ®æ¥è¯´æ˜¯æœ‰ç”¨çš„ã€‚'
- en: '**b. Polynomial Kernel**: *K*(*x*,*y*) = (*x* Â· *y* + c)*áµˆ*'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**b. å¤šé¡¹å¼æ ¸**ï¼š*K*(*x*,*y*) = (*x* Â· *y* + c)*áµˆ*'
- en: '- Transformation (for *d* = 2, *c* = 1 in â„Â²):'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '- å˜æ¢ï¼ˆå¯¹äº *d* = 2ï¼Œ*c* = 1 åœ¨ â„Â² ä¸­ï¼‰ï¼š'
- en: '*Ï†*(*x*â‚,*x*â‚‚) = (1, âˆš2*x*â‚, âˆš2*x*â‚‚, *x*â‚Â², âˆš2*x*â‚*x*â‚‚, *x*â‚‚Â²)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*Ï†*(*x*â‚,*x*â‚‚) = (1, âˆš2*x*â‚, âˆš2*x*â‚‚, *x*â‚Â², âˆš2*x*â‚*x*â‚‚, *x*â‚‚Â²)'
- en: '- This captures all polynomial terms up to degree *d*.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '- è¿™æ¶µç›–äº†æ‰€æœ‰æœ€é«˜ä¸º *d* æ¬¡çš„å¤šé¡¹å¼é¡¹ã€‚'
- en: '**c. RBF Kernel**: *K*(*x*,*y*) = exp(-*Î³*||*x* - *y*||Â²)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**c. RBF æ ¸**ï¼š*K*(*x*,*y*) = exp(-*Î³*||*x* - *y*||Â²)'
- en: '- Transformation (as an infinite series):'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '- å˜æ¢ï¼ˆä½œä¸ºä¸€ä¸ªæ— ç©·çº§æ•°ï¼‰ï¼š'
- en: '*Ï†*(*x*â‚,*x*â‚‚)= exp(-*Î³*||*x*||Â²) * (1, âˆš(2*Î³*)*x*â‚, âˆš(2*Î³*)*x*â‚‚, â€¦, âˆš(2*Î³*Â²/2!)*x*â‚Â²,
    âˆš(2*Î³*Â²/2!)*x*â‚*x*â‚‚, âˆš(2*Î³*Â²/2!)*x*â‚‚Â², â€¦, âˆš(2*Î³â¿*/*n*!)*x*â‚*â¿*, â€¦)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*Ï†*(*x*â‚,*x*â‚‚) = exp(-*Î³*||*x*||Â²) * (1, âˆš(2*Î³*)*x*â‚, âˆš(2*Î³*)*x*â‚‚, â€¦, âˆš(2*Î³*Â²/2!)*x*â‚Â²,
    âˆš(2*Î³*Â²/2!)*x*â‚*x*â‚‚, âˆš(2*Î³*Â²/2!)*x*â‚‚Â², â€¦, âˆš(2*Î³â¿*/*n*!)*x*â‚*â¿*, â€¦)'
- en: '- Can be thought of as a similarity measure that decreases with distance.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '- å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªç›¸ä¼¼æ€§åº¦é‡ï¼Œéšç€è·ç¦»çš„å¢åŠ è€Œå‡å°ã€‚'
- en: '![](../Images/3ec3cc06460d608cd7214914174c67c9.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ec3cc06460d608cd7214914174c67c9.png)'
- en: This is to illustrate how kernel would transform the input space. In reality,
    the computation of each point in this Feature Space itself is not performed as
    it is expensive to compute, thatâ€™s why it is called implicit.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ—¨åœ¨è¯´æ˜æ ¸å¦‚ä½•è½¬æ¢è¾“å…¥ç©ºé—´ã€‚å®é™…ä¸Šï¼Œç‰¹å¾ç©ºé—´ä¸­æ¯ä¸ªç‚¹çš„è®¡ç®—æœ¬èº«å¹¶ä¸ä¼šæ‰§è¡Œï¼Œå› ä¸ºè®¡ç®—éå¸¸æ˜‚è´µï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒè¢«ç§°ä¸ºéšå¼çš„åŸå› ã€‚
- en: Kernel Trick
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ¸æŠ€å·§
- en: The â€œtrickâ€ part of the kernel trick is that we can perform operations in this
    higher-dimensional space solely using the kernel function, without ever explicitly
    computing the transformation *Ï†*(x).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¸æŠ€å·§çš„â€œæŠ€å·§â€éƒ¨åˆ†åœ¨äºï¼Œæˆ‘ä»¬å¯ä»¥ä»…ä½¿ç”¨æ ¸å‡½æ•°ï¼Œåœ¨è¿™ä¸ªæ›´é«˜ç»´çš„ç©ºé—´ä¸­æ‰§è¡Œæ“ä½œï¼Œè€Œæ— éœ€æ˜¾å¼è®¡ç®—å˜æ¢ *Ï†*(x)ã€‚
- en: 'Notice that in the dual form, the data points only appear as dot products (*xáµ¢*
    Â· *xâ±¼*). This is where the kernel trick comes in. We can replace this dot product
    with a kernel function: (*xáµ¢* Â· *xâ±¼*) â†’ *K*(*xáµ¢*, *xâ±¼*)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œåœ¨å¯¹å¶å½¢å¼ä¸­ï¼Œæ•°æ®ç‚¹ä»…ä»¥ç‚¹ç§¯çš„å½¢å¼å‡ºç° (*xáµ¢* Â· *xâ±¼*)ã€‚è¿™å°±æ˜¯æ ¸æŠ€å·§çš„ä½œç”¨æ‰€åœ¨ã€‚æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªç‚¹ç§¯æ›¿æ¢ä¸ºæ ¸å‡½æ•°ï¼š(*xáµ¢* Â· *xâ±¼*)
    â†’ *K*(*xáµ¢*, *xâ±¼*)
- en: This process cannot be done if we are just using the primal form, that is one
    of the main reason why the dual form is preferable!
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ä»…ä½¿ç”¨åŸå§‹å½¢å¼ï¼Œåˆ™æ— æ³•è¿›è¡Œæ­¤è¿‡ç¨‹ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå¯¹å¶å½¢å¼æ›´å¯å–çš„ä¸»è¦åŸå› ä¹‹ä¸€ï¼
- en: This substitution implicitly maps the data to a higher-dimensional space **without
    explicitly computing the transformation**.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ›¿ä»£æ–¹æ³•éšå¼åœ°å°†æ•°æ®æ˜ å°„åˆ°æ›´é«˜ç»´ç©ºé—´**è€Œä¸æ˜¾å¼è®¡ç®—å˜æ¢**ã€‚
- en: '![](../Images/a948f98c9e82e1974e89f67b3cd2b244.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a948f98c9e82e1974e89f67b3cd2b244.png)'
- en: Decision Function with Kernel Trick
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ ¸æŠ€å·§çš„å†³ç­–å‡½æ•°
- en: 'The resulting decision function for a new point *x* becomes:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ–°ç‚¹ *x* çš„å†³ç­–å‡½æ•°ç»“æœä¸ºï¼š
- en: '*f* (*x*) = sign(Î£*áµ¢* *Î±áµ¢yáµ¢K*(*xáµ¢*, *x*) + *b*)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '*f* (*x*) = sign(Î£*áµ¢* *Î±áµ¢yáµ¢K*(*xáµ¢*, *x*) + *b*)'
- en: where the sum is over all support vectors (points with *Î±áµ¢* > 0).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­æ±‚å’Œæ˜¯é’ˆå¯¹æ‰€æœ‰æ”¯æŒå‘é‡ï¼ˆç‚¹çš„ *Î±áµ¢* > 0ï¼‰ã€‚
- en: '![](../Images/3916df7fe6b42f1589c29aea40e3598a.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3916df7fe6b42f1589c29aea40e3598a.png)'
- en: ğŸŒŸ Support Vector Classifier (with Kernel Trick) Code Summary
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŒŸ æ”¯æŒå‘é‡åˆ†ç±»å™¨ï¼ˆå¸¦æ ¸æŠ€å·§ï¼‰ä»£ç æ€»ç»“
- en: 'The results above can be obtained using the following code:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°ç»“æœå¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç å¾—åˆ°ï¼š
- en: '[PRE1]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/87e23140d1dd4151ec7f60baeb4f8ba2.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87e23140d1dd4151ec7f60baeb4f8ba2.png)'
- en: 'Note: Due to some numerical instability in SVC, we cannot make the intercept
    from scikit-learn and the manual calculation to agreeâ€¦ Thatâ€™s why I didnâ€™t show
    how to calculate bias manually (even though it should be the same way as the linear
    kernel).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼šç”±äº SVC å­˜åœ¨ä¸€äº›æ•°å€¼ä¸ç¨³å®šæ€§ï¼Œæˆ‘ä»¬æ— æ³•ä½¿å¾— scikit-learn ä¸­çš„æˆªè·ä¸æ‰‹åŠ¨è®¡ç®—ä¸€è‡´â€¦â€¦è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘æ²¡æœ‰å±•ç¤ºå¦‚ä½•æ‰‹åŠ¨è®¡ç®—åç½®ï¼ˆå°½ç®¡å®ƒåº”è¯¥ä¸çº¿æ€§æ ¸çš„è®¡ç®—æ–¹æ³•ç›¸åŒï¼‰ã€‚
- en: Key Parameters
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…³é”®å‚æ•°
- en: 'In SVM, the key parameter would be the penalty/regularization parameter C:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ SVM ä¸­ï¼Œå…³é”®å‚æ•°æ˜¯æƒ©ç½š/æ­£åˆ™åŒ–å‚æ•° Cï¼š
- en: 'Large C: Tries hard to classify all training points correctly, potentially
    overfitting'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§ Cï¼šåŠªåŠ›å‡†ç¡®åˆ†ç±»æ‰€æœ‰è®­ç»ƒç‚¹ï¼Œå¯èƒ½ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆ
- en: 'Small C: Allows more misclassifications but aims for a simpler, more general
    model'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å° Cï¼šå…è®¸æ›´å¤šçš„è¯¯åˆ†ç±»ï¼Œä½†ç›®æ ‡æ˜¯å¾—åˆ°ä¸€ä¸ªæ›´ç®€å•ã€æ›´é€šç”¨çš„æ¨¡å‹
- en: Of course, if you are using non-linear kernel, you also need to adjust the degree
    (and coefficients) related to that kernel.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œå¦‚æœä½ ä½¿ç”¨çš„æ˜¯éçº¿æ€§æ ¸ï¼Œä½ è¿˜éœ€è¦è°ƒæ•´ä¸è¯¥æ ¸ç›¸å…³çš„åº¦æ•°ï¼ˆå’Œç³»æ•°ï¼‰ã€‚
- en: Final Remarks
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ€åçš„å¤‡æ³¨
- en: 'Weâ€™ve gone over a lot of the key concepts in SVMs (and how they work), but
    the main idea is this: Itâ€™s all about finding the right balance. You want your
    SVM to learn the important patterns in your data without trying too hard on getting
    every single training data on the correct side of the hyperplane. If itâ€™s too
    strict, it might miss the big picture. If itâ€™s too flexible, it might see patterns
    that arenâ€™t really there. The trick is to tune your SVM so it can identify the
    real trends while still being adaptable enough to handle new data. Get this balance
    right, and youâ€™ve got a powerful tool that can handle all sorts of classification
    problems.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»è®¨è®ºäº†å¾ˆå¤šå…³äº SVM çš„å…³é”®æ¦‚å¿µï¼ˆä»¥åŠå®ƒä»¬çš„å·¥ä½œåŸç†ï¼‰ï¼Œä½†ä¸»è¦æ€æƒ³æ˜¯è¿™æ ·çš„ï¼šè¿™å…¨æ˜¯å…³äºæ‰¾åˆ°åˆé€‚çš„å¹³è¡¡ã€‚ä½ å¸Œæœ›ä½ çš„ SVM å­¦ä¼šè¯†åˆ«æ•°æ®ä¸­çš„é‡è¦æ¨¡å¼ï¼Œè€Œä¸æ˜¯è¿‡äºåŠªåŠ›åœ°è®©æ¯ä¸€ä¸ªè®­ç»ƒæ•°æ®éƒ½è½åœ¨è¶…å¹³é¢çš„æ­£ç¡®ä¸€ä¾§ã€‚å¦‚æœå®ƒå¤ªä¸¥æ ¼ï¼Œå¯èƒ½ä¼šé”™è¿‡å…¨å±€ï¼›å¦‚æœå®ƒå¤ªçµæ´»ï¼Œå¯èƒ½ä¼šçœ‹åˆ°ä¸€äº›å¹¶ä¸å­˜åœ¨çš„æ¨¡å¼ã€‚è¯€çªæ˜¯è°ƒæ•´ä½ çš„
    SVMï¼Œä½¿å…¶èƒ½å¤Ÿè¯†åˆ«å‡ºçœŸæ­£çš„è¶‹åŠ¿ï¼ŒåŒæ—¶ä»å…·æœ‰è¶³å¤Ÿçš„é€‚åº”æ€§æ¥å¤„ç†æ–°æ•°æ®ã€‚æŠŠè¿™ä¸ªå¹³è¡¡åšå¥½ï¼Œä½ å°±æœ‰äº†ä¸€ä¸ªå¯ä»¥è§£å†³å„ç§åˆ†ç±»é—®é¢˜çš„å¼ºå¤§å·¥å…·ã€‚
- en: Further Reading
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥é˜…è¯»
- en: For a detailed explanation of the [Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
    and its implementation in scikit-learn, readers can refer to the official documentation,
    which provides comprehensive information on its usage and parameters.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå…³äº[æ”¯æŒå‘é‡æœº](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)åŠå…¶åœ¨
    scikit-learn ä¸­å®ç°çš„è¯¦ç»†è§£é‡Šï¼Œè¯»è€…å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼Œè¯¥æ–‡æ¡£æä¾›äº†å…³äºå…¶ä½¿ç”¨å’Œå‚æ•°çš„å…¨é¢ä¿¡æ¯ã€‚
- en: Technical Environment
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æŠ€æœ¯ç¯å¢ƒ
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä½¿ç”¨çš„æ˜¯ Python 3.7 å’Œ scikit-learn 1.5ã€‚è™½ç„¶æ‰€è®¨è®ºçš„æ¦‚å¿µé€šå¸¸é€‚ç”¨ï¼Œä½†ä¸åŒç‰ˆæœ¬çš„å…·ä½“ä»£ç å®ç°å¯èƒ½ç•¥æœ‰ä¸åŒã€‚
- en: About the Illustrations
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºæ’å›¾
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…åˆ›ä½œï¼Œèåˆäº†æ¥è‡ª Canva Pro çš„æˆæƒè®¾è®¡å…ƒç´ ã€‚
- en: Reference
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] T. M. Mitchell, [Machine Learning](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)
    (1997), McGraw-Hill Science/Engineering/Math, pp. 59'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] T. M. Mitchell, [æœºå™¨å­¦ä¹ ](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)
    (1997), McGraw-Hill Science/Engineering/Mathï¼Œç¬¬59é¡µ'
- en: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ˜¾ğ™¡ğ™–ğ™¨ğ™¨ğ™ğ™›ğ™ğ™˜ğ™–ğ™©ğ™ğ™¤ğ™£ ğ˜¼ğ™¡ğ™œğ™¤ğ™§ğ™ğ™©ğ™ğ™¢ğ™¨ ğ™ğ™šğ™§ğ™š:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ˜¾ğ™¡ğ™–ğ™¨ğ™¨ğ™ğ™›ğ™ğ™˜ğ™–ğ™©ğ™ğ™¤ğ™£ ğ˜¼ğ™¡ğ™œğ™¤ğ™§ğ™ğ™©ğ™ğ™¢ğ™¨ ğ™ğ™šğ™§ğ™š: '
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----62e831e7b9e9--------------------------------)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----62e831e7b9e9--------------------------------)'
- en: Classification Algorithms
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ†ç±»ç®—æ³•
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----62e831e7b9e9--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----62e831e7b9e9--------------------------------)8ä¸ªæ•…äº‹![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
- en: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½è¿˜å–œæ¬¢ï¼š
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----62e831e7b9e9--------------------------------)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----62e831e7b9e9--------------------------------)'
- en: Regression Algorithms
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å›å½’ç®—æ³•
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----62e831e7b9e9--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This â€œdummyâ€ doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----62e831e7b9e9--------------------------------)5ä¸ªæ•…äº‹ï¼[ä¸€åªæˆ´ç€è¾«å­å’Œç²‰è‰²å¸½å­çš„å¡é€šå¨ƒå¨ƒã€‚è¿™ä¸ªâ€œè™šæ‹Ÿâ€å¨ƒå¨ƒï¼Œå¸¦ç€åŸºç¡€è®¾è®¡å’Œå¿ƒå½¢è£…é¥°çš„è¡¬è¡«ï¼Œå½¢è±¡åœ°ä»£è¡¨äº†æœºå™¨ä¸­çš„è™šæ‹Ÿå›å½’å™¨æ¦‚å¿µã€‚å°±åƒè¿™ä¸ªç©å…·èˆ¬çš„äººç‰©æ˜¯ä¸€ä¸ªç®€åŒ–çš„ã€é™æ€çš„äººç‰©è¡¨ç¤ºä¸€æ ·ï¼Œè™šæ‹Ÿå›å½’å™¨ä¹Ÿæ˜¯ä¸€ç§åŸºæœ¬æ¨¡å‹ï¼Œä¸ºæ›´å¤æ‚çš„åˆ†ææä¾›åŸºå‡†ã€‚](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----62e831e7b9e9--------------------------------)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----62e831e7b9e9--------------------------------)'
- en: Ensemble Learning
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›†æˆå­¦ä¹ 
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----62e831e7b9e9--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----62e831e7b9e9--------------------------------)4ä¸ªæ•…äº‹ï¼[](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
