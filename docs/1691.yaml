- en: Running Local LLMs is More Useful and Easier Than You Think
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/running-local-llms-is-more-useful-and-easier-than-you-think-f735631272ad?source=collection_archive---------0-----------------------#2024-07-11](https://towardsdatascience.com/running-local-llms-is-more-useful-and-easier-than-you-think-f735631272ad?source=collection_archive---------0-----------------------#2024-07-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A step-by-step guide to run Llama3 locally with Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://guillaume-weingertner.medium.com/?source=post_page---byline--f735631272ad--------------------------------)[![Guillaume
    Weingertner](../Images/fbfb34af986a7788394b6033c6954d57.png)](https://guillaume-weingertner.medium.com/?source=post_page---byline--f735631272ad--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f735631272ad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f735631272ad--------------------------------)
    [Guillaume Weingertner](https://guillaume-weingertner.medium.com/?source=post_page---byline--f735631272ad--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f735631272ad--------------------------------)
    ·6 min read·Jul 11, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c33e44339c2e97b84b8ec61429cda142.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by AI by Author
  prefs: []
  type: TYPE_NORMAL
- en: '#1 Why Local LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ChatGPT is great, no doubt about that, but it comes with a significant drawback:
    everything you write or upload is stored on OpenAI’s servers. Although this may
    be fine in many cases, when dealing with sensitive data this might become a problem.'
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, I started exploring open-source LLMs which can be run locally
    on personal computers. As it turns out, there are actually many more reasons why
    they are great.
  prefs: []
  type: TYPE_NORMAL
- en: '1\. **Data Privacy**: your information stays on your machine.'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. **Cost-Effective**: no subscription fees or API costs, they are free to
    use.'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. **Customization**: models can be fine-tuned with your specific system prompts
    or datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. **Offline Functionality**: no internet connection is required.'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. **Unrestricted Use**: free from limitations imposed by external APIs.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, setting up a local LLM is surprisingly straightforward. This article provides
    a step-by-step guide to help you install and run an open-source model on your…
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
