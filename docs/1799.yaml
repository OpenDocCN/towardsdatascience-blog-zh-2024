- en: Forecasting US GDP using Machine Learning and Mathematics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器学习和数学预测美国GDP
- en: 原文：[https://towardsdatascience.com/forecasting-us-gdp-using-machine-learning-and-mathematics-62f3f794d690?source=collection_archive---------2-----------------------#2024-07-24](https://towardsdatascience.com/forecasting-us-gdp-using-machine-learning-and-mathematics-62f3f794d690?source=collection_archive---------2-----------------------#2024-07-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/forecasting-us-gdp-using-machine-learning-and-mathematics-62f3f794d690?source=collection_archive---------2-----------------------#2024-07-24](https://towardsdatascience.com/forecasting-us-gdp-using-machine-learning-and-mathematics-62f3f794d690?source=collection_archive---------2-----------------------#2024-07-24)
- en: What can we learn from this modern problem?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们能从这个现代问题中学到什么？
- en: '[](https://medium.com/@dmongia_35626?source=post_page---byline--62f3f794d690--------------------------------)[![Dron
    Mongia](../Images/97b524f351f2dbb489cb9dc6fc340fce.png)](https://medium.com/@dmongia_35626?source=post_page---byline--62f3f794d690--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--62f3f794d690--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--62f3f794d690--------------------------------)
    [Dron Mongia](https://medium.com/@dmongia_35626?source=post_page---byline--62f3f794d690--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@dmongia_35626?source=post_page---byline--62f3f794d690--------------------------------)[![Dron
    Mongia](../Images/97b524f351f2dbb489cb9dc6fc340fce.png)](https://medium.com/@dmongia_35626?source=post_page---byline--62f3f794d690--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--62f3f794d690--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--62f3f794d690--------------------------------)
    [Dron Mongia](https://medium.com/@dmongia_35626?source=post_page---byline--62f3f794d690--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--62f3f794d690--------------------------------)
    ·14 min read·Jul 24, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--62f3f794d690--------------------------------)
    ·14分钟阅读·2024年7月24日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3fbd13ca97f54686d59cd4faecac6b41.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fbd13ca97f54686d59cd4faecac6b41.png)'
- en: Photo by [Igor Omilaev](https://unsplash.com/@omilaev?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[Igor Omilaev](https://unsplash.com/@omilaev?utm_source=medium&utm_medium=referral)于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '**Motivation: why would we want to forecast US GDP?**'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**动机：我们为什么要预测美国GDP？**'
- en: GDP is a very strong metric of a country’s economic well-being; therefore, making
    forecasts of the measurement highly sought after. Policymakers and legislators,
    for example, may want to have a rough forecast of the trends regarding the country’s
    GDP prior to passing a new bill or law. Researchers and economists will also consider
    these forecasts for various endeavors in both academic and industrial settings.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: GDP是衡量一个国家经济福祉的一个非常重要的指标；因此，预测这一指标非常受关注。例如，政策制定者和立法者可能希望在通过新法案或法律之前对国家GDP的趋势做出粗略预测。研究人员和经济学家也会在各种学术和工业领域的工作中考虑这些预测。
- en: '**Procedure: how can we approach this problem?**'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**过程：我们如何接近这个问题？**'
- en: Forecasting GDP, similarly to many other time series problems, follows a general
    workflow.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多其他时间序列问题类似，GDP预测遵循一个一般性的工作流程。
- en: Using the integrated FRED (Federal Reserve Economic Data) library and API, we
    will create our features by constructing a data frame composed of US GDP along
    with some other metrics that are closely related (GDP = Consumption + Investment
    + Govt. Spending + Net Export)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用集成的FRED（联邦储备经济数据）库和API，我们将通过构建一个包含美国GDP及其他密切相关指标的数据框来创建我们的特征（GDP = 消费 +
    投资 + 政府支出 + 净出口）
- en: Using a variety of statistical tests and analyses, we will explore the nuances
    of our data in order to better understand the underlying relationships between
    features.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用多种统计检验和分析方法，我们将探索数据的细微差别，以更好地理解特征之间潜在的关系。
- en: Finally, we will utilize a variety of statistical and machine-learning models
    to conclude which approach can lead us to the most accurate and efficient forecast.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将利用多种统计和机器学习模型来得出哪种方法能带给我们最准确和高效的预测结果。
- en: Along all of these steps, we will delve into the nuances of the underlying mathematical
    backbone that supports our tests and models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些步骤中，我们将深入探讨支持我们检验和模型的基本数学框架的细微差别。
- en: '**Step 1: Feature Creation**'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**步骤 1：特征创建**'
- en: To construct our dataset for this project, we will be utilizing the FRED (Federal
    Reserve Economic Data) API which is the premier application to gather economic
    data. Note that to use this data, one must register an account on the FRED website
    and request a custom API key.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建这个项目的数据集，我们将利用FRED（联邦储备经济数据）API，这是收集经济数据的首选应用程序。请注意，要使用这些数据，必须在FRED网站上注册账户并申请一个自定义API密钥。
- en: Each time series on the website is connected to a specific character string
    (for example GDP is linked to ‘GDP’, Net Export to ‘NETEXP’, etc.). This is important
    because when we make a call for each of our features, we need to make sure that
    we specify the correct character string to go along with it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 网站上的每个时间序列都与一个特定的字符串相连接（例如，GDP连接到“GDP”，净出口连接到“NETEXP”等）。这一点非常重要，因为当我们调用每个特征时，我们需要确保指定正确的字符串来配合它。
- en: 'Keeping this in mind, lets now construct our data frame:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这一点，现在让我们构建数据框：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Notice that since we have defined functions as opposed to static chunks of
    code, we are free to expand our list of features for further testing. Running
    this code, our resulting data frame is the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于我们已经定义了函数，而不是静态代码块，因此我们可以自由地扩展我们的特征列表以进行进一步测试。运行这段代码后，我们得到的数据框如下：
- en: '![](../Images/b7ae9f89eac9b86b0cb20261a2c07e7f.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7ae9f89eac9b86b0cb20261a2c07e7f.png)'
- en: (final dataset)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: （最终数据集）
- en: We notice that our dataset starts from the 1960s, giving us a fairly broad historical
    context. In addition, looking at the shape of the data frame, we have 1285 instances
    of actual economic data to work with, a number that is not necessarily small but
    not big either. These observations will come into play during our modeling phase.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到我们的数据集从1960年代开始，这为我们提供了一个相当广泛的历史背景。此外，从数据框的形状来看，我们有1285个实际经济数据实例，这个数量虽然不算小，但也不算大。这些观察将在我们建模阶段发挥作用。
- en: '**Step 2: Exploratory Data Analysis**'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**步骤2：探索性数据分析**'
- en: Now that our dataset is initialized, we can begin visualizing and conducting
    tests to gather some insights into the behavior of our data and how our features
    relate to one another.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的数据集已经初始化，我们可以开始可视化并进行测试，从而获取一些关于数据行为及其特征之间关系的洞察。
- en: '**Visualization (Line plot):**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**可视化（折线图）：**'
- en: 'Our first approach to analyzing this dataset is to simply graph each feature
    on the same plot in order to catch some patterns. We can write the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析这个数据集的第一个方法是将每个特征绘制在同一图表上，以便捕捉一些模式。我们可以编写以下代码：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Running the code, we get the result:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后，我们得到的结果是：
- en: '![](../Images/f2b62eec9e69b6fe2b12d21217107e35.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2b62eec9e69b6fe2b12d21217107e35.png)'
- en: (features plotted against one another)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: （特征之间的绘图）
- en: Looking at the graph, we notice below that some of the features resemble GDP
    far more than others. For instance, GDP and PCE follow almost the exact same trend
    while NETEXP shares no visible similarities. Though it may be tempting, we can
    not yet begin selecting and removing certain features before conducting more exploratory
    tests.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 看图时，我们注意到一些特征与GDP的相似度远高于其他特征。例如，GDP和PCE几乎遵循完全相同的趋势，而NETEXP则没有明显的相似性。虽然可能会很诱人，但我们在进行更多探索性测试之前，还不能开始选择并去除某些特征。
- en: '**ADF (Augmented Dickey-Fuller) Test:**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**ADF（增强型迪基-富勒）检验：**'
- en: The ADF (Augmented Dickey-Fuller) Test evaluates the stationarity of a particular
    time series by checking for the presence of a unit root, a characteristic that
    defines a time series as nonstationarity. Stationarity essentially means that
    a time series has a constant mean and variance. This is important to test because
    many popular forecasting methods (including ones we will use in our modeling phase)
    require stationarity to function properly.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ADF（增强型迪基-富勒）检验通过检查单位根的存在来评估特定时间序列的平稳性，单位根是定义时间序列为非平稳性的特征。平稳性本质上意味着时间序列具有恒定的均值和方差。进行此测试非常重要，因为许多流行的预测方法（包括我们在建模阶段将使用的方法）需要平稳性才能正常运行。
- en: '![](../Images/fc808d998fca289a59d232b4a07aec12.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc808d998fca289a59d232b4a07aec12.png)'
- en: Formula for Unit Root
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 单位根公式
- en: 'Although we can determine the stationarity for most of these time series just
    by looking at the graph, doing the testing is still beneficial because we will
    likely reuse it in later parts of the forecast. Using the Statsmodel library we
    write:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管通过观察图表我们可以确定大多数时间序列的平稳性，但进行测试仍然是有益的，因为我们可能会在后续的预测阶段重用这些测试。使用Statsmodel库，我们编写如下代码：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'giving us the result:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的结果是：
- en: '![](../Images/974ea0b3207fbfe0a4af91f4957f2d55.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/974ea0b3207fbfe0a4af91f4957f2d55.png)'
- en: (ADF Test results)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: （ADF测试结果）
- en: The numbers we are interested from this test are the P-values. A P-value close
    to zero (equal to or less than 0.05) implies stationarity while a value closer
    to 1 implies nonstationarity. We can see that all of our time series features
    are highly nonstationary due to their statistically insignificant p-values, in
    other words, we are unable to reject the null hypothesis for the absence of a
    unit root. Below is a simple visual representation of the test for one of our
    features. The red dotted line represents the P-value where we would be able to
    determine stationarity for the time series feature, and the blue box represents
    the P-value where the feature is currently.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个测试中关注的数字是P值。接近零的P值（等于或小于0.05）表示平稳性，而接近1的P值则表示非平稳性。我们可以看到，所有的时间序列特征由于其统计上不显著的P值，都是高度非平稳的，换句话说，我们无法拒绝关于单位根不存在的零假设。下面是我们其中一个特征的测试简单可视化表示。红色虚线表示我们能够确定时间序列特征是否平稳的P值，而蓝色框表示该特征当前的P值。
- en: '![](../Images/4abee4a8fd2bf4e883c33c276457b596.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4abee4a8fd2bf4e883c33c276457b596.png)'
- en: (ADF visualization for NETEXP)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: （NETEXP的ADF可视化）
- en: '**VIF (Variance Inflation Factor) Test:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**VIF（方差膨胀因子）测试：**'
- en: The purpose of finding the Variance Inflation Factor of each feature is to check
    for multicollinearity, or the degree of correlation the predictors share with
    one another. High multicollinearity is not necessarily detrimental to our forecast,
    however, it can make it much harder for us to determine the individual effect
    of each feature time series for the prediction, thus hurting the interpretability
    of the model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 查找每个特征的方差膨胀因子（VIF）的目的是检查多重共线性，或者预测变量之间的相关程度。高多重共线性不一定对我们的预测有害，但它会使我们更难确定每个特征时间序列对预测的单独影响，从而影响模型的可解释性。
- en: 'Mathematically, the calculation is as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学上，计算如下：
- en: '![](../Images/83a0be71deb630d58bab2a36e5bf4094.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83a0be71deb630d58bab2a36e5bf4094.png)'
- en: (Variance Inflation Factor of predictor)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: （预测变量的方差膨胀因子）
- en: 'with *X*j representing our selected predictor and *R*²j is the coefficient
    of determination for our specific predictor. Applying this calculation to our
    data, we arrive at the following result:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*X*j表示我们选择的预测变量，*R*²j是我们特定预测变量的决定系数。将此计算应用于我们的数据，我们得出以下结果：
- en: '![](../Images/d78b31f4b9919259c798c16fc5f0fabb.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d78b31f4b9919259c798c16fc5f0fabb.png)'
- en: (VIF scores for each feature)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: （每个特征的VIF评分）
- en: Evidently, our predictors are very closely linked to one another. A VIF score
    greater than 5 implies multicollinearity, and the scores our features achieved
    far exceed this amount. Predictably, PCE by far had the highest score which makes
    sense given how its shape on the line plot resembled many of the other features.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们的预测变量之间有非常紧密的关联。VIF得分大于5意味着多重共线性，而我们特征所获得的得分远远超过了这个值。可以预见，PCE的得分最高，这也是可以理解的，因为其在线图上的形状与许多其他特征相似。
- en: 'Step 3: Modeling'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3步：建模
- en: Now that we have looked thoroughly through our data to better understand the
    relationships and characteristics of each feature, we will begin to make modifications
    to our dataset in order to prepare it for modeling.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经深入分析了数据，以更好地理解每个特征之间的关系和特征的性质，我们将开始对数据集进行修改，以便为建模做准备。
- en: '**Differencing to achieve stationarity**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过差分实现平稳性**'
- en: To begin modeling we need to first ensure our data is stationary. we can achieve
    this using a technique called differencing, which essentially transforms the raw
    data using a mathematical formula similar to the tests above.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始建模，我们首先需要确保数据是平稳的。我们可以使用一种叫做差分的方法来实现，这本质上是通过类似上述测试的数学公式来转换原始数据。
- en: 'The concept is defined mathematically as:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 该概念在数学上定义为：
- en: '![](../Images/aed0be843d2dfa1b1249170a84df02fb.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aed0be843d2dfa1b1249170a84df02fb.png)'
- en: (First Order Differencing equation)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: （一阶差分方程）
- en: This makes it so we are removing the nonlinear trends from the features, resulting
    in a constant series. In other words, we are taking values from our time series
    and calculating the change which occurred following the previous point.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得我们从特征中去除了非线性趋势，从而得到了一个常数序列。换句话说，我们从时间序列中提取出值，并计算与前一个点之间发生的变化。
- en: 'We can implement this concept in our dataset and check the results from the
    previously used ADF test with the following code:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个概念应用于我们的数据集，并使用以下代码检查之前使用的ADF测试结果：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'running this results in:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后结果为：
- en: '![](../Images/13297aef25c3f1abca6c69b392b360b8.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13297aef25c3f1abca6c69b392b360b8.png)'
- en: (ADF test for differenced data)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: （差分数据的ADF检验）
- en: 'We notice that our new p-values are less than 0.05, meaning that we can now
    reject the null hypothesis that our dataset is nonstationary. Taking a look at
    the graph of the new dataset proves this assertion:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到新的p值小于0.05，这意味着我们现在可以拒绝原假设，即我们的数据集是非平稳的。查看新数据集的图表证实了这一断言：
- en: '![](../Images/4cd4f014b03f09bde08b6f998f15fe92.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4cd4f014b03f09bde08b6f998f15fe92.png)'
- en: (Graph of Differenced Data)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: （差分数据的图表）
- en: We see how all of our time series are now centered around 0 with the mean and
    variance remaining constant. In other words, our data now visibly demonstrates
    characteristics of a stationary system.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到所有的时间序列现在都集中在0附近，均值和方差保持不变。换句话说，我们的数据现在明显展示了平稳系统的特征。
- en: '**VAR (Vector Auto Regression) Model**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**VAR（向量自回归）模型**'
- en: The first step of the VAR model is performing the **Granger Causality Test**
    which will tell us which of our features are statistically significant to our
    prediction. The test indicates to us if a lagged version of a specific time series
    can help us predict our target time series, however not necessarily that one time
    series causes the other (note that causation in the context of statistics is a
    far more difficult concept to prove).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: VAR模型的第一步是执行**Granger因果关系检验**，它将告诉我们哪些特征对我们的预测具有统计学意义。该测试告诉我们，特定时间序列的滞后版本是否可以帮助我们预测目标时间序列，但并不一定意味着一个时间序列导致了另一个时间序列（请注意，统计学中的因果关系是一个更难证明的概念）。
- en: 'Using the StatsModels library, we can apply the test as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用StatsModels库，我们可以按如下方式应用测试：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Running the code results in the following table:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后会生成以下表格：
- en: '![](../Images/d926ffb0542cc4ebe11520d5e637eddd.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d926ffb0542cc4ebe11520d5e637eddd.png)'
- en: (Sample of Granger Causality for two features)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: （Granger因果关系检验的示例，涉及两个特征）
- en: Here we are just looking for a single lag for each feature that has statistically
    significant p-values(>.05). So for example, since on the first lag both NETEXP
    and GovTotExp, we will consider both these features for our VAR model. Personal
    consumption expenditures arguably did not make this cut-off (see notebook), however,
    the sixth lag is so close that I decided to keep it in. Our next step is to create
    our VAR model now that we have decided that all of our features are significant
    from the Granger Causality Test.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只关心每个特征的单个滞后，其p值具有统计学意义（>0.05）。例如，由于在第一个滞后时，NETEXP和GovTotExp都具有统计学意义，因此我们会将这两个特征考虑进VAR模型。个人消费支出可能没有达到这一标准（见笔记本），但是第六个滞后非常接近，因此我决定保留它。下一步是创建我们的VAR模型，因为我们已经决定所有特征在Granger因果关系检验中都是显著的。
- en: 'VAR (Vector Auto Regression) is a model which can leverage different time series
    to gauge patterns and determine a flexible forecast. Mathematically, the model
    is defined by:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: VAR（向量自回归）模型可以利用不同的时间序列来衡量模式，并确定一个灵活的预测。数学上，该模型由以下公式定义：
- en: '![](../Images/f11eaeef138234215f2348bda28faf5a.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f11eaeef138234215f2348bda28faf5a.png)'
- en: (Vector Auto Regression Model)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: （向量自回归模型）
- en: 'Where *Y*t is some time series at a particular time t and *A*p is a determined
    coefficient matrix. We are essentially using the lagged values of a time series
    (and in our case other time series) to make a prediction for *Y*t. Knowing this,
    we can now apply this algorithm to the data_diff dataset and evaluate the results:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *Y*t 是某一时刻 t 的时间序列，*A*p 是已确定的系数矩阵。我们实际上是在利用时间序列的滞后值（在我们的案例中是其他时间序列）来预测 *Y*t。了解这一点后，我们现在可以将该算法应用于data_diff数据集，并评估结果：
- en: '![](../Images/2712377799137a622265b5ed812aaf0a.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2712377799137a622265b5ed812aaf0a.png)'
- en: (Evaluation Metrics)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: （评估指标）
- en: '![](../Images/b483d05226c2be735c416b43cb10f10c.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b483d05226c2be735c416b43cb10f10c.png)'
- en: (Actual vs Forecasted GDP for VAR)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: （VAR模型的实际与预测GDP对比）
- en: Looking at this forecast, we can clearly see that despite missing the mark quite
    heavily on both evaluation metrics used (MAE and MAPE), our model visually was
    not too inaccurate barring the outliers caused by the pandemic. We managed to
    stay on the testing line for the most part from 2018–2019 and from 2022–2024,
    however, the global events following obviously threw in some unpredictability
    which affected the model’s ability to precisely judge the trends.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看这个预测，我们可以清楚地看到，尽管在使用的两个评估指标（MAE和MAPE）上严重偏离，但我们的模型在视觉上并不太不准确，除了因疫情引起的异常值外。从2018到2019年，以及从2022到2024年，我们基本上维持在测试线附近，然而随后的全球事件显然带来了一些不可预测性，影响了模型准确判断趋势的能力。
- en: '**VECM (Vector Error Correction Model)**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**VECM（向量误差修正模型）**'
- en: 'VECM (Vector Error Correction Model) is similar to VAR, albeit with a few key
    differences. Unlike VAR, VECM does not rely on stationarity so differencing and
    normalizing the time series will not be necessary. VECM also assumes **cointegration**,
    or long-term equilibrium between the time series. Mathematically, we define the
    model as:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: VECM（向量误差修正模型）与VAR相似，尽管有一些关键的不同之处。与VAR不同，VECM不依赖于平稳性，因此差分和归一化时间序列不再是必须的。VECM还假设存在**协整**，即时间序列之间的长期均衡。在数学上，我们将模型定义为：
- en: '![](../Images/5619e8ab39353fb30a31818414ce003f.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5619e8ab39353fb30a31818414ce003f.png)'
- en: (VECM model equation)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: （VECM模型方程）
- en: 'This equation is similar to the VAR equation, with Π being a coefficient matrix
    which is the product of two other matrices, along with taking the sum of lagged
    versions of our time series *Y*t. Remembering to fit the model on our original
    (not difference) dataset, we achieve the following result:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程类似于VAR方程，其中Π是一个系数矩阵，是另外两个矩阵的乘积，并且计算我们时间序列*Y*t的滞后版本的和。记住要在我们的原始（非差分）数据集上拟合模型，得到以下结果：
- en: '![](../Images/b80ed2ebd8453a3fe0fd50f270e4e3f2.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b80ed2ebd8453a3fe0fd50f270e4e3f2.png)'
- en: (Actual vs Forecasted GDP for VECM)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: （VECM的实际GDP与预测GDP）
- en: Though it is hard to compare to our VAR model to this one given that we are
    now using nonstationary data, we can still deduce both by the error metric and
    the visualization that this model was not able to accurately capture the trends
    in this forecast. With this, it is fair to say that we can rule out traditional
    statistical methods for approaching this problem.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管由于我们现在使用的是非平稳数据，与VAR模型相比很难进行直接比较，但我们仍然可以通过误差度量和可视化结果推断出该模型未能准确捕捉到此预测中的趋势。因此，可以公平地说，我们可以排除传统统计方法来解决这个问题。
- en: '**Machine Learning forecasting**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习预测**'
- en: When deciding on a machine learning approach to model this problem, we want
    to keep in mind the amount of data that we are working with. Prior to creating
    lagged columns, our dataset has a total of 1275 observations across all time-series.
    This means that using more complex approaches, such as LSTMs or gradient boosting,
    are perhaps unnecessary as we can use a more simple model to receive the same
    amount of accuracy and far more interpretability.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定使用哪种机器学习方法来建模这个问题时，我们需要牢记我们所处理的数据量。在创建滞后列之前，我们的数据集总共有1275个观测值跨越所有时间序列。这意味着使用更复杂的方法，如LSTM或梯度提升，可能是多余的，因为我们可以使用一个更简单的模型来获得相同的准确度，同时具有更高的可解释性。
- en: '**Train-Test Split**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练-测试集划分**'
- en: 'Train-test splits for time series problems differ slightly from splits in traditional
    regression or classification tasks (Note we also used the train-test split in
    our VAR and VECM models, however, it feels more appropriate to address in the
    Machine Learning section). We can perform our Train-Test split on our differenced
    data with the following code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列问题的训练-测试集划分与传统回归或分类任务中的划分略有不同（请注意，我们在VAR和VECM模型中也使用了训练-测试集划分，但在机器学习部分讨论更为合适）。我们可以在差分数据上执行训练-测试集划分，使用以下代码：
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here it is imperative that we do not shuffle around our data, since that would
    mean we are training our model on data from the future which in turn will cause
    data leakages.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们必须确保不打乱我们的数据，因为这意味着我们在使用未来的数据进行训练，从而可能会导致数据泄漏。
- en: '![](../Images/de5a1ce10a9912a4601563441503a514.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de5a1ce10a9912a4601563441503a514.png)'
- en: example of train-test split on time series data
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据上训练-测试集划分的示例
- en: Also in comparison, notice that we are training over a very large portion (90
    percent) of the data whereas typically we would train over 75 percent in a common
    regression task. This is because practically, we are not actually concerned with
    forecasting over a large time frame. Realistically even forecasting over several
    years is not probable for this task given the general unpredictability that comes
    with real-world time series data.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 同时进行比较时，请注意我们正在训练数据的很大一部分（90%），而在常见的回归任务中通常训练75%的数据。这是因为从实际操作角度看，我们并不关心预测一个很长的时间范围。实际上，即使是预测几年的数据，对于这个任务来说也是不太可能的，因为现实世界的时间序列数据具有很强的不确定性。
- en: '**Random Forests**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机森林**'
- en: Remembering our VIF test from earlier, we know our features are highly correlated
    with one another. This partially plays into the decision to choose random forests
    as one of our machine-learning models. decision trees make binary choices between
    features, meaning that theoretically our features being highly correlated should
    not be detrimental to our model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们之前做的VIF测试，知道我们的特征之间高度相关。这在一定程度上促使我们选择随机森林作为机器学习模型之一。决策树在特征之间做出二元选择，这意味着理论上特征之间的高度相关性对模型不会造成不利影响。
- en: '![](../Images/eca013bc75fccede71560849246b59d1.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eca013bc75fccede71560849246b59d1.png)'
- en: Example of a traditional binary decision tree that builds random forests models
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 传统二叉决策树的示例，用于构建随机森林模型
- en: To add on, random forest is generally a very strong model being robust to overfitting
    from the stochastic nature of how the trees are computed. Each tree uses a random
    subset of the total feature space, meaning that certain features are unlikely
    to dominate the model. Following the construction of the individual trees, the
    results are averaged in order to make a final prediction using every individual
    learner.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，随机森林通常是一个非常强大的模型，因为它能够抵抗由于树的计算方式中的随机性所带来的过拟合。每棵树使用的是整个特征空间的一个随机子集，这意味着某些特征不太可能主导模型。构建完单个树之后，结果会被平均化，从而使用每个个体学习器做出最终预测。
- en: 'We can implement the model to our dataset with the following code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码将模型应用到我们的数据集：
- en: '[PRE6]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'running this gives us the results:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码会得到以下结果：
- en: '![](../Images/3ca1b24217fb26ad0ef1b59f43daaf68.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ca1b24217fb26ad0ef1b59f43daaf68.png)'
- en: (Evaluation Metrics for Random Forests)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: （随机森林的评估指标）
- en: '![](../Images/c0688d7c0e77bc7292b383b26984a3e3.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0688d7c0e77bc7292b383b26984a3e3.png)'
- en: (Actual vs Forecasted GDP for Random Forests)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: （随机森林的实际与预测GDP对比）
- en: We can see that Random Forests was able to produce our best forecast yet, attaining
    better error metrics than our attempts at VAR and VECM. Perhaps most impressively,
    visually we can see that our model was almost perfectly encapsulating the data
    from 2017–2019, just prior to encountering the outliers.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，随机森林能够提供我们迄今为止最佳的预测，获得了比VAR和VECM模型更好的误差指标。或许最令人印象深刻的是，从视觉上看，我们可以看到模型几乎完美地呈现了2017–2019年的数据，恰好是在遭遇异常值之前。
- en: '**K Nearest Neighbors**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**K最近邻**'
- en: KNN (K-Nearest-Neighbors) was one final approach we will attempt. Part of the
    reasoning for why we choose this specific model is due to the feature-to-observation
    ratio. KNN is a distanced based algorithm that we are dealing with data which
    has a low amount of feature space comparative to the number of observations.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: KNN（K-最近邻）是我们尝试的最后一个方法。选择这个模型的部分原因是因为特征与观测的比例。KNN是一种基于距离的算法，我们处理的数据特征空间相对较小，而观测数量较多。
- en: 'To use the model, we must first select a hyperparameter *k* which defines the
    number of neighbors our data gets mapped to. A higher *k* value insinuates a more
    biased model while a lower *k* value insinuates a more overfit model. We can choose
    the optimal one with the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用该模型，我们首先需要选择一个超参数*k*，它定义了数据映射到的邻居数。较高的*k*值意味着模型更偏向某些特征，而较低的*k*值则意味着模型可能会出现过拟合。我们可以使用以下代码选择最优的*k*值：
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Running this code gives us:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码会得到：
- en: '![](../Images/99f8d61e42cf3e26d8b022ba6d1a7d7d.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99f8d61e42cf3e26d8b022ba6d1a7d7d.png)'
- en: (accuracy comparing different values of k)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: （比较不同k值的准确度）
- en: 'We can see that our best accuracy measurements are achieved when *k*=2, following
    that value the model becomes too biased with increasing values of *k*. knowing
    this, we can now apply the model to our dataset:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，当*k*=2时，我们获得了最佳的准确度度量值。超过这个值后，模型会随着*k*值的增加而变得越来越偏向某些特征。了解这一点后，我们可以将模型应用到我们的数据集中：
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'resulting in:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是：
- en: '![](../Images/79f5cb7098825c4ddd54c80da4a7f5e2.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79f5cb7098825c4ddd54c80da4a7f5e2.png)'
- en: (Evaluation metrics for KNN)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: （KNN的评估指标）
- en: '![](../Images/76927c9c5d7fd1281174d717c802f2ac.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76927c9c5d7fd1281174d717c802f2ac.png)'
- en: (Actual vs Forecasted GDP for KNN)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: （KNN的实际与预测GDP对比）
- en: We can see KNN in its own right performed very well. Despite being outperformed
    slightly in terms of error metrics compared to Random Forests, visually the model
    performed about the same and arguably captured the period before the pandemic
    from 2018–2019 even better than Random Forests.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，KNN本身表现得非常好。尽管在误差度量上稍微被随机森林超越，但从视觉效果来看，模型的表现几乎相同，甚至可以说在2018–2019年疫情爆发前的那一段时间，KNN的表现要比随机森林更好。
- en: '**Conclusions**'
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Looking at all of our models, we can see the one which performed the best was
    Random Forests. This is most likely due to Random Forests for the most part being
    a very strong predictive model that can be fit to a variety of datasets. In general,
    the machine learning algorithms far outperformed the traditional statistical methods.
    Perhaps this can be explained by the fact that VAR and VECM both require a great
    amount of historical background data to work optimally, something which we did
    not have much of given that our data came out in quarterly intervals. There also
    may be something to be said about how both the machine learning models used were
    nonparametric. These models often are governed by fewer assumptions than their
    counterparts and therefore may be more flexible to unique problem sets like the
    one here. Below is our final best prediction, removing the differencing transformation
    we previously used to fit the models.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看我们所有的模型，我们可以看到表现最好的模型是随机森林。这很可能是因为随机森林大多数情况下是一个非常强大的预测模型，能够适应多种数据集。总体来说，机器学习算法远远超过了传统的统计方法。或许可以解释的是，VAR和VECM都需要大量的历史背景数据才能最优运行，而我们由于数据是按季度间隔获取的，历史数据并不充足。此外，也可以说，这两种机器学习模型都是非参数模型。这些模型通常假设较少，因此可能对像这里这样的独特问题集更具灵活性。下面是我们最终的最佳预测，去除了之前为拟合模型而使用的差分变换。
- en: '![](../Images/f43369d43765369d17baa7ef30ebb2c5.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f43369d43765369d17baa7ef30ebb2c5.png)'
- en: (Actual vs Forecasted GDP for Random Forests (not differenced))
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: (随机森林的实际GDP与预测GDP（未差分）)
- en: Challenges and Areas of Improvement
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 挑战与改进方向
- en: By far the greatest challenge regarding this forecasting problem was handling
    the massive outlier caused by the pandemic along with the following instability
    caused by it. Our methods for forecasting obviously can not predict that this
    would occur, ultimately decreasing our accuracy for each approach. Had our goal
    been to forecast the previous decade, our models would most likely have a much
    easier time finding and predicting trends. In terms of improvement and further
    research, I think a possible solution would be to perform some sort of normalization
    and outlier smoothing technique on the time interval from 2020–2024, and then
    evaluate our fully trained model on new quarterly data that comes in. In addition,
    it may be beneficial to incorporate new features that have a heavy influence on
    GDP such as quarterly inflation and personal asset evaluations.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 就这个预测问题而言，最大的挑战无疑是处理疫情引起的大量离群值，以及疫情之后的持续不稳定。显然，我们的预测方法无法预测这种情况的发生，最终导致每种方法的准确性下降。如果我们的目标是预测过去十年的数据，我们的模型可能会更容易发现和预测趋势。在改进和进一步研究方面，我认为一个可能的解决方案是对2020-2024年的时间区间进行某种归一化和离群值平滑技术处理，然后在新季度数据到来时评估我们的完全训练好的模型。此外，纳入对GDP有重大影响的新特征，例如季度通货膨胀率和个人资产评估，可能会是有益的。
- en: References
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: For traditional statistical methods- [https://link.springer.com/book/10.1007/978-1-4842-7150-6](https://link.springer.com/book/10.1007/978-1-4842-7150-6)
    , [https://www.statsmodels.org/stable/generated/statsmodels.tsa.vector_ar.vecm.VECM.html](https://www.statsmodels.org/stable/generated/statsmodels.tsa.vector_ar.vecm.VECM.html)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于传统统计方法 — [https://link.springer.com/book/10.1007/978-1-4842-7150-6](https://link.springer.com/book/10.1007/978-1-4842-7150-6)
    , [https://www.statsmodels.org/stable/generated/statsmodels.tsa.vector_ar.vecm.VECM.html](https://www.statsmodels.org/stable/generated/statsmodels.tsa.vector_ar.vecm.VECM.html)
- en: For machine learning methods — [https://www.statlearning.com/](https://www.statlearning.com/)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习方法 — [https://www.statlearning.com/](https://www.statlearning.com/)
- en: For dataset — [https://fred.stlouisfed.org/docs/api/fred/](https://fred.stlouisfed.org/docs/api/fred/)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据集 — [https://fred.stlouisfed.org/docs/api/fred/](https://fred.stlouisfed.org/docs/api/fred/)
- en: FRED provides licensed, free-to-access datasets for any user who owns an API
    key, read more here — [https://fredhelp.stlouisfed.org/fred/about/about-fred/what-is-fred/](https://fredhelp.stlouisfed.org/fred/about/about-fred/what-is-fred/)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: FRED为任何拥有API密钥的用户提供许可的、免费的数据集，详细信息请参阅此处 — [https://fredhelp.stlouisfed.org/fred/about/about-fred/what-is-fred/](https://fredhelp.stlouisfed.org/fred/about/about-fred/what-is-fred/)
- en: All pictures not specifically given credit in the caption belong to me.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 所有未在图片说明中特别注明的图片归我所有。
- en: Notebook
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 笔记本
- en: please note that in order to run this notebook you must create an account on
    the FRED website, request an API key, and paste said key into the second cell
    of the notebook.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为了运行此笔记本，您必须在FRED网站上创建一个帐户，申请一个API密钥，并将该密钥粘贴到笔记本的第二个单元格中。
- en: '[https://github.com/Dronmong/GDP-Forecast](https://github.com/Dronmong/GDP-Forecast)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/Dronmong/GDP-Forecast](https://github.com/Dronmong/GDP-Forecast)'
