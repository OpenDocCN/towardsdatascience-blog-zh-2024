<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Unraveling Unstructured Movie Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Unraveling Unstructured Movie Data</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unraveling-unstructured-movie-data-04d5ff787600?source=collection_archive---------8-----------------------#2024-02-09">https://towardsdatascience.com/unraveling-unstructured-movie-data-04d5ff787600?source=collection_archive---------8-----------------------#2024-02-09</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="fr fs ft fu fv fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/9bcaa0e799d0ad12c1c54169c510968f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qI-i8FI9RACiyokb3K59-A.png"/></div></div></figure><div/><div><h2 id="aef0" class="pw-subtitle-paragraph hc ge gf bf b hd he hf hg hh hi hj hk hl hm hn ho hp hq hr cq dx">How to Use LLMs and Controlled Vocabularies for Enhanced Similarity Models</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hs ht hu hv hw ab"><div><div class="ab hx"><div><div class="bm" aria-hidden="false"><a href="https://stevehedden.medium.com/?source=post_page---byline--04d5ff787600--------------------------------" rel="noopener follow"><div class="l hy hz by ia ib"><div class="l ed"><img alt="Steve Hedden" class="l ep by dd de cx" src="../Images/af7bec4a191ab857eccd885dd89e88b4.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*O80NSnmxNIhFhPEm9Kd0cA.png"/><div class="ic by l dd de em n id eo"/></div></div></a></div></div><div class="ie ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--04d5ff787600--------------------------------" rel="noopener follow"><div class="l if ig by ia ih"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ii cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ic by l br ii em n id eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ij ab q"><div class="ab q ik"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b il im bk"><a class="af ag ah ai aj ak al am an ao ap aq ar in" data-testid="authorName" href="https://stevehedden.medium.com/?source=post_page---byline--04d5ff787600--------------------------------" rel="noopener follow">Steve Hedden</a></p></div></div></div><span class="io ip" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b il im dx"><button class="iq ir ah ai aj ak al am an ao ap aq ar is it iu" disabled="">Follow</button></p></div></div></span></div></div><div class="l iv"><span class="bf b bg z dx"><div class="ab cn iw ix iy"><div class="iz ja ab"><div class="bf b bg z dx ab jb"><span class="jc l iv">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar in ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--04d5ff787600--------------------------------" rel="noopener follow"><p class="bf b bg z jd je jf jg jh ji jj jk bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="io ip" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">16 min read</span><div class="jl jm l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 9, 2024</span></div></span></div></span></div></div></div><div class="ab cp jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="h k w ea eb q"><div class="ks l"><div class="ab q kt ku"><div class="pw-multi-vote-icon ed jc kv kw kx"><div class=""><div class="ky kz la lb lc ld le am lf lg lh kx"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l li lj lk ll lm ln lo"><p class="bf b dy z dx"><span class="kz">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ky lr ls ab q ee lt lu" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lq"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lp lq">1</span></p></button></div></div></div><div class="ab q kd ke kf kg kh ki kj kk kl km kn ko kp kq kr"><div class="lv k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lw an ao ap is lx ly lz" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ma cn"><div class="l ae"><div class="ab cb"><div class="mb mc md me mf gb ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lw an ao ap is mg mh lu mi mj mk ml mm s mn mo mp mq mr ms mt u mu mv mw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lw an ao ap is mg mh lu mi mj mk ml mm s mn mo mp mq mr ms mt u mu mv mw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lw an ao ap is mg mh lu mi mj mk ml mm s mn mo mp mq mr ms mt u mu mv mw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="42ee" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><em class="nt">The accompanying code for this tutorial is </em><a class="af nu" href="https://github.com/SteveHedden/kg_llm" rel="noopener ugc nofollow" target="_blank"><em class="nt">here.</em></a></p><p id="1272" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><a class="af nu" href="https://en.wikipedia.org/wiki/Recommender_system" rel="noopener ugc nofollow" target="_blank">Recommender systems</a> are how we find much of the content and products we consume, probably including this article. A recommender system is:</p><blockquote class="nv nw nx"><p id="a7c8" class="mx my nt mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">“a subclass of information filtering system that provides suggestions for items that are most pertinent to a particular user.” — Wikipedia</p></blockquote><p id="ebba" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Some examples of recommender systems we interact with regularly are on Netflix, Spotify, Amazon, and social media. All of these recommender systems are attempting to answer the same question: given a user’s past behavior, what other products or content are they most likely to like? These systems generate a lot of money — <a class="af nu" href="https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers" rel="noopener ugc nofollow" target="_blank">a 2013 study from McKinsey</a> found that, “35 percent of what consumers purchase on Amazon and 75 percent of what they watch on Netflix come from product recommendations.” Netflix famously started an open competition in 2006 offering a <a class="af nu" href="https://en.wikipedia.org/wiki/Netflix_Prize" rel="noopener ugc nofollow" target="_blank">one million dollar prize</a> to anyone who could significantly improve their recommendation system. For more information on recommender systems see <a class="af nu" rel="noopener" target="_blank" href="/the-remarkable-world-of-recommender-systems-bff4b9cbe6a7">this</a> article.</p><p id="6496" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Generally, there are three kinds of recommender systems: content based, collaborative, and a hybrid of content based and collaborative. Collaborative recommender systems focus on users’ behavior and preferences to predict what they will like based on what other similar users like. Content based filtering systems focus on similarity between the products themselves rather than the users. For more info on these systems see <a class="af nu" href="https://www.nvidia.com/en-us/glossary/recommendation-system/#:~:text=A%20recommendation%20system%20is%20an,demographic%20information%2C%20and%20other%20factors" rel="noopener ugc nofollow" target="_blank">this Nvidia piece.</a></p><p id="9d03" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Calculating similarity between products that are well-defined in a structured dataset is relatively straightforward. We could identify which properties of the products we think are most important, and measure the ‘distance’ between any two products given the difference between those properties. But what if we want to compare items when the only data we have is unstructured text? For example, given a dataset of movie and TV show descriptions, how can we calculate which are most similar?</p><p id="b49e" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">In this tutorial, I will:</p><ol class=""><li id="17d8" class="mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns ny nz oa bk">Show a basic similarity model (no controlled vocabulary) of unstructured text using natural language processing (NLP) techniques</li><li id="8da7" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns ny nz oa bk">Create a genre list using an LLM</li><li id="765c" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns ny nz oa bk">Use the genre list to tag films with genres</li><li id="d5f7" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns ny nz oa bk">Use the genre tags to build a similarity model</li><li id="60e0" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns ny nz oa bk">Use the genre tags to create a network visualization</li></ol><p id="30ec" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The goal, for me, in writing this, was to learn two things: whether a taxonomy (controlled vocabulary) significantly improved the outcomes of a similarity model of unstructured data, and whether an LLM can significantly improve the quality and/or time required to construct that controlled vocabulary.</p><p id="d5b9" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">If you don’t feel like reading the whole thing, here are my main findings:</p><ul class=""><li id="06b7" class="mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns og nz oa bk">The basic NLP model (without a controlled vocabulary) certainly has some problems — it sometimes uses words for identifying similar movies that are not relevant (like the protagonists’ first name or the location).</li><li id="0c70" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns og nz oa bk">Using a controlled vocabulary does significantly improve the outcomes of the similarity model, at least based on some of the examples I have been using to test the models.</li><li id="f002" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns og nz oa bk">Building a simple, basic genre list using an LLM is easy — building a useful and/or detailed genre taxonomy is hard i.e. it would take more iterations or more descriptive prompts. I ended up building a quick and dirty list of about 200 genres without definitions, which worked good enough for doing simple similarity calculations.</li><li id="aa00" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns og nz oa bk">Even this very basic genre list built using an LLM has issues, however. There are duplicate genres with minor spelling differences, for example.</li><li id="f99a" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns og nz oa bk">Using an LLM to tag the movies and TV shows took a very long time. This might just be a problem in the way I have structured my code though.</li><li id="0278" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns og nz oa bk">Perhaps not surprisingly, the depth and breadth of the taxonomy matters. Like I said above, building a detailed and descriptive taxonomy of movie genres is difficult and would require a lot more work than I am willing to do for this tutorial. But depending on the use case, that level of detail might not be necessary. I started by building a taxonomy of thousands of genres with synonyms and definitions but that had drawbacks — the tagging became harder and the similarity calculations were often not as good. Because I was only looking at a couple thousand movies, having a genre list of thousands of genres just made every movie unique and similar to almost nothing.</li><li id="8482" class="mx my gf mz b hd ob nb nc hg oc ne nf ng od ni nj nk oe nm nn no of nq nr ns og nz oa bk">Visualizing movies and genres as graphs is awesome, as always.</li></ul><h1 id="5373" class="oh oi gf bf oj ok ol hf om on oo hi op oq or os ot ou ov ow ox oy oz pa pb pc bk">Basic Similarity Model of Unstructured Text Using NLP Techniques</h1><p id="585f" class="pw-post-body-paragraph mx my gf mz b hd pd nb nc hg pe ne nf ng pf ni nj nk pg nm nn no ph nq nr ns fj bk">We could use natural language processing (NLP) to extract key words from the text, identify how important these words are, and then find matching words in other descriptions. <a class="af nu" href="https://medium.com/mlearning-ai/basic-content-based-recommendation-system-with-python-code-be920b412067" rel="noopener">Here</a> is a tutorial on how to do that in Python. I won’t recreate that entire tutorial here but here is a brief synopsis:</p><p id="9f12" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">First, we extract key words from a plot description. For example, here is the description for the movie, ‘Indiana Jones and the Raiders of the Lost Ark.’</p><blockquote class="nv nw nx"><p id="2a3d" class="mx my nt mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">“When Indiana Jones is hired by the government to locate the legendary Ark of the Covenant, he finds himself up against the entire Nazi regime.”</p></blockquote><p id="48aa" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">We then use out-of-the-box libraries from sklearn to extract key words and rank their ‘importance’. To calculate importance, we use term-frequency-inverse document frequency (tf-idf). The idea is to balance the frequency of the term in the individual film’s description with how common the word is across all film descriptions in our dataset. The word ‘finds,’ for example, appears in this description, but it is a common word and appears in many other movie descriptions, so it is less important than ‘covenant’.</p><figure class="pj pk pl pm pn fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pi"><img src="../Images/26363683659234d8de294e2a80095aaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JzdvD4LQb51arhgFgy3jlA.png"/></div></div><figcaption class="po pp pq fo fp pr ps bf b bg z dx">Image by author</figcaption></figure><p id="54d8" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This model actually works very well for films that have a uniquely identifiable protagonist. If we run the similarity model on this film, the most similar movies are: ‘Indiana Jones and the Temple of Doom’, ‘Indiana Jones and the Last Crusade’, and ‘Indiana Jones and the Kingdom of the Crystal Skull’. This is because the descriptions for each of these movies contains the words, ‘Indiana’ and ‘Jones’.</p><p id="9b86" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">But there are problems here. How do we know the words that are extracted and used in the similarity model are relevant? For example, if I run this model to find movies or TV shows similar to ‘Beavis and Butt-head Do America,” the top result is “Army of the Dead.” If you’re not a sophisticated film and TV buff like me, you may not be familiar with the animated series ‘<a class="af nu" href="https://en.wikipedia.org/wiki/Beavis_and_Butt-Head" rel="noopener ugc nofollow" target="_blank">Beavis and Butt-Head</a>,’ featuring ‘unintelligent teenage boys [who] spend time watching television, drinking unhealthy beverages, eating, and embarking on mundane, sordid adventures, which often involve vandalism, abuse, violence, or animal cruelty.’ The description of their movie, ‘Beavis and Butt-head Do America,’ reads, ‘After realizing that their boob tube is gone, Beavis and Butt-head set off on an expedition that takes them from Las Vegas to the nation’s capital.’ ‘Army of the Dead,’ on the other hand, is a Zack Snyder-directed ‘<a class="af nu" href="https://en.wikipedia.org/wiki/Army_of_the_Dead" rel="noopener ugc nofollow" target="_blank">post-apocalyptic zombie heist film</a>’. Why is Army of the Dead considered similar then? Because it takes place in Las Vegas — both movie descriptions contain the words ‘Las Vegas’.</p><p id="1f5d" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Another example of where this model fails is that if I want to find movies or TV shows similar to ‘Eat Pray Love,’ the top result is, ‘Extremely Wicked, Shockingly Evil and Vile.’ ‘Eat Pray Love’ is a romantic comedy starring Julia Roberts as Liz Gilbert, a recently divorced woman traveling the world in a journey of self-discovery. ‘Extremely Wicked, Shockingly Evil and Vile,’ is a true crime drama about serial killer Ted Bundy. What do these films have in common? Ted Bundy’s love interest is also named Liz.</p><figure class="pj pk pl pm pn fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pt"><img src="../Images/7bed12ca5db9daac58186a0cc548d848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JzbrDcvOlR0j-vb4vLT8Hw.png"/></div></div><figcaption class="po pp pq fo fp pr ps bf b bg z dx">Image by author</figcaption></figure><p id="df7a" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">These are, of course, cherry-picked examples of cases where this model doesn’t work. There are plenty of cases where extracting key words from text can be a useful way of finding similar products. As shown above, text that contains uniquely identifiable names like Power Rangers, Indiana Jones, or James Bond can be used to find other titles with those same names in their descriptions. Likewise, if the description contains information about the genre of the title, like ‘thriller’ or ‘mystery’, then those words can link the film to other films of the same genre. This has limitations too, however. Some films may use the word ‘dramatic’ in their description, but using this methodology, we would not match these films with film descriptions containing the word ‘drama’ — we are not accounting for synonyms. What we really want is to only use relevant words and their synonyms.</p><p id="86bf" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">How can we ensure that the words extracted are relevant? This is where a taxonomy can help. What is a taxonomy?</p><h1 id="cee6" class="oh oi gf bf oj ok ol hf om on oo hi op oq or os ot ou ov ow ox oy oz pa pb pc bk">Create a genre taxonomy using an LLM</h1><blockquote class="nv nw nx"><p id="6ccb" class="mx my nt mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">“A taxonomy (or taxonomic classification) is a scheme of classification, especially a hierarchical classification, in which things are organized into groups or types.” — <a class="af nu" href="https://en.wikipedia.org/wiki/Taxonomy" rel="noopener ugc nofollow" target="_blank">Wikipedia</a></p></blockquote><p id="bda1" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Perhaps the most famous example of a taxonomy is the one used in biology to categorize all living organisms — remember domain, kingdom, phylum class, order, family, genus, and species? All living creatures can be categorized into this hierarchical taxonomy.</p><p id="b0a1" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk"><strong class="mz gg"><em class="nt">A note on terminology: </em></strong><em class="nt">ontologies are similar to taxonomies but different. As </em><a class="af nu" href="https://www.forbes.com/sites/cognitiveworld/2019/03/24/taxonomies-vs-ontologies/?sh=35eb9c327d53" rel="noopener ugc nofollow" target="_blank"><em class="nt">this</em></a><em class="nt"> article explains, taxonomies classify while ontologies specify. “An ontology is the system of classes and relationships that describe the structure of data, the rules, if you will, that prescribe how a new category or entity is created, how attributes are defined, and how constraints are established.” Since we are focused on classifying movies, we are going to build a taxonomy. However, for the purposes of this tutorial, I just need a very basic list of genres, which can’t even really be described as a taxonomy. A list of genres is just a tag set, or a controlled vocabulary.</em></p><p id="2aac" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">For this tutorial, we will focus only on genre. What we need is a list of genres that we can use to ‘tag’ each movie. Imagine that instead of having the movie, ‘Eat Pray Love’ tagged with the words ‘Liz’ and ‘true’, it were tagged with ‘romantic comedy’, ‘drama’, and ‘travel/adventure’. We could then use these genres to find other movies similar to Eat Pray Love, even if the protagonist is not named Liz. Below is a diagram of what we are doing. We use a subset of the unstructured movie data, along with GPT 3.5, to create a list of genres. Then we use the genre list and GPT 3.5 to tag the unstructured movie data. Once our data is tagged, we can run a similarity model using the tags as inputs.</p><figure class="pj pk pl pm pn fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp pu"><img src="../Images/a57c3870bee7f19b01f99cd7029a0148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nqAscTAJ5H_ZVsBlXdISLQ.png"/></div></div><figcaption class="po pp pq fo fp pr ps bf b bg z dx">Image by author</figcaption></figure><p id="57a9" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">I couldn’t find any free movie genre taxonomies online, so I built my own using a large language model (LLM). I started with <a class="af nu" href="https://medium.com/@elias_69893/an-llm-agent-that-builds-and-maintains-a-job-title-taxonomy-77d02c4c6100" rel="noopener">this</a> tutorial, which used an LLM agent to build a taxonomy of job titles. That LLM agent looks for job titles from job descriptions, creates definitions and responsibilities for each of these job titles, and synonyms. I used that tutorial to create a movie genre taxonomy, but it was overkill — we don’t really need to do all of that for the purposes of this tutorial. We just need a very basic list of genres that we can use to tag movies. Here is the code I used to create that genre list.</p><p id="de76" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">I used Netflix movie and TV show description data available <a class="af nu" href="https://www.kaggle.com/datasets/shivamb/netflix-shows?resource=download" rel="noopener ugc nofollow" target="_blank">here</a> (License <a class="af nu" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank">CC0: Public Domain</a>).</p><p id="35f7" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Import required packages and load english language NLP model.</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="60c6" class="pz oi gf pw b bg qa qb l qc qd">import openai<br/>import os<br/>import re<br/>import pandas as pd<br/>import spacy<br/>from ipywidgets import FloatProgress<br/>from tqdm import tqdm<br/><br/># Load English tokenizer, tagger, parser and NER<br/>nlp = spacy.load("en_core_web_sm")</span></pre><p id="e254" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Then we need to set up our connection with OpenAI (or whatever LLM you want to use).</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="0b5e" class="pz oi gf pw b bg qa qb l qc qd">os.environ["OPENAI_API_KEY"] = "XXXXXX"  # replace with yours</span></pre><p id="ee8f" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Read in the Netflix movie data:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="0ffe" class="pz oi gf pw b bg qa qb l qc qd">movies = pd.read_csv("netflix_titles.csv")<br/>movies = movies.sample(n=1000) #I just used 1000 rows of data to reduce the runtime</span></pre><p id="2a10" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Create a function to predict the genre of a title given its description:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="238a" class="pz oi gf pw b bg qa qb l qc qd">def predict_genres(movie_description):<br/>    prompt = f"Predict the top three genres (only genres, not descriptions) for a movie with the following description: {movie_description}"<br/>    response = openai.completions.create(<br/>      model="gpt-3.5-turbo-instruct",  # You can use the GPT-3 model for this task<br/>      prompt=prompt,<br/>      max_tokens=50,<br/>      n=1,<br/>      stop=None,<br/>      temperature=0.2<br/>    )<br/>    predicted_genres = response.choices[0].text.strip()<br/>    return predicted_genres</span></pre><p id="1dab" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Now we iterate through our DataFrame of movie descriptions, use the function above to predict the genres associated with the movie, then add them to our list of established unique genres.</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="8410" class="pz oi gf pw b bg qa qb l qc qd"># Create an empty list to store the predicted genres<br/>all_predicted_genres = []<br/><br/># Create an empty set to store unique genres<br/>unique_genres_set = set()<br/><br/># Iterate through the movie descriptions<br/>for index, row in tqdm(movies.iterrows(), total=movies.shape[0]):<br/>    <br/>        # Get the movie description<br/>        movie_description = row['description']<br/>    <br/>        # Predict the genres for the movie description<br/>        predicted_genres = predict_genres(movie_description)<br/>    <br/>        # Extract genres from the text<br/>        predicted_genres_tokens = nlp(predicted_genres)<br/>        predicted_genres_tokens = predicted_genres_tokens.text<br/>        <br/>        # Use regular expression to extract genres<br/>        genres_with_numbers = re.findall(r'\d+\.\s*([^\n]+)', predicted_genres_tokens)<br/>        <br/>        # Remove leading/trailing whitespaces from each genre<br/>        predicted_genres = [genre.strip().lower() for genre in genres_with_numbers]<br/>    <br/>        # Update the set of unique genres<br/>        unique_genres_set.update(predicted_genres)<br/><br/># Convert the set of unique genres back to a list<br/>all_unique_genres = list(unique_genres_set)</span></pre><p id="92b0" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Now turn this list into a DataFrame and save to a csv file:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="2cfe" class="pz oi gf pw b bg qa qb l qc qd">all_unique_genres = pd.DataFrame(all_unique_genres,columns=['genre'])<br/>all_unique_genres.to_csv("genres_taxonomy_quick.csv")</span></pre><p id="d741" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Like I said, this is a quick and dirty way to generate this list of genres.</p><h1 id="b418" class="oh oi gf bf oj ok ol hf om on oo hi op oq or os ot ou ov ow ox oy oz pa pb pc bk">Use the genre list to tag films with genres</h1><p id="8d6f" class="pw-post-body-paragraph mx my gf mz b hd pd nb nc hg pe ne nf ng pf ni nj nk pg nm nn no ph nq nr ns fj bk">Now that we have a list of genres, we need to tag each of the movies and TV shows in our dataset (over 8,000) with them. To be able to use these tags to calculate similarity between two entities, we need to tag each movie and TV show with more than one genre. If we only used one genre, then all action movies will be equally similar, even though some may be more about sports and others, horror.</p><p id="a2db" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">First, we read in our genre list and movie dataset:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="0293" class="pz oi gf pw b bg qa qb l qc qd">#Read in our genre list<br/>genres = pd.read_csv('genres_taxonomy_quick.csv')  # Replace 'genres_taxonomy_quick.csv' with the actual file name<br/>genres = genres['genre']<br/><br/>#Read in our movie data<br/>movies = pd.read_csv("netflix_titles.csv")<br/>movies = movies.sample(n=1000) #This takes a while to run so I didn't do it for the entire dataset at once</span></pre><p id="f929" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">We already have a function for predicting genres. Now we need to define two more functions: one for filtering the predictions to ensure that the predictions are in our established genre list, and one for adding those filtered predictions to the movie DataFrame.</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="ae15" class="pz oi gf pw b bg qa qb l qc qd">#Function to filter predicted genres<br/>def filter_predicted_genres(predicted_genres, predefined_genres):<br/>    # Use word embeddings to calculate semantic similarity between predicted and predefined genres<br/>    predicted_genres_tokens = nlp(predicted_genres)<br/>    predicted_genres_tokens = predicted_genres_tokens.text<br/>    # Use regular expression to extract genres<br/>    genres_with_numbers = re.findall(r'\d+\.\s*([^\n]+)', predicted_genres_tokens)<br/>    # Remove leading/trailing whitespaces from each genre<br/>    predicted_genres = [genre.strip().lower() for genre in genres_with_numbers]<br/><br/>    filtered_genres = []<br/>    similarity_scores = []<br/><br/>    for predicted_genre in predicted_genres:<br/>        max_similarity = 0<br/>        best_match = None<br/>        for predefined_genre in predefined_genres:<br/>            similarity_score = nlp(predicted_genre).similarity(nlp(predefined_genre))<br/>            if similarity_score &gt; max_similarity:  # Adjust the threshold as needed<br/>                max_similarity = similarity_score<br/>                best_match = predefined_genre<br/>        filtered_genres.append(best_match)<br/>        similarity_scores.append(max_similarity)<br/><br/>    # Sort the filtered genres based on the similarity scores<br/>    filtered_genres = [x for _, x in sorted(zip(similarity_scores, filtered_genres), reverse=True)]<br/>    <br/>    return filtered_genres<br/><br/>#Function to add filtered predictions to DataFrame<br/>def add_predicted_genres_to_df(df, predefined_genres):   <br/>    # Iterate through the dataframe<br/>    for index, row in tqdm(df.iterrows(), total=df.shape[0]):<br/>        # Apply the predict_genres function to the movie description<br/>        predicted_genres = predict_genres(row['description'])<br/>        # Prioritize the predicted genres<br/>        filtered_genres = filter_predicted_genres(predicted_genres, predefined_genres)<br/>        # Add the prioritized genres to the dataframe<br/>        df.at[index, 'predicted_genres'] = filtered_genres</span></pre><p id="8319" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Once we have these functions defined, we can run them on our movies dataset:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="1333" class="pz oi gf pw b bg qa qb l qc qd">add_predicted_genres_to_df(movies, genres)</span></pre><p id="9230" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Now we do some data cleaning:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="af0e" class="pz oi gf pw b bg qa qb l qc qd"># Split the lists into separate columns with specific names<br/>movies[['genre1', 'genre2', 'genre3']] = movies['predicted_genres'].apply(lambda x: pd.Series((x + [None, None, None])[:3]))<br/><br/>#Keep only the columns we need for similarity<br/>movies = movies[['title','genre1','genre2','genre3']]<br/><br/>#Drop duplicates<br/>movies = movies.drop_duplicates()<br/><br/>#Set the 'title' column as our index<br/>movies = movies.set_index('title')</span></pre><p id="2f24" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">If we print the head of the DataFrame it should look like this:</p><figure class="pj pk pl pm pn fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qe"><img src="../Images/1eecf770581a33e10b76f6d2a77063de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pGySMpHrjxlh_tcmSlI8eg.png"/></div></div><figcaption class="po pp pq fo fp pr ps bf b bg z dx">Image by author</figcaption></figure><h1 id="0503" class="oh oi gf bf oj ok ol hf om on oo hi op oq or os ot ou ov ow ox oy oz pa pb pc bk">Use the genre tags to build a similarity model</h1><p id="810e" class="pw-post-body-paragraph mx my gf mz b hd pd nb nc hg pe ne nf ng pf ni nj nk pg nm nn no ph nq nr ns fj bk">Now we turn the genre columns into dummy variables — each genre becomes its own column and if the movie or TV show is tagged with that genre then the column gets a 1, otherwise the value is 0.</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="5e42" class="pz oi gf pw b bg qa qb l qc qd"># Combine genre columns into a single column<br/>movies['all_genres'] = movies[['genre1', 'genre2', 'genre3']].astype(str).agg(','.join, axis=1)<br/><br/># Split the genres and create dummy variables for each genre<br/>genres = movies['all_genres'].str.get_dummies(sep=',')<br/><br/># Concatenate the dummy variables with the original DataFrame<br/>movies = pd.concat([movies, genres], axis=1)<br/><br/># Drop unnecessary columns<br/>movies.drop(['all_genres', 'genre1', 'genre2', 'genre3'], axis=1, inplace=True)</span></pre><p id="4e62" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">If we print the head of this DataFrame, this is what it looks like:</p><figure class="pj pk pl pm pn fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qf"><img src="../Images/6a403777c5b4922440ac69a840305ede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ETL5OuC7epps1im0czxlZA.png"/></div></div><figcaption class="po pp pq fo fp pr ps bf b bg z dx">Image by author</figcaption></figure><p id="0d05" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">We need to use these dummy variables to build a matrix and run a similarity model across all pairs of movies:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="3b24" class="pz oi gf pw b bg qa qb l qc qd"># If there are duplicate columns due to the one-hot encoding, you can sum them up<br/>movie_genre_matrix = movies.groupby(level=0, axis=1).sum()<br/><br/># Calculate cosine similarity <br/>similarity_matrix = cosine_similarity(movie_genre_matrix, movie_genre_matrix)</span></pre><p id="1b8a" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Now we can define a function that calculates the most similar movies to a given title:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="9b07" class="pz oi gf pw b bg qa qb l qc qd">def find_similar_movies(movie_name, movie_genre_matrix, num_similar_movies=3):<br/>    # Calculate cosine similarity<br/>    similarity_matrix = cosine_similarity(movie_genre_matrix, movie_genre_matrix)<br/>    <br/>    # Find the index of the given movie<br/>    movie_index = movie_genre_matrix.index.get_loc(movie_name)<br/>    <br/>    # Sort and get indices of most similar movies (excluding the movie itself)<br/>    most_similar_indices = np.argsort(similarity_matrix[movie_index])[:-num_similar_movies-1:-1]<br/>    <br/>    # Return the most similar movies<br/>    return movie_genre_matrix.index[most_similar_indices].tolist()</span></pre><p id="d0a9" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Let’s see if this model finds movies more similar to ‘Eat Pray Love,’ than the previous model:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="fdb0" class="pz oi gf pw b bg qa qb l qc qd"># Example usage<br/>similar_movies = find_similar_movies("Eat Pray Love", movie_genre_matrix, num_similar_movies=4)<br/>print(similar_movies)</span></pre><p id="09e9" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The output from this query, for me, were, ‘The Big Day’, ‘Love Dot Com: The Social Experiment’, and ’50 First Dates’. All of these movies are tagged as romantic comedies and dramas, just like Eat Pray Love.</p><figure class="pj pk pl pm pn fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qg"><img src="../Images/c760e9f8b5ef45a4bcb4df301050b036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ccawpoJM6lXO1UP73YwMbw.png"/></div></div><figcaption class="po pp pq fo fp pr ps bf b bg z dx">Image by author</figcaption></figure><p id="fdea" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">‘Extremely Wicked, Shockingly Evil and Vile,’ the movie about a woman in love with Ted Bundy, is tagged with the genres romance, drama, and crime. The most similar movies are, ‘The Fury of a Patient Man’, ‘Much Loved’, and ‘Loving You’, all of which are also tagged with romance, drama, and crime. ‘Beavis and Butt-head Do America’ is tagged with the genres comedy, adventure and road trip. The most similar movies are ‘Pee-wee’s Big Holiday’, ‘A Shaun the Sheep Movie: Farmageddon’, and ‘The Secret Life of Pets 2.’ All of these movies are also tagged with the genres adventure and comedy — there are no other movies in this dataset (at least the portion I tagged) that match all three genres from Beavis and Butt-head.</p><h1 id="843b" class="oh oi gf bf oj ok ol hf om on oo hi op oq or os ot ou ov ow ox oy oz pa pb pc bk">Use the genre tags to create a network visualization</h1><p id="990d" class="pw-post-body-paragraph mx my gf mz b hd pd nb nc hg pe ne nf ng pf ni nj nk pg nm nn no ph nq nr ns fj bk">You can’t link data together without building a cool network visualization. There are a few ways to turn this data into a graph — we could look at how movies are conneted via genres, how genres are connected via movies, or a combination of the two. Because there are so many movies in this dataset, I just made a graph using genres as nodes and movies as edges.</p><p id="f600" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Here is my code to turn the data into nodes and edges:</p><pre class="pj pk pl pm pn pv pw px bp py bb bk"><span id="00ae" class="pz oi gf pw b bg qa qb l qc qd"># Melt the dataframe to unpivot genre columns<br/>melted_df = pd.melt(movies, id_vars=['title'], value_vars=['genre1', 'genre2', 'genre3'], var_name='Genre', value_name='GenreValue')<br/><br/>genre_links = pd.crosstab(index=melted_df['title'], columns=melted_df['GenreValue'])<br/><br/># Create combinations of genres for each title<br/>combinations_list = []<br/><br/>for title, group in melted_df.groupby('title')['GenreValue']:<br/>    genre_combinations = list(combinations(group, 2))<br/>    combinations_list.extend([(title, combo[0], combo[1]) for combo in genre_combinations])<br/><br/># Create a new dataframe from the combinations list<br/>combinations_df = pd.DataFrame(combinations_list, columns=['title', 'Genre1', 'Genre2'])<br/><br/>combinations_df = combinations_df[['Genre1','Genre2']]<br/><br/>combinations_df = combinations_df.rename(columns={"Genre1": "source", "Genre2": "target"}, errors="raise")<br/><br/>combinations_df = combinations_df.set_index('source')<br/><br/>combinations_df.to_csv("genreCombos.csv")</span></pre><p id="0c82" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This produces a DataFrame that looks like this:</p><figure class="pj pk pl pm pn fw fo fp paragraph-image"><div class="fo fp qh"><img src="../Images/8a3894ceaabed0ec7f86dba4bfeeae78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*KI8C-clzdeSb2sJU5iuLOg.png"/></div><figcaption class="po pp pq fo fp pr ps bf b bg z dx">Image by author</figcaption></figure><p id="609e" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">Each row in this DataFrame represents a movie that has been tagged with these two genres. We did not remove duplicates so there will be, presumably, many rows that look like row 1 above — there are many movies that are tagged as both romance and drama.</p><p id="bcba" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">I used <a class="af nu" href="https://gephi.org/" rel="noopener ugc nofollow" target="_blank">Gephi</a> to build a visualization that looks like this:</p><figure class="pj pk pl pm pn fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/9bcaa0e799d0ad12c1c54169c510968f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qI-i8FI9RACiyokb3K59-A.png"/></div></div><figcaption class="po pp pq fo fp pr ps bf b bg z dx">Image by author</figcaption></figure><p id="7cc9" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">The size of the nodes here represents the number of movies tagged with that genre. The color of the nodes is a function of a community detection algorithm — clusters that have closer connections amongst themselves than with nodes outside their cluster are colored the same.</p><p id="1b70" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">This is fascinating to me. Drama, comedy, and documentary are the three largest nodes meaning more movies are tagged with those genres than any others. The genres also naturally form clusters that make intuitive sense. The genres most aligned with ‘documentary’ are colored pink and are mostly some kind of documentary sub-genre: nature/wildlife, reality TV, travel/adventure, history, educational, biography, etc. There are a core cluster of genres in green: drama, comedy, romance, coming of age, family, etc. One issue here is that we have multiple spellings of the ‘coming of age’ genre — a problem I would fix in future versions. There is a cluster in blue that includes action/adventure, fantasy, sci-fi, and animation. Again, we have duplicates and overlapping genres here which is a problem. There is also a small genre in brown that includes thriller, mystery, and horror — adult genres often present in the same film. The lack of connections between certain genres is also interesting — there are no films tagged with both ‘stand-up’ and ‘horror’, for example.</p><h1 id="bb49" class="oh oi gf bf oj ok ol hf om on oo hi op oq or os ot ou ov ow ox oy oz pa pb pc bk">Conclusion</h1><p id="62e3" class="pw-post-body-paragraph mx my gf mz b hd pd nb nc hg pe ne nf ng pf ni nj nk pg nm nn no ph nq nr ns fj bk">This project has shown me how even the most basic controlled vocabulary is useful, and potentially necessary, when building a content-based recommendation system. With just a list of genres we were able to tag movies and find other similar movies in a more explainable way than using just NLP. This could obviously be improved immensely through a more detailed and description genre taxonomy, but also through additional taxonomies including the cast and crew of films, the locations, etc.</p><p id="4706" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">As is usually the case when using LLMs, I was very impressed at first at how well it could perform this task, only to be disappointed when I viewed and tried to improve the results. Building taxonomies, ontologies, or any controlled vocabulary requires human engagement — there needs to be a human in the loop to ensure the vocabulary makes sense and will be useful in satisfying a particular use case.</p><p id="a3ab" class="pw-post-body-paragraph mx my gf mz b hd na nb nc hg nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns fj bk">LLMs and knowledge graphs (KGs) naturally fit together. One way they can be used together is that LLMs can help facilitate KG creation. LLMs can’t build a KG themselves but they can certainly help you create one.</p></div></div></div></div>    
</body>
</html>