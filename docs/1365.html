<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Computing Minimum Sample Size for A/B Tests in Statsmodels: How and Why</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Computing Minimum Sample Size for A/B Tests in Statsmodels: How and Why</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://towardsdatascience.com/computing-minimum-sample-size-for-a-b-tests-in-statsmodels-how-and-why-398e357945d9?source=collection_archive---------3-----------------------#2024-05-31">https://towardsdatascience.com/computing-minimum-sample-size-for-a-b-tests-in-statsmodels-how-and-why-398e357945d9?source=collection_archive---------3-----------------------#2024-05-31</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="d5d5" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A deep-dive into how and why Statsmodels uses numerical optimization instead of closed-form formulas</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://jasonjiajs.medium.com/?source=post_page---byline--398e357945d9--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Jason Jia" class="l ep by dd de cx" src="../Images/e3e3bdf0873cb48384dcf2f76a964ebd.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*MI2p65lqTJnBTWSoiDBnig.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--398e357945d9--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://jasonjiajs.medium.com/?source=post_page---byline--398e357945d9--------------------------------" rel="noopener follow">Jason Jia</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--398e357945d9--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">¬∑</span></span></div><span data-testid="storyPublishDate">May 31, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/cfc8f9479bd992d2d46961c47bd201c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kYnWmzf0MmNDNSIVEbprlA.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image generated by DALL-E</figcaption></figure><h1 id="02e4" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Introduction</h1><h2 id="d4e0" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk">There is currently no good resource on how Statsmodels computes the minimum sample size.</h2><p id="9ac8" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">It is critical to calculate the minimum sample size required before conducting an A/B test. A popular way to do it is by calling the <a class="af pl" href="https://www.statsmodels.org/stable/generated/statsmodels.stats.power.tt_ind_solve_power.html" rel="noopener ugc nofollow" target="_blank">tt_ind_solve_power function</a> in Python‚Äôs Statsmodels package, but there are currently 2 gaps when it comes to understanding how it works:</p><p id="8a8b" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">1. There are many great articles (e.g. by <a class="af pl" rel="noopener" target="_blank" href="/experiment-sample-size-calculation-using-power-analysis-81cb1bc5f74b">Stan Nsky</a>, TDS 2019) explaining what the parameters mean and provide examples of function calls. However, they do not explain how the function actually computes the sample size and why the procedure is correct.</p><p id="7187" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">2. There are also many great articles (e.g. by <a class="af pl" rel="noopener" target="_blank" href="/probing-into-minimum-sample-size-formula-derivation-and-usage-8db9a556280b#c172">Mintao Wei</a>, TDS 2023) that explain the statistical derivation based on a z-test for proportions such as conversion rates, which is also a popular choice for many online sample size calculators (e.g. <a class="af pl" href="https://www.evanmiller.org/ab-testing/sample-size.html" rel="noopener ugc nofollow" target="_blank">Evan Miller‚Äôs Calculator</a>). However, this is not the method used by Statsmodels and results can differ.</p><h2 id="da31" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk">This is important for data scientists because Statsmodels is commonly used to compute sample size in Python.</h2><p id="5ba0" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">Data scientists frequently use Statsmodels to get the minimum sample size, but may not be aware that it employs a different method from what most articles describe and what most online calculators use. It is essential to understand how the function works so that we can trust its results.</p><h2 id="f77a" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk">This article bridges the gap by explaining how Statsmodels actually works.</h2><p id="fee5" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">This article aims to make the novel contribution of explaining how <code class="cx pr ps pt pu b">tt_ind_solve_power</code> actually computes the sample size, why the procedure is correct and what benefits it brings over closed-form solutions. [1]</p><p id="b512" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk"><strong class="ou fr">Part 1:</strong> It will first explain how sample size is computed and why the procedure is correct in two steps:</p><ol class=""><li id="e4cb" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk pv pw px bk">Show the statistical derivation for sample size calculations.</li><li id="96b4" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk pv pw px bk">Write a stripped-down version of <code class="cx pr ps pt pu b">tt_ind_solve_power</code> that is an exact implementation of the statistical derivation and produces the same output as the original function</li></ol><p id="dcc1" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk"><strong class="ou fr">Part 2: </strong>Following which, it will explain two benefits it brings over closed-form solutions:</p><ol class=""><li id="6316" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk pv pw px bk">Benefits to generalizability</li><li id="7743" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk pv pw px bk">Benefits to statistical intuition</li></ol></div></div></div><div class="ab cb qd qe qf qg" role="separator"><span class="qh by bm qi qj qk"/><span class="qh by bm qi qj qk"/><span class="qh by bm qi qj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="f9df" class="nc nd fq bf ne nf ql gq nh ni qm gt nk nl qn nn no np qo nr ns nt qp nv nw nx bk">Part 1: How Statsmodels computes minimum sample size and why it is correct</h1><h2 id="b958" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk">1.1. Showing the statistical derivation for sample size calculations</h2><h2 id="673f" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk"><strong class="al">Core Idea</strong></h2><p id="0b9a" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">A general A/B test is an unpaired two-sample t-test. Rather than using a closed-form solution, Statsmodels obtains the minimum sample size in two steps:</p><ol class=""><li id="2c82" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk pv pw px bk">For a given sample size, compute the associated power of the test.</li><li id="97f5" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk pv pw px bk">Run a numerical optimization algorithm to find the sample size that returns the target power of the test.</li></ol><h2 id="ef68" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk"><strong class="al">Notation and Concepts</strong></h2><p id="615a" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">These are some terms we will use throughout the article:</p><ul class=""><li id="4990" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk qq pw px bk"><strong class="ou fr">n</strong>: minimum required sample size. n = n_1 + n_2</li><li id="717a" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">n_1, n_2</strong>: minimum required sample size for the treatment and control group, respectively</li><li id="241d" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">ratio: </strong>n_2 = n_1 * ratio, where for a 50:50 allocation, ratio = 1</li><li id="3c6e" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">p</strong>: p-value</li><li id="17cd" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">ùõº:</strong> significance level / type I error</li><li id="7164" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">ùõΩ:</strong> type II error; 1-ùõΩ is power</li><li id="5abd" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">Œº_1, Œº_2</strong>: means of treatment group and control group, respectively</li><li id="e8a2" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">XÃÑ1, XÃÑ2:</strong> sample means of treatment group and control group, respectively</li></ul><figure class="mm mn mo mp mq mr"><div class="qr io l ed"><div class="qs qt l"/></div></figure><ul class=""><li id="9e32" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk qq pw px bk"><strong class="ou fr">t_(1-ùõº):</strong> critical value / t-score that cuts off the top 100ùõº(%) of the standard t distribution.</li><li id="a668" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">MDE:</strong> the minimum detectable effect, or the level of statistically significant difference that can be detected given all other parameters (e.g. a base conversion rate of 10%, an expected uplift of 50% and so an expected treatment conversion rate of 15% means that the MDE is 15‚Äì10=5%=0.05)</li><li id="ae1b" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">ùúé:</strong> standard deviation of observations in each group, assumed to be the same</li><li id="5282" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">d:</strong> Cohen‚Äôs d / standardized effect size, given by MDE / ùúé</li><li id="94e0" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk"><strong class="ou fr">H_0, H_1:</strong> null hypothesis, alternative hypothesis</li></ul><h2 id="4ef0" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk"><strong class="al">Derive the formula for power of a test</strong></h2><ol class=""><li id="6339" class="os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk pv pw px bk"><strong class="ou fr">Define the null and alternative hypothesis:</strong></li></ol><figure class="mm mn mo mp mq mr"><div class="qr io l ed"><div class="qu qt l"/></div></figure><p id="6e3a" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk"><strong class="ou fr">2. Derive the distribution of the test statistic under the null hypothesis (H_0):</strong></p><p id="9ae8" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">We find that <strong class="ou fr">under the null hypothesis</strong>, the test statistic t follows a <strong class="ou fr">t-distribution</strong> with <strong class="ou fr">(n_1 + n_2 - 2) degrees of freedom</strong>.</p><figure class="mm mn mo mp mq mr"><div class="qr io l ed"><div class="qv qt l"/></div></figure><p id="7021" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">This follows from the following:</p><figure class="mm mn mo mp mq mr"><div class="qr io l ed"><div class="qw qt l"/></div></figure><p id="5c87" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Where the sample variance of X is computed as such:</p><figure class="mm mn mo mp mq mr"><div class="qr io l ed"><div class="qx qt l"/></div></figure><p id="249a" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk"><strong class="ou fr">3. Derive the distribution of the test statistic under the alternative hypothesis (H_1):</strong></p><p id="02b0" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">We find that <strong class="ou fr">under the alternative hypothesis</strong>, assuming that the difference in means is the MDE, the test statistic t follows a <strong class="ou fr">non-central t-distribution</strong> with <strong class="ou fr">non-centrality parameter Œ∏ = d * sqrt((n1 * n2) / (n1 + n2)) </strong>and <strong class="ou fr">(n_1 + n_2 - 2) degrees of freedom</strong>.</p><p id="c249" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">A non-central t-distribution (nct) with a positive non-centrality parameter can be roughly thought of as a standard t-distribution shifted to the right. [2] Intuitively, the standard t-distribution happens under the null when we expect 0 effect on average, while the non-central t-distribution happens under the alternative when we expect a positive effect that is on average roughly equal to the MDE.</p><p id="da52" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Definition: A non-central t-distribution random variable T with non-centrality parameter Œ∏ and ŒΩ degrees of freedom is defined as:</p><figure class="mm mn mo mp mq mr"><div class="qr io l ed"><div class="qy qt l"/></div></figure><p id="81cd" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">where Z is a standard normal random variable, and <em class="qz">V</em> is a chi-squared distributed random variable with ŒΩ degrees of freedom.</p><p id="b445" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">The proof starts from the observation that under the alternative hypothesis, the true difference in means is MDE and so we can subtract MDE and divide by the population standard deviation to get a standard normal variable.</p><figure class="mm mn mo mp mq mr"><div class="qr io l ed"><div class="ra qt l"/></div></figure><p id="3b5c" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk"><strong class="ou fr">4. Compute the power</strong></p><p id="eaa2" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Since we know the distribution of the test statistic under the null and alternative hypotheses, and the cdf of both distributions are known, we can calculate power easily given the level of significance and type of test (two-tailed, greater, smaller). The diagram below visualizes how:</p></div></div><div class="mr"><div class="ab cb"><div class="lm rb ln rc lo rd cf re cg rf ci bh"><figure class="mm mn mo mp mq mr rh ri paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rg"><img src="../Images/f7537362230bff4e8f958aaa8ca1cac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*5AW_ZuRrXTynsZ4QpBKn9Q.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Diagram by author</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="76bf" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">In Python, the implementation looks like this:</p><pre class="mm mn mo mp mq rj pu rk bp rl bb bk"><span id="f255" class="rm nd fq pu b bg rn ro l rp rq">def power(self, effect_size, nobs1, alpha, ratio=1, df=None,<br/>          alternative='two-sided'):<br/>    nobs2 = nobs1*ratio<br/>    if df is None:<br/>        df = (nobs1 + nobs2 - 2)<br/><br/>    # Get non-centrality parameter<br/>    nobs = nobs1 * nobs2 / (nobs1 + nobs2)<br/>    d = effect_size<br/>    nc_param = d * np.sqrt(nobs)<br/><br/>    # Get effective level of signifiance, alpha_<br/>    if alternative in ['two-sided']:<br/>        alpha_ = alpha / 2.<br/>    elif alternative in ['smaller', 'larger']:<br/>        alpha_ = alpha<br/>    else:<br/>        raise ValueError("alternative has to be 'two-sided', 'larger' " +<br/>                        "or 'smaller'")<br/>    <br/>    # Compute power of a t-test<br/>    power = 0<br/>    if alternative in ['two-sided', 'larger']:<br/>        crit_upp = stats.t.isf(alpha_, df) # isf = inverse survival function = value where Pr(t &gt; value) = alpha<br/>        power += 1 - special.nctdtr(df, nc_param, crit_upp)  # 1 - Pr(t &lt; crit_upp) = Pr(t &gt; crit_upp) for non-central t distribution<br/>    if alternative in ['two-sided', 'smaller']:<br/>        crit_low = stats.t.ppf(alpha_, df) # ppf = percent point function = value where Pr(t &lt; value) = alpha<br/>        power += special.nctdtr(df, nc_param, crit_low) # <br/>    return power</span></pre><h2 id="1357" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk"><strong class="al">Obtain minimum sample size using numerical optimization</strong></h2><p id="cd17" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">Given that we now know how to computer power for a given set of parameters, we can then run a numerical optimization method to find the minimum sample size that achieves the target power. Since the total sample size is a function of the treatment sample size (n = n_1 + ratio * n_1), we will be finding n_1.</p><p id="c67b" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">This works because power is monotonically increasing in sample size n_1. Intuitively, more samples means that A/B testing results are more certain and so if the alternative hypothesis is true, more values will reject the null hypothesis (see left subplot of figure below).</p><p id="81cc" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">But this also means that subtracting off the target power gives a monotonically increasing function with a negative start point and a positive end point. By the intermediate value theorem and monotonicity of the function, there is a unique root that corresponds to our minimum sample size (see right subplot of figure below).</p></div></div><div class="mr"><div class="ab cb"><div class="lm rb ln rc lo rd cf re cg rf ci bh"><figure class="mm mn mo mp mq mr rh ri paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rr"><img src="../Images/c66e6dffb8db57745b2cf9d9a2543f10.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*7EXRLu8SW_COPBfg8OkI4g.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Figure by author</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="604f" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">A popular, high-performing numerical optimization method is <strong class="ou fr">Brent‚Äôs method</strong>. Brent‚Äôs method is a root-finding algorithm that combines various techniques such as the bisection method, the secant method and inverse quadratic interpolation. Further details of its implementation in Statsmodels can be found <a class="af pl" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brentq.html" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="9bbe" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">In Python, the implementation looks like this:</p><pre class="mm mn mo mp mq rj pu rk bp rl bb bk"><span id="b685" class="rm nd fq pu b bg rn ro l rp rq">def solve_power(self, effect_size=None, nobs1=None, alpha=None, power=None,<br/>                ratio=1., alternative='two-sided'):<br/>    print('--- Arguments: ---')<br/>    print('effect_size:', effect_size, 'nobs1:', nobs1, 'alpha:', alpha, 'power:', power, 'ratio:', ratio, 'alternative:', alternative, '\n')<br/>    <br/>    # Check that only nobs1 is None<br/>    kwds = dict(effect_size=effect_size, nobs1=nobs1, alpha=alpha,<br/>                power=power, ratio=ratio, alternative=alternative)<br/>    key = [k for k,v in kwds.items() if v is None]<br/>    assert(key == ['nobs1'])<br/><br/>    # Check that the effect_size is not 0<br/>    if kwds['effect_size'] == 0:<br/>        raise ValueError('Cannot detect an effect-size of 0. Try changing your effect-size.')<br/><br/>    # Initialize the counter<br/>    self._counter = 0<br/><br/>    # Define the function that we want to find the root of<br/>    # We want to find nobs1 s.t. current power = target power, i.e. current power - target power = 0<br/>    # So func = current power - target power<br/>    def func(x):<br/>        kwds['nobs1'] = x<br/>        target_power = kwds.pop('power') # always the same target power specified in keywords, e.g. 0.8<br/>        current_power = self.power(**kwds) # current power given the current nobs1, note that self.power does not have power as an argument<br/>        kwds['power'] = target_power # add back power to kwds<br/><br/>        fval = current_power - target_power<br/>        print(f'Iteration {self._counter}: nobs1 = {x}, current power - target power = {fval}')<br/>        self._counter += 1<br/>        return fval<br/>    <br/>    # Get the starting values for nobs1, given the brentq_expanding algorithm<br/>    # In the original code, this is the self.start_bqexp dictionary set up in the __init__ method<br/>    bqexp_fit_kwds = {'low': 2., 'start_upp': 50.}<br/><br/>    # Solve for nobs1 using brentq_expanding<br/>    print('--- Solving for optimal nobs1: ---')<br/>    val, _ = brentq_expanding(func, full_output=True, **bqexp_fit_kwds)<br/>    <br/>    return val</span></pre><h2 id="8dbf" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk">1.2. Writing a stripped-down version of tt_ind_solve_power that is an exact implementation of the statistical derivation and produces the same output as the original function</h2><p id="3131" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">The source file in Statsmodels is available <a class="af pl" href="https://github.com/statsmodels/statsmodels/blob/main/statsmodels/stats/power.py" rel="noopener ugc nofollow" target="_blank">here</a>. While the original function is written to be more powerful, its generalizability also makes it harder to gain intuition on how the code works.</p><p id="1dde" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">I thus looked through the source code line-by-line and simplified it down from 1,600 lines of code to 160, and from 10+ functions to just 2, while ensuring the that implementation remains identical.</p><p id="0517" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">The stripped-down code contains just two functions under the TTestIndPower class, exactly following the statistical derivation explained in Part 1:</p><ol class=""><li id="87d4" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk pv pw px bk"><strong class="ou fr">power</strong>, which computes power given a sample size</li><li id="5467" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk pv pw px bk"><strong class="ou fr">solve_power</strong>, which finds the minimum sample size that achieves a target power using Brent‚Äôs method</li></ol><p id="61d4" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">This is the full code for the stripped-down version with a test to check that it produces the same output as the original function:</p><figure class="mm mn mo mp mq mr"><div class="qr io l ed"><div class="rs qt l"/></div></figure></div></div></div><div class="ab cb qd qe qf qg" role="separator"><span class="qh by bm qi qj qk"/><span class="qh by bm qi qj qk"/><span class="qh by bm qi qj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="9929" class="nc nd fq bf ne nf ql gq nh ni qm gt nk nl qn nn no np qo nr ns nt qp nv nw nx bk">Part 2: Benefits of the numerical optimization approach used by Statsmodels</h1><h2 id="c7ed" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk">2.1. Benefits to generalizability</h2><p id="fba5" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">This approach can be easily generalized to finding other parameters of interest (e.g. finding the level of significance or minimum detectable effect instead of sample size).</p><p id="b590" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Via the closed-form solution approach, we need to find an equation for each parameter, which can be complex or infeasible. In contrast, the same numerical optimization approach works for any parameter.</p><h2 id="bcfc" class="ny nd fq bf ne nz oa ob nh oc od oe nk of og oh oi oj ok ol om on oo op oq or bk">2.2. Benefits to statistical intuition</h2><p id="14fe" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">This approach is arguably more intuitive because it is a natural extension of the concept of statistical power. Further, the concept of the non-central t-distribution offers clearer insights into how minimum sample size changes when other parameters change.</p><p id="7cbf" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk"><strong class="ou fr">Case 1: Change in parameter leading to increase in Œ∏ and thus an increase in power</strong></p><p id="d824" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Recall that the non-centrality parameter<strong class="ou fr"> </strong>is Œ∏ = d * sqrt((n1 * n2) / (n1 + n2)). An increase in Œ∏ effectively shifts the non-central distribution to the right, reducing the overlap between the distributions under the two hypotheses.</p><p id="b8cc" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">This can be created by the following:</p><ul class=""><li id="f3aa" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk qq pw px bk">Increase in MDE which increases Cohen‚Äôs d and thus increases Œ∏</li><li id="1e3b" class="os ot fq ou b go py ow ox gr pz oz pa of qa pc pd oj qb pf pg on qc pi pj pk qq pw px bk">Decrease in population standard deviation which increases Cohen‚Äôs d and thus increases Œ∏</li></ul><p id="2ebd" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">This increases power given the same sample size (see Case 1 in diagram below), and thus reduces the minimum sample size.</p><p id="c8f7" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk"><strong class="ou fr">Case 2: Change in parameter leading directly to an increase in power without changing Œ∏</strong></p><ul class=""><li id="be2f" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk qq pw px bk">An increase in the level of significance means that more values will lead to a rejection of the null. This directly increases power (see Case 2 in diagram below) and reduces the minimum sample size.</li></ul><p id="6a86" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk"><strong class="ou fr">Case 3: Change in target power</strong></p><ul class=""><li id="0a4e" class="os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk qq pw px bk">An increase in target power means that the initial n will no longer meet the higher target power, thus requiring an increase in minimum sample size.</li></ul></div></div><div class="mr"><div class="ab cb"><div class="lm rb ln rc lo rd cf re cg rf ci bh"><figure class="mm mn mo mp mq mr rh ri paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rg"><img src="../Images/5d68924648af71a50c77c3c4ec9f8591.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*GV4qOzOtf0nAyH4v7kMimg.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Diagram by author</figcaption></figure></div></div></div></div><div class="ab cb qd qe qf qg" role="separator"><span class="qh by bm qi qj qk"/><span class="qh by bm qi qj qk"/><span class="qh by bm qi qj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="8470" class="nc nd fq bf ne nf ql gq nh ni qm gt nk nl qn nn no np qo nr ns nt qp nv nw nx bk">Conclusion</h1><p id="be68" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">The function to solve for minimum sample size in Statsmodels is powerful and relies on numerical optimization. While different from standard closed-form solutions, this approach makes it easier to see the statistical intuition behind how sample size is computed, and to generalize to computing other parameters of interest. It is an approach worth understanding for data scientists interested in marketing and product analytics.</p></div></div></div><div class="ab cb qd qe qf qg" role="separator"><span class="qh by bm qi qj qk"/><span class="qh by bm qi qj qk"/><span class="qh by bm qi qj"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="5968" class="nc nd fq bf ne nf ql gq nh ni qm gt nk nl qn nn no np qo nr ns nt qp nv nw nx bk">References</h1><p id="7252" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">Deng, L. (2020). Required Sample Size for A/B Testing. <a class="af pl" rel="noopener" target="_blank" href="/required-sample-size-for-a-b-testing-6f6608dd330a">https://towardsdatascience.com/required-sample-size-for-a-b-testing-6f6608dd330a</a></p><p id="7f5d" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Kohavi, R., Tang, D., &amp; Xu, Y (2020). Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing. In <em class="qz">Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing</em> (p. I). Cambridge: Cambridge University Press.</p><p id="7656" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Miller, E. (2013). <a class="af pl" href="https://www.evanmiller.org/ab-testing/sample-size.html" rel="noopener ugc nofollow" target="_blank">Sample Size Calculator</a>.</p><p id="d7fe" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Nsky, S. (2019). Experiment sample size calculation using power analysis. <a class="af pl" rel="noopener" target="_blank" href="/experiment-sample-size-calculation-using-power-analysis-81cb1bc5f74b">https://towardsdatascience.com/experiment-sample-size-calculation-using-power-analysis-81cb1bc5f74b</a></p><p id="7bbe" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">Wei, M. (2023). Probing into Minimum Sample Size Formula: Derivation and Usage. <a class="af pl" rel="noopener" target="_blank" href="/probing-into-minimum-sample-size-formula-derivation-and-usage-8db9a556280b">https://towardsdatascience.com/probing-into-minimum-sample-size-formula-derivation-and-usage-8db9a556280b</a></p><h1 id="26b6" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Footnotes</h1><p id="8a5d" class="pw-post-body-paragraph os ot fq ou b go ov ow ox gr oy oz pa of pb pc pd oj pe pf pg on ph pi pj pk fj bk">[1] The equivalent function in R is <code class="cx pr ps pt pu b">pwr.t.test</code>. We use the Python version because the open-source code is available for readers to view, compare and work through.</p><p id="976d" class="pw-post-body-paragraph os ot fq ou b go pm ow ox gr pn oz pa of po pc pd oj pp pf pg on pq pi pj pk fj bk">[2] The general non-central t distribution is not symmetric or centered around Cohen‚Äôs d, but tends towards being so as the degrees of freedom increases.</p></div></div></div></div>    
</body>
</html>