- en: 'Reinforcement Learning 101: Q-Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/reinforcement-learning-101-q-learning-27add4c8536d?source=collection_archive---------3-----------------------#2024-02-28](https://towardsdatascience.com/reinforcement-learning-101-q-learning-27add4c8536d?source=collection_archive---------3-----------------------#2024-02-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Decoding the Math behind Q-Learning, Action-Value Functions, and Bellman Equations,
    and building them from scratch in Python.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@cristianleo120?source=post_page---byline--27add4c8536d--------------------------------)[![Cristian
    Leo](../Images/99074292e7dfda50cf50a790b8deda79.png)](https://medium.com/@cristianleo120?source=post_page---byline--27add4c8536d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--27add4c8536d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--27add4c8536d--------------------------------)
    [Cristian Leo](https://medium.com/@cristianleo120?source=post_page---byline--27add4c8536d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--27add4c8536d--------------------------------)
    ·32 min read·Feb 28, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0813814464a90ae4b67445650eaf0162.png)'
  prefs: []
  type: TYPE_IMG
- en: Image Generated by DALLE
  prefs: []
  type: TYPE_NORMAL
- en: In the previous article, we dipped our toes into the world of reinforcement
    learning (RL), covering the basics like how agents learn from their surroundings,
    focusing on a simple setup called GridWorld. We went over the essentials — actions,
    states, rewards, and how to get around in this environment. If you’re new to this
    or need a quick recap, it might be a good idea to check out that piece again to
    get a firm grip on the basics before diving in deeper.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/reinforcement-learning-101-building-a-rl-agent-0431984ba178?source=post_page-----27add4c8536d--------------------------------)
    [## Reinforcement Learning 101: Building a RL Agent'
  prefs: []
  type: TYPE_NORMAL
- en: Decoding the Math behind Reinforcement Learning, introducing the RL Framework,
    and building one RL simulation from…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/reinforcement-learning-101-building-a-rl-agent-0431984ba178?source=post_page-----27add4c8536d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Today, we’re ready to take it up a bit. We will explore more complex aspects
    of RL, moving from simple setups to dynamic, ever-changing environments and more
    sophisticated ways for our agents to navigate through them. We’ll dive into the
    concept of the Markov Decision Process, which is very important for understanding
    how RL works at a deeper level. Plus, we’ll take a closer look at Q-learning,
    a key algorithm in RL that shows how…
  prefs: []
  type: TYPE_NORMAL
