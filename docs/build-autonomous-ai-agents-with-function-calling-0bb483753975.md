# ä½¿ç”¨å‡½æ•°è°ƒç”¨æ„å»ºè‡ªä¸»AIä»£ç†

> åŸæ–‡ï¼š[https://towardsdatascience.com/build-autonomous-ai-agents-with-function-calling-0bb483753975?source=collection_archive---------0-----------------------#2024-04-02](https://towardsdatascience.com/build-autonomous-ai-agents-with-function-calling-0bb483753975?source=collection_archive---------0-----------------------#2024-04-02)

## å°†æ‚¨çš„èŠå¤©æœºå™¨äººè½¬å˜ä¸ºèƒ½å¤Ÿä¸å¤–éƒ¨APIäº¤äº’çš„ä»£ç†

[](https://medium.com/@jyipkl?source=post_page---byline--0bb483753975--------------------------------)[![Julian Yip](../Images/2afc0ac6c4dcccaa57ffe70b2f5a14d0.png)](https://medium.com/@jyipkl?source=post_page---byline--0bb483753975--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0bb483753975--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0bb483753975--------------------------------) [Julian Yip](https://medium.com/@jyipkl?source=post_page---byline--0bb483753975--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0bb483753975--------------------------------) Â·é˜…è¯»æ—¶é—´ 11 åˆ†é’ŸÂ·2024å¹´4æœˆ2æ—¥

--

å‡½æ•°è°ƒç”¨å¹¶ä¸æ˜¯ä»€ä¹ˆæ–°é²œäº‹ã€‚2023å¹´7æœˆï¼ŒOpenAIä¸ºå…¶GPTæ¨¡å‹å¼•å…¥äº†å‡½æ•°è°ƒç”¨åŠŸèƒ½ï¼Œç°åœ¨è¿™ä¸€åŠŸèƒ½æ­£åœ¨è¢«ç«äº‰å¯¹æ‰‹é‡‡ç”¨ã€‚è°·æ­Œçš„Gemini APIæœ€è¿‘ä¹Ÿæ”¯æŒäº†è¿™ä¸€åŠŸèƒ½ï¼Œè€ŒAnthropicæ­£åœ¨å°†å…¶é›†æˆåˆ°Claudeä¸­ã€‚å‡½æ•°è°ƒç”¨æ­£åœ¨æˆä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ï¼Œå¢å¼ºäº†å®ƒä»¬çš„èƒ½åŠ›ã€‚å­¦ä¹ è¿™é¡¹æŠ€æœ¯ä¼šæ›´åŠ æœ‰ç”¨ï¼

ç‰¢è®°è¿™ä¸€ç‚¹ï¼Œæˆ‘è®¡åˆ’ç¼–å†™ä¸€ä»½å…¨é¢çš„æ•™ç¨‹ï¼Œæ·±å…¥æ¢è®¨å‡½æ•°è°ƒç”¨ï¼Œè¶…è¶ŠåŸºæœ¬ä»‹ç»ï¼ˆå¸‚é¢ä¸Šå·²æœ‰å¾ˆå¤šç›¸å…³æ•™ç¨‹ï¼‰ã€‚é‡ç‚¹å°†æ”¾åœ¨å®é™…åº”ç”¨ä¸Šï¼Œæ„å»ºä¸€ä¸ªå®Œå…¨è‡ªä¸»çš„AIä»£ç†ï¼Œå¹¶å°†å…¶ä¸Streamlité›†æˆï¼Œæä¾›ç±»ä¼¼ChatGPTçš„ç•Œé¢ã€‚è™½ç„¶ä½¿ç”¨OpenAIè¿›è¡Œæ¼”ç¤ºï¼Œä½†æœ¬æ•™ç¨‹ä¹Ÿå¯ä»¥è½»æ¾é€‚åº”æ”¯æŒå‡½æ•°è°ƒç”¨çš„å…¶ä»–LLMï¼Œä¾‹å¦‚Geminiã€‚

# **å‡½æ•°è°ƒç”¨æœ‰ä»€ä¹ˆç”¨é€”ï¼Ÿ**

å‡½æ•°è°ƒç”¨ä½¿å¼€å‘è€…èƒ½å¤Ÿæè¿°å‡½æ•°ï¼ˆå³å·¥å…·ï¼Œæ‚¨å¯ä»¥å°†å…¶è§†ä¸ºæ¨¡å‹æ‰§è¡Œçš„æ“ä½œï¼Œä¾‹å¦‚è¿›è¡Œè®¡ç®—æˆ–ä¸‹è®¢å•ï¼‰ï¼Œå¹¶è®©æ¨¡å‹æ™ºèƒ½åœ°é€‰æ‹©è¾“å‡ºä¸€ä¸ªåŒ…å«è°ƒç”¨è¿™äº›å‡½æ•°æ‰€éœ€å‚æ•°çš„ JSON å¯¹è±¡ã€‚æ›´ç®€å•æ¥è¯´ï¼Œå®ƒä½¿å¾—ï¼š

+   **è‡ªä¸»å†³ç­–**ï¼šæ¨¡å‹èƒ½å¤Ÿæ™ºèƒ½åœ°é€‰æ‹©å·¥å…·æ¥å›ç­”é—®é¢˜ã€‚

+   **å¯é çš„è§£æ**ï¼šå“åº”ä»¥ JSON æ ¼å¼è¿”å›ï¼Œè€Œä¸æ˜¯æ›´å…¸å‹çš„å¯¹è¯å¼å“åº”ã€‚ä¹ä¸€çœ‹ï¼Œè¿™ä¼¼ä¹æ²¡ä»€ä¹ˆï¼Œä½†æ­£æ˜¯è¿™ç§æ ¼å¼è®©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èƒ½å¤Ÿä¸å¤–éƒ¨ç³»ç»Ÿè¿æ¥ï¼Œæ¯”å¦‚é€šè¿‡ç»“æ„åŒ–è¾“å…¥çš„ APIã€‚

å®ƒå¼€å¯äº†è®¸å¤šå¯èƒ½æ€§ï¼š

+   **è‡ªä¸»AIåŠ©æ‰‹**ï¼šæœºå™¨äººå¯ä»¥ä¸å†…éƒ¨ç³»ç»Ÿäº’åŠ¨ï¼Œæ‰§è¡Œè¯¸å¦‚å®¢æˆ·è®¢å•å’Œé€€è´§ç­‰ä»»åŠ¡ï¼Œè€Œä¸ä»…ä»…æ˜¯å›ç­”æŸ¥è¯¢

+   **ä¸ªäººç ”ç©¶åŠ©æ‰‹**ï¼šå‡è®¾ä½ æ­£åœ¨è®¡åˆ’æ—…è¡Œï¼ŒåŠ©æ‰‹å¯ä»¥æœç´¢ç½‘é¡µã€æŠ“å–å†…å®¹ã€æ¯”è¾ƒé€‰é¡¹ï¼Œå¹¶å°†ç»“æœæ€»ç»“åœ¨Excelä¸­ã€‚

+   **ç‰©è”ç½‘è¯­éŸ³å‘½ä»¤**ï¼šæ¨¡å‹å¯ä»¥æ§åˆ¶è®¾å¤‡æˆ–æ ¹æ®æ£€æµ‹åˆ°çš„æ„å›¾å»ºè®®æ“ä½œï¼Œæ¯”å¦‚è°ƒæ•´ç©ºè°ƒæ¸©åº¦ã€‚

*(ç¨å¾®åé¢˜ï¼šä¸ºäº†å®ç°è¿™äº›æ½œåŠ›ï¼Œæˆ‘ä»¬å¿…é¡»æœ‰ä¸€ä¸ªç³»ç»ŸåŒ–çš„æ–¹æ³•æ¥è®¾è®¡æˆ‘ä»¬çš„æç¤ºå¹¶è¿›è¡Œæµ‹è¯•ã€‚æˆ‘ä¹Ÿå†™äº†ä¸€ç¯‡å…³äºæ­¤çš„æ–‡ç« ï¼)*

[](/prompt-like-a-data-scientist-auto-prompt-optimization-and-testing-with-dspy-ff699f030cb7?source=post_page-----0bb483753975--------------------------------) [## åƒæ•°æ®ç§‘å­¦å®¶ä¸€æ ·æ„å»ºæç¤ºï¼šä½¿ç”¨DSPyè¿›è¡Œè‡ªåŠ¨æç¤ºä¼˜åŒ–å’Œæµ‹è¯•

### å°†æœºå™¨å­¦ä¹ æ–¹æ³•åº”ç”¨äºæç¤ºæ„å»º

towardsdatascience.com](/prompt-like-a-data-scientist-auto-prompt-optimization-and-testing-with-dspy-ff699f030cb7?source=post_page-----0bb483753975--------------------------------)

ä¸å†æµªè´¹æ—¶é—´ï¼Œè®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ä¸€ä¸‹åŠŸèƒ½è°ƒç”¨æ˜¯ä»€ä¹ˆï¼

# åŠŸèƒ½è°ƒç”¨çš„ç»“æ„

å€Ÿé‰´[Geminiçš„åŠŸèƒ½è°ƒç”¨æ–‡æ¡£](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling)ï¼ŒåŠŸèƒ½è°ƒç”¨å…·æœ‰ä»¥ä¸‹ç»“æ„ï¼Œåœ¨OpenAIä¸­ä¹Ÿé€‚ç”¨

![](../Images/9793c45c8d104b8ac96e104541df9644.png)

æ¥è‡ª[Geminiçš„åŠŸèƒ½è°ƒç”¨æ–‡æ¡£](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling)çš„å›¾ç‰‡

1.  ç”¨æˆ·å‘åº”ç”¨ç¨‹åºå‘å‡ºæç¤º

1.  åº”ç”¨ç¨‹åºä¼ é€’ç”¨æˆ·æä¾›çš„æç¤ºä»¥åŠåŠŸèƒ½å£°æ˜ï¼Œè¿™äº›åŠŸèƒ½å£°æ˜æ˜¯å¯¹æ¨¡å‹å¯èƒ½ä½¿ç”¨çš„å·¥å…·çš„æè¿°

1.  åŸºäºåŠŸèƒ½å£°æ˜ï¼Œæ¨¡å‹å»ºè®®ä½¿ç”¨çš„å·¥å…·å’Œç›¸å…³è¯·æ±‚å‚æ•°ã€‚**æ³¨æ„ï¼Œæ¨¡å‹ä»…è¾“å‡ºå»ºè®®çš„å·¥å…·å’Œå‚æ•°ï¼Œå¹¶ä¸ä¼šå®é™…è°ƒç”¨è¿™äº›åŠŸèƒ½**

1.  & 5\. æ ¹æ®å“åº”ï¼Œåº”ç”¨ç¨‹åºè°ƒç”¨ç›¸å…³çš„API

6\. & 7\. æ¥è‡ªAPIçš„å“åº”å†æ¬¡ä¼ å…¥æ¨¡å‹ï¼Œè¾“å‡ºä¸€ä¸ªäººç±»å¯è¯»çš„å“åº”

8\. åº”ç”¨ç¨‹åºå°†æœ€ç»ˆå“åº”è¿”å›ç»™ç”¨æˆ·ï¼Œç„¶åä»ç¬¬1æ­¥å¼€å§‹é‡å¤ã€‚

è¿™çœ‹èµ·æ¥å¯èƒ½æœ‰äº›å¤æ‚ï¼Œä½†è¿™ä¸ªæ¦‚å¿µå°†é€šè¿‡ç¤ºä¾‹è¯¦ç»†è¯´æ˜

# æ¶æ„

åœ¨æ·±å…¥ä»£ç ä¹‹å‰ï¼Œå…ˆç®€è¦è¯´æ˜ä¸€ä¸‹æ¼”ç¤ºåº”ç”¨ç¨‹åºçš„æ¶æ„

## **è§£å†³æ–¹æ¡ˆ**

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºæ¸¸å®¢è®¿é—®é…’åº—æ„å»ºä¸€ä¸ªåŠ©æ‰‹ã€‚è¯¥åŠ©æ‰‹å¯ä»¥è®¿é—®ä»¥ä¸‹å·¥å…·ï¼Œä½¿å…¶èƒ½å¤Ÿè®¿é—®å¤–éƒ¨åº”ç”¨ç¨‹åºã€‚

+   `get_items`ã€`purchase_item`ï¼šé€šè¿‡APIè¿æ¥åˆ°å­˜å‚¨åœ¨æ•°æ®åº“ä¸­çš„äº§å“ç›®å½•ï¼Œåˆ†åˆ«ç”¨äºæ£€ç´¢å•†å“åˆ—è¡¨å’Œè¿›è¡Œè´­ä¹°

+   `rag_pipeline_func`ï¼šé€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰è¿æ¥åˆ°æ–‡æ¡£å­˜å‚¨ï¼Œä»éç»“æ„åŒ–æ–‡æœ¬ï¼ˆä¾‹å¦‚é…’åº—çš„å®£ä¼ å†Œï¼‰ä¸­è·å–ä¿¡æ¯

![](../Images/aa901baf05ab30875134a9a0b958aa14.png)

## **æŠ€æœ¯æ ˆ**

+   **åµŒå…¥æ¨¡å‹**ï¼š[all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

+   **å‘é‡æ•°æ®åº“**ï¼š[Haystackçš„InMemoryDocumentStore](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore)

+   **LLM**ï¼š[é€šè¿‡OpenRouterè®¿é—®çš„GPT-4 Turbo](https://openrouter.ai/models/openai/gpt-4-1106-preview)ã€‚é€šè¿‡OpenRouterï¼Œä½ å¯ä»¥åœ¨é¦™æ¸¯æ— VPNè®¿é—®ä¸åŒçš„LLM APIã€‚æ­¤æµç¨‹å¯ä»¥é€šè¿‡ç¨å¾®ä¿®æ”¹ä»£ç ï¼Œä½¿ç”¨å…¶ä»–æ”¯æŒå‡½æ•°è°ƒç”¨çš„LLMï¼ˆä¾‹å¦‚Geminiï¼‰è¿›è¡Œé€‚é…

+   **LLMæ¡†æ¶**ï¼š[Haystack](https://haystack.deepset.ai/)å› å…¶æ˜“ç”¨æ€§ã€å‡ºè‰²çš„æ–‡æ¡£å’Œç®¡é“æ„å»ºçš„é€æ˜æ€§è€Œè¢«é€‰ä¸­ã€‚æœ¬æ•™ç¨‹å®é™…ä¸Šæ˜¯ä»–ä»¬[ç²¾å½©æ•™ç¨‹](https://haystack.deepset.ai/tutorials/40_building_chat_application_with_function_calling)çš„å»¶ä¼¸ï¼Œä¸»é¢˜ç›¸åŒ

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼

# ç¤ºä¾‹åº”ç”¨

## å‡†å¤‡å·¥ä½œ

è®¿é—®[Github](https://github.com/yip-kl/llm_function_calling_demo)æ¥å…‹éš†æˆ‘çš„ä»£ç ã€‚ä»¥ä¸‹å†…å®¹å¯ä»¥åœ¨`function_calling_demo` Notebookä¸­æ‰¾åˆ°

è¯·å…ˆåˆ›å»ºå¹¶æ¿€æ´»ä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œç„¶åé€šè¿‡`pip install -r requirements.txt`å®‰è£…æ‰€éœ€çš„åŒ…

## **åˆå§‹åŒ–**

æˆ‘ä»¬é¦–å…ˆè¿æ¥åˆ°OpenRouterã€‚æˆ–è€…ï¼Œä½¿ç”¨åŸå§‹çš„`OpenAIChatGenerator`ï¼Œå¦‚æœæ²¡æœ‰è¦†ç›–`api_base_url`ï¼Œä¹Ÿå¯ä»¥å·¥ä½œï¼Œå‰ææ˜¯ä½ æœ‰OpenAIçš„APIå¯†é’¥

```py
import os
from dotenv import load_dotenv
from haystack.components.generators.chat import OpenAIChatGenerator
from haystack.utils import Secret
from haystack.dataclasses import ChatMessage
from haystack.components.generators.utils import print_streaming_chunk

# Set your API key as environment variable before executing this
load_dotenv()
OPENROUTER_API_KEY = os.environ.get('OPENROUTER_API_KEY')

chat_generator = OpenAIChatGenerator(api_key=Secret.from_env_var("OPENROUTER_API_KEY"),
  api_base_url="https://openrouter.ai/api/v1",
  model="openai/gpt-4-turbo-preview",
        streaming_callback=print_streaming_chunk)
```

ç„¶åæˆ‘ä»¬æµ‹è¯•æ˜¯å¦å¯ä»¥æˆåŠŸè°ƒç”¨`chat_generator`

```py
chat_generator.run(messages=[ChatMessage.from_user("Return this text: 'test'")])
```

```py
---------- The response should look like this ----------
{'replies': [ChatMessage(content="'test'", role=<ChatRole.ASSISTANT: 'assistant'>, name=None, meta={'model': 'openai/gpt-4-turbo-preview', 'index': 0, 'finish_reason': 'stop', 'usage': {}})]}
```

## æ­¥éª¤1ï¼šå»ºç«‹æ•°æ®å­˜å‚¨

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å»ºç«‹äº†åº”ç”¨ç¨‹åºä¸ä¸¤ä¸ªæ•°æ®æºä¹‹é—´çš„è¿æ¥ï¼š**æ–‡æ¡£å­˜å‚¨**ç”¨äºéç»“æ„åŒ–æ–‡æœ¬ï¼Œ**åº”ç”¨æ•°æ®åº“**é€šè¿‡APIè¿æ¥

**ä½¿ç”¨ç®¡é“ç´¢å¼•æ–‡æ¡£**

æˆ‘ä»¬åœ¨`documents`ä¸­æä¾›æ ·æœ¬æ–‡æœ¬ï¼Œä¾›æ¨¡å‹æ‰§è¡Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€‚è¿™äº›æ–‡æœ¬è¢«è½¬æ¢ä¸ºåµŒå…¥å¹¶å­˜å‚¨åœ¨å†…å­˜æ–‡æ¡£å­˜å‚¨ä¸­

```py
from haystack import Pipeline, Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.writers import DocumentWriter
from haystack.components.embedders import SentenceTransformersDocumentEmbedder

# Sample documents
documents = [
    Document(content="Coffee shop opens at 9am and closes at 5pm."),
    Document(content="Gym room opens at 6am and closes at 10pm.")
]

# Create the document store
document_store = InMemoryDocumentStore()

# Create a pipeline to turn the texts into embeddings and store them in the document store
indexing_pipeline = Pipeline()
indexing_pipeline.add_component(
    "doc_embedder", SentenceTransformersDocumentEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
)
indexing_pipeline.add_component("doc_writer", DocumentWriter(document_store=document_store))

indexing_pipeline.connect("doc_embedder.documents", "doc_writer.documents")

indexing_pipeline.run({"doc_embedder": {"documents": documents}})
```

å®ƒåº”è¯¥è¾“å‡ºä¸æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„`documents`æ ·æœ¬ç›¸å¯¹åº”çš„å†…å®¹

```py
{'doc_writer': {'documents_written': 2}}
```

**å¯åŠ¨APIæœåŠ¡å™¨**

ä½¿ç”¨Flaskåˆ›å»ºçš„APIæœåŠ¡å™¨ä½äº`db_api.py`ï¼Œç”¨äºè¿æ¥SQLiteã€‚è¯·é€šè¿‡åœ¨ç»ˆç«¯è¿è¡Œ`python db_api.py`æ¥å¯åŠ¨å®ƒ

![](../Images/7036bc280c989f445aeae16d0544b7ed.png)

å¦‚æœæˆåŠŸæ‰§è¡Œï¼Œè¿™å°†åœ¨ç»ˆç«¯æ˜¾ç¤º

è¿˜è¦æ³¨æ„ï¼Œä¸€äº›åˆå§‹æ•°æ®å·²æ·»åŠ åˆ°`db_api.py`ä¸­

![](../Images/9adc825085a9c02489dc32ff3bf6fad1.png)

æ•°æ®åº“ä¸­çš„ç¤ºä¾‹æ•°æ®

## æ­¥éª¤2ï¼šå®šä¹‰å‡½æ•°

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºæ¨¡å‹å‡†å¤‡å®é™…çš„å‡½æ•°ï¼Œä»¥ä¾¿åœ¨è°ƒç”¨å‡½æ•°åï¼ˆå¦‚**å‡½æ•°è°ƒç”¨ç»“æ„**ä¸­æè¿°çš„ç¬¬4-5æ­¥ï¼‰è¿›è¡Œè°ƒç”¨

**RAGåŠŸèƒ½**

å³`rag_pipeline_func`ã€‚è¿™æ˜¯è®©æ¨¡å‹é€šè¿‡æœç´¢å­˜å‚¨åœ¨æ–‡æ¡£å­˜å‚¨ä¸­çš„æ–‡æœ¬æ¥æä¾›ç­”æ¡ˆã€‚æˆ‘ä»¬é¦–å…ˆå°†RAGæ£€ç´¢å®šä¹‰ä¸ºHaystackç®¡é“

```py
from haystack.components.embedders import SentenceTransformersTextEmbedder
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
from haystack.components.builders import PromptBuilder
from haystack.components.generators import OpenAIGenerator

template = """
Answer the questions based on the given context.

Context:
{% for document in documents %}
    {{ document.content }}
{% endfor %}
Question: {{ question }}
Answer:
"""
rag_pipe = Pipeline()
rag_pipe.add_component("embedder", SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2"))
rag_pipe.add_component("retriever", InMemoryEmbeddingRetriever(document_store=document_store))
rag_pipe.add_component("prompt_builder", PromptBuilder(template=template))
# Note to llm: We are using OpenAIGenerator, not the OpenAIChatGenerator, because the latter only accepts List[str] as input and cannot accept prompt_builder's str output
rag_pipe.add_component("llm", OpenAIGenerator(api_key=Secret.from_env_var("OPENROUTER_API_KEY"),
  api_base_url="https://openrouter.ai/api/v1",
  model="openai/gpt-4-turbo-preview"))

rag_pipe.connect("embedder.embedding", "retriever.query_embedding")
rag_pipe.connect("retriever", "prompt_builder.documents")
rag_pipe.connect("prompt_builder", "llm")
```

æµ‹è¯•å‡½æ•°æ˜¯å¦æ­£å¸¸å·¥ä½œ

```py
query = â€œWhen does the coffee shop open?â€
rag_pipe.run({"embedder": {"text": query}, "prompt_builder": {"question": query}})
```

è¿™åº”è¯¥ä¼šäº§ç”Ÿä»¥ä¸‹è¾“å‡ºã€‚æ³¨æ„ï¼Œæ¨¡å‹ç»™å‡ºçš„`replies`æ¥è‡ªæˆ‘ä»¬ä¹‹å‰æä¾›çš„æ ·æœ¬æ–‡æ¡£

```py
{'llm': {'replies': ['The coffee shop opens at 9am.'],
  'meta': [{'model': 'openai/gpt-4-turbo-preview',
    'index': 0,
    'finish_reason': 'stop',
    'usage': {'completion_tokens': 9,
     'prompt_tokens': 60,
     'total_tokens': 69,
     'total_cost': 0.00087}}]}}
```

ç„¶åæˆ‘ä»¬å¯ä»¥å°†`rag_pipe`è½¬åŒ–ä¸ºä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°ä»…æä¾›`replies`ï¼Œè€Œä¸åŠ å…¥å…¶ä»–ç»†èŠ‚

```py
def rag_pipeline_func(query: str):
    result = rag_pipe.run({"embedder": {"text": query}, "prompt_builder": {"question": query}})

    return {"reply": result["llm"]["replies"][0]}
```

**APIè°ƒç”¨**

æˆ‘ä»¬å®šä¹‰äº†`get_items`å’Œ`purchase_item`å‡½æ•°ï¼Œç”¨äºä¸æ•°æ®åº“äº¤äº’

```py
# Flask's default local URL, change it if necessary
db_base_url = 'http://127.0.0.1:5000'

# Use requests to get the data from the database
import requests
import json

# get_categories is supplied as part of the prompt, it is not used as a tool
def get_categories():
    response = requests.get(f'{db_base_url}/category')
    data = response.json()
    return data

def get_items(ids=None,categories=None):
    params = {
        'id': ids,
        'category': categories,
    }
    response = requests.get(f'{db_base_url}/item', params=params)
    data = response.json()
    return data

def purchase_item(id,quantity):

    headers = {
    'Content-type':'application/json', 
    'Accept':'application/json'
    }

    data = {
        'id': id,
        'quantity': quantity,
    }
    response = requests.post(f'{db_base_url}/item/purchase', json=data, headers=headers)
    return response.json()
```

**å®šä¹‰å·¥å…·åˆ—è¡¨**

ç°åœ¨æˆ‘ä»¬å·²ç»å®šä¹‰äº†å‡½æ•°ï¼Œæˆ‘ä»¬éœ€è¦è®©æ¨¡å‹è¯†åˆ«è¿™äº›å‡½æ•°ï¼Œå¹¶é€šè¿‡æä¾›æè¿°æ¥æŒ‡ç¤ºå®ƒä»¬å¦‚ä½•ä½¿ç”¨ã€‚

ç”±äºæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨çš„æ˜¯OpenAIï¼Œ`tools`æ ¼å¼å¦‚ä¸‹ï¼Œéµå¾ª[OpenAIè¦æ±‚çš„æ ¼å¼](https://cookbook.openai.com/examples/function_calling_with_an_openapi_spec)

```py
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_items",
            "description": "Get a list of items from the database",
            "parameters": {
                "type": "object",
                "properties": {
                    "ids": {
                        "type": "string",
                        "description": "Comma separated list of item ids to fetch",
                    },
                    "categories": {
                        "type": "string",
                        "description": "Comma separated list of item categories to fetch",
                    },
                },
                "required": [],
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "purchase_item",
            "description": "Purchase a particular item",
            "parameters": {
                "type": "object",
                "properties": {
                    "id": {
                        "type": "string",
                        "description": "The given product ID, product name is not accepted here. Please obtain the product ID from the database first.",
                    },
                    "quantity": {
                        "type": "integer",
                        "description": "Number of items to purchase",
                    },
                },
                "required": [],
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "rag_pipeline_func",
            "description": "Get information from hotel brochure",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The query to use in the search. Infer this from the user's message. It should be a question or a statement",
                    }
                },
                "required": ["query"],
            },
        },
    }
]
```

## **æ­¥éª¤3ï¼šå°†æ‰€æœ‰å†…å®¹æ•´åˆ**

ç°åœ¨æˆ‘ä»¬æœ‰äº†å¿…è¦çš„è¾“å…¥æ¥æµ‹è¯•å‡½æ•°è°ƒç”¨ï¼åœ¨è¿™é‡Œæˆ‘ä»¬åšäº†å‡ ä»¶äº‹ï¼š

1.  æä¾›åˆå§‹æç¤ºç»™æ¨¡å‹ï¼Œä»¥ä¾¿ç»™å®ƒä¸€äº›ä¸Šä¸‹æ–‡

1.  æä¾›ä¸€ä¸ªç¤ºä¾‹ç”¨æˆ·ç”Ÿæˆçš„æ¶ˆæ¯

1.  æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å°†å·¥å…·åˆ—è¡¨ä¼ é€’ç»™`tools`ä¸­çš„èŠå¤©ç”Ÿæˆå™¨

```py
# 1\. Initial prompt
context = f"""You are an assistant to tourists visiting a hotel.
You have access to a database of items (which includes {get_categories()}) that tourists can buy, you also have access to the hotel's brochure.
If the tourist's question cannot be answered from the database, you can refer to the brochure.
If the tourist's question cannot be answered from the brochure, you can ask the tourist to ask the hotel staff.
"""
messages = [
    ChatMessage.from_system(context),
    # 2\. Sample message from user
    ChatMessage.from_user("Can I buy a coffee?"),
    ]

# 3\. Passing the tools list and invoke the chat generator
response = chat_generator.run(messages=messages, generation_kwargs= {"tools": tools})
response
```

```py
---------- Response ----------
{'replies': [ChatMessage(content='[{"index": 0, "id": "call_AkTWoiJzx5uJSgKW0WAI1yBB", "function": {"arguments": "{\\"categories\\":\\"Food and beverages\\"}", "name": "get_items"}, "type": "function"}]', role=<ChatRole.ASSISTANT: 'assistant'>, name=None, meta={'model': 'openai/gpt-4-turbo-preview', 'index': 0, 'finish_reason': 'tool_calls', 'usage': {}})]}
```

ç°åœ¨è®©æˆ‘ä»¬æ£€æŸ¥å“åº”ã€‚æ³¨æ„å‡½æ•°è°ƒç”¨æ˜¯å¦‚ä½•è¿”å›æ¨¡å‹é€‰æ‹©çš„å‡½æ•°ä»¥åŠè°ƒç”¨è¯¥å‡½æ•°çš„å‚æ•°çš„ã€‚

```py
function_call = json.loads(response["replies"][0].content)[0]
function_name = function_call["function"]["name"]
function_args = json.loads(function_call["function"]["arguments"])
print("Function Name:", function_name)
print("Function Arguments:", function_args)
```

```py
---------- Response ----------
Function Name: get_items
Function Arguments: {â€˜categoriesâ€™: â€˜Food and beveragesâ€™}
```

å½“å‡ºç°å¦ä¸€ä¸ªé—®é¢˜æ—¶ï¼Œæ¨¡å‹å°†ä½¿ç”¨å¦ä¸€ä¸ªæ›´ç›¸å…³çš„å·¥å…·

```py
# Another question
messages.append(ChatMessage.from_user("Where's the coffee shop?"))

# Invoke the chat generator, and passing the tools list
response = chat_generator.run(messages=messages, generation_kwargs= {"tools": tools})
function_call = json.loads(response["replies"][0].content)[0]
function_name = function_call["function"]["name"]
function_args = json.loads(function_call["function"]["arguments"])
print("Function Name:", function_name)
print("Function Arguments:", function_args)
```

```py
---------- Response ----------
Function Name: rag_pipeline_func
Function Arguments: {'query': "Where's the coffee shop?"}
```

å†æ¬¡æ³¨æ„ï¼Œè¿™é‡Œå¹¶æ²¡æœ‰å®é™…è°ƒç”¨å‡½æ•°ï¼Œè¿™æ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥è¦åšçš„ï¼

**è°ƒç”¨å‡½æ•°**

ç„¶åæˆ‘ä»¬å¯ä»¥å°†å‚æ•°ä¼ é€’åˆ°é€‰å®šçš„å‡½æ•°ä¸­

```py
## Find the correspoding function and call it with the given arguments
available_functions = {"get_items": get_items, "purchase_item": purchase_item,"rag_pipeline_func": rag_pipeline_func}
function_to_call = available_functions[function_name]
function_response = function_to_call(**function_args)
print("Function Response:", function_response)
```

```py
---------- Response ----------
Function Response: {'reply': 'The provided context does not specify a physical location for the coffee shop, only its operating hours. Therefore, I cannot determine where the coffee shop is located based on the given information.'}
```

ç„¶å`rag_pipeline_func`çš„å“åº”å¯ä»¥ä½œä¸ºä¸Šä¸‹æ–‡ä¼ é€’ç»™èŠå¤©ï¼Œé€šè¿‡å°†å…¶é™„åŠ åˆ°`messages`ä¸‹ï¼Œä¾›æ¨¡å‹æä¾›æœ€ç»ˆç­”æ¡ˆ

```py
messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))
response = chat_generator.run(messages=messages)
response_msg = response["replies"][0]

print(response_msg.content)
```

```py
---------- Response ----------
For the location of the coffee shop within the hotel, I recommend asking the hotel staff directly. They will be able to guide you to it accurately.
```

æˆ‘ä»¬ç°åœ¨å·²ç»å®Œæˆäº†èŠå¤©å¾ªç¯ï¼

## æ­¥éª¤4ï¼šè½¬å˜ä¸ºäº’åŠ¨èŠå¤©

ä¸Šé¢çš„ä»£ç å±•ç¤ºäº†å¦‚ä½•è¿›è¡Œå‡½æ•°è°ƒç”¨ï¼Œä½†æˆ‘ä»¬æƒ³æ›´è¿›ä¸€æ­¥ï¼Œå°†å…¶è½¬åŒ–ä¸ºäº’åŠ¨èŠå¤©

è¿™é‡Œæˆ‘å±•ç¤ºäº†ä¸¤ç§æ–¹æ³•ï¼šä»æ›´åŸå§‹çš„`input()`ï¼Œå®ƒå°†å¯¹è¯æ‰“å°åˆ°ç¬”è®°æœ¬æœ¬èº«ï¼Œåˆ°é€šè¿‡**Streamlit**æ¸²æŸ“å®ƒï¼Œæä¾›ç±»ä¼¼ChatGPTçš„UI

`**input()**` **å¾ªç¯**

è¯¥ä»£ç æ¥è‡ª[Haystackçš„æ•™ç¨‹](https://haystack.deepset.ai/tutorials/40_building_chat_application_with_function_calling)ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿå¿«é€Ÿæµ‹è¯•æ¨¡å‹ã€‚*æ³¨æ„ï¼šæ­¤åº”ç”¨ç¨‹åºæ˜¯ä¸ºäº†å±•ç¤ºå‡½æ•°è°ƒç”¨çš„æ¦‚å¿µï¼Œè€Œéæ—¨åœ¨åšåˆ°å®Œç¾ç¨³å¥ï¼Œä¾‹å¦‚ä¸æ”¯æŒåŒæ—¶å¤„ç†å¤šä¸ªé¡¹ç›®çš„é¡ºåºã€æ²¡æœ‰å¹»æƒ³ç­‰ã€‚*

```py
import json
from haystack.dataclasses import ChatMessage, ChatRole

response = None
messages = [
    ChatMessage.from_system(context)
]

while True:
    # if OpenAI response is a tool call
    if response and response["replies"][0].meta["finish_reason"] == "tool_calls":
        function_calls = json.loads(response["replies"][0].content)

        for function_call in function_calls:
            ## Parse function calling information
            function_name = function_call["function"]["name"]
            function_args = json.loads(function_call["function"]["arguments"])

            ## Find the correspoding function and call it with the given arguments
            function_to_call = available_functions[function_name]
            function_response = function_to_call(**function_args)

            ## Append function response to the messages list using `ChatMessage.from_function`
            messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))

    # Regular Conversation
    else:
        # Append assistant messages to the messages list
        if not messages[-1].is_from(ChatRole.SYSTEM):
            messages.append(response["replies"][0])

        user_input = input("ENTER YOUR MESSAGE ğŸ‘‡ INFO: Type 'exit' or 'quit' to stop\n")
        if user_input.lower() == "exit" or user_input.lower() == "quit":
            break
        else:
            messages.append(ChatMessage.from_user(user_input))

    response = chat_generator.run(messages=messages, generation_kwargs={"tools": tools})
```

![](../Images/a3322060f0f01905204135a0cec63711.png)

åœ¨IDEä¸­è¿è¡Œäº’åŠ¨èŠå¤©

è™½ç„¶å®ƒå¯ä»¥å·¥ä½œï¼Œä½†æˆ‘ä»¬å¯èƒ½å¸Œæœ›æœ‰ä¸€äº›çœ‹èµ·æ¥æ›´æ¼‚äº®çš„ä¸œè¥¿ã€‚

**Streamlitç•Œé¢**

Streamlitå°†æ•°æ®è„šæœ¬è½¬åŒ–ä¸ºå¯åˆ†äº«çš„Webåº”ç”¨ï¼Œè¿™ä¸ºæˆ‘ä»¬çš„åº”ç”¨æä¾›äº†æ•´æ´çš„UIã€‚ä¸Šé¢å±•ç¤ºçš„ä»£ç è¢«æ”¹ç¼–æˆä¸€ä¸ªStreamlitåº”ç”¨ï¼Œä½äºæˆ‘ä»“åº“çš„`streamlit`æ–‡ä»¶å¤¹ä¸‹ã€‚

ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿è¡Œï¼š

1.  å¦‚æœä½ è¿˜æ²¡æœ‰åšï¼Œä½¿ç”¨`python db_api.py`å¯åŠ¨APIæœåŠ¡å™¨

1.  å°†OPENROUTER_API_KEYè®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼Œä¾‹å¦‚`export OPENROUTER_API_KEY = â€˜@REPLACE WITH YOUR API KEYâ€™`ï¼Œå‡è®¾ä½ åœ¨Linuxä¸Šæˆ–ä½¿ç”¨git bashæ‰§è¡Œ

1.  åœ¨ç»ˆç«¯ä¸­ä½¿ç”¨`cd streamlit`å‘½ä»¤å¯¼èˆªåˆ°`streamlit`æ–‡ä»¶å¤¹

1.  é€šè¿‡`streamlit run app.py`è¿è¡ŒStreamlitã€‚ä½ çš„æµè§ˆå™¨ä¸­åº”è¯¥ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªæ–°æ ‡ç­¾é¡µæ¥è¿è¡Œè¯¥åº”ç”¨ç¨‹åºã€‚

å°±æ˜¯è¿™æ ·ï¼å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ã€‚

![](../Images/d47ce72177773e21a95ff14e3e8e5b1d.png)

Streamlit ç”¨æˆ·ç•Œé¢

**é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…æä¾›*
