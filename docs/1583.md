# 一种新的方法来检测大型语言模型的“虚构”幻觉

> [https://towardsdatascience.com/a-new-method-to-detect-confabulations-hallucinated-by-large-language-models-19444475fc7e?source=collection_archive---------13-----------------------#2024-06-25](https://towardsdatascience.com/a-new-method-to-detect-confabulations-hallucinated-by-large-language-models-19444475fc7e?source=collection_archive---------13-----------------------#2024-06-25)

## 通过使用第二个LLM计算语义熵，我们可以更好地标记那些由于缺乏知识而被认为不可靠的答案

[](https://lucianosphere.medium.com/?source=post_page---byline--19444475fc7e--------------------------------)[![LucianoSphere (Luciano Abriata, PhD)](../Images/a8ae3085d094749bbdd1169cca672b86.png)](https://lucianosphere.medium.com/?source=post_page---byline--19444475fc7e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--19444475fc7e--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--19444475fc7e--------------------------------) [LucianoSphere (Luciano Abriata, PhD)](https://lucianosphere.medium.com/?source=post_page---byline--19444475fc7e--------------------------------)

·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--19444475fc7e--------------------------------) ·阅读时间10分钟·2024年6月25日

--

![](../Images/0a3aed953512c31815f25a6ed9c30281.png)

图片由[Jametlene Reskp](https://unsplash.com/@reskp?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

正如你所知道的，人工智能在过去两年中取得了巨大进展，特别是在大型语言模型（LLMs）的开发和大规模部署方面。这些模型似乎具有令人印象深刻的推理和问答能力；然而，一个持久的挑战是它们倾向于“幻觉”，即生成带有虚假或随意内容的输出。这些幻觉可能带来严重后果，因此当前大量LLM开发的研究都在致力于尽可能抑制它们。为此，一篇新论文提出了一种名为“语义熵”的方法，能够识别和减轻由知识缺乏引起的特定类型幻觉，即所谓的“虚构”。不用多说，这对在多个应用场景中更可靠地使用LLM非常有用，尤其是在那些需要事实知识的应用中。值得注意的是，量化语义熵需要应用第二个LLM来评估LLM生成的序列之间的相似性。继续阅读以了解更多细节和一些示例。
