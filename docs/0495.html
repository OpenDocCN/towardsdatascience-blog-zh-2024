<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Forecast Time Series Data Using any Supervised Learning Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Forecast Time Series Data Using any Supervised Learning Model</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-forecast-time-series-data-using-any-supervised-learning-model-02dd62cd4bda?source=collection_archive---------0-----------------------#2024-02-22">https://towardsdatascience.com/how-to-forecast-time-series-data-using-any-supervised-learning-model-02dd62cd4bda?source=collection_archive---------0-----------------------#2024-02-22</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="c803" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Featurizing time series data into a standard tabular format for classical ML models and improving accuracy using AutoML</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@mturk24?source=post_page---byline--02dd62cd4bda--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Matthew Turk" class="l ep by dd de cx" src="../Images/2c000da20cc4e662d1fd21e0eca90988.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*9QZLgFRcpMNS32KrVyN8kQ@2x.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--02dd62cd4bda--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@mturk24?source=post_page---byline--02dd62cd4bda--------------------------------" rel="noopener follow">Matthew Turk</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--02dd62cd4bda--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 22, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">14</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/c143b6e4b58b16095c1e0dda4e22ce73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NtMw6jNfTUslB5cmD3ZkCw.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Source: <a class="af nc" href="https://www.vecteezy.com/members/ahasanaraakter" rel="noopener ugc nofollow" target="_blank">Ahasanara Akter</a></figcaption></figure><p id="4476" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This article delves into enhancing the process of forecasting daily energy consumption levels by transforming a time series dataset into a tabular format using open-source libraries. We explore the application of a popular multiclass classification model and leverage AutoML with Cleanlab Studio to significantly boost our out-of-sample accuracy.</p><p id="850c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The key takeaway from this article is that we can utilize more general methods to model a time series dataset by converting it to a tabular structure, and even find improvements in trying to predict this time series data.</p><h1 id="f393" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Take a Snapshot</h1><p id="cdb0" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">At a high level we will:</p><ul class=""><li id="7164" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pa pb pc bk">Establish a baseline accuracy by fitting a Prophet forecasting model on our time series data</li><li id="19fa" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk">Convert our time series data into a tabular format by using open-source featurization libraries and then will show that can outperform our Prophet model with a standard multiclass classification (Gradient Boosting) approach by a <strong class="nf fr">67% reduction in prediction error</strong> (increase by 38% raw percentage points in out-of-sample accuracy).</li><li id="2526" class="nd ne fq nf b go pd nh ni gr pe nk nl nm pf no np nq pg ns nt nu ph nw nx ny pa pb pc bk">Use an AutoML solution for multiclass classification <strong class="nf fr">resulted in a 42% reduction in prediction error</strong> (increase by 8% in raw percentage points in out-of-sample accuracy) compared to our Gradient Boosting model and <strong class="nf fr">resulted in a 81% reduction in prediction error</strong> (increase by 46% in raw percentage points in out-of-sample accuracy) compared to our Prophet forecasting model.</li></ul><p id="abc6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To run the code demonstrated in this article, here’s the <a class="af nc" href="https://github.com/mturk24/blog_posts/blob/main/time_series_automl/time_series_automl.ipynb" rel="noopener ugc nofollow" target="_blank">full notebook</a>.</p><h1 id="a74b" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Examine the Data</h1><p id="de5b" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">You can download the dataset <a class="af nc" href="https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption?select=PJME_hourly.csv" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="b0cc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The data represents PJM hourly energy consumption (in megawatts) on an hourly basis. PJM Interconnection LLC (PJM) is a regional transmission organization (RTO) in the United States. It is part of the Eastern Interconnection grid operating an electric transmission system serving many states.</p><p id="adfd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s take a look at our dataset. The data includes one datetime column (<code class="cx pi pj pk pl b">object</code> type), and the Megawatt Energy Consumption (<code class="cx pi pj pk pl b">float64</code>) type) column we are trying to forecast as a discrete variable (corresponding to the quartile of hourly energy consumption levels). Our aim is to train a time series forecasting model to be able to forecast the tomorrow’s daily energy consumption level falling into 1 of 4 levels: <code class="cx pi pj pk pl b">low</code> , <code class="cx pi pj pk pl b">below average</code> , <code class="cx pi pj pk pl b">above average</code> or <code class="cx pi pj pk pl b">high</code> (these levels were determined based on quartiles of the overall daily consumption distribution). We first demonstrate how to apply time-series forecasting methods like Prophet to this problem, but these are restricted to certain types of ML models suitable for time-series data. Next we demonstrate how to reframe this problem into a standard multiclass classification problem that we can apply any machine learning model to, and show how we can obtain superior forecasts by using powerful supervised ML.</p><p id="58fa" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We first convert this data into a average energy consumption at a daily level and rename the columns to the format that the Prophet forecasting model expects. These real-valued daily energy consumption levels are converted into quartiles, which is the value we are trying to predict. Our training data is shown below along with the quartile each daily energy consumption level falls into. The quartiles are computed using training data to prevent data leakage.</p><p id="e687" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We now show the training data below, which is the data we are using to fit our forecasting model.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pm"><img src="../Images/853f65f5e4e0336e3d5a2d015e420413.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*3ZnMIEzkIiEUf1lIe8xTOw.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Training data with quartile of daily energy consumption level included</figcaption></figure><p id="d4f5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We then show the test data below, which is the data we are evaluating our forecasting results against.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pn"><img src="../Images/7d8f8c364bbda6c109fefa760b02272d.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*WH3PCZXrlQHo11js08Ay5A.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Test data with quartile of daily energy consumption level included</figcaption></figure><h1 id="1ca9" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Train and Evaluate Prophet Forecasting Model</h1><p id="293e" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">As seen in the images above, we will use a date cutoff of <code class="cx pi pj pk pl b">2015-04-09</code> to end the range of our training data and start our test data at <code class="cx pi pj pk pl b">2015-04-10</code> . We compute quartile thresholds of our daily energy consumption using ONLY training data. This avoids data leakage - using out-of-sample data that is available only in the future.</p><p id="4537" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Next, we will forecast the daily PJME energy consumption level (in MW) for the duration of our test data and represent the forecasted values as a discrete variable. This variable represents which quartile the daily energy consumption level falls into, represented categorically as 1 (<code class="cx pi pj pk pl b">low</code>), 2 (<code class="cx pi pj pk pl b">below average</code>), 3 (<code class="cx pi pj pk pl b">above average</code>), or 4 (<code class="cx pi pj pk pl b">high</code>). For evaluation, we are going to use the <code class="cx pi pj pk pl b">accuracy_score</code> function from <code class="cx pi pj pk pl b">scikit-learn</code> to evaluate the performance of our models. Since we are formulating the problem this way, we are able to evaluate our model’s next-day forecasts (and compare future models) using classification accuracy.</p><pre class="mm mn mo mp mq po pl pp bp pq bb bk"><span id="67d0" class="pr oa fq pl b bg ps pt l pu pv">import numpy as np<br/>from prophet import Prophet<br/>from sklearn.metrics import accuracy_score<br/><br/># Initialize model and train it on training data<br/>model = Prophet()<br/>model.fit(train_df)<br/><br/># Create a dataframe for future predictions covering the test period<br/>future = model.make_future_dataframe(periods=len(test_df), freq='D')<br/>forecast = model.predict(future)<br/><br/># Categorize forecasted daily values into quartiles based on the thresholds<br/>forecast['quartile'] = pd.cut(forecast['yhat'], bins = [-np.inf] + list(quartiles) + [np.inf], labels=[1, 2, 3, 4])<br/><br/># Extract the forecasted quartiles for the test period<br/>forecasted_quartiles = forecast.iloc[-len(test_df):]['quartile'].astype(int)<br/><br/># Categorize actual daily values in the test set into quartiles<br/>test_df['quartile'] = pd.cut(test_df['y'], bins=[-np.inf] + list(quartiles) + [np.inf], labels=[1, 2, 3, 4])<br/>actual_test_quartiles = test_df['quartile'].astype(int)<br/><br/># Calculate the evaluation metrics<br/>accuracy = accuracy_score(actual_test_quartiles, forecasted_quartiles)<br/><br/># Print the evaluation metrics<br/>print(f'Accuracy: {accuracy:.4f}')<br/>&gt;&gt;&gt; 0.4249</span></pre><p id="9890" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The out-of-sample accuracy is quite poor at 43%. By modelling our time series this way, we limit ourselves to only use time series forecasting models (a limited subset of possible ML models). In the next section, we consider how we can more flexibly model this data by transforming the time-series into a standard tabular dataset via appropriate featurization. Once the time-series has been transformed into a standard tabular dataset, we’re able to employ any supervised ML model for forecasting this daily energy consumption data.</p><h1 id="29a3" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Convert time series data to tabular data through featurization</h1><p id="11b9" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Now we convert the time series data into a tabular format and featurize the data using the open source libraries <code class="cx pi pj pk pl b">sktime</code>, <code class="cx pi pj pk pl b">tsfresh</code>, and <code class="cx pi pj pk pl b">tsfel</code>. By employing libraries like these, we can extract a wide array of features that capture underlying patterns and characteristics of the time series data. This includes statistical, temporal, and possibly spectral features, which provide a comprehensive snapshot of the data's behavior over time. By breaking down time series into individual features, it becomes easier to understand how different aspects of the data influence the target variable.</p><p id="a8bc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><code class="cx pi pj pk pl b">TSFreshFeatureExtractor</code> is a feature extraction tool from the <code class="cx pi pj pk pl b">sktime</code> library that leverages the capabilities of <code class="cx pi pj pk pl b">tsfresh</code> to extract relevant features from time series data. <code class="cx pi pj pk pl b">tsfresh</code> is designed to automatically calculate a vast number of time series characteristics, which can be highly beneficial for understanding complex temporal dynamics. For our use case, we make use of the minimal and essential set of features from our <code class="cx pi pj pk pl b">TSFreshFeatureExtractor</code> to featurize our data.</p><p id="27ae" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><code class="cx pi pj pk pl b">tsfel</code>, or Time Series Feature Extraction Library, offers a comprehensive suite of tools for extracting features from time series data. We make use of a predefined config that allows for a rich set of features (e.g., statistical, temporal, spectral) to be constructed from the energy consumption time series data, capturing a wide range of characteristics that might be relevant for our classification task.</p><pre class="mm mn mo mp mq po pl pp bp pq bb bk"><span id="00e8" class="pr oa fq pl b bg ps pt l pu pv">import tsfel<br/>from sktime.transformations.panel.tsfresh import TSFreshFeatureExtractor<br/><br/># Define tsfresh feature extractor<br/>tsfresh_trafo = TSFreshFeatureExtractor(default_fc_parameters="minimal")<br/><br/># Transform the training data using the feature extractor<br/>X_train_transformed = tsfresh_trafo.fit_transform(X_train)<br/><br/># Transform the test data using the same feature extractor<br/>X_test_transformed = tsfresh_trafo.transform(X_test)<br/><br/># Retrieves a pre-defined feature configuration file to extract all available features<br/>cfg = tsfel.get_features_by_domain()<br/><br/># Function to compute tsfel features per day<br/>def compute_features(group):<br/>    # TSFEL expects a DataFrame with the data in columns, so we transpose the input group<br/>    features = tsfel.time_series_features_extractor(cfg, group, fs=1, verbose=0)<br/>    return features<br/><br/><br/># Group by the 'day' level of the index and apply the feature computation<br/>train_features_per_day = X_train.groupby(level='Date').apply(compute_features).reset_index(drop=True)<br/>test_features_per_day = X_test.groupby(level='Date').apply(compute_features).reset_index(drop=True)<br/><br/># Combine each featurization into a set of combined features for our train/test data<br/>train_combined_df = pd.concat([X_train_transformed, train_features_per_day], axis=1)<br/>test_combined_df = pd.concat([X_test_transformed, test_features_per_day], axis=1)</span></pre><p id="2977" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Next, we clean our dataset by removing features that showed a high correlation (above 0.8) with our target variable — average daily energy consumption levels — and those with null correlations. High correlation features can lead to overfitting, where the model performs well on training data but poorly on unseen data. Null-correlated features, on the other hand, provide no value as they lack a definable relationship with the target.</p><p id="c130" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">By excluding these features, we aim to improve model generalizability and ensure that our predictions are based on a balanced and meaningful set of data inputs.</p><pre class="mm mn mo mp mq po pl pp bp pq bb bk"><span id="a8d8" class="pr oa fq pl b bg ps pt l pu pv"># Filter out features that are highly correlated with our target variable<br/>column_of_interest = "PJME_MW__mean"<br/>train_corr_matrix = train_combined_df.corr()<br/>train_corr_with_interest = train_corr_matrix[column_of_interest]<br/>null_corrs = pd.Series(train_corr_with_interest.isnull())<br/>false_features = null_corrs[null_corrs].index.tolist()<br/><br/>columns_to_exclude = list(set(train_corr_with_interest[abs(train_corr_with_interest) &gt; 0.8].index.tolist() + false_features))<br/>columns_to_exclude.remove(column_of_interest)<br/><br/># Filtered DataFrame excluding columns with high correlation to the column of interest<br/>X_train_transformed = train_combined_df.drop(columns=columns_to_exclude)<br/>X_test_transformed = test_combined_df.drop(columns=columns_to_exclude)</span></pre><p id="5e4a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If we look at the first several rows of the training data now, this is a snapshot of what it looks like. We now have 73 features that were added from the time series featurization libraries we used. The label we are going to predict based on these features is the next day’s energy consumption level.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pw"><img src="../Images/b848d10e4e2b4dc50a8d87d45c91344c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P4_PI-8qP45YNdB7h0Y4mw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">First 5 rows of training data which is newly featurized and in a tabular format</figcaption></figure><p id="ffc6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">It’s important to note that we used a best practice of applying the featurization process separately for training and test data to avoid data leakage (and the held-out test data are our most recent observations).</p><p id="7821" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Also, we compute our discrete quartile value (using the quartiles we originally defined) using the following code to obtain our train/test energy labels, which is what our y_labels are.</p><pre class="mm mn mo mp mq po pl pp bp pq bb bk"><span id="6a2a" class="pr oa fq pl b bg ps pt l pu pv"># Define a function to classify each value into a quartile<br/>def classify_into_quartile(value):<br/>    if value &lt; quartiles[0]:<br/>        return 1  <br/>    elif value &lt; quartiles[1]:<br/>        return 2  <br/>    elif value &lt; quartiles[2]:<br/>        return 3  <br/>    else:<br/>        return 4  <br/><br/>y_train = X_train_transformed["PJME_MW__mean"].rename("daily_energy_level")<br/>X_train_transformed.drop("PJME_MW__mean", inplace=True, axis=1)<br/><br/>y_test = X_test_transformed["PJME_MW__mean"].rename("daily_energy_level")<br/>X_test_transformed.drop("PJME_MW__mean", inplace=True, axis=1)<br/><br/>energy_levels_train = y_train.apply(classify_into_quartile)<br/>energy_levels_test = y_test.apply(classify_into_quartile)</span></pre><h1 id="a22d" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Train and Evaluate GradientBoostingClassifier Model on featurized tabular data</h1><p id="8fb2" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Using our featurized tabular dataset, we can apply any supervised ML model to predict future energy consumption levels. Here we’ll use a Gradient Boosting Classifier (GBC) model, the weapon of choice for most data scientists operating on tabular data.</p><p id="942a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Our GBC model is instantiated from the <code class="cx pi pj pk pl b">sklearn.ensemble</code> module and configured with specific hyperparameters to optimize its performance and avoid overfitting.</p><pre class="mm mn mo mp mq po pl pp bp pq bb bk"><span id="7a53" class="pr oa fq pl b bg ps pt l pu pv">from sklearn.ensemble import GradientBoostingClassifier<br/><br/>gbc = GradientBoostingClassifier(<br/>    n_estimators=150,<br/>    learning_rate=0.1,<br/>    max_depth=4,<br/>    min_samples_leaf=20,<br/>    max_features='sqrt',<br/>    subsample=0.8,<br/>    random_state=42<br/>)<br/><br/>gbc.fit(X_train_transformed, energy_levels_train)<br/><br/><br/>y_pred_gbc = gbc.predict(X_test_transformed)<br/>gbc_accuracy = accuracy_score(energy_levels_test, y_pred_gbc)<br/>print(f'Accuracy: {gbc_accuracy:.4f}')<br/>&gt;&gt;&gt; 0.8075</span></pre><p id="7b6a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The out-of-sample accuracy of 81% is considerably better than our prior Prophet model results.</p><h1 id="9052" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Using AutoML to streamline things</h1><p id="27c8" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">Now that we’ve seen how to featurize the time-series problem and the benefits of applying powerful ML models like Gradient Boosting, a natural question emerges: Which supervised ML model should we apply? Of course, we could experiment with many models, tune their hyperparameters, and ensemble them together. An easier solution is to let AutoML handle all of this for us.</p><p id="66ac" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here we’ll use a simple AutoML solution provided in <a class="af nc" href="https://cleanlab.ai/" rel="noopener ugc nofollow" target="_blank">Cleanlab Studio</a>, which involves zero configuration. We just provide our tabular dataset, and the platform automatically trains many types of supervised ML models (including Gradient Boosting among others), tunes their hyperparameters, and determines which models are best to combine into a single predictor. Here’s all the code needed to train and deploy an AutoML supervised classifier:</p><pre class="mm mn mo mp mq po pl pp bp pq bb bk"><span id="8260" class="pr oa fq pl b bg ps pt l pu pv"><br/>from cleanlab_studio import Studio<br/><br/>studio = Studio()<br/>studio.create_project(<br/>    dataset_id=energy_forecasting_dataset,<br/>    project_name="ENERGY-LEVEL-FORECASTING",<br/>    modality="tabular",<br/>    task_type="multi-class",<br/>    model_type="regular",<br/>    label_column="daily_energy_level",<br/>)<br/><br/>model = studio.get_model(energy_forecasting_model)<br/>y_pred_automl = model.predict(test_data, return_pred_proba=True)</span></pre><p id="0e59" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Below we can see model evaluation estimates in the AutoML platform, showing all of the different types of ML models that were automatically fit and evaluated (including multiple Gradient Boosting models), as well as an ensemble predictor constructed by optimally combining their predictions.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk px"><img src="../Images/74c3bf0f045edd844f9b2651ce32701b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*Ihfgn-PZMerDWoN40zL99A.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">AutoML results across different types of models used</figcaption></figure><p id="d54d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After running inference on our test data to obtain the next-day energy consumption level predictions, we see the test accuracy is 89%, a 8% raw percentage points improvement compared to our previous Gradient Boosting approach.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk py"><img src="../Images/9ab4cd48956b723421b807d7b19d0c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iyq4ZT3kAHtJx1YBYJpSXw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">AutoML test accuracy on our daily energy consumption level data</figcaption></figure><h1 id="8455" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Conclusion</h1><p id="85e5" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">For our PJM daily energy consumption data, we found that transforming the data into a tabular format and featurizing it achieved a <strong class="nf fr">67% reduction in prediction error</strong> (increase by 38% in raw percentage points in out-of-sample accuracy) compared to our baseline accuracy established with our Prophet forecasting model.</p><p id="2dc9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We also tried an easy AutoML approach for multiclass classification, which <strong class="nf fr">resulted in a 42% reduction in prediction error</strong> (increase by 8% in raw percentage points in out-of-sample accuracy) compared to our Gradient Boosting model and <strong class="nf fr">resulted in a 81% reduction in prediction error</strong> (increase by 46% in raw percentage points in out-of-sample accuracy) compared to our Prophet forecasting model.</p><p id="4b0f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">By taking approaches like those illustrated above to model a time series dataset beyond the constrained approach of only considering forecasting methods, we can apply more general supervised ML techniques and achieve better results for certain types of forecasting problems.</p><p id="d8ca" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Unless otherwise noted, all images are by the author.</p></div></div></div></div>    
</body>
</html>