- en: The Accuracy vs Interpretability Trade-off Is a Lie
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确性与可解释性的权衡是一个谎言
- en: 原文：[https://towardsdatascience.com/the-accuracy-vs-interpretability-trade-off-is-a-lie-0bf89c84f5b3?source=collection_archive---------5-----------------------#2024-10-16](https://towardsdatascience.com/the-accuracy-vs-interpretability-trade-off-is-a-lie-0bf89c84f5b3?source=collection_archive---------5-----------------------#2024-10-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-accuracy-vs-interpretability-trade-off-is-a-lie-0bf89c84f5b3?source=collection_archive---------5-----------------------#2024-10-16](https://towardsdatascience.com/the-accuracy-vs-interpretability-trade-off-is-a-lie-0bf89c84f5b3?source=collection_archive---------5-----------------------#2024-10-16)
- en: Why, if we look at the bigger picture, black-box models are not more accurate
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么，从大局来看，黑盒模型并不更准确
- en: '[](https://conorosullyds.medium.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)[![Conor
    O''Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)
    [Conor O''Sullivan](https://conorosullyds.medium.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://conorosullyds.medium.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)[![Conor
    O''Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)
    [Conor O''Sullivan](https://conorosullyds.medium.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)
    ·7 min read·Oct 16, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0bf89c84f5b3--------------------------------)
    ·阅读时间：7分钟·2024年10月16日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c825d5b59c5d7e78ee67cff1bb29dfd0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c825d5b59c5d7e78ee67cff1bb29dfd0.png)'
- en: Photo by [Nathan Cima](https://unsplash.com/@nathan_cima?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Nathan Cima](https://unsplash.com/@nathan_cima?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: When I started as a data scientist, I was expecting to use state-of-the-art
    models. XGBoost, Neural Networks. These things are complex and interesting and
    surely they would drive improvements. Little did I know, the models faced a hurdle
    — explaining them to other people.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始做数据科学家时，我本以为会使用最先进的模型。XGBoost、神经网络。这些东西复杂且有趣，肯定能带来改进。然而，我并未料到，模型面临的一个难题是——如何向其他人解释它们。
- en: Who’d have thought you need to understand the decisions your automated systems
    make?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 谁能想到你需要理解你的自动化系统所做的决策？
- en: To my joy, I stumbled down the rabbit hole of [model agnostic methods](/what-are-model-agnostic-methods-387b0e8441ef).
    With these, I could have the best of both worlds. I could train black box models
    and then explain them using methods like [SHAP](/introduction-to-shap-with-python-d27edc23c454),
    [LIME](/a-deep-dive-on-lime-for-local-interpretations-872bea23952f), [PDPs](/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa),
    [ALEs](/deep-dive-on-accumulated-local-effect-plots-ales-with-python-0fc9698ed0ee)
    and [Friedman’s H-stat](/understanding-freidmans-h-statistic-h-stat-for-interactions-43fb5e31a586).
    We no longer need to trade accuracy for interpretability!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 令我高兴的是，我偶然走进了[与模型无关的方法](/what-are-model-agnostic-methods-387b0e8441ef)这个兔子洞。通过这些方法，我可以同时享有两全其美的效果。我可以训练黑盒模型，然后通过像[SHAP](/introduction-to-shap-with-python-d27edc23c454)、[LIME](/a-deep-dive-on-lime-for-local-interpretations-872bea23952f)、[PDPs](/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa)、[ALEs](/deep-dive-on-accumulated-local-effect-plots-ales-with-python-0fc9698ed0ee)和[Friedman’s
    H-stat](/understanding-freidmans-h-statistic-h-stat-for-interactions-43fb5e31a586)等方法来解释它们。我们不再需要为了可解释性而牺牲准确性！
- en: Not so fast. That thinking is flawed.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 不是那么快。那种思维是错误的。
- en: 'In our pursuit of best performance, we often miss the point of machine learning:
    that is, to make accurate predictions on new unseen data. Let’s discuss why complex
    models are not always the best way of achieving this. Even if we can explain them
    using other methods.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们追求最佳性能的过程中，我们常常忽视了机器学习的真正意义：即在新的未见数据上做出准确的预测。让我们来讨论一下，为什么复杂模型并不总是实现这一目标的最佳方法。即使我们可以通过其他方法来解释它们。
- en: What is the accuracy vs interpretability trade-off?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是准确性与可解释性之间的权衡？
