- en: Is Open Source the Best Path Towards AI Democratization?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源是实现AI民主化的最佳途径吗？
- en: 原文：[https://towardsdatascience.com/is-open-source-the-best-path-towards-ai-democratization-b62a1153dcd4?source=collection_archive---------11-----------------------#2024-06-25](https://towardsdatascience.com/is-open-source-the-best-path-towards-ai-democratization-b62a1153dcd4?source=collection_archive---------11-----------------------#2024-06-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/is-open-source-the-best-path-towards-ai-democratization-b62a1153dcd4?source=collection_archive---------11-----------------------#2024-06-25](https://towardsdatascience.com/is-open-source-the-best-path-towards-ai-democratization-b62a1153dcd4?source=collection_archive---------11-----------------------#2024-06-25)
- en: '*While the open-source model has democratized software, applying it to AI raises
    legal and ethical issues. What is the end goal of the OS AI movement?*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*尽管开源模型已经使软件民主化，但将其应用于AI时会引发法律和伦理问题。开源AI运动的最终目标是什么？*'
- en: '[](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[![Julius
    Cerniauskas](../Images/fdff5669f0b16936af3cb59bb4c14526.png)](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------)
    [Julius Cerniauskas](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[![Julius
    Cerniauskas](../Images/fdff5669f0b16936af3cb59bb4c14526.png)](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------)
    [Julius Cerniauskas](https://julius-c.medium.com/?source=post_page---byline--b62a1153dcd4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------)
    ·6 min read·Jun 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b62a1153dcd4--------------------------------)
    ·阅读时间：6分钟·2024年6月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/df87b28e8d652e618b3f9b5e4d88156b.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df87b28e8d652e618b3f9b5e4d88156b.png)'
- en: The race for the future of AI has just encountered a tiny bump on the road —
    the definition of “open-source.” The first time the general public heard there
    was conflict over this term was early spring, when Elon Musk, a co-founder of
    OpenAI, [sued OpenAI](https://www.reuters.com/legal/elon-musk-sues-openai-ceo-sam-altman-breach-contract-2024-03-01/)
    for breaching its original non-profit mission (months later, he decided to withdraw
    his claims, though).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: AI未来的竞争刚刚遇到了一点小障碍——“开源”的定义。公众第一次听到这个术语有争议是在春初，当时OpenAI的联合创始人埃隆·马斯克[起诉OpenAI](https://www.reuters.com/legal/elon-musk-sues-openai-ceo-sam-altman-breach-contract-2024-03-01/)违反了其最初的非盈利使命（尽管几个月后他决定撤回诉讼）。
- en: Indeed, for quite some time, OpenAI preached the word of the open-source community.
    However, this claim was widely critiqued, and a [recent report](https://pure.mpg.de/rest/items/item_3526897_1/component/file_3526898/content)
    showed that the underlying ChatGPT models are a closed system, with only an API
    remaining open to some extent. OpenAI wasn’t the only tech company trying to get
    on the “open-washing” train — Meta LLaMA and Google BERT were both marketed as
    “open-source AI.”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，OpenAI曾长期宣传开源社区的理念。然而，这一说法受到了广泛批评，最近的一份[报告](https://pure.mpg.de/rest/items/item_3526897_1/component/file_3526898/content)显示，底层的ChatGPT模型是一个封闭系统，只有API在某种程度上保持开放。OpenAI并非唯一一个试图加入“开源洗白”行列的科技公司——Meta的LLaMA和谷歌的BERT也都被宣传为“开源AI”。
- en: 'Unfortunately, the problem of branding a system as “open-source” when it’s
    actually not isn’t just about marketing: there are instances where tagging oneself
    as “open-source AI” can bring legal exemptions, so the risk of businesses abusing
    the term is real. To straighten things up, the Open Source Initiative (OSI), an
    independent non-profit that helped coin the definition of open-source software,
    has announced it will host a [global workshop series](https://opensource.org/blog/the-open-source-ai-definition-gets-closer-to-reality-with-a-global-workshop-series)
    to gather diverse input and push the definition of open-source AI to a final agreement.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，将一个系统标榜为“开源”而实际上并非如此的问题，不仅仅是营销问题：有些情况下，标榜为“开源人工智能”可以带来法律豁免，因此企业滥用这一术语的风险是真实存在的。为了解决这一问题，开源倡议（OSI）——一个帮助创造开源软件定义的独立非营利组织——宣布将举办一系列[全球研讨会](https://opensource.org/blog/the-open-source-ai-definition-gets-closer-to-reality-with-a-global-workshop-series)，以收集各方意见，并推动开源人工智能定义达成最终一致。
- en: While technocrats and developers are battling over the scope of the term, it
    is a good time to ask a question that might be slightly uncomfortable — is the
    open-source movement the best way to democratize AI and make this technology more
    transparent?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管技术专家和开发人员在争论这一术语的范围，但现在是提出一个可能略显不舒服的问题的时候——开源运动是否是民主化人工智能、让这项技术更加透明的最佳途径？
- en: Open-source software vs open-source AI
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源软件与开源人工智能
- en: Open-source software usually refers to a decentralized development process where
    the code is made publicly available for collaboration and modification by different
    peers. OSI has developed a clear [set of rules for open source definition](https://opensource.org/osd),
    from free redistribution and non-discrimination to unrestrictive licensing. However,
    there are a couple of sound reasons why these principles cannot be easily replanted
    to the field of AI.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 开源软件通常指的是一种去中心化的开发过程，在这个过程中，代码公开供不同的同行进行协作和修改。OSI（开源倡议）制定了一套明确的[开源定义规则](https://opensource.org/osd)，从自由再分发和非歧视到不受限制的许可。然而，有几个合理的原因说明这些原则无法轻易地移植到人工智能领域。
- en: First, most AI systems are built on vast training datasets, and this data is
    subject to different legal regimes, from copyright and privacy protection to trade
    secrets and various confidentiality measures. Thus, opening up the training data
    bears a risk of legal consequences. As [VP for AI research at Meta Joëlle Pineau](https://news.itsfoss.com/open-source-definition-ai/)
    has noted, current licensing schemes were not meant to work with software that
    leverages large amounts of data from a multitude of sources. However, leaving
    the data closed makes the AI system open-access but not open-source since there’s
    little anyone can do with the algorithmic architecture without having a glimpse
    into the training data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，大多数人工智能系统都是建立在庞大的训练数据集之上的，而这些数据受到不同法律体系的约束，包括版权、隐私保护、商业机密和各种保密措施。因此，开放训练数据存在法律风险。如[Meta公司人工智能研究副总裁Joëlle
    Pineau](https://news.itsfoss.com/open-source-definition-ai/)所指出，目前的许可方案并不是为处理利用来自多个来源的大量数据的软件而设计的。然而，将数据保持封闭，使得人工智能系统可以公开访问，但并非开源，因为没有看到训练数据，任何人都无法利用算法架构。
- en: 'Second, the number of contributors who participate in developing and deploying
    an AI system is much larger than that of software development, where there might
    be only one firm. In the case of AI, different contributors might be held liable
    for different parts and outputs of the AI system. However, it would be difficult
    to determine how to distribute the liability between different open-source contributors.
    Let’s take a hypothetical scenario: if the AI system based on the open-source
    model hallucinates outputs that prompt emotionally distressed people to harm themselves,
    who is the one responsible?'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，参与开发和部署人工智能系统的贡献者数量远远大于软件开发中的贡献者数量，后者可能只有一家企业。在人工智能的情况下，不同的贡献者可能会对人工智能系统的不同部分和输出承担责任。然而，要确定如何在不同的开源贡献者之间分配责任将是困难的。我们假设一个场景：如果基于开源模型的人工智能系统产生了误导性的输出，促使情绪困扰的人伤害自己，那么谁将为此负责？
- en: The risk of openness
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开放性的风险
- en: OSI bases its efforts on the argument that, in order to make some modifications
    to the AI model, one needs access to the underlying architecture, the training
    code, documentation, weighting factors, data preprocessing logic, and, of course,
    the data itself. As such, a truly open system should allow complete freedom to
    use and modify the systems, meaning that anyone can participate in the technology’s
    development. In the ideal world, this argument would be absolutely legitimate.
    The world, however, is not ideal.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: OSI的努力基于这样的论点：要对人工智能模型进行一些修改，必须访问其底层架构、训练代码、文档、加权因子、数据预处理逻辑，以及当然，数据本身。因此，一个真正开放的系统应该允许完全自由地使用和修改系统，这意味着任何人都可以参与技术的发展。在理想的世界里，这一论点是完全正当的。然而，世界并不理想。
- en: Recently, [OpenAI has acknowledged](https://www.technologyreview.com/2024/03/25/1090111/tech-industry-open-source-ai-definition-problem/)
    they are uncomfortable releasing powerful generative AI systems as open-source
    unless all risks are carefully assessed, including misuse and acceleration. It
    might be argued whether this is an honest consideration or a PR move, but the
    risks are indeed there. Acceleration is the risk we don’t even know how to tackle
    — this was clearly shown by the last two years’ rapid AI developments that left
    the legal and political community confused over a number of regulation questions
    and challenges.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，[OpenAI已承认](https://www.technologyreview.com/2024/03/25/1090111/tech-industry-open-source-ai-definition-problem/)除非经过仔细评估所有风险，包括滥用和加速，否则他们不愿意将强大的生成性人工智能系统作为开源发布。人们可能会争论这是否是真诚的考虑，还是一项公关举措，但风险确实存在。加速是我们甚至不知道如何应对的风险——这一点在过去两年的快速人工智能发展中得到了清晰体现，令法律和政治界在众多监管问题和挑战面前感到困惑。
- en: Misuse — be it for criminal or other purposes — is even harder to contain. As
    [RAND-financed research](https://www.rand.org/pubs/research_reports/RR3139-1.html)
    has shown, most future AI systems will probably be dual-use, meaning that the
    military will take and adapt commercially developed technologies instead of developing
    military AI from scratch. Therefore, the risk of open-source systems getting into
    the hands of undemocratic states and militant nonstate actors cannot be overrated.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 滥用——无论是用于犯罪还是其他目的——甚至更难以遏制。正如[RAND资助的研究](https://www.rand.org/pubs/research_reports/RR3139-1.html)所显示的那样，未来的大多数人工智能系统可能会是双重用途的，这意味着军方将会采用并改进商业开发的技术，而不是从零开始开发军事人工智能。因此，开源系统落入非民主国家和激进非国家行为者之手的风险不容忽视。
- en: Also, there are less tangible risks, such as increased bias and disinformation,
    that must be considered when releasing an AI system under open-source licenses.
    If the system is free to modify and play with, including the possibility to alter
    training data and training code, there is little the original AI provider can
    do to ensure the system will remain ethical, trustworthy, and responsible. Probably,
    it is why OSI has explicitly called these issues as “out of scope” when defining
    their mission. Thus, while open source may equalize the playing field, allowing
    smaller actors to benefit from AI innovation and drive it further, it also bears
    an inherent risk of making AI outputs less fair and accurate.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还存在一些更为无形的风险，比如偏见和虚假信息的增加，这些都必须在发布开源人工智能系统时予以考虑。如果该系统可以自由修改和操作，包括更改训练数据和训练代码的可能性，那么原始的人工智能提供者几乎无法做任何事情来确保系统保持道德、值得信赖和负责任。可能正是出于这个原因，OSI在定义其使命时明确将这些问题称为“超出范围”。因此，尽管开源可能平衡竞争环境，让小型参与者也能从人工智能创新中受益并推动其发展，但它也固有地带来了使人工智能输出变得不公平和不准确的风险。
- en: The use and abuse of the open-source model
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源模型的使用与滥用
- en: To summarize, it is yet unclear how the widely-defined open-source model might
    be applied to AI, which is mostly data, without inflicting serious risks. Opening
    AI systems would require novel legal frameworks, such as [Responsible AI Licenses](https://www.licenses.ai/)
    (RAIL), that would allow developers to prevent their work from being used unethically
    or irresponsibly.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，目前仍不清楚如何将广泛定义的开源模型应用于主要由数据构成的人工智能领域，而不会带来严重风险。开放人工智能系统将需要新的法律框架，例如[负责任的人工智能许可证](https://www.licenses.ai/)（RAIL），以便允许开发者防止他们的工作被不道德或不负责任地使用。
- en: It is not to say, however, that OSI’s mission to consolidate a single definition
    isn’t important for the future of AI innovation, but that importance primarily
    lies not in the quest for promoting innovation and democratization but in the
    necessity to ensure legal clarity and mitigate potential manipulations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是说OSI统一定义的使命对于AI创新的未来不重要，而是这种重要性主要不在于推动创新和民主化，而在于确保法律的清晰性并减少潜在的操控风险。
- en: Let’s take the example of the newly released [EU AI Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206&amp%3Bqid=1716811772119)
    — the first ever comprehensive AI development regulation. The AI Act provides
    explicit exceptions for open-source General-Purpose AI (GPAI) models, easing up
    the transparency and documentation requirements. These are the models that power
    most current consumer-oriented generative AI products, such as ChatGPT. The exemptions
    do not apply only if the model bears “systemic risk” or is profit-oriented.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以刚刚发布的[欧盟AI法案](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206&amp%3Bqid=1716811772119)为例——这是首部全面的AI发展法规。AI法案为开源通用人工智能（GPAI）模型提供了明确的例外，放宽了透明度和文档要求。这些模型驱动着大多数当前面向消费者的生成式AI产品，比如ChatGPT。只有当模型具有“系统性风险”或是以盈利为目的时，这些豁免才不适用。
- en: Under such circumstances, more (or less) permissive open-source licenses can
    actually act as a way to avoid transparency and documentation requirements, a
    behavior that is very likely having in mind the ongoing struggle of AI firms to
    acquire multifaceted training data without breaching copyright and data privacy
    laws. The industry must agree on a unanimous definition of “open-source” and impose
    this definition; without it, bigger players will determine what “open-source”
    means with their interests in mind.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，更加宽松（或更加严格）的开源许可证实际上可能成为一种规避透明度和文档要求的手段，这种行为很可能是考虑到AI公司在不违反版权和数据隐私法的情况下，获取多维度训练数据的持续斗争。行业必须就“开源”达成一致的定义并强制执行；否则，大型公司将根据自身利益来决定“开源”的含义。
- en: Democratizing data, not systems
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 民主化数据，而非系统
- en: As much as a clear definition is needed for legal purposes, it remains doubtful
    whether a widely-defined open-source approach can bring the anticipated technological
    advancements and level the playing field. AI systems are mostly built on data,
    and the difficulty of acquiring it on a large scale is the strongest competitive
    advantage of Big Tech, along with computing power.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管出于法律目的需要明确的定义，但是否广义定义的开源方法能够带来预期的技术进步并平衡竞争环境，仍然存疑。AI系统主要建立在数据之上，获取大规模数据的难度是大科技公司的最强竞争优势之一，此外还有计算能力。
- en: Making AI open-source won’t remove all structural barriers that small players
    face — a constant influx of data, proper computing power, and highly skilled developers
    and data scientists will still be needed to modify the system and train it further.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使AI开源并不能消除小型企业所面临的所有结构性障碍——仍然需要不断流入的数据、适当的计算能力以及高度熟练的开发人员和数据科学家来修改系统并进一步训练它。
- en: Preserving the open internet and open web data that is accessible to everyone
    might be a more important mission in the quest for AI democratization than pushing
    the open source agenda. Due to conflicting or outdated legal regimes, internet
    data today is fragmented, hindering innovation. Therefore, it is vital for governments
    and regulatory institutions to look for ways to rebalance such fields as copyright
    protection, making public data easier to acquire.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在追求AI民主化的过程中，保护开放互联网和所有人都能访问的开放网络数据可能比推动开源议程更为重要。由于法律制度的冲突或过时，今天的互联网数据是碎片化的，阻碍了创新。因此，政府和监管机构必须寻找方法，重新平衡诸如版权保护等领域，使公共数据更容易获取。
