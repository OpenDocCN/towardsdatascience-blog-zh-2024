["```py\n# create TPU node\ngcloud alpha compute tpus queued-resources create v5litepod-1-resource \\\n     --node-id v5litepod \\\n     --project <project-id> \\\n     --zone us-central1-a \\\n     --accelerator-type v5litepod-1 \\\n     --runtime-version v2-alpha-tpuv5-lite \\\n     --valid-until-duration 1d \\\n     --service-account <service-account> \\\n\n# check TPU node status (wait for state to be ACTIVE)\ngcloud alpha compute tpus queued-resources describe v5litepod-1-resource \\\n     --project <project-id> \\\n     --zone us-central1-a\n\n# SSH to TPU node\ngcloud alpha compute tpus tpu-vm ssh v5litepod \\\n     --project <project-id> \\\n     --zone  us-central1-a\n\n# install dependencies\npip install torch_xla[tpu] \\\n     -f https://storage.googleapis.com/libtpu-releases/index.html\npip install torch_xla[pallas]\npip install timm\n\n# run tests\npython train.py\n\n#exit ssh\nexit\n\n# delete TPU node\ngcloud alpha compute tpus queued-resources delete v5litepod-1-resource \\\n     --project <project-id> \\\n     --zone us-central1-a --force --quiet\n```", "```py\n# general imports\nimport os, time, functools\n# torch imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch_xla.core.xla_model as xm\n# custom kernel import\nfrom torch_xla.experimental.custom_kernel import flash_attention\n# timm imports\nfrom timm.layers import Mlp\nfrom timm.models.vision_transformer import VisionTransformer\n\nclass TPUAttentionBlock(nn.Module):\n    def __init__(\n            self,\n            dim: int = 768,\n            num_heads: int = 12,\n            attn_fn = None,\n            **kwargs\n    ) -> None:\n        super().__init__()\n        self.attn_fn = attn_fn\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n        self.norm1 = nn.LayerNorm(dim)\n        self.norm2 = nn.LayerNorm(dim)\n        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n        self.proj = nn.Linear(dim, dim)\n        self.mlp = Mlp(\n            in_features=dim,\n            hidden_features=dim * 4,\n        )\n\n    def forward(self, x_in: torch.Tensor) -> torch.Tensor:\n        x = self.norm1(x_in)\n\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim)\n        qkv = qkv.permute(2, 0, 3, 1, 4)\n        q, k, v = qkv.unbind(0)\n\n        if self.attn_fn is None:\n            attn = q @ k.transpose(-2, -1)\n            attn = attn.softmax(dim=-1)\n            x = attn @ v\n        else:\n            x = self.attn_fn(q, k, v)\n\n        x = x.transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = x + x_in\n        x = x + self.mlp(self.norm2(x))\n        return x\n```", "```py\ndef train(dataset, attn_fn=None):\n    device = xm.xla_device()\n\n    train_loader = DataLoader(\n        dataset,\n        batch_size=128,\n        num_workers=os.cpu_count(),\n        pin_memory=True\n    )\n\n    # configure the VisionTranformer in a manner that complies with the \n    # Pallas flash_attention kernel constraints\n    model = VisionTransformer(\n        block_fn=functools.partial(TPUAttentionBlock, attn_fn=attn_fn),\n        img_size=256,\n        class_token=False,\n        global_pool=\"avg\"\n    )\n\n    optimizer = torch.optim.SGD(model.parameters())\n    loss_fn = torch.nn.CrossEntropyLoss()\n\n    # copy the model to the TPU\n    model = model.to(device)\n\n    model.train()\n\n    t0 = time.perf_counter()\n    summ = 0\n    count = 0\n\n    for step, data in enumerate(train_loader):\n        # copy data to TPU\n        inputs = data[0].to(device=device, non_blocking=True)\n        label = data[1].to(device=device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n        with torch.autocast('xla', dtype=torch.bfloat16):\n            output = model(inputs)\n            loss = loss_fn(output, label)\n        loss.backward()\n        optimizer.step()\n        xm.mark_step()\n\n        # capture step time\n        batch_time = time.perf_counter() - t0\n        if step > 20:  # skip first steps\n            summ += batch_time\n            count += 1\n        t0 = time.perf_counter()\n        if step > 100:\n            break\n\n    print(f'average step time: {summ / count}')\n```", "```py\n# use random data\nclass FakeDataset(Dataset):\n    def __len__(self):\n        return 1000000\n\n    def __getitem__(self, index):\n        rand_image = torch.randn([3, 256, 256], dtype=torch.float32)\n        label = torch.tensor(data=index % 1024, dtype=torch.int64)\n        return rand_image, label\n\nds = FakeDataset()\n\nprint('PyTorch native')\ntrain(ds, attn_fn=None)\n\nprint('PyTorch SDPA')\ntrain(ds, attn_fn=functools.partial(F.scaled_dot_product_attention, scale=1.0))\n\nprint('Pallas flash_attention')\ntrain(ds, attn_fn=flash_attention)\n```", "```py\nimport functools, timeit\nimport jax\nimport jax.numpy as jnp\nfrom jax.experimental import pallas as pl\nfrom jax.experimental.pallas import tpu as pltpu\n\n# set to True to develop/debug on CPU\ninterpret = False\n\ndef matmul_kernel_int8(x_ref, y_ref, z_ref, acc_ref, *, nsteps):\n    @pl.when(pl.program_id(2) == 0)\n    def _():\n        acc_ref[...] = jnp.zeros_like(acc_ref)\n\n    acc_ref[...] += jnp.dot(\n        x_ref[...], y_ref[...], preferred_element_type=jnp.int32\n    )\n\n    @pl.when(pl.program_id(2) == nsteps - 1)\n    def _():\n        z_ref[...] = acc_ref[...]\n\n@functools.partial(jax.jit, static_argnames=['bm', 'bk', 'bn'])\ndef matmul_int8(\n        x: jax.Array,\n        y: jax.Array,\n        *,\n        bm: int = 128,\n        bk: int = 128,\n        bn: int = 128,\n):\n    m, k = x.shape\n    _, n = y.shape\n    return pl.pallas_call(\n        functools.partial(matmul_kernel_int8, nsteps=k // bk),\n        grid_spec=pltpu.PrefetchScalarGridSpec(\n            num_scalar_prefetch=0,\n            in_specs=[\n                pl.BlockSpec(block_shape=(bm, bk), \n                             index_map=lambda i, j, k: (i, k)),\n                pl.BlockSpec(block_shape=(bk, bn),\n                             index_map=lambda i, j, k: (k, j)),\n            ],\n            out_specs=pl.BlockSpec(block_shape=(bm, bn), \n                                   index_map=lambda i, j, k: (i, j)),\n            scratch_shapes=[pltpu.VMEM((bm, bn), jnp.int32)],\n            grid=(m // bm, n // bn, k // bk),\n        ),\n        out_shape=jax.ShapeDtypeStruct((m, n), jnp.int32),\n        compiler_params=dict(mosaic=dict(\n            dimension_semantics=(\"parallel\", \"parallel\", \"arbitrary\"))),\n        interpret=interpret\n    )(x, y) \n```", "```py\ndef benchmark(f, ntrials: int = 100):\n    def run(*args, **kwargs):\n        # Compile function first\n        jax.block_until_ready(f(*args, **kwargs))\n        # Time function\n        res=timeit.timeit(lambda: jax.block_until_ready(f(*args, **kwargs)),\n                             number=ntrials\n                              )\n        time = res/ntrials\n        # print(f\"Time: {time}\")\n        return time\n\n    return run\n\ndef analyze_matmul(m: int, k: int, n: int, dtype: jnp.dtype,\n                   mm_func):\n    x = jnp.ones((m, k), dtype=dtype)\n    y = jnp.ones((k, n), dtype=dtype)\n    time = benchmark(mm_func)(x, y)\n    print(\"Matmul time: \", time)\n    mm_ops = 2*m*k*n/time\n    v5e_ops = 394e12 if dtype == jnp.int8 else 197e12\n    print(f\"OP/s utilization: {mm_ops / v5e_ops * 100:.4f}%\")\n    print()\n\nprint(\"bfloat16 Pallas matmul\")\nmm = functools.partial(matmul, bm=512, bk=1024, bn=1024)\nanalyze_matmul(8192, 8192, 8192, jnp.bfloat16, mm)\n\nprint(\"int8 Pallas matmul\")\nmm = functools.partial(matmul_int8, bm=512, bk=1024, bn=1024)\nanalyze_matmul(8192, 8192, 8192, jnp.int8, mm)\n\nprint(\"XLA int8 matmul\")\nmm = functools.partial(jnp.matmul, preferred_element_type=jnp.int32)\nanalyze_matmul(8192, 8192, 8192, jnp.int8, mm)\n```", "```py\nimport timeit\nimport jax\nfrom jax.experimental import pallas as pl\nimport jax.numpy as jnp\n\n# set to True to develop/debug on CPU\ninterpret = False\n\n# perform giou on a single block\ndef giou_kernel(preds_left_ref,\n                preds_top_ref,\n                preds_right_ref,\n                preds_bottom_ref,\n                targets_left_ref,\n                targets_top_ref,\n                targets_right_ref,\n                targets_bottom_ref,\n                output_ref):\n    epsilon = 1e-5\n\n    # copy tensors into local memory\n    preds_left = preds_left_ref[...]\n    preds_top = preds_top_ref[...]\n    preds_right = preds_right_ref[...]\n    preds_bottom = preds_bottom_ref[...]\n\n    gt_left = targets_left_ref[...]\n    gt_top = targets_top_ref[...]\n    gt_right = targets_right_ref[...]\n    gt_bottom = targets_bottom_ref[...]\n\n    # Compute the area of each box\n    area1 = (preds_right - preds_left) * (preds_bottom - preds_top)\n    area2 = (gt_right - gt_left) * (gt_bottom - gt_top)\n\n    # Compute the intersection\n    left = jnp.maximum(preds_left, gt_left)\n    top = jnp.maximum(preds_top, gt_top)\n    right = jnp.minimum(preds_right, gt_right)\n    bottom = jnp.minimum(preds_bottom, gt_bottom)\n\n    # intersection width and height\n    inter_w = jnp.maximum(right - left, 0)\n    inter_h = jnp.maximum(bottom - top, 0)\n\n    # intersection area\n    inter_area = inter_w * inter_h\n\n    # union of two boxes\n    union_area = area1 + area2 - inter_area\n\n    iou_val = inter_area / jnp.maximum(union_area, epsilon)\n\n    # Compute the smallest enclosing box\n    enclose_left = jnp.minimum(preds_left, gt_left)\n    enclose_top = jnp.minimum(preds_top, gt_top)\n    enclose_right = jnp.maximum(preds_right, gt_right)\n    enclose_bottom = jnp.maximum(preds_bottom, gt_bottom)\n\n    # enclosing box width and height\n    enclose_w = jnp.maximum(enclose_right - enclose_left, 0)\n    enclose_h = jnp.maximum(enclose_bottom - enclose_top, 0)\n\n    # enclosing box area\n    enclose_area = enclose_w * enclose_h\n\n    # Compute GIOU\n    delta_area = (enclose_area - union_area)\n    enclose_area = jnp.maximum(enclose_area, epsilon)\n    output_ref[...] = iou_val - delta_area / enclose_area\n\n@jax.jit\ndef batch_giou(preds, targets):\n    m, n, _ = preds.shape\n    output = pl.pallas_call(\n        giou_kernel,\n        out_shape=jax.ShapeDtypeStruct((m, n), preds.dtype),\n        in_specs=[pl.BlockSpec(block_shape=(128, 128),\n                               index_map=lambda i, j: (i, j))]*8,\n        out_specs=pl.BlockSpec(block_shape=(128, 128),\n                                index_map=lambda i, j: (i, j)),\n        grid=(m // 128, n // 128),\n        compiler_params=dict(mosaic=dict(\n            dimension_semantics=(\"parallel\", \"parallel\"))),\n        interpret=interpret\n    )(*jnp.unstack(preds, axis=-1), *jnp.unstack(targets, axis=-1))\n    return output\n```", "```py\ndef batched_box_iou(boxes1, boxes2):\n    epsilon = 1e-5\n\n    # Compute areas of both sets of boxes\n    area1 = (boxes1[..., 2]-boxes1[..., 0])*(boxes1[..., 3]-boxes1[..., 1])\n    area2 = (boxes2[..., 2]-boxes2[..., 0])*(boxes2[..., 3]-boxes2[..., 1])\n\n    # corners of intersection\n    lt = jnp.maximum(boxes1[..., :2], boxes2[..., :2])\n    rb = jnp.minimum(boxes1[..., 2:], boxes2[..., 2:])\n\n    # width and height of intersection\n    wh = jnp.clip(rb - lt, a_min=0)\n\n    # area of the intersection\n    inter = wh[..., 0] * wh[..., 1]\n\n    # union of the two boxes\n    union = area1 + area2 - inter\n    iou = inter / jnp.clip(union, a_min=epsilon)\n\n    # corners of enclosing box\n    lti = jnp.minimum(boxes1[..., :2], boxes2[..., :2])\n    rbi = jnp.maximum(boxes1[..., 2:], boxes2[..., 2:])\n\n    # Width and height of the enclosing box\n    whi = jnp.clip(rbi - lti, a_min=0)\n\n    # Area of the enclosing box\n    areai = jnp.clip(whi[..., 0] * whi[..., 1], a_min=epsilon)\n\n    # Generalized IoU\n    return iou - (areai - union) / areai\n```", "```py\nfrom jax import random\n\nbatch_size = 1024\nn_boxes = 256\nimg_size = 256\nboxes = []\nfor i in range(2):\n    k1, k2 = random.split(random.key(i), 2)\n\n    # Randomly generate box sizes and positions\n    box_sizes = random.randint(k1, shape=(batch_size, n_boxes, 2), minval=1, maxval=img_size)\n    top_left = random.randint(k2, shape=(batch_size, n_boxes, 2), minval=0, maxval=img_size - 1)\n    bottom_right = jnp.clip(top_left + box_sizes, 0, img_size - 1)\n\n    # Concatenate top-left and bottom-right coordinates\n    rand_boxes = jnp.concatenate((top_left, bottom_right), axis=2)\n\n    boxes.append(rand_boxes.astype(jnp.float32))\n\ntime = benchmark(batch_giou)(boxes[0], boxes[1])\nprint(f'Pallas kernel: {time}')\ntime = benchmark(batched_box_iou)(boxes[0], boxes[1])\nprint(f'JAX function: {time}')\ntime = benchmark(jax.jit(batched_box_iou))(boxes[0], boxes[1])\nprint(f'Jitted function: {time}')\n```"]