<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Exposing Jailbreak Vulnerabilities in LLM Applications with ARTKIT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Exposing Jailbreak Vulnerabilities in LLM Applications with ARTKIT</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exposing-jailbreak-vulnerabilities-in-llm-applications-with-artkit-d2df5f56ece8?source=collection_archive---------5-----------------------#2024-09-25">https://towardsdatascience.com/exposing-jailbreak-vulnerabilities-in-llm-applications-with-artkit-d2df5f56ece8?source=collection_archive---------5-----------------------#2024-09-25</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="ad1f" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Automated prompt-based testing to extract hidden passwords in the popular Gandalf challenge</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://kennethleungty.medium.com/?source=post_page---byline--d2df5f56ece8--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Kenneth Leung" class="l ep by dd de cx" src="../Images/2514dffb34529d6d757c0c4ec5f98334.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*dMs7hqFw5Rbh8d9KsvRogA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d2df5f56ece8--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://kennethleungty.medium.com/?source=post_page---byline--d2df5f56ece8--------------------------------" rel="noopener follow">Kenneth Leung</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d2df5f56ece8--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 25, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">4</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/230fce087f3a477a98c22383a35031b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gFxJXLcsMeHxJnob"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@tex450?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Matthew Ball</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="deb1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As large language models (LLMs) become more widely adopted across different industries and domains, significant security risks have emerged and intensified. Several of these key concerns include breaches of data privacy, the potential for biases, and the risk of information manipulation.</p><p id="8364" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The Open Worldwide Application Security Project recently published the <a class="af nc" href="https://owasp.org/www-project-top-10-for-large-language-model-applications/" rel="noopener ugc nofollow" target="_blank">ten most critical security risks</a> of LLM applications, as described below:</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="oa ob l"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Source: <a class="af nc" href="https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-slides-v1_1.pdf" rel="noopener ugc nofollow" target="_blank">OWASP Top 10 for LLM Applications v1.1</a></figcaption></figure><p id="674b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Identifying these risks is essential for ensuring that LLM applications continue to provide value in real-world situations while maintaining their safety, effectiveness, and robustness.</p><p id="b3ff" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In this article, we explore how to use the open-source <a class="af nc" href="https://github.com/BCG-X-Official/artkit" rel="noopener ugc nofollow" target="_blank">ARTKIT</a> framework to automatically evaluate security vulnerabilities of LLM applications using the popular Gandalf Challenge<strong class="nf fr"> </strong>as an illustrative example.</p><h2 id="ae8b" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">Contents</h2><blockquote class="ox oy oz"><p id="874c" class="nd ne pa nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><em class="fq">(1) </em><a class="af nc" href="#fc75" rel="noopener ugc nofollow"><em class="fq">About Prompt Injection Vulnerabilities</em></a><em class="fq"><br/>(2) </em><a class="af nc" href="#cae4" rel="noopener ugc nofollow"><em class="fq">Gandalf Challenge</em></a><em class="fq"><br/>(3) </em><a class="af nc" href="#ec2d" rel="noopener ugc nofollow"><em class="fq">Introducing ARTKIT</em></a><em class="fq"><br/>(4) </em><a class="af nc" href="#3d85" rel="noopener ugc nofollow"><em class="fq">Approach Overview</em></a><em class="fq"> <br/>(5) </em><a class="af nc" href="#15ac" rel="noopener ugc nofollow"><em class="fq">Step-by-Step Walkthrough</em></a></p></blockquote><p id="8090" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">You can find the codes in the accompanying <a class="af nc" href="https://github.com/kennethleungty/ARTKIT-Gandalf-Challenge" rel="noopener ugc nofollow" target="_blank">GitHub repo of this article</a>.</p></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="fc75" class="pj od fq bf oe pk pl gq oi pm pn gt om po pp pq pr ps pt pu pv pw px py pz qa bk">(1) About Prompt Injection Vulnerabilities</h1><p id="0501" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">A prompt injection vulnerability is a type of cyberattack that arises when attackers exploit an LLM with carefully crafted inputs, leading it to execute malicious instructions unintentionally.</p><p id="035d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Prompt injection attacks can be difficult to detect and can lead to serious consequences such as leakage of sensitive information, unauthorized access, and manipulation of decision-making processes.</p><p id="60b0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">It can be performed directly or indirectly:</p><h2 id="2766" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(i) Direct (Jailbreaking)</h2><ul class=""><li id="d752" class="nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny qg qh qi bk">Attackers directly modify underlying system prompts, thereby convincing the LLM system to disregard its safeguards. It allows attackers to generate harmful responses or exploit backend systems by interacting with insecure functions and data stores.</li><li id="5777" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><strong class="nf fr">Example</strong>: An attacker crafts prompts instructing the LLM to ignore the instructions in the original system prompts and instead return private information like passwords.</li></ul><h2 id="91a0" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(ii) Indirect</h2><ul class=""><li id="084a" class="nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny qg qh qi bk">Attackers manipulate external inputs (e.g., files, websites) that the LLM ingests, allowing them to control the LLM’s responses and actions, even if the injected text is invisible to users.</li><li id="19a2" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><strong class="nf fr">Example</strong>: An attacker uploads a document embedded with prompts—concealed in a zero-point font—instructing LLMs to evaluate the user’s resume as that of an exceptional job candidate. When the recruiter uses an LLM to assess the resume, it inadvertently showcases the candidate as highly qualified, thereby skewing the hiring process.</li></ul><blockquote class="ox oy oz"><p id="987b" class="nd ne pa nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">There are different types of prompt injection attacks, such as virtualization, obfuscation, and role-playing attacks. Details can be found <a class="af nc" href="https://www.lakera.ai/blog/guide-to-prompt-injection#prompt-injection-techniques-attack-types" rel="noopener ugc nofollow" target="_blank">here</a>.</p></blockquote></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="cae4" class="pj od fq bf oe pk pl gq oi pm pn gt om po pp pq pr ps pt pu pv pw px py pz qa bk">(2) Gandalf Challenge</h1><p id="fcc0" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">In this project, we attempt to automatically crack the <a class="af nc" href="https://gandalf.lakera.ai/" rel="noopener ugc nofollow" target="_blank"><strong class="nf fr">Gandalf Challenge</strong></a>, an interactive game that demonstrates the security vulnerabilities of LLM applications and highlights mitigation strategies.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qo"><img src="../Images/3c37ec2b522eb01071335a12740ac61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x1RMdsNiWYDg-9SRcCgaow.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Screenshot from publicly accessible Gandalf website, utilized under fair use</figcaption></figure><p id="acd8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The objective of the game is simple: use prompt engineering techniques to trick the LLM behind Gandalf’s interface to reveal a password.</p><p id="ef6c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The game consists of ten progressively difficult levels based on various defenses employed to prevent password disclosure, such as prompts instructing not to reveal the password, input guardrails that filter user prompts, and output guardrails that block responses containing passwords.</p></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="ec2d" class="pj od fq bf oe pk pl gq oi pm pn gt om po pp pq pr ps pt pu pv pw px py pz qa bk">(3) Introducing ARTKIT</h1><p id="4b96" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">As LLM systems become more commonplace, it is important to build user trust by ensuring that the models perform reliably even in adversarial conditions. This is where <strong class="nf fr">ARTKIT</strong> comes in handy in testing LLM systems for their proficiency, equitability, safety, and security.</p><p id="462d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">ARTKIT is an open-source framework for developing powerful automated end-to-end pipelines to test and evaluate LLM-based applications like chatbots and virtual assistants.</p><p id="1a58" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Its simplicity and flexibility in building fit-for-purpose pipelines make it an excellent tool for data scientists and engineers to conduct human-in-the-loop testing of LLM systems.</p><p id="975b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">For example, ARTKIT facilitates the effective use of LLMs to automate critical steps in <strong class="nf fr">red-teaming</strong>, such as generating adversarial prompts to exploit LLMs and analyzing their responses to uncover potential vulnerabilities.</p><blockquote class="ox oy oz"><p id="4341" class="nd ne pa nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The structured process of simulating attacks on a system to uncover its vulnerabilities and improve security is known as <strong class="nf fr">red-teaming</strong>. It allows organizations to strengthen their defenses against real-world threats by understanding potential breaches from an attacker’s perspective.</p></blockquote><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qp"><img src="../Images/7fe0d3eb40497cdea6525577914f96cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7kyqz3TqzLDC4CKt8FnIjg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">ARTKIT allows for the clever use of Generative AI (GenAI) models like LLMs as part of powerful pipelines to automate testing and evaluation of GenAI systems | Image used under <a class="af nc" href="https://github.com/BCG-X-Official/artkit/blob/1.0.x/LICENSE" rel="noopener ugc nofollow" target="_blank">Apache License 2.0</a></figcaption></figure><p id="4a63" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">One of ARTKIT’s standout features is its support for automated <a class="af nc" href="https://bcg-x-official.github.io/artkit/user_guide/generating_challenges/multi_turn_personas.html" rel="noopener ugc nofollow" target="_blank">multi-turn conversations</a> between an attacker system and a target system, which we will explore in this article.</p><p id="3dcf" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Given that LLM systems may struggle to maintain context and coherence over prolonged chats, the ability to scale the testing of extended, multi-turn interactions is crucial in identifying potential vulnerabilities.</p></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="3d85" class="pj od fq bf oe pk pl gq oi pm pn gt om po pp pq pr ps pt pu pv pw px py pz qa bk">(4) Approach Overview</h1><p id="2731" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">Here is an overview of our approach to demonstrating LLM jailbreaking:</p><ul class=""><li id="50d2" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qg qh qi bk">Conduct <strong class="nf fr">model-based</strong> <strong class="nf fr">red-teaming</strong>, where we use an LLM model to attack a target system (i.e., Gandalf)</li><li id="11e2" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk">Utilize ARTKIT and OpenAI’s GPT-4o to create an attacker LLM that employs password extraction techniques in its adversarial prompts while engaging in multi-turn conversations until the password is divulged.</li></ul><blockquote class="ox oy oz"><p id="602a" class="nd ne pa nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">OpenAI API keys can be found on the <a class="af nc" href="https://platform.openai.com/api-keys" rel="noopener ugc nofollow" target="_blank">API key page</a>.</p></blockquote></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="15ac" class="pj od fq bf oe pk pl gq oi pm pn gt om po pp pq pr ps pt pu pv pw px py pz qa bk">(5) Step-by-Step Walkthrough</h1><p id="b831" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">Let’s review the steps for using ARTKIT to extract passwords in the Gandalf challenge. You can find the accompanying Jupyter notebook <a class="af nc" href="https://github.com/kennethleungty/ARTKIT-Gandalf-Challenge/blob/main/gandalf_challenge.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="nf fr">here</strong></a>.</p><h2 id="0d57" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(5.1) Install ARTKIT</h2><p id="6fd1" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">ARTKIT can be installed via either PyPI (<code class="cx qq qr qs qt b">pip install artkit</code>) or Conda (<code class="cx qq qr qs qt b">conda install -c conda-forge artkit</code>). For this project, I am using <strong class="nf fr">version 1.0.7</strong>.</p><p id="179b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Because ARTKIT provides out-of-the-box support for popular model providers like OpenAI and Anthropic, there is no need to install those packages separately.</p><p id="85b1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Since we will utilize services from external model providers, it is recommended to store the access keys in <code class="cx qq qr qs qt b">.env</code> files and load them with <code class="cx qq qr qs qt b">python-dotenv</code>. The steps to do so can be found <a class="af nc" href="https://github.com/BCG-X-Official/artkit?tab=readme-ov-file#environment-variables" rel="noopener ugc nofollow" target="_blank">here</a>.</p></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="def0" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(5.2) Load Dependencies</h2><p id="83ea" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">We load the necessary dependencies and access keys:</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="2cdb" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(5.3) Create Class to Access Gandalf</h2><p id="81c2" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">To facilitate interaction with the LLM behind Gandalf, we create a class called <code class="cx qq qr qs qt b">GandalfChat</code> to encapsulate the necessary functionality to chat with Gandalf and handle message formatting and response processing.</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure><p id="38e4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s take a closer look at the<code class="cx qq qr qs qt b">GandalfChat</code> class:</p><ul class=""><li id="0d5c" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qg qh qi bk"><code class="cx qq qr qs qt b">GandalfChat</code> inherits from ARTKIT’s <code class="cx qq qr qs qt b">HTTPXChatConnector</code> class. Because Gandalf serves as a custom HTTP endpoint rather than a standalone LLM object, <code class="cx qq qr qs qt b">HTTPXChatConnector</code> enables us to establish a seamless connection to it</li><li id="7c9c" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><code class="cx qq qr qs qt b">Level</code> enumeration structures the difficulty levels so that they can be referenced using member names like <code class="cx qq qr qs qt b">LEVEL_01</code>.</li><li id="86ba" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><code class="cx qq qr qs qt b">build_request_arguments</code> formats the request to include arguments such as the difficulty level and input prompt.</li><li id="5a83" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><code class="cx qq qr qs qt b">parse_httpx_response</code> processes the LLM output based on the HTTP response object returned by the API.</li><li id="9e07" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><code class="cx qq qr qs qt b">get_default_api_key_env</code>provides the environment variable name where the API key for the chat system might be stored.</li></ul><p id="c587" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In addition to supporting custom systems like Gandalf, ARTKIT also offers pre-built classes for seamless connections to popular LLM platforms like OpenAI and AWS Bedrock.</p><p id="01fa" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This integration flexibility is another key strength of ARTKIT, enabling efficient red-teaming against mainstream LLMs.</p><blockquote class="ox oy oz"><p id="4622" class="nd ne pa nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Details about <code class="cx qq qr qs qt b"><em class="fq">HTTPXConnector</em></code> can be found in “Calling custom endpoints via HTTP”<em class="fq"> </em>section <a class="af nc" href="https://github.com/BCG-X-Official/artkit/blob/1.0.x/sphinx/source/user_guide/advanced_tutorials/creating_new_model_classes.ipynb" rel="noopener ugc nofollow" target="_blank">of this tutorial</a>.</p></blockquote></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="2220" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(5.4) Instantiate Chat Model Instance for Gandalf</h2><p id="715b" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">We create an instance of <code class="cx qq qr qs qt b">GandalfChat</code> as a model object containing the URL of the Gandalf API endpoint and the desired difficulty level. In this example, we will be tackling Level 4.</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure><p id="87b2" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We also utilize ARTKIT’s <code class="cx qq qr qs qt b">CachedChatModel</code> as a wrapper around <code class="cx qq qr qs qt b">GandalfChat</code> to enable the caching of responses into an SQLite database (<code class="cx qq qr qs qt b">gandalf_cache.db</code>).</p><p id="9258" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The advantage of storing these chat interactions is that we can minimize redundant API calls for repeated queries, which in turn speeds up response time and reduces costs.</p><p id="2d72" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We also set a 10-second cutoff using <code class="cx qq qr qs qt b">Timeout</code> to limit the wait time for API responses, ensuring our requests do not hang indefinitely.</p></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="94ca" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(5.5) Setup Attacker LLM</h2><p id="9d82" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">We use OpenAI’s GPT-4o model to jailbreak Gandalf, which we instantiate using the <code class="cx qq qr qs qt b">OpenAIChat</code> class designed for OpenAI LLMs:</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure><p id="2a5f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Just as we did with the Gandalf chat object, we use <code class="cx qq qr qs qt b">CachedChatModel</code> to wrap the GPT-4o LLM to enable response caching.</p></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="9849" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(5.6) Define Attacker LLM Objective and System Prompts</h2><p id="a8e5" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">With the attacker LLM ready, we proceed with prompt engineering to define the objective prompt and the attacker system prompt.</p><p id="186a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Because we will use ARTKIT’s multi-turn interaction feature, we need to explicitly specify a separate prompt to describe the attacker LLM’s objective (i.e., make Gandalf reveal its password) so that its responses are well-guided.</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure><blockquote class="ox oy oz"><p id="e1ab" class="nd ne pa nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The objective prompt is saved as a dictionary in a list because we can store and use more than one objective for different steps in the pipeline.</p></blockquote><p id="9cbe" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Next, we define the system prompt that guides the attacker LLM’s strategy in extracting passwords. The prompt is crafted such that the attacker LLM devises indirect and creative techniques to mislead Gandalf about the true intent of the inquiry, thereby bypassing its guardrails.</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure><p id="022b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Notice that the system prompt contains the <code class="cx qq qr qs qt b">{objective}</code> parameter in which the objective prompt will be dynamically injected.</p><p id="6363" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Moreover, we need to include the following two dynamic parameters for multi-turn interactions to happen:</p><ul class=""><li id="992c" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qg qh qi bk"><code class="cx qq qr qs qt b">{max_turns}</code>: Maximum turns allowed for the LLM to accomplish the objective, preventing it from engaging in endless conversations.</li><li id="f39d" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><code class="cx qq qr qs qt b">{success_token}</code>: The token to output when the LLM achieves its objective. It serves as a signal to terminate the conversation early.</li></ul></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="13ff" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(5.7) Run Multi-Turn Interactions with Gandalf</h2><p id="504e" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">We are now one step away from initiating our jailbreaking attempts on Gandalf; all that remains is to link the components and execute them.</p><p id="7514" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">ARTKIT’s <code class="cx qq qr qs qt b">run</code> function allows us to orchestrate the execution of a sequence of steps in a processing pipeline and return the result of the executed flow.</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure><p id="f892" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Here is a look at the parameters of <code class="cx qq qr qs qt b">ak.run</code>:</p><ul class=""><li id="6cc3" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qg qh qi bk">The <code class="cx qq qr qs qt b">input</code> parameter accepts the <code class="cx qq qr qs qt b">objectives</code> variable that contains the objective defined in the preceding step.</li><li id="7f8f" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk">The <code class="cx qq qr qs qt b">steps</code>parameter accepts a set of steps to execute, where each step is defined with the <code class="cx qq qr qs qt b">ak.step</code> function. In this case, we only have one <code class="cx qq qr qs qt b">ak.step</code> step to run, which is to conduct multi-turn interactions between the attacker LLM (<code class="cx qq qr qs qt b">challenger_llm</code>) and Gandalf (<code class="cx qq qr qs qt b">target_llm</code>).</li><li id="6a81" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk">In the <code class="cx qq qr qs qt b">ak.step</code> function, we use <code class="cx qq qr qs qt b">ak.multi_turn</code> to orchestrate multi-turn conversations, thereby maintaining the context and conversation history.</li><li id="8272" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk">We also specify the success token (<code class="cx qq qr qs qt b">success_token</code>), the maximum turns (<code class="cx qq qr qs qt b">max_turns</code>), and the attacker LLM system prompt (<code class="cx qq qr qs qt b">attacker_prompt</code>).</li></ul><p id="2152" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Executing the code above kickstarts the multi-turn interactions aimed at breaking through Gandalf’s defenses, with the output saved in <code class="cx qq qr qs qt b">results</code>.</p></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="03b9" class="oc od fq bf oe of og oh oi oj ok ol om nm on oo op nq oq or os nu ot ou ov ow bk">(5.8) View Interaction History and Secret Password</h2><p id="adcf" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">After executing the jailbreak, it is time for us to review the outcome. We run the following helper code to structure the conversation history and output more clearly.</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure><p id="de1f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">And now, the moment of truth! Below is an instance of the interactions between our attacker LLM and Gandalf:</p><figure class="mm mn mo mp mq mr"><div class="nz io l ed"><div class="qu ob l"/></div></figure><p id="a2c5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Through a series of clever prompt techniques (e.g., generating riddles, extracting letters), we successfully extracted the hidden password (i.e., <strong class="nf fr">UNDERGROUND</strong>) despite Gandalf’s best efforts to guard it.</p><blockquote class="ox oy oz"><p id="ded8" class="nd ne pa nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Spoiler: Password for every level can be found <a class="af nc" href="https://www.lakera.ai/blog/who-is-gandalf" rel="noopener ugc nofollow" target="_blank">here</a>.</p></blockquote></div></div></div><div class="ab cb pb pc pd pe" role="separator"><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph pi"/><span class="pf by bm pg ph"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="84ac" class="pj od fq bf oe pk pl gq oi pm pn gt om po pp pq pr ps pt pu pv pw px py pz qa bk">(6) Wrap-up</h1><p id="c1e5" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">In this article, we demonstrated how ARTKIT can be used for automated prompt-based testing of LLM systems to unveil jailbreaking vulnerabilities. Leveraging LLMs’ capabilities for model-based red-teaming offers a powerful means to scale and accelerate the testing of LLM systems.</p><p id="a192" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">While we focused on Level 4 in this showcase, the ARTKIT setup was able to smoothly overcome Levels 1 to 6. Beyond that, human intervention became necessary, involving advanced prompt engineering and parameter adjustments.</p><p id="d99f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">This highlights the importance of combining automation with human-led red-teaming, where automation saves time by identifying basic vulnerabilities, allowing humans to focus on more complex risks.</p><p id="32b5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The integration of human oversight can be tailored to different sophistication levels, ensuring a balanced and comprehensive testing approach.</p><h1 id="5637" class="pj od fq bf oe pk qv gq oi pm qw gt om po qx pq pr ps qy pu pv pw qz py pz qa bk">Before you go</h1><p id="02cf" class="pw-post-body-paragraph nd ne fq nf b go qb nh ni gr qc nk nl nm qd no np nq qe ns nt nu qf nw nx ny fj bk">I welcome you to follow this <a class="af nc" href="https://kennethleungty.medium.com/" rel="noopener">Medium</a> page and visit my <a class="af nc" href="https://github.com/kennethleungty" rel="noopener ugc nofollow" target="_blank">GitHub</a> to stay updated with more engaging and practical content. Meanwhile, have fun red-teaming LLM systems with ARTKIT!</p><ul class=""><li id="d033" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny qg qh qi bk"><a class="af nc" href="https://github.com/kennethleungty/ARTKIT-Gandalf-Challenge" rel="noopener ugc nofollow" target="_blank">View this project’s GitHub Repo</a></li><li id="d029" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><a class="af nc" href="https://github.com/BCG-X-Official/artkit" rel="noopener ugc nofollow" target="_blank">Visit ARTKIT GitHub Repo</a></li><li id="9af1" class="nd ne fq nf b go qj nh ni gr qk nk nl nm ql no np nq qm ns nt nu qn nw nx ny qg qh qi bk"><a class="af nc" href="https://gandalf.lakera.ai/" rel="noopener ugc nofollow" target="_blank">Play Gandalf Challenge</a></li></ul><div class="ra rb rc rd re rf"><a href="https://levelup.gitconnected.com/inside-the-leaked-system-prompts-of-gpt-4-gemini-1-5-claude-3-and-more-4ecb3d22b447?source=post_page-----d2df5f56ece8--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="rg ab ig"><div class="rh ab co cb ri rj"><h2 class="bf fr hw z io rk iq ir rl it iv fp bk">Inside the Leaked System Prompts of GPT-4, Gemini 1.5, and Claude 3</h2><div class="rm l"><h3 class="bf b hw z io rk iq ir rl it iv dx">Unveiling prompts behind the LLMs from OpenAI, Google, and more</h3></div></div><div class="rn l"><div class="ro l rp rq rr rn rs lr rf"/></div></div></a></div><div class="ra rb rc rd re rf"><a href="https://betterprogramming.pub/text-to-audio-generation-with-bark-clearly-explained-4ee300a3713a?source=post_page-----d2df5f56ece8--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="rg ab ig"><div class="rh ab co cb ri rj"><h2 class="bf fr hw z io rk iq ir rl it iv fp bk">Text-to-Audio Generation with Bark, Clearly Explained</h2><div class="rm l"><h3 class="bf b hw z io rk iq ir rl it iv dx">Discover capabilities of Bark, the open-source GenAI text-to-speech model</h3></div></div><div class="rn l"><div class="rt l rp rq rr rn rs lr rf"/></div></div></a></div></div></div></div></div>    
</body>
</html>