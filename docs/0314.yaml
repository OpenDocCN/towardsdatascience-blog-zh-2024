- en: How Fast Is MLX? A Comprehensive Benchmark on 10 Apple Silicon Chips and 3 CUDA
    GPUs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://towardsdatascience.com/how-fast-is-mlx-a-comprehensive-benchmark-on-8-apple-silicon-chips-and-4-cuda-gpus-378a0ae356a0?source=collection_archive---------5-----------------------#2024-02-02](https://towardsdatascience.com/how-fast-is-mlx-a-comprehensive-benchmark-on-8-apple-silicon-chips-and-4-cuda-gpus-378a0ae356a0?source=collection_archive---------5-----------------------#2024-02-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A benchmark of the main operations and layers on MLX, PyTorch MPS and CUDA GPUs.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tristanbilot.medium.com/?source=post_page---byline--378a0ae356a0--------------------------------)[![Tristan
    Bilot](../Images/64c2628ae710042d80ca2ee2feb3da37.png)](https://tristanbilot.medium.com/?source=post_page---byline--378a0ae356a0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--378a0ae356a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--378a0ae356a0--------------------------------)
    [Tristan Bilot](https://tristanbilot.medium.com/?source=post_page---byline--378a0ae356a0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--378a0ae356a0--------------------------------)
    Â·6 min readÂ·Feb 2, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d3887a6e98407c73beb38abfd85ae6c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by author: Example of benchmark on the softmax operation'
  prefs: []
  type: TYPE_NORMAL
- en: In less than two months since its first release, Appleâ€™s ML research teamâ€™s
    latest creation, MLX, has already made significant strides in the ML community.
    It is remarkable to see how quickly the new framework has garnered attention,
    as evidenced by over 12k stars on [GitHub](https://github.com/ml-explore/mlx)
    and a growing community of over 500 members on [Hugging Face](https://huggingface.co/mlx-community)
    ðŸ¤—.
  prefs: []
  type: TYPE_NORMAL
- en: In a [previous article](https://medium.com/towards-data-science/mlx-vs-mps-vs-cuda-a-benchmark-c5737ca6efc9),
    we demonstrated how MLX performs in training a simple Graph Convolutional Network
    (GCN), benchmarking it against various devices including **CPU**, PyTorchâ€™s [**MPS**](https://pytorch.org/docs/stable/notes/mps.html),
    and **CUDA** **GPUs**. The results were enlightening and showed the potential
    of MLX in running models efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: In this exploration, we delve deeper, setting out to benchmark multiple key
    operations commonly leveraged in neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Test bed
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our benchmark, each operation is evaluated based on a variety of experiments,
    varying in input shape and size. Weâ€™ve run these sequentially and multiple times
    across different processes to ensure stable and reliable runtime measures.
  prefs: []
  type: TYPE_NORMAL
