<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Easily Deploy a Local Generative Search Engine Using VerifAI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Easily Deploy a Local Generative Search Engine Using VerifAI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-easily-deploy-a-local-generative-search-engine-using-verifai-cdf9dedf53c0?source=collection_archive---------4-----------------------#2024-11-21">https://towardsdatascience.com/how-to-easily-deploy-a-local-generative-search-engine-using-verifai-cdf9dedf53c0?source=collection_archive---------4-----------------------#2024-11-21</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="43ea" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">An open-source initiative to help you deploy generative search based on your local files and self-hosted (Mistral, Llama 3.x) or commercial LLM models (GPT4, GPT4o, etc.)</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://datawarrior.medium.com/?source=post_page---byline--cdf9dedf53c0--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Nikola Milosevic (Data Warrior)" class="l ep by dd de cx" src="../Images/ebea6501c00030561a59a4a12ab7a79a.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/0*XSmifXlC__XRUMiB.jpg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--cdf9dedf53c0--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://datawarrior.medium.com/?source=post_page---byline--cdf9dedf53c0--------------------------------" rel="noopener follow">Nikola Milosevic (Data Warrior)</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--cdf9dedf53c0--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 21, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">3</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="8d49" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">I have previously written about <a class="af nf" rel="noopener" target="_blank" href="/how-to-build-a-generative-search-engine-for-your-local-files-using-llama-3-399551786965">building your own simple generative search</a>, as well as on the <a class="af nf" rel="noopener" target="_blank" href="/verifai-project-open-source-biomedical-question-answering-with-verified-answers-5417cd9003e0">VerifAI project</a> on Towards Data Science. However, there has been a major update worth revisiting. Initially, VerifAI was developed as a biomedical generative search with referenced and AI-verified answers. This version is still available, and we now call it <strong class="ml fr">VerifAI BioMed</strong>. It can be accessed here: <a class="af nf" href="https://app.verifai-project.com/" rel="noopener ugc nofollow" target="_blank">https://app.verifai-project.com/</a>.</p><p id="b40e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">The major update, however, is that you can now index your local files and turn them into your own generative search engine </strong>(or productivity engine, as some refer to these systems based on GenAI). It can serve also as an enterprise or organizational generative search. We call this version <strong class="ml fr">VerifAI Core</strong>, as it serves as the foundation for the other version. In this article, we will explore how you can in a few simple steps, deploy it and start using it. Given that it has been written in Python, it can be run on any kind of operating system.</p><h1 id="99e6" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Architecture</h1><p id="8085" class="pw-post-body-paragraph mj mk fq ml b go oc mn mo gr od mq mr ms oe mu mv mw of my mz na og nc nd ne fj bk">The best way to describe a generative search engine is by breaking it down into three parts (or components, in our case):</p><ul class=""><li id="d97d" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne oh oi oj bk">Indexing</li><li id="a608" class="mj mk fq ml b go ok mn mo gr ol mq mr ms om mu mv mw on my mz na oo nc nd ne oh oi oj bk">Retrieval-Augmented Generation (RAG) Method</li><li id="4606" class="mj mk fq ml b go ok mn mo gr ol mq mr ms om mu mv mw on my mz na oo nc nd ne oh oi oj bk">VerifAI contains an additional component, which is a verification engine, on top of the usual generative search capabilities</li></ul><p id="f6a4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Indexing in VerifAI can be done by pointing its indexer script to a local folder containing files such as PDF, MS Word, PowerPoint, Text, or Markdown (.md). The script reads and indexes these files. Indexing is performed in dual mode, utilizing both lexical and semantic indexing.</p><p id="0e81" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For lexical indexing, VerifAI uses <strong class="ml fr">OpenSearch</strong>. For semantic indexing, it vectorizes chunks of the documents using an embedding model specified in the configuration file (models from <strong class="ml fr">Hugging Face</strong> are supported) and then stores these vectors in <strong class="ml fr">Qdrant</strong>. A visual representation of this process is shown in the diagram below.</p><figure class="os ot ou ov ow ox op oq paragraph-image"><div role="button" tabindex="0" class="oy oz ed pa bh pb"><div class="op oq or"><img src="../Images/5d23755d1cc6f35287d4b9a18ce08121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fEIGk8a_e-wOoKBB-XCvBw.png"/></div></div><figcaption class="pd pe pf op oq pg ph bf b bg z dx">Architecture of indexing (diagram by author)</figcaption></figure><p id="c198" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">When it comes to answering questions using VerifAI, the method is somewhat complex. User questions, written in natural language, undergo preprocessing (e.g., stopwords are excluded) and are then transformed into queries.</p><p id="e82b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For <strong class="ml fr">OpenSearch</strong>, only lexical processing is performed (e.g., excluding stopwords), and the most relevant documents are retrieved. For <strong class="ml fr">Qdrant</strong>, the query is transformed into embeddings using the same model that was used to embed document chunks when they were stored in Qdrant. These embeddings are then used to query Qdrant, retrieving the most similar documents based on <strong class="ml fr">dot product similarity</strong>. The dot product is employed because it accounts for both the angle and magnitude of the vectors.</p><p id="a554" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Finally, the results from the two engines must be merged. This is done by normalizing the retrieval scores from each engine to values between 0 and 1 (achieved by dividing each score by the highest score from its respective engine). Scores corresponding to the same document are then added together and sorted by their combined score in descending order.</p><p id="c0b9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Using the retrieved documents, a prompt is built. The prompt contains instructions, the top documents, and the user’s question. This prompt is then passed to the large language model of choice (which can be specified in the configuration file, or, if no model is set, defaults to our locally deployed fine-tuned version of Mistral). Finally, a verification model is applied to ensure there are no hallucinations, and the answer is presented to the user through the GUI. The schematic of this process is shown in the image below.</p><figure class="os ot ou ov ow ox op oq paragraph-image"><div role="button" tabindex="0" class="oy oz ed pa bh pb"><div class="op oq pi"><img src="../Images/2be84f495093fd14b2f9ef63f0548f71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dtgu1vA6U5d94yGNdsY-mg.png"/></div></div><figcaption class="pd pe pf op oq pg ph bf b bg z dx">Architecture of retrieval, generation, and verification (image by author). The model is based on the combination of the following papers: <a class="af nf" href="https://arxiv.org/pdf/2407.11485" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2407.11485</a>, <a class="af nf" href="https://aclanthology.org/2024.bionlp-1.44/" rel="noopener ugc nofollow" target="_blank">https://aclanthology.org/2024.bionlp-1.44/</a></figcaption></figure><h1 id="ab59" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Installing the necessary libraries</h1><p id="4e90" class="pw-post-body-paragraph mj mk fq ml b go oc mn mo gr od mq mr ms oe mu mv mw of my mz na og nc nd ne fj bk">To install VerifAI Generative Search, you can start by cloning the latest codebase from GitHub or using one of the available releases.</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="109f" class="pn nh fq pk b bg po pp l pq pr">git clone https://github.com/nikolamilosevic86/verifAI.git</span></pre><p id="605c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">When installing VerifAI Search, it is recommended to start by creating a clean Python environment. I have tested it with Python 3.6, but it should work with most Python 3 versions. However, Python 3.10+ may encounter compatibility issues with certain dependencies.</p><p id="eca1" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To create a Python environment, you can use the <code class="cx ps pt pu pk b">venv</code> library as follows:</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="246d" class="pn nh fq pk b bg po pp l pq pr">python -m venv verifai<br/>source verifai/bin/activate<br/></span></pre><p id="ca2d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">After activating the environment, you can install the required libraries. The requirements file is located in the<strong class="ml fr"> </strong><code class="cx ps pt pu pk b">verifAI/backend</code><strong class="ml fr"> </strong>directory<strong class="ml fr">.</strong> You can run the following command to install all the dependencies:</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="952f" class="pn nh fq pk b bg po pp l pq pr">pip install -r requirements.txt</span></pre><h1 id="3671" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Configuring system</h1><p id="229a" class="pw-post-body-paragraph mj mk fq ml b go oc mn mo gr od mq mr ms oe mu mv mw of my mz na og nc nd ne fj bk">The next step is configuring VerifAI and its interactions with other tools. This can be done either by setting environment variables directly or by using an environment file (the preferred option).</p><p id="4392" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">An example of an environment file for VerifAI is provided in the <code class="cx ps pt pu pk b">backend</code> folder as <code class="cx ps pt pu pk b">.env.local.example</code>. You can rename this file to <code class="cx ps pt pu pk b">.env</code>, and the VerifAI backend will automatically read it. The file structure is as follows:</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="04c0" class="pn nh fq pk b bg po pp l pq pr">SECRET_KEY=6293db7b3f4f67439ad61d1b798242b035ee36c4113bf870<br/>ALGORITHM=HS256<br/><br/>DBNAME=verifai_database<br/>USER_DB=myuser<br/>PASSWORD_DB=mypassword<br/>HOST_DB=localhost<br/><br/>OPENSEARCH_IP=localhost<br/>OPENSEARCH_USER=admin<br/>OPENSEARCH_PASSWORD=admin<br/>OPENSEARCH_PORT=9200<br/>OPENSEARCH_USE_SSL=False<br/><br/>QDRANT_IP=localhost<br/>QDRANT_PORT=6333<br/>QDRANT_API=8da7625d78141e19a9bf3d878f4cb333fedb56eed9097904b46ce4c33e1ce085<br/>QDRANT_USE_SSL=False<br/><br/>OPENAI_PATH=&lt;model-deployment-path&gt;<br/>OPENAI_KEY=&lt;model-deployment-key&gt;<br/>OPENAI_DEPLOYMENT_NAME=&lt;name-of-model-deployment&gt;<br/>MAX_CONTEXT_LENGTH=128000<br/><br/>USE_VERIFICATION = True<br/><br/>EMBEDDING_MODEL="sentence-transformers/msmarco-bert-base-dot-v5"<br/><br/>INDEX_NAME_LEXICAL = 'myindex-lexical'<br/>INDEX_NAME_SEMANTIC = "myindex-semantic"</span></pre><p id="976f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Some of the variables are quite straightforward. The first Secret key and Algorithm are used for communication between the frontend and the backend.</p><p id="1c44" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Then there are variables configuring access to the <strong class="ml fr">PostgreSQL</strong> database. It needs the database name (<strong class="ml fr">DBNAME</strong>), username, password, and host address where the database is located. In our case, it is on localhost, on the docker image.</p><p id="3333" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The next section is the configuration of <strong class="ml fr">OpenSearch</strong> access. There is IP (localhost in our case again), username, password, port number (default port is 9200), and variable defining whether to use SSL.</p><p id="ec4a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A similar configuration section has <strong class="ml fr">Qdrant</strong>, just for Qdrant, we use an API key, which has to be here defined.</p><p id="7e66" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The next section defined the generative model. VerifAI uses the OpenAI python library, which became the industry standard, and allows it to use both <strong class="ml fr">OpenAI API, Azure API</strong>, <strong class="ml fr">and user deployments via vLLM, OLlama, or </strong><a class="af nf" href="https://developer.nvidia.com/nim" rel="noopener ugc nofollow" target="_blank"><strong class="ml fr">Nvidia NIMs</strong></a><strong class="ml fr">.</strong> The user needs to define the path to the interface, API key, and model deployment name that will be used. We are soon adding support where users can modify or change the prompt that is used for generation. In case no path to an interface is provided and no key, the model will download the Mistral 7B model, with the QLoRA adapter that we have fine-tuned, and deploy it locally. However, in case you do not have enough GPU RAM, or RAM in general, this may fail, or work terribly slowly.</p><p id="6fdd" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">You can set also <strong class="ml fr">MAX_CONTEXT_LENGTH</strong>, in this case it is set to 128,000 tokens, as that is context size of GPT4o. The context length variable is used to build context. Generally, it is built by putting in instruction about answering question factually, with references, and then providing retrieved relevant documents and question. However, documents can be large, and exceed context length. If this happens, the documents are splitted in chunks and top n chunks that fit into the context size will be used to context.</p><p id="6445" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The next part contains the HuggingFace name of the model that is used for embeddings of documents in Qdrant. Finally, there are names of indexes both in OpenSearch (<strong class="ml fr">INDEX_NAME_LEXICAL</strong>) and Qdrant (<strong class="ml fr">INDEX_NAME_SEMANTIC</strong>).</p><p id="8e33" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">As we previously said, VerifAI has a component that verifies whether the generated claim is based on the provided and referenced document. However, this can be turned on or off, as for some use-cases this functionality is not needed. One can turn this off by setting <strong class="ml fr">USE_VERIFICATION</strong> to False.</p><h1 id="91c7" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Installing datastores</h1><p id="fcfd" class="pw-post-body-paragraph mj mk fq ml b go oc mn mo gr od mq mr ms oe mu mv mw of my mz na og nc nd ne fj bk">The final step of the installation is to run the <code class="cx ps pt pu pk b">install_datastores.py</code> file. Before running this file, you need to install Docker and ensure that the Docker daemon is running. As this file reads configuration for setting up the user names, passwords, or API keys for the tools it is installing, it is necessary to first make a configuration file. This is explained in the next section.</p><p id="90a5" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This script sets up the necessary components, including OpenSearch, Qdrant, and PostgreSQL, and creates a database in PostgreSQL.</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="f927" class="pn nh fq pk b bg po pp l pq pr">python install_datastores.py</span></pre><p id="35dc" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Note that this script installs Qdrant and OpenSearch without SSL certificates, and the following instructions assume SSL is not required. If you need SSL for a production environment, you will need to configure it manually.</p><p id="df0a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Also, note that we are talking about local installation on docker here. If you already have Qdrant and OpenSearch deployed, you can simply update the configuration file to point to those instances.</p><h1 id="75bc" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Indexing files</h1><p id="7c56" class="pw-post-body-paragraph mj mk fq ml b go oc mn mo gr od mq mr ms oe mu mv mw of my mz na og nc nd ne fj bk">This configuration is used by both the indexing method and the backend service. Therefore, it must be completed before indexing. Once the configuration is set up, you can run the indexing process by pointing <strong class="ml fr">index_files.py</strong> to the folder containing the files to be indexed:</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="33eb" class="pn nh fq pk b bg po pp l pq pr">python index_files.py &lt;path-to-directory-with-files&gt;</span></pre><p id="3f9f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We have included a folder called <strong class="ml fr">test_data</strong> in the repository, which contains several test files (primarily my papers and other past writings). You can replace these files with your own and run the following:</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="6421" class="pn nh fq pk b bg po pp l pq pr">python index_files.py test_data</span></pre><p id="1135" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This would run indexing over all files in that folder and its subfolders. Once finished, one can run VerifAI services for backend and frontend.</p><h1 id="7d63" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Running the generative search</h1><p id="cc39" class="pw-post-body-paragraph mj mk fq ml b go oc mn mo gr od mq mr ms oe mu mv mw of my mz na og nc nd ne fj bk">The backend of VerifAI can be run simply by running:</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="0c4d" class="pn nh fq pk b bg po pp l pq pr">python main.py</span></pre><p id="4daf" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This will start the FastAPI service that would act as a backend, and pass requests to OpenSearch, and Qdrant to retrieve relevant files for given queries and to the deployment of LLM for generating answers, as well as utilize the local model for claim verification.</p><p id="cd0b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Frontend is a folder called client-gui/verifai-ui and is written in React.js, and therefore would need a local installation of Node.js, and npm. Then you can simply install dependencies by running npm install and run the front end by running npm start:</p><pre class="os ot ou ov ow pj pk pl bp pm bb bk"><span id="5696" class="pn nh fq pk b bg po pp l pq pr">cd ..<br/>cd client-gui/verifai-ui<br/>npm install<br/>npm start</span></pre><p id="1ad0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Finally, things should look somehow like this:</p><figure class="os ot ou ov ow ox op oq paragraph-image"><div role="button" tabindex="0" class="oy oz ed pa bh pb"><div class="op oq pv"><img src="../Images/5e50d230e27c2b95425ca2d3766d55d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VkF7TdwhzqwvKMZZgD4tdQ.png"/></div></div><figcaption class="pd pe pf op oq pg ph bf b bg z dx">One of the example questions, with verification turned on (note text in green) and reference to the file, which can be downloaded (screenshot by author)</figcaption></figure><figure class="os ot ou ov ow ox op oq paragraph-image"><div role="button" tabindex="0" class="oy oz ed pa bh pb"><div class="op oq pw"><img src="../Images/dbfa4e8ee9292aac605f14c577b144db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUqL70I6ZF2ERps8UPtQdw.png"/></div></div><figcaption class="pd pe pf op oq pg ph bf b bg z dx">Screenshot showcasing tooltip of the verified claim, with the most similar sentence from the article presented (screenshot by author)</figcaption></figure><h1 id="36ea" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Contributing and future direction</h1><p id="f154" class="pw-post-body-paragraph mj mk fq ml b go oc mn mo gr od mq mr ms oe mu mv mw of my mz na og nc nd ne fj bk">So far, VerifAI has been started with the help of funding from the Next Generation Internet Search project as a subgrant of the European Union. It was started as a collaboration between The Institute for Artificial Intelligence Research and Development of Serbia and Bayer A.G.. The first version has been developed as a generative search engine for biomedicine. This product will continue to run at <a class="af nf" href="https://app.verifai-project.com/" rel="noopener ugc nofollow" target="_blank">https://app.verifai-project.com/</a>. However, lately, we decided to expand the project, so it can truly become an open-source generative search with verifiable answers for any files, that can be leveraged openly by different enterprises, small and medium companies, non-governmental organizations, or governments. These modifications have been developed by Natasa Radmilovic and me voluntarily (huge shout out to Natasa!).</p><p id="49f4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">However, given this is an open-source project, available on GitHub (<a class="af nf" href="https://github.com/nikolamilosevic86/verifAI" rel="noopener ugc nofollow" target="_blank">https://github.com/nikolamilosevic86/verifAI</a>), we are welcoming contributions by anyone, via pull requests, bug reports, feature requests, discussions, or anything else you can contribute with (feel free to get in touch — for both BioMed and Core (document generative search, as described here) versions website will remain the same — <a class="af nf" href="https://verifai-project.com" rel="noopener ugc nofollow" target="_blank">https://verifai-project.com</a>). So we welcome you to contribute, start our project, and follow us in the future.</p></div></div></div></div>    
</body>
</html>