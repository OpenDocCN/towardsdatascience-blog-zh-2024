- en: How to practice data analyst interviews with AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-practice-data-analyst-interviews-with-ai-e933a027e609?source=collection_archive---------12-----------------------#2024-08-12](https://towardsdatascience.com/how-to-practice-data-analyst-interviews-with-ai-e933a027e609?source=collection_archive---------12-----------------------#2024-08-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using LLMs to generate synthetic data and code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mathewnxwang?source=post_page---byline--e933a027e609--------------------------------)[![Mathew
    Wang](../Images/487d76ba764d66af4f4bdd72f395d58f.png)](https://medium.com/@mathewnxwang?source=post_page---byline--e933a027e609--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e933a027e609--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e933a027e609--------------------------------)
    [Mathew Wang](https://medium.com/@mathewnxwang?source=post_page---byline--e933a027e609--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e933a027e609--------------------------------)
    ·8 min read·Aug 12, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/94cdfdd742c1f83f94ea057bf6d28d57.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Scott Graham](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Intro
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I’ve been working on weekend LLM projects. When contemplating what to work
    on, two ideas struck me:'
  prefs: []
  type: TYPE_NORMAL
- en: '**There are few resources for practicing data analytics interviews** in contrast
    to other roles like software engineering and product management. I relied on friends
    in the industry to make up SQL and Python interview questions when I practiced
    interviewing for my first data analyst job.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**LLMs are really good at generating synthetic datasets and writing code.**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As a result, I’ve built the **AI Data Analysis Interviewer** which automatically
    creates a unique dataset and generates Python interview questions for you to solve!
  prefs: []
  type: TYPE_NORMAL
- en: This article provides an overview of how it works and its technical implementation.
    You can check out the repo [here](https://github.com/mathewnxwang/data_analysis_interview_tool/tree/main).
  prefs: []
  type: TYPE_NORMAL
- en: Demo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When I launch the web app I’m prompted to provide details on the type of interview
    I want to practice for, specifically the company and a dataset description. Let’s
    say I’m interviewing for a data analyst role at Uber which focuses on analyzing
    ride data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/75aed9c03ef8ff4d364477cc0e47299a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After clicking Submit and waiting for GPT to do its magic, I receive the AI
    generated questions, answers, and an input field where I can execute code on the
    AI generated dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e18b8f7b3ee76ed23e2a78d99c3ab8a6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Awesome! Let’s try to solve the first question: calculate the total distance
    traveled each day. As is good analytics practice, let’s start with data exploration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/73dcc32b41105c3c97ecd042f74041a4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It looks like we need to group by the ride_date field and sum the distance_miles
    field. Let’s write and submit that Pandas code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a541d03751698530798f9994483d4862.png)'
  prefs: []
  type: TYPE_IMG
- en: Looks good to me! Does the AI answer agree with our approach?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f4c0dda442a99b7a9183da79e71dc9d4.png)'
  prefs: []
  type: TYPE_IMG
- en: The AI answer uses a slightly different methodology but solves the problem essentially
    in the same way.
  prefs: []
  type: TYPE_NORMAL
- en: 'I can rinse and repeat as much as needed to feel great before heading into
    an interview. Interviewing for Airbnb? This tool has you covered. It generates
    the questions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4cc47cd2ff09cdba93d2765d1d7d09c3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Along with a dataset you can execute code on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2fffe8f5b44a4c0ab747bc7cf4ab41a2.png)'
  prefs: []
  type: TYPE_IMG
- en: How to use the app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Check out the readme of the repo [here](https://github.com/mathewnxwang/data_analysis_interview_tool/blob/main/README.md#how-to-run)
    to run the app locally. Unfortunately I didn’t host it but I might in the future!
  prefs: []
  type: TYPE_NORMAL
- en: High-level design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The rest of this article will cover the technical details on how I created the
    AI Data Analysis Interviewer.
  prefs: []
  type: TYPE_NORMAL
- en: LLM architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I used OpenAI’s gpt-4o as it’s currently my go-to LLM model (it’s pretty easy
    to swap this out with another model though.)
  prefs: []
  type: TYPE_NORMAL
- en: 'There are 3 types of LLM calls made:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset generation**: we ask a LLM to generate a dataset suitable for an
    analytics interview.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Question generation**: we ask a LLM to generate a couple of analytics interview
    questions from that dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Answer generation**: we ask a LLM to generate the answer code for each interview
    question.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Front-end
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I built the front-end using Flask. It’s simple and not very interesting so I’ll
    focus on the LLM details below. Feel free to check out [the code in the repo](https://github.com/mathewnxwang/data_analysis_interview_tool/tree/main)
    however!
  prefs: []
  type: TYPE_NORMAL
- en: Design details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LLM manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMManager is a simple class which handles making LLM API calls. It gets our
    OpenAI API key from a local secrets file and makes an OpenAI API call to pass
    a prompt to a LLM model. You’ll see some form of this in every LLM project.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Dataset generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here is where the fun starts!
  prefs: []
  type: TYPE_NORMAL
- en: 'We first prompt a LLM to generate a dataset with the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s break it down:'
  prefs: []
  type: TYPE_NORMAL
- en: Many LLM models follow a prompt structure where the LLM accepts a system and
    user message. The system message is intended to define general behavior and the
    user message is intended to provide specific instructions. Here we prompt the
    LLM to be a world class interviewer in the system message. It feels silly but
    hyping up a LLM is a proven prompt hack to get better performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We pass the user inputs about the company and dataset they want to practice
    interviewing with into the user template through the string variables {company}
    and {description}.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We prompt the LLM to output data in csv format. This seems like the simplest
    tabular data format for a LLM to produce which we can later convert to a Pandas
    DataFrame for code analysis. JSON would also probably work but may be less reliable
    given the more complex and verbose syntax.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want the LLM output to be parseable csv, but gpt-4o tends to generate extra
    text likely because it was trained to be very helpful. The end of the user template
    strongly instructs the LLM to just output parseable csv data, but even so we need
    to post-process it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The class DataGenerator handles all things data generation and contains the
    generate_interview_dataset method which makes the LLM call to generate the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that the clean_llm_dataset_output method does the light post-processing
    mentioned above. It removes any extraneous text before “id,” which denotes the
    start of the csv data.
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs only can output strings so we need to transform the string output into
    an analyzable Pandas DataFrame. The convert_str_to_df method takes care of that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Question generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can prompt a LLM to generate interview questions off of the generated dataset
    with the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To break it down once again:'
  prefs: []
  type: TYPE_NORMAL
- en: The same system prompt is used here as we still want the LLM to embody a world-class
    interviewer when writing the interview questions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The string output from the dataset generation call is passed into the {dataset}
    string variable. Note that we have to maintain 2 representations of the dataset:
    1\. a string representation that a LLM can understand to generate questions and
    answers and 2\. a structured representation (i.e. DataFrame) that we can execute
    code over.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We prompt the LLM to return a list. We need the output to be structured so we
    can iterate over the questions in the answer generation step to generate an answer
    for every question.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The LLM call is made with the generate_interview_questions method of DataGenerator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Answer generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With both the dataset and the questions available, we finally generate the
    answers with the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We make as many answer generation LLM calls as there are questions, so 3 since
    we hard coded the question generation prompt to ask for 3 questions. Technically
    you could ask a LLM to generate all 3 answers for all 3 questions in 1 call but
    I suspect that performance would worsen. We want the maximize the ability of the
    LLM to generate accurate answers. A (perhaps obvious) rule of thumb is that the
    harder the task given to a LLM, the less likely the LLM will perform it well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The prompt instructs the LLM to refer to the dataset as “df” because our interview
    dataset in DataFrame form is called “df” when the user code is executed by the
    CodeExecutor class below.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope this article sheds light on how to build a simple and useful LLM project
    which utilizes LLMs in a variety of ways!
  prefs: []
  type: TYPE_NORMAL
- en: 'If I continued to develop this project, I would focus on:'
  prefs: []
  type: TYPE_NORMAL
- en: Adding more validation on structured output from LLMs (i.e. parseable csv or
    lists). I already covered a couple of edge cases but LLMs are very unpredictable
    so this needs hardening.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 2\. Adding more features like
  prefs: []
  type: TYPE_NORMAL
- en: Generating multiple relational tables and questions requiring joins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL interviews in addition to Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom dataset upload
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difficulty setting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
