- en: 'The New Frontiers of LLMs: Challenges, Solutions, and Tools'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-new-frontiers-of-llms-challenges-solutions-and-tools-b1d48c34cf8e?source=collection_archive---------2-----------------------#2024-01-25](https://towardsdatascience.com/the-new-frontiers-of-llms-challenges-solutions-and-tools-b1d48c34cf8e?source=collection_archive---------2-----------------------#2024-01-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://towardsdatascience.medium.com/?source=post_page---byline--b1d48c34cf8e--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page---byline--b1d48c34cf8e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b1d48c34cf8e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b1d48c34cf8e--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page---byline--b1d48c34cf8e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b1d48c34cf8e--------------------------------)
    ·Sent as a [Newsletter](/newsletter?source=post_page---byline--b1d48c34cf8e--------------------------------)
    ·3 min read·Jan 25, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Large language models have been around for several years, but it wasn’t until
    2023 that their presence became truly ubiquitous both within and outside machine
    learning communities. Previously opaque concepts like fine-tuning and RAG have
    gone mainstream, and companies big and small have been either building or integrating
    LLM-powered tools into their workflows.
  prefs: []
  type: TYPE_NORMAL
- en: As we look ahead at what 2024 might bring, it seems all but certain that these
    models’ footprint is poised to grow further, and that alongside exciting innovations,
    they’ll also generate new challenges for practitioners. The standout posts we’re
    highlighting this week point at some of these emerging aspects of working with
    LLMs; whether you’re relatively new to the topic or have already experimented
    extensively with these models, you’re bound to find something here to pique your
    curiosity.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Democratizing LLMs: 4-bit Quantization for Optimal LLM Inference**](/democratizing-llms-4-bit-quantization-for-optimal-llm-inference-be30cf4e0e34)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantization is one of the main approaches for making the power of massive models
    accessible to a wider user base of ML professionals, many of whom might not have
    access to limitless memory and compute. [Wenqi Glantz](https://medium.com/u/ce7cd5b8b74a?source=post_page---user_mention--b1d48c34cf8e--------------------------------)
    walks us through the process of quantizing the Mistral-7B-Instruct-v0.2 model,
    and explains this method’s inherent tradeoffs between efficiency and performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Navigating the World of LLM Agents: A Beginner’s Guide**](/navigating-the-world-of-llm-agents-a-beginners-guide-3b8d499db7a9)How
    can we get LLMs “to the point where they can solve more complex questions on their
    own?” [Dominik Polzer](https://medium.com/u/3ab8d3143e32?source=post_page---user_mention--b1d48c34cf8e--------------------------------)’s
    accessible primer shows how to build LLM agents that can leverage disparate tools
    and functionalities to automate complex workflows with minimal human intervention.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/41f848543855fdc6762d8c38848f6b66.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Beth Macdonald](https://unsplash.com/@elsbethcat?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[**Leverage KeyBERT, HDBSCAN and Zephyr-7B-Beta to Build a Knowledge Graph**](/leverage-keybert-hdbscan-and-zephyr-7b-beta-to-build-a-knowledge-graph-33d7534ee01b)LLMs
    are very powerful on their own, of course, but their potential becomes even more
    striking when combined with other approaches and tools. [Silvia Onofrei](https://medium.com/u/ab562e798558?source=post_page---user_mention--b1d48c34cf8e--------------------------------)’s
    recent guide on building a knowledge graph with the aid of the Zephyr-7B-Beta
    model is a case in point; it demonstrates how bringing together LLMs and traditional
    NLP methods can produce impressive results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Merge Large Language Models with mergekit**](/merge-large-language-models-with-mergekit-2118fb392b54)As
    unlikely as it may sound, sometimes a single LLM might not be enough for your
    project’s specific needs. As [Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page---user_mention--b1d48c34cf8e--------------------------------)
    shows in his latest tutorial, model merging, a “relatively new and experimental
    method to create new models for cheap,” might just be the solution for those moments
    when you need to mix-and-match elements from multiple models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Does Using an LLM During the Hiring Process Make You a Fraud as a Candidate?**](/does-using-an-llm-during-the-hiring-process-make-you-a-fraud-as-a-candidate-99a05678536b)The
    types of questions LLMs raise go beyond the technical—they also touch on ethical
    and social issues that can get quite thorny. [Christine Egan](https://medium.com/u/8e9b4d1cb38?source=post_page---user_mention--b1d48c34cf8e--------------------------------)
    focuses on the stakes for job candidates who take advantage of LLMs and tools
    like ChatGPT as part of the job search, and explores the sometimes blurry line
    between using and misusing technology to streamline tedious tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As always, the range and depth of topics our authors covered in recent weeks
    is staggering—here’s a representative sample of must-reads:'
  prefs: []
  type: TYPE_NORMAL
- en: Going beyond LLMs, [Nate Cibik](https://medium.com/u/82bf2304955e?source=post_page---user_mention--b1d48c34cf8e--------------------------------)
    dives deep into the emerging world of large *multimodal* models (LMMs) and [how
    they’re shaping the autonomous robotics](/navigating-the-future-62ea60f27046)
    field.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a new project walkthrough, [Christabelle Pabalan](https://medium.com/u/4200eb8e8b26?source=post_page---user_mention--b1d48c34cf8e--------------------------------)
    combines [NLP techniques, feature engineering, and visualization](/evaluating-cinematic-dialogue-which-syntactic-and-semantic-features-are-predictive-of-genre-2c69a71af6e2)
    to assess the links between the semantic attributes of movie dialogue and genre.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Where is temporal graph learning headed this year](/temporal-graph-learning-in-2024-feaa9371b8e2)?
    [Shenyang(Andy) Huang](https://medium.com/u/8aa224c5cedd?source=post_page---user_mention--b1d48c34cf8e--------------------------------)
    and coauthors Emanuele Rossi, [Michael Galkin](https://medium.com/u/4d4f8ddd1e68?source=post_page---user_mention--b1d48c34cf8e--------------------------------),
    Andrea Cini, and Ingo Scholtesoffer a panoramic overview of the field’s trajectory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Causal inference is an essential concept for all data professionals, but its
    meaning can vary depending on your role. [Zijing Zhu, PhD](https://medium.com/u/7d83c09fb5d4?source=post_page---user_mention--b1d48c34cf8e--------------------------------)
    zooms in on [how these differences play out in academia and in industry](/how-is-causal-inference-different-in-academia-and-industry-fb5afd12e2e7).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diffusion has made a splash in recent years in the context of AI-generated images,
    but as [Christopher Landschoot](https://medium.com/u/b64548f914a5?source=post_page---user_mention--b1d48c34cf8e--------------------------------)
    shows, [its potential extends to the world of music and audio generation](/audio-diffusion-generative-musics-secret-sauce-f625d0aca800)
    as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thank you for supporting the work of our authors! If you’re feeling inspired
    to join their ranks, why not [write your first post? We’d love to read it](http://bit.ly/write-for-tds).
  prefs: []
  type: TYPE_NORMAL
- en: Until the next Variable,
  prefs: []
  type: TYPE_NORMAL
- en: TDS Team
  prefs: []
  type: TYPE_NORMAL
