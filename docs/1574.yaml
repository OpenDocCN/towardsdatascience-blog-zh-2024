- en: Making LLMs Write Better and Better Code for Self-Driving Using LangProp
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/making-llms-write-better-and-better-code-for-self-driving-using-langprop-99c6c3dc9508?source=collection_archive---------4-----------------------#2024-06-25](https://towardsdatascience.com/making-llms-write-better-and-better-code-for-self-driving-using-langprop-99c6c3dc9508?source=collection_archive---------4-----------------------#2024-06-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Analogy from classical machine learning: LLM (Large Language Model) = optimizer;
    code = parameters; LangProp = PyTorch Lightning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[![Shu
    Ishida](../Images/3c2d6092188ab1e0427e63cd0f1fada6.png)](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)
    [Shu Ishida](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)
    ·9 min read·Jun 25, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: You have probably used ChatGPT to write your emails, summarize documents, find
    out information, or help you debug your code. But can we take a step further and
    make ChatGPT drive a car?
  prefs: []
  type: TYPE_NORMAL
- en: This was the question we wanted to answer when I started my internship at [Wayve](https://wayve.ai/)
    in March last year. Wayve is an autonomous driving startup in London, applying
    end-to-end learning to the challenging problem of urban driving. At the time,
    the company was just about to launch its LLM research team, which has since successfully
    developed [LINGO-1](https://wayve.ai/thinking/lingo-natural-language-autonomous-driving/?doing_wp_cron=1718832390.6593759059906005859375)
    and [LINGO-2](https://wayve.ai/thinking/lingo-2-driving-with-language/). [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)
    had just come out, and [Voyager](https://github.com/MineDojo/Voyager) had not
    come out yet. And yet, the disruption caused by LLMs was palpable. The question
    was, how can we use this new technology to driving, a domain where language isn’t
    the main modality?
  prefs: []
  type: TYPE_NORMAL
- en: In this blog post, I would like to give an overview of our paper [**LangProp**](https://arxiv.org/abs/2401.10314),
    which we presented at the LLM Agents workshop at ICLR (the International Conference
    on Learning Representations) last month (May 2024).
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/shuishida/LangProp?source=post_page-----99c6c3dc9508--------------------------------)
    [## GitHub - shuishida/LangProp'
  prefs: []
  type: TYPE_NORMAL
- en: Contribute to shuishida/LangProp development by creating an account on GitHub.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'github.com](https://github.com/shuishida/LangProp?source=post_page-----99c6c3dc9508--------------------------------)
    [](https://arxiv.org/abs/2401.10314?source=post_page-----99c6c3dc9508--------------------------------)
    [## LangProp: A code optimization framework using Large Language Models applied
    to driving'
  prefs: []
  type: TYPE_NORMAL
- en: We propose LangProp, a framework for iteratively optimizing code generated by
    large language models (LLMs), in both…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2401.10314?source=post_page-----99c6c3dc9508--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Motivation: Let’s apply ML to code writing, literally.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The challenge of applying LLMs to driving comes in twofold: firstly, LLMs are,
    as the name says, very large models that require a lot of compute and can be slow
    to run, which makes them not-so-ideal for safety-critical real-time applications,
    such as autonomous driving; secondly, while language is good at high-level descriptions
    and serves as a sophisticated tool for logic, reasoning and planning, it doesn’t
    have the granularity and detail that is needed to describe observations and give
    spatial control actions.'
  prefs: []
  type: TYPE_NORMAL
- en: We realised, however, that we don’t necessarily have to use LLMs for inferring
    driving actions. What we could do instead is to make LLMs write the code for driving
    itself.
  prefs: []
  type: TYPE_NORMAL
- en: If you have ever used ChatGPT to write code then this may sound like a terrible
    idea. The code that it writes seldom works out of the box, and often contains
    some errors. But what if we use LLMs to also detect bugs and automatically fix
    them, thereby iteratively improving the code quality?
  prefs: []
  type: TYPE_NORMAL
- en: We took this idea a step further — instead of just fixing bugs, we designed
    a training framework that allows us to improve the code that the LLM generates
    towards an objective function of your choice. You can “train” your code to improve
    on a training dataset and try to reduce the losses. The code improvements can
    be quantified by running it on a validation dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Does this start to sound like Machine Learning? Because it essentially is! But
    are we fine-tuning the LLM? No — in fact, there is no neural network that is being
    fine-tuned. Instead, we are fine-tuning the code itself!
  prefs: []
  type: TYPE_NORMAL
- en: In LangProp, the “code” is the *parameters* of the model, and the LLM is the
    *optimizer* that guides the *parameters* to improve in the direction that reduces
    the loss. Why is this cool? Because by applying this thinking, we can now automate
    optimization of software themselves in a data-driven way! With deep learning,
    we witnessed the power of data-driven approaches to solving hard-to-describe problems.
    But so far, the application domain of machine learning has been constrained to
    models parametrized by numeric values. Now, they can deal with systems described
    in code, too.
  prefs: []
  type: TYPE_NORMAL
- en: If you have followed the history of Artificial Intelligence, this is an elegant
    way to unify the once popular approach of Symbolic AI with the more modern and
    successful Machine Learning approach. Symbolic AI was about having human experts
    describe a perfect model of the world in the form of logic and code. This had
    its limitations, as many complex tasks (e.g. object recognition) were beyond what
    human experts can feasibly describe with logic alone. Machine Learning, on the
    other hand, lets the data speak for itself and fits a model that best describes
    them in an automated way. This approach has been very successful in a wide range
    of disciplines, including pattern recognition, compression and function approximation.
    However, logic, reasoning, and long-term planning are fields where naively fitting
    a neural network on data often fails. This is because it is challenging to learn
    such complex operations in the modality of neural network parameter space. With
    LLMs and LangProp, we can finally apply the data-driven learning method to learn
    symbolic systems and automate their improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Disclaimer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we dive in further, I feel that some disclaimers are in order.
  prefs: []
  type: TYPE_NORMAL
- en: This work on LangProp was conducted as an internship project at Wayve, and does
    not directly reflect the company’s Research & Development priorities or strategies.
    The purpose of this blog post is to describe LangProp as a paper, and everything
    in this blog post is written in the capacity of myself as an individual.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While we demonstrated LangProp primarily for the case of autonomous driving,
    we also would like to stress its limitations, such as (a) it requires perfect
    observation of the environment, (b) we only made it work in a simulated environment
    and it is far from real-world deployment, (c) the generated driving code is not
    perfect nor sophisticated, and has many issues to be suitable for real-world deployment.
    We see LangProp as a research prototype that showcases the potential of LLMs applied
    to data-driven software optimization, not as a product for deployment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you need further information on the limitations of LangProp, please check
    out the limitation section in the appendix of [our paper](https://arxiv.org/abs/2401.10314).
  prefs: []
  type: TYPE_NORMAL
- en: With that said, let’s take a look at how LangProp works!
  prefs: []
  type: TYPE_NORMAL
- en: How does LangProp work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: …we bring back Symbolic AI and Evolutionary Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/c4ff0907157b6d125d5dc66f17ebb19b.png)'
  prefs: []
  type: TYPE_IMG
- en: An overview of the LangProp trainer. The LLM generates variations of code, which
    is then evaluated on the training dataset. Codes with high scores are kept. The
    LLM is provided with information about the failure modes of the code and rewrites
    them to achieve higher performance on the training metric. (image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: LangProp is designed like PyTorch Lightning — a LangProp module keeps track
    of the *parameters* (collection of scripts) that are trained and used for inference.
    In the training mode, a policy tracker keeps a record of the inputs, outputs,
    and any exceptions during the forward pass. The performance of the code is evaluated
    by an objective function. Based on the scores, the policy tracker re-ranks the
    scripts that currently exist, and passes the top k scripts to the LLM for refinement.
    At inference time, making a prediction is as simple as calling the code with the
    best score.
  prefs: []
  type: TYPE_NORMAL
- en: The LangProp trainer takes a LangProp module to be trained, a training dataset,
    and a validation dataset. The dataset can be any iterable object, including a
    PyTorch Dataset object, which makes applying LangProp to existing tasks easier.
    Once the training is finished, we can save a *checkpoint*, which is the collection
    of refined code along with some statistics for ranking the code.
  prefs: []
  type: TYPE_NORMAL
- en: The mechanism we use to choose the best code and improve them is similar to
    evolutionary algorithms, in which samples are initially chosen randomly, but then
    the ones that are high-performing are kept and perturbed to spawn a new generation
    of fitter samples.
  prefs: []
  type: TYPE_NORMAL
- en: Applying LangProp to driving
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/33980cea1ea0f6899272c51db1fe4d39.png)'
  prefs: []
  type: TYPE_IMG
- en: Overview of the LangProp driving agent in CARLA (image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s try using LangProp to drive in CARLA!
  prefs: []
  type: TYPE_NORMAL
- en: '[CARLA](https://carla.org/) is an open-sourced driving simulator used for autonomous
    driving research. There is a [leaderboard challenge](https://leaderboard.carla.org/)
    to benchmark your self-driving car agent. We tested LangProp on the standard routes
    and towns in this challenge.'
  prefs: []
  type: TYPE_NORMAL
- en: The good thing about formulating LangProp as a Machine Learning framework is
    that, now we can apply not just classic supervised learning but also imitation
    learning and reinforcement learning techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, we start our training on an offline dataset (driving demonstrations
    from an expert that contains state and action pairs), and then perform online
    rollouts. During online rollout, we employ DAgger [1], which is a dataset aggregation
    technique where samples collected by online rollouts are labelled with expert
    labels and aggregated with the current dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The input to the model (the code) is a Python dictionary of the state of the
    environment, including the poses and velocities of the vehicle and surrounding
    actors, and the distances to the traffic light / stop sign. The output is the
    driving action, which is the speed and steering angle at which the vehicle should
    drive.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever there is an infraction, e.g. ignoring a traffic light or stop sign,
    collision with another vehicle, pedestrian or cyclist, or being stationary for
    too long, there is a penality to the performance scores. The training objective
    is to maximize the combined score of imitation learning scores (how well can the
    agent match the ground truth action labels) and the reinforcement learning scores
    (reducing the infraction penalty).
  prefs: []
  type: TYPE_NORMAL
- en: LangProp driving agent in action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now watch the LangProp agent drive!
  prefs: []
  type: TYPE_NORMAL
- en: A LangProp agent driving in CARLA, a driving simulation benchmark (video by
    the author)
  prefs: []
  type: TYPE_NORMAL
- en: We saw during training that, the initial driving policy that ChatGPT generates
    is very faulty. In particular, it often learns a naive policy that copies the
    previous velocity. This is a well-known phenomenon called causal confusion [2]
    in the field of imitation learning. If we just train with behavioral cloning on
    the offline dataset, such naive but simple policies obtain a high score compared
    to other more complex policies. This is why we need to use techniques such as
    DAgger and reinforcement learning to make sure that the policy performs in online
    rollout.
  prefs: []
  type: TYPE_NORMAL
- en: After an iteration or two, the model stops copying the previous velocity and
    starts moving forward, but is either overly cautious (i.e. stops whenever there
    is an actor nearby, even if they are not in collision course), or reckless (driving
    forward until it collides into an actor). After a couple more iterations, the
    model learns to keep a distance from the vehicle in front and even calculates
    this distance dynamically based on the relative velocities of the vehicles. It
    also predicts whether other actors (e.g. J-walking pedestrians) are on collision
    course with the vehicle by looking at the velocity and position vectors.
  prefs: []
  type: TYPE_NORMAL
- en: In the experiments in [our paper](https://arxiv.org/abs/2401.10314), we show
    that the LangProp driving agent outperforms many of the previously implemented
    driving agents. We compare against both a PPO expert agent (Carla-Roach [3], TCP
    [4]) and researcher-implemented expert agents (TransFuser [5], InterFuser [6],
    TF++ [7]), and LangProp outperformed all expert agents except for TF++. All the
    expert agents were published after the GPT 3.5 training cutoff of September 2021,
    so this result is both surprising and exciting!
  prefs: []
  type: TYPE_NORMAL
- en: Closing remark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thank you for joining me on the ride! While in this work we primarily explored
    the application of LangProp to autonomous driving in CARLA, we also showed that
    LangProp can be easily applied to more general problems, such as the typical RL
    environment of CartPole-v1\. LangProp works best in environments or problems where
    feedback on the performance can be obtained in the form of text or code, giving
    the model a richer semantic signal that is more than just numerical scores.
  prefs: []
  type: TYPE_NORMAL
- en: There are endless possible applications of LangProp-like training to iteratively
    improve software based on data, and we are excited to see what will happen in
    this space!
  prefs: []
  type: TYPE_NORMAL
- en: 'If you liked our work, please consider building on top of it and citing our
    paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Stéphane Ross, Geoffrey Gordon, and Drew Bagnell. “A reduction of imitation
    learning and structured prediction to no-regret online learning.” In *Proceedings
    of the fourteenth international conference on artificial intelligence and statistics*,
    *JMLR Workshop and Conference Proceedings*, 2011.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Pim De Haan, Dinesh Jayaraman, and Sergey Levine. “Causal confusion in
    imitation learning”. *Advances in Neural Information Processing Systems*, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Zhejun Zhang, Alexander Liniger, Dengxin Dai, Fisher Yu, and Luc Van Gool.
    “End-to-end urban driving by imitating a reinforcement learning coach.” In P*roceedings
    of the IEEE/CVF international Conference on Computer Vision*, pp. 15222–15232,
    2021.'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Penghao Wu, Xiaosong Jia, Li Chen, Junchi Yan, Hongyang Li, and Yu Qiao.
    “Trajectory-guided control prediction for end-to-end autonomous driving: A simple
    yet strong baseline.” *Advances in Neural Information Processing Systems*, 35:6119–6132,
    2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] Kashyap Chitta, Aditya Prakash, Bernhard Jaeger, Zehao Yu, Katrin Renz,
    and Andreas Geiger. “Transfuser: Imitation with transformer-based sensor fusion
    for autonomous driving.” *IEEE Transactions on Pattern Analysis and Machine Intelligence*,
    2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] Hao Shao, Letian Wang, Ruobing Chen, Hongsheng Li, and Yu Liu. “Safety-enhanced
    autonomous driving using interpretable sensor fusion transformer.” In *Conference
    on Robot Learning*, pp. 726–737\. PMLR, 2023.'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] Jaeger, Bernhard, Kashyap Chitta, and Andreas Geiger. “Hidden biases of
    end-to-end driving models.” *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*. 2023.'
  prefs: []
  type: TYPE_NORMAL
