- en: Improve Your RAG Context Recall by 95% with an Adapted Embedding Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/improve-your-rag-context-recall-by-40-with-an-adapted-embedding-model-5d4a8f583f32?source=collection_archive---------0-----------------------#2024-10-12](https://towardsdatascience.com/improve-your-rag-context-recall-by-40-with-an-adapted-embedding-model-5d4a8f583f32?source=collection_archive---------0-----------------------#2024-10-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Step-by-step model adaptation code and results attached
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@vignesh865?source=post_page---byline--5d4a8f583f32--------------------------------)[![Vignesh
    Baskaran](../Images/52afb4a7a3cd0329dc1ba9d931413788.png)](https://medium.com/@vignesh865?source=post_page---byline--5d4a8f583f32--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5d4a8f583f32--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5d4a8f583f32--------------------------------)
    [Vignesh Baskaran](https://medium.com/@vignesh865?source=post_page---byline--5d4a8f583f32--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5d4a8f583f32--------------------------------)
    ·10 min read·Oct 12, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval-augmented generation (RAG) is one prominent technique employed to
    integrate LLM into business use cases, allowing proprietary knowledge to be infused
    into LLM. This post assumes you already possess knowledge about RAG and you are
    here to improve your RAG accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s review the process briefly. The RAG model consists of two main steps:
    retrieval and generation. In the retrieval step, several sub-steps are involved,
    including converting context text to vectors, indexing the context vector, retrieving
    the context vector for the user query, and reranking the context vector. Once
    the contexts for the query are retrieved, we move on to the generation stage.
    During the generation stage, the contexts are combined with prompts and sent to
    the LLM to generate a response. Before sending to the LLM, the context-infused
    prompts may undergo caching and routing steps to optimize efficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: For each of the pipeline steps, we will conduct numerous experiments to collectively
    enhance RAG accuracy. You can refer to the below image that lists(but is not limited
    to) the experiments performed in each step.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/72472ed36ec30d6d1ab16d6d3dc1b23a.png)'
  prefs: []
  type: TYPE_IMG
